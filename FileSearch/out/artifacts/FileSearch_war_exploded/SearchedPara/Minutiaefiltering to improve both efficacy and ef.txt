 fi ngerprint and out its area. In order to overcome this problem, we use two fi 1. Introduction
Fingerprints are the most used features for biometric identi -cation. Fingerprints are present on the surface of fi ngertips and they are patterns formed of ridges and valleys. Their individuality, which is determined by the local ridge characteristics and their relationships ( Hong et al., 1998 ), makes them appropriate for identi fi cation purposes, since each individual has unique prints. The characteristics or features of a fi ngerprint are usually classi fi ed into three levels ( Maltoni et al., 2009; Feng and Jain, 2011 ):
Level 1 ( Global ) refers to the global ridge line fl ow (orientations) and the features derived from it (singular points).

Level 2 ( Local ) considers minutiae details extracted from the ridge skeleton.

Level 3 ( Fine-detail ) includes intra-ridge details such as width, shape, ridge contours, sweat pores, and creases.

Level 2 features (minutiae) are the most commonly used ones for fi ngerprint matching ( Jiang and Yau, 2000; Deng and Huo, 2005; Chen et al., 2006; Cappelli et al., 2010 ), that is, to check whether two fi ngerprints belong to the same individual. Notice that neither Level 1 features nor Level 3 features are usually considered for matching. The former ones because of their distinctiveness are not suf fi cient to accurately perform the match-ing, whereas the latter ones because they require high quality fi ngerprints, which are not usually available.

In the last years, fi ngerprint recognition has acquired a big importance due to its advantages for identifying people, but there are also legal concerns about its use. One of the hot topics in research is the encoding of fi ngerprints, which seeks to store the fi ngerprint in the database in a template format from which the original image cannot be retrieved. There are many minutiae-based algorithms that perform this task ( Lee and Kim, 2010; Ahmad et al., 2011 ).

A minutia is de fi ned as a local discontinuity in the fi pattern (ridge skeleton). Many minutiae types can be found in fi ngerprints, but only two of the mareconsideredbymostofthe
Automatic Fingerprint Identi fi cation Systems (AFISs): ridge endings and ridge bifurcations. The usage of minutiae provides several advantages to the matching process: they are distinctive and compact, and human experts also use them to match fi ngerprints.
Nevertheless, the extraction of minutiae from fi ngerprint images is a dif fi cult task ( Maio and Maltoni, 1997; Hong et al., 1998 ). Moreover,
As a consequence, minutiae extraction becomes a key component in the development of AFISs ( Ratha and Bolle, 2004; Maltoni et al., 2009 ). Two different types of errors can be attributed to these methods: missing minutiae (non-d etected real minutiae) and spur-ious minutiae (non-existing detec ted minutiae). Such errors might be produced by poor-quality images, but also due to creases or scars in the fi ngerprint pattern. In addition to these errors, the quality of the minutiae should also be assessed, that is, how close are the estimated minutiae positions and angles from the real minutiae ones ( Ratha et al., 1995; Gao et al., 2010 ). Regarding erroneous minutiae, a missing minutia can only be recovered (detected) improving the minutiae extraction method; otherwise, a spurious minutiae can be detected and removed from the minutiae set by post-processing techniques ( Chikkerur et al., 2005 ).

This post-processing step is of great importance, since a large number of spurious minutiae are usually detected on poor-quality fi ngerprints, whereas the number of correct minutiae detected might be enough to perform a successful matching (around 12 correctly matched minutiae are usually suf fi cient to claim the individuality of a fi ngerprint Dass, 2010 ). The removal of spurious minutiae, maintaining the correct ones, improves the results of the matching process ( Hong et al., 1998 ).

In this paper, we focus on the well-known MINDTCT minutiae extractor, which is provided with NBIS software package ( Watson et al., 2010 ). Our aim is to study the behavior of two different approaches to remove borderline minutiae and thus enhance the minutiae set given by MINDTCT: the usage of the convex hull formed by the minutiae and a segmentation-based approach (pre-sented in Section 3 ). In this manner, we have a two-fold objective:
First, we aim to improve the minutiae set obtained by MINDTCT eliminating the spurious borderline minutiae, using the two mentioned approaches. Then, we will compare the quality of the original and the fi ltered minutiae sets to validate the studied post-processing mechanisms.

Second, we will investigate the in fl uence of the spurious minutiae on several matching methods to show that an adequate post-processing can be effective to enhance the results obtained in AFISs. More speci fi cally, we will show that robust methods are not severely affected by spurious minutiae in terms of accuracy, whereas simpler ones can be highly in fl uenced by their presence. Furthermore, reducing the num-ber of minutiae the computational complexity of the matching is reduced, obtaining faster matching times, which are also evaluated in this paper.

In order to carry out these objectives, we have developed an exhaustive experimental study, where we aim to evaluate both the quality of the minutiae extracted (with and without fi ltering) and the effect of the fi ltering methods in different state-of-the-art matching methods (both in terms of accuracy and complexity).
In total, twelve databases of three different types have been evaluated: fi ve databases arti fi cially generated with SFinGe ( Cappelli et al., 2004; Maltoni et al., 2009 ), six databases from the FVC competitions, and one database captured by the authors' research groups. The parallel architecture presented in Peralta et al. (2014) has been used to allow the execution of huge amounts of matches in a reasonable time. We will show that almost 75% of the spurious minutiae detected by MINDTCT can be removed by an adequate post-processing, highly reducing the error rates of the matchers (the reduction varies depending on their robustness) and their execution times.

The rest of the paper is organized as follows. In Section 2.1 , we recall several related works to minutiae fi ltering and quality evaluation. In Section 2.2 , we describe the quality measures used in this paper. In Section 3 , we present two different post-processing methods for borderline minutiae fi ltering. The experi-mental framework used to develop the experiments is presented in Section 4 . Next, Section 5 presents the experimental study carried out to evaluate both the quality of the minutiae and the performance of the matching methods. Finally, Section 6 con-cludes the paper and presents some future research lines based on the obtained results. 2. Fingerprint minutiae
In this section, we fi rst recall some related works to minutiae extraction and post-processing. Next, we review some metrics already used to assess the quality of the extracted minutiae with respect to the ground-truth ones. 2.1. Minutiae extraction in AFISs
Two types of minutiae detection algorithms can be found in the specialized literature depending on how they deal with the print image. Binarization-based methods ( Jain et al., 1997; Watson et al., 2010 ) carry out a binarization process followed by the thinning of the obtained image, producing a new image from which the minutiae can be easily extracted. Thus, errors in both phases bring along the detection of spurious minutiae. Otherwise, gray-level intensities-based methods ( Maio and Maltoni, 1997; Jiang et al., 2001 ) directly extract the minutiae from the gray-scale image with-out requiring to pre-process the image. Although the pre-processing is avoided, these methods also pr oduce spurious minutiae in low quality fi ngerprints. Hence, indepen dent of the method used to extract the minutiae, two types o f errors can be produced, as we have previously mentioned: s purious and missing minutiae.
Focusing on the spurious minutiae, post-processing techniques can be considered in order to prune them. Two different approaches canbefoundintheliterature( Chikkerur et al., 2005; Maltoni et al., 2009 ): 1. Structural post-processing : heuristics based on the relative location and the length of the ridges, among other structural information, are used to remove minutiae ( Jiang et al., 2001 ).
These rules are usually strongly related to the minutiae extrac-tion algorithm. For example, in Xiao and Raafat (1991) ,a number of structures resulting from the thinning of the image leading to spurious minutiae were identi fi ed and different heuristics were proposed to eliminate such minutiae. In Hung (1993) and Zhao and Tang (2007) , the authors take advantage of the duality property of the ridge endings and bifurcations using the negative and positive gray-level images to detect and prune minutiae. 2. Filtering based on gray-level : the gray-scale values in the neighborhood of the minutiae are used to verify the minutiae.
Most of these approaches rely on previously labeled spurious and correct minutiae to train a classi fi er able to decide whether each minutia is spurious or not. In Prabhakar et al. (2000) , the gray-scale values are directly used to train a Learning Vector Quanti fi er classi fi er. Neural networks are used in Maio and Maltoni (1998) , Santhanam et al. (2007) and Kumar and Deva Vikram (2010) to learn to fi lter minutiae with different pre-processing steps and features to represent the minutiae as the input for the classi fi er.

MINDTCT extracts the minutiae from an input image following six steps: (1) generation of image maps, (2) binarization of the image, (3) detection of the initial minutiae set, (4) removal of spurious minutiae, (5) ridge counting between neighboring min-utiae and (6) assessment of the minutiae quality. Both the 4th and the 6th steps are related to minutiae post-processing. The former aims to remove spurious minutiae by structural post-processing, whereas the latter assigns a quality index to each minutia, which allows for further processing of the minutiae. However, despite these processes, a certain number of spurious minutiae are still present in the extracted minutiae set, as it can be observed in Fig. 1 . Observe that most of the spurious minutiae lie on the border between the fi ngerprint and the background.

Although we are centering our attention on MINDTCT, we should notice that there are several minutiae extractors in the literature ( Maio and Maltoni, 1997; Jain et al., 1997; Gao et al., 2010 ), but MINDTCT is still competitive, despite a number of spurious minutiae detected ( Dass, 2010 ). 2.2. Minutiae quality evaluation
Minutiae quality can be understood in two ways. It can be related to the con fi dence of the minutiae extractor algorithm on the extracted minutia. In this case, the quality might help the matching process to reject fi ngerprints, remove low quality minutiae or assign weights depending on the quality. The quality given to each minutia by MINDTCT is an example of this type of quality. In MINDTCT the quality is assigned depending on the gray-level of the pixels in the neighborhood of the minutiae and on the local quality assigned to the minutiae location (quality map). However, this quality is not adequate by itself for post-processing, since low quality is assigned to areas near singular points, even though the minutiae are correctly detected. This fact will be clearly shown carrying out several experiments using the quality as fi ltering criterion (Section 5 ).

In this paper, we refer to minutiae quality (and its evaluation) as the quality of the minutiae obtained with respect to the ground-truth ones. However, obtaining ground-truth minutiae is a very dif fi cult task. For this reason, we take advantage of the SFinGe software tool ( Cappelli et al., 2004; Maltoni et al., 2009 ), which generates realistic synthetic fi ngerprints, allowing a straightfor-ward evaluation of AFISs. Moreover, since the fi ngerprints are generated from minutiae, the ground-truth minutiae become available (among other interesting ground-truth data) and hence, it makes possible to properly evaluate the performance of minu-tiae post-processing methods and to observe their in fl uence on different matching algorithms. Furthermore, the experiments carried out with SFinGe are easily reproducible by other research-ers using the same parameters for the generation process, which are provided in Section 4 . In addition, we carry out an indirect evaluation of the minutiae in the fi ngerprint veri fi cation and identi fi cation problem considering databases from the FVC and a real one.

In the specialized literature the Goodness Index (GI) has been considered to measure the quality of minutiae with respect to the ground-truth ones ( Hong et al., 1998; Zhao and Tang, 2002 ). The GI combines the number of correctly detected minutiae (paired with ground-truth minutiae, P ), the number of spurious minutiae ( S ) and the number of missing minutiae ( M ) in a unique value, easing the comparison between different methods. Its computation is shown in Eq. (1) , where T is the total number of ground-truth minutiae. Notice that for the minutiae pairing a tolerance box centered around each ground-truth minutia is used (in our experiments this box is a 10 pixels radius circle). The maximum value of GI is 1, meaning that all ground-truth minutiae are correctly paired with the corresponding detected minutiae and there are no missing minutiae ( P  X  T and M  X  S  X  0). Hence, the greater the GI is, the greater the quality of the detected minutiae is: GI  X  P M S T  X  1  X 
Besides from the GI, other metrics to quantify the quality of the minutiae have been used in the literature. That is the case of the True Positive Rate (TPR) and the Positive Predictive Value (PPV). The
TPR is the percentage of correctly detected minutiae with respect to the number of ground-truth minutiae  X  TPR  X  P = T  X  P =  X  P  X  M  X  X  , whereas the PPV is the percentage of correctly detected minutiae among all the minutiae detected  X  PPV  X  P =  X  P  X  S  X  X  .Hence,theformer is related to the number of missing minutiae, whereas the latter is related to the number of spurious minutiae.

In addition to these measures quantifying the accuracy of the minutiae, in the sense that they measure the proportion of correctly detected minutiae, we propose other metrics in Section 4.3.1 to measure, among the correctly detected minutiae, how close are the localization and the orientation estimations of the minutiae with respect to the corresponding ground-truth ones.
This measurement is interesting in order to analyze the deviations produced by the minutiae extractors. Reasonably, if a minutia is correctly detected but its localization or angle difference is large, the extracted minutiae can be considered as spurious, whereas the real one can be considered as missing. 3. Post-processing methods for borderline minutiae fi ltering
In this section we describe two alternatives for minutiae
The former uses a convex hull approach to fi nd spurious minutiae (Section 3.1 ), whereas the latter considers the segmentation of the fi ngerprint to fi lter the minutiae in the borders (Section 3.2 ). 3.1. Convex hull-based fi ltering
The convex hull of a set of points S is de fi ned as the convex polygon that contains all the elements of S with the smallest area.
Fig. 2 depicts an example of the convex hull for a set of points. It shows the concept of convex hull as the analogy of an elastic-band that surrounds the complete set S and then is released, so that the enclosed points form the convex hull.

This idea has been widely used in the specialized literature as a simple, but ef fi cient, mechanism to remove spurious minutiae ( Wen and Guo, 2009; Cappelli et al., 2010 ). In this work, we implement the convex hull idea in conjunction with the quality assessment mechan-ism of MINDTCT, providing an intuitive way to fi lter the minutiae set.
A minutia m i is formed by four components  X  x i ; y i ;  X   X  x ; y i  X  are the coordinates in the fi ngerprint image. i is the orientation or minutia angle. q refers to the quality of the minutia.
 Thus, after the minutiae detection process accomplished by
MINDTCT, a fi ngerprint F can be represented as a vector of r minutiae m  X f m 1 ; m 2 ; ... ; m r g . To determine which minutiae of a given fi ngerprint F are susceptible of being spurious, we focus on their coordinates x i and y i and their quality q i (with i
Initially, the convex hull of the fi ngerprint minutiae set is calculated using Graham's (1972) scan algorithm. This algorithm places a random point P g among the minutiae, and converts their coordinates to polar. Then, the minutiae are ordered by their newly calculated polar angle. The minutiae are grouped in triplets according to their order, forming triangles as depicted in Fig. 3 .
The minutiae m i belongs to the convex hull if and only if
The process is repeated for all triplets, obtaining the set of minutiae that form the convex hull  X  m CH  X  .

Then, minutiae in m CH with their quality lower than the threshold are included in the set of candidate spurious minutiae m s minutiaeareremovedfromtheoriginalminutiaeset m .Ifthe resulting set has at least r min minutiae, it is taken as the minutiae set. Otherwise, the infor mation loss is considered too high and the fi ltering is not applied. Note that if  X  is set to the maximum quality value (100), the algorithm will remove all the minutiae in the convex hull.

The main highlights of the convex hull approach are its simplicity and intuitiveness. The convex hull can be very easily superposed to the fi ngerprint image, and the correctness of the fi ltered minutiae can be visually checked. As for the computational impact, our implementa-tion has the complexity of Graham's scan algorithm, which is of
O( n log n ), with n being the number of minutiae of the fi Thus, the convex hull computation is reasonably fast.

However, this method has some drawbacks. The most impor-tant one is that it is very sensitive to image translations, as it can be clearly observed in Fig. 4 , which shows two captures of the same fi ngerprint. The fi ngerprint in Fig. 4 a is correctly centered, and the convex hull is correctly detected, including most of the image spurious minutiae. Otherwise, the fi ngerprint in Fig. 4 ais translated and many of the minutiae that lie on the image borders are not spurious. The usage of the MINDTCT quality parameter that we propose intends to reduce the impact of these kinds of translations. However, the quality assignment process of MINDTCT assigns low qualities to the minutiae near the image borders, even when they are correctly detected, and this may dif fi cult the fi ltering process. 3.2. Segmentation-based fi ltering
This method consists of detecting the fi ngerprint area in the image, that is, to de fi ne a segmentation mask for the fi
Once the mask is de fi ned, all the minutiae that were detected out of the fi ngerprint region or near the borders are deleted. In such a way, we aim to decrease the number of spurious minutiae while maintaining the number of correctly detected ones.
 The segmentation process combines the concepts presented in
Ratha et al. (1995) , Hong et al. (1998) ,and Bazen and Gerez (2001) .A fi ngerprint image usually has two well-differentiated areas: the back-ground and the fi ngerprint itself. In the former there are usually low variations of the gray-level intensities, since it tends to be homo-geneous (although the intensity may vary and can be different depending on the device used). On the contrary, the latter presents a high variance of gray-level intensities due to the presence of ridges and valleys. On this account, an effective methodology for segmentation can be developed considering the local variance (block-wise variance) of the pixel intensity values.

The operating procedure of the whole algorithm is presented hereafter: 1. Normalization : A desired mean M 0 and variance V 0 for the fi ngerprint image are established. The image is then normal-ized in such a way that its mean and variance take values M and V 0 , respectively. This pre-processing reduces the gray-level variations along ridges and valleys, which facilitates further processing. In our case, this phase allows us to set a global threshold for all the images. Normalization is a pixel-wise operation in which a new image I norm is created starting from the original image I (with original mean and variance M and V , respectively) as follows: I norm  X  i ; j  X  X  2. Block-wise variance computation : The gray-level variance of each block in the normalized image is computed (blocks of 8 8 pixels are used in our experiments). 3. Thresholding : Each block is assigned to the background or to the fi ngerprint depending on its variance following a global threshold ( T v ). Blocks with variance greater than the threshold belong to the fi ngerprint, whereas the rest are assigned to the background. 4. Re fi nement : In order to obtain a unique fi ngerprint area, three iterations of hole fi lling are carried out, where blocks discor-dant with more than half of its 8-neighbors are changed. Then, an erosion process is performed to ensure that the fi ngerprint region does not contain any background zone.

After carrying out the segmentation of the fi ngerprint, all the minutiae located on blocks belonging to the background and whose quality is lower than  X  are pruned. In addition to these minutiae, those lying on the borderline blocks, that is, in blocks having a background block in its 8-neighborhood, are also removed. An example of the application of this process to the minutiae obtained using MINDTCT algorithm can be shown in Fig. 5 . The shaded area corresponds to the background detected by the segmentation algo-rithm. We can observe that the studied method has effectively removed a great amount of spurious minutiae lying on the borders of the fi ngerprint. 4. Experimental framework
In this section, we show the main aspects related to the experimental setup that we will use in this work. Section 4.1 details the databases used. Section 4.2 summarizes the methods used in this study with their respective parameters. Finally,
Section 4.3 describes the performance measures needed to pro-vide a faithful comparison of the obtained results. 4.1. Databases
This section describes the 12 databases used for this study, grouped into three categories: 5 SFinGe-generated (Section 4.1.1 ), 6 FVC data-bases (Section 4.1.2 ) and a real database captured by the authors (Section 4.1.3 ). 4.1.1. SFinGe databases
To evaluate the ef fi cacy of the analyzed minutiae fi ltering techniques we will use the SFinGe tool ( Cappelli et al., 2004;
Maltoni et al., 2009 ) to generate fi ve synthetic databases with different sizes. This software allows us to control the quality and other features of the generated fi ngerprints. In order to make the generation process reproducible, Table 1 shows the con fi guration parameters of the SFinGe tool that we have used to generate the databases. These parameters have been selected aiming to obtain realistic fi that offer a wide range of image qualities, including very low quality fi ngerprints with highly corrupted areas.

In the fi ve databases, we have generated 25 impressions of each fi ngerprint. For each fi ngerprint, we have to differentiate between template and input impressions. In order to perform a more real setup, we carry out an enrolment process in the synthetic databases. This process selects a good quality impression as template, ensuring a minimum of 40 ground-truth minutiae. In case all 25 impressions have less than 40 minutiae, the sample with the highest number of minutiae is taken as template. The remaining 24 samples are the databases generated, showing the size of the databases and the average number of ground-truth minutiae of the template and input fi ngerprints. 4.1.2. FVC databases
In order to get the most realistic behavior, we have only taken those FVC databases that contain real fi ngerprints. Thus, we have used
DB1A and DB2A from FVC2000 ( Maio et al., 2002a ), FVC2002 ( Maio et al., 2002b )andFVC2004( Maio et al., 2004 ), making a total of six real databases, whose main features are described in Table 2 . 4.1.3. Captured database
To complete this study, the experiments have been repeated with a database of real fi ngerprints, which have been captured by the authors' research groups in three different cities. The prints have been captured with an optical sensor (SecuGen
Hamster Plus), and belong to the thumb, fore fi nger and middle fi nger of both hands of 356 people. The captures were taken within three different sessions, between 2 and 3 weeks apart, obtaining two template images and twelve test images (four per session) per fi ngerprint.

After removing failed captures and selecting a single random template image and three random test images per fi nger and per session, the fi nal database is formed by 1530 template fi ngerprints and 13,770 input fi ngerprints, whose overall statistics are shown in Table 2 . 4.2. Algorithms and con fi guration of the parameters
Minutiae-based matching algorithms can work at different levels with the minutiae sets, comparing small groups of them (local approaches), using the whole minutiae sets (global approaches) and combining both philosophies (hybrid approaches). In this work, we will use four well-known minutiae-based matchers: Jiang ( Jiang and Yau, 2000 ), Deng ( Deng and Huo, 2005 ), Chen ( Chen et al., 2006 )and
MCC ( Cappelli et al., 2010 ). These matchers are brie fl hereafter:
Jiang's algorithm is a classical hybrid matching algorithm in which each minutia is represented with a feature vector that is related to its neighboring minutiae. Thus, the most similar pair of feature vectors should correspond to the same minutia, and the remaining minutiae are globally matched, obtaining the similarity score.

Deng's algorithm also presents a hybrid approach, but is based on the minutiae graph triangulation. Once the triangle set of each fi ngerprint is computed using the Delaunay triangulation, the algorithm calculates the global score associated with each triangle pair. The fi nal score is the maximum global score.
Chen's method is local and focuses on getting robustness despite the fi ngerprint distortion. It calculates a local topology for each minutia with a fi xed radius. Then, it compares local topologies of fi ngerprints to establish the similarity. If they are similar enough, it includes a second comparison with a higher radius, aiming to avoid image distortion problems.

MCC uses both local and global information to perform the matching, building tridimensional data structures (called cylin-ders) from minutiae distances and angles. This method includes its own fi ltering process that is based on the convex hull idea. In our experiments we will test two versions of this algorithm depending on the cylinder's size (8 and 16), disabling its own fi ltering process when it is used in combination with the analyzed fi ltering methods to avoid a double removing stage. We will call these modi fi ed variants as MCC8n and
MCC16n, to distinguish them from the original algorithm with the embedded fi ltering method.

Note that these algorithms are translation and rotation invar-iant. The con fi guration parameters of all the methods used in this study are common for all databases, and they were selected according to the recommendation of the corresponding authors ( Table 3 ). This can be done because the study is performed comparing the algorithms with themselves. Furthermore, this parameter setting allows future comparisons for other studies, and produces a more realistic setup, avoiding the over fi may arise from speci fi c parameter optimization. The value for the r parameter was selected because at least 12 minutiae are needed to claim the individuality of a fi ngerprint ( Dass, 2010 ). 4.3. Performance measures
In this section we present three different types of performance measures that we used to evaluate the minutiae fi ltering methods from different perspectives. In Section 4.3.1 , we describe the group of metrics, which are related to the quality of the detected minutiae in comparison with ground-truth minutiae. These metrics aim to extend those de fi ned in Section 2.2 . The second ones are devoted to measure the performance of the matching algorithms in the fi ngerprint veri fi cation problem (Section 4.3.2 ). Finally, the third group aims to measure the identi fi cation perfor-mance of the algorithms (Section 4.3.3 ). 4.3.1. New minutiae quality evaluation metrics
In addition to the measures explained in Section 2.2 , in this work we propose a simple similarity measure not to replace the previous proposals, but to expand them providing information about the difference between ground-truth minutiae and the corresponding correctly extracted minutiae. In conjunction with GI, TPR and PPV, the proposed metrics provide more information about how similar two sets of minutiae are.

These metrics measure the difference between the location and angle estimation of the extracted minutiae and the ground truth ones. They are computed as follows. For each ground-truth minutia, the nearest extracted minutia in a ten pixels radius is selected as matched minutia (which cannot be then matched with a different ground-truth minutiae). If there are no extracted minutiae in this area, the ground-truth minutia is marked as missing. When all the ground-truth minutiae are categorized as matched or missing ones, the remaining extracted minutiae (if any) are considered to be spurious. After this process, for each paired minutiae their Euclidean distance in pixels is computed. Finally, the average of the Euclidean distances of all pairs is obtained to measure the location error. This error is denoted as Mean Euclidean Distance (MED). Similarly, the absolute average difference between the angles of the matched minutiae pairs (in degrees) is computed and denoted as mean angle distance (MAD). 4.3.2. Measuring the performance of the matchers in the veri problem
In order to measure the effectiveness of the matchers, we consider the well-known False Matching Rate (FMR), False Non-Matching Rate (FNMR), and Equal-Error Rate (EER), which indi-cates the value where FMR and FNMR are equal. Furthermore, we use other useful indicators such as FMR100 (the lowest achievable
FNMR for a FMR r 1 % ) and FMR1000 (the lowest FNMR for a FMR r 0 : 1 % ). 4.3.3. Measuring the performance of the matchers in the identi fi cation problem
The measures presented in the preceding section offer average values for 1vs1 comparisons. Thus, we use some additional values to complete the scope of our study, which use the concept of rank.
Within an identi fi cation process, where the input fi ngerprint is compared to all template fi ngerprints in a database, the rank is the position of the genuine score if all the obtained scores are ordered in descending order. In other words, the rank is the minimum number of database fi ngerprints that have to be returned by the identi fi cation system to ensure that the correct identity is included. The accuracy measures in these case are R100 (lowest rank that allows an error lower than 1%) and R1000 (lowest rank that allows an error lower than 0.1%). The optimum value for these measures is 1, whereas the worst one is the size of the database.
Additionally, the CMC (Cumulative Match Curve) is used to show graphically the behavior of a matching algorithm. The curve shows the error associated with each rank. 5. Experimental study
This section presents all the experiments that have been designed for this work. There is one section for each of the tested databases: SFinGe (Section 5.1 ), FVC (Section 5.2 ) and captured (Section 5.3 ). As we have mentioned, this experimentation has several objectives, and we have divided this section accordingly: 1. To check the accuracy of the different matchers when using the minutiae extracted by MINDTCT in comparison the accu-racy obtained with a perfect minutiae extractor that obtains ground-truth minutiae (Section 5.1.1 ). 2. To verify the usefulness of the MINDTCT minutia quality value.
The same accuracy measures from the veri fi cation and identi-fi cation problems are used to compare the results when only minutiae over a certain quality threshold are used for the matching (Section 5.1.2 ). 3. To measure the quality of the extracted minutiae with respect to the fi ltered ones. The quality measures described in Sections 2.2 and 4.3.1 are computed for all the minutiae sets, s comparing whether the quality of the fi ltered minutiae over-come that of the original ones (Section 5.1.3 ). 4. To test the effect of the convex hull and segmentation both types of matching problems considered. We perform an analysis of the veri fi cation and identi fi cation accuracy mea-sures ( Sections 5.1.4, 5.1.5, 5.2 and 5.3 ). 5.1. SFinGe databases
In this section, we use the SFinGe databases, which provide the ground-truth minutiae, to study the minutiae statistics and the behavior of the minutiae extractor and all the proposed fi schemes along with several minutiae matchers. 5.1.1. Performance evaluation with MINDTCT vs ground-truth minutiae
The fi rst step of this experimental study consists of comparing the results obtained with the minutiae extracted by MINDTCT with those obtained using ground-truth minutiae, in order to quantify the loss of accuracy.

Following the experimental framework established, Table 4 shows the veri fi cation performance measures obtained for each matching algorithm and database. In this table, we observe that the matching algorithms maintain their respective performance ranking independent of the minutiae considered (ground-truth or
MINDTCT). MCC16 is the best performing algorithm in all the databases, while Deng is by far the worst algorithm. Nevertheless, except for the Deng algorithm, the achieved error rates are very low for ground-truth minutiae, whereas they suffer great increase when MINDTCT minutiae are used. The bad behavior of Deng's algorithm could be explained because it uses additional informa-tion (the ridge count) that is not included in the ground-truth information provided by SFinGe, and therefore it has to be obtained from the data extracted by MINDTCT. However, the element that provides the most information to Deng's algorithm is still the minutiae set itself.

The results on the identi fi cation problem for the same algo-rithms and databases are also shown in Table 4 . It can also be observed that MINDTCT introduces noise and erroneous informa-tion deteriorating the results obtained, as expected. It can be noted that although Deng is the less accurate algorithm, Chen obtains the maximum possible values in most of the cases. This is due to some outliers, corresponding to genuine scores with value zero.
These outliers appear because by de fi nition the rank is a max-imum value. The other matchers do not have outliers in their results, although it can be observed that MINDTCT minutiae perform considerably worse than the perfect results achieved using ground-truth minutiae. 5.1.2. MINDTCT quality value
The previous results con fi rm that the minutiae extraction process is a critical step in a fi ngerprint identi fi cation system, and thus a deeper study of the extracted minutiae must be performed. As explained in Section 2.2 , MINDTCT algorithm provides a quality value for each extracted minutia. Fig. 6 a shows the average quality distribution per fi ngerprint of the fi sidered databases. As all databases have been generated using the same parameters with SFinGe, the average characteristics are very similar. Fig. 6 b shows how much the average number of minutiae per fi ngerprint is reduced when we fi lter the minutiae with a basic quality threshold. These fi gures follow a very clear pattern, marking three sharp separations: 10, 30 and 50. According to
Fig. 6 b, these thresholds leave each fi ngerprint with an average of 45, 32 and 21 minutiae.
 As the fi rst approach to reduce the loss of accuracy when using
MINDTCT, we have fi ltered the extracted minutiae using their quality value. This fi ltering consists of removing the minutiae whose quality is below a fi xed threshold. Note that MINDTCT results shown in Table 4 correspond to a threshold with value 0. Table 5 shows the veri fi cation results obtained for all algorithms and databases when this simple fi lter is used with the three selected thresholds. We stress in bold-face the best result for each database and each algorithm. In general, the table shows that the variation in the error rate with respect to the quality threshold depends on the matching algorithm. On the one hand, Jiang and Deng obtain better results when the 10 threshold is used (variant Th-10). The same occurs for Chen and the Th-30 variant. However, with the other thresholds the accuracy is often lower than the one obtained considering the whole minutiae set. On the other hand, the performance loss of MCC is dramatic when the threshold is high. This is due to the embedded fi ltering technique of MCC, which is based on the convex hull.

Additionally, Table 6 shows the identi fi cation results for the same algorithms and databases. Now only Jiang and Deng show a certain improvement in the results, when the threshold 10 is used.
In all other cases the obtained results are worse than when the whole set of minutiae extracted by MINDTCT is used.

Therefore, we can conclude that this simple threshold-based technique is not useful to improve the accuracy, but the improve-ment that can be observed in some speci fi c cases (such as Jiang with 10 threshold or Chen with 30 threshold) suggests that there may be some way to obtain the desired performance gain eliminating minutiae. It is also clear that the quality value provided by MINDTCT is not valid by itself to fi lter the minu-tiae sets, since minutiae in critical zones of the fi ngerprint (such as singular points) are deleted even though they are correctly detected. 5.1.3. Minutiae quality comparison: MINDTCT and fi ltering with convex hull and segmentation Once we have shown that the usage of the quality given by
MINDTCT is not useful by itself, in this section we analyze the effect of the application of the fi ltering techniques described in Section 3 to the minutiae extracted by MINDTCT. In order to do so, we use the minutiae quality measures presented in Sections 2.2 and 4.3.1 .This way,weareabletostudywhetherthe fi ltering techniques allow us to improve the quality of the minutiae.

Table 7 shows the average number of minutiae found in each database and each method, while Table 8 presents the differences between ground-truth, extracted and fi ltered minutiae sets. Obser-ving these tables, we can make the following observations about the weaknesses of MINDTCT:
It is clear that extracting real minutiae is a very dif fi due to noise and distortions of the fi ngerprint images. Thus, we observe that wide distance and angle differences are found between matched minutiae. This fact affects negatively the performance of matching algorithms. Nevertheless, MINDTCT is able to detect about 31 of the 37 real minutiae in each fi ngerprint (on average, see Table 2 ).

MINDTCT overlooks about 6 minutiae per fi ngerprint (on average). These missing minutiae may produce a performance degradation of the matching algorithms.

The number of detected spurious minutiae is high. As we observed in the example presented in Fig. 1 , an important number of these spurious minutiae are near to the borders of the fi ngerprint.
 This experimental study con fi rms our premises about
MINDTCT. Among these drawbacks, the most remarkable problem of this minutiae extractor is the high number of spurious minutiae detected. However, these minutiae can be addressed by a post-processing step, as we have mentioned earlier.

Otherwise, the analyzed fi ltering procedures remove up to 16 of the extracted minutiae. Thus, the resulting number of fi minutiae can be lower than the number of real minutiae, but the absolute difference is smaller than when using MINDTCT. More-over, this fact could be due to missing minutiae rather than the removal of real ones. For this reason, we need to investigate the results in terms of the quality of the minutiae. It is also clear that
CH-10 and Seg-10 produce very similar minutiae statistics. Due to their low threshold value, they remove only minutiae that are spurious with a very high probability, and thus these fi lters are those removing the lowest number of minutiae (the most con-servative ones). When the threshold is increased, so does the number of fi ltered minutiae, but this also brings along an increase in the probability of removing real minutiae.

MINDTCT has the greatest number of both spurious and matched minutiae, and the highest TPR. For all the described methods an important decrease in the number of spurious minutiae in comparison with the bare use of MINDTCT can be observed. Additionally, the number of matches is always very close to the number achieved by
MINDTCT, meaning that the vast majority of pruned minutiae are spurious.

If we focus on the GI measure, Seg-20 fi ltering always reaches the highest values. Hence, this approach offers the best balance between spurious and missing minutiae. Otherwise, Seg-100 obtains the best PPV in all cases, meaning that it is the method that removes the most spurious minutiae, and hence most of the remaining minutiae are real, although the number of missing minutiae is slightly higher than that of other approaches. It is also the approach with the lowest MSD and MAD, meaning that the removed minutiae are those that are the furthest from their respective ground-truth minutiae. 5.1.4. Performance evaluation for the veri fi cation problem
So far, we have observed that the fi lter methods improve the minutiae quality. However, the goal of this operation is to perform more accurate matchings. This section analyzes the results obtained with the different fi ltering approaches presented in this work in the framework of fi ngerprint veri fi cation. Table 9 shows the results for the two convex hull variants. In almost all cases, the CH-10 approach performs better than the CH-100 approach, because the additional quality criterion avoids the removal of real minutiae. Focusing on the CH-10 variant, it can be observed that the results with Chen and Jiang matchers are slightly improved. In the case of MCC, the results are similar to those obtained with
MINDTCT. However, the obtained results are better than those shown in Table 5 , where the fi ltering criteria was only based on the quality assigned to the minutiae by MINDTCT. Finally, Deng shows a deterioration of the accuracy when the fi lters are applied.
The matching results obtained with the minutiae sets fi ltered using the segmentation method are shown in Table 10 , where we observe that the segmentation fi lter has reduced the error rates achieved by all algorithms in almost all the cases. These results are closer to that obtained with ground-truth minutiae for all the considered thresholds. The results with Deng and MCC have also been improved by the applied fi lter. Moreover, in general the most accurate variant is Seg-100, which is the one that reduces mostly the number of minutiae and has the highest PPV. This highlights this measure as a good one to determine the veri fi cation accuracy.
Besides the accuracy improvements, the reduction of spurious minutiae reduces the computational complexity of the matching process. Fig. 7 and Table 11 show the average runtime 1 of the matching algorithms. In the fi gure, the fi lters are ordered in decreasing order of the number of minutiae. It is clearly shown that the matching time is proportional to the average number of minutiae in each database. Thus, Seg-100 is both the most precise and the fastest approach, and highlights as the optimal among the tested fi lters. Otherwise, the use of non-fi ltered MINDTCT minu-tiae leads to the slowest execution times. 5.1.5. Performance evaluation for the identi fi cation problem
In this section we analyze the obtained results in terms of the identi fi cation performance measures, and more speci fi cally using R100 and R1000 as de fi ned in Section 4.3.3 .

Table 12 shows the results for the convex hull-based fi lter. As in the previous section, when we compare these results with those obtained with MINDTCT, it can be shown that the CH-10 fi lter improves the results, mainly with MCC. However, the CH-100 variant removes too many minutiae and causes a certain loss of accuracy. The Deng algorithm performs better when no minutiae are removed, and Chen shows a high sensibility to outliers, as in the previous sections.

Finally, Table 13 contains the results of the segmentation-based fi lter. Now the improvement in the obtained results is very clear, meaning that the difference between genuine and impostor scores has been increased as a result of the removal of spurious minutiae.
Therefore, it can be concluded that the fi ltering that removes the greatest number of minutiae (Seg-100) is also the one that achieves the best results in most of the cases. Consequently, the identi fi cation time obtained with this approach is also the fastest among all tested schemes, as it can be observed in Fig. 8 and
Table 14 , which show the average identi fi cation time in BD1. This time corresponds to the initial processing of the input fi plus 1000 matchings. Again, the fi gure orders the fi lter in decreas-ing order of the number of minutiae. Hence, this fi ltering method produces both faster and more accurate results, outperforming the usage of MINDTCT without post-pr ocessing, and even improving the results of the MCC internal fi ltering mechanism.

Finally, we conclude the study on the identi fi cation framework showing the CMC curves for the largest database considered (BD5) for all algorithms and all fi ltering schemes, on Fig. 9 . For the Jiang and Chen algorithms, Seg-100 fi lter dominates all solutions (except the ground-truth minutiae), closely followed by Seg-20.
The usage of MINDTCT alone obtains one of the worst CMC curves, showing the importance of a good pre-processing step. For Deng, both convex hull variants have very bad results, while all the other approaches present very similar CMC curves. In the case of MCC, all variants have very high and similar scores because of its higher robustness, but again the segmentation fi lter provides the best results. 5.2. FVC databases
Some of the experiments have been repeated with the well-known FVC databases, to allow reproducible results in a bench-mark manner and to avoid the bias in the conclusions due to the usage of a unique source of fi ngerprints. In order to verify the behavior of the segmentation and convex hull approaches, we have repeated the experiments with the best con fi guration for each one of them (CH-10 and Seg-100), as well as for the initial minutiae set extracted by MINDTCT. The minutiae statistics of the obtained databases are shown in Table 15 . The results in the table show that between 20% and 40% of the extracted minutiae are deleted when using Seg-100, which is more than when using the SFinGe databases, due to the lower quality of the FVC fi ngerprints.
This deletion is re fl ected in an important reduction of the match-ing and identi fi cation times, independent of the accuracy results achieved.

Table 16 shows the veri fi cation results obtained with these databases. The fi rst fact that should be noted is that the FVC complexity increases over the years, and hence the lowest EER rates are obtained for FVC2000, and the highest ones are seen for FVC2004.

With the FVC databases, the Seg-100 variant greatly improves the results in all cases, except sometimes for the FMR1000 value with the Deng algorithm. Otherwise, the results of the convex hull approach are more similar to those obtained without fi ltering.
The table also shows that the improvement obtained with Seg-100 depends on both the matcher and the database, although it is always remarkable. Moreover, the improvement is higher for the most dif fi cult database, where a huge difference can be observed between the ERR in the MINDTCT column and that of the Seg-100.
This result, along with the large number of removed minutiae, highlights the Seg-100 approach as a very good tool to improve both the matching accuracy and its runtime, especially for low-quality databases such as those of FVC2004.

The identi fi cation accuracy results are shown in Table 17 . Again, the best results are those obtained by the Seg-100 approach. 5.3. Captured database
The same experiments carried out for the FVC databases in the previous section have been executed in this case. Table 18 presents the minutiae statistics of this database. In this case, the number of minutiae removed by the fi lters is not as high as for the FVC databases, but still the Seg-100 variant is the one that removes the most of them.

Table 19 shows the veri fi cation results obtained with the captured database. It can be seen in the table that Seg-100 still improves the results, although the difference is not as high as for other databases. In some cases the CH-10 fi lter performs better, and for the Deng algorithm both fi lters produce worse results than when the non-fi ltered minutiae set is used. However, this matcher obtains more precise results for this database, especially if they are compared to those obtained with the SFinGe databases. This behavior reveals the lack of robustness of this algorithm, whose accuracy tends to be affected by the particular fi ngerprint features, although for this database its results are close to those obtained by the best matcher (MCC).
 The particular error values are similar to those presented in
Section 5.1 , except for Deng. This highlights the SFinGe databases as being reasonably realistic, since the behavior of the algorithms is similar to the database of real fi ngerprints.
 The identi fi cation accuracy results are shown in Table 20 .
Again, the Deng algorithm is the only one for which Seg-100 does not produce the best results, whereas Jiang and MCC signi improve their accuracy. Concretely, the R rates for MCC are reduced by about 50%. 6. Conclusions and future lines
In this contribution, we have studied two fi lters to improve the minutiae extraction of MINDTCT: a convex hull-based fi lter and a segmentation-based fi lter. These fi lters have been tested with several con fi gurations and databases. We have performed an analysis of the number of spurious and missing minutiae that arise when using MINDTCT, and we have shown that the studied fi lters can reduce the number of spurious minutiae without compromising the number of matched ones.

In our experiments, we have analyzed the in fl uence of these spurious minutiae in several state-of-the-art minutiae-based matchers. The compared schemes allow one to remove spurious minutiae providing more accurate results even for robust match-ing algorithms such as MCC. The segmentation based fi lter is especially powerful, and the variant that removes the most minutiae is also the one that provides the best accuracy. Therefore, in addition to the accuracy improvements, the resulting reduction of number of minutiae leads to a faster matching process. These positive results are even better when the fi ngerprint database is of low quality, because the segmentation removes a higher number of spurious minutiae, leading to both better accuracy and runtime, as it can be seen with the FVC databases. This fact shows the importance of an appropriate fi ngerprint post-processing for both the accuracy and the ef fi ciency of the matching algorithms.
The results of this study have also shown that the PPV is a good minutiae quality measure, and the fi lters with high PPV tend to produce better matching accuracy. Finally, it has been observed that the SFinGe databases have a reasonably realistic behavior, as the results obtained with it are similar to those obtained with a database of real fi ngerprints, captured by the authors' research groups in controlled conditions.

As future work, we aim to consider new strategies to remove harmful minutiae and speed up the matching process, as well as to develop a novel matching algorithm that includes the minutiae fi ltering process.
 Acknowledgments This work was supported by the research projects CAB (CDTI), TIN2011-28488 and TIN2009-14575. D. Peralta holds an FPU scholarship from the Spanish Ministry of Education and Science (FPU12/04902).
 References
