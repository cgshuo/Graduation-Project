 Web and enterprise search systems process billions of queries per day, making them amongst the most highly-used computing services. A typical service provides a dialog box for query input, and in response generates a search engine result page ,orSERP, which contains a ranked list of (often) ten query-biased summaries (or snippets ), to-gether with matching links to the underlying documents. Users are normally presumed to examine the SERP  X  X rom the top X , reading the snippets in the order they are pre-sented, making a decision about each in regard to the likely usefulness of the underlying document, and clicking to access those documents for which the snippet suggests rele-vance. If the bottom of the SERP is reached, users can access a second page of results for the same query; or reformulate the query to fetch a fresh page of (possibly overlap-ping) results; or switch to a different search system (again to get possibly overlapping results); or can exit their search entirely. Users might also undertake any of these actions even before reaching the bottom of the first SERP.

In this paper we take a fresh look at this presumed behavior, presenting the outcomes of a user experiment in which gaze tracking was coupled with an instrumented web browser in order to measure both the explicit actions users took while viewing a SERP (clicks and query reformulations), and also their implicit actions, as indicated by their gaze behavior.
 Knowledge of user behavior allows better interfaces to be constructed, and hence allows more efficient searching. Another way we can exploit knowledge of user behavior is in understanding search effectiveness metrics. Given a query and a particular ranking of documents in a SERP in response to that query, it is natural to enquire whether or not the ranking is  X  X ood X  compared to the SERP generated by some other system, or by some other configuration of the same system. To quantify search effectiveness, a range of metrics have been described, varying from simple ones such as Prec@ k (the fraction of the first k documents in the SERP that are relevant) through to complex mechanisms such as normalized discounted cumulative gain (NDCG) [6].

Moffat and Zobel [11] drew a direct relati onship between the user X  X  behavior while reading the SERP and a metric for measuring r etrieval effectiveness. They argued that search quality could be measured in units of  X  X xpected relevant documents identified per snippet examined X , and that users could be modeled as starting at the top of the SERP, and proceeding from rank i to rank i + 1 with some probability p , with p ad-justed according to the nature of the query an d the persistence of the searcher. That is, they suggest that at rank i the user has probability p of next accessing rank i + 1, and probability ( 1  X  p ) of exiting the search without examining any document snippets at ranks i + 1 or beyond. The resultant effectiveness metric, RBP, is formulated as a weighted sum over a vector of relevance-at-rank values, where r i is the relevance of the i th-ranked document as a fractional value between zero and one, with one meaning  X  X ompletely relevant X .

That is, the RBP metric can be thought of as being a direct consequence of a simple one-state, three-transition, user model in which the probability of exiting the reading state remains p throughout. Other possible models are then apparent: in Prec@ k ,the user model is that users read exactly k of the presented snippets; and in reciprocal rank, or RR, the user is modeled as reading until the first relevant document is encountered, and then exiting the reading state. Similarly, average precision, AP, defined as the aver-age of the precision values at each depth at w hich a relevant document occurs, can also be regarded as being a weighted-precision metric: where R =  X   X  i = 1 r i is the total relevance in the collection (for this query). That is, AP can also be regarded as being of the form  X  i w i  X  r i ,where w i is the weight assigned to the i th-ranked document. In the case of RR and AP the user model is adaptive , since the weights w i are a function not only of i , but of r i . Robertson [12] proposes a correspond-ing user model in which (for binary relevance values r i  X  X  0 , 1 } ) the user is assumed to proceed through the ranking examining snippe ts/documents until an identified relevant document is encountered, picked at random from amongst all of the R relevant docu-ments for this query. Other adaptive metrics  X  ones in which the exit probability p is a function of relevance, p i = f ( r 1 .. r i ) for some relationship f () , have also been described [17]. A  X  X o depth k  X  truncated and scaled version of discounted cumulative gain (DCG) [6] is another example of a static weighted precision metric, in which w i depends only on i . Note that DCG itself cannot be fitted to this weighted-precision structure, since the set of weights 1 / ( log 2 ( i + 1 )) used to discount the relevance scores r i is a non-convergent series, and would give rise to a model in which the user is expected to read an arbitrarily large number of doc uments for each query that they pose.
 Another metric has also been proposed recently  X  the time-biased gain (TBG) of Smucker and Clarke [13]. Rather than assessing user effort by counting the number of snippets viewed, Smucker and Clarke measure effort in terms of time spent on task. In this model of user behavior, inspection of snippets takes a certain length of time, and viewing of the underlying document adds a further variable time, depending on the length of the document, and whether it has been viewed previously. User willingness to continue reading down the ranking is assumed to erode as a function of time, rather than of snippets viewed, a further point of difference. Smucker and Clarke analyze the behavior of a set of 48 users, each spending up to ten minutes undertaking each of four search tasks. From this data they infer values for a number of critical parameters that drive their model, including probabilities that a document will be viewed, given that it is relevant (according to external relevan ce judgments), and the probability that it will be saved (regarded as being relevant by the subject), given that it has been viewed.
Common to many of these metrics is that the effectiveness value can be interpreted as being the rate at which relevance is accr ued in terms of documents inspected (or, in the case of TBG, time spent) by a probabilistic user; and hence the only difference between these metrics is the estimate of how the user behaves. All of these models also share another feature  X  they are plausible only if users do indeed read  X  X rom the top X ; or, at least, read SERPs in such a way that it can be logically equated in some way to a  X  X rom the top X  reading order. A range of user studies have suggested that this is indeed the case, albeit with some variation [1,4,5,7]; and a key purpose of our study was to further explore that assumption. To investigate user behavior, an instru mented web browser was used to access a com-mercial search service via its API. A total of n = 34 subjects were each asked to carry out six search tasks, after exploring the system via a training task. The six search tasks were of three different difficulty levels, following the categorization given by Wu et al. [16]. Table 1 lists half of the tasks, one of type remember , one of type understand , and one from the hardest category, analyze .

The browsing interface used in the experiments allowed users to click on documents and read them, but not open tabs or further windows. A pre-determined  X  X tarter query X  was the first one run for each topic; thereafte r, subjects were free t o run other queries while they explored that topic, and to move to further pages in the results listing for any query. If a document was selected and opened for reading, it could only be closed by the user selecting one of two buttons, indicating whether the viewed document was  X  X seful X  or  X  X ot useful X  for answering the information need. Only when that assess-ment had been lodged did the original SER P become accessible again. We took these user-supplied judgments as being definitive of relevance for that user, and did not carry out any further judgments, working on the principle that the user X  X  behavior is based on what they think at the time, rather than what an expert says via a post-hoc assessment. Users were asked to  X  X ollect a set of answer pages that in your opinion allow that in-formation need to be appropriately met X ; t hey were free to elect when they had reached that point, and move on to the next topic.

Search results were presented in SERPs that each contained ten links to documents, with seven of the links visible  X  X bove the fold X  at the time the page was opened, and three more visible on scrolling. A set of  X  X ext page X  links was provided at the bottom of each SERP, while a query box at the top of the SERP allowed fresh queries to be issued. The information need statement f or the topic was displayed at the top of each answer page, as a reminder to the participant of what they were looking for. Figure 1 shows (part of) a typical SERP screen for one of the analyze tasks.  X  X acelab X  gaze-tracking equipment 1 monitored the user X  X  gaze on the screen through-out each session. The stream of observations from the tracker was then reduced to fix-ations of at least 75 milliseconds duration within a 5-pixel radius; and sequences of fixations within the area of each displayed s nippet were further amalgamated. That se-quence was then integrated with the browser log data that noted user actions, including: queries and query reformulations; clicks and document opens; and document judgments made. The resulting processed data can be thought of as sequences of snippet numbers that follow the user X  X  gaze, interspersed w ith notes about explicit actions undertaken, such as clicks, judgments, and query reformulations.

Topics were presented to participants in a structured manner so as to minimize any ordering effects. As an independent dimension of the exploration, we also systemati-cally degraded the SERPs in half of the subject-topic combinations, using a technique described by Jones et al. [8]. In these diluted results, all of the odd-rank positions were replaced by documents that contained words matching the query, b ut were off-topic. In this paper we focus exclusively on the undiluted results; an analysis of the differences in user behavior arising from the dilution is part of a separate study [14]. Each of the 34 users can thus be thought of as contributing three topics to the pool of data, with one topic drawn from each of the three categories shown in Figure 1.
 The majority of the study participants we re undergraduate or graduate students in STEM topic areas, all fluent in English (though many as a second language), major-ity male, and for the most part aged in their twenties. A total of 37 participants were identified initially, but technical issues meant that the data from three people was not used in the analysis. Ethics approval for the experimental design was granted by RMIT University X  X  Ethics Advisory Board. We now examine some of the data we collected during our experimentation.
 Click-Throughs. The relative frequency of click-throughs is shown in Figure 2, plot-ted as a function of snippet rank in the results page. The expected downward trend is present [7], and serves as a useful confirmatio n of two effects: the search service is more likely to place promising items near the top of the ranking; and users are more likely to view items near the top of the SERP. In combination, these two factors mean that click-throughs are more top-biased than document viewings.

Click information, and in particular whether clicked-on documents were subse-quently marked as being useful, can be used to investigate whether participants were taking their search tasks seriously. For each pair of participants, the mean percentage agreement (calculated as the number of documents that were given the same relevance rating by both participants, divided by the total number of documents that were viewed by both participants) was 79%. For the relevant-only class, the proportion of specific agreement is 85%. This is very high; for example, Voorhees [15] reports pairwise posi-tive agreement of 42% to 49% between primary and secondary TREC assessors. How-ever, it should be noted that the latter evaluation was carried out over a full set of TREC relevance pools, while our comparison is over the subset of documents that were clicked on by users, and hence likely to include a hi gher rate of relevant documents. In any case, the high level of agreement suggests that our user study participants were in fact atten-tive to their task.
 Fixations. Figure 3 shows how the set of fixations was distributed over the rank posi-tions in the SERP. In Figure 3(a), the distribution of first fixation points for the subject-topic-query combinations is plotted. The top snippet in the SERP dominates, and is the first one read 38% of the time. But ranks two and three also attract a significant fraction of the first fixations, and the participants were more likely to start with either the second or third snippet than they were to start with the first. Snippets that fall below the bottom of the screen (ranks eight and above) are also sometimes the first one viewed; indicating that in some rare cases the user X  X  first action is to scroll the results window.
Across all fixations recorded during the experiments, shown in Figure 3(b), snippets that are closer to the top of the results page are more likely to be viewed than snippets lower down. But the relationship is not m onotonic, and the first rank position is not the one that is most frequently viewed  X  positions 3 and then 2 enjoy that status. The role of the number of snippets in each SERP, and of the location of the  X  X old X   X  the point below which users needed to scroll down the p age in order to reveal more snippets  X  is apparent in this second graph. (Where user s requested a second page of results for the same query, the snippets were labeled as being at ranks 11 X 20, and so on.) The three snippets below the fold are rather less likely to be viewed; and snippets on the second results page are even less likely to be looked at.
 Fixation Progressions. We d e fi n e a jump as the difference between consecutive fix-ations for the same subject and topic. For example, if the t th snippet viewed in the SERP is at rank d t , then the t th jump is given by j t = d t + 1  X  d t . An ideal  X  X rom-the-top X  reader would have d t = t and hence generate a jump sequence of j t =+ 1values; while at the other extreme, a genuinely random reader would make a selection from j  X  X  X  d
Table 2 gives an overview of the jump distribution observed in our experiments. Neg-ative movements are nearly as likely as positive ones, with 57% of the jumps positive and 43% of the jumps negative. The median jump value is + 1, as expected; however the mean jump value is only + 0 . 1. At face value, these observations suggest that the document reading order is neither  X  X rom the top X  nor random.

In fact, there is a certain amount of embedded structure in the jump sequence, but at a higher level than is revealed by Table 2. Table 3 lists observed occurrences of forwards and backwards jumps, first as overall totals matching the second row of Table 2, and then broken down by three conditioning categories: those jumps that are the difference between the first two fixations (that is, the fi rst jump in each SERP displayed); those that took place immediately following a prior backwards jump; and those that took place immediately following a for wards jump. This is, each colu mn of the table represents an estimate of the relative probability of backwards and forwards jumps (as shown by the parenthesized values), given one unit of knowledge of the gaze sequence. As has already been noted, the overall count of backwards jumps is only modestly smaller than the overall count of forwards jumps. But when the estimates are conditioned by one prior event, a different picture emerges  X  after a backwards jump, it is very likely that the next transition will be forwards again; and after a forwards jump, there is heightened likelihood of a backwards jump.

Table 4 sums adjacent pairs of jumps to get a net change over sequences of three consecutive fixations. For example, the gaze sequence  X 1 , 3 , 2 , 3 , 4 , 3 , 5 X  would reduce to the 1-jump sequence  X  + 2 ,  X  1 , + 1 , + 1 ,  X  1 , + 2 X  and then be further reduced to the 2-jump sequence  X  + 1 , 0 , + 2 , 0 , + 1 X . As the table shows, when adjacent pairs of jumps are combined, the dominant outcome is  X 0 X   X  around a quarter of the time the user will be looking at the same document again two steps from now. Table 5 provides further details. The most common 2-jump is  X  + 1 , + 1 X ; with the  X   X  1 , + 1 X  and  X  + 1 ,  X  1 X  com-binations also relatively common. The only double-negative combination in the top 12 is  X   X  1 ,  X  1 X ; after that, the next double negative combinations are  X   X  2 ,  X  1 X  at rank 16 (0 . 012), and then  X   X  1 ,  X  2 X  and  X   X  1 ,  X  3 X  at equal rank 22, with probabilities below 1%.
More importantly, the direction and magn itude of the first jump in each pair influ-ences the second. Figure 4 explores this connection. Here, the horizontal axis gives the first jump, the vertical gives the second, an d the level of shading gives the probability of the second jump conditioned on the first (so each column  X  X dds up to 1 X ). Regardless of what jump has just happened, a jump of + 1 (that is, reading down the results list) is very common, although this effect is weaker following a large positive (downward) jump since there are fewer results left. Other patterns are also evident. A jump in one di-rection ( + or  X  , down or up) is commonly followed by a jump in the other. In particular, jumps are commonly in the opposite direction and are of about the same magnitude, an effect that gives rise to the shaded band around the diagonal. This explains the tendency to an overall outcome of  X 0 X , in Table 4.

The relative abundance of these effects  X  jumps of + 1, and jumps in one direction being followed by equal jumps in the other  X  might describe a user who is consciously or unconsciously looking at a result, often going back to some sort of  X  X est so far X  to compare it, then going forward a little and repeating the sequence.
Taken together, these statistics suggest that there are a wide variety of reading be-haviors, and the assumption that the average user reads a search results list from the top until they stop is somewhat simplistic, even if that is what click-through patterns might suggest. Instead, it appears that a modi fied sequential reading process takes place: searchers maintain a  X  X one of interest X  that is a small number of snippets (two or three) wide, and read backwards and forwards freel y within that zone, maintaining a local-ized set of potentially interesting snippets th at are evaluated against each other before a click-through takes place. It is the zone that is likely to start near the top of the page, and then steadily progress downwards, rather than the fixations themselves.

It is also worth noting that some of the effect that has been observed may be due to the inherent imprecision of the gaze-track ing hardware and software (our tracker is generally accurate to within 10 pixels), and it might be that a sequence  X   X  1 , + 1 X  reflects the user X  X  eyes drifting slightly offline while reading a single snippet, and that only a single fixation was involved.
 Exit From a SERP. Figure 5 shows the distribution of the lowest-ranked snippets that were viewed, for each query. Distinct peaks can be observed at ranks 7 and 10. These peaks are a consequence of the screen layout within the browser: 7 snippets showed above the fold, and 10 were presented on each query page. The smaller peak at 20 sim-ilarly marks the end of the second page of results. Putting all modeling aside, there is clearly a strong influence on user behavior cau sed by presentation geometry. It seems questionable whether the default  X  X en results per page X  is an optimal setting, since some users won X  X  scroll at all. On the other hand, those that make the additional cognitive commitment to do so are rewarded with only three additional answers, before encoun-tering an even more challenging hurdle in the form of a  X  X ext page X  link. Investigating the influence of screen geometry, and the rel ative impact of the two barriers (needing to scroll, and needing to click on a link), is an interesting area for future work. Impact of Task Type. Recall that participants in our user study carried out search tasks of three complexity levels: remember , understand and analyze . Figure 6 plots the mean fixation rank as a function of fixation sequence (fitted with a polynomial). For the sim-plest task category, remember , views were unlikely to move below the fold. On the other hand, for the more complex understand and analyze tasks, views were likely to continue to the bottom of the first results page. The different slopes also suggest that reading speed tended to be higher for more complex tasks. When users need to assem-ble a larger number of answer documents, they may be more inclined to scan the entire results list first, to get a feel for the range of answer documents that are available to them. For simpler tasks, a more common strategy seems to be to inspect the top rank positions more carefully, until one or two satisfactory items are found and the task is completed. Information retrieval systems provide s earchers with multiple results in response to a query, typically formatted as a ranked list of document summaries. This paper inves-tigated the long-standing assumption that users read through such a list from top to bottom, one item at a time.

Analysis of eye-tracking and click data from a study of 34 searchers showed that there are large variations in viewing behavior. While rank one was the most common single place to start looking, in over 60% of cases participants began their exploration of a results page from a different position; overall, the most frequently viewed positions were at ranks two and three. Examination of sequences of gaze movements showed that most users in fact shifted their attention freely within a zone of interest, typically consisting of two to three snippets. On average, this zone tended to start near the top of a results page, and shift slowly downwards. This detail is not apparent from click behavior alone, which suggests that click behavior is not a good proxy for viewing behavior and may not be a good proxy for users X  decision processes or effort.
The majority of information retrieval ev aluation metrics are based on either posi-tional (static) or cascade (adaptive) models of user behavior, both of which assume lin-ear, top-to-bottom reading patterns [3]. Given the findings above, it appears that these models are not capturing complexities that are present in searcher behavior. Investi-gating how such patterns can be incorporated into refined models, and how this might impact on evaluation metrics, is an interesting avenue for future work.

Our analysis also showed differences in gaze behavior for tasks of different complex-ity levels: for simple remember tasks, searchers tended to constrain their attention to the top half of the results list, with their zone of interest flattening out at around rank posi-tion five, presumably after they have found a sufficient number of relevant documents to satisfy their information need. For more co mplex tasks, users worked their way down the results list more quickly, and also to a gr eater depth, on average. This effect of task type on search behavior needs to be better understood. For example, different tasks might be approached with different expectations about the number of documents that need to be found; this might partially explain why users tended to read faster for the more complex tasks. We have investigated some of these relationships in other work based on the same user study [10]; and also explored the effect that answer quality has on user behavior [14].

A related issue is the potential impact that the instructions given to user study par-ticipants might have on their search behavior. Such effects have been observed when administering questionnaires, for example [9]. While prior work has demonstrated that framing artificial information needs in a task-based scenario can increase the fidelity of searcher behavior [2], the impact on gaze be havior when reading a search results screen is an open research question.
 Acknowledgments. We thank Dingyun Zhu for his help running the experiments. This work was supported by the Australian Research Council.

