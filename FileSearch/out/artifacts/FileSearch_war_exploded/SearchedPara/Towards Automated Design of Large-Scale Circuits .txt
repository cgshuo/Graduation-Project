 With ever-growing scales and complexities of electronic circuits, both automated design and knowledge discovery of them become even more challenging tasks for artificial intelligence. As an important branch of Evolvable Hardware (EHW) [1,2], an emerging field, evolutionary design of circuits (EDC) [2] refers to applications of artificial-evolution based techniques especially Genetic Algorithms (GAs)[3] to circuits) according to design targets. It is theoretically capable of automatic searching out optimized solutions to problems of circuit design even without a priori knowledge and human interventions, although the reality is far from ideal. 
As to logic or digital circuits, EDC is mainly implemented at two distinct abstract-levels, gate-level and function-level. In contrast with a function-level evolution [1,2,4] that usually employs larger scale modules with more complex functions and directly evaluates fitness on hardware (e.g . programmable logic devices), a gate-level evolution [5-7] usually takes logic gates as basic units and evaluates individual's fitness through software simulation, which endow it with some advantages such as applicability and analyzability. So far, most works reported in gate-level evolution are concentrated on combinational circuits especially arithmetic circuits, mainly for the sake of seeking novel or efficient building-blocks. But they seldom managed to deal with multiple objectives or design requirements involving function, gate count and operating speed of logic circuits [5-7, 10]. 
We have developed a novel approach to gate-level multi-objective evolution of larger scale logic circuits. The approach features an adaptive multi-objective genetic algorithm and a mechanism of two-way enhancements of EDC and knowledge discovery, as illustrated in Fig. 1. The remainder of this paper was contributed to introduction of main ideas, algorithms and experimental results of it. As depicted in Fig. 2, the gate-level abstract model adopted in this paper take the form of a rectangle array comprising logic units of C rows by L columns, each of which has K inputs, M outputs and N kinds of configurable functions. For all logic units, let the |1  X  i  X  q }. Then, if each unit is allowed to input from the arrays' external inputs, units' outcomes and logic constant LC ={0,1} and to feed its outcomes to other units and the signals are subsequently taken as sources) are permitted which consequently result in a sequential circuit. Otherwise, if each unit is not allowed to input from the units located unit located in column x , feedbacks are actually prohibited and the array is restricted to represent combinational circuits. Thus, such an array model is universal and convenient for representation of both sequential and combinational circuits. 
To encode the array, all units including the virtual units for external inputs are numbered orderly from rows to columns. A unit located in row i and column j , 1  X  i  X  C , 0  X  [ IS equal to the sequence numbers of the K units that output to it respectively, and TS CN corresponds to its current function selected. By linking all units' encoding strings and encoding, i.e. chromosome of a potential circuit looks as follows decrease the problem scale and to improve ef ficiency, it is helpful to define as compact as possible a subset of logic functio ns, considering research intention of and the design task. For most EDC tasks of combinational circuits, it is feasible to adopt just two-input logic gates with 4 configurable functions, AND2, OR2, NOT and XOR (eXclusive-OR), which are most often used in conventional designs and form a complete logic set. As to sequential circuits, it is usually necessary to include additional memory-units, e.g., registers or latches in the subset. To design circuits is unavoidable to meet multiple targets or specifications, which make it a typically difficult multi-objective optimization problem expressed as 
To solve the problem with efficiency and simplicity, a well-known fitness function in the form of 'sum of weighted objective functions' was adopted with modifications, which converts the problem into its single-objective equivalent that a GA is good at Where Fit i ( X ) denotes the normalized objective function corresponding to object function f i ( X ); w i denotes the relevant weight factor for i =1... N , which satisfies 
To let the genetic search process pay attention to all objectives, the weight factors { w i } are designed to change dynamically in a way similar to that of the back-propagation learning algorithm commonly used in artificial neural networks Where  X   X  [0, 1] is a constant suggested 0.8 or so by experiments; ) ( t Fit average fitness of all individuals in the population. Provided that  X  w i (0)=1, E q u a ti on ( 4 relevant weight factor and resultant optimizing pressure on the objective would be, while an less optimized objective and its weight factor will be treated in a reverse direction. Meanwhile, initial values of the weight factors are still meaningful to express user-preferences, although it is usually set as w i (0)=1/n, 1  X  i  X  n . 
For gate-level EDC, design targets mainly include expected functions or behaviors, efficiency of resource usage and operating speed of circuits. It is vital for an evolved circuit to behave 100% correctly according to the expectation, which is usually described with a truth table for combinational circuit or a state table for a sequential one. So, it is natural to express such a design object with a ratio of Number of Matched Operations ( NMO ) to Total Number of defined Operations ( TNO ) 
Each operation corresponds to a specified co mbination of (input, output) or (input, current state, output, next state), and it is scored 1 for 'correct' and 0 for 'incorrect' by a simulation subprogram designed to figure out every unit's logic level and active time for every operation. The active time is estimated by the unit's location in a signal path, based on the assumption that each unit's propagation-delay is independent of its logic function. To get a smoother landscape that is consequently easier to search, each output variable is counted respectively when computing NMO and TNO . 
As a less gate-number is usually preferable, it is also natural to measure efficiency of resource usage of a circuit in terms of gate count. While every candidate circuit Number of Unused Gates ( NUG ), which are gates that have no effective effect on the candidate's behavior, e.g. even numbers of NOT gates linked in serial, a gate with its output not referred, etc. By identifying all Unused Gates in a circuit with their predefined features and simulation results, the relevant objective function can be computed as NUG divided by TNG (i.e., Total Number of Gates comprised) Operating speed of a candidate circuit can be estimated with its Maximal Propagation-Delay ( MPD ) from external inputs to array outputs, using simulation results regarding active time . The objective function can be computed as Where, k 1 is a user-defined parameter. With the normalized objective functions to be maximized, Fit 1 , Fit 2 and Fit 3 , the fitness function to synthetically evaluate a candidate circuit can be defined as Some GA parameters especially crossover probability P c and mutation probability P m have great effects on performances of the GA, and their optimal values are hard to be predefined because they vary with conditions. To improve the GA's performances, P c and P m are ordered to self-adapt to genetic-procedure and individuals' diversity. The former is estimated by relative generation number , a ratio of the current generation number t to the maximal generation number defined t max . The latter is measured with concentration degree of individuals in the population, which is estimated as &lt;+ exactly, it will simultaneously vary with the latter but in a reverse direction. On these bases, P c and P m are ordered to adapt themselves in the following manners slowly decrease in the evolution process, meanwhile they will respond to the changes of individuals' diversity. With such a self-adaptation mechanism simulating some principles of bionomics and developmental biology [8-9], P c and P m will be probably suitable for a whole evolution process, e.g., a higher P c and a higher P m to speed the the coming premature (local) convergence implied by an increasing f d ( t ) during the whole process of evolution search, a lower P c and a lower P m to improve the quality of the 'optimal solution' at the final stage of evolution ( t 0  X  t  X  t max ), etc. Although EDC has succeeded in obtaining efficient or novel solutions, it is weak in solving large-scale and complex problems mainly due to its computation-expensive nature. Therefore, the idea of divide and conquer featured by conventional design methodologies is also useful to EDC, that is, to decompose a problem into several simpler sub-problems and solve them (top-down), or conversely, to build a circuit by connecting modules of several types together (bottom-up). As shown in Fig. 1, these involve extracting meaningful sub-circuits or design principles from the evolved solutions and reusing them by integrating EDC with Case-Based Reasoning (CBR), so as to solve the scaling problem an d to understand the evolved circuits. 
CBR is an artificial intelligence technique that solves new problems by using or adapting past solutions. In CBR systems knowledge is embodied in a library of past cases (i.e., case-base), rather than being enc oded in classical rules. Each case typically contains a description of the problem, plus a solution containing implicit knowledge and/or the outcome. To solve a current problem with CBR, it is matched against the cases in the case-base, and similar cases ar e retrieved and used to suggest a solution which is reused and tested for success and then revised if necessary. Finally the CBR quite suits EDC requirements of extraction and reuse of principles contained in EDC results, as demonstrated by some preliminary results [11, 12]. 
The primary difficulties herein exist in building a case-base. While CBR relies on cases that have known structure, e.g. attribute value pairs, evolved circuits lack any understanding incorporated in their structures. As a result, all knowledge beyond their functionality must be identified before building a useful case-base. Instead of using a GA as a knowledge lean method to generate knowledge for a case-base, we employed the GA with efficient and flexible genotype-phenotype mapping to produce efficient solutions and to consequently eas e the creation of a case-base. 
The first step to create a case-base is to remove redundant information and facilitate the CBR functions of matching, retrieval and adaptation. The second step involves splitting the normalized circuits into sub-circuits and calculation of their structure, behavior and functionality. It is followed by separating the sub-circuits into perfect and imperfect solution elements for the given requirements. Finally, the circuits are indexed according to their function, behavior, structure, and sub-circuits, by using a case-based indexing mechanism. Each circuit or case in the case-base stores its own information on its similarity to all other cases, which is represented by four indexes correspond to its function, behavior, structure and sub-circuits respectively. These indexes need only be calculated once, and additional cases can be indexed in linear time proportional to the size of the case-base. With the case-base built, matching of cases is achieved efficiently by using the Nearest Neighbor Matching function that ranks the cases, giving rise to applications such as discovery of equivalent circuits or implementations of logic functions, transform formulas and optimal circuits in terms of gate count, speed, etc. Moreover, imitating the way that human designs manage to solve relatively large scale problems mainly by assembling verified build-blocks, appropriate cases or circuits in the case-base can be retrieved, assembled and tested automatically towards larger and more complex circuits in accordance with the ex pected behaviors and performances of circuits. In this way, novel knowledge for circuit design could be discovered from EDC results, and in return the knowledge discovered will help understand the evolved circuits and partly solve the scaling problem of EDC. By integrating the ideas discussed above in to an EGA framework with roulette-wheel selection, one-point crossover and simple mutation, which is theoretically proved able to converge in a probability 1, the approach for evolutionary discovery is created. With this approach, evolutionary design experiments on some benchmark problems for gate-level evolution [6,7,10], including even-parity checkers and multipliers, have been implemented successfully. Thanks to th e adaptation measures that are validated to improve robustness of GA, the experiments worked very well with a set of parameters. Besides the parameters given, initial values of weight factors are set as w (0)= w 2 (0)= w 3 (0)=1/3, whereas population size and maximal generation number were specified according to the problem scale. 
An n -bit digital multiplier is a combinational circuit that output the product of two groups of n-bit binary numbers . A series of experiments were carried out on program were performed. A 2-bit multiplier evolved is depicted in Fig. 3, which is as good as the best one ever known. A 3-bit multiplier evolved is depicted in Fig. 4, where GN is short for gate number and DN for delay number. It is 10.7% more efficient and 20% faster than the best one designed by a human expert, which features GN=28 and DN=10. Meanwhile, it is in fact as good as the most efficient one evolved gates with one input inverted . One such nonstandard AND gate is actually equivalent to 2 gates, i.e., a AND gate in conjunction with a XOR gate as emerged in our results that is rather difficult even for human experts to design, our result evolved from GN=64, DN=24) and that evolved by Miller et al [6, 10] from a conventional design result, which consists of 57 gates including 10 nonstandard AND gates and features DN=20. All these evolved circuits feature wondrous reuses of inner outcomes. They imply that our approach is effective and it surpassed its congeners and human experts, especially with larger circuits. With the techniques discussed in section 5, some experiments were carried out on evolved circuits. For a binary addition, the core of a binary multiplication, following expressions that derive the carry from the addends have been identified Where CF n and CS n denote respectively the least-bit and the secondary-least-bit of the efficient implementations of multipliers. 
By analyzing the experimental results of even-parity checkers of increasing inputs, formula for even-parity checkers of arbitrary bits wa s also found as transform formulas regarding exclusive-OR logic were also obtained as Although the above extracted principles are easy to prove with knowledge of Boolean algebra, they are rather difficult for human experts to dig out with conventional approaches. These results imply that the approach is useful to acquisition and discovery of relevant knowledge. In this paper, a novel EDC approach involving CBR-based data mining was proposed and verified. By virtue of a series of measures cooperating together, this approach was proved capable of automated design of multi-objective optimized logic circuits, and it was shown very helpful in discovery of novel and optimized building-blocks along with new principles and rules. In future we will study the ways to enhance EDC and knowledge discovery more efficiently and interactively so as to solve large-scale problems and acquire new knowledge. 
