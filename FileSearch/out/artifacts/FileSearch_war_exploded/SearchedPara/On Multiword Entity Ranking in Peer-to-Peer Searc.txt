 Previously [2], we postulated the advantage of using entity extraction to implement a new Peer-to-Peer (P2P) search framework for reducing network traffic and providing a trade off between precision and recall. We now propose an entity ranking method designed for the  X  X hort documents X  characteristic of P2P, which significantly improves both precision and recall in  X  X op results X  P2P search. We construct a dynamic entity corpus using n-grams correlations between user query terms. H.3.3 [ Information Storage and Retrieval ]: Information search and retrieval General Terms : Performance, Experimentation. Peer-to-peer (P2P) file sharing sy stems are distributed networks in which peers exchange information directly with each other. Every terms called a descriptor, which we view as a short document. In most P2P file-sharing systems, to find a file, users issue a query, terms in the query are independently matched against descriptors of other peers, and only those that ma tch all query terms are returned to the user (conjunctive queries (C Q)). The main disadvantage is clear: no attention is given for the semantics that many multiple terms constitute of. We identify multiword named entities (of any type) by computing the statistical correlation between terms in each n-gram accumulated over P2P data. N-grams that incl ude terms with high correlation between them generate a named entity corpus, and are used to parse each query to its correct entities by a simple matching of the n-grams appearing in the query with the corpus entities. To evaluate our method, we compare a proposed statistical function against a well studied one, and evaluate both over four well known performance measures. We report a minor difference between the two, but a significant improveme nt over standard conjunctive queries ranking. We then enrich the entity corpus using metadata and show an additional improvement. Each file for each peer contains a descriptor which describes the file (e.g., Red Hot Chili Peppers, Greates t Hits). We construct an n-gram table that includes unigrams, bigrams, trigrams, and 4grams, based on the large collection of desc riptors that peers hold. Each n-gram is stored with its frequency. After constructing the n-gram table, along with their frequencies, we apply a statistical measure method called  X  the fair Symmetric Conditional Probability X  (SCP) that tests the statistical correlation between n terms [1]. probability of terms ) ... ( AVP is computed by averaging over all possible partitions. For comparison, we use an additional correlation function called  X  X xponential Frequency Growth X  (EFG): [2] where ) ( Our experiments showed that SCP and EFG are both successful statistical functions to identify multi word entities. However, due to to identify exceptions (e.g., rare entities). Thus, we added an optional enhanced technique that exploits the presence of metadata in many shared files (e.g. artist name, album name, etc.), and use it to enrich the entity corpus. We tested both SCP and EF G performance on 1,000,000 file descriptors crawled from LimeWire  X  X  Gnutella system, using IR-Wire, a publicly available research tool [3]. We also used a database of 20,687 song artists (perform ers and songwriters) and 55,794 songs (the data were collect ed by www.secondhandsongs.com), likewise publicly available. After computing n-grams and frequencies accumulated from the collection, we separately applie d the SCP and EFG functions to every n-gram in the table. Ideally, real entities would get higher values on average than non-entities; therefore, we compared the average of our known entities SCP/EF G values, with the average of the entire n-grams SCP/EFG values. Clearly, the n-gram collection has many true multiword entities that are not present in our entity database, and therefore, we expect those entities to have high values as well. However, we assume that most of the n-grams are not entities, and we expect the average of the entire collection to be significantly lower than the average of a small group of known multiword entities. Table 1 confirms our assumption; we note a significant difference between the statistical functions average values for the known entities and the entire n-gram collection. For example, the EFG average valu e of 2,500 bigrams that were identified as 2-word entities is 15. 70, while the EFG average value of the entire bigrams collection is 1.18. Furthermore, we can see in Table 1 that the average function value is different for each entity length (i.e., average SCP value of 2-word entities is different from the average SCP value of 3-word entities). Therefore, three thresholds were determined for each function. All thresholds were experimentally evaluated. We propose a two phase algorithm that uses entity based ranking to improve precision and recall in  X  X op results X . For the  X  X ffline X  phase, we assume global information is av ailable. Here STAT is either SCP or EFG, and thresholds. Using the 1,000,000 file descriptors collection, plus three different randomly chosen sets of 96 queries also collected from IRWire [3], we simulated a centralized P2P search, in which global information is available, and all the nodes are visited in each search; query evaluation Table 1. SCP and EFG Average Values for Known Entities Versus the Entire Collection. was done manually by us. We first retrieved files using standard conjunctive queries and ranked the results based on group size (used as a baseline). We then re-ranked the results using our proposed entity ranking algorithm (we compare 4 different functions for multiword named entity: SCP, SCP + metadata, EFG, and EFG + metadata). We used the following well known performance measures: Precision at top k files: (we chose 10 = k and 20 = k ), Binary Preference (bpref) (with R=5), and Mean Reciprocal Rank (MRR). Our results are presented in Table 2; we denote the combination of SCP and metadata by SCP+, EF G and metadata by EFG+, and conjunctive queries by CQ. It is shown that both SCP and EFG achieve a significant (P-value &lt; 0. 01, paired t-test) improvement over the standard conjunctive queri es. Metadata were only helpful in a few queries where both SCP and EFG failed to identify entities; as a result, it only provides a minor improvement. In this work we assumed a centralized P2P network; we leave the decentralized network study and s calability issues for future work. P er f ormed  X  X  ff line X  ( p re p rocessin g ): Performed  X  X nline X : 
