 Searching for scientific publications on the Web is a tedious task, especially when exploring an unfamiliar domain. Typ-ical scholarly search engines produce lengthy unstructured result lists that are di cult to comprehend, interpret and browse. We propose a novel method of organizing the search results into concise and informative topic hierarchies. The method consists of two steps: extracting interrelated topics from the result set, and summarizing the topic graph. In the first step we map the search results to articles and categories of Wikipedia, constructing a graph of relevant topics with hierarchical relations. In the second step we sequentially build nested summaries of the produced topic graph using a structured output prediction approach. Trained on a small number of examples, our method learns to construct infor-mative summaries for unseen topic graphs, and outperforms unsupervised state-of-the-art Wikipedia-based clustering. H.3.3 [ Information Storage And Retrieval ]: Clustering; H.3.5 [ Information Storage And Retrieval ]: Online In-formation Services X  Web-based services academic search; search result clustering; topic hierarchy; graph summarization; structured prediction; Wikipedia;
We search for publications on a daily basis X  X o keep up with our research fields, to expand our competences, and to find related work. The number of papers being published is far beyond what a scientist can consume, so we have to be very selective in what we read or even look through. Schol-arly digital libraries and search engines allow us to easily find papers provided we know, at least partially, their ti-tle or other bibliographic data, such as authors, publication venue, and year. The way the search results are presented X  the infamous  X  X en blue links X  X  X owever, proves insu cient for more complex, yet typical, information seeking tasks. Whether reviewing related work or exploring a new research domain, we often want to perceive the returned results as a whole, identify the constituent topics, and understand their span and interrelations. We would also like to find papers more e ciently without sifting through the overlong lists of mostly irrelevant items. Grouping the search results accord-ing to salient topics, were we be able to identify them, could help in this regard. Concise and structured visual represen-tation of the topics would provide both the global picture and the means to focus on the relevant details.

Predefined taxonomies provide a natural way of group-ing the scholarly search results in a given scientific discipline. Computer science publications, for instance, can be orga-nized with respect to ACM Computing Classification Sys-tem (CSS) , and biomedical articles with respect to Medical Subject Headings (MeSH) . One of the benefits of such pre-defined taxonomies is that they provide hierarchical group-ing of publications, which can be viewed at desired level of granularity. Another benefit is that the groups have well-defined semantics and meaningful labels corresponding to the subtopics of the discipline in question. Hierarchical re-lations between the subtopics provide additional useful in-formation about the structure of the field in a visual way.
The main drawback of the predefined taxonomies is that they have to be manually created and kept up-to-date, which requires significant e  X  ort. For example, ACM reports 120 computing specialists having worked on the new version of the Computing Classification System 1 . Assigning new articles to existing categories manually is impractical at the scale of an academic search engine like Google Scholar , when the collection of publications is expanded in an auto-mated way while crawling the Web. Categorizing the articles automatically, on the other hand, is a nontrivial task.
Unsupervised learning methods , such as clustering, self-organizing maps, and latent topic models, constitute an alternative approach to grouping and visualization of the scholarly search results. The advantage of this approach is that grouping is completely automatic, while the main drawback is that the results of the grouping are not easily interpretable. Firstly, some of the discovered groups may simply not correspond to distinct topics relevant to a hu-man user. Secondly, generating meaningful cluster labels is still a challenge for unsupervised methods despite persistent research e  X  orts in this direction [6]. http://www.acm.org/news/featured/2012-acm-ccs
Another limitation inherent to most of the unsupervised grouping methods is the necessity of choosing the number of groups (clusters, topics, etc.) with hierarchical clustering being a notable exception. In order to discover meaningful topics in the result set, unsupervised models have to be pre-viously built on a large corpus of data, a  X  X niversal dataset X  [21], which is usually a computationally expensive task that cannot be performed on the fly. For most of the methods this implies choosing all the parameters, such as the num-ber of topics, beforehand. The chosen topic granularity then has to remain fixed, even though it may not be optimal for specific users and queries.

Wikipedia is a large online encyclopedia that is collab-oratively edited by Web users. Containing over 4 million articles in English alone, it covers a broad range of subjects in considerable detail. Wikipedia articles can be viewed as fine-grained topics with short and meaningful titles. The articles are arranged into categories that form a subsump-tion hierarchy and can be viewed as higher-level topics. The network of articles and categories combines most of the ad-vantages and avoid most of the drawbacks of both predefined taxonomies and unsupervised learning X  X ased groupings.
We propose a Wikipedia-based method for summarizing document collections, in this case applied to academic search results. Given a document collection, we first build a large graph of relevant Wikipedia topics and then select the most informative subgraph thereof to serve as a topic summary (e.g. Figure 1). Selecting an informative summary is a chal-lenging problem, first, due to its combinatorial nature, and second, due to the vagueness of the notion of informative-ness. In this paper we propose a novel approach to building informative summaries through structured output predic-tion. We construct the summary subgraphs sequentially,  X  X rowing X  them from smaller subgraphs, which allows us to alleviate the complexity of the problem, while maintaining the collective contribution of topics into the quality of the summary. In order to capture the properties important for good topic summaries, we learn how to grow such summaries from examples. We demonstrate that our method is able to learn from a small number of examples and produce infor-mative topic summaries for unseen document collections.
In the following section we review existing approaches to grouping search results and finding topics in document col-lections. In sections 3 and 4 we show how to extract topic hi-erarchies from Wikipedia and describe our method of graph summarization. We report on the evaluation of the proposed method in Section 5 and conclude the paper in Section 6.
The benefits of the structured representation of search results have long been realized in the area of general Web search. Cutting et al. [8] first introduced a clustering method, Scatter/Gather, as a metaphor for exploring document col-lections, while Hearst and Pedersen evaluated this method in the context of Web search [14]. A variety of clustering algorithms have since been applied to Web search results. We refer the reader to [6] for an extensive survey on the subject. The problem of choosing meaningful cluster labels has always remained crucial. Selecting the labels after and independently of the clustering phase is a di cult problem. Zamir and Etzioni [28] suggested using a su x tree for dis-covering phrases to form initial cluster seeds and serve as cluster labels. Another influential work, Osiriski et al. [22], represents the class of methods in which providing cluster labels is the central goal. This work is also an early example of using a dimensionality reduction technique for discover-ing topics in search results. Other data mining techniques that have been applied to this problem include agglomera-tive clustering [17], k-means clustering [27], concept lattices [7], and probabilistic topic models [21].

Organizing the results of academic search has not been discussed widely in the literature. However, there has been a substantial amount of research into organizing publica-tion collections, discovering and visualizing scientific topics, and identifying research trends. Probabilistic topic mod-els represent a class of methods that have been extensively employed in the context of scientific papers. Gri th and Steyvers [11] applied Latent Dirichlet Allocation (LDA) [4] X  a general-purpose topic model X  X o a collection of abstracts from PNAS. A correlated topic model developed by Blei and La  X  erty [3] improved upon LDA by introducing pair-wise topic correlations. Pachinko allocation [16] allowed more complex and sparse topic correlations by modeling topic mixtures through directed acyclic graphs. Specific topic models have been developed to account for various aspects of the scientific literature, such as explicit document authorship [23], topic evolution [2], and citations [13]. As mentioned in the introduction, the main drawback of topic models is not producing meaningful topic labels.

Using external knowledge sources, such as Wikipedia, for organizing search results and documents in general has also been discussed in the literature. Gabrilovich and Markovitch [10] proposed representing texts as weighted combination of concepts based on Wikipedia articles for the purpose of com-puting semantic relatedness between texts. Han and Zhao [12] grouped the search results according to the topics de-fined as communities in the graph of semantic relatedness between Wikipedia articles. S  X ac  X area et al. [26] exploited redirects and disambiguation pages of Wikipedia to improve the results of formal concept analysis. In the work of Calli et al. [5] semantic relations derived from Wikipedia were used to improve the performance of the Su x Tree Clustering al-gorithm. Similarly to our work, Scaiella et al. [25] annotated the search result snippets with links to Wikipedia articles. The grouping of the results in their approach was performed based on the spectral clustering of the graph of snippets and topics. In contrast to these works, we use both articles and categories of Wikipedia to directly represent topics in the result set, and rely on their hierarchical relations for fur-ther grouping and visualization. More importantly, we sum-marize the document-topic graph in a supervised manner, which allows us to learn nontrivial combinations of features responsible for informative topic summaries.
In this section we describe the procedure of extracting a valid and useful hierarchy of relevant topics from Wikipedia. As an input we assume to have a collection of documents D = { d 1 ,d 2 ,...,d N } , which in the scenario of academic search may be publication abstracts retrieved by a search engine. The result of this step is a topic graph G ( V, E ), with links ( v, v 0 ) 2 E representing hierarchical parent-child relations between the topics, and a relation R  X  V  X  D defining which documents are relevant to which topics. For a valid topic hi-erarchy, graph G must be an acyclic.
We treat both articles and categories of Wikipedia as top-ics. The procedure of building the topics graph consists of the following steps: a ) mapping documents to Wikipedia articles, b ) retrieving the parent categories, c ) merging du-plicate topics, d ) breaking the cycles in the topic graph, and e ) extending the main topic.

Mapping the documents to Wikipedia is performed using wikification procedure [18]. Wikification annotates ar-bitrary texts with links to Wikipedia articles in the same way as Wikipedia articles are linked to each other. We concate-nate the texts of the documents into a single query string and submit it to Wikipedia Miner [19] X  X n open source wik-ification tool. We then associate each document with the set of Wikipedia articles to which its text has been linked. R := { ( v, d ) | the wikified text of d contains a link to v } ,
Retrieving the parent categories is a step that estab-lishes relations between the topics, providing the main tool for generalization and summarization. For every article v obtained at the previous step, we augment the discovered set of topics V with all its parent categories: Relations Pages in category and Subcategories defined be-tween Wikipedia pages become links in the topic graph:
Merging duplicate topics. Some of the topics have both an associated article and a category in Wikipedia. In order for our topic graph to contain no redundant nodes we merge such duplicate topics into one. In addition, we merge near-duplicate topics whose titles coincide up to lemmatiza-tion , for instance, the article Decision tree and the category Decision trees . After this step we start treating articles and categories as topics without any distinction.

Breaking the cycles. Due to occasional cycles, the cate-gory graph of Wikipedia does not form a valid hierarchy. For the purpose of our method we detect and break the cycles in the topic graph using a depth-first search.

Extending the main topic. When the main topic of the collection of documents (e.g. the search results) is very spe-cific, it will be represented as a leaf node in the topic graph. At this step we detect the main topic and augment it with child nodes to provide additional usful information about its structure. Our simple heuristic approach selects the topic with the most associated documents as the main topic v main When extending v main with a child topic v we require the following properties to hold: a ) v should be already present in the topic graph ( v 2 V ), b ) Wikipedia article about v should contain a link to the article about v , c ) v should not be an ancestor of v main in the topic graph. Interestingly, the child nodes v introduced in this way are often not proper subtopics of v main , but can be viewed as such in context (think, for instance, of Regularized trees in the context of Feature selection ). The described heuristic procedure thus usually transforms the topic graph in a useful way, providing the main topic with informative sub-structure.
The topic graph G and topic-document relation R built at the previous step contain useful information about the distribution of topics in our document collection D .How-ever, at this point the graph is too large to be an informative visual representation of the documents: for a hundred pub-lication abstracts, the typical number of topics in G exceeds two hundred. At this step we select a subgraph of G to be used as a visual summary of the document collection. Given alimit T on the number of topics in the summary, our goal is to select the subgraph G T that represents the collection of documents in the most informative way.

We do not intend to grasp the exact notion of  X  X nforma-tiveness X , which may not be objectively definable. Instead, we define the properties important for good topic summaries and learn their correct proportions from examples.
The learning problem , formulated as structured pre-diction, is to find weights w for a linear scoring function that is maximized by good topic summaries. The summaries for new topic graphs G are then constructed by maximizing this function over the set of all possible subgraphs: Computing the argmax is generally prohibitively expensive, as it requires evaluating the scoring function over | V | graphs. We alleviate this problem by imposing an additional constraint that is natural for our settings. Specifically, we require that for a given input graph G the optimal topic summaries of di  X  erent sizes should be nested: In other words, bigger summaries can be obtained from smaller ones by only adding new topics: This requirement is justified by the principle of least sur-prise: when moving from less to more detailed summaries, the user will likely not expect the topics to disappear. Con-sidering this requirement, the problem can be reformulated as predicting the sequence of topics  X  v 1 ,  X  v 2 ,...,  X  v fixes constitute the nodes of intermediate summary graphs. Assuming that we have  X  X round truth X  examples of the form (( G, R ) , ( v 1 ,...,v T )), we can view this as an imitation learn-ing problem, in which we want to copy the expert X  X  behavior in selecting the topics ( v 1 ,...,v T ).

DAgger (Dataset Aggregation) framework [24] allows us to reduce this problem to training a local policy that predicts the best next action (topic v t +1 ) given the current state (ini-tial input ( G, R ) plus the current summary  X  G t ). In essence, DAgger ensures that such a policy behaves well when ap-plied to its own-generated, often non-optimal, states. The way this is accomplished is by iteratively retraining the pol-icy on an updated training set. At each iteration the training set is augmented with examples (( G, R,  X  G t ) ,v opt t +1 inputs ( G, R,  X  G t ) are produced by the current policy, and outputs v opt t +1 are optimal actions provided by the expert.
Applying DAgger requires two ingredients: 1. apolicy  X  :( G, R,  X  G t ) 7!  X  v t +1 that can be trained on 2. an  X  X xpert X   X   X  :( G, R, v 1 ,v 2 ,...,v T ,  X  G t ) 7! v
Providing the policy. In order to build the policy  X  , we need a classifier that can learn how to map an interme-diate topic graph ( G, R,  X  G t ) to the best next topic  X  v view this as a structured prediction problem similar to the formulations (1, 2). Specifically, during training we would like to learn a linear function that is maximized by optimal decisions v t +1 . The prediction is then performed by maximizing the learned function for a given input ( G, R,  X  G t ) over the possible set of topics: The crucial distinction from the formulations (1, 2) is that argmax is computed over the set of topics rather then sub-graphs, which is feasible. We apply the SV M rank software [15] to this prediction problem. In order to compute the partial ranking r G,R,  X  G input ( G, R,  X  G t ) we define the loss between the sequences and compute its value with respect to the optimal decision: r In our experiments we defined ` G,R to be a 0 X 1 loss, which corresponds to specifying no preferences between non-optimal decisions, resulting in an easier problem for SV M rank . Providing the expert actions. At each iteration of DAgger we need to compute the optimal actions v opt t +1 for all states ( G, R,  X  G t ) generated by our current policy. This is accomplished by minimizing the loss with respect to the true optimal sequence: In these settings 0 X 1 loss is inappropriate, as it gives equal score to all non-optimal sequences, rendering the minimiza-tion problem meaningless in most cases. An obvious can-didate for ` 0 G,R is Jaccard distance function. However, it turns out that Jaccard distance does not take into account similarities between topics: it tends to add topics present in the optimal sequence, even when the non-optimal partial sequence already contains similar topics. In other words, it encourages redundancy in the built topic summaries.
We designed a matching-based loss function ` 0 G,R that does not su  X  er from this problem: The matching score greedily assigns best-scoring candidate topics to the topics from the optimal sequence, starting from the first optimal topic v 1 . The score of the assignment ( v, v is computed as Jaccard distance between the sets of docu-ments transitively associated with the topics v and v 0 , plus a constant  X  if v = v 0 . The final matching score is the average of the assignment scores divided by 1 +  X  .

Features. In order to compute the scoring function in the formulations (3, 4) we need a joint feature representation ( G, R,  X  G t ,v t +1 ) that will allow the classifier  X  to learn the distinction between good and bad topic summaries. The features we use constitute various properties of the topic graph G t +1 that results from adding the topic v t +1 to the graph  X  G t , and include, for instance, document coverage and overlap of topics in the graph. We refer the reader to [20] for the detailed description of the features.

Connecting topics and documents. The learning pro-cedure described above allows us to sequentially select the topics v 1 ,v 2 ,...,v T to be included into the topic summary G
T . In order to completely define the summary graph, we need to decide how to connect the topics with links. On one hand, we want to maintain the hierarchical relations be-tween the topics in the graph, but on the other hand we do not want to clutter the topic summary with unneces-sary links. The way we solve this problem is by introducing the minimum possible number of links that still maintain the hierarchical structure of the original topic graph: for every v i ,v j 2 V T such that v i is an ancestor of v j in the original graph G , v i must be an ancestor of v j in the topic summary G T . Technically, this amounts to computing the transitive closure G + ( V, E + ) of the original graph, selecting the subgraph of G + containing the nodes v 1 ,v 2 ,...,v T computing the transitive reduction of the result.
We carried out the evaluation of the proposed method on the search results obtained from Microsoft Academic Search for 10 distinct queries. For each query we collected one hun-dred top results, discovered the topics in their titles and ab-stracts, and built the topic graph as described in Section 3. The topic graphs were then annotated with  X  X round truth X  topic sequences of length 8, corresponding to nested sum-maries of the topic graphs. The summaries were selected so as to represent the search results and the discovered topics in the most informative way according to our judgement.
The method was evaluated on the task of predicting the topic sequences using leave-one-out cross-validation on the described dataset. Two di  X  erent performance metrics were http://academic.research.microsoft.com/ used: precision@n and match@n. Precision@n measures the percent of correctly predicted topics in the subsequence of length n, taking into account only exact matches. Simi-larly, match@n measures the match score (6) between the subsequences of length n, thus allowing for partial matches between similar topics. For the sake of comparison we imple-mented a baseline greedy coverage algorithm, and adapted the spectral clustering X  X ased method of Scaiella et al. [25].
Baseline GreedyCov algorithm. Selects topics by greed-ily optimizing the document coverage, that is, choosing the topic covering the most of the documents that are not yet covered. We should note that this is a reasonable baseline: it optimizes the frequency and the diversity of the selected topics, both properties being important for a good summary. Our method can also be seen as greedily optimizing a linear combination of features, the di  X  erence being that the feature weights are learned from the training data.

Labeled spectral clustering. Scaiella et al. [25] re-cently proposed a novel method for search result clustering based on Wikipedia. The method performs a particular form of spectral clustering on the graph of documents and top-ics, with subsequent selection of cluster labels. For conve-nience we will refer to this method as LSC (labeled spectral clustering). In the first step of LSC the documents (search result snippets) are annotated with links to Wikipedia arti-cles using TAGME [9]. The topics are then connected with non-hierarchical links based on their relatedness. The subse-quent graph pre-processing step selects the most significant topics by greedily solving a variation of a set cover problem.
The topics are then iteratively clustered based on the spec-tral properties of the graph of topics and their relations. At each iteration the algorithm selects one of the big clusters X  those covering more than max documents X  X nd splits it in two. Informally, the algorithm ensures that the sparsest of the big clusters is selected, and that the split goes through the sparse region of the corresponding topic subgraph. As recommended in [25], in order to obtain T final clusters we build T + m 1 clusters with the described algorithm and then merge m smallest clusters into one. Finally, each clus-ter is labeled with the topic that is most strongly associated with the documents in the cluster. We treat the produced cluster labels as the final output of LSC constituting the top-ical representation of the search results.
 Overall there are the following main di  X  erences between LSC and our algorithm: a ) LSC uses only Wikipedia articles to represent topics, while we use both articles and categories; b ) LSC relies on similarity-based relatedness between topics, while we rely on hierarchical relations in the article-category network; c )in LSC topic aggregation is performed on the basis of clustering, while in our method on the basis of topic generalization (based on the hierarchy); d ) LSC selects topics through unsupervised procedure of labeled clustering, while we rely on supervised structured output prediction.
Details of the evaluation setup. For the ease of com-parison, we used TAGME as a topic annotator for all the three algorithms, thus running LSC in the original settings. When evaluating the results produced by LSC we first embed-ded them into the topic graph, built as described in Section 3, in order to correctly match the results to  X  X round truth X  topics, in particular to capture similar topic matches.
The employed evaluation metrics precision@n and match@n assess the sequences of summary graphs of increasing sizes t 2 1 , 2 ,...,T , as they are produced by our method. In or-der to evaluate the method of Scaiella et al. on the same basis, we ran LSC varying the parameter values and for each t selected the best average result across folds according to the metric in question. For simplicity, max was fixed at the value of 3 which is arguably the smallest number of docu-ments we would like to see in a cluster. We should note that changing the value of max did not notably a  X  ect the re-sults, which confirms the robustness of the method reported by Scaiella et al. The value of m  X  X he number of the small-est clusters to be merged X  X as ranged from 1 to 5, which in our experiment corresponded to producing from 8 to 12 clusters prior to merging. The performance of our method was taken at the iterations of DAgger from one to ten.
Evaluation results. Figure 2 shows the performance of the three evaluated methods in terms of match@n. The figure for precision@n omitted for space reasons shows sim-ilar behavior. The first iteration is equivalent to not using DAgger , which corresponds to training only on the states encountered in the ground truth labeling. As we can see from the figure, at n = 1 the curves coincide, as for each of the 10 queries the methods happen to agree on the first pre-dicted topic. As the number of topics increases, the curves begin to diverge, with the growing advantage of our method over the other two. The advantage over LSC , measured as the di  X  erence between the scores, becomes statistically sig-nificant with p-value of 0 . 05 starting from n = 3, and over GreedyCov starting from n = 6. The di  X  erence between the performance scores of GreedyCov and LSC is not significant for any n . We should note that the performance increase of our method after the first iteration justifies the procedures of dataset aggregation.

We can see that GreedyCov performs reasonably well for small n , which indicates that document coverage is an im-portant characteristic for summary topic graphs of small sizes. As more topics are added to the graph, the per-formance of GreedyCov notably deteriorates. At the point when most of the documents are covered by previously se-lected topics, the greedy coverage strategy becomes subopti-mal, as it starts to prefer  X  X utlying X  topic nodes. The spec-tral clustering X  X ased LSC method encourages regular topic sizes both in terms of contained Wikipedia articles and doc-uments. The drawback of LSC in the context of our task is that it is designed for plain rather than hierarchical cluster-ing. In general we can conclude that, being unsupervised methods, LSC and GreedyCov encode some of the impor-tant properties of good topic summaries. However, as they are not specifically tailored for producing hierarchical sum-maries of various sizes, the captured properties are not suf-ficient for building the sequences of informative summary graphs. In these settings our supervised method has an ad-vantage, as it is able to learn how to combine multiple prop-erties in order to build high-quality summary sequences.
Prototype implementation. The proposed techniques are being implemented in a prototype Web tool ScienScan. The tool organizes the search results returned by an ex-isting service, currently Microsoft Academic Search, and is publicly available at http://scienscan.disi.unitn.it .
We introduced a method for grouping academic search results according to the network of Wikipedia article and category pages. The method produces concise and struc-tured topical summaries useful for visualization and brows-ing. The topics in the summaries are fine-grained, meaning-fully labeled, and up-to-date due to the nature of Wikipedia. We developed a novel algorithm based on structured predic-tion that learns how to produce informative topic summaries from a small number of examples. The proposed method re-lies on the publicly available data and can be implemented on top of existing academic search services.
This research was partially supported by grant prin 2009lnp494 (Statistical Relational Learning: Algorithms and Applica-tions) from the Italian Ministry of University and Research.
