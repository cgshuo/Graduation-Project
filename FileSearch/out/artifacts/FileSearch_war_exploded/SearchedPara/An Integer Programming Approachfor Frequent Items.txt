 The rapid growth of transactional data brought, soon enough, into attention the need of its further exploitation. In this paper, we in-vestigate the problem of securing sensitive knowledge from being exposed in patterns extracted during association rule mining. In-stead of hiding the produced rules directly, we decide to hide the sensitive frequent itemsets that may lead to the production of these rules. As a first step, we introduce the notion of distance between two databases and a measure for quantifying it. By trying to min-imize the distance between the original database and its sanitized version (that can safely be released), we propose a novel, exact al-gorithm for association rule hiding and evaluate it on real world datasets demonstrating its effectiveness towards solving the prob-lem.
 H.2.8 [ Database Applications ]: Data mining; K.4.1 [ Public Pol-icy Issues ]: Privacy.
 Privacy preserving data mining, association rule mining, sensitive itemset hiding, optimization, integer programming.
 Algorithms, Design.
Transactional databases have been widely established in the ma-jority of organizations allowing the efficient storage of large vol-umes of data. No matter what the specific needs of each individual organization are, there is a commonly accepted demand for data acquisition, storage and analysis of this information. Data mining technology has enacted an exceptional role towards the analysis part of these huge piles of data. Using data mining techniques, a modern company can understand the behavior of its customers, support decision making and gain an overall significant benefit over Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. its rivals. Thus, a plethora of data mining algorithms have been constructed especially for handling transactional data.

However the undeniable benefit of analyzing corporate data, there always lurks the fear of unauthorized access to sensitive informa-tion which are stored or inferred from the data. Consider for in-stance the governmental organization that deals with individual tax-ation. The information system on such an organization is expected to contain invaluable sensitive knowledge, such as social security numbers, income, owned property, etc., that must, by all means, re-main confidential. Consider now the scenario under which this data needs to be mined from an affiliated organization in order to assist the government in decision making. Although this organization needs to have access to the general knowledge stored in the reposi-tory, it does not need (and must therefore not be granted) any access to individuals X  sensitive information or derived sensitive patterns. Hiding this information alone (i.e. by removing the corresponding attributes from the dataset) may not be enough to prohibit leak-age of sensitive knowledge. Indeed, association rule mining may reveal sensitive patterns that were even unknown to the database owner prior to their mining. Moreover, inference techniques might be used to uncover private data, as discussed in [7], [13] and [8]. The challenge that arises from this artificial example is the follow-ing: How can we expect reasonable data mining results that will allow for correct decision making when, at the same time, prohibit the disclosure of sensitive information?
Similar motivating examples are discussed in [21], [6], [14] and [19]. Association rule hiding algorithms try to provide a solution to this crucial problem. They do so by accepting a small deviation of the original database that will disallow the production of sen-sitive itemsets at a pre-specified support threshold, usually set by the owner of the data. By prohibiting the construction of sensitive itemsets, we are certain that at the given minimum support thresh-old, and no matter how low the confidence level is set, no sensitive association rule will be exposed. A final critical point that needs to be addressed is that the hiding process should be accomplished in such a way that non-sensitive knowledge remains, to the maximum possible extend, intact.

In this paper we propose a novel, exact technique, for associa-tion rule hiding that is based on the notion of distance between the original database and its sanitized version, where all sensitive rules have been hidden. By quantifying distance, we gain knowledge of the minimum modification that needs to be made in the original dataset in order to hide sensitive, while minimally affecting non-sensitive, itemsets. Then, we formulate an algorithm based on in-teger programming, in which distance is the optimization criterion that needs to be minimized. The experimental evaluation shows that this technique can yield good results on real world datasets.
The rest of the paper is organized as follows: Section 2 pro-vides an overview of the state-of-the-art methodologies for privacy preserving data mining and association rule hiding. In Section 3 we formalize the problem and describe the primary concepts upon which we base the proposal for the new privacy model, discussed in Section 4. Section 5 demonstrates the solution methodology that we followed and Section 6 presents the experiments we conducted to prove the effectiveness of our approach. Some concluding re-marks comprise the contents of Section 7.
There has been a lot of active research in the field of privacy pre-serving data mining. Clifton et. al. in [6], [5] discuss the security and privacy implications of data mining and propose some data ob-scuring strategies (aggregation, fuzzyfication, sampling, augmenta-tion) that can be applied on the original dataset to prohibit inference and discovery of sensitive knowledge. Moreover, they propose re-strictive control over the access to the data and/or elimination of certain references that can lead to disclosure of sensitive informa-tion.

Verykios et. al. in [20] present a classification of the differ-ent privacy preserving techniques based on five dimensions: data distribution, data modification, data mining algorithm, data or rule hiding and privacy preservation. The first dimension refers to the distribution of the data which, in a decentralized setting, can be either horizontal or vertical. In a horizontal distribution individ-ual records reside in different places, while in a vertical one all the values for different attributes reside in different places. Based on data modification, the authors refer to the case of blocking, where the original value of an attribute is replaced by a  X  ?  X . Probably the most important dimension in the classification taxonomy, is the one referring to the privacy preservation technique that is used. Most techniques are heuristic in nature, primarily in order to speed up the hiding process. However, heuristics suffer from local minima problems and usually fail to identify the optimal solution. Our ap-proach is generally exact in nature and uses a heuristic only in the case that an optimal solution does not exist.

The paper in [18] presents two algorithms for association rule hiding that use unknowns. The first algorithm attempts to reduce the support of the sensitive rules, while the second one concentrates on the reduction of confidence. Our proposed methodology can be classified under the same category of blocking techniques since it aims at reducing the support of the sensitive rules in order to hide them.

In [12], Menon et. al. present an integer programming optimiza-tion algorithm for hiding sensitive itemsets while minimizing the number of modified transactions. To avoid the NP-hardness issue of solving the entire problem, the authors decided to reduce the problem size to capture only the sensitive itemsets, requesting that their support remains low. Their methodology is computationally efficient and scalable.

Finally, in [19], Sun and Yu present a very interesting greedy border-based approach for hiding sensitive frequent itemsets. Their methodology is based on the notion of the border constructed by the non-sensitive frequent itemsets in an attempt to track the impact of altering transactions. Instead of considering each non-sensitive itemset individually, their algorithm focuses on preserving the qual-ity of the resulting border.

Figure 1: An itemsets lattice demonstrating border revision
In this section we provide some basic definitions that will allow us to introduce our problem statement. Moreover, we capture the itemsets hiding process as a border revision operation and present algorithms that compute the prior and posterior borders.
Let I = { i 1 ,i 2 ,...,i m } be a set of literals, called items .Any subset of I : I k  X  I is called an itemset . Furthermore, let D repre-sent a transactional database, where each transaction T i set. D can be represented as D = { T 1 ,T 2 ,...,T n } .Fromnow on, we use n to refer to the total number of transactions and m to denote the total number of distinct items appearing in D . To distin-guish between transactions that correspond to the same itemset, we associate with each transaction a unique identifier TID . A transac-tion T i supports an itemset I j from the set I ,if I j  X  items in the itemset appear in the transaction. Alternatively, each transaction can be represented as an m -dimensional binary vector b ,where b j =1 , if and only if, the j -th item appears in the trans-action [15]. Following this notation, the whole database can appear as an n  X  m binary array where: We will call the above representation of D as bitmap . Bitmap rep-resentations are typically sparse in nature. However, there are cur-rently several methodologies that allow their efficient storage, such as the Compressed Sparse Row (CSR) methodology explained in [17].
 Suppose W = { W 1 ,W 2 ,...,W | W | } is a set of itemsets and W  X   X  ( I ) ,where  X  ( I ) is the powerset of I . We will use D denote the set of transactions supporting any of the sets in W . Thus, Givenanitemset I k we denote by  X  ( I k ) its support count ,i.e.the number of transactions in D that contain it. We define the support of an itemset as the fraction of the transactions in the database in which it appears: sup ( I k )=  X  ( I k ) n . When we need to distinguish between the occurrences of an itemset in two distinct databases, say D and D , we will include the referring database in our notation, i.e.  X  D ( I k ) .
 Based on the bitmap representation, the support count of itemset X can be expressed as follows: We will say that an itemset X is large or frequent in D , if and only if, its support value in D is at least equal to a minimum threshold. We call this threshold msup and request that: sup ( X )  X  for X to be frequent. All itemsets with support less than msup are infrequent .

Let  X  min refer to the minimum support count, relative to msup , that defines the borderline between frequent vs infrequent itemsets in D . Then,  X  min = | D | X  msup . Based on this notation, an itemset X will be frequent in D , if and only if,  X  ( X )  X 
Suppose F = { X  X  I : sup D ( X )  X  msup } is the set of all frequent itemsets in D .Wedefinethe negative border of F , denoted as B  X  ( F ) , to be the set of all infrequent itemsets from D in which all proper subsets appear in F . Formally, Symmetrically, we define the positive border of F to be the set of all maximally frequent itemsets appearing in F , An association rule can be defined as an implication of the form A  X  B ,where A, B  X  I and A  X  B =  X  . Every associa-tion rule has two measures strongly related to it: its support and its confidence . The support value of a rule A  X  B is equal to sup ( A  X  B )=  X  ( A  X  B ) n and its confidence is equal to conf B
We consider a subset of the frequent itemsets that contain sen-sitive information, in the sense that these itemsets may lead to the production of sensitive association rules. We call such itemsets sen-sitive and denote their set as SI . Based on the definition of SI ,we use set S to represent the minimal sensitive itemsets, and SS to de-note the set of all sensitive itemsets and their supersets, i.e.
We are given a database D containing transactions T and a mini-mum support threshold msup set by the owner of the data. A subset SI of the frequent itemsets F , discovered in D , are considered as sensitive and must be protected from being disclosed to unautho-rized parties. Our goal is to sanitize selected transactions from D that will disallow the production of rules from itemsets in SI , thus produce a sanitized version D of the original database, in which all these rules are hidden . Moreover, we want to minimize the san-itization impact to any non-sensitive itemsets.

Due to the closure property of the Apriori algorithm (also known as the apriori principle ) [2], it is easy to notice that hiding the item-sets in S will certainly result in hiding all itemsets in SI . Moreover, hiding the itemsets in S results in hiding all itemsets in SS , meaning all sensitive itemsets and their proper supersets. This fact may at a first glance, misleadingly, seem unwanted but in reality it is per-fectly acceptable. An example will help us demonstrate this claim. Suppose that  X  ab  X  is a sensitive itemset that has to be protected and  X  abc  X  is a proper superset. Based on the apriori principle, if itemset  X  abc  X  is reported as frequent, then all its proper subsets must also be reported as frequent. Removing  X  ab  X  but allowing  X  abc  X  would leave an important security gap since one could then easily infer the existence of  X  ab  X  due to the observed existence of  X  abc  X  X nthe resulting set of frequent itemsets.
Sensitive itemset hiding can be considered as a border revision process. Consider the lattice presented in Figure 1. Based on a specific  X  min value, we can attain an initial border that separates frequent from infrequent itemsets. The corresponding borderline is shown in Figure 1, labeled as  X  X riginal border X . The hiding process can then be defined as the revision of this initial border so that it excludes from the frequent itemsets all sensitive itemsets and their supersets. That is, in the ideal scenario, where no non-sensitive itemsets are harmed. In order to hide frequent itemsets, the original borderline will have to move up in the lattice. The original borders in Figure 1 are as follows: As a first step in our approach we would like to model the initial border. We can define a borderline using the notion of positive and negative borders in D , as presented earlier. A straight-forward way to compute the negative border is to incorporate it in the Apriori al-gorithm [2]. The new Apriori algorithm, which we call NB-Apriori , is shown in Algorithm 1. We excluded the presentation of Apriori-Gen function, since it does not need to be modified. The proposed method is based on Apriori X  X  candidate generation scheme, which uses ( k  X  1 ) frequent itemsets to produce candidate k large item-sets. Thus, it achieves to identify the first infrequent candidates in the lattice, whose all subsets are found as frequent. In this algo-rithm, we use F n to denote large n -itemsets in D .

Having identified the original negative border, the next step is to compute the positive border B + ( F ) . Algorithm 2, presents a level-wise (in the size of large itemsets) approach to achieve this com-putation. Assume F is the set of frequent itemsets identified using Apriori. For each itemset in F we associate a counter, initialized to zero. The algorithm first sorts these itemsets in decreasing length and then for all itemsets of the same length, say k , it identifies their ( k  X  1 ) large subsets and increases their counters by one. The value of k iterates from the length of the largest identified frequent item-set down to 1. Finally, the algorithm performs a one-pass through all the counters and collects the large itemsets having a value of zero in the associated counter. These large itemsets, constitute the positive border B + ( F ) .

As mentioned earlier, the borderline of the original dataset needs to be revised in order to allow us to hide sensitive itemsets. We first need to identify the ideal borderline after itemsets hiding. This will be identical to the real borderline of D if and only if the solution to the hiding procedure is ideal , i.e. database D allows us to hide the sensitive itemsets without changing any non-sensitive frequent itemset to infrequent. On the other hand, if this is not possible, we need a way to minimally affect the ideal borderline in order to iden-tify the nearest solution to the problem. We treat both approaches as constraint satisfaction problems and solve them with the help of integer programming ( see Section 5). Especially in the latter case, we use a heuristic to remove constraints that will minimally affect the ideal borderline in order to adjust to a real one. Algorithm 3 presents the hiding procedure in which we identify F by removing from F all sensitive itemsets and their supersets. To do so, we first iterate over all sensitive itemsets SI and large itemsets F and identify those large itemsets that are supersets of the sensitive. We remove these from the list of large itemsets, thus con-struct a new set F with the remaining large itemsets. By moving top-down in the new lattice we identify infrequent itemsets whose all proper subsets are frequent in F , thus compute the negative border of the ideal solution B  X  ( F ) .

As a final step in the border revision context, we need to compute the ideal positive border for D . This is accomplished in exactly the same way we used for D , by applying Algorithm 2 in D (i.e. after hiding all the itemsets in SS ). Assuming that we were applying the procedure of border revision in database D (represented by the lattice depicted in Figure 1), we would get the revised border as shown in the same figure. In the new database D , both itemsets AC and ABC are hidden.
 Algorithm 1 Computation of the Large Itemsets and the Negative Border B  X  ( F ) 1: procedure NB-A PRIORI (D,  X  min ) 3: for k =2; F k  X  1 =  X  ; k ++ do 5: for each t  X  T i do for all transactions in D 6: C t = subset( C k , t ) get cand. subsets of t 7: for each candidate c  X  C t do 8: c.count ++ 9: end for 10: end for 11: F k = { c  X  C k | c.count  X   X  min } 12: B  X  ( F )= { c  X  C k | c.count &lt;  X  min } 13: end for 14: end procedure 15: procedure G ET L ARGE I TEMS (D,  X  min ) 16: for T i  X  D do traverse all transactions 17: for x  X  T i do traverse all items in transaction 18: x.count ++ 19: end for 20: end for 21: for each item x do 22: if x.count  X   X  min then item x is frequent 23: x  X  F k 24: else 25: x  X  B  X  ( F ) add item to negative border 26: end if 27: end for 28: end procedure
Our proposed methodology attempts to hide sensitive itemsets by sanitizing selected transactions. The sanitization approach we follow is based on the modification of selected b ij values from one to zero, thus excluding certain items from some transactions. Since we do not add or remove any transactions, the sanitized version D of the database will have the same size as the original one. There-fore, | D | = | D | .Using F to denote the set of frequent itemsets in the sanitized database D , our target for hiding sensitive itemsets can be expressed as:
It is trivial to prove that the above property can easily be achieved for any dataset D . The simplest solution will probably be to identify all items appearing in the frequent itemsets in S i and remove them from all transactions in D ,i.e. However, this is certainly a naive approach towards solving the problem. What one would like to do in reality is to hide all sen-sitive itemsets by minimally affecting the original dataset. This minimum harm can be quantified as F = F  X  SS meaning that in the ideal case, we expect the sanitized database D to contain all the frequent itemsets of D except from the sensitive ones. By only removing items from transactions in D , we ensure that D will con-tain no ghost-itemsets (i.e. itemsets appearing to be frequent only due to the side-effects of the sanitization process). However, we still need to minimize the loss of non-sensitive frequent itemsets. Algorithm 2 Computation of the Positive Border B + ( F ) 1: procedure PB-C OMPUTATION (F) 2: count { 0 ... | F |} X  0 initialize counters 3: F sort =reverse-sort( F ) 4: for each k -itemset f  X  F sort do 5: for all ( k  X  1) -itemsets q  X  F sort do 6: if q  X  f then 7: q.count ++ 8: end if 9: end for 10: end for 11: for each f  X  F sort do 12: if f.count =0 then 13: f  X  B + ( F ) add itemset to B + ( F ) 14: end if 15: end for 16: end procedure
Menon, et. al. in [12] use the notion of accuracy as the opti-mization criterion for deriving the solution. Maximizing accuracy is equivalent to minimizing the number of transactions from D that need to be modified. Although we consider this measure to lead to an interesting property, we argue that it is the number of actual item modifications rather than the number of sanitized transactions that needs to be minimized. Indeed, an algorithm may alter less transactions, but in a much higher degree than another one, that probably alters more transactions in a much lower degree. A basic drawback of the accuracy measure is that it penalizes all potential modifications of a frequent itemset, say for instance, both  X  X bc X   X   X  and  X  X bc X   X   X  X b X  , to the same extend. Based on this mishap, we propose a novel global measure of quality, called distance ,that aims at capturing the proximity between the initial and the sanitized database. Formally, we define distance as follows: where b ij refers to the original database D and b ij to its sanitized version D . Due to the fact that in our proposed methodology we allow only exclusion of items from transactions, minimizing the outcome of the above formula is exactly the same as maximizing the number of ones left in D . Thus, The formula above captures the optimization criterion of our inte-ger program formulation, presented in Section 5. The distance met-ric allows us to approximate the ideal solution as much as possible. Since we only want to reduce the support of the minimum sensitive itemsets, i.e. itemsets in S ,the b ij values that will be zeroed out will need to refer to items within transactions supporting itemsets in S. If Z is the set of all candidate b ij values for sanitization, then Having defined the optimization criterion that we need to minimize, our next target is to identify the set of transactions in which we will apply it. Solving the entire problem is well known to be NP-hard [3] [12]. Therefore, we will have to use only a subset of the transactions in our formulation. We proceed by demonstrating the two possible constraints for a frequent itemset appearing in D .
An itemset X will continue to be frequent in D if and only if and will be infrequent otherwise, i.e. when Based on these inequalities we argue that any ideal solution will necessarily satisfy them for the entire problem. Specifically, for all frequent itemsets appearing in F  X  SS , we want them to remain frequent in D and therefore they should s atisfy inequality (4). On the contrary, all frequent itemsets in SS should be hidden in D and therefore they must satisfy inequality (5). If at least one inequality does not hold for an itemset in F , then the identified solution is not ideal. We will call such solutions suboptimal . Solving this system of inequalities for all possible itemsets in I is NP-hard since in the general case there are |  X  | X  1=2 m  X  1 such inequalities.
We should mention at this point th at the two inequalities, namely (4) and (5), are not of the same importance. While it is crucial to ensure that inequality (5) holds for all sensitive itemsets in D (in order to be hidden), inequality (4) just allows us to revise the bor-der of the frequent vs infrequent patterns in the itemsets lattice, thus ensuring minimization of the side-effects in the hiding procedure. As we present in Section 5, we exploit the difference in the signif-icance of these two inequalities in order to obtain the best possible sub-optimal solutions when ideal ones do not exist.
 Algorithm 3 Hiding All Sensitive Itemsets and their Supersets 1: procedure H IDE SS( F , F , SI ) 2: for each s  X  SI do for all sensitive itemsets 3: for each f  X  F do for all large itemsets 4: if s  X  f then large itemset is sensitive 5: F = F  X  f remove itemset f 6: end if 7: end for 8: end for 9: end procedure
Hopefully, it turns out that the NP-hard problem of the 2 m  X  1 inequalities can be reduced to an extend that is solvable while yield-ing the exact same set of solutions. In the following theorems, we prove how this reduction is achieved. Then, based on the reduced set of produced inequalities, we formulate a constraint satisfaction problem and solve it using binary integer programming.
Although we are unable to solve the entire problem, due to its exponential growth, we argue that we can minimize its size up to a point, without any loss on the attained solution. Specifically, we argue that we can remove certain inequalities of the system that do not affect its set of solutions. The rational behind this claim is that in a typical case there exist many overlapping itemsets in D and therefore a large number of overl apping ine qualities are produced. Identifying such inequalities will help us drastically reduce the size of the problem up to a point that it becomes solvable.

As we presented earlier, an one-to-one correspondence exists be-tween itemsets and produced inequalities in our system. Given that C is the total set of affected itemsets, such that we denote by L C the set of solutions of the corresponding inequal-ities from C . The set of solutions for the system of inequalities will be the intersection among the solution produced for each individual inequality. Thus, we can write Based on the above notation, the set of solutions that corresponds (produced, for example, by an itemset C 2 ) with a solution set being a proper subset of the solution set of another inequality, say C we can deduce that the latter inequality can be removed from any system containing th e first inequality, without affecting the global solution of this system. In this case we have that L { C 2 and we state that C 2 covers C 1 . From this point on, we will use u ij  X  U (corresponding to b ij s) to denote the bitmap value of transaction i and item j ,when i participates in the sanitization pro-cess. These u ij values need to be adjusted accordingly to enable us to hide sensitive itemsets while yielding a result with the least effect on the rest of the database.

We proceed our discussion by presenting some theorems that as-sist us in identifying overlapping itemsets, reducing in this way the size of the problem.
 T HEOREM 1. If X  X  ( F  X  SS ) then X covers all its subsets.
P ROOF . Suppose Y  X  X . To prove the theorem we need to show that X covers Y, or equivalently that L { X }  X  L { Y } consider the inequality produced by X, i.e.
 Suppose that this i nequality holds for a combination of u values, corresponding to a solution l  X  L { X } . If in the bitmap rep-resentation that demonstrates the intermediate form of the sanitized database D we substitute all variables u ij with their values from l , then every b ij bit gains a specific binary value. Therefore: Since Y  X  X , we deduce that D { X }  X  D { Y } which sets the nota-tion D { Y }  X  D { X } as meaningful. As a result of (7), the summation P From inequalities (6) and (8), we have that: From (7), we can see that From both (9) and (10) it is proved that An important corollary that holds as an immediate consequence of Theorem 1, is that any itemset belonging in the positive border of F  X  SS covers all its subsets.
 T HEOREM 2. If F is the set of all frequent itemsets in D ,then F =  X  ( B + ( F )) .

P ROOF . Based on the definition of the positive border we know that B + ( F )  X  F . Due to the downward closure property of the frequent itemsets, all subsets of a frequent itemset are also frequent. Therefore, all subsets of B + ( F ) must also be frequent: To prove the theorem, we only need to show that or (equivalently) that if X  X  F ,then Assume that the above condition does not hold. Then, From (13) and (14) we conclude that since, if X  X  B + ( F ) then (14) does not hold for Y = X .From (13), (15) and the definition of the positive border, we have that Therefore, Relation (14) shows that Y 1 /  X  B + ( F ) and since Y 1  X  (16)), we have that  X  Y 2  X  F : Y 1  X  Y 2 , therefore | Y |
Y 2 | X | Y 1 | +1 that due to inequality (17) becomes | Y 2 | X  2
As it can be noticed, using induction we can prove that  X   X   X  :  X  Y k  X  F : | Y k | X  k . This means that there is no upper bound in the cardinality of frequent itemsets, a conclusion that is obviously wrong. Therefore, our assumption in (13) and (14) does not hold and we have proved that (12) holds. This concludes our proof.

Theorems 1 and 2 allowed us to prove that the itemsets of B cover all itemsets of F . In the same manner one can prove that the itemsets of B  X  ( F ) cover all itemsets of  X  ( I )  X  F  X  X   X  } fore, the itemsets of the positive and the negative borders, cover all possible itemsets. In other words the ideal solution L found based on: However, it is possible that there exist more covered itemsets in C . A special case of coverage of an itemset X  X  I appears when the corresponding ine quality pr oduced by X holds for all possible com-binations of binary values u ij  X  U . Under this particular case, it is easy to show that itemset X is covered by any itemset Y  X  following theorems identify itemsets covered by other itemsets.
T HEOREM 3. If X  X  ( B  X  ( F )  X  B  X  ( F )) ,then L { X }
P ROOF .Since X  X  B  X  ( F )  X  B  X  ( F )  X  X  X  B  X  ( F ) and therefore inequality (5) should hold for X : Assume l  X  X  0 , 1 } | U | to be a combination of binary values for variables u ij  X  U . If in the bitmap that represents the intermediate form of D we substitute all variables u ij with their values from l , then each b ij gets a specific binary value. Therefore, Moreover, since X  X  B  X  ( F )  X  B  X  ( F )  X  X  X  B  X  ( F ) therefore X/  X  F , which leads to From equations (20) and (21), we conclude that equation (19) holds for the arbitrary l  X  X  0 , 1 } | U | and therefore | L { X }
Based on Theorem 3, we can safely remove from set C all item-sets in B  X  ( F ) without altering its solution L C . In other words, if we set then, L C remains the ideal solution of the problem.

The next theorem proves that after removing all common item-sets of B  X  ( F ) and B  X  ( F ) , the remaining itemsets in C from B  X  ( F ) are only the minimum sensitive ones.
 T HEOREM 4. Prove that S = B  X  ( F )  X  ( B  X  ( F )  X  B  X  (
P ROOF . We will prove the equivalent statement that if X B  X  ( F ) and X/  X  B  X  ( F ) ,then X  X  S . Suppose that this state-ment does not hold. Then, the following should hold: It is easy to prove that X  X  F .Otherwise, From (23), due to the definition of the negative border we have that  X 
Y  X  X : Y  X  F and since F  X  F , On the other hand, from equations (24) and (26) we conclude that  X 
Y  X  X : Y /  X  F , which contradicts with equation (27) and therefore our assumption in (26) is wrong, meaning that X
Basedon(25)and S  X  SS ,wehavethat X/  X  SS ,whichin combination with the facts that X  X  F and F = F  X  SS , states that X  X  F . This conclusion violates our assumption in (23) so we have proved that equation (25) does not hold. Therefore, X  X  S .

P ROOF . This theorem states that if an itemset X does not contain any items from those appearing in the minimum sensitive itemsets (in S ), then the resulting inequalities will always hold, i.e. do not contain any u ij  X  U values. The inequality produced from X has the summation tion we have that I j  X  X and since X  X  I S =  X  , we conclude that I /  X  I S , therefore b ij = b ij : Equality (28) consists of two cons tant parts and therefore should either always be true (i.e. for all u ij  X  U ) or always be false (i.e. independently from the u ij  X  U values). In the first case we will have that L { X } = { 0 , 1 } | U | , while in the latter one we have that L { X } =  X  . We proceed by examining the following two cases: As we can see, in any case we have that L { X } = { 0 , 1 } | U | Based on Theorem 5, we can define C as: Using the formalization above, we achieve to reduce the problem of satisfying all in equalities pr oduced by all itemsets in D ,tothe examination of a much smaller set C , that will also provide us the ideal solution L C , if one exists.
After our formalization of the sensitive itemsets hiding proce-dure, the whole problem can been regarded as a Constraint Satis-faction Problem (CSP). A CSP [16] is defined by a set of variables , X ,X 2 ,...,X n , and a set of constraints , C 1 ,C 2 ,...,C each variable X i has a non-empty domain D i of potential values . The constraints, on the other hand, involve a subset of the variables and specify the allowable combinations of valid values that these variables can attain. An assignment that does not violate the set of constraints is called consistent .A solution of a CSP is a com-plete assignment of values to the variables that satisfies all the con-straints. As a final remark, in CSP s we usually wish to maximize or minimize an objective function subject to a number of constraints.
CSP s can be solved by using various techniques such as Lin-ear and Non-linear Programming [11]. In our context all variables are binary ; this fact provides us with an important advantage as we will see later on. To solve our CSP we use a technique called Binary Integer Programming (BIP) [9] that transforms the CSP to an optimization problem. Our formulation enables us to solve the sanitization problem in D and is capable of identifying the ideal solution (if one exists). In the case of problems where ideal solu-tions are infeasible we provide a relaxation of this algorithm (using a heuristic targeted for inequalities selection and removal) that al-lows identification of a good suboptimal solution. where V = { X  X  B + ( F ): X  X  I S =  X  } Figure 2: The Binary Integer Programming Formulation  X  P where  X  i  X  X  0 , 1 }
Figure 2 presents the CSP formulation as a BIP .However,aswe can notice, the degree of the constraints participating in the prob-lem formulation is a-priori unknown, and can be as large as the number of items in the given dataset D . This fact prohibits us from solving the BIP problem in the format that is presented in Figure 2. Fortunately though, due to the binary nature of the variables, we are capable of handling this issue. To do so, we replace any inequality that contains at least one product of two or more u ij variables, with a number of inequa lities that each c ontains no produc t of variables and, when all solved, we attain exactly the same solution as the initial one. The side-effect of this approach is that it increases the number of constraints in the system. On the other hand, the result-ing inequalities are very simple and allow for fast solutions, thus adhere for an efficient solution of the CSP . A number of temporary binary values  X  i need to be introduced, as shown in Figure 3. Af-ter applying the Constraints Degree Reduction (CDR) approach all constraints are linear and therefore a linear optimization solver can be applied to provide L C .
 Algorithm 4 Relaxation Procedure in V 1: procedure S ELECT R EMOVE (Constraints C R , V , D ) 5: if  X  D ( R i )= cr msup then 6: Remove (c) remove constraint from the CSP 7: end if 8: end for 9: end procedure The final case that needs to be examined is what happens if the BIP optimization problem yields no solution, i.e. is unsolvable. This means, that an ideal database D cannot be found based on our distance criterion. What allows us to proceed in such a case and identify a good solution, is the fact that the IP problem that contains only the constraints imposed by the sensitive itemsets in S , will always have a solution. Even in a non-ideal case, we can identify a solution if we remove some of the constraints imposed by the itemsets in V ( see Figure 2). In a realistic situation, only a small fraction of constraints will have to be discarded. The question here is how do we select which inequalities to remove. Algorithm 4 provides a simple heuristic for selection and removal of inequalities from the BIP system presented in Figure 2. It applies a relaxation procedure by removing all constraints that correspond to maximal size and minimum support itemsets in V . The rationale behind this heuristic is that the hidden itemsets in D (due to the side-effects of hiding itemsets in SS ) will be the first that would be hidden in D if the support threshold was increased, since their current support is also low. After removing a small subset of the constraints, we expect the remaining problem to be solvable. As a final point, we need to mention that we iteratively apply this relaxation procedure until the CSP is solveable, each time potentially removing more than one constraints from the CSP .
To demonstrate our core approach we will use an example. Con-sider the transactional database shown in Table 1. Using a mini-mum support threshold msup =0 . 2 , the set of frequent itemsets identified by Apriori is:
Suppose we want to hide sensitive itemset { AB } , therefore S {
AB } . As a first step we compute the ideal set of frequent itemsets for D using Algorithm 3. That is: Table 2: Intermediate form of database D used in the example The ideal positive border for D will then be:
To produce the needed constraints for the CSP , we consider all itemsets appearing in C ( see eq. (34)). In this example we have that:
First, we substitute in all trans actions supporting the sensitive itemsets, their current b ij values of the sensitive items with u values. This constitutes the intermediate form of database D ,as shown in Table 2. For each itemset in ( V  X  S ) we create a constraint as follows:
The first two inequalities correspond to itemsets in V whereas the third one is for the sensitive itemset in S . From these con-straints, only the third one contains products of u ij variables and therefore needs to be replaced. Based on Figure 3 we replace it, while introducing two new temporary binary variables,  X  1 Using this procedure we achieve to linearize all initial constraints. The corresponding CSP is presented in Figure 4. We solve it us-ing BIP and we get one among the three potential ideal solutions, presented in Table 3.

Table 3: The three ideal solutions for the CSP in the example where { u 51 ,u 52 ,u 81 ,u 82 ,  X  1 ,  X  2 } X  X  0 , 1 }
We tested our algorithm on real world datasets using different parameters such as minimum support threshold and number/size of sensitive itemsets to hide. In this section, we provide the list of datasets we used, their special characteristics, the selected parame-ters and the attained experimental results.
All real datasets we used to evaluate our methodology are pub-
Datasets BMS-WebView-1 and BMS-WebView-2 both contain click stream data from the Blue Martini Software, Inc. and were used for the KDD Cup 2000 [10]. The mushroom dataset was pre-pared by Roberto Bayardo (University of California, Irvine) [4]. These datasets demonstrate varyi ng characteristics in terms of the number of transactions and items and the average transaction lengths. Table 4 summarizes them.

The primary bottleneck of our approach was the time taken to run the frequent itemset mining algorithm. The thresholds of min-imum support were properly selected to ensure a large amount of frequent itemsets. Among them, we randomly selected a portion and characterized them as sensitive . We conducted several experi-ments trying to hide 1-, 2-, 4-and 5-sensitive itemsets. Since our sanitization methodology is item-based, the higher the number of items in a sensitive itemset, the more the u ij variables involved and therefore the more constraints need to be solved. To avoid the explosion in the number of constraints we enforced two pruning techniques. Firstly, we removed tautologies, i.e. inequalities that always hold. Secondly, we partiti oned inequa lities, identified over-lapping sets and kept only the most specific inequality from each set. Both pruning techniques can be easily applied and relieve the solver from a good portion of unnecessary work. Our code was implemented in Perl and C and we conducted our experiments on a PC running Linux on an Intel Pentium D, 3.2 Ghz processor. The integer programs were solved using ILOG CPLEX 9.0 [1].
We evaluated our algorithm by the metric of distance between databases D and D . The lower the distance, the better the quality of the hiding process. Since even in the non-ideal situation we en-sure that sensitive itemsets have been successfully hidden, we argue that in any case the sanitized database D can be safely released to third parties.

As a final comment on the evaluation procedure we mention that it is not sensible to compare the attained experimental results against the widely known metric of accuracy (as used in other state-of-the-art algorithms). The reason is that in our case what we try to minimize is not the number of transactions from D that will be sanitized (which is what the metric of accuracy captures), but the total number of individual items that will be removed from transac-tions in D . These two goals are highly distinct. According to our perception a good sanitization p rocedure should try to minimize not the number of affected transactions but the total number of af-fected items. Thus, the metric of accuracy would be inappropriate to evaluate the outcome of the presented methodology.
In order to test our approach we considered the following hid-ing scenarios: hiding 1 1-itemset ( HS1 ), hiding 2 1-itemsets ( HS2 ), hiding 1 2-itemset ( HS3 ), hiding 2 2-itemsets ( HS4 ), hiding 1 4-itemset ( HS5 ), hiding 2 4-itemsets ( HS6 ), and hiding 1 5-itemset ( HS7 ). Table 5 summarizes the attained experimental results. The number of u ij variables participating in the CSP provides an es-timate of the worst-case scenario in the context of our algorithm; it is equivalent to the maximum distance between D and D .The fourth column shows the actual distance of the two databases as re-ported by the solver. It corresponds to the actual number of items that were hidden from individual transactions.
At a first glance, a short-coming of our proposed methodology seems to be the time required for solving the produced CSPs ,es-pecially due to the number of constraints introduced by the CDR approach. However, due to the fact that the produced constraints in-volve binary variables and no products among these variables exist, it turns out that the solution time is low. To support our claim, we created a dataset of 10,000 transactions with 10 items each, where all items participate in all transactions. We set msup to 1.0 and ex-tracted all itemsets from the lattice. Then, we hided 2 1-itemsets and 2 4-itemsets, all consisting of disjoint items. To ensure our problem has a feasible solution, we relaxed it using only the con-straints of set S that always lead to a satisfiable CSP . Based on our formulation, the total number of u ij variables participating in the problem are 100,000. To split their products for the 2 4-itemsets, another 20,000  X  i variables were introduced. The total number of constraints were 100,004 and the optimal solution is 99,996 (since 4 items, one belonging in each sensitive itemset, need to be zeroed in a transaction). CPLEX was capable of identifying this solution within 889 seconds (approx. 15 min), which we consider low for such a demanding problem. Of course, adding the constraints from set V increases time complexity, but in all our experiments so far the solver was able to rapidly identify the infeasibility of the given problem. Thus, the relaxation procedure (presented in algorithm 4) was soon applied to allow for the production of a solvable CSP .
In this paper we presented a novel methodology for sensitive itemsets hiding in transactional databases. We defined a new metric to quantify the distance of the initial database D and its sanitized version D and we formulated the hiding process as a constraint satisfaction procedure. Using integer programming, we achieved to solve the CSP pursuing the minimization of the distance between the two databases. This approach has the benefit of being exact when an ideal solution can be identified. When an ideal solution is not achievable, a relaxation approach, targeted at minimally affect-ing the original database, is applied. Finally, we conducted several experiments to demonstrate the effectiveness of this approach to-wards hiding sensitive knowledge. The authors would like to thank Yannis Tsolakis and George V. Moustakides for their valuable comments and overall support. [1] ILOG CPLEX 9.0 User X  X  Manual . ILOG Inc., Gentilly, [2] R. Agrawal and R. Srikant. Fast algorithms for mining [3] M. Atallah, A. Elmagarmid, M. Ibrahim, E. Bertino, and [4] R. Bayardo. Efficiently mining long patterns from databases. [5] C. Clifton, M. Kantarcioglu, and J. Vaidya. Defining privacy [6] C. Clifton and D. Marks. Security and privacy implications [7] C. Farkas and S. Jajodia. The inference problem: A survey. [8] S. Fienberg and A. Slavkovic. Preserving the confidentiality [9] C. Gueret, C. Prins, and M. Sevaux. Applications of [10] R. Kohavi, C. Brodley, B. Frasca, L. Mason, and Z. Zheng. [11] D. Luenberger. Introduction to Linear and Non-linear [12] S. Menon, S. Sarkar, and S. Mukherjee. Maximizing [13] M. Morgenstern. Controlling logical inference in multilevel [14] S. Oliveira and O. Zaiane. Privacy preserving frequent [15] E. Pontikakis, Y. Theodoridis, A. Tsitsonis, L. Chang, and [16] S. Russell and P. Norvig. Artificial Intelligence: A Modern [17] Y. Saad. SPARSKIT: A basic toolkit for sparse matrix [18] Y. Saygin, V. Verykios, and C. Clifton. Using unknowns to [19] X. Sun and P. S. Yu. A border-based approach for hiding [20] V. Verykios, E. Bertino, I. Fovino, L. Provenza, Y. Saygin, [21] V. Verykios, A. Elmagarmid, E. Bertino, Y. Saygin, and
