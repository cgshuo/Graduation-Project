 The complexity of medical terminology raises challenges when searching medical records. For example,  X  X ancer X ,  X  X umour X , and  X  X eoplasms X , which are synonyms, may prevent a tra-ditional search system from retrieving relevant records that contain only synonyms of the query terms. Prior works use bag-of-concepts approaches, to deal with this by represent-ing medical terms sharing the same meanings using concepts from medical resources (e.g. MeSH). The relevance scores are then combined with a traditional bag-of-words representa-tion, when inferring the relevance of medical records. Even though the existing approaches are effective, the predicted retrieval effectiveness of either the bag-of-words or bag-of-concepts representation, which may be used to effectively model the score combination and hence improve retrieval performance, is not taken into account. In this paper, we propose a novel learning framework that models the impor-tance of the bag-of-words and the bag-of-concepts represen-tations, combining their scores on a per-query basis. Our proposed framework leverages retrieval performance predic-tors, such as the clarity score and AvIDF, calculated on both representations as learning features. We evaluate our pro-posed framework using the TREC Medical Records track X  X  test collections. As our proposed framework can signifi-cantly outperform an existing approach that linearly merges the relevance scores, we conclude that retrieval performance predictors can be effectively leveraged when combining the relevance scores.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search &amp; Retrieval]: Search process General Terms: Experimentation, Performance Keywords: Medical Records Search; Regression; Controlled Vocabulary; Retrieval Performance Predictors
Medical terminology, which can be complex, inconsistent, and ambiguous, poses an important challenge when search-ing in the medical domain [9, 10, 12, 15, 16]. For exam-ple,  X  X eart disease X  can be referred to as  X  X oronary artery disease X ,  X  X oronary heart disease X , or  X  X HD X . This means that traditional search systems may not be able to retrieve medical documents relevant to a query, if those documents contain only synonyms of the query terms. To tackle this, prior works (e.g. [2, 8]) proposed bag-of-concepts (BoC) ap-proaches to represent medical documents and queries us-ease X ,  X  X oronary artery disease X ,  X  X oronary heart disease X , and  X  X HD X , which share the similar meaning, are represented with the same concept. For instance, Aronson [2] deployed MetaMap [3] to identify medical concepts in medical records and queries and represented them in the form of the UMLS Concept Unique Identifiers (CUIs). Intuitively, such ap-proaches should alleviate the terminology mismatch prob-lem. However, empirical studies [15, 16] have shown that the BoC performance can be inconsistent, sometimes underper-forming the traditional bag-of-words representation (BoW), since not all documents and queries could be effectively rep-resented using medical concepts. For example, medical con-cepts may not be found in some queries. To cope with such a challenge, other works (e.g. [9, 15, 16]) combined the rele-vance scores of both BoW and BoC when inferring the rele-vance of a document. In particular, Srinivasan [15] proposed the so-called score combination approach that linearly com-bines the relevance scores from both BoW and BoC, when inferring the relevance of a document d towards a query Q , as follows [15]: where  X  is a parameter to emphasise the relevance score computed using BoW, which is set to 2.00 for all queries, as suggested in [9, 15].

In the context of medical records search, Limsopatham et al. [9] improved retrieval performance markedly by us-ing the aforementioned score combination to merge the rele-vance scores from the BoW and their proposed task-specific representation (i.e. a BoC). They showed that combining the relevance scores from BoW and BoC is effective for searching in the medical domain. Importantly, these score combina-tion approaches merge the relevance scores computed from both BoW and BoC representations by fixing a particular weight irrespective of the query.
 We hypothesise that by learning a weight for BoW and BoC on a per-query basis, we can rank medical records more effectively. In this paper, we propose a novel learning h ttp://www.ncbi.nlm.nih.gov/mesh http://www.nlm.nih.gov/research/umls/ framework to model the importance of BoW and BoC, when i nferring the relevance of a medical record. Our proposed regression-based learning framework leverages retrieval per-formance predictors, such as the clarity score [5] and query scope [7], computed on both BoW and BoC as features, to learn an effective combination model on a per-query basis.
We evaluate our proposed framework in the context of the TREC 2011 [19] and 2012 [18] Medical Records track. Our results show that our learning framework is effective. Indeed, it significantly outperforms an existing strong score combination baseline.

The main contributions of this paper are threefold: 1. We show that some particular queries benefit more 2. We propose a novel regression-based learning frame-3. We thoroughly evaluate our proposed framework using
The remainder of this paper is structured as follows. Sec-tion 2 introduces our novel regression framework that lever-ages retrieval performance predictors to learn an effective score combination model. Our experimental setup and re-sults are presented in Sections 3 and 4. Finally, we provide concluding remarks in Section 5.
In this section, we describe our novel learning framework that models the combination of the relevance scores from the bag-of-words (BoW) and the bag-of-concepts (BoC) repre-sentations, for medical records search. The central idea is that queries may benefit differently from BoW and BoC; hence, we propose to learn a weight for BoW and BoC on a per-query basis. To do so, we use retrieval performance predictors as learning features to estimate the predicted re-trieval effectiveness of each representation, when estimating the relevance scores of a medical record. In particular, we deploy a regression technique to learn the importance of the two representations when combining their relevance scores.
Our framework consists of four components: 1. A score combination model. 2. A procedure to estimate the model parameter for a 3. A set of learning features to learn the model. 4. A regression procedure to infer the model using the In the remainder of this section, we describe each of these four components.
To take advantage of both BoW and BoC, we follow [15] and combine the relevance scores of a medical record d to-wards a query Q as follows: where  X  Q (0  X   X  Q  X  1) is a per-query parameter to esti-mate the importance of the relevance scores computed using Table 1: List of learning features used to predict the importance of the relevance scores from the bag-of-words (BoW) and bag-of-concepts (BoC) represen-tations.
 the bag-of-words (BoW) and bag-of-concepts (BoC) repre-s entations. The higher the  X  Q , the more the relevance score depends on BoW. Indeed, to generalise the model, we in-troduce a modification to Equation (1) of [15] with respect to the weighting between the relevance scores of BoW and BoC, so that our combination model can take into account the situation where only BoW (  X  Q = 1) or BoC (  X  Q = 0) is individually effective. In addition, when  X  Q = 0 : 667, our model could produce the same list of medical records as Equation (1) with the recommended setting (i.e.  X  = 2 : 00), since the proportion of relevance scores from BoW and BoC computed by Equations (1) and (2) are equal.
Next, in order to estimate an effective  X  Q of the combina-tion model, described in Section 2.1 (Equation (2)), on the training set, we identify the best  X  Q that achieves the opti-mal retrieval effectiveness in terms of a particular retrieval measure (e.g. infNDCG) for each training query. Indeed, for each query, we sweep the  X  Q parameter between 0 and 1 to find the best combination model in terms of the retrieval performance for that query. The identified effective  X  Q pa-rameter is used as the weight for the learning component of our framework to learn an effective combination model from the retrieval performance prediction features.
We next identify the features that we will use to choose the weight for an unseen query. These features should gen-eralise across queries and correlate well with the  X  Q that could result in the optimal retrieval performance. Table 1 lists our features. In particular, as previously discussed in Section 1, we propose to use existing retrieval performance predictors to estimate the retrieval performance of BoW and BoC. Hence, we use the ratio between the retrieval perfor-mance predictors computed on BoW and BoC, as the learn-ing features. Specifically, the first set of features (Features 1-4), including the clarity score [5], SCQ [21], MaxSCQ [21] and NSCQ [21], consider the ambiguity of a query by mea-suring the coherence of the language used in each medical record. The more similar the query model is to the col-lection model, the better the retrieval performance would be expected. The next set of features (Features 5-8) mea-sure the specificity of each query within a representation approach. Indeed, queries with explicit intents could result in a better performance than queries with general terms. The features include Average Inverse Collection Term Fre-quency (AvICTF) [4], Average Inverse Document Frequency ( AvIDF) [4], EnIDF [4], and the query scope (  X  ) [7]. Next, Feature 9, the Average of the Pointwise Mutual Information over all query term pairs (AvPMI) [4], focuses on the re-lationship between query terms. The more co-occurrences among query terms, the better the chance that the relevant documents are being retrieved. Features 10-11 measure the distribution of informativeness among the query terms (i.e.  X  1 and  X  2 [7]), as a query with informative terms could at-tain an effective retrieval performance. Finally, Feature 12 is the number of non-stopword query terms, which could im-pact the normalisation methods of the probabilistic retrieval models, and hence affect retrieval performance [7].
We view the task of estimating the importance of different representation approaches as a supervised regression prob-lem, where the objective is to predict a proper weight (  X  for each query, based on effective weights for similar train-ing queries. By doing so, we would benefit from the fact that several retrieval performance predictors of the repre-sentation approaches can be used as learning features, when combining the relevance scores.

While any regression learners could be used here, we de-ploy the Gradient Boosted Regression Trees (GBRT) [17] combination model discussed in Section 2.1, as it has been shown to be effective in several search and regression tasks (e.g. [17, 20]). We use the root-mean-square error (RMSE) as the loss function when learning a combination model. Our proposed framework leverages retrieval performance predic-tors, introduced in Section 2.3, as learning features for the GBRT learner.
In this section, we discuss our experimental setup when evaluating our proposed framework. In particular, Section 3.1 describes the used test collections and Section 3.2 discusses our ranking strategies.
We evaluate our framework using the 34 and 47 queries from the TREC 2011 and 2012 Medical Records track [18, 19], respectively. The task is to retrieve patient visits rel-evant to a given query. Indeed, a patient visit is identified by the medical records associated with a particular visit to a hospital by a patient. The collection contains about 102k medical records, which are associated with 17,265 patient visits [18, 19].

TREC deployed various measures to cope with the pos-sible incompleteness of the gold-standard relevance judge-ments. In particular, bpref is used as the official measure for TREC 2011 [19], while infNDCG and infAP are used for TREC 2012 [18].
We index the medical records using Terrier [14]. For the bag-of-words (BoW) representation, we apply Porter X  X  English stemmer and remove stopwords. For the bag-of-concepts (BoC) representation, we follow [9] and apply the so-called task-specific representation to represent medical records and queries using only medical concepts related to h ttp://code.google.com/p/jforests/ the medical decision criteria (namely, symptom, diagnostic test, diagnosis, and treatment), as it has been shown to be ef-fective for medical records search. In all experiments, the ef-fective parameter-free DPH term weighting model [1] is used to rank medical records. To learn the combination model, when ranking medical records, we use the default setting of GBRT from the jforests package. We use a 5-fold cross val-idation across the 34 topics of TREC 2011 and 47 topics of TREC 2012, where each fold has separate training and test query sets. When training the combination model, we target the bpref and infNDCG retrieval measures for TREC 2011 and 2012 topics sets, respectively. Finally, to rank patient visits based on the relevance scores of their associated medi-cal records, we use the expCombSUM voting technique [13], which gives more importance to the highly relevant medi-cal records. Following [11], the number of medical records voting for the relevance of patient visits is limited to 5,000.
We evaluate the retrieval effectiveness of our proposed framework to learn an effective combination model of the bag-of-words (BoW) and the bag-of-concepts (BoC) repre-sentations using the retrieval performance predictors dis-cussed in Section 2. Table 2 compares the retrieval perfor-mance of our framework on the TREC 2011 and 2012 Med-ical Records track test collection with three baselines, in-cluding a traditional bag-of-words representation (BoW), a task-specific representation [9] (BoC), and an existing score combination approach [15] (i.e. Equation (1)) with the sug-gested setting from [9, 15]. In addition, to evaluate the opti-mal potential effectiveness, the best retrieval performances that our proposed framework and the existing score combi-nation could achieve are also reported (denoted oracle).
From Table 2, we observe the following. First, we see that for both TREC 2011 and TREC 2012 topics sets, both our proposed framework and the existing score combination ap-proach markedly outperform the baselines where either of the representations are taken into account. This shows that combining the relevance scores from BoW and BoC is effec-tive for medical records search. Next, for the TREC 2012 topics set, the retrieval performances of our framework (5-fold) markedly outperform those of the score combination baseline (  X  = 2). In particular, in terms of the infNDCG re-trieval performance, our framework (infNDCG 0.4723) sig-nificantly outperforms (paired t-test, p &lt; 0 : 05) the existing score combination baseline (infNDCG 0.4557). For the in-fAP measure, our proposed framework performs markedly better than the score combination baseline (+6.5% improve-ment, from 0.1975 to 0.2133). In addition, our proposed framework (5-fold) also results in a markedly better retrieval effectiveness than the best possible setting of the score com-bination baseline (oracle). Indeed, in terms of infNDCG, our proposed framework significantly outperforms the score combination with the best setting for upto 3.21% ( p &lt; 0 : 05). For the infAP retrieval measure, our regression-based frame-work performs +4.50% better than the best setting of the score combination. However, for the TREC 2011 topics set, our framework (5-fold) could not outperform the score com-bination (  X  = 2) baseline (bpref 0.5078 vs. 0.5118). This is partially due to the fact that the TREC 2011 topics set con-tains only 34 queries; hence, with a small number of queries, when we conduct a 5-fold cross validation, the training and test sets could not generalise.

Finally, we discuss the optimal retrieval performance that our proposed framework could achieve to evaluate the po-over a baseline are denoted a , aa and aaa , respectively. tential effectiveness of our framework, if more training data w ere available. As expected, we observe that, with the best setting, our framework (oracle) significantly ( p &lt; 0 : 01) out-performs all of the approaches discussed in this paper. This supports our hypothesis that some particular queries differ-ently benefit from BoW and BoC. In particular, the retrieval performance of our framework with the best setting is upto +17.06% better than the 5-fold cross validation. Impor-tantly, we find that the mean of the effective weights (  X  with the best possible setting) across the two collections is 0.48459 (0  X   X  Q  X  1), while the standard deviation is 0.38085, which suggests that the effective weight should in-deed vary across topics. For example, to attain an effective retrieval performance when a query contains multiple com-plex concepts (e.g. topic#106: patients who had positron emission tomography (PET), magnetic resonance imaging (MRI), or computed tomography (CT) for staging or moni-toring of cancer),  X  in the combination model (Equation (2)) should be low, if all the concepts in the query can be effec-tively identified. From this, we conclude that there is no one combination of BoW and BoC that is effective for all queries. Hence, per-query prediction approaches, like the ones deployed here, have great potential to improve medical records search. However, there is still an open research area to explore effective features and learners to close the perfor-mance gap between the cross-validation and oracle regimes, even though by deploying the existing learner and features, our framework could in general markedly and significantly outperform the existing score combination approach [15].
We have tackled the challenge of dealing with the complex and ambiguous terminology in medical records search by modelling the combination of the relevance scores from both bag-of-words (BoW) and bag-of-concepts (BoC) representa-tions. We have proposed a regression-trees-based learning framework that can effectively handle this combination us-ing the Gradient Boosted Regression Trees to learn an effec-tive combination model via retrieval performance predictors, such as the clarity score [5] and the query scope [7]. We have shown that our proposed framework is effective for the med-ical records search, as it could markedly and significantly outperform an effective score combination approach [15].
