 HAI ZHAO Shanghai Jiao Tong University &amp; Soochow University CHANG-NING HUANG and MU LI Microsoft Research Asia BAO-LIANG LU Shanghai Jiao Tong University 5: 2  X  H. Zhao et al. 1. INTRODUCTION Chinese text is written without natural delimiters such as white spaces, so word segmentation is often an essential first step in Chinese language process-ing. Though it seems simple, Chinese word segmentation is actually not a triv-ial problem, and has been an active research area in computational linguistics for more than 20 years [Fan and Tsai 1988; Sproat and Shih 1990; Sproat et al. 1996; Sun et al. 1998; Sun and Tsou 2001; Sproat and Shih 2002; Gao et al. 2005].

Chinese word segmentation is challenging partially due to the difficulty in defining what encompasses a word in Chinese. In the literature, there are var-ious linguistic criteria in the theoretical linguistic community [Packard 2000], each of which provides valuable insight to Chinese  X  X ord-hood. X  Though these definitions or standards are in general agreement with each other, there are specific instances in which they are not. Fortunately, the rapid development of corpus linguistics has allowed a segmentation standard to be effectively repre-sented by a segmented corpus. This brings an obvious convenience in explic-itly or implicitly avoiding those ambiguities or conflicts inside segmentation standards. In addition, this provides broader word description than a guide-line manual. The drawbacks of a rule-based method, used in a corpus-based method, can be overcome by enlarging the corpus [Sproat and Shih 2002].
Chinese word segmentation can be classified into two categories: dictionary-based methods and statistical methods.

The most successful dictionary-based methods are variations of the max-imum matching algorithm, which greedily searches through a sentence in an attempt to find the longest subsequence of Chinese characters that matches a word entry in a pre-compiled dictionary [Nie et al. 1994]. Typi-cally, a dictionary-based approach addresses the ambiguity problem with some heuristics. There exist two kinds of ambiguities in Chinese word segmentation when using the dictionary approach. One is overlapping ambiguity, which can be roughly detected by a mismatch from forward maximum matching (FMM) and backward maximum matching (BMM). The other is combination ambigu-ity, which can be defined by an uncertain decision to split a character sequence when both the whole character sequence and all its members exist in the dic-tionary [Tsai 2006]. To solve the ambiguity problem well, many techniques have been developed, including various kinds of statistical learning methods [Luo et al. 2002; Li et al. 2003; Sun et al. 2006].

The performance of dictionary-based methods largely depends upon the cov-erage of the dictionary. However, it is difficult to compile a complete dictionary due to the appearance of out-of-vocabulary (OOV) words (namely, unknown words). Thus, researchers turn to statistic-based methods to better deal with OOV words, and in particular, OOV detection. There are two strategies that handle OOV word detection. While Wu and Jiang [2000] and Chen [2003] han-dle it separately, Sproat et al. [1996], Xue [2003], and Gao et al. [2005] treat it as part of the segmentation procedure. In this article, we unify OOV word detection and Chinese word segmentation.

The current trend in OOV word detection is to employ character-based methods. Since all Chinese words are formed by a closed set of characters of about 6,500 or about 3,500 in most cases, 1 it is most straightforward to regard OOV word detection as combining these successive single characters within a focused scope 2 Yuan [1997] and Fu and Wang [1999] tackled OOV word detec-tion based on four word-formation patterns and head-middle-tail structures. Xue [2003] pioneered character-based tagging method via maximum entropy (MaxEnt) modeling. Since then, much attention has been paid to character-based methods, and various learning models such as support vector machines (SVMs) and conditional random fields (CRFs) have been employed within this framework [Peng et al. 2004; Tseng et al. 2005; Goh et al. 2005; Zhu et al. 2006].

In this study, we focus on a corpus-based learning method for Chinese word segmentation. With the availability of a large segmented corpus, the acquisi-tion of word segmentation information is regarded as a supervised learning of the segmented corpus.

Motivated by linguistic facts, we classify characters in Chinese text into more categories according to their positions in words than those in previous work [Xue 2003]. Such a categorization extension is transformed into an ex-tension of the tag set that is essentially used in learning procedure, which brings a general trend of performance enhancement. In addition, we explore ensemble learning for effectively integrating linguistic resources with CRF it-self adopted as the ensemble scheme and an assistant segmenter approach proposed to deal with various additional linguistic resources (outside the train-ing corpus and including lexicons, named entity information, and segmented corpora with different standards). All these construct a general scheme for properly integrating various kinds of linguistic information into Chinese word segmentation. 5: 4  X  H. Zhao et al.

In summary, we will describe a suite of complete techniques for Chinese word segmentation and show that Chinese word segmentation can be properly tackled using a unified supervised learning framework, given a segmented cor-pus, with possible consideration of additional linguistic information.
The remainder of the article is organized as follows. Section 2 discusses technical trends revealed by international Chinese word segmentation bake-offs. Section 3 briefly introduces conditional random fields. Sections 3.1 and 3.2 describe basic feature template setting and tag set selection, respectively, with their experimental results given in Section 4. Section 5 presents and evaluates an assistant segmenter method for integrating additional linguistic knowledge. Sections 6 and 7 compare and discuss our system with the state-of-the-art ones, respectively. Finally, Section 8 summarizes our contributions in this article. 2. THE CORPUS For a comprehensive comparison of Chinese word segmentation in a common test corpora, SIGHAN held three International Chinese Word Segmentation Bakeoffs in 2003, 2005, and 2006, 3 and attracted 12, 23, and 24 participants, respectively [Sproat and Emerson 2003; Emerson 2005; Levow 2006].

Each bakeoff specifies two types of test tracks: open test, which has no lim-itation on additional resources, and closed test, which only allows the corre-sponding training data.

We regard the closed test as a standard supervised learning task from train-ing data alone, and the open test as common characteristics of human lan-guage, which is the point in which natural language learning differs from other data learning paradigms.

All the corpora since Bakeoff-2003 4 Table I) are taken as our evaluation data sets. For evaluation, we adopt the commonly-used recall ( R ), precision ( P ), and F -measure ( 2 RP / ( R + P ) ), where recall is the proportion of correctly seg-mented words in the gold-standard segmentation, precision is the proportion of correctly segmented words output by the segmenter, and F 1 -measure is the harmonic mean of recall and precision.

To check which makes the most performance loss in Chinese word segmen-tation on different corpora, each bakeoff [Emerson 2005; Sproat and Emerson 2003; Levow 2006] adopts the FMM algorithm to generate topline and baseline performance figures. This is done by generating a dictionary based only on the vocabulary in each test (topline) and training (baseline) corpus and segment-ing the respective test corpus. In addition, the performance gaps between a perfect system (100%) and the topline, and between topline and baseline, 5 are also presented in Tables II, III, and IV, respectively. If we take the value of 1 minus topline as a metric of ambiguity loss, and topline minus baseline the metric of OOV loss, then from the ratio between OOV loss and ambiguity loss that is given in the bottom row of each table, we see that OOV loss is far more than ambiguity loss (from 4.9 to 25.6 times).

Notice that Xue and Shen [2003] proposed a character-based tagging method using a maximum entropy model and achieved the second rank in closed test of 5: 6  X  H. Zhao et al.
 AS2003 corpus among the official results of Bakeoff-2003 (see Table V, where recalls of in-vocabulary (IV) word are also given), which has the highest re-call of OOV ( R OOV ) in this track [Sproat and Emerson 2003; Xue and Shen 2003; Asahara et al. 2003; Chen 2003]. Xue and Shen [2003] also obtained the third best result in the CityU2003 closed test with the highest R OOV , 0.670. These results imply that the character-based tagging method is effective for OOV word detection. As OOV word detection is much more serious than seg-mentation ambiguities, it is possible for researchers to get performance en-hancement only if suitable techniques are adopted to strengthen this method. This assessment did come true in Bakeoff-2005. In all of proposed methods of Bakeoff-2005, the character-based tagging method quickly rose as the most remarkable in obtaining the best results in almost all test corpora [Low et al. 2005; Tseng et al. 2005].

Based on above investigation, we adopt the character-based tagging frame-work for Chinese word segmentation in this study. 3. THE LEARNING FRAMEWORK Peng et al. [2004] first used CRFs for Chinese word segmentation by treating it as a binary decision task, such that each Chinese character is labeled ei-ther as the beginning of a word or not. Following Peng et al. [2004], we employ the state-of-the-art linear-chain conditional random fields [Lafferty et al. 2001] with tunable Gaussian prior. 6 CRF often outperforms MaxEnt model [Rosen-feld et al. 2006], another popular machine-learning method in NLP. The main reason is that CRF suffers less from the label bias problem when compared to MaxEnt and other conditional Markov models [Lafferty et al. 2001]. So far, CRF has been very successful in a good number of NLP applications [Sha and Pereira 2003].

Given a particular sequence of characters, a CRF computes the probability of its corresponding hidden label sequence as where Y = { y t } is the label sequence for the sentence, f k is a feature function,  X  k is the weight value for the corresponding feature function f k , W is the sequence of unsegmented characters, Z ( W ) is a normalization term, T is the tag set, and t reflects the position of current character. In particular, we employ the CRF++ package version 0.42 developed by Taku Kudo. 7
Given the learning framework, we need to define the corresponding fea-tures. Similar to MaxEnt, our CRF-based learning framework regards Chi-nese word segmentation as a character-based tagging task. For details about feature generation, please refer to the work in Ratnaparkhi [1996]. Here we treat all features as functions derived from various feature templates and tag sets. So, our method is about two key issues: feature template settings and tag set selection. 3.1 Feature Template Settings The probability model and corresponding feature function are defined over the set H  X  S , where H is the set of possible contexts (or any predefined condition) and S is the set of possible tags. Generally, a feature function can be defined as where h i  X  H and t j  X  S .

For simplicity, features are generally organized into groups by called feature templates. For example, a unigram template C 1 stands for the next character occurring in the corpus after the current character C 0 .

Table VI shows basic feature templates while Table VII lists four widely-used sets for experimental comparison.

Here we give an explanation to feature template (c) in Table VI. Feature template (c) is slightly improved from the counterparts in Low et al. [2005]. T , for n =  X  1 , 0 , 1, stands for some predefined class (type) of previous, current, or next character. There are five defined classes: numbers or characters that stand for numbers represent class 1, those characters whose meanings are date and time represent class 2, English letters represent class 3, punctuation 5: 8  X  H. Zhao et al.
 labels represent class 4 and other characters represent class 5. The character set for each class is shown in Table VIII. 8 3.2 Tag Set Selection Various sets of tags have been proposed in the literature, which are shown in Table IX. For example, Xue [2003] and Low et al. [2005] used the four-tag set in the MaxEnt model. Peng et al. [2004] and Tseng et al. [2005] used the two-tag set in the CRF model, and Zhang et al. [2006] used the three-tag set.
Though features are determined by both feature template and tag sets, in the literature, the tag set is often specified beforehand and paid much less at-tention than the feature template. However, we will show that tag set selection is as important as feature template set selection.

To better model longer words, we extend the four-tag set as adopted in Xue [2003] and Low et al. [2005]. In particular, the tag B 2 is added into the four-tag set to form a five-tag set, which stands for the second character position in a multi-character word only if it is not the last character in the word. Similarly, the tag B 3 is added into the five-tag set to form a six-tag set, which stands for the third character position in a multi-character word only if it is not the last character. For systematic evaluation, Table X lists various tag sets explored in this study.

Given various possibilities, it will be interesting to select an effective tag set in the segmentation task. Since our task is to segment a sequence of characters into a sequence of words with various lengths (in characters), it is natural to consider the word length distribution in a corpus. Tables XI and XII show the distribution of words with different lengths in all the 12 training corpora of the three bakeoffs.

Two factors exist in determining the importance of words with different lengths, especially long ones. The first factor is the percentage of the corpus covered by the words no less than a certain length, k , in characters and can be calculated by 5: 10  X  H. Zhao et al.
 where N i is the number of those words whose lengths are i , and K is the largest length of a word in the corpus. The second factor is related to the average length of all words and can be calculated by where N = P K i =1 N i is the number of all words in the corpus.

By leveraging both factors, the average weighted word length is computed in this study as where L k is the average weighted word length for i  X  k . In particular, if k = 1, then L 1 = l a v g . By involving l a v g , we can fairly compare different segmented corpora using L k .

Tables XIII and XIV are the distribution of average weighted word length of 12 training corpora in the three bakeoffs. It is observed that average word length of MSRA2005, MSRA2006, 9 and CTB2003 are the longest. As for CityU2005 and CityU2006, though they are not the shortest ones, their av-erage weighted lengths are the shortest if we only consider the words longer than four characters.

Note that a six-tag set can label a five-character or shorter word without repeating its tags. For example, X   X   X (give) is tagged by  X  S  X ,  X   X  X   X  (peace) is tagged by  X  BE  X ,  X   X  X  X  X  X  X   X  (Tian X  X nmen Square) is tagged by  X  BB 2 B 3 ME , X   X   X  X  X  X  X   X  (space shuttle) is tagged by  X  BB 2 B 3 E , X  and so on. The fact that all the characters in a word can be tagged by different tags allows precise character discrimination in different positions of a word. 10 Considering that five-character or shorter words have covered around 99% of any corpus with different segmentation standards (Tables XI and XII), employing the six-tag set is enough to capture discriminative information. In addition, the capability of labeling a five-character word without repeating tags means that the learner actually works within a five-character window context even only with unigram feature templates. According to values in Tables XIII and XIV, average word lengths of 12 corpora ranges from 1.5 to 1.7 characters. Therefore, a three-word window may effectively cover 4.5 to 5.1 characters. That is, learning from a five-character window is equally doing that both from previous and next two characters and previous and next words. Note that the six-tag set is the smallest one that can fully tag a five-character word without repeating its tags.

We employ L 5 as our empirical criteria to determine if the six-tag set should be taken. If L 5 is larger than the pre-defined threshold, then we adopt the six-tag set. Otherwise, we consider a tag set with five or less tags. We will see that the threshold can be empirically set to 0.02 from experimental results in those training corpora of Bakeoff-2003 and 2005.

We don X  X  consider a tag set with more than six tags until now due to two reasons. The first reason is that word length statistics. Tables XI and XII show that more than 99% of words in all corpora are less than six characters. This low bound will be 99.50% if MSRA2005 and MSRA2006 are excluded. This will also explain why the six-tag set works well in most cases. The second reason is related to computational cost. CRF learning is quite sensitive to the number of tags and too many tags will cause a dramatic increase in computational cost. In spite of these issues, we will still consider some tag sets with more than six tags to explore possible performance improvement. 4. EXPERIMENTS WITH DIFFERENT FEATURE TEMPLATES AND TAG SETS Twelve corpora are available from Bakeoff-2003, 2005, and 2006, and all of them are selected to perform the evaluation. Table I gives a summary of these corpora. All experimental results in the rest of this article will be evaluated by F -measure unless specified. 4.1 Experimental Results on Bakeoff 2003 and 2005 Tables XV and XVI compare different tag sets and feature template sets on CTB2006 11 (GB encoding) and CityU2003 (Big5 encoding), respectively. They show that TMPT-1 performs best when combined with the six-tag set. Though both TMPT-2 and TEMT-4 are simple n -gram template sets, it can be also ob-served that TMPT-2 or TMPT-4 yields substantial performance improvement 5: 12  X  H. Zhao et al.
 when combined with a larger tag set. Meanwhile, TMPT-1 loses its top perfor-mance place when combined with the two-tag set.

Table XVII demonstrates the relationship between tag set selection and average weighted word length using the feature template set TMPT-4 by default. Though the difference is slight, the CityU2005 corpus with the small-est L 5 value (the criterion to choose the six-tag set) among six corpora and gets the better performance at the five-tag set instead of the six-tag set, while MSRA2005 and CTB2003, the two corpora with the largest L 5 , obtain the most performance increase from the five-tag to the six-tag set. 4.2 Experimental Results on Bakeoff 2006 In this section, we report experimental results on the corpora of Bakeoff-2006. Still, different combinations of tag sets and feature template sets are consid-ered. Especially, we consider three effective feature template sets originally for a two-tag set [Peng et al. 2004; Tseng et al. 2005; Tsai et al. 2006], and refer them as T Peng, T Tseng and T Tsai respectively in the following. As Tseng et al. [2005] and Tsai et al. [2006] used some additional features besides n -gram ones, the n -gram parts of their feature template sets are extracted to construct two feature template sets, T TsengNgram and T TsaiNgram, respec-tively. Those additional features that Tseng et al. [2005] used are listed in Table XVIII and noted as T TsengAdd. All feature templates in this set are re-lated to self-collected lexicons extracted from the training corpus. Thus this set is also applied to strengthen T Peng and T TsaiNgram. For the four-tag set, the same n -gram set that was also adopted by Xue [2003] and Low et al. [2005] for MaxEnt learning, TMTP-2, is correspondingly used. For six-tag set, TMPT-4 is adopted. In addition, character type feature T  X  1 T 0 T 1 , noted as PT3, is also used as an extra feature for the two-tag set. Table XIX compares different combinations of feature template and tag sets employed in the state-of-the-art systems.

Some results using MaxEnt and SVM from Wang et al. [2006] and Zhu et al. [2006] are also given in Table XIX. An ensemble method was used in Wang et al. [2006], where MaxEnt and n -gram language model were integrated through a simple weighted method. In Zhu et al. [2006], SVM with the exact same feature template set as Ng and Low [2004] was adopted. In addition, some postprocessing rules were applied to further correct those incorrect seg-mentations by the SVM segmenter.
 5: 14  X  H. Zhao et al.

Table XIX suggests a general trend that the more tags in tag set, the better performance we obtain. It also shows that Tseng X  X  additional feature templates work well for all n -gram feature template sets with a two-tag set. This is due to that this set of feature templates were designed to compensate the deficiency of the two-tag set.

To see whether an improvement is significant, we also conduct significance tests using paired t -test. In this article, ***, **, and * denote p -values of an improvement less than 0.01, in-between (0.01, 0,05] and greater than 0.05, which mean significantly better, moderately better, and slightly better, respec-tively. The significance tests are performed between the results of four-tag and two-tag sets and between those of six-tag and two/four-tag sets, as shown in Table XX. Three feature template sets, T TsaiNgram+T TsengAdd, TMTP-2 and TMPT-4, are applied to two, four, and six-tag sets, respectively. Table XX shows that most performance improvements are significant as the tag set is continuously enlarged.

Notice that most researchers who adopted CRF as their learning model used the two-tag set, though some subsequent work has shown that four or six tags were more effective. This is largely due to computational cost.

For example, CRF training using L-BFGS algorithm often requires hun-dreds or thousands of iterations [Malouf 2002], each of which involves calcu-lating the log-likelihood and its derivative. Cohn et al. [2005] shows that the time complexity of a single iteration is O ( n 2 l ), where n l is the number of labels (tags) and it is still an issue to state the precise bound on the number of iter-ations. Moreover, efficient CRF implementations normally cache the feature values for every possible clique labeling for the training data. This leads to a space requirement of O ( n 2 l ), too.

The preceeding theoretical analysis means that a CRF learner with a six-tag set will cost nine times as much memory or time as that with a two-tag set for the same task. This is not acceptable in most practical applications. Please refer to Tables XXI, XXII, and XXIII for detailed comparison in practice. These tables show that training cost does increase as the tag set is enlarged. However, the actual increase is not so much as the prediction by the theoretical analysis. The experimental results show that the six-tag set costs nearly twice as much time as the four-tag set and about three times as the two-tag set. Fortunately, the memory cost with the six n -gram feature templates, TMTP-4, remains very close to that of the two-and four-tag sets with the n -gram feature template sets [Peng et al. 2004; Tseng et al. 2005; Tsai et al. 2006; Xue 2003]. This may be attributed to two factors. The first is the imbalance of tag distribution. We take the training corpus of CityU2006 with the six-tag set as an example. Tag S covers 28.35% of the corpus, tag B covers 32.36%, tag E covers 32.36%, while other three tags, B 2 , B 3 , and M as a whole only cover 6.93%. The second factor is that less feature templates prefer the larger tag set and vice versa. For example, TMPT-4 for the six-tag set includes six templates, while TMPT-2 for the four-tag set includes ten templates.

One reason that we finally choose the six-tag set as our standard tag set is that larger tag set can at most slightly improve the performance. Another reason is that the more tags mean the more training time and memory the system needs. Thus, the six-tag set is a good trade-off. 4.3 More Than Six Tags This section evaluates the effectiveness of more than six tags in more detail. Only an even number of tags is taken into account to ensure the learning con-ducted in a sliding window that is symmetrical to the current character. For example, given unigram feature templates, the six-tag set ranges from previ-ous two to next two characters, the eight-tag set ranges from previous three to next three characters, and the 14-tag set ranges from previous six to next six characters, and so on.

Considering how the six-tag set is extended from the four-tag set, we may continuously extend the six-tag set to the eight-tag set in the same way by including two more tags B 4 and B 5 to represent the fourth and fifth positions of characters in a multi-character word. Similarly two more tags B 6 and B 7 5: 16  X  H. Zhao et al.
 are added into the eight-tag set to form the ten-tag set, and so does for larger tag set.

Table XXIV compares different tag sets with the feature template set TMPT-4 by default, on the four corpora of Bakeoff-2006.

It should be noted that although the eight-tag set reaches its peak perfor-mance on three corpora, it only slightly outperforms the six-tag set. Thus, it is hard to recognize the performance differences as statistically significant. In addition, we cannot observe an obvious trend of performance increase when the tag set is continuously enlarged according to the results in Table XXIV, though much more time-consuming and memory-consuming learning with larger than the six-tag sets are expected. However, an obvious performance increase with the eight-tag set compared to the six-tag set can be found in MSRA2006 cor-pus. Note that L 7 value of MSRA2006 (0.0546) 12 is much more than that of CityU2006 (0.0045) or CTB2006 (0.0108). This explains why an obvious peak performance appears with the eight-tag set in MSRA2006 corpus. Even though the eight-tag set can achieve better performance than the six-tag set in most cases, considering that learning with it will cost twice as much time than that with the six-tag set, we still prefer the six-tag set in this study. 4.4 Experimental Results with Different FeatureTemplate Sets To evaluate the contribution of different feature templates with or without character type feature, we perform this group of experiments with two tem-plate sets, TMPT-1 and TMPT-4 (Table XXV). It is observed that as demon-strated by Low et al. [2005] the character type feature is helpful though n -gram features still contribute most. 5. UNIFYING ASSISTANT SEGMENTERS INTO THE LEARNING FRAMEWORK Since learning only from a training corpus is not always enough, it is some-times beneficial for Chinese word segmentation to use additional linguistic resources. Assistant segmenter is a feature method that represents addi-tional linguistic knowledge. Here, two types of additional feature templates are adopted to improve the performance further. 5.1 Assistant Segmenter Low et al. [2005] observed that though different segmentation standards are presented, segmentation differences only exist in a few words. In fact, most word segmenters trained on different corpora agree in most cases. To verify this observation, we demonstrate some results on cross-test among different segmentation standards on the four corpora of Bakeoff-2006.

Our method is straightforward in that the segmenter is trained on a training corpus and the test is performed on the corresponding test corpus and the other three test corpora as well. All of the systems employ the same feature template set TMPT-4 and the six-tag set. Tables XXVI and XXVII show that as expected, different standards agree in most of segmentation cases.

Tables XXVI and XXVII display a consistent rate of more than 84% among four segmentation standards of Bakeoff-2006. Note that the least rate of con-sistency occurs between MSRA2006 and other three corpora. This means that the MSRA segmentation standard adopts quite different guideline from the other standards. Though it is not directly comparable due to different evalu-ation circumstances, we are still reminded that the rate of agreement among human judgment was only 76% on average as reported in Sproat et al. [1996].
The consistency among different standards makes it feasible to customize a pre-defined standard into any other standards as reported by Gao et al. [2005]. And it also motivates us to incorporate different segmenters into one segmenter on the current standard. For convenience, we call the segmenter subjected to the current standard the main segmenter, and the others assis-tant segmenters.

A feature template will be added for an assistant segmenter: 5: 18  X  H. Zhao et al. where t ( C 0 ) is the output tag of the assistant segmenter for the current charac-ter C 0 . For example, consider character sequence,  X  X  X  X  X  X  (He comes from Beijing), an assistant segmenter gives the tag sequence  X  SBEBE  X  according to its output segmentation, then t ( C 0 ) by this assistant segmenter is S , B , E , B , and E for each current character, respectively.

Indeed, our study shows that the more assistant segmenters are used, the better performance we can achieve. However, not all assistant segmenters are helpful for segmentation tasks in some special cases. In addition to cross-validation in training corpus that could be a general method to select the useful assistant segmenter, we empirically adopt a principle that only those assistant segmenters that are different from main segmenter in either training corpora or features should be chosen. In detail, if assistant and main segmenters are trained with the same types of features, then the training corpus of the assis-tant segmenter should be quite different from that of the main segmenter. The word  X  X uite X  means that two training corpora should not overlap too much. For example, the former should be neither the same as the latter nor a superset of the latter. If two training corpora overlap, then the features used by the assistant segmenter and the main segmenter should be somewhat different, too. In one word, the assistant segmenter should be somewhat different from the main segmenter in prior knowledge about the training set. From the view of machine learning, the assistant segmenter approach here is to equally take CRF itself as an ensemble learning strategy to integrate selected assistant seg-menters into the main segmenter. Thus, learning from the same corpus with the same way cannot bring more useful information for the ensemble goal. This issue has been summarized as a diversity requirement for learning component in ensemble learning community [Kuncheva and Whitaker 2003]. Therefore, our principle may be viewed as a special case deduced from this general inte-gration principle in machine learning. We will find that the principle of using an assistant segmenter is useful in alleviating a great deal of computational cost by cross-validation.

The proposed assistant segmenter method is more convenient and tractable compared to the additional training corpus method [Low et al. 2005]. First, the assistant segmenter is a parameter-free approach, that is, no parameters are defined or required by our approach, while the additional corpus method is not. Second, the additional corpus method is only able to extract material from external corpus, but fails to take advantage of a well-trained segmenter if the external corpus cannot be accessed at all. Third, the assistant segmenter is more computationally efficient than the additional corpus method, especially for CRF learning. The reason is that the increase of training corpus size leads to a simultaneous increase in training cost. Meanwhile, assistant segmenters only slightly increase the training cost. 5.2 External Dictionary The external dictionary method for character-based word segmentation was first introduced by Low et al. [2005]. We continue to adopt this technique in this study.

Assuming that a subsequence includes C 0 in the sentence, then the longest word W in the dictionary that matches such a subsequence will be chosen. The following features derived from the dictionary are added: where t 0 is the boundary tag of C 0 in W , and L is the number of characters in W , namely, the length of W . Our empirical study shows that t 0 is more effective than t  X  1 or t 1 ; that is why this tag is adopted.

In this study, we apply the same online dictionary from Peking University as employed in Low et al. [2005], which contains approximately 108,000 words of one to four characters in length. 13
It is interesting that we may also regard the external dictionary method as a variant of assistant segmenter to some degree. An example is a maximal matching segmenter with the specified external dictionary (we will verify this assertion through experiments). Thus, all of our additional techniques for inte-grating additional linguistic information can be viewed as assistant segmenter ones. 5.3 Assistant Segmenter Feature as Standard Adaptation Though most previous word segmenters were developed on some standard that assumes a single correct segmentation, there is still some work that at-tempts a segmentation standard adaptation, or development of customizable segmenters to make full use of existing work. The first adaptation method was introduced by Gao et al. [2004], which can be viewed as an improved ver-sion of that in Brill [1995], where the adaptation rules (or transformations) are acquired automatically from application data via the transformation-based learning (TBL) method. Though the use of TBL for Chinese word segmentation is not new [Palmer 1997; Hockenmaier and Brew 1998], none of them aim at standard adaptation, but error-driven word segmentation instead [Gao et al. 2004].

TBL method is an error-driven technique for corpus tagging task. Assum-ing that an initial annotator, some predefined transformation rules and an annotated corpus are available, TBL runs iteratively to find the best rule that causes the most error reduction in the whole corpus to determine the order of using rules until no rules can reduce errors. As for TBL-based standard adap-tation, it requires an initial segmentation, a goal segmentation, and a space of allowable transformations. Under the adaptation paradigm proposed by Gao et al. [2004; 2005], the initial segmentation is the output of the generic seg-menter that holds the original segmentation standard. The goal segmentation is represented by adaptation data. The transformation templates can adopt either words or some predefined types. 5: 20  X  H. Zhao et al.

Some problems can be handled well using simple heuristic rules for spe-cial cases by TBL. However, defining the rules for special cases can be time-consuming, difficult, and prone to errors and omissions. Normally a different rule set is needed for each domain. TBL-based standard adaptation works well in most cases as reported in Gao et al. [2004; 2005]. However, it still has an obvious drawback in that its training is very expensive, that is, too much memory and time is required. In addition, we also expect more performance enhancement by considering improved technique.

Using the same technique as the assistant segmenter method, a novel stan-dard adaptation may be conducted. Our proposed standard adaptation method works like the following. Suppose a segmenter S follows the original segmen-tation standard A , and we wish to adapt the segmenter S to segmentation standard B . In this case, we train the CRF segmenter with the following fea-ture templates: (1) all CRF feature templates for the segmentation standard B using a training data set segmented according to standard B , and (2) a feature template t ( C 0 ), where the tag t ( C 0 ) is output by segmenter S based on segmen-tation standard A . In this novel adaptation framework, we just reappraise each feature template in our system with assistant segmenter features. Now, assistant segmenter based feature will become the main feature in training, and others are the assistant (transformation) ones as adaptation rules. The adaptation procedure will still be the training of CRF. Nothing is different in the segmentation system besides our viewpoint of it.

Of course, some assistant transformation rules (additional features) can still be used for performance enhancement of standard adaptation. Segmentation standard adaptation with assistant segmenter also allows us to make a cus-tomized tradeoff between training cost and adaptation performance as the TBL method did. For example, if we want to get the better adaptation performance, then we may put all basic feature templates defined in TMPT-1. Or, we only take some unigram feature templates for faster training.

To verify the effectiveness of the proposed approach, we perform some com-parison experiments. In particular, we adopt the MSR standard as the original segmentation standard as described in MSRSeg of Gao et al. [2005]. 14 This standard was also developed by Microsoft Research Asia in Beijing. As the builder of these segmented corpora, we recognize that MSRA standard, rep-resented by MSRA2005 or MSRA2006 corpora of bakeoff, is related to MSR standard as they share some guidelines. Thus, the difference between them is actually slight according to our evaluation. However, this fact does not imply that the assistant segmenter as standard adaptation is constrained by the sim-ilarity or difference of standards. We will show that our approach is capable of adopting any existing standard.
 Different additional feature template sets are used as adaptation rules in CTB2006 and MSRA2006 corpora to demonstrate the adaptation performance. Table XXVIII shows the experimental results, where unigram stands for the three unigram feature templates defined in Table VI. Still from a view of the assistant segmenter, the results in the leftmost column with title  X  X one X  in Table XXVIII are given by direct segmentation of MSRSeg, or by a CRF seg-menter only with features as outputs of MSRSeg assistant segmenter. Both of them output the same segmentation for the same input sentence. The results in the other three columns are given by the CRF segmenter with correspond-ing adaptation feature template set incorporated with MSRSeg assistant seg-menter. We observe that the more adaptation features are used, the higher performance we can obtain.

To give a comparison with TBL-based adaptation [Gao et al. 2005], we also perform a group of experiments in four corpora of Bakeoff-2003. Without con-sidering sophisticated handcrafted transformation rules as employed in exist-ing work, we simply use two feature sets in training. Nevertheless, Table XXIX shows that our approach is superior to the existing TBL method. 5.4 Assistant Named Entity Recognizer The idea to integrate named entity (NE) information into a segmenter is straightforward from the assistant segmenter framework. Intuitively, a se-quence of words will be more convincingly segmented if it is also recognized as NE. Actually, NE is almost always segmented as a word in almost all segmen-tation standards.

A feature template will be added for an assistant NE recognizer: where t NE ( C 0 ) is the output tag of the assistant NE recognizer for the current character C 0 . For example, consider a character sequence,  X  X  X  X  X  X  (He comes from Beijing), an assistant NE recognizer identifies  X  X  (Beijing) as  X  X OCATION X  NE according to its output, then t NE ( C 0 ) will be  X  X o X ,  X  X o X ,  X  X o X ,  X  Location  X  Start  X  and  X  Location  X  End  X  for each current character, respectively. In this study, we use MSRSeg as our NE recognizer since it also outputs NE information. Besides person name, location name, and organization name, 5: 22  X  H. Zhao et al.
 NE outputs of MSRSeg also include ten types of factoid words such as date, duration, money, time, integer, e-mail, phone and so on. For details, please refer to Gao et al. [2005]. 5.5 Evaluation This group of experiments is to explore what will happen if we use many as-sistant segmenters in a task to integrate various linguistic resources. All the evaluations are done on the four corpora of Bakeoff-2006. With the help of the cross-validation method in training corpus and the proposed principle to select assistant segmenters, we integrate as many of the other segmenters as possible that are trained on all corpora from Bakeoff-2003, 2005, and 2006 with feature template set TMPT-4. The word segmenter and NE recognizer, MSRSeg, described in Gao et al. [2005], is also integrated.
 Table XXX shows the IDs of those concerned assistant segmenters, where ID  X  X SRSeg X  means that MSRSeg only works as word segmenter, ID  X  X SRSegNE X  means that MSRSeg only works as NE recognizer, and ID  X  X SRA2005 X  stands for an assistant segmenter that is trained on MSRA2005 training corpus with feature template set TMPT-4, and so on. Experimental results with incremental assistant segmenter combination for CTB2006 and MSRA2006 are shown in Tables XXXI and XXXII, respectively. Note that as-sistant segmenter features are incrementally integrated into the system for performance enhancement from left to right in Table XXXI or XXXII. For example, the result of column with the title  X +C X  in Table XXXI indicates a feature template set of TMPT-1+Ext.Dict.+C, and the result of next column  X +D+E X  indicates a feature template set of TMPT-1+Ext.Dict.+C+D+E, and so on. The order to add assistant segmenters is simply according to alphabetical order of IDs except for MSRSeg and MSRSegNE. Our empirical results show that the final performance does not depend on such an order and the final se-lected assistant segmenter set is always the same.

Our experimental results do show that the more assistant segmenters are used, the better performance we can achieve. However, according to the prin-ciple as mentioned in Section 5.1 that assistant segmenter should differ from the main segmenter to some degree, though we used all corpora of three Bake-offs to train assistant segmenters for tasks of Bakeoff-2006. Two assistant segmenters, AS2003 and AS2005, are not selected for AS2006 task, and the assistant segmenter MSRA2005 is not selected for MSRA2006. We also avoid using CTB2003 and MSRA2006 assistant segmenters in all tasks because the respective training corpus is a subset of that of CTB2006 and MSRA2005, re-spectively.

We may show one of the consequences when the principle of using assistant segmenter is violated. As we know the training corpus of MSRA2005 is a su-perset of that of MSRA2006, training for the main segmenter of MSRA2006 will be quickly prone to overfitting by the outputs of MSRA2005 assistant seg-menter, and all effective other features are ignored by main segmenter through learning. Thus a dramatic decrease in performance occurs if we insist on using this assistant segmenter as shown in Table XXXII. In fact, such a low result is just what we can obtain when we train the segmenter in training corpus of MSRA2005 and test it in test corpus of MSRA2006 with TMPT-4 feature template set. 15
Table XXXIII compares the contributions of different types of open feature templates. In Table XXXIII, basic features stand for feature template set TMPT-1, and MSRSegNE is still used as assistant NE recognizer. All assistant segmenters stand for all possible ones for the respective task except for those that are prohibited by the proposed principle of selecting assistant segmenter. Note that they may not be the same set for four tasks. Three columns whose titles contain  X + X  means that their feature template sets are the union set of TMPT-1 and the corresponding feature template set as titled, respectively. The title  X  X ll features X  in the rightmost column means that all feature template sets in previous four columns should be used. Table XXXIII shows that assis-tant segmenter approach is robust for all kinds of linguistic resources. This verifies the effectiveness in integrating various linguistic information into a system. 5: 24  X  H. Zhao et al.
 6. PERFORMANCE COMPARISON WITH EXISTING WORK 6.1 Experimental Results in Corpora of Bakeoff-2003 and 2005 The comparison between our results and the best-reported results are shown in Tables XXXIV through to XXXIX. 16 There are two types of reported results for each corpus. One is the best official result in Bakeoff-2003 and 2005. The other is presented by individual articles (i.e., post-evaluation) [Zhang and Liu 2003; Peng et al. 2004; Tseng et al. 2005; Low et al. 2005]. All of our results are obtained with a six-tag set.

To check if performance improvement is statistically significant, we perform some statistical significance tests in the results of closed test. Following pre-vious work [Sproat and Emerson 2003] and assuming the binomial distrib-ution, we may compute 95% confidence interval as  X  2 p p (1  X  p ) / n according to the Central Limit Theorem for Bernoulli trials [Grinstead and Snell 1997], where n is the number of trials (words). We suppose that the recall represents the probability of correct word identification, and the precision represents the probability that a character string that has been identified as a word is really a word. Thus two types of intervals, C r and C p , can be computed, respectively. One can determine if two results are significantly different at a 95% confidence level by checking whether their confidence intervals overlap. The values of C r and C p for experimental results in Bakeoff-2003 and 2005 are given in Tables XXXV and XXXVIII. Since many results given by individual literatures do not give the values of R and P , comparison in these two tables is performed between our results with TMPT-4 and the best official results of Bakeoff-2003 and 2005 [Sproat and Emerson 2003; Emerson 2005].

We find that the results of our system are much better than the best results of Bakeoff-2003 except for that in CTB2003 corpus. As we perform the ex-periments with the same system from Bakeoff-2003 to Bakeoff-2005, we may regard this as a consistent technical progress in Chinese word segmentation since 2003.

Some simplified results with assistant segmenter approach in open test are also demonstrated. Only one assistant segmenter is assigned for each task since our system has almost outperformed all the existing ones only with ex-ternal dictionary technique. MSRSeg assistant segmenter is used for all tasks of Bakeoff-2003. As for each task of Bakeoff-2005, an assistant segmenter that is trained with TMPT-4 from the other training corpus in the same character encoding is used. 6.2 Experimental Results in Corpora of Bakeoff-2006 The comparison between our results and the best existing results in Bakeoff-2006 are shown in Tables XL-XLII. All features in Table XXXIII are used for 5: 26  X  H. Zhao et al.
 open test (the last row in Table XLII). The results of statistical significance tests are given in Table XLI [Levow 2006]. We see that our current system still obtains competitive performance in corpora of Bakeoff-2006. 6.3 Additional Metrics To demonstrate some further difference between our results and the others, we also give a comparison of F -measure of OOV word ( F OOV ). Fiv. The re-sults of other participants except for us who ranked the first and the second in F -measures are given in Table XLIII. 17 We find that the order of F OOV is basically kept the same as F -measures of the whole performance. This fur-ther suggests that OOV word detection is very important for improvement of the whole segmentation performance, which is the point that our method pays great attention to.

Similar to Table XLIII, R OOV comparison is also given in Table XLIV. We find that though our system earns the highest R OOV in all four corpora, we do not get the same results in the word segmentation performance on the whole. This partially suggests that F OOV is a better performance metric than R OOV to evaluate how OOV word identification affects the whole performance. 7. RELATED WORK 7.1 Feature Templates Some existing systems with their feature templates, tag sets, and learning models are listed in Table XLV. There is another comparison between the system in Tseng et al. [2005] and ours: we select six n -gram feature templates in Table VI for the closed test, while there are 15 groups of feature templates in Tseng X  X  system. However, with an appropriate tag set, our system performs better (see Table XXXVII).

We attribute the superiority of our system to an effective combination of tag sets and feature template sets. A joint selection for such a collocation has demonstrated through experimental results in Tables XV and XVI. Though all feature templates that are originally used to identify OOV words in Tseng et al. [2005] don X  X  appear in our system, we do not lose such types of active features as our system is running, since additional tags with n -gram feature templates may still help to identify those consequent characters that finally form Chinese words.

The most significant difference from Peng et al. [2004] and Tseng et al. [2005] to our system is all n -gram feature templates that consist of C  X  2 or C 2 are removed. It seems that our system only considers three-character win-dow in context, but it is not the actual effect as discussed in Section 3.2. The 5: 28  X  H. Zhao et al.
 five-character window is still handled by our system with even more precise categorization information of characters.

It is possible to construct a state-of-the-art segmentation system still with a two-tag set or four-tag set, which has been verified in Tseng et al. [2005], Low et al. [2005], and Tsai et al. [2006]. However, it is often much more difficult to select useful feature templates than to select tag sets. Therefore, it will be more convenient to consider tag set selection for the first time. On the other hand, we may recognize that more feature templates in Tseng et al. [2005] than ours were used only because the two-tag set was adopted in their system.
In a word, if we may fully use tag set selection incorporated with feature template selection, then we will be able to develop a more effective and sim-plified system. In addition, this system can achieve competitive performance compared to existing systems. 7.2 Postprocessing There was a postprocessing issue in MaxEnt systems of Xue [2003] and Low et al. [2005]. If each character is just assigned the tag with the highest prob-ability, then it is possible that the MaxEnt classifier sometimes produces an illegal sequence of tags (e.g., M is followed by S ). To eliminate such possibil-ities, additional techniques were adopted in previous work. Typically, given an input character sequence, a decoding algorithm is demanded, running only within valid tag sequences.

It is fortunate that CRF is a sequence learner which can resist label-bias de-fined in Lafferty et al. [2001]. Thus, these types of invalid tag sequences never appear during our experiments, only if training corpus itself does not include invalid tag sequences. In detail, MaxEnt Markov model uses a per-state expo-nential model for the conditional probabilities of next states given the current state, while CRF has a single exponential model for the joint probability of the entire sequence of labels given the observation sequence. Thus, the normalizer Z ( W ) in Equation (1) should be computed through the entire sequence for CRF model training. This can lead to an optimal model in the whole sequence which MaxEnt Morkov model cannot guarantee.
 8. CONCLUSION In this article, we address a traditional and basic issue in Chinese language processing, Chinese word segmentation. Our analysis shows that character-based tagging framework has been a powerful learning framework in this field. Then we adopt the framework with CRF for this study.

Our contribution on the learning framework of Chinese word segmentation are two-fold. 1) We consider both feature template selection and tag set se-lection instead of previous feature template selection only method. A com-prehensive investigation of different tag sets is studied by analysis of average weighted word length computed from segmented corpus. We propose that av-erage weighted word length of the corpus can be taken as the criteria to effec-tively choose tag set. We also show that a segmentation system with a six-tag set and six n -gram feature templates can achieve competitive performance in benchmark data sets from Bakeoffs. 2) As for integration of additional linguis-tic resources, an assistant segmenter approach is proposed, and its effective-ness is verified. The assistant segmenter method is easy to handle. We also show that this method can be generalized to integrate different types of lin-guistic resources, including corpora, dictionaries and trained segmenters. In addition, assistant segmenter method is also regarded as an effective standard adaptation method for different segmentation standards.

Based on the proposed method, our system provides state-of-the-art perfor-mance in all corpora of three bakeoffs.
 The authors would like to warmly thank Dr. Jianfeng Gao from Researcher of Microsoft Research, Prof. Guodong Zhou from Soochow University, and Dr. Chunyu Kit from City University of Hong Kong, for their valuable ad-vice and friendly help. The authors also thank all anonymous reviewers who give many insightful comments and helped us improve this article greatly. 5: 30  X  H. Zhao et al.
 5: 32  X  H. Zhao et al.

