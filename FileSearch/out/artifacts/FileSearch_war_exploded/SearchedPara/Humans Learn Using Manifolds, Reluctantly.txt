 Bryan R. Gibson, Xiaojin Zhu, Timothy T. Rogers  X  , Charles W. Kalish  X  , Joseph Harrison  X  Consider a classification task where a learner is given train ing items x d -dimensional feature vectors. The learner is also given the corresponding class labels y Y . In this paper, we focus on binary labels Y  X  { X  1 , 1 } . In addition, the learner is given some unlabeled items x and unlabeled items x smooth, lower dimension manifolds , such as those schematically shown in Figure 1(a). The quest ion is: given this knowledge of labeled and unlabeled data, how w ill the learner classify x Will the learner ignore the distribution information of the unlabeled data, and simply use the labeled data to form a decision boundary as in Figure 1(b)? Or will the learner propagate labels along the nonlinear manifolds as in Figure 1(c)? Figure 1: On a dataset with manifold structure, supervised l earning and manifold learning make dramatically different predictions. Large symbols repres ent labeled items, dots unlabeled items. supervised learning [2, 11]. The designer of the algorithm c an choose to make the manifold as-sumption, also known as graph-based semi-supervised learn ing, which states that the labels vary slowly along the manifolds or the discrete graph formed by co nnecting nearby items. Consequently, understood [1, 6, 9, 10]. Alternatively, the designer can ch oose to ignore the unlabeled data and perform supervised learning, which results in Figure 1(b). When the learner is a human being, however, the answer is not so clear. Consider that the human learner does not directly see how the items are distributed i n the feature space (such as Figure 1(a)), but only a set of items (such as those in Figure 2(a)). The unde rlying manifold structure of the data may not be immediately obvious. Thus there are many possibil ities for how the human learner will behave: 1) They may completely ignore the manifold structur e and perform supervised learning; 2) They may discover the manifold under some learning conditio ns and not others; or 3) They may always learn using the manifold.
 For readers not familiar with manifold learning, the settin g might seem artificial. But in fact, many natural stimuli we encounter in everyday life are distribut ed on manifolds. An important example is face recognition, where different poses (viewing angles ) of the same face produce different 2D images. These images can be quite different, as in the fronta l and profile views of a person. However, if we continuously change the viewing angle, these 2D images will form a one-dimensional manifold in a very high dimensional image space. This example illustr ates the importance of a manifold to facilitate learning: if we can form and maintain such a face m anifold, then with a single label (e.g., the name) on one of the face images, we can recognize all other poses of that person by propagating the label along the manifold. The same is true for visual obje ct recognition in general. Other more abstract stimuli form manifolds, or the discrete analogue, graphs. For example, text documents in a corpus occupy a potentially nonlinear manifold in the other wise very high dimensional space used to represent them, such as the  X  X ag of words X  representation .
 There exists little empirical evidence addressing the ques tion of whether human beings can learn using manifolds when classifying objects, and the few studi es we are aware of come to opposing is morphed into the profile face of a different person. When par ticipants were shown such sequences during training, their ability to match frontal and profile f aces during testing was impaired [8]. This might be evidence that people depend on manifold structure s temming from temporal and spatial proximity to perform face recognition. On the other hand, Va ndist et al. conducted a categorization experiment where the true decision boundary is at 45 degrees in a 2D stimulus space (i.e., an in-formation integration task). They showed that when the two c lasses are elongated Gaussian, which are parallel to, and on opposite sides of, the decision bound ary, unlabeled data does not help learn-ing [7]. If we view these two elongated Gaussian as linear man ifolds, this result suggests that people do not generally learn using manifolds.
 This study seeks to understand under what conditions, if any , people are capable of manifold learning in a semi-supervised setting. The study has important impli cations for cognitive psychology: first, if people are capable of learning manifolds, this suggests t hat manifold-learning models that have been developed in machine learning can provide hypotheses a bout how people categorize objects in natural domains like face recognition, where manifolds app ear to capture the true structure of the domain. Second, if there are reliable methods for encouragi ng manifold learning in people, these methods can be employed to aid learning in other domains that are structured along manifolds. For machine learning, our study will help in the design of algori thms which can decide when to invoke the manifold learning assumption. We designed and conducted a set of experiments to study manif old learning in humans, with the following design considerations. First, the task was a  X  X at ch learning X  paradigm in which partici-pants viewed all labeled and unlabeled items at once (in cont rast to  X  X nline X  or sequential learning paradigm where items appear one at a time). Batch learning al lows us to compare human behavior against well-established machine learning models that typ ically operate in batch mode. Second, we avoided using faces or familiar 3D objects as stimuli, despi te their natural manifold structures as discussed above, because we wished to avoid any bias resulti ng from strong prior real-world knowl-edge. Instead, we used unfamiliar stimuli, from which we cou ld add or remove a manifold structure easily. This design should allow our experiments to shed lig ht on people X  X  intrinsic ability to learn using a manifold.
 Participants and Materials. In the first set of experiments, 139 university undergraduat es partici-pated for partial course credit. A computer interface was cr eated to represent a table with three bins, as shown in Figure 2(a). Unlabeled cards were initially plac ed in a central white bin, with bins to either side colored red and blue to indicate the two classes y  X  { X  1 , 1 } . Each stimulus is a card. Participants sorted cards by clicking and dragging with a mo use. When a card was clicked, other similar cards could be  X  X ighlighted X  in gray (depending on c ondition). Labeled cards were pinned down in their respective red or blue bins and could not be move d, indicated by a  X  X in X  in the corner of the card. The layout of the cards was such that all cards rem ained visible at all times. Unlabeled cards could be re-categorized at any time by dragging from an y bin to any other bin. Upon sorting all cards, participants would click a button to indicating c ompletion.
 consisted of a set of 20 cards with animal line drawings on a wh ite background. The images were chosen to approximate a linear continuum between fish and mam mal, with shark, dolphin, and whale at the center. The second set of stimuli used for the act ual experiment was composed of 82  X  X rosshair X  cards, each with a pair of perpendicular, axis-parallel lines, all of equal length, crossing encoded as x  X  [0 , 1] 2 , whose two features representing the positions of the verti cal and horizontal lines, respectively. Procedure. Each participant was given two tasks to complete.
 Task 1 was a practice task to familiarize the participant wit h the interface. The participant was asked to sort the set of 20 animal cards into two categories, w ith the two ends of the continuum (a clown fish and a dachshund) labeled. Participants were tol d that when they clicked on a card, highlighting of similar cards might occur. In reality, high lighting was always shown for the two nearest-neighboring cards (on the defined continuum) of a cl icked card. Importantly, we designed the dataset so that, near the middle of the continuum, cards f rom opposite biological classes would be highlighted together. For example, when a dolphin was cli cked, both a shark and a whale would be highlighted. The intention was to indicate to the partici pant that highlighting is not always a clear give-away for class labels. At the end of task 1 their fish vs. m ammal classification accuracy was presented. No time limit was enforced.
 Task 2 asked the participant to sort a set of 82 crosshair card s into two categories. The set of cards, the number of labeled cards, and the highlighting of cards de pended on condition. The participant was again told that some cards might be highlighted, whether the condition actually provided for highlighting or not. The participant was also told that card s that shared highlighting may not all have the same classification. Again, no time limit was enforc ed. After they completed this task, a follow up questionnaire was administered.
 Conditions. Each of the 139 participants was randomly assigned to one of 6 conditions, shown in Figure 3, which varied according to three manipulations: The number of labeled items l can be 2 or 4 ( 2 l vs. 4 l ). For conditions with two labeled items, the labeled items are always ( x ( x 1 , y 1 =  X  1) , ( x 2 , y 2 = 1) , ( x 3 , y 3 = 1) , ( x 4 , y 4 =  X  1) in Figure 2(b). We chose these four labeled points by maximiz ing the prediction differences made by seven machine learning models, as discussed in the next se ction. Unlabeled items are distributed on a uniform grid or manifol ds ( grid U vs. moons U ). The items x . . . x 82 were either on a uniform grid in the 2D feature space, or along two  X  X alf-moons X , which is a well-studied dataset in the semi-supervised learning com munity. No linear boundary can separate the two moons in feature space. x Highlighting similar items or not (the suffix h). For the moons U conditions, the neighboring cards of any clicked card may be highlighted. The neighborhood is d efined as within a radius of  X  = 0 . 07 in the Euclidean feature space. This value was chosen as it in cludes at least two neighbors for each point in the moons U dataset. To form the unweighted graph shown in Figure 3, an ed ge is placed between all neighboring points.
 The rationale for comparing these different conditions wil l become apparent as we consider how different machine-learning models perform on these datase ts. Figure 3: The six experimental conditions. Large symbols in dicate labeled items, dots unlabeled items. Highlighting is represented as graph edges. We hypothesize that human participants consider a set of mod els ranging from simple to sophis-ticated, and that they will perform model selection based on the training data given to them. We start by considering seven typical machine learning models to motivate our choice, and present the models we actually use later on. The seven models are: (graph) Graph-based semi-supervised learning [1, 10], which propagates labels along the graph. I t reverts to supervised learning when there is no graph (i.e., no highlighting). (1NN,  X  distance. (1NN,  X  els are similar to exemplar models in psychology [3]. (multi-v) multiple vertical linear bound-aries. (multi-h) multiple horizontal linear boundaries. (single-v) a single vertical linear boundary. (single-h) a single horizontal linear boundary. We plot the label predi ctions by these 7 models on 4 l moons U are identical to 4 l moons U h , except that  X (graph) X  is not available.
 For conceptual simplicity and elegance, instead of using th ese disparate models we adopt a single model capable of making all these predictions. In particula r, we use a Gaussian Process (GP) with different kernels (i.e., covariance functions) k to simulate the seven models. For details on GPs see standard textbooks such as [4]. In particular, we find sev en different kernels k to match GP classification to each of the seven model predictions on all 6 conditions. This is somewhat unusual in that our GPs are not learned from data, but by matching othe r model predictions. Nonetheless, it is a valid procedure to create seven different GPs which will later be compared against human data. For models (1NN,  X  w.r.t. the corresponding model prediction on all 6 conditio ns. For model (1NN,  X  Reproducing Kernel Hilbert Space trick in [6]. That is, we ex tend a base RBF kernel k with a graph component: where x, z are two arbitrary items (not necessarily on the graph), k is the kernel vector between x and all l + u points x Gram matrix with K unweighted edges on the  X  NN graph defined earlier for highlighting, and c is the parameter that we tune. We take the base RBF kernel k to be the tuned kernel for model (1NN,  X   X  k is a valid kernel formed by warping the base kernel k along the graph, see [6] for technical details. We used the GP classification implementation with Expectati on Propagation approximation [5]. In the end, our seven GPs were able to exactly match the predictions made by the seven models in Figure 4. We will use these GPs in the rest of the paper. We now compare human categorization behaviors to model pred ictions. We first consider the ag-gregate behavior for all participants within each conditio n. One way to characterize this aggregate behavior is the  X  X ajority vote X  of the participants on each i tem. That is, if more than half of the participants classified an item as y = 1 , the majority vote classification for that item is y = 1 , and so on. The first row in Figure 5 shows the majority vote for each condition. In these and all further plots, blue circles indicate y =  X  1 , red pluses y = 1 , and green stars ambiguous, meaning the classification into positive or negative is half-half. We al so compute how well the seven GPs predict human majority votes. The accuracies of these GP models are s hown in Table 1 1 . Figure 5: Human categorization results. (First row) the maj ority vote of participants within each condition. (Bottom three rows) a sample of responses from 18 different participants.
 Of course, a majority vote only reveals average behavior. We have observed that there are wide fidence scores were fairly low in all conditions. It was also n oted that strategies for completing the task varied widely, with some participant simply categoriz ing cards in the order they appeared on the screen, while others took a much longer, studied approach. M ost interestingly, different participants seem to use different models, as the individual participant plots in the bottom three rows of Figure 5 suggest. We would like to be able to make a claim about what mod el, from our set of models, each participant used for classification. In order to do this, we c ompute per participant accuracies of the seven models on that participant X  X  classification. We th en find the model M with the highest accuracy for the participant, out of the seven models. If thi s highest accuracy is above 0.75, we declare that the participant is potentially using model M ; otherwise no model is deemed a good fit and we say the participant is using some  X  X ther X  model. We sho w the proportion of participants in each condition attributed to each of our seven models, plus  X  other X , in Table 2. Based on Figure 5, Table 1, and Table 2, we make some observati ons: 1. When there are only two labeled points, the unlabeled distrib ution does not encourage humans to It seems they are  X  X locked X  by the simpler vertical or horizo ntal hypothesis, which perfectly explains the labeled data. 3. When there are four labeled points but no highlighting, the di stribution of unlabeled data still does not encourage people to perform manifold learning (compari ng 4 l grid U vs. 4 l moons U ). This further suggests that people can not easily extract manifold struct ure from unlabeled data in order to learn, when there is no hint to do so. However, most participants hav e given up the simple single vertical or horizontal decision boundary, because it contradicts wi th the four labeled points. 4. Finally, when we provide the graph structure, there is a mark ed switch to manifold learning simpler hypotheses, together with a stronger graph hint, fin ally gives the originally less preferred manifold learning model a chance of being used. It is under th is condition that we observed human manifold learning behavior. Do humans really learn using manifolds? Could they have adop ted a  X  X ollow-the-highlighting X  procedure to label the manifolds 100% correctly: in the begi nning, click on a labeled card x to highlight its neighboring unlabeled cards; pick one such ne ighbor x  X  and classify it with the label of x ; now click on (the now labeled) x  X  to find one of its unlabeled neighbors x  X  X  , and repeat? Because our graph has disconnected components with consistently la beled seeds, this procedure will succeed. The procedure is known as propagating-1NN in semi-supervis ed learning (Algorithm 2.7, [11]). In this section we present three arguments that humans are not b lindly following the highlighting. the two conditions have the same  X  NN highlighting.
 according to a labeled highlighted neighbor x . Conversely, if a participant classifies x  X  as class y , while all neighbors of x  X  are either still unlabeled or have labels other than y  X  , she could not have been using follow-the-highlighting on x  X  . We say she has taken a leap-of-faith on x  X  . The strict follow-the-highlighting procedure would yield zer o leaps-of-faith.
 Third, the basic challenge of follow-the-highlighting is t hat the underlying manifold structure of the stimuli may have been irrelevant. Would participants have s hown the same behavior, following the highlighting, regardless of the actual stimuli? We therefo re designed the following experiment. Take the 4 l moons U h graph which has 4 labeled nodes, 78 unlabeled nodes, and an ad jacency matrix (i.e., edges) defined by  X  NN, as shown in Figure 3. Take a random permutation  X  = (  X  the feature vector of the i th unlabeled point to x This creates the random-looking graph in Figure 6(a) which w e call 4 l moons U h R condition (the suffix two connected components with consistent labeled seeds. Ho wever, now the highlighted neighbors may look very different than the clicked card.
 If we assume humans blindly follow the highlighting (perhap s noisily), then we predict that they are more likely to classify those unlabeled points nearer (i n shortest path length on the graph, not participated in the new 4 l moons U h R condition. Figure 6(b) shows the above behavioral evaluati on, which does not exhibit the predicted correlation, and is cle arly different from the same evaluation for similar to having no highlighting in how it affects human cat egorization. This can be seen from the We have presented a set of experiments exploring human manif old learning behaviors. Our results suggest that people can perform manifold learning, but only when there is no alternative, simpler explanation of the data, and people need strong hints about t he graph structure.
 We propose that Bayesian model selection is one possible way to explain these human behaviors. Recall we defined seven Gaussian Processes, each with a diffe rent kernel. For a given GP with kernel k , the evidence p ( y hidden discriminant function sampled from the GP. With mult iple candidate GP models, one may perform model selection by selecting the one with the larges t marginal likelihood. From the absence of manifold learning in conditions without highlighting or with random highlighting, we speculate behavioral evaluation for 4 l moons U h R , where the x -axis is the shortest path length of an unlabeled point to a labeled point, and the y -axis is the fraction of participants who classified that unl abeled only when strong hints (highlighting) exists and agrees wit h the underlying unlabeled data manifold structure. Under this assumption, we can then explain the co ntrast between the lack of manifold 2 l moons U h condition, the evidence for the seven GP models on the two lab eled points are: (graph) 0.249, (1NN,  X  h) 0.249. The graph-based GP has slightly lower evidence tha n several other GPs, which may be due to our specific choice of kernel parameters in (1). In any c ase, there is no reason to prefer the GP with a graph kernel, and we do not expect humans to learn on m anifold in 2 l moons U h . On the other hand, for 4 l moons U h , the evidence for the seven GP models on those four labeled po ints are: (graph) 0.0626, (1NN,  X  0.0341, (single-h) 0.0342. The graph-based GP has a small le ad over other GPs. In particular, it is better than the evidence 1/16 for kernels that treat the four labeled points essentially independently. The graph-based GP obtains this lead by warping the space alo ng the two manifolds so that the two positive (resp. negative) labeled points tend to co-vary. T hus, there is a reason to prefer the GP with a graph kernel, and we do expect humans to learn on manifold in 4 l moons U h .
 We also explore the convex combination of the seven GPs as a ri cher model for human behavior: used, and is more powerful than selecting a single kernel. Ag ain, we optimize the mixing weights  X  by maximizing the evidence p ( y be easily solved up to local optimum (because evidence is in g eneral non-convex) with a projected gradient method, given the gradient of the log evidence. For the 2 l moons U h condition, in 100 trials with random starting  X  values, the maximum evidence always converges to 1/4, while the optimum  X  is not unique and occupies a subspace (0 ,  X  0.0626. i.e., it again suggests that people would perform ma nifold learning in 4 l moons U h . Of course, this Bayesian model selection analysis is over-s implified. For instance, we did not con-sider people X  X  prior p (  X  ) on GP models, i.e., which model they would prefer before seei ng the data. It is possible that humans favor models which produce axis-p arallel decision boundaries. Defining and incorporating non-uniform p (  X  ) priors is a topic for future research.

