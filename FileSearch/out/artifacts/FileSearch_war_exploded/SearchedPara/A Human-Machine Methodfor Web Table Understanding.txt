 Tabular data on the Web has become a rich source of structured data that is useful for ordinary users to explore. According to a recent Google study [2], there are a total of 14 billion raw HTML tables and, among those, 150 million relational data tables, easily making Web tables one of the richest structured data sources.There are many real-world applications that can benefit from high-quality Web tables. First, search engines can utilize Web tables to improve the result quality. Existing search engines usually return relevant Web pages for queries and require users to  X  X ine X  answers from the returned Web pages. Ob-viously if there are many relevant high-quality Web tables, s earch engines can utilize these high-quality structured data to directly compute the answers and do not require users to search answers from documents. Query-answer (QA) sys-tems can also utilize Web tables to easily generate answers for queries. Second, many systems want to provide Internet users with OLAP functionality, which is not supported in traditional keyword-based search systems. For example, if a user wants to know the average price of  X  iphone 5  X  in Beijing. Search en-gines cannot answer such queries. If we can extract Web tables about prices of  X  iphone 5  X  in Beijing. We can utilize these Web tables to answer such queries. Third, knowledge bases can use Web tables to enrich themselves by adding more concepts, entities and relationships between columns.

Due to the potential, tables on the W eb have recently attracted a number of studies with the goals of understanding the semantics of those Web tables and providing effective search and exploration mechanisms over them [10,5,6,2]. Table understanding is to identify, recognize and interpret tabular structures to enable a variety of tasks such as data extraction, data interpretation, data integration, and search and analysis.

There are many research challenges in Web table understanding. The first challenge is how to identify large-scale high-quality Web tables. On one hand, there are billions of Web pages and only some of them contain tabular data. On the other hand, the Web data is rather dirty (due to typing errors or different representations for the same entity). Thus it is non-trivial to identify high-quality Tables from large numbers of Web pages. The second one is how to recognize Web tables. There is usually no description information for each Web table. The column names of Web tables are also usua lly incomplete or inaccurate because the same concept/entity may have differen t representations. Thus it is rather hard to determine the subject of a Web table (the main content the Web ta-ble describes) , the concept of each col umn, and the entity of each cell value in the table. The third challenge is how to integrate multiple Web tables from different sources. Since Web tables fro m different sources may be relevant, we want to integrate them to generate more accurate and complete structured data. The fourth challenge is how to use Web ta bles to effectively support search and analysis applications. Internet users are only familiar with keyword queries and do not understand structured query languages. We need to bring the unstruc-tured queries and the underlying structured data much closer so as to help users explore Web tables.

To address these challenges, we propose a human-machine hybrid method for understanding tables on the Web. We combine knowledge bases, crowds, and algorithms together and develop effectiv e techniques to improve the quality of web table understanding. In this paper, we focus on four main problems -Web table extraction, Web table interpretation, Web table integration, and Web table search and analysis.
 Paper Structure: In the paper, we first introduce our human-machine hybrid framework in Section 2 and then discuss some open problems in Section 3. Next we review some important related work s in Section 4. Finally we conclude the paper in Section 5. 2.1 Human-Machine Hybrid Framework We propose a human-machine framework to effectively understand Web tables. Figure 2.1 shows the framework which contains four main components: Web Table # %*('(**!&amp;% # %*(*!&amp;% #( %%#.)!) +(. %),( %*!*. -*(*!&amp;% Extraction, Web Table Interpretation, Web Table Integration, Web Table Search and Analysis . Web Table Extraction extracts and generates Web tables from billions of Web pages and obtains high-quality Web tables. Web Table Interpretation annotates Web tables as follows. Given a Web table with several columns and each column having multiple cell values, Web table interpretation wants to (1) label each column with top-k relevant concepts; (2) label each cell value in the table with top-k entities; (3) identify the relat ionships between columns; and (4) find the primary keys of the Web table. Web Table Integration integrates multiple Web tables by finding correspondences between their primary keys and other columns. In other words, it finds the table pairs with primary keys corresponding to the same concept and correlates other columns which also correspond to the same concept. Web table integration has the following differences with traditional schema mapping. First, the tables in the schema mapping problem are usually well-structured and clean while Web tables are rather dirty (Since there may exist errors and inconsistencies in We b data). Second, the primary keys in Web tables are not given. Third, the number of cell values in Web tables is usually much smaller than that in schema-matching problems. Thus traditional instance-level schema mapping techniques may not work for integrating Web tables. Web Table Search and Analysis provides users with search and analysis functionalities. For example, users can search on the Web tables and get analysis results from We tables. Next we discuss th e details of each component. 2.2 Web Table Extraction To extract Web tables from Web pages, we enumerate each W eb page and detect whether the Web page contains tables. If yes, we extract the tables from the page as follows. We use the rule-based metho d to detect and extract the Web tables. The basic idea is that if a page contains Web tables, it usually contains some important keywords, e.g.,  X  table, tr, th, td  X . We can utilize these rules to extract Web tables. In addition, to ext ract Web tables in a specific topic, we employ a dictionary based entity extraction method. We take the entities in the given topic as a dictionary and check whether the Web page contains enough entities in the dictionary. We can als o support approximate matching between entities and substrings in a dictionary by using similarity functions (e.g., Jaccard and Edit distance) to quantify the similarity. Then we can extend approximate entity extraction methods to address the Web table extraction problem. Inter-ested readers refer to [12,3] for more details about approximate directionally based entity extraction. 2.3 Web Table Interpretation We utilize knowledge bases to effectively annotate Web tables. A knowledge base consists of many concepts and each c oncept has large numbers of entities. Different concepts may have  X  X ype-subtype X  relationships. For example, Figure 2 shows a part of a knowledge base. In the figure, the leaf nodes are entity set and intermediate nodes are concepts.

For each column, we identify the concepts that have large similarity with the column to annotate the column. The similarity between a column and a concept can be quantified by using existing set sim ilarity functions (on the set of cell val-ues of the column and the set of entities o f the concept), e.g., Jaccard coefficient or Cosine similarity. For example, the J accard similarity between the second col-umn of the Web table to the concepts  X  /film  X ,  X  /film/drama  X ,  X  /film/war  X  are respectively 3/5, 1/2, and 1/5. If we want to select top-1 concept for the second column, it should be  X  /film  X .

There are several challenges to annotate the Web tables using knowledge bases. First, there are large numbers of Web tables, and knowledge bases have large numbers of entities. It is challenging to annotate Web tables using knowl-edge bases, especially finding top-k concepts for each column. To address this challenge, we devise a Map-Reduce based similarity join method. We extend the partition-based method to support similarity joins in parallel [13]. Second, since Web tables many contain errors or the same entity may have different represen-tations, it is very important to support fuzzy matching between cell values and entities. For example, although the cell value  X  The Da Vinci Code  X  X ntheWeb table does not exactly match the entity  X  Da Vinci Code  X  in the knowledge base, they should represent the same entity. If we can support fuzzy matching, they can be approximately matched and identified as the same entity and thus the fuzzy matching based method can improve the annotation quality. To address the second challenge, we use hybrid similarity functions which tolerate fuzzy matching between tokens in set similarity functions. Interested readers refer to [27] for details about the hybrid similarity functions and how to support such complex similarity functions.

After annotating the columns, we can get top-k concepts of each column. Then for each cell value, we can find top-k entities from the entities of these concepts. Notice that this problem can be reduced to the problem of top-k similarity join, which, given two sets of entities, for each entity in a set, finds top-k similar entities from another set. We devise efficient similarity join based algorithms to address this problem [4,13,26].

In terms of relationship discovery between different columns, we can model the problem as the Steiner graph problem which finds Steiner trees from a graph. The concepts in the knowledge base can be modelled as a graph where nodes are concepts and edges are relationshi ps between concepts. Given a Web table, each column corresponds to several nodes (entities) in the knowledge base. We want to find a Steiner tree which covers all columns with the minimum cost (i.e., the sum of the edge weights in the Steiner tree). We adopt existing Steiner tree based method to address this problem [17]. 2.4 Web Table Integration Web table integration includes three steps. In the first step, we require to discover the primary keys (or subjects) of each Web table. In the second step, we identify the concepts of each column. In the third step, we integrate Web tables with their primary keys mapping to the same concep t. These Web tables can be integrated together. Then we integrate other columns which map to the same concept. Next we discuss the details of each step.
 Primary Key Discovery: We utilize the Steiner tree of each Web table to discover its primary keys. Intuitively, the column that has (directly or indirectly) relationships to each other column should be the primary keys. We can use this idea to identify the primary keys. To improve the quality, we propose a human-machine hybrid method. We first cluster the Steiner trees based their structures. Then from each cluster, we select some St einer trees as representatives and ask crowds for finding the accurate primary keys of these Steiner trees. Based on the results of representatives, we utilize them to select primary keys for other Steiner trees with similar structures. In this way, we can utilize crowds to improve the quality.
 Human-Machine Concept Determination: In the second step, we identify the concepts of each column. Although w e can use the concept determination method discussed in Section 2.3, the quality may be not good enough. To ad-dress this problem, we propose a human-machine based concept determination method. First, we use the machine based method to identify top-k concepts of each column. Then we construct a gra ph where nodes are columns and con-cepts. There is an edge from a column to a concept/column if their similarity is not smaller than a threshold and the edge weight is their similarity. Next we want to select some edges to ask questions from crowds and utilize the answers to judge whether we need to check other edges. Notice that we can utilize the  X  transitivity  X  property to reduce the number of questions. The basic idea is that given two concepts c 1 and c 2 and a concept T . If the similarity between c 1 and T is very large, and the similarity between c 1 and c 2 is also very large, then we can deduce that the similarity between c 2 and T should be large based on the transitivity rule. In this way, we only need to ask the question between c 1 and T and avoid the question between c 2 and T . Thus we can reduce the money cost. This is a challenge to select  X  X mportant X  edges to ask questions and how to ask the questions  X  X n an appropriate order X . We have proved that it is better to first ask questions of edges with large similarity [28]. Based on this idea, we can devise efficient methods to select edges to ask questions.
 Web Table Integration: We identify the tables whose primary keys correspond to the same concept and integrate them together as follows. For two tables that can be integrated on primary keys, we check whether their other columns can map to the same concept. If yes, we also integrate these columns. In this way, we can integrate multiple Web tables. 2.5 Web Table Search and Analysis Given the Web tables, we need to provide the Internet users with search and analysis functionalities. There are two challenges. First, how to judge whether a query can be effectively answered by Web tables. Second, how to efficiently answer search and aggregation queries on Web tables. To address the first chal-lenge, we use query logs to help us check whether Web tables contain the answers of a query. We construct a bipartite graph where nodes are queries and Web ta-bles and there is an edge between a query and a Web table if the Web table is an answer of the query. Based on the bipartite graph, for each new query, we can determine whether we can use Web tables to answer the query. For the second challenge, there are three main sea rch strategies: keyword search, form-based search (aka. query by example -Q BE), and SQL. However they have some limitations. First, keyword search does not support aggregation queries. Second, SQL is hard to use for Internet users since it requires users to know SQL syntax and the underlying schema. Third, the form based method has less usability than keyword search and worse expressiveness than SQL. To address this problem, we propose a new search paradigm, called search-as-you-type, to improve user search experiences.
 Search-as-You-Type: It returns answers as users type in queries letter by letter. It can provide users with instant feedback and help users to modify their input queries. It can reduce users typing effort. Moreover, our method can also tolerate the errors and inconsistencies between queries and the underlying data. We utilize similarity functions to tolerate the errors, e.g., Edit Distance. In other words, even if the data approximately m atches the query, we still can find it as an answer. The big challenge is to support instant feedback for each keystroke, which is usually in several milliseconds. To address this issue, we devise effective trie-based indexing structures and efficient search algorithms [18,15,11,16,8]. Search-as-You-Type on Forms: Keyword search methods cannot support aggregation queries. To address this limitation, we enable search-as-you-type on forms [14]. As users type in queries letter by letter in forms, we can on-the-fly return answers and aggregate on the attribute the users are typing in. The big challenge is how to support on-the-fly aggregation and search on multiple attributes. We devise effective multi-trie based index and search algorithms [14]. SQL Suggestion: In many real-world applications, many users must type in SQL queries, e.g., Database Administrator (DBA), SQL programmers. To boost users SQL coding productivity, we propose SQL suggestion which on-the-fly sug-gests SQL queries as users type in keywords letter by letter [7]. The big challenge is how to generate structured queries based on limited keywords. Moreover, we want to support aggregation queries, e.g., max, count, min. It is rathe chal-lenging to support structure queries as well as aggregation queries. We propose template-based index structure and threshold-based algorithms to effectively generate SQL queries [7]. There are still many open problems and r esearch opportunities in Web table understanding. 3.1 Extracting Web Tables from Unstructured Data The number of tables on the Web is limited and large volume of Web content is in unstructured format. Thus Web tables are not enough to support various applications. If we can extract more Web tables from unstructured data, we can increase the number of Web tables so as to cover more real-world applications. The challenge is how to extract and integrate structured data from unstructured content. A possible way is to use knowledge bases to guide the extraction and integration. It calls for effective techni ques to support semantic and structure aware extraction and integration. 3.2 Quality Control in Web Table Interpretation Many cell values in Web tables may not appear in knowledge bases, and in this way the knowledge base interpretation method cannot understand such tables. Although we can utilize crowds to annotate these tables, crowds may return inaccurate answers for such  X  X ncommon X  data (since they do not appear in knowledge bases, they should be infrequent and thus crowds may not be familiar with such uncommon data), thus the quality cannot be guaranteed. In addition, workers in crowdsourcing platforms may also return inaccurate answers, we need to devise effective methods to tolerate the errors. To address these problems, it calls for effective quality control techniques to guarantee the quality in Web table interpretation.
 3.3 Large-Scale Web Table Integration Due to the high-money-cost and large-latency limitations in crowdsourcing, it is rather expensive and time consuming to use crowds to annotate and integrate Web tables. It calls for new methods to s upport large numbers of Web tables. It may be an opportunity to combine machine learning algorithms, knowledge bases, and crowds to integrate multiple Web tables. First, the crowds only anno-tate some Web tables that are hard to correctly annotate for algorithms. Then, we use machine leaning based algorithms to use crowd X  X  answers to annotate other Web tables so as to reduce the number of questions submitted to crowds. Iteratively, we can integ rate large numbers of Web tables with less money cost and high quality. In this section, we review some importan t existing studies that are related to Web table understanding.
 Web Table Systems: Google has launched a FusionTable project [10] to gather high-quality relational tables from the Web. Elmeleegy et al. [5,6] proposed to extract and integrate tables from Web lists. Cafarella et al. [2] built a WebTable system by extracting and leveraging the relational information embedded in HTML tables on the Web.
 Web Table Annotation: Limaye et al.[19] studied how to annotate columns of Web tables, i.e., determining the concept of each column of Web tables, the entity of each cell value, and the relationship b etween columns. They employed machine learning based techniques which are neither scalable nor efficient. Venetis et al. proposed a simple majority-rule mechan ism of selecting the concept(s) that the most cells in the column have been mapped to, but with a much larger knowledge base that is derived from the Web [25]. Obviously this method does not support fuzzy matching between cell values and entities and leads to low recall. Yakout et al. [30] studied how to augment entities with attribute values and discovering attributes using Web tables. Pimplikar et al. [23] studied how to answer table queries based on column keywords.
 Knowledge Bases: Freebase [1] is a collaboratively created graph database for structuring human knowledge which is manually built by thousands of data-lovers. Freebase contained about 4 thousand types and 40 million entities. Probase [29] is a universal, probabilistic taxonomy which is harnessed from bil-lions of Web pages using some predefined patterns, such as  X  X sA X  and  X  X uch as X  patterns. Probase included more than 2.7 million types and about 22 mil-lion entities. Yago [24] is a large semantic knowledge base which is derived from Wikipedia, WordNet and GeoNames. Yago contained about 0.3 million types and 9 million entities.
 Crowdsourcing: Crowdsourcing recently attracte d significant attention from both industrial and academic communities. Amazon developed a crowdsourc-ing platform, called Amazon Mechanical Turk (https://www.mturk.com/mturk/ welcome). There are about millions of active users and we can conduct real experiments on this platform. From database communities, Franklin et al. [9] developed a crowdsourcing database system to answer database-hard queries. Parameswaran et al. developed [22] effici ent filtering algorithms using crowds. Liu et al. [20] developed a crowdsourcing data analytics system. Marcus et al.[21] enabled crowds to support joins and sorts. We studied the crowdsourcing entity solution problem [28]. In this paper, we introduce the potential of Web tables and discuss the research challenges in Web table understanding. We propose a human-machine framework for effectively and efficiently understanding Web tables. We develop effective in-dexes and algorithms to address four main problems in Web table understanding: Web table extraction, Web Table Interpretation, Web table integration, and Web table search and analysis. We also discuss some open problems and research op-portunities in Web table management. We believe that Web table management will attract much more attention from both industrial and academic communities in the near future.
 Acknowledgement. This work was partly supported by the National Nat-ural Science Foundation of Ch ina under Grant No. 61003004 and 61272090, National Grand Fundamental Research 973 Program of China under Grant No. 2011CB302206, and a project of Tsinghua University under Grant No. 20111081073, and the  X  X ExT Research Cen ter X  X  funded by MDA, Singapore, under Grant No. WBS:R-252-300-001-490.

