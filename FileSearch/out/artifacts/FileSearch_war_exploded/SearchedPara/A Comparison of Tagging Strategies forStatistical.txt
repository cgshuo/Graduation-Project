 The purpose of information extraction (IE) is to find desired pieces of information in natural lan-guage texts and store them in a form that is suitable for automatic querying and processing. IE requires a predefined output representation ( target structure ) and only searches for facts that fit this representation. Simple target struc-tures define just a number of slots to be filled with a string extracted from a text ( slot filler ). For this simple kind of information extraction, statistical approaches that model IE as a token classification task have proved very successful. These systems split a text into a series of to-kens and invoke a trainable classifier to decide for each token whether or not it is part of a slot filler of a certain type. To re-assemble the clas-sified tokens into multi-token slot fillers, various tagging strategies can be used.

So far, each classification-based IE approach combines a specific tagging strategy with a spe-cific classification algorithm and specific other parameter settings, making it hard to detect how each of these choices influences the results. To allow systematic research into these choices, we have designed a generalized IE system that allows utilizing any tagging strategy with any classification algorithm. This makes it possible to compare strategies or algorithms in an iden-tical setting. In this paper, we describe the tag-ging strategies that can be found in the liter-ature and evaluate them in the context of our framework. We also introduce a new strategy, called Begin/After tagging or BIA , and show that it is competitive to the best other strate-gies. While there are various approaches that employ a classification algorithm with one of the tagging strategies described below, there are no other comparative analyses of tagging strategies yet, to the best of our knowledge.

In the next section, we describe how IE can be modeled as a token classification task and ex-plain the tagging strategies that can be used for this purpose. In Sec. 3 we describe the IE frame-work and the experimental setup used for com-paring the various tagging strategies. In Sec. 4 we list and analyze the results of the compari-son. There are multiple approaches that model IE as a token classification task, employing standard classification algorithms. These systems split a text into a series of tokens and invoke a trainable classifier to decide for each token whether or not it is part of a slot filler of a certain type. To re-assemble the classified tokens into multi-token slot fillers, various tagging strategies can be used.
The trivial ( Triv ) strategy would be to use a single class for each slot type and an addi-tional  X  O  X  class for all other tokens. However, this causes problems if two entities of the same type immediately follow each other, e.g. if the names of two speakers are separated by a line-break only. In such a case, both names would be collapsed into a single entity, since the trivial strategy lacks a way to mark the begin of the second entity.

For this reason (as well as for improved classi-fication accuracy), various more complex strate-gies are employed that use distinct classes to mark the first and/or last token of a slot filler. The two variations of IOB tagging are proba-bly most common: the variant usually called IOB2 classifies each token as the begin of a slot filler of a certain type ( B-type ), as a continua-tion of the previously started slot filler, if any ( I-type ), or as not belonging to any slot filler ( O ). The IOB1 strategy differs from IOB2 in us-ing B-type only if necessary to avoid ambiguity (i.e. if two same-type entities immediately follow each other); otherwise I-type is used even at the beginning of slot fillers. While the Triv strat-egy uses only n + 1 classes for n slot types, IOB tagging requires 2 n + 1 classes.

BIE tagging differs from IOB in using an ad-ditional class for the last token of each slot filler. One class is used for the first token of a slot filler ( B-type ), one for inner tokens ( I-type ) and an-other one for the last token ( E-type ). A fourth class BE-type is used to mark slot fillers consist-ing of a single token (which is thus both begin and end). BIE requires 4 n + 1 classes.

A disadvantage of the BIE strategy is the high number of classes it uses (twice as many as IOB1 | 2 ). This can be addressed by introduc-ing a new strategy, BIA (or Begin/After tag-ging). Instead of using a separate class for the last token of a slot filler, BIA marks the first to-ken after a slot filler as A-type (unless it is the begin of a new slot filler). Begin ( B-type ) and continuation ( I-type ) of slot fillers are marked in the same way as by IOB2 . BIA requires 3 n + 1 classes, n less than BIE since no special treat-ment of single-token slot fillers is necessary.
The strategies discussed so far require only a single classification decision for each token. An-other option is to use two separate classifiers, one for finding the begin and another one for finding the end of slot fillers. Begin/End ( BE ) tagging requires n + 1 classes for each of the two classifiers ( B-type + O for the first, E-type + O for the second). In this case, there is no distinction between inner and outer (other) to-kens. Complete slot fillers are found by com-bining the most suitable begin/end pairs of the same type, e.g. by taking the length distribution of slots into account. Table 1 lists the properties of all strategies side by side. Our generalized IE system allows employing any classification algorithm with any tagging strat-egy and any context representation, provided that a suitable implementation or adapter ex-ists. For this paper, we have used the Winnow (Littlestone, 1988) classification algorithm and the context representation described in (Siefkes, 2005), varying only the tagging strategy. An ad-vantage of Winnow is its supporting incremen-tal training as well as batch training. For many  X  X eal-life X  applications, automatic extrac-tions will be checked and corrected by a human revisor, as automatically extracted data will al-ways contain errors and gaps that can be de-tected by human judgment only. This correction process continually provides additional training data, but the usual batch-trainable algorithms are not very suited to integrate new data, since full retraining takes a long time.

We have compared the described tagging strategies on two corpora that are used very of-ten to evaluate IE systems, CMU Seminar An-nouncements and Corporate Acquisitions . 1 For both corpora, we used the standard setup: 50/50 training/evaluation split, averaging results over five (Seminar) or ten (Acquisitions) random splits,  X  X ne answer per slot X  (cf. Lavelli et al. (2004)). Extraction results are evaluated in the usual way by calculating precision P and re-call R of the extracted slot fillers and combin-ing them in the F-measure , the harmonic mean of precision and recall: F = 2  X  P  X  R P + R . 2 For sig-nificance testing, we applied a paired two-tailed Table 3: Incremental Training: Significance of Changes Compared to IOB2 Table 4: Batch Training: Significance of Changes Compared to IOB2 Student X  X  T-test on the F-measure results, with-out assuming the variance of the two samples to be equal. Table 2 list the F-measure results (in percent) reached for both corpora using batch training. Incremental results have been omitted due to lack of space X  X hey are generally slightly worse than batch results, but in many cases the dif-ference is small. For the Corporate Acquisitions , the batch results of the best strategies (IOB2 and BIA) are better than any other published results we are aware of; for the Seminar An-nouncements , they are only beaten by the ELIE system (Finn and Kushmerick, 2004). 3
Tables 3 and 4 analyze the performance of each tagging strategy for both training regimes, using the popular IOB2 strategy as a baseline. The first item in each cell indicates whether the strategy performs significantly better ( X + X ) or worse ( X  X  X ) than IOB2 or whether the per-formance difference is not significant at the 95% level ( X  X  X ). In brackets, we show the significance of the comparison and whether the results are better or worse when significance is ignored. Considering these results, we see that the IOB2 and BIA strategies are best. No strategy is able to significantly beat the IOB2 strategy on any slot, neither with incremental nor batch training. The newly introduced BIA strategy is the only one that is able to compete with IOB2 on all slots. The IOB1 and Triv strategies come close, being significantly worse than IOB2 only for one or two slots. The two-classifier BE strategy is weaker, being significantly outper-formed on three (incremental) or four (batch) slots. Worst results are reached by the BIE strategy, where the difference is significant in about half of all cases. The good performance of BIA is interesting, since this strategy is new and has never been used before (to our knowledge). The Triv strategy would have supposed to be weaker, considering how simple this strategy is. Previously, classification-based approaches to IE have combined a specific tagging strategy with a specific classification algorithm and specific other parameter settings, making it hard to de-tect how each of these choices influences the re-sults. We have designed a generalized IE sys-tem that allows exploring each of these choices in isolation. For this paper, we have tested the tagging strategies that can be found in the lit-erature. We have also introduced a new tagging strategy, BIA ( Begin/After tagging).

Our results indicate that the choice of a tag-ging strategy, while not crucial, should not be neglected when implementing a statistical IE system. The IOB2 strategy, which is very popular, having been used in public challenges such as those of CoNLL (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al., 2004), has been found to be indeed the best of all established tagging strategies. It is ri-valed by the new BIA strategy. In typical sit-uations, using one of those strategies should be a good choice X  X ince BIA requires more classes, it makes sense to prefer IOB2 when in doubt. Considering that it is not much worse, the Triv strategy which requires only a single class per slot type might be useful in situations where the number of available classes is limited or the space or time overhead of additional classes is high. The two-classifier BE strategy is still in-teresting if used as part of a more refined ap-proach, as done by the ELIE system (Finn and Kushmerick, 2004). 4 Future work will be to ob-serve how well these results generalize in the context of other classifiers and other corpora. To combine the strengths of different tagging strategies, ensemble meta-strategies utilizing the results of multiple strategies could be explored.
