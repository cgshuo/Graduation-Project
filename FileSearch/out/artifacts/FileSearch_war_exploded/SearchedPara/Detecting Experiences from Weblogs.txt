 In traditional philosophy, human beings are known to acquire knowledge mainly by reason-ing and experience . Reasoning allows us to draw a conclusion based on evidence , but people tend to believe it firmly when they experience or o b-serve it in the physical world. Despite the fact that direct expe rience s play a crucial role in ma k-ing a firm decision and solving a problem, people often resort to indi rect experiences by reading written materials or asking around. Among many sources people resort to, the Web has become the largest one for human exp e-riences, especially with the proliferation of we b-logs. 
While Web doc uments contain various types of informa tion including facts, encyclopedic kno wledge, opinions, and expe riences in general , personal experiences tend to be found in weblogs more often than other web document s like news articles, home pages, and scientific p apers. As such, we have begun to see some research efforts in mining experience -related attributes such as time, location, topic, and experience r, and their relations from weblogs (Inui et al., 2008; Kur a-shima et al., 2009) . 
Mined experiences can be of pr actical use in wide application areas. For example, a collection of experiences from the people who visited a resort area would help planning what to do and how to do things correctly without having to spend time sifting through a variety of resources or r ely on co mmercially -oriented sources. Another example would be a public service de-partment gleaning inform ation about how a park is being used a t a specific location and time. 
Experiences can be recorded around a frame like  X  X ho did what, when, where, and why  X  al-though opinions and emotions can be also linked. Therefore attributes such as location, time, and activity and their relations must be extracted by devising a method for selecting experience-containing sentences based on verbs that have a particular linguistics case frame or belong to a  X  X o X  class ( Kurashima et al., 2009 ). However, this kind of method may extract the following sentences as containing an experience : None of the sentences contain actual experiences because hypotheses, questions , and orders have not actually happened in the real world. For e x-perience mining, it is important to ensure a sen-tence mentions an event or passes a factuality test to contain experience ( Inui et al. , 2008) . tecting experiences from weblogs . We formulate the problem as a classification task using var ious linguistic features including tense, mood, a spect, modality , experience r, and verb classes. 
Based on our observation that experience -revealing sentences tend to have a certain li n-guistic style (Jijkoun et al., 2010) , we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences.
 tomatic construction of a lexicon for verbs r e-lated to a ctivities and events . While there have been well -known studies ab out classifying verbs based on aspe ctual features (Vendler, 1967), thematic roles and selectional restrictions (Fil l-more, 1968; So mers, 1987 ; Kipper et al. , 200 8) , valence alternations and intuitions (L evin , 1993) and conceptua l structures (Fil lmore and Bak er, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al. , 2008 ) are sufficient for identifying experience -revealing verbs. We introduce a method for const ructing an activ i-ty/event verb lexicon based on Vendler  X  X  theory and statistics obtained by utilizing a web search engine. ded in a collection of activities or events which an ind ividual or group has actually undergone 1 . It can be subjective as in opinions as well as obje c-tive , but our focus in this article lies in objective knowledge. The following sentences contain o b-jective exp eriences: Whereas sentences like the following contain subjective knowledge : Subject knowledge has b een studied extensively for various functions such as identification, po-larity detection, and holder extraction under the name s of opinion mining and sentiment analysis (Pang and Lee, 2008).

In summary, our contribution lies in three a s-pects: 1) conception of experience detection, which is a precursor for experience mining, and specific related tasks that can be tackled with a high performance machine learning based sol u-tion; 2) examination and identification of salient linguistic features for experience de tection; 3) a novel lexicon construction method with identif i-cation of key features to be used for verb classi-fication. 
The re mainder of the paper is organized as fo l-lows. Section 2 present s our lexicon construction method with experiments. Section 3 desc ribes the experience detection method , including expe-rimental setup, evaluation, and results. In Section 4, we discuss related work, before we close with conclusion and future work in Section 5. Since our definition of experience is b ased on activities and events, it is critical to determine whether a sentence contain s a predicate descri b-ing an activity or an event . To this end, it is quite conceivable that a lexicon containing activ ity / event verbs would play a key role. Given that our ultimate goal is to extract experiences from a large amount of weblogs, we opt for increased coverage by automatically constructing a lexicon rather than high precision obtainable by manua l-ly crafted lexicon . 
Based on the theory of Vendler (1967), we classify a given verb or a verb phrase into one of the t wo categories: activity and state . We consi d-er all the verbs and verb phrases in WordNet (Fellbaum, 1998) which is the largest electronic lexical database. In addition to the linguistic schemata features based on Vendler  X  X  theory, we used thematic role features and an external knowledge feature. 2.1 Background Vendler (1967) propose s that verb meanings can be categorized into four basic classes, states, a c-tivities, achievements , and accomplishments, de-pending on interaction s between the verbs and their aspectual and temporal modifiers. Table 1 shows some examples for the classes. 
Vendler (1967) and Dowty (1979) introduce linguistic schemata that serve as evidence for the classes . Table 2. Query matrix. The  X   X  X  indicates that the query is applied. No Schem a indicates that no sch ema is applied when the w ord itself is a query. bs, prs, prp, pts, ptp correspond to base form, present simple (3 rd person singular), present pa r-ticiple, past simple and past participle, respec t-fully. Below are the six schemata we chose because they can be tested automatically : progressive , force , persuade , stop , for, and carefully ( An aste-risk denote s that the statement is aw kward).  X  States cannot occur in progressive tense:  X  States cannot occur as complements of  X  Achievement s cannot occur as compl e- X  Achievements cannot occur with time a d- X  State and achievement cannot occur with The schemata are not perfect because verbs can shift classes due to various contextual factors such as arguments and senses. However, a verb certainly has it s fundamental class that is its most natural ca tegory at least in its dominant use. 
The four classes can further be grouped into two gen uses : a genus of processes going on in time and the other that refers to non-processes. Activity and accomplishment belong to the for-mer whereas state and achievement belong to the latter. As can be seen in table 1, states are rather immanent operations an d achievements are those occur in a single moment or operations related to perception level . On the other hand , activity and accomplishment are processes ( transeunt oper a-tions ) in traditional philosophy. W e henceforth call the first genus activity and the latter state. Our aim is to classify verbs into the two genuses. 2.2 Feature s based on Linguistic Schemata We developed a relatively simple computational testing method for the schemata. Assuming that an awkward expression like,  X  John is liking something  X  won  X  X  occur frequently , for example, we genera ted a co-occurrence based test for the first linguistic schem a using the Web as a corpus. By issuing a search query, ((be OR am OR is OR was OR were OR been) and ? ing) where  X ? X  represents the verb at hand, to a s earch engine, we can get an estimate about how the verb is likely to belong to state . A test can be generated for each of the schemata in a similar way.
 forms (i.e. , 3 rd person singular present, present part icip le, simple past, past participle) available. However, some of the patterns cannot be applied to some forms . For example, other forms except the base form cannot come as a complement of force (e.g. , force to runs.*) . Therefore, we created a query matrix whi ch represents all query pat terns we have applied , in t able 2. 
Based on the query matrix in table 2, we i s-sued queries for all the verbs and verb phrases from WordNet to a search engine . We used the Google news archive search for two reasons. First, since news articles are written rather fo r-mally compared to weblogs and other web pages, the statistics o btained for a test would be more reliable. Second, Google provides an advanced option to retrieve sni ppets containing the query word. Normally, a snippet is composed of 3~5 sentences. 
The basic statistics we consider are hit count , candidate sentence count and correct sentence count which we use the notation s H ij ( w ), S ij and C ij ( w ), respectfully , where w is a word, i the linguistic schema and j the verb f orm from the query matrix in t able 2. H ij ( w ) was directly g a-thered from the Google search engine. S ij ( w ) is the number of sentence s containing the word w in the search result snippets. C ij ( w ) is the number of correct sentences matching the query pattern am ong the candidate sentences. For example, the progressive schema for a verb  X  X uild  X  can r e-trieve the following sentences .  X  X uilding  X  in the first example is a progressive verb , but the one in second is a noun, which does not satisfy the linguistic schema . For a POS and grammatical check of a candidate sentence, w e used the Stanford POS tagger (Toutanova et al., 2003) and Stanford dependency parser (Klein and Manning, 2003) . 
For each linguistic schema , we derived three features: Absolute hit ratio , Relative hit ratio and Valid ratio for which we use the notation s A i ( w ) , R ( w ) and V i ( w ), respectfully, where w is a word and i a linguistic schema. The index j for summ a-tions represents the j -th verb form . They are computed as follows. Absolute hit ratio is computes the extent to which the target word w occurs with the i -th schema over all occurrences of the schema. The denomi nator is the hit count of wild card  X * X  matching any single word with the schema pa t-tern from Google (e.g., H 1 (*), the progressive test hit count is 3.82  X  10 8 ). Relative hit ratio computes the extent to which the target word w occurs with the i -th schema over all occurrences of the word. The denominator is the sum of all verb forms. Valid ratio means the fraction of co r-rect sentence s among candidate sentences. The weight of a linguistic schema increases as the valid ratio gets high. With the three different can generate a total of 18 features. 2.3 Features based on case f rames Since the hit count via Google API sometimes returns un reliable results (e.g., when the query becomes too long in case of long verb phrases) , we also consider additional features. While our initial observ ation indicated that the existing le x-ical resources would not be sufficient for our goal, it occurred to us that the linguistic theory behind them would be worth exploring as gen e-rating additional features for categorizing verbs for the two classes. Consider the following e x-amples: The subject of a state verb is dative (D) as in [12] whereas the subject for an action verb takes the agent (A) role. In addition, a verb with the in-strument (I) role tends to be an action verb. F rom these observations , we can use the distribution of cases ( thematic role s) for a verb in a corpus . Ac-tivity verbs are expected to have high frequency of agent and i nstrument role s than state verbs. Although a verb may have more than one case frame, it is possible to determine which thematic roles used more dominantl y. 
We utilize two major resources of lexical se-mantics, Verb net (Kipper et al., 2008 ) based on the theory of Levin (1993) , and Frame net (Baker et al., 2003) , which is based on Fillmore (1968). Levin (1993) demonstrated that syntactic alterna-tions can be th e basis for groupings of verbs se-mantically and accord reasonably well with li n-guistic intuitions. Verb net provides 274 verb classes with 23 the matic roles covering 3 ,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles , cov ering 11,583 words i ncluding verbs, nouns, adverbs, etc. 
Using Verbnet alone does not suit our needs because it has a relatively small number of e x-ample sentences. Framenet contains a much lar g-er number of examples but the vast number of semantic roles presents a problem. In order to get meaningful distribu tions for a manageable nu m-ber of thematic roles, w e used Semlink (Loper et al., 2007) that provides a mapping between Fr a-me net and Verb net and uses a total of 23 thema t-ic roles of Verb net for the annotated corpora of the two resources. By the mapping, we obtained distributions of the thematic roles for 2,868 unique verbs that exist in both of the r esources. For example, the verb  X  X onstruct  X  has high fre-quencies with agent , material and product roles. 2.4 Features based on how -to instructions Ryu et al. (2010) presented a method for extract-ing ac tion steps for how -to goals from eHow 2 a we bsite containing a large number of how -to in-struc tions . The authors attempted to extract a c-tions comprising a verb and some ingredients like an object entity from the documents based on syntactic pa ttern s and a CRF based model. 
Since each extracted action has its probability , we can use the value as a feature for state / acti v-ity verb classification. However, a verb may ap-pear in different contexts and can have multiple proba bility va lues . To ge nerate a single value for a verb, we combine mul tiple probabil ity va lues using the following si gmoid function: Evidence of a word w being an action in eHow is denoted as E ( w ) where variable t is the sum of indi vidual action probabili ty values in D w the set of documents from which the word w has been extracted as an action. The higher probability a word gets and the more frequent the word has been extracted as an action , the more evidence we get. 2.5 Classification For training, w e select ed 80 seed verbs from Dowty X  s list (1979) which are r epresentative verbs for each Vendler (1967) class. The selec-tion was based on the lack of w ord sense amb i-guity. One of our classifiers is based on Maximum Entropy (ME) models that implement the intu i-tio n that the best model will be the one that is consistent with the set of constraint s imposed by the evidence, but otherwise is as uniform as pos sible (Berger et al., 1996). ME models are widely used in natural language processing tasks for its flexibility to incorporate a divers e range of features. The other one is based on Support Ve c-tor Machine (Chang and Lin, 2001) which is the state -of-the -art algorithm for many classification tasks. We used RBF kernel with the default se t-tings (Hsu et al. , 2009) becau se it is been known to show moderate performance using multiple feature compositions . 
The features we consider ed are a total of 4 2 real values: 18 from linguistic schemata, 23 the-matic role distributions, and one from eHow. In order to examine which featur es are discrimin a-tive for the classifica tion , w e used two well known feature selection methods, Chi -square and information gain. 2.6 Results Table 3 shows the classification performance values for different feature selection methods . The eva luation was done on the training data with 10-fold cross validation. 
Note that the precision and recall are macro -averaged values across the two classes, activity and state. The most discriminative features were absolute ratio and relative ratio in conjunction with the for ce, stop, progressive, and persuade schem ata, the role distribution of experiencer , and the eHow evidence. 
It is noteworthy that eHow evidence and t he distribution of experiencer got in to the top 10. Other thematic roles did not perform well b e-cause of the data sparseness. Only a few roles (e.g. , expe rience , agent, topic, location) among the 23 had frequency values other than 0 for many verbs . Data sp ars eness affected the lingui s-tic schemata as well. Many of the verbs had zero hit counts for the for and carefully schem ata. It is also interesting that the validity ratio V i ( w ) was not shown to be a good fe ature -generating stati s-tic . 
We finally trained ou r model with the top 10 features and classified all WordN et verbs and verb phrases. For a ctual construction of the le x-icon, 11,416 verbs and verb phrases were class i-fied into the two classes roughly equally. We randomly sam pled 200 items and examined how accurately the cla ssification was done. A total of 164 items were correctly classified , resulting in 82% accuracy. Some examples from the classif i-cation are shown in table 4.

A further analysis of the results show that most of the errors occurred with domai n-specific verbs (e.g. , ablactate , alkalify , and transaminate in chemistry) and multi-word verb phrases (e.g., turn a nice dime; keep one  X  X  shoulder to the wheel ). Since many features are computed based on Web resources, rare verbs cannot be classified cor rectly when their hit rations are very low. The domain -specific words rarely appear in Framenet or e -how, either. As mentioned earlier, experience-revealing sen-tences tend to have a certain linguistic style. Having converted the proble m of experience de-tection for sentences to a classification task, we focus on the extent to which various linguistic features contribute to the performance of the b i-nary classifier for sentences. We also explain the experimental setting for evaluation, inc luding the classifier and the test corpus. 3.1 Linguistic f eatures In addition to the verb class feature available in the verb lexicon constructed automatically, we used tense, mood, aspect, modality, and expe-rience r features. 
Verb class: The feature comes di rectly from the lexicon since a verb has been classified into a state or activity verb. The predicate part of the sentence to be classified for experience is looked up in the lexicon without sense disambiguation. 
Tense: The tense of a sentence is importan t since an experience -revealing sentence tends to use past and present tense. F uture tenses are not experiences in most cases. We use POS tagging (Toutanova et al., 2003) for tense determination, but since the Penn tagset provides no future tenses, they ar e dete rmined by exploiting modal verbs such as  X  X ill  X  and future expressions such  X  X oing to  X . 
Mood: It is one of distinctive forms that are used to signal the modal status of a sentence. W e consider three mood categories: indicative, i m-perative and subjunctive. We determine the mood of a se ntence by a small set of heuristic rules using the order of POS occurrences and punctuation marks.

Aspect: It defines the temporal flow of a verb in the activity or state. Two categories are used: progressive and perfect ive . This feature is dete r-mined by the POS of the predicate in a sentence.
Modality: In linguistics, modals are expre s-sions broadly associated with notions of possibi l-ity . While modality can be classified at a fine level (e.g. , epistemic and deontic), we s imply determine whether or not a sentence includes a modal marker that is involved in the main predi-cate of the sen tence. In other words, this binary feature is determined based on the existence of a model verb like  X  can  X ,  X  X hall  X ,  X  X ust  X , and  X  may  X  or a p hrase like  X  have to  X  or  X  X eed to  X . The d e-pendency parser is used to ensure a modal mar k-er is indeed associated with the main predicate. 
Experiencer: A sentence can or cannot be treated as containing an experience depending on the subject or experiencer of the verb (note that this is different from the experience r role in a case frame) . Co nsi der the following sentences : The first sentence is considered an experience since the subject is a person. However, the second sen tence with the same verb is not, be-cause the subject is a non -animate abstract co n-cept. That is, a non-animate noun can hardly constitute an experience . In order to make a di s-tinction, we use the depe ndency parser and a named -entity recognizer (Finkel et al., 2005) that can recognize person pronouns and person names. 3.2 Classification To train our classifier, we first crawled weblogs from Wordpress 3 , one of the most popular blog sites in use today. Worpress provides an interface to search blog posts with queries. In selecting experience-containing blog pots, we used loc a-tion names such as Central Park, SOHO, Seoul and general place names such as airport, subway station, and restaurant because blog posts with some places are ex pected to describe experiences rather than facts or t houghts. 
We crawled 6,000 blog posts. After deleting non-English and multi -media blog posts for which we could not obtain any meaning ful text data , the number became 5,326. We randomly sampled 1,000 sentences 4 and asked three ann o-tators to judge whether or not individual se n-tences are considered contain ing an experience based o n our definition. For maximum accuracy, we decided to use only those sentences all the three annotators agreed, resulting in a total of 568 sentences. 
While we tested several classif iers, we chose to use two different classifiers based on SVM and L ogistic Regression for the final experimen-tal results because they showed the best perfo r-mance. 3.3 Results For comparison purposes, w e take the method of Kurashima et al. (2005) as our baseline because the method was used in subsequent studies (K u-rashima et al., 2006; Kurashima et al., 2009) where exp erience attributes are extracted . We briefly describe the method and present how we implemented it . 
The method first extracts all verbs and th eir dependent phrasal unit fro m candidate sentences . The candi date goes through three filters before it is treated as experience -containing sentence . First, the candidates that do not have an objective case (Fillmore, 1968) are eliminated because their defin ition of experience as  X  X ction + object X . This was done by identif ying the ob ject -indicating particle (case marker) in Japanese. Next, the candidates belonging to  X  X ecome X  and  X  X e X  statements based on Japanese verb types are filtered out. Finally, the candidate sentences i n-cluding a verb that indicates a movement are eliminated because the main inter est was to iden-tify an activity in a place. 
Although their definition of experience is somewhat different from ours (i.e .,  X  X ction + ob-ject X  ), they used the method to generate cand i-date sentences from which various experience attributes are extracted. From this perspective, the method functioned like our experience dete c-tion. Put differently, the definition and the m e-thod by which it is determined were much cruder than the one we are using, which seems close to our general understanding. 5
The three filtering steps were implemented as follows. We used the dependency par ser for e x-trac ting objective cases using the direct object relation . The second step, howeve r, could not be applied because there is no grammatical distin c-tion among  X  X o, be, become X  statements in Eng-lish. We had to alter this step by adopting the approach of Inui et al. (2008). The authors pr o-pose a lexicon of exp erience expression by co l-lecting hyponyms from a hierarchical ly stru c-tured dictionary. We collected all hyponyms of words  X  X o X  and  X  X ct X , from WordN et (Fellbaum, 1998). Lastly, we remove d all the verbs that are under the hierarchy of  X  X ove X  from WordNet . 
We not only compared our results with the baseline in terms of precision and recall but also Table 6. Experience Detection Performance without Individual Feat ures evaluated individual features for their impo rtance in experience detec tion (classification). T he evalu ation was co nducted with 10-fold cross v a-lidation. The results are shown in t able 5 . 
The performance, especially precision, of the baseline is much low er than those of the others . The method devised for Japanese doesn X  t seem suitable for English . It seems that the linguistic style s shown in experience expressions are dif-ferent from ea ch other . In addition, the lexicon we constructed for the baseline (i.e., using the WordNet) contains more errors than our activity lexicon for activity verbs. Some hyponyms of an activity verb may not be activity verbs. (e.g.,  X  X ppear  X  is a hy ponym of  X  do X  ). 
There is almost no difference between the L o-gistic Regression and SVM classifiers for our methods although SVM was inferior for the bas eline. The performance for the best case with all the features included is very promising , closed to 92% precision and recall. Among the features, the lexicon, i.e. , verb classes, gave the best result when each is used alone, followed by modality , tense , and mood . Aspect was the worst but close to the baseline. This result is very en-couraging for the automatic lexicon construction work because the lexicon plays a pivotal role in the overall performance.

In order to see the effect of including indivi d-ual features in the feature set, p recision and re-call were measured after eliminating a particular fea ture from the full set . The results are shown in table 6. Although the absence of the lexicon fe a-ture hurt the pe rformance most badly, still the performance was rea sonably high (roughly 84 % in precision and r ecall for the L ogisti c Regre s-sion case). Si milar to table 5, the aspect and ex-pe rience features were the least contributors as the performance drops are almost negligible. Experience mining in its entirety is a relatively new area where various natural language processing and text mining techniques can play a significant role. While opinion mining or sent i-ment analysis, which can be considered an i m-portant part of experience mining, has been st u-died quite extensively (see Pang and Lee X  s exce l-lent survey ( 2008) ), another sub-area, factuality analysis, begins to gain some popularity ( Inui et al., 2008 ; Saur  X , 2008 ). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP re sea rch areas such as named entity reco gnition and verb classific ation are strongly related. The previous work on expe-rience detection relies on a handcrafted lexicon.
There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers , 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al. , 2008 ) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000) , who attempted to categorize verbs i nto state or event classes based on 14 tests similar to those of Vendler  X  X . They attempted to compute co-occurrence st atistics from a corpus. The event class, however, includes activity , ac-complishment , and achievement . Similarly, Z a-crone and Lenci (2008 ) attempted to categorize verbs in Italian into the four Vendler classes u s-ing the Vendler tests by using a tagged corpus. They focused on existence of arguments such as subject and object that should co-occur with the linguistic features in the tests.

The m ain difference between the previous work and ours lies in the goal and scope of the work. Since our work is specifically geared t o-ward domain-independent experience detection, we attempted to maximize the coverage by using all the verbs in WordNet, as opposed to the verbs appearing in a particular domain -specific corpus (e.g. , medicine domain) as done in the previous work. Another di fference is that while we are not limited to a particular domain, we did not use extensive human -annotated corpus other than using the 80 seed verbs and existing lexical r e-sources. We defined experience detection as an essential task for experience mining, which is restated as de termining whether individual sentences con-tain experience or not. Viewing the task as a classification problem, we focused on identific a-tion and examination of various linguistic fe a-tures such as verb class, tense, aspect, mood, modality, and experience, all of which were computed automatically. For verb classes, in pa r-ticular, we devised a method for classifying all the verbs and verb phrases in WordNet into the activity and state classes. The experimental r e-sults show that verb and verb phrase classifica-tion method is reasonably accurate with 91% precision and 78% recall with m anually co n-stru cted gold standard consisting of 80 verbs and 82% accuracy for a random sample of all the WordNet entries. For experience detection, the performance was very promising, closed to 92% in precision and recall when all the features were used. A mong the features, the verb classes, or the lexicon we constructed, contr ibuted the most. and reduce the errors in lexicon construction, i.e., verb classification, caused by data sparseness, we need to devise a different method, perhaps using domain specific resources. new research area, there are many areas to ex-plore. In addition to refinements of our work, our next step is to develop a method for representing and extrac ting actual experiences from exp e-rience-revealing sentences. Furthermore, c ons i-dering that only 13% of the blog data we processed contain experiences, an interesting extension is to apply the methodol ogy to extract other types of knowledge such as f acts, which are not necessarily experiences. This research was supported by the IT R&amp;D pr o-gram of MKE/KEIT under grant KI001877 [L o-catio nal/Societal Relation -Aware Social Media Service Technology], and by the MKE (The Mi nistry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program supervised by the NIPA (National IT Industry Promotion Agency) [N I-PA -2010 -C1090 -1011-0008].

Approach to Natural Language Processing. Co m-putational Linguistics . 
