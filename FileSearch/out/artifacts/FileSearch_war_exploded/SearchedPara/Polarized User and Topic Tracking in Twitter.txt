 Digital traces of conversations in micro-blogging platforms and OSNs provide information about user opinion with a high degree of resolution. These information sources can be exploited to under-stand and monitor collective behaviors. In this work, we focus on polarization classes , i.e., those topics that require the user to side exclusively with one position. The proposed method provides an iterative classification of users and keywords: first, polarized users are identified, then polarized keywords are discovered by monitor-ing the activities of previously classified users. This method thus allows tracking users and topics over time. We report several ex-periments conducted on two Twitter datasets during political elec-tion time-frames. We measure the user classification accuracy on a golden set of users, and analyze the relevance of the extracted keywords for the ongoing political discussion.
Recently, the analysis of blogging platforms and streaming infor-mation sources (e.g., Twitter) has received great attention in the In-formation Retrieval and in the Data Mining communities. We focus on the frequent scenario where users interact and produce contents according to a set of polarization classes . By polarization classes we mean subjects that require the user to side exclusively with one part. Political parties are typical examples of these classes. Other examples include brand analysis, products comparison, and opin-ion mining in general. In these scenarios the polarization classes are known, and some limited information may also be available, e.g., a set of relevant keywords. This limited knowledge allows us to restrict the scope of the analysis, but several challenging tasks are left open. The first is how to identify the users being polar-ized (or not) according to those classes. The second task concerns the identification of the most relevant sub-topics being discussed among such users. The third is how to monitor the evolution of such user communities and their on-line discussions over time. Those tasks are all very challenging as the available knowledge may be approximate or insufficient, and it may also become obsolete over time. Therefore, the classification into polarization classes should be able to self-update continuously by catching upcoming relevant users and discussion topics. The present work is related to the Topic Detection and Tracking (TDT) subject [2], which has been widely explored within the scope of news stream analysis [11]. We focus on content and user tracking for polarized users. This no-tion is connected with the concept of controversy in Social Media, which have been studied, mostly in political contexts, using data coming from different sources [1, 4, 6, 8]. Another related research area is trending topics analysis. Various trend detection models are proposed in [7, 9]. Our approach is different in several regards from current literature, since we rather focus on the identification of polarized communities. In our experiments we use electoral data from Twitter. In this case, the polarization classes are political par-ties and candidates. Several works analyzed the opportunities and limitations in using Twitter as a predictor of an election X  X  outcome [3, 5, 10]. Our goal is completely different, as we do not draw any conclusion about the expected share of votes for the given parties or candidates. We use this specific kind of data, as it is a typical example of polarized users. We show that the proposed algorithm is able to identify polarized users, by also analyzing the ongoing discussions among the respective communities.

The main contribution of this work is a new iterative algorithm, named PTR (Polarization TRacker), for the discovery of polarized users in a Twitter stream, and a temporal version TPTR (Temporal PTR), able to track users and topics over time. While there exist several works about community detection and trending topic track-ing, we propose a novel setting where the number of communities is known, but very little information is provided (a keyword per class only), and those communities are competing with each other. We conduct an objective evaluation of the proposed algorithms by measuring their classification accuracy on a golden set of users.
Let T = { t 1 ,t 2 ,... } be the stream of tweets generated by the set of users U = { u 1 ,u 2 ,... } . We focus on the analysis of user behavior with respect to a set of polarization classes C . The goal of this work is thus to build a partitional clustering of the Twit-ter users, where each of the clusters is associated by construction with a single polarization class (or unassigned). Our method can be seen as a semi-supervised clustering one, although, unlike classic methods, we do not provide any class representative around which the final clustering is induced. Indeed, the proposed method is only loosely supervised as the only knowledge available is the number of classes, and a short class description (a keyword).

An important issue is the evaluation of our algorithm. To this end, we exploit a golden set of polarized users, each unequivocally associated with a class c  X  C . Note that such knowledge is not exploited to train a classifier, but only for evaluation purpose. Algorithm 1 User Classification Algorithm 1:
The Polarization TRacker (PTR) algorithm requires some ini-tial seed topics that identify the classes of interests. We propose to identify them with a single textual keyword for each class c  X  C . Although each keyword identifies a topic, e.g., a political party, it is not sufficient to correctly classify users, as all these seed topics are likely to be mentioned in many users X  tweets, e.g., to contrast the achievements of a given party with the deficiencies of the oth-ers. Without loss of generality, we limit our keyword selection to Twitter hashtags . Therefore, the single textual keyword we ini-tially choose for each class c is a single hashtag appearing in the user tweets, and around them we start identifying the user clusters. The final goal is to extract the best discriminating hashtags that are able to identify the actual clusters of polarized users, who belong with high probability to one of the classes c  X  X  .

We denote the representative hashtags, one for each c  X  X  , called seed hashtags , by H  X  =0 c , where  X  is the algorithm X  X  iteration num-ber. Note that each initial set H  X  =0 c , one for each c , is not nec-essarily composed of a discriminating hashtag. This set H then used to classify polarized users on the basis of their use of the seed hashtags. We denote by U  X  +1 c the clusters of users in U that are identified as belonging to class c , according to their tweets and to the given hashtags H  X  c . Similarly, the new hashtags H are generated by finding those that best discriminate the users in U c . This refinement process is iterated for all c  X  C : from hashtags { H  X  c } c  X  X  to users { U  X  +1 c } c  X  X  , and finally to hashtags { H  X  +1 c } c  X  X  . The algorithm terminates when H  X  c converges. Specifically, PTR iterates the two classification steps U and H ASHTAGS C LASS . Algorithm 1 illustrates the former step of the iterative process 1 . The goal of this step is to identify polarized users on the basis of the given hashtags. First, we identify polar-ized tweets, which mention hashtags in H c . We consider the clas-sification of each single tweet t by considering all the mentioned hashtags H t , as we believe each tweet is a very relevant expression of a user X  X  thought on a specific topic. Since we are interested in polarized users, with the goal of achieving high precision we dis-card all the tweets which contain hashtags belonging to more than one set { H c } c  X  X  . For each user u  X  U and for each class c  X  C we denote the set of polarized tweets by T u,c . We thus measure the user polarization: if for some classes c , the number of tweets in T u,c is significantly larger than for any other class (parameter  X  ), then the user is labeled with the class c and added to the set of polarized users U c (see line 7). Note that the user classification is intended to be an update of the classification conducted during the previous step. The goal the second step is to process all the hash-tags adopted by classified users U c in order to discover a new set of Algorithm 2 Hashtag Classification Algorithm 1: discriminating hashtags H c , as illustrated in Alg. 2. In order to de-tect { H c } c  X  X  , we take into considerations all the hashtags H by any user u  X  U c , and not only those occurring in the polarized tweets T u,c (line 4). This allows to extend our analysis to the full set of topics discussed by the users, even if they were not captured in the early iterations of the algorithm. First, for each c  X  C we retrieve the set of hashtags used by the users in U c , considering all their tweets, denoted by T c , independent of the classification of the single tweets in the previous iteration. In our experiments we con-sider the top frequent 500 hashtags in T c . Given the resulting set of candidate hashtags for each c  X  X  , namely H  X  c , we extract from them the new hashtags that highly discriminate each class c , and these are eventually added to the new set H c (line 7). Specifically, the discriminating hashtags are those highly used by the current set of users U c , and partially used by any other user in U c define a function S c ( h ) to measure the goodness of hashtag h for each community of polarized users U c . Let T h be the set of tweets in T mentioning hashtag h , independent of the users who posted these tweets. Moreover, let T H  X  c be the set of tweets in T contain-ing at least one hashtag in the set H  X  c . We score the goodness of a hashtag for a polarization class as follows: where we consider the naive hypothesis of independent occurrence of the hashtags in the various sets. In practice, S c ( h ) is the prob-ability of seeing h only in H  X  c , whereas h is not present in all the other sets of hashtags H  X  c 0 6 = c . Given a hashtag h , the score S used to rank the various classes, thus assigning h to class with the highest score. Since we aim at promoting high discriminating hash-tags, not only we assign the hashtag h having the highest S the new set H c , but only if S c ( h ) &gt;  X   X  S c 0 ( h ) ,  X  c  X   X  1 . Note that if a tie exists between the to 2-top scores classes, the hashtag h is not assigned to any H c , since it is considered not discriminating enough.
We use two Twitter datasets related to political elections that re-cently took place in Italy. Dataset IT13 : data about primary elec-tion for largest social democratic political party in Italy (PD), which took place in December 2013 with 3 candidates: Mr. Renzi, Mr. Cuperlo, and Mr. Civati. Dataset EU14 : data about European Par-liament election held in Italy in May 2014 2 . The data are collected through Twitter API by querying a list of keywords related to the topic and the candidates, large enough to guarantee a good coverage of the elections. Both final datasets cover 9 days before the elec-tion day. We discard partial data and potentially irrelevant tweets, considering only tweets being geo-located and in Italian language. Table 1b reports some information about the two datasets.
We build an evaluation dataset by identifying those users whose opinion can be inferred with high confidence. During elections, as for other events, very specific hashtags are used over Twitter to express a strong intention of vote or an explicit membership in a group. We assume that users that frequently use one of such hashtags are strongly sided with one of the competing parties and they will not change idea in the short term. Such hashtags, named golden hashtags , are handpicked among the 500 most frequent in the data. The used golden hashtags are of the kind #IVoteParty . We identify one/two golden hashtags per class c  X  C both in the EU14 (e.g. #IVoteTsipras for AET) and in the IT13 (e.g. #prefeRenzi for Renzi) dataset. The set of reference users were identified by applying Algorithm 1 with the above golden hashtags as input. This guarantees that a user is safely considered as polar-ized to a party c  X  C if her tweets contain only one of the golden hashtags associated with the various classes c  X  X  . We denote with Z = { z 1 ,z 2 ,... } this set of polarized users, and with Z those supporting a specific formation c ( Z c is a partitioning of Z ). The composition of resulting golden dataset is reported in Table 1a. The golden dataset is thus a small fraction of the full dataset. A global analysis of the Twitter stream cannot be based on a few very polarized hashtags. Note that the relative popularity of the parties is not simply proportional to the number of votes received, but it depends on the efficacy of the hashtag promoted. We remark that, for the sake of fairness, we remove the golden hashtags from the datasets before the application of any algorithm. The set of users Z in the golden dataset, is used to evaluate the users classification accuracy of the proposed method. Given the users classification U provided by some given algorithm, precision, recall and F-Measure are restricted to the set Z . Formally, for any given class c  X  C , precision and recall are defined as: The F-measure F c is the harmonic means of P c and R c . The macro F -measure average over the classes c  X  C is denoted with F . In addition, as the proposed algorithm may not be able to classify all of the users in Z , we report also the user coverage  X  and  X  on both the golden set and the overall dataset respectively:
As a baseline we use the k -means clustering algorithm. Each user u is represented by a vector of 500 features, corresponding to the 500 most frequent hashtags in the dataset. The user feature vector stores the frequency of a hashtag in the stream of tweets T published by the user. We discard users who do not use any hashtag in their tweets. We normalize the feature vectors for each user to unit L 2 norm. We impose the number of the clusters k equal to the number of classes |C| and, to simulate the same starting condition of our method, we built the initial centroids so as to encode the seed hashtags. The centroid for a class c is thus a vector with a single 1 in the position of the seed hashtag, and 0 otherwise. The result of the k -means baseline is thus a clustering of users based on the seed hashtags provided. Table 2a reports the results of the k -means baseline. F-measure values are low for the IT13 dataset. For in-stance, k -means provides low accuracy and recall for the first class. This is mainly due to the fact that the hashtags corresponding to popular parties or candidates are very often used by different users, regardless of their orientation. In other cases (e.g., LN and AET), the hashtags are used mostly within the respective communities.
In the following, we analyze in detail the iteration-by-iteration behavior of the proposed PTR algorithm. We test our algorithm by setting  X  = 2 and  X  = 1 , after a tuning step. During the first iteration, PTR is fed with the seed hashtags. Algorithm 1 uses those hashtags to find a subset of polarized users in U . This step is similar to other works, where mentions of a party or candidate are used to estimate their popularity or to classify users [3, 10]. Unlike other approaches, PTR aims at discovering a subset of polarized users, thus requiring,that a user mentions a party at least twice any other. The results of such user classification are evaluated over the golden dataset , as reported in the first line of Table 3a. Regard-ing average precision, PTR is already significantly superior to the k -means baseline for IT13 dataset. This is already surprising, as the seed hashtags are very generic. On the other hand, the k -means baseline might be negatively affected by the sparsity of the data. The results are different on the two datasets in terms of average re-call. PTR has similar performance to k -means on the IT13 dataset, while the recall is significantly lower on the EU14 dataset. This is confirmed by the coverage values  X  and  X  . In comparison with the baseline, the performance of PTR in terms of macro F -measure is satisfactory on the IT13 dataset, but not on the EU14 dataset yet. The output of the first iteration is a new set of hashtags which is exploited in the next iteration. By looking at the best scoring hashtag, we can already observe an interesting behavior of the al-gorithm for some c  X  C . In dataset EU14, the best tags for FI and LN are the leaders of the respective parties, detecting that the orig-inal seed hashtags are not discriminating in this case. In Table 2b we report in detail the results after the second iteration of PTR. The first interesting result is that the average recall is significantly higher on both datasets. This is due to the new hashtags discovered in addition to the seed ones during the previous iteration, which, in turn, lead to the identification of a larger set of users: the cov-erage  X  is now beyond 80% on the golden set, and  X  has doubled in this iteration. Also the average precision is higher w.r.t. the pre-vious iteration scoring more than 0.7. This is both because of the increased number of classified users, and of the updated user clas-sification. As a result, the F -measure has an overall improvement w.r.t. the k -means baseline of +71% and +7% on datasets IT13 and EU14 respectively. As shown in Table 3a PTR becomes stable very early. The largest improvement is achieved with the second iterations. This means that the most relevant hashtags are discov-ered early, and only slight changes occur afterwards. The subse-quent iterations marginally increase the number of classified users. Note that the algorithm is classifying the polarized users found in the whole set U . PTR found about 6.7 and 27 thousands polar-ized users on the dataset IT13 and EU14 respectively. We conclude that in most cases, two iterations of the algorithm provide sufficient classification quality. For the lack of space we can not report a ex-haustive qualitative analysis of the outcome, but we observe that the procedure is able to extract relevant keywords: namely promi-nent politicians, the party itself and political mottoes characterizing each c in the political scene.
 We finally propose a variant of PTR, that is TPTR (temporal PTR), to perform the tracking of topics and users in time. In our case we consider the evolution day by day. The procedure follows Algorithm 1 and Algorithm 2 with the difference that at iteration  X  only the tweets T u written in the  X  -th day are considered. We perform TPTR on IT13 and on EU14 datasets. In Table 3b the evaluation of the temporal iterative procedure is shown. The macro F -measure is increasing day by day both for the effect of a better classification and for the presence of new users. Note that we eval-uate the time iterative method day by day on the entire golden set of users. F-measure values are low because not all users in the golden set were active every day.
We propose a novel algorithm for the simultaneous tracking of polarized users and discriminating topics in OSNs. Specifically, it iteratively detects polarized users, and from their contents the dis-cussed discriminating topics. We also introduce a temporal variant, where the information extracted during one day of analysis is ex-ploited for the next day. Indeed, the classification of users makes the algorithm more robust in terms of concept drifts, as new trends may be detected as early as they pop up. At the same time, the iden-tification of discriminating topics helps in detecting users moving from one class to another. The algorithm is tested on two Twit-ter data samples. We evaluate the quality of user classification on a golden set of users, showing significant improvements over the baseline. The proposed methodology is general and it can be ap-plied to different scenarios. We believe that this methodology based on polarization may also impact on broad area of social network analysis, e.g., by complementing the proposed classification with community detection and information diffusion over time. As a fu-ture work, we aim to improve the temporal analysis dealing with streaming data.
 Supported by EC H2020 Program INFRAIA-1-2014-2015 (654024). [1] L. A. Adamic and N. Glance. The political blogosphere and [2] J. Allan. Topic detection and tracking: event-based [3] M. Coletto, C. Lucchese, S. Orlando, and R. Perego.
 [4] K. Garimella, G. De Francisci Morales, A. Gionis, and [5] D. Gayo-Avello, P. T. Metaxas, and E. Mustafaraj. Limits of [6] C. V. Gysel, B. Goethals, and M. de Rijke. Determining the [7] J. Lin, R. Snow, and W. Morgan. Smoothing techniques for [8] A. Makazhanov, D. Rafiei, and M. Waqar. Predicting [9] M. Mathioudakis and N. Koudas. Twittermonitor: trend [10] A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe. [11] F. Walls, H. Jin, S. Sista, and R. Schwartz. Topic detection in
