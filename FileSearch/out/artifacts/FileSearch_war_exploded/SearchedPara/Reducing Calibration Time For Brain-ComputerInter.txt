 BCI systems typically require training on the subject side a nd on the decoding side (e.g. [1, 2, 3, 4, 5, 6, 7]). While some approaches rely on operant condition ing with extensive subject training (e.g. [2, 1]), others, such as the Berlin Brain-Computer Int erface (BBCI) put more emphasis on the machine side (e.g. [4, 8, 9]). But when following our philoso phy of  X  X etting the machines learn X , a calibration session of approximately 20-30 min was so far re quired, even for subjects that are beyond the status of BCI novices.
 The present contribution studies to what extent we can omit this brief calibration period. In other words, is it possible to successfully transfer information from prior BCI sessions of the same sub-ject that may have taken place days or even weeks ago? While th is question is of high practical importance to the BCI field, it has so far only been addressed i n [10] in the context of transfering channel selection results from subject to subject. In contr ast to this prior approach, we will focus on the more general question of transfering whole classifier s, resp. individualized representations between sessions. Note that EEG (electroencephalogram) pa tterns typically vary strongly from one session to another, due to different psychological pre-con ditions of the subject. A subject might for example show different states of fatigue and attention, or use diverse strategies for movement imagination across sessions. A successful session to sessi on transfer should thus capture generic  X  X nvariant X  discriminative features of the BCI task.
 For this we first transform the EEG feature set from each prior session into a  X  X tandard X  format (sec-tion 2) and normalize it. This allows to define a consistent me asure that can quantify the distance between representations. We use CSP-based classifiers (see section 3.1 and e.g. [11]) for the dis-crimination of brain states; note that the line of thought pr esented here can also be pursued for other feature sets resp. for classifiers. Once a distance function (section 3.2) is established in CSP filter space, we can cluster existing CSP filters in order to obtain t he most salient prototypical CSP-type filters for a subject across sessions (section 3.3). To this e nd, we use the IBICA algorithm [12, 13] for computing prototypes by a robust ICA decomposition (sec tion 3.3). We will show that these new CSP prototypes are physiologically meaningful and further more are highly robust representations which are less easily distorted by noise artifacts. Our BCI system uses Event-Related (De-)Synchronization (E RD/ERS) phenomena [3] in EEG sig-nals related to hand and foot imagery as classes for control. The term refers to a de X  or increasing band power in specific frequency bands of the EEG signal durin g the imagination of movements. These phenomena are well-studied and consistently reprodu cible features in EEG recordings, and are used as the basis of many BCI systems (e.g. [11, 14]). For t he present study we investigate data from experiments with 6 healthy subjects: aw (13 sessions), al (8 sessions), cm (4 sessions), ie (4 sessions), ay (5 sessions) and ch (4 sessions). These are all the subjects that participated i n at least 4 BCI sessions. Each session started with the recording of ca libration data, followed by a machine learning phase and a feedback phase of varying duration. All following retrospective analyses were performed on the calibration data only.
 During the experiments the subjects were seated in a comfort able chair with arm rests. For the recording of the calibration data every 4.5 X 6 seconds one of 3 different visual stimuli was presented, indicating a motor imagery task the subject should perform d uring the following 3 X 3.5 seconds. The randomized and balanced motor imagery tasks investigat ed for all subjects except ay were left hand ( l ), right hand ( r ), and right foot ( f ). Subject ay only performed left-and right hand tasks. Between 120 and 200 trials were performed during the calibra tion phase of one session for each motor imagery class.
 Brain activity was recorded from the scalp with multi-chann el EEG amplifiers using at least 64 channels. Besides EEG channels, we recorded the electromyo gram (EMG) from both forearms and the right lower leg as well as horizontal and vertical electr ooculogram (EOG) from the eyes. The EMG and EOG channels were exclusively used to ensure that the subjects performed no real limb or eye movements correlated with the mental tasks. As their a ctivity can directly (via artifacts) or indirectly (via afferent signals from muscles and joint rec eptors) be reflected in the EEG channels they could be detected by the classifier. Controlling EMG and EOG ensured that the classifier operated on true EEG signals only.
 Data preprocessing and Classification The time series data of each trial was windowed from 0.5 secon ds after cue to 3 seconds after cue. The data of the remaining interval was band pass filtered betw een either 9 Hz  X  25 Hz or 10 Hz  X  25 Hz, depending on the signal characteristics of the subjec t. In any case the chosen spectral interval comprised the subject specific frequency bands that contain ed motor-related activity.
 For each subject a subset of EEG channels was determined that had been recorded for all of the subject X  X  sessions. These subsets typically contained 40 t o 45 channels which were densely located (according to the international 10-20 system) over the more central areas of the scalp (see scalp maps in following sections). The EEG channels of each subject wer e reduced to the determined subset before proceeding with the calculation of Common Spatial Pa tterns (CSP) for different (subject specific) binary classification tasks.
 After projection on the CSP filters, the bandpower was estima ted by taking the logvariance over time. Finally, a linear discriminant analysis (LDA) classi fier was applied to the best discriminable two-class combination. 3.1 Introduction of Common Spatial Patterns (CSP) The common spatial pattern (CSP) algorithm is very useful in calculating spatial filters for detecting ERD/ERS effects ([15]) and can be applied to ERD-based BCIs, see [11]. It has been extended to multi-class problems in [14], and further extensions and ro bustifications concerning a simultaneous optimization of spatial and frequency filters were presente d in [16, 17, 18]. Given two distributions in a high-dimensional space, the (supervised) CSP algorith m finds directions (i.e., spatial filters) that maximize variance for one class and simultaneously min imize variance for the other class. Af-ter having band-pass filtered the EEG signals to the rhythms o f interest, high variance reflects a strong rhythm and low variance a weak (or attenuated) rhythm . Let us take the example of discrim-inating left hand vs. right hand imagery. The filtered signal corresponding to the desynchronization of the left hand motor cortex is characterized by a strong mot or rhythm during imagination of right hand movements (left hand is in idle state), and by an attenua ted motor rhythm during left hand imagination. This criterion is exactly what the CSP algorit hm optimizes: maximizing variance for the class of right hand trials and at the same time minimizing variance for left hand trials. Further-more the CSP algorithm calculates the dual filter that will fo cus on the area of the right hand and it will even calculate several filters for both optimization s by considering the remaining orthogonal subspaces.
 Let  X  i be the covariance matrix of the trial-concatenated matrix o f dimension [channels  X  con-catenated time-points] belonging to the respective class i  X  X  1 calculating a matrix Q and diagonal matrix D with elements in [ 0 This can be solved as a generalized eigenvalue problem. The p rojection that is given by the i -th row of matrix Q has a relative variance of d i ( i -th element of D ) for trials of class 1 and relative variance 1  X  d i for trials of class 2. If d i is near 1 the filter given by the i -th row of Q maximizes variance for class 1, and since 1  X  d i is near 0, minimizes variance for class 2. Typically one woul d retain projections corresponding to the three highest eige nvalues d i , i.e., CSP filters for class 1, and projections corresponding to the three lowest eigenvalues , i.e., CSP filters for class 2. 3.2 Comparison of CSP filters Since the results of the CSP algorithm are the solutions of a g eneralized eigenvalue problem, where every multiple of an eigenvector is again a solution to the ei genvalue problem. If we want to compare different CSP filters, we must therefore keep in mind that eve ry point on the line through a CSP filter point and the origin can be identified (except for the origin i tself). More precisely, it is sufficient to consider only normalized CSP vectors on the (#channels-1)-dimensional hypersphere. This suggests that the CSP space is inherently non-euclidean. As a more app ropriate metric between two points c 1 and c 2 in this space, we calculated the angle between the two lines c orresponding to these points. When applying this measure to a set of CSP filters ( c i ) i  X  n , one can generate the distance matrix which can then be used to find prototypical examples of CSP filt ers. Fig.1 shows an example of a distance matrix for 78 CSP filters for the discrimination of t he variance during imagined left hand movement and foot movement. Based on the left hand signals, t hree CSP filters showing the lowest eigenvalues were chosen for each of the 13 sessions. The same number of 3  X  13 filters were chosen for the foot signals. The filters are arranged in groups accor ding to their relative magnitude of the eigenvalues, i.e., filters with the largest eigenvalues are grouped together, then filters with the second largest eigenvalues etc.
 The distance matrix in Fig.1 shows a block structure which re veals that the filters of each group have low distances amongst each other as compared to the distance s to members of other groups. This is especially true for filters for the minimization of variance in left hand trials. 3.3 Finding Clusters in CSP space The idea to find CSP filters that recur in the processing of diff erent sessions of a single subject is very appealing, since these filters can be re-used for efficie nt classification of unseen data. As an example of clustered parameters, Fig.2 shows a hierarchica l clustering tree (see [19]) of CSP filters of different sessions for subject al . Single branches of the tree form distinct clusters, which a re also clearly visible in a projection of the first Multi-Dimen sional Scaling-Components in Fig.1 (for MDS, see [20]).
 The proposed metric of section 3.2 coincides with the metric used for Inlier-Based Independent Component Analysis (IBICA, see [12, 13]). This method was or iginally intended to find estimators of the super-Gaussian source signals from a mixture of signa ls. By projecting the data onto the hypersphere and using the angle distance, it has been demons trated that the correct source signals can be found even in high-dimensional data. The key ingredient o f this method is the robust identification of inlier points as it can be done with the  X  -index (see [21]), which is defined as follows: Let z  X  X  c 1 z , according to the distance m . We then call the average distance of z to its neighbors the  X  -index of z , i.e. If z lies in a densely populated region of the hypersphere, then t he average distance to its neighbors is small, whereas if it lies in a sparse region, the average di stance is high. The data points with the smallest  X  are good candidates for prototypical CSP filters since they a re similar to other filters in the comparison set. This suggests that these filters are good solutions in a number of experiments and are therefore robust against changes in the data such as o utliers, variations in background noise etc. Fig.3 shows an overview of the validation methods used for th e algorithms under study. The left part shows validation methods which mimick the following BCI sce nario: a new session starts and no data has been collected yet. The top row represents data of al l sessions in original order. Later rows describe different data splits for the training of the CSP fil ters and LDA (both depicted in blue solid lines) and for the testing of the trained algorithms on unsee n data (green dashed lines). The ordinary CSP method does not take any historical data from prior sessi ons into account (second row). It uses training data only from the first half of the current session. This serves as a baseline to show the general quality of the data, since half of the session data is generally enough to train a classifier that is well adapted to the second half of the session. Note that th is evaluation only corresponds to a real BCI scenario where many calibration trials of the same day ar e available. 4.1 Zero training methods This is contrasted to the following rows, which show the excl usive use of historic data in order filters from this collection as described in section 3.3 (fou rth row), or use a combination of row three and four that results in a concatenation of CSP filters a nd derived CSP prototypes (fifth row). Feature concatenation is an effective method that has been s hown to improve CSP-based classifiers considerably (see [22]). 4.2 Adaptive training methods The right part of Fig.3 expands the training sets for rows thr ee, four and five for the first 10, 20 or 30 trials per class of the data of the new session. In the methods of row 4 and 5, only LDA profits from the new data, whereas CSP prototypes are calculated exclusi vely on historic data as before. This approach is compared against the ordinary CSP approach that now only uses the same small amount of training data from the new session.
 This scheme, as well as the one presented in section 4.1, has b een cross-validated such that each available session was used as a test session instead of the la st one. The underlying question of this paper is whether informatio n gathered from previous experimental sessions can prove its value in a new session. In an ideal case existing CSP filters and LDA classifiers could be used to start the feedback phase of the new session im mediately, without the need to collect new calibration data.
 We checked for the validity of this scenario based on the data described in section 2. Table 1 shows the classification results for the different classification methods under the Zero-training validation scheme. For subjects al , ay and ch , the classification error of CONCAT is of the same magnitude as the ordinary (training-based) CSP-approach. For the other three subjects, CONCAT outperforms the methods HIST and PROTO . Although the ideal case is not reached for every subject, th e table shows that our proposed methods provide a decent step towards the g oal of Zero-training for BCI. Another way to at least reduce the necessary preparation tim e for a new experimental session is to record only very few new trials and combine them with data fro m previous sessions in order to get a quicker start. We simulate this strategy by allowing the ne w methods HIST , PROTO and CONCAT to take a look also on the first 10, 20 or 30 trials per class of th e new session. The baseline to compare their performance would be a BCI system trained only on these initial trials. In Fig. 4, this comparison is depicted. Here the influence of the number of in itial training trials becomes visible. If no new data is available, the ordinary classification approa ch of course can not produce any output, whereas the history-based methods, e.g. CONCAT already generates a stable estimation of the class labels. All methods gain performance in terms of smaller tes t errors as more and more trials are added. Only after training on at least 30 trials per class, or dinary CSP reaches the classification level that CONCAT had already shown without any training data of the current se ssion.
 Fig.5 shows some prototypical CSP filters as detected by IBIC A clustering for subject al and left hand vs. foot motor imagery. All filters have small support (i .e., many entries are close to 0), and the few large entries are located on neurophysiologically i mportant areas: Filters 1 X 2 and 4 X 6 cover the motor cortices corresponding to imagined hand movement s, while filter 3 focuses on the central foot area. This shows that the cluster centers are spatial fil ters that meet our neurophysiological ex-pectations, since they are able to capture the frequency pow er modulations over relevant electrodes, while masking out unimportant or noisy channels. Advanced BCI systems (e.g. BBCI) recently aquired the abili ty to dispense with extensive subject training and now allow to infer a blueprint of the subject X  X  v olition from a short calibration session of approximately 30 min. This became possible through the use o f modern machine learning technol-ogy. The next step along this line to make BCI more practical i s to strive for zero calibration time. Certainly it will not be realistic to achieve this goal for ar bitrary BCI novices, rather in this study we have concentrated on experienced BCI users (with 4 and more s essions) and discussed algorithms to re-use their classifiers from prior sessions. Note that the c onstruction of a classifier that is invariant against session to session changes, say, due to different vi gilance, focus or motor imagination across sessions is a hard task.
 Our contribution shows that experienced BCI subjects do not necessarily need to perform a new calibration period in a new experiment. By analyzing the CSP parameter space, we could reveal an appropriate characterization of CSP filters. Finding clu sters of CSP parameters for old sessions, novel prototypical CSP filters can be derived, for which the n europhysiological validity could be shown exemplarily. The concatenation of these prototype fil ters with some CSP filters trained on the same amount of data results in a classifier that not only pe rforms comparable to the presented ordinary CSP approach (trained on a large amount of data from the same session) in half of the subjects, but also outperforms ordinary CSP considerably w hen only few data points are at hand. This means that experienced subjects are predictable to an e xtent that they do not require calibration anymore.
 We expect that these results can be even further optimized by e.g. hand selecting the filters for PROTO , by adjusting for the distribution changes in the new sessio n, e.g. by adapting the LDA as presented in [23], or by applying advanced covariate-shift compensation methods like [24]. Future work will aim to extend the presented zero training id ea towards BCI novices.
 [1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtsche ller, and T. M. Vaughan,  X  X rain-[2] N. Birbaumer, A. K X bler, N. Ghanayim, T. Hinterberger, J . Perelmouter, J. Kaiser, I. Iversen, [3] G. Pfurtscheller and F. H. L. da Silva,  X  X vent-related EE G/MEG synchronization and desyn-[4] B. Blankertz, G. Curio, and K.-R. M X ller,  X  X lassifying S ingle Trial EEG: Towards Brain Com-[5] L. Trejo, K. Wheeler, C. Jorgensen, R. Rosipal, S. Clanto n, B. Matthews, A. Hibbs, [6] L. Parra, C. Alvino, A. C. Tang, B. A. Pearlmutter, N. Yeun g, A. Osman, and P. Sajda,  X  X inear [7] W. D. Penny, S. J. Roberts, E. A. Curran, and M. J. Stokes,  X  EEG-Based Communication: A [8] B. Blankertz, G. Dornhege, M. Krauledat, K.-R. M X ller, V . Kunzmann, F. Losch, and G. Curio, [9] G. Pfurtscheller, C. Neuper, C. Guger, W. Harkam, R. Ramo ser, A. Schl X gl, B. Obermaier, and [10] M. Schr X der, T. N. Lal, T. Hinterberger, M. Bogdan, N. J. Hill, N. Birbaumer, W. Rosenstiel, [11] H. Ramoser, J. M X ller-Gerking, and G. Pfurtscheller,  X  Optimal spatial filtering of single trial [12] F. C. Meinecke, S. Harmeling, and K.-R. M X ller,  X  X obust ICA for Super-Gaussian Sources X , [13] F. C. Meinecke, S. Harmeling, and K.-R. M X ller,  X  X nlier -based ICA with an application to [14] G. Dornhege, B. Blankertz, G. Curio, and K.-R. M X ller,  X  Boosting bit rates in non-invasive [15] Z. J. Koles and A. C. K. Soong,  X  X EG source localization: implementing the spatio-temporal [16] G. Dornhege, B. Blankertz, M. Krauledat, F. Losch, G. Cu rio, and K.-R. M X ller,  X  X ombined [17] S. Lemm, B. Blankertz, G. Curio, and K.-R. M X ller,  X  X pat io-Spectral Filters for Improved [18] R. Tomioka, G. Dornhege, G. Nolte, K. Aihara, and K.-R. M  X ller,  X  X ptimizing Spectral Filter [19] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification , Wiley &amp; Sons, 2nd edn., 2001. [20] T. Cox and M. Cox, Multidimensional Scaling , Chapman &amp; Hall, London, 2001. [21] S. Harmeling, G. Dornhege, D. Tax, F. C. Meinecke, and K. -R. M X ller,  X  X rom outliers to [22] G. Dornhege, B. Blankertz, G. Curio, and K.-R. M X ller,  X  Combining Features for BCI X , in: [23] P. Shenoy, M. Krauledat, B. Blankertz, R. P. N. Rao, and K .-R. M X ller,  X  X owards Adaptive [24] S. Sugiyama and K.-R. M X ller,  X  X nput-Dependent Estima tion of Generalization Error under
