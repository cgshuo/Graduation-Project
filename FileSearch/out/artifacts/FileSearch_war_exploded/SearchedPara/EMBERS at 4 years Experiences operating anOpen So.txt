 EMBERS is an anticipatory intelligence system forecasting population-level events in multiple countries of Latin Amer-ica. A deployed system from 2012, EMBERS has been gen-erating alerts 24x7 by ingesting a broad range of data sources including news, blogs, tweets, machine coded events, cur-rency rates, and food prices. In this paper, we describe our experiences operating EMBERS continuously for nearly 4 years, with specific attention to the discoveries it has en-abled, correct as well as missed forecasts, lessons learnt from participating in a forecasting tournament, and our perspec-tives on the limits of forecasting including ethical consider-ations.
 civil unrest, event forecasting, open source indicators.
Modern communication forms such as social media and microblogs are not only rapidly advancing our understand-ing of the world but also improving the methods by which we can comprehend, and even forecast, the progression of events. Tracking population-level activities via  X  X assive pas-sive X  data has been shown to quite accurately shed light into large-scale societal movements.

Two years ago, in KDD 2014, we described EMBERS [15], a deployed anticipatory intelligence system [5] that forecasts significant societal events (e.g., civil unrest events such as protests, strikes, and  X  X ccupy X  events) using a large set of open source indicators such as news, blogs, tweets, food prices, currency rates, and other public data. The EM-BERS system has been running continuously 24x7 for nearly 4 years at this point and our goal in this paper is to present the discoveries it has enabled, both correct as well as missed forecasts, and lessons learned from participating in a fore-casting tournament including our perspectives on the limits of forecasting and ethical considerations. In particular, we shed insight into the value proposition to an analyst and how EMBERS forecasts are communicated to its end-users.
The development of EMBERS is supported by the Intelli-gence Advanced Research Projects Activity (IARPA) Open Source Indicators (OSI) program. EMBERS currently fo-cuses on multiple regions of the world but for the purpose of this paper we focus primarily on the 10 Latin Ameri-can countries, specifically the countries of Argentina, Brazil, Chile, Colombia, Ecuador, El Salvador, Mexico, Paraguay, Uruguay, and Venezuela. Similarly, EMBERS generates forecasts for multiple event classes X  X nfluenza-like-illnesses [3], rare diseases [16], elections [12], domestic political crises [8], and civil unrest X  X ut in this paper we focus primarily on civil unrest as this was the most challenging event class with hundreds of events every month across the countries studied here. EMBERS forecasts are scored against the Gold Stan-dard Report (GSR), a monthly catalog of events as reported in newspapers of record in these 10 countries. The GSR is compiled by MITRE corporation using human analysts.
Our key contributions can be summarized as follows: 1. Unlike retrospective studies of predictability, EMBERS 2. In an attempt to demystify the state-of-the-art in fore-3. While social media is often touted as the key to event 4. We consider the separation of civil unrest events into 5. We describe our current best understanding of the lim-
We begin by providing a brief review of forecasting sys-tems, followed by a quick preview of EMBERS, its system ar-chitecture, machine learning models, and measures for eval-uating its performance. For more details, please see [15].
Forecasting societal events such as civil unrest has a long tradition in the intelligence analysis and political science community. We distinguish between forecasting systems versus event coding systems (systems that provide struc-tured representations of ongoing events reported in news-papers), and focus on the former. Early forecasting sys-tems such as ICEWS [14] provided very broad coverage in countries but were limited by their spatio-temporal resolu-tion (e.g., typically country-and month-level forecasting for specific events of interest [19]). The ICEWS events of inter-est are domestic political crises, international crises, eth-nic/religious violence, insurgencies, and rebellion. A similar project in scope is PITF (Political Instability Task Force) [6] funded by the CIA. To the best of our knowledge, only EMBERS provides the most-specific spatial resolution (city-level) and the most-specific temporal resolution (daily-level) capability in forecasting.
 The software architecture of EMBERS (Early Model Based Event Recognition using Surrogates) is designed as a loosely coupled, share-nothing, highly distributed pipeline of pro-cesses connected via ZeroMQ. In this manner, the system is both highly scalable and fault tolerant. The EMBERS pipeline can loosely be broken up into four stages: inges-tion, enrichment, modeling, and selection. In the first stage, ingestion, data is collected from a variety of sources and streamed into the following stages in real-time. The en-richment stage takes the raw data from the ingestion stage and processes it in various ways including natural language processing, geocoding, and relative time phrase normaliza-tion. After enrichment, the modeling stage feeds the en-riched data into the various models that make up EMBERS. Unlike other systems which use single monolithic models to make predictions, EMBERS combines the results of several different models to arrive at the most accurate forecasts. Figure 1: An example depicting how an alert is scored with respect to the ground truth.
 Figure 2: Alert sent at time t 1 predicting an event at time t 3 can be matched to a GSR event that happened at time t 2 and reported at time t 4 if t 1 &lt; t 4.
 In particular, the separate alerts from each model are de-duplicated, fused, and selected and finally emitted as a full forecast for a real world event.

The structure of a civil unrest forecast is shown in Figure 1 (left). A forecast constitutes four fields, corresponding to the when, where, who, and why of the protest. These fields are respectively denoted as the date, location, population, and event type. Location is recorded at the city level. Population and event type are fields chosen from a categorical set of possibilities. The figure further shows how an alert with all these fields are scored against a GSR event. In the basic scoring methodology shown in Figure 1 each of the four fields are weighted uniformly and a total quality score out of 4 is obtained. Apart from this each alert also has a lead-time associated with it calculated as shown in Figure 2.
Rather than design one model to integrate all possible data sources, EMBERS adopted a multi-model approach to forecasting. Each model utilized a specific (possibly overlap-ping) set of data sources and is tuned for high precision, so that the union of these models can be tuned for high recall. A fusion/suppression engine [7] allows a tunable strategy to issue more or fewer alerts depending on whether the ana-lyst X  X  objective is to obtain a higher precision or recall. The underlying models used in EMBERS are: (i) planned protest model [13], (ii) dynamic query expansion [20], (iii) volume-based model [9], (iv) cascade regression [2], and (v) a base-line model. The planned protest model, for news and social media (Twitter, Facebook), identifies explicit signs of orga-nization and calls for protest, resolves relative mentions of time (e.g.,  X  X ext Saturday X ) and space (e.g.,  X  X he square X ) to issue forecasts. The dynamic query expansion (DQE) model uses Twitter as a data source and learns time-and country-specific expansions of a seed set of keywords to identify spe-cific situational circumstances for civil unrest. For instance, in Venezuela (an economy where the government exercises stringent price controls), there were a series of protests in 2014 stemming from the shortage of toilet paper, a novel cir-cumstance that was uncovered by DQE. The volume-based model uses a range of data sources, spanning social, eco-nomic and political indicators. It uses classical statistical models (LASSO and hybrid regression models) to forecast civil unrest events using features from social media (Twitter and blogs), news sources, political event databases (ICEWS and GDELT [10]), Tor [4] statistics, food prices, and cur-rency exchange rates. It aims to provide a multi-source perspective into forecasting by leveraging the selective su-periorities of different data sources. The cascade regres-sion model aims to model activity related to organization and mobilization in Twitter [2]. Finally, the baseline model uses maximum likelihood estimation over the GSR to issue history-based forecasts.

The EMBERS project is unique not just in its algorithmic underpinnings but also in the use of new measures for eval-uation, specifically aimed at determining forecasting perfor-mance. As shown in Figure 2, one of the primary measures of EMBERS performance is lead time, the number of days by which a forecast  X  X eats the news X , i.e., the date of report-ing of the event. Lead time should not be confused with date quality, i.e., the difference between the predicted date and the actual date of the event. The date quality is one of the components of the quality score, the other components being the location score, event type score, and population score. Figure 1 shows how these other components are scored be-tween an EMBERS forecast and a GSR record.

Given a set of alerts and a set of GSR events for a given month, the lead time is used as a constraint to define le-gal (alert, event) pairs so that we can construct a bipartite matching to optimize the best quality score. From this bi-partite matching, measures of precision and recall can be derived, i.e., by assessing the number of (un)matched events or alerts. Finally, a confidence score is used to assess the quality of probabilities imputed by EMBERS to its fore-casts, and measured in terms of the Brier score. For more details, please see [15].

We now turn to a discussion of specific discoveries enabled by EMBERS, into civil unrest in Latin America, and into the complexity of the forecasting enterprise as a whole.
First, we begin with a performance analysis of EMBERS, from both a quantitative point of view with respect to the GSR and with respect to end-user (analyst) goals.
Figure 3 depicts both the targets set by the IARPA OSI program as well as the actual measures achieved by the EMBERS system. As shown here, the easiest target to achieve in EMBERS was, surprisingly, the lead time objec-tive. This was feasible due to EMBERS X  X  focus on model-ing both planned and spontaneous events. Planned events are sometimes organized with as many as several weeks of Figure 3: IARPA OSI targets and results achieved by EM-BERS. Figure 4: Comparison of number of perfect scores (4.0) ob-tained by EMBERS vs a baserate model each month in 2013. lead time and thus identifying indicators of organization was instrumental in achieving lead time objectives. The confi-dence (mean probability) scores were also achieved by EM-BERS and involved careful calibration of probabilities by taking into account estimates of model propensities and data source reliabilities. The measure that was most difficult to achieve was the quality score as it involved a four compo-nent additive score and thus tangible improvements in score required more than incremental improvements in forecast-ing specific components. Finally, recall and precision in-volve a natural underlying trade-off and the deployment of our fusion/suppression engine provided the ability to bal-ance this trade-off to meet IARPA OSI X  X  objectives. Apart from comparing mean scores another interesting measure is to see how many perfect matches (4.0 quality score) are ob-tained by EMBERS. Fig. 4 shows the number of alerts issued by EMBERS that matched perfectly to an event in the fu-ture on a monthly basis for 2013. It is clear that EMBERS makes almost double the number of fully accurate forecasts as compared to a baserate model.The baserate model gener-ates alerts using the rate of occurrence of events in the past three months.
In addition to the quantitative measures above, our expe-rience interacting with analysts demonstrated an interesting dichotomy as to how analysts use EMBERS alerts. Some an-alysts preferred to use EMBERS in an  X  X nalytic triage X  sce-nario wherein they could tune EMBERS for high recall so that they would apply their traditional measures of filtering
EMBERS forecasts that there will be a violent protest on February, 18th 2014 in Caracas , the capital city of
Venezuela . It predicts that the protest will involve people working in the business sector. The protest will be related to discontent about economic policies.

There were 5, 5, and 5 other similar warnings in last 2, 7 and 30 days , respectively.

The forecast date of the warning falls in week 7 , which may have historical importance ; this week is found to be sta-tistically significant (pval=0.00461919415894, zscore=2.832, avg. count=57.25, mean=21.569 +/-12.597)
Audit trail of the warning includes an article printed 2014-02-17 .

Major players involved in the protest include Venezuelan opposition leader, students, President Nicolas Maduro, and Leopoldo Lopez .
 Reasons : Protest against rising inflation and crime; Protestors want a political change; President Nicolas Maduro has accused US consular officials and right-wing .
Protests are characterized by : Venezuelan opposition leader spearheaded days of protest and calling for peaceful demon-stration ; Maduro accused official on 2014-12-16 ; Protests have seen several deadly street protests; Three people were killed on 2014-02-12 ; Demonstrations setting days of clashes; supporters to march to Interior Ministry on 2014-02-18 . Figure 5: An example narrative for an EMBERS alert. Here, color red indicates named entities, green refers to descriptive protest related keywords. Items in blue are historical or real time statistics and those in magenta refer to inferred reasons of the protest. and analysis to hone in on forecasts of interest. Other ana-lysts instead viewed EMBERS as a data source and preferred to use it in a high precision mode, e.g., wherein they were focused on a specific region of the world (e.g., Venezuela) and/or aimed to investigate a particular social science hy-pothesis (e.g., whether disruptions in global oil markets led to civil unrest).

To support these diverse classes of users, we implemented two mechanisms in the alert delivery stage. First, we im-plemented a mechanism wherein in addition to generating alerts, EMBERS also forecasted the expected quality score for each forecast (using machine learning methods trained on past GSR-alert matches). This expected quality score measure provided a way for analysts to use quality directly as a way to tune the system to receive greater or fewer alerts. Second, we implemented an automated narrative generation capability (see Fig. 5) wherein EMBERS auto-generates a summary of the alert in English prose. As shown in Fig. 5, a narrative comprises many parts drawn from different sources of information. One source constitutes the named entities wherein the system uses  X  X ikification X  to identify definitions and descriptions of named entities on Wikipedia. A second source is historical (or real-time) statistics of warning out-put and warning performance and situating the alert in this context. The third source pertains to inferred reasons for the protest using knowledge graph identification techniques.
Next, we detail some of the successful as well as not so successful forecasts made by EMBERS over the past few years in Latin America.
 Figure 6: EMBERS performance during the Brazilian Spring (June 2013). These protests were the largest and most significant protests in Brazil X  X  recent history and caught worldwide attention. Millions of Brazilians took part in these demonstrations, also known as the Brazilian Spring or the Vinegar Movement (in-spired from the use of vinegar soaked cloth by demonstrators to protect themselves from police teargas). These protests were sparked by an increase in public transport fares from R $3 to R $3 . 20 by the government of President Dilma Rouss-eff.
 As shown in Fig. 6, while missing the initial uptick, EM-BERS did forecast the increase in the order-of-magnitude of protest events during the Brazilian Spring and also captured the spatial spread in the events. In addition EMBERS cor-rectly forecast that this event will span the broad Brazilian general population (as opposed to being confined to specific sectors).

Around 68% of EMBERS alerts during this period origi-nated from the planned protest model. This is due to the fact that social networking platforms (Twitter and Face-book) as well as conventional news media played a key role in organization of these uprisings. Although initial protests were primarily due to the bus fare increases, they quickly morphed into more broader dissatisfaction to include wider issues such as government corruption, over-spending, and police brutality. The demonstrators also made calls for po-litical reforms. In response, President Rousseff proposed a plebiscite on widespread political reforms in Brazil (but this was later abandoned). Through its dynamic query expan-sion model, EMBERS was able to capture such discussions on Twitter (see Fig. 7), and tracked their evolution as events unfolded through June.

The protests intensified in late June (see Fig. 6), which were forecast correctly by EMBERS, and these events also coincided with FIFA 2013 Confederation Cup matches. We believe this was an important factor in helping the protests gain momentum, as the events were covered by international media. A majority of protests occurred in the cities that were hosting FIFA soccer matches. EMBERS issued most of its alerts for these host cities (see Fig. 8), viz. Rio de Janeiro, S  X ao Paulo, Belo Horizonte, Salvador, and Porto Alegre, among others. For example, on 27th June during the Confederations Cup semi-final in Fortaleza, around 5000 Figure 7: Word cloud representing tweets identified by EM-BERS dynamic query expansion model.
 Figure 8: Geographic overlap of protest events (from the GSR) and EMBERS alerts for Brazil during June 2013. protesters clashed with the police near the Castelao stadium. In this case EMBERS had forecast an alert the day before. Later on the 30th of June, when the last games of the con-federation cup took place in Rio de Janeiro and Salvador, they were plagued by mass protests as well; EMBERS pre-dicted these events and submitted multiple alerts for Rio for the 28th and 29th June and one for Salvador for 29th June. In early 2014 Venezuela began experiencing a situation of turmoil with a large portion of its population protesting due to insecurity, inflation and shortage of basic goods. This period saw one of the highest levels of civil disobedience in Venezuela with protests beginning in January with the murder of a former Miss Venezuela. However, the protests started gaining more importance and turned violent and more frequent with students joining the movement follow-ing an attempted rape of a student on a campus in San Cristobal. EMBERS captured some of these first calls-to-protest at San Cristobal and its nearby surrounding areas and correctly forecast the population (Education) and that the protests would turn violent. A majority of the protesters were demanding that president Nicolas Maduro step down owing to the poor economic policies and widespread cor-ruption. EMBERS succeeded in capturing that the reason behind the protests were mainly against government policies Figure 9: Geographical spread of protests (and forecasts) during the Venezuelan student protests (Feb-Mar 2014). Figure 10: EMBERS performance during the Venezuelan student protests (Feb-Mar 2014). with corruption being a major theme. The EMBERS models working on Twitter were also clearly able to identify some of the major leaders involved in the protest, such as the key op-position leader Leopoldo Lopez. Though the events mainly began in San Cristobal, they spread widely throughout the country; EMBERS captured this spread very well as shown in Fig. 9. Fig. 10 shows how EMBERS closely forecast the spike in the number of events during this period.
 In September 2014, there were some peaceful protests by students from Ayotzinapa in Mexico against discriminatory hiring practices for teachers. During these protests, police opened fire on the students killing around three; 43 stu-dents went missing. This poor handling of the protest by the Mexican government caused widespread demonstrations throughout the country over the next few months in sup-port of the families of the 43 missing students. Many of these protests were violent in nature with demonstrators expressing extreme dissatisfaction against the government of president Pena Nieto. EMBERS, as shown in Fig. 16 forecast an uptick in Mexico protests during early October 2014 with a lead time of about three days. It also generated a series of alert spikes coinciding with the first large-scale nationwide protests between October 5th and 8th. Fig. 11 provides a timeline of GSR events and EMBERS alerts for Mexico during this period. This figure provides a detailed comparison of the continuous stream of alerts produced by EMBERS during this period against how the actual events unfolded in the real world. a daily basis.
 Colombia witnessed two different significant protests during this period, one during late December 2014 and the other during February 2015. Towards the end of 2014, the Colom-bian government was on the process of moving forward with peace negotiations to end 50 years of conflict with the Rev-olutionary Armed Forces of Colombia (FARC). With the FARC rebels having been associated with various acts of terror, e.g., extortion, armed conflict, kidnapping, ransom, and illegal mining, for a long period, the people of Colom-bia gathered in huge numbers to protest against possible amnesty for the FARC rebels. EMBERS successfully fore-cast the uptick in the number of events during the middle of December 2014 as indicated in Fig. 12. This figure also depicts the increase in protest counts during February 2015, although in this case EMBERS over-predicted the counts.
The protests in February 2015 were qualitatively different in nature and were led by truckers unions demanding bet-ter freight rates, labor rights, and revolting against high fuel prices. The truckers protests extended for about a month and caused an estimated loss of about $300 million to the Colombian economy. EMBERS forecast the truckers protests accurately at the onset of these events but over-estimated the number of protests during February 11-12. The February 2015 protests in Paraguay were mainly car-ried out by peasants against the actions of President Ho-racio Cartes. The protests were carried out after president Horacio X  X  public revelation that he had opened two private Swiss bank accounts. The protests also had a historical sig-nificance. They were also being carried out as a tribute to peasant leaders and activists who were murdered. The peas-ants also protested against the introduction of a new public-private partnership law. EMBERS forecast the uptick in the number of Paraguay protests during mid February 2015 as shown in Fig. 13.
 Figure 12: EMBERS performance during the Colombia protests (Dec 2014 to Mar 2015).
 Figure 13: EMBERS performance during the Paraguay protests (Feb. 2015). Figure 14: EMBERS performance during the Brazilian protests of March 2015.
Next, we outline specific large-scale events that EMBERS failed to forecast accurately, along with a discussion of un-derlying reasons.
The beginning of 2015 saw a series of protests in Brazil demanding the removal of president Dilma Roussef amidst much furore against the increasing corruption in the coun-try. The number of protests increased significantly due to the revelations that many politicians belonging to the rul-ing party accepted bribes from the state-run energy com-pany Petrobas. The protests drew huge participation from the general population, with protesters generally estimated to be around a million. EMBERS, as shown in Figure 14, picked up the onset of events but failed to capture the sud-den rise in the number of events.

During this period there was a significant architectural change in the EMBERS processing pipeline. As mentioned in Section 2 the EMBERS system enrichment pipeline con-sists of the following steps: natural language processing, geocoding, and relative time phrase normalization (tempo-ral tagging). During early 2015 EMBERS had moved to the Heideltime [17] temporal tagger versus the previously used TIMEN [11] temporal tagger. (This choice was made be-cause Heideltime supported more languages and an active development cycle.) Heideltime had no support for Por-tuguese (the primary language of Brazil) and the EMBERS software development team had extended Heideltime to sup-port Portuguese by translating the underlying resources for Spanish to Portuguese. As it turns out, the simple transla-tion of rules from Spanish to Portuguese was not sufficient and this affected the recall of one of the key models for Brazil, viz. the planned protest model. Since the planned protest model relies almost exclusively on the quality of in-formation (specifically, date) extraction from text, its per-formance significantly deteriorated. This was subsequently corrected for the future by adding more rules and correcting existing rules (which were translated from Spanish) in Hei-deltime for Portuguese with the aid of language experts and extensive backtesting. Fig. 15 shows an example detection before and after the changes.
 Figure 15: Example depicting the improvement in time phrase recognition after changes to Heideltime.
 Figure 16: EMBERS performance during Mexico protests (Oct 2014).
The days of December 2014 witnessed a continuation of the series of protests that began in October 2014 as de-scribed in Section 4.1. People turned out in huge numbers in different cities of Mexico demanding President Pena Ni-eto X  X  ouster owing to the manner in which the case of the 43 missing students were handled. The protests were largely peaceful except for a few cases where vehicles were torched and windows and office equipment were broken.

EMBERS missed the huge single day spike on December 1st. Though having predicted a nationwide event for De-cember 1, EMBERS failed to capture the individual cities where the protests would take place out and thus was un-able to forecast the number of events accurately. On man-ual retrospective, it was found that the date, viz. December 1, was picked by the protesters due to its historical signif-icance. This was the day when President Pena Nieto was sworn in (in 2012) amidst much controversy and opposition from many specific constituent groups. The manual analy-sis also led to the understanding of how special dates were mentioned by the twitterati #1Dmx . Dates mentioned us-ing such abbreviations went unrecognized by the EMBERS system and was one of the main reasons for EMBERS not being able to capture the peak on December 1st despite its historical significance.
The EMBERS forecasts during the 2013 Brazilian Spring as shown in Fig. 6 was able to capture the peak but as can be seen the system was unable to capture the initial onset. See Section 7 for a detailed discussion of the limits of forecasting. Table 1: Comparison of performance measures under abla-tion testing. Social media sources contribute toward recall but, due to their noisy nature, lower other measures of per-formance.

Different data sources provide different value to the fore-casting enterprise. It is important that we understand the value of a data source w.r.t. its forecasting potential. In this section we describe ablation testing in EMBERS where the incremental value addition is evaluated for specific data sources. In particular, we are interested in determining the utility of using social media versus traditional media such as news and blogs. Table 1 shows the percentage improve-ment or degradation in performance measures when specific sources are removed. It clearly shows that social media sources are mainly necessary in achieving high recall but are not that useful in achieving high lead times, for which traditional media sources are required. This behavior is ex-pected as social media is where daily chatter occurs whereas signs of organization and calls for protest often happen over (or are reported in) traditional meadia. Mainly, Table 1 makes it evident that to build a successful forecasting sys-tem we need a good mix of both traditional and social media sources. Fig. 17 shows a snapshot of the EMBERS ablation visualizer. The visualizer provides an analyst with the ca-pability to selectively remove data sources and assess the differences in final alerts.
The GSR contains a mix of everyday, mundane, protests as well as surprising events such as the Brazilian Spring. We aimed to ascertain the relative ease of forecasting each class of events with respect to the baserate model described in section 3.1. To define surprising events, we employed a maximum entropy approach. For this purpose, each event is assumed to be describable in terms of three dimensions: country, population, and event type. The GSR can then be conceptualized as a cube. We infer a maximum entropy Table 2: Surprising events identified by a maximum entropy analysis over the GSR.
 distribution conditioned on the marginals induced by the cube using iterative proportional fitting [1].
 Every month, events from the last three months of the GSR are used to populate the underlying cube of counts and a iterative proportional fitting procedure is used to esti-mate the expected counts for each cell. The resultant sam-ple counts are then scaled to match the observed number of GSR events in the current month. The cell-wise difference between the inferred maxent distribution and the observed GSR is computed and all cells with significance greater than five standard deviations are classified as containing surpris-ing events. In essence, this approach takes the GSR as input and creates a truncated GSR against which we can evaluate EMBERS (and the baserate model).
 In Table 2 we present several inferred events in Latin America from our maximum entropy filter. For all these events, we compare the recall of both EMBERS and baser-ate model in Figure 18. It is clear that EMBERS is able to forecast these significant upticks consistently and that the baserate model is not able to.
While examining the events of civil unrest closely in the past few years, it was clear to our team that events carry two distinct types of uncertainties: cause and timing . Fig. 19 summarizes these uncertainties.

Among all the incidents of civil unrest that we encounter, the largest and the most significant ones are planned events. These events are usually organized by political parties, labor and student unions. Since it takes a huge effort to organize protest demonstrations that attract thousands, the organiz-ers must disseminate information regarding the venue and Figure 18: Performance of EMBERS vs a baserate model for surprising events.
 Timing
Figure 19: Studying the limitations of event forecasting. the date and time. These announcements are posted on the organizers X  websites and are widely shared on social media. By scouring our sources, it has been possible for EMBERS to accurately forecast the occurrence of these types of protests.
The recurring events take place on a regular basis. For instance, in Chile and Argentina the  X  X others of the dis-appeared X  protest the disappearance of their children by the military dictatorships of the 1970s and 1980s on a cer-tain particular day of the week and in the same plaza. In some countries with large Muslim populations, fighting and protests break out regularly after Friday evening prayer as people stream out of the mosques after listening to fiery sermons. These are typically small events but if they are reported as part of our GSR, EMBERS models will be able to forecast them.

The protests for which the causes are known but not the timing are staged spontaneously. These events are the outcomes of longstanding frustration and anger which fuel widespread protests in response to trigger events. Thus, the viral videos of police brutality or a sudden change in govern-ment policy can start a prairie fire of protests. The Brazilian Spring with origins in bus fares and which channeled public anger against corruption and government mismanagement is a classical example. The challenge here is not just to be aware of the underlying tensions that might erupt when an event occurs, but to also distinguish between events that do and do not perform as triggers. Algorithms to better model precursors is an area of further research that will aid further forecasting this class of events.

Finally, black swan events [18] are rare and truly unfore-seen and can happen as a result of natural disasters, the sudden death of a leader, or even the sudden rise of a small group that can truly destabilize a nation. (Each of these types of events can in turn spark civil unrest.) For instance the rise of the Islamic State in Iraq and Syria (ISIS) has truly confounded policymakers all over the world. While there were other Sunni groups, from al-Qaeda to al-Nusra, that contributed to instability, the rapid ascendance of ISIS, which did not depend on an isolated terrorist attack and burst out with a clear holding of territories as a full-scale insurgency, surprised most observers. It might not be feasi-ble to forecast the beginnings of such events; however, once such movements have been initiated, models should be able to detect and forecast their momentum.
EMBERS, as an anticipatory intelligence system, has many powerful legitimate uses but is also susceptible to abuse.
First, it is important to have a discussion of civil unrest and its role in society. In our opinion, under the proper cir-cumstances, civil unrest enhances the ability of citizens to communicate not only their views but also their priorities to those who govern them. Governments constantly need to make choices and find it difficult to know, on specific is-sues at particular times, how their constituencies value the available options. Elections are retrospective indicators and rarely issue-specific; polling taps into sentiment, but is not a good indicator of priorities or strength of feeling because of the low cost associated with responding. Events, on the other hand, indicate a willingness to bear some costs (orga-nization, mobilization, identification) in support of an issue and thus reveal not only preferences but provide some indi-cation of priorities.

An open sources indicators approach, as we have used here, is a potentially powerful tool for understanding the social construction of meaning and its translation into be-havior. EMBERS can contribute to making the transmis-sion of citizen preferences to government less costly to the economy and society as well. There are economic costs to even peaceful disruptions embodied in civil unrest due to lost work hours and the deployment of police to manage traf-fic and the interactions between protestors and bystanders. Given the vulnerability of large gatherings to provocation by handfuls of violence-oriented protestors (e.g., Black Box anarchists in Brazil) the economic, social and political costs of large-scale public demonstrations are also potentially sig-nificant to marchers, bystanders, property owners and the government  X  democratically elected or not. The right to demonstrate can still be respected but if the government responds to grievances in time, the protestors may cancel the event or fewer people might participate in the event. In today X  X  interconnected society, protests also cause disrup-tions to supply chain logistics, travel, and other sectors, and anticipating disruptions is key to ensuring safety as well as reliability.

The potential power of civil unrest forecasting systems, like those of most scientific advances, is susceptible to abuse by both democratic and non-democratic governments. The appropriate safeguards require developing transparent and accountable democratic systems, not outlawing science. Non-democratic governments may clearly abuse such forecasting systems. But even here the value of forecasting civil unrest is not simply negative. Many non-democratic regimes tran-sition to democratic ones, often in a violent process but not always (in Latin America, authoritarian regimes negotiated transitions to democracy without a civil war in Mexico, Hon-duras, Peru, Bolivia, Brazil, Uruguay, Argentina and Chile). The rational choice models of authoritarian decision-making in such crises always explain a dictatorship X  X  collapse rather than accommodation to a transition by pointing to the lack of credible information in a dictatorship regarding citizens X  true feelings. EMBERS-like models may thus provide the in-formation that facilitates and encourages some transitions.
We have presented our experiences and lessons learnt from operating EMBERS continuously 24x7 over a period of four years. EMBERS has proven itself to be a reliable predictor of civil unrest events in 10 different countries by ingesting data from multiple languages. EMBERS has been a wonder-ful testbed for our data science team and even in its misses much has been learnt.

Future work falls primarily in three directions. First, we intend to investigate more formal methods to model precur-sors to protests, so that better precursor detection can con-stitute better protest forecasting. Second, we will continue to build a strong systems capability to forecasting societal events, by enlarging the scope of regions and languages cov-ered. Finally, we are investigating techniques to remove or reduce the human element required in generating the GSR. Currently the most human intensive part of the EMBERS project is generating a GSR for training and validation of the models.
 Supported by the Intelligence Advanced Research Projects Activity (IARPA) via DoI/NBC contract number D12PC000337, the US Government is authorized to reproduce and dis-tribute reprints of this work for Governmental purposes notwith-standing any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the au-thors and should not be interpreted as necessarily represent-ing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the US Government. [1] Y. M. Bishop, S. E. Fienberg, and P. W. Holland. [2] J. Cadena, G. Korkmaz, C. J. Kuhlman, et al.
 [3] P. Chakraborty, P. Khadivi, B. Lewis, A. Mahendiran, [4] R. Dingledine, N. Mathewson, and P. F. Syverson. [5] A. Doyle, G. Katz, K. Summers, C. Ackermann, et al. [6] J. A. Goldstone, R. H. Bates, D. L. Epstein, et al. A [7] A. Hoegh, S. Leman, P. Saraf, and N. Ramakrishnan. [8] Y. Keneshloo, J. Cadena, G. Korkmaz, and [9] G. Korkmaz, J. Cadena, C. J. Kuhlman, A. Marathe, [10] K. Leetaru and P. Schrodt. GDELT: Global Data on [11] H. Llorens, L. Derczynski, et al. TIMEN: An Open [12] A. Mahendiran, W. Wang, J. A. S. Lira, et al. [13] S. Muthiah, B. Huang, J. Arredondo, et al. Planned [14] S. P. O X  X rien. Crisis Early Warning and Decision [15] N. Ramakrishnan, P. Butler, S. Muthiah, N. Self, et al. [16] T. Rekatsinas, S. Ghosh, S. R. Mekaru, et al. [17] J. Str  X  otgen and M. Gertz. HeidelTime: High Quality [18] N. N. Taleb. The Black Swan. The Impact of the [19] M. D. Ward, N. W. Metternich, C. Carrington, et al. [20] L. Zhao, F. Chen, et al. Unsupervised Spatial Event
