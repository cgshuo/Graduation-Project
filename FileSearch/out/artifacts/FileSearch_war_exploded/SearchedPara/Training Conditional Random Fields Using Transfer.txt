 , and Yalou Huang  X  } @nankai.edu.cn
Motivated by the desire for improving human-machine communication systems, recognizing visual gestures has been a recent topic of research. Due to its dynamic na-ture and the dependence between observations over time, gesture recognition has been formulated into a sequence labeling problem which arises from many scientific fields. Recently, Latent-Dynamic Conditional Random Fields (LD-CRF) [1], an effective extension of Conditional Random Fields (CRF) [2] , has been proposed for gesture recognition tasks in which there are transitions between the internal sub-structures as well as those between labels.
 To learn high-level features, deep architecture based on Deep Neural Network (DNN) has been widely used to enhance traditional shallow models. It is argued by a number of researchers [3] X  X 5] that DNN is powerful in learning high-level representation for the classifier. Recent research [6], [7] shows that the combination of CRF and Neural Network (NN) can achieve better performance in many tasks. How-ever, the large number of parameters introduced by coupled NN make the model difficult to train. In order to prevent the model from overfitting, it necessitates an enormous amount of labeled training data that is very expensive to acquire. In this paper, we propose a transfer learning method for CRF model. This method exploits the meaningful infor-mation in both labeled and unlabeled data to help learn high-level features for gesture recognition. A variety of transfer learning methods have been investigated [8] X  X 10] for many tasks. The basic assumption of transfer learning is that a target learning task can be enhanced by leveraging the knowledge learnt from suitable related tasks. Most transfer learning methods have achieved great improvement against the traditional learning methods. There are very limit research on transfer learning for CRF. An existing transfer learning method for CRF [11] is linear and not able to learn high-level feature from input sequences. Besides, the needed related tasks do not necessarily always exist in real world, which often makes many transfer learning methods fail.
In our work, we design a pseudo auxiliary task from the data of the main task for transfer learning. Observing that the neighboring frames of visual gesture sequence are smooth and have similar tendencies, an unsupervised se-quence model is constructed to capture such knowledge from the input sequence whether labeled or unlabeled. Acting as an auxiliary task, it can guide the learning of the parameters of hidden layers and output layers of LDCRF by jointly training, which is known as transfer learning or multitask learning [12]. Furthermore, the pseudo task can be very helpful when real auxiliary tasks are absent.

To transfer the knowledge from the auxiliary task, we first construct a deep CRF model by incorporating a convolu-tional neural network (CNN) with the LDCRF model, which is motivated by the success of [6] and [7]. The model can learn the multilayer sequence feature extractor and sequence labeling model simultaneously. Secondly, based on the deep architecture, we design a joint loss function of the unsuper-vised pseudo auxiliary learning task and the main task of LDCRF by sharing the parameters of the feature extractor. Therefore, the parameters in hidden layers can be better leant aided by the meaningful transferred knowledge from the auxiliary task. And by leveraging the abundant unlabeled data, the need of expensive labeled sequences can be largely reduced. We evaluate the algorithm on continuous gesture data. The performance of our model is much better than that of the state-of-the-art methods under both supervised and semi-supervised learning conditions.

The contributions of this work are summarized as follows. The rest of this paper is organized as follows. In Section II, we introduce the CRF and LDCRF model. In Section III, we describe the transfer learning framework for CRF, including the deep CRF, the unsupervised sequence model, and the joint training of the tasks. We then compare the proposed methods with existing representative models on different gesture recognition tasks in Section IV. In Section V, we introduce previous work that is related to this paper. Finally conclusions are given in Section VI.

In this section we first briefly review the basics of Con-ditional Random Fields. Then a recently proposed gesture recognition model LDCRF is introduced.The LDCRF is characterized by its ability to capture the intrinsic structure of sequences. Such capability particularly appealing for gesture recognition and other similar tasks.
 A. Condition Random Fields
It is widely recognized that Conditional Random Fields (CRF) [2] models are very powerful in sequence labeling tasks which arise from many scientific fields. The CRF model and its extensions are advantageous in capturing the structure of the data by modeling the transitions between different classes. In visual gesture recognition, we work with a linear chain CRF to learn a mapping from a observation sequence x = {  X  1 , X  2 ,..., X   X  } to a hidden state sequence h = {  X  1 , X  2 ,..., X   X  } . The observation vector  X   X  represnts the frame at time t. For classical CRF models, each hidden state  X  corresponds to a class label  X  , and  X  ( y  X  x ;  X  )=  X  ( h  X  x ;  X  ) A linear chain CRF defines the conditional probability of as  X  ( h  X  x ;  X  )= where  X  is a parametric potential function and  X  is a vector of linear weights. The functions  X  (  X   X  , X   X   X  1 , x , X  ) compute a set of features given the node at time  X  . Usually the functions  X (  X  ) is sum of state functions and transition functions, where  X   X  and  X   X  are feature functions.  X   X  are state functions that depend on a single hidden variable, and  X   X  are tran-sition functions that depend on pairs of hidden variables. Therefore, the set of model parameters  X  = {  X , X  } .
The partition function  X  ( x ;  X  ) is a normalization factor over all the possible states of h  X  of length  X  x  X  defined as
Typically, given a set of labeled training sequences  X  = weights can be estimated by maximizing the log-likelihood with respect to the conditional probability B. Latent-Dynamic Conditional Random Fields
In the application of gesture recognition, there are internal substructures within a gesture. For example, when a head-nod gesture is performed, the participant first moves his head down and then up which are the two substructures of the nodding gesture respectively.To capture the substructures, the LDCRF model has disjoint sets of hidden states associate with each class label. For each class label  X   X  ,  X   X   X  is the set of possible hidden states correspondingly. With this definition, the LDCRF model is defined as
Since sequences which have any  X   X   X   X  X  X   X   X  will by definition  X  ( y  X  h , x ;  X  )=0 , eq.(7) can be expressed as: The conditional probability  X  ( h  X  x ;  X  ) in the LDCRF has a formula similar to that defined in (1) and a potential similar formula to that defined in (2).

The inference for linear chain CRF and LDCRF can be performed exactly and efficiently using dynamic program-ming algorithm.

In this section, we describe the framework of the transfer learning method for CRF. In the main task, the LDCRF, an extension of standard CRF, is coupled with a deep architecture of CNN [5] to learn high-level features. Then a pseudo auxiliary task is designed to jointly learn with the main task by sharing the hidden layers. With the extra knowledge transferred from the unsupervised model of the auxiliary task, the CRF model not only exploits the structure information in labeled data, but also plays with unlabeled data.
 A. Deep CRF
In our model for visual sequence labeling tasks, we introduce a deep neural network for traditional shallow CRF model. This deep architecture automatically learns powerful nonlinear features from the raw input data, which is an extra capability not present in the shallow models. As is shown in Figure 1, the undirected graphical model is learned simultaneously with the hierarchical feed-forward layers which serve as feature extractors.

Using (1) as the expression of CRF model, we define our deep CRF as  X  ( h  X  x ;  X , X  )= where  X  = {  X  1 , X  2 ,..., X   X  } is a sequence of features learned from a raw input sequence, and each  X   X   X   X  (  X   X  ;  X  ) is a nonlinear function x  X   X   X  with parameter  X  .
 The formulas presented in (9) give an idea of learning CRF with a generic feed-forward nonlinear feature extractor  X  (  X   X  ;  X  ) . The proposed model is like a DNN which generally optimizes the classifier and hidden-layer features simultane-ously.

In the task of gesture recognition, our implementation of  X  (  X   X  ;  X  ) itself is a deep neural network with a convolutional layer and fully connected layers. The convolutional layer helps enrich each derived feature  X  with more context information, and is less sensitive to the temporal variation of gestures.

Given an input sequence x , the convolutional layer outputs another sequence c (  X  ) .The  X   X  X  X  element of the convolutional layer output at time  X  is : where  X  is the size of the kernel, and  X  is a non-linear (tanh) transformation function. After the sequential convolution step, the new sequence is fed into several classical fully connected layers: where  X  =1 ,  X  X  X  X  , X  , and the parameter vector  X  includes all the weights  X  and bias term  X  . Therefore, the overall deep CRF model contains multiple nonlinear hidden layers and one structured-output layer.

The convolutional layer provides invariance under tem-poral translation by keeping relevant local information. The higher layers learn more relevant abstract features to the classification task compared with the lower ones. This is a mature approach in feature learning used in convolutional neural networks [5]. For the general case, the convolution layers and the fully connected layers can be flexibly plugged in or removed. The model (9) is different from traditional CRF defined by (1) in its learning process. It not only learns the linear parameters, e.g.,  X  , but also optimizes the features by tuning the parameter  X  in the feature extractor  X  .This capacity of learning features is important, especially when the task is complex.
 B. Feature Function
In the deep CRF model , there are two kinds of feature functions which are state functions and transition feature functions. A state function model the dependency of a vertex and a given label. Assume  X   X  has dimension  X  ,wehave  X  X  X  X  X   X  state functions. There are  X  X  X  X  X  X  X  X  X  X  transition functions and each corresponds to a hidden state variable pair (  X , X   X  ) . The transition function is defined as: C. Unsupervised Markov Random Field Sequence Model
In this subsection, we design an unsupervised sequence model to jointly learn with the supervised deep CRF model, which constitutes a semi-supervised transfer learning frame-work for sequence learning task. In our transfer learning setting the additionally introduced auxiliary task essentially serves as a meaningful regularizer of feature extractor pa-rameter  X  .

With the multiple hidden layers, the deep CRF model is able to learn high-level abstract features from raw in-put together with the classification model. However, the hidden layers introduce more parameters into the model which increases the need of large amount labeled training data to prevent the model from overfitting. Thanks to the architecture of the deep CRF model, it is very easy to extend the model to do transfer learning with related auxiliary tasks. The basic assumption of transfer learning is that there are suitable related tasks by hand that may provide extra useful information by jointly training with the target task. The training data from such tasks helps our method learn the target model better. However, related tasks do not always exist in the real world. For our model, we design a pseudo auxiliary task from the main task for transfer learning. The model of the pseudo task not only exploits the internal information of the data, but also handles unlabeled data. When real auxiliary tasks are absent, the pseudo task can be very helpful.

The correlation between the observations provides another source of information to distill meaningful features. Taking the sequence of human action as an example, the action at the time  X  usually is the extension of the trend of action in the past several time points, that is, there usually exists some physical dependence between consecutive observations in a sequence. Intuition suggests that a meaningful feature representation must be predictive for the dynamics of the observational sequences.

Therefore, we design an unsupervised sequence model as an auxiliary task. One can decompose the distribution  X  ( x ) as a product of factors depending on its neighboring nodes: where  X  is the set of maximum cliques in the sequence, the factor  X  (  X   X  ) only depends only on the subset  X   X  .By adopting the first order neighborhood system, we have the factorized form
Next we let the feature transformation part  X  ( x  X  ;  X  ) into play, and define the above conditional probability by a form involving the transformation parameter  X  ,  X  ( x ;  X , X  )= where  X (  X   X  , X   X   X  1 ;  X  ) is a parametric potential function. The function  X   X  =  X  (  X   X  ;  X  ) is exactly the nonlinear function used by the previously defined deep CRF in (9),  X  is a parameter matrix, and  X  is a partition function. This is essential the Gibbs distribution that defines an unsupervised Markov Random Fields model. The Markov Random Fields model has been successfully used for image analysis [13]. Here we introduce an unsupervised MRF based on feature extractors to capture the variability and the interactions of the neighboring observations.

Usually the partition function  X  involves summation over the entire range of possible x which is intractable. To tackle this problem, the global likelihood is replaced by a sum of local pseudo-likelihood [14] maximize instead of the global likelihood  X  ( x ) . Then the normalization of each local likelihood is It can be very flexible to design the potential functions for the learning tasks under different application scenarios. The function defined in (17) is used to learn the dependence between the nodes of the sequence: where  X  is a  X   X   X  parameter matrix. From (9) and (14), we can see that both of the tasks share the same transformation  X  (  X   X  ;  X  ) . With some derivation, we obtain sequence model is different from traditional models in that a nonlinear transformation is learned in addition to modeling the dynamics.

Since the neighboring frames have similar tendencies, the proposed unsupervised sequence model articulates such regularities mathematically. It restricts the frame sequence filtered by hidden layers as smooth as possible. As a aux-iliary task of the transfer learning which will be described latter, this model provides an important guidance for the learning of the parameter  X  of the feature extractor  X  (  X  D. Joint Training
With the supervised model (9) and the unsupervised model (14), it is natural to consider the joint model  X  ( y , x ;  X , X , X  )=  X  ( y  X  x ;  X , X  ) that, without sharing of parameters, the two models are independent. Given labeled sequences { x (  X  ) , y (  X  ) } , X  = 1 ,  X  X  X  X  , X  , the loss function for the two tasks are defined as (18) and (19) respectively.
Letting the two models share the nonlinear feature trans-formation  X  (  X  ;  X  ) , as is shown in figure 2, we are able to develop a transfer learning framework for sequence model. The joint model aims to minimize the loss where parameter vector  X =(  X , X , X  ) . The third term is the log of a Gaussian prior with variance  X  2 , i.e.,  X  ( X )  X 
We use gradient descendent method to search for the optimal parameters. In our experiments, we use BFGS [15] to optimize the objective function. Below are some derivatives from the supervised Deep CRF of the first task: where  X   X , X  is the  X  th element of hidden feature vector  X  at time  X  . The partial derivative  X  X  X   X , X  / X  X  X   X  can be easily calculated by back propagation algorithm of neural network, which we omit them for lack of space. Note that the marginal probabilities  X  (  X , X   X  )  X  x ) can be computed efficiently using belief propagation [16].

For the second task, we have the derivatives w.r.t. pa-rameter matrix  X  and parameter  X  of the hidden layers respectively, where  X  =  X   X   X   X   X  1  X   X   X , X  , and  X  X  X   X , X  / X  X  X   X  can be also calculated by back propagation algorithm of neural network. E. Training with Unlabeled Data
Manually labeling data can be very expensive, while the unlabeled data are usually abundant and easy to obtain. With the unsupervised sequence model, it is very straightforward to use unlabeled data when training. Given labeled se-quences { x (  X  ) , y (  X  ) } , X  =1 ,  X  X  X  X  , X  , and unlabeled sequence { x (  X  ) } , X  =  X  +1 ,  X  X  X  X  , X  +  X  , we get a semi-supervised sequence model minimizing the similar loss with (20), while the  X  1 and  X  2 are slightly changed:
In the joint training of the two learning tasks, the same gradient descendent optimization technique, BFGS, is per-formed to search the optimal parameters.
 F. Inference
In this transfer learning framework for CRF, the main task is jointly trained with the auxiliary to boost the generaliza-tion and make use of the unlabeled data. In the testing phase, given a new test sequence x , only the model of the main task, deep CRF, is used to estimate the most probable label sequence y  X  that maximizes our conditional model:
By associating a disjoint set of hidden states with each class label, the previous equation can be expressed by:
As we mentioned in the previous subsection, we use belief propagation to compute the marginal probability  X  (  X   X  =  X   X  x ,  X ) for each possible states  X   X  X  X  . The marginal probabilities are summed according to the disjoint set of hidden states  X   X   X  . Then the predicted label  X   X   X  is the one associated the maximum sum of marginal probabilities.
To demonstrate the effectiveness of the proposed model on real world problems, we test our model on three different vi-sual gesture recognition datasets [1]: (1) AvatarEye consists of eye gaze estimates from 6 human participants X  interaction with a virtual embodied agent. The goal is to recognize gaze aversion gestures from unsegmented video sequences. (2) MelHead consists of head velocities from 16 human participants interacting with a robot. The goal is to label each frame as head-nod or other-gesture. (3) WidgetHead is another head gesture dataset consists of head velocities from 12 participants who interacted with gesture-based widgets. All the three datasets are manually annotated for ground truth. The eye gesture recognition task has labels  X  = { eye gaze , other -gesture } . Both the two head gesture recognition tasks have labels  X  = { head -nod , other -gesture } .
Because each dataset contains a large amount of  X  X ther-gesture X  frames, we perform some preprocessing to make the datsets smaller and reduce the training time, which doesn X  X  affect the evaluation of the methods. The long sequences are broken into unsegmented subsequences. Each subsequence consists of one complete target gesture (head-nod or eye-gaze) subsequences and the non-target gesture frames before and after the subsequence. The length of the non-target gesture subsequences in the unsegmented subsequences is randomly chosen. The resulted datasets contain all the target gesture subsequences in the original datasets, and the amount of non-target gesture frames is twice as much as the target gesture frames, which keeps the unbalanced characteristic of the datasets. As the result, there are 72 sequences in Avatar-Eye, 244 sequences in WidgetHead, and 152 sequences in MelHead. To compare the performance, we use the receiver operation characteristic (ROC) curve and the area under the ROC curve (AUC) for evaluation.
 A. Models
To verify the effectiveness of our proposed transfer learning architecture for CRF, we compared our transfer learning CRF model with several baseline methods. The baseline methods can be categorized into two classes, i.e. sequence models such as CRF, LDCRF, and non-sequence models such as SVM, NN. Moreover, the methods can be orthogonally classified as deep learning models such as NN, and shallow learning models for the others. Each baseline method is tuned with window size  X  =1 , 3 , 5 .

The first baseline model is a standard CRF model with each hidden states  X  corresponds to a label of the gesture frames  X  . A LDCRF model is trained with a set of hidden states associated to each label, and the number of states per label is varied from 3 to 6 during training. The non-sequential models, SVM and NN, are trained on frame-based samples. The SVM model is a shallow learning model with a Radial Basis Function (RBF) kernel. The NN model is a deep learning model , whose hidden layers consists of one convolutional layer and two fully connected layers. Our proposed method is tested under 2 configurations. D-LDCRF : It is a Deep LDCRF model as shown in Figure(1), with the output layer being standard LDCRF loss function. The hidden layers consists of one convolutional layer and two fully connected layers. The kernel size is validated with  X  =1 , 3 , 5 .

D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  : It consists of a similar target task loss function to D-LDCRF and a loss function from the pseudo auxiliary task described in Section III-C. By transferring knowledge through the feature extractor, the loss functions from two tasks are jointly trained.
 B. Supervised Learning Experimental Results
In the supervised learning experiments, we run 3-fold cross validation on the three datasets. All of the models are trained on the whole labeled training set. For the model with transfer learning, D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  , the target task and the auxiliary task are fed with all the training sequences. Under such situation, the transfer learning models utilize no extra data but more meaningful regularization information provided by the pseudo task.
 Figure 3 shows the ROC results with the three datasets. The curves of the baseline methods are slight different with those in [1], because we preprocess the data differently. From the results, we can draw same conclusion as in [6] and [7] that the deep model D-LDCRF outperforms its shallow counterparts, LDCRF, and it is interesting to note that NN also achieves better performance than shallow SVM. Furthermore, it is important to note that transfer learning with the pseudo task does provide useful information which makes the D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  further improve the D-LDCRF performance.

For better understanding the capacity of the models, we plot the prediction probability on some randomly selected test subsequences, as is shown in Figure 4 from which we can see that the D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  has much more certainty and accuracy than the LDCRF and CRF.
 C. Semi-supervised Learning Experimental Results
To test the effectiveness of transferring knowledge from pseudo task when labeled data are limited and unlabeled data are available, we conduct semi-supervised learning experiments on the three datasets.

We train the models with variously randomly selected 5% , 10 %15 % , 20% , and 25% of the training sequences to examine the models X  performance given different training sizes. We report the average AUC as well as standard deviation of 3 trials of each training size.

Figure 5 shows the representative models of Deep se-quence modles and shallow sequence models. We plot D-LDCRF, D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  , LDCRF, and CRF for clear demonstration of the comparison. It is obvious that D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  performs the best on each dataset with the aid of unlabeled data. However, the D-LDCRF without transfer learning produced poor results even compared with the shallow models. This is due to the insufficient training data for its large amount of parameters. With the aid of transfer learning, the performance is boosted a large margin, as is shown by the results of D-LDCRF  X  X  X  X  X  X  X  X  X  X  X  X  .
Figure 6 plots the likelihood curves on some randomly se-lected test sequences which are catenated for demonstration. The models are trained on unlabeled sequences and 20% labeled sequences. It is obvious that the using of unlabeled data makes the model more certainty on the prediction.
Figure 7 plots the similarity pattern of the raw feature and learned feature of a test sequence from AvatarEye gesture data (there are similar results on other datasets, which are omit due to the limitation of space). The plotted data are the frames of an unsegmented sequence with positive frames located at the center of the sequence. The data are indexed by the frame number. The pattern of Figure 7(a) plots the frame-frame similarity of a raw input. The projected data in Figure 7(b) is the frame-frame similarity of the hidden feature output by the hidden layers of a trained model with 16 labeled training sequences. It is obvious that the learned feature shows more block-like within the same class while the pattern of the raw sequence are more dissimilar. Furthermore, Figure 7(c) shows the hidden feature output by a deep CRF transfer learning model which trained with 10% labeled training sequences and the other training sequence as unlabeled training data. Attributed to our transfer learning method for the deep CRF, the block is even more clear than the other two patterns.

In sequence labeling tasks, CRF [2] and its related models have achieved state-of-the-art performance. The standard CRF can model the interactions between labels, which offers them the ability to learn the structures and dynamics of sequence data. CRF have been applied successfully to many sequence labeling tasks such as Natural Language Processing [17] [18] [19] [20], bioinformatics [21] [22], and computer vision [23] [24] etc. Observing that each class has distinct substructures, Hidden-state Conditional Random Fields has been proposed to capture the intrinsic dynamic for object recognition [25] and segmented gesture recognition [26]. For unsegmented gesture sequence label-ing, LDCRF [1] combines the strength of HCRF and CRF and achieves the best performance in head gesture and eye gesture recognition. Lafferty et al. [27] present a kernelized version of linear CRF to enable nonlinear mapping. A similar model on combining neural network and CRF [6] was proposed for the same purpose recently, which achieves good results in several sequence labeling tasks and less costive in computation than kernel CRF. However, these models are still shallow compare with our model and not able to transfer knowledge between multiple tasks.
Although much work has been done in transfer learning [8] X  X 10], there is very limited research on transfer learning for CRF models. Sutton and McCallum propose a method to transfer knowledge for CRF from old tasks to new tasks [11]. For the similar purpose, Arnold et al. [28] proposed hierarchical feature tree priors for transfer learning on named entity extraction tasks. Since the tasks are trained separately and sequentially, there is limitation when it is hard to decide the training order of the tasks. Without much effort, our model can be apply to different transfer learning scenarios such as domain adaption and multi-task learning. Further-more, compared with the model we proposed, they are not semi-supervised models.

Under the framework of transfer learning, our method provides a natural way to exploit both labeled and unlabeled data, which is know as semi-supervised learning. It is widely recognized that unlabeled data are of great value to reduce the cost of labeling data and improve the generalization. There have been developed many popular semi-supervised models, such as co-training [29], graph-based methods [30], and entropy minimization methods [31], etc. However, there are much less semi-supervised method for sequence models like CRF. Jiao et al. [32] extended the entropy minimization method to linear-chain CRF, which used the label entropy on unlabeled data as a regularization. This kind of methods are known to be fragile. Furthermore, it makes an assumption that there are minimal overlaps between labels that need to compute the entropy. So one can only make use of unlabeled data from the same source, or know all of the possible labels at least. The regularization in our model dose not make any assumption about the probability distribution over label sequences, which makes our model work without any information about the labels of the unlabeled data. Hence it potentially can be extended to make use the data from different tasks.

A wide range of recent work has shown the power of deep models for difficult recognition tasks. Yu et al. [33] present transfer learning methods based on DNN. Their work differs from ours in that they use a standard CNN and deal with i.i.d. data, we focus on the structured data, i.e. sequence data, with complex dependencies between data nodes. Weston et al. [34] propose a TDNN [35] method for NLP tasks, where there are sequence data involved. In the work of [36], the authors apply CNN for object recognition task in video. These approaches are related to ours in using sequence convolution to learn hierarchical features within a sequence. But our model is essentially different in its structured output space, which captures the interactions between labels as well as observations. Besides, we design an unsupervised model for the interaction between observations as well as that between hidden states in CRF. By jointly training, the proposed transfer learning architecture gives a novel approach to leverage unlabeled sequence data.

The research on transfer learning for sequence data is limited. In this work we proposed a deep algorithm of transfer learning for sequence models to enhance the high-level feature learning. By taking advantage the structure information, we constructed an unsupervised MRF sequence model as an auxiliary pseudo task. With shared parameters through feature extractor, the dependence between neigh-boring frames acts as a meaningful regularizer and guides the learning of the parameters in the feature extractor. Moreover, the joint learning with the pseudo task that leverages unlabeled data naturally turns the proposed deep sequence model into a semi-supervised learning method. The experimental results of supervised learning and semi-supervised learning demonstrates the superior performance of the proposed transfer learning method for CRF model in gesture recognition tasks. we will apply our algorithm to other sequence labeling applications besides gesture recog-nition and w.

In this work, the auxiliary task is created from the main task. In fact, our model is readily to extend to make use of the data that could be labeled differently from the main task or unlabeled from related tasks. In future work, we will extend our model to learn other kinds of settings of the auxiliary tasks. Furthermore, it is also worth to apply our algorithm to other sequence labeling applications besides gesture recognition.

