 1. Introduction 1.1. Artificial neural networks  X  prediction tools in Transportation engineering
Artificial neural network models (or neural networks hereafter) are receiving more and more attention in the various aspects of transportation engineering due to their modelling flexibility, predictive ability and generalization potential. Their application ranges from traffic operations ( Van Lint et al., 2005; Smith and
Demetsky, 1995; Chien et al., 1994; Dharia and Adeli, 2003 ), incident detection and prediction ( Xie et al., 2007; Dia and Rose, 1998 ) and transportation planning ( Dia and Panwai, 2007; Tillema et al., 2006 ) to infrastructure management ( Yang et al., 2006;
Mukkamala and Sung, 2003 ) and environmental studies ( Cai et al., 2009; Shiva Nagendra and Khare, 2004 ). Neural networks have also been adopted in the public transport context to model bus travel times ( Kalaputapu and Demetsky, 1995; Jeong and Rilett, 2004; Chen et al., 2007 ).

Traditionally,neuralnetworksusedforpredictionpurposesgive rise to a point prediction when they are presented with a set of input values. However, there is always a degree of uncertainty associated with any point prediction. That uncertainty, as will be the model or the inherent uncertainty in the dataset used for model development. Due to these reasons, point prediction performance deteriorates and predictions become unreliable. 1.2. Knowledge of prediction uncertainty  X  applications in Transportation engineering
A common problem associated with point predictions is that they deliver no information about different kinds of uncertainty affecting the prediction performance. However, the reliability of point predictions can be enhanced through providing a measure of prediction uncertainty ( Khosravi et al., 2010a ), or at least by quantifying the extent that each different source contributes into prediction unreliability. This issue has motivated some studies in the transportation literature to provide a prediction range, rather than a point prediction, for the relevant dependent variable.
Inherently, the width of these ranges is directly related to the degree of confidence in the point predictions. For instance, studies focussed on predicting travel time variability provide a measure of uncertainty in travel time prediction by quantifying the variance of et al., 2005; Li, 2006 ). These variance values, which indicate the passengers by helping them to better plan their trips, hence would have a range of applications in intelligent transportation systems.
In public transport operations, predicting a range for travel times can assist in defining slack times needed in the scheduling process to maximize on-time performance ( Mazloumi et al., 2010 ). The quality of transit signal priority schemes can also be enhanced by downstream signalized intersection ( Kim and Rilett, 2005 ). 1.3. Quantifying the uncertainty in predictions made by neural networks  X  research objectives
To cope with the weakness of neural networks in providing prediction confidence, one approach is to specify intervals (rather than points) where predictions may lie with a predefined like-lihood. Depending on what source of uncertainty is considered by these intervals, different terms are used to specify these measures ofconfidence,i.e.confidenceintervalsorpredictionintervals.Many previous researchers have quantified confidence intervals. For instance, Van Hinsbergen et al. (2009) and Park and Lee (2004) used Bayesian technique to construct confidence intervals for travel time predictions made by neural networks. From a Bayesian inference perspective, each parameter in a neural network is conceived as a distribution rather than a single value. Conse-quently, neural network outcomes will also form a distribution, which can be further used to construct intervals around each prediction point. However, the computationally intensive nature of
Bayesian technique has limited the application of this approach in confidence estimation for neural network predictions ( Dybowski andRoberts, 2001 ). However,tothebestofourknowledge,nowork has been completed to construct prediction intervals for neural networks employed in transportation applications.

This paper contributes to understand this domain by demon-strating a relatively straightforward approach, founded in max-imum likelihood techniques, for constructing prediction intervals.
The maximum likelihood approach, as opposed to the Bayesian algorithm,willgiverisetoasingle value(ratherthanadistribution) for each model parameter and hence for output values. The paper firstdiscussesthepossiblesourcesofuncertaintyinneuralnetwork predictions. Then, following a general description of neural net-works,theconceptsofconfidenceintervalsandpredictionintervals are presented and techniques to quantify each of them are discussed. The proposed methodology is then applied to predict bus travel times along a bus route in Melbourne, Australia, and its performance is evaluated. The final section of the paper presents the conclusions and identifies directions for future research. 2. Sources of uncertainty
In the neural network community, it is common to consider two sources for uncertainty associated with neural network outcomes: uncertainty in training dataset and uncertainty in model structure ( Heskes, 1997; Papadopoulos et al., 2001; Dybowski and Roberts, 2001 ). Those sources are discussed separately in the subsections which follow. 2.1. Uncertainty in training dataset to the inherent uncertainty in the input data. This uncertainty in randomly selecting a training dataset from the associated popula-time prediction might be related to a range of stochastic factors, variables have stochastic characteristics and are difficult, or even impossible, to model with deterministic variables.

Consequently, not all the possible realizations of the dependent variable are available in the training dataset, and the training dataset used to train a neural network is only one of a large number a different neural network, there could be a distribution for output values when certain input values are given. Note that in many practical problems, both input and target values might be asso-ciated with an uncertainty or a noise because of imperfections in data collection tools or techniques. However, in the analysis presented in this paper, it is assumed that there is no noise associated with data acquisition. 2.2. Uncertainty in model structure
Model uncertainty variance (measured by the variance denoted by s 2 m ) contributes to total prediction uncertainty in two ways:
There is always an uncertainty in the values of the neural networkparameterssincean errorfunctioncanhavemanylocal minima resulting in a number of possible values for network weights. In addition, suboptimal training, e.g. premature ter-mination of a training algorithm, may introduce bias in model weights which is another source of uncertainty.

As for regression techniques, neural networks are also prone to structural misspecification. The lack of input variables that can adequately model the dependent variable is an example of a model misspecification, which introduces uncertainty in pre-diction outcomes.

It is common to assume that s 2 e and s 2 m are independent and total prediction variance s 2 t can be obtained from s 2 t ( Heskes, 1997; Papadopoulos et al., 2001; Dybowski and Roberts, the prediction confidence of a neural network, and to quantify how these sources might affect the prediction confidence. To this end, there could be two statistical measures of confidence, confidence a neural network. The next section differentiates between those two measures. 3. Methodology
In this section, the general mathematical structure of a neural network is presented as a foundation for the discussion which follows. Subsequent sections focus on quantification of s 2 3.1. General description of feed forward neural networks
Let us assume that we are interested in developing a neural network to model target values t n  X  X  t n 1 , ::: , t n d x n  X  X  x n 1 , ::: , x n e  X  from a dataset of X  X  X  x 1 , poses, we consider a neural network that consists of input, hidden and output layers as shown in Fig. 1 . The input layer may contain e input nodes, the hidden layer h and the output layer d nodes. The input layer receives the input values which are processed through the network to give rise to output values y  X  x n  X  X  X  y 1 The hidden layer is actually the main estimation core of the model. There could be several hidden layers, but one hidden layer is sufficient to closely map most relationships ( Jain and Nag, 1997 ).
The mathematical expression of how the neural network following equations: y  X  x  X  X  f o where w jk and w ij are the network weights whose values are calibrated from the training data. The functions f o and f sponding to output and hidden nodes, respectively) are activation functions transforming the weighted sum of the outputs in the left of each node. While a range of transfer functions are available (including logistic, hyperbolic and sigmoid functions), the sigmoid function f h ()commonlyassociateshiddenlayersinmosttraveltime prediction models ( Van Lint, 2004; Liu, 2008 ). A linear activation function f o () is also commonly used for the output nodes f  X  a  X  X  where y j is called bias associated with hidden node j , which also needs to be adjusted based onthe data.Biases togetherwith weight values will form the vector of model parameters W . 3.2. Training a neural network
Calibration of neural network parameters is achieved through a training process. This training mechanism is normally based on maximum likelihood approach that seeks to find the optimum parameter values by maximizing likelihood derived from the training data. As shown by Bishop (1995) , this approach is equivalent to the minimization of an error function such as the sum of squared errors of the predictions as formulated in the following: E  X  1 2
However, other error functions exist in literature such as root mean squared error (RMSE), mean absolute percentage error (MAPE), etc. Qi and Zhang (2001) have compared these criteria forselectingtheoptimalneuralnetworkparametersandconcluded that there is no best method.

Trainingof a neural network ultimatelyaims to develop a model that predicts well on new, unseen test examples, i.e. it generalizes well. A superior approach to ensure a good generalization ability is
Bayesian regularized back-propagation approach ( Bishop, 1995 ) that uses the Levenberg X  X arquardt ( Hagan and Menhaj, 1999 ) algorithm to minimize a linear combination of prediction error E and weights E  X  E
D  X  a E W  X  4  X  of the weight regularizer on the solution, and is determined such of this form can lead to considerable improvements in network networkwill lead tosmall weightsthat inturnhave thepotential to help in having a good generalization ( Bishop, 1995 ). 3.3. Measures of prediction confidence: confidence intervals versus prediction intervals
First, assumethat g  X  x n ; w o  X  isthe  X  X rue X  unknownneuralnetwork that generated target vector t n , where w o is the  X  X rue X  vector of model parameters. For simplicity, assume that both vectors x t are one dimensional, so t  X  g  X  x i ; w o  X  X  e i i  X  1 , ::: , N  X  5  X  where e i is an error term with the average zero and variance s 2
Within the training process, the unknown function g  X  x i estimated by finding the best estimates ^ w o for w o . Minimizing the error function in Eq. (3) will yield a set of outputs y average of target values given the input vector x i , E  X  t y  X  g  X  x i ; ^ w o  X  E  X  t 9 x i  X  6  X  the estimation of the true but unknown function g  X  x i ; w concerned with the distribution of the quantity g  X  x ; w o  X  g  X  x i ; ^ w o  X  X  g  X  x i ; w o  X  y i  X  7  X  accuracy of prediction outputs by focussing on the distribution of the quantity t g  X  x i ; w o  X  X  t i y i  X  8  X 
Thus, a CI is concerned with that part of the prediction uncertainty which is caused by the model inability to capture the  X  X rue X  unknown g  X  x is always enclosed in its corresponding PI. To better understand relationship between the network prediction y i  X  g l  X  x value t i , the unknown underlying function g  X  x i ; w o 3.4. Quantifying model structure uncertainty variance
This section discusses how model structure uncertainty s 2 be quantified through constructing confidence intervals.
Generally,threemainapproacheshavebeenused forestimating prediction confidence: Bayesian framework based on Bayesian based on a Taylor expansion of the regression function ( Khosravi et al., 2010b ) and the Bootstrap method which is essentially a resampling method ( Van Lint, 2004, Li, 2006 ). Papadopoulos et al. (2001) and Dybowski and Roberts (2001) elaborate on the pros and cons of these techniques. However, there is no distinct preference reported in the literature for any of these techniques.
The latter approach, the Bootstrap method, is chosen in this study to construct the confidence intervals for two reasons. First, unlike the Bayesian framework that involves the computation of a
Hessian matrix, which limits its use in many applications ( Dybowski and Roberts, 2001 ), the bootstrap is efficient and relatively easy method to implement in both research and practice ( Li, 2006 ). In addition, unlike the Delta method, the Bootstrap method gives rise to input-dependent values for variance ( Dybowski and Roberts, 2001 ).

TheBootstraptechniqueestimatesthestandarderrorofamodel parameter ( Efron, 1982 ), so it can be used to estimate s 2 on resampling with replacement of the available dataset and training an individual network on each resampled subset of the original dataset. A resample dataset D has the form of  X  x the resampled sets is equal to the size of the original dataset N ,a resampled set may contain some input X  X utput pairs more than once while other pairs may not be present at all. If there are B resampled sets, a collection of B networks of the same architecture is formed, and the variance of the outputs of individual networks is for a neural network are as follows:
Randomly draw B independent bootstrap samples from the training dataset of size N . Each sample consists of N pairs of input X  X utput variables.

Train a neural network with each sample. Corresponding to a certain input value x i , the estimate from neural network trained on the b th, b  X  1, y , B bootstrap sample is y b  X  x i  X  .
Estimate the model uncertainty variance s 2 m associated with input value x i using the outputs of the B alternative networks s 2  X  x i  X  X  y  X  x i  X  X 
Assuming that target values follow a Normal distribution, the 95% confidence intervals are then constructed using  X  y 7 Z a s m  X  and Z a  X  1 : 96. Corresponding to each input vector x a 95% confidence interval implicates a range where the mean of a worthnotingthatbustraveltimeshavebeenshowntofollowanormal distribution under normal condi tions and narrow departure time windows ( Mazloumi et al., 2010 ). For the case when travel times 3.5. Quantifying input data noise variance
To quantify the uncertainty s 2 e caused by error term e i input data, maximum likelihood based approaches can be adopted which unlike the computationally intensive Bayesian mechanism extended the traditional network structure and used a new set of hidden units to compute s 2 e . Their approach changes the network error function leading to the reformulation of weight updating equations in training algorithms which in turn required massive computational effort. Unlike that method, which is not easily implementable in many existing commercial tools, the method adopted in this study is more straightforward.

The variance of t conditioned on (or given) x i , Var  X  t calculated from Var  X  t 9 x i  X  X  E  X  X  E  X  t 9 x i t  X  2 9 x i  X  11  X  On the other hand, from Eqs. (3) and (6), one can conclude that if Eq. (3) is used to train a neural network, for each input x network f  X  x i ; v o  X  with the same input values and the objective function in Eq. (12) will give rise to estimates of Var  X  t E  X  f  X  x i ; v o  X  uses the same input values and the same objective function (as shown in Eq. (3)), but the target values are the square of the f  X  x i ; v o  X  is also associated with uncertainty in its structure which can be also captured through a bootstrap analysis. Therefore s 2  X  Var  X  t 9 x i  X  X  s 2 m 2  X  13  X  constructed by adopting  X  y i 7 1 : 96 s t  X  for each input vector x the dependent variable would occur with 95% probability. 4. Case study
The methodology detailed in the previous section is used to examine the impact of different sources of uncertainty in travel time predictions in the context of an 8-km-long portion of a bus route in inner Melbourne, Australia. This portion of the route comprises four sections (which are similar in length) and are demarcated by five timing point stops (see Fig. 3 ). Those timing points are the major bus stops and at each of them, bus arrival/ departure times are monitored to maintain consistency and track schedule adherence. Bus headways vary from 10 min in peak hours to about half an hour in the off-peak. Buses on this portion of the route operate in mixed traffic and there is no separate lane allocated to buses. 4.1. Data
Some of the buses (not all of them) over this route were equipped with GPS devices, and their arrival/departure times corresponding to timing point stops were recorded. About 1800 weekday travel time observations were obtained for each route section over a six month period (starting from February 2007). presentation reveals the considerable variability of travel times at the same time of day for each section. For instance, travel times in
Section 2 at 2:00 pm, range from about 200 s to just over 500 s over different days. This may be due to a range of factors including variationsin passenger demand and traffic flowover different days, various signal delays experienced by different buses, and variation that travel times for each section can be classified into four time periods: AM peak (7 am X 10 am), inter peak (10 am X 4 pm), PM peak (4 pm X 7 pm) and off-peak (before 7 am and after 7 pm). This taxonomy will be used later to assess the performance of the proposed methodology by time period.

The study aims to construct confidence and prediction intervals for each route section. To this end, a set of explanatory variables was needed. The selection of explanatory variables was guided by evidencefound inliterature( Mazloumietal.,2010 ) ofkeyvariables in bus travel time prediction. Traffic flow data collected by
SCATS loop detectors was available from each intermediate signa-lized intersection. SCATS data included traffic counts and traffic degree of saturation values averaged over a predefined aggregation period before departure of each bus from an upstream timing point stop. Four different aggregation period lengths are considered: 2, 15, 30 and 60 min. It is worth noting that while traffic counts reflect the fluctuations in demand, degree of saturation values, defined as the ratio of the effectively used green time to the total available green time for each movement ( Lee et al., 2002 ), capture the changes in both demand and capacity (signal cycle and green time lengths).

Also available were data on weather conditions in terms of the hourly amount of rain that fell over the corresponding one hour period, and a measure of schedule adherence quantified by subtracting the observed arrival time from scheduled arrival time for each bus at the upstream timing point stop (i.e. before entering the section). The next section briefly explains how the study 100 200 300 400 500 600 700 800 900
Travel time (second) 0 100 200 300 400 500 600 700 800 900 100 200 300 400 500 600 700 800 900
Travel time (second) 0 100 200 300 400 500 600 700 800 900 selected the input variables and the aggregation period which lead to the most accurate predictions. 4.2. Input variable (feature) selection
The performance of a neural network often deteriorates when the number of input variables increases, i.e. the dimension of input space increases.Thishasbeenreferredas the curse of dimensionality in the literature ( Bellman, 1961; Bishop, 1995 ). This phenomenon may lead to the choice of irrelevant input variables for modelling, which may unnecessarily increase model complexity and hence lead to a poor generalization. Increasing the number of input variables also leads to neural networks needing more training examples to effectively understand the input X  X utput relationship. However, dataset size is limited in many applications.
Feature selection techniques have been applied in many pro-blems to reduce dimensionality ( Srivastava et al., 2000; Khosravi et al., 2007 ) to either the original input variables or to a set of features constructed through combining original input variables.
These techniques discard those inputs which carry little useful information to solve the problem ( Peng et al., 2005 ). One approach in this realm is principal component analysis (PCA) which com-bines inputs together to produce a smaller set of features, called principal components ( Jolliffe, 2002 ). Principal components are linear combinations of the original variables, and are orthogonal to each other, so there is no redundant information. However, the results of this technique will never give the importance of original dependent variable.

An alternative approach to identify irrelevant input variables and to explore the impact of individual input variables on a dependent variable is to use statistical techniques such as a regression analysis ( Li, 2006 ). These techniques compensate for the inability of the neural network approach to provide insight into the statistical significance of particular explanatory variables.
Mazloumi et al. (2009) used the same dataset (as used in this paper) to evaluate the value of traffic flow data in predicting bus traveltimeand employeda regression analysis to identifytheinput variables for their neural network prediction model. It was suggested that to predict bus travel time for each section, the input variables should include the average of saturation degree (i.e.aggregationperiodequalsto15 min)fromtheupstreamtiming point stop along with the schedule adherence at the upstream before each bus enters each route section. The next section adopts these variables for modelling purposes. 4.3. Development of neural network models
Theproposedmethodworkswithtwoneuralnetworks.Thefirst network g  X  x i ; w o  X  predictstheaveragetraveltimegivenacertainset of input values x i , whereas the second neural network f  X  x predicts the variance imposed by training data noise. Following a conventional approach to train neural networks, we randomly split up the travel time dataset of each section into a training dataset and a testing dataset. Out of the 1800 travel time observa-tions available for each section, 80% were randomly selected for training the networks, and the remaining 20% were set aside for testing the networks. To make sure that the prediction results are not biased to certain travel times, this task is undertaken 10 times (i.e. we randomly select the training and testing sets 10 times). Therefore, the results reported hereafter are the average on 10 different training sets (when developing the models in this section) and on 10 testing sets (when testing the models in Section 5).
To develop a neural network, two features of the network have to be determined including the number of hidden layers and the number of neurons in each layer. This is a trade-off between model estimation capability and its generalizing ability. As the number of hidden layer neurons increases, the model becomes more prone to over-fitting of the data hence to poor generalization. On the other hand,asmallnumberofneuronsinamodelmaynot besufficientto efficiently describe the complexity of the underlying problem.
To assist in determining the optimum number of hidden neurons,constructive/destructivealgorithms(alsoknownas grow-ing and pruning algorithms) and evolution techniques can be employed. The former algorithms start with an extreme network (either small or large) and neurons are added or removed step by step until a predetermined criterion is met. The problem with constructive algorithms is that they are usually trapped in local minima and often lead to big networks ( Angeline et al., 1994 ). The drawback of destructive algorithms is also related to the assign-ment of credit to the structural components of the network in order to decide whether a connection or node must be removed ( Garcia-Pedrajas et al., 2003 ). The problematic issue with evolutionary based techniques is their massive computation requirements that make them impractical in many real world applications ( Khosravi et al., 2010a ).

The networks developed in this paper consist of one hidden layer neuron that has been shown to be sufficient to closely map any relationship ( Bishop, 1995 ). To determine the number of hidden layer neurons, a traditional approach is the widely accepted trial and error process. In this study, we use a k -fold cross-validation method ( k  X  5) applied on the training dataset, to test several network structures with differing numbers of hidden layer neuron. For each model, the root mean squared error (RMSE) is selected
RMSE  X 
Table1 reportsthechangeintheperformanceof g  X  x i ; w o  X  (which predicts the average travel time) with respect to the number of hidden layer neurons adopted. Similarly, the results reported in of travel times) to the number of hidden layer neurons. In each table, the best model results are underlined for each section. 5. Results
To predict the average travel time for each section, the best g  X  x ; w o  X  model is selected on the basis of the results reported in each model is now applied on the testing dataset (i.e. 20% of the travel times that have been put aside). The results reported in
Table 3 illustrate model performance (in terms of RMSE) by time period. Except for Section 4, the poorest model performance is in peak periods. In Section 4 there is also a peak in inter peak travel period (when the RMSE reaches 113 s), may be explained by factors which are not captured in the model.

We now turn to quantify separately the effect of model structure ffiffiffiffiffiffiffi s 2 p and input data noise total prediction uncertainty is also computed as understand the contribution of each source of uncertainty to total uncertainty. Table 4 shows the results of this investigation, where model structure is shown to have a minor effect on total uncertainty compared to that produced by training data noise. For example, consider the results of Section 1, access the whole day (that is the of 94 s, the total uncertainty (considering uncertainty from both minor component of total uncertainty.

To quantitatively explore the performance of PIs, one approach is to compare the prediction interval coverage probability (PICP) to the expected coverage probability. Mathematically, PICP is defined as PICP  X  1 n where c i  X  1if y i A  X  L  X  x i  X  , U  X  x i  X  ,otherwise c input value x i , y i is the model prediction, and L  X  x i lower and upper bounds of the prediction interval. It is expected that the 95% prediction intervals encompass the observed travel method outlined in this paper leads to very robust prediction intervals capable of encompassing observed travel times in accor-dance with expectations. However, there are persistent signs of overestimation in off-peak hours where the PICP values are higher than 95%. We theorize that the proposed method results could be improved if data on other potentially relevant explanatory vari-ables, such as passenger demand, were available. 6. Summary and conclusion
Despite existing reports of the successful exploitation of neural networks, the predictions made by neural networks are always associated with neural network outcomes were discussed, includinguncertaintyarisingfrominherent noiseininput data,and that due to model structure. Two alternative measures were also introduced to quantify how different uncertainty sources contri-bute to total prediction uncertainty. Confidence intervals measure the uncertainty in model structure, while prediction intervals are concerned with total variance. To construct confidence intervals corresponding to each input value set, a Bootstraping analysis was employed, while a maximum likelihood based approach was used to quantify the variance in input data.

The proposed methodology was applied in the context of predicting bus travel time over different sections of a bus route in Melbourne, Australia. The travel time for each section of the route was modelled as a function of traffic saturation degree values and a measure of schedule adherence. The results of this applica-tion revealed that a major portion of uncertainty in predictions is nature of some key factors like signal delay or dwell time. Overall, the proposed approach has proved to provide robust prediction intervals around prediction values.

The approach proposed here to construct prediction intervals is effective (in terms of accuracy) and efficient (from an ease of implementation perspective). As a result, it can be regarded as a promising means for both researchers and practitioners to statis-tically explore neural network outputs. The prediction intervals it provides can be disseminated to travellers through traveller information systems to enable them to efficiently plan their trips.
In the context of public transport, the proposed framework can be a promising means to help operators in developing timetables and defining slack times to maximize on-time performance. Compara-tive research exploring other techniques for confidence estimation is a promising direction for future research. Meanwhile, inclusion of other variables affecting bus travel time, such as passenger demand, may lead to more reliable model outcomes and more accurate prediction intervals.
 Acknowledgment
The authors would like to acknowledge Ventura Bus Company and VicRoads for supplying the GPS and SCATS data, respectively, for this research.
 References
