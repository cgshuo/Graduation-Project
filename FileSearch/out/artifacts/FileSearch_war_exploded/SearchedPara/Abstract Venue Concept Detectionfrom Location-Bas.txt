 With the advent of online social networks such as Facebook, Foursquare, etc., geo-tagging has become a popular activity online where people broadcast their location [ 1 , 2 ]. Such geo-tagged information can be useful to advertisers who want to recommend a venue or a product based on the user X  X  past movement patterns or construct more interesting lifestyle patterns as proposed in [ 3 ], where rather than estimating lifestyles from the check-in data directly, we can first convert each check-in to an abstract data, in which the specific name of the venue can be replaced by an abstract name. This will help mitigate sparsity problem to a large extent. We present a novel generative probabilistic model that exploits textual information obtained from location-based social networks (LBSNs) to uncover meaningful latent concepts related to venues, or Point of Interest (POI). We call such automatically discovered concepts  X  X bstract venue concepts X . For example, a concept representing  X  X pscale hotels X  may be discovered and it may contain representative terms such as  X  X ive-star X ,  X  X uxury X ,  X  X xpensive X , etc. Abstract venue concepts enable semantic characterization of venues, facilitating a better understanding of venues for both users and service providers, which could poten-tially benefit services such as venue recommendation [ 4 ]. While we could use the categories provided by Foursquare and similar services, the taxonomies which are used by these LBSNs are not always sufficiently fine-grained. For example, by investigating the category tree 1 of Foursquare, we can easily observe that the LBSN assigns all types of hotels the to same category hotel , rather than distinguishing finer properties of the hotel, such as  X  X pscale hotel X . Moreover, these taxonomies are LBSN-specific, which causes problems when we want to integrate check-in data from different LBSNs.
 Text data obtained from LBSNs has also been used in geographical discovery to elicit the semantic concepts of venues with aggregated text data from venue profiles. However, we observe that the text data in venue profiles originates from two different sources. The first source is tags , which is a set of discrete terms describing the intrinsic properties of the venue, e.g.  X  X otels X ,  X  X hopping mall X , etc. Tags are usually drawn from a relatively fixed word lexicon. The second source is comments , which are sentences written by users expressing their opinions about the venue. The linguistic property of comments is rather different from tags in that it consists of natural expressions which can be grammatical or ungrammatical, written by any users. Table 1 shows the venue document of the Ritz-Carlton, an upscale hotel located in Hong Kong. It contains the whole tag set and an example of comments.
 One novelty of our model is that we consider tags and comments separately, and our proposed model offers tailor-made modeling for these two kinds of text data, exploiting their different characteristics. Meanwhile, the modeling of these two parts are tied to each other in a coordinated manner which makes our approach considerably different from existing approaches. Experimental results obtained by our model are more superior than other comparative models. For each particular venue on a LBSN such as Foursquare, textual information, namely tags and user comments, are aggregated into a single document, called venue profile document. The category names of the given venue are also included as tags in our model. As a result, a venue profile document is composed of a bag of tags and a bag of words extracted from user comments.
 depicted in Fig. 1 . As mentioned in Sect. 1 , one characteristic of our model is that it exploits different characteristics of words and tags, and offers tailor-made modeling for each of them. At the same time, the modeling of words and the modeling of tags are tied to each other in a coordinated manner. Precisely, an abstract venue concept is modeled as a probability distribution of tags, denoted by  X  and a probability distribution of words, denoted by  X  . Tags and words may have different vocabularies. The variable | Z | denotes the number of abstract venue concepts.
 in our graphical model represents a venue profile document, which contains a set of words, denoted by W and a set of tags, denoted by T . The number of words and tags is denoted by | W | and | T | respectively. Each venue profile document is associated with a distribution of abstract concepts, denoted as  X  .  X  is assumed to be drawn from a Dirichlet distribution with a hyper-parameter  X  .  X  has two components, namely tag concept assignment denoted as z concept assignment denoted as z w . Each tag t is associated with z the distribution of tags for the concept represented by z Words in user comments are modeled in a different manner due to the dif-ferent characteristics of user comments compared with tags. It is common that user comments may contain some unrelated content which has no relationship with the abstract venue concept at all. We employ a background distribution to model the general words in user comments, denoted by the variable b ,which shares some resemblances with the modeling paradigm in [ 10 ]. The dimension of the variable b is the total number of words in the word vocabulary. User com-ments are treated as mixture of words in the background and words related to the abstract venue concept. Thus each word w is associated with either z b , which is governed by a binary variable x . x is associated with a Bernoulli distribution  X  with parameter  X  . The generative process of our model can be written as: 1. Draw  X  from Dirichlet (  X  )and  X  from Beta (  X  ) 2. For each abstract venue concept i. Draw global tag distribution  X  from Dirichlet (  X  ) ii. Draw global word distribution  X  from Dirichlet (  X  ) 3. For each venue profile document i. For each word w  X  W in the aggregated user comment ii. For each tag t  X  T We use Gibbs sampling to compute the approximate posterior in our model. Let |
R w | denote the number of tokens in the vocabulary built from user com-ments. Let | R t | denote the number of tokens in the vocabulary built from venue tags. Let | B | denote the number of tokens in the background corpus. Let  X  denote an element in the hyper-parameter vector related to the word w .Let n w denote number of times a word w in the user comment has been sam-pled from the abstract venue concept z w . Similarly, let  X  a vector  X  .Let n z t t denote number of times a tag t in the tag vocabulary has been sampled from the abstract venue concept z t .Let  X  z element in the hyper-parameter vector  X  .Let q z t and q z of times a global abstract venue concept has been sampled in a venue profile document. Note that when we have excluded the counts of the current case in our sampling equations. Let  X  = { w , t , X , X , X , X  } . The complete likelihood of the model is denoted in Eq. 1 .

P ( z w , z t , w , x , t |  X ,  X ,  X ,  X  )= P ( z w |  X  ) P (  X  Where Eqs. 4 , 5 and 6 depict the formulations used in our Gibbs sampler. After sampling sufficient number of times, the parameters  X  and  X  are calculated with Eqs. 7 and 8 . After the abstract venue concepts are detected, the next component is to auto-matically select one label to semantically describe the meaning of each concept. tags and a ranked list of words from comments, obtained from matrices  X  and  X  respectively. The terms in the list coherently describe one venue concept. How-ever, due to the intrinsic difference of tags and comments as shown in Sect. 1 , these two lists generally contain some similar as well as different terms. For example, consider an abstract venue concept representing colleges, the corre-sponding abstract venue concept distribution for tags may consist of terms such as  X  X ibrary X ,  X  X lectronics X ,  X  X ollege X ,  X  X ookstore X . Whereas the distribution of words in the abstract venue concept from the user comments may consist of  X  X ice X ,  X  X ibrary X ,  X  X xcellent X ,  X  X wesome X , etc. Our objective is to automatically select representative tokens, such as  X  X ollege X  to serve as labels for that concept. We adopt a technique based on the average Pointwise Mutual Information (PMI) described in [ 11 ], which also uses the same technique for finding topic labels. The value of PMI for a pair of words w i and w j is calculated with Eq. 9 , where P ( w i ,w j ) denotes the probability of observing both w list. P ( w i )and P ( w j ) are the overall probability of token w Then the average PMI is calculated by averaging over all the tokens in the list, denoted by Eq. 10 . PMI measures the association between one event to other events using information theory and statistics. In our case, intuitively, tokens that has more co-occurrence with other tokens will get higher PMI. For each discovered concept, we basically choose two concept labels that have the highest average PMI from the tag list and word list. We select the word with the highest avgPMI from the two ranked lists discovered by our model.
 4.1 Datasets We used the official Foursquare API to crawl text data related to tags and user comments corresponding to that venue. We crawled data from the follow-ing countries and in brackets we list the number of venue profile documents: (1) Australia (30,880), (2) Canada (50,063), (3) Hong Kong (5,282), (4) India (12,277), (5) Indonesia (302,725), (6) Singapore (18,082), and (7) USA (879,476). We selected those venues which had text content in both tags and user comments. Each venue document obtained from Foursquare contains several tags and up to 20 comments. 4.2 Comparative Models We choose a range of comparative models including some state-of-the-art topic models. Specifically, we compare our proposed model denoted as  X  X ur Model X  with (1) Latent Dirichlet Allocation ( LDA ) model [ 9 ]. We compare with both vari-ational inference [ 9 ] and collapsed Gibbs sampling based algorithms [ 12 ] denoted by vLDA and cLDA respectively. (2) Topical N-gram ( TNG )[ 13 , 14 ] model which is a phrase discovery topic model, (3) Hierarchical Dirichlet Processes ( HDP ) topic model [ 15 , 16 ], which is a nonparametric extension to the LDA model, (4) Biterm topic model ( BTM )[ 17 , 18 ], which is a topic model suited for short texts as most of the documents in our collection are short. We use publicly available source codes of all these models. We used the same parameter settings of these models as described in their respective works. We use fixed symmetric Dirichlet distrib-utions in our model in which we set  X  =0 . 5,  X  =0 . 01,  X  =0 . 01. In addition, we fixed  X  =0 . 01 in our model. All models are run for 1000 iterations. We combine user comments and tags in one document for the comparative methods as used in [ 8 ]. 4.3 Concept Coherence Evaluation The first evaluation measures the quality of concepts generated by the models. To enable large scale evaluation, we evaluate topical coherence using an auto-mated technique called observed coherence model discussed in [ 19 ]. The idea is to automatically find out whether the list of tokens in each concept are semantically related, which in turn leads to better concept interpretability.
 of 10 except the HDP model which automatically finds out the number of latent concepts. We run the topic models for five times due to randomization as adopted in [ 20 ]. Therefore, for each concept, each model was run for five times and the average coherence score was computed in each run. Then the macro-average coherence score was computed for all five runs. We then computed the average across different number of concepts from 10 to 200.
 from the table that our model has obtained the best average coherence score with improvements that is statistically significant according to two-tailed test with p&lt; 0 . 01 against each of the comparative models. One may argue that comparative models may perform better if we separately model user comments and venue tags as separate documents. We found that results obtained from such strategy are even worse due to the sparsity problem. Our model jointly models words from user comments along with other useful information from venues, leading to more coherent concepts which mitigates the sparsity issue. In addition, introducing the background distribution helps us get rid of many irrelevant words which were dominant in many comparative models. Presenting only the average performance for all topics hides the per-topic performance of a model, but it must be noted that our model performs consistently better than the comparative models at different number of topics. 4.4 Concept Label Evaluation We also evaluate the quality of the concept labeling task. We hired five human annotators to give ratings to concept labels. In our annotation task, each concept was presented in the form of its top-20 words ranked with decreasing probability value, followed by suggested label for the concept. Since our model generates two word distributions each of which will have a label of its own. In order to reduce the cognitive load on the human annotators, we only gave them the list of five concepts from each model, i.e. | Z | =5.For HDP , five concepts were randomly selected. We gave the ordinal scale rating questions to the annotators as described in [ 21 ]. The ratings range from 0 to 3. We considered the scores as voting given by the human annotators and computed the average score from all annotators for each model.
 We present the results in Table 3 . We see from the results that our model has obtained the highest value compared with other models.
 Specially, the standard LDA methods, i.e. vLDA and cLDA , which aggregate tags and comments and do not model them differently, perform worse than our model. This observation shows the advantage of our tailor-made modeling, which exploits different characteristics of tags and comments. In addition, the relatively worse performances of HDP , compared with LDA , show that the venue profile documents do not have distinct hierarchical properties. The BTM ,whichis suitable for short texts, fails to get better results, although most of the documents in our collection are short. TNG shows comparable performance with standard LDA . 4.5 Sample Concept Case Study We present top 20 terms from some abstract venue concepts from our model discovered from the  X  X ustralia X  dataset in Table 4 . We have merged the top ten words from two lists output by our model, and arranged the words in decreasing order of their probability values in the list presented below. There are two terms, one from each distribution, selected as labels which are in bold font. We see from the sample terms that our model has generated meaningful and coherent terms. For example, the second concept, which is labeled with  X  X ollege X  and  X  X ibrary X , apparently represents a college. Most of the words are related to college where university students play video games in the residential buildings. They go to the library to read books, listen to music, watch television or DVD, etc. els because of the following reasons. First, the background distribution in our model helps get rid of many general words from the distributions. This helps focus on only relevant content words in the user comments. Comparative models such as LDA , TNG , etc. are not designed to handle this. Although we could adopt aggressive pre-processing methods and then input the pre-processed text to the comparative models, it involves manual labour to select such general terms and removing them. Automatically removing the general words from the corpus can also be adopted, for example, using term-frequency and inverse document fre-quency score and removing those words which have low scores. But this involves selecting an appropriate threshold value, and we need to expend some computing time too. We could have considered a background distribution in the compar-ative models by modifying the models slightly and their sampling algorithms, however, those models still lack the ability to separately model user comments and tags in order to generate high quality abstract venue concepts. We have proposed a new model to generate abstract venue concepts from LBSNs venue profiles. Our model jointly models user comment text and tags. Meanwhile, the model offers tailor-made modeling for these two kinds of text data, exploiting their different characteristics.We conducted extensive experiments and found our model to be superior compared with comparative models in both the coherence of concept and the quality of labels.
