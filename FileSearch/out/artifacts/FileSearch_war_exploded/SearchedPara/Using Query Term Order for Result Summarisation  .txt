 We report on two experiments performed to test the importance of Term Order in automatic summarisation. Experiment one was undertaken as part of DUC 2004 to which three systems were submitted, each with a different summarisation approach. The system that used document Term Order outperformed those that did not use Term Order in the ROUGE evaluation. Experiment two made use of human evaluations of search engine results, comparing our Query Term Order summaries with a simulation of current Google search engine result summaries in terms of summary quality. Our QTO system X  X  summaries aided users X  relevance judgements to a significantly greater extent than Google X  X . H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Query formulation .
 Algorithms, Performance, Experimentation.
 Query Term Order, Term Order, Summary Quality. Automatic summarisation approaches commonly use a bag of words model, title terms, term frequency and sentence order [1]. These approaches more or less ignore term order. We believe that term order in a document or query is an implicit indicator of a term X  X  importance. Therefore, our hypothesis is that including term order in automatic summarisation produces better summaries than not including it. To prove our hypothesis we have done two experiments testing the importance of Term Order in documents summarisation and Query Term Order in search result summarisation. The rest of the poster describes our weighting scheme, which takes term order into account. The first experiment was implemented while participating in task 1 of DUC 2004 and the second experiment used human evaluation to determine summaries X  quality by comparing our QTO and a simulation of the then current Google system. shows that combining TO, TF and SO can produce better summaries than TF alone or TF and SO. The second experiment aimed to test whether counting Query Term Order could produce better search result summaries to help search engine users in making relevance judgements. In this experiment, our system was designed slightly differently to the first experiment because we changed the sentence weighting scheme by combining Query Term Order (QTO), TF and SO to extract sentences as summaries so that we could use Google X  X  summaries as the baseline comparison with our QTO system summaries. We selected 6 TREC9 queries and used each to retrieve 10 web pages (in English) from Google. The 60 summaries were output with exactly the same format and font in order not to be visibly distinct for the selected subjects during the evaluation process. Ten subjects were selected and split into two groups to evaluate summary quality. Each summary X  X  quality was scored for the extent to which it accurately represented the original page X  X  content ( representativeness ) and the extent to which it allowed the original page X  X  relevance to the particular query to be judged ( meaningfulness ). The QTO system X  X  sentences weighting scheme was as follows:  X  QTO: The first step was to use stop words to break the query into a set of weighted segments. These segments were stored in their original order. In the second step each segment was checked in order to break the segment into a set of single terms if it contained more than one term. Each single term generated from the second step was stored after those from the first stage, and their original order was retained. For example: the input query of TREC9 No. 522  X  how is water supplied to mojave desert region  X  generate to a set of terms as  X  water supplied  X ,  X  mojave desert region  X ,  X  water  X ,  X  supplied  X ,  X  mojave  X ,  X  desert  X ,  X  region  X  .  X  TF: Only the top ten percent of frequent words in the page were selected because web pages often contain more terms than DUC X  X  data.  X  SO: The approach was the same as in experiment one but script languages and style sheets appearing in the page were also removed. We used the following equations to determine each term X  X  weighting. Where N, M and K are the total number of terms in each category of QTO, TF and SO respectively. Each score in these three categories was normalised to between 0 and 1 and also occupied an equal ratio of 33% in the total score. The summary X  X  quality is calculated according to A,B and C formulas. In formula A, S represents the mean value of summaries X  representativeness score and is normalised to between 0 and 1, q represents the number of subjects from 1 to m, l represents the number of summaries from 1 to n, S ql represents 
