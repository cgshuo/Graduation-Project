 In this paper, we focus on XML data integration by study-ing rewritings of XML target schemas in terms of source schemas. Rewriting is very important in data integration systems where the system is asked to find and assemble XML documents from the data sources and produce doc-uments which satisfy a target schema.
 As schema representation, we consider Visibly Pushdown Automata (VPAs) which accept Visibly Pushdown Langua-ges (VPLs). The latter have been shown to coincide with the family of (word-encoded) regular tree languages which are the basis of formalisms for specifying XML schemas. Fur-thermore, practical semi-formal XML schema specifications (defined by simple pattern conditions on XML) compile into VPAs which are exponentially more concise than other rep-resentations based on tree automata.

Notably, VPLs enjoy a  X  X ell-behavedness X  which facili-tates us in addressing rewriting problems for XML data inte-gration. Based on VPAs, we positively solve these problems, and present detailed complexity analyses.
 H.2.3 [ Information Systems ]: Database Management X  Languages ; F.4.3 [ Theory of Computation ]: Mathemat-ical Logic and Formal Languages X  Formal Languages Algorithms, Languages, Theory XML, data integration, visibly pushdown languages
The Extensible Markup Language (XML) is the ubiqui-tous standard for representing data and documents on the Web and is used in a variety of domains ranging from collab-orative commerce to medical databases. One of the most im-portant applications of XML is data integration, where XML is used to structure or wrap data from multiple provider sources. Such sources contain diverse information and they present to the outside world a schema for the data they make available. A crucial problem in this setting is to be able to determine relevant sources and then combine them produc-ing data which satisfy a given target-schema. This is exactly the focus of this paper.
 Schemas for XML. In this paper, we will represent XML schemas by Visibly Pushdown Automata (VPAs) introduced in [2]. VPAs are in essence pushdown automata, whose push or pop mode can be determined by looking at the input only (hence their name). VPAs recognize Visibly Pushdown Lan-guages (VPLs), which form a well-behaved and robust family of context-free languages. VPLs enjoy useful closure proper-ties and several important problems for them are decidable. Furthemore, VPLs have been shown to coincide with the class of (word-encoded) regular tree languages.

When it comes to (formal) XML schema specifications, the most popular ones are Document Type Definition (DTD) XML Schema ([16]) and Relax NG ([4]). Notably, all these schema formalisms can be captured by Extended Document Type Definitions (EDTDs) (cf. [13, 12, 14, 5]). It is well known that the tree languages specified by EDTDs coincide with (unranked) regular tree languages (cf. [5]). Recent work [11] has also shown that EDTDs can be directly compiled into VPAs.

For all the above reasons, working with VPAs makes our methods as general as possible with respect to the current XML schemas. Also, decision problems for VPAs have the same complexity as those for unranked tree automata, which have been the classical tool for representing EDTD-based schemas for XML.
 On the other hand, when finally applying the automata on XML documents, by using VPAs, we do not have the over-head of building and storing the tree representation of doc-uments, which is a price to pay when using tree automata. This is because VPAs are word automata (as opposed to tree ones), and XML documents are initially words (strings) before being possibly transformed into trees.

A stronger reason for preferring VPAs over tree automata for XML is that VPAs are often more natural and exponen-tially more succinct than tree automata when it comes to  X  X emi-formally X  specify documents using pattern-based con-ditions on the global linear order of XML. Fleshing out the example of [1], to express that we want properly nested XML documents which contain elements a 1 ,...,a n (in this order) we can specify the word language L ( X   X  a 1  X   X  /a 1  X   X  ...  X  properly nested words on  X . Notably, this specification com-piles into a deterministic VPA of linear size, but standard deterministic bottom-up tree automata for this specification must be of size exponential in n . Such approaches for spec-ifying wanted documents are not uncommon or contrived examples in favor of VPAs. Rather, they are very practical and popular among users accustomed with regular expres-sions, and as such, embodied in important software such as the prominent .NET platform of Microsoft (cf. [6]). Rewritings. In this paper, we study the following two families of target-rewriting/source-composition problem for XML information integration: To illustrate, suppose that we have three XML sources: S 1 containing documents about books, with elements such S 2 containing documents about books (as above) and also S 3 containing documents about publishers, with elements Now, suppose that we also have a target schema specifica-tion T asking for (full) documents about books and their publishers. Let s 1 , s 2 and s 3 be symbols in some  X  X uter alphabet X  representing the XML sources. Informally, these symbols are the source  X  X d X  X  X  or  X  X ames. X  Then, ( s 1 + s would be a relevant rewriting, while s 1 s 3 would be a safe rewriting of T . After formally defining VPAs in Section 2, we give a detailed and more enhanced version of this exam-ple in Section 3.

Using a relevant rewriting for merging documents from different sources might create documents which might or might not fit a target schema. For example, using ( s 1 + s might create not only book-publisher documents, but also journal-publisher documents, and clearly, the latter do not fit the target schema. On the other hand, using a safe rewrit-ing, always creates documents which fit the target schema. In contrast, documents obtained by a relevant rewriting need an additional check for their validity, and this adds a data-complexity dimension in the data-integration problem under consideration.

Also, in order to perform document merges, one needs to specify join elements which will make the merge possi-ble. For example, for documents from source S 1 and S 3 , one needs to specify that the merge should be based on the equality of the pid contents. In this paper, we will assume that such join conditions are given for any meaningful pair of sources, and thus focus exclusively on the rewriting (re-formulating) the target schema in terms of source schemas.
Orthogonally with being relevant or safe, the rewritings can be  X  X omplete X  or  X  X artial. X  A rewriting is complete when its words do not have  X  X ncovered X  XML data (text) placeholders, otherwise it is partial. For example the above hand, if source S 3 is not available, then the best one can do is to compute partial rewritings ( s 1 + s 2 )  X  and s 1  X  ,where  X  and  X  represent languages (on the base alphabet) optimally chosen to satisfy the relevancy and safety, respectively, of the rewritings. By using partial rewritings we can obtain docu-ments having data in some parts and dataless  X  X keletons X  in some other parts. Depending on the availability of sources, the system can compute complete or partial rewritings.
Notably, for regular languages, the analogous problems have been positively solved. We mention here [10] and [3] which provide two different algorithms for computing the analog of safe rewriting for regular languages. On the other hand, [7] gives an algorithm for computing the analog of rele-vant rewriting for regular languages. Also, partial rewritings of regular languages have been studied in [8] and [9].
On the negative side, rewriting problems are unsolvable for context free languages (CFLs). This can be easily shown by reduction from the undecidable problems of non-empti-ness of intersection for CFLs (for relevant rewritings) and inclusion for CFLs (for safe rewritings).

In this paper, we positively solve the rewriting problems for VPLs of properly nested words. We believe that our re-sults are important not only from a database perspective, but also from a formal language one as they enrich the body of positive results for VPLs. Specifically, our contributions in this paper are as follows. Firstly, we discuss and for-mally define relevant and safe complete rewritings for XML, and present algorithms for computing these rewritings. Sec-ondly, we study optimal partial rewritings presenting key properties and algorithms to compute them. Finally, we give detailed complexity analyses by showing upper and lower bounds for the rewriting problems that we consider. Organization. The rest of the paper is organized as follows. In Section 2, we overview VPAs and VPLs. In Section 3, we illustrate and formally define rewritings. In Section 4 and 5, we study complete and partial rewritings, respectively. Section 6 concludes the paper.
VPAs were formally introduced in [2] and are a special case of pushdown automata. Their alphabet is partitioned into three disjoint sets of call, return and local symbols, and their push or pop behavior is determined by the consumed symbol. Specifically, while scanning the input, when a call symbol is read, the automaton pushes one stack symbol onto the stack; when a return symbol is read, the automaton pops off the top of the stack; and when a local symbol is read, the automaton only moves its control state. Formally, a visibly pushdown automaton (VPA) A is a 6-tuple ( Q, ( X  ,f ),  X ,  X  , q , F ), where 1. Q is a finite set of states. 2.  X   X  is the alphabet partitioned into the (sub) al-3.  X  is a finite stack alphabet, and  X   X   X isaspecial 4. q 0 is the initial state. 5. F is the set of final states. 6.  X  =  X  c  X   X  r  X   X  l  X   X  is the transition relation and  X 
ArunofaVPA A ,onaword w = x 1 x 2 ...x k  X   X   X  ,is a sequence  X  =( q 0 , X  0 ) , ( q 1 , X  1 ) ,..., ( q k , X  k and  X  i  X  ( X  \{ X } )  X   X  ,  X  0 =  X  and  X  afor every 1  X  i following holds:
Arun  X  =( q 0 , X  0 ) ,..., ( q k , X  k ) is accepting if q  X  k =  X  .Aword w is accepted by a VPA if there is an accepting run in the VPA which spells w . A language L is a visibly pushdown language (VPL) if there exists a VPA that accepts all and only the words in L . The VPL accepted by aVPA A is denoted by L ( A ). We remark that here, we are asking for an empty stack in the end of an accepting run because we are interested in VPLs of properly nested words.
We assume that schema VPAs do not contain local sym-bols 2 and that the data (text) can go wherever a call symbol meets a return symbol in the words accepted by such VPAs. Thus, if a word w = ab  X  b  X  a is accepted by a schema VPA, then an XML document corresponding to w would be for example ab cikm  X  b  X  a ,where c , i , k and m are local symbols. We note that, all our results can be easily modified to han-dle the case of schema VPAs containing local symbols (or wildcards for local symbols) as well.
Example 1. Suppose that we want to build a VPA ac-cepting XML documents describing books. Such documents will have a title element, one or more author elements, and
When referring to arbitrary elements of  X  r , we will use  X  a,  X  b,... in order to emphasize that these elements correspond to a,b,... elements of  X  c .
On the other hand, the VPAs for capturing rewritings will contain local symbols representing source names. a publisher ID (pid) element. A VPA accepting well-formed documents of this structure is A 1 = ( Q, ( X  ,f ) ,  X  , X ,q where Q = { q 0 ,q 1 ,q 2 ,q 3 ,q 4 ,q 5 ,q 6 ,q 7 ,q 8 } ,  X = X  c  X   X  r  X = {  X  b , X  t , X  a , X  p } , F = { q 8 } ,  X  = { ( q 0 , book, q 1 , X  b ) , ( q 1 ,title,q 2 , X  t ) , We show this VPA in Fig. 1.

For simplicity, in the rest of the paper, we sometimes omit the state labels from the example VPAs.
We first introduce the rewritings for XML by means of an example and discuss in detail their properties.

Suppose that the VPA of Example 1 represents the schema of a source S 1 of XML documents. Also, suppose that we have two other sources as well, S 2 and S 3 ,withschema represented by VPA A 2 and A 3 given in Fig. 2. Source S contains (XML) documents about books and journals, while S 3 contains documents about publishers.

Let  X  = { s 1 ,s 2 ,s 3 } be an alphabet of source names ; s s and s 3 are the names of the first, second and third source, respectively.

Now, let a target schema T be represented by VPA A shown in Fig. 3 [top]. The transitions labeled by # , X  # are wildcard transitions. This target schema asks for XML doc-uments containing full information about books. Specifi-cally, it asks for information not only about their title and authors, but also about their publishers.

It can be easily seen that we can compose sources S or S 2 with S 3 to get documents that might fit the target schema T . Namely, a possible rewriting of T using S 1 , S and S 3 can be captured by the VPA in Fig. 3 [bottom-left]. This rewriting suggests joining together documents from S with documents from S 3 ,ordocumentsfrom S 2 with doc-uments from S 3 . While the former documents indeed fit the target schema, the latter ones  X  X ossibly X  fit the target schema. This is because source S 2 provides not only docu-ments about books but also documents about journals, and clearly, the target schema does not ask for journal data. An-other rewriting is given in Fig. 3 [bottom-right]. This rewrit-ing is safe since it only suggests joining together documents from S 1 with documents from S 3 .

Observe that, in a rewriting, the source schemas do not need to completely  X  X over X  all the parts of the target schema (for instance bp and bp are  X  X ncovered X  in our example). The role of such symbols is to add extra structure to the information supplied by the sources.

However, in a complete rewriting, we do not allow words with uncovered data placeholders. Specifically, we do not want to have in a complete rewriting words where an opening tag (call symbol) is immediately followed by a closing tag (return symbol), e.g. a a . In such a case, the word is not able to pull data from the sources to cover that part of the target schema.

Depending on the availability of data sources, we can com-pute instead partial rewritings which extract the most pos-sible out of the available sources. For example, if source S is not available, we construct the partial rewritings given in Fig.4.

If we substitute the source VPLs for their names in a rewriting, we get the  X  X xpansion language X  induced by the rewriting. Intuitively, this is the language of all the docu-ments that the rewriting is able to possibly generate from the documents in the sources. The main property of the rewrit-ings captured by VPAs A and A p in Fig. 3 [bottom-left] and Fig.4 [top], respectively, is that their expansion languages have a non-empty intersection with the target language. On the other hand, the expansion languages of the rewritings captured by VPAs A and A p in Fig. 3 [bottom-right] and Fig.4 [bottom], respectively, is that they are completely con-tained in the target language.

Finally, observe that in both rewritings, the source names are local symbols in the rewriting. This is because the source languages are VPLs of properly nested words.
Here, we formalize the complete rewritings that we de-scribed above by example. For better readability we post-pone the formalization of partial rewriting to Section 5. Let 1. T and S 1 , ..., S n be the target and source languages, 2.  X  =  X  c  X   X  r be the underlying XML alphabet of these 3.  X  = { s 1 ,...,s n } be the alphabet (namely the set) of 4. Exp be a substitution defined on symbols, words and Now, we define the (complete) rewritings as follows.
Definition 1. The maximal relevant rewriting T is the set of all words w on  X  c  X   X   X   X  r such that 1. Exp ( w )  X  T =  X  2. w does not have an a  X  a subword for any a  X   X  c .
Definition 2. The maximal safe rewriting T is the set of all words w on  X  c  X   X   X   X  r such that 1. Exp ( w )  X  T ,and 2. w does not have an a  X  a subword for any a  X   X  c . The second condition in the above definitions asks for the  X  X ompleteness X  of rewritings. As we show in the next section, both T and T are VPLs with  X  as their alphabet of local symbols. Clearly, T  X  T .
Let A and A 1 ,..., A n be (nondeterministic) VPAs for the target and source schema languages, T and S 1 ,...,S n ,re-spectively. As these languages represent XML structural schemas, they do not have local symbols, but only call and return symbols. Let specifically, A =( Q, ( X  c  X   X  r ,f ) ,  X  , X ,q 0 ,F ), where Q = { q 0 ,q 1 ,...,q m } .

We denote by A ij ,for0  X  i, j  X  m , the VPA obtained by A making states q i and q j initial and final, respectively. Formally, A ij =( Q, ( X  c  X   X  r ,f ) ,  X  , X ,q i , { q j } A we construct automaton where  X  =  X   X  X  ( q i ,s k ,q j ): S k  X  L ( A ij ) =  X  for 0
As S k and L ( A ij ) are VPLs, the non-emptiness of their in-tersection can be decided in polynomial time (see [2]). VPA A , in contrast to A and A 1 ,..., A n , does have local sym-bols. They are the source names, i.e. the  X  elements. For VPA A , we show that Theorem 1. A accepts all and only the words w on  X  c  X   X   X   X  r such that Exp ( w )  X  T =  X  .
 Before presenting the proof, we illustrate the construction of A with the following example.

Example 2. Suppose that we have the target schema cap-tured by the VPA in Fig. 5 [first] and the source schemas captured by the VPAs in the same figure [second] and [third]. Then the constructed VPA A is the one given in the bottom of the figure.
 Based on Theorem 1 and Definition 2, for the maximal rel-evant rewriting T ,wehavethat Corollary 1. T = L ( A )  X  M c ,where M =( X  c  X   X   X   X  r )  X   X { a  X  a : a  X   X  c } X  ( X  c  X   X   X   X  Now, we give the proof of Theorem 1.
 Proof of Theorem 1.  X  all  X  X et w  X  ( X  c  X   X   X   X  r )  X  such that Exp ( w )  X  T = Suppose that w has some  X  symbol in it; otherwise the claim Figure 5: VPAs A [first], A 1 [second], A 2 [third] and A [fourth]. follows trivially. As such, w = u 1 s i 1 u 2 ...u p s some positive integer p and u i  X  ( X  c  X   X  r )  X  ,for1  X  i Now, there exist words v i 1 , ..., v i p in S i 1 , ..., S tively, such that u 1 v i 1 u 2 ...u p v i p u p +1 is accepted by that A goes on for accepting u 1 v i 1 u 2 ... u p v i p u ically, A starts in q 0 (withanemptystack),isin q i 1 after reading u 1 ,thengoesto q j 1 after reading v i 1 ,andsoon. Since, words v i h ,for1  X  h  X  p , are properly nested, and is a VPA, A will have the same stack when being in both q
Hence, if A starts consuming word v i h from state q i h on an empty stack (behaving as A i h ,j h ), it will eventually reach state q j h with an empty stack as well. This means that v which is the condition for having an s i h -transition from q to q j h . All this holds for 1  X  h  X  p .Thus,wehavethat w = u 1 s i 1 u 2 ...u p s i p u p +1 is a word accepted by this proves our claim.  X  only  X  X et w  X  L ( A ). As such, w will take A from initial state q 0 to some final state q f starting with an empty stack and ending again with an empty stack. Suppose that w has some  X  symbol in it, otherwise its  X  X xpansion X  has trivially a non-empty intersection with T .

As before, word w canbewrittenas u 1 s i 1 u 2 ...u p s i p for some positive integer p and u i  X  ( X  c  X   X  r )  X  ,for1 i states that A goes for accepting w . Specifically, A starts in q 0 (with an empty stack), is in q i 1 after reading u hops to q j 1 after reading s i 1 , and so on. Recall that s s i p are local symbols for A , and thus, the stack remains  X  X s is X  upon reading them.

Now, by the construction of A there exist words v i 1 , ..., v i p in S i 1 , ..., S i p , respectively, such that v i h takes automaton A from q i h to q j h starting and ending with the same stack. From this and from the fact that A accepts u same subsequence of states. As u 1 v i 1 u 2 ...u p v i p Exp ( w ), we have that Exp ( w )  X  T =  X  .

Next, we show the following theorem for the complexity of computing the maximal relevant rewriting ( T )ofatarget VPL T in terms of source VPLs S 1 ,...,S n .

Theorem 2. Computing T can be done in polynomial time.
 Proof. To construct VPA A takes polynomial time. Then, we need to take the intersection with the complement of the mask M =( X  c  X   X   X   X  r )  X   X { a  X  a : a  X   X  c } X  ( X  c  X   X  One can build an NFA for M which has O ( |  X  c | ) states. Thus, computing the complement of M canbedoneinex-ponential time in the size of  X  c . However, since L ( A VPL of properly nested words, T can be computed instead by intersecting L ( A ) with the complement of M =( X  c  X   X   X   X  r )  X   X { a  X  b : a  X   X  c and  X  b  X   X  r } X 
We can always construct an NFA recognizing M which has only three states, regardless of the alphabet size. So, we can construct a DFA for M which has not more than 8 states, regardless of the alphabet size. By changing the final states to non-final and vice versa, we obtain a DFA for M As this DFA has not more than 8 states, we can compute L (
A )  X  M c in polynomial time. For computing the safe rewriting, we first determinize VPA A obtaining a deterministic VPA accepting the same language. For notational simplicity let us denote by the same  X  X otational signature X  the deterministic variant of A notations only, and one should not confuse this automaton with the one in the previous subsection.

As in [2], for deterministic VPA A we have that
As VPA A captures an XML schema, it does not have transitions with local symbols. However, in general when a VPA does have such transitions, there is a third condition for a VPA to be deterministic: We mention this third condition as the VPAs we construct for the safe rewritings are deterministic and they have tran-sitions with local symbols.

In addition to the above conditions (listed in [2]), here we also require that deterministic VPAs do not get stuck in any state for any symbol when reading a properly nested word. The latter can be achieved by adding a  X  X arbage state. X 
Specifically, let q g be a new state which we add to A = ( Q, ( X  c  X   X  r ,f ) ,  X  , X ,q 0 ,F ). Also, let  X  = {  X  a and  X   X   X  =  X  . Then we add the following transitions to  X  : Formally, we have
Fa c t 1. Given any properly nested word w ,VPA A , starting from any state with an empty stack, is able to (deter-ministically) fully consume w and finish with with an empty stack as well.

Now, on this deterministic VPA A we perform the con-struction of the previous subsection and obtain A .
Language-wise, an A built on a deterministic A is the same as an A built on a non-deterministic A .Also, A is non-deterministic no matter whether the base VPA A is de-terministic or not. This is because the S languages have in general more than one word, and thus, from a given state, canjumptomorethanonestatewith s -labeled transitions. However, the structure of an A built on a deterministic A different from that of an A built on a non-deterministic A
This is because a deterministic A (with a garbage state as above) is able to fully consume a given properly nested word and does that in only one way. From this and the construction of A , if a properly nested word w  X  ( X  c  X   X   X  )  X  is able to take A from the initial state to a non-final state (starting and ending with an empty stack), then there exists u  X  Exp ( w ), such that u is not accepted by A .[On the other hand, if A is built on a non-deterministic A this couldhappenevenif u is accepted by A . This happens when word u is able to take A , from the initial state, not only to a final state, but also to some non-final one. Clearly, this cannot happen with a deterministic VPA.]
On the contrary, if word w  X  ( X  c  X   X   X   X  r )  X  takes A from the initial state to final states only, then Exp ( w ) L ( A )= T .

Conversely, let word w  X  ( X  c  X   X   X   X  r )  X  have the property that Exp ( w )  X  L ( A )= T . From this and the fact that the S languages are properly nested, we have that w is propely nested. As A , by construction, does not get stuck on properly nested words, it is able to consume w ,starting from the initial state with an empty stack and ending in a number of states again with empty stack. We claim that all these ending states are final. Suppose not; i.e. there exists one of those states, say q , which is not final. By the construction of A , we have that there exists word u  X  Exp ( w ) that can take base automaton A from state q 0 to q . Since base automaton A is deterministic, there is only one way to consume u andthisimpliesthat u cannot take A from q to some other (than q ) state which would  X  X opefully X  be final. Thus, u is not accepted by A , i.e. u  X  T , and this is a contradiction.

Hence, for VPA A constructed as above [on a determin-istic base VPA A that does not get stuck on properly nested words], and a word w  X  ( X  c  X   X   X   X  r )  X  ,wehavethat
Theorem 3. w  X  T if and only if upon reading w , A reaches only final states.

From the above theorem, in order to compute the safe rewriting we need to extract all the words which take A from its initial state to only final states. For this, we use on A the determinization procedure of [2]. This procedure is applied  X  X s is X  on A to obtain a deterministic variant of it. The procedure, among other information, also encodes in a state, say p , of the newly created VPA A , the subset of states, say Q p , that the VPA A reaches upon reading the words that take A from its initial state to p .The condition of [2] for designating a state as final in the output VPA is that the corresponding subset of states (from the input VPA) has some final state in it. Specifically, state p , according to [2], would be designated as final if Q p  X  F = where F is the set of final states in A .Nowinsteadofthis condition, we will require that a state p in A is final only if its Q p  X  F . One can verify that for VPA A obtained in this way, we have that Theorem 4. A accepts all and only the words in ( X  c  X   X   X   X  r )  X  which can take A from its initial state to final states only.
 From this and Theorem 3, we have that Corollary 2. A accepts all and only the words w on  X  c  X   X   X   X  r such that Exp ( w )  X  T .
 From this and Definition 2, we finally have that Corollary 3. T = L ( A )  X  M c ,where M =( X  c  X   X   X   X  r )  X   X { a  X  a : a  X   X  c } X  ( X  c  X   X   X   X 
Next, we show the following theorem which establishes an upper bound for computing the maximal safe rewriting T .
Theorem 5. Computing T can be done in doubly expo-nential time.
 Proof. Let us refer to the construction of this section for computing T . Computing a deterministic VPA A needs exponential time (see [2]). Computing VPA A needs ex-ponential time in the size of A ,andthissizemightbeex-ponential. Intersecting with mask M is absorbed by the complexity of the previous steps. Thus, in total, we need doubly exponential time in the size of a non-deterministic VPA for the target language.
 A matching lower bound can be derived from the 2EX-PTIME lower bound for the analogous problem for regular languages [3].

Remark 1. Regular languages and VPLs of properly nes-ted words are incomparable families of languages. However, we can encode any regular language L on some alphabet  X  as a VPL L of properly nested words over alphabet  X   X   X  , where  X  = {  X  a : a  X   X  } ,bytaking L = { a 1  X  a 1 ...a a ...a p  X  L } . Thus, any lower bound for problems on regu-lar languages carries over VPLs of properly nested words. Thus, we formally state that
Theorem 6. Computing T is 2EXPTIME-hard.
Here we study partial rewritings. Specifically, some words in the target language could only  X  X artially be rewritten X  in terms of the sources. Nevertheless, such words are able to pull data from the sources, albeit partial. For example, suppose that the target language has a word a  X  ab  X  bc  X  cd we only have available sources S 1 = { a  X  a } , S 2 = { S 3 = { d  X  d } . Then, the best we can do is to partially rewrite the target word as s 1 s 2 c  X  cs 3 .
 ing word X  in that we cannot rewrite a  X  ab  X  bc  X  cd  X  using the given sources. On the other hand, s 1 b  X  bc  X  cs optimal as it can be further rewritten into s 1 s 2 c  X  cs Definition 3. Aword w  X  ( X  c  X   X   X   X  r )  X  , such that Exp ( w )  X  T =  X  ,is type-one non-optimal if it has some subword which belongs to S i ,forsome i  X  [1 ,n ] .
Intuitively, such a word w = w 1 w 2 w 3 ,where w 2  X  S i be further rewritten in terms of the sources. Specifically, it canberewrittenas w 1 s i w 3 . Thisisbecause and thus Exp ( w 1 s i w 3 )  X  T =  X  (since Exp ( w )  X  T =
All the words that do not satisfy Definition 3 are called type-one optimal .

Certainly, when it comes to partial rewritings, we need to compute all the optimal rewriting words and filter out those that are non optimal. Formally, for target and source VPLs, T and S 1 ,...,S n , respectively, we define
Definition 4. The maximal relevant partial rewriting ( T p ) is the set of all type-one optimal words on  X  c  X   X   X  Now, we define Definition 5. Aword w  X  ( X  c  X   X   X   X  r )  X  , such that Exp ( w )  X  T ,is type-two non-optimal iff there exist w 1 and w 3 , such that w = w 1 w 2 w 3 , w 1 ,w 3  X  ( X  c  X   X  w 2  X  S i for some i  X  [1 ,n ] and Exp ( w 1 )  X  S i  X  Exp ( w
Intuitively, such a word w = w 1 w 2 w 3 ,where w 2  X  S i be further rewritten in terms of the sources. Specifically, it canberewrittenas w 1 s i w 3 . Thisisbecause
All the words that do not satisfy Definition 5 are called type-two optimal .

Definition 6. The maximal safe partial rewriting ( T p ) is the set of all type-two optimal words on  X  c  X   X   X   X  r
We show the following relationships between the rewrit-ings introduced so far.
 Theorem 7. (a) T  X  T p ,(b) T  X  T p and (c) T p  X  T p . Proof. (a) Let w  X  T .Then Exp ( w )  X  T =  X  . Now suppose that w is not in T p . Then, w canbewrittenas w 1 w 2 w 3 ,such that w 2  X  S i ,forsome i  X  [1 ,n ]. Since S i is a VPL of properly nested words, w 2 is properly nested as well. As such, w 2 contains at some point a call symbol immediately followed by a return symbol. Thus, w  X  T , and this is a contradiction. (b) Similar to (a). (c) Direct from definitions. We can compute T p by first constructing VPA A as in Subsection 4.1 and then intersecting with the complement of mask M p =( X  c  X   X   X   X  r )  X   X  ( S 1  X  ...  X  S n )  X  ( X  c  X   X   X  We capture this construction with the following statement. Theorem 8. T p = L ( A )  X  ( M p ) c .

Thus, regarding an upper bound for the maximal relevant partial rewriting we have
Theorem 9. Computing T p can be done in exponential time.
 Proof. Computing VPA A is polynomial. Intersecting with the complement of mask M p is exponential.
 Regarding the lower bound, we show that computing T p is PSPACE-hard. For this, we start by the following theorem. Theorem 10. Deciding the emptiness of T  X  T p is PSPACE-hard.
 Proof. We show this via a reduction from the following PSPACE-complete problem given in [8].

As we showed in Remark 1 (in Section 4.2), although reg-ular languages and VPLs of properly nested words are incom-parable families of languages, we can easily carry over any lower bound for problems on regular languages to analogous problems for VPLs of properly nested words. In particular, if K and L , in the above problem, are VPLs of properly nested words on  X   X   X  , then the problem becomes PSPACE-hard. Specifically, we have
Now, our reduction is as follows. Take  X  c = X , X  r = X  , target T = K and single source S = L . By the construc-tion of VPA A (see Subsection 4.1), T  X  L ( A ). Based on Theorem 8, we have that
T p = L ( A )  X  [( X  c  X  X  s } X   X  r )  X   X  S  X  ( X  c  X  X  s } X   X  Thus, T  X  T p = T  X  [( X  c  X  X  s } X   X  r )  X   X  S  X  ( X  c  X  X  s T  X  [( X  c  X   X  r )  X   X  S  X  ( X  c  X   X  r )  X  ] c .
 The second equality follows from the fact that T  X  ( X  c  X   X  )  X  . Finally, it is clear that, K  X  [( X   X   X  )  X   X  L  X  ( X   X   X  )  X  ] c is empty if and only if T is empty.
 From the above theorem, we can conclude that comput-ing the maximal partial relevant rewriting is PSPACE-hard. This is because, given T p , we can test for the emptiness of T  X  T p in time polynomial in the size of T p (the size of T is absorbed by the size of T p ). Thus, our algorithm for com-puting T p is optimal, under the assumption that PSPACE  X 
SUB-EXPTIME.
On the other hand, computing the maximal partial safe rewriting T p is more complicated. We first compute VPA A as in Subsection 4.2. Recall that this VPA accepts all (and only) the words w in ( X  c  X   X   X   X  r )  X  such that Exp T . From this and the definition of T p , it follows that T L (
A ). Thus, we need to find a mask to filter out unwanted words, which are those that still have subwords that can be rewritten in terms of the sources. It might seem that the above mask M p would do the job. However this is not true as the following example illustrates.

Example 3. Let T = { ea  X  a  X  eb  X  bd  X  d } and S 1 = { b  X  b, c  X  c } and S 3 = { d  X  d } .Then, A will accept the language and by intersecting with the complement of we only get the empty set. What we want is to filter out the (type-two) non-optimal words ea  X  a  X  eb  X  bd  X  d , es and compute T p = { es 1  X  eb  X  bs 3 } .
 In order to build the aforementioned mask, we need to be able to detect words in L ( A ) that can be further rewritten.
Now, let  X  = { s 1 ,...,s n } be another alphabet of source names, for which we require  X   X   X =  X  . We build VPA A on A in exactly the same way as we built A on A , but using  X  as the set of view names. Recall that A is already deterministic (see Subsection 4.2), so we do not need to determinize it first.

In order to state the key property of A , let us first define substitution Exp on  X  c  X   X   X   X   X   X  r as Exp ( s i )= S i and Exp ( s i )= s i ,for1  X  i  X  n ,and Exp ( a )= a ,for a  X   X  c  X   X  r .Also,weextend Exp to words and languages similarly as in Section 3.
 As in Theorem 2, we can show that Now, consider language N = L ( A )  X  ( X  c  X   X   X   X   X   X  r )  X   X   X   X  ( X  c  X   X   X   X   X  This language contains all the words w in L ( A )thathave some symbol from  X  . By the construction of A ,wehave that for such words w , Exp ( w )  X  L ( A ). Formally, we show that
Theorem 11. Exp ( N ) is the set of all (type-two) non-optimal words in L ( A ) .
 Proof. Let w  X  Exp ( N ). As such, there exists word v  X  N whose expansion includes w , i.e. w  X  Exp ( v ). Since v  X  v = v 1 s i v 2  X  L ( A )and Exp ( v 1 )  X  S i  X  Exp ( v 2 for some i  X  [1 ,n ], and v 1 ,v 2  X  ( X  c  X   X   X   X   X   X  r ) this, we have that w  X  Exp ( v )= Exp ( v 1 )  X  S i  X  Exp Conversely, let w  X  ( X  c  X   X   X   X  r )  X  be a non-optimal word. As such, there exist w 1 ,w 2 ,w 3  X  ( X  c  X   X   X   X  r )  X  such that w = w 1 w 2 w 3 , w 2  X  S i and Exp ( w 1 )  X  S i  X  Exp ( w for some i  X  [1 ,n ]. Since L ( A )isthesetof all words in ( X  c  X   X   X   X  r )  X  whose expansion is contained in T ,wehave that { w 1 } X  S i  X { w 3 } X  L ( A ). From the construction of w s i w 3  X  L ( A ), and furthermore, w 1 s i w 3  X  N . Finally, our claim follows since w  X  Exp ( w 1 s i w 3 ).
 From all the above we conclude that Corollary 4. T p = L ( A )  X  ( Exp ( N )) c .

Using the above construction we get a quad-exponential time upper bound. For this observe that computing VPA A is triple exponential. Computing N by intersecting with ( X  c  X   X   X   X   X   X  r ) thesizeof A . Obtaining Exp ( N ) is polynomial in the size of
A . Computing ( Exp ( N )) c and finally producing T p is exponential in the size of A , for a total of quad-exponential time.

However, with the following theorem we show how to ob-tain a triple exponential time upper bound by computing A more efficiently.

Theorem 12. Computing T p can be done in triply expo-nential time.
 Proof. We can obtain A in only doubly exponential time, thus having in total triply-exponential time instead. For this, from VPA A , we construct in polynomial time VPA B which is the same as A , but also has for each transition ( ,s i , ), where 1  X  i  X  n , an (additional) transition ( ,s We show that Lemma 1. L ( B )= L ( A ) .
 Proof. Recall that VPA A accepts all and only the words w on  X  c  X   X   X   X   X   X  r such that Exp ( w )  X  L ( A ).  X   X   X  X et w  X  L ( B ) and suppose that w has some  X  or  X  symbol in it; otherwise the claim follows immediately. As p ,andwhere u h  X  ( X  c  X   X  r )  X  ,for1  X  h  X  p +1, and  X  s if we replace all the  X  s symbols in w by their correspond-ing S languages, we get only words in T . Differently said, Exp ( Exp ( w ))  X  T . This means that Exp ( w )  X  L ( A [Recall that L ( A )isthesetofallwordsin( X  c  X   X   X   X  r )  X  with expansion completely contained in T ]. The condition that Exp ( w )  X  L ( A ) is exactly what is required from a word to be in L ( A ). Thus, w  X  L ( A ).  X   X   X  Now suppose that w = u 1  X  s i 1 u 2 ...u p  X  s i p as above) is in L ( A ). This means that Exp ( w )  X  L ( A In other words, by replacing all the s symbols in w by their corresponding source languages, we get words that are in-cluded in L ( A ). Further replacing the s symbols, we get words that are included in T .Inshort, Exp ( Exp ( u 1  X  s i 1 u 2 ...u p  X  s i p u p +1 )) = u
By the construction, if B accepts a word v = u 1 s i 1 u 2 u s i p u p +1 it will also accept all the other words obtained from v by changing an arbitrary number of s symbols to their s counterparts. Clearly, word w is among these and hence in L ( B ). (End of Lemma 1) The above lemma concludes the proof of this theorem.
Regarding the lower bound, we show that computing the maximal safe partial rewriting T p is 2EXPTIME-hard. For this, we start by the following theorem.
 Theorem 13. Computing T p  X  M c ,where M =( X  c  X   X   X   X  r )  X   X { a  X  a : a  X   X  c } X  ( X  c  X   X   X   X  is 2EXPTIME-hard.
 Proof. Based on Theorem 7 (and its proof), we have that T  X  T p and T p  X  M c = T . Also, reasoning similarly as in Theorem 2, we have that T p  X  M c = T p  X  M c ,where M = ( X  Recall that the DFA for M c has not more than 8 states.
So, we can compute T by computing T p  X  M c ,which can be done in polynomial time in the size of T p .Now, our claim follows because computing T is 2EXPTIME-hard (see Theorem 6).
 From the above theorem, we can conclude that computing the maximal safe partial rewriting is 2EXPTIME-hard.
We formally defined relevant and safe rewritings for VPLs of properly nested words, both in complete and partial set-tings. In summary our results are as follows.
As VPLs of properly nested words capture all the pop-ular (formal and semi-formal) XML schema languages, we believe that our results about rewritings of VPLs serve as an important step in approaching XML data integration. [1] Alur, R. Marrying Words and Trees. In Proc. 26 th [2] Alur, R., and Madhusudan, P. Visibly Pushdown [3] Calvanese, D., De Giacomo, G., Lenzerini, M., [4] Clark, J., and M. Murata, M. RELAX NG [5] Comon, H., Dauchet, M., Gilleron, R., [6] Friedl, F., E. Mastering Regular Expressions. [7] Grahne, G., and Thomo, A. An Optimization [8] Grahne, G., and Thomo, A. Algebraic Rewritings [9] Grahne, G., and Thomo, A. New Rewritings and [10] Hashiguchi, K. Representation Theorems on [11] Kumar, V., Madhusudan, P. and Viswanathan, [12] Martens, W., Neven, F., Schwentick, T., Bex, [13] M. Murata, D. Lee, M. Mani, and K.
 [14] Schwentick, T. Automata for XML -A survey. J. [15] Segoufin, L., and Vianu, V. Validating Streaming [16] Sperberg-McQueen, C., M., and Thomson, H.

