 Building models that make good predictions about the world c an be a complicated task. Humans, however, seem to have the remarkable ability to split this ta sk up into manageable chunks. For instance, the activity in a park may have many complex intera cting components (people, dogs, balls, etc.) and answering questions about their joint state would be impossible. It can be much simpler to answer abstract questions like  X  X here will the ball bounce ? X  ignoring most of the detail of what else might happen in the next moment. Some other questions li ke  X  X hat will the dog do? X  may still be very difficult to answer in general, as dogs are complicate d objects and their behavior depends on many factors. However, in certain situations, it may be re latively easy to make a prediction. If a ball has just been thrown, one may reasonably predict that th e dog will chase it, without too much consideration of other potentially relevant facts. In shor t, it seems that humans have a lot of simple, localized pieces of knowledge that allow them to make predictions abou t particular aspects of the world in restricted situations. They can combine these abst ract predictions to form more concrete, detailed predictions. Of course, there has been substantia l effort in exploiting locality/independence structure in AI. Much of it is focused on static domains witho ut temporal concerns (e.g. [1]), though these ideas have been applied in dynamical settings as well ( e.g. [2, 3]). Our main contribution is to provide a novel mathematical formulation of  X  X ocal mod els X  of dynamical systems that make only certain predictions in only certain situations. We als o show how to combine them into a more complete model. Finally, we present empirical illustratio ns of the use of our local models. 1.1 Background In this paper we will focus on learning models of uncontrolle d discrete dynamical systems (we leave consideration of controlled systems to future work). At eac h time step i the system emits an obser-vation o i from a finite set of observations O . We call sequences of observations tests and let T be of past observations. We use the letter  X  to represent the null history in which no observation has yet been emitted. A prediction of a test t = o i +1 ...o i + k given a history h = o 1 ...o i , which we denote p ( t | h ) , is the conditional probability that the sequence t will occur, given that the sequence h has histories H is defined: H def = { t  X  X  : p ( t |  X  ) &gt; 0 } X  X   X  } . We use models to make predictions: Definition 1. A complete model can generate predictions p ( t | h ) for all t  X  X  and h  X  X  . A model that can make every such prediction can make any condi tional prediction about the system [4]. For instance, one may want to make predictions about whe ther any one of a set of possible futures will occur (e.g.  X  X ill the man throw a ball any time be fore he leaves the park? X ). We can represent this type of prediction using a union test (also called a  X  X ollective outcome X  by Jaeger [5]). Definition 2. A union test T  X  X  is a set of tests such that if t  X  T then no prefix of t is in T . The prediction of a union test is a sum of predictions: p ( T | h ) def = P t  X  T p ( t | h ) . Models may be provided by an expert, or we can learn them from e xperience with the system (in the form of a data set of observation sequences emitted by the sys tem). The complexity of representing and learning a model often depends on the complexity of the sy stem being modeled. The measure of complexity that we will adopt is called the linear dimension [6] and is defined as the rank of t  X  X  and h i  X  X  ). It is also closely related to the number of underlying stat es in a Hidden Markov Model. We will not define it more formally here but note that wh en we say one system is simpler than another, we mean that it has a smaller linear dimension.
 We will now present the main contributions of our work, start ing by precisely defining a local model, and then showing how they can be combined to create a more comp lete model. In contrast to a complete model, a local model has limited pre diction responsibilities and hence makes only certain predictions in certain situations.
 Definition 3. Given a set of tests of interest T I and a set of histories of interest H I , a local model is any model that generates the predictions of interest : p ( t | h ) for all t  X  X  I and h  X  X  I . We will assume, in general, that the tests of interest are uni on tests. In this paper, we will place a constraint on H I  X  X  which we will call the  X  X emi-Markov X  property, due to its clo se relationship to the concept of the same name in the  X  X ptions X  literature [7 ]; this assumption will be relaxed in future work. In words, we require that, in order to determine if the current history is of interest, we need only look at what has happened since the preceeding history of interest. Put formally, Definition 4. A set of histories of interest H I is semi-Markov iff h, h  X   X  X  I  X  X   X  } and ht  X  X  I for some t  X  X  , implies that either h  X  t  X  X  I or p ( h  X  t |  X  ) = 0 .
 As a simple example, consider the 1D Ball Bounce system (see Figure 1). The agent observes a line of pixels, one of which (the location of the  X  X all X ) is black; the rest are white. The ball moves along the line, changing direction when it hits the edg e.
 Each time step, with probability 0 . 5 , the ball sticks in place, and with probability 0 . 5 it moves one square in its current direction.
 One natural local model would make one-step predictions abo ut only one pixel, p . It has two tests of interest: the set of all one-step tests in which the pixel p is black, and the set of all one-step tests in which p is white. All histories are of interest. This local model ans wers the question  X  X hat is the chance the ball will be in pixel p next? X  Note that, in order to answer this question, we need on ly observe the color of the pixels neighboring p . We will refer to this example as Model A . Another, even more restricted local model would be one that h as the same tests of interest, but whose histories of interest are only those that end with pixe l p being black. This local model would essentially answer the question  X  X hen the ball is in pixel p , what is the chance that it will stick? X  In order to make this prediction, the local model can ignore all detail; the prediction for the test of interest is always 0 . 5 at histories of interest. We will refer to this local model as Model B . In general, as in the examples above, we expect that many deta ils about the world are irrelevant to making the predictions of interest and could be ignored in or der to simplify the local model. Taking tests and histories of interest, we will show how to convert a primitive observation sequence into an abstract observation sequence that ignores unnecessary detail. A complete model of the abstracted system can be used as a local model in the original, primitive system. The abstraction pr oceeds in two steps (shown in Figure 2). First, we construct an interme diate system which makes predictions for all tests, but only updates at histories of interest. The n we further abstract the system by ignoring details irrelevant to making predictions for just the tests of interest. 2.1 Abstracting Details for Local Predictions Incorporating Histories Of Interest : Intuitively, since a local model is never asked to make a prediction at a history outside of H I , one way to simplify it is to only update its predictions at histories of interest. Essentially, it  X  X akes up X  whenever a history of interest occurs, sees what observation sequence happened since it was last awake, upda tes, and then goes dormant until the next history of interest. We call the sequences of observati ons that happen between histories of interest bridging tests . The set of bridging tests T B is induced by the set of histories of interest. t [1 ...j ] denotes the j -length prefix of t ) and either  X  h  X  X  I such that ht  X  X  I or | t | =  X  . Conceptually, we transform the primitive observa-tion sequence into a sequence of abstract observa-tions in which each observation corresponds to a bridging test. We call such a transformed sequence the Temporally Extended or T E sequence (see Fig-ure 2). Note that even when the primitive system has a small number of observations, the T E system can have infinitely many, because there can be an infin-ity of bridging tests. However, because it does not update between histories of interest, a model of T E may be simpler than a model of the original system.
 To see this, consider again the 1D Ball Bounce of size k . This system has linear dimension O (2 k ) , in-tuitively because the ball has 2 possible directions and k possible positions. Recall Model B , that only applies when the ball lands on a particular pixel. The br idging tests, then, are all possible ways the ball could travel to an edge and back. The probability of e ach bridging test depends only on the current direction of the ball. As such, the T E system here has linear dimension 2, regardless of k . It is possible to show formally that the T E system is never more complex than the original system. Proposition 1. If the linear dimension of a dynamical system is n then, given a semi-Markov set of histories of interest H I , the linear dimension of the induced T E system, n T E  X  n . Proof. (Sketch) The linear dimension of a system is the rank of the sy stem dynamics matrix (SDM) corresponding to the system [6]. The matrix corresponding t o the T E system is the submatrix of the SDM of the original system with only columns and rows corresp onding to histories and tests that are sequences of bridging tests. A submatrix never has greater r ank than the matrix that contains it. What good is a model of the TE system? We next show that a model of the TE system can make predictions for all tests t  X  T in all histories of interest h  X  H I . Specifically, we show that the prediction for any test in a history of interest can be expressed as a prediction of a union test in T E . For the following, note that every history of interest h  X  X  I can be written as a corresponding sequence of bridging tests, which we will call s h . Also, we will use the subscript T E to distinguish predictions p T E ( t | h ) in T E from predictions p ( t | h ) in the original system. Proposition 2. For any primitive test t  X  T in the original system, there is a union test S t in T E such that p ( t | h ) = p T E ( S t | s h ) for all h  X  X  I .
 Proof. We will present a constructive proof. First suppose t can be written as a sequence of bridging tests s t . Then trivially S t = { s t } . If t does not correspond to a sequence of bridging tests, we can re-write it as the concatenation of two tests: t = t 1 t 2 such that t 1 is the longest prefix of t that is where h, ht 1  X  X  I . We know already that p ( t 1 | h ) = p T E ( s t there must be a set of bridging tests B t The probability of seeing t 2 is the probability of seeing any of the bridging tests in B t at the history of interest ht 1 , p ( t 2 | ht 1 ) = P b  X  B S t = { s t 1 b : b  X  B t 2 } , which gives us the result.
 Since tests of interest are union tests, to make the predicti on of interest p ( T | h ) for some T  X  T I A model of T E is simpler than a complete model of the system because it only makes predictions at histories of interest. However, it still makes predictio ns for all tests. We can further simplify our modeling task by focusing on predicting the tests of interes t.
 Incorporating Tests of Interest: Recall Model A from our example. Since all histories are of interest, bridging tests are single observations, and T E is exactly equivalent to the original system. However, note that in order to make the predictions of intere st, one must only know whether the ball is neighboring or on the pixel. So, we need only distinguish o bservations in which the ball is nearby, and we can group the rest into one abstract observation:  X  X he ball is far from the pixel. X  In general we will attempt to abstract away unnecessary deta ils of bridging tests by aliasing bridging tests that are equivalent with respect to making the predict ions of interest. Specifically, we will define a partition, or a many-to-one mapping, from T E observations (the bridging tests T B ) to abstract observations A . We will then use a model of the abstract system with A as its observations (see Figure 2) as our local model. So, A must have the following properties: (1) we must be able to express the tests of interest as a union of sequences of abs tract observations in A and (2) an abstracted history must contain enough detail to make accur ate predictions for the tests of interest. Let us first consider how to satisfy (1). For ease of expositio n, we will discuss a special case. We assume that tests of interest are unions of one-step tests (i .e., for any T  X  T I , T  X  O ) and that T I partitions O , so every observation is contained within exactly one test o f interest. One natural example that satisfies this assumption is where the local mod el makes one-step predictions for a particular dimension of a vector-valued observation. Ther e is no fundamental barrier to treating tests of interest that are arbitrary union tests, but the developm ent of the general case is more complex. Note that if a union test T  X  O , then the equivalent T E union test, S T , consists of every bridging the bridging tests, T B , according to their first observation. As such, if we chose A = S I , or any refinement thereof, we would satisfy criterion (1). However , S I may not satisfy (2). For instance, in our 1D Ball Bounce, in order to make accurate predictions f or one pixel it does not suffice to observe that pixel and ignore the rest. We must also distingu ish the color of the neighboring pixels. This problem was treated explicitly by Talvitie et al. [10]. They define an accurate partition : Definition 6. An observation abstraction A is accurate with respect to T I iff for any two primitive abstract observation O i  X  X  , we have p ( T | h 1 ) = p ( T | h 2 ) ,  X  T  X  X  I .
 The system we are abstracting is T E , so the observations are bridging tests. We require an accur ate refinement of S I . Any refinement of S I satisfies criterion (1). Furthermore, an accurate refinemen t is one that only aliases two histories if they result in the sa me predictions for the tests of interest. Thus, we can use an abstract history to make exactly the same predictions for the tests of interest that we would make if we had access to the primitive history. So, an accurate refinement also satisfies criterion (2). Furthermore, an accurate refinement always e xists, because the partition that distin-guishes every observation is trivially accurate, though in general we expect to be able to abstract away some detail. Finally, a model of the abstract system may be far sim pler than a model of the original system or the T E system, and can be no more complex: Proposition 3. If the linear dimension of a dynamical system is n then the linear dimension of any local model M , n M  X  n T E  X  n .
 Proof. (Sketch) The rows and columns of the SDM corresponding to an a bstraction of T E are linear combinations of rows and columns of the SDM of T E [10]. So, the rank of the abstract SDM can be no more than the rank of the SDM for T E . Learning a local model: We are given tests and histories of interest and an accurate a bstraction. To learn a local model, we first translate the primitive traje ctories into T E trajectories using the abstraction (as in Figure 2). We can then train any model on the abstracted data. In our experiments, we use POMDPs [11], PSRs [4], and low-order Markov models as l ocal model representations. 2.2 Combining Local Models Consider a collection of local models M . Each local model M  X  M has tests of interest T I M , histories of interest H I M , and is an exact model of the abstract system induced by a give n accurate refinement, A M . At any history h , the set of models M h def = { M  X  M : h  X  H I M } is available to make predictions for their tests of interest. However, we may wish to make predictions that are not specifically of interest to any local model. In that case, we must combine the abstract, coarse predictions made by individual models into more fine-graine d joint predictions. We will make a modeling assumption that allows us to efficiently combine th e predictions of local models: Definition 7. The local models in M h are mutually conditionally independent, given h iff for any subset { M 1 , M 2 , ..., M k }  X  M h , and any T 1  X  T I M A domain expert specifying the structure of a collection of l ocal models should strive to satisfy this property as best as possible since, given this assumpti on, a collection of local models can be used to make many more predictions than can be made by each ind ividual model. We can compute the predictions of finer-grained tests (intersections of te sts of interest) by multiplying predictions together. We can also compute the predictions of unions of te sts of interest using the standard formula: Pr ( A  X  B ) = Pr ( A ) + Pr ( B )  X  Pr ( A  X  B ) . At any history h for which M h 6 =  X  , a collection of local models can be used to make predictions fo r any union test that can be constructed by unioning/intersecting the tests of interest of the model s in M h . This may not include all tests. Of course making all predictions may not be practical, or necessary. A collectio n of local models can selectively focus on making the most important predicti ons well, ignoring or approximating less important predictions to save on representational complex ity.
 Of course, a collection of local models can be a complete model. For instance, note that any model that can make the predictions p ( o | h ) for every o  X  O and h  X  H is a complete model. This is because every prediction can be expressed in terms of one-step predictions: p ( o 1 ...o k | h ) = of tests of interest of models in M h at every h , then M is a complete model. That said, for a given M , the mutual conditional independence property may or may no t hold. If it does not, predictions made using M will be approximate, even if each local model in M makes its predictions of interest exactly. It would be useful, in future work, to explore bound s on the error of this approximation. When learning a collection of local models in this paper, we as sume that tests and histories of in-terest as well as an accurate refinement for each model are giv en. We then train each local model individually on abstract data. This is a fair amount of knowl edge to assume as given, though it is analogous to providing the structure of a graphical model and learning only the distribution pa-rameters, which is common practice. Automatically splitti ng a system into simple local models is an interesting, challenging problem, and ripe ground for fu ture research. We hope that casting the structure learning problem in the light of our framework may illuminate new avenues to progress. 2.3 Relationship to Other Structured Representations Here we briefly discuss a few especially relevant alternativ e modeling technologies that also aim to exploit local and independence structure in dynamical syst ems.
 DBNs: The dynamic Bayes network (DBN) [2] is a representation that exploits conditional indepen-dence structure. The main difference between DBNs and our co llection of local models is that DBNs specify independence structure over  X  X idden variables X  wh ose values are never observed. Our rep-resentation expresses structure entirely in terms of predi ctions of observations. Thus our structural assumptions can be verified using statistical tests on the da ta while DBN assumptions cannot be directly verified. That said, a DBN does decompose its world state into a set of random variables. It stores the conditional probability distribution for each v ariable, given the values in the previous time step. These distributions are like local models that make on e-step predictions about their variable. For each variable, a DBN also specifies which other variables can be ignored when predicting its next value. This is essentially our accurate refinement, whi ch identifies details a local model can ignore. Histories of interest are related to the concept of c ontext-specific independence [12]. Relational Models: Relational models (e.g. [3]) treat the state of the world as a conjunction of predicates. The state evolves using  X  X pdate rules, X  consis ting of pre-conditions specifying when the rule applies and post-conditions (changes to the state). Up date rules are essentially local models with pre and post-conditions playing the roles of histories and tests of interest. Relational models typically focus on Markov worlds. We address partial observ ability by essentially generalizing the  X  X pdate rule. X  The main strength of relational models is tha t they include first-order variables in update rules, allowing for sophisticated parameter tying a nd generalization. We use parameter tying in our experiments, but do not incorporate the formalism of v ariables into our framework. Others: Wolfe and Singh recently introduced the Factored PSR [13] wh ich is essentially a special collection of local models. Also related are maximum entrop y models (e.g. [14], [15]) which represent predictions as weighted products of features of t he future and the past. Large Scale Example: In this section we present preliminary empir-ical results illustrating the application of collections o f local models.
 Our first example is a modified, uncontrolled version of an arc ade game (see Figure 3). The observations are 64  X  42 pixel images. In the im-age is a 2  X  2 pixel ball and a wall of 6  X  4 pixel bricks. After the ball hits a brick, the brick disappears. When the ball hits the bott om wall, it bounces at a randomly selected angle. An episode ends when th ere are no more bricks. In our version there are two types of  X  X pecial bricks. X  After the ball hits a dark brick, all bricks require two hits r ather than one to break. After the ball hits a light brick, all bricks req uire only one hit to break. When they are first placed, bricks are regular (medium gray) with proba bility 0.9 and dark or light each with probability 0.05. This system is stochastic, partially obs ervable (and because of the special bricks, not short-order Markov). It has roughly 10 20 observations and even more underlying states. The decomposition into local models is specified in Table 1 1 . Quite naturally, we have local models to predict how the bricks (rows 1-2), the ball (row 3), and the background (row 4) will behave. This structure satisfies the mutual conditional independence pr operty, and since every pixel is predicted by some model at every history, we can make fully detailed 64  X  42 pixel one-step predictions. More or less subdivision of models could be applied, the trad eoff being the complexity of individual models versus the total number of local models. With the stru cture we have selected there are ap-proximately 25,000 local models. Of course, naively traini ng 25,000 models is impractical. We can improve our data efficiency and training time though paramet er tying. In this system, the behavior of objects does not depend on their position. To take advanta ge of this, for each type of local model Figure 5: Left: Results for the 1D Ball Bounce problem. Error bars are omitted to avoid graph clutter. Right: DBN structure used. All nodes are binary. Th e shaded nodes are hidden. Links from  X  X el. X  at t  X  1 to all nodes at t omitted for simplicity. (12 in total, since there is a ball model for each of the 9 direc tions) we combine all translated tra-jectories associated with various positions and use them to train a single shared model. Each local model maintains its own state, but the underlying model para meters are shared across all models of the same type, associated with different positions. Note th at position does matter in the first time step, since the ball always appears in the same place. As a res ult, our model makes bad predictions about the first time step. For clarity of presentation, we wil l ignore the first time-step in our results. For the local models themselves, we used lookup table based s hort-order Markov representations. Though the overall system is not short-order Markov, each lo cal model is. Our learned local models were first-order Markov except the one responsible for predi cting what will happen to a brick when the ball hits it. This model was second-order Markov. No loca l model had more than 200 states. Figure 4: Results for the ar-cade game example.
 Learning Comparisons: In this experiment, we will compare parameter learning resu lts for col-lections of local models to a few other methods on a simple exa mple, whose complexity is easily controlled. Recall the 1D Ball Bounce. We learned a model of t he 1D Ball Bounce of size 5 and 20 using two collections of local models with no parameter tyin g (using PSRs and POMDPs as local models respectively), two flat models (a PSR and a POMDP), and a DBN 2 .
 Both collections of local models have the following structu re: for every pixel, there are two types of model. One predicts the color of the pixel in the next time s tep in histories when the ball is not in the immediate neighborhood about the pixel. This model ig nores all pixels other than the one it is predicting. The other model applies when the ball is in the pixel. It jointly predicts the colors of the pixel and its two neighbors. This model distinguishes br idging tests in which the ball went to mutual conditional independence property and allows predi ction of primitive one-step tests. As with the arcade game example, in each trial we trained each model on various numbers of episodes (of length 50) and then measured their log likeliho od on 1000 test episodes (also of length 50). We report the likelihood ratio averaged over 20 trials. The results are shown in Figure 5. The collections of local models both perform well, outperformi ng the flat models (dashed lines). Both of the flat models X  performance degrades as the size of the wor ld increases from 5 to 20. The collec-tions of local models are less affected by problem size. The l ocal PSRs seem to take more data than the local POMDPs to learn a good model, however they ultimate ly seem to learn a better model. The unexpected result is that DBN training seemed to perform worse than flat POMDP training. We have no explanation for this effect, other than the fact that different graphical structures could cause different local extrema issues for the EM algorithm. Clearl y, given these results, a more thorough empirical comparison across a wider variety of problems is w arranted.
 Conclusions: We have presented a novel formalization of the idea of a  X  X oca l model. X  Preliminary empirical results show that collections of local models can be learned for large-scale systems and that the data complexity of parameter learning compares fav orably to that of other representations. Acknowledgments Erik Talvitie was supported under the NSF GRFP. Satinder Sin gh was supported by NSF grant IIS-0413004. Any opinions, findings, and conclusions or recomme ndations expressed in this material are those of the authors and do not necessarily reflect the vie ws of the NSF.

