 Frequent subgraph mining is an active research area with successful applications in, e.g., chemoinformatics [15], software science [4], and computer vision [13]. The task is to enumerate the complete set of frequently appearing subgraphs in a graph database. Early algorithms include AGM [8], FSG [9] and gSpan [19]. Since then, researchers paid considerable efforts to improve the efficiency, for example, by mining closed patterns only [20], or by early pruning that sacrifices the completeness (e.g., lea p search [18]). However, graph mining algorithms are still too slow for large graph databases (see e.g.,[17]). The scalability of graph mining algorithms is much worse than those for more restricted classes such as trees [1] and sequences [14]. It is due to th e fact that, for trees and sequences, it is possible to design a pattern extension rule that does not create duplicate patterns (e.g., rightmost extension) [1]. For general graphs, there are multiple ways to generate the same subgraph pa ttern, and it is necessary to detect du-plicate patterns and prune the search tree whenever duplication is detected. In gSpan [19], a graph pattern is represented as a DFS code, and the duplication check is implemented via minimality checking of the code. It is a very clever mechanism, because one does not need to track back the patterns generated so far. Nevertheless, the complexity of duplication checking is exponential to the pattern size [19]. It harms efficiency subs tantially, especially when mining large patterns.

A linear graph is a graph whose vertices are totally ordered [3,5] (Figure 1). For example, protein contact maps, RNA seco ndary structures, alternative splicing patterns in molecular biology and predicate-argument structures [11] in natural languages can be represented as linear graphs. Amino acid residues of a protein have natural ordering from N-to C-terminus, and English words in a sentence are ordered as well. Davydov and Batzoglou [3] addressed the problem of aligning several linear graphs for RNA sequences, assessed the computational complexity, and proposed an approximate algorithm. Fertin et al. assessed the complexity of finding a maximum common pattern in a set of linear graphs [5]. In this pa-per, we develop a novel algorithm, linear graph miner (LGM), for enumerating frequently appearing subgraphs in a large number of linear graphs. The advan-tage of employing linear graphs is that we can derive a pattern extension rule that does not cause duplication, which makes LGM much more efficient than conventional graph mining algorithms.

We design the extension rule based on the reverse search principle [2]. Perhaps confusingly,  X  X everse search X  does not refer to a particular search method, but a guideline for designing enumeration algorithms. A pattern extension rule specifies how to generate children from a parent in the search space. In reverse search, one specifies a rule that generates a parent uniquely from a child (i.e., reduction map ). The pattern extension rule is obtained by  X  reversing X  the reduction map: When gen-erating children from a parent, all possible candidates are prepared and those map-ping back to the parent by the reduction map are selected. An advantage of reverse search is that, given a reduction map, the c ompleteness of the resulting pattern ex-tension rule can easily be proved [2]. In data mining, LCM, one of the fastest closed itemset miner, was designed using rever se search [16]. It is applied in the design of a dense module enumeration algorithm [6] and a geometric graph mining algo-rithm recently [12]. In computational geo metry and related fields, there are many successful applications 1 . LGM X  X  reduction map is very simple: remove the largest edge in terms of edge ordering. Fortunately, it is not necessary to take the  X  X an-didate preparation and selection X  approach in LGM. We can directly reverse the reduction map to an explicit extension rule here. Linear graphs can be perceived as the fusion of graphs and sequences. Sequence mining algorithms such as Prefixspan [14] can usually detect gaped se-quence patterns. In applications like motif discovery in protein contact maps [7], it is essential to allow  X  X aps X  in linear graph patterns. More precisely, discon-nected graph patterns should be allowed for such applications. Since conventional graph mining algorithms can detect only connected graph patterns, their appli-cation to contact maps is difficult. In thi s paper, we aim to detect connected and disconnected patterns with a unified framework.

In experiments, we used a protein 3D-structure dataset from molecular biol-ogy. We compared LGM with gSpan in efficiency, and found that LGM is more efficient than gSpan. It is surprising to us, because LGM detects a much larger number of patterns including disconnected ones. To compare the two methods on the same basis, we added supplementary edges to help gSpan to detect a part of disconnected patterns. Then, t he efficiency difference became even more significant. Let us first define linear graphs and associated concepts.
 Definition 1 (Linear graph). Denote by  X  V and  X  E the set of vertex and edge labels, respectively. A labeled and undirected linear graph g =( V, E, L V ,L E ) consists of an ordered vertex set V  X  N ,anedgeset E  X  V  X  V , a vertex labeling L
V : V  X   X  V and an edge labeling L E : E  X   X  E . Let the size of the linear graph | g | be the number of its edges. Let G denote the set of all possible linear graphs and let  X   X  X  denote the empty graph.
 The difference from ordinary graphs is that the vertices are defined as a subset of natural numbers, introducing the total order. Notice that we do not impose connectedness here. The order of edges is defined as follows: Definition 2 (Total order among edges).  X  e 1 =( i, j ) ,e 2 =( k, l )  X  E g , e &lt; e e 2 if and only if i) i&lt;k or ii) i = k, j &lt; l .
 Namely, one first compares the indices of th e left nodes. If they are identical, the right nodes are compared. The subgraph relationship between two linear graphs is defined as follows.
 Definition 3 (Subgraph). Given two linear graphs g 1 =( V 1 ,E 1 ,L V 1 ,L E 1 ), g an injective mapping m : V 1  X  V 2 such that 1.  X  i  X  V 1 : L V 1 ( i )= L V 2 ( m ( i )) , vertex labels are identical, 3.  X  ( i, j )  X  E 1 : i&lt;j  X  m ( i ) &lt;m ( j ), the order of vertices is conserved. The difference from the ordinary subgraph relation is that the vertex order is conserved. Finally, frequent subgraph mining is defined as follows.
 Definition 4 (Frequent linear subgraph mining). Forasetoflineargraphs G = { g 1 ,  X  X  X  ,g | G | } ,g i  X  X  , a minimum support threshold  X &gt; 0andamaximum pattern size s&gt; 0, find all g  X  X  such that g is frequent enough in G , i.e., Before addressing the frequent pattern mining problem, let us design an algo-rithm for enumerating all subgraphs of a linear graph. For simplicity, we do not consider vertex and edge labels in this section, but inclusion of the labels is straightforward. 3.1 Reduction Map Suppose we would like to enumerate all subgraphs in a linear graph shown in the bottom of Figure 2, left. All linear subgraphs form a natural graph-shaped search space, where one can traverse upwards or downwards by deleting or adding an edge (Figure 2, left). For enumeration, however, one has to choose edges in the search graph to form a search tree (Figure 2, right). Once a search tree is defined, the enumeration can be done either by depth-first or breadth-first traversal. To this aim, we specify a reduction map f : G X  X  which transforms a child to its parent uniquely. The mapping is chosen such that when it is applied repeatedly, we eventually reduce it to an element of the solution set S X  X  . Formally, we write  X  x  X  X  :  X  k  X  0: f k ( x )  X  X  . In our case, the reduction map is defined as removing the  X  X argest X  edge from the child graph. The largest edge is defined via the total order introduced in Definition 2. By evaluating the mapping repeatedly the graph is shrunk to the empty graph. Thus, here we have S = {  X  } .
By applying f ( g ) for all possible g  X  X  , we can induce a search tree with  X   X  X  being the root node, shown in Figure 2, right. A question is if we can always define a unique search tree for any linear graph. The reverse search theorem [2] says that the proposition is true iff any node in the graph-shaped search space converges to the root node (i.e., empty graph) by applying the map a finite number of times. For our reduction map, it is true, because each possible linear graph g  X  X  is reduced to the empty graph by successively applying f to g .
A characteristic point of reverse search is that the search tree is implicitly defined by the reduction map. In actual traversal, the search tree is created on demand: when a traverser is at a node with graph g and would like to move down, a set of children nodes are generated by extending g . More precisely, one enumerate all linear graphs by inverting the reduction mapping such that the tree is explored from the root node towards the leaves.

The inverse mapping f  X  1 : G X  X   X  generates for a given linear graph g  X  X  a set of extended graphs X = { g | f ( g )= g } .

There are three types of extension pa tterns according to the number of added nodes in the reduction mapping: (A) no-node-addition, (B) one-node-addition, (C) two-nodes-addition. Let us define the largest edge of g as ( i , j ) , i &lt; j . Then, the enumeration of case A is done by adding an edge which is larger than ( i , j ). For case B, a node is inserted to the position after i , and this node is connected to every other node. If the new edge is smaller than ( i , j ), this extension is canceled. For case C, two nodes are inserted to the position after i . In that case, the added two nodes must be connected by a new edge . All patterns of valid extensions are shown in Figure 3. This example does not include node labels, but for actual applications, node labels need to be enumerated as well. In frequent pattern mining, we employ the same search tree described above, but the occurrence of a pattern in all linear graphs are tracked in an occurrence list L G ( g ) [19], defined as follows: Algorithm 1. Linear Graph Miner (LGM) When a pattern g is extended, its occurrence list L G ( g ) is updated as well. Based on the occurrence list, the support of each pattern g , i.e., the number of linear graphs which contains the pattern, is calculated. Whenever the support is smaller than the threshold s , the search tree is pruned at this node. This pruning is possible, because of the anti-monotonicity of the support, namely the support of a graph is never larger than that of its subgraph. Algorithm 1 describes the recursive algorithm for frequent mining. In line 13, each pattern g is extended to larger graphs g  X  f  X  1 ( g ) by inverse reduction mapping f  X  1 . The possible extensions f  X  1 ( g ) for each pattern g are found using the location list L G ( g ). The function Mine is recursively called for each extended pattern g  X  f  X  1 ( g ) in line 15. The graph pruning happens in lines 7, if the support for the pattern g is smaller than the minimum support threshold  X  or in line 11 if the pattern size | g | is equal to the maximum pattern size s . The computational time of frequent pattern mining depends on the minimum support and maximum pattern size thresholds [19]. Also, it depends on the  X  X en-sity X  of the database: If all graphs are almost identical (i.e., a dense database), the mining would take a prohibitive amount of time. So, conventional worst case analysis is not amenable to mining algorithms. Instead, the delay ,intervaltime between two consecutive solutions, is ofte n used to describe the complexity. Gen-eral graph mining algorithms including gSpan are exponential delay algorithms, i.e., the delay is exponential to the size of patterns [19]. The delay of our algo-rithm is only polynomial, because no duplication checks are necessary thanks to the vertex order.
 Theorem 1 (Polynomial delay). For N linear graphs G , a minimum support  X &gt; 0 , and a maximum pattern size s&gt; 0 , the time between two successive calls to Report in line 9 is bounded by a polynomial of the size of input data. Proof. Let M := max i | V g i | , F := max i | E g i | . The number of matching locations in the linear graphs G can decrease in case g is enlarged, becaus e the only largest edge is added. Considering the number of variations, it is easy to see that the location list always satisfies | L G ( g ) | X  M 2 N . Therefore, the mapping f  X  1 ( g )can be produced in O ( M 2 N ) time, because the procedure searches for the location list in line 13.

The time complexity between two successive calls to Report can now be bounded by considering two cases after Report has been called once.  X  Case 1. There is an extension g fulfilling the minimum support condition,or  X  Case 2. There is no extension g fulfilling the minimum support condi-Thus, the total time between two successive calls to Report is bounded by O ( M 2 NF ). We performed a motif extraction experiment from protein 3D structures. Frequent and characteristic patterns are often called  X  X otifs X  in molecular biol-ogy, and we adopt that terminology here. All experiments were performed on a Linux machine with an AMD Opteron processor (2 GHz and 4GB RAM). 6.1 Motif Extraction from Protein 3D Structures We adopted the Glyankina et al X  X  dataset [7] which consists of pairs of homol-ogous proteins: one is derived from a t hermophilic organism and the other is from a mesophilic organism. This dataset was made for understanding struc-tural properties of proteins which are responsible for the higher thermostability of proteins from thermophilic organisms compared to those from mesophilic or-ganisms. In constructing a linear graph from a 3D structure, each amino acid is represented as a vertex. Vertex labels are chosen from { 1 ,..., 6 } , which repre-sents the following six classes: aliphatic { AV L I M C } ,aromatic { FWYH } , polar {
STNQ } , positive { KR } , negative { DE } , special (reflecting their special con-formation properties) { GP } [10]. An edge is drawn between the pair of amino acid residues whose distance is within 5 angstrom. No edge labels are assigned. In total, 754 graphs were made. Average number of vertices and edges are 371 and 498, respectively, and the number of labels is 6. To detect the motifs char-acterizing the difference between two organisms, we take the following two-step approach. First, we employ LGM to find frequent patterns from all proteins of both organisms. In this setting, we did not use (c-6) patterns in Figure 3. Fi-nally, the patterns significantly associat ed with organism difference are selected via statistical tests.

We assess the execution time of our algorithm in comparison with gSpan. The linear graphs from 3D-structure proteins are not always connected graphs and the gSpan can not be applied to such disconnected graphs. Hence, we made two kinds of gaped linear graph: 1-gap linear graph and 2-gap linear graph. 1-gap linear graph is a linear graph whose con tiguous vertices in a protein sequence are connected by an edge; 2-gap linear graph is a 1-gap linear graph whose two vertices skipping one in a protein seque nce are connected by an edge (Figure 4). We run gSpan on two datasets: one consists of 1-gap linear graphs and the other consists of 2-gap linear graphs. We run LGM on the original linear graphs. We set the maximum execution time to 12 hours for both programs. Figure 5 shows the execution time by changing minimum support thresholds. gSpan does not work on the 2-gap linear graph dataset even if the minimum support threshold is 50. Our algorithm is faster than gSpan on the 1-gap linear graph dataset, and its execution time is reasonable.

Then, we assess a motif extraction ability of our algorithm. To choose signif-icant subgraphs from the enumerated subgraphs, we use Fisher X  X  exact test. In this case, a significant subgraph should distinguish thermophilic proteins from mesophilic proteins. Thus, for each frequent subgraph, we count the number of proteins containing this subgraph in the thermophilic and mesophilic proteins; and generate a 2  X  2 contingency table, which includes the number of thermophilic organisms that contain subgraph gn TP , the number of thermophilic organisms that does not contain a subgraph gn FP , the number of mesophilic organisms that does not contain a subraph gn FN and the number of mesophilic organisms that contain a subgraph gn TN . The probability representing the independence in the contingency table is calculated as follows: where n P is the number of thermophilic proteins; n N the number of mesophilic proteins; n g the number of proteins with a subgraph g ; n g the number of proteins without a subgraph g . The p-value of the two-sided Fisher X  X  exact test on a table can be computed by the sum of all probabilities of tables that are more extreme than this table.

We ranked the frequent subgraphs according to the p-values, and obtained 103 subgraphs whose p-values are no more than 0.001. Here, we focused on a pair of proteins, TATA-binding protein and human polII promotor protein, where TATA-binding protein is derived from a thermophilic organism and human polII promotor is from a mesophilic organism. The reason we chose these two proteins is that they include a large number of statistically significant motifs which are mutually exclusive between two organis ms. These two proteins share the same function as DNA-binding protein, but their thermostabilities are different. Fig-ure 6 shows the top-3 subgraphs in significance. Figure 7 shows 3D-structure proteins, TATA-binding protein (left) and human polII promotor protein(right), and the amino acid residues forming top3-subgraphs are represented by spheres. We proposed an efficient frequent subgraph mining algorithm from linear graphs. A key point is that vertices in a linear gra ph are totally ordered. We designed a fast enumeration algorithm from linear graphs based on this property. For an ef-ficient enumeration without duplication, we define a search tree based on reverse search techniques. Different from gSpan, our algorithm enumerates frequent sub-graphs including disconnected ones by traversing this search tree. Many kinds of data, such as protein 3D-structures and alternative splicing forms, which can be represented as linear graphs, include disconnected subgraphs as important patterns. The computational time of our algorithm is polynomial-delay.
We performed a motif extraction experim ent of a protein 3D-structure dataset in molecular biology. In the experiment, our algorithm could extract important subgraphs as frequent patterns. By comparing our algorithm to gSpan with respect to execution time, we have shown our algorithm is fast enough for the real world datasets.

Data which can be represented as linear graphs occur in many fields, for instance bioinformatics and natural language processing. Our mining algorithm from linear graphs provide a new way to analyze such data. This work is partly supported by research fellowship from JSPS for young sci-entists, MEXT Kakenhi 21680025 and the FIRST program. We would like to thank M. Gromiha for providing the protein 3D-structure dataset, T. Uno and H. Kashima for fruitful discussions.

