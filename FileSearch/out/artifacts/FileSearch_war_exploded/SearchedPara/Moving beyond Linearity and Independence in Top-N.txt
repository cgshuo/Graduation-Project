 This paper suggests a number of research directions in which the recommender systems can improve their quality, by mov-ing beyond the assumptions of linearity and independence that are traditionally made. These assumptions, while pro-ducing effective and meaningful results, can be suboptimal, as in lots of cases they do not represent the real datasets. In this paper, we discuss three different ways to address some of the previous constraints. More specifically, we fo-cus on the development of methods capturing higher-order relations between the items, cross-feature interactions and intra-set dependencies which can potentially lead to a con-siderable enhancement of the recommendation accuracy. During the last years, the area of top-N recommendation has received great attention and become widespread [3]. The methods developed [7, 8, 10, 11, 13, 14] provide better recom-mendations as the years go by. However, there are still some simplifications assumed that might not always represent re-ality. When this is the case, the methods developed clearly suffer from the ignorance of this valuable information, that is anyway present in the dataset.
 The first assumption that is commonly made is the one of independence. In a k -nearest neigbors system [8], it is as-sumed that every item that the user has purchased indepen-dently contributes to the rating score that the user would give to another target item. This assumption holds in a lot of commercial modern systems, like the ones suggesting a set of songs to a user, based on his listening history [5]. Moving beyond independence, the vast majority of recom-mender systems developed are still simple; they mostly cre-ate linear models. An example of this is a modern top-N rec-ommendation method [11] that performs better than other algorithms and it is based on a linear regression model. In the same way, when side information is taken into account, it still exploits linear relations between the features [4, 12, 17]. We think that these assumptions while providing us with easy-to-interpret and simple models, they set a limit to the capabilities of recommender systems. By allowing recom-mender systems to develop more complex methods that will better capture real-life data, we may be able to get more effective and powerful recommendations. It should be noted that such approaches have already been introduced [15, 16] for rating prediction methods. However, this is not the case for top-N recommendation methods. Also, it has been shown [7] that top-N recommendation methods and rat-ing prediction methods exhibit different characteristics, so a simple extension would not suffice. Towards this direc-tion, in this work, we will investigate the following research questions: The way we have addressed or plan to address the above re-search questions is analyzed in the following sections. Initial results [6] show that more complex interactions exist in the datasets and when taken into account, they can improve the recommendation quality. Current top-N recommendation methods compute the rec-ommendations by taking into account only relations between pairs of items. However, when higher-order relations be-tween items exist, the above approach is suboptimal. In [6], we propose a way (HOSLIM) to incorporate higher-order relations in recommender systems.
 More specifically, we first verify the existence of higher-order relations in real-world datasets, by measuring how prevalent are the itemsets with strong association beyond the items that comprise it (beyond pairwise associations). We use dif-ferent metrics to measure the strength of the associations and different ways to measure how well the itemsets with strong association cover the datasets. From our analysis, we conclude that the presence of higher-order relations in dif-ferent real-world datasets is clear and it cannot be ignored. We then specify the itemsets, i.e. the sets of items that are co-purchased by at least  X  users in the dataset. We compute the likelihood that a user will buy a specific item as a sparse aggregation of both the items and the itemsets purchased by the user. Our method builds upon the SLIM method [11] which estimates the rating that a user would give to an item as a sparse aggregation of the items rated by the user: where R is the user  X  items rating matrix and S is the sparse aggregation coefficient matrix learned, that represents the similarities between the items.If R 0 denotes the users  X  itemsets matrix containing the information whether a user purchased all the items constituting an itemset, then the model pro-posed by our apporach is: The sparse matrix representing the similarities between items and itemsets ( S 0 ) as well as S are learned, by solving an l and l 2 regularized optimization problem. These matrices are used during the prediction time, in order to recommend the best top-N items to a user, by taking into account the higher-order information captured by the itemsets-items in-teraction.
 After doing a full parameter study, exploring different levels of sparsity as well as different values of support threshold, we saw that the proposed method outperforms a variety of other top-N recommendation methods: the traditional and popular k -nearest neighbors [8], SLIM which is a mod-ern top-N recommendation method outperforming the rest of the existing top-N methods [11] and HOKNN, which is the method that was the first to incorporate itemsets into the recommendation [8]. On top of that, we showed that there is a strong positive correlation between the existence of higher-order relations in a dataset and the performance of the proposed method, which demonstrates that our method can indeed capture effectively the existence of higher-order information and use it to improve the recommendation qual-ity. In addition, we suggested a constrained version of our method, which controls the complexity and provides more efficient recommendations. By introducing this constraint, the recommendation performance is either not affected at all in some cases, or slightly decreased but still higher than the performance of the competing methods. In this way, our method can be easily used in order to provide good-quality recommendations fast.
 The main purpose of this work was to answer the research question whether higher-order information exists in real-world datasets and whether incorporating it could help the recommendation quality. The take-away message was that by coupling the incorporation of higher-order associations (when they do exist) with a state-of-the-art top-N method, the quality of the recommendations made is improved be-yond the current best results. Modern recommender systems in general also have side in-formation, except from the traditional rating data. Side in-formation could be user-based, like user demographics (e.g. age, gender, ethnicity, country of residence, user interests), or item-based (e.g.product characteristics), or both. A lot of recommender systems also have reviews , which are asso-ciated with the ratings themselves. By aggregating all the reviews written about a specific item, we have item side in-formation and similarly by aggregating all the reviews writ-ten by a specific user, we have user side information. Differ-ent recommendation methods [4,12,17,19] take into account side information, as it enriches the ratings with additional features which if used properly can help improve the recom-mendation quality.
 The existing approaches for incorporating side information exploit linear relations between the features. This means that the rating a user would give to an item is predicted as a linear combination of the different features of the user/item side information. However, these methods do not incorpo-rate the interaction between the features. For example, let X  X  suppose that a user is interested in articles related to  X  X ec-ommender Systems X . This feature is indicative of the fact that he will like articles related to  X  X ollaborative Filtering X  or  X  X atrix factorization X . Such cross-feature interactions are often not explicitly modeled by the methods.
 In the work we are planning to do, we would like to better capture such cross-feature interactions, in the form of a bi-linear model. More specifically, if I (items  X  item-features) is the matrix capturing item-side information, we will learn a matrix F (item-features  X  item-features) that will capture the cross-feature interaction. Specifically, the model used to estimate the ratings that users will give to items will be: It is worth noting that RI basically represents the user side information, as for every user, his side information is the aggregation of the item side information of the items he rated.
 In the same way, we can also incorporate user side infor-mation, too. If U (users  X  user-features) is the matrix cap-turing user-side information, then we can learn a matrix W (user-features  X  user-features) that will also capture the cross-feature interaction, for the user side now. Then, the model will be: We can either use Equations 3 and 4 individually, or we can combine them (depending on how sparse our datasets are) to get where  X  denotes the strength of the user vs item side infor-mation.
 In order to produce better quality results, apart from the side information, we can also incorporate a collaborative fil-tering component, which will take into account only the rat-ing information. Different models can be used to include the rating information, but we will use the SLIM model [11] which estimates the rating that a user would give to an item as a sparse aggregation of the items rated by the user, described in Equation 1. Then by combining Equations 1 and 5, we get: where  X  is also a parameter.
 For a more complete model, we can also include the linear side information. In [12], it was shown that the best method is a collective approach in which it is assumed that there exist correlations between users X  copurchase behaviors on two items and the similarity of those items X  side information. Thus, the weight matrix S that represents the weights on the ratings should also represent the weights on the features of the side info. In other words, S should satisfy  X  R = RS , as well as  X  I = IS.
 Finally, in order to tie all the pieces together and in order to get the best possible results, since we took into account the cross-feature interactions, apart from the linear part, we can also take into account the higher-order rating information, apart from the linear part. Then, Equation 6 combined with Equation 2 becomes:  X 
R =  X  ( RS + R 0 S 0 ) +  X RIFI T + (1  X   X   X   X  ) UWU T R. (7) Top-N recommender systems provide a list of N items, in which the user will be likely interested in. The items that are recommended are the ones that have the highest scores. However, this does not guarantee that the list as a whole is the best possible, even though the individual items are [2,9]. The reason is that the individual items could be very similar. For example, if the item with the highest score for a user is the book  X  X lice in Wonderland X  and there are two different versions of this book, a paperback and a hard one, then normally these two different versions have very high scores, so there is a high probability that they will end up both being recommended to the user, resulting in the user losing another meaningful recommendation.
 This happens a lot, in many recommender systems. One example is music playlists, when the same artist X  X  songs are recommended again and again, or even worse all the versions of the same song are played. Another example is groceries recommendation, when let X  X  say a user is recommended both yellow and green bananas. Finally, another example is the advertisements in a commercial break, that are played in a row.
 We propose to stop recommending every item in the list independently but instead follow a set-recommendation ap-proach that will take into account the intra-set dependen-cies. In order to do this, we will use the side information of the items. For every item, we will find its k -nearest neigh-bors, in terms of side information features. Very similar items share a lot of the same intrinsic properties, that are encoded in side information. A very high similarity value threshold with the item in question will be imposed. If no neighbors exceeding this high threshold are found for an item, this is acceptable, as we would not like a system that probably eliminates items of importance to the user. More analytically, top-N recommendation methods create an ordered list of all items for every user. This list is ordered according to how likely a user is to buy this item. The top-N items of this list are provided to the user. In our proposed method, for the first item in the top-N list, the k nearest neighbors of that item are removed from the set of potential candidate items recommended to the user. If the top-N list contained none of these neighbors, nothing changes. If the top-N list contained one or more of these neighbors, then the overall list of items is shifted one or more positions respectively, resulting in a different set of N items being on the top, thus having a new top-N list. The same procedure is done for the second, the third until the N th item in the list. In the end, the top-N list provided to the user will provide only high-quality recommendations, without two or more items in the list being extremely similar.
 The existing methods [18] try to tackle the above problem, in training time, having the users create collections. However, in the vast majority of systems, this is not the default user behavior. Users usually like or buy some items, without creating explicit collections. We believe that it is important in order to address the problem, not to modify user behavior. In order to do this, we will change the prediction part of the model, and not the learning part.
 Other existing methods [1, 2] focus on diversity or creating non-obvious recommendations. However, our primary goal is the recommendation quality, so we are totally fine if the recommendations made are not the most unexpected or di-verse to a user. In the trade-off diversity vs accuracy, they choose diversity, by making sure that the accuracy does not fall down a prespecified threshold. However, we focus on accuracy. Also, by eliminating only items that it is really crucial to be removed, in order to avoid a repetitive list, we manage to present additional items, that might be of interest to a user, thus potentially even improving the ac-curacy. Also, in [1], the approach presented will be tried in the context of a massive open online course, but we will try it on a wide variety of datasets that may have different characteristics from an online course. For example, in an online course, there is the notion of prerequisites that will be taken into account, but in other datasets like groceries, this notion does not exist, so we should provide good-quality, diverse recommendations without the help of this notion. In this work, we wish to evolve recommender systems to a stage in which the methods developed will not rely on over-simplifications, such as linearity and independence. These assumptions are commmonly made in the methods devel-oped in recommender systems. Based on these assumptions, we can get recommendation results that are general and in some cases sufficient.
 However, in a lot of real-world datasets, these assumptions do not hold, resulting in the methods relying on those to underperform. In order to improve the recommendation quality, we think that we should make full use of the dif-ferent data we have available and learn the more complex relations that might characterize them. The ultimate goal is to develop more sophisticated and realistic models that will improve the recommendation quality. Towards this direction, in this extended abstract, we suggest three different ways in which this can be achieved. First, we suggest taking into account the higher-order relations in users X  rating data. The existing recommender systems com-pute pairwise associations. However, in real life, purchasing a subset of items in a set might significantly increase the like-lihood of purchasing the rest (e.g. in a grocery store users tend to buy items that form the ingredients in recipes). Also, we suggest finding the cross-feature interactions, as many approaches for incorporating side information exploit only linear relations between the features. Finally, we propose developing set recommendation algorithms, that will take into account the intra-set dependencies. In this way, we will predict a set of items such that the overall quality of the set will not just be the sum of the quality values of its members. This work was supported in part by NSF (IOS-0820730, IIS-0905220, OCI-1048018, CNS-1162405, and IIS-1247632) and the Digital Technology Center at the University of Min-nesota. Access to research and computing facilities was pro-vided by the Digital Technology Center and the Minnesota Supercomputing Institute. [1] Panagiotis Adamopoulos. Beyond rating prediction [2] Gediminas Adomavicius and YoungOk Kwon.
 [3] Gediminas Adomavicius and Alexander Tuzhilin.
 [4] Deepak Agarwal and Bee-Chung Chen.
 [5] Fabio Aiolli. A preliminary study on a recommender [6] Evangelia Christakopoulou and George Karypis.
 [7] Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. [8] Mukund Deshpande and George Karypis. Item-based [9] Derek L Hansen and Jennifer Golbeck. Mixing it up: [10] Yifan Hu, Yehuda Koren, and Chris Volinsky.
 [11] Xia Ning and George Karypis. Slim: Sparse linear [12] Xia Ning and George Karypis. Sparse linear methods [13] Rong Pan, Yunhong Zhou, Bin Cao, Nathan Nan Liu, [14] Steffen Rendle, Christoph Freudenthaler, Zeno [15] Steffen Rendle and Lars Schmidt-Thieme.
 [16] Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey [17] Ajit P Singh and Geoffrey J Gordon. Relational [18] Greg Walsh and Jennifer Golbeck. Curator: a game [19] Shuang-Hong Yang, Bo Long, Alex Smola, Narayanan
