 Label propagation exploits the structure of the unlabeled documents by propagating the label information of the train-ing documents to the unlabeled documents. The limita-tion with the existing label propagation approaches is that they can only deal with a single type of objects. We pro-pose a framework, named  X  relation propagation  X , that allows for information propagated among multiple types of objects. Empirical studies with multi-label text categoriza-tion showed that the proposed algorithm is more effective than several semi-supervised learning algorithms in that it is capable of exploring the correlation among different cate-gories and the structure of unlabeled documents simultane-ously.
 H.3.3 [ Information Storage ad Retrieval ]: [Informa-tion Search and Retrieval]; I.2.6 [ Artificial Intelligence ]: Learning X  Concept Learning Algorithms, Experimentation, Theory Label propagation, Relation propagation, Semi-supervised Learning, Graph Laplacian
Label propagation is proven to be effective for both text categorization and information retrieval [2, 1, 4, 3]. The key idea is to estimate the confidence scores of the unlabeled documents by propagating the label information of the la-beled documents through the similarity graph among doc-uments. The limitation of most previous work is that they did not consider the scenarios in many applications that the label information needs to be propagated not only among Figure 1: An example of the connected graph for relation propagation objects of the same type, but also between objects of differ-ent types. For instance, multi-label classification problem has two types of objects: documents and categories.
We propose a generalized propagation framework for mul-tiple types of objects (in particular, documents and cat-egories) which propagates the relationship between docu-ments and categories. We construct a weighted graph as follows: each node O ( i,j ) =( d i ,c j ) in the graph represents the relationship that document d i belongs to the category c ;anytwonodes O ( i,j ) and O ( k,l ) in the graph are con-nected by an edge whose weight reflects the correlation be-tween the two corresponding relationships. In other words, a large similarity between node O ( i,j ) and O ( k,l ) indicates that document d i is likely to be assigned to class c i if docu-ment d k belongs to class c l , and vice versa. It is important to note that class c k and c l can be different in the above propagation scheme. Figure 1 illustrates an example of the graph for the relation propagation with three documents and three categories. we refer to the proposed framework as  X  Relation Propagation  X , or RP for short. we first describe the framework of relation propagation for two types of objects, followed by the generalization to multiple types of objects.

Let A =( a 1 ,a 2 ,...,a n )and B =( b 1 ,b 2 ,...,b m )denote the two types of objects. Let f ( a i ,b j ): A X B X  R de-note the relation function between an object of type A and an object of type B .Let y denote the vector of size mn whose element y ( i,j ) corresponds to the relation f ( a double index ( i, j ) is used to refer an element in vector y . For the convenience of discussion, we assume that the first N l elements in vector y , denoted by y l , are the labeled re-lations, and the remaining N u = mn  X  N l elements in y , denoted by y u , are the unlabeled relations that need to be predicted. Finally, let S A =[ S A i,j ] n  X  n and S B =[ S denote the matrices of similarities among the objects of type A and among the objects of type B , respectively. The energy function can be defined as follows: erator is defined as a diagonal matrix whose diagonal element is that minimizes the energy function is Replacing normal similarity matrices with normalized simi-larity matrices, y u can be defined as:
It is straightforward to extend the above formulism to the case of multiple types of objects. Let T =( O 1 , O 2 ,..., denote the t different types of objects. Let f : O 1  X O 2 O t  X  R denote the relation function among t different types of objects. Let { S k =[ S k i,j ] n k  X  n k ,k =1 , 2 ,...,t similarity matrices for the t types of objects. We then have the energy function for the t types of objects written as: where each element in the vector y , i.e., y ( o 1 i responds to the relation f ( o 1 i 1 ,o 2 i 2 ,...,o t i t lar to the one in Equation (2) will minimize the above energy function.

It is straightforward to apply the framework of relation propagation to multi-label learning. Let X  X  denote the col-lection of documents by D =( d 1 , d 2 ,..., d n ), and the set of categories by C =( c 1 ,c 2 ,...,c m ). Then, the relation f ( d i ,c j ) is a binary function that outputs 1 when document d belong to the j -th category, and 0 otherwise. Using simi-(3) for multi-label learning can be expanded as:
We compare the proposed algorithm to the label propaga-tion approach(LP), KNN method and spectral graph trans-ducer (SGT) for multi-label learning. We randomly selected 100 categories and textual description of 1000 images as our testbed from the ESTA 1 . For the selected testbed, the num-ber of documents for each category varies from 14 to around 176, and the average number of documents per category is around 44. Meanwhile, the number of categories per docu-ment varies from 1 to 12, and the average number of cate-gories per document is around 4.

We evaluate the proposed algorithm using F1 measure based on precison/recall across documents (micro-average) and precision/recall across categories (macro-average) at the first 20 ranks. Finally, 10% of documents are used for train-ing and 90% are used for testing. The average F1 measure for 10 fold is used as final evaluation metric. Figure 2 shows the classification results.
In this paper, we presented a graph-based framework for label propagation, named  X  X elation propagation X , that al-lows for propagating label information among multiple types of objects simultaneously. Empirical studies with multi-label text categorization have verified that the proposed al-gorithm for multi-label learning is more effective than both the label propagation using harmonic functions and the spec-tral graph transducer, particularly when the number of train-ing examples is small. [1] W. Chu and Z. Ghahramani. Preference learning with [2] C. Williams. Computation with infinite neural [3] D. Zhou, B. Sch  X  olkopf, and T. Hofmann.
 [4] X. Zhu, Z. Ghahramani, and J. D. Lafferty.
 http://ir.shef.ac.uk/imageclef/2004/stand.html
