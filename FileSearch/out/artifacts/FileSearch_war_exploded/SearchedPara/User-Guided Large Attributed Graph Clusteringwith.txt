 Jianping Cao 1 , Senzhang Wang 2( With the coming of big data era, the clustering of large attributed graphs has drawn a lot of research attention. One of the major challenges in this field is the attribute selection, which has not been fully explored. Recent research addressed this problem either by using the properties of datasets (e.g. the data density, the topology) [ 1 , 2 ] or by applying user preference to guide clustering [ 7 ]. As user-guided clustering is more interpretable and flexible, it attracts more research attentions recently [ 4  X  7 ]. Different from conventional unsupervised clustering methods, user-guided clustering is semi-supervised which allows a user to select a small amount of samples for a particular cluster based on his/her preference. However, existing user-guided clustering assumes there is only one user to anno-tate the preferred samples. The clustering results largely rely on the labeled samples given by the user. Thus the clustering results may largely rely on the user selected samples based on his/her knowledge on the graph. A potential issue is that the clustering can be biased to the user X  X  preference or knowledge. In this paper, we propose a framework for user-guided large attributed graph clustering which allows multiple users to annotate their preferred samples inde-pendently. An individual may only have partial knowledge about the target clus-ters, and multiple annotators provide us an effective way to reveal the common knowledge toward a specific issue. Here we borrow the idea of crowdsourcing [ 18 , 24 ] for user-guided clustering with multiple annotations. The general idea can be illustrated by Fig. 1 . Suppose three annotators answer such a common ques-tion, e.g.,  X  X ho are the data mining researchers? X  As depicted in Fig. 1 ,eachof the annotators gives his/her own annotation based on their own knowledge inde-pendently. However, since the data is too big, the annotations are sparse and may hardly overlap [ 23 ]. If we only use one of the annotations, we may get the clusters of  X  X BM Ph.D students, X   X  X omputer science professors, X  or  X  X AKDD authors. X  However, if we combine the annotations together, we may find out the clusters of  X  X ata mining researchers X  through the shared conferences of  X  X ata mining. X  There are two major challenges for introducing multiple annotators to anno-tate the samples for cluster analysis. (1) It is challenging to combine the annota-tions of different users due to the fact that the annotations are not only sparse but also overlap very little. Thus it is hard to apply conventional techniques like major-ity voting to combine them in a straightforward manner. (2) It is also challenging to address the scalability issue of the proposed approach. Under the background of big data, the graph scale can be extremely large and the attribute dimensions can be very high, developing a scalable algorithm is becoming critically important. To address the above mentioned challenges, we propose an approach for C lustering G raphs with M ultiple A nnotations ( CGMA ). A basic assumption here is that each annotator may label the samples of the preferred clusters based on only a few of the sample attributes instead of all of them [ 7 ]. With such an assumption, we map each annotation to the attribute space to obtain the weight vector denoting the relevance of attributes. In this way, the problem of combining sparse annotations is transformed into combining the weight vectors correspond-ing to the annotators in the common attribute space. Once the combined weight vector is obtained, we use it re-weigh the entire network to obtain a pure seed set which we used it for further clustering. The target cluster will be obtained by expanding these seed sets using a local partitioning method. The contributions of this paper can be addressed as follows,  X 
We introduce a novel problem of user-guided clustering in large attributed networks with multiple annotations. Different from previous user-preference guided clustering, which is often biased, using multiple annotations can alle-viate the bias. To the best of our knowledge, this is the first paper applying multiple annotations for graph clustering.  X 
We propose a two-step clustering approach CGMA to address the proposed problem. CGMA combines multiple annotations in an unbiased way, and it also amplifies the sparse annotations by re-sampling and expansion process.
The proposed approach has near-linear time complexity.  X  We conduct a series of experiments on various large networks to examine
CGMA . The experimental results show the effectiveness and efficiency of our method.
 related work of this research. Section 3 gives the details of the CGMA algo-rithm. Next, we will show the experimental results of CGMA on real networks compared with some competitive baselines in Sect. 4 . Finally, Sect. 5 concludes the paper. Clustering of homogeneous graphs can be sorted into two groups, the plain graph clustering and the attributed graph clustering. Traditional methods mostly target at plain graphs, and they have been well studied in literatures, for example, the partitioning methods METIS [ 27 ] and spectral clustering [ 14 ] aim to find a k -way partitioning of the graph. Community detection methods [ 16 ] cluster the graph into variable size communities, which is significantly different from partitioning-based methods. Autopart, cross-associations [ 4 ], and information theoretic co-clustering [ 13 ] are parameter-free examples to graph clustering methods. Several methods [ 19 , 20 ] also allow clusters to overlap as observed in real-world social and communication networks. However, all of these methods are limited to plain graphs (without attributes). Compared to the wide range of works on plain graph mining, there has been much less works on attributed graphs. The representa-tive methods [ 2 , 11 ] aim to partition the given graph into structurally dense and attribute wise homogeneous clusters. These methods, however, enforce attribute homogeneity in all attributes. Recently some methods loosen this constraint by unsupervised feature selection [ 1 ] to extract cohesive subgraphs with homogene-ity in a subset of attributes. However, all of these methods either do not perform a selection of attributes, or select the attributes in a biased way. Semi-supervised clustering applies a small amount of labeled data to aid and bias the clustering of unlabeled data [ 8 ]. There are various kinds of methods for semi-supervised clustering considering user-given pairwise constraints like  X  X ust-link X  and  X  X annot-link X  [ 10 ]. It is also known as constraint-based clustering where the constraints are often strict to follow [ 12 ]. However, most of these methods are based on vector data, thus they are not applicable to graphs with attributes. Methods on seeded community mining [ 19 , 22 ] find communities around (user-given) seed nodes. However, those methods find structural communities on plain graphs and neither are applicable to attributed graphs, nor enable user guid-ance on attributes. Our proposed method has two advantages compared with above mentioned methods. First, we apply user-given example sets to automat-ically infer the possible combination of representative attributes. Second, the constraints of traditional semi-supervised clusterings are hard, while the con-straints given by different users are soft, causing the combination problem to be addressed in this study. In this section, we will present the framework of CGMA to address the prob-lem of using multiple annotations to guide attributed graph clustering. First of all, we give the formulation of our problem. Given a large attributed graph G ( V, E, F ) with | V | = n nodes and | E | = m edges, where each node is associated with |
F | = d attributes, we target to extract cluster C from G of K users. Each user independently labels the samples based on his/her own knowledge. The samples annotated by the k -th user are denoted as set U k , we assume that nodes inside it are similar to each other, and they are dissimilar to the nodes outside the set. 3.1 Framework The proposed approach CGMA combines the annotations first in an unbiased way to obtain the guidance information. Then, a local clustering method is applied to cluster the graph with the guidance of combined annotations. Thus, CGMA addresses the problem in two phases, the annotations combination and cluster extraction.
 Annotations Combination. Since the annotations are sparse labels with little overlaps, straightforward methods like majority voting may not effectively cap-ture the relations among the annotations. In this paper, we combine the anno-tations through each one X  X  inferred weights in relevance to the feature space. Here are two major steps. The first step is mapping the annotations to the attribute space to facilitate measuring the similarity of the annotations. For different annotators, the attributes they think are essential to a particular clus-ter may be different due to their biased knowledge. Our first goal is to infer the attribute weights of U k ( k  X  X  1 ,  X  X  X  ,K } ) that make the example nodes as similar to each other as possible. The similarity between two nodes can be measured by the (inverse) Mahalanobis distance: the distance between two nodes with feature weight matrix A k as a positive definite matrix [ 3 ], and it denotes the attribute weight that is relevant to annotator k s preference.
 metric learning problem [ 3 ]. The essence is to minimize the distance among the nodes in U k . The optimal A k can be obtained by solving the following convex optimization problem. respectively. Following [ 7 ], we consider the annotated node pairs as similar set, and the un-annotated node pairs as dissimilar set. The un-annotated pairs are randomly selected from the edges of un-annotated part. To emphasize the differ-ence between similar and dissimilar set, we set | P k D | P
D [ 17 ]. According to [ 3 ], the above objective function is convex and enables effi-cient, local-minima-free algorithms to solve it, especially for a diagonal solution. each sample set. Since A k is a diagonal matrix, we assign attribute vector  X  k = diag ( A k )( k  X  1 ,  X  X  X  ,K ) and combine the vectors  X  tance [ 15 ]. Each weight vector  X  k can be viewed as a point in a d -dimensional Euclidean space, where the distances d ij ( i, j  X  1 ,  X  X  X  measured by Euclidean distance. For each point  X  k , we first compute its local density  X  k as its importance. Here, the local density of  X  of points within a distance d c to it (Eq. 2 ). where  X  ( x )=1if x&lt; 0and  X  ( x ) = 0 otherwise, and d The algorithm is only sensitive to the relative magnitude of  X  Algorithm 1. Combination: The Combining of Annotations Thus the results of analysis are robust with respect to the choice of d Finally, we get the combination  X  of weight vectors  X  1 , each vector X  X  importance  X  k .
 We give the details of combining the annotation results in Algorithm 1 .The step of inferring the attribute weights of an annotation is illustrated in A 1 Lines 2 X 15, and the combination of the attribute vectors is shown in A 1 Lines 17 X 22. In our setting, all pairs of example nodes in U k constitute P create P k D by randomly drawing pairs of nodes that do not belong to user k  X  X  example set ( A 1 Lines 7 X 11). Note that if  X  k =0( A 1 Line 18),  X  no contribution to the combined vector  X  . That denotes user k  X  X  opinion will be ignored ( A 1 Line 20). In the last step, we get a combined  X  , and then we normalize it.
 Cluster Extraction. We use the information of combined annotations to extract the target cluster from the graph. Since a global clustering method would be time-consuming and can not scale well to large graph, we apply a seed-set-expansion algorithm to identify clusters locally with lower computa-tional complexity.
 There are two major problems in this step. First, how to extract the seed set samples of the cluster based on the different annotations from multiple annota-tors and the combined attribute weight vector? Second, how to develop a local partitioning method so that the expansion of seed sets will be scalable to large graphs? Therefore, we explain our algorithm focusing on two parts, the identifi-cation of seed set S of the cluster and its expansion rules.
 vector  X  to re-weigh the entire graph, then select the edges with high weight (similarity) to shape the seed set. We call this process as  X  X e-sampling X , which aims to enrich the samples space for the expansion process. Specifically, we firstly measure the weights of all the edges. Then, we assign the edges with high weights over threshold w r as seeds. Simply, we assign a linear interpolation as w the weights of samples, w r =  X w max +(1  X   X  ) w min , where  X  is a parameter falls in [0 , 1]. w max and w min represent the maximum and minimum value of the example edges weighted by  X  , respectively. Algorithm 2 details the process of finding the pure seed set by re-sampling.
 of strict rules. Following the expansion process in [ 19 ], the expansion process carefully adds new nodes to each component of S . In this paper, we apply con-ductance [ 19 ] to measure the quality of a cluster as it accounts for both the cut size and the total volume/density retained within the cluster. The weighted edges of S , respectively. The lower the conductance of a cluster is, the better the quality of the cluster is with few cross-cut edges and large within-density. component, and adds the ones that will decrease the conductance of the cluster. The process will simultaneously kick out the (nodes) edges within a cluster that will decrease the conductance of the cluster. The process continues until there is no node changing that would decrease the quality of a component. Due the page limitation, we do not illustrate the algorithm, please refer [ 15 ] for more details. 3.2 Complexity Analysis (1) The combination of annotations. Since every annotator provides the same Algorithm 2. Find seed set by re-sampling (2) The finding and expansion of seed set. Since  X  is supposed to be sparse with only a few non-zero entries for focused attributes, the multiplicative factor becomes effectively constant yielding a complexity of O ( m ). In the process of expansion, we enlist all the non-member neighbors as the candidate set and evaluate their weighted  X  conductance. As discussed above, the complexity is n  X  S d ( n ). Since S  X  V , it is equivalent O ( m ). As we add one node at each iteration, the total complexity becomes O ( | S | m ) where scale of the seed set, and | S | &lt;&lt; n .
 To sum up, the complexity of the two phases comes to O ( Kd/ It is critically low comparing to the large scale of graphs. In order to evaluate the clustering quality and scalability of CGMA , we com-pare it with two representative graph clustering techniques METIS [ 27 ]and F ocusCO [ 7 ] on real-world datasets. METIS is a classical graph partitioning algorithm which expects the number of clusters as input. F ocusCO is a local clustering approach proposed recently using the guidance of a single user. To introduce CGMA clearly, we conduct our experiments on the  X  X our-area X  dataset, a co-authorship network of computer science researchers. The attributes of the authors are the conferences in which they have published papers in the areas of database (DB), data mining (DM), machine learning (ML), and infor-mation retrieval (IR). We use multiple annotations from 50 persons, each person gives 20 sample nodes in responding to the same question in one experiment. For the convenience of study, our problem is identifying the researchers belonging to the four areas, respectively. The ground truth clusters of an area consists of all the researchers whoever published at least one paper in the area.
 duct a parameter study of  X  , and we show the F1-score of the clustering results with different settings of  X  . As shown in Fig. 2 , the F1-score of the final cluster-ing results is not linearly related to  X  . One can see that without the re-sampling step the F1-score of the final results in each of experiments is critically low, about or less than half of the value when  X  =0 . 4. The F1-score of the final clustering results presents that the re-sampling properly will improve clustering performance significantly.
 Accuracy. We compare the cluster results with METIS and F ocusCO . Here we set the clusters number of METIS as four, which performs the best on this dataset. As shown in Fig. 3 , one can see that F1-score of our method is significantly higher than that of the two baselines, which shows the superior performance of the proposed method. The experimental results show that our method significantly outperforms the other two methods.
 Stability. We also examine the stability of the proposed CGMA . Although we have different annotations as inputs, they are annotated under the same question. Therefore, the annotations are all theoretically related a common clustering. We use the normalized mutual information (NMI) to evaluate the stability of the proposed clustering approach. Here, we use average NMI between each pair of clustering results to indicate the stability of a method. Higher NMI implies a more stable clustering result. As shown in Fig. 5 , the proposed approach CGMA gets more stable results than other two methods. With the increasing of  X  ,the stability of CGMA improves significantly.
 Scalability. We select five subsets of  X  X our-area X  with the size from 100 to 27200. Each dataset scale is three times larger than its previous one. Then we conduct extensive experiments on these datasets. Note that the annotation vol-umes change with the scale of experimental graphs. Larger scale of the graph needs more annotations. For each dataset, we run the experiments for ten times and average the results. The experimental results are shown in Fig. 5 . Note that for CGMA , the extraction of cluster can be performed in parallel, thus the computing time can be significantly reduced. As the figure shown, the running time of METIS increases with the increasing of graph scale. However, the run-ning time of CGMA and F ocusCO is stable. In such case, the running time of CGMA is also comparable to METIS and F ocusCO (Fig. 4 ).
 To further examine the scalability of CGMA , we conduct more experiments on two different types of real world attributed networks. The first is crawled from P olBlogs , a citation network among a collection of online blogs that discuss political issues. The attributes of P olBlogs are the keywords in the blogs. The second dataset is crawled from T witter , and it is a following network with a collection of discussed topics. The attributes are the keywords in their posts. Statistics of the datasets are given in also given in Table 1 . The average running time (total) and their standard deviations are in Table 1 . The running time of CGMA is the total running time including the annotation combination and clustering extractions steps. As it shows, the running time demonstrates the efficiency of our approach. It only takes less than 2 s to cluster the Twitter dataset with more than 14 thousand nodes, which shows CGMA can be scalable to very large graphs. The experimental results prove that CGMA is a scalable approach that can deal with various datasets. In this work, we introduced a novel problem of finding clusters with multi-example sets in large attributed graphs. The challenge here is how to combine them in an unbiased way in order to conduct a clustering. To address these challenges, we proposed CGMA in this paper which has two major phases: (1) combining the various example sets, (2) re-sampling the seed sets and expand-ing them to find a batch of densely connected clusters. Extensive experiments are conducted to examine the CGMA , and the experimental results showed that the proposed approach outperforms baseline methods.

