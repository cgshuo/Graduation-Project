 Selective sampling is an active variant of online learning in which the learner is allowed to adaptively query the label of an observed example. The goal of selective sampling is to achieve a good trade-off between prediction performance and the number of queried labels. Existing selective sampling al-gorithms are designed for vector-based data. In this paper, motivated by the ubiquity of graph representations in real-world applications, we propose to study selective sampling on graphs. We first present an online version of the well-known Learning with Local and Global Consistency method (OLLGC). It is essentially a second-order online learning al-gorithm, and can be seen as an online ridge regression in the Hilbert space of functions defined on graphs. We prove its regret bound in terms of the structural property (cut size) of a graph. Based on OLLGC, we present a selective sampling algorithm, namely Selective Sampling with Local and Global Consistency (SSLGC), which queries the label of each node based on the confidence of the linear function on graphs. Its bound on the label complexity is also derived. We analyze the low-rank approximation of graph kernels, which enables the online algorithms scale to large graphs. Experiments on benchmark graph datasets show that OLLGC outper-forms the state-of-the-art first-order algorithm significantly, and SSLGC achieves comparable or even better results than OLLGC while querying substantially fewer nodes. More-over, SSLGC is overwhelmingly better than random sam-pling.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.1 [ Pattern Recognition ]: Models Algorithms, Experimentation Selective Sampling on Graphs, Online Learning, Regret Bound, Mistake Bound, Label Complexity
Selective sampling [13] [8] is an active variant of online learning [9] in which the learner is allowed to adaptively query the labels of a sequence of examples. The learner X  X  goal is to achieve a good trade-off between error rate and the number of queried labels. This can be viewed as an abstract protocol for interactive learning applications. Re-cently, several advanced selective sampling algorithms [6] [24] were proposed, demonstrating more promising results than traditional passive online learning. However, we note that existing selective sampling algorithms are specifically designed for vector-based data.

Graphs have recently received significant attention be-cause of their increasingly important role in real life appli-cations. Examples include the friendship network in Face-book 1 , co-author and citation networks in DBLP 2 , and the World Wide Web. In these applications, the data (nodes) are not independent and identically distributed (i.i.d.) as is typically assumed in statistical learning applications, be-cause of the impact of the linkage structure of the graph. Learning a function defined on a graph from a set of la-beled nodes has been studied extensively in machine learning both in off-line and online settings. More specifically, in the offline learning scenario, a majority of the literature is of-ten referred to as graph-based semi-supervised learning [30] [29]. On the other hand, the pioneering work towards online learning on graphs is probably [19]. Inspired by this work, the state-of-the-art Graph Perceptron Algorithm (GPA) was proposed in [18] and further analyzed in [17] [16].
Based on the above observation, a natural question arises as to whether we can design selective sampling algorithms for graphs. The results of this paper show that the answer is in the affirmative. In this paper, we propose to study selective sampling on graphs. Our work is built on a well-known model on graphs, namely learning with local and global consistency. This model is a state-of-the-art model on graphs and is particularly amenable to analysis in the context of selective sampling. We first present an online version of the well-known Learning with Local and Global Consistency method (OLLGC). It is essentially a second-order online learning algorithm, and can be seen as an on-h ttp://www.facebook.com http://www.informatik.uni-trier.de/  X  ley/db/ li ne ridge regression in the Hilbert space of functions de-fined on a graph. We prove its regret bound in terms of cut size of a graph. Based on OLLGC, we present a se-lective sampling algorithm, namely Selective Sampling with Local and Global Consistency (SSLGC), which queries the labels of nodes based on the confidence of the linear function on graphs. We also derive a bound on the label complex-ity of our proposed algorithm. Lastly, in order to scale the proposed algorithms as well as existing online learning algo-rithms to large graphs, we discuss the low-rank approxima-tion technique for graph kernels. Experiments on benchmark graph datasets show that OLLGC outperforms GPA [18] substantially. Furthermore, the selective sampling algorithm (SSLGC) achieves comparable or even better results than OLLGC, while querying substantially fewer nodes. More-over, SSLGC provides superior results to random sampling.
The main contributions of this paper are three-fold: (1) we present an online learning with local and global consis-tency (OLLGC), and prove its regret bound; (2) we present a selective sampling algorithm on graphs based on OLLGC, and derive its bound on label complexity; and (3) we analyze the low-rank approximation of graph kernels, which enables greater scalability of our algorithms as well as existing algo-rithms, when the graphs are large.
 The remainder of this paper is organized as follows. In Section 2, we briefly review the related literature. In Sec-tion 3, we present an online version of learning with local and global consistency, followed by its regret bound. In Sec-tion 4, we devise a selective sampling algorithm on graphs based on the online algorithm derived in previous section, and analyze its bound on the label complexity. We discuss and analyze the low-rank approximation of graph kernels for online algorithms in Section 5. The experiments on bench-mark graph datasets are demonstrated in Section 6. Finally, we present the conclusions in Section 7.
Throughout this paper, we will use lower case letters to denote scalars, lower case bold letters to denote vectors (e.g., w ), upper case letters to denote the elements of a matrix or a set, and bold-face upper case letters to denote matrices (e.g., A ). 0 is a vector of all zeros with appropriate length. I is an identity matrix with an appropriate size. We use w denote the transpose of a vector w , and A  X  1 the inverse of a matrix A . Given a matrix L , L  X  denotes its pseudo inverse. diag(  X  1 , . . . ,  X  n ) denotes a diagonal matrix with diagonal elements equal to  X  i  X  X . Furthermore, we use  X  X  X  X  denote the  X  2 -norm of a vector.
For ease in exposition, we briefly discuss online learning, active learning and selective sampling, in the context of both vector-based data and graph data.
Online learning has been studied extensively in the ma-chine learning community. In the past several decades, a va-riety of online learning algorithms have been proposed. Due to the sequential nature of online learning, it is very suitable to be applied to big data from many real-world applications. Roughly speaking, online learning algorithms can be cate-gorized into first-order algorithms [25] [23] and second-order algorithms [5] [12]. In general, second-order online algo-rithms are better than first-order online algorithms [20].
The extension of online learning to graph data was origi-nally studied in [19]. After that work, the well-known Graph Perceptron Algorithm (GPA) was proposed in [18] and fur-ther analyzed in [17] [16]. It is worth noting that the set-ting of online learning on graphs is essentially transductive , where the whole graph is already provided, but the learner is presented with the nodes in a sequential manner. This is different from the inductive paradigm for vector-based on-line learning. In addition, all the online learning algorithms on graphs mentioned before are first-order algorithms. Note that the first contribution of our paper, i.e., online learning with local and global consistency is a second-order algorithm on graphs, which is better than first-order algorithms.
Active learning [11] [28] aims to minimize the required level of acquisition of labeled data by actively selecting a few carefully chosen examples to query the oracle for their la-bels. There are several papers on active learning on graphs. For instance, [1] proposed an effective label acquisition for collective classification. [2] proposed an active learning algo-rithm for networked data based on ensemble and relational learning. Yet, there is no theoretical guarantee that these methods are better than random sampling. [7] studied ac-tive learning on graphs and trees. [21] proposed a nonadap-tive active learning method by minimizing the variance of Gaussian Field and Harmonic Function (GFHF) [30]. In our previous work [15], we proposed a nonadaptive active learn-ing approach on graphs, by minimizing the data-dependent error bound of LLGC [29], which was shown to be better than [21].
Selective sampling [8] [6] combines the idea of online learn-ing and active learning. Similar to online learning, a selec-tive sampling algorithm observes examples in a sequential manner. After each observation, the algorithm predicts its label. However, rather than receiving the correct label pas-sively, the algorithm can choose whether to receive feedback indicating whether the label is correct or not. It is obvious that by using selective sampling, we need much less labeling effort, since the labels of many examples can be predicted with very high confidence. In other words, selective sam-pling is online active learning.

Linear models lend themselves well to selective sampling settings, because the variance of a classifier on an example can be viewed as a measure of confidence for the classifica-tion. If this confidence is too low, then the selective sampler will query the label and use it, along with the example, to update the linear model. For graph data, the key question is how to define an example as well as a linear model. We will show that learning with local and global consistency can be equivalently formulated as a linear model on the graphs.
In this section, we present an online version of learning with local and global consistency (LLGC) [29]. To make our paper self-contained, we briefly review LLGC.
Given a graph G = ( V, E ), where v i  X  V is the i -th node of a graph, and e ij  X  E is the link (edge) between i -th node and the j -th node. Each link e ij is associated with a weight S ij , which reflects the strength of the link. S  X  R n  X  n is called adjacency matrix of the graph. For undi-rected graph, S is a symmetric matrix, while for directed graph, S is asymmetric. In the setting of transductive clas-sification, some of the nodes in the graph are labeled, i.e., y  X  { X  1 } , while the remainder are unlabeled, i.e., y i = 0. Our goal is to obtain a prediction about the labels of those unlabeled nodes. Through our paper, we assume that the graph G is connected, though our results can be generalized to disconnected graphs with more involved arguments.
The basic assumption of graph regularization is based on the concept of homophily in networks. If two nodes v i and v are linked together, then their labels are likely to be sim-ilar. Let f : V  X  R be a nonparametric function defined on the nodes of a graph. For an undirected graph, graph regularization [27] is mathematically written as follows: where f i is the function value on the i -th node, i.e., f ( v ferred to as the degree matrix. The i th diagonal entry D [10]. Eq. (1) is called Graph Regularization . Intuitively, the objective function incurs a heavy penalty, if neighbor-ing nodes v i and v j are mapped far apart. Suppose the eigen decomposition of L is L = V X V  X  = where  X  = diag(  X  1 , . . . ,  X  n ), 0  X   X  1  X   X  2  X  . . . eigenvectors. One property of the graph Laplacian is that its smallest eigenvalue is 0 (i.e.,  X  1 = 0), and the associ-ated eigenvector is 1 . For connected graphs, the algebraic multiplicity of the zero eigenvalue is 1 (i.e.,  X  2 &gt; 0).
Learning with Local and Global Consistency (LLGC) [29] was originally proposed for semi-supervised learning and lat-ter successfully used for classification on graphs [22]. In the setting of binary classification, it solves the following prob-lem, ularization parameter, which controls the balance between the squared loss and the graph regularization.
In order to derive the online version of LLGC, we derive an equivalent formulation of LLGC as follows. Specifically, we consider the dual problem of Eq. (2). Using the definition of graph kernel [27], we have where L  X  is the inverse (or pseudo inverse) of L , i.e., L  X   X  2  X  C , where C &gt; 0 is a constant.

Substituting Eq. (3) back into Eq. (2), we have
We assume that L  X  = M T M , where M  X  R d  X  n . We define w = M . The optimization problem in Eq. (4) can be rewritten as follows: Now we can see that the above objective function is essen-tially a ridge regression, where each column of M can be seen as a vector-based example. This insight enables us adapt the technique from online ridge regression to derive an online version of LLGC. We will discuss the selection of M in Section 5. Now we are ready to propose the online version of LLGC. Before that, let us state the formal problem setting of online learning on graphs. From now on, we assume T = n . Let Online learning operates on a sequence of nodes. In round t , the algorithm receives an incoming node m t  X  R d , and predicts its label  X  y t  X  { X  1 , +1 } . After the prediction, the true label y t  X  { X  1 , +1 } is revealed and the loss  X  ( y evaluated. The goal of online learning is to minimize the cumulative number of mistakes over the entire graph.
Given { ( m 1 , y 1 ) , ( m 2 , y 2 ) , . . . , ( m t , y m t  X  R d and y t  X  X  X  1 , 1 } , online LLGC aims at solving the following optimization problem: It is worth noting that the above problem is a Follow-the-Regularized-Leader problem [26], which has been extensively studied in the online learning community.

The optimal solution for w t +1 to Eq. (6) is
We define A 0 =  X  I , A t =  X  I + b =
The calculation A  X  1 t seems to be computationally expen-sive. Fortunately, we do not need to calculate A  X  1 t explic-itly. In fact, A  X  1 t can be incrementally calculated by the Sherman-Morrisan Identity [14]. In addition, the above up-date is performed in each iteration, which is not sufficiently efficient for large graphs. To resolve this problem, inspired by the mistake-driven algorithms such as Second-Order Per-ceptron (SOP) [5], we let our online algorithm update the model parameters ( A , b and w ) only when it incurs a mis-take ( X  y t  X  = y t ). Note that this modification does not affect the soundness of our algorithm, as will be seen in our the-oretical analysis. Furthermore, our algorithm is different from SOP either, because it does not use the current node to update the weight vector ( w ) until the label of current node is revealed. In summary, we show the proposed online LLGC in Algorithm 1. A lgorithm 1 Online Learning with Local and Global Con-sistency (OLLGC)
In put: Adjacency matrix S , rank d , regularization pa-rameter  X  Output: w T Compute L = D  X  S and M from L
Initialize: A 0 =  X  I , b 0 = 0 , w 0 = 0 for t = 1 to T do end for
No te that in each iteration of our algorithm, whenever an update is invoked, the time complexity is O ( d 2 ).
Now we will prove the regret bound of OLLGC. This bound shows that, for any ordering of nodes on a graph, our algorithm cannot perform much worse than the best pre-dictor learned in hindsight. The proof technique is adapted from potential-based gradient descent [9] (a.k.a., mirror de-scent [26]), as well as SOP [5].
 First, we define the regret of OLLGC as follows: where  X  t ( w t ) = 1 2 ( w  X  t m t  X  y t ) 2 a nd  X  t ( u ) =
F or the ease of proof, we define a set M = { t : sign( w y } , which is the set of round indices for which an algorithm makes a mistake. We rewrite Eq. (6) as a potential-based gradient descent problem: where D  X  t  X  1 ( w , w t ) is the Bregman divergence [4], defined as follows: D and  X  t is a potential function, defined as follows: It is easy to verify that the optimization problems in Eqs. (6) and (10) are equivalent. Moreover, we have  X   X  t ( w t +1 mistake-driven update strategy into OLLGC, A t is actually defined as A t =
We begin with three technical lemmas, which facilitate the proofs of the main theoretical result of OLLGC. The first lemma is a property of potential-based gradient descent. Lemma 1 For any u , we have  X 
The second lemma is an upper bound of Similar lemma has been proved in [5] [9].
 Lemma 2 Assume that  X  m t  X  2  X  B for all t , then for Al-gorithm 1, we have  X  where  X  i , i = 1 , . . . , d are the eigenvalues of M ] .

The third lemma relates the norm  X  u  X  2 with the struc-tural property of a graph.
 Lemma 3 Suppose G is a connected graph, for any u = M , f i  X  X  X  1 , 1 } , i = 1 , . . . , n and  X   X  2  X  C , we have where  X ( f ) is the cut size corresponding to the class assign-ment of f .
 Theorem 4 (Regret Bound) Let S = { ( m 1 , y 1 ) , . . . , ( m (
R d  X { X  1 } ) T . Then for any u  X  R d such that ( u T m t y ) 2  X   X  , f  X  X  X  1 , 1 } T , and  X   X  2  X  C , we have Proof. Using Lemma 1, we have where  X   X  (  X  ) is the Fenchel conjugate function [3] of  X  ( w ), and here we used a very useful property of Bregman diver-gence [9]. Since  X  t ( w t ) = ( w  X  t m t  X  y t ) m t , and D ( u  X  w )  X  A  X  1 Using Lemmas 2 and 3 completes the proof.

I n fact, we can also bound the number of mistakes made by Algorithm 1 for any ordering of nodes on a graph. Corollary 5 (Mistake Bound) Let S = { ( m 1 , y 1 ) , . . . , ( m T , y T ) } X  ( R d  X { X  1 } ) T . Then for any u  X  R d ( u
T m t  X  y t ) 2  X   X  , we have |M| X  min This bound is very interesting, because it directly implies that the better the off-line LLGC works on a graph, the smaller the number of mistakes made by OLLGC. This is consistent with our intuition.
In this section, we will present a selective sampling algo-rithm based on OLLGC proposed in previous section. First of all, we formally give the definition of selective sampling on graphs.
Selective sampling is a modification of the online learn-ing protocol for binary classification. At each round t , the learner receives a node m t  X  R d , and outputs a binary pre-diction  X  y t  X  X  X  1 , 1 } . After each prediction, the learner may observe the true label y t only by querying for it. Hence, if no query is issued at time t , then y t remains unknown. Since the learner X  X  performance is deemed to improve as more la-bels are observed, the goal of selective sampling is to trade off predictive performance and the number of queries.
In our paper, following [6], we assume that Pr( Y t = 1 | u is the Bayes classifier of unknown norm  X  u  X  which satis-fies | u  X  m t |  X  1 for all t . We also define  X  t = u  X  further define  X   X  t = w  X  t m t , which is an estimator of  X 
Our algorithm is motivated by the Bound on Bias Query (BBQ) algorithm [6] [24]. We introduce the following rele-vant quantities, where B t is the bias of the estimator for the margin  X   X  r is a bound on the variance.

Different from BBQ algorithm, the learner in our algo-rithm does not necessarily update the model whenever it queries the label. Instead, it updates the model when it queries the label and a mistake is detected. This makes SSLGC computationally more efficient, without significantly affecting the theoretical properties. In summary, we show the selective sampling with local and global consistency in Algorithm 2.

Intuitively speaking, our algorithm issues a query when a common upper bound on the bias and variance of the cur-rent estimate of  X   X  t is larger than a given threshold vanishing as t  X   X  , where 0  X   X   X  1 is an input parameter. When this upper bound on bias and variance gets small, we infer by a simple large deviation argument that the margin of OLLGC on the current example is close enough to the margin of the Bayes optimal classifier. Hence the learner can safely avoid issuing a query in that round. In each iteration of the algo-rithm, whenever an update is invoked, the time complexity is O ( d 2 ).
We define the regret of our selective sampling algorithm as follows: uniformly over the number T of prediction rounds. Follow-ing previous papers [6] [24], our bound can depend on the Al gorithm 2 Selective Sampling with Local and Global Consistency (SSLGC)
Inp ut: Adjacency matrix S , rank d , regularization pa-rameter  X  , and  X  .
 Output: w T Compute L = D  X  S and M from L
Initialize: A 0 =  X  I , b 0 = 0 , w 0 = 0 for t = 1 to T do end for n umber of rounds where the label Y t are close to being ran-dom. According to our model, this is captured by  X T  X  where T = |{ 1  X  t  X  T : |  X  t | &lt;  X  }| .

Our main theoretical result provides bounds on the cumu-lative regret and the number of queried labels (label com-plexity) for Algorithm 2. We begin with a technical lemma. Lemma 6 For all  X  &gt; 0 , we have where N T is the total number of queries issued in the rst T rounds.
 Theorem 7 If Algorithm 2 is running with input  X   X  [0 , 1] , then for any ordering of T nodes on a graph, f  X  X  X  1 , 1 } T and  X   X  2  X  C , the cumulative regret satis es R Moreover, the number of queried nodes is upper bounded as N Pr oof. We have He nce the cumulative regret can be bounded as follows: Using Lemmas 6 and 3 completes the proof of the regret bound. Finally, in order to derive a bound on the number of queried labels (label complexity), we have N No te that the label complexity is O ( dT  X  log( T )), which is smaller than O ( T ) when  X  is sufficiently small. Roughly speaking, the larger the value of  X  , the more nodes the learner will query. One may argue that our regret bound depends on d , which is not desirable. However, rather than the case of vector-based selective sampling, where d could be larger than T , d is smaller than T (or n ) in our case. It is worth noting that if we choose d = T , the label complexity becomes O ( T  X  +1 log( T )), which implies that the learner will query all the nodes. This indicates that in order to make selective sampling really work, we need to choose d &lt; T . In this sense, low-rank approximation of L  X  is preferred. On the other hand, since the regret bound is decreasing with  X  , a larger value of  X  is preferable for superior prediction performance. In other words, it needs to query more nodes to obtain better performance. Therefore, there is a trade-off between label complexity and prediction performance.
Finding the M given a graph kernel L  X  is not difficult. In fact, M can be calculated directly from L . Recall that the eigen decomposition of L is L = we could choose M as follows In this way, L  X  is reconstructed exactly, but the time com-plexity of our algorithms becomes O ( n 2 ), which is compu-tationally expensive for large graphs.

In this paper, in order to make our algorithms as well as existing online learning algorithms scalable to large graphs, we propose to choose M as follows where d  X  n . Thus, L  X  is approximated by a low-rank matrix  X  M  X   X  M with rank d . And the time complexity of our online algorithms is O ( d 2 )  X  O ( n 2 ). In the sequel, we will analyze the impact of such low-rank approximation on our algorithms. Denote  X  L =  X  [14],  X  L is the best rank-d approximation of L , while  X  the best rank-d approximation of L  X  .

Due to space limit, we only analyze the impact of low-rank approximation on OLLGC. The analysis for SSLGC is similar and therefore omitted. By taking a close look at the regret bound of OLLGC in Theorem 5, we can see that there are two terms depending on M (or L  X  or L ). One is  X  2 ( L ), the other is
F irst, note that  X  2 ( L ) is the second smallest eigenvalue of L . Based on the above definitions, the second smallest eigenvalue of  X  L is the same as that of L provided that d 2. Hence, low-rank approximation does not introduce any approximation error in  X  2 ( L ) as long as d  X  2.
Second, if we choose the exact M as in Eq. (27), then d = n , and  X  i , i = 1 . . . , n are the eigenvalues of M ]. Let us consider the simple case where M = { 1 , 2 , . . . , T In this case,  X  i , i = 1 . . . , n are the eigenvalues of Based on some linear algebra manipulations, it is easy to show that  X  i , i = 1 . . . , n are also the eigenvalues of i.e. ,  X  i = 1  X  imate  X  M as in Eq. (28), and suppose the eigenvalues of  X   X   X  , i = 1 , . . . , d are actually the top d largest eigenvalues of  X  that, under the condition that  X  i are sufficiently large for i &gt; d , the approximate  X  M provides a good approximation for ment is similar but more involved.

The above arguments justify the validity of low-rank ap-proximation for graph kernels.
In this section, we empirically evaluate the effectiveness of the proposed algorithms. All the experiments are performed on a PC with Intel Core i5 3.20G CPU and 48GB RAM and all algorithms in our experiments are implemented in Matlab .
We used four real-world graph data sets to evaluate the online learning and selective sampling algorithms. Coauthor 2 is an undirected co-author graph data set ex-tracted from the DBLP database in four areas: machine learning , data mining , information retrieval and databases . It contains a total of 1711 authors, each of which is repre-sented by a node. The edge between each pair of authors is weighted by the number of papers they have co-authored. Each class contains about 400 authors.
 Cora 3 contains 2708 scientific publications classified into one of seven classes: Case Based , Genetic Algorithms , Neu-ral Networks , Probabilistic Methods , Reinforcement Learn-ing , Rule Learning and Theory . The citation graph contains 5429 links.
 IMDB 4 is an international organization whose objective is to provide useful and up-to-date movie information. We cre-ate a graph based on the co-actor relationship among 17046 movies from four genres:  X  X omance X ,  X  X ction X ,  X  X nimation X  and  X  X hriller X . Each genre is considered as a class. PubMed 5 contains 19717 scientific publications from the PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links.
Some graphs in the above data sets are directed, and we simply use S  X  max( S , S  X  ) to transform them into undi-rected graphs. Table 1 summarizes the characteristics of the data sets introduced above. h ttp://www.cs.umd.edu/  X  sen/lbc-proj/data/cora.tgz http://www.imdb.com/ http://www.cs.umd.edu/projects/linqs/projects/lbc/Pubmed-Diabetes.tgz
We evaluated the performance of online learning and selec-tive sampling with the use of three measures: (i) cumulative error rate, which reflects the prediction performance of on-line learning algorithms; (ii) number of queried labels, which reflects the label efficiency of an algorithm; and (iii) cumu-lative computational time, which measures the efficiency of online learning. Note that the smaller the above measures, the better the performance of an online learning algorithm.
We compare the proposed algorithms with the Graph Per-ceptron Algorithm (GPA) [18]. The algorithms we studied and their parameter settings are summarized as follows.
Graph Perceptron Algorithm (GPA) [18]: This is the state-of-the-art first-order online learning algorithm on graphs. There is no required parameter for this algorithm. Note that the Perceptron algorithm is not affected by the step-size.

Online Learning with Local and Global Consis-tency (OLLGC) : This is the proposed second-order online learning algorithm on graphs. The parameter  X  is tuned by dom shuffle.

Selective Sampling with Local and Global Consis-tency (SSLGC) : This is the proposed selective sampling algorithm on graphs. The parameter  X  is tuned according to In our experiments, we fix  X  = 0 . 4 for all the data sets. We
In order to compare these algorithms fairly, we randomly shuffle the ordering of nodes for each dataset. We repeat each experiment 20 times and calculate the average results.
The above algorithms are naturally designed for binary classification, while the data sets have more than two classes. In order to apply the algorithms to those data sets, we use one-vs-rest scheme, which is a standard technique for adapt-ing binary classifiers to the multi-class scenario.
We first study the impact of low-rank approximation on the performance of online learning algorithms. We try dif-ferent ranks for approximation, and run all the algorithms. Because of the space limit, we used the Cora data set as a case study, because similar observations are obtained for the other data sets. Specifically, we changed the rank of the ap-proximation using the grid { 10 , 50 , 100 , 250 , 500 , 750 , 1000 The results are shown in Figure 1.

It is evident that the higher the rank, the better the pre-diction performance because of a lower error rate. However, higher rank incurs higher computational cost, especially for second-order algorithms (OLLGC and SSLGC), because the time complexity of second-order algorithms is O ( d 2 ), where d is the rank. It implies that we need to obtain a trade-off Figure 1: A case study of the impact of rank on the prediction performance (a) and time cost (b) in the Cora dataset. between the predictive performance and the computational cost. Therefore, in the rest of our experiments, we chose d = 100, because the corresponding performance is good while the computational time is short. In fact, under differ-ent values of d , our algorithms are always better than GPA. Therefore, choosing d = 100 does not affect the fairness of the comparison in the rest of our experiments.
The experimental results are shown in Table 2. For each data set, we executed paired t-tests of the error rate between the proposed algorithms and GPA at a 95% confidence in-terval. We found that the improvements of our algorithms over GPA are always significant. We also show the results with respect to the round of online learning in Figure 2. In all subfigures, the horizontal-axis represents the rounds of online learning, while the vertical-axis is the cumulative number of mistakes, queried nodes or cumulative time, av-eraged over 20 runs. Because of space limitations, we only show results on the IMDB and PubMed datasets.

We can see that OLLGC outperforms GPA significantly on every data set. This is consistent with previous obser-vations in vector-based online learning: second-order algo-rithms are generally better than first-order algorithms [20]. However, OLLGC requires more time than GPA. The rea-son is that the time complexity of GPA is O ( d ), while the time complexity of OLLGC is O ( d 2 ). However, given the significant performance improvement of OLLGC over GPA, OLLGC is still very appealing.

SSLGC is better than GPA as well. Moreover, SSLGC achieves comparable results to OLLGC. Intuitively, SSLGC uses fewer labeled nodes than OLLGC, so that its perfor-mance should be no better than OLLGC. However, we can see that on PubMed dataset, SSLGC is even better than OLLGC. The reason is that the class distribution of PubMed is unbalanced. And when the data are unbalanced, passively querying the labels may be harmful, because the weight vec-tor of the learner tends to be over-updated to fit the data from the majority class. That is why SSLGC could be better than OLLGC on the PubMed dataset.

Furthermore, it can be seen that SSLGC queried substan-tially fewer nodes while GPA and OLLGC queried every node. Although SSLGC queried much fewer nodes than OLLGC, their performances are comparable. This indicates that SSLGC is more label-efficient. Another advantage of label-efficiency is that SSLGC costs less time than OLLGC. The reason is obvious: once a node is queried, the model will The smaller the value of the measure, the better the performance. Figure 2: Cumulative error rate (first row), cumu-lative number of queried nodes (second row) and cumulative time (third row) with respect to the on-line learning rounds on IMDB (first column); and PubMed (second column) datasets. The lower the curve, the better the performance. be updated as long as a mistake is incurred. Since SSLGC queried fewer nodes, it has lower chance than OLLGC to update the model, which turns out to be computationally more efficient.
Now we will study the impact of  X  in our selective sam-pling algorithm. We will also compare it with random sam-pling. Generally speaking, the smaller the value of  X  , the fewer the number of queried nodes. Specifically, we set  X  to We calculate the average ratio of queried nodes for different values of  X  . Then, we test random sampling which is built on GPA. Rather than querying every node, the random sam-pling will query a node with probability 0 &lt; p &lt; 1. In other words, for each node, the learner draw a value from a stan-dard uniform distribution U (0 , 1). If the value is smaller than p , it queries the label. Otherwise, it does not. For fair comparison, we set p equal to the ratio of queried nodes in SSLGC. The comparison is shown in Figure 3.

We can observe that SSLGC is better than random sam-pling consistently under different ratio of queried nodes. This strengthens the advantage of SSLGC over random sam-pling. This is also why selective sampling is demanded for label effectiveness. It will actively query those nodes whose labels are uncertain. In contrast, random sampling just pas-sively queries the nodes, without considering the informa-tiveness of each node.
In this paper, we presented an online version of the well-known Learning with Local and Global Consistency method (OLLGC), and proved its regret bound in terms of the struc-tural properties of a graph. Based on OLLGC, we pre-sented Selective Sampling with Local and Global Consis-tency (SSLGC). We also derived a bound on the label com-plexity of SSLGC. Experiments show that OLLGC outper-forms the state-of-the-art first-order algorithm substantially, and the selective sampling algorithm outperforms random sampling overwhelmingly given the same number of queried labels.

Note that in this paper, we studied transductive online learning and selective sampling on graphs. In our future work, we will study inductive online learning and selective sampling on graphs.
We would like to thank the anonymous reviewers for their helpful comments. This work was supported in part by U.S. National Science Foundation grants IIS-0905215, CNS-0931975, the U.S. Army Research Laboratory under Coop-erative Agreement No. W911NF-09-2-0053 (NS-CTA), the U.S. Air Force Office of Scientific Research MURI award FA9550-08-1-0265, and MIAS, a DHS-IDS Center for Mul-timodal Information Access and Synthesis at UIUC. better the performance. [1] M. Bilgic and L. Getoor. Effective label acquisition for [2] M. Bilgic, L. Mihalkova, and L. Getoor. Active [3] S. Boyd and L. Vandenberghe. Convex optimization . [4] L. M. Bregman. The relaxation method of finding the [5] N. Cesa-Bianchi, A. Conconi, and C. Gentile. A [6] N. Cesa-Bianchi, C. Gentile, and F. Orabona. Robust [7] N. Cesa-Bianchi, C. Gentile, F. Vitale, and [8] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni. [9] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, [10] F. R. K. Chung. Spectral Graph Theory . American [11] D. A. Cohn, L. E. Atlas, and R. E. Ladner. Improving [12] K. Crammer, A. Kulesza, and M. Dredze. Adaptive [13] Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. [14] G. H. Golub and C. F. V. Loan. Matrix computations [15] Q. Gu and J. Han. Towards active learning on graphs: [16] M. Herbster and G. Lever. Predicting the labelling of [17] M. Herbster, G. Lever, and M. Pontil. Online [18] M. Herbster and M. Pontil. Prediction on a graph [19] M. Herbster, M. Pontil, and L. Wainer. Online [20] S. C. H. Hoi, J. Wang, and P. Zhao. Exact soft [21] M. Ji and J. Han. A variance minimization criterion to [22] M. Ji, Y. Sun, M. Danilevsky, J. Han, and J. Gao. [23] N. Littlestone. Learning quickly when irrelevant [24] F. Orabona and N. Cesa-Bianchi. Better algorithms [25] F. Rosenblatt. The perceptron: A probabilistic model [26] S. Shalev-Shwartz. Online learning and online convex [27] A. J. Smola and R. I. Kondor. Kernels and [28] S. Tong and D. Koller. Support vector machine active [29] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and [30] X. Zhu, Z. Ghahramani, and J. D. Lafferty.

