 The advancement of information technologies has made it never easier for various or-ganizations (e.g., hospitals, bus companie s, census bureaus) to create large repositories of user data (e.g., patient data, passenger commute data, census data). Such data repos-itories are of tremendous research value. For example, statistical analysis of patient data can help evaluate health risks and develop new treatments; passenger commute data provides invaluable insights into the effectiveness of transportation systems; cen-sus data is an essential source of information for demographic research. Despite of the research value of data, they are seldom available for public accesses, due to concerns over individual privacy. A common practice to address this issue is to anonymize the data by removing all personal identifiers (such as names and IDs). Nevertheless, re-cent research [2 X 4, 11 X 14, 16] has shown that eliminating personal identifiers alone is insufficient for privacy protection, since the remaining attributes in the data may still be exploited to re-identify an individual. This has motivated numerous data publishing techniques (see [1, 7, 9] for surveys) that aim to provide better privacy protection based on formal models of privacy requirements.

Differential privacy [8] is the state-of-the-art privacy model for data publishing. In-formally, it requires that a sensitive dataset T should be modified using a randomized algorithm G with the following property: Even if we arbitrarily change one tuple in T and then feed the modified data as input to G , the output of G should still be more or less the same with the case when the original T is the input. In other words, the output of G should only rely on the general properties of the input data, and should not be very sensitive to any particular tuple. This ensures that, when an adversary observes the data modified by G , he would not be able to infer much about any individual tuple in the original data, i.e., privacy is preserved.

Meanwhile, the data generated from G can still be useful, as long as the modification imposed by G does not significantly change the statistical properties of the original data. The design of such an algorithm G , however, is often highly non-trivial due to stringent requirements of differential privacy and t he inherent complexity of the input/output data. In what follows, we first formalize the concept of differential privacy, and then demonstrate how we may utilize wavelet transforms and Bayesian networks to improve the utility of data released under differential privacy. We say that two datasets are neighboring , if they have the same cardinality and they differ in only one tuple. The formal definition of differential privacy is as follows: Definition 1 (  X   X   X  -Differential Privacy [8]). A randomized algorithm G satisfies  X  -differential privacy, if for any two neighboring datasets T 1 and T 2 and for any output O of G ,wehave Note that  X  is a user-specified parameter that controls the degree of privacy protection; a smaller  X  leads to stronger privacy assuran ce. Figure 1 illustrates Definition 1.
The Laplace mechanism [8] is the most fundamental mechanism for achieving dif-ferential privacy. To explain, consider that we have a non-private algorithm F whose output is a set of numeric values. Given F , the Laplace mechanism can transform F into a differentially private algorithm, by adding i.i.d. noise (denoted as  X  ) into each output value of F . The noise  X  is sampled from a Laplace distribution Lap (  X  ) with the following pdf: Pr[  X  = x ]= 1 2  X  e  X  X  x | / X  . We refer to  X  as the magnitude of the Laplace noise.

Dwork et al. [8] prove that th e Laplace mechanism ensures  X  -differential privacy if  X   X  S ( F ) / X  ,where S ( F ) is the sensitivity of F : Definition 2 (Sensitivity [8]). Let F be a function that maps a dataset into a fixed-size vector of real numbers. The sensitivity of F is defined as where  X  1 denotes the L 1 norm, and T 1 and T 2 are any two neighboring datasets.
Intuitively, S ( F ) measures the maximum possible change in F  X  X  output when we modify one arbitrary tuple in F  X  X  input. A large S ( F ) indicates that F may reveal sig-nificant information about a certain tuple, in which case we should inject a large amount of noise into F  X  X  output to protect privacy. This explains why the Laplace mechanism sets the standard deviation of the noise proportional to S ( F ) / X  . Suppose that we are to publish a relational table T that contains d attributes A ,A 2 ,...,A d , each of which is discrete and ordered. We define n as the number of tuples in T ,and m as the size of the multi-dimensional domain on which T is defined,
To release T under  X  -differential privacy, we can first transform T into a d -dimensional frequency matrix M with m entries, such that (i) the i -th ( i  X  [1 ,d ] ) dimension of M is indexed by the values of A i , and (ii) the entry in M with a coordinate vector x 1 ,x 2 ,...,x d stores the number of tuples t in T such that t = x 1 ,x 2 ,...,x d .(Note: M can be regarded as the lowest level of the data cube of T .)
Notice that if we modify a tuple in T , then (i) at most two entries in the frequency matrix M will change, and (ii) each of those two entries will change by 1 . Therefore, if we regard M as the output of a function, then by Definition 2, the sensitivity of the function equals 2 . Hence, using the Laplace mechanism, we can ensure  X  -differential privacy by adding Laplace noise Lap (2 / X  ) into each entry of M .

The above noise injection approach is simp le, but it fails to provide accurate results for aggregate queries. Specifically, if we answer a range-count query using a noisy fre-quency matrix M  X  generated with the aforementioned approach, then the noise in the query result has a variance  X  ( m/ X  2 ) in the worst case. This is because (i) each en-try in M  X  has a noise variance 8 / 2 (by the pdf of Lap (2 / X  ) ), and (ii) a range-count query may cover up to m entries in M  X  . Note that m is typically an enormous num-ber, as practical datasets often contain multiple attributes with large domains. Hence, a  X  ( m/ X  2 ) noise variance can render the query resu lt meaningless, especially when the original result is small. In Section 4, we address this problem by utilizing wavelet transforms [5, 15]. This section introduces Privelet (pri vacy preserving wavelet ), a data publishing tech-nique that not only ensures -differential privacy, but also provides accurate results for all range-count queries . In particular, Privelet guarantees that any range-count query can be answered with a noise whose variance is polylogarithmic in m . This signifi-cantly improves over the O ( m ) noise variance bound provided by the first-cut solution in Section 3.
 Overview. At a high level, Privelet works in two steps as follows. First, it derives the frequency matrix M of the input table T , and then applies a wavelet transform on the frequency matrix M . Generally speaking, a wavelet transform is an invertible linear function, i.e., it maps M to another matrix C , such that (i) each entry in C is a linear combination of the entries in M , and (ii) M can be losslessly reconstructed from C . The entries in C are referred to as the wavelet coefficients . Second, Privelet adds an in-dependent Laplace noise to each wavele t coefficient in a way that ensures -differential privacy. This results in a new matrix C  X  with noisy coefficients. Finally, Privelet maps C  X  back to a noisy frequency matrix M  X  , which is returned as the output.
 In the following, we clarify the details of Privelet . We first focus on the case when T has only one attribute (i.e., M is a one-dimensional matrix), and introduce the one-dimensional Haar wavelet transform (HWT) . After that, we explain how this wavelet transform can be incorporated in Privelet . Finally, we clarify how our solution can be extended to the case when T is multi-dimensional.
 One-Dimensional HWT. For ease of exposition, we assume that the number m of entries in M equals 2 l ( l  X  N )  X  this can be ensured by inserting dummy values into M [15]. Given M , the one-dimensional HWT converts it into 2 l wavelet coefficients as follows. First, it constructs a full binary tree R with 2 l leaves, such that the i -th leaf of R equals the i -th entry in M ( i  X  [1 , 2 l ] ). It then generates a wavelet coefficient c for each internal node N in R , such that c =( a 1  X  a 2 ) / 2 ,where a 1 ( a 2 ) is the average value of the leaves in the left (right) subtree of N . After all internal nodes in R are processed, an additional coefficient (referred to as the base coefficient ) is produced by taking the mean of all leaves in R . For convenience, we refer to R as the decomposition tree of M , and slightly abuse notation by not distinguishing between an internal node in R and the wavelet coefficient generated for the node.
 Example 1. Figure 2 illustrates an HWT on a one-dimensional frequency matrix M with 8 entries v 1 ,...,v 8 . Each number in a circle (square) shows the value of a wavelet coefficient (an entry in M ). The base coefficient c 0 equals the mean 5 . 5 of the entries in M . The coefficient c 1 has a value  X  0 . 5 , because (i) the average value of the leaves in its left (right) subtree equals 5 ( 6 ), and (ii) (5  X  6) / 2=  X  0 . 5 .

Given the Haar wavelet coefficients of M ,anyentry v in M can be easily recon-of the decomposition tree R (we regard the root of R as level 1 ). We have where g i equals 1 (  X  1 )if v is in the left (right) subtree of c i .
 Example 2. In the decomposition tree in Figure 2, the leaf v 2 has three ancestors c 1 =  X  0 . 5 , c 2 =1 ,and c 4 =3 . Note that v 2 is in the right (left) subtree of c 4 ( c 1 and c 2 ), and the base coefficient c 0 equals 5 . 5 .Wehave v 2 =3= c 0 + c 1 + c 2  X  c 4 . Privelet with 1D HWT. Privelet with the one-dimensional HWT follows the three-step paradigm mentioned previously. Given a parameter  X  and a table T with a single or-dinal attribute, Privelet first computes the Haar wavelet coefficients of the frequency matrix M of T . It then adds to each coefficient c a random Laplace noise with magni-tude  X / W Haar ( c ) ,where W Haar is a weight function defined as follows: For the base coefficient c , W Haar ( c )= m ; for a coefficient c i at level i of the decomposition tree, W coefficients are computed, Privelet converts them back to a noisy frequency matrix M  X  based on Equation 2, and then terminates by returning M  X  .

By the properties of the Laplace mechanism [8], it can be proved that the above version of Privelet ensures  X  -differential privacy with =2(1+log 2 m ) / X  ,where  X  is the input parameter [17]. In addition, it also provides strong utility guarantee for range-count queries, as shown in the following lemma.
 Lemma 1 ([17]). Let C be a set of one-dimensional Haar wavelet coefficients such that each coefficient c  X  C is injected independent noise with a variance at most (  X / W Haar ( c )) 2 .Let M  X  be the noisy frequency matrix reconstructed from C . For any range-count query answered using M  X  , the variance of noise in the answer is at most (2+log 2 | M  X  | ) / 2  X   X  2 .

By Lemma 1, Privelet achieves -differential privacy while ensuring that the result of any range-count query has a noise variance bounded by In contrast, under the same privacy requireme nt, the first-cut solution in Section 3 incurs a noise variance of O ( m/ 2 ) in query answers.

Finally, we point out that Privelet with the one-dimensional HWT has an O ( n + m ) time complexity for construction. This follows from the facts that (i) mapping T to M takes O ( m + n ) time, (ii) converting M to and from the Haar wavelet coefficients incur O ( m ) overhead [15], and (iii) adding Laplace noise to the coefficients takes O ( m ) time. Extension to Multi-dimensional Datasets. For the case when M is a multi-dimensional matrix, we apply the multi-dimensional Haar wavelet transform [15] on M , and then inject noise into the wavelet coefficients in a manner similar to the one-dimensional case [17]. After that, we obtain a noisy matrix M  X  from the noisy coef-ficients, by applying the inverse multi-dimensional Haar wavelet transform. It can be proved that, by any range-count query answered using M  X  , its noise variance is at most O ((log m ) d / X  2 ) . In addition, the time complexity of the solution is O ( n + m ) . The Privelet approach in Section 4 suffers from the curse of dimensionality. In particu-lar, it requires converting the input table T into a frequency matrix M whose number of entries is exponential to the number d of attributes in T  X  this incurs prohibitive over-heads even when d is moderate. In addition, its noise variance bound (for range-count query results) is O ((log m ) d / X  2 ) , which also increases exponentially with d . In fact, these deficiencies are not unique to Privelet : most existing techniques for differentially private data publishing require materializing M , and they provide poor data utility when d is large.

We propose to circumvent the curse of dimensionality as follows: We first approxi-mate the high-dimensional data distribution in T with a set of low-dimensional distribu-tions, and then inject noise into the low-dimensional distributions for privacy protection; after that, we use the modified distributions to reconstruct a high-dimensional dataset T , and then publish T  X  . This approach improves data utility since it performs noise in-jection on low-dimensional data (instead of T ), which is much less susceptible to noise injection. The core of our approach is an algorithm that utilizes Bayesian networks [10] to obtain low-dimensional approximations of high-dimensional data. In the following, we first introduce Bayesian networks, and then clarify our approach.
 Bayesian Networks. Let A be the set of attributes in T ,and d be the size of A .A Bayesian network on A is a way to compactly describe the (probability) distribution of the attributes in terms of other attributes. Formally, a Bayesian network is a directed acyclic graph (DAG) that (i) represents each attribute in A as a node, and (ii) models conditional independence among attributes in A using directed edges. As an example, Figure 3 shows a Bayesian network over a set A of five attributes, namely, age , educa-tion , workclass , title ,and income . For any two attributes X,Y  X  X  , there exist three possibilities for the relationship between X and Y : Case 1: Direct Dependence. There is an edge between X and Y , say, from Y to X . This indicates that for any tuple in T , its distribution on X is determined (in part) by its value on Y .Wedefine Y as a parent of X , and refer to the set of all parents of X as its parent set . For example, in Figure 3, the edge from workclass to income indicates that the income distribution depends on the type of job (and also on title).
 Case 2: Weak Conditional Independence. There is a path (but no edge) between Y and X . Assume without loss of generality that the path goes from Y to X . Then, X and Y are conditionally independent given X  X  X  parent set. For instance, in Figure 3, there is a two-hop path from age to income , and the parent set of income is { workclass , title } . This indicates that, given workclass and job title of an individual, her income and age are conditionally independent.
 Case 3: Strong Conditional Independence. There is no path between Y and X . Then, X and Y are conditionally independent given any of X  X  X  and Y  X  X  parent sets.
Formally, a Bayesian network N over A is defined as a set of d attribute-parent (AP) pairs , ( X 1 , X  1 ) ,..., ( X d , X  d ) , such that 1. Each X i is a unique attribute in A ; 2. Each  X  i is a subset of the attributes in A\{ X i } . We say that  X  i is the parent set of X 3. For any 1  X  i&lt;j  X  d ,wehave X j /  X   X  i , i.e., there is no edge from X j to X i in N . This ensures that the network is acyclic, namely, it is a DAG.

We define the degree of N as the maximum size of any parent set  X  i in N .For example, Table 1 shows the AP pairs in the Bayesian network N 1 in Figure 3; N 1  X  X  degree equals 3 , since the parent set of any attribute in N 1 has a size at most three.
Let Pr[ A ] denote the full distribution of tuples in database T .The d AP pairs in N essentially define a way to approximate Pr[ A ] with d conditional distributions any X i and any X j /  X   X  i are conditionally independent given  X  i ,wehave Let Pr N [ A ]= d i =1 Pr[ X i |  X  i ] be the above approximation of Pr[ A ] defined by N . Intuitively, if N accurately captures the conditional independence among the at-tributes in A ,then Pr N [ A ] would be a good approximation of Pr[ A ] . In addition, if the degree of N is small, then the computation of Pr N [ A ] is relatively simple as it requires only d low-dimensional distributions Pr[ X 1 |  X  1 ] , Pr[ X 2 |  X  2 ] ,..., Pr[ X d |  X  d ] . Low-degree Bayesian networks are the core of our solution to release high-dimensional data.
 Solution Overview. Our solution for releasing a high-dimensional data T under  X  -differential privacy, dubbed PrivBayes , runs in three phases: 1. Construct a k -degree Bayesian network N over the attributes in T ,usingan (  X / 2) -differentially private method. ( k is a small value that can be chosen automatically by PrivBayes .) 2. Use an (  X / 2) -differentially private algorithm to generate a set of conditional distribu-tions of T , such that for each AP pair ( X i , X  i ) in N , we have a noisy version of the con-3. Use the Bayesian network N (constructed in the first phase) and the d noisy condi-tional distributions (constructed in the second phase) to derive an approximate distri-bution of the tuples in T , and then sample tuples from the approximate distribution to generate a synthetic dataset T  X  .

In short, PrivBayes utilizes a low-degree Bayesian network N to generate a synthetic dataset T  X  that approximates the high dimensional input data T . The construction of N is highly non-trivial, as it requires carefully selecting AP pairs and the value of k to derive a close approximation of T without violating differential privacy. Interested readers are refer to [18] for the details of the algorithm for PrivBayes  X  X  first phase. In the following, we provide the details of the second and third phases of PrivBayes . Generation of Noisy Conditional Distributions. Suppose that we are given a k -degree Bayesian network N . To construct the approximate distribution Pr N [ A ] , we need d conditional distributions Pr[ X i |  X  i ] ( i  X  [1 ,d ] ), as shown in Equation (4). Algo-rithm 1 illustrates how the distributions specified by our algorithm can be derived in a differentially private manner. In particular, for any i  X  [ k +1 ,d ] , the algorithm first materializes the joint distribution Pr[ X i , X  i ] (Line 3), and then injects Laplace noise into Pr[ X i , X  i ] to obtain a noisy distribution Pr  X  [ X i , X  i ] (Line 4-5). To enforce the fact that these are probability distributions, all negative numbers in Pr  X  [ X i , X  i ] are set to zero, then all values are normalized to maintain a total probability mass of 1 (Line 5). After that, based on Pr  X  [ X i , X  i ] , the algorithm derives a noisy version of the con-ditional distribution Pr[ X i |  X  i ] , denoted as Pr  X  [ X i |  X  i ] (Line 6). The scale of the Laplace noise added to Pr[ X i , X  i ] is set to 4( d  X  k ) /n X  , which ensures that the gen-incur any privacy cost, as it only relies on Pr  X  [ X i , X  i ] instead of the input data T . Overall, Lines 2-6 of Algorithm 1 construct ( d  X  k ) noisy conditional distributions Pr  X  [ X Pr  X  [ X property of differential privacy [6]. In particular, composability indicates that when a set of k algorithms satisfy differential privacy with parameters  X  1 , X  2 ,..., X  k , respectively, the set of algorithms as a whole satisfies ( i  X  i ) -differential privacy.

Algorithm 1. NoisyConditionals ( T , N , k ): returns P  X 
After Pr  X  [ X k +1 |  X  k +1 ] ,..., Pr  X  [ X d |  X  d ] are constructed, Algorithm 1 proceeds directly from Pr  X  [ X k +1 , X  k +1 ] , which has been computed in Lines 2-7 of Algorithm 1. Such derivation is feasible, since our algorithm [18] for constructing the Bayesian net-work N ensures that X i  X   X  k +1 and  X  i  X   X  k +1 for any i  X  [1 ,k ] . Since each Pr  X  [ X construction of Pr  X  [ X i |  X  i ] does not incur any privacy overhead. Therefore, Algo-rithm1asawholeis ( / 2) -differentially private. Example 3 illustrates Algorithm 1. Example 3. Suppose that we are given a 2 -degree Bayesian network N over a and ( D, { A,C } ) .Given N , Algorithm 1 constructs two noisy joint distributions Pr  X  [ A,B,C ] and Pr  X  [ A,C,D ] . Based on Pr  X  [ A,C,D ] , Algorithm 1 derives a noisy conditional distribution Pr  X  [ D | A,C ] . In addition, the algorithm uses Pr  X  [ A,B,C ] Given these four conditional distributions, the input tuple distribution is approximated as Generation of Synthetic Data. Even with the simple closed-form expression in Equa-tion 4, it is still time and space consuming to directly sample from Pr  X  N [ A ] by comput-ing the probability for each element in the domain of A . Fortunately, the Bayesian network N provides a means to perform sampling efficiently without materializing Pr
N [ A ] . As shown in Equation 4, we can sample each X i from the conditional distri-bution Pr  X  [ X i |  X  i ] independently, without considering any attribute not in  X  i  X  X  X i } . Furthermore, the properties of N ensure that X j /  X   X  i for any j&gt;i . Therefore, if we sample X i ( i  X  [1 ,d ] ) in increasing order of i , then by the time X j ( j  X  [2 ,d ] )istobe sampled, we must have sampled all attributes in  X  j , i.e., we will be able to sample X j from Pr  X  [ X j |  X  j ] given the previously sampled attributes. That is to say, the sampling of X j does not require the full distribution Pr  X  N [ A ] .

With the above sampling approach, we can generate an arbitrary number of tuples from Pr  X  N [ A ] to construct a synthetic database T  X  . In this paper, we consider the size of T  X  is set to n , i.e., the same as the number of tuples in the input data T . Privacy Guarantee. The correctness of PrivBayes directly follows the composabil-PrivBayes require direct access to the input da tabase, and each of them consumes  X / 2 privacy budget. No access to the original database is invoked during the third (sam-pling) phase. The results of first two steps, i.e., the Bayesian network N and the set of noisy conditional distributions, are sufficient to generate the synthetic database T  X  . Therefore, we have the following theorem.
 Theorem 1 ([18]). PrivBayes satisfies  X  -differential privacy. This paper reviews the concept of differential privacy as well as two methods, Privelet and PrivBayes , for improving utility in differen tially private data publishing. Privelet utilizes wavelet transforms to ensure that any range-count query can be answered with noise variance that is polylogarithmic to the size of the input data domain. Meanwhile, PrivBayes employs Bayesian networks to publish high-dimensional datasets without incurring prohibitive computation overheads or excessive noise injection.

