 In this work we study the task of term extraction for word cloud generation. We present a folksonomy-based term ex-traction method, called tag-boost , which boosts terms that are frequently used by the public to tag content. Our ex-periments with tag-boost-based term extraction over differ-ent domains demonstrate tremendous improvement in word cloud quality, as reflected by the agreement between ex-tracted terms and manually assigned tags of the testing items. Additionally, we show that tag-boost can be ef-fectively applied even in non-tagged domains, by using an external rich folksonomy borrowed from a well-tagged do-main.

The emergence of social media applications in recent years has encouraged people to be actively involved in content creation and classification. Collaborative bookmarking sys-tems such as Delicious ( delicious.com ) and Dogear for the enterprise [12], as well as many other content sharing sites, encourage users to tag available content for their own use, as well as for the public.

Tags annotated by users form a taxonomy of the tagged items, commonly referred to as a folksonomy .Thevalue of a folksonomy is derived from the unique vocabulary and explicit meanings added by the people who tag the items. Folksonomies have been found to be extremely useful for many information retrieval (IR) applications, including tag cloud representation of social media items, query refinement, and search and browse enhancement [6, 4].

A word cloud is a visual depiction, typically used to pro-vide a visual summary or a semantic view of an item or a cluster of items that have something in common (e.g., the search results for a specific query). Clouds are usually gen-erated using the tags assigned to an item (referred to as tag clouds ), or important terms extracted from the item X  X  de-scription (referred to as word clouds ). Clearly, meaningful, high-quality tag clouds can be generated in well-tagged do-mains where the resources are widely tagged. An item can be successfully represented by a tag cloud that is based on its own tags, or on tags associated with similar items. However, when manual (user-provided) tags are not available, feature selection techniques can be used to extract meaningful terms from the item X  X  content or from other textual resources that are related to the item, such as anchor text or the item X  X  metadata [5]. These extracted terms can be used to create a word cloud [10, 9]. Word clouds, however, are usually infe-rior to tag clouds, since significant terms, from a statistical perspective, do not necessarily serve as good labels for the content from which they were extracted [3]. Recently, word clouds have been popularized by leading social media sites such as Twitter and Facebook , as an alternative to tag clouds due to the sparseness of manual tags in these domains.
In this section, we describe the technique we used for word cloud generation, based on a tag-cloud generation technique originally described by Amitay et al. [1]. This method proved to perform properly when applied on manual tags of well-tagged items and therefore provides a basis for our work.

Most cloud generation techniques that are based on exist-ing manual tags, rank the tags associated with the items in order to create a cloud from the top-ranked tags. In many cases, tags are ranked according to the number of times they were used to tag an item. Let e be an item tagged by k manual tags, ( t 1 ,...,t k ), then a tag cloud (a ranked list of representative tags) can be generated by ranking the tags accordingtothetagscore, s ( t, e )= tf ( t, e )  X  ief ( t ), where tf ( t, e )=log( freq ( t, e ) + 1) is proportional to freq ( t, e ), the number of times e was tagged by t ; ief ( t )=log N N t the inverse entity frequency of the tag t ,where N is the to-tal number of items, and N t is the number of items tagged by t . Such a weighting scheme is analogous to the popular vector-space tf-idf weighing approach. Thus, a highly used tag (high tf ), which is assigned to only a few items in the collection (high ief ), is ranked higher in the cloud.
A cloud for a cluster of tagged items is generated by ranking the tags assigned to all items in the cluster. Let S = { e 1 ...,e n } be a list of tagged items, ranked accord-ing to an arbitrary score function, Score ( e ). Each item e is associated with a list of tags ( t i 1 ,...,t i k i ), k non-tagged item e j , k j = 0). The aggregated score of a tag, with respect to S , is determined as follows: Thus, tags that are frequently assigned to many highly scored items are ranked higher in the tag-cloud.
 The same formula can be used for word cloud generation. Given a set of items, each associated with a set of extracted terms, then a word cloud can be generated using Equation 1, where the term score per item, s ( t, e ), is determined by the the term extraction method.
 Term extraction is strongly related to feature selection, which is the process of selecting a set of terms for text represen-tation. We experimented with four fundamental extraction techniques [11]: 1) tf-idf , which selects terms from the item textual description with maximum tf-idf weights; 2) Mutual Information (MI), which measures how much information the presence/absence of a term contributes to the item de-scription; 3)  X  2 , which measures the statistical independence of the occurrence of the term in the item description and its occurrence in the collection; and 4) Kullback-Leibler diver-gence (KL), which looks for a set of terms that maximize the KL divergence between the language model of the item X  X  content and the language model of the entire collection [2].
We can also consider more sophisticated combination poli-cies between tags and terms, like measuring the mutual re-lationships between them [14]. However, existing methods assume the existence of sufficient associated tags. Advanced integration approaches of terms and tags in sparsely-tagged domains have not yet been studied, to the best of our knowl-edge, and we suggest this as a direction for future work. Internal extracted terms are very useful for IR applications such as text clustering and categorization [11]. However, in general, extracted terms are not always optimal for tagging. Carmel et al. [3] showed that in many cases, even when manually associated tags appear in the text, pure statistical methods have difficulty in identifying them as good descrip-tors. An important term, as determined by common statisti-cal criteria, is not always considered a good label by humans. Therefore, our main hypothesis is that terms considered as good labels by humans have specific characteristics that are not always exposed by standard statistical extraction ap-proaches. We attempt to measure the likelihood of a term being considered by humans as a good tag.
 Let C be a collection of items, and let w be a term. Let C w  X  C ,and T w  X  C be the set of items containing w ,and the set of items tagged by w , respectively. We mark w  X  e ,if term w appears in e  X  X  description. We mark tag ( w, e ), when w is used to tag e .Wemark tag ( w )if w is used to tag any item in C .

The probability of term w to tag an item e when appearing in its description can be approximated by maximum likeli-hood estimation (MLE): Pr C ( tag ( w, e ) | w  X  e ) def = Pr
C ( tag ( w, e ) | w  X  e ) estimates the probability that a term w found in the item X  X  description will also be used to tag that item. Thus, terms with high values should be biased for word cloud generation.

The second measure we apply approximates the global likelihood of a term to be used as a tag. Our approximation is based on the assumption that a term w ,usedtotagmany items in the collection, is more likely to be used as a tag for any item in the collection, compared to terms which are rarely used as tags: Pr C ( tag ( w )) def = | T w | | C |
When estimating probabilities based on a limited amount of data, smoothing is a fundamental approach to adjust the maximum likelihood estimator and thereby correct the in-accuracy due to data sparseness [13]. For example, a term that has never been used to tag the items to which it be-longs ( Pr C ( tag ( w, e ) | w  X  e ) = 0), should still be considered a good candidate for tagging when it is frequently used to tag other items in the collection (with high Pr C ( tag ( w ))). Therefore, the tag-boost probability we apply is based on the Jelinek-Mercer smoothing of the two estimators:
Pr smooth C ( tag ( w, e ) | w  X  e ) def =( 2) The smoothing coefficient  X  , can be optimally tuned for each individual collection. In our experiments, described in Sec-tion 3, we set  X  to 0 . 9 as it seems to perform well for all collections with which we experimented.

Finally, we boosted each term extracted from the item X  X  description, by any statistical term extraction technique, by multiplying its (statistical) weight by the estimated tag-boost probability. We then selected terms with the maxi-mum boosted score for word cloud representation:
We also note that both estimators of the term-tagging characteristics can be inferred from any collection of tagged items. Thus, as we will show, it is possible to estimate those probabilities from an external well-tagged collection, to boost terms in a sparsely-tagged collection that suffers from insufficient statistics.
The main assumption behind our evaluation approach is that manual tags assigned to an item are good labels for summarizing its main characteristics. Therefore, given a testing item associated with good manual tags, the quality of a word cloud generated for that item can be estimated by measuring the number of manual tags retrieved, as well as their relative position in the ranked list of extracted terms. The average precision (AP) measure estimates the quality of a ranked list of terms by measuring the number and rank of the manual tags in the list. MAP, the mean AP over a set of testing items, is the main evaluation measure we used for this work. We also used P@10, the relative frequency of manual tags in the top ten retrieved terms, as a complemen-tary measurement.
 Data. We experimented with term extraction methods over four social media datasets, described in Table 1.
Delicious is a dataset made up of 144.5K unique web pages, all of them with their corresponding social tags re-trieved from Delicious during June 2008 1 . Thisisawell-tagged dataset with 1.85M tags (67K unique tags). All doc-uments (web-pages) are assigned at least one tag. http://nlp.uned.es/social-tagging/delicioust140/ Table 2: Word cloud quality of several term extrac-tion methods, with and without tag-boost
CiteULike is an online bookmarking service that allows users to bookmark academic articles. For our experiments, we used a random sample of 235K documents, with a total of 209K tags (54K unique tags).

Dogear is an enterprise social bookmarking system [12], popularly used by thousands of employees, to organize their bookmarks of both intranet and Internet documents. The Dogear dataset contains 198K web pages, bookmarked with a total of 743K tags (47K unique tags).

BlogCentral is an enterprise blog service allowing employ-ees to publish personal blogs within the intranet and to com-ment on other people blogs [7]. The dataset contains 119K blog posts, tagged with a total of 350K tags (24K unique tags).
 periment, we evaluated several term extraction methods for a single item, with and without tag-boost over the four do-mains. For each domain, we randomly selected 1000 items, each assigned with at least 5 unique tags for testing. For each item, we generated a word cloud by extracting the most important terms from the item X  X  content. We mea-sured its quality according to the manual tags of that item. The (statistical) term extraction methods select the most informative terms from the item X  X  content; we then boosted each term by the tag-boost probability, according to Equa-tion 3. Table 2 represents the MAP achieved by the different term extraction methods over the four domains.

The results reveal no significant difference in performance among the different statistical methods, in terms of the agreement between the generated word cloud and the man-ual tags assigned to an item, as measured by MAP. How-ever, tag-boost improved that agreement significantly for all methods, particularly for Delicious (80% on average for MAP). The improvement was less impressive for the other domains but still significant (65% for BlogCentral , 23% for Dogear and 41% for CiteULike ). In all domains, the im-provement achieved by tag-boost was statistically significant (paired t-test p&lt; 0 . 001). Interestingly,  X  2 , which is the in-ferior method over all collections, outperformed all other methods (albeit insignificantly) when combined with tag-boost.

Since no significant difference in performance was mea-sured among the term extraction methods, we focused the following experiments on the KL extraction method as a representative for statistical term extraction.
 are usually created for a set of items, rather than for an individual item, due to the sparseness of manual tags per item, even in well-tagged domains. We now describe two experiments that evaluate term extraction methods for word cloud generation for a cluster of items.

In the first experiment, we measured the quality of a word cloud created for the result list of a query. For each domain, we ran 100 text queries, randomly selected from a query log, and created two clouds for the top-10 results per query. We created the manual tag-cloud from the tags of retrieved items according to Equation 1. We then created the term-based word cloud by the same formula, using the 30 terms per item extracted from its content. We used the top 10 tags of the manual tag cloud to measure the precision of the word cloud. Table 3 shows the quality of the word cloud, while using KL and tag-boost-based KL (KL+TB) for term extraction, over the four domains. Tag-boost significantly improved the word cloud quality (by more than 200% on Delicious !), to better agree with manual based tag clouds. Table 3: Quality of word clouds generated for result lists of queries
In the second experiment we measured the quality of a word cloud generated for a cluster of items tagged by a per-son. The word cloud X  X  quality was measured using the per-son X  X  in-tags (terms used to tag that user by others). This evaluation is highly reliable since a person X  X  in-tags, provided by other users, represent well the person X  X  topics of interest, while they are also independent of the tagged items. There-fore, the higher the agreement of the word cloud generated for the person X  X  items with her in-tags, the higher its quality.
We selected 1000 people for testing in the Dogear and the BlogCentral domains, each associated with at least 5 in-tags 2 . Table 4 shows the quality of the different term extraction methods used for word cloud generation. The last row shows the quality of the manual-based tag cloud
We could not run this experiment on Delicious and Ci-teULike since we do not have the in-tags for users in these domains. of those items, which is given for reference. While the KL-based extraction method fails to agree with the users X  in-tags, using tag-boost improves the quality by more than 100% on Dogear , and by 60% on BlogCentral ,performing almost as well as manual tags.
 Table 4: Quality of word clouds generated for clus-ters of items, all tagged by the same person final experiment, we examined whether an external folkson-omy can be used for word cloud generation. The data we used was taken from Twitter . Users can tag their tweets by hashtags ; however, less than 30% of the tweets are tagged, and many of the hashtags are used for marking a thread of discussion rather than for labeling [8]. Consequently, manual tags in Twitter are useless for cloud generation. Moreover, its poor folksonomy cannot even be used for tag-boosting. Therefore, Twitter is an excellent example for a sparsely-tagged domain.

We used the Twitter domain to examine whether an ex-ternal folksonomy can be effectively used to replace the use-less folksonomy for tag-boosting. Existing hashtags were treated as regular terms while the Delicious and CiteULike folksonomies were used for tag-boosting. In order to evalu-ate the word cloud quality in this case, we manually tagged a random sample of 1000 tweets, extracted from a collec-tion of 100K tweets that we collected during one week in November 2010. Tweets were tagged according to their con-tent, while considering their hashtags and urls (when they existed). The average number of manual tags per tweet was 2.5 and about 20% of the tweets were not tagged due to difficulties in understanding their underlying topics.
The word-cloud quality was measured in two cases. First, we extracted 5 terms from each tweet X  X  content, using KL with and without tag-boost, and measured the agreement between them with the tweet X  X  manual tags. Second, we ran 100 randomly selected queries and measured the quality of the word cloud generated for the top-10 results for each query,basedontheseextractedterms. Table5showsthe effectiveness of tag-boost for the Twitter domain, first us-ing the Delicious folksonomy, and then using the CiteULike folksonomy. In both cases, tag-boost significantly improved the quality of extracted terms, using the two folksonomies, despite the fact that both folkosonomies were borrowed from different domains. The Delicious folksonomy was superior to the CiteULike folksonomy for tag-boosting, since it is more general and presumably better fits the Twitter domain.
In this work we studied the task of term extraction for word cloud generation in sparsely-tagged domains, in which manual tags are scarce. We presented the tag-boost en-hancement approach for term-extraction methods, which boosts Table 5: Quality of the word clouds generated for Twitter items, using the Delicious (Del.) and the CiteULike (CUL) folksonomies for tag-boosting terms that are frequently used by the public to tag content. Our experiments with tag-boost enhancement, over several enterprise and non-enterprise domains, demonstrated a tremen-dous improvement in word cloud quality, as reflected by the agreement between the generated word clouds and the cor-responding manual tags of the testing items. Moreover, we showed that tag-boost can even be applied in non-tagged domains, by using an external folksonomy borrowed from a well-tagged domain.

For future work we intend to investigate the contribution of tag-boost-based term extraction for other applications. We also intend to explore mutual relations between tags and terms in sparsely-tagged domains, in which manual tags (if they exist) and internal terms can be mixed to provide a better cloud representation.
