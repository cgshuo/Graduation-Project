 We investigate the problem of learning document classifiers in a multilingual setting, from collections where labels are only partially available. We address this problem in the framework of multiview learning, where different languages correspond to different views of the same document, com-bined with semi-supervised learning in order to benefit from unlabeled documents. We rely on two techniques, coregular-ization and consensus-based self-training, that combine mul-tiview and semi-supervised learning in different ways. Our approach trains different monolingual classifiers on each of the views, such that the classifiers X  decisions over a set of unlabeled examples are in agreement as much as possible, and iteratively labels new examples from another unlabeled training set based on a consensus across language-specific classifiers. We derive a boosting-based training algorithm for this task, and analyze the impact of the number of views on the semi-supervised learning results on a multilingual ex-tension of the Reuters RCV1/RCV2 corpus using five dif-ferent languages. Our experiments show that coregulariza-tion and consensus-based self-training are complementary and that their combination is especially effective in the in-teresting and very common situation where there are few views (languages) and few labeled documents available. H.3 [ Information Storage and Retrieval ]: Information Storage -Record classification; I.2 [ Artificial Intelligence ]: Learning Algorithms, Experimentation, Theory Multilingual Document Classification, Learning from Multi-ple Views, Semi-supervised Learning
In this paper, we address the problem of semi-supervised learning of document classifiers in a multilingual setting where documents are available as a parallel corpus with two or more languages for which labels are only partially avail-able.

Our motivation is that multilingual collections are becom-ing more and more common in national and supranational contexts. However, the bulk of document classification and organization techniques and research is developed in the monolingual setting, most often for English. In addition, la-beling text documents may require cost-and time-intensive human annotation, hence the widespread interest for semi-supervised text classification approaches that leverage unla-beled documents to speed-up the learning process.

Our work addresses the two issues of limited annotation and multilingual setting. Using the different languages as different views on a document, we develop a multiview, semi-supervised approach that learns from collection of multilin-gual documents.

We formalize the problem as follows. Given a collection of partially-labeled documents written in different languages and belonging to a set of classes that is fixed across lan-guages, we wish to learn a number of monolingual classifiers for this common set of classes. Note that this problem is different from cross-language text categorization [5], where a document written in one language must be classified in a category system learned in another language.

In our setting, we assume that each document is avail-able in several languages and we are interested in learning improved monolingual classifiers. We also emphasize that we wish to develop inter-dependent monolingual classifiers, rather than a single multilingual classifier, as we wish to be able to classify an incoming document in whatever language it is made available, without having to translate it before-hand.

There have been at least two approaches to multiview semi-supervised learning. One can use coregularization [19] to improve the view-specific classifiers by constraining them to agree on some unlabeled data, leveraging unlabeled data in a multiview learning framework. A more recent proposal [3], by contrast, leverages the multiple views in a semi-supervised learning framework by using the consensus be-tween the different views in a self-training framework. Our solution is to combine those two components into a sin-gle boosting-based algorithm. View-specific classifiers are trained using coregularization, and a consensus-based self-training process iteratively labels unlabeled examples on which the view-specific classifiers agree.

Using a large publicly available corpus of multilingual doc-uments extracted from the Reuters RCV1 and RCV2 cor-pora, we show that our approach consistently improves over both coregularization and self-training taken in isolation. We also analyze the conditions in which the combination is most profitable. It turns out that adding coregulariza-tion to consensus-based self-training helps most when there are few languages and few documents available. This is a particularly interesting setting when resources are limited, and corresponds in particular to the common situation of bilingual data.

In the next section, we position our work with respect to the state of the art. In Section 3, we then present the prob-lem of multiview semi-supervised learning for multilingual text classification. Section 4 describes the boosting-based algorithm we developed to obtain the language-specific clas-sifiers. In Section 5, we present experimental results ob-tained with our approach on a subcollection of the Reuters RCV1/RCV2 corpus. Finally, in Section 6 we discuss the outcomes of this study and give some pointers to further research.
Document classification has been a very popular applica-tion domain for Machine Learning algorithms, and in partic-ular for multiview [7] and semi-supervised learning [16, 12]. The setting of multilingual document classification, however, has been much less studied so far [1, 2].

Interestingly, the original work on co-training [7] intro-duced both multiview and semi-supervised learning on a document classification task. Since then, both fields have de-veloped greatly but mostly independently. Semi-supervised learning approaches include generative approaches, density-based or graph-based approaches (cf. [9] for an overview). Multiview learning techniques include multiple kernel learn-ing [4] and techniques relying on kernel Canonical Correla-tion Analysis [11].

Some recent work more in line with the original co-training approach have introduced coregularization [19, 8], where classifiers are learnt in each view using a multiview regu-larizer that constrains predictions made in each view to be as similar as possible.

When this multiview regularizer is computed on unlabeled data, this provides a way to perform semi-supervised learn-ing in a multiview setting. More recently, a semi-supervised multiview approach has been developed [3] where classifiers are learned on each view using standard single view train-ing, but unlabeled examples are iteratively labeled in a self-training manner using the consensus across the views. The multiview consensus ensures higher confidence in the label-ing, which yields improved semi-supervised learning rates.
Our work analyses and illustrates the combination of these two techniques. We use a coregularization component sim-ilar to [19, 8], with the key difference that instead of the coregularized least squares, we penalize disagreement using a Kullback-Leibler divergence which has a more natural in-terpretation in the context of probabilistic classifier outputs. In addition, it allows us to develop a novel boosting-based algorithm for solving the coregularized multilingual classifi-cation problem.

We combine this coregularized learning with a consensus-based self-training framework similar to [3] where unlabeled documents are iteratively labeled using the consensus pre-diction across the multiple views.

As both coregularization and consensus-based self-training use multiview information and unlabeled data for training, the key question we address is to see whether the two tech-niques can be complementary and improve on each other, as opposed to being completely redundant. We also inves-tigate in which conditions such a complementarity may be exploited. We are particularly interested in the effects of coregularization in the common situation where the number of views is small (eg bilingual documents) and few labeled data are available.
We consider V input spaces X v  X  R d v ;  X  v  X  X  1 , .., V an output space Y .Wetake Y = { X  1 , +1 } sincewerestrict our presentation to binary classification. Each multiview document x  X  X  1  X  ...  X X V is a sequence where each view x v provides a representation of the same document in a different vector space X v . In the seminal work on co-training [7], web pages are represented by either their textual content (first view) or anchor text pointing to them (second view). In our setting of multilingual classifi-cation, each view is the textual representation in a different language. Although typically one of the views is the original version of the document and the others are its translations, we never rely on this information and treat all views equally. Note that in this framework all views of each document are present simultaneously, hence we deal with multilingual text classification in a parallel corpus .
 We further assume that we have a labeled training set Z = { ( x i ,y i ) | i  X  X  1 , .., l }} and a possibly much larger set of unlabeled training data that we split into two parts denoted respectively by X 1 U = { x l + i | i  X  X  1 , .., m X
U = { x l + m 1 + i | i  X  X  1 , .., m 2 }} . Our goal is to obtain V binary classifiers { h v : X v  X  X  X  1 , 1 }| v  X  X  1 , .., V ing each on one view, such that the predictive performance as estimated for example from a test set is optimized. Note that by construction, the label for a given document is the same for all views.
We iteratively learn each classifier h v ,  X  v  X  X  , while keep-ing fixed the classifiers for the other views, h u ,u  X  X  X  by optimizing the loss L ( h v , Z ,X 1 U , X  )= C ( h v , Z )+  X  where C ( h v , Z ) is the (monolingual) cost of h v on the la-beled training set Z , d ( h v ,h u ,X 1 U ) measures the divergence between the two classifiers h v and h u on the unlabelled doc-uments in X 1 U ,and  X  is a discount factor which modulates the influence of the disagreement cost on the optimization.
For the monolingual cost, we consider the standard mis-classification error: where [[  X  ]] is equal to 1 if the predicate  X  is true, and 0 other-wise. As this cost is non-continuous and non-differentiable, it is typically replaced by an appropriate convex and dif-ferentiable proxy. Following standard practice in Machine Learning algorithms, we replace [[ z  X  0]] by the upper bound a log(1+ e  X  z ), with a =(log2)  X  1 . The monolingual misclas-sification cost becomes: Assuming that each classifier output may be turned into a posterior class probability, we measure the disagreement between the output distributions for each view using the Kullback-Leibler (KL) divergence. Using the sigmoid func-tion  X  ( z )=(1+ e  X  z )  X  1 to map the real-valued outputs of the functions h v and h u into a probability, and assuming that the reference distribution is the output of the classifier learned on the other views, h u ,u  X  X  1 , ..., V } X  u = v ,the disagreement d ( h v ,h u ,X 1 U ) becomes where for two binary probabilities p and q , the KL diver-gence is defined as:
There are two reasons for choosing the KL divergence: first, it is the natural equivalent in the classification con-text of the l 2 norm used for regression in previous work on coregularization [19, 8, 18]; second, it allows the derivation of a boosting approach for minimizing the local objective function (1), as described in the following section.
In order to learn the classifier h v for view v , we need to minimize
L ( h v , Z ,X 1 U , X  )= 1 +  X  We show how the loss-minimization of (2) is equivalent to the minimization of a Bregman distance. This equivalence will allow us to employ the boosting-like parallel-update op-timization algorithm proposed by [10] to learn a linear clas-sifier h v : x v  X   X  v ,x v minimizing (2).

A Bregman distance B F of a convex, continuously differ-entiable function F : X   X  R on a set of closed convex set  X  is defined as  X  p, q  X   X  ,B F ( p || q ) def = F ( p )  X  F ( q )  X   X  F ( q ) , ( p
One optimization problem arising from a Bregman dis-tance is to find a vector p  X   X   X , closest to a given vector q  X   X withrespectto B F , under the set of linear constraints { p  X   X  | p t M v =  X  p t M v } ,where  X  p  X   X  is a specified vector and M v is a n  X  d matrix, with n the number of examples in the training set and d the dimension of the problem. 1 Defining the Legendre transform as the dual optimization problem can be stated as finding a vector q in the closure  X  Q of the set Q = { L F ( q, M v R p } ,forwhich B F (  X  p || q ) is the lowest, under the set of linear constraints { q  X   X  | q t M v =  X  p t M v } .

It has been shown that both of these optimization prob-lems have the same unique solution [14]. Moreover, [10] have proposed a single parallel-update optimization algorithm to find this solution in the dual form.

They have further shown that their algorithm is a general procedure for solving problems which aim to minimize the exponential loss, like in Adaboost, or a log-likelihood loss, like in logistic regression. Indeed, they showed the equiv-alence of these two loss minimization problems in terms of Bregman distance optimization.

In order to apply the boosting algorithm proposed by [10], we have to define a continuously differentiable function F such that by properly setting  X ,  X  p , q 0 and M v ,theBregman distance B F (0 || L F ( q 0 ,M v  X  v )) is equal to Eq. (2). Following [10], we choose:  X  p  X   X =[0 , 1] n ,F ( p )= where  X  v i are non-negative real-valued weights associated to examples x v i .
 This definition yields that  X  p, q  X   X   X   X :
B F ( p || q )=
Using Equations (3) and (4), and setting q 0 = 1 2 1 ,the vector with all components set to 1 2 ,and M v the matrix Equation (3) writes:
B F (0 || L F ( q 0 ,M v  X  v )) =
We have deliberately set the number of examples to n as in our equivalent rewriting of the minimization problem the latter is not exactly m 1 .
All vectors  X  i  X  X  1 , .., n } , X  i y i x v i should be normalized in order to respect the constraint M v  X  [  X  1 , 1] n  X  d . Algorithm 1: Parallel-update optimization algorithm Input :Matrix  X  v, M v  X  [  X  1 , 1] n  X  d .

Initialize :Let  X  v,  X  v  X  0 for v =1 , ..., V do end
Output :  X  v ,thesequence  X  (1) v , X  (2) v , ... verifying lim By developing Eq. (2), we get: L ( h v , Z ,X 1 U , X  )= K + 1 ( V  X  1) m 1 ( V  X  1) m 1 where K is a constant which does not depend on h v .
In order to make Eq. (6) identical to Eq. (5) (up to a constant), we create, for each unlabeled document x v i  X  two examples ( x v i , +1) and ( x v i ,  X  1) (which makes n = l + 2 m 1 ), and set the weights as follows:  X 
As a consequence, minimizing Eq. (2) is equivalent to minimizing B F (0 || q )over q  X   X  Q ,where
This equivalence allows us to adapt the parallel-update optimization algorithm described in [10] to learn each specific-view classifier, as described in Algorithm 1.
We embed the boosting-based coregularized classifier learn-ing inside a self-training framework (cf. [22], Section 3) which relies on consensus across views in order to automati-cally label documents from an unlabeled document pool X 2
Each monolingual classifier h v ,v  X  X  is first initialized on the supervised monolingual cost alone, then we iteratively Algorithm 2: Coregularized semi-supervised Learning Input : A set of labeled training examples Z ; Two sets of unlabeled training data X 1 U and X 2 U ;
Initialize :Set Z U \  X  X  X  ; repeat until X 2 U =  X  or X U \ =  X  ;
Output : Classifiers h v ,  X  v  X  X  1 , ..., V } optimize each of the h v classifiers while keeping the classi-fiers for the other views fixed, until the global objective has reached a (possibly local) minimum.

This alternating optimization of partial cost functions bears similarity with the block-coordinate descent technique [6]. At each iteration, block coordinate descent splits variables into different subsets, the set of the active variables and the sets of inactive ones, then minimizes the objective function along active dimensions while inactive variables are fixed at current values.

Once all language-specific classifiers have been trained we assign class labels to unlabeled examples in X 2 U for which all mono-lingual classifiers predict the same class label. These newly labeled examples are added to the labeled training set. We then go back to the boosting-based coregularized classifier training using the combined labeled data, and so on until either no remaining unlabeled example can be labeled by consensus, or all unlabeled examples have been labeled. As shown by [3], focusing on functions which agree across several views reduces the complexity of the function class and therefore improves the prediction ability of the resulting model.

Algorithm 2 summarizes this coregularized self-training strategy.
We conducted a number of experiments aimed at evaluat-ing how the combination of coregularization and consensus-based self-training can help to take advantage of multilingual unlabeled documents in order to learn efficient classification functions.
We perform experiments on a publicly available multi-lingual multiview text categorization corpus extracted from Table 1: Number of documents per language (left) and per class (right) in Reuters RCV1/RCV2 sub-collectionusedinourexperiments. the Reuters RCV1/RCV2 corpus [3]. 3 This corpus con-tains more than 110K documents from 5 different languages, ( English , German , French , Italian , Spanish ), distributed over 6 classes (Table 1). Documents that originally had more than one of these 6 labels were assigned to the smallest class. We reserved a test split containing 25% of the documents, respecting class and language proportions. Within the train-ing set containing the remaining 75% of documents, we ran-domly sampled labeled documents ( Z ), and split the re-maining unlabeled data into two subsets: one for evaluating the coregularization term ( X 1 U ), and one for the self-training process ( X 2 U ). The motivation for that split is to avoid bias: as coregularization enforces agreement between classifiers, it may yield artificially high consensus for the examples used in the coregularization term.

This corpus of multilingual documents is originally a com-parable corpus as it covers the same subset of topics in all languages. In order to produce multiple views for each doc-uments, each original document extracted from the Reuters corpus was translated in all other languages using a phrase-based statistical machine translation system [20]. The in-dexed translations are part of the corpus distribution.
More precisely, each document is indexed by the text ap-pearing in its title ( headline tag) and body ( body tag). As preprocessing, all text is lowercased, digits are mapped to a single digit token, and tokens containing non-alphanumeric characters are removed. For each language, words in a sto-plist as well as tokens occurring in less than 5 documents were also filtered out. Documents were then represented as a bag of words, using a TFIDF weighting scheme based on BM25 [17].

Results are evaluated over the test set using the accu-racy and the standard F 1 measure [21], which is the har-monic average of precision and recall. The reported perfor-mance is averaged over the resulting five language-specific classifiers. In addition, we also averaged over 10 random (train/unlabeled/test) sets of the initial collection.
To validate the coregularized consensus-based self-training approach described in the previous section, we test the fol-lowing six classification methods. The first method is a purely supervised technique which does not make use of any unlabeled examples in the training stage. The follow-ing methods make use of the multiview and semi-supervised learning approaches in different ways, using coregulariza-tion and/or consensus-based self-training separately or in http://multilingreuters.iit.nrc.ca/ combination, over different subsets of the unlabeled training documents.
Our aim is to show the gradual effect of each of the multi-view and semi-supervised learning approaches on the boost-ing algorithm, progressing from Boost to reg-Boost and Boost-cst ,to reg-Boost-cst . Note that the reg-Boost and Boost-cst algorithms use the two separate unlabeled training subsets in different manners. SVM-cst is the same as Boost-cst using a SVM algorithm instead of Boosting. This will allow us to benchmark the boosting-based algo-rithm against the state of the art SVM model in a similar framework. Note that adding co-regularization in a SVM im-plementation requires some significant changes to the un-derlying code, which is why we do not provide reg-SVM vari-ants. Finally, using all the unlabeled training examples in Boost-cst  X  and comparing the results to reg-Boost-cst will allow us to uncover the situations in which it is ben-eficial to combine coregularization and self-training rather than use the latter alone on the combined unlabeled data. This gives an idea of the true benefit brought by coregular-ization. with p&lt;. 01 .
 1 Acc. F 1 Acc. F 1 Acc. F 1
Boost 0 . 771  X  0 . 506  X  0 . 662  X  0 . 398  X  0 . 765  X  0 . 323  X  0 . 505  X  0 . 347  X  0 . 781  X  0 . 587  X  0 . 793 reg-Boost 0 . 793  X  0 . 532  X  0 . 689  X  0 . 419  X  0 . 783 0 . 342  X  0 . 513  X  0 . 372  X  0 . 803  X  0 . 608  X  0 . 815
Boost-cst 0 . 804  X  0 . 572  X  0 . 708  X  0 . 421  X  0 . 794 0 . 365  X  0 . 511  X  0 . 384  X  0 . 866  X  0 . 655  X  0 . 848
SVM-cst 0 . 815 0 . 583 0 . 720  X  0 . 438 0 . 800  X  0 . 378  X  0 . 522  X  0 . 395  X  0 . 873  X  0 . 662  X  0 . 861
We start our evaluation by analyzing the gains provided by coregularization, the consensus-based self-training and the combination of both, over the baseline boosting algo-rithm. We measure the classification accuracy and F 1 for a fixed number of labeled and unlabeled examples in the train-ing set. In order to study the role of unlabeled data on the learning behavior we begin our experiments with very few labeled training examples. The size of the labeled training sets in these first experiments is fixed to 50 (an average of 10 per language), with an equal sampling of 25 positive and 25 negative examples in Z . For coregularization, results are reported for the best discount factor  X  = 1, although as illustrated in Section 5.3.1, results are fairly stable across a wide range of values. We will later investigate the impact on the test performance of the number of labeled examples and the number of views (cf Sections 5.3.3 and 5.3.2). Table 2 summarizes results obtained by Boost , reg-Boost , Boost-cst , SVM-cst and reg-Boost-cst averaged over five languages and 10 random splits of tests sets for our six main categories. We use bold face to indicate the highest perfor-mance rates, and the symbol  X  indicates that performance is significantly worse than the best result, according to a Wilcoxon rank sum test used at a p-value threshold of 0 . 01 [15]. From these results it becomes clear that: 1. Using the first part of the unlabeled training examples 2. The consensus-based self-training framework implemen-3. Finally, the combination of coregularization and self-
Our analysis of these results is that both coregulariza-tion and the consensus-based self-training provide consistent improvements over training independent monolingual clas-sifiers. Both are instances of multiview learning, and both rely in some way on the consensus between classifiers trained on the different views. The question therefore arises as to how redundant these two techniques are? Our experimental results suggest that these techniques are in fact complemen-tary.

The gains provided by adding coregularization to the self-training boosting-based model is in fact similar to the gain provided by coregularization in the supervised setting, which suggest that the two effects are essentially independent and additive. In order to analyze more finely the situations in which the combination of coregularization and consensus-based self-training is more advantageous, we compared all the algorithms, including Boost-cst  X  ,fordifferentnumbers of languages and different amounts of labeled documents. These results are reported in Section 5.3.2 and 5.3.3, right after we address the issue of the discount factor  X  .
We analyze the influence of the discount factor  X  on the performance of reg-Boost-cst for varying amounts of la-beled training data. 4 The results obtained on class E21 are presented in Figure 1. Note that  X  controls the relative im-portance of the unlabeled data in the coregularization (with  X  = 0 corresponding to no regula rization). Figure 1 shows that unlabeled examples become relatively less important as more labeled data is available: as the amount of labeled training data increases from 50 to 300, the optimal discount factor  X  moves away from 1.

We recall that for  X  = 1, unlabeled data plays the same role in the training procedure as labeled data.

Note also that in all cases, the performance of the resulting classifiers seems relatively stable for a wide range of values of  X  . This suggests that the results are not overly sensitive to a precise choice of discount factor  X  .
We also analyze the behavior of the various algorithms for growing initial amounts of labeled data in the training set. Figure 2, illustrates this by showing the F 1 measures on classes CCAT and ECAT with respect to the number of la-beled documents in the initial labeled training set Z .For all labeled data sizes, the proportion of negative/positive ex-amples is maintained at 50%. As expected, all performance curves increase monotonically with respect to the additional
We always maintain the proportion of positive/negative documents in the labeled training set to 50%/50%. training set Z . labeled data. When there are sufficient labeled examples, all algorithms actually converge to the same F 1 value, sug-gesting that the labeled data carries sufficient information and that no additional information could be extracted from unlabeled examples. For a low number of labeled training data, the contribution of each of the algorithms that use unlabeled data is clearly shown. Note that these curves are obtained using five languages, such that the highest perfor-mance is achieved by Boost-cst  X  , which is consistent with the findings of the previous section. When fewer views are available, the relative positions of the top algorithms are dif-ferent, but the effect is similar in that the gains are more important when fewer initial labeled documents are avail-able.
In our experiments, the unlabeled training set was split in two parts, one for coregularization and one for self-training. Our motivation was to examine the effect of each of the techniques individually without introducing any bias by per-Figure 1: F 1 with respect to the coregularization factor  X  for different labeled training sizes on class E21 . forming coregularization and self-training on the same un-labeled data. The previous results suggest that the per-formance gain is higher when unlabeled examples are it-eratively labeled in the self-training framework than when they are used in coregularization to enforce agreement be-tween the language-specific classifiers. The question there-fore arises as to what the performance would be if all the un-labeled examples were used in consensus-based self-training rather than being split between coregularization and self-training? In addition, the consensus is expected to be more reliable when there are many views than when there are few, in which case the language-specific classifiers could agree by chance but erroneously. We therefore investigate the effect of the number of views on the performance of the reg-Boost-cst and Boost-cst  X  algorithms. Figure 3 de-picts these results by comparing both algorithms for varying numbers of languages on two classes, E21 and C15 .Allre-Figure 3: F 1 with respect to the number of languages used for coregularization and self-training on classes E21 (solid) and C15 (dash). Comparisons involve reg-Boost-cst ( ) and the boosting algorithm using the unlabeled examples ( X 1 U  X  X 2 U ) for self-training Boost-cst  X  ( ). sults obtained for less than five languages are averaged over all possible such combinations of languages.

These results show that for five languages, using all the unlabeled data for self-training is slightly more efficient than reserving part of it for coregu larization. However, when the number of views is smaller, the combination of both coregu-larization and consensus-based self-training is more advan-tageous. Note that this is a common situations, for example when only bilingual documents are available.

This result suggests that in the situation where we have few views, reducing the disagreement between language spe-cific classifiers through coregularization may lead to a more effective use of consensus-based labeling, decreasing the num-ber of noisy examples added to the training set during self-training. On the other hand, when the number of views is large, the consensus is usually reliable enough without the need for coregularization.
In this paper we proposed a multiview semi-supervised boosting algorithm for multilingual document classification. We have shown how to embed a disagreement-based coregu-larization term into a classification objective function using a Bregman distance. This embedding allowed us to adapt an existing boosting algorithm to learn language-specific clas-sifiers while enforcing consistency in prediction across lan-guages. We then proposed a self-training algorithm which assigns class labels to unlabeled data based on the consensus of the classifier predictions across the different views.
Our results show clearly that the consensus based self-training allows to reach high performance in the situation where few initial labeled training documents are available. We also showed that when there are fewer languages, com-bining coregularization with the consensus-based self-training approach provides a better leverage of the unlabeled data by improving the quality of the consensus.
 This work was supported in part by the IST Program of the European Community, under the PASCAL2 Network of Excellence, IST-2002-506778. [1] J.J.G.Adeva,R.A.Calvo,andD.L.deIpi  X  na.
 [2] M.-R. Amini and C. Goutte. A Co-classification [3] M.-R. Amini, N. Usunier, and C. Goutte. Learning [4] F. R. Bach, G. R. G. Lanckriet, and M. I. Jordan. [5] N. Bel, C. H. Koster, and M. Villegas. Cross-lingual [6] D. P. Bertsekas. Nonlinear Programming .Athena [7] A. Blum and T. M. Mitchell. Combining Labeled and [8] U. Brefeld, T. G  X  artner, T. Scheffer, and S. Wrobel. [9] O. Chapelle, B. Sch  X  olkopf, and A. Zien, editors. [10] M. Collins, R. E. Schapire, and Y. Singer. Logistic [11] J. D. Farquhar, D. R. Hardoon, H. Meng, [12] T. Joachims. Transductive Inference for Text [13] T. Joachims. Training Linear SVMs in Linear Time. [14] J. D. Lafferty, S. D. Pietra, and V. D. Pietra. [15] E. Lehmann. Nonparametric Statistical Methods Based [16] K. Nigam, A. McCallum, S. Thrun, and T. M.
 [17] S. E. Robertson, S. Walker, S. Jones, [18] D. S. Rosenberg and P. L. Bartlett. The Rademacher [19] V. Sindhwani, P. Niyogi, and M. Belkin. A [20] N. Ueffing, M. Simard, S. Larkin, and J. H. Johnson. [21] C. J. Van Rijsbergen. Information Retrieval . [22] X. Zhu. Semi-supervised Learning Literature Survey.
