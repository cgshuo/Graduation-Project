 Department of Informatics Engineering, Faculty of Sciences and Technology, University of Coimbra/CISUC, University of Coimbra, Coimbra, Portugal
Department of Informatics Engineering, Faculty of Engineering, University of Porto, Porto, Portugal
LIACC  X  Artificial Intelligence and Computer Scienc e Laboratory, University of Porto, Porto, Portugal LIAAD  X  Laboratory of Artificial Intelligence and Decision Support, University of Porto, Porto, Portugal School of Engineering, University of Minho, Guimar X es, Portugal 1. Introduction
RoboCup is a scientific and educational international project [22] that provides researchers with a standard problem within which a large number of technologies can be incorporated and examined. This competition brings together many types of challenges similar to human soccer, such as those presented with the learning of individual agents and teams, multi-agent team planning and plan-execution in ser-vice of team-work, opponent modeling among others [23].
Despite the difference in competitiveness among soccer teams developed for the 2D simulation league compared to the human soccer teams, the importance of preparing a simulated soccer team for the next opponent occupies a similar role in achieving a game victory. Normally, as part of the preparation for a match, a soccer coach tries to adapt his strategy in order to increase the possibility of defeating the opponent. In consequence of that, in this research, we have used data from the RoboCup Soccer group, more precisely the log files produced in the 2009 2D simulation league. In this league two teams of eleven virtual agents try to attain the best possible final result, which means scoring more goals than their opponent. In each game the agents need to connect to a soccer server, which is responsible for supporting the entire competition (simulating the match between the virtual teams) and, at the end, generating a log file. This file contains information relating to 1 : 1. Perception Information  X  This kind of information is split into three distinct groups: audio, visual 2. Action Information  X  This group includes information related to the actions of each player within
Throughout the years, recommendation systems have occupied a key role in many business environ-ments, especially concerning their online component. Usually, these systems include rule-based recom-menders and user customization. Because of that, some researchers classified it as collaborative filtering (CF) [30]. Theoretically, this type of approaches is based on the notion of  X  X ollaboration effects X  that similar items get similar responses from similar users [44]. This personalization is the main approach for the recommendation systems. From a soccer perspective, this recommendation can be related to the type of strategy that a team must use to defeat a specific opponent. Therefore, in this project, a Model-Based CF technique was used to construct the best online behavior model for the FCPortugal team in order to increase its performance against a given opponent. The main contribution of this research work is to es-tablish an objective function that allows the characterization of a complex environment such as a soccer game optimizing the performance of a soccer team. This process includes two distinct phases: offline (made up of 5 distinct steps) based on the 2D simulation league log files and an automatic statistical tool (explained later), which calculates a set of final game statistics defined by a sports research group made up of academic sports professors; and online phase (made up of 2 distinct steps), based on the previously generated knowledge. The obtained results were quite promising and with this approach the performance of FC Portugal increased more than 35%.
 The remainder of this paper is organized as follows: Section 2 presents a brief review of the literature. Section 3 presents a generalization of the problem that was treated in this research work. Section 4 presents the statistical tool that was created to calculate the final game statistics and the team strategy parameters that were used in the game simulation. Section 5 outlines the methodological steps used in this project and also the algorithms used to detect the opponent X  X  behavior. Section 6 outlines the results that were collected and finally, the last section presents the conclusions and proposals for further study. 2. Preliminaries 2.1. Problem formulation
Contextualizing soccer environment with CF, our research problem can be explained as follows: given a vector of continuous variables x (the vectors are represented in bold), the goal is to select the strategy s  X  S that maximizes the average of the continuous variable y . The relation between x , s and y must be in
D ) the goal is given by Eq. (1). occured in the end of game i . 2.2. Collaborative filtering
Over the past years, researchers have identified three CF categories  X  Memory-based, Model-based and Hybrid approaches  X , each presenting advantages and disadvantages. The main advantage of the Memory-based CF approaches is their easy implementation; however, the decrease of performance when data are sparse constitutes its main drawback. In comparison, Model-based CF better addresses the spar-sity and scalability issues and also improve prediction performance; however, this type of technique normally looses useful information when using dimensionality reduction techniques. Finally, Hybrid approaches overcome CF problems, especially in gray sheep issues (explained below), its implementa-tion presents, however, an increased complexity and expense.

Regardless of the used approach, CF algorithms can face a set of problems regarding data sparsity (challenging issue when a system needs to evaluate a very large data set), scalability (critical when the number of users and items grow dramatically), synonymy (the tendency of the same or similar items to have different names), gray sheep (when the users opinions do not consistently fit within a defined user group  X  an outlier  X  turning its classification a hard task for the CF), shilling attacks (when users punctuate positively their items and negatively the items of other users, invalidating any kind of recommendation), among others [36].
 Based on the main advantages and drawbacks of the three CF categories exposed, in this project a Model-based approach was used, mainly due to its improvement of prediction performance (compared to the Memory-based) and less complex implementation, when compared to hybrid approaches.

To develop the model-based approach a combination of two algorithms was used: a cluster algorithm (used as an intermediate step for classifying the set of opponent strategies) and Support Vector Machine. This choice was supported by the fact that cluster algorithms present better scalability than typical CF methods, using smaller clusters rather than entire customer base [13,43]. In this context, K-means was used as the cluster technique, based on its efficiency and easy implementation [21]. The second algo-rithm is Support Vector Machine, that through real-time opponent analysis, and using an offline model (previously developed), recommends which is the best strategy that maximize team performance. 2.3. Motivating discussions
Having ISI (Thomson Reuters) dataset as our knowledge dataset, we performed a large set of searches using different combinations of the keywords: CF plus soccer or robotic soccer or robocup and/or team performance. Unfortunately, we didn X  X  find any type of research that performs CF in soccer, which proves the novelty of this kind of approaches in a soccer scenario. Afterwards, we decided to search separately the keywords and we found a research area that has aroused much interest in the research community: automatic modeling of a human player or even another agent. A strong area in this domain is the human imitation area. Following Aler et al. [4], this topic is present in several fields, such as cognitive sci-ence [11], user modeling [42] or robotics [24]. With regards to the cognitive area, [11] presented a work that tried to model the internal cognition of students. However, over the years, researchers have exploited different perspectives, including Agent Modulation in terms of relationships between Inputs and Outputs (IOAM). Treating the cognition problem as a black box, the IOAM approach can include feature-based modeling [40], C4.5  X  IOAM [41] among others. It is important to note that the IOAM approach only deals with discrete and static domains (the opposite in comparison to a robotic environment). In the user modulation field there were two major areas: user profile creation and behavior cloning. The first area is related to the World Wide Web. With the fast growth in research in information retrieval on the web, companies assume the need to create user profiles in order to group them into communities with common interests [27]. Consequently, users can be classified into stereotypes and their interests can then be predicted.

Behavioral cloning is related to the ability to reproduce exactly a set of actions previously executed by an agent or a human. One example of a research project in this area was produced by Sammut et al. [32], which consists of learning to pilot a simulator through cloning a human pilot simulation experience. The authors used many piloting styles and because of this the learning process did not present good results. Furthermore, this kind of problem (learning from humans) presents three main issues (when compared to machines or agents): humans are less systematic, their behavior varies more and they make more errors. These three issues constitute important issues in this application domain. However, in 2004 these limitations were overcome with the Bauckhage et al. [5] research. These authors provided good imitation play skills on di fferent levels such as r eactive, strategy and mo tion modeling. Using Quake II (a very popular first person shooter game) 2 as the project base, these researchers allow a human to play the game and record his pairs of state vectors and actions. Following this, and in order to reduce the vectors dimension, they used a self-organizing map and a multilayer neural network to map these vectors in actions. At the end, the results appeared promising.

Over the years in the robotic field two different areas have appeared: human imitation and opponent classifier. For the first area, and similar to the approach presented in the previous paragraph, Aler et. al. [4] presented an IOAM approach to model a human playing RoboSoccer. This approach consists of allowing a human to play soccer using the soccer server (the platform that supports the RoboCup 2D simulation league) and a set of low level commands that includes dash, turn and kick. Using the Part machine-learning algorithm, these authors were able to construct the human player model and to implement it in a computer agent. From the results, it was proved that the modulated agent was capable of scoring more goals than the other ones in the same environment. It is important to note that this approach constitutes the first imitation approach in the RoboCup environment.
A different area is opponent behavior classification. The main goal of this topic is not to imitate the opponents but to model them in order to choose the best strategy to defeat them. Normally these models are not learned but predefined and they are used to classify an opponent (usually the team as a whole, and not an individual agent).

Over the years, in the RoboCup soccer environment, a lot of research has been related to opponent modeling, it mostly focused on a coach agent (how a coach agent with limited and restricted communi-cation with its players can improve the performance of his team). Stone et al. [35] presented a low-level positioning and interaction agent approach based on an ideal world (where the performance of the op-posing team is the best possible). However, in this approach, the process of positioning adaptation does not change throughout the game and it is independent of the opposing team (it is a generic approach). This constitutes s severe approach limitation. An extension of this work is proposed by Ledezma et al. [25] with the main goal of improving the low level skills of the modeled agent. Druecker et al. [15] used a neural network to identify the opposing team formation. However this kind of information is very limited, not revealing itself quite capable of improving the performance of a soccer team. Similar to Druecker, Riley presented a learning formation approach based on players X  positions [31]. However, the limitations presented by this study are similar to the previous one.

In conclusion, it is clear that many studies have tried to solve the problem of modeling opponent team behavior, detecting single variables that can improve team performance, like, for instance, detecting the team formation, or trying to analyze the relationship between the  X  X ome or away X  effect. However, at this point it is important to state that improving the performance of a soccer team is a very complex task and because of that researchers must analyze the big picture of a game, which involves selecting which are the variables that most influence the final game result (the aim of the game), to achieve good improvements. Finally, it is important to emphasize that there is no research that uses CF in the improvement of a soccer team performance. 3. Statistical extracting tool and team strategy definition
In this project, a soccer tool capable of extracting final game statistics (through the games logs) was developed. Based on SoccerScope 2 software, 3 new features were implemented in order to fulfill the expectations of the soccer experts. Using a sequential temporal analysis, a set of almost sixty statistics was defined (implemented using Java language). Furthermore, a team strategy was also created according to two types of information (explained later). 3.1. Final game statistics
A set of statistics was previously validated by a board made up of sports experts (constituted by 15 academic professors whose research work is included in soccer area). Generically, these statistics can be divided into five groups: Passes, Shots, Goals, Set Pieces and Ball Possession. 3.1.1. Pass
A successful pass occurs when a kick is executed by a soccer player and after a few cycles, a teammate receives the ball without a player from the opposing team intercepting it. In this work, the number of successful passes in each part of the match is analyzed as well as those passes that are intercepted by a player from the opposing team. Other variations of the pass that were also detected in this work are the  X  X ing chain X  and  X  X ass chain X . In order to detect the  X  X ing chain event X , the soccer field was split into three equal regions/corridors: left, middle and right. If the event algorithm detects a successful pass between two teammates and if this pass occurs between the left and the right regions (or vice-versa), the algorithm will classify it as a successful pass and a  X  X ing chain X . The  X  X ass chain event X  consists of identifying the number of successful consecutive passes that a team is capable of completing during a match. 3.1.2. Shot
A shot event occurs when a player, in his attacking midfield, kicks the ball in the direction of the goal (with a 5 meters margin) with enough force for the ball to reach it. After this kick, if a player from the opposing team intercepts the ball the event is classified as an intercepted shot. Otherwise, two situations can occur: the player X  X  kick results in a goal or the ball leaves the field. In this last situation, if the ball leaves the field very close to the goal, the event is classified as a  X  X hot on target X ; otherwise it is considered a  X  X hot X . 3.1.3. Goal To detect a goal event using a temporal sequential analysis, three consecutive cycles must be analyzed. ball needs to be over the goal line. Finally, in the last cycle the ball must have passed the goal line completely. If these three conditions occur in the soccer match the event will be detected as a goal event. The number of goals scored in both parts of the game is registered. The region of the field from where opportunities X  is created and consists of identifying the situations where an attacking player has a large probability of scoring a goal. The probability calculus is based on the position of the player (inside or outside the penalty area) and the number of players that he has in his view field aligned with the goal line. For each player this probability decreases by 0.2 plus 0.2 if the player is outside the penalty area. 3.1.4. Set pieces A Set piece is an extremely important game situation [18] and can be divided as Corners, Goal-Kicks, Throw-Ins and Fouls. In this work all of these groups are detected, however, within the Fouls group, only offside situations are classified. 3.1.5. Ball possession
A soccer team has the possession of the ball in a given interval of time if, during that time, none of the players from the opposing team intercept the ball and the ball does not leave the playing field. To classify ball possession more succinctly, the soccer field was divided into twelve equal parts (six defensive and six offensives). Furthermore, a new concept was introduced which consists of evaluating the time a team takes to get to the last third of the field without losing the ball. This information is extremely relevant in order to classify the offensive style that a team uses during a game. This classification is divided into four levels: slow, medium, fast or break depending on when the opposing team recovers the ball. 3.2. Team strategy definition
In this research two distinct high-level variables were used to increase the flexibility of our team movements in combination. In order to define this information, the Playmaker tool [16,29] was used. This tool is comprised of two distinct modes: formation definition and set play definition. 3.2.1. Team formation
Team formation is defined by the positioning used by the players in order to occupy the field in the best possible manner. In this tool, the players X  positions are calculated through a Delaunay Triangulation [3] and a linear interpolation algorithm. For this task we used the same algorithm that was used in the Gouraud Shading algorithm [19], which simulates the differing light and color effects along a surface.
The formation definition is based on the ball position. All ball positions included in the formation definition are used as vertices to create the triangulat ion. After determining th e triangle (B1, B2, and B3) that encompasses the current ball position (B), player positions are calculated (P (B1), P (B2), and P (B3) are the players X  position when the ball is in the corresponding point). Figure 1 illustrates an example of the interpolation process [29]. 1. Calculate the I value (the intersection point between the line B1B and segment B2B3); 2. Calculate the interpolated target position regarding I as the current ball position and B2 and B3 as 3. Calculate the new player position in relation to the ball position B Eq. (2):
In this research, two distinct formations were defined (1-4-3-3 and 1-4-4-2) and 115 points were used for the definition of each formation. The experimental results showed that this type of approach is adequate for this context allowing a rich definition of a formation, relating the ball poistion with the players positions. An example of a 1-4-3-3 formation definition using the Playmaker tool is illustrated in Fig. 2. 3.2.2. Set-plays
The Set-Plays definition can be seen as a flexible team plan for a specific game situation that can involve a specific game period, the number of scored goals, a game situation, such as a set piece, or even the opposing players X  position on the field.

Normally, a Set-Play is identified by a name, a set of parameters (conditions) and players. Furthermore, a set play can be seen as a list of states. The possible transaction between these steps can be divided into three groups: (1) abort if not all the conditions to continue with the set play are met; (2) the next step transaction when all the conditions to continue are met; and finally (3) the finish transaction which indicates that a set play execution is completed.

In this research 8 different set plays were used. They can be divided into four groups relating to a specific game situation (Kick-off, Free Kick, Goal Kick and Corner Kick). Only one SetPlay of each group was used in each simulation game. An example of a SetPlay (a Kick-off situation) is illustrated below. The black and white line symbolizes the movement of the player and the ball respectively. It is important to note that if, for some reason, the conditions for the realization of a Set-Play are not met it will be aborted.

Kick-off is a situation that characterizes the beginning or recommencement of a soccer match (e.g. after a goal is scored). In this work two set plays relating to this game situation were used: 1. Kick-off to winger constituted by 4 step (Fig. 3); 2. Kick-off to winger constituted by 2 steps (Fig. 4); 4. Methodology
We describe the general idea of our approach to solve the given problem, i.e., the recommendation of a strategy for our team, given the way the opponent is playing. The idea is to select the strategy that has obtained the highest average of goal differences from past games where the opponents have played as our current opponent is playing. Or, using a different language, our two goals are: to locally rank the strategies by decreasing order of the average goal differences, and to select the top one.
In the next section we describe in detail our approach divided in two phases: online and offline. Then, we present the main algorithms used. 4.1. Project architecture details This approach has two distinct phases: offline and online (Fig. 5). All learning tasks are done off-line. This means that the main computation effort is done off-line.

The offline phase has 5 steps: 1. Simulation: It consists of developing a tool that automatically calculates the final game statistics 2. Feature selection: It uses the MARS algorithm [17,33] to select the statistics that most influence 4. Training classifier: It trains a classifier that can predict the group that best characterizes a given 5. Selection of the best strategy per cluster: Using the features selected in step 2, the variable Goal 6. Prediction: Given a new set of values for the input variables it uses the classifier trained in step 4 7. Assignment of the best strategy: Using both the information calculated in step 5 and the cluster Further information about the different steps will be included in the Experimental Results section. Finally, it is important to note that all the data processing in this project was performed using the R software version 2.11.0. 4 4.2. Multivariate adaptive regression splines (MARS)
Friedman X  X  1991 Multiple Adaptive Regression Sp lines (MARS) model [17,33] employs recursive partitioning to locate produc t spline basis functions of an adjustab le degree, rather than constants. This results in smooth adaptive function approximation as opposed to the crude steps or plateaus provided by regression trees. The method also takes into consideration splines involving interactions between previously selected variables so it can orient its basis functions other than on the original data axis. To aid interpretation, model terms are collected according to their inputs and their influence is reported in an ANOVA manner. The effects of individual variables and pairs of variables are collected together and graphically presented as function plots. MARS also employs cross-validation, prunes terms after over-growing, and can handle categorical variables.

MARS builds its models according to Eq. (4) where the aim is to add together the weight of basis functions B i ( x ) ( c i are constant terms).
The construction of the MARS models is divided into two distinct phases: the forward and the back-ward passes. In the forward pass the algorithm starts with a model, which only consists of the intercept term. After that, and being a greedy algorithm, it will include in the model the basis functions pairs that give the maximum reduction for the sum-of-squares residual error. Each new basis function consists of a term, already in the model, multiplied by a new hinge function, which is defined by a variable and a knot. This addition conti nues until the maximum number of terms is reached or if the change in the residual error is negligible. In order to generalize the model produced in this phase, the backward pass consists of pruning the model. It will remove terms one by one until the best sub model is reached and this is evaluated by the GCV (Generalized Cross Validation) measure variable.

The result of MARS is an interpretable equation. The features used in the equation are the ones that are selected to explain the target variable. Since the MARS algorithm uses the recursive partitioning algorithm [10], this approach to selecting features is similar to the one described in [12]. 4.3. K-Means algorithm
Data clustering or Q-analysis or Typology or Clumping or even Taxonomy (depending on the applied be found at Webster [21]  X  X  statistical classification technique for discovering whether the individuals of a population fall into different groups by making quantitative comparisons of multiple characteristics X .
Clustering algorithms can be divided into two groups: Hierarchical and Partitional [21]. The Hierar-chical algorithm works in two ways: (1) it starts by agglomerating all of the data in the same cluster and recursively dividing the cluster into small clusters (divisive mode); or (2) it starts to put each data point in respective clusters and merges the most similar clusters in a hierarchical cluster (agglomerative mode). On the other hand, the Partitional algorithm does not impose a hierarchical structure and finds each iteration according to the minimization of a given distance measure.

Normally, due to the nature of the available data, the Partitional algorithms were preferentially se-lected. One of the most famous/adopted Cluster Partitional, due to its simplicity, efficiency and empiri-cal success, is the K-Means algorithm. Over the years it has been used in several areas. The first work dates back to the 1950s [34]. It does not use a target field and this algorithm tries to uncover patterns in similarities. 4.4. Bagging
The bagging algorithm is constituted by three distinct steps. The first step consists in generate X k bootstrap samples (i.e., samples with replacement) of size n from an original dataset (with the same size). After that, the algorithm will train a predictor (tree) for each generated sample (the number of trees is typically 50 X 100 times [7,8], a value given by the X k input parameter of the algorithm). Finally and, depending of the problem nature, the final result is the most predicted class by its base-classifiers (majority voting). 4.5. Random forest
Created by Breiman [9] Random Forest instantly became a commonly used method, mainly due to its simplicity (in terms of training and tuning) and performance [38]. Similar to the previously analyzed algorithm, Random Forest constructs a given number of trees. However, during the construction of each tree, at each node v variables are randomly selected (considering v&lt; number of input variables) and trees in the forest is the predicted class (for more details see [9]).
 4.6. Support vector machines (SVM) Based on the concept of decision planes that define decision boundaries, SVMs were developed by Vapnik [39], for binary classification. This technique tries to find the optimal separating hyperplane between two classes by maximizing the margin between the classes X  closest points. The points lying on the boundaries are called support vectors and the middle of the margin is our optimal separating hyperplane. To construct an optimal hyperplane, SVM employs an iterative training algorithm which is used to minimize an error function. A more complete overview can be found in Vapnik [39] and Boser et al. [6]. 5. Experimental results
In this section all the achieved results obtained in the two project phases (online and offline) will be described. 5.1. The offline phase
With regards to Fig. 5, the first step of our approach was to develop a framework capable of automati-cally calculating the final game statistics through RoboCup 2006 X 2009 2D Simulation League log files. subset of the calculated statistics (60) that most influence the game result and for that we used the MARS algorithm. However, we have started standardizing the data (Eq. (5)  X  where  X  ( x ) is the sample average and  X  ( x ) is the sample standard deviation) based on a previous work developed by Abreu et al. [1]. That work had two main goals: to select a feature subset in order to avoid irrelevant features that can decrease the performance of the clustering algorithm (step 3) and obtain an evaluation function that is used in step 7. For this reason the MARS and the RReliefF algorithms were tested and at the end MARS had a minor mean squared error (for more details please consult Abreu et al. [1]). Consequently, in step (2) we used the MARS algorithm to discover the final games statistics that most influenced the games results (using as a target the difference of scored goals). The obtained expression is shown in Eq. (6). This expression includes variables relating to the total number of bad passes (Bad-PassTot), Pass Chains (PassChainTot), outside situations (OutTot), number of goals (GaolsTot), number of attacks (AttTot) and, finally, the statistics relating to ball possession per zones (1-LBposs-Def, 2-MBposs-Def, 3-RtBposs-Att etc.). The following measures are used to evaluate the MARS function: the coefficient of determination (RSq) which measures the quality of adjustment, the generalized coefficient of determination (GRSq) that measures how well the next value can be predicted using the structural part of the model and the past values of the residuals. The GRSq and RSq values vary between 0 and 1 (as higher the better). Having this previous knowledge as a base, the input of the system consists of three robotic teams X  binaries that occupied distinct positions in the final classification table (RoboCup 2009 2D league) in order to have a high spectrum of final game simulation results. Following this, 32 distinct team strategies (16 set plays combinations plus 2 formations) were defined and, in order to avoid outliers, each team used the same tactic in 10 simulations. As such, we simulated 480 games (3 teams  X  16 strategies  X  10 simulations). Using the obtained subset of statistics, the data instances are then grouped according to their similarity (step (3)). For that, we have used the K-means algorithm. In order to determine the optimal number of k clusters is (the optimal number of cluster is a compromise between the minimum sum square errors and the minimum number of clusters), the GAP algorithm was used. According to Tibshirani et al. [37] the number that maximized the GAP should be used as the number of clusters (in our case this value was 9). In step (4) and according to the guidelines presented in Meyer et al. [26] three data mining methods (SVM, Random Forest and Bagging) were trained for the prediction of the cluster previous step). In the training process a 10-fold Cross Validation was used and more than 1920 log files, including matches of the RoboCup 2D simulation league between 2006 and 2009 were also used.
With reference to the percentage rate in the test set of the 10-fold cross validation (previously de-scribed), SVM is the one that presents the highest result (96.4%), followed by RandomForest (93.59%) and Bagging (80.15%).

In step (5) the expected best strategy (combination of Set Play and Formation) was defined according to the one that obtained best results in past games where the opponents were playing as our current opponent is playing (this step ends the offline phase). 5.2. The online phase
For step (6), the SVM model generated in step (4) was used to predict the cluster where each game (input data) is expected to be more similar to (the duration of this process is 10 cycles). Finally, in step (7), the expected best strategy was assigned according to cluster predicted in step (6).

To produce experimental results for the online components, 840 games were simulated (280 per oppo-nent team) between FC Portugal and each of the following teams : Wright Eagle, Nemesis and Bahia 2D. In that simulation, the online (OL) phase was executed using different frequencies in a simulated robotic soccer with 6000 cycles: every 500 cycles (OL500), every 1000 cycles (OL1000) and every 2000 cycles (OL2000)  X  a simulated robotic soccer has 6000 cycles. These three configurations were compared with a Baseline algorithm, which is an approach that chooses the strategy that FC Portugal will use before the game and, during the game it does not make any changes. The results were evaluated according to the number of wins, draws and defeats (Tables 3 and 4 illustrated those achievements). If, for some reason, there was a draw between the results produced by at least two algorithms (same number of victories, defeats and draws), a draw scale was used. This scale consisted of assigning 4 points for a victory, 2 points for a draw and 1 point for a loss. These values increased 0.1 per goal scored (increasing with the difference of goals scored in case of victory and decreasing in case of defeat). For instance, if FC Portugal wins two games by the difference of 2 or 12 goals, these games will be ranked with 4.2 and 5.2 points respectively. On the other hand, if this team loses two games by the difference of 2 or 12 goals, these games will be ranked with 0.8 and  X  0.2 points respectively (this scale was used to measure the team X  X  performance in Table 2).

The comparison is done using the Friedman rank test. We have compared the average of the results of each of the three configurations plus the baseline approach (four different options). The 280 simulations per opponent team were divided into 4 distinct groups (one per option). The ranks obtained are shown in Table 1. The null hypothesis of equivalence between the four predictors is rejected with a p -value of 0.00000303. Comparing the three configurations against the baseline for a 5% significance level with the Bonferroni-Dunn test [14], we have obtained CD = 1.2617. CD is the critical value for the difference of mean ranks between the baseline and any other of the three predictors. It is proved that OL500 and OL2000 are better than the baseline. 5.3. Performance improvements
Regarding the scale presented above (Table 2), we were able to improve the FC Portugal team X  X  per-formance by over 35% (35.87%, 35.31% and 35.34%) for the three used online frequencies. Doing a more deep analysis concerning the opponent (using the same scale), for the Nemesis team, every OL configurations beat the baseline approach (always more than 135% of improvement). The FC Portugal team presented a smaller improvement against the Bahia 2D (around 28%). This result is explained by the fact that Bahia team is a rookie in the RoboCup competition and, because of that, teams like FC Portugal normally win the games scoring many goals and for that reason the improvement will always be a little bit limited (comparing to the others two teams).

Regarding to the number of wins, defeats and draws (Table 3), the three OL approaches presented outstanding results. In global terms (without individual team analysis), the OL500 increased the number of wins by 25.78%, decreased the number of losses by 7.34% and also decreased the number of draws by 51.72%. In what concerns to OL1000, it presented an increase of wins of 24.44%, a decrease of defeats of 7% and an also a 48.28% decrease in the number of draws. Finally, to OL2000, it presented an increase of wins (25.55%) and a decrease of 6.31% and 68.87% for defeats and draws respectively.
Finally, in what concerns to the difference of goals scored (always from the FC Portugal perspective), the numbers presented were also excellent: 98.45%, 98.79% and 98.38% for the OL500, OL1000 and OL2000, respectively (Table 4), which constitutes an admirable result, when comparing to other studies, such as that by Stone et al. [35], which presented an increase of 9 scored goals in average and that by Ledezma et al. [25], that increased in average one scored goal (in one hundred games). In conclusion it is proved without any doubts that our approach is capable to improve a performance of a robotic simulated soccer team. 6. Conclusions and future work
In this research, an approach capable of constructing an online team model was presented. From a soccer team coach perspective it is important to obtain all possible knowledge relating to how the oppo-nent plays. Such knowledge can be used to prepare new games (offline phase) or to adapt the strategy used along the game (online phase). Focusing on these two phases, the main goal of this research is to prove that if a coach agent during the game periodically changes his team strategy using the knowledge previously generated in the offline phase, it is possible to improve his team X  X  performance. We based our strategy in two very simple premises  X  two team formations and 8 different set plays  X  and proved that it is possible to increase the team X  X  performance. As outlined in the previous section, SVM proved to be the best algorithm in the prediction step (step (4)). Additionally, OL500 and OL2000 proved to be better than a baseline approach to increase FCPortugal performance (step (7)).

The obtained results were very promising and the team X  X  performance increased by 35.87% and 35.4% using the OL500 and OL2000, respectively. If we executed an opponent individual analysis, for the Nemesis team, the performance of our team improved by more than 135% in each tested case. For the top tournament team (Wright Eagle), the improvement was of 37.58% for OL500 and 31.62% for OL2000. Also, establishing a comparison between other literature works, none of the analyzed works presented results as promising as those presented in this paper. They simply increased the number of scored goals (by an average of 1 [25] or 9 [35]).
 This problem is an example of a much more generic type of problems (as described in the Problem Formulation section). We believe that the approach we presented can be used in many different environ-ments such as health treatment strategy selection where it is very important to identify the best strategy to eliminate/control a disease throughout proliferation markers/hormonal receptors status or in transport planning to select planning options such as bus/train frequency in order to optimize the general quality of the service (e.g minimize delays). The presented framework can be used for problems with a finite num-ber of strategies. Both x and y variables (as described in the Problem Generalization section) assume continuous values in soccer environment. However, the used framework could be easily extended for non numerical variables by: (1) using a different distance function in clustering when x has non-numeric variables (see step (3) in Fig. 10) and/or (2) using a different criterion (such as the mode instead of the average, for instance) to rank strategies when y is non-numeric (step (5) in Fig. 10).
 Acknowledgment This work is part-funded by the ERDF  X  European Regional Development Fund through the COM-PETE Programme (operational programme for competitiveness), by the Portuguese Funds through the FCT (Portuguese Foundation for Science and Technology) within project FCOMP  X  01-0124-FEDER-022701.
 References
