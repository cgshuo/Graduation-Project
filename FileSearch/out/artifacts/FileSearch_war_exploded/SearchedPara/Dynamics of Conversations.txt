 How do online conversations build? Is there a common model that human communication follows? In this work we explore these questions in detail. We analyze the structure of conversations in three different social datasets, namely, Usenet groups, Yahoo! Groups, and Twitter. We propose a simple mathematical model for the generation of basic con-versation structures and then refine this model to take into account the identities of each member of the conversation. Categories and Subject Descriptors: H.2.8 [ Database Management ]: Database Applications X  Data mining General Terms: Algorithms, Experimentation, Measure-ment, Theory Keywords: Conversations, Threads, Graph models, Hu-man response, Usenet, Groups, Twitter
In today X  X  world, information networks such blogs, on-line forums, and other online content-generating communi-ties are among the most important sources of knowledge. In such networks, information is provided and disseminated through social interaction among members of the commu-nity. Understanding the dynamics of such interactions is therefore essential in making sense of how this information is generated, how reliable is each piece of information, and how the content generation process can be influenced to achieve better results.

There has been significant research on the dynamics of networks of linked information such as the web, where con-tent providers (webpage authors) form a graph by linking to each other. We know various properties of such graphs, the-oretical generative models that provide simple explanations for underlying processes that gives rise to these properties, and methods for using the graph structure in order to ex-tract information about the reliability and importance of various nodes. Funded in part by Yahoo! Research
Another important class of information networks that have not received enough attention from a theoretical point of view are those where units of information have relatively short life-spans (shorter than that of webpages), and there-fore time is an essential part of the dynamics of network creation. This class includes Twitter, online discussion fo-rums, and news websites. With the modern-day shortened news cycle, such networks are becoming increasingly impor-tant.

In this paper, we seek to study a class of such networks, namely, the network formed by conversation threads in on-line communities. We will examine three different data sam-ples: Yahoo! Groups, Usenet, and Twitter. In addition to the important role time plays in the growth of such networks, a factor that makes them a particularly desirable object of study is that the links in these networks have a more or less uniform meaning: a link from a node  X  to another  X  means that the message corresponding to  X  is in reply to that of  X  . Each node is in response to only one other node (if any), and furthermore, each node is identified with a distinct author. In other words, nodes in these networks are more atomic units of information than, say, webpages.

Our goal is to shed light on how conversations form in different online groups by studying several questions: What are the common properties of conversation threads? What similarities and differences can be observed between different groups? Can we build models to capture these properties? Can we analyze them? How can we characterize group con-versations (i.e., conversations that engage a group of users) as opposed to those that are primarily pairwise exchanges?
The rest of this paper is organized as follows: We start by reviewing the related work in Section 2. In Section 3, we describe the three main datasets that we use in this study: Yahoo! Groups, Usenet, and Twitter. We will first examine the properties of the threads and the induced social net-works in Section 4. In addition to the usual observations of the power-law/heavy-tailed distributions, we make two key observations by analyzing the data: (1) the depth of such threads grow sub-linearly but super-logarithmically in the size of the thread, and (2) a law similar to Heaps X  law [15] holds for the number of distinct authors in a thread.

Section 5 and Section 6 contain a description of gener-ative models for conversation threads. For each model we prove a number of theoretical results, show simulation re-sults, and give results of learning algorithms on our datasets on the model (to learn the parameters of the model). We start with the branching process model, which is the clas-sical model in probability theory for generating trees (sim-ilar to what Erd  X  os X  X   X enyi model is for generating graphs); this serves as a baseline model. Next, in Section 6 we give a preferential-attachment-type model [1] that combines the rich-gets-richer principle with the element of time. We also give a model for the distribution of the authors of the mes-sages in a thread that is based on a variant of the copying process [18] in Section 6.3. Finally, we give a mixture model for forums such as Twitter where the types of threads we observe are not homogeneous, and show how expectation-maximization algorithms can be used to partition the con-versations into different classes. Section 8 contains some anecdotal examples from our dataset, based on our study. Section 9 contains concluding remarks.
The related work falls into the following main categories: work on conversations and human activity in general, cross-community group dynamics, and graph models.
 Conversations and human activity. The work closest to ours is that of Liben-Nowell and Kleinberg, who studied the structure of chain letter propagation [25], showed that the structure was characterized by a deep tree-like pattern, and proposed a probabilistic model to generate such trees. Golub and Jackson [12] built on this to show that a basic branching process model combined with the selection bias of observing only large diffusion can explain the results in [25]. These lines of work concern a mechanism for the spread of information in a social network. We, on the other hand, are interested in studying the patterns of interactions and repeated interactions (i.e., conversations) in closed groups.
Another work related to ours is that of Leskovec, Back-strom, and Kleinberg [20], who considered the propagation of  X  X emes X  across the Web in the context of news cycle. In course of studying this problem, they consider a model where they combine recency and the preferential attachment process. However, their focus is not on a graph generation model and, as they indicate, the combining form they pro-pose does not seem to be analysis-friendly.

There has also been some exploration into the dynamic processes of conversation and information propagation. Barabasi [3] postulated that the bursty nature of human behavior is a consequence of a decision-based queuing process and used it to explain the heavy-tailed activity patterns in e-mail com-munications; Vazquez et al. [8, 31] further explored this model. This was reproduced in [23], where response times to blog posts were shown to have a similar heavy-tailed dis-tribution.

Conversations can also be characterized as information cascades , phenomena in which an action or idea becomes adopted due to the influence of others, typically, neighbors in some network [4, 11, 13]. Cascades on random graphs us-ing a threshold model have been theoretically analyzed [33]. There has been empirical analysis of the topological patterns of cascades in various contexts, such as recommendation net-works [24, 19] and blog posts [23]. In the latter, authors ex-tracted  X  X ascades X , or conversation threads, from a large set of blog posts, and studied patterns with respect to the sizes and shapes of these cascades, as well as topological aspects of the network at large. They continued this to show that different genres of blogs have different patterns of cascade shapes [27].
 Cross-community studies. There have been several pre-vious studies across social networks data. Backstrom et al. studied Yahoo! Groups data, defining  X  X hriving X  groups and tracking engagement of core users in groups [2]; see also [7]. Kumar, Novak, and Tomkins studied the topological struc-ture and component size distribution of Flickr and Yahoo! 360 networks, identifying  X  X tar X  structures and showing how they persisted and eventually joined the giant component [17]. Leskovec et al. studied the edge arrivals of different online networks, proposing a generative model [21]. There has been a significant body of work on forum data. Microsoft X  X  Netscan Project has conducted a very thorough study of Usenet discussion patterns, depicting hierarchy of newsgroups and their changes between 2000 and 2004 [30], studying the social roles of Usenet authors [10], and creating a visualization tool for different author roles identified [32]. Other authors explored the network structure of different groups and studied cross-posting behavior [26].
 Graph models. There has been a lot of work on developing tractable mathematical models for real-world graphs and so-cial networks, starting with the legendary Erd  X  os X  X   X enyi  X  model. For a detailed survey of these models, the readers are referred to [6, 9, 16]. There have been a few develop-ments on graph models since these surveys, e.g., [22, 21]; these are beyond the scope of our work. To the best of our knowledge, group conversations have not been explicitly addressed in any of the previous works.

For a detailed background on branching processes, the readers are referred to the classic book by Harris [14].
We first describe the three sources of data that will be used in our study, namely, messages from a set of Usenet groups, messages from a set of public Yahoo! Groups, and Twitter tweets over a month. The first and the last datasets are publicly available and hence our experiments and obser-vations are repeatable.
 Each dataset consists of records, where each record has the ID of message, the ID of its parent message (if applicable), the author of the message, and a timestamp. Notice that all the three datasets enable conversations among users, i.e., messages can be posted in response to earlier messages. We will use these sources to show some commonalities in thread structures.
 Usenet groups. Usenet is a decentralized set of fo-rums across different subjects and languages. We sam-pled Usenet based on groups posted to in early January 2010, according to http://newsadmin.com/top100tmsgs. asp , using the server Giganews. For a complete list of the groups crawled, refer to http://www.cs.cmu.edu/  X mmcgloho/pubs/groupthreads-list.txt . This gave us a broad sample of newsgroups, including some on political discussion ( alt.politics , it.politica ), recreational ac-tivities and hobbies ( rec.outdoors.rv-travel , rec.music. beatles ), and general news or ads ( news.lists.filters , alt.marketplace.online.ebay ). This crawl produced around 10 million posts in total. Most groups had be-tween 1,000 and 5,000 users, with some as few as 20. We also had a deeper crawl that focused only on political groups, see [26]. This consisted of around 200 groups with posts from 2004 X 2008. This included several general poli-tics groups ( alt.politics , talk.politics.misc ), some na-tional politics groups ( it.politica , uk.politics ), state or regional groups ( pa.politics , bc.politics ), and topical groups ( uk.politics.guns , talk.politics.drugs ). This produced 37 million posts.

While Usenet is declining in popularity, it has the feature that it is public, easy to crawl, and has an obvious thread structure (with reply-to as a line in the header). Further-more, certain Usenet groups are still very active, and have not declined in usage. This is the rationale for having Usenet as part of our data sample.
 Yahoo! Groups. Yahoo! Groups is a popular on-line groups application. We chose public groups from Yahoo! that were moderated (unmoderated groups were mostly spam); we restricted our attention to groups that were still active, i.e., they were not deleted or suspended. We also restricted the sample to groups that had at least ten messages and had at least ten distinct users. This resulted in 13,102 groups in the dataset with over 14.9 million posts. The groups in our data included ones such as WrestlingGear , cookbook-reviews , IndianaSPCA , welcometomorocco , neurosurgeonsclub , etc. These groups covered a broad set of topics and interests. Most groups contain 500 to 5,000 users, with some as few as ten (our minimum threshold for including in the dataset). The data was collected in January 2010.
 Twitter. Twitter is an extremely popular social application where users send short messages (called tweets ), sometimes in response to other messages. We examined a large sub-set of tweets for the month of September 2009. Since the tweets are small (at most 140 characters), in addition to the message meta-data (which includes reply-to information), we have the entire message itself! This allows us to use the message content for our study, if needed.

For each of these datasets, we first ran an algorithm to find the threads, which in this case are the connected com-ponents. This partitioned the data into threads, forming the basis of our study. Table 1 gives a high-level view of the datasets.
We use the following conventions in our paper. We denote messages by letters  X , X , X ,... . Messages are assumed to have a thread structure, i.e., each message  X  is either a new message or is a message in response to an earlier message  X  . In the latter case, we call  X  to be the parent of  X  (denoted parent(  X  )) and  X  to be a child of  X  . A message with no children is a leaf message and a message with no parent is the root message. Thus, the root message, along with its descendants form a connected component (in particular, a rooted tree), which we call a thread . All the messages in a group can be decomposed into disjoint threads. For a given thread and a message  X  , let path(  X  ) denote the set of messages from  X  to the root of the thread.
 Each message  X  has a timestamp  X  (  X  ) associated with it. The messages in a thread are created chronologically and hence if  X  is a parent of  X  , then  X  (  X  )  X   X  (  X  ). The author  X  (  X  ) of a message  X  is the person who wrote it. A single person can author multiple messages in a thread. Let  X  be the set of all authors;  X   X   X   X  denotes that  X  is chosen uniformly at random from  X  .
In this section we state the main observations about the threads from our three datasets. The observations we make here are the basis behind the development of our generative models.

Most of the observations are illustrated for Usenet ; the other two datasets follow mostly similar qualitative patterns, although the actual parameters vary, and are omitted for space.
We study the distribution of thread sizes and depth (which is the length of the maximum path to a leaf from the root in a thread). Figure 1(a) shows the size and the depth dis-tribution in Usenet . As we note, not surprisingly, these are both heavy-tailed. Figure 1: (a) Size and depth distributions and (b) size vs depth in Usenet .

Next, we consider the relationship between size and depth: what is the average depth of a thread of a given size? Figure 3(b) plots this data. It somewhat surprising that there is a power law relationship between size and depth  X  the size is roughly quadratic in depth. This observations hints that traditional models such as preferential attachment are prov-ably insufficient to model conversation threads, since such models generate graphs with logarithmic diameter. We next study the degree distribution  X  of the threads. The degree distribution for Usenet is shown in Figure 2. From Figure 2, it is arguable that the degree distribution is close to a power law, i.e.,  X  (  X  )  X   X   X   X  for some  X  &gt; 2.
Let  X  = E[  X  ], the mean of the distribution  X  . Values of  X  and  X  for the three datasets are shown in Table 2.

Next we ask the question: is the degree distribution inde-pendent of the level of a thread? Figure 3 shows the degree distribution at each level of the thread (the root is assumed to be at level 1). It is easy to see that the distribution be-Figure 2: Degree distribution of threads in Usenet . comes  X  X teeper X  with the level since having more children becomes less likely at higher levels.
Figure 3: Per-level degree distribution in Usenet .
We study the properties of authors of messages in a thread. We first consider the size of a thread and the average number of distinct authors in the thread. We also consider the average of the most number of times an author occurs in a thread. Figure 4 shows these plots. We find that there is a polynomial relationship between the size of a thread and the number of authors participating in the thread. In fact, this relationship is very reminiscent of the Heap X  X  Law in information retrieval [15], which relates the vocabulary size to the document collection size.
The Galton X  X atson branching process is a classical model in probability theory for generating a random tree. This models many phenomena like the growth of a population (birth processes), and are important objects in random graph theory [5]. In this section we study this model as a generative model for threads, and discuss properties of the real conversations that they do or do not satisfy. This is perhaps the most basic tree generation model, and serves Figure 4: Average number of unique authors and maximum author activity vs thread size in Usenet . as a benchmark for us, similar to the role the Erd  X  os X  X   X enyi  X   X , X  model plays in graph generation.

Recall that in branching processes, each individual in gen-eration  X  produces a random number of individuals in gener-ation  X  +1 according to a probability distribution. These ran-dom numbers are drawn independently for different nodes.
Let  X  be a fixed probability distribution on non-negative integers. The messages in a thread are generated by the following process. Each thread starts with a root node and proceeds in discrete steps. At the  X  th step of the process, each leaf at the  X  th level of the thread constructed so far independently generates a certain number of children ac-cording to the distribution  X  , i.e., a leaf  X  has  X  children with probability  X  (  X  ). If  X  = 0, then  X  is a leaf. If  X  &gt; 0, then the children of  X  participate in the (  X  + 1)st step. The process terminates when there are no more new children.
Notice that the only parameter of the model is the dis-tribution  X  . We can fit the real dataset to BP-Model and compute the maximum likelihood estimate for this param-eter:  X  (  X  ) is estimated to be the fraction of nodes with  X  children in the data; it can be easily shown that this is in-deed the maximum-likelihood estimator. BP-Model can simulate the inferred distribution in order to generate the threads.
Let  X   X  be the random variable denoting the number of children at the  X  th level of the threads. Let  X  = P  X   X  the random variable denoting the size of the thread. From the definition of a branching process, the mean size of a thread is given by the recurrence In our case, from Table 2, since  X  &lt; 1 for all three datasets, the branching process dies out almost surely.

We now analyze the tails of two properties of the threads generated by the model, namely, their size and their depth. We first show that the tail of the size distribution is quanti-tatively similar to that of the degree distribution. Let  X   X   X  be a random variable distributed according to  X  .

Lemma 1. For any  X  &gt; 0 and  X  &gt; 0 ,  X  [  X   X  ] &lt;  X  if and only if  X  [  X   X   X  ] &lt;  X  .
Proof Sketch. It is easy to see that the size distribution stochastically dominates the degree distribution. Therefore, if the degree distribution does not have a finite  X  th moment, then the size distribution also does not have a finite  X  th moment.

Conversely, we show that if the degree distribution has a finite  X  th moment, then the  X  th moment of the size dis-tribution is also finite. For simplicity, we illustrate this for  X  = 2. From the basic theory of branching processes [14], the generating function for  X   X  is given by the  X  th iterate  X  of the generating function  X  of  X  . The second moment of  X  is given by  X   X  X   X  (1). We know that  X   X  1 (1) =  X   X  (1) =  X  and let  X  (1) =  X   X  X  (1) =  X  &lt;  X  by assumption. It is also easy to see that  X   X  X   X  (1) =  X   X  . By simple calculations, one can obtain the recurrence  X  from which An important corollary of the above lemma is that the dis-tribution of the size of a the tree generated using a branching process follows a heavy-tail distribution 1 if and only if the distribution of the number of children is heavy tailed.
Next, we analyze the depth of threads generated by the model. We show that the depth has an exponential vanishing tail.

Lemma 2. If  X  &lt; 0 , the probability that the tree generated by the branching process has depth at least  X  is exponentially small in  X  .

Proof. The expected number of children in the  X  th gen-eration is given by E[  X   X  ] =  X   X  . For a tree to have depth at least  X  , this number must be at least 1. By the Markov inequality, the probability of this event is at most Pr[  X  1]  X  E[  X   X  ] =  X   X  .
 From this, we see that the distribution of depths of threads generated by BP-Model does not in particular have a heavy tail.
The main advantage of BP-Model is its conceptual sim-plicity. Furthermore, it is also easy to estimate the param-eters of the model, and as we observed, the parameter (i.e., the degree distribution) can be succinctly approximated by a power law. By Lemma 1, it also leads to a heavy-tailed size distribution, provided the degree distribution is heavy-tailed (see Figure 1). As we will see in Section 7, BP-Model is sufficient to elicit different types of conversations.
The main drawbacks of BP-Model are the following. (1) The model is not generative, i.e., the degree distribu-tion is stipulated and the messages are created according to this distribution. In this sense, this model is similar to the configuration model [28] in random graph theory, where a random graph with a specified degree sequence is generated. The model does not try to abstract the social processes be-hind the creation of messages and the growth of threads.
By a heavy-tail distribution we mean a distribution that dominates a power law distribution for some exponent. (2) This model cannot capture the depth distributions of threads that are observed in reality (Figure 1(a)). From Lemma 2, we know that the depth cannot be heavy-tailed; this is seen in the in Figure 5. BP-Model also cannot cap-Figure 5: Size and depth distribution of threads us-ing BP-Model (with  X  estimated from Usenet ). ture the quadratic relationship between size and depth in Figure 1(b).

Moreover, the size distribution generated by the model has a tail that is quantitatively similar to that of the degree distribution. However, in reality, the size distribution has a flatter tail than the degree distribution (for sake of brevity, we do not show these figures). (3) In the branching process model, the number of chil-dren at each node is determined by a single distribution. However, this is not realistic as seen in Figure 3. A vanilla branching process model cannot capture this phenomenon. (4) The branching process model does not capture the or-der in which the messages are created, i.e., the timestamps associated with the messages are left out. Furthermore, the model does not capture the author of messages. These are two critical parameters that distill the essence of conversa-tions in social settings.
In this section, we propose new models for the growth of threads of conversation.

First, we consider a model that incorporates recency. The idea behind this model (called T-Model ) is based on the fol-lowing observation: as in the preferential attachment model, messages that have already received many replies are more likely to receive a new reply. But in addition to this, new messages receive more attention than the old ones. This effect might not be very pronounced in the growth of net-works such as the web where the nodes (webpages) have a relatively long  X  X ifespan X . On discussion forums and Twitter, however, messages quickly become outdated, and therefore (as we will demonstrate later in the paper using data and simulation) there is a clearly observable tendency that a new message added to a thread is in response to a relatively re-cent message. Our model captures this fact by assigning a higher probability of being the next message that receives a reply not only to high-degree messages, but also to the recent messages.

As noted in Section 2, a similar high-level idea was ex-plored in the context of tracking news phrases [20].
We now give a formal definition of T-Model . We assume the thread grows in discrete time steps. Each time, either a decision is made to stop the thread (i.e., no more message will be added to it), or to add a message in reply to one of the current messages in the thread denoted by  X  (i.e., the new node will be added as a child of  X  ). The probability of the latter decision depends on two parameters of the node  X  . One parameter is the current degree of  X  ; we denote this by deg  X  . The other parameter, called the recency of  X  and denoted by  X   X  , is the number of time steps since  X  was added to the thread.

In general, we take the probability of the decision to add a child to  X  to be proportional to some function  X  (deg  X  of the degree and recency of  X  , and the probability of death to be proportional to a constant  X  . That is, the probability of termination is  X  P the denominator is over all nodes  X  currently in the thread.
For the rest of this paper, we focus on a particular form of the function  X  : when  X  is a linear combination of deg and and an exponentially decreasing function in  X   X  . That is,  X  (deg  X  , X   X  ) =  X  deg  X  +  X   X   X  for constants  X   X  0 and  X   X  (0 , 1). We choose this form of function because of the following: (1) An exponential  X  X iscounting X  function like  X   X   X  is the standard way to model dependence on time. (2) A linear combination is perhaps the simplest and most natural way to combine the recency and the degree 2 . (3) Considering a linear combination (as opposed to, e.g., the square root of the degree plus the exponential discount) allows us to compute the denominator of the probability ex-pressions independent of the current degrees, and this makes this model particularly amenable to mathematical analysis, as we see in this Section. 3
Note that both the degree and recency components play a role in generating different types of threads. If the former plays a prominent role, then we get  X  X ushy X  threads  X  where many messages are in response to a single earlier message. If the latter plays a prominent role, then we get  X  X kinny X  threads  X  where the thread is essentially a path and mes-sages appear in succession as a cascade of responses.
In this section we show that the degree distribution of graphs generated from T-Model has a heavy tail.

Theorem 3. Let  X  be a thread with  X  nodes generated from the model in the above section with  X  (deg  X  , X   X  ) =  X  that have at least  X  children is at least  X (  X   X  1 ) .
Proof Sketch. With  X  (deg  X  , X   X  ) =  X  deg  X  +  X   X   X  , at the time that the thread has  X  nodes, we have
Another natural alternative that we considered is the prod-uct of the degree with the exponential discounting term, i.e.,  X  (deg  X  , X   X  ) =  X   X   X  deg  X  . While this formulation might makes sense intuitively, it does not generate graphs similar to what we see in practice. In particular, the exponential discount-ing factor does not let the degrees of the nodes to grow to a heavy-tailed distribution.
We have also done simulations with a few other reasonable choices of  X  , and did not observe fundamentally different results.

X Now, we consider the  X  th node added to the thread, and study the growth of the degree of this node at time  X  , as  X  grows. We denote the degree of this node at time  X  by  X   X  Note that  X   X  (  X  ) is a random variable, and  X   X  (  X  + 1)  X   X  either one (if the (  X  + 1) X  X t node connects to  X  ) or zero (if it doesn X  X ). The probability that  X   X  (  X  + 1)  X   X   X  (  X  ) = 1 is P  X   X  (deg  X  , X   X  ) +  X  Therefore, we have and We couple the sequence of random variables  X   X  (  X  + 1) , X  2) ,... with another sequence which instead of the inequal-ities (1) and (2), satisfies the corresponding equalities. We call these random variables  X   X   X  (  X  ). By coupling,  X   X  tically dominates  X   X   X  (  X  ). Therefore, it is enough to prove the desired lower bounds on  X   X   X  (  X  ) instead of  X   X  (  X  ). To do this, we first calculate the expected value of  X   X   X  (  X  ), which we denote by  X  X  X   X  (  X  ). This can be calculated from the recurrence rela-tions given by (1) and (2). The solution of these recurrences is The above equation can be proved easily by induction on  X  using recurrences given by (1) and (2). This means that for every  X  , the expected degree of the  X  th node of the thread grows at least linearly with time. Furthermore, the sequence of random variables  X   X   X  (  X  ) defines a martingale, and therefore by standard martingale concentration inequalities [29], if  X   X   X  is large enough, the value of  X   X   X  (  X  ) is concentrated around its expectation. Putting these together, we obtain that for  X  =  X  large enough and  X  &lt;  X   X   X  (1), with a large probability, we have This means that the number of nodes that have degree at least  X  is bounded from below by the number of  X   X  X  satisfying  X  X  X  +  X / (1  X   X  ) &lt; 0 . 5  X  X  X / X  , which is  X (  X / X  ). Thus, the frac-tion of nodes having degree at least  X  is at least  X (  X   X  1
Upon understanding the process from which the thread structures are generated, we may also want to understand who is responsible for generating the reply message.
In this section we propose a model (called TI-Model ) for author identity. The motivation for TI-Model comes from the observation that authors tend to respond to responses to their own earlier messages. Thus, when a new message  X  arrives as a child of message  X  in a thread  X  , the author  X  (  X  ) is likely to be chosen from the set {  X  (  X  ) } for some  X  along the path from  X  to root(  X  ). (There is a slight caveat that  X  is unlikely to be  X  since  X  (  X  ) is most likely not the same as  X  (  X  ).)
The above observations, combined with the empirical ev-idence of Heap X  X  law (Figure 4), suggests a modified Polya urn process in order to reproduce author identity patterns. When a new message  X  arrives with  X  = parent(  X  ), then  X  (  X  ) is chosen according to the following process. Let  X  (  X  ) = path(parent(  X  )). Note that this model can also be viewed as a variant of the copying model [18]: with probability  X  &gt; 0, we copy one of the authors from path(parent(  X  )); with probability  X   X  min(  X , 1  X   X  ), we copy  X  itself; and with the remaining probability, we choose a random author from  X  . By this pro-cess, the probability that an author is chosen is proportional to the number of times he/she already authored a message in the path to the root.

From data, it is easy to statistically learn the parameters  X  and  X  of TI-Model . It is possible to show that the above modified Polya urn process generates a heavy tail for the number of occurrences of an author on a path (proof omit-ted). However, it seems much harder to analyze the number of occurrences in a tree, since different paths share nodes.
In this section we estimate the parameters of TI-Model from the data and simulate the model to see if the statistics match the empirical findings. The parameters are estimated through a simple grid search and maximum likelihood com-putation. Table 3 shows the parameters of T-Model esti-mated from the data.

We consider the size vs depth relationship and the degree distribution conditioned at each level, to see if these resem-ble the empirical observations. Figure 6 shows these plots for Usenet , simulated using the parameters from Table 3. These show that T-Model is able to reasonably capture the empirical observations. Figure 6: (a) Size vs depth (b) Per-level degree dis-tribution for T-Model simulation of Usenet .

Finally, we consider the number of unique authors as a function of thread size, by using TI-Model . Figure 7 shows the plot. We can see that this is reasonably consistent with the observation we made in Figure 4. Figure 7: Unique authors vs thread size in TI-Model . Communities such as Twitter, Yahoo! Groups, and Usenet are quite diverse, and as a result, sometimes we observe threads with very different characteristics on these communities. In particular, one can observe that on twit-ter, threads of conversation are primarily of two different types: conversations that are mainly between two individu-als, and conversations that are among a group of individuals. For the former type of conversation, the thread is  X  X kinny X , growing more or less as a path (sometimes with few addi-tional leaves), whereas for the second type, the thread is often  X  X ushy. X  To more accurately model the threads in such settings where there is heterogeneity in the types of threads, we consider models that are mixtures of the mod-els proposed in previous sections. In particular, a simple model is to consider mixtures of BP-Model , with differ-ent parameters: each thread is of one of the types 1 ,..., X  , where the probability of each type is given. Given the type  X  , the thread is generated according to a branching process with probability distribution  X  (  X  ) for the number of children of each node.

A useful application of a mixture model is that by fitting the data to such a model (i.e., estimating the maximum likelihood parameters of the model) we obtain a classifica-tion of the threads in the dataset. For example, we have applied the method on Twitter with  X  = 2, and the result-ing clustering of the thread matches the intuitive clustering between the long threads of pairwise conversations and the wider group conversation threads. Figure 8 shows the values of the parameters BP-Model (i.e., the degree distribution) for Twitter for  X  = 2. Clearly,  X  (1) corresponds to the bushy threads and  X  (2) corresponds to the skinny threads.
To fit the data to a mixture model, we use an adapta-tion of the well-known expectation-maximization (EM) algo-rithm. The EM algorithm starts with a random partition-ing of the threads into  X  classes. In each iteration, for each class, the algorithm estimates the maximum likelihood set of parameters (in the case of branching processes, this is simply counting the number of nodes with a certain num-ber of children). Then, fixing these sets of parameters, the Figure 8: Values of  X  (1) , X  (2) for Twitter and BP-Model . algorithm reclassifies each thread to the model that is most likely to have generated it. This algorithm continues until it converges, or a certain maximum number of iterations is reached.

We state a few observations about the EM algorithm ap-plied to our datasets (in particular the twitter dataset, which appears to be the most heterogeneous among the three): first, the algorithm converges quite fast. The median num-ber of rounds it takes for the algorithm to converge is 11. This is significant given the size of the dataset.

In fact, it is not hard to prove that the EM algorithm as described above always converges in a finite number of rounds. This is based on the fact that the likelihood of the current calculated solution in this algorithm always in-creases. However, the convergence is to a local maximum of the likelihood function, and not necessarily a global maxi-mum. In our experiments, the difference between the log-likelihoods of the solution in 10 different runs of the al-gorithm is less than 0.01%. Furthermore, the parameters calculated for the classification in different runs are almost equal.
We next examine some of the groups in particular for those with the highest values for  X  (high degree of preferential attachment),  X  (high recency effect), and low/high values of  X  (high/low copying effect). Preferential behavior. The Usenet groups with the highest degree of preferential attachment are shown below. Nearly all of the top ones were politically-related. There were a few additional high-activity non-political groups with somewhat higher values (e.g. rec.games.pinball had a value of 0.7), but this is significantly less than those shown.
This would lead us to believe that political groups tend to have  X  X ushier X  threads, and less  X  X ack and forth X  paths between a few people.
 Recency. On the other hand, there are some groups that had a higher recency effect  X  some of the lower traffic poli-tics groups (those with fewer users overall) tended to follow this pattern. The top groups are shown below.
 Identity  X  X opying X . Finally, we examined which groups had the highest and lowest rates of identity copying; that is, which groups showed the highest incidence of choosing au-thors from upwards in the thread (as opposed to more uni-formly distributed). High values of  X  indicate a low copying rate  X  new authors tended to join in often. Low values of  X  indicate a low copying rate. Here are some of the higher and lower  X  values among Usenet  X  there were 13 total groups with the highest  X  ; we show a selection.

Interestingly, nearly all of the rec.music groups followed a pattern of low copying, with more uniform behavior. The highest copying groups were IT-help related groups, which is not surprising given the back-and-forth question/answer format that such groups foster. 8.2 Y!Groups
We repeated the experiments of determining  X  and  X  for the Y!Groups data. While the characterization of the groups was less obvious, we show a few groups with unusu-ally high values of each parameter (  X  = 10 and  X  = 0 . 99.) 8.3 Twitter
Finally, we repeated the experiments for Twitter . To find out the topic of a thread, we chose the most popular hashtag ( #tag ) among the messages in a thread and assume it to denote the topic of the thread.

The topics with the highest  X  and the topics with the highest  X  are shown next. The first set corresponds to topics with  X  X ushy X  threads and the second set corresponds to topics with a stronger sense of time (sports, movies, etc.) and hence the threads tend to be  X  X kinny. X 
In this paper we studied the problem of how online con-versations build. We proposed simple mathematical models that can capture the patterns in human exchanges. Our models encapsulate both time of the message and identity of the author of the message. Using three different publicly available datasets, we study the structure of conversations and explore the model for these datasets.

There are several potential future applications of this work. We identify two such applications (1) Our method can be used to identify group conversa-tions in systems like e-mail, and offering tools to facilitate such conversations. (2) Our method can be used to identifying friendship re-lationships between users: declaring someone a friend or following someone on social applications like Facebook or Twitter is not a good indication of an actual friendship re-lationship between the individuals. So, to identify who X  X  friends with whom, we need to look at the interaction be-tween individuals. Our classification identifies one-on-one interactions, which are more informative than interactions in the context of a group.
