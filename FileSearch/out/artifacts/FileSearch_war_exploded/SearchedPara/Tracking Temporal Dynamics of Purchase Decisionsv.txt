 Improvements in information technology have made it eas-ier for industry to communicate with their customers, raising hopes for a scheme that can estimate when customers will want to make purchases. Although a number of models have been developed to estimate the time-varying purchase prob-ability, they are based on very restrictive assumptions such as preceding purchase-event dependence and discrete-time effect of covariates. Our preliminary analysis of real-world data finds that these assumptions are invalid: self-exciting behavior, as well as marketing stimulus and preceding pur-chase dependence, should be examined as possible factors influencing purchase probability. In this paper, by employ-ing the novel idea of hierarchical time rescaling, we propose a tractable but highly flexible model that can meld various types of intrinsic history dependency and marketing stimuli in a continuous-time setting. By employing the proposed model, which incorporates the three factors, we analyze ac-tual data, and show that our model has the ability to pre-cisely track the temporal dynamics of purchase probability at the level of individuals. It enables us to take effective marketing actions such as advertising and recommendations on timely and individual bases, leading to the construction of a profitable relationship with each customer.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Self-exciting Process; Time-rescaling Theorem; E-commerce; Panel Data; Purchase Behavior; Point Process
With the explosive growth of e-commerce systems, indus-trial practitioners now have the potential to communicate with their customers wherever and whenever they want. This situation puts strong pressure on the practitioners to find the right time to communicate with each of their cus-tomers, that is, the time when she is most likely to make a purchase [23, 24, 26]. The purpose of this paper is to pro-pose a feasible method for tracking the fluctuation in the underlying purchase probability of a customer, based on her transaction data.

The negative binomial distribution (NBD) model [8], which has been applied extensively in marketing studies, is a stan-dard model for estimating the purchase probability of a cus-tomer. The model, however, assumes that the purchase probability is stationary over time, and is independent of all non-stationary marketing variables and the customer X  X  purchase history. Thus the NBD model says nothing about when to communicate with a customer. Some extensions of the NBD model have been proposed, although to maintain model tractability, they are based on unrealistic assump-tions such as the purchase behavior only depends on the last purchase decision, and that the effect of marketing vari-ables is piecewise constant over time [6, 16, 10, 1, 12, 14, 22, 21]. Our analysis finds that these assumptions are vi-olated in actual data. To achieve a more realistic model, we have to overcome the trade-off between model flexibility and tractability, which is not possible with the conventional approach.

In this paper, by employing the novel idea of hierarchi-cal time rescaling, we achieve a tractable but highly flexible model for estimating customers X  purchase probability over time. Due to its flexibility, the model is able to incorporate the effects of time-varying marketing variables and various types of history dependency in a continuous-time setting. Because of its tractability, the model offers the real-time tracking of each customer X  X  purchase probability, as well as the efficient optimization of model parameters. We call the proposed model, the Hierarchical Time-Rescaling model (HTRm).

We assess the potential of HTRm for capturing customers X  purchase behaviors by applying it to real-world data consist-ing of three categories of transaction data. HTRm is intro-duced in general form, and we propose a specific form that is suitable for analyzing transaction data. It incorporates three possible rate fluctuation factors: seasonal sales, self-excitation, and the preceding purchase-events. We compare the predictive performance of the proposed model against the results achieved by the NBD model and other models with fewer factors, and show that HTRm X  X  inclusion of vari-ous factors is essential for precisely estimating customer pur-chase dynamics. Figure 1: A schema for the estimation and predic-t ion procedure via point process. Solid bars repre-sent observed purchase decisions, and dashed bars represent a most likely purchase sequence in the fu-ture.

The rest of the paper is organized as follows. In Sec-tion 2, we describe the problem of estimating a customer X  X  purchase behavior via a point process, and outlines related work. In Section 3, we construct HTRm in a form specif-ically designed to analyze purchase data. In Section 4, we develop a feasible algorithm, based on the Monte Carlo EM algorithm, for estimating the model parameters. Section 5 applies HTRm to real-world data, and shows that the model has the ability to precisely estimate the underlying dynamics of customer purchase dynamics. Finally, Section 6 provides our conclusions. We first introduce a basic method for analyzing purchase events occurring in time. The theory of point process [20], which has been introduced in not only marketing science [8] but also such diverse disciplines as neuroscience [5] and seismology [17], provides a powerful tool for modeling and analyzing the stochastic structure of point events occurring in continuous time. In the point process framework, the pur-chase behavior of a customer is characterized by the purchase rate , that is, the instantaneous probability for a customer to make a purchase decision at each point in time [8, 10, 19]. Suppose that customer u (1  X  u  X  U ) makes a sequence of purchase decisions, { t u j } n j =0  X  ( t u 0 ,t u 1 ,  X  X  X  ,t open observation period ( t u 0 ,T ]. We can estimate u  X  X  pur-chase rate,  X  u ( t ), by evaluating the probability density of the observation occurring, given by = h = h where the exponential on the right-hand side of Equation (1), called the survivor function [20], represents the proba-bility of no purchase events occurring in the open intervals ( t ,t u j +1 ) for 0  X  j  X  n  X  1 and the half-open interval ( t If the purchase rate is estimated as  X   X  u ( t ) based on Equation (1), we can predict future purchase times, { t u j } j&gt;n tion, see Figure 1. The notation is summarized in Table 1. Note that we take the initial purchase point t u 0 a s the start of the observation, because industrial practitioners usually start monitoring customer X  X  transactions from the first oc-currence. In that case, the initial purchase t u 0 is not regarded as being generated from  X  u ( t ), and thus the probability den-sity (1) does not have factor  X  u ( t u 0 ).

The difficulty in performing the estimation and predic-tion procedures comes from the costly integral, R  X  u ( t ) dt , in the survivor function. Therefore, to make the point process model tractable, a simple purchase rate  X  u ( t ) should be de-signed so that the survivor function is obtained analytically. To pursue the dynamical purchase behaviors of customers, which may modulate intricately depending on the history of purchase decisions and/or time-varying marketing variables, we need to make  X  u ( t ) as flexible as possible. To address the trade-off between model tractability and its flexibility, several purchase rate models have been proposed, as briefly outlined in the following. For simplicity, we omit the user index of u when discussing a model on an individual basis. The most standard model for analyzing customers X  purchase behavior is the NBD model [8]. In it, purchase rate  X  ( t ) is assumed to be stationary over time,  X  ( t ) =  X  , leading to the analytical survivor function, exp  X   X  ( T  X  t 0 ) . This model is based on a time-homogeneous Poisson process [20], and thus its inter-event intervals, t j  X  t j  X  1 , should obey an exponential distribution, and there should be no correlation between successive inter-event intervals.

Inclusion of History Dependency: To relax the lim-itations, the NBD model was extended by the renewal point process, which allows the purchase rate to be dependent on the last purchase decision [10, 6, 16, 1, 22]. Thus the purchase rate  X  ( t ) can be expressed by using a cumula-tive distribution of the inter-event intervals, F ( t j  X  t as  X  ( t ) =  X  d dt l og 1  X  F ( t  X  t j ) , for t j &lt; t &lt; t ing to the analytical survivor function, 1  X  F ( T  X  t n ) Q j =1 1  X  F ( t j  X  t j  X  1 ) . The inter-event intervals, t may obey a non-exponential distribution, dF ( t j  X  t j  X  1 but there should be no correlation between successive inter-event intervals.

Inclusion of Covariate: It was also proposed to in-corporate time-varying covariates such as seasonality and price promotion into the renewal model, in which the sur-vivor function can be obtained analytically, as long as the piecewise constancy of covariates is assumed [10, 1, 12, 21].
These NBD-based models marginally improve the explana-tory power of the original NBD model, although they are inadequate for reproducing real purchase behavior. The as-sumption of piecewise constancy in covariates is violated when their modulation frequency is higher than the purchase rate, and the history dependency of purchase behavior is not necessarily very simple, both of which are found to be the c ase in the transaction data we analyzed (see Section 5). In preparation for our model construction, we here provide a description of the time-rescaling theorem. The theorem has been applied in such fields as neuroscience [5] and seismol-ogy [17], mainly for evaluating the goodness-of-fit of point process models to data. In this paper, we utilize the idea of time-rescaling for constructing our flexible and tractable model (Section 3). The time-rescaling theorem states that any point process may be transformed into a Poisson pro-cess with a unit rate, which can be easily demonstrated as follows. With rescaled time  X ( t ), defined by the probability density (1) at real time t is transformed into that at rescaled time  X ( t ) as, which is identical to the probability density that the cus-tomer makes a sequence of purchase decisions, {  X  j } n j =0 the period [0 ,  X ( T )], at the unit purchase rate. With this theorem, we can assess goodness-of-fit of the model by eval-uating how well the statistics of the rescaled time sequence {  X  j } n j =0 agree with those of a Poisson process with a unit rate.

The time-rescaling theorem implies that the difficulty of calculating a survivor function is equivalent to that of per-forming a time-rescaling procedure (2), which is a key point of our model construction.
In this section, we construct a striking model that over-comes the limitations of the conventional NBD-based mod-els, namely, the renewal property and the piecewise con-stancy, at the same time. We achieve complicated time rescaling by performing simple time-rescaling operations hi-erarchically. In each operation, time is rescaled by each of the factors that induce the purchase rate to fluctuate, such as marketing stimulus and intrinsic history dependency one by one, and finally the incorporation of various rate fluctu-ation factors is achieved. To the best of our knowledge, this is the first proposal of the concept and the first formaliza-tion of hierarchical time rescaling for capturing customers X  purchase behavior.
To allow time-rescaling (2) to be performed analytically, we construct the purchase rate  X  ( t ) in the following two steps: (i) First, instead of converting t into  X ( t ) at one time, we convert t in the following hierarchical manner, for 0  X  m  X  M  X  1, where  X  m  X  m ( t ) is a factor that rescales the m th rescaled time  X  m ( t ), and M denotes the highest level of the hierarchy. Here, we assume that each factor  X  m  X  m can be integrated analytically. (ii) Next, we construct purchase rate  X  ( t ) as a unit in the M th rescaled time,  X  M ( t ), leading to the factorized rate, For calculation details, see Appendix A.

Figure 2 illustrates how proposed model performs time-rescaling hierarchically (5). In each time-rescaling step, a new time  X  m +1 is defined by rescaling the current time  X  with the time-inhomogeneous factor  X  m ( X  m ), according to which the strongly fluctuating rate (the blue curve at the top) drops its fluctuation factors,  X  m , one by one in de-scending order, before eventually being converted into a unit (the blue curve at the bottom). The scales of the rescaled times, represented by the lower black bars, show that the time with a higher rate is elongated, and vice versa (dashed line), thus compensating for the fluctuation of the rate. It is worth noting that the sequence of purchase decisions gen-erated from  X  ( t ) (red bars) seems to be uncorrelated or be aligned in a Poisson manner in rescaled time  X  M ( t ). We call the proposed model the Hierarchical Time-Rescaling model (HTRm).

The key advantage of HTRm is that under the weak as-sumption that each factor  X  m  X  m has an analytical inte-gral, we can compute the rescaled time  X  M ( t ), and thus obtain the probability density (1) analytically. We place no further restriction on the functional form of the indi-vidual factors  X  m ( X  m ). Thus, by incorporating of multiple rate fluctuation factors, HTRm is able to reproduce a rich variety of purchase behaviors, while maintaining excellent tractability.
In Section 5, our analysis of real-world transaction data produced a finding that contradicted the time-homogeneous Poisson assumption (see Table 3): one is the non-exponential distribution of inter-event intervals (IEIs), the other is the positive correlation between successive IEIs. Both could be explained by self-excitation and/or renewal behavior of a customer, although a time-varying marketing stimulus might cause the purchase rate to fluctuate, leading the customer to behave in a non-Poisson manner.

Thus, we provide HTRm with three possible rate fluc-tuation factors, namely, sale, self-excitation, and preceding purchase dependency: The sale factor is modeled by the se-quence of alpha-functions, in which each of the sale events triggers a rapid excitation of the purchase rate followed by a slow decay; The self-excitation factor is expressed by the Hawkes process with exponential decay [3, 11, 15], where a purchase event gives an additional rise in the purchase rate, which provokes further purchase events; The factor of the preceding purchase dependency can be modeled by us-ing the Weibull hazard function [1]. Denoting the factors as  X  sale ,  X  excite , and  X  pre , respectively, we propose the following purchase model for a customer: where the corresponding rescaled times are denoted by respectively.
 counting process of the purchase events and the winter (sum-mer) sale events, respectively: the sample paths of the count-ing processes jump 1 immediately following the associated event points, and are constant otherwise [20]. Thus first we model the sale factor  X  sale ( t ) by using alpha functions as where r 0 represents the base rate, and t w ( s ) i , a w ( s ) represent the start point, the impact, and the timescale of the i th winter (summer) sale, respectively. Second, by em-ploying the Hawkes process with exponential decay [3, 11, 15], we model the self-exciting factor  X  excite ( t ) as where a h and b  X  1 h are the impact and the timescale of a purchase event, respectively. Finally, we model the factor of the preceding purchase dependency,  X  pre ( t ), by using the Weibull hazard function, where f  X  ( x )  X   X x  X   X  1 exp  X  x  X  and F  X  ( x )  X  1  X  exp  X  x are the Weibull distribution and its cumulative distribution with shape parameter  X  , respectively. Substituting Equa-tions (9-11) into Equation (8), we obtain the corresponding rescaled times in the following analytical forms:
 X ( t ) = r 0 ( t  X  t 0 )  X ( t ) =  X ( t ) +  X ( t ) = where x  X  y = max { x,y } .

Let a set of individual parameters be denoted as  X   X  ( a s ,a w ,b s ,b w ,r 0 ,a h ,b h , X  ). Then, for the proposed model (6-12), we can evaluate the logarithm of the probability den-sity of the data (7) efficiently by using  X  sale ( t j ),  X ( t  X ( T ) as follows: where the first term is calculated from Equation (9), the second term is calculated as the third term is calculated as
X = ( n  X  1) log  X  + (  X   X  1)  X  X  X  j =  X ( t j +1 )  X   X ( t j ) + a h and the remaining terms (the logarithms of the left-and right-censored survivor functions) are given by where
 X ( T )  X   X ( t n ) =  X ( T )  X   X ( t n )
The proposed model (6-12) has the ability to mimic a variety of history-dependent purchase behaviors depending on the set of three parameters, ( a h ,b h , X  ), which is summa-rized in Figure 3A-E. In practice, the effect of sales, which is shown in Figure 3F, is multiplied into each of the behav-iors. In Appendix B, we provide an efficient procedure for generating sample purchase points from the proposed model.
We developed a purchase model (6-12) on an individual basis, in which the eight parameters, a s , a w , b s , b b , and  X  , differ among customers. Letting the set of indi-vidual parameters for customer u (1  X  u  X  U ) be denoted by we assume that each of the parameters is generated from a gamma prior distribution: p (  X  u l |  X   X  l , X   X  l ) = 1  X (  X  where  X   X  l and  X   X  l are the scale and shape parameter of the gamma distribution, respectively. The scale parameter  X   X  represents the mean of  X  l a cross all customers, and the shape parameter  X   X  l , which determines the coefficient of variation of the distribution as  X   X  1 / 2  X  in  X  l across all customers. Then, the prior distribution of  X  is expressed as p (  X  u |  X , X  ) = Q 8 l =1 p (  X  u l |  X   X  The notation is summarized in Table 2. The NBD model [8] is a special case of the proposed model (6-12,19-20) for  X  Based on the empirical Bayes method, the sets of aggregate parameters,  X  and  X  , can be determined by maximizing the marginal likelihood, where { t u j } and D denote customer u  X  X  purchase data and all of the customers X  data, respectively. Given a set of data D , the maximization is performed based on the Monte Carlo expectation maximization algorithm [25]: aggregate param-eters are determined by iteratively maximizing the expected value of the complete-data log-likelihood, the Q function, where  X  ( p ) and  X  ( p ) are the aggregate parameters of the p th tion with respect to the posterior distribution of  X  u under the p th estimate of the aggregate parameters, To perform the expectation, we employ the following Monte Carlo sum, where g (  X  u ) is a function of  X  u , N MC is the Monte Carlo sample size, and  X  u i is the i th sample of  X  u generated from its posterior distribution. The sampling is performed by a variant of the Markov Chain Monte Carlo (MCMC) method, or the Metropolis X  X astings algorithm [2], in which we chose a lognormal proposal distribution for  X  u . The ( p +1)th es-timate of (  X , X  ) is then determined by the conditions for dQ/d X  = dQ/d X  = 0, leading to the following update rule: where  X  (  X  ) is the digamma function. Because log(  X  )  X   X  (  X  ) is a monotonically decreasing function, we can obtain the root of Equation (27) with the bisection method [18]. Given the aggregate parameters to be determined as ( X   X ,  X   X  ), we can obtain the posterior mean estimate of the individual parameters  X  u as The expectation is performed by the Monte Carlo sum (25). The scalability for the estimation algorithm is discussed in Appendix C.
We examine the potential efficiency of the HTR model to capture customers X  purchase behaviors by applying it to e-commerce and panel data sets.
The e-commerce data set contains transactions about fash-ion items conducted over 230 weeks (October 1, 2009  X 
Data set F ashion Fashion L Milk Coffee # of customers 7,129 563 3,131 2,240 # of trans. 83,129 20,928 131,961 111,235 period [week] 230 230 50 50 mean IEI [week] 11.3 4.5 1.0 0.8 cv of IEI 1.37 1.39 1.50 2.26 correlation **0.25 **0.23 **0.40 **0.25 F ebruary 27, 2014) as performed at a commercial website, where the first 200 weeks of data are used for model fitting, and the remaining 30 weeks serve to evaluate the model X  X  predictive performance. We denote the data set by Fashion . We also consider its subset consisting of the loyal customers, those who made at least 20 transactions during first 200 weeks. We denote the subset by Fashion L . The timestamp of the winter and summer sales is given as: t s 1 = 37, t 88, t s 3 = 141, t s 3 = 193, t w 1 = 62, t w 2 = 114, t w 218 [week].

The panel data consists of two categories of transaction data sets, namely, milk and coffee drink 1 . We denote the data sets by Milk and Coffee , respectively. The both con-tain transactions gathered over 50 weeks (January 1, 2013  X  December 17, 2013), where the first 45 weeks of data are used for model fitting, and the remaining 5 weeks for model evaluation. We have no information about sales. For all four date sets, we omit customers who made less than 5 transac-tions during the fitting period. The purchase time point is measured in hours. The data statistics are summarized in Table 3.

As mentioned in Section 3.2, Table 3 shows that the Pois-son behavior, assumed in the NBD model, is violated in all data sets: (i) the coefficient of variation for IEIs largely devi-ates from unity, indicating a non-exponential distribution of tween successive IEIs. The non-exponential distribution and the positive correlation indicate that the customers makes purchase decisions depending on the last or more previous decisions, but the seasonal sale could also cause the cus-tomers X  non-Poissonian behaviors. Using our HTRm, we elu-cidate the details of the history dependency and the degree I ndividual consumer panel research data (SCI) collected by INTAGE Inc. (Tokyo, Japan) of contribution of the seasonal sale on such non-Poissonian b ehaviors.
Based on the e-commerce data, we compare HTRm X  X  pre-dictive performance against the results achieved by the NBD model (NBD : a s = a h = 0,  X  = 1), HTRm with only the sale effect (HTR sale : a h = 0,  X  = 1), and HTRm with only the history dependency (HTR history : a w = a s = 0). We denote the HTRm with both the sale effect and the history depen-dency by HTR. Based on the panel data, on the other hand, we compare the predictive performance of HTRm against that of the NBD model. Because we have no information about sales for the panel data, we denote HTRm developed from only the history dependency by HTR.

In accordance with the procedure described in Section 4, we estimated the aggregate and individual parameters of each model based on the training data. The estimated ag-gregate parameters are summarized in Table 4. Using the es-timated individual parameters  X   X  u , we evaluated the predic-tive performance of each model based on the log-likelihood for the test data, where D test represents the purchase timestamps in the test data. Figure 4 shows that HTR performed better than the other models for all four data sets. The comparison between Figure 4A and Figure 4B found that the effect of the sea-sonal sales is smaller in Fashion L than in Fashion , which is consistent with the fact that loyal customers are less respon-sive to the price promotion. The results indicate that the inclusion of various factors is essential for precisely estimat-ing customers X  purchase dynamics.

Using the time-rescaling theorem as a basis, we also eval-uated the predictive performance by checking whether or not the purchase points rescaled by the estimated individ-ual parameters,  X ( t j ), follow a Poisson process. Here, we checked the following two points: (i) whether the rescaled IEIs,  X  X  j  X   X ( t j +1 )  X   X ( t j ), follow an exponential distri-bution with mean of 1; (ii) whether the successive rescaled IEIs,  X  X  j and  X  X  j +1 , have no correlation between them. Figure 5 shows the semi-log plot of the empirical distribu-tion of rescaled intervals  X  X  j (upper figures) and the scat-ter diagram in the (log( X  X  j ), log( X  X  j +1 )) plane (lower fig-ures). The significant correlation between successive inter-vals, found in the NBD model, was removed in HTRm per-fectly for the Fashion and Fashion L data sets (Figure 5A and B), and partially for the Milk and Coffee data sets (Figure 5C and D). The distribution of the rescaled intervals deviates greatly from the exponential with mean of 1 (dashed line) in the NBD model (Figure 5A-D), which is substantially im-proved in HTRm for all of the data sets except the Fashion data set. In the Fashion data set (Figure 5A), over half of the customers (63 %) have less than 10 transactions, thus it is harder to estimate individual parameters accurately com-pared to in the other data sets. It should be emphasized that HTRm achieved higher predictive performance than the sim-pler NBD model (Figure 4A) even for this very sparse data set.

It is worth noting that the winter or summer sale X  X  effect
Fashion N BD HTR  X  r 0 0 .071 0.051  X  r 0 3.148 16.25  X  a h 0 0.073  X  a h  X  0.535  X  b h -1.338  X  b h -2.340  X   X  1 0.844  X   X   X  22.36  X  a w 0 0.354  X  a w  X  1.640  X  a s 0 0.899  X  a s  X  1.755  X  b w -0.340  X  b w -2.196  X  b s -0.552  X  b s -4.716
Milk N BD HTR  X  r 0 0 .932 0.588  X  r 0 1.930 2.364  X  a h 0 0.265  X  a h  X  3.054  X  b h -0.980  X  b h -18.59  X   X  1 1.673  X   X   X  6.894 mean IEI, see Table 3-4), and thus the piecewise constancy o f covariates, assumed in the previous studies [12, 21], is not valid for the data we analyzed. The estimated individual parameters are summarized in Figure 6. Figure 6A shows that the history dependency of purchase decisions is widely distributed among item cate-gories. The purchase rate in Fashion rises briefly after a purchase decision is made ((d) in Figure 6B), while due to its self-exciting dynamics, the rate in Fashion L sometimes keeps its value high for several months ((c) in Figure 6B). The difference in the purchase dynamics might imply that because the prices of fashion items are relatively high, the psychological impact of a spending decision would be sub-stantial for usual customers, and thus cancel out the intrin-sic self-exciting effect seen in loyal customers. On the other hand, the purchase rate in Milk drops to zero immediately after a purchase decision occurred and the value remains low for a while, resulting in the periodic purchase pattern ((b) in Figure 6B). The purchase rate in Coffee also has a brief  X  X efractory period X  after each purchase decision, which prevents quick successive purchases. Sometimes, however, it shows transient activation due to its strong self-exciting effect ((a) in Figure 6B).

Figure 6A also shows that the temporal dynamics of pur-chase decisions differ largely across customers even in the same item category. Especially in the milk category, the pe-riodicity of purchase behavior is estimated to have strong heterogeneity. This might be caused by the fact that some customers occasionally purchase milk only when needed, while others, who drink milk every day, purchase new fresh milk before the expiration date, which regularizes the inter-purchase intervals. Regardless, the broad distributions in Figure 6A suggest that the temporal dynamics of customers X  purchase behavior should be examined individually. test data achieved by NBD, HTR sale (  X  =  X  sale ), HTR history (C-D) Log-likelihoods of test data achieved by NBD and HTR (  X  =  X  p
Given the individual parameter  X   X  u , the current state of the purchase rate,  X  u ( t now ), can be computed so quickly (of the order of milliseconds) based on the individual obser-vation { t u j } , because HTRm guarantees that  X  u ( t now is expressed by analytical functions (see Section 3). Fig-ure 6B displays examples of real-time estimates of the pur-chase rate. In it, purchase decisions are observed frequently in the intervals during which the estimated purchase rate was high, indicated by the shaded rectangles. When the using the time rescaling theorem (see Appendix B). Based on the current and future state of the purchase rate, we can make the go/no-go decisions on marketing actions such as advertising and recommendation.
In this paper, we constructed an innovative model that can track the temporal dynamics of a customer X  X  purchasing de-cisions. Our model offers a fast way of estimating the current and future state of the purchase rate, which is intricately in-fluenced by various intrinsic and external factors. We incor-porated the factors that are thought to dominate the mod-ulation of the purchase rate, namely, seasonal sales, self-excitation, and preceding purchase-events, into the model, and confirmed that our proposed model achieved high pre-dictive performance when challenged with real-world data in the categories of fashion, milk, and coffee beverages. This result indicates that the proposed model has the ability to discover the hidden dynamics of purchase behavior at the level of individuals, suggesting that the model will enable us to take effective marketing actions such as advertising and recommendations on a timely and individual basis.
A natural extension of this study is to extend our model to incorporate interaction among customers [13, 21] or among items [24], which is expected to improve its predictive per-formance. HTRm is not limited to purchase event data, but is widely applicable to any sequences of event points. Thus sale points. this model may help unveil the underlying dynamics of social interaction [7], financial markets [4], and so on. [1] G. M. Allenby, R. P. Leone, and L. Jen. A dynamic [2] C. Bishop. Pattern Recognition and Machine Learning . [3] C. Blundell, K. A. Heller, and J. M. Beck. Modelling [4] C. G. Bowsher. Modelling security market events in [5] E. N. Brown, R. Barbieri, V. Ventura, and et al. The [6] C. Chatfield and G. J. Goodhardt. A consumer [7] R. Crane and D. Sornette. Robust dynamic classes [8] A. S. C. Ehrenberg. The pattern of consumer [9] S. Gr  X  un and R. Stefan. Analysis of Parallel Spike [10] S. Gupta. Stochastic models of interpurchase time [11] A. G. Hawkes. Spectra of some self-exciting and [12] C.-Y. Huang and C.-S. Lin. Modeling the audience X  X  [13] T. Iwata, A. Shah, and Z. Ghahramani. Discovering [14] K. Kopperschmidt and W. Stute. Purchase timing [15] Y. Matsubara, Y. Sakurai, B. A. Prakash, and et al. [16] D. G. Morrison and D. C. Schmittlein. Generalizing [17] Y. Ogata. Statistical models for earthquake [18] W. H. Press. Numerical Recipes in C: the Art of [19] D. C. Schmittlein, D. G. Morrison, and R. Colombo. [20] D. L. Snyder. Random Point Processes . Wiley New [21] R. Takahashi, H. Mizuta, N. Abe, and et al. Collective [22] G. Trinh, C. Rungie, M. Wright, C. Driesener, and [23] J. Wang, B. Sarwar, and N. Sundaresan. Utilizing [24] J. Wang and Y. Zhang. Opportunity model for [25] G. C. Wei and M. A. Tanner. A Monte Carlo [26] G. Zhao, M. L. Lee, W. Hsu, and W. Chen. Increasing
From Equations (4) and (5), the differential of  X  M ( t ) with respect to real time t is given by d dt Thus, substituting Equation (30) into Equation (1) yields the probability density under the M th rescaled time as, where  X  M j  X   X  M ( t j ). Equation (31) indicates that the pur-chase rate at time  X  M ( t ) has a unit value.

In HTRm, a sequence of purchase decisions ( t 1 , t 2 ,  X  X  X  ), generated from the purchase rate  X  ( t ), is transformed into that in the rescaled time hierarchically as where ( X  1 ,  X  2 ,  X  X  X  ) is regarded as being realized from a Pois-son process with a unit rate (see Section 3). This prop-erty suggests that we can generate a sequence of purchase Figure 7: The cpu time for estimating individual pa-r ameters against the number of customers in Fashion . The Monte Carlo sample size and the burn-in size is 10,000 and 5,000, respectively. A 30-core CPU (2.6 GHz) computer was used to perform the estimation. points ( t 1 ,t 2 ,  X  X  X  ) by inversely transforming a sequence of time points ( X  1 ,  X  2 ,  X  X  X  ), generated from a Poisson process with a unit rate, into that in real time as The simulation algorithm proceeds as follows: 0. Assume that the last purchase occurred at t 0 , and that 1. Draw a random variable  X  X  j  X   X  j  X   X  j  X  1 from the 2. Find  X  j as the root of  X  X  j =  X ( X  j )  X   X ( X  j  X  1 ), leading 3. Find  X  j as the root of  X  X  X  j =  X ( X  j )  X   X ( X  j  X  1 ), leading 4. Find t j as the root of  X  X  j =  X ( t j )  X   X ( t j  X  1 ). Because 5. j  X  j + 1, and go back to 1.

Given the aggregate parameter (  X , X  ), we can estimate  X   X  u efficiently using parallel computation because each cus-tomer X  X  parameter  X   X  u is estimated based on his/her own data { t j } . Figure 7 shows that the cpu time is proportional to the number of customers. When the EM iteration number and the cpu time for estimating  X   X  u are denoted by N EM  X  t respectively, the cpu time for determining the aggregate parameter (  X , X  ) is represented by N EM  X  t . The aggregate parameter can be determined efficiently based on a randomly selected subset of the whole customer data, which makes the cpu time N EM  X  t less than several hours. It should be em-phasized here that we do not need to update the values of  X   X  u and (  X , X  ) frequently, but should do so after a certain amount of data is observed.
