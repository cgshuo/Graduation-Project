 lowing two directions has drawn considerable interest: lea rning a common feature representation parameters, where the rows and columns correspond to tasks a nd features. From this perspective, eter matrix, and modeling the task relatedness aims to find an d utilize the relations among rows. ture [1, 2, 12, 21]. In this paper we propose a new regularizat ion approach and show how several previous approaches are variants of special cases of it. The key contribution is a matrix-normal penalty with sparse inverse covariances, which provides a f ramework for characterizing and cou-penalty that decomposes the full covariance of matrix eleme nts into the Kronecker product of row verse covariances. We compare the proposed method to relate d models on two real-world data sets: detecting landmines in multiple fields and recognizing face s between different subjects. infer task structure via principal components [1, 12], inde pendent components [30] and covariance parameters [2] is a special case of our proposed framework. O n the other hand, assuming models and select both task and feature structures in multiple para metric models.
 16, 18] and applied to predictive modeling in the Bayesian li terature. For example, the standard where MCMC is used for sampling from the resulting posterior . Recently, matrix normal distribu-tions have also been used in nonparametric Bayesian approac hes, especially in learning Gaussian covariance function of the GP prior is decomposed as the Kron ecker product of a covariance over functions and a covariance over examples. We note that the pr oposed matrix-normal penalty with Bayesian inference can be performed. We will pursue this dir ection in our future work. 3.1 Definition [18, 13, 16]. Consider an m  X  p matrix W . Since we can vectorize W to be a mp  X  1 vector, the normal distribution on a matrix W can be considered as a multivariate normal distribution on a vector of mp dimensions. However, such an ordinary multivariate distri bution ignores the special structure of W as an m  X  p matrix, and as a result, the covariance characterizing the e lements of structure of W , matrix normal distributions assume that the mp  X  mp covariance can be decomposed as the Kronecker product  X   X   X  , and elements of W follow: where  X  is an m  X  m positive definite matrix indicating the covariance between rows of W ,  X  is a p  X  p positive definite matrix indicating the covariance between columns of W ,  X   X   X  is the Kronecker product of  X  and  X  , M is a m  X  p matrix containing the expectation of each element of W , and V ec is the vectorization operation which maps a m  X  p matrix into a mp  X  1 vector. Due to an m  X  p matrix W , parameterized by the mean M , row covariance  X  and column covariance  X  , has a compact log-density [18]: log P ( W ) =  X  where | | is the determinant of a square matrix, and tr {} is the trace of a square matrix. 3.2 Maximum likelihood estimation (MLE) Consider a set of n samples { W normal distribution as eq. (2). The maximum likelihood esti mation (MLE) of mean M is [16]: The MLE estimators of  X  and  X  are solutions to the following system: (  X   X   X  , 1 from the definition in eq. (1), where only the Kronecker produ ct  X   X   X  is identifiable. parameter vector and performing maximum-a-posterior esti mation, e.g.,  X  2 penalty and  X  1 penalty natural to use matrix-variate priors to design regularizat ion penalties.
 In this section, we propose a matrix-normal penalty with spa rse inverse covariances for learning the algorithm, and in Section 4.4 we discuss other useful con straints in our framework. 4.1 Learning with a Matrix Normal Penalty sets are { D m models for the m tasks but appropriately share knowledge among tasks. Model parameters are represented by an m  X  p matrix W , where parameters for a task correspond to a row. of multiple tasks as a matrix W : 1) we set M = 0 , indicating a preference for simple models; 2) the m  X  m row covariance  X  describes the similarity among tasks; 3) the p  X  p column covariance where  X  controls the strength of the regularization, ( y ( t ) and positive definite, eq. (5) is convex w.r.t. W and thus W can be optimized efficiently [22]. Now we discuss a few special cases of (5) and how is previous wo rk related to them. When we fix  X  = I m and  X  = I p , the penalty term can be decomposed into standard  X  2 -norm penalties on the m  X  2 regularization (but tasks are still tied by sharing the para meter  X  ).
 When we fix  X  = I additional constraint tr {  X  }  X  1 on the trace of  X  to avoid setting  X  to infinity. When we fix  X  = I correlation  X  given as prior knowledge and empirical loss L as the max-margin hinge loss.  X  to be infinity matrices. We can impose constraints on  X  and  X  to avoid this, but a more natural log-density (2). As a result, the total loss L is: Based on this formula, we can infer task structure  X  and feature structure  X  given the model pa-rameters W , as the following problem: This problem is equivalent to maximizing the log-likelihoo d of a matrix normal distribution as in eq. (2), given W as observations and expectation M fixed at 0 . Following Section 3.2, the MLE of  X  and  X  can be obtained by the  X  X lip-flop X  algorithm: will not affect the optimization of W using eq. (5), since only  X   X   X  matters for this purpose. 4.2 Sparse Covariance Selection in the Matrix-Normal Penal ty note that a clustering of tasks can be expressed by block-wis e sparsity of  X   X  1 . regularize and select task and feature structures.
 Formally, we rewrite (6) to include two additional  X  1 penalty terms on the inverse covariances: where || || therefore the sparsity of task and feature structures.
 Based on the new regularization formula (9), estimating W given  X  and  X  as in (5) is not affected, while inferring  X  and  X  given W , previously shown as (7), becomes a new problem: As in (8), we can iteratively optimize  X  and  X  until convergence, as follows: as a basic solver and consider (11) as an  X  1 regularized  X  X lip-flop X  algorithm: and  X  The following lemma proves that restricting  X  space of optimal models W we can obtain. As a result, we eliminate one regularization p arameter. Lemma 1. Suppose W  X  belongs to a minimizer ( W  X  ,  X   X  ,  X   X  ) for eq. (9) with some arbitrary choice of  X  ,  X  choice of  X   X  ,  X   X  4.3 The Algorithm 1) Estimate W by solving (5), using  X  = I 2) Infer  X  and  X  in (9) (by solving (11) until convergence), using the estima ted W from step 1); 3) Estimate W by solving (5), using the inferred  X  and  X  from step 2).
 number of data points and step 2) is independent of it, so the m ethod scales well with the number 4.4 Additional Constraints We can have additional structure assumptions in the matrix-normal penalty. For example, consider: other words, the restrictions are enforced by a projection s tep.
 may consider the constraints with unknown quantities c problem w.r.t. W ,  X  ,  X  , c algorithm in (11) needs to solve  X  1 penalized covariance selection with equality constraints (15) sparse covariance selection) in the future work. and classifying faces between different subjects, respect ively. 5.1 Data Sets and Experimental Settings The landmine detection data set from [26] contains examples collected from different landm ine radar imaging, which includes moment-based features, corr elation-based features, an energy ratio matrix, corresponding to 19 tasks and 10 coefficients (including the intercept) for each task. The distribution of examples is imbalanced in each task, wit h a few dozen positive examples and several hundred negative examples. Therefore, we use the av erage AUC (Area Under the ROC as to see how well multi-task learning handles this case.
 The face recognition data set is the Yale face database, which contains 165 images of 15 subjects. The 11 images per subject correspond to different configurations i n terms of expression, emotion, collect task-average classification errors over 30 runs, and report mean and standard errors. Laplacianfaces [10], which have been shown to provide bette r discriminative power than Eigenfaces (PCA), fisherfaces (LDA) and Laplacianfaces on several benc hmark data sets. In each random run, experiments of all 28 classification tasks in the extracted feature space. 5.2 Models and Implementation Details STL : learn  X  2 regularized logistic regression for each task separately.
 discussed in Section 4.1, this is related to eq. (5) with only a task structure  X  . MTL-F : multi-task feature learning [2], which corresponds to fixi ng the task covariance  X  as I and optimizing (6) with only the feature covariance  X  .
 In addition, we also study various different configurations of the proposed framework: MTL( I MTL(  X  &amp; I MTL( I MTL(  X  &amp;  X  ) : learn W ,  X  and  X  using (9), inferring both task and feature structures. MTL(  X  &amp;  X  ) MTL(  X  &amp;  X  ) free diagonal entries in  X  are useful when features are of different importance, e.g, c omponents extracted as orthogonal Laplacianfaces usually capture de creasing amounts of information [10]. We use conjugate gradients [22] to optimize W in (5), and infer  X  and  X  in (11) using graphical lasso [17] as the basic solver. Regularization parameters  X  and  X  Table 1: Average AUC scores (%) on landmine detection: means (and standard errors) over 30 random runs. For each column, the best model is marked with  X  and competitive models (by paired t-tests) are shown in bold . consider 3 values for each parameter, leading to 3 4 = 64 combinations chosen by cross validation. 5.3 Results on Landmine Detection The results on landmine detection are shown in Table 1. Each r ow of the table corresponds to a model in our experiments. Each column is a training sample si ze. We have 30 random runs for each sample size. We use task-average AUC score as the performanc e measure and report the mean and standard error of this measure over 30 random runs. The best model is marked with  X  , and models model in a one-sided paired t-test with  X  = 0 . 05 ).
 Overall speaking, MTL(  X  &amp;  X  ) and MTL(  X  &amp;  X  ) For small training sizes, restricted  X  and  X  (  X  training size ( 160 per task), free  X  and  X  give the best performance. The best model performs better than MTL-F [2] and much better than MTL-C [21] with sma ll training sets. MTL( I MTL( I MTL(  X  &amp;  X  ) performs well given large numbers of training samples. MTL(  X  &amp;  X  ) MTL(  X  &amp;  X  ) 5.4 Results on Face Recognition Empirical results on face recognition are shown in Table 2, w ith the best model in each column marked with  X  and competitive models displayed in bold. MTL-C [21] perfor ms even worse than In addition, MTL(  X  &amp;  X  ) sufficient training data ( 5 or 7 per subject). Compared to MTL(  X  &amp;  X  ), MTL(  X  &amp;  X  ) should be equally regularized. Compared to MTL(  X  &amp;  X  ) random runs. For each column, the best model is marked with  X  and competitive models (by paired t-tests) are shown in bold . and face recognition show that we consistently outperform p revious methods.
 Acknowledgement : this work was funded in part by the National Science Foundat ion under grant NSF-IIS0911032 and the Department of Energy under grant DES C0002607.
 Proof of Lemma 1.
 We prove lemma 1 by construction. Given an arbitrary choice o f  X  ,  X  eq. (9) with certain  X   X  ,  X   X  We denote the objective function in eq. (9) with  X  ,  X  Also, we denote the objective function with our constructed parameters  X   X  ,  X   X  The key step in our proof is that, by construction, the follow ing equality always holds: examples, depending only on W (and training data). The second part is the log-density of ma trix log-density is the same; 3) by our construction, the third pa rt is not changed. Based on this equality, if ( W  X  ,  X   X  ,  X   X  ) minimizes Obj  X , X   X  , X   X  () , we have that
