 Complex search tasks that utilize information from several data sources, are answered by integrating the results of dis-tinct basic search queries. In such integration, each basic query returns a ranked list of items, and the main task is to compute the join of these lists, returning the top-k combi-nations . Computing the top-k join of ranked lists has been studied extensively for the case where the answer comprises merely complete combinations. However, a join is a lossy operation, and over heterogeneous data sources some highly-ranked items, from the results of the basic queries, may not appear in any combination. Yet, such items and the par-tial combinations in which they appear may still be relevant answers and should not be discarded categorically.
In this paper we consider a join where combinations are padded by nulls for missing items. A combination is maximal if it cannot be extended by replacing a null by an item. We present algorithms for computing the top-k maximal combi-nations and provide an experimental evaluation.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Performance Data integration, search, top-k, join, maximal answers
Search is a fundamental service provided by numerous applications. Usually, a basic search application returns a ranked list of relevant items by posing a single query over  X 
This work was partially supported by GIF grant 2165-1738.6/2007 and by MOST grant 3/6472.
 a single data source. Yet, some complex search tasks re-quire combining the answers of several basic search queries, by joining the ranked lists [1]. The result of a join is a set of combinations , where each combination is a set of related items X  X omprising a single item from each list. Combina-tions are ranked according to the ranking scores of the items they comprise.

When integrating information from different sources, the algorithms should be able to cope with missing data, and should avoid discarding data from one source simply because it does not have a matching data in another source. In incomplete combinations , nulls fill in for missing items. However, in order to provide as much relevant information as possible, the result comprises only combinations that are maximal , in the sense that none of these combinations is a proper subset of any other combination. Requiring max-imality prevents duplications such as having in the result several subsets of the same combination.

Computing the join of ranked lists, for the case where the result contains only complete combinations, is a well-studied subject. Ilyas et al. proposed a method that uses pipelining and binary join operators, for computing equijoin of ranked lists [2]. This approach has been further investigated by Schnaitter and Polyzotis [3]. In this paper, we show how their algorithm can be modified to return maximal rather than complete combinations. We refer to the modified algo-rithms by the name hnl . We also introduce two additional join algorithms that return maximal answers. One algo-rithm, namely vnl , is more efficient than hnl for the case where associations between items in the lists are infrequent. The second algorithm is a hybrid between vnl and hnl and it outperforms both in almost all cases.

In this paper, we present our join algorithms and the op-timizations that were used for an efficient implementation of these algorithms. Experimental evaluation illustrates the benefits of each algorithm. Combined Search Query. A combined search query Q comprises several basic search queries Q = ( q 1 , q 2 , . . . , q We refer to q 1 , . . . , q t as the subqueries of Q . A preliminary step for evaluating a combined search query Q is to evaluate all its subqueries. The result of this step is the pre-answer of Q , PreAns ( Q ) = ( L 1 , . . . , L t ), where L is the answer to q j . L j is a list of items ( o j 1 , o sorted in descending order by their relevance score . Complete Combinations. Given a combined query Q , items of different lists of the pre-answer are joined to form combinations. The join operation is based on conditions which determine whether the items should be joined. We refer to a pair of items that are joined as associated. The and false otherwise.
 A complete combination is a t -tuple of items, such that each item is an element of the corresponding list of the pre-answer, and every pair of items in C is associated. We denote by Join ( Q ) the set of all the combinations that are produced by joining the lists of the pre-answer of Q .
The score of a combination C , denoted score ( C ), is the result of a monotonic function over the item scores. Maximal Combinations. We represent missing values us-ing nulls, denoted by the  X  symbol. A partial combination is a t -tuple of elements, where each element is either an item of the corresponding list or a null value, and every pair of non-null items is associated. When computing the score of a partial combination, a null value is considered as an item whose score is zero.

A partial combination C 1 = ( o i 1 , o i 2 , . . . , o i partial combination C 2 = ( o j 1 , o j 2 , . . . , o j t C , if for every 1  X  k  X  t , either o j k =  X  or o j k = o i is, every non-null item in C 2 is equal to the corresponding item in C 1 .

A combination is maximal if it is not a proper subset of any other combination. Formally, a combination C is maximal if there is no combination C  X   X  ( L 1  X  X  X } )  X  X  X  X  X  ( L t  X  X  X } ) such that C
We denote by MaxJoin ( Q ) the set of all maximal com-binations that are produced by joining the lists of the pre-answer of Q . The top-k maximal answers of Q are the k combinations with the highest scores in MaxJoin ( Q ).
In this section we present algorithms for computing the top-k maximal answers for a given combined search query Q . Throughout this section, we assume that the input consists modify these lists by adding a null value with score zero at the end of each list. We denote these extended lists by L 1 , . . . , L condition is such that a null value, in any list, is associated with any item and with any null of any other list.
The algorithms we present manage a heap of size (at most) k that stores combinations. We denote by MinScore ( H ) a function that returns the minimal score of a combination in H if the heap is full, or zero in the case that H currently contains less than k combinations.

We denote by H. add ( C ) the two-step addition operation that (1) adds a combination C to H , if there is no other combination in H that subsumes C ; and (2) if after the addition there are k + 1 elements in H , removes from H the combination with the lowest score.
The first algorithm we consider is essentially a modifi-cation of the algorithm of Ilyas et al. [2], where instead of applying it over L 1 , . . . , L t , we apply it over the lists L 1 , . . . , L gorithm iterates over the lists, horizontally, and in each iter-ation adds the discovered combinations to the heap H . We denote this algorithm by hnl .

Initially, the algorithm visits the first item of each list, and in the i -th iteration it visits the i -th item of each list. When visiting an item o j i of list j , the algorithm joins the singleton { o j i } with all the items of the other lists that were visited before o j i . That is, the algorithm computes the join of the lists T i; 1 , . . . , T i;j  X  1 , { o j i } , T i T i;j are the top-i items of L + j , and it adds the produced combinations to H .

For computing the join in each iteration, the algorithm employs the vertical nested loop algorithm ( vnl ) that is presented in the following section (Section 3.2). As an opti-mization, it takes the singleton list as the outermost list, in the nested loop.

In order to apply early termination, when for some visited item o j i it holds that score ( o 1 1 , . . . , o j  X  1 1 MinScore ( H ), the algorithm stops visiting items of list j . o is lower than the score of the lowest combination in the heap H , then there is no additional possible combination that can be added to H , among the combinations that contain an item lower than o j i in L + j . Thus, the algorithm stops visiting items below o j i in L + j . When in all the lists the algorithm either reaches this stopping condition or reaches the end of the list, the computation terminates.

Note that in hnl , all the complete combinations are con-structed prior to the construction of partial combinations.
The Vertical Nested-Loop Algorithm (Algorithm 1), vnl for short, is an optimized version of an algorithm that iter-ates over the lists in a vertical fashion. Essentially, vnl ates through the lists by nested loops and maintains the top combinations in a heap H . Whenever it finds a combination C , it inserts C to H by applying H. add ( C ), (i.e., C is being added to H only if there is no combination in H that sub-sumes C , and the score of C is higher than MinScore ( H )). In order to increase the efficiency, vnl breaks the loops in cases where continuing the iteration would not be able to produce relevant combinations, i.e., combinations that will be inserted to the top-k heap. Consequently, vnl checks less combinations than a naive nested loop algorithm.

In hnl , a partial combination can be inserted into H only after all the relevant complete combinations were added to H . This is not the case in vnl . A partial combination may be added to the heap H prior to the insertion of some complete combination. Yet, in each step of the algorithm all the combinations in H are maximal combinations. This is because when a combination C is added to H , there cannot be in H a combination that subsumes C .
Consider the two algorithms vnl and hnl that we have discussed so far. An analysis can show that vnl is more efficient than hnl when the percentage of associations is low, i.e., when there are relatively few associated pairs. hnl more efficient than vnl when the percentage of associations is high. The reason is that vnl may read, in such case, much more items than hnl in its inner loops. Algorithm 1 Vertical Nested Loops ( vnl ) Input: L 1 ,  X  X  X  , L t ; k Output: Top-k maximal combinations 1: add an item  X  with score 0 to the end of each list, cre-2: H :=  X   X  a heap of size k 3: for a 1 in L + 1 do 5: break 6: end if 7: ... 8: for a i in L + i do 9: let s = score ( a 1 , . . . , a i , o i +1 1 , . . . , o 10: if s &lt; MinScore ( H ) then 11: break 12: end if 13: if exists 1  X  j  X  i  X  1 s.t. not JCon ( a j , a i ) then 14: continue 15: end if 16: ... 17: for a t in L + t do 18: if JCon ( a t , a j ) = true for 1  X  j  X  t  X  1 then 19: newComb := ( a 1 , . . . , a t ) 20: H. add ( newComb ) 21: end if 22: end for 23: ... 24: end for 25: ... 26: end for
The hybrid approach tries to combine the benefits of both algorithms for producing an algorithm that is at least as efficient as hnl in the case where there are many associations between items, and at least as efficient as vnl when there are a few associations between items.

Algorithm vhnl is a hybrid, between vnl and hnl , that works as follows. It computes a value h , iterates over the h first elements of each list using vnl and then continues by iterating over the lists horizontally using hnl , starting from the ( h + 1)-st row. Note that when h = 0, the hybrid algorithm vhnl immediately applies hnl , while for h  X  m , where m is the number of items in the longest list, vhnl calls only to vnl , without switching to hnl .

Our goal is to choose h such that vhnl will outperform both vnl and hnl . We do that as follows. Given the lists L , . . . , L t , we denote by P ij the probability that a pair ( o , o j ), of uniformly selected items o i  X  L i and o j  X  L are associated. That is, if A ij is the set of associated pairs of items in L i  X  L j , then The probability that some randomly chosen tuple among the tuples of L 1  X  L 2  X  X  X  X  X  L t is a combination is Thus, h items from each list are expected to yield h t  X  P combinations. Since k combinations fill the top-k heap, we Algorithm 2 vhnl .
 Input: L 1 , . . . , L t ; k Output: Top-k maximal combinations 1: H :=  X   X  a heap of size k 2: Compute h according to Equation 1 3: For i = 1 , . . . , t let V i be the top h items in L i 4: Compute vnl ( V 1 , . . . , V t , k , H ) 6: return H take k = h t  X  P C , and we compute h as follows:
Algorithm 2 presents vhnl . It computes h using Equa-tion 1, and applies vnl and hnl accordingly. The P ij -s probabilities for the computation of h are either known a priori or being estimated using sampling.
We conducted a variety of experiments to evaluate the performance of the presented algorithms. In what follows, we first describe the experimental methodology and then present the results of the evaluation.
The experiments were conducted on a 2.0GHz Pentium 4 machine with 2GB RAM, running the Windows XP operat-ing system. The algorithms were implemented in Java. In order to be able to vary parameters on demand we utilized synthetic data sets. We generated lists of synthetic items, controlling various parameters (e.g., number of lists, their lengths, association degree X  X he probability that two items are joined). We also tested our techniques on real geospa-tial data set. The data is part of a digital map of the city Tel-Aviv. The data set consists of 400 geographical objects in four lists (cinemas, hotels, pharmacies and synagogues). Each object has a relevance score, latitude and longitude. We joined two items if the Euclidean distance between them is at most 200 meters.

The parameters m (list length), t (number of lists), k (number of desired outputs), and p (association degree) are specified for each experiment. The default values are m = 1000, t = 4, k = 100, and p = 2%. The score of a combina-tion, in both the synthetic and real data sets, is the sum of scores of the joined items.
 Evaluation metrics. To evaluate the performance of the algorithms, we measured, in addition to the running times (which are measured in milliseconds), the number of items scanned (#ItemsReads), and the number of pairwise association checks (#BinJoins). The first measure is the access cost of the algorithm, while the second corresponds to the join computational cost.
In the following experiments, the scores in every list are distributed uniformly in the range [0,100]. The first experi-ment studies the effect of the association degree on the per-formance of the algorithms over synthetic data (with default parameters). The results are presented in Figure 1. When the association degree is low (up to 2%), all algorithms read the entire input, which is expected as there are relatively few combinations, and the top-k ones are not necessarily located high on the lists. However, there is a significant difference in the join cost of the algorithms. vnl is more ef-ficient than hnl , both in running time and in join cost. Note that for low association degrees, even when there are dozens of complete combinations, the top-10 answer (and obviously for larger values of k ) contains partial combinations. As the association degree increases, and the top-k results are located higher in the lists, the access cost of all algorithms decreases. However, in this case the trend is reversed as outperforms vnl . It reads less items and performs less join checks than vnl . vhnl is almost optimal in all degrees of association. This emphasizes the importance of estimating the depth in the lists over which vnl should be executed.
The second experiment evaluates the performance of the algorithms as we vary the desired number of outputs (i.e., k). Figure 2 shows the results over real data as a function of k . All algorithms have about the same running time (less than 16 milliseconds). vnl has the worst access cost, and hnl has the worst join cost. As expected, all costs are increased when k is increased. vhnl , again, is the most efficient when considering both access cost and join cost.

Figure 3 shows the join cost over synthetic data with low association degree, as a function of k . In this case, the algo-rithms read the entire input. Hence, only the join cost varies. In addition, vhnl performs the same as vnl (because h is high) and better than hnl . When k increases, the join cost of vhnl and vnl only slightly increases, because such in-Figure 3: Join cost as a function of k ( m = 1000 , t = 4 , p = 2% ) crease only requires maintaining a larger priority queue. To conclude, vhnl is the best algorithm in almost all cases, for all measures. [1] S. Ceri and M. Barambilla. Search Computing: [2] F. Ilyas, G. Aref, and K. Elmagarmid. Supporting [3] K. Schnaitter and N. Polyzotis. Evaluating rank joins
