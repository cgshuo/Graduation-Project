 This paper introduces retargeted matrix factorization (R-MF); a novel approach for learning the user-wise ranking of items in the context of collaborative filtering. R-MF learns to rank by  X  X etar-geting X  the item ratings of each user, searching for a monotonic transformation of the ratings that results in a better fit while pre-serving the ranked order of each user X  X  ratings. The retargeting is combined with an underlying matrix factorization regression model that couples the user-wise rankings to exploit shared low dimen-sional structure. We show that R-MF recovers a unique solution under mild conditions, and propose a simple and efficient optimiza-tion scheme that alternates between retargeting the ratings subject to ordering constraints, and matrix factorization regression. The retargeting step is independent for each user, and is trivially paral-lelized. The ranking performance of retargeted matrix factorization is evaluated on benchmark movie recommendation datasets and re-sults in superior ranking performance compared to collaborative filtering algorithms specifically designed to optimize ranking met-rics.
 H3.3 [ Information Search and Retrieval ]: Information filtering X  Collaborative Filtering ; G3 [ Probability and Statistics ]: Correla-tion and regression analysis Algorithms, Experimentation Matrix factorization; Collaborative filtering; Learning to rank
The focus of research in the recommender systems literature has begun to shift from algorithms and metrics for optimizing regres-sion accuracy to learning and measuring the ranking of items for each user. Learned rating scores are not shown in most practical deployments of recommender systems. Instead, the user is shown a few of the top items as ordered by the recommender system. This means that although regression metrics such as root mean square error (RMSE) and mean absolute error (MAE) are easier to op-timize, ranking metrics such as normalized discounted cumulative gain (NDCG) and expected reciprocal return (ERR) [18] are a more accurate reflection of how recommender systems are used in prac-tice [9].

This paper proposes retargeted matrix factorization (R-MF), a novel approach for learning the user-wise ranking of items inspired by the study of learning to rank (LETOR) in the the information retrieval literature [18]. There, initial approaches using point-wise ranking models [8] were replaced by pair-wise models [10], and are now being superseded by list-wise ranking models [6, 2]. The list-wise approach learns a ranking model for the entire set of items and has gained prominence in the LETOR literature with strong theo-retical guarantees and superior empirical performance [19]. Re-targeted matrix factorization (R-MF) transforms the matrix fac-torization (MF) model into a user-wise ranking model by adjust-ing the rating values based on the regression fit. These adjust-ments are constrained to monotonic transformations that preserve the order of the user ratings. We show that R-MF inherits use-ful statistical and optimization theoretic properties when the loss function for the matrix factorization is a Bregman divergence [4], a family of divergences that includes such popular loss functions such as squared loss, Kullback-Leibler (KL) divergence and the I-divergence (also known as the generalized KL divergence). In the context of learning to rank, Bregman divergences are further motivated as the unique family of cost functions that are strongly consistent with the NDCG metric [19].

The main contributions of this paper are as follows: This paper is organized as follows, we begin with an overview of related work in Section 1.1. This is followed by a discussion of the modeling approach and some of the resulting properties in Sec-tion 2. We propose a simple alternating optimization scheme in Section 3. Experimental results are discussed in Section 4 and we conclude in Section 5.

Notation: Vectors are denoted by bold lower case letters, matri-ces are capitalized. x &gt; denotes the transpose of the vector x , || x || denotes the L 2 norm. A vector x is defined to be in descending or-der if x i  X  x j when i &gt; j, the set of such vectors is denoted by R X  . Vector x is isotonic with y if x i  X  x j implies y i  X  y j simplex is denoted by  X  and  X  denotes the subset of an unit sim-plex such that each of its members are component-wise bounded away from 0 by . The positive orthant is denoted by R d + denotes its subset such that each of its members are component-wise bounded away from 0 by .
Models for user-wise ranking have been studied by several re-searchers in the recommender systems literature. Point-wise mod-els applied to collaborative filtering predict user ratings using re-gression or classification methods, the final ranking is defined by the ordering of the regression scores. It is often difficult to extract a clear relationship between the regression scores and the item rank-ings. Cremonesi et al. [9] showed that methods trained to opti-mize regression metrics may not be effective for top-k recommen-dation. Steck et al. [24] proposed modifications of matrix factoriza-tion methods motivated by top-k ranking performance. A related class of point-wise ordinal regression models have also been pro-posed. These models are optimized so that user ratings are correctly placed in ordered bins corresponding to the different rating levels. For instance, maximum margin matrix factorization (MMMF) [23] jointly optimized the matrix factorization and the user rating bins using the Hinge loss, C OFI R ANK -ordinal [26] used bundle methods with squared loss for fast optimization of the user and item fac-tors and ordinal regression bins, and Ordrec [14] combined ordinal logistic regression with matrix factorization.

Ranking performance may be improved further by using a pair-wise approach. In this case, the model is trained to order each pair of items [17]. Balakrishnan et al. [3] proposed a pairwise classifi-cation approach for collaborative ranking. The authors showed ef-fective ranking performance as measured using the NDCG metric. Pair-wise ranking results in a model with computational cost that is quadratic in the number of items to be ranked. This is a significant increase in computational cost and may be prohibitive in large scale recommender systems with millions of ratings 1 . The learned pair-wise orders must also be converted into a fully ordered list (at ad-ditional computational cost). Of significant concern is the fact that pair-wise orders are not necessarily transitive. Hence, orders over pairs of items may not directly translate into an ordered list. For ex-ample, given three items { a,b,c } , there is no consistent ordered list
List-wise approaches avoid the computational and consistency hazards of pair-wise methods. In addition, list-wise methods often have stronger statistical and optimization theoretic guarantees [19,
Sub-sampling has been proposed as an approach to reduce this computational burden [3]. However, we note that any computa-tional savings also apply to competing approaches.
 Table 1: Examples of identically separable (IS) Bregman diver-gences. Squared loss (top) and KL divergence (bottom). 2], and superior empirical performance. List-wise models applied to collaborative filtering are known as user-wise ranking models. C
OFI R ANK [25], a popular approach for user-wise collaborative fil-tering, trains a matrix factorization model to optimize a bound of the NDCG metric. Shi et al. [21] adapted the list-wise ranking al-gorithm proposed in [6] to collaborative filtering by replacing the underlying linear regression model with a matrix factorization re-gression model.

The outlined related work is focused on models for optimizing top-k ranking performance and not on regression metrics such as RMSE / MAE [13]. Further, there is a large literature on the use of side information such as features [5] and graphs [15] for rec-ommender systems. The use of such side information enables the model to be used for cold start i.e. predicting the rankings of users with no training ratings. Such extensions are not discussed here in detail and are left as a subject for future work.

The proposed framework includes a choice of loss function in the family of Bregman divergences. A unified approach for matrix fac-torization with Bregman divergence loss functions was proposed by Singh and Gordon [22], showing that several well known methods such as non-negative matrix factorization (NMF), weighted singu-lar value decomposition (SVD), maximum margin matrix factoriza-tion (MMMF), probabilistic latent semantic indexing (pLSI) and other related models can be posed as special cases of this frame-work.
Let  X  :  X  7 X  R ,  X  = dom  X   X  R d be a strictly convex, closed function, differentiable on int  X  . The corresponding Breg-man divergence D  X   X   X  : dom(  X  )  X  int(dom(  X  )) 7 X  R + defined as D  X  x y ,  X  ( x )  X   X  ( y )  X  X  x  X  y ,  X   X  ( y )  X  . From strict convexity it follows that D  X  x y  X  0 and D  X  x y = 0 iff. x = y . Bregman divergences are (strictly) convex in their first argument, but not necessarily convex in their second.
 In this paper we only consider functions of the form  X  (  X  ) : x 7 X  P i  X  ( x i ) that are sums of identical scalar convex functions applied to each component. We refer to this class as identically sep-arable ( IS ). This class has properties particularly suited to ranking. Squared loss and Kullback-Leibler divergence (KL) are members of this family (Table 1).

The Legendre conjugate  X  (  X  ) of the function  X  (  X  ) is defined as (  X  )  X  ( x ) ,  X  ( x ) , sup  X  (  X   X  , x  X  X  X   X  (  X  )) . If  X  (  X  ) is a convex function of Legendre type [20] (as will always be the case in this mapping.
Let w ij be a binary variable that denotes whether user i has rated item j ( w ij = 1 ) or not ( w ij = 0 ). We denote the true ratings by Y ij and predicted ratings by  X  Y ij . Let U and V denote the set of users and items respectively. Let V i denote the set of items rated by user i and |V i | its cardinality. The item recommendation task Figure 1: Monotone retargeting [2] searches for an order pre-serving transformation of the target scores that may be easier for the regressor to fit. consists of learning the user X  X  taste from the training ratings. A popular technique for item recommendation is matrix factorization (MF) [13]. In MF, the predictions take the form: where u i  X  R d is called a user factor for user i and v j the item factor for item j. Further, let U  X  R |U| X  d with U ( i ) = u i represent the collected user factors and let V  X  R |V| X  d V ( j ) = v j represent the collected item factors. Note that this fac-torization constrains the rank of the matrix  X  Y to be upper-bounded by d. For reasons of scalability, this matrix should never be explic-itly maintained. Its entries can be generated dynamically from the user and item factors as needed.

In MF, the factors are learned by minimizing the squared Eu-clidean distance between the actual ratings and the predicted rat-ings as: For recommender systems, making the model predictions close to the ratings is only a means to an end. The true objective is to facili-tate the ordering of the items according to the users preference. On one hand the objective (2) is solving a harder problem, and on the other hand, in its goal to keep the predicted  X  Y ij point-wise close to the observed Y ij the regressor may generate predictions close in squared Euclidean sense with estimated scores that induce an incorrect order, thereby misdirecting the algorithm [9]. This is par-ticularly true when one uses a regressor of limited function-fitting capacity. In this context the cost function (2) is unnecessarily strict.
These drawbacks are now well recognized and have inspired sev-eral ranking based approaches to the the recommendation problem. The newer approaches replace (2) by other cost functions that de-pend not on the predicted scores themselves, but on the order in-duced by them. Examples of such cost functions include the nor-malized cumulative discounted gain (NDCG), expected reciprocal return (ERR) and mean absolute precision (MAP) [18]. However, the domain of these cost functions is the space of permutations of the list of items. This is not only a discrete (combinatorial) space, but also one whose size grows exponentially with the number of items. This makes training with respect to these cost functions dif-ficult.

In this paper we adapt a list-wise learning to rank (LETOR) al-gorithm called monotone retargeting (MR) [2], developed recently by the authors, to the recommendation task. MR introduces a new family of cost functions that have desirable computational and sta-tistical properties. It uses a cost function that is truly a function of the order and not of the predicted values, therefore well suited for ranking. The key observations that motivates the MR is that (i) the combinatorial problem of LETOR can be transformed into a prob-lem of searching over the space of all monotonic transformations and (ii) it is possible to design an efficient, convergent technique to solve the challenging task of minimizing over this infinite function space without sacrificing generality. A pictorial representation of MR is shown in Fig. 1.
Given any loss function D : R  X  R 7 X  R + , we may define a pointwise LETOR based MF problem by: where f : R 7 X  R is some regression function with parameters u i and v j . As discussed earlier, this is unnecessarily stringent for ranking. A conceptually better alternative is: where  X  i : R 7 X  R is a monotonic increasing transformation and M is the class of all such transformations. With no loss in gener-ality of modeling, we may apply the monotonic transform to Y instead. This avoids the minimization over the function compo-sition, but the need for minimizing over the set of all monotone functions remains.

As noted in [2] the optimization over the infinite space of func-tions M can be converted into one over finite dimensional vector spaces provided we have a finite characterization of the constraint set R X  i . Without loss of generality, the monotone transformation can be applied to the left hand side i.e. to the sorted ratings. Let Y i,  X  represent the item ratings for user i arranged in (non-unique) sorted order. Further, let V i  X  R |V i | X  d represent the subset of item factors corresponding to the items rated by user i , sorted to match the ratings Y i,  X  . The resulting cost function is: f (  X  ) is applied element-wise to result of the matrix vector product V u i , and R X  i represents all vectors that are sorted in decreasing order. Hence R X  i includes vectors r  X  R |V i | such that r for some k. Since the vectors r are the targets given to the regressor to fit, it is more robust to enforce separation between the compo-nents, i.e. maintain r k  X  r k +1 + . We indicate the set of all such separated decreasing ordered sets by R  X  i . We now characterize these sets.

The Set R X  i : The convex composition r =  X  r 1 + (1  X   X  ) r of two isotonic vectors r 1 and r 2 preserves isotonicity, as does the scaling  X  r for any  X   X  R + . Hence the set R X  i is a convex cone. Clearly the same holds for R  X  i . Convex-conicity makes the problem computationally tractable because the set can be described entirely by its extreme rays, or by the extreme rays of its polar. R X  i can be expressed as the image of the set { under a linear transformation by a particular upper triangular matrix S with positive entries. The matrix S is not unique and can be generated from any vector v  X  R + |V i | , but since any member from the allowed class of S is sufficient for a exhaustive representation of R X  i we use the vector 1 to generate S. The property is stated formally in the following lemma:
L EMMA 1. The set R X  i of all vectors in R |V i | that are sorted in a descending order is given by S x s . t . x  X  X  R + } |V where S is a triangular matrix generated from a vector 1 such that the k th row S ( k, :) is { 0 } k  X  1  X  1 ( k :) The proof of Lemma 1 appears in [2]. In addition, the following lemma defining R  X  i follows directly from Lemma 1 and is stated without proof.

L EMMA 2. The set R  X  i of all vectors in R |V i | that are sorted in a descending order and whose consecutive components are sep-arated by is given by S x s . t . x  X  { R } |V i | X  1  X  R is a triangular matrix generated from a vector 1 such that the k row S ( k, :) is { 0 } k  X  1  X  1 ( k :)
In addition to these sets we shall make frequent use of the set of all discrete probability distributions that are in descending order, i.e. R X  i  X   X  i that we represent by  X   X  i . We give a similar represen-tation of this set by generating an upper triangular matrix T from the vector v  X  i = { 1 , 1 2 ,  X  X  X  1 i  X  X  X  1 |V This is formally stated in the following lemma:
L EMMA 3. The set  X   X  i of all discrete probability distributions of dimension |V i | that are in descending order is the image T x such that x  X   X  i where T is an upper triangular matrix generated from the vector v  X  i = { 1 , 1 2  X  X  X  1 |V v  X  ( k :) The proof of Lemma 3 appears in [2]. Similar to the set R  X  will use a well separated version of  X   X  i denoted by  X   X  sists of discrete probability distributions sorted in decreasing order but also satisfying r i &gt; r i +1 + i . Note that vectors in  X   X  not only sorted but have an increasing gap between consecutive components. The motivation for such a construction is that even if the regressor is inaccurate, if the inaccuracy is more or less uni-form across the components, the top entries of the predictions will be less prone to order reversal than the bottom ones: a desirable feature for ranking. The following lemma formally states the rep-resentation for  X   X  i .

L EMMA 4. The set  X   X  i of all discrete probability distribu-tions of dimension |V i | that are in descending order is the image T x s . t . x  X   X  i where T is an upper triangular matrix gener-ated from the vector v  X  i = { 1 , 1 2  X  X  X  1 |V The prof of Lemma 4 follows directly from Lemma 3.
With appropriate choices of the distance like function D (  X  ,  X  ) and the curve fitting function f (  X  ) we can transform (3) into a bi-convex optimization problem over a product of convex sets. We choose D (  X  ,  X  ) to be a Bregman divergence D  X   X   X  as defined in Section we define C  X  a b = D  X  a (  X   X  )  X  1 ( b ) . The resulting cost function is given by:
Let y i = (  X   X  )  X  1 ( V i u i ) with represent the vector of predicted ratings of user i . Using Legendre duality one recognizes that equa-tion (4) quantifies the gap in the Fenchel-Young inequality where  X  is the Legendre conjugate of  X  . Although this clarifies the issue of separate convexity in r i and y i , the conditions under which joint convexity is obtained are not obvious.
Joint convexity, if ensured, guarantees global minimum even for a coordinate-wise minimization because our constraint set is a prod-uct of convex sets. This important question is resolved in the fol-lowing theorem from [2] (Theorem 2).

T HEOREM 1. The gap in the Fenchel-Young inequality:  X  ( y )+  X  ( x )  X  X  x , w  X  for any twice differentiable strictly convex  X  (  X  ) with a differentiable conjugate (  X  )  X  (  X  ) =  X  (  X  ) is jointly convex if and only if  X  ( x ) = c || x || 2 for all c &gt; 0 .

We note that since we maintain explicit representation of the fac-tor matrices U and V , the optimization problem is no longer convex with respect to these factors. However, the following proposition from [1] (Proposition 5) shows conditions under which all local minima in terms of U and V are global, and correspond to the same regression matrix  X  Y = UV &gt; .

P ROPOSITION 1. Let G be a twice differentiable convex func-tion on matrices of size p  X  q with compact level sets. Let d &gt; 1 and ( U,V )  X  R p  X  d  X  R q  X  d a local optimum of the function H : R p  X  d  X  R q  X  d 7 X  R defined by H ( U,V ) = G ( UV &gt; is U such that  X  H ( U,V ) = 0 and the Hessian of H at ( U,V ) is positive semi-definite. If U or V is rank deficient, then N = UV is a global optimum of G , that is  X  G ( N ) = 0 .
 Combining Theorem 1 and Proposition 1, it follows that under mild conditions, R-MF using squared loss recovers a unique solution. Proposition 1 applied to other Bregman divergences can only pro-vide local optimality guarantees.
For any sorted vector r , finding the permutation of y that mini-mizes D  X  r y shows up as a sub-problem in our formulation that needs to be solved in an inner loop. Thus solving it efficiently is critical and this is yet another instance where Bregman divergences are very useful.

For an arbitrary divergence function the search over the optimal permutation is a non-linear assignment problem that can be solved only by exhaustive enumeration. For an arbitrary separable diver-gence the optimal permutation may be found by solving a linear assignment problem, which is an integer linear program and hence also expensive to solve (especially in an inner loop, as required in our algorithm). 3
On the other hand, if  X  (  X  ) is IS, the solution is remarkably sim-ple, as shown in Lemma 5 where r 1 r 2 denotes a vector in components r 1 and r 2 .
The Fenchel-Young inequality:
One of our baseline tools, C OFI R ANK -NDCG [25] does need to solve such an assignment problem in each iteration. Speed com-parisons are included in Section 4. L EMMA 5. If r 1  X  r 2 and y 1  X  y 2 and  X  (  X  ) is IS, then: Lemma 5 is trivially extended by induction to the vector case.
We safeguard against overfitting by adding squared Frobenius norm regularization for the matrices U and V. Note that the cost function (4) is not invariant to scale. For example squared Eu-clidean distance and KL divergence are homogeneous functions of degree 2 and 1 respectively. Thus the cost can be reduced just by scaling its arguments down, without actually learning the task. To remedy this, we restrict the r i  X  X  from shrinking below a predefined size. This is accomplished by constraining r i  X  X  to lie in an appro-priate closed convex set not only separated from the origin but also to a set of vectors whose adjacent components are separated from each other. For the latter we use the set  X   X  as defined before. After these modifications we obtain the final formulation 4 as:
In our formulation we assume that the true movie ratings are to-tally ordered, though the finer ordering between similar items is not visible to the ranking algorithm. Let P j = { P partition of the index set of V j , such that all items in P the same training score. (for example the set of all movies rated 5 by a particular user). The sets V j effectively get partitioned fur-ther into { P jk } k j k =1 . Though the ratings provide an order between movies from any two different sets P jk and P jl , the order within any set P jk remains unknown. To retrieve the total order we intro-duce a block-diagonally restricted permutation matrix P j permute indices in each P jk independently. Since the items in P are not equivalent they are available for re-ordering as long as that minimizes the cost (5). IS Bregman divergences have the special property that sorting minimizes the divergence over all permuta-tions (Lemma 5). Thus update (6) can be accomplished by sorting.
The combined algorithm for R-MF is given in Fig. 2. We cy-cle through all three update steps until convergence. The update (7) can be solved using any of a number of constrained convex optimization algorithms. We implemented (7) using the exponenti-ated gradient (EG) algorithm [12], a proximal gradient method for simplex constrained vectors. EG requires simple multiplicative up-dates using the function gradient followed by a normalization step. Update (6) is a parallel sort. The user and item factors (8) can be updated using any number of matrix factorization algorithms [22].
To apply the results of Proposition 1 to the regularized case, we will require the variational representation of the matrix trace norm k X k  X  under similar rank deficient conditions for the mapping be-tween the cost function G ( N ) and H ( U,V ) : Table 2: Data sizes after preprocessing to remove users with less than 30 ratings
We evaluated R-MF on four publicly available recommendation datasets:
Data preprocessing: First, we removed all users with less than 30 ratings. Each of the evaluated datasets contains the time-stamp of the user rating. For each user, we selected the last third of the ratings sorted by user-time as the test set, the middle third as the validation set, and any left over ratings were selected as the training set. This partitioning scheme ensures that each user has at least 10 ratings in the validation and test sets so we are able to compute the top-k performance metrics for at least 10 retrieved items per user. Details of the dataset sizes after preprocessing are provided in table Table 2.

We experimented with R-MF using squared loss motivated by the optimization theoretic guarantees discussed in Section 2.3. Fur-ther experiments with other Bregman divergences will be imple-mented in an extended version of this manuscript. We also eval-uated the performance of C OFI R ANK -NDCG [25] and C OFI ordinal [26] as baseline models using the C++ implementation pro-vided by the authors 8 . For all models, we selected the regulariza-
The models are scored using metrics commonly used for eval-uating ranking models [18]. We plot normalized discounted cu-mulative gain (NDCG) and precision in Fig. 3 while varying the number of retrieved items k = { 1 ,... 10 } . Further results with movielens.umn.edu www.grouplens.org/node/73 www.flixster.com available at www.cofirank.org Table 3: Expected reciprocal return (ERR) results on rec-ommender system datasets.  X  X  X  represents datasets where C
OFI R ANK -NDCG did not finish after running for more than seven days.
 other ranking metrics were also computed including expected re-ciprocal return ( ERR ) in Table 3, mean average precision ( MAP ) in Table 4, and NDCG of the full list in Table 5. For the precision and MAP metrics, a movie was labelled as relevant if its rating was greater than 4.

Our experiments show that R-MF improves ranking performance over C OFI R ANK -NDCG and C OFI R ANK -ordinal as measured by all the metrics that we computed. We note that C OFI [26] has been shown to outperform several state of the art mod-els including maximum margin matrix factorization [23] and Gaus-sian process ordinal regression [7]. The results were even more striking when we compared the NDCG performance of R-MF to C
OFI R ANK -NDCG, though the algorithm is specifically designed to optimize NDCG. Our results confirm the observation of other authors, including the authors of C OFI R ANK that C OFI seems to out-perform C OFI R ANK -NDCG. It is unclear why this is the case. We found that C OFI R ANK to be susceptible to overfitting when we compared the test performance with the training NDCG values. This might explain some of the performance gap. Our re-sults were qualitatively very similar for rank 10 and rank 20 mod-els.

R-MF was implemented in Python/Numpy. Cython was used to implement the parallel retargeting updates (7) and parallel sorting (6). The matrix factorization step (8) was solved using alternating least squares. The code was executed on a 2.4GHz quad-core Intel Xeon processor. Timing on the larger movie datasets are shown in Table 6 and compared to C OFI R ANK . We found that R-MF exhibited much better scaling behavior as the size data increased. We suspect that the large observed runtimes of C OFI R ANK -NDCG are due to the cost of the linear assignment problem that must be solved for each user at every iteration. The linear assignment can be solved using a number of efficient algorithms [16], but the computational requirements scale cubically with the number of ratings per user. R-MF is able to avoid solving this linear assignment problem as we prove that sorting recovers the optimal ordering (Section 2.4).
Our experience suggests that the speed of the method can be sig-nificantly improved by (i) implementation using a faster language e.g c++ (ii) matrix factorization using stochastic gradient descent or other scalable solvers (iii) interleaving the factorization and retar-geting steps, as the matrix factorization is the most computationally intensive portion of the algorithm. We leave such implementation improvements to future work.
 Table 4: Mean absolute precision (MAP) results on recom-mender system datasets. Relevant ratings have a value greater than 4.  X  X  X  represents datasets where C OFI R ANK -NDCG did not finish after running for more than seven days.
 Table 5: NDCG Results on recommender system datasets.  X  X  X  represents datasets where C OFI R ANK -NDCG did not finish af-ter running for more than seven days.
 Table 6: Average training time (mins) on the larger rec-ommender system datasets.  X  X  X  represents datasets where C
OFI R ANK -NDCG did not finish after running for more than seven days. The Movielens 10M (rank 20) result of C OFI R ANK NDCG is based on the average runtime for a subset of the pa-rameters, as the full parameter sweep did not finish running. Rank 10 121.025 329.889 41.641 Rank 20 259.051 340.569 30.276 Rank 10 396.900 2912.179 1391.249 Rank 20 663.889 7609.683 820.579 Rank 10 1657.314  X  2459.418
Rank 20 2203.207  X  897.989 In this paper, we proposed retargeted matrix factorization (R-MF), a novel approach for learning the user-wise ranking of items for collaborative filtering. Retargeted matrix factorization improves Gaussian process ordinal regression [7]. the ranking performance by searching for a monotonic transfor-mation of the ratings that results in a better fit while preserving their ranked order. R-MF was compared to the ranking and ordi-nal regression variants of C OFI R ANK and evaluated on benchmark movie recommendation datasets. Our results show that retargeted matrix factorization results in superior ranking performance com-pared to C OFI R ANK , though C OFI R ANK is specifically designed to optimize NDCG. Our results also highlight the scalability of R-MF in comparison to C OFI R ANK . We plan to explore scalability and implementation concerns in more detail in future work. Al-though the unique solution is only guaranteed for squared loss, the performance results presented in [2] provide some motivation for experimenting with other Bregman divergences in future work.
Authors acknowledge support from NSF grant IIS 1016614 [1] J. Abernethy, F. Bach, T. Evgeniou, and J.-P. Vert. A new [2] S. Acharyya, O. Koyejo, and J. Ghosh. Learning to rank with [3] S. Balakrishnan and S. Chopra. Collaborative ranking. In [4] A. Banerjee, S. Merugu, I. Dhillon, and J. Ghosh. Clustering [5] J. Basilico and T. Hofmann. Unifying collaborative and [6] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to [7] W. Chu and Z. Ghahramani. Gaussian processes for ordinal [8] K. Crammer and Y. Singer. Pranking with ranking. In [9] P. Cremonesi, Y. Koren, and R. Turrin. Performance of [10] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efficient [11] M. Jamali and M. Ester. A matrix factorization technique [12] J. Kivinen and M. K. Warmuth. Exponentiated gradient [13] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization [14] Y. Koren and J. Sill. Ordrec: an ordinal model for predicting [15] O. Koyejo and J. Ghosh. A kernel-based approach to [16] H. Kuhn. The Hungarian method for the assignment problem. [17] N. N. Liu, M. Zhao, and Q. Yang. Probabilistic latent [18] T. Liu. Learning to Rank for Information Retrieval . [19] P. Ravikumar, A. Tewari, and E. Yang. On NDCG [20] R. T. Rockafellar. Convex Analysis (Princeton Landmarks in [21] Y. Shi, M. Larson, and A. Hanjalic. List-wise learning to [22] A. P. Singh and G. J. Gordon. A unified view of matrix [23] N. Srebro, J. D. M. Rennie, and T. S. Jaakola.
 [24] H. Steck. Training and testing of recommender systems on [25] M. Weimer, A. Karatzoglou, Q. V. Le, and A. Smola. [26] M. Weimer, A. Karatzoglou, and A. J. Smola. Improving
