 XML has become a popular method of data representation both on the web and in databases in recent years. One of the reasons for the popularity of XML has been its ability to encode structural information about data records. However, this structural characteristic of data sets also makes it a chal-lenging problem for a variety of data mining problems. One such problem is that of clustering, in which the structural aspects of the data result in a high implicit dimensionality of the data representation. As a result, it becomes more dif-ficult to cluster the data in a meaningful way. In this paper, we propose an effective clustering algorithm for XML data which uses substructures of the documents in order to gain insights about the important underlying structures. We pro-pose new ways of using multiple sub-structural information in XML documents to evaluate the quality of intermediate cluster solutions, and guide the algorithms to a final solu-tion which reflects the true structural behavior in individual partitions. We test the algorithm on a variety of real and synthetic data sets.  X 
The research of the authors from Tsinghua University was partly supported by the Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry of China, National Basic Research Program of China under grant number 2006CB303103, Basic Research Foundation of Tsinghua National Laboratory for Informa-tion Science and Technology (TNList), Program for Selected Talents (i.e.,  X  X u Gan Ren Cai X ) at Tsinghua University, and National Natural Science Foundation of China under Grant No. 60573061 and 60573094.
 Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00. H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms XML, clustering The clustering problem is defined as follows. For a database D of records, we would like to segment the data into groups of objects which are similar to one another. The similarity between the objects is defined with respect to some user-defined objective function. The clustering problem is widely known in the literature because of its use in a large num-ber of applications. A number of interesting methods for clustering are discussed in [7, 11, 17]. The wide use of the web and the flexibility of the XML representation has pop-ularized the use of XML documents. The semi-structured nature of XML document definitions allows the modelling of a wide variety of databases as XML documents. The textual nature of XML documents allows the use of standard Infor-mation Retrieval methods on XML representations. Other alternatives include the use of a flattened multi-dimensional representation of the data in order to perform the clustering. However, these methods ignore the structural information in the data, which often turns out to be crucial for the mining process [3, 15, 16].

The problem of structural clustering of XML documents is a challenging task because most known clustering algo-rithms cannot be generalized easily to take into account the structural behavior of XML documents. There are several reasons for this: (1) Many clustering algorithms typically require the computation of similarity between different ob-jects as a subroutine. The problem of computing similar-ity between XML documents has itself been known to be a difficult research problem. (2) Even if the computation of similarity can be performed effectively, the use of such func -tions is often not likely to lead to meaningful clusters. Thi s is because much of the clustering information is encoded in substructures of the XML documents. This is somewhat analogous to the problem of projected clustering [1, 2] in which useful clustering information is encoded in subsets o f dimensions. In the case of structural data, the problem is even more acute because a very high implicit dimensionality is encoded in the structural behavior of the documents. (3) Many clustering algorithms require the use of intermediate clustering representatives to perform the clustering task ef-fectively. The structural representation of XML documents makes this task much more difficult.
 This paper presents a structural method for clustering XML data. In this case, the similarity within a cluster is defined in terms of the containment of particular frequent substructures which occur frequently in that particular se g-ment of the data. Thus, similarity is quantified in terms of containment of frequent substructures within a particu-lar segment. These substructures are those analogous to the projected dimensions used in subspace clustering [1, 2] . As we shall see, such a substructure containment definition helps us define clusters in a very robust way, since the clus-ters are defined not by individual substructures, but by sets of substructures . We further note that while our methods have been developed for the case of XML data, they are ap-plicable to a variety of data domains such as biological data which use structural information in the representation.
This paper is organized as follows. In Section 2, we will discuss the related work to XML data clustering. In Section 3, we present the basic algorithm for clustering of XML doc-uments. Section 4 discusses some algorithm implementation issues and optimization techniques, mainly focusing on ef-ficient approaches for mining the frequent substructures of the XML documents. This approach concentrates on a novel use of a sequential pattern representation of a traversal of the tree structure. The empirical results are presented in section 5. Section 6 contains the conclusions and summary.
One of the earliest work on clustering tree structured data is the XClust algorithm [8], which was designed to cluster XML schemas in order for efficient integration of large num-bers of Document Type Definitions (DTDs) of XML sources. It adopts the agglomerative hierarchical clustering metho d which starts with clusters of single DTDs and gradually merges the two most similar clusters into one larger cluster . The similarity between two DTDs is based on their element similarity, which can be computed according to the seman-tics, structure, and context information of the elements in the corresponding DTDs.

One of the shortcomings of the XClust algorithm is that it does not make full use of the structure information of the DTDs, which is quite important in the context of cluster-ing tree-like structures. Two recent approaches of cluster -ing tree structured data are also based on the hierarchical clustering method [10, 5]. S-GRACE is a ROCK-like [6] hierarchical clustering algorithm [10]. In [10], an XML doc -ument is converted to a structure graph (or s-graph), and the distance between two XML documents is defined ac-cording to the number of the common element-subelement relationships, which can capture better structural simila rity relationships than the tree edit distance in some cases [10] . In [5], the XML documents are modeled as rooted ordered labelled trees, and a framework for clustering XML docu-ments by using structural summaries of trees is presented. The aim is to improve algorithmic efficiency without com-promising cluster quality.

In contrast to the previous work, our XProj algorithm employs a projection based structural approach and uses a set of frequent substructures as the representative with re -spect to an intermediate cluster of XML documents. As a frequent substructure preserves more structural informat ion than the simple element-subelement relationships [10], th e use of multiple frequent substructures as the representati ve makes structural similarity (and self-similarity) propos ed for XProj algorithm very robust and accurate. Furthermore, multiple substructural portions of the document collectio n are used to in order to associate a representative set with a given cluster, rather than a single representative. To make the structural similarity more comparable among different sets of representatives and the similarity calculation mor e efficient, the representatives only include the frequent sub -structures of size l . The idea behind this design is analogous to the projection-based subspace clustering [1, 2].
To speed up the frequent substructure representative min-ing, XProj adopts a set of high quality approximate struc-tures, that is, sequences of tree edges. The selection of rep re-sentative substructures is based on the sequential coverin g paradigm, which can be leveraged for rule based classifi-cation. In addition, recent advances in frequent sequence mining [9, 12, 14] can be leveraged in order to perform ap-proximate substructure mining in an efficient way. In this paper, we will utilize these methodologies in order to im-prove the efficiency of the process.
We model XML documents as ordered, labelled, rooted trees. We do not distinguish between attributes and ele-ments of an XML document, since both are mapped to the label set. The basic XML clustering algorithm is imple-mented as a partition based algorithm which tries to con-struct partitions that maximize the structural commonal-ities among the documents within a partition. The con-struction of clusters of XML documents presents a number of unique challenges which are not encountered for the case of other kinds of multi-dimensional data sets. This is be-cause most clustering algorithms require us to construct th e following measures on multi-dimensional records: In order to achieve these goals, we design an XML clus-tering algorithm which works with frequent substructures of the underlying documents. These frequent substructures ar e utilized to measure the similarity between particular grou ps of documents. Thus, a group of documents is defined to be most similar, when it results in a large number of similar substructures at a specified support level. We note that the use of frequent substructures in order to define similarity among documents is analogous to the concept of projected clustering in multi-dimensional data. As in the case of pro-jected clustering [1, 2], we are using (structural) project ions of the space in order to define similarity.

In the projected XML clustering algorithm, instead of us-ing individual XML documents as representatives for par-titions, we use sets of substructures of the documents as possible representatives. A set S of substructures is said to be a representative of a given collection, if each structure in it appears as a frequent substructure in that collection. In general, we would like to construct clusters of documents which are similar enough so that the underlying frequent structures cover a significant fraction of the tree nodes in the collection. In order to understand this way of defin-ing similarity, let us define the concept of coverage of XML documents. First we define the concept of substructures.
Definition 1. A substructure T , of a rooted, ordered, la-belled tree, T  X  , is an undirected, connected, labelled, acyclic graph, whose vertices and edges can be one-to-one mapped to a subset of vertices and edges of T  X  that preserves the ver-tex labels and ancestor-descendant relationships among th e corresponding vertices.
 Definition 2. Let T be a substructure of the document R . A substructural alignment of T to R is defined to be a correspondence from each node in T to a node in R , which define the substructural relationship of T to R . We note that there can be more than one possible substruc-tural alignment of T to the document R . Also, we note that even though a node in T corresponds to each node in R , the reverse may not be true.

Definition 3. A structure T is defined to be frequent in collection of XML documents R at a user defined minimum support, min sup, if it occurs as a substructure of at least min sup fraction of the documents in the collection R .
Definition 4. A node x in the document R is said to be uncovered by structure T , if a substructural alignment from T to R cannot be found so that node x aligns with some node in T .
 This definition can now be generalized to a set of structures as opposed to a single structure. This generalization is de-fined as follows.

Definition 5. A node x in the document R is said to be uncovered by the set of structures T = { T 1 . . . T k substructural alignment from any structure T i to R cannot be found such that node x aligns with some node in T i . Clearly, if a node in a document remains uncovered by the frequent structures in a collection, this is not very good fr om a clustering point of view. This provides us a natural way to define the similarity of the documents in a collection to a set of structures. The similarity of a document to a set of structures in a collection is defined as the fraction of nodes in the document which are covered by any structure in the collection.

Definition 6. The structural similarity  X  ( R, T ) of a doc-ument R to a structural collection T = { T 1 . . . T k } is defined to be the fraction of nodes in R which are covered by some structure in T .

We note that we use the fraction of nodes which are cov-ered by the structural collection, since it normalizes for t he total number of nodes in the document. We can easily gener-alize this definition to similarity between sets of documents and sets of structures by averaging the structural similari ty over the different documents. Therefore, we have:
Definition 7. The structural similarity  X ( R , T ) of the set of documents R = { R 1 . . . R j } to the set of frequent structures T = { T 1 . . . T k } is defined as the average struc-tural similarity over the different documents in R to T . Therefore, we have: This lays the ground for us to define the frequent sub-structural self-similarity of a document collection.

Definition 8. For a given level of user defined minimum support denoted by min sup, the frequent sub-structural self-similarity of a document collection R at level l is defined as the structural similarity  X ( R , F l ) , where F l are the set of frequent substructures of R with l nodes.
 We note that the frequent sub-structural self-similarity o f a document collection provides a good understanding of the level of homogeneity in the document collection from a sub-structural point of view. When a collection contains noisy and random documents, it will not be possible to mine fre-quent structures which cover a significant fraction of nodes in the collection. Consequently, the self-structural simi lar-ity index is also likely to be low. On the other hand, for a homogeneous collection, a very high percentage of nodes are likely to be covered by frequent structures. Therefore, the frequent substructural self-similarity can be used as a sur ro-gate for the self-similarity behavior of collection at the s truc-tural level. Therefore, our aim is to construct the partitio n of the document collection in such a way that the frequent substructural set from the collection covers as many nodes as possible. An interesting observation is that we have used only frequent structures of size l in order to measure the structural self-similarity. This is because structures of size l cannot be fairly compared to structures of size ( l +1) for the purpose of coverage. For example, if we allow substructures of any size to be present in the set of frequent structures, then the structures containing only 1 node would lead to a very high level of coverage. Thus, choosing the rank of the substructures is analogous to choosing the dimensionality of the projection in the case of projected clustering.
The pseudo-code for clustering of XML documents is il-lustrated in Figure 1. The primary approach is to use a sub-structural modification of a partition based approach i n which the clusters of documents are built around groups Algorithm XProj(Document Set: D , Minimum Support: min sup , Structural Size: l , NumClusters: k ) begin
Initialize representative sets S 1 . . . S k ; /*See Sect. 4.3*/ while ( convergencecriterion =false) begin
Assign each document D  X  D to one of the sets in
Compute the freq. substructures of size l from each if ( |M i |  X  min sup )  X  1 end; end Figure 1: The Sub-structural Clustering Algorithm (High Level Description) of representative sub-structures. Thus, instead of a sin-gle representative of a partition-based algorithm, we use a substructural set representative for the structural cluster-ing algorithm. Initially, the document set D is randomly divided into k partitions with equal size, and the sets of sub-structure representatives are generated by mining fre -quent sub-structures of size l from these partitions. Sim-ilarly, in each iteration, the sub-structural representat ives (of a particular size, and a particular support level) of a given partition are the frequent structures from that parti -tion. These structural representatives are used to partiti on the document collection and vice-versa. We note that this can be a potentially expensive operation because of the de-termination of frequent substructures; in the next section , we will illustrate an interesting way to speed it up. In or-der to actually partition the document collection, we calcu -late the number of nodes in a document which are covered by each substructural set representative. A larger cover-age corresponds to a greater level of similarity. The aim of this approach is that the algorithm will determine the most important localized sub-structures over time. This is analogous to the projected clustering approach which deter -mines the most important localized projections over time. Once the partitions have been computed, we use them to re-compute the representative sets. These re-computed rep -resentative sets are defined as the frequent sub-structures of size l from each partition. Thus, the representative set S is defined as the substructural set from the partition M i which has size l , and which has absolute support no less than ( |M i |  X  min sup ). Thus, the newly defined representative set S i also corresponds to the local structures which are de-fined from the partition M i . Note that if the partition M contains too few documents such that ( |M i | X  min sup ) &lt; 1, the representative set S i remains unchanged.

Another interesting observation is that the similarity fun c-tion between a document and a given representative set is defined by the number of nodes in the document which are covered by that set. This makes the similarity function more sensitive to the underlying projections in the docu-ment structures. This leads to more robust similarity cal-culations in most circumstances. In order to ensure ter-mination, we need to design a convergence criterion. One useful criterion is based on the increase of the average sub-structural self-similarity over the k partitions of documents. Let the partitions of documents with respect to the current iteration be M 1 . . . M k , and their corresponding frequent sub-structures of size l be S 1 . . . S k respectively. Then, the average sub-structural self-similarity at the end of the cu r-rent iteration is  X  = P k i =1  X ( M i , S i ) /k . Similarly, let the average sub-structural self-similarity at the end of the th e previous iteration be  X   X  . In the beginning of the next it-eration, the algorithm computes the increase of the aver-age sub-structural self-similarity,  X   X   X   X  , and checks if it is smaller than a user-specified threshold  X  . If not, the al-gorithm proceeds with another iteration. Otherwise, the algorithm terminates. In addition, an upper bound on the number of iterations is imposed. This is done in order to ef-fectively handle situations in which the threshold  X  is chosen to be too small.
A key issue is the frequent substructure mining in each it-eration, which can make the procedure rather expensive. In this section, we will describe the process of efficiently findi ng frequent substructure representatives by using approxima te mining techniques.
In the sub-structural clustering algorithm shown in Figure 1, there are two main time-consuming operations. One is the mining of the representative frequent substructures of siz e l from each XML document set. Another is the computation of the alignments of a set of representative substructures i n a given XML document. This is partly due to the high com-putational complexity of the graph isomorphism problem. Because our goal is to cluster XML documents, we may not need the exact algorithm to mine frequent substructures or compute substructural alignments. One approach for im-proving the algorithm efficiency is to use approximate data representation in order to remove or simplify the graph iso-morphism problem, while maintaining as much structural relationship among tree nodes as possible.

One simple way of doing this is to use the set of node labels to represent a sub-structure and use a set of frequent label sets to approximate the corresponding set of frequent sub-structures. Although this method is fast because of the pres -ence of many efficient frequent itemset mining algorithms, it no longer preserves any structural information and cannot achieve good clustering quality. In order to alleviate this problem, the sequence of a pre-order depth-first traversal of the tree edges is adopted as the compromise between the complex tree structure and its corresponding simple node label set, where an edge is denoted by a pair of node la-bels. The advantage of the edge sequence representation is that it preserves both the parent-child relationship and th e ordering among the sibling nodes. For example, the edge sequence representations of the three sub-structures in Fi g-ure 2 are h AB, BC, CE, AB, BD i , h AB, BC, BD, BD i , and h AB, BC, CE, BD, AB, BD i , respectively. Furthermore, the use of the sequence representation also guarantees the abil ity to use efficient data mining algorithms.

The pre-order depth-first traversal of a tree structure as-sures that a parent node is always visited prior to its child nodes and a left sibling node is always visited prior to its right sibling nodes. Based on this edge traversal ordering, the following property holds.

Property 1. (Subsequence relationship) If a tree T 1 is a subtree of another tree T 2 , the edge sequence representation of T 1 must be a subsequence of the edge sequence represen-tation of T 2 . 2
We note that Property 1 connects the sequence relation-ship to the substructural relationship. The property indi-cates that if a substructure is frequent, its corresponding edge sequence must be frequent too. For example, the tree structure shown in Figure 2(a) is a substructure of the tree structure shown in Figure 2(c). Suppose the minimum sup-port is 2, the tree shown in Figure 2(a) is frequent. And since h AB, BC, CE, AB, BD i  X  h AB, BC, CE, BD, AB, BD i , edge sequence h AB, BC, CE, AB, BD i is also frequent. Note there may exist a false mapping between two tree struc-tures and their corresponding edge sequences, where the false mapping means although one tree is not a fully con-nected substructure of another tree, their edge sequences have subsequence relationship. For example, the tree shown in Figure 2(b) is not a substructure of the tree shown in Figure 2(c). However, there is a subsequence relationship between their edge sequence representations. For example, h AB, BC, BD, BD i  X  h AB , BC , CE, BD , AB, BD i holds. The dark edges in Figure 2(c) correspond to the edge se-quence of h AB, BC, BD, BD i . Due to the existence of po-tential false mappings , the support of an edge sequence may be higher than that of the corresponding tree structure.
One way to reduce the false mapping problem is to add some constraints during the process of mining frequent se-quences. One such constraint is that all sibling nodes should have the same parent node. For example, the last three adja-cent edges in sequence h AB, BC, BD, BD i indicate that the three child nodes with labels C , D , and D have the same parent node with a label B . However, in sequence h AB , BC , CE, BD , AB, BD i , the first BD edge does not share the same parent node with the second BD edge. Thus the align-ment of h AB, BC, BD, BD i in h AB , BC , CE, BD , AB, BD i is not a valid one. A simpler solution for the false mapping problem is to allow it. Since our goal is to cluster XML docu-ments, and the edge sequence partly preserves the structural information, the false mapping of a subsequence relationship still reflects a kind of similarity between the two correspond-ing structures. Therefore, the advantages of adding such constraints remains unclear from an effectiveness point of view. While we have mentioned a possible constraint-based solution to the false mapping problem for other data mining problems, we chose not to use it for the clustering problem. It is possible to adapt a number of efficient sequential pat-tern mining algorithms to mine frequent edge sequences of size l  X  1 (corresponding to l tree nodes). In our XProj algo-rithm, we revise one of the latest sequential pattern mining algorithms, BIDE [14], to mine frequent sequences of size l  X  1. BIDE is a projection-based algorithm, which mines fre-quent closed sequences with respect to a prefix by building and scanning its projected database. As we are only inter-ested in the frequent sequences of size l  X  1, some enhance-ments can be made to the BIDE algorithm. For example, some short projected sequences in the sequence databases cannot be used to count frequent sequences of size l  X  1, and can therefore be safely pruned from the projected sequence database. Furthermore, once the size of the current prefix sequence reaches l  X  1, we do not grow it any more. Note that the revised BIDE algorithm stops growing the current prefix sequence once it reaches a size of l  X  1, and hence it will not be subsumed by its super-sequences even if it is non-closed. In addition, we turn off the sequence closure checking and search space pruning. Thus, the revised BIDE algorithm can mine the complete set of frequent sequences of size l  X  1. For more details of the BIDE algorithm, we refer to [14].
There are several other potential forms of sequence repre-sentation of a tree structure. A simple variant of the edge sequence representation is the node label sequence. Because it does not maintain the parent-child relationship, it pre-serves too little structural information, and may not work well for XML clustering. A typical example is shown in Figure 3(a)-(c), in which we expect that the structural simi-larity between the two trees in Figure 3(b)-(c) is larger than that between the two trees of Figure 3(a)-(b). However, if we examine their node label sequences (i.e., h B, C, D, E i , h F, C, D, E i , and h F, C, D, G i ), it is difficult to differentiate the two similarities, because each pair of them has a com-mon subsequence of size 3. Another example is shown in Figure 3(d)-(e). Figure 3(d) and Figure 3(e) are two dif-ferent tree structures, but they have identical node label sequences, that is, h A, B, C, D, E i . Another extreme rep-resentation is the path sequence. In the pre-order depth-first traversal of a tree structure, each tree node is repre-sented by the path from the root node to itself. For ex-ample, the path sequences of the two trees shown in Fig-ure 3(d) and Figure 3(f), are h A, AB, ABC, ABD, ABE i and h F, F B, F BC, F BD, F BE i , respectively. This exam-ple illustrates that the path sequence representation enco des more differentiating structural information.
Given a document partition M i (1  X  i  X  k ), its corre-sponding seed set S i may contain a large number of frequent sub-structures of size l . Although we have adopted the se-quence to approximate a tree structure, the computation of the similarity function between a document and the seed set S i is still quite costly. It will be desirable to select a small number of high quality substructures (or sequences), and only use this set of representative sub-structures to compu te the similarity function and the average sub-structure self -similarity over the k partitions of the documents. We note that the support of a frequent sub-structure with respect to a given partition M i usually indicates the degree of its local-ity to M i . Thus, a good representative sub-structure should have a support as high as possible. One way of achieving this goal is to simply select the top-K most frequent sub-structures of size l as the corresponding seed set S i .
One problem with the set of the top-K most frequent sub-structures of size l is that they may overlap a lot with each other, and thus may not cover all the documents in the corresponding partition. A solution to this problem is to use the sequential covering paradigm to select a number of frequent sub-structures which cover the documents in the partition. Starting from the sub-structure with the highes t support, the documents covered by this sub-structure are removed from the partition and this sub-structure is added to the seed set. Then, the next sub-structure is retrieved, i f it covers some remaining documents in the partition. The documents covered by this new sub-structure are removed from the partition, and the corresponding sub-structure is treated as a new representative sub-structure of the seed set. This procedure is repeated until all the documents in the partition are covered or the number of selected sub-structures reaches a user-specified threshold.
The XProj algorithm described in Section 3 initializes the representative sets by randomly dividing the XML database into k partitions and mining frequent substructures of size l for each partition, where k is the number of clusters. We refer to this kind of initialization method as Randomized Initialization . One problem with this method is that it is very hard to find some highly frequent substructures from the randomly generated partitions. Thus, it tends to pro-duce low quality clusters in the following iterations or nee ds too many iterations to converge.

In order to generate more robust sets of representative substructures, one method is to directly compute k high-quality frequent sequences of size l -1 from the original database, and use each one of them as a representative substructure for one cluster. This results in a robust initialization. The pr ob-lem is in choosing the k representative frequent sequences of size l -1. Our criteria is that the selected k representative sequences should be frequent and distinctive enough from each other in order to cover as many XML documents as possible. To achieve this goal, we adopt a variant of the se-quential covering paradigm. We first use the revised BIDE algorithm to find the complete set of frequent sequences of size l -1 from the original database. We then choose one frequent sequence which covers the greatest number of in-put XML documents and remove the input XML documents covered by this selected sequence from the database. Sub-sequently, we choose another frequent sequence which can cover the remaining input XML documents the most and remove the corresponding covered input XML documents from the database. This procedure continues until k repre-sentative frequent sequences have been selected, which wil l be used to create the set of initialized seeds for the algo-rithm. One advantage of this approach is that it tends to create highly non-overlapping clusters of documents, and represents the entire input space fairly well for an initial iza-tion approach. We refer to this method as Coverage-based Initialization .

Note that each initial representative set contains only one frequent sequence, and all the initial representative sequ ences have the same length. Given an XML document, R , it is pos-sible that R supports several initial representative sequences at the same time, and the similarity between R and any ini-tial representative supported by R will equal the similarity between R and another initial seed supported by R . As a result, we need a tie-breaking rule in order to determine which partition R should be assigned to. In XProj, we sim-ply choose the initial seed with the lowest support among all the R -supported seed sequences. As our experiments will demonstrate, this heuristic works well in practice. Outlier Documents. We note that the tree approximation method discussed in Section 4.1 converts an XML document to a sequence of tree edges. A set of frequent sequences of size l -1 is used as a representative for a given partition of XML documents. However, in some cases, the length of a se-quence representation of an XML document may be shorter than l -1. If this happens, it is hard to determine the parti-tion to which the corresponding XML document should be assigned. In XProj algorithm, we will temporarily treat it as an outlier, which will not participate in the iterations o f partitioning. After XProj finds a semi-final set of k clusters, we can compute the similarity between the outlier and each cluster of XML documents and assign it to the most similar cluster. If desirable, some documents with very low similar -ity to all clusters can remain as outliers. In the following, we will define the similarity between an outlier and a cluster of XML documents.

Consider an outlier XML document, denoted by R o , and a cluster of XML documents, R = { R 1 . . . R m } . Let | R note the number of edges in the sequence representation of XML document R i , while | R o T R i | is the number of com-mon edges of the sequence representations of R o and R i . The similarity between R o and R ,  X ( R o , R ), is defined as follows.
 Highly Frequent sequences. If the XML documents to be clustered are homogenous, their corresponding sequence s are very similar to each other even when they come from different classes. In this case, the frequent sequence minin g algorithm will generate many highly frequent subsequences . From the clustering point of view, these subsequences almos t appear in each XML document, and are not differentiable in terms of their cluster membership. As a result, the highly frequent subsequences are not useful for the clustering tas k and can be removed from the clustering process. In XProj, a user can specify a maximum support threshold, max sup , in order to not generate the sequences with very high support.
We compared XProj with some recently developed XML clustering algorithms. We evaluated various aspects of the algorithm design, analyzed the algorithm sensitivity with several important parameters, and tested scalability. The results will show that the XProj algorithm is an extremely effective algorithm which retains a high level of scalabilit y.
We implemented the Xproj algorithm using Microsoft Vi-sual C++ 6.0 and performed a thorough experimental study on a Windows machine with AMD Athlon 2000+ and 768MB memory installed. We used both real and synthetic data sets to test the algorithm. These data sets are described below. Synthetic Data Sets. We used the same sets of synthetic XML documents which were generated by the XML gener-ator provided by the author of [5]. The first two data sets, denoted by DB1000DTD10MR3 and DB1000DTD10MR6, both contain 1000 XML documents and were generated from 10 different real DTDs as shown in Figure 6, each of which was used to generate 100 documents. The parameter MaxRe-peats, which determines the maximum number of times a node will appear as a child of its parent node, was set for DB1000DTD10MR3 and DB1000DTD10MR6 at 3 and 6 re-spectively. The actual number of repeats generated is a random value between 0 and MaxRepeats. The parameter NumLevels that determines the maximum number of tree levels was set to 7 as in [5].

The third data set, DB300DTD3MR6, contained 300 syn-thetic XML documents generated from three similar DTDs as shown in Figure 7. Similarly, each DTD was used to gen-erate 100 documents. The parameter MaxRepeats was set at 6 for this dataset. Note the three DTDs in Figure 7 are quite similar to each other, and this makes the clustering process for this collection a quite challenging one. Real Data Set. The real data set we used is SIGMOD Record, which can be downloaded from http://www.acm.org/ sigmod/record/xml . It contains 140 XML documents cor-responding to two DTDs, IndexTermsPage.dtd and Ordi-naryIssuePage.dtd(70 XML documents for each DTD). It is denoted by SIGMOD140DTD2.

As in [5], we used two popular information retrieval met-rics, precision P R and recall R , to evaluate the clustering quality. Given a cluster C i , let its dominant DTD be D i (i.e., the majority of its documents have a DTD D i ), a i the number of documents in C i which have a DTD D i , b i the number of documents in C i which do not have a DTD D , c i be the number of documents which are not in C i but have a DTD D i . The precision P R and recall R are defined as follows.

In this section, we will present the effectiveness, scalabil -ity, and sensitivity analysis of the XProj algorithm. We compared XProj with two XML clustering algorithms. One is the Chawathe algorithm, which is based on Chawathe X  X  tree edit distance [4] to compute the similarity. Another point of comparison is the latest XML clustering algorithm, which is based on structure summaries and an enhanced tree edit distance algorithm [5]. We denote it by the Structure algorithm. Both algorithms are single-link hierarchial cl us-tering algorithms and the results about them are from [5]. We compared the Precision and Recall of the three algo-rithms on data sets with both heterogeneous and homoge-neous DTDs.

We first compared XProj with the other two algorithms using data sets DB1000DTD10MR6 and DB1000DTD10MR3, which were generated according to 10 heterogeneous DTDs. In order for XProj to generate 10 clusters, we set k =10. The minimum support min sup was set to 0.01, l was set to 4, and the maximum support max sup was set to 0.8, and we used the coverage based initialization to initialize the se ed sets. Also, for each partition, we adopted the sequential coverage paradigm to choose the set of representative fre-quent sequences of size l . Table 1 depicts the comparison results for data set DB1000DTD10MR6. We can see that both the XProj and Structure algorithms work very well for this data set, and have higher precision and recall than Chawathe X  X  tree edit distance based algorithm. The Struc-ture algorithm generates one more cluster than XProj, and has a recall of 0.98, which means that it treats 20 XML doc-uments as outliers, while XProj can perfectly cluster all th e 1000 documents into exact 10 clusters. Thus, it has better clustering quality than the Structure algorithm. Compared to DB1000DTD10MR6, DB1000DTD10MR3 contains some smaller XML documents. XProj shows similar compara-tive results for this data set as well. Both the Chawathe and Structure algorithms generate more than 10 clusters, but have worse clustering quality than XProj for data set DB1000DTD10MR3.
 The 10 DTDs used to generate DB1000DTD10MR6 and DB1000DTD10MR3, are quite different from each other, and most clustering algorithms can achieve reasonable qual -ity with them. However, the three DTDs used to generate data set DB300DTD3MR6 are quite similar to each other, which makes the clustering quite challenging. The Structure algorithm was unable to identify groups of XML documents without using tree summaries and the calculated PR values were lower than 0.3 [5]. We were very interested in the per-formance of XProj on DB300DTD3MR6 data set with ho-mogeneous DTDs. For this data set, we chose l = 4, k = 3, min sup = 0 . 01, and max sup = 0 . 8. XProj can cluster DB300DTD3MR6 with perfect quality. As shown in Table 2, even with structure summaries turned on, the Structure al-gorithm can only achieve a precision of 0 . 78 and a recall of 0 . 78. These are much lower than those of XProj. This demonstrates that XProj also works well for difficult data sets with homogeneous DTDs. The reason for this is that the XProj algorithm is able to differentially find substructures which can discriminate between the different DTDs. Note the perfect results for XProj in the above experiments can only be achieved by using the Coverage based Initialization method with some tuned input parameters. First, we com-pare the performance between Coverage based Initialization and Randomized Initialization . Then, we present some sen-sitivity analysis to illustrate that XProj can generate good clustering results over a wide range of parameters.
In Section 4.3 we proposed Coverage based Initialization in order to generate more robust seed sets of representa-tive substructures than Randomized Initialization . We com-pared the two methods on data sets DB1000DTD10MR6, DB300DTD3MR6, and SIGMOD140DTD2. In the exper-iments, we set min sup at 0.01, max sup at 0.8, sequence length parameter l at 4, and the number of clusters at the number of DTDs. Table 3 shows the comparison results in terms of the algorithm precision. We can see that Coverage based Initialization provides more than 20% higher precision than Randomized Initialization for both DB1000DTD10MR6 and DB300DTD3MR6 data sets. This indicates that Cov-erage based Initialization is very helpful in improving the clustering quality of the algorithm. The SIGMOD140DTD2 data set is simple, and both methods achieve the same preci-sion when the parameter l is not too small. However, Cover-age based Initialization still outperforms Randomized Initial-ization with a small l for this data set. For example, when l equals 3, XProj with Coverage based Initialization has a pre-cision 100%, while the precision of XProj with Randomized Initialization is only 89.8% for this data set. All our re-sults over a variety of parameter values show similar trends as suggested in Table 3. This suggests that Coverage based Initialization is able to avoid the local optima in which the randomized method may get trapped. This can improve the clustering quality significantly.
We used DB300DTD3MR6 and SIGMOD140DTD2 to per-form the sensitivity analysis with some important input pa-rameters. Here, we are interested in how the sequence length parameter l , the minimum support threshold min sup , and the maximum support threshold max sup affect the algo-rithm X  X  clustering quality.
 Table 3: Comparison: Randomized and Coverage based Initialization (Precision).
 Figure 4: Sensitivity analysis (Varying l , SIG-MOD140DTD2 and DB300DTD3MR6).

We first tested the impact of the sequence length param-eter l on the clustering quality. Figure 4 shows the results with respect to precision. In the experiment, we set the num-ber of clusters at 3 and 2 for data sets DB300DTD3MR6 and SIGMOD140DTD2, and fixed min sup and max sup at 0.01 and 0.8 respectively. We can see that when we change the sequence length l from 3 to 6 the precision is always higher than 92.0% for data set DB300DTD3MR6. This is much better that the best precision that can be achieved by the Structure algorithm. For data set SIGMOD140DTD2 the precision is always 100.0%. This illustrates that the XProj algorithm is able to perform effectively within practical se-quence length parameter limits.

We then evaluated the impact of the minimum support min sup and the maximum support max sup to the cluster-ing quality of XP roj . We fixed the length parameter l at 4 and used the difficult data set DB300DTD3MR6. From Table 4 we see that different combinations of the minimum and maximum support thresholds have different precisions. However, for a variety of minimum and maximum support Table 4: Sensitivity analysis (Varying min sup and max sup , DB300DTD3MR6). thresholds, XProj algorithm always achieves much higher precision than the Structure algorithm.
We used all the three synthetic data sets and the real data set SIGMOD140DTD2 to test clustering scalability by replicating them from 2 to 16 times. For all these data sets, we fixed the minimum support, min sup , at 0.1, the maximum support, max sup , at 0.8, sequence length l at 4, and the number of clusters, k , at the number of DTDs used to generate the corresponding data sets. As we can see from Figure 5, XProj shows linear scalability against the number of XML documents. This is because both the sequential pattern mining and cluster assignment procedur es scale linearly with data set size. This is a useful property, since it means that the algorithm can easily be scaled up to very large data sets.
In this paper, we presented a projected clustering algo-rithm for XML documents. The algorithm works with the use of subspace projections for finding multiple substruc-tures which represent the seed sets for individual clusters . The use of multiple substructures to represent seed sets results in a robust clustering approach for the algorithm. At the same time, we discuss how to use a sequential pat-tern based approach for finding the substructures of interes t from the documents. Since sequential pattern mining is a well studied problem, known algorithms can be leveraged for finding the relevant frequent substructures. This resul ts in an efficient approach which can be used over very large data sets. We also show the qualitative advantages of the method over the best known techniques for XML document clustering. [1] C. C. Aggarwal, C. Procopiuc, J. Wolf, P.S. Yu, J.-S. Park. Fast Algorithms for Projected Clustering.

Proceedings of the ACM SIGMOD Conference , 1999. [2] C. C. Aggarwal. A Human-Computer Interactive Method for Projected Clustering. IEEE Transactions on
Knowledge and Data Engineering , 16(4), 448 X 460, 2004. [3] T. Asai, K. Abe, S. Kawasoe, H. Arimura, H.

Satamoto, S. Arikawa. Efficient substructure discovery from large semi-structured data. ACM SIAM
International Conference on Data Mining , 2002. [4] S.S. Chawathe. Comparing Hierachical data in external memory. Very Large Data Bases Conference , 1999. [5] T. Dalamagas, T. Cheng, K. Winkel, T. Sellis. Clustering XML Documents Using Structural
Summaries. Information Systems , Elsevier, January 2005. Also appeared in EDBT 2004 Workshops on
Current Trends in Database Technology , 2004. [6] S. Guha, R. Rastogi, K. Shim. ROCK: a Robust Clustering Algorithm for Categorical Attributes,
International Conference on Data Engineering , 1999. [7] A. Jain and R. Dubes. Algorithms for Clustering Data.
Prentice Hall, Englewood Cliffs NJ, USA, 1988. [8] M. Lee, W. Hsu, L. Yang, X. Yang. XClust: Clustering XML Schemas for Effective Integration. ACM
Conference on Information and Knowledge Management , 2002. [9] W. Li, J. Han, J. Pei. CMAR: Accurate and Efficient Classification Based on Multiple Class-Association
Rules. International Conference on Data Mining , 2001. [10] W. Lian, D.W. Cheung, N. Mamoulis, S. Yiu. An Efficient and Scalable Algorithm for Clustering XML Documents by Structure. IEEE Transactions on
Knowledge and Data Engineering, Vol 16, No. 1 , 2004. [11] R. Ng, J. Han. Efficient and Effective Clustering
Methods for Spatial Data Mining. VLDB Conference , 1994. [12] J. Pei, J. Han, B.-M. Asl, H. Pinto, Q. Chen, U.
Dayal, M.-C. Hsu. PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth.
International Conference on Data Engineering , 2001. [13] A. Termier, M-C. Rousset, M. Sebag. TreeFinder: a First Step towards XML Data Mining. International
Conference on Data Mining , 2002. [14] J. Wang, J Han. BIDE: Efficient Mining of Frequent Closed Sequences. International Conference on Data
Engineering , 2004. [15] K. Wang, H.Q. Liu. Discovering Typical Structures of Documents: A Road Map Approach. ACM SIGIR
Conference , 1998. [16] M. J. Zaki, C. C. Aggarwal. XRules: An Effective Structural Classifier for XML Data. ACM KDD
Conference , 2003. [17] T. Zhang, R. Ramakrishnan, M. Livny. BIRCH: An Efficient Data Clustering Method for Very Large
Databases. ACM SIGMOD Conference , 1996. [18] M. J. Zaki. Efficiently Mining Frequent Trees in a
Forest. ACM KDD Conference , 2002.
