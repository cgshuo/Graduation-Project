 Microblogging such as Twitter and Weibo is a popu-lar social networking service, which allows users to post messages up to 140 characters. There are mil-lions of active users on the platform who stay con-nected with friends. Unfortunately, spammers also use it as a tool to post malicious links, send unso-licited messages to legitimate users, etc. A certain amount of spammers could sway the public opinion and cause distrust of the social platform. Despite the use of rigid anti-spam rules, human-like spammers whose homepages having photos, detailed profiles etc. have emerged. Unlike previous "simple" spam-mers, whose tweets contain only malicious links, those "smart" spammers are more difficult to distin-guish from legitimate users via content-based fea-tures alone (Ferrara et al., 2014).
There is a considerable amount of previous work on spammer detection on social platforms. Re-searcher from Twitter Inc. (Chu et al., 2010) collect bot accounts and perform analysis on the user behav-ior and user profile features. Lee et al. (2011) use the so-called social honeypot by alluring social spam-mers X  retweet to build a benchmark dataset, which has been extensively explored in our paper. Some researchers focus on the clustering of urls in tweets and network graph of social spammers (Yang et al., 2012; Wang et al., 2015; Wang, 2010; Yang et al., 2011), showing the power of social relationship fea-tures.As for content information modeling, (Hu et al., 2013) apply improved sparse learning methods. However, few studies have adopted topic-based fea-tures. Some researchers (Liu et al., 2014) discuss topic characteristics of spamming posts, indicating that spammers are highly likely to dwell on some certain topics such as promotion. But this may not be applicable to the current scenario of smart spam-mers.

In this paper, we propose an efficient feature ex-traction method. In this method, two new topic-based features are extracted and used to discrim-inate human-like spammers from legitimate users. We consider the historical tweets of each user as a document and use the Latent Dirichlet Allocation (LDA) model to compute the topic distribution for each user. Based on the calculated topic probabil-ity, two topic-based features, the Local Outlier Stan-dard Score (LOSS) which captures the users inter-ests on different topics and the Global Outlier Stan-dard Score (GOSS) which reveals the users interests on specific topic in comparison with other users, are extracted. The two features contain both local and global information, and the combination of them can distinguish human-like spammers effectively.
To the best of our knowledge, it is the first time that features based on topic distributions are used in spammer classification. Experimental results on one public dataset and one self-collected dataset fur-ther validate that the two sets of extracted topic-based features get excellent performance on human-like spammer classification problem compared with other state-of-the-art methods. In addition, we build a Weibo dataset, which contains both legitimate users and spammers.

To summarize, our major contributions are two-fold:  X  We extract topic-based features (GOSS and  X  We build a dataset of Chinese microblogs for
In the following sections, we first propose the topic-based features extraction method in Section 2, and then introduce the two datasets in Section 3. Ex-perimental results are discussed in Section 4, and we conclude the paper in Section 5. Future work is pre-sented in Section 6. In this section, we first provide some observations we obtained after carefully exploring the social net-work, then the LDA model is introduced. Based on the LDA model, the ways to obtain the topic prob-ability vector for each user and the two topic-based features are provided. 2.1 Observation After exploring the homepages of a substantial num-ber of spammers, we have two observations. 1) so-cial spammers can be divided into two categories. One is content polluters, and their tweets are all about certain kinds of advertisement and campaign. The other is fake accounts, and their tweets resem-ble legitimate users but it seems they are simply ran-dom copies of others to avoid being detected by anti-spam rules. 2) For legitimate users, content polluters and fake accounts, they show different patterns on topics which interest them.
  X  Legitimate users mainly focus on limited topics  X  Content polluters concentrate on certain topics.  X  Fake accounts focus on a wide range of topics  X  Spammers and legitimate users show differ-
To better illustrate our observation, Figure. 1 shows the topic distribution of spammers and le-gitimate users in two employed datasets(the Honey-pot dataset and Weibo dataset). We can see that on both topics (topic-3 and topic-11) there exists obvi-ous difference between the red bars and green bars, representing spammers and legitimate users. On the Honeypot dataset, spammers have a narrower shape of distribution (the outliers on the red bar tail are not counted) than that of legitimate users. This is because there are more content polluters than fake accounts. In other word, spammers in this dataset tend to concentrate on limited topics. While on the Weibo dataset, fake accounts who are interested in different topics take large proportion of spammers. Their distribution is more flat (i.e. red bars) than that of the legitimate users. Therefore we can detect spammers by means of the difference of their topic distribution patterns. 2.2 LDA model Blei et al.(2003) first presented Latent Dirichlet Al-location(LDA) as an example of topic model. Each document i is deemed as a bag of words W = { w i 1 ,w i 2 ,...,w iM } and M is the number of words. Each word is attributable to one of the document X  X  topics Z = { z i 1 ,z i 2 ,...,z iK } and K is the number of topics.  X  k is a multinomial dis-tribution over words for topic k .  X  i is another multinomial distribution over topics for document i . The smoothed generative model is illustrated in Figure. 2.  X  and  X  are hyper parameter that affect scarcity of the document-topic and topic-word dis-tributions. In this paper,  X  ,  X  and K are empirically set to 0.3, 0.01 and 15. The entire content of each Twitter user is regarded as one document. We adopt Gibbs Sampling (Griffiths and Steyvers, 2004) to speed up the inference of LDA. Based on LDA, we can get the topic probabilities for all users in the em-ployed dataset as: X = [ X i ; X 2 ;  X  X  X  ; X n ]  X  R n  X  K , where n is the number of users. Each element X i = [ p ( z 1 ) p ( z 2 )  X  X  X  p ( z K )]  X  R 1  X  K is a topic probability vector for the i th document. X i is the raw topic probability vector and our features are de-veloped on top of it. 2.3 Topic-based Features Using the LDA model, each person in the dataset is with a topic probability vector X i . Assume x ik  X  X i denotes the likelihood that the i th tweet account favors k th topic in the dataset. Our topic based fea-tures can be calculated as below.

Global Outlier Standard Score measures the de-gree that a user X  X  tweet content is related to a certain topic compared to the other users. Specifically, the "GOSS" score of user i on topic k can be calculated as Eq.(1):
The value of GOSS ( x ik ) indicates the interest-ing degree of this person to the k th topic. Specifi-cally, if GOSS ( x ik ) &gt; GOSS ( x jk ) , it means that the i th person has more interest in topic k than the j th person. If the value GOSS ( x ik ) is ex-tremely high or low, the i th person showing ex-treme interest or no interest on topic k which will probably be a distinctive pattern in the fowllow-ing classfication. Therefore, the topics interested or disliked by the i th person can be manifested which the pattern of the interested topics with re-[ GOSS ( x i 1 )  X  X  X  GOSS ( x iK )] our first topic-based feature, and it hopefully can get good performance on spammer detection.

Local Outlier Standard Score measures the de-gree of interest someone shows to a certain topic by considering his own homepage content only. For in-stance, the "LOSS" score of account i on topic k can be calculated as Eq.( 2):  X  ( x i ) represents the averaged interesting degree for all topics with regarding to i th user and his tweet content. Similarly to GOSS , the topics interested or disliked by the i th person via considering his sin-[ LOSS ( x i 1 )  X  X  X  LOSS ( x iK )] , and LOSS becomes our second topic-based features for the i th person. We use one public dataset Social Honeypot dataset and one self-collected dataset Weibo dataset to vali-date the effectiveness of our proposed features.
Social Honeypot Dataset : Lee et al. (2010) cre-ated and deployed 60 seed social accounts on Twitter to attract spammers by reporting back what accounts interact with them. They collected 19,276 legitimate users and 22,223 spammers in their datasets along with their tweet content in 7 months. This is our first test dataset.

Our Weibo Dataset : Sina Weibo is one of the most famous social platforms in China. It has im-plemented many features from Twitter. The 2197 le-gitimate user accounts in this dataset are provided GOSS+LOSS by the Tianchi Competition 1 held by Sina Weibo. The spammers are all purchased commercially from multiple vendors on the Internet. We checked them manually and collected 802 suitable "smart" spam-mers accounts.

Preprocessing : Before directly performing the experiments on the employed datasets, we first delete some accounts with few posts in the two employed since the number of tweets is highly in-dicative of spammers. For the English Honeypot dataset, we remove stopwords, punctuations, non-ASCII words and apply stemming. For the Chi-nese Weibo dataset, we perform segmentation with ter preprocessing steps, the Weibo dataset contains 2197 legitimate users and 802 spammers, and the honeypot dataset contains 2218 legitimate users and 2947 spammers. It is worth mentioning that the Honeypot dataset has been slashed because most of the Twitter accounts only have limited number of posts, which are not enough to show their interest inclination.
 Actual 4.1 Evaluation Metrics The evaluating indicators in our model are show in Table 2 . We calculate precision, recall and F1-score (i.e. F1 score) as in Eq. (3). Precision is the ratio of selected accounts that are spammers. Recall is the ratio of spammers that are detected so. F1-score is the harmonic mean of precision and recall. precision = 4.2 Performance Comparisons with Baseline Three baseline classification methods: Support Vector Machines (SVM), Adaboost, and Random Forests are adopted to evaluate our extracted fea-tures. We test each classification algorithm with scikit-learn (Pedregosa et al., 2011) and run a 10-fold cross validation. On each dataset, the em-ployed classifiers are trained with individual feature first, and then with the combination of the two fea-tures. From Table 1, we can see that GOSS+LOSS achieves the best performance on F1-score among all others. Besides, the classification by combina-tion of LOSS and GOSS can increase accuracy by more than 3% compared with raw topic distribution probability. 4.3 Comparison with Other Features To compare our extracted features with previously used features for spammer detection, we use three UFN+UC+UF+LOSS+GOSS 0.925 0.920 0.923 0.952 0.946 0.949 Feature Description
UFN most discriminative feature sets according to Lee et al. (2011)(Table 4). Two classifiers (Adaboost and SVM) are selected to conduct feature performance comparisons. Using Adaboost, our LOSS+GOSS features outperform all other features except for UFN which is 2% higher than ours with regard to precision on the Honeypot dataset. It is caused by the incorrectly classified spammers who are mostly news source after our manual check. They keep posting all kinds of news pieces covering diverse topics, which is similar to the behavior of fake ac-counts. However, UFN based on friendship net-works is more useful for public accounts who pos-sess large number of followers. The best recall value of our LOSS+GOSS features using SVM is up to 6% higher than the results by other feature groups. Regarding F1-score, our features outper-form all other features. To further show the ad-vantages of our proposed features, we compare our combined LOSS+GOSS with the combination of all the features from Lee et al. (2011) (UFN+UC+UH). It X  X  obvious that LOSS+GOSS have a great advan-tage over UFN+UC+UH in terms of recall and F1-score. Moreover, by combining our LOSS+GOSS features and UFN+UC+UH features together, we obtained another 7.1% and 2.3% performance gain with regard to precision and F1-score by Adaboost. Though there is a slight decline in terms of recall. By SVM, we get comparative results on recall and F1-score but about 3.5% improvement on precision. In this paper, we propose a novel feature extraction method to effectively detect "smart" spammers who post seemingly legitimate tweets and are thus dif-ficult to identify by existing spammer classification methods. Using the LDA model, we obtain the topic probability for each Twitter user. By utilizing the topic probability result, we extract our two topic-based features: GOSS and LOSS which represent the account with global and local information. Ex-perimental results on a public dataset and a self-built Chinese microblog dataset validate the effectiveness of the proposed features. In future work, the combination method of local and global information can be further improved to max-imize their individual strengths. We will also apply decision theory to enhancing the performance of our proposed features. Moreover, larger datasets on both Twitter and Weibo will be built to further validate our method.

