 1. Introduction
Since the number of individuals having brain disorders such as alzheimer, schizophrenia, autism and multiple sclerosis are increasing dramatically in recent days, analyzing magnetic reso-nance (MR) images of the brain is becoming more important. The accurate analysis of brain MR depends on the process of medical image registration. The key method of registration can only be achieved by the detection of landmark points on the MR images. Typical landmark points can be ob tained through the extraction of analogous structures. Skull boundary, brain stem (BS), cerebellum, nasion, tip of nose and corpus callosum (CC) are the good candidates commonly accepted in the literature ( Lee et al., 1998 ).
CC is one of the most distinguished structures used for land-mark detection. It is made up of white matter (WM) and is the central place of neural fi bers passing from one hemisphere of the brain to the other. Its distinct shape, caused by its white matter in T1-weighted images, makes it easy to be detected (in Fig. 1 ). Locating CC is crucial for registering the subject's MRI to a reference system like Talairach atlas ( Talairach and Tournoux, 1988 ). Therefore, CC segmentation is the mandatory previous step of the registration.

In literature, there are various approaches to extract CC that can be grouped into two categories. The fi rst group named as model-based , aims to fi t CC into a high precision model in which changes of the area, volume and boundary should be accurately tracked in periodic scans. Typical approaches of the model-based studies can be summarized as shape analysis, template matching, principal component analysis (PCA) based def ormable models, contour model-ing, frequency based deformable models, snakes algorithms, etc et al., 2007 ; Lai et al., 2011 ; Jacob et al., 2004 ). Model-based methods are not concerned with segmentation of CC. In ( Ishaq et al., 2007 ) PCA is applied on the mean pro manually extracted CC regions from the MRI set. In ( Farag et al., 2010 ; Munim et al., 2007 ; Elnakib et al., 2010 ), they claim that the contour tracks of the CC are either given manually or taken from the ready templates produced by the other studies. Then, they match these counter tracks with their synthetically produced CC shape models (i.e. 3D Bezier Curvature based). Like in ( Lai et al., 2011 ), some of the methods for model-based approaches assert that automatic extraction of CC is performed using deformable geodesic surface modeling. In these studies, 3D surface construc-tion lies on binary mask usage and voxel labeling. Since binary mask production is a dif fi cult task, manual masking or an auto-matically generated corrupted mask is used ( Shi et al., 2010 ). In ( Jacob et al., 2004 ), CC is segmented through the snake algorithm where the image of CC region is cropped and fed into snake algorithm manually by radiologist. So, snake approach draws the active contours of CC semi-automatically. The last example can be given as in ( Elnakib et al., 2011 ), the model-based approach uses aligned shape templates. The templates are manually segmented and aligned at fi xed positions. Then, statistical similar regions are isolated from trained image as CC region.

On the other hand, the primary focus of the second group named as intensity-based methods, is to locate CC for detecting the landmark points like anterior commissure (AC), posterior commis-sure (PC), anterior point (AP), posterior point (PP), etc. for image registration purposes. This category uses histogram based analysis, thresholding based segmentations, landmark detection methods and neural network based approaches ( Shenton et al., 1995 ; Mangin et al., 1996 ; Reddick et al., 1997 ; V X rard et al., 1997 ; 1979 ; Kanungo et al., 2006 ; Iqbal, 2010 ; Hu. et al., 2008 ; Allaou and Nasri, 2012 ).

Our methods which automatically extract CC fall into the cate-gory of intensity-based methods. The aim of model-based approaches is the diagnosis of brain disorders such as autism and Alzheimer's disease using the changes in size of anatomical structures in the brain. On the other side, our study focuses on the extraction of landmarks for registration to a standard brain atlases or templates.
Hence, the studies related with the model-based category are beyond the scope of this paper.

OneoftheearliestworksonextractingCCisseenonthe
In this study, the tissues on MR images are segmented into different classes like gray matter, white matter and cerebrospinal fl the supervision of an operator. After the tissues are manually labeled, a connectivity program is run to subdivide the tissues into region of interests (ROI). CC is one of the ROI delineated by the manually prescribed landmarks. Although this study presents the extraction and 3D evaluation of the CC, the performance of the progress is directly degraded by the human factor (i.e. operator).
Mangin et al. simulate information fl ow between two-hemispheres of the brain to highlight the bottlenecks corresponding to important structures. The solution for Dirichlet  X  Neumann problem based on partial differential equations is applied to the information to this image for extracting CC. However, the information simulation requires a presegmentation of the brain MR image. Besides, the high and low thresholding values of the hysteresis process are manually fed by pathologist ( Mangin et al., 1996 ).

In 1997, Reddick et al. present a new method to segment brain tissues (i.e. white matter, gray matter etc.) in MR image. In their study, a self-organizing neural network is used to cluster the pixels. Unlike the preceding manual approaches, this method provides automated segmentation. According to the work, each cluster holds best representative pixel values of the tissues after training pixels in MR datasets ( Reddick et al., 1997 ). Although the pixels are classi fi ed into their tissue cluster automatically, the method suffers from misclassi fi cation (11.3%) and prior knowledge about the number of clusters (i.e. tissues). Besides, segmentation cannot be granulated to smaller structures like CC.

Meanwhile, V X rard et al. use scene analysis on thresholded midsagittal image to locate CC and brain stem (BS) ( V X rard et al., 1997 ). In order to fi nd the peak points, the algorithm initially reconstructs the plot of continuous histogram signal as connected line segments using recursive cutting. A set of threshold values are generated according to the line segments, peak points, line passing through the start and end points of the histogram. For each threshold value the binary image is analyzed to locate CC using prior knowledge, such as location, orientation and area. This approach is a milestone in the intensity-based methods. However, the algorithm exhibits dif fi culties in histogram processing. It expects the histogram to have three peaks and two valleys which restrict the generalization of the method.

Belardinelli et al. proposed an algorithm based on neural network named as Locally Excitatory Globally Inhibitory Network (LEGION) ( Belardinelli et al., 2003 ). This neural network uses oscillator nodes activated by local and global inhibitor threshold-ing values. Although this algorithm tries to generalize the seg-mentation of brain structures, there is no reported performance result on segmentation. Besides, the selection of threshold values is not clari fi ed.

Hu et al. propose a set of algorithms to locate the Talairach cortical landmarks ( Hu et al., 2005 ). Firstly, the slices contain-ing the ROIs are extracted. The ROIs are segmented with range-constrained thresholding by using prior knowledge obtained from the analysis of true segmentations of 18 phantom and 20 IBSR data sets. The landmarks are found by using morphological fi lters and local re fi nement of the segments. Under the circumstance of a failure in detecting AC and PC, the remaining cortical landmarks cannot be determined. They have to be selected manually.
Prakash et al. identi fi es CC in the process of locating AC and PC ( Prakash et al., 2006 ). In a similar fashion to V X rard et al. V X rard et al., 1997 , anatomical features such as length, width, orienta-tion and area are used to identify CC in a series of binarization iterations. Differently, the thresholds are selected from the bright-est pixel intensity within the range of 7 20%. The process continues to test threshold values until the CC is identi
The notion of vulnerability of the process is that it stops at the fi rst structure that fi ts to the range of predetermined anatomical values.

Intensity-based methods discussed so far perform a segmenta-tion step using thresholding. The most common approach to the optimum threshold value for a gray-level image is Otsu's method ( Otsu, 1979 ) where the main idea is to maximize the inter-class variance. It is mostly used to extract segments from a background with a different level of gray.

However, applying Otsu's method to CC extraction, yields degraded results. Since the goal is to automate the extraction process, evolutionary based optimization algorithms should be used for determining optimum threshold value. Genetic algorithms (GAs) are the main focus of this paper.

Kanungo et al. uses crowding method in a GA to fi nd the threshold value for segmentation of images that have bimodal features ( Kanungo et al., 2006 ). The histogram for such images contains two peak points. The method fi nds these peak points using crowding in GAs, followed by another GA that fi nds the minimum histogram value between these peaks. This optimum value successfully segments the image. The algorithm fails for images with more than two features or when the peaks overlap. This method is not applied on medical images until a similar method is used on lung image border construction in a disserta-tion by Iqbal ( Iqbal, 2010 ).

Hu et al. uses GA to fi nd optimum threshold value for medical imaging ( Hu et al., 2008 ). Although the method automatically selects the threshold via GA, this value is obtained after the classi of sets through the rough set. It should be noted that this method is applied for only B-ultrasound gray images. They are not used in brain MR images.

Allaoui and Nasri make a study on segmentation of synthetic and real abdominal X-ray image and thorax ( Allaou and Nasri, 2012 ). This method is limited with 4 gray level intensities on a limited dataset. The performances are not reported to be applic-able to brain MR images.

This paper has the following contributions as opposed to the methods already discussed. Three improving novel algorithms are presented as distinct solutions for extracting CC. In all methods, the extraction process is totally automated; there is no user interaction involved.

The fi rst one is similar to V X rard et al.'s approach ( V X rard et al., 1997 ). Contrary to their solution, our method is not limited to three peaks and two valleys in the histograms. This primary version of our solution uses fi xed searched range in histogram processing and uses fi xed prior anatomical information for locating CC in the MR image. It also gives the fi rst matched solution as the result without comparing it for a better solution. It performs successfully in 64 of 67 (95.5%) MR images from the Ege University MRI dataset.
Our second novel method focuses on locating the CC using a GA with a new fi tness function that uses anatomical ratios, instead of fi xed prior knowledge or scene analysis of our fi rst method. Another contribution of this method is that, the algorithm does not stop at the fi rst solution, but searches for the most similar structure to the CC. Since this method does not do any histogram analysis like fi nding peaks and valleys, it searches the whole range of the histogram. This method performs successfully in 62 of 67 (92.5%) images. Although the performance is lower than the performance of the fi rst one, the dependency to prior knowledge has decreased considerably.

Our third method gathers the strong points of our fi rst and second algorithms using GAs. GA does histogram analysis to fi nd out peaks and valleys automatically. The search space de for the second method is reduced by the fi rst method's valley matching approaches using GAs. The method uses crowding to fi nd the peaks in the multi-modal histogram of the MR image. This method performs successfully in 61 of 67 (%91) images. Although the performance is lower than our fi rst two methods, the search space is reduced compared to the second algorithm.

Final contribution of our study is that there is no reported method for extracting CC automatically using GAs in literature.
The rest of the paper is organized as follows. The second section presents our three novel approaches for extracting CC from midsagittal MR images. This is followed by the performance results of each method. Finally, the section of conclusion and future work is discussed. 2. Material and methods 2.1. Datasets
In our study, T1-weighted midsagittal MR images are used from two different datasets. The fi rst one is Ege University MRI Dataset. This set contains T1 MR images with a size of 512 512. They are acquired from Siemens Magnetom Verio 3 Tesla system in the DICOM (Digital Imaging in Medicine and Communications) image format. This format uses hexadecimal encoding for pixel values, which has a range of [0, 2 16 ]. The images are supplied by Ege University's brain MRI dataset. The dataset contains 67 subjects composed of 41 females and 16 males.
 The second dataset is Information eXtraction from Images (IXI) MRI dataset. This dataset is provided by the Imperial College and contains T1 MR images from three different hospitals in London. T1-weighted MR images from the Hammersmith Hospital are selected for comparison because they are captured by a 3 Tesla system, like in Ege University ( Imperial College, 2013 ). 2.1.1. Brain rotation information for midsagittal plane
Extracting Midsagittal slice of the subjects' brain is not a simple operation. Since the axial and coronal rotations de fi ne the brain orientation distortion, it should be corrected before determination of accurate midline. There are basically two methods for orientation correction. The fi rst one is achieved manually by the radiologist. In this approach, the main focus is precise and consistent alignment of the subject. The radiologist corrects the scanning through naked-eye observation. Like in Fig. 2 (Ege University MR scan), after capturing the orthogonal axes ( Kouwe et al., 2005 )  X  the MR scanning software supports the radiologist by drawing guided lines (by localizer)-for both axial and coronal slices, radiologist completes 3D brain MR scanning. The second method of correcting orientation is done through the application of mathematical methods on the scanned 3D brain MR slices. Symmetrical projection of the left-right hemi-spheres is one of the most common mathematical methods used in literature ( Yeji and Hyun, 2003 ; Qingmao and Wieslaw, 2003 ; for symmetrical characteristics. If the trial line cuts the axial brain slice into two equal parts (i.e. almost symmetry), the angle of the cut gives the brain rotation distortion.

In our proposed method, all subjects are aligned consistently and radiologist adjusts the MR scans manually before starting the whole process. Since the scans are obtained in a consistent manner, there is no need for a mathematical correction or 3D interpolation of adjacent slices. In Fig. 3 one of the subjects' (i.e. subject id#: 17) axial slices from our  X  Ege University MRI Dataset are shown as an example to demonstrate the consistency. All images in the dataset have the same characteristics for both axial and coronal orientations. 2.1.2. Selection of midsagittal slice
After the midsagittal plane is obtained accurately through the consistent alignment or automatic correction, the correct choice of midsagittal slice should be handled.

One of the well-known methods for selecting the true mid-sagittal slice is the searching algorithm that gives the maximum responses for the gray and the white matters among the middle slices. Although this method technically sounds good, it is com-plicated. Since the boundaries of the gray and white matters are not known, the additional segmentation algorithms should be applied. Instead, ( V X rard et al., 1997 ) uses a pseudo slice obtained by mixing middle slices. In their work, the slice at the middle and its two adjacent neighbor slices are taken into consideration. Three planes are compared with each other according to the intensity values of pixels. The lowest values are used to construct the pseudo midsagittal image ( V X rard et al., 1997 ).

In our proposed method, each subject has m slices. First of all, we extended V X rard's method by taking the middle slice with its neighbor in the range of [ 2,  X  2]. As a result, we produced pseudo midsagittal image by choosing lowest intensity values by comparing these fi ve mid-slices. Then we applied VM algorithm to each of the images respectively. For each image, CC is extracted correctly, as seen in Fig. 4 . When we observe the dataset composed by 67 subjects, dealing directly with mid-slice (i.e. m /2) is enough to get correct extraction of CC. Besides, we have the advantage of reducing computational complexity. 2.2. Methods
Three improving novel algorithms are presented in this study as distinct solutions. Each proposed algorithm extracts CC with performances up to 95.5%. There is no reported publication in literature that has high performance on extracting CC compared to our three algorithms.

The fi rst one, called Valley Matching (VM), is based on rough histogram analysis supported with fi xed prior anatomical infor-mation of CC. The second one named as Evolutionary CC Detection (ECD), enhances the process using a new fi tness function based on anatomical geometrical ratios. The third one, called Evolutionary Valley Matching (EVM), improves the ECD by reducing the search space of the GA. 2.2.1. Valley Matching algorithm
VM primarily analyses the histogram of the brain MR image to fi nd the starting bin of the threshold value range. Fitting process is evaluated by using prior fi xed anatomical information of CC. The whole algorithm can be viewed in Fig. 5 .

Initially, VM method transforms intensity values of DICOM images from hexadecimal encoding to octal encoding. The transfor-mation is done by dividing each intensity value by the maximum intensity value of the MR image and multiplying the quotient by 255. The reason why the intensity values are mapped into the range of [0, 255] is to standardize the histograms. Because, the maximum gray level values of the images in Ege University MRI Dataset varies in the range of [700, 1500]. By this standardization, the illumination differences are also passed on to the new mapped histograms. The mean of the mapped histograms enables us to model the illumina-tion characteristics of the 3 Tesla MR device. Hence, matching each images new standardized histogram onto the mean histogram removes the illumination differences.

Application of a certain algorithm on all images yields incon-sistent results because of varying lightning pro fi les of each image. illumination pro fi le (common lightning conditions). Hence, histo-gram matching is applied. Since matching requires a reference histogram, the mean histogram of randomly selected 10 images is generated. This mean histogram provides 3 Tesla MR illumination modeling.

Matched histograms are not ready to be analyzed because of the jagged view (i.e. ripples) of the histogram signal. This jagged pattern of the histogram prevents the detection of the local optimums (i.e. peaks and valleys).

To avoid getting stuck on ripples, the histogram is smoothed by sliding k-bin values where k is window size as indicated in Fig. 6 . Smoothing for an intensity value at index i , is done by averaging the adjacent intensity values in the range of ( i k , i  X  k ). Besides, smoothing is also performed with geometric and harmonic mean functions using different k values ranged in ( Lee et al., 1998 ; Shi et al., 2010 ). Regarding to the test results k is assigned with the value of 8 for smoothing ( Fig. 7 ). Determination of the k value and the averaging method are discussed under the section  X  Results and Discussion  X  .

Since the background color occupies most of the MR image, the highest peak point of the histogram, max ( h i  X  ), can be found at low gray-level intensities. Histogram values before this point are cleared by setting their values to max ( h i  X  ). This ensures the removal of any decrements that may steer the algorithm to a false local minimum.

Gradient descent algorithm is applied on the histogram to fi nding v , the second peak is detected by hill climbing approach.
The bin having the closest value to v beyond the second peak is assigned as w ( Fig. 8 ). The algorithm starts searching the histo-gram in the range of [ w 5, w  X  30] to locate the CC. This range is based on prior knowledge obtained from the analysis of MR images as explained in results and discussion section.
For each value of the range, following steps are taken to locate the CC. a. The image is thresholded. b. Median fi lter is applied to the resulting binary image to get rid of the smaller objects. Typical mask size is 5 5. (Since the structure of brain contains small valuable particles, the other mask sizes such as 7, 9, 11, etc. are not used) c. The objects are extracted and labeled through the connected component analysis using 4-connectivity ( Fig. 9 ). Since the aim is to isolate objects from each other, 8-connectivity algorithm is not considered. d. CC is one of the largest components extracted from the previous connectivity analysis. In order to identify the CC, prior knowledge of fi xed anatomical measurements is used. They can be summarized as follows: e. If all the conditions hold, the CC is detected and the algorithm terminates ( Fig. 10 .). Otherwise, the algorithm moves on to the next intensity value. If the search range is completed, then the CC could not be detected.
 Algorithm 1. Valley Matching Algorithm (VM) 1. Scale intensity values of MR image to [0,256) 2. Calculate the average histogram ( meanhist ) of randomly 3. Match image histogram to meanhist 4. Smooth the matched histogram 5. Find the fi rst peak point 6. Find the valley after peak point using gradient descent 7. Find the second peak after valley using hill climbing 8. Find the point after the second peak where histogram value 9. for each intensity L in the range[ w 5, w  X  30] 10. Threshold the image with L 11. Apply median fi lter with the mask size of 5 5 12. Find connected components using 4-connectivity 13. for each component in components do 14. if area is greater than 5 cm 2 and 15. orientation is between [ 13, 13] a nd 16. horizontal positioning is [ 40, 40] to center of 17. width/height ratio is between [2.5, 4.5] then 18. mark bounding box as CC and exit 19. end if 20. end for each 21. end for each 2.2.2. Evolutionary based algorithms 2.2.2.1. An overview of genetic algorithms.
 Algorithm 2. Basic work fl ow of a generic GA. 1. Produce an initial random population of solutions 2. Evaluate the fi tness of all individuals 3. while termination condition not met or generations not 4. Select the parents by the roulette wheel method to 5. Apply single point crossover 6. Apply mutation 7. Evaluate fi tness of new individuals 8. Generate a new population by inserting new 9. end while
GAs are search heuristics, operating on a population of solu-tions to fi nd an optimum result. Each solution of the population is represented as a chromosome (i.e. individual). A typical run of a GA begins with an initial random population. The individuals are graded by the fi tness function to get their fi tness values used for populating the next generation. The roulette wheel method is applied for parent selection process. The individuals with higher fi tness values get higher probability for being selected as a parent. The offspring are produced by the single point crossover operator. This operator de fi nes a random point in the chromosome and swaps the head and tail sections of each parent to produce two new offspring. Next, a typical mutation is applied with changing a single gene value in the chromosome with a low degree of probability. Next generation is constructed with these highly-new individuals or replacing the lowly-fi t parents with them. Iterative steps of the algorithm continue until termination condi-tion is met or the number of generations runs out.

In the following sub-sections, our novel evolutionary algo-rithms inspired by generic GA are described. 2.2.2.2. Evolutionary CC detection. ECD uses a GA with a novel CC Matching Fitness (CMF) Function. CMF function utilizes the similarity of the structures in the view of anatomical ratios instead of fi xed values. There is no need to do any additional intensity on histogram analysis.

Every chromosome is modeled as a gray-level pixel value. They are encoded as an array of bits so that each chromosome is 16 bits long as indicated in Fig. 11 .

At the fi rst phase of ECD, a random initial population of size n is generated with chromosomes that have values up to m , the highest pixel value of the image. The maximum observed value changes from about 700 to 1500 in our test images. This gives us the advantage of reducing the 16 bit search space while keeping precision of the pixel values.

In GAs, there are common methods of parent selection such as roulette-wheel, elitist approach, fi tness-proportionate, rank selec-tion etc. In each of these methods, parent selection is done in the view of stronger individuals. Since these methods do not give equal opportunity to all individuals in the population, we do not prefer to use them in our method.

The pairs are decided by a random permutation of population size, n . Parents are selected with the index number of this permuta-tion in a sequential order. Assume that, a population of size 100 has a random permutation like {19, 25, 24, 1 ... }. The fi made up of chromosomes with index numbers 19 and 25 from the population, where the second pair takes chromosomes with index numbers 24 and 1. Using this permutation, every chromosome gets the chance to become a parent with a random partner.
 There are two important operators in the breeding phase of the GA. The fi rst operator is the crossover operator and the other one is mutation operator.

Our GA uses uniform crossover. This crossover method creates two offspring from two parents with the population crossover probability P c . Fig. 12 shows an example of the process using two 4 bit chromosomes. In ECD, P c is set to 0.5, in order not to bias one of the parents.

The second operator is mutation. It is applied to each offspring at gene level with mutation probability P m . The gene value is negated if the probability holds. The process is repeated for each chromosome and for every gene of the chromosome. In ECD, P set to 0.1, in order to increase variety.

After the operators complete their tasks with generating the offspring, the GA calculates the fi tness value of the offspring and the parents using CMF.

Our CMF function uses the geometrical ratios of CC measure-ments. There are many studies that calculate the area, width and height of CC ( Rauch and Jinkins, 1996 ; Bersani et al., 2010 ; Seixas mentsaregivenasCCarea(CCA),CCwidth(CCW),andCCheight (CCH). The two ratios, Eqs. (1 )and( 2 ), are newly de fi paper to be used in the fi tness function. They are the ratio of CCA to the bounding box in Eq. (1) , and the ratio of CCW to CCH in Eq. (2) . a  X  CCA =  X  CCW CCH  X  X  1  X  r  X  CCW = CCH  X  2  X 
Since the mean and standard deviations of these ratios will be required, 30 random samples from the 67 subjects of Ege Uni-versity brain MRI dataset are used as a training set. Obtained values are indicated in Table 1 .

The input parameters of the CMF are the original gray level image and the intensity value which will be used as threshold. CMF returns the result as a fl oating number in the range of [0, 1].
The internal steps of CMF are implemented as follows. a. The image is thresholded, and then median fi lter is applied.
Connected components are extracted using 4-connectivity. These three initial steps remain unchanged from the VM method. b. Each candidate component's ff value is calculated. In order to fi nd CC, Eq. (3) is devised to give a similarity to CC value for each object using the values shown in Table 1 . ff  X  a  X  ; r  X   X  X  1 2 f  X  a where f is the normal distribution function de fi ned in Eq. (4) .
The parameters a  X  (bounding box ratio) and r  X  (width height ratio) are the currently processed object's ratios. f  X  x j  X  ; s  X  X  1 s ffiffiffiffiffiffi
This function returns values between [0, 1] where the value 1 is assigned to the object that is most similar to the average CC. c. The highest ff value among the candidate components is returned as the fi tness value.

Algorithm 3. CC Matching Fitness (CMF) Function 1. Set F to 0 2. Threshold image I with the input parameter L 3. Apply median fi lter [5 5] 4. Find connected components using 4-connectivity 5. for each component in components do 6. Find a using Eq. (1) 7. Find r using Eq. (2) 8. Find similarity to CC using Eq. (3) 9. if similarity is greater than F then 10. update F to similarity value 11. end if 12. end for each 13. return F
Using CMF algorithm de fi ned in detail above, the fi tness values for the parents and the offspring are calculated. Two individuals that have the largest fi tness values are elected to become members of the next generation. Using this method, highly fi t chromosomes can survive many generations, eliminating even their own offspring.
The fi ttest member of the new generation is recorded for keeping track of the global solution. The stopping condition of the GA is controlled by convergence or maximum number of generations. Convergence is observed as the stabilization of the global solution.
Algorithm 4. Evolutionary CC Detection Algorithm (ECD). 1. Find the maximum intensity value and call it m 2. Generate a random population of size N up to value m , call it pop 3. Generate empty array A to store fi tness values for each intensity value 4. G is the number of generations 5. while G 4 0 or end condition is met 6. Create an empty population of size N and call it newpop 7. Randomize pop order 8. for index i in pop , increment i by 2 9. Set the next i and i  X  1 as parents 10. Crossover parents to create offspring 11. Mutate offspring 12. if fi tness value is not available in array for the 13. Calculate parents and offspring fi tness values using 14. Save the fi tness values to A at corresponding 15. end if 16. Sort fi tness values and add two of fi ttest member to 17. end for 18. set newpop as pop 19. if fi ttest member has not changed H generations then 20. end condition is met 21. end if 22. Decrement G by 1 23. end while 24. return the highest fi t member intensity value as the 2.2.2.3. Evolutionary Valley Matching. EVM improves ECD by inheriting the reduction of search space used in VM. In order to achieve this hybridization, EVM uses a series of four GAs. The one fi nds the peaks in the histogram without the need for smoothing. ECD forms the base of the remaining algorithms. The second one extracts the valley between the peaks. The w point in Fig. 5 is found by the next GA. The fi nal algorithm uses CMF to fi nalize the detection of CC.

Although GAs are good at converging to a single global optimum, another approach is required to converge and maintain multiple global optimums such as the brain MR images with characteristics of multilevel intensities.

The fi rst GA uses a method based on crowding. De Jong proposes the crowding method in ( De Jong, 2013 ) for maintaining diversity in the population. Crowding replaces the offspring with the most similar existing member of the population. This keeps the members and removes the un fi t members of the class.

To maintain more than one class, Cede X o et al. proposes the multi-model function optimization called multi-niche crowding (MNC) ( Cede X o et al., 1995 ). MNC improves the standard crowding method by getting rid of erroneous behavior during parent selection. Corrected parent selection enables MNC to keep stable subpopula-tions until generations run out.

Multi-niche crowding works as follows to fi nd the peaks of the histogram. a. The chromosome representation and the initial population generation are same with ECD algorithm. b. The fi rst parent is selected randomly. It is paired with a mate among a group composed of C s chromosomes selected randomly from the population. The choice is done using the distance similarity metric. Let us assume that our fi rst random chromo-some holds the value 246. The candidate group has C s  X  4 chromosomes selected randomly with the values 199, 412, 23 and 761. Since 199 is the closest one, it is elected as the mate. c. The ability of generating offspring of these parents is checked by the crossover probability, P c . Therefore, P c is set to a value between [0.9, 1]. If the probability does not hold, algorithm continuous with next pair. d. The interval crossover operator is applied. It is different from the gene based uniform crossover operator used in ECD. This crossover operator uses chromosome values instead of chro-mosome bit patterns. Hence, the crossover operator selects a single random value between the parents with a relaxation constant  X  applied on borders. The parent values in the previous example, 199 and 246, produces an offspring between the values (199  X  , 246  X   X  ). e. The mutation operator is applied on gene level with the prob-ability P m , like in ECD. f. C f groups are formed by assigning randomly chosen s members for each. The chromosomes most similar to the offspring are marked as replacement candidates in each group. The least candidate found in Eq. (5) is replaced with the offspring. min f d l 2  X  offspring ; cnd i  X g ; 8 cnd A C f  X  5  X  where d l 2 is Euclidean distance and cnd represents candidate.
This procedure is called worst among the most similar . The offspring is replaced whether the least fi t chromosome is or not. The new chromosome takes its place among the population immediately and is available for selection in the next mating process. g. The algorithm runs for every chromosome in the population.
The GA ends after the maximum number of generations is reached. h. When the GA ends, the population holds the fi nal generation.  X  Most similar selection principle  X  for pairing parents and  X  worst among the most similar principle  X  for offspring replace-ment provides accumulation around the peak points. i. The population is sorted according to the frequencies of the chromosomes. The most frequent value is selected as one of the peaks. The second peak is selected among the remaining points that are not within the range of [ 7 0.1 m ]. 0.1 refers to the 10% of proximity de fi ned in ( Cede X o et al., 1995 ). m is the highest intensity value. j. The peak with smaller bin value is set as p 1 , while the other becomes p 2 . k. Cede X o et al. suggests setting the population size n to at least 20 p , where p is the expected number of peaks ( De Jong, 2013 ).
The candidate group count, C s , and the replacement group counts, s , are suggested to be set to 2 p. P c is set to 0.95 and P set to 0.01, while the  X  is set to 1.
 This GA successfully locates the peaks in the histogram.
The second GA fi nds the valley, v , using ECD by taking peak points ( p , p 2 )foundinthe fi rst GA as the search range. The histogram ( Fig. 13 )isusedasthe fi tness function with the principle of smaller the histogram value, the fi tter the pixel intensity.
 The third GA fi nds the corresponding bin value w in Fig. 8 using the maximum intensity value. The fi tness function looks for the closest value to v . q  X  0 : 5 x  X  2 w 0 : 1 m  X   X   X  6  X 
Once w is located, the range of the search space is set as [ q , q  X  0.1 m ] where q is de fi ned in Eq. (6) in the fourth GA. The fi tness function is the CMF.
 Algorithm 5. Peak fi nding based on multi-niche crowding (MNC). 1. Calculate histogram of image I and call it h 2. Find the maximum intensity value of I and call it m 3. Create a random population of size N , call it pop 4. G is the number of generations 5. while G 4 0 6. for each member A do 7. Select C s number of members from pop 8. Find the most similar member to A and call it M 9. Use interval crossover between A and M to create 10. Mutate Z 11. Create C f groups with s number members randomly selected from pop 12. Find the most similar member to Z from each group 13. Among the similar members, replace the least fi t member with Z 14. end for each 15. Decrement G by 1 16. end while 17. Count and sort the frequencies of the population members 18. Set peak 1 to most frequent value 19. Set peak 2 to the next frequent value which is at least m distance away from peak 1 20. return peak 1 and peak 2
Algorithm 6. Evolutionary Valley Matching Algorithm (EVM). 1. Find the maximum intensity value of the image and call it m 2. Find peak 1 and peak 2 using multi-niche crowding based algorithm 3. Find the valley, between peaks using GA 4. Find the matched valley point w , between peak 2 and m 5. Calculate range q with Eq. (6) 6. Find the threshold value between [ q , q  X  0.1 m ] using GA that uses CMF as fi tness function 3. Results and discussion
In this paper, three novel algorithms named as VM, ECD and EVM are proposed. ECD and EVM are based on evolutionary algorithms. The described methods are tested on 67 T1-weighted Ege University
MRI dataset and the IXI MRI dataset. For testing, T1-weighted MR images from the Hammersmith Hospital have been used because they are captured by a 3 Tesla Philips system ( Imperial College, 2013 ). The algorithms are tested on an Ubuntu 12.10 Linux operating system that runs on an Intel Core i7 3.20 GHz processor with 16 GB of memory.

The VM method uses fi xed searched range in histogram proces-sing and uses fi xed anatomical values for locating CC in the MR image. The performance of VM depends on the constant parameter k , histogram smoothing kernel and fi xedsearchrange.Inorderto determine the correct value, we have tested k with the values {1, 2 geometric, harmonic means). For each combination of {k, kernel}, the search range is tested in the interval of w 7 55 respectively for left and right neighborhood range. The best scores are obtained with k  X  8, normal mean kernel and the range [ 5, 30]. The kernel selection results are given in Table 2 , while range selection results are indicated in Table 3 .

Fixed anatomical information of CC used in VM is area, orienta-tion, positioning and ratio. CC area is given as different values in different studies ( Rauch and Jinkins, 1996 ; Bersani et al., 2010 ; work, in order not to miss the CC among the connected components, reported minimum value of 5 cm 2 is accepted. Using values 5.7, 6 or 7 result in performance degradation. Horizontal orientation is tested range of [ 13 1 ,13 1 ]. The natural positioning of CC can be observed in the center of image. However, the vertical positioning of the dataset has varied considerably. Therefore, only horizontal position-ing is applied closest to the medial axis as 7 40 pixels.
The strongest point of our algorithm VM is that, the directly found point w is also the solution (threshold value) for CC extraction.
In other words, 61% of dataset is solved without the need for searching the range [ 5, 30]. Overall performance of VM is 95.52% on Ege University MRI Dataset.

In our second algorithm ECD, the population size n is taken as 150. The population size n is tested for {90,100,110 ... and seen that 150 covers the solutions. The GA runs at most 150 generations. This value covers all possible values of histo-gram range. Therefore, lifespan of the population is determined by maximum number of generations or the convergence at the best fi t value. The analysis of ECD parameters such as P c (0.5) and
P (0.1) are determined by trial and error.

In our EVM algorithm, the points are considered to belong to the same peak if they are in the 10% proximity as reported in ( Cede X o et al., 1995 ). This value is reasonable because the peaks are expected to be around 20% apart. So, no further change is needed. The maximum number of generations, size of the population,
P parameters are the same as in ECD. C s is the number of members selected randomly in parent selection phase. This number is accepted in our paper as 3 p where p is the number of expected peaks. C f is the number of groups in the replacement phase and is taken as 3 in ( Cede X o et al., 1995 ). This value yielded best results for our algorithm as well. Finally, s , which is the number of members in C f groups, is accepted as 3 p , similar to C s ECD uses CC measurements from Ege University MRI dataset.
As already discussed in section 2.2.2, the measurements of 30 random samples are used to calculate the mean and standard deviations of a and r ( Table 1 ).

Table 4 illustrates the points found by our three algorithms for the fi rst 15 images of Ege University MRI Dataset. Since ECD does not work on histogram, only threshold value ( t ) is given. For VM and EVM, fi rst peak ( p 1), second peak ( p 2), valley bin point ( matched valley point ( w ) and threshold value ( t ) are given for each sample MR image. It should be noted that VM rescales the image to [0, 2] while ECD and EVM works on [0, 2 16 ].

The success rates of the proposed algorithms and the state of art method (V X rard et al.'s algorithm) applied both on Ege University MRI Dataset and IXI MRI Dataset, are given in Table 5 . The details of V X rard et al.'s algorithm are given at the end of this section. VM performs the best in success rate and also in run-time on Ege University MRI Dataset ( Table 6 ). Because, it incorporates more prior fi xed information about the position and the size of CC. Although the success rate of ECD is almost the same as VM, it should be preferable to VM because of the following circumstances:
VM requires mean histogram construction for modeling MR device illumination, where ECD does not.
 VM uses preprocessing such as histogram smoothing, where ECD does not.

VM needs intensity transformation from unsigned 16 bit to unsigned 8 bit representation, on the other hand ECD runs on unmapped intensity values.

VM uses priory knowledge, fi xed values, but ECD performs with anatomical ratios which removes dependency on fi xed values.
ECD performs better on the IXI MRI Dataset which means ECD is generalizable method.

Test results show that EVM fails in only one image in contrast to ECD, since this image has the threshold level out of the range de fi ned as q . EVM is preferable to ECD in the view of the reduction in the search space of ECD. As can be seen from the Table 6 , the population (N) and generation ( G ) size are the same for both algorithms. However, the search range in which CMF is applied is different. ECD calculates CMF for the range of m , whereas EVM uses tighter range of  X  (where m is always greater than  X  result, EVM is much faster than ECD ( Table 6 ) and performs almost the same with ECD at Ege University MRI Dataset and performs the best at IXI MRI Dataset. Besides, EVM does not depend on fi values similar to ECM. In literature there are no reported perfor-mances of any algorithms related with the extraction of CC. Our performances pave the way for segmenting CC in brain MR images. The time values given in Table 6 are obtained by running the algorithms at least 10 times for the whole set.
 The failed images are further analyzed to work out the problems. Fig. 14 presents two sample brain images for which EVM has failed to extract CC properly. Both of the images contain the CCs that are intertwined with neighboring tissues which makes them hard to isolate even with the naked eye.

Overall, among the three algorithms, EVM is the least dependent on variations of MR image acquisitions. On the other hand, VM performs accurately and fast for the given correct parameter values. 3.1. Testing V X rard ' s method
V X rard et al. use histogram analysis to detect both CC and BS in the midsagittal MR image. The peak at the lower intensity values indicates the background; the others belong to the white and the gray matter. Since the background peak is not needed, they modify the histogram by limiting this peak to that of the white or gray matter. Then, they use a line cutting algorithm on the histogram to get its main features ( V X rard et al., 1997 ).

Algorithm 7. Line cutting algorithm (LC). 1. Draw a line from the start point A to end point P on the histogram and call it L 2. Find the point I having the largest orthogonal distance to L 3. Recursively repeat the algorithm until the count of line segments reaches 20 or minimum value of the largest orthogonal distance is reached
Algorithm 8. V X rard's scene analysis algorithm. 1. Calculate the histogram and call it h 2. Use the LC algorithm to re-represent the histogram 3. First valley is called as E 4. Cumulative histogram value from E to end is called it F 5. Find the threshold value T 0 where cumulative histogram value is 0.4 F T 6. for T 0 in the range ( T 0 7 30) 7. The image is thresholded with T 0 8. Identify regions using four-connectivity algorithm 9. Elect candidates larger than 2 cm 2 10. Highest ranked regions by F CC and F BS are selected as CC and BS 11. if CC and BS are not available 12. Set T 0 to the next value 13. else 14. Break for loop 15. end if 16. end
The line cutting algorithm starts with a line that passes through the fi rst ( A ) and last ( P ) points on the histogram. For each point, the one ( I ) with the highest orthogonal distance to this line is detected. This point creates two lines; [AI] and [IP]. The algorithm continues recursively creating new two lines until the stopping condition is met. Resultant line segments are used to detect the point ( E ) for the valley that corresponds to the c (CSF).
In this study, F T is de fi ned by the sum of all histogram values from the valley point ( E ) to the end. V X rard et al. argue that the threshold value T 0 between 0.2 F T and 0.6 F T gives good results for extracting both CC and BS. Initially T 0 value of 0.4 F T testing is continued with 20 potential threshold values centered onto T 0 .

Once the image is binarized using the T 0 value, the regions are identi fi ed by a four-connectivity method. The regions larger than 2cm 2 are taken as candidates of CC and BS. V X rard et al. de two cost functions F CC and F BS which are linear combinations of the coordinates, width, length, center of gravity and form factor (the ratio of their width to their height) of the candidates. The highest candidates ranked by F CC and F BS are elected as CC and BS. V X rard's success rate stayed at 37% (25 out of 67) on Ege University MRI dataset and 8.7% (16 out of 185) on the IXI MRI Dataset. It should also be noted that the algorithm takes longer time to complete than VM, even though it has a lower degree of time complexity. This is because it tries all the possible threshold values in most of the images, while VM fi nds the CC in fewer numbers of trials. 3.2. Complexity analysis of methods
The methods detailed in the Section 2.2 are analyzed in the view of computational complexity in the following part of this section.
 Theorem 1. The running time complexity of VM algorithm is O (p  X  c 2 ) where each MR image has size of [p p] and c is the number of bins used in the histogram.

Proof . Line 1 in scales the intensity values of MR image that can be performed in O ( p 2 ) time complexity. The construction of an image histogram takes O ( p 2 ). The Line 2 is executed in O ( p the average histogram of randomly selected 10 images ( meanhist ) is calculated. Since the histogram of the image is matched to the smoothed in O ( c ). Each of the lines starting from 5 ending with 8 is performed in O ( c ) time in worst case. All the lines between 9 and 21 run at maximum 36 times independent from any image parameters. In Big-O notation, constant multipliers are ignored. So, constant factor 36 is ignored for all operations achieved inside the loop. Since ity. Line 11 applies the median fi lter and is performed in O ( p In Line 12, 4-connectivity algorithm is used to fi nd the connected components. It can be performed in O ( p 2 ). Lines 13 to 20 repeat for each connected component. The if control in lines 14  X  17 is executed in O (1) time. Line 18 marks the CC with bounding box performs in constant time, O (1). Thus, the total time complexity for VM algorithm is O ( p 2  X  c 2 ).
 Theorem 2. The running time complexity of CMF function is O(p where each MR image has size of [p p].
 in O ( p 2 ). In Line 3, the median fi lter is performed in O ( p connectivity algorithm is used to fi nd the connected components connected component. The lines 6 and 7 calculate the a and r values, so each operation is performed in O (1). The if control in Line 9 is it performs in O (1). Hence, the total time complexity of the CMF function is O ( p 2 ).
 Theorem 3. The running time complexity of ECD algorithm is O (GN  X  mp 2 ) where each MR image has size of [p p], G is the number of generations, N is the size of population and m is the number of different intensity values.

Proof . Line 1 fi nds the maximum intensity value in O ( p Generating a random population of size N takes O ( N ) time in Line 2. In Line 3, an empty array is created for storing the fi for each intensity values in O ( m ). The while loop between lines 5  X  23 executes O ( G ) times. Since the Line 6 creates an empty population of size N , it takes O ( N ) time. Randomizing population times so the complexity is O ( N ). Line 9 sets the fi rst two members of the population as parents in constant time, O (1). Line 10 crossovers the parents and Line 11 mutates the offspring in O (16) where each member is represented by 16 bits. For calculating the fi tness values of the parents and offspring, CMF function with complexity O ( p 2 ) is used. For the same individuals, CMF always returns same results. To avoid recalculation, memoization is used by storing obtained fi tness values. Although the lines 12 and 13 are in the while and for loops, they are executed m times in the worst case, because there are m different intensity values. Hence, CMF will be called at most m times, in O ( mp 2 ) and the complexity of Line 14 is O ( m ). There are 2 parents and 2 offspring, so this operation is executed in 4 p 2  X  O ( p 2 ). Sorting these 4 is performed in O (4 log 2 4)  X  O (8) constant time. Thus, the com-The if control block in lines 19, 20, 21 and decrementing G variable by 1 are achieved in constant O (1) time. Hence, the total complex-ity is O ( GN  X  mp 2 ).
 Theorem 4. The running time complexity of peak fi nding based MNC is O(GN  X  N log 2 (N)  X  p 2 ) where N is the size of population and MR image has size of [p p].

Proof . The construction of an image histogram takes O ( p Line 2 fi nds the maximum intensity value of MR image that can be performed in O ( p 2 ) time complexity. Since the random population of size N is created, Line 3 is executed in O ( N ). The while loop in lines 5  X  16 executes O ( G ) times. Lines 6 to 14 repeat for each member A of population, so the complexity is O ( N ). Line 7 selects C number (i.e. small constant value of 4) of members from the population. It takes constant time O (1). Finding M which is the most similar member to A from the selected members, is executed in O (1) time. Line 9 creates offspring Z from A and M by interval crossover. It performs in O (16). Line 10 mutates Z in O (16). Creating C groups (i.e. small constant value of 4) with s members randomly selected from the population is executed in O ( sC f ). Line 12 the most similar member to Z from each group in O ( sC f ). Among the similar members, replacing the least fi t member with Z takes O ( C f ) time. Thus, the complexity of while loop is O ( GN ( sC C and s are constant values that can be ignored. So, the while loop complexity can be simpli fi ed as O ( GN ). Counting is performed in O ( N ) and sorting the frequencies of each population member is executed in O ( N log 2 ( N )), so Line 17 takes O ( N log 18 and 19 set the peak 1 and peak 2 variables in O (1). Thus, the total time complexity for peak fi nding based on multi-niche crowding algorithm is O ( GN  X  N log 2 ( N )  X  p 2 ).
 Theorem 5. The running time complexity of EVM algorithm is O (N log 2 (N)  X  GN  X   X  p 2 ) where each MR image has size of [p p], G is the number of generations, N is the size of population and intensity value range.

Proof . Line 1 fi nds m , the maximum intensity value of MR image in O ( p 2 ). While fi nding peak 1 and peak 2 multi-niche crowding based algorithm with O ( GN  X  N log 2 ( N )  X  p 2 ) complexity is used. Line 3 fi nds the valley between peaks and Line 4 fi nds the matched valley point using GA. GA performs in O ( GN ), since it checks each generations in the population. Calculating range q is executed in constant O (1) time. CMF usage in the ECD algorithm is done for m intensity values. But in EVM algorithm, CMF is called for only the intensity values in the range (  X  )of[ peak 1, w ]. Since GA with function CMF is used, Line 6 takes O ( GN  X   X  p 2 ) time while the threshold. Thus, the total time complexity of the evolutionary valley matching algorithm is O ( N log 2 ( N )  X  GN  X   X  p
Theorem 6. The running time complexity of Line Cutting Algorithm is O(c log 2 (c)) where c is the number of bins used in the image histogram.

Proof .Line1takes O (1) time to complete. Line 2 tests all bins to continues this process until the count of line segments reach 20 or minimum value of the largest orthogonal distance is reached. There-fore, the algorithm takes O ( c log 2 ( c )) time to complete.
Theorem 7. The running time complexity of Verard ' s Algorithm is O (p c log 2 (c)) where each MR image has size of [p p], and c is the number of bins used in the histogram.
 Proof . The histogram construction takes O ( p 2 ) time on Line 1.
The line cutting algorithm used in Line 2 takes O ( c log
Line 4 sums up the values starting from point E in O ( c ) time and assigns the value to F T . Line 5 fi nds the threshold point where the cumulative histogram value equals 0.4 F T in O ( c ) time. The loop between lines 6  X  16 runs at most 60 times. The thresholding on
Line 7 and the identi fi cation of areas on Line 8 takes O ( p
Line 9 fi nds the candidate regions in linear time which depends on the number of regions in O (1). Line 10 takes constant time to compare region properties to prede fi ned CC and BS values. The control statements between lines 11 and 15 take constant time O (1). Therefore, the total time complexity of the algorithm is O ( p c log 2 ( c )). 4. Conclusion and future work
In this paper, we have proposed three distinct novel algorithms to extract CC from T1-weighted midsagittal brain MR images.
In order to interrogate the generalization characteristics of our algorithms, we have tested them on to two different datasets captured on a 3 Tesla MRI; Ege University MRI Dataset which consists of 67 images, and IXI MRI dataset of Imperial College which consists of 185 images ( Imperial College, 2013 ). The methods in literature focus commonly on extraction of
AC and PC points for registering MR images. These are the reference points used to align subject's image onto the Talairach atlas ( Talairach and Tournoux, 1988 ). In current studies, locating
AC and PC points can be easily done through the positioning of CC structure. Most of them extract CC manually.

In our study, we propose three novel fully automated algo-rithms to extract CC: VM, ECD and EVM. The existing methods cannot output performances that can rival ours, because a coarse extraction of the area including CC is adequate for them.
VM successfully extracts 95.52% of the Ege University MRI dataset. The corresponding point, w , is successfully matched as the threshold point in 61% of the cases. This speeds up the algorithm.
VM extracts 43.8% of the images of the IXI MRI Dataset. Since VM is based on histogram analysis, the differences in the size and the illumination pro fi les on IXI MRI Dataset directly affects the perfor-mance of VM. The images in the IXI MRI Dataset are in the size of 256 256 and the illumination pro fi le of 3 Tesla Philips system is not identical to 3 Tesla Siemens system. One of the future works related with VM algorithm is to generalize it.

ECD, based on evolutionary algorithm attains a 92.5% success rate on Ege University MRI dataset, and performs 74% on IXI MRI
Dataset. ECD performs better than VM, because of CMF function which uses anatomical ratios instead of prior fi xed information. Besides, the preprocessing steps of VM are not required.
EVM, also based on evolutionary algorithm, reduces the search space of ECD by applying the principles of VM. So, EVM is faster than ECD. EVM has a success rate of 91% on Ege University MRI
Dataset and 81% on IXI MRI Dataset. Since the VM is going to be improved in an upcoming study, the EVM is also going to be revised.
 EVM is the most accurate and affective algorithm for extracting
CC on both datasets. According to the variety of subjects under the parameters of age, sex and ethnicity of the datasets, EVM solution is a generalization for automatic CC extraction problem.
Our three novel algorithms form the basis for the future studies on medical imaging that deal with intensity-based CC extraction methods. They are also important for landmark points detection as a preprocessing step. AC and PC points are valuable among these landmarks. Because, the line determined by the AC and PC positions is used for image registration to brain atlases. Our algorithms can be used as a preprocessing module for model-based approaches to get segmented CC as input. Besides, our algorithms can be used in medical image segmentation where the interested tissue extraction is required.

It is also planned to publish the Ege University MRI Dataset with open access for the researches in this area.
 Acknowledgments The authors wish to express their gratitude to Prof. Dr. Ali Saffet
G X n X l of the Faculty of Medicine, Ege University for his guidance and the provision of the brain MR image dataset used in SoCAT projects. The gratitude is also extended to the Radiology Depart-ment for their continuous support.
 References
