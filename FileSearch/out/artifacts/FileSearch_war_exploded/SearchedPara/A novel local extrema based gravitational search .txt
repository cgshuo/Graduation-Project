 1. Introduction
In recent years face recognition has become a widely researched topic since it has numerous real world applications like authentica-tion, identi fi cation, advanced human computer interaction and many of pattern recognition, image processing, computer vision, machine learning, etc. With the growing imp ortance of biometric recognition systems ( Jain and Prabhakar, 2004 ), due to low susceptibility to security loss, face recognition based biometrics has gained much popularity in recent times.

Many approaches to face recognition have been proposed over the last two decades ( Zhao et al., 2003; Jafri and Arabnia, 2009;
Chakrabarty et al., 2013 ) most of which are based on supervised learning. Hence they follow a common sequence of steps. There is a be a feature selection/reduction procedure where a reduced set of highly discriminating features are selected employing a suitable algorithm which may attempt to op timize a suitable cost function. ( Ye et al., 2004 ), singular value decomposition (SVD) based method ( Gao et al., 2008 ) etc.

Our present research concentrates on those more challenging face recognition problems which suffer from small sample size (SSS) problem, typically in those situations where there is only a single training sample available per class/person. The research on face recognition problem using single training sample per person is well known as a very challenging probl em and it has gained prominence law enforcement, critical surveillance scenarios and checking for access control etc. ( Tanetal.,2006;Zhuetal.,2012 ). Our present work is inspired by the method proposed by Gao et al. (2008) in which the single training image of a particular class is decomposed into two component images using SVD and then the intra class distance can be conveniently determined using these two resulting images. However, the SVD based FLDA approach in Gao et al. (2008) paper we propose a novel method of solving the FLDA cost function with the feature extraction phase, thus effectively merging the operations required in two steps. The iterative stochastic optimiza-tion problem is solved using a recently proposed method, called gravitational search algorithm (GSA). GSA is a powerful iterative optimization algorithm based on Newton's laws of gravity and motion ( Rashedietal.,2009;Paletal.,2013 ). Several interesting applications have recently been proposed using GSA in the domains of e.g. image processing ( Sun and Zhang, 2013 )anddataclustering ( Hatamlou et al., 2012; Hatamlou et al., 2011 ). Three modi the GSA have been proposed in this paper with the objective of the GSA in processing of 2-D images. The second variation introduces a novel random local extrema based GSA (RLEGSA). To the best of our knowledge and belief, although some local best methods have been proposed earlier for a similar swarm intelligence based method called particle swarm optimization (PSO) ( Suganthan, 1999; Das the genre of GSA. The third variation incorporates the automated selection of projection vectors within the GSA based cost function optimization framework.

The rest of this paper is organized as follows. Section 2 provides a description of the SVD and FLDA based feature extraction schemes for the single training image per person scenario.
Section 3 describes an overview of the traditional gravitational search algorithm and detailed descriptions of the novel variants proposed in this work. Section 4 presents the experiments and simulation results. Section 5 concludes the paper. 2. SVD and FLDA based feature extraction scheme Let us consider there are C classes with each having a single image
I
A  X  m n ( k  X  1, ... , C ). If m Z n ,thenlet U k A  X  m m value of I k such that s i k is in descending order of magnitude as be described as ( Gao et al., 2008; Golub and Loan, 1983 )
I  X 
Hence each image can be thought of being constituted as a summation of n basis images where each basis image corresponds to a particular singular value and the energy content of a basis 3. Gravitational search algorithm and the proposed variants 3.1. Gravitational search algorithm (GSA)
GSA is a relatively recently proposed optimization algorithm consider an isolated system of p objects called agents or particles.
This can be considered a universe consisting of only these p agents which obey (1) Newton's Law of Motion and (2) Newton's Law of
Gravity. Let the position of the i th agent ( i  X  1, 2, ... dimensional space at time t be given by
X  X  t  X  X f x 1 i  X  t  X  ; x 2 i  X  t  X  ; ... ; x n i  X  t  X g X  11  X 
Also we de fi ne three types of masses of an agent ( Rashedi et al., 2009 ):
At a certain instant of time t , the gravitational force experi-enced by an object i due to the object j in the dimension d is given by Newton's Law of Gravity as follows ( Rashedi et al., 2009 ):
F  X  t  X  X  G  X  t  X  M pi  X  t  X  M aj  X  t  X  R gravitational mass of agent i ,  X  is a small positive constant (
R ( t ) is the Euclidean distance between two agents i and j .
R  X  t  X  X   X  X i  X  t  X  ; X j  X  t  X   X   X  13  X 
Now the gravitational constant G ( t ) at time t is given by ( Rashedi et al., 2009; Mansouri et al., 1999 )
G  X  t  X  X  G  X  t 0  X  t 0 t where t 0 is the initial time/iteration. Hence G ( t ) gradually decreases over time, representing the effect of ageing. The intro-duction of this concept facilitates stronger and stronger exploita-tions in later parts of iterations as it is desired that the changes should be lesser and lesser as the system converges toward a solution. The total gravitational force on a particle i in the d th dimension is ( Rashedi et al., 2009 )
F  X  t  X  X   X  p where rand j is an uniformly distributed random number in the interval [0,1]. This introduces the stochastic element into the algorithm. Next, by Newton's Law of Motion, the acceleration of the agent i at time t in dimension d is calculated as a  X  t  X  X  F where M ii is the inertial mass of the i th agent.

Now the velocity, position and mass update equations are as follows: v  X  t  X  1  X  X  rand i v d i  X  t  X  X  a d i  X  t  X  X  17  X  3.2. Two dimensional gravitational search algorithm (2-D GSA)
The fi rst modi fi cation of GSA proposed in this work is devel-oped in order to account for a two dimensional solution space. In this case the position variable for the i th particle ( i  X  1, 2, becomes an n n matrix (corresponding to the size of the W matrix) as follows:
X  X  t  X  X f x kl i  X  t  X g i  X  1 ; ... ; p ; k  X  1 ; ... ; n ;
Thus the modi fi ed force calculation equation between two particles is developed as
F  X  t  X  X  G  X  t  X  M pi  X  t  X  M aj  X  t  X  R given as
R  X  t  X  X   X  X i  X  t  X  ; X j  X  t  X   X   X  26  X 
F  X  t  X  X   X  p
Accordingly, the modi fi ed acceleration, velocity and position update equations are given as a  X  t  X  X  F v  X  t  X  1  X  X  rand i v kl i  X  t  X  X  a kl i  X  t  X  X  29  X  x  X  t  X  1  X  X  x kl i  X  t  X  X  v kl i  X  t  X  1  X  X  30  X 
The mass update equations remain the same as in the tradi-tional GSA. 3.3. 2-D random local extrema gravitational search algorithm (2-D RLEGSA)
This is the second proposed variation of GSA in this paper, where instead of using the global best and global worst values in 3.4. Modi fi ed random local extrema gravitational search algorithm (MRLEGSA) incorporating automated selection of number of projection vectors
In Gao et al. (2008) , the scheme actually utilized different subsets of projection vectors from the optimal transform matrix solution W obtained by solving the generalized eigenvalue problem. The selection of number of f such projection vectors from the n vectors in W matrix ( f r n ) and which such f vectors should be chosen were both carried out manually. Their extensive experimentations showed that, for each separate face database, the performance varies individually with variation in number and choices of f vectors and no correlation can be obtained in determining their optimal choices which means they had to make an extensive manual search for the best combination of f vectors for each face database. This inspired us to propose an improved algorithm which can perform an additional task of an automated selection of the number of optimal projection vectors to be chosen from the W matrix and which candidate f vectors should be chosen that will lead to better performance accuracy. This has been referred to here as the third proposed modi fi cation of GSA. It actually augments the RLEGSA proposed in the previous subsec-tion by incorporating the automated selection of number of projection vectors and also which projection vectors to be chosen from the W matrix.

Here for the i th agent, the solution space contains, besides the n n matrix X i ( t ), an n 1 vector S i ( t ), given as
X  X  t  X  X f x kl i  X  t  X g n n i  X  1 ; ... ; p ; k  X  1 ; ... ;
S  X  t  X  X f s l i  X  t  X g i  X  1 ; ... ; p ; l  X  1 ; ... ; n  X  35  X 
The vector S i ( t ) is named the selection vector since it will be used to select the optimal number of projection vectors. Each element in the selection vector S i ( t ) is initialized by a number pulled from a uniform random distribution in [0, 1] and then it undergoes modi fi cations in its velocity and position in each UNTIL termination criterion is satis fi ed vs  X  t  X  1  X  X  rand i vs l i  X  t  X  X  as l i  X  t  X  X  45  X 
Hence the new position and selection update equations are given as x  X  t  X  1  X  X  x kl i  X  t  X  X  vx kl i  X  t  X  1  X  X  46  X  s  X  t  X  1  X  X  s l i  X  t  X  X  vs l i  X  t  X  1  X  X  47  X  smax  X  t  X  1  X  X  max f S i  X  t  X  1  X g X  48  X  smin  X  t  X  1  X  X  min f S i  X  t  X  1  X g X  49  X  ^ s  X  t  X  1  X  X  s l i  X  t  X  1  X  smin i  X  t  X  1  X  smax sbin  X  t  X  1  X  X 
Now normalized Euclidian distance of the i th particle from any other particle is given as d  X  max j  X   X  X i X j  X   X  where j  X  1to p and j The corresponding distance vector for particle i is given as
D  X f d ij g ; j  X  1 ; 2 ; ... ; p  X  53  X 
D  X  sort ascend  X  D i  X  X  54  X  Thus the neighborhood of the i th particle is given as
N  X  particles corresponding to first q t i elements of D asc where q  X  t  X  X  K t iter
If q i ( t ) 4 p then q i ( t )  X  p , and K the scaling constant. fi t ( t ) is the fi tness value of the agent i at time t .
Now, the selection variables introduced will become operative while calculating the fi tness fi t i ( t ). The feature matrix W for evaluation of the fi tness function corresponding to the candi-date solution X i ( t ) is extracted as
W which are equal to 1.

The formulations of fi t i ( t ), lbest i ( t ), lworst i
M ( t  X  1) remain unchanged as given in Section 3.3 . Algorithm 3 describes the implementation of the Modi fi ed RLEGSA. Algorithm 3. MRLEGSA.
 BEGIN
Create p particles and make randomized initialization of position matrices X and selection vectors S .
 Initialize iteration number t  X  1 REPEAT:
END 4. Experimental results
Extensive experimentations have been carried out to determine the effectiveness of the proposed algorithms. At fi rst the 2-D version of the traditional GSA proposed in Section 3.2 and the local extrema based variation (RLEGSA) proposed in Section 3.3 have been separately evaluated on two well known benchmark face databases and the recognition accuracies have been compared with four existing comparable methods, as shown in Table 1 . The
Yale A database published by Yale University has 11 images each from 15 individuals with lighting, occlusion and facial emotion variations. Fig. 1 shows the 11 different images for one person in the Yale A database. The ORL database published by Cambridge
University has 10 images each from 40 individuals. Here there are also variations of occlusion and facial expressions along with changes in scale and tilting. Fig. 2 shows the 10 different images for one person in the ORL database.

During training, the fi rst image of each individual is taken as the single training image. All the remaining images have been taken as testing samples. For classi fi cation purpose a simple et al. ). These conditions are chosen to be identical with the experimental conditions considered in other methods chosen here for comparison so that we can perform a fair comparison in an identical platform. As mentioned, the performance of the pro-posed method is compared with four state-of-the-art, competing, existing methods, all of whom use different variations of 2-D FLDA for a similar face recognition problem using single training image based on the projection approach. It reported a top recognition accuracy of 18.67% for Yale A database and 44.17% for ORL database. The second method, proposed by Zhang et al. (2005) , is based on the singular value perturbation approach. It reported a top recognition accuracy of 23.33% for Yale A database and 46.39% for ORL database. The third method, proposed by S. Chen et al. (2004) , is based on the non-overlapping image block approach.
It reported a top recognition accuracy of 32.00% for Yale A database and 70.83% for ORL database. The fourth method, proposed by Gao et al. (2008) , reported a top recognition accuracy of 34.67% for Yale A database and 75.56% for ORL database.
In comparison, by using the 2-D version of the traditional GSA, the top recognition rates achieved are 32.73% for Yale A database (comparable to method 3) and 75.56% for ORL database (compar-able to method 4). However using the proposed 2-D RLEGSA top recognition rates achieved are 38.57% for Yale A database and 76.92% for ORL database which could comfortably outperform all its fi ve competing algorithms. This shows that the proposed local extrema based version of the 2-D GSA could prove to be indeed face recognition problems using single training images per person.
To make a performance comparison of the recognition rates for different competing methods with variations in the manually chosen number of projection vectors, for different face databases, the detailed performance evaluation results are plotted in effort and yet it could produce almost identical performance as
RLEGSA which means it was successful, in each case, to auto-matically determine the best performing f optimal projection vectors, because of which the top performance of RLEGSA could also be approached using MRLEGSA. Hence the objective of introducing the innovation in MRLEGSA to automate a manual, tedious procedure and yet achieve the desired, best performance was fully achieved.

The results obtained for the two benchmark databases employ-ing the proposed 2-D RLEGSA are further analyzed in greater detail by calculating several popular performance indices like true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN). Further analyses are also carried out to calculate other popular performance measures like precision and speci
These results are presented in Table 3 . These results demonstrate that for the ORL database the results obtained are quite encoura-ging as both precision and speci fi city values calculated are quite high. However, for the Yale A database, the precision value is quite
These results are, overall, in conformation with the results pre-sented in Table 1 where it has been demonstrated that, generally speaking, the overall performance achievable for ORL database is much better than for Yale A database, for single training sample per person situation. However, it has also been shown in Table 1 that, for the Yale A database, compared to other competing algorithms, our proposed 2-D RLEGSA could achieve quite superior performance.

Finally, a detailed discussion on the computation time com-plexity comparison of the proposed methods is provided in
Table 4 . For each algorithm, the average computation time con-sumed over 10 independent runs is calculated and reported here, for each of Yale A and ORL databases. These algorithms were simulated in MATLAB 2011b environment with system speci fi tions being 8 GB RAM, INTEL i7 processor and Windows 8 OS.
The results show that 2-D GSA consumes least computation time. This is understandable because, among the three variants of
GSA developed in this work, this variant is least complex and also the accuracy achievable with this method is not satisfactory.
Another notable feature is that, for each run of MRLEGSA, the average time consumed is not more than 20% of the average time consumed for each run of RLEGSA. On the other hand, as mentioned before, RLEGSA requires several trial runs before the best performance can be achieved, whereas this process is auto-mated in MRLEGSA where it can fi nd the optimized performance in a single run. Hence it can be easily appreciated that MRLEGSA can produce satisfactory and comparable performance with respect to RLEGSA and, overall, it requires less computational time compared to RLEGSA. Hence, this analysis further justi fi utility of MRLEGSA over that of RLEGSA, as mentioned before. 5. Conclusions
In this work, a new approach to solve SVD based face recogni-tion problems involving single training image per person is proposed using stochastic optimization approaches. The problem is solved using GSA, a contemporary algorithm recently proposed under the category of heuristic optimization methods, which attempts to determine an optimal transform matrix W such that a cost functional J ( W ) is minimized. In this context two new variants of GSA, called the 2-D version of GSA, and a 2-D randomized local extrema based GSA (RLEGSA) have also been proposed. Then further sophistication is incorporated in this approach, by automating the process of selection of projection vectors to propose another new variant called Modi fi ed RLEGSA (MRLEGSA). Several experiments carried out for two benchmark
