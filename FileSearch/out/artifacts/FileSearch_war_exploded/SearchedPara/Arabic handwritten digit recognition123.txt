 Sherif Abdleazeem  X  Ezzat El-Sherif Abstract In this paper, we fill a gap in the literature by studying the problem of Arabic handwritten digit recogni-tion. The performances of different classification and fea-ture extraction techniques on recognizing Arabic digits are going to be reported to serve as a benchmark for future work on the problem. The performance of well known classifiers and feature extraction techniques will be reported in addi-tion to a novel feature extraction technique we present in this paper that gives a high accuracy and competes with classifier/features combinations will be evaluated on Arabic digits in terms of accuracy and classification time. The results are analyzed and the problem of the digit  X 0 X  is identified with a proposed method to solve it. Moreover, we propose a stra-tegy to select and design an optimal two-stage system out of our study and, hence, we suggest a fast two-stage classifica-tion system for Arabic digits which achieves as high accuracy as the highest classifier/features combination but with much less recognition time.
 Keywords Benchmark  X  Arabic digits  X  Indian digits  X  Classifiers  X  Feature extraction  X  Two-stage 1 Introduction Handwritten digit recognition problem can be seen as a sub-task of the more general Optical Character Recognition (OCR) problem. However, there are some applications (e.g., postal code and bank checks reading) that are restricted to recognizing digits but require very high accuracy and speed. In addition, handwritten digit recognition problem is usually used as a benchmark for comparing different classification techniques [ 1 ].

While recognition of handwritten Latin digits has been extensively investigated using various techniques [ 1  X  8 ], lit-tle work has been done on Arabic handwritten digit recogni-tion. Al-Omari et al. [ 9 ] proposed a system for recognizing Arabic digits from  X 1 X  to  X 9 X . They used a scale-, translation-, rotation-invariant feature vector to train a probabilistic neural network (PNN). Their database was composed of 720 digits for training and 480 digits for testing written by 120 persons. They achieved 99.75% accuracy. Said et al. [ 10 ]usedpixel values of the 16  X  20 size-normalized digit images as features. They fed these values to an Artificial Neural Network (ANN), where number of its hidden units is determined dynamically. They used a training set of 2400 digits and a testing set of 200 digits written by 20 persons to achieve 94% accuracy. In a previous paper [ 11 ], we introduced a large Arabic Digits dataBase (the ADBase X  X ee Sect. 2.1 for more details) and devised a two-stage system for recognizing Arabic digits. The first stage is an ANN fed with a short but powerful feature vector to handle easy-to-classify digits. Ambiguous digits are rejected to the more powerful second stage which is an SVM fed with a long feature vector. The system had a good timing performance and achieved 99.15% accuracy on the ADBase. Note that results of different works cannot be com-pared because the used databases are not the same.

Naming conventions for different numeral systems may be confusing. Digits used in Europe and several other coun-tries sometimes are called  X  X rabic Numbers X ; and digits used in Arab world are sometimes called  X  X indi Numbers X . A different naming convention is used in this paper. Digits used in Europe will be referred to as  X  X atin Digits X  and that used in Arab world as  X  X rabic Digits X . It is worthwhile to mention here that Arabic and Persian handwritten digits (digits used in Iran) are similar but not identical. However, there are some writing styles for Persian digits that are very similar to Arabic which leads some researchers to consider Arabic and Persian digits to be the same [ 12 , 13 ]. Tables 1 and 2 show Arabic and Persian handwritten digits with different writing styles as well as their printed versions.

In this paper, we are going to study the performance of various classifiers/features combinations on the Arabic digit recognition problem. Well-known feature extraction tech-niques besides one novel technique we introduce in this paper are considered. Results are then analyzed leading to the notice of the problem introduced by the Arabic digit  X 0 X . A sug-gestion of how to alleviate this problem is then introduced. For the sake of comparison, the performances of the same classifier/features combinations are evaluated on Latin digits. Moreover, a selection process of a two-stage system is pre-sented and an optimal two-stage system for Arabic digits is suggested.
 The remaining of the paper is organized as follows. Section 2 is about the two Arabic digits databases used in this study: the ADBase and the MADBase. Sects. 3 and 4 introduce the classification and the feature extraction tech-niques used, respectively. Section 5 reports and discusses the results. Section 6 is about the selection process of the opti-mal two-stage classifier for Arabic digits. And in Sect. 7 ,we conclude. 2 Arabic digits databases Both databases (ADBase and MADBase) are available for free online at http://datacenter.aucegypt.edu/shazeem . 2.1 The ADBase The ADBase [ 11 ] is composed of 70,000 digits written by 700 participants. Each participant wrote each digit (from  X 0 X  to  X 9 X ) ten times. The database is partitioned into two sets: a training set (60,000 digits to 6,000 images per class) and a test set (10,000 digits to 1,000 images per class). Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from single institution (to ensure variability of the test set). 2.2 The MADBase The MADBase is a modified version of the ADBase that has the same format as MNIST [ 1 ]. This is done to ensure the validity of any comparison made between Latin and Ara-bic digit recognition problems (see Sect. 5 for a comparison between Arabic and Latin digits results). The MADBase is created from ADBase as follows. For each digit of ADBase, its height ( h ) and width ( w ) are calculated, and then size-normalized [ 20 ] to have a new height ( h new ) and new width (w whether h or w is greater. If h &gt;w, then h new is set to 20, and w new to floor ( 20  X  w/ h ). If w&gt; h , then w new to 20 and h new to floor ( 20  X  h /w). This procedure ensures that each digit of MADBase is confined in a 20  X  20 box, while its aspect ratio is preserved. Then each digit is placed in a 28  X  28 white background such that its center of gravity coincides with the center of the white background.
 Note that the images of the ADBase are binary. When the ADBase images are down-sampled to form the MADBase, an antialiasing filter is applied to the images. This made the images of the MADBase gray-scaled.

Figure 1 shows samples of ADBase and their MADBase versions. In this paper, we evaluate the performance of dif-ferent classification and feature extraction techniques on MADBase. The ADBase is used just for extracting size infor-mation required to alleviate the problem of the Arabic digit  X 0 X  as will be clear in Sect. 5 . 3 Brief description of the used classification techniques In this section, a brief description of each of the used clas-sification techniques is going to be presented. In the results section (Sect. 5 ), the accuracy of each classifier/features com-bination and the timing performance of each classifier will be reported as well. Some of the used classification techniques have parameters that need to be specified (e.g. number of hidden neurons in the neural network). Such parameters are optimized using a validation set. The validation set is com-posed of 10,000 samples chosen randomly from the training set. Once the optimized parameters values are found, they are used to train the classifiers on the whole training set. 3.1 K -Nearest neighbor The K -Nearest Neighbor (KNN) [ 14 ] is one of the simplest classification techniques; yet gives surprisingly high accu-racy. In KNN, there is no training stage. All training samples must be present in the testing phase; and Euclidean distances between each training sample and the sample to be tested are calculated. The K training samples that have the smallest distances to the test sample are found and their classes are identified. The most frequent class in the selected K training samples is declared to be the class of the test sample. In this study, we used K = 3. 3.2 Parzen window Parzen window estimates the probability density for the input feature space using kernel density estimation technique [ 15 ]. In this technique, every sample in the training set creates a bump in the feature space with a shape that depends on the type of kernel used. For a certain test sample, the probability that it belongs to a certain class is the sum of all the contribu-tions of bumps created by the training samples of that class at this test sample. The kernel used in this study is the Gaussian kernel with a variance chosen to have the best performance on the validation set. The Parzen window, like KNN, needs all the training set to be available at test time. 3.3 Two-layer neural network The Two-Layer Neural Network (2-NN) [ 14 ] is one of the most powerful classifiers. It can actually model any target function if we are allowed to increase the number of hidden units as we wish. Unfortunately, an ANN with very large hidden layer trained by limited number of training samples gives poor results because of the overfitting problem. Hence, the number of hidden units of ANN should be selected to be high enough to model the problem at hand but not too high to overfit. The number of hidden units is selected to have the best performance on the validation set. 3.4 OVO One-Layer Neural Network One-Layer Neural Network (1-NN) is a linear classifier that originally solves two-class problems. One way to extend linear classifiers to the C -class case (where C = 10 in case of our problem) is to train C different two-class linear classi-fiers; each responsible for separating one class from the other ( C  X  1) classes. This technique is called  X  X ne-versus-All X  (OVA) learning. Another approach is the so-called  X  X ne-versus-One X  (OVO) or  X  X airwise X  approach [ 16 ]. In this tech-nique, C ( C  X  1 )/ 2 classifiers (45 classifiers in our case) are trained. Each classifier is trained using the training samples of just two classes; i.e., each classifier specializes in sepa-rating just two classes. In the test phase, each test sample is presented to all the C ( C  X  1 )/ 2 classifiers; and the most fre-quently decided class is declared the winner. An OVO linear classifier can construct decision boundaries that cannot be constructed using an OVA linear classifier [ 17 , 18 ]; hence, it is more powerful. 3.5 PCA + Quadratic Linear classifiers assume that decision boundaries needed for classification can be constructed using a set of hyperplanes. Such an assumption may or may not hold. If this assump-tion does not hold and we still wish to use a linear classifier, we may transform the problem into a space of much higher dimension; high enough for the problem to be linearly sepa-rable. One way to increase the dimensionality of the problem is to use a polynomial expansion of the input vector. Unfor-tunately, this expansion leads to prohibitively large dimen-sionality especially if the problem original dimensionality is already high. One way to overcome this problem is to select only the most informative dimensions of the original pro-blem and ignore the others. Most informative dimensions (in the original space or a linearly transformed version of it) can be found using Principal Component Analysis (PCA) algo-rithm [ 15 ]. In this work, we use PCA to extract the most informative dimensions and then quadratically expand them [ 1 , 3 ]. The quadratically expanded feature vector is then fed to 1-NN. We denote this technique PCA + Quadratic. 3.6 OVO linear SVM SVM is considered one of the most powerful classification techniques and is now widely used in many pattern recog-nition applications. The linear SVM is originally a binary classifier that constructs a hyperplane separating between two classes just like 1-NN. However, SVM algorithm tries to find the most optimal separating hyperplane; the one that achieves maximum margin [ 19 ]. To extend the linear SVM to handle the multiclass case ( C &gt; 2) we used the OVO technique discussed earlier. We add here that the linear SVM could be seen as an SVM with a dot product kernel K ( x 1 [ 19 ], K ( x where s is constant, we chose to be 1. 3.7 OVO RBF SVM The linear SVM assumes that classes to be separated are linearly separable. If this assumption does not hold, then we can use the idea of space dimensionality expansion discussed earlier. Because the expanded space would be of very high dimensionality, the feature dimensionality might be reduced first using PCA. However, non-linear SVM uses a mathema-tical trick that enable us to expand (using a kernel) the feature vector to any dimensionality we desire (even infinite dimen-sionality!) without actually the expansion process [ 19 ]. The nonlinear SVM is originally designed for two-class problem. Extending it to multi-class can be done using the OVO or the OVA schemes. We used the OVO scheme. [start delete] We evaluated only the unique support vectors to optimize the recognition time [end delete]. The kernel we used is the RBF kernel K ( x 1 , x 2 ) , K ( x where the  X  is the RBF kernel parameter.

To classify a pattern x using OVO RBF SVM, the follo-wing discriminant function g nm ( x ) is evaluate for each class pairofclasses n and m , g where x nmi is the i th pattern in the subset of the training set containing classes n and m , X  nmi  X  X  are constants found by the training algorithm of SVM, and y nmi  X  X  are constants such that y =+ 1 when x x nmi belongs to class m values for only a subset of the training set called  X  X upport vectors X . Eq. ( 3 ) then needs not be calculated for all training set patterns; only support vectors need to be considered. The number of support vectors then is an important factor affec-ting the evaluation time of the nonlinear SVM. Actually, there are many situations in which we find that a certain training pattern is used as a support vector in more than one binary classifier of the OVO scheme. Hence, to save recognition time, we apply the kernel for a certain support vector for some pair of classes only once. If the same support vector is used with another pair of classes, its previously calculated kernel evaluation is used. The common support vectors are found as follows. We prepare a list that is initially empty to hold the common support vectors (we will denote it CSV ). After training a binary SVM that separates between digits n and m , it will have a list of support vectors SV nm . Each ele-ment of SV nm is considered; if it is already in CSV , we ignore it and continue scanning SV nm ; if not, we add it to CSV .We do this for all binary SVMs. While doing such scanning of support vectors, we also replace the list of support vectors of each binary SVM, SV nm , with a new list that contains a pointer for each support vector to its location in CSV ;we call this list PSV nm . Now, when a pattern x is required to be classified by the OVO SVM scheme, we calculate the kernel evaluations for this pattern using each common support vec-tor in CSV , and then put them in a list we call KCSV with the same order of common support vector in CSV .Nowwe are done with all the necessary kernel evaluations. To calcu-late the value of Eq. 3 for the pattern x , we scan the PSV in each binary SVM and grab the corresponding previously calculated kernel evaluations from KCSV . 3.8 Gaussian classifier Gaussian classifier (GC) starts with the assumption that the probability distribution of feature vector of each class is Gaussian. This leads to the following discriminant function for class c [ 14 ], g ( x ) = x t W ln | c | ,  X  c is the estimated mean of x that belongs to class c , to class c , and  X  t  X  denotes matrix transpose. The parame-ters  X  c and c are estimated for each class in the training phase using any parameter estimation technique like maxi-mum likelihood which we used. We note that the size of the matrix c is d  X  d ; this means that the number of parameters to be estimated is a function of d 2 . For large feature vector, this leads to overfitting and the inverse of c becomes singu-lar. To avoid this, we may put some restrictions on the form of the covariance matrix, e.g. all classes have the same . Another option is to reduce the dimensionality of the pro-blem, e.g. using PCA. We have taken the latter approach. The dimension of the feature vector after applying PCA ( d ) is specified using the validation set. Noting that the quantities W 3.9 Fisher linear discriminant Fisher linear discriminant technique [ 15 ] separates two classes using a linear hyperplane defined by the equation, w x + w 0 = 0 , where w = S  X  1 1 is the first class covariance matrix, 2 is the second class covariance matrix, and w 0 = X  1 2 (  X  1 +  X  2 ) S  X  1 The technique is extended to handle multiclass using OVO scheme described in Sect. 3.4 . 4 Brief description of the used feature extraction techniques In this comparative study, we use a set of well-known fea-ture extraction techniques. In addition, we introduce a novel feature extraction technique we called  X  X ocal directional features X  that gives high accuracy rate compared with other features. In this section, a brief description of the used feature extraction techniques is introduced.

All feature extraction techniques that will be discussed operate on the 20  X  20 window of the MADBase image that confine the digit; i.e. after removing the blank border around it. After applying the feature extraction algorithm on a digit image, a variable transformation (x 0 . 5 ) is then applied on the resulting feature vector [ 3 ]. 4.1 Gradient features To extract gradient features [ 3 ], the gradient operator is first applied to the gray-scale image of the digit to give two gra-dient components: strength | g ( x , y ) | and direction g at each point ( x , y ) of the image f . This is done by applying Sobel operator [ 20 ] on the image to extract vertical and hori-zontal gradient components, g ( x , y ) = f ( x + 1 , y  X  1 ) + 2 f ( x + 1 , y ) + f (  X  f ( x  X  1 , y  X  1 )  X  2 f ( x  X  1 , y )  X  f ( x  X  1 , y g ( x , y ) = f ( x  X  1 , y + 1 ) + 2 f ( x , y + 1 ) + f (  X  f ( x  X  1 , y  X  1 )  X  2 f ( x , y  X  1 )  X  f ( x + 1 , y where f ( x , y ) is the intensity of image f at point ( x ( x , y ) is the gradient component at x -direction at location ( x , y ), and g at location ( x , y ).
 Then the gradient strength and direction is extracted using Eqs. ( 7 ) and ( 8 ), respectively, | g ( x , y ) |= g 2 x ( x , y ) + g 2 y ( x , y ) (7) g ( x , y ) = tan  X  1 g y The gradient vector g ( x , y ) (expressed as strength [delete]strength[delete] | g ( x , y ) | and direction g ( each point ( x , y ) of the image is then decomposed into the eight Freeman [ 20 ] directions shown in Fig. 2 . The gradient vector is decomposed into the eight Freeman directions by projecting the vector into the nearest two Freeman directions as shown in Fig. 3 .

The gradient features are composed of eight layers; each corresponding to one of the Freeman directions. Each layer is the projection of the gradient vectors of the image into the corresponding Freeman direction.

A Gaussian mask h ( x , y ) is then applied to each layer, h ( x , y ) = and then the layers are uniformly sampled to give 5 measurements. The parameter  X  is related to the sampling interval t via the empirical relation  X  = that the gradient features are composed of 8  X  5  X  5 = 200 elements. The gradient feature extraction technique is very powerful as shown in [ 3 ] and as will be shown in Sect. 5 of this paper. 4.2 Kirsch features The Kirsch features [ 3 ] are extracted by decomposing the image into 4 layers corresponding to four edge orientations: horizontal ( g h ), vertical ( g v ), right diagonal ( g rd diagonal ( g ld ). These layers are extracted by applying Kirsch 555 -3 0 -3 -3 -3-3 -3 -3 -3 50-3 55-3 masks on the image, g g v = max ( | f  X  k v 1 | , | f  X  k v 2 | ), (11) g g where * denotes 2D convolution operation [ 20 ], k h 1 and k are Kirsch masks responsible for extracting horizontal edges, 1 and k v 2 for vertical edges, k rd 1 and k rd 2 for right diago-nal edges, and k ld 1 and k ld 2 for left diagonal edges. Figure 4 shows all Kirsch masks.

A Gaussian mask is then applied to all the 4 layers and 5  X  5 measurements are extracted from each of them in the same manner done with gradient features (Sect. 4.1 ). This means that Kirsch features are composed of 4  X  5  X  5 = 100 elements. 4.3 Local chain code features To extract the local chain code features [ 21 ], the contour of the digit is first followed by a contour following algorithm [ 31 ], and then each contour point of the image is marked with the corresponding Freeman direction. The image is then decomposed into 8 layers; each layer contains only contour points that belong to the corresponding Freeman direction. Each of the eight layers is then uniformly partitioned into 5  X  5 zones. Each zone is averaged leading to a feature vector of 200 elements. 4.4 Wavelet features Wavelet transform [ 20 ] extracts the essential information contained in a signal or image. This may help in reducing the dimensionality of the problem which leads to faster classifi-cation. Also it might reduce the noise and the non-essential information that may confuse the classifier leading to bet-ter classification performance. Wavelet transform could be applied on the image directly or could be applied on the gradient decomposition of the image [ 22 ]. In our study, we applied the former method. The image is first resized to be 64  X  64 and then the image is composed into three resolution levels. The third level approximation of the image (which is a 8  X  8 image) is then used as features. This means that wavelet features are composed of 64 elements. 4.5 Concatenation of low-dimensional features Here we concatenate six families of low-dimensional features to form one feature vector. While each of these low-dimensional features is not very effective, their concatenation proved to be a powerful feature vector. Each of the six low-dimensional feature families is going to be discussed in the following subsections. 4.5.1 Raw image zoning In this technique, the image is uniformly partitioned into 5 zones [ 23 ]. The average of each zone is calculated leading to a feature vector of 25 elements. See Fig. 5 . 4.5.2 Vertical and horizontal projections In this technique, the horizontal and vertical histograms of the image are calculated leading to a feature vector of 40 elements [ 23 ] (remember that we are working on the 20  X  window that confines the digit not all 28  X  28 pixels of the MADBase digits). See Fig. 6 . 4.5.3 Vertical and horizontal cross counts The image is first binarized, and then the vertical and hori-zontal cross counts are calculated. The vertical cross counts are calculated by scanning each row of the binary image and each transition from 0 to 1 or from 1 to 0 increases a coun-ter that has an initial value of zero; then the scanned row is associated with the counter value at the end of the scanning process. A similar procedure is done for each column. This leads to a feature vector of 40 elements. See Fig. 7 . 4.5.4 Centroidal distances In this technique [ 11 , 24 ], the digit image is partitioned into 16 sectors around the digit center of gravity (the centroid) as showninFig. 8 . Then the centroid of each sector is calculated. The distances between the whole digit centroid and sectors centroids are calculated and normalized by dividing them by the digit bounding box diameter. This forms a 16-element feature vector. 4.5.5 Directional features The directional features are formed as follows [ 11 , 25 ]. Each background pixel is labeled by a 4-element vector. For each background pixel we walk upward; if a foreground pixel is found, the first element of the 4-element vector is set to  X 1 X  otherwise set to  X 0 X . Then we walk to the right; if a foreground pixel is found, the second elements is set to  X 1 X  otherwise set to  X 0 X ; and so on till we finish the four principal directions. Then for each combination of 0 X  X  and 1 X  X  in the 4-element vector, we give a different label. Hence, we have 16 different labels.

The label  X 0000 X  that indicates finding no foreground pixel in any direction actually does not show up because the image border bound the digit either in the horizontal or the verti-cal direction. Hence, we have only 15 labels. Now each of background pixels has one label of the 15 labels. The final feature vector is the histogram of such labels giving rise to a 15-element feature vector. 4.5.6 Length-normalized contour In this technique [ 11 ], the horizontal and vertical coordinates of the boundary pixels of the digit are used as features. First, the boundary of the digit is extracted using a contour follo-wing algorithm; then, each boundary point is stored by its horizontal and vertical coordinates. Horizontal locations are magnitude-normalized by dividing them by the width of the digit bounding box. Vertical locations are also magnitude-normalized by dividing them by the height of the bounding box. Then both horizontal and vertical locations are parti-tioned into 10 portions and the average of each portion is calculated leading to a feature vector of length 20.
Feeding the classifier with the concatenation of different features without any preprocessing step would lead to very bad results because features of large magnitudes will domi-nate. Hence, we applied mean and variance normalization [ 14 ] to all the low-dimensional features discussed in this section before concatenating them into a feature vector of length 156. 4.6 Local directional features Local directional features extraction is a novel technique that, we present in this paper. It is a natural extension of the directional features presented in Sect. 4.5.5 . Like directional features, each background pixel is labeled by a 4-element vector which leads to 16 different labels. However not all labels are used. Only nine labels corresponding to 9 situa-tions are considered: (1) closed from all directions (i.e. black pixel can be reached when moving in all the principal four directions), (2) open up (i.e. black pixel can be reached when moving in the principal four directions except when moving upward), (3) open down, (4) open right, (5) open left, (6) open up and right, (7) open up and left, (8) open down and right, and (9) open down and left.

The image is then decomposed into nine layers; each layer corresponds to one of the nine labels. Pixel ( x , y ) in layer # n is illuminated only if pixel ( x , y ) in the image has been given the label # n . A Gaussian mask is then applied to all the nine layers and 5  X  5 measurements are extracted from each of them in the same manner done with gradient fea-tures (Sect. 4.1 ). This means that local directional features are composed of 225 elements. See Fig. 9 . 5 Results In this section, the accuracies of each pair of the nine classi-fiers and six feature extraction techniques on the Arabic digit recognition are going to be presented. Many of the classifi-cation techniques used have some parameters that need to be adjusted. Here we summarize these parameters and discuss how we set their values: (i) Number of hidden neurons of the neural networks (h). (ii) The constant C of the linear SVM.
 (iii) The constants C and  X  of the RBF SVM.
 (iv) The kernel variance of Parzen window (  X  2 ).
 (v) The dimensionality after applying PCA for the
Table 3 shows the parameters values used for different combinations of classifiers and features. Table 4 shows the accuracy of each combination on the MADBase test set. Table 5 shows the classification timing performance (not including feature extraction time) of each of the features/ classification. We measured the timing performance for a cer-tain classifier/features combination by the ratio of the CPU seconds needed to classify one pattern and the CPU seconds needed to classify one pattern using the classifier/features that have the least timing. The classifier/features combination that gives least timing was found to be linear SVM /Wavelet.
The column named  X  X verage accuracy X  of Table 4 shows the average accuracy of each feature set. This is used as an assessment of the powerfulness of each feature set. The last column orders the feature sets according to their average accuracies. Similarly, the row named  X  X verage accuracy X  shows the average accuracy of each classifier as an assess-ment of classification techniques powerfulness. The last row of the table orders the classifiers according to their average accuracies. 5.1 The problem of the Arabic digit  X 0 X  The Arabic digit  X 0 X  is just a dot which can be of various pecu-liar shapes when written fast by the hand as shown in Fig. 10 . Digit  X 0 X  may get confused with almost all other digits (espe-cially 1 and 5). However, the eye can easily differentiate bet-ween them because the digit  X 0 X  is clearly much smaller than any other digit. Table 6 shows the confusion matrix of the most powerful classifier/features pair: RBF SVM/gradient. It is clear from this confusion matrix that most of errors involve the digits  X 0 X . One way to solve this problem is to introduce a size sensitive feature to all the feature sets we used (this means that the length the feature vector of the gra-dient features becomes 201, and that of Kirsch becomes 101, etc.). This helps greatly in reducing the confusion the digit  X 0 X  introduces. The size-sensitive feature we propose is the area of the digit bounding box to the average bounding box areas of the training set digits. Because the MADBase digits are size-normalized, we calculated the size-sensitive feature using the original digit images of ADBase (see Sect. 2 for a discussion of ADBase and MADBase). Table 7 shows the confusion matrix of RBF SVM/gradient after adding the size-sensitive feature. Table 8 displays the accuracies of different classifier/features pairs on MADBase after adding the size-sensitive feature extracted from ADBase. 5.2 Latin digits For the sake of comparison, we applied the same classifiers/ features combinations to Latin digits of the MNIST library. The results are summarized in Table 9 . We see that the best classifier/features combination for both Arabic and Latin digits is RBF SVM with gradient features and both gain nearly the same accuracy (around 99.4%). This may lead to the conclusion that the two problems are the same. However, if we look at the less powerful classifiers/features combinations in Tables 8 and 9 , we see obviously that the results of Latin and Arabic digits are different. The reason why RBF SVM and gradient features always give the best results is that they are both powerful, not because different techniques perform the same for Arabic and Latin digits. But one may ask: what is the importance of the fact that less powerful classifiers performs differently on Arabic and Latin digits while the best classification technique performs equally likely? At the end, we will use the most powerful technique. This is really true if we used one stage classifier. But if we wanted to use a two-stage classifier, the less power-ful classifiers will be used; and hence, the difference between Arabic and Latin digits will lead to different structures of the two-stage system. This will be made clear in Sect. 6 . 6 An optimal two-stage classification system As noticed from Table 8 , the best accuracy on MADBase is achieved by RBF SVM with gradient features (99.48%). However, the classification time of the SVM is very high making the system not practical. A well-known technique to speed up the classification process is to use a two-stage struc-ture in which a fast classifier is put as a first stage and a time consuming classifier, yet more powerful than the first stage, is put as a second stage [ 27 , 28 ]. The pattern to be classified is handled first by the first stage. If the classification deci-sion of the first stage is made with high confidence score (the confidence score of the top class is higher than a predefined threshold), its decision is accepted and the classification pro-cess ends. If the decision confidence is below that threshold, it is rejected to be classified by the second stage. An impro-vement of this procedure is possible if the second stage has a different module for each class. In this case, when the first stage rejects some pattern to the second stage, it indicates also which classes had the k highest confidence scores [ 8 ]. Hence, the second stage could safely evoke the modules responsible for only those k classes saving considerable processing time. Figure 11 illustrates this idea.

In this section, we are going to search for the optimal two-stage system for the Arabic digit recognition problem using the classification and feature extraction techniques reported in this study. We mean by  X  X ptimal two-stage system X  the one that achieves the lowest recognition time under the condition that it achieves the highest possible accu-racy. We have 54 different features/classifier combinations; this means that there are 54  X  53 possible two-stage sys-tems. To find the optimal two-stage system, we may try all the 54  X  53 possible two-stage structures, and then selects the optimal one. However, this encounters unnecessary trials. Our definition of  X  X ptimality X  asserts that the two-stage sys-tem should achieve the highest possible accuracy. This could be achieved if we put the classifier that achieves the highest possible accuracy as second stage. It is true that a two-stage system could achieve accuracy higher than the second stage alone, but the increase in the accuracy, if it happens at all, is usually negligibly small. This reasoning leads us to put the RBF SVM with gradient features as the second stage which reduces the search space to only 53 trials. The search space could be reduced further if we study the case when a classifier with a feature extraction technique other than the gradient features is used as a first stage. In this case the fea-ture extraction step is evoked twice, one for the first stage and the other for the second stage. On the other hand, if we used the gradient features with the first stage, the feature extrac-tion step is executed only once to generate a feature vector for both first and second stage. Moreover, the gradient fea-tures set gains the highest accuracy with almost all classifiers as obvious from Table 8 ; this means that it will be the best choice for all first stage candidates. Thus we may safely not consider the features/classifier combinations that do not use the gradient features. Now, we are left with only 9 trials. If we note that the KNN and Parzen classifier are very time consuming and have recognition time more than the second stage itself, we can see obviously that they could not be pos-sible candidates to be first stage. Finally, the Fisher classifier has the same timing performance as the linear SVM but with lower accuracy which means that the linear SVM is for sure a better candidate to be first stage than the Fisher classifier. The same concept applies for the Gaussian classifier as it has higher recognition time than the linear SVM but with lower accuracy. Now we are left with four possible candidates for the first stage: (i) 1-NN, (ii) linear SVM, (iii) 2-NN, and (iv) PCA + Quadratic; all with gradient features. Our strategy is then to try the mentioned four classification techniques with gradient features as first stage and RBF SVM with gradient features as second stage on the test set and pick the one that achieves the lowest recognition time provided that the overall accuracy is as high as that of the second stage.

Now we are left with the problem of deciding the value of the first stage threshold and the number of classes k that are passed to the second stage. In the following two subsections, strategies for deciding the threshold and the parameter k are going to be introduced. 6.1 First stage threshold As our goal is to reduce the recognition time while retaining the accuracy of the second stage, the first stage threshold may be selected to be the one that commits no errors. This prevents the error leakage from the first stage. However, this will be too strict a strategy. We actually can allow the first stage to commit some errors if these errors are also commit-ted by the second stage. Hence, our strategy of picking the first stage threshold might be as follows. We first train the first stage on the set {training set}-{validation set} (see Sect. 5 for how we chose the validation set), then use it to classify the patterns of the validation set. We store a record for each clas-sified pattern of the validation set. Each record contains two entries: (i) whether the pattern is wrongly classified while correctly classified by the second stage (given code  X 1 X ) or otherwise (given code  X 0 X ) and (ii) the corresponding deci-sion score of the top class. And then all the validation set patterns records are ordered from high to low according to their decision score. This ordered list is then traversed form top to bottom searching for the first record of pattern that is wrongly classified and correctly classified by the second stage (i.e., marked with code  X 1 X ). When we find such pat-tern, we stop traversing the list and declare the decision score of this pattern to be the first stage threshold. This process is illustrated with a hypothetical example in Fig. 12 .
We add a note here that 1-NN and linear SVM were desi-gned using the OVO scheme which does not provide a smooth confidence score which is necessary for acceptable rejection performance. To alleviate this problem, we used the tech-nique devised by Price et al. [ 29 ] to produce an output pro-bability of the OVO scheme using the output probabilities of all the binary classifiers of the scheme. This worked well with 1-NN, but not with linear SVM as the binary linear SVM does not even produce probabilistic output. The linear SVM was made to give probabilistic output using the calibrating procedure devised by Platt [ 30 ]. 6.2 The parameter k The process by which we pick a value of k is described as follows. For each value of k (which ranges from 1 to 10), we calculate the number of errors committed. We consider an error is committed if the true class of the pattern is not among the top k classes. The value of k that leads to zero errors (in the sense described) is chosen. However, this will be too strict a criterion for choosing k as we can be tolerant for some errors to be committed as far as they are also committed by the second stage. Hence, we choose the value of k that leads to zero errors in the first stage that are correctly classified by the second stage.

We note here that the RBF SVM (the second stage) actually does not have a different module for each class, but a different module for each pair of classes. However, this is not a pro-blem as we can tailor a sub-classifier for the top-k classes using the binary classifiers concerning each of the top-k classes only. 6.3 Selecting the optimal cascade Table 10 shows the k values to reach zero error and number of patterns rejected to reach 1 error pattern for the first stage classifiers candidates. These two quantities are calculated using the validation set. Table 10 also shows the accuracy and recognition time of the overall system on the test set if each of the classifiers candidates is used as a first stage with k values and thresholds calculated using the validation set. The table indicates that 2-NN is the best candidate to be a first stage. Note here that the feature vector used is the one that includes the size-sensitive feature. This is why the timing performance of second stage alone (the RBF SVM with gradient features) appears in Table 10 is different from that appears in Table 5 in which the original feature vector without the size-sensitive feature is used.

For the sake of comparison, we applied the same proce-dure for selecting a fast two-stage classification system for Latin digits. The results are shown in Table 11 . We note here that the selection of the best two-stage system is not obvious whether it should be 1-NN or PCA-Quad as one achieves higher accuracy than the other but with higher recognition time. But it is clear that 2-NN (which is the best choice for digits. This means that while the best individual classifier for both Arabic and Latin digits is the same (RBF SVM with gradient features) the optimal two-stage system for them is not the same. This means that careful study of the problem at hand is necessary even if it looks very close to other known problems. 7 Conclusion In this paper, we have evaluated the performance of a number of feature sets and classification techniques on the problem of recognizing Arabic digits. Since there is very little research that has been done on Arabic digits so far, the results of our work hopefully serves as a benchmark for future research on Arabic digits. In addition, we have introduced a new feature extraction technique: the  X  X ocal directional features X . Out of the results we identified and alleviated the problem introdu-ced by the digit  X 0 X . Moreover, we proposed a strategy to select and design an optimal two-stage system and used it to suggest a two-stage system for Arabic digits that achieved very high accuracy with low recognition time.
 References
