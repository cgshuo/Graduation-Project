 Frequent subgraph mining has been an important research problem in the liter-ature, with many efficient algorithms proposed [10,12,21,24,1,8,17]. Given a col-lection D of graphs, frequent subgraph mining is to discover all subgraphs whose frequencies are no less than a user-specified threshold f min . Frequent subgraphs are useful in many applications, for example, as active chemical structures in HIV-screening datasets, spatial motifs in protein structural families, discrimina-tive features in chemical compound classification [4], and indexing features [26] in graph databases to support graph queries.

One major issue in frequent subgraph mining is the difficulty of exploring and analyzing numerous patterns generated due to the exponential number of com-binations. Given a graph with n edges, the total number of possible subgraphs could be 2 n . Hundreds of thousands of frequent subgraphs may be generated un-der a moderate minimum frequency threshold. A partial solution to this problem is mining closed or maximal frequent subgraphs [25,9,19], which generates fewer subgraph patterns. But in many cases the maximal and closed graph patterns can still be quite numerous, so the difficulty of exploring a large number of patterns still exists.

In the literature, there have been several methods which use probabilistic models to summarize frequent itemsets [23,22,11]. These probabilistic models, as a concise summarization, are effective t o restore all the frequent itemsets and their frequencies. In this paper, we also use a probabilistic model to summarize frequent subgraphs by preserving their structure and frequency information as much as possible. Given a set of frequent subgraphs, we partition them into a few subsets. From each subset we choose a representative, which is called a template subgraph. All the frequent s ubgraphs in a subset are subgraphs of the corresponding template subgraph. The template subgraph is a summarization model which can restore the subgraphs in the subset and their frequencies. This problem is more challenging than itemset summarization, due to two difficulties in subgraph mining: (1)  X  X ultiple embeddings X , i.e., a subgraph can have multi-ple embeddings in a summarization model which is a template subgraph; and (2)  X  X opological constraint X , i.e., the topological structure specifies the connectivity constraint among nodes and edges, while in itemset summarization, there is no such constraint between individual items. To solve the problem, we make an independence assumption between edges in a frequent subgraph. We take a re-gression approach to estimate the parameters in the independence probabilistic model by least square estimation. The probabilistic model allows users to restore frequent subgraphs and their frequenc ies from template subgraphs. To ensure a good summarization quality, we allow users to specify an error tolerance  X  and our algorithms take a top-down approach to discover k template subgraphs. Multiple regression models will be built based on the k template subgraphs to control the frequency restoration error within  X  . We have evaluated our subgraph summarization approach on real graph datasets. Experimental results show that our method can achieve a concise summari zation with high accuracy in terms of subgraph frequency restoration error.

The rest of this paper is organized as follows. We formally define the problem of frequent subgraph summarization in Section 2 and propose the summarization algorithms in Section 3. We report the experimental results in Section 4 and discuss the related work in Section 5. Finally, Section 6 concludes the paper. Agraph G is a triple ( V,E,  X  ), where V and E are the node set and the edge set, respectively.  X  is a finite set of labels, and each node v  X  V or edge ( u, v )  X  E is mapped to a label in  X  , denoted as  X  ( v )or  X  ( u, v ). A graph g is a subgraph of another graph G if there exists a subgraph isomorphism from g to G , denoted as g  X  G . G is called a supergraph of g .
 Definition 1. Subgraph Isomorphism. For two graphs g and G , G contains a subgraph that is isomorphic to g , if there is an injective function h : V g  X  V
G , such that respectively.
 Definition 2. Frequent Subgraph. Given a collection D of graphs, a graph g is frequent if f ( g )  X  f min ,where f ( g ) is the number of graphs in D containing g ,and f min is a user-specified minimum frequency threshold.
 A frequent subgraph g is a maximal one if and only if there does not exist another frequent subgraph g and g  X  g . A frequent subgraph g is a closed one if and only if there does not exist another frequent subgraph g , g  X  g and f ( g )= f ( g ). Anti-monotonicity holds for frequent subgraphs in a graph database, which means the subgraphs of a frequent subgraph are also frequent.
Given a set of frequent subgraphs F , we study how to summarize them into a small number of representatives, called template subgraphs, so that all frequent subgraphs and their frequencies can be restored accurately. 3.1 Subgraph Summarization by Regression We propose to use a regression approach to frequent subgraph summarization. Based on the subgraph containment relationship, we can build a partial order graph (POG) consisting of all frequent subgraphs. Fig. 1 shows an example. Each node in the POG is a frequent subgraph. Subgraphs in the same level are of the same size, measured by the number of edges. In the POG, two subgraphs are connected by a directed edge from the large r one to the smaller one, if the smaller one is a subgraph of the larger and differs by one edge. Suppose g is a subgraph in the POG, we use connected children to r epresent its connected neighbors smaller than g ,and g is called a connected parent. We use reachable children to represent all the nodes that can be reach ed by traveling along the edges in the POG, starting from g . A maximal subgraph does not have a connected parent in POG. If there is more than one maximal frequent subgraph, we add a union of all maximal frequent subgraphs as the root of the POG.
Suppose g and g are two connected subgraphs in the POG, where g and g differ by only one edge e ,thatis, g  X  X  e } = g .Let p ( g | g ) denote the conditional probability that a graph G from D containing g also contains g .Since g  X  X  e } = g ,wedenote p ( g | g )as p ( e | g ), the conditional probability that a graph G from a graph database D containing g also contains edge e .Let f ( g )denotethe frequency of a frequent subgraph g ,then Given any two frequent subgraphs g 1 and g l that differ by l  X  1edges { e probabilities, we have To simplify the joint probability estimation, we apply the following independence assumption: whether a frequent subgraph g contains an edge e is independent of where  X  denotes an arbitrary subgraph g that g  X  X  e } is frequent. Under this assumption, we can rewrite Eq. (3) for subgraph g l and g 1 as follows: Given a frequent subgraph g ,let G = { g 1 ,g 2 ,  X  X  X  ,g n } be the frequent subgraphs reachable from g in the POG. Suppose we know the frequency f ( g )of g ,aswell as all the probabilities p ( e j )ofedgesin g , with the independent assumption, we can estimate the frequency of each graph g i  X  X  according to Eq. (4). By applying the logarithmic transformation on both sides of the equation, we have Similar to the regression approach in [11], we can build a regression model Y = X X  + E for G ,where E is the matrix of error terms,
Y = Here, 1 e i  X  g j is an indicator that edge e i belongs to graph g j . 1 e i  X  g j =1if e  X  g regression model is to minimize the sum of squares of the errors (residues), which is Then the solution is By applying the above regression approach, we are able to summarize any fre-quent subgraph g in the POG, together with all its reachable children, as a regres-sion model. We call g a template subgraph. The template subgraphs can restore all frequent subgraphs and their frequencies. We define the relative restoration error as follows.
 Definition 3. Average Relative Restoration Error. Let F denote the set of frequent subgraphs. For each subgraph g  X  X  , f ( g ) and r ( g ) are the true frequency and the restored frequency of g , respectively. The relative frequency restoration error of the frequent subgraph set F is Subgraph Summarization with Error Tolerance  X  . Given a set of frequent subgraphs F , and a maximum error tolerance  X  , the problem of frequent sub-graph summarization is to partition F into as few groups as possible, and each group G satisfies the following: (1) G can be summarized as a single regression model, and (2)  X  avg ( G )  X   X  ,where  X  avg is defined in Definition 3. 3.2 Summarization Framework Our summarization framework is presented in Algorithm 1, which is in a top-down fashion. The algorithm starts from a single template subgraph, the root of the POG, which is a union template subgraph for all maximal frequent sub-graphs. Let g be a template subgraph, we use  X  avg ( g ) to denote the average restoration error of the regression model built on g with its reachable children. In each repeated loop from line 3 to line 8, the algorithm first divides the tem-plate subgraph with the maximum average restoration error into two template subgraphs, if the error is larger than the threshold  X  , and then tries to merge the newly generated template subgraphs with other template subgraphs, until all the template subgraphs have an average restoration error  X   X  .

We use a binary tree T to maintain the generated template subgraphs. At line 1 in Algorithm 1, T is the root of POG G .Atline6,weusethesymbolofset ALGORITHM 1: Summarization Framework
ALGORITHM 2: divide (Template g ) union to denote the update of binary tree T . g 1 is a child of g in POG, and g 2 is g withadifferentregressionmodel.Theupdateisdonebyaddingthenew template subgraph g 1 to T as a child of g and update the regression model of g by the one of g 2 . 3.3 Template Subgraph Division Algorithm 2 presents the procedure to divide a template subgraph. Consider a template graph g to be divided, the potential new template subgraphs are the connected children of g . Take Fig. 2 as an example. c 1 , c 2 and c 3 are g  X  X  connected children in the POG. Suppose c i is selected (1  X  i  X  3). Then we have two template subgraphs: c i and g . There exist frequent subgraphs that are the descendants of both c i and g .Werestrictthemtobelongtoonlyone template subgraph, either c i or g , in order to obtain better regression models. The rule is to let the sharing part belong to the smaller template subgraph c i .
We discuss how to build regression models for this case. Let e be the edge that appears in g but does not appear in c i . All the descendants of c i in the POG do not contain e . In other words, the descendants of g are divided into two parts: frequent subgraphs containing e and frequent subgraphs not containing e . By selecting c i ,thePOGrootedat g is divided into two subgraphs. One POG subgraph G i is rooted at c i and contains all descendants of c i . The other POG subgraph G g contains g and all its descendants excluding those in G i .As indicated in Fig. 2, the dotted lines indicate some descendant of G g may be a supergraph of some graph in G i because of the existence of the edge e ,andmust be deleted. We build regression models for G i and G g , respectively. Among all the possible children of g , we select the child node c i of g in the POG which results in the minimum sum of residues of the regression models for both G i and G g .As the division continues, the residues and the average relative restoration errors will decrease. Eventually, the algorithm will stop when the average restoration error  X   X  . 3.4 Template Subgraph Merging After the update of the binary tree for template subgraphs, a merging step is conducted at line 7 in Algorithm 1. The merging step serves as a refinement step of the binary tree with the hope to reduce the total number of template subgraphs by merging the updated template subgraphs with its parent subgraph or sibling subgraphs. Algorithm 3 presents the procedures of the merging step.
For a divided template subgraph g , g 1 is a child of g in the POG. Due to the division, all subgraphs reachable from g are divided into two sets, where g 1 and g 2 are the template subgraphs, respectively. Due to the change of the regression models, it is possible that g 2 could be merged with its parent g p in the binary tree T and the average restoration error is below  X  . Apparently, either the average restoration error of g 2 or that of g p should be smaller than  X  . For example, in Fig. 2, suppose c 1 is the divided template subgraph and c 4 is the child with the
ALGORITHM 3: merge (BinaryTree T ,Template g,g 1 ,g 2 ) minimum total residue. Then it is possible that merging c 1 and g will generate a regression model whose average restoration error is below  X  . 3.5 Queriable Summarization Given our frequent subgraph summarization with restoration error control, we can provide an answer when a user wants to know the frequency of a frequent subgraph. Since every frequent subgraph in the POG belongs to one and only one template subgraph, we only need to know which template subgraph it belongs to. Based on Eqs. (6) and (8), we can estimate the restored frequency r ( g )ofa frequent subgraph g according to the following equation, In our summarization framework, there is a partial order among edges to avoid the problems caused by multiple embeddings in a template graph. Upon all the template subgraphs obtained, we can identify which template subgraph a query graph g belongs to by utilizing the global edge ID X  X . In this section, we evaluate the perfo rmance of our proposed summarization method. All the experiments were run on a server with 4 CPU and 24GB memory running GNU/Linux.

We use the AIDS antiviral screen compound dataset 1 . There are totally 43850 chemical compounds, which are classified into three categories: Confirmed Active (CA); Confirmed Moderately active (CM); and Confirmed Inactive (CI). As chemical compounds belonging to CI are not useful for the drug discovery, we use datasets CA and CM in our experiments. CA contains 463 compounds and CM contains 1093 compounds. We list the number of frequent subgraphs mined from CA and CM under different minimum support in Table 1.
 Experiment Setting: We implemented two variants of our summarization framework in Algorithm 1, namely, asc and ran . As discussed, in a union tem-plate subgraph, we could arrange the order of maximal frequent subgraphs in different ways to avoid the issues caused by multiple embeddings and common reachable children. ran denotes that we arrange the order randomly in division, while asc denotes that maximal frequent subgraphs are always sorted in the ascending order of their sizes, measured by number of edges, during the union template creation.

Fig. 3 reports the summarization results on datasets CM and CA. Fig. 3(a) and 3(b) report the quality and running time on CM under different values of minimum support when the restoration error tolerance is 10%. Generally, a smaller value of support means a large number of frequent subgraphs. Under the same error tolerance, asc can generate a more compac t summarization, i.e., a smaller number of template subgraphs, than ran . It is also more efficient than ran . Similar performance can be obser ved in Fig. 3(c) and 3(d) on CA. acs always generates fewer template subgraphs than ran . Compared with the number of frequent subgraphs in CM and CA shown in Table 1, we can find that the number of generated template subgraphs is up to several hundred times smaller than that of the frequent subgraphs in both datasets under a smaller error tolerance. Frequent Subgraph Summarization: One potential issue in frequent sub-graph mining is the huge number of the discovered frequent subgraphs. Closed frequent subgraph [25] and maximal frequent subgraph [9,19] can partially solve this issue, but in many cases the number of closed or maximal subgraphs is still very huge. Recently researchers [3,15, 28,6] have focused on selecting a small number of representative graph pattern s to represent many similar subgraphs. The similarity could be maximum common subgraph [6], graph edit distance [3,28], or Jaccard distance [15]. Sampling is another approach to solve the over-loading issue. Hasan et al. [7] propose d a sampling strategy based random walks on the frequent subgraph lattice.
 Frequent Subgraph Mining: Many algorithms have been proposed for finding frequent subgraphs in graph databases, where the frequency of a subgraph is the total number of graphs containing the subgraph in the database. Similar to the Apriori-based approaches in frequent itemset mining, Apriori-based algorithms for frequent subgraph mining are proposed in [10,12,21], where the search strat-egy follows a breadth-first manner. Subgraphs of small sizes are searched first. Once identified, new candidate subgraphs are generated by joining two highly overlapping frequent subgraphs. In each iteration, the size of these candidate subgraphs is increased by one. Other algorithms [24,1,8,17] employ a pattern-growth style. New candidate subgraphs are generated by adding a new edge to the current. It is possible that a candidate subgraph can be extended from multiple frequent subgraphs. In gSpan [24], each candidate subgraph is associ-ated with a depth-first code for duplicate identification. There are also research efforts on finding frequent subgraphs in a single large graph [2,14,5,13], where an important problem is how to calculate the frequency. One solution [13] is to consider the maximum number of non-overlapping embeddings as the frequency. Other Large Graph Summarization: There are also works for large graph summarization. Navlakha et al. [16] proposed an approach to generate a compact graph representation which can be restored to the original graph with bounded error. They used a single super-node to represent a clique or near-clique, with an additional table recording the missing edges. The quality of the summary is measured by the minimum description length. Tian et al. [20] proposed two aggregating algorithms for graph summarization. The top-down approach first groups together all the nodes with the same category attributes. Then the groups of nodes are repeatedly split until there are k groups. The bottom-up approach first groups together all the nodes with both the same node attributes and the same edge attributes. Then small groups of nodes are merged into larger ones till there are k groups left. Zhang et al. [27] extended Tian X  X  approach to deal with numerical attributes by automatically categorizing numerical attribute values. They also proposed an interestingness m easure to identify the most interesting resolutions. In this paper, we have proposed a frequent subgraph summarization framework with an independence probabilistic model. A regression approach is applied to estimate the parameters in the summarization model. Our summarization frame-work takes a top-down approach to recursively partition a summarization graph template into two, until the user-specifie d error tolerance is sa tisfied. Experimen-tal results on real datasets show that our summarization model can effectively control the frequency restoration error w ithin 10% with a concise representation.
In the future, we plan to study how to integrate our summarization frame-work into the pattern mining process to save the computation cost of finding all frequent subgraphs. We will also study the frequent subgraph summariza-tion problem in a single large graph. Depending on the definition of frequency, the anti-monotonicity property does not always hold, which will introduce new challenges in the summarization framework to avoid false-positive subgraphs. Acknowledgments. This work is supported by the Hong Kong Research Grants Council (RGC) General Research Fund (GRF) Project No. CUHK 418512 and 411211.

