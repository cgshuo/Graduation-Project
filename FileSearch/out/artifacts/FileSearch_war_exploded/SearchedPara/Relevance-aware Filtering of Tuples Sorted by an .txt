 Sorting tuples by an attribute value is a common search sce-nario and many search engines support such capabilities, e.g. price-based sorting in e-commerce, time-based sorting on a job or social media website. However, sorting purely by the attribute value might lead to poor user experience because the relevance is not taken into account. Hence, at the top of the list the users might see irrelevant results. In this paper we choose a different approach. Rather than just return-ing the entire list of results sorted by the attribute value, additionally we suggest doing the relevance-aware search re-sults (post-)filtering. Following this approach, we develop a new algorithm based on the dynamic programming that directly optimizes a given search quality metric. It can be seamlessly integrated as the final step of a query processing pipeline and provides a theoretical guarantee on optimality. We conduct a comprehensive evaluation of our algorithm on synthetic data and real learning to rank data sets. Based on the experimental results, we conclude that the proposed algorithm is superior to typically used heuristics and has a clear practical value for the search and related applications. Search Metric; Attribute; Filtering; Dynamic Programming H.3.3 [ Information Search and Retrieval ]: Information filtering, Retrieval models, Search process, Selection process
Many search engines support sorting of the search results by an attribute value, e.g. sort items by price in e-commerce or sort resumes by the update time on the job websites. A similar scenario exists in the social domain when the goal is to construct a chronologically sorted social feed, e.g. Twit-ter, Facebook. However, sorting purely by the attribute value might not be the best approach since at the top of the c  X  list users might find irrelevant results. For example, see the screenshots of the search user interfaces for Indeed.com and Amazon.com on Figure 1. In both cases the results sorted by the attribute values are hardly relevant for the queries.
To evaluate how such search scenarios are supported to-day, we conducted the ad hoc evaluation of ten popular search engines from the e-commerce and job industries 1 . For each search engine we submitted 25 queries (different queries for different industries), applied the sorting based on one of the attributes (relevance, date, price), and judged the qual-ity of results 2 . The ranking by relevance is of very high qual-ity. The average Precision@10 is 0 . 86. On the other hand, we found that the search results are far from relevant when the attribute-based sorting is done. For instance, across the sites the average Precision@1 is 0 . 44, Precision@5 is 0 . 45, and 61% of queries have the Precision@10 below 0 . 5. We think that it is mainly due to the relevance not being taken into account when the attribute-based sorting is requested. Therefore, our research questions are: (RQ1) Can the qual-ity of results sorted by the attribute value be improved by incorporating the relevance into the ranking process? (RQ2) What is the best way to accomplish it?
In this paper we propose a new principled approach to per-form relevance-aware search results (post-)filtering via direct optimization of a given search quality metric . Our algorithm uses the ideas from dynamic programming and is guaranteed to deliver the optimal solution. The algorithm is presented in Section 3. The experiments on synthetic and real learning to rank (L2R) data sets are described in Section 4.
This work is related to the research on search user behav-ior analysis, search metrics, and learning to rank. The pro-posed algorithm is based on the dynamic programming [1].
Researchers studied the way people interact with search engines by analyzing mouse movements, eye-tracking and click logs. Joachims et al. [9] discovered the position bias phenomenon, i.e. the results at the first two positions re-ceive most attention, and then it quickly drops. Plus, on average users tend to read the results in a linear order from top to bottom. Craswell et al. [4] explored how the position bias might arise and proposed four hypotheses and the cor-responding probabilistic click models. They found that the  X  X ascade X  model, where users view results from top to bot-tom and leave as soon as they see a worthwhile document, is
Amazon, Walmart, Target, Etsy, BestBuy, NewEgg for products and Indeed, LinkedIn, SuperJob, Monster for jobs. we don X  X  describe the exact setup due to the page limit. the best explanation for position bias in early ranks. Dupret et al. [5] generalized this model by allowing for the possibil-ity that a user skips a document without examining it.
Complementary to the work on search models, a lot of at-tention has been devoted to the design and analysis of search metrics. Thus, in addition to the traditional metrics, like the Precision and the Recall, J  X  arvelin and Kek  X  al  X  ainen proposed the (Normalized) Discounted Cumulative Gain ( DCG ) [8], Chapelle et al.  X  the Expected Reciprocal Rank ( ERR ) [2], to name just a few. Recently, Chuklin et al. [3] developed a unified framework to convert any click model into the eval-uation metric. Essentially, all search metrics model the po-sition bias and penalize the top ranked irrelevant results.
Numerous ranking algorithms have been developed to ac-curately predict the relevance of documents. Typically, these algorithms are based on machine learning and find the op-timal parameters by optimizing the  X  X urrogate X  objective function. However, the solution to the approximation is not always optimal for the original ranking problem. Therefore, recently several approaches have been proposed that directly optimize a given search metric. For instance, Xu et al. [12] focus on the algorithms that optimize the objectives upper-bounding the original non-smooth search metrics. Tan et al. [11] proposed DirectRank , which is based on the itera-tive coordinate ascent with the smart line search procedure.
Attribute-based ranking, however, has been handled very differently. Rather than taking the relevance into account, search engines return the list of results sorted by the at-tribute value or suboptimal heuristics are used (Section 4.1). Inspired by the recent advancements in L2R, in this work we bridge the gap between the relevance-based ranking and the attribute-based ranking by proposing to do relevance-aware search results filtering, which directly optimizes a given search metric, when the sorting by the attribute value is requested. It is worth highlighting the difference between the proposed algorithm and a famous TA algorithm by Fagin et al. [6]. While TA algorithm finds the top-k most relevant tuples by scoring them individually , we return the tuples, which cumulatively optimize a given search quality metric. The ordering of the tuples is as crucial as their relevance.
We consider the scenario when a user requests the sorting of the search results by the attribute value, e.g. by date (Fig-ure 1, A) or by price (Figure 1, B). Our goal is to produce the final ranking that both satisfies the strict ordering con-straints and optimizes a given search quality metric (in turn it minimizes the user X  X  effort on finding relevant results). We only focus on the results filtering and assume that the rele-vance scores are already predicted by the ranking algorithm. Therefore, the formalization of our problem looks as follows.
Input: a list of tuples { ( t i ,r i ) } l i =1 , where t tribute value and r i  X  R + is the relevance score predicted by the ranking algorithm; a search quality metric Q.

Output: a (sub)list of indices J delivering the maximum to the metric Q and totally ordered based on the attribute value, i.e. J = arg max Q ( r j i | j i  X  J ) , s.t. t j 1
Throughout the paper, we consider the DCG as the search quality metric (although ERR or other metric can be used), date as the attribute, and the input sorted chronologically. It is worth mentioning that the formalization above covers the post-filtering scenarios as well, i.e. the input might con-sist of tuples that passed some other filtering algorithm.
Currently, this problem is solved heuristically. Mainly there are two approaches built around the same idea of thresholding. We can take only the results that have the relevance score above the threshold. We can also sort the results by the relevance score, take the top-k elements, and finally re-sort the list by date. While these approaches are easy to implement, they have two major drawbacks. First, it is not clear how to set the threshold. Second, the described approaches are the approximate solutions of our problem. Even the result set constructed from the top-k tuples sorted by relevance, being re-sorted by the attribute value, gets ordered randomly if we look at the relevance component.
The solution that guarantees optimality is to enumer-ate all possible subsequences, compute the metric for each one, and take the best one. However, this approach is not tractable as the number of subsequences is exponential. We propose a polynomial algorithm based on the dynamic pro-gramming [1]. There are three key observations behind our algorithm: (1) natural enumeration order for subsequences; (2) additivity of the metric; (3) optimality of subproblems.
First, all subsequences can be partitioned into the factor classes based on their length, i.e. in each factor class there will be the subsequences of the same length. To enumerate all subsequences, we can iterate over the factor classes and Algorithm 1 (A1) Relevance-aware filtering of totally or-dered set via direct optimization of a search quality metric Input: DCG and { ( t i ,r i ) } l i =1 , s.t. t i &lt; ... &lt; t Output: J = arg max DCG ( r j i | j i  X  J ), s.t. t j 1 &lt; ... &lt; t 1: M  X  Matrix ( l + 1 ,l + 1); M (: , 0)  X  0; M (0 , :)  X  0; 2: Path  X  Matrix ( l + 1 ,l + 1); # to recover max sequence 3: for i in 1, . . . , l 4: for j in 1, . . . , i 6: if M ( i  X  1 ,j  X  1) + gain &gt; M ( i  X  1 ,j ) 7: M ( i,j )  X  M ( i  X  1 ,j  X  1) + gain ; 8: Path ( i,j )  X  ( i  X  1 ,j  X  1); 9: else 10: M ( i,j )  X  M ( i  X  1 ,j ); 11: Path ( i,j )  X  ( i  X  1 ,j ); 12: ( i,j )  X  arg max M ( l, :); # last element of solution 13: J  X  List (); J.append ( j ); 14: while i &gt; 1 and j &gt; 1 15: if P ( i,j ) .last &lt; j 16: J.append ( P ( i,j ) .last ); 17: ( i,j )  X  P ( i,j ); # jump to shorter subsequence 18: return J.reverse () within each factor class enumerate all subsequences. Sec-ond, the search metrics are additive and can be computed in linear time from the beginning of the list to the end [2]. It means that having a partial metric value for the prefix, we can compute the new metric value by simply adding the gain/utility provided by the current element. Third, the op-timal subsequence for the prefix of length k is one of the optimal subsequences from each of the factor classes for the prefix of length k  X  1 with or without the current element appended (proof by induction for the prefix length).
Combining the observations above, we present our algo-rithm and its analysis. It starts by initializing the memoiza-tion matrix to store the optimal DCG values for subprob-lems and the transition matrix to reconstruct the optimal subsequence. Then, it iterates over the prefixes of the input sequence in the outer loop and over the factor classes in the inner loop. The cell ( i,j ) is for the optimal subsequence of length j for the prefix of length i . At each step we decide whether we should append the current element of the input sequence i to the optimal subsequence of length j  X  1 for the prefix of length i  X  1 (the recursion on lines 6-11). If we append the current element, we go diagonal. If we don X  X  ap-F igure 2: Dependencies in the memoization matrix, a legal evaluation order, and the optimal path. pend, we keep the existing optimal subsequence of length j and stay on the same column. A legal evaluation order and the dependencies between the cells are shown in Figure 2, A. Finally, to reconstruct the optimal subsequence, we find the maximum in the last row (the last element is always  X  X n X  since the elements are non-negative) and go backwards in the Path matrix. If the line is diagonal, we take the ele-ment in the next cell. Otherwise, we skip. The Path matrix is depicted in Figure 2, B. The complexity (both time and space) of the algorithm is O ( l 2 ) because we have two nested loops, costing us O (1) time at each iteration, and the square memoization matrices. It is guaranteed to deliver the op-timum because we  X  X irtually X  enumerate all subsequences within the dynamic programming framework. For a toy ex-optimal solution is { 1 , 3 , 4 , 5 } with the DCG equal to 12 . 40.
In this section we study how our approach contributes to the ranking quality using two real LETOR [10] (MQ2007, MSLR-WEB10K) and synthetically generated data sets.
To answer our research questions, we do the simulations using the real learning to rank data sets. We extend MQ2007 and MSLR-WEB10K data sets by assigning a random times-tamp to each document to model the sorting by the attribute value. Scikit-learn 3 implementation of the Gradient Boosted Regression Trees ( GBRT ) [7] is used to predict the relevance scores. The optimal parameters for the final GBRT model are picked using cross validation for each data set. We use the 5-fold cross validation partitioning from LETOR [10].
Three popular baselines are considered, which are typi-cally used to perform the filtering of the search results: Baseline 1 (B1) : sort by the attribute value, no filtering; Baseline 2 (B2) : sort by the attribute value, keep the re-sults with the predicted relevance scores above the threshold (we normalized the scores to [0,1] and set the threshold=0 . 5); Baseline 3 (B3) : sort results by the predicted relevance score, take the top-k (where k is the cutoff point for the metric value calculation), and re-sort by the attribute value.
The evaluation procedure works as follows. First, we train the GBRT on the training folds. Second, we predict the rel-evance scores using the trained GBRT model for the docu-ments in the testing fold. Third, we apply a baseline filtering algorithm to the documents in the testing fold by working with the relevance scores from the step two and the ran-domly generated timestamps. Fourth, we apply our filtering algorithm to the tuples that passed the baseline filtering. Finally, knowing the true relevance labels, we calculate the NDCG @ k for the filtered result list sorted by the times-tamp. To make sure that the conclusions are not due to randomness, we average the results from 1000 runs.

The results of the experiment are presented in Table 1 and 2. We can see that the output (post-)filtered with our algorithm is regularly better than the baselines. We applied the binomial test and found that almost all differences in the NDCG values are statistically significant (marked in bold), p -value is below 0 . 001. One average the increase in the met-ric value is around 2-4%. Moreover, since the data sets used have very different characteristics (e.g. the average query Table 1: The demonstration of effectiveness of the proposed approach on MQ2007 data set. length for MQ2007 is 40 and for MSLR-WEB10K  X  120), the experiment suggests that the algorithm achieves good performance for a wide range of input problems. Yet, one should note that the increase in the ranking quality comes with the extra computational cost because the complexity of our algorithm is O ( l log l ) times larger than for the baselines.
In this section we focus on the filtering only (both rele-vance labels and timestamps are generated) and study how the algorithm behavior changes for different input sizes and relevance label distributions. We consider the following four label distributions modeling the real situations: (a) uniform integer in the range [0 , 5]; (b) uniform real in the range [0 , 5]; (c) power law, the slope  X  = 2 . 0; (d) 3 x 2 125 with the support in the range [0 , 5]. We generate the input lists for the filtering algorithm by sampling from the corresponding distribution. Similarly to the previous experiment, we simulate each com-bination of conditions 1000 times and average the runs. Only the Baseline 1 is used in this experiment for simplicity. The data from the simulation is presented in Figure 3.

There are several observations that could be made with the help of this figure. First, the output size is linearly pro-portional to the input size (Figure 3, C). DCG also grows linearly with the growth of the input size (Figure 3, A). Sec-ond, the proposed algorithm always outperforms the Base-line 1 (Figure 3, B), which is expected because we do the filtering directly optimizing a given search quality metric. Third, both the graph for the ratio of the DCG values and the graph for the ratio of the output sequence lengths for the proposed algorithm and the baseline monotonically converge for the longer input lists (Figure 3, B and D). This means Figure 3: The behavior of the algorithm (A1) for dif-ferent input sizes and relevance label distributions. Table 2: The demonstration of effectiveness of the proposed approach on MSLR-WEB10K data set. that our algorithm works better when the original hit list is shorter. Fourth, higher gains in DCG over the baseline are characteristic for the relevance label distributions, where relevant results are more probable (Figure 3, B). The obser-vations above are valid for non-degenerate cases, e.g. not all labels are the same or sorted in a special order.
In this paper we addressed the important problem in search, that is, how to increase the relevance of the search results sorted by an attribute value. Our solution is based on the idea to perform relevance-aware search results filtering by directly optimizing a given search quality metric. We devel-oped a simple, yet effective algorithm based on the dynamic programming, which consistently outperforms typically used heuristic approaches and is guaranteed to deliver the opti-mal solution. In the future, we plan to integrate the pro-posed algorithm in a real search engine and instrument an A/B test to see how such a modification will affect the user engagement and satisfaction with the search results.
We thank Karrie Karahalios, ChengXiang Zhai, and anony-mous reviewers for their valuable comments and suggestions.
