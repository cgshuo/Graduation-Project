 Scientific papers, which deliver the latest scientific research progress and achieve-ment, are of great importance for scientific researchers to share ideas, find in-terested topics, identify potential research directions, and evaluate academic achievement. Nowadays, there are more than 5 million papers published each year, with an annual increase of 7% -8%, which makes it impossible for re-searchers to  X  X anually X  track all relevant papers of their interested topics from such massive datasets. Therefore, scientific paper mining has been proposed for efficient paper retrieval and analysis.
 retrieval, hence is widely adopted in scientific paper mining systems. Nowadays, there exist quite a few scientific search and analysis engines for scientific paper mining, such as Google Scholar [2] and Microsoft Academic Search [3]. Howev-er, those engines are usually limited to  X  X eyword X  search, which cannot satisfy various query demands. Even with the same keyword query, different users may have different expectations. For example, a user might want to get the most related papers that exactly contain the keyword, while another user might wan-t to search for the papers under the topic about the keyword. However, the  X  X eyword X  search cannot capture the difference. noring the relationships among synonyms and the topics/themes of papers, topic models are proposed to effectively associate keywords and topics. Latent Dirich-let Allocation (LDA) [4] initiates the study of topic models. Then many re-searchers extend the topic models in different perspectives. Steyvers et al. [5] built probabilistic author-topic models to analyze the relationships between au-thors and topics. Wang et al. [6] introduced a topic-over-time (TOT) model to capture the time X  X  effect on topic trend. More recently, Tang et al. [7] propose a patent mining method with a combination of the topic model and the language model. However, this work employs the product of the two models X  values, thus users cannot balance the tradeoff degree of the two models according to their query expectations.
 el TAIL(Time-Author-Institute-Literature) model to capture the relationships among literature, authors, institutes and time stamps. The TAIL model is a combination of three models: Customized Model (CM), Author Model (AM), Institute Model (IM). The CM is a tradeoff-balanced combination of language model and probabilistic topic model, which could deliver various customized paper queries; while AM and IM could identify authors/institutes that are spe-cialties at some hot research topics, as well as generate hot topic lists that are being studied by the authors/institutes, providing valuable data supports for scientific research cooperations. Based on the TAIL model, we implement the Massive Scientific Paper Mining (MSPM) system and set up a B/S (Brows-er/Server) structure for web services. The evaluation results on large real data show that our MSPM system could deliver desirable mining results for various user query expectations.
 preliminaries of this paper. Section 3 proposes the TAIL model and Section 4 introduces the implementation structure of TAIL-based MSPM system. We evaluate the performance of MSPM system in Section 5, and draw conclusions in Section 6. Here, we firstly define some notions that we will use in the paper, and then introduce the language model [1] and topic models [4][6] that we adopted. 2.1 Dictionary The valid information of the papers is processed to generate multiple dictionaries, including the word dictionary W , the author dictionary A and the institute dictionary I . The elements in each dictionary are distinct. The notions relevant to those dictionaries are defined in Table 1.
 2.2 Language Model The language model is usually associated with a document in a collection. With a query Q as input, retrieved documents are ranked based on the probability that the document X  X  language model would generate the terms of the query. According to the language model in [1], given a set of papers and a keyword, the relevance between the keyword and the specific paper can be calculated by Eq. (1). where N i is the number of distinct words in the i -th paper, N j i is the frequency of N
W is the number of distinct words in all papers.  X  is the Dirichlet smoothing factor and its value is set according to the average length of the papers in the database [1].
 words. Then the probability of a specific paper d j generating a query q can be calculated by Eq. (2). 2.3 Topic Model Probabilistic topic models are important tools for scientific paper mining, which identify the latent topics/themes of massive unstructured documents. In topic models, papers can be seen as random mixtures over various topics, each of which can be characterized by a distribution over words. According to the LDA model [4], the paper-topic distribution and the topic-word distribution,  X  and  X  , can be estimated by Eq. (3) and (4). of the j -th word assigned to the k -th topic,  X  and  X  are the hyper parameters in the LDA model.
 paper by Eq. (5). where Then the relevance between a query q and a specific paper can be derived by Eq. (7). into our model. With TOT, the  X  ik and  X  kj defined in Eq. (3) and (4) become the definitions in Eq. (8) and (9). where the superscript t refers to the values at time t , and  X  is the parameter that controls the effect of the values in the previous time on that of the current time.
 In this section, we will introduce the TAIL Model that contains the Customized Model (CM), the Author Model (AM), and the Institute Model (IM). Our pro-posed TAIL Model could well capture the correlation of topics, time stamps, authors, institutes and literatures . 3.1 Customized Model As the language models are usually limited to keyword search, we combine the topic model with the language model for topic/theme related queries. Different from the combined models in [7], which employ the product of language model value and topic model value, we define a customized factor  X  2 [0 , 1] to balance the tradeoff of the two models. Users could set different  X  values to balance the tradeoff degree, according to their special query requirements. Thus, the relevance between a keyword and a paper under CM is defined in Eq. (10). cases of CM where  X  = 1 and  X  = 0, respectively. Similarly, the relevance between a query and a paper is defined in Eq. (11). 3.2 Author Model and Institute Model To capture the authors X  and the institutes X  expertise on specific research areas, we propose model-based analysis of authors and institutes by the Author Model (AM) and the Institute Model (IM), respectively.
 we should measure the relevance score of an author/institue and the papers under specific topics, as well as generate hot topics associated with each au-thor/institute, indicating which topics are the author X  X /institute X  X  specialties. The methodologies of these two models are similarly summarized as follows. define ad and id in Eq. (12) to record whether an author/institute is associated with a paper. are the paper-topic distribution and the topic-word distribution, respectively. calculated by Eq. (13) and Eq. (14), respectively. topics with users X  queries. The relevance score of an author a l on a query q is derived by Eq. (15). where to accurately deliver authors/institutes that are specialties at some hot research topics, as well as generate hot topic lists that are being studied by the au-thors/institutes, providing valuable data supports for scientific research cooper-ations. In this section, we will demonstrate the implementation structure of our TAIL model-based Massive Scientific Paper Mining(MSPM) System. As is shown in Fig. 1, MSPM system is set up as a B/S structure, divided into four levels: data plane, model plane, application plane and user interface.
 At the same time, valuable information from the paper meta data is extracted, cleaned, and stored as the valid data for model-based analysis.
 TAIL model, processed for the application plane. Firstly, the words are assigned to LM, LDA and CM for data preprocessing. Then AM and IM help obtain the ranking lists of authors and institutes based on the relevance scores, while the TOT model involving time stamps helps generate the topic trends. Moreover, the coauthor networks and cooperation networks among institutes could also be clearly identified.
 the modeling data. Customized requirements from the user interface are delivers to the model plane, while the mining results are delivered to the user interface. To evaluate the performance of MSPM system, we experimented on large real data, containing more than 2.76 million papers from 6877 journals, published from 2005 to 2011. Each paper has structured information of title, keywords, abstract, authors, institutes, and etc. 5.1 Customized Paper Query The basic function of MSPM system is the customized paper query. Users could provide the keywords and set the customized factor  X  , according to their query expectations. Table 2 shows the top 10 query results of the keyword  X  X ocial network X  with  X  = 0 . 2, from which we can see that MSPM system could deliver closely related query results.
 to 1. It is clear that the ranks of some papers change dramatically with the change of  X  , while those of the other papers have no obvious changes. Thus, the customized factor could well distinguish papers of different properties. 5.2 Author/Institute Mining With specific keyword queries, users could get the top authors and institutes with the highest relevance scores. The authors and institutes in the resulting lists are known to be the specialties in the keyword related research domains. Table 3 shows the sample of top authors and institutes mining results with the keyword  X  X ocial network X . Note that the results are for reference only due to data set limitations.
 5.3 Precision of Query Results To evaluate the performance of customized query, 5 graduate students are invite to judge whether the papers, authors and institutes in the returned results are relevant to their query expectations. If a paper/author/institute is rejected by more than one student, it will be regarded as irrelevant and imprecise result. We launch 50 queries with different keywords for each model, and the average precision is calculated based on the students X  judgements. As for our CM model, the query precision is further optimized with different  X  , denoted by CM Opt. ing the precision in the top N papers. It is shown that the precision of CM is superior to that of LM [1] and LDA [4]. Moreover, CM models with larger N have lower precisions, which indicates that focusing on fewer query results will lead to better query performance. In addition, the precisions of AM and IM indi-cate that users could get desirable results from the author and institute mining. In this paper, we propose a novel TAIL model to capture the correlation of top-ics, time stamps, authors, institutes and literatures for massive scientific paper mining. The TAIL model defines a customized factor to balance the tradeoff of the language model and the topic model, providing customized paper queries for users. Based on the TAIL model, we implement the Massive Scientific Paper Mining (MSPM) system and set up a B/S structure to provide web services. The evaluation results on large real data show that our MSPM system could deliver desirable mining results for various user query expectations. As for future work, our model could be further optimized by measuring paper quality and popularity based on citations, which would result in more interesting returned papers and author/institute ranking lists.
 This work was supported by the National 863 Program of China (No. 2012AA011005) and Research Fund for the Doctoral Program of Higher Education of China (Grant No. 20111102110019).

