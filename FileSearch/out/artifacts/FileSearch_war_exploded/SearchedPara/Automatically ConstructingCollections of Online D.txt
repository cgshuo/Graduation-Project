 Categories and Subject Descriptors: H.4 [Information Systems Applications]: Information Search and Retrieval General Terms: Algorithms, Design.
 Keywords: Online databases, modular classifiers, focused web crawling.
Due the the explosion in the number of online databases, there has been increased interest in leveraging the high-quality information present in these databases [6, 1, 8]. How-ever, finding the right databases can be very challenging. For example, if a biologist needs to locate databases related to molecular biology and searches on Google for the key-words  X  X olecular biology database X  over 27 million docu-ments are returned. Among these, she will find pages that contain databases, but the results also include a very large number of pages from journals, scientific articles, etc.
Recognizing the need for better mechanisms to locate on-line databases, people have started to create online database collections such as the Molecular Biology Database Collec-tion [4], which lists databases of value to biologists. This col-lection, however, has been manually created and is manually maintained by the National Library of Medicine. Since it is estimated that there are over 20 million online databases [6], manual approaches to this problem are not practical. Be-sides, since new databases are constantly being added, the coverage of a manually maintained collection can be greatly compromised.

In this paper, we describe a new approach to the problem of automatically locating and organizing online databases that belong to a given domain. There are a number of is-sues that make this problem particularly challenging. Since online databases are sparsely distributed on the Web, an effi-cient strategy is needed to locate the forms that serve as en-try points to these databases. In addition, online databases do not publish their schemas and their contents are often hard to retrieve. Thus, a scalable solution must determine the relevance of a form to a given database domain by ex-amining just the information available in (and around) the form. As shown in Figure 1, our framework for constructing topic-specific online database collections consists of two key components that address these problems: a focused crawler that efficiently locates pages that contain forms; and a form-filtering process that identifies forms that belong to a given database domain. Below, we give a brief overview of these components. For a more detailed description, see [2].
A na  X  X ve approach to the problem of locating forms would be to visit all Web pages and extract the forms in these pages. Because the Web is large and forms are sparsely dis-tributed, this solution is highly-inefficient X  X oo many pages are visited unnecessarily. Besides, an exhaustive crawl can take weeks and this limits the ability to maintain the form set up-to-date.

A more efficient alternative is to use a focused crawler. In our solution, we use the Form Focused Crawler (FFC) [1]. The FFC is trained to efficiently locate forms that serve as the entry points to online databases X  X t focuses its search by taking into account both the contents of pages and patterns in and around the hyperlinks in paths to a Web page . Sim-ilar to focused crawlers (see e.g., [3]), the FFC focuses the crawl on a given topic X  X t uses classifier which, based on the contents of pages, guides the crawler to focus the search on pages that belong to a specific topic. To further focus the crawl, the FFC judiciously prioritizes links to follow that are more likely to lead to pages that contain forms X  X t does so by learning patterns of links that lead to pages which contain forms in a given database domain. An experimen-tal evaluation showed that the FFC is more efficient (up to an order of magnitude) than a set of representative crawlers. For more details about the FFC, the reader is referred to [1].
Although the FFC is trained to focus its crawl on a partic-ular topic and database domain, the set of forms it retrieves is highly heterogeneous. Some forms are non-searchable, i.e., they do not correspond to database queries. Exam-ples of non-searchable forms include forms for login, mailing list subscriptions, quote requests. Other forms, although searchable, may belong to different databases domains. The Figure 2: Variability in Web Forms. (a) Forms in Job domain with different attribute names repre-senting the same concepts; (b) forms in two dis-tinct domains, Hotel and Airfare, which contain at-tributes with similar labels. problem is further complicated by the fact that there can be high variability in the contents and structures of forms that belong to a domain, as well as high similarity between forms in different domains.

The form-filtering component of our framework aims to se-lect from the set retrieved by the crawler only relevant forms. More precisely, the problem we are trying to solve can be stated as follows: Given a set F of heterogeneous, automat-ically gathered Web forms and an online database domain D , our goal is to select from F only the forms that are entry points to databases in D . In other words, we would like to filter out all irrelevant forms  X  X he non-searchable forms and searchable forms that do not belong to the domain D .
Since our goal is to devise a general solution to this prob-lem, that works across different domains, we formalize the problem of identifying relevant forms in a particular database domain in terms of inductive learning concepts [7]. But un-like previous works on form classification which built mono-lithic classifiers, our approach is based on a divide-and-conquer strategy. Instead of using a single, complex clas-sifier, our form filtering process uses two simpler classifiers that learn patterns of different subsets of the form feature space.

The Generic Form Classifier ( GFC ) learns patterns of structural features of forms, such as, for example: number of hidden tags; number of radio tags; number of file inputs; number of submit tags; number of image inputs; number of buttons; number of resets; number of password tags; num-ber of textboxes; number of items in selection lists; sum of text sizes in textboxes; submission method (post or get). Empirically, we have observed that these structural charac-teristics of a form are a good indicator as to whether the form is searchable or not [1].

The GFC is effective for identifying searchable forms, re-gardless of their domains. However, even when a focused crawler is used, the set of forms retrieved may include search-able forms from many different domains (see e.g., Figure 2(b)). To identify searchable forms that belong to a given domain,
Table 1: Effectiveness of classifier composition. as the second step of our form-filtering process, we use a more specialized classifier, the Domain-Specific Form Clas-sifier ( DSFC ). The DSFC uses the textual content of a form to determine its domain. Intuitively, the form con-tent is often a good indicator of the database domain X  X t contains metadata and data that pertain to the database. For example, form attribute names often match the names of fields in the database, and selection lists often contain values that are present in the database.

The results of preliminary experiments over representative database domains, shown in Figure 1, indicate that the com-bination of the GFC and DSFC is very effective and lead to high values for classification recall, precision and accuracy.
This paper presents the first end-to-end solution to the problem of automatically constructing topic-specific online database collections. It combines a focused crawler, that automatically and efficiently locates forms on the Web, with a form-filtering process that accurately identifies forms that belong to a particular database domain.

Unlike previous approaches to form classification which require manual pre-processing of forms (see e.g., [5]), all the features used in our form-filtering process can be automat-ically extracted from Web pages. Besides, by partitioning the feature space, not only can simpler classifiers be con-structed that are more accurate and robust, but this also enables the use of learning techniques that are more effec-tive for each feature subset. Our experiments show that this composition is effective and outperforms solutions based on monolithic classifiers that consider the whole feature space. [1] L. Barbosa and J. Freire. Searching for Hidden-Web [2] L. Barbosa and J. Freire. Combining classifiers to [3] S. Chakrabarti, M. van den Berg, and B. Dom. Focused [4] M. Galperin. The molecular biology database [5] A. Hess and N. Kushmerick. Automatically attaching [6] W. Hsieh, J. Madhavan, and R. Pike. Data [7] T. Mitchell. Machine Learning . McGraw Hill, 1997. [8] W. Wu, C. Yu, A. Doan, and W. Meng. An Interactive
