 In this paper, we formulate a new research problem of learning from vaguely labeled one-class data streams, where the main objective is to allow users to label instance groups, instead of single instances, as positive samples for learning. The batch-labeling, however, raises serious issues because labeled groups may contain non-positive samples, and users may change their labeling interests at any time. To solve this problem, we propose a Vague One-Class Learning (VOCL) framework which employs a double weighting approach, at both in stance and classifier levels, to build an ensembling framework for learning. At instance level, both local and global filterings are considered for instance weight adjustment. Two solutions are proposed to take instance weight values into the classifier training process. At classifier level, a weight value is assigned to each classifier of the ensemble to ensure that learning can quickly adapt to users X  interests. Experimental results on synthetic and real-world data streams demonstrate that the proposed VOCL framework significantly outperforms other methods for vaguely labeled one-class data streams. One-Class learning represents a large body of applications [1-5] where only one class of samples  X  ( i.e. , positive samples) are labeled for training, and the final goal is to predict whether a new instance falls into the same category as the positive examples or no t. Because only one class of samples is labeled, general discriminative measures, such as Gini index or Information Gain, are no longer valid to help build decision trees or rules for predictions. Common solutions are to transfer th e learning into some well defined maximization problems [6-7], or to treat learning as a binary classification task if some unlabeled samples are also provided [8-9]. For either case, the quality of the labeled samples plays important role, and falsely labeled positive samples will deteriorate learner accuracies significantly, as shown in Figure 1. collection, storage, and tran smission technologies, recent years have witnessed an in creasing number of stream-oriented applications where sy stems are required to handle data with continuous volumes and inconsistent or conflicting concepts underneath the data. Under such circumstances, the identified ch allenges are twofold: (1) continuous growth of data volumes; and (2) dynamic drifting [13] (or evolving) of the data concepts. Many solutions [10-14] exist to handle data streams for classification, clustering, an d association mining. From a supervised learning perspective, existing algorithms rely on two procedures, incremental learning and ensemble learning [15], for stream data mining [10, 12-13]. The former builds a single model and uses new data to continuously update the model, whereas for the latter, the classifier consists of a number of base models each trained from a small portion of r ecent stream data. Although ensemble learning and incr emental learning are both effective, the former, in practice, has additional advantages mainly because of the followi ng reasons: (1) ensemble learning trains its models from a small portion of stream data, so it can efficiently handle streams with fast growing data volumes; and (2) the final predictions of an ensemble classifier are the voting of a number of base models, so concept drifting in the stream can be rapidly addressed by changing weight values of the voting members. techniques for supervised learning in data stream environments. The main focus, so far, has been limited to tackle the data volumes and th e concept drifting challenges. By doing so, they all assume that a labeling process exists to accurately label stream data. In a one-class learning scenario, this is equivalent to the setting that an agent (or a user) is required to examine the data and precisely label positive samples ( i.e. samples of interest to users). For one-class data streams, this is a major deficiency or technical barrier. First of all, the continuous nature of the stream data requires users to provide a fast response for labeling. Second, due to possible changing of user interests, even carefully labeled positive samples may contain inconsistency and conflict with each other. Consequently, traditional instance-based labeling is neither effective nor practical for stream-oriented applications. Alternatively, we can allow the user to merge samples into groups and label sample groups instead. We call this problem vague learning, because such a batch-labeling process is essentially vague and inaccurate in the sense that a labeled group may contain samples not of interest to users and we do not actually know which particular instances are genuinely positive. If we cons ider stream data mining and one-class learning as a whole, the major research challenges for vague one-clas s learning are threefold: 1. Vague/imprecise positive samples: Different from 2. Changing or inconsistent user interests: During the 3. Increasing data volumes: Aggregating all examples addressing the above issues, by using a double weighting based ensembling framework. More specifically, to handle the vague/imprecise positive sample challenge, we will assign a weight value to each individual instance to reveal its relevance to users X  interests. Two solutions are proposed to build one-class learners with instance weight values. To handle the change of user interests, we employ a pair-wise agreement based appr oach to adjust classifier weights for them to adapt to users X  interests. By stacking the instance and the classifier level weights together, we build an ensemble framework, which naturally solves the data volume challenge for stream data mining. Section 2 defines the problem and discusses simple solutions. Section 3 proposes our methods for one-class learning with sample weights, which will be further integrated into the framework in Section 4. Experimental results are reported in Section 5, and we conclude in Section 6. Formally, we assume that a data stream constitutes of samples arriving on a chunk-by-chunk basis, with S denoting the i th data chunk and S i-1 denoting the chunk arriving one time step earlier than S i . Once instances in S are collected, users can label a group of instances in S positive samples (denoted by PS i ) and our objective is to build a prediction model from historical data chunks ... S S i-2 , S i-1 , and PS i , in order to accurately predict instances in a future chunk S i+1 . We call this problem vague one-class learning , because we assume samples in PS i are vaguely or inaccurately labeled. In our problem setting, we do not intend to find best instance subsets for labeling ( i.e. , which portion of instances in S i should be labeled), nor are we interested in identifying falsely labeled positive samples. In addition, we assume that only instances in the current chunk ( S i ) are accessible, and once the algorithm moves from chunk S i-1 to chunk S i , all instances in chunk S its predecessors (... S i-3 , S i-2 ), become inaccessible, except the models trained from them. The reason we enforce this assumption is because aggregating historical data requires extra storage, and most stream data mining algorithms are required to make predictions based on one-scanning of the data streams without referring to historical data. Intuitively, the follo wing three methods can be applied to solve the vague one-clas s learning problem. Local One-Class Learning (LOCL): LOCL treats data in the current chunk S i as a static dataset with the training set constituting of labeled samples in S i ( i.e. , PS i ). A one-class classifier is trained from PS i and is used later on to predict samples in S i+1 . Ensemble One-Class Learning (EOCL): EOCL employs an emsemble learning paradigm to combine multiple local one-class classifiers to form a committee for prediction. More specifically, for each data chunk S i a one-class leaner ( L ) is trained from PS i (just like LOCL does), and a number of k learners L i-k-1 ,..., L i-1 , and L i trained from PS ,..., PS i-1 , and PS i respectively, are collected to form an ensemble E to predict instances in S i+1 . Filtering One-Class Learning (FOCL): FOCL is motivated by a recent one-class stream data mining effort [8] with an additional data filtering module [17-18]. For each data chunk S i and its predecessor chunk S apply cross validation to the labeled portion in S i ( i.e. , PS with incorrectly classified positive samples directly excluded from PS i . In addition, the above cross-validation classifiers trained from PS i are also used to classify unlabeled samples in S i ( i.e. , US i ) and all instances in S with samples, on which the majo rity classifiers agree to be positive, included into PS i . Finally, a classifier trained from PS i is used to predict instances in S i+1 FOCL has the privilege of accessing instances in both S and S i-1 , which violates the problem setting defined in Section 2.1 (only instances in S i are accessible). The purpose of having the relaxation for FOCL is to allow the existing method [8] to be implemented and compared with the solutions we intend to deliver in this paper. One essential change of the vague one-class learning for data streams is that positive samples are vaguely labeled and may contain non-positive samples. To differentiate genuine positive and false positive samples, we propose to assign a weight value to each individual instance to indicate its relevance to users X  interests. In the following sections, we first introduce a popular one-class learner, One-Class SVM (OC-SVM). In Section 3.2, we propose a solution which combines instance weight values and OC-SVM X  X  to build one-class SVM with sample weights. In Section 3.3, we propose a sampling based approach to enable weighted learning for generic one-class learners. One-class SVM is a special type of support vector machines, where learning intends to find a hyper-sphere enclosing all positive samples [6] or hyper-planes separating positive examples from the origin with the maximum margin [7]. the objective function of the Sch X lkopt OC-SVM model [7] is to discover the hyper-plane, determined by W T  X  X = separates the positive samples from the origin with the maximal margin. Because many non-linear problems may be linearly separable after proper transformations, kernel transformations  X  () are normally employed to transfer an input example from one space to another, which gives the hyper-plane denoted by W T  X   X  ( X )=  X  . This objective is defined by the convex problem given in Eq. (1), where W is orthogonal to the determined hyper-plane,  X  is the fraction of positive samples not separated from the origin by the determined hyper-plane. x i is the i th positive sample and  X  i is a slack variable which defines the  X  X enalty X  if a sample is not separated from the original. transfers an input example from one space to another. Numerous kernels, such as linear, polynomial, and Gaussian kernels, exist for su ch purposes. Eq. (2) gives the Gaussian kernel (also called Radial Basis Function), one of the most popularly used kernels in SVM . which determine the hyper-pl ane. If a new instance x satisfies W T  X   X  ( x t )  X   X  , it is classified as a positive example, otherwise, it is regarded as a non-positive sample. Assume the existence of a number of n positive instances, x , x 2 ,..., x n , each of which has a weight value w 1 w class SVM with sample weights is to take instance weight values into consideration for learning, such that the hyper-planes can favor instances w ith large weight values, and vice versa. One possible solution is to directly tie each instance X  X  weight value w i to its slack variable, so if an instance has a small weight value, we can directly reduce the impact of this instance X  X  slack variable on the objective function. This intuition leads to a new objective function defined by Eq. (3). The dual problem of Eq. (3) is given in Eq. (4), where  X  ,...,  X  n are the Lagrange multipliers. Eq. (4) can be directly solved by standardized Quadratic Programming. Denote the solutions by  X   X   X  n  X   X   X  ,..., , weight W is then given by Eq. (5). Because the decision of a one-class classifier is based on the hyper-plane W T  X   X  ( X )=  X  , the solutions given in Eq. (5) and the parameter  X  form a new one-class classifier, denoted by L . When classifying a new instance x decision is made based on the function given in Eq. (6), with +1 indicating that x t is predicted as a positive sample. The second approach of including instance weight values for one-class learning is to use weight values to change training sample distributions, such that an instance with larger weight values will have a better chance in influencing the formulation of the decisions, whereas a zero weight instance will not participate in the training at all. This objective can be achieved by employing a sampling technique to form a new training set with its distribution biased towards instances with large weight values. After that, we can trai n a one-class classifier from the sampled set for prediction. denoting ( x i , w i ) an instance x i with weight value w straightforward way for weight-based sampling is to employ sampling-with-replacement to sequentially examine each instance x i from S and include x i into a new set S  X  with probability given in Eq. (7). Such a sampling-with-replacement ap proach, however, cannot guarantee that instances are draw n independently from S to form a new set S  X  , so it cannot ensure that the sample set S formed from the same distribution as S . needs, the Rejection Sampling [19] from statistics provides a solution to ensure that instances are independently sampled from the given distribution. In short, suppose we need to sample from a target distribution f ( x ) to form another distribution following f ( x ). Assume further that we have a second distribution g ( x ) ( e.g. , a uniform distribution) from which we have a reasonable method of independent sampling. If there is a constant c | c  X  g(x)  X  f(x)  X  x , then the pseudo-code given in Figure 2 will result in a sample set following distribution f (x) with instances independently sampled from the given distribution.

Output: S  X  , a sampled set following the same distribution as S . mechanism in Figure 2 to build a number of sets S  X  1 , S S  X  , each of which is of the same size as S . Denoting L one-class learner trained from S  X  l , the final prediction on an instance x t is based on the majority voting of all classifiers, as shown in Eq. (9) where  X  denotes the number of sets sampled from S . learning approach are threef old: (1) rejection sampling independently draws instances to form a new distribution, w.r.t. instances X  weight values. It is inherently superior to other sampling mechanisms like sampling with/without replacement, because instan ces are not independently drawn from the latter approaches [20]; (2) the final predictions, which are the voting of the classifiers trained from a number of sampled sets, are typically more accurate than what a single classifier can offer; and (3) the weighted sampling approach can be app lied to any one-class learner to accommodate instance weight values for learning. The proposed vague one-class learning (VOCL) framework, as shown in Figure 3, mainly consists of three components: stream data, instance weighting, and classifier weighting. At the stream data layer, data are processed in a chunk-by-ch unk manner with each chunk S i containing two subsets PS i and US i , where PS vaguely labeled positive samples (denoted by clusters with blue dots and circles in Figure 3) and US unlabeled samples in S i . Once instances in S i are ready for processing, an instance weighting process is triggered to calculate instance weight va lues. Instances with their weight values greater than 0 are collected as positive samples with different weight values (denoted by different sizes of dots or circles in Figure 3). After that, a one-class classifier is trained from weighted instances, and a number of k classifiers form an ensemble E to predict instances in S i+1 . To ensure that predictions can be quickly adjusted to follow users X  preferences or interests, a weighting procedure is applied to dynamically tune classifier weight values for predictions. strea m The instance weighting procedure is to determine proper weight values for instances in S i , so the ones mostly relevant to the users X  curren t interests will receive large weight values, and vice versa. Such a weighting process consists of local weighting and global weighting two parts. 4.1.1 Local Weighting The local weighting process, as its name suggests, is to determine instance weight values by using samples in local chunk S i . For this purpose, we assume that the majority instances in the vaguely labeled sample set ( PS i to reveal users X  interests to some extent, so a one-class classifier built from PS i can be used to justify whether an instance is of user X  X  interests or not. Based on this assumption, we employ a cross-validation based approach, as shown in Figure 4, to separate instances in PS non-overlapping subsets. The aggregation of any f -1 subsets forms a training set to build a generic one-class classifier, which is used to classify instances in the excluded subset, say F j . If a positive instance p in F classified as positive, a weight 1.0 is assigned to p , otherwise p  X  X  local weight is set as 0.5. By doing so, the labeled positive instances are treated differently depending on whether the instances are consistent with majority positive samples or not. In addition, because the cross-validation process in Figure 4 trains a total of f classifiers from PS i , we can use all f classifiers to predict unlabeled instances in US i , and determine their weight values based on Eq. (9). 4.1.2 Global Weighting The purpose of global weighting is to determine a weight value for both positive and unlabeled instances in S using a number of classifiers trained from the chunks preceding to the current chunk S i . More specifically, given data chunk S i and k -1 classifiers, L j-k+1 , L trained from PS i-k+1 , PS i-k+2 , ..., PS i-1 , the global weight of an instance x in S i is the percentage of classifiers predicting x as positive, as given by Eq. (10). To combine local and global weights to form a single measure, we calculate the su mmation of local and global weight values and further divide this value by the difference between two weights, as defined in Eq. (11), where a and b are the Laplace smoothing parameters, which control the range of the final output (in our experiments, we set a and b both equal to 0.5, which gives unified weight values between [1,5]). Obviously, the measure defined by Eq.(11) favors instances with large local and global values, and will return a maximum value for instances with maximum local and global weights. Assuming a number of k one-class classifiers, L , .., L i , are forming an ensemble E to predict instances in S i+1 , an important issue is to assign a proper weight value to each individual classifier in E , such that final predictions can be quickly adjusted to the users X  current interests. Traditionally, this problem is solved by setting each classifier X  X  weight as its error rate (or accuracy) on an evaluation set which shares the same distribution as the test set [12-14]. For vaguely labeled data streams, this approach has three disadvantage s: (1) in one-class learning paradigm, the number of labeled positive samples is very limited; (2) finding an evaluation set sharing the same distribution as the test set ( i.e. , S i+1 ) is essentially difficult, because user interests may ch ange without any indications; and (3) the most recently labeled set PS i cannot be used as an evaluation set because its instances are vaguely labeled, whereas in other stream data environments the most recent training set can be used as the evaluation set. To address these issues, we propose to use a pair-wise agreement between a classifier L l and the most recent classifier L assign a weight value for L l , as defined by Eq.(12), where the most recent classifier L i will receive the largest weight 1. Figure 5 lists the detailed procedures of the proposed VOCL learning framework. Given a data stream S , VOCL takes two parameters N (chunk size) and k (the number of classifiers forming the ense mble) as input. A new data chunk S i is formed after the collection of N instances. Users can apply any technique (such as k -means clustering) to merge instances in S i into groups and label one or multiple groups as positive, with instances in the labeled groups forming a positive sample set of S i ( i.e. , PS that, the instance weighting procedures are triggered, as shown on Steps 5 to 9 in Figure 5. A new classifier L trained from a weighted sample set of S i , and this classifier along with the most recent k -1 classifiers ( L i-k+1 L i-1 ) form an ensemble E . The weight of each ensemble member is calculated based on its pair-wise agreement with L i on unlabeled samples in S i . From Steps 12 to 14, VOCL updates the emseble E and discards the oldest ensemble member ( i.e. , L i-k+1 ) to ensure that the system only maintains the most recent k classifiers. After that, the system waits for new samples and repeats the while loop if necessary. The key advantages of VOCL lie on its ability of tolerating vaguely labeled samples. If all instances in PS precisely labeled, our problem becomes the traditional one-class stream data mining, and the strengths of VOCL, compared to its other peers, ar e also obvious. First of all, because user interests may gradually shift or rapidly change, so assigning weight va lues to both instances and classifiers provides great flexibility to dynamically adjust the model and predict new samples. Second, the learning process of VOCL involves unlabeled samples in each data chunk to build predictors. This mechanism allows VOCL to utilize additional information to benefit the learning. We implement the VOCL framework using Java platform and WEKA data mining tools [21]. The one-class SVM with sample weights is modified based on the one-class SVM source code provided in LibSVM [22]. Benchmark Methods &amp; Parameters: For comparison purposes, we implement three benchmark methods, LOCL, EOCL, and FOCL, which have be en introduced in Section 2. For all methods, except the weighted one-class SVM, we use one-class SVM provided in the LibSVM as the generic one-class learner (using default parameter settings and Gaussian kernel). For VOCL, we implement two versions with VOCL w and VOCL s denoting that committee members are trained by using weighted one-class SVM (Section 3.2) and weighted sampling (Section 3.3) respectively. To make fair comparisons, both EOCL and VOCL use the same number of classifiers ( k ) to form the ensembles. Due to page limitations, we omit the details of the algorithm performance with respect to the chunk size (N), ensemble size (k) etc . because the impact of these factors has been addressed more or less in the stream data mining literature [10-14]. Instead, we use chunk size N=1000, ensemble size k=10, local filter folds f=10, and weighted sampling ensemble size  X  =10, for all streams. The purpose of fixing these parameters is to fully investigate and compare algorithm performance under different vague learning scenarios. Measures: The majority experimental comparisons are based on the prediction accuracies on chunk S i+1 , assuming chunks ... S i-2 , S i-1 , S i have been observed so far. Because we are mainly interested in algorithms X  performance across the whole stream, unless specified otherwise, we normally report the average accuracy (and the standard deviation) of each method over all data chunks. Positive Class &amp; User Interest Models: Because one-class learning only requires one class of samples ( i.e. , positive samples), whereas our benchmark data streams contain more than one classes. To provide positive samples for one-class learning, we us e the following three user interest models to select one particular class as the positive class, and treat samples from the remaining classes as non-positive samples. following three models: constant, regular shifting, and probability shifting. In the constant model, users are interested in one particular class across the whole data stream. In the regular shifting model, users regularly shift theirs interest, from one class to another class, after a fixed number of chunks. In probability shifting model, users change their interests with the probability given in Eq. (13), where Elaps denotes the number of chunks the currently selected positive class has elapsed so far. For the majority experiments in the paper we use the probability shifting model, because it X  X  closer to real-world models. Vague Labeling: To provide vague labels for each data chunk, we employ a random vague labeling and a clustering vague labeling in our experiments. In random vague labeling , users are allowed to specify the percentage of labeled instances (  X  ) and the percentage of genuine positive samples (  X  ) in a labeled subset of each chunk. For each chunk S i , instances are randomly selected to be included in the positive sample set ( PS i ) to meet the constraints (  X  and  X  ) specified by users. In some circumstances,  X  and  X  may not be satisfied simultaneously. For such a case, the labeling will first try to build a label set with the required size (  X  ) and then try to ensure that the genuine positive samples in the labeled set satisfying the  X  constraint. For clustering vague labeling , users first apply simple k -means clustering to each data chunk and merges samples into a number of clusters. After that, clusters are sorted based on the purity with respect to the selected positive class ( i.e. , the percentage of genuine positive samples in each cluster) in a descending order. The clusters are selected from the top to the bottom of the list, with instances in the selected clusters included the labeled set, until the size of the labeled set reaches the  X  constraint. In clustering vague labeling, users cannot control the percentage of genuine positive samples in the labeled set, because a cluster can have any percentage of genuine positive samples. In the experiments, the purities of the data chunks are also reported if necessary. Data Streams: Four benchmark streams downloaded from the Stream Data Mining Repository [23] are used in our experiments.
 Sensor data stream contains information (temperature, humidity, light, and sensor voltage) collected from 56 sensors deployed in Intel Berkeley Research Lab, as shown in Figure 6. The whole st ream contains consecutive information recorded over a 2 months period (1 reading per 1-3 minutes). We select sensors from four regions (the ellipses) , and the learning task is to correctly identify which region a particular reading is coming from. The processed stream has four classes ( i.e. , four regions) and 1051229 samples, each of which has five dimensions. Figure 6: the sensor distribution map deployed in Intel Berkeley Research Lab. Each number denotes a sensor location, and the large ellipses denote the sensor regions used Power contains hourly power supply of an electricity company from two sources: power supply from the main grid and power transformed from other grids. The learning task of this stream is to predict which hours (one out of the 12 periods from (0,2], (2,4],..., (22,24]) the current power supply belongs to. The whole stream contains 29,928 samples, each of which has four dimensions. KDD-99 was collected from the KDD CUP challenge in 1999, and the task is to build predictive models capable of distinguishing between possible intrusions and normal connections. The original data (10% sampling) contain 41 features, 494,021 samples, and over 22 intrusion types. We select three major classes (Nor mal, Neptune, and Smurf) to form a data stream with 485,269 instances. HyperP is a synthetic data stream containing gradually evolving (drifting) concepts defined by Eq. (14), where the value a j , j =1, 2,.., d , controls the shap e of the decision surfaces, and the value f ( x ) determines the class label of each instance x . The concept drifting of the data streams is simulated and controlled through the following parameters [13-14]: (1) t , controlling the magnitude of the concept drifting; (2) p , controlling the number of attributes whose weights are involved in the change; and (3) h and g  X  {-1, 1}, controlling the weight adjustment direction for attributes involved in the change. After the generation of long as a i is involved in the concept drifting). Meanwhile, after the generation of M instances, there is an h percentage of chances that weight change will inverse its direction, i.e. , g = -g for all attributes a change. In our experiments, the HyperP stream has five classes and 100,000 instances, each of which contains d =10 dimensions. The concept drifting involves p =5 attributes, and attribute weights change with a magnitude of t =0.1 in every M =2000 instances and weight adjustment inverses the direction with h =20% of chance. Random vague labeling allows users to control the size of the positive sample set (  X  ) and its purity levels (  X  ), so we can investigate detailed algorithm performances under fully controlled vague labeling scenarios. three user interest models: c onstant, regular shifting, and probability shifting. The results from the constant user interest model (Figure 7(a)) clearly show that five methods are roughly separated into three tiers with VOCLs and VOCLw outperforming FOCL, and FOCL further outperforming LOCL and EOCL. In fact, such ranking is also valid for all user interest models in Figure 7. Although we do expect that LOCL and EOCL to be ineffective for vague one-class learning, the results in Figure 7 actually show that one-class ensemble learning (EOCL) is not doing any better than local learning, regardless of whether the user interests are constant or shifting back and forth. For one-class streams with vaguely labeled samples, simply aggregating classifier s across data chunks to form an ensemble without differentiating sample types (genuine positive or false positive) may not bring any improvement at all. The results from FOCL further support our hypothesis and show that sign ificant performance gain can be achieved by refining vaguely labeled samples in the current and most recent chunks.  X  their results are mostly comparable with VOCLs performing slightly better than VOCLs. Actually, VOCLs not only has a higher mean a ccuracy than VOCLw, it also has smaller standard deviation values, which means that VOCLs X  X  predictions are more stable than VOCLw. 
Indeed, and although both VOCLs and VOCLw are ensembling frameworks, each committee member of 
VOCLs is another ensemble predictor. This asserts that if learning is supposed to take the instance weight values into consideration, using weighted sampling to form a bagging predictor may receive better performances than directly include weight values to form a single learner. 
This observation, of course, ma y also attribute to the fact that an ensemble predictor is likely more stable and accurate than a single learner. models, we can observe that although VOCLs and 
VOCLw can outperform FOCL , it becomes increasingly difficult for them to receive large performance gains when user interests change in a random manner ( i.e. probability shifting). This is because when user interests remain stable, VOCLs and VOCLw can leverage information across multiple chunks to strengthen the prediction accuracy, whereas FOCL can only utilize information from neighboring chunks for learning. On the other hand, as users shift their interests away from the current class, the majority models trained from historical data chunks should be discarded. FOCL naturally fits such environments by using only two data chucks for training, so a shifting interest can be quickly adjusted. For VOCLs and VOCLw, it will take at least k -1 chunks for them to completely discard old concepts . In short, although FOCL employs a filtering mechanism to leverage information from neighboring chunks, it suffers from the deficiency of direct instance exclusion (w hich may eliminate genuine positive samples) and inclusion (which may include false-positive samples), and insufficient utilization of global knowledge from the historical data. under situations where the size of the labeled set ( varies or the percentage of genuine positive samples ( varies. In short, the results largely support our conclusion that when positive samples are (randomly) vaguely labeled, VOCL provides effec tive solution to differentiate vaguely labeled positive samples and leverage information across multiple chunks for learning. 
In this subsection, we compare algorithm performance under scenarios that users can merge instances into clusters for labeling. In our experiments, we first use k -means to merge instances in S i into k clusters, and then let users label one or multiple clusters as positive until the labeled set reaches size  X  (please refer to Section 5.1 for detailed procedures). In Figure 9, we first report the average accuracies with respect to different k values for k -means clustering (using the probability shifting model). from 3 to 50, we can observe that the purities of the labeled sample sets continuously improve. This is easy to understand because larger cluster numbers imply smaller size clusters, so the labeling process may have a better chance to select clusters containing more genuine positive samples. Interestingly, the results in Figure 9 show that while the purity of the labeled set improves, no significant improvement is actually observed for all methods, except VOCLs and VOCLw which only receive a small amount of performance gains. We believe that this is mainly because genuine positive samp les selected by random vague labeling are usually more representative, from a supervised learning perspectiv e, than those selected by clustering vague labeling. Indeed, in random vague labeling, genuine positive samples are randomly selected which may represent the underlying learning problem in a best way. For clustering vague labeling, genuine positive samples are selected by cluste rs. Because instances within one cluster usually represent a specific aspect of a big problem, genuine positive samples selected from this approach intend to be less representative. specifying different positive set sizes (  X  ) with a fixed cluster number ( k =20) for all chunks (we omit the accuracies of VOCLw to repo rt labeling purities of each stream). The results confirm that as the size of the labeling set grows, it is mostly helpfu l for all methods to receive performance gain. (1) the VOCL learning framework can outperform FOCL and other methods for one-class data streams labeled by clustering based batch-labeling; (2) VOCL is much less sensitive than other methods w.r.t. the purities and the representativeness of the samples. In other words, VOCL can not only tolerate vaguely labeled samples, it can also work effectively on a training set where genuine positive samples are relatively less effective to represent the underlying learning concepts; and (3) comparing random vague labeling and clustering vague labeling, the former has a better capability of building a labeling set preserving the original learning concepts, whereas the latter is more effective in helping users identify positive samples. 
In this paper, we formulated a new research problem of vague one-class learning for da ta streams. We argued that in data stream environments, providing fast and accurate labeling information is crucia l but difficult to realize, mainly because that existi ng instance-based labeling approaches are expensive and time consuming. 
Alternatively, we advocated a vague labeling paradigm which allows users to merge instances into groups and label positive groups instead. The vague labeling approach, nevertheless, raises three special challenges. 
First, a vaguely labeled training set may contain non-positive instances. Second, users may shift their interests at any time and the concepts underneath the data may also change gradually. Last, as data volumes continuously grow, it makes traditional one-class learning algorithms incapable of handling stream data. To solve these problems, we proposed a double weighting based Vague 
One-Class Learning (VOCL) framework. Experimental results on four data streams confirmed that VOCL significantly outperforms its rival peers to support one-class learning for vaguely labeled data streams. remain wide open. We list here two problems which, in our opinion, deserve further investigations. First, label summarization: a unique featur e of one-class learning is that users do not have class categories but all selected samples as regarded as positive. Providing summaries for labeled samples becomes an essential issue to help understand user interests at high levels or to help cluster multiple one-class data streams into groups. Second, active one-class data stream learning: we have shown that labeling quality plays a fundamental role for one-class learning. Proposing new solutions for users to identify important samples for labeling is another direction which should also be addressed for one-class stream data mining. 
