 Classification is one of the fundamental tasks in machine learning that has been stud-ied substantially over decades. Recent studies [1, 8, 9] show that classification ensemble learning techniques such as Bagging [2] and Boosting [6] are very powerful for increas-ing accuracy by generating and aggregating multiple classifiers.

Classification based on patterns is a relatively new methodology. Patterns are con-junctions of simple conditions, where each c onjunct is a test of the value of one of the attributes. Emerging Patterns (EPs) [4] are defined as multivariate features (i.e., patterns or itemsets) whose supports (or frequencies) change significantly from one class to an-other. As a relatively new family of classifiers, EP-based classifiers such as the CAEP classifier [5] and the JEP-classifier [7] ar e not only highly accurate but also easy to un-derstand. It is an interesting question how to combine multiple EP-based classifiers to further improve the classification accuracy.
 Bagging of previous EP-based classifiers (such as the CAEP classifier and the JEP-Classifier) does not work because of the following reasons: (1) these classifiers -us-ing a scoring function that aggregates supports -heavily biased toward the support of EPs; (2) the supports remain relatively stable with respect to different samples. These properties are very similar to the Naive Bayes (NB) classifier, as it is remarked in [1] that NB is  X  X ery stable X . It is well recognized that an important pre-requisite for clas-sification ensemble learning to reduce tes t error is to generate a diversity of ensem-ble members. Therefore, our aim is to produce multiple diverse EP-based classifiers with respect to different bootstrap samples. Our solution is a new scoring function for EPs-based classifiers. The key idea is to abandon the use of support in the scoring function, while making good use of the discriminating information (i.e., growth rates) contained in EPs. Our scoring function not only maintains the high accuracy, but also makes the classifiers diverse with respect to different bootstrap samples. We also de-velop a new method for combining the knowl edge learned in each individual classifier. Instead of simply using majority voting, we only consider the votes of member clas-sifiers that have good knowledge about a specific test -if a classifier does not have enough knowledge about the test, its right of voting is deprived. We carried out experi-ments on a number of benchmark datasets to study the performance of our new scoring function and voting scheme. The results show that our method of creating ensembles often improve classifier performance vs. l earning a classifier over the entire dataset directly.

We highlight the following contributions. First, we studied bagging of the EP-based classifiers for the first time. Our analysis shows that CAEP classifier and JEP-Classifier are stable inducers due to their scoring function favoring EPs X  support rather than EPs X  discriminating power (growth rates). Second, we proposed a new scoring function for EP-based classifiers, which maintains the excellent accuracy while increasing the di-versity of ensemble members. Both t-tests and wilcoxon rank sum tests show that the bagged ensemble of the new-scoring-function based classifiers often significantly im-proves classification performance over an individual classifier. What is more, our en-semble classifiers are superior to other ensemble methods such as bagged C4.5, boosted C4.5 and RandomForest [3]. Lastly, we designed a new scheme to combine the outputs of ensemble members. Different from the static weighting of bagging and boosting, we assign weights to member classifiers dynamically  X  instance-based , based on whether they have specific knowledge to classify the test. Our scheme can also be applied to combine the outputs of other rule based classifiers. We assume any instance is represented by an itemset. We say an instance S contains another X ,if X  X  S . The support of X in a dataset D , supp D ( X ) ,is count D ( X ) / | D | , where count D ( X ) is the number of instances in D containing X .

We first use a two-class problem to illustrate the main idea of our scoring function and then discuss how to generalize it in the case of more than two classes. Let the training dataset D contain two classes: D = D i  X  D  X  i . Suppose X is an EP of class C i and S is a test to classify. We define GrowthRate i ( X )= supp i ( X ) /supp  X  i ( X ) . If X S , we can not use X to determine whether S belongs to class C i .However,if X  X  S , we can use it effectively: we predict that S belongs to class C i with confidence of GrowthRate i ( X ) / ( GrowthRate i ( X )+1) . This is because
GrowthRate i ( X )+1 = Similarly, we predict that S does not belong to class C i (belonging to C  X  i instead) Note that if X is a JEP (where GrowthRate i ( X )=  X  ), we let GrowthRate i ( X ) / ( GrowthRate i ( X )+1)=1 and 1 / ( GrowthRate i ( X )+1)=0 .
 To determine whether S belongs to class C i , we may also consider EPs of class C  X  i . Using Y , we predict that S belongs to C i with confidence of 1 / ( GrowthRate  X  i ( Y )+ 1) = supp i ( X ) / ( supp i ( X )+ supp  X  i ( X )) .When Y has large growth rate, the impact of
Y on the final decision is very small and hence negligible. However, when its growth rate is relatively small (e.g., GrowthRate  X  i ( Y ) &lt; 5 ), its impact should be considered.
For a k -class ( k  X  2) problem, where D = D 1  X  D 2  X  X  X  X  X  D k , we use the one-against-all class binarization t echnique to handle it. For each class D i , we discover a set E (
C i ) of EPs from ( D  X  D i ) to D i ,andaset E (  X  C i ) of EPs from D i to ( D  X  D i ) ,where  X  C i refers to the non-C i class ( D  X  D i ) . We then use the following scoring function. Definition 1. Given a test instance T ,aset E ( C i ) of EPs of data class C i and a set E (  X  C i ) of EPs of data class non-C i ,the score of T for the class C i is defined as Note GrowthRate ( X )= supp C i ( X ) /supp  X  C i ( X ) since X  X  E ( C i ) ; Growth -Rate ( Y )= supp  X  C
Then we have the following: score ( T,C i ) Let the impact of an EP be its support in class C i divided by the support across all classes. The impact measures how much more frequently an EP appear in its home class than in the whole dataset. The above formula effectively means summing up the contributions of all EPs that are contained in the test. Given a number of independently learned EP-based classifiers, we must combine their knowledge effectively. A reasonable combining scheme is to simply let all the classifiers vote equally for the class to be predicted. However, some member classifiers may have no EPs to use to classify a test instance (where the scores for all classes will be zero). These classifiers should be deprived of their rights to vote. The ensemble scheme is formally shown in Definition 2.
 Definition 2. Given the ensemble classifier C  X  (the combination of N classifiers built from N bagged training datasets C 1 , C 2 ,  X  X  X  , C N ) and a test instance T =( x t ,y t ) for the test T ,  X  (true) = 1 and  X  (false) = 0 . Note that C i ( T )=  X  1 when C i fails to classify T ;otherwise, C i ( T )= j, j  X  Y = { 1 , 2 ,  X  X  X  ,k } .
 Our voting scheme is different from the static weighting of bagging and boosting. It assigns weights to member classifiers dynamically  X  instance-based , based on whether they have specific knowledge to classify the test. Our scheme can also be applied to combine the outputs of other rule based classifiers. We evaluate the proposed approaches to learning by experiments on 27 well-known datasets from the UCI Machine Learning Repository. We use WEKA [10] X  X  Java im-plementation of C4.5, SVM, RandomForest , bagging and boosting. The accuracy was obtained by using the methodology of stratified ten-fold cross-validation (CV-10).
Since we will use the newly proposed scoring function (definition 1) as the base classifier (denoted as EP base ) to create classifier ensembles, we investigate its perfor-mance first. We do not provide detailed classifier accuracy due to the space constraint. Instead we present a win/draw/loss summary in Table 1 (left part) to compare overall performance of EP base against each other classifier (C4.5, SVM, JEP-Classifier). We find that EP base achieves an average accuracy similar to other classifiers (SVM and JEP-Classifier) and higher than C4.5.

Then we investigate the performance of bagging our new EP-based classifier. We choose 51 bags, generating 51 diverse ensemble members. The ensemble classifier is denoted as EP bag . The results clearly show that EP bag is superior to single EP-based classifier: t-tests show that EP bag is significantly better than EP base on 14 datasets and never significantly worse on the remaining 13 datasets. The improvement is due to the diversity of ensemble members. EP bag is also superior to bagged C4.5, boosted C4.5 and RandomForest, as validated by t-tests and Wilcoxon signed rank test for signifi-cance (Table 1 right part).

The number of trials TN is equal to the number of classifiers built. We plot the effect of TN on accuracy in Figure 1. Not surprisingly, as TN increases, the performance of the ensemble classifier usually improves, although there are fluctuations. We expect the ensemble of EP-based classifiers maintains the ability of noise tolerance. From Figure 2, we see clearly that the EP-ensemble classifier has good noise tolerance and consistently achieves higher accuracy than C4.5 and RandomForest across all noise levels. In this paper, we discussed why the  X  X agging X  of CAEP and JEP-Classifier produces no gain. Based on the analysis, we propose a new scoring function to use EPs in clas-sification. This new EP classifier is not only highly correct, but also give diversified outputs on different bootstrap samples. The two characteristics of our new EP classifier are important for the success of creating ensembles of them. We also develop a new, dynamic (instance based) voting scheme to combine the output. This voting scheme can be applied to combine the results of other rule-based classifiers. The experiments show that our method is able to create very eff ective ensembles of EP-based classifiers.
