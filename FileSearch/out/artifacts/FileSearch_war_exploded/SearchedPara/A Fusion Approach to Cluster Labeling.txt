 We present a novel approach to the cluster labeling task us-ing fusion methods. The core idea of our approach is to weigh labels, suggested by any labeler, according to the es-timated labeler X  X  decisiveness with respect to each of its suggested labels. We hypothesize that, a cluster labeler X  X  la-beling choice for a given cluster should remain stable even in the presence of a slightly incomplete cluster data. Using state-of-the-art cluster labeling and data fusion methods, evaluated over a large data collection of clusters, we demon-strate that, overall, the cluster labeling fusion methods that further consider the labeler X  X  decisiveness provide the best labeling performance.

The cluster labeling task aims at finding a single label to a given cluster of documents [1, 6]. Such label should best describe (to a human) the cluster X  X  main topic [6].
Numerous previous works have focused on the develop-ment of various cluster labeling methods [6, 12, 13, 11, 2, 4, 7]. Two main types of cluster labeling methods may be employed, namely direct and indirect methods. Cluster labels may be directly extracted from the content of the cluster X  X  documents. For example, cluster labels can be ex-tracted using various feature selection methods [9], choosing the most frequent terms (keywords, n-grams, phrases, etc) in the cluster or the top weighed cluster centroid X  X  terms [5]. In addition, cluster labels can be extracted using anchor text [6], named entities [12], utilizing the cluster X  X  hierar-chy [13], etc. Cluster labels may be further indirectly ex-tracted using external relevant label sources, e.g, using Wikipedia X  X  categories [11, 2], Dbpedia X  X  graph [7], Free-base X  X  concepts [4], etc.

In this work we present a novel approach to the cluster labeling task using fusion methods [14]. The core idea of our approach is to weigh labels, suggested by any labeler, according to the estimated labeler X  X  decisiveness with re-spect to each of its suggested labels.

We hypothesize that, a cluster labeler X  X  labeling choice for a given cluster should remain stable even in the presence of a slightly incomplete cluster data. The stability of a cluster labeler X  X  decisiveness, therefore, dictates how much should one relay on its cluster labeling decisions.

We first describe how a given cluster labeler X  X  decisive-ness may be estimated given any of its suggested labels. We then demonstrate how such estimate can be further used to combine several cluster labelers within state-of-the-art fu-sion methods for boosting the overall cluster labeling per-formance.

To the best of our knowledge, our work is the first to sug-gest a meta -cluster labeling solution based on fusion meth-ods.
Let C denote a cluster of documents, obtained by some clustering algorithm [1]. For a given cluster C , a cluster labeler L suggests one or more labels, presumed to best rep-resent the cluster X  X  main topic.

Our main goal is to combine the scores of labels that were initially extracted by several cluster labeling methods. Therefore, we assume a cluster meta -labeling framework, where a set of cluster labelers L = { L 1 , . . . , L m } is provided as an input together with the cluster C , which we wish to label. Each labeler L  X  L takes a cluster C as an input and may suggest a pool of total of n L distinct candidate cluster labels L ( C ). Each candidate label l  X  L ( C ) is scored by labeler L according to its (internal)  X  X elief X  on how well label l represents the main topic of cluster C .

Let S L ( l | C ) denote the score assigned to label l  X  L ( C ) by labeler L  X  L and let L [ k ] ( C ) denote the list of top-k scored labels. In addition, let r l ( L ( C )) denote the rank of label l  X  L ( C ) according to its relative score S L ( l | C ).
We now present a novel fusion approach, tailored to the cluster labeling task. We first describe how a given cluster labeler X  X  decisiveness about some suggested cluster label can be effectively estimated. We then shortly describe how the new estimate can be used to combine several cluster labelers within state-of-the-art fusion methods.
For a given cluster labeler L  X  L and a label l  X  L [ k ] suggested by L and ranked at position r l ( L [ k ] ( C )), we now derive an estimate of the decisiveness of labeler L with re-spect to that specific label choice at that specific posi-tion . We hypothesize that, a cluster labeler X  X  labeling choice for a given cluster should remain stable even in the presence of a slightly incomplete cluster data.

The stability estimate is derived by measuring what effect may slight changes applied on the original input cluster C have on the labeler L  X  X  labeling decisions. Such change ef-fects are simulated in the form of incomplete versions of the cluster C . For that, several sub-clusters are sampled, each contains a subset of documents from the original cluster C . That is, given a noise level  X   X  [0 , 1], a sub-cluster C sampled by (randomly) choosing (1  X   X  )  X  | C | of the original cluster C  X  X  documents, where | C | denotes the number of doc-uments in cluster C . Note that, the random noise  X  should be kept as limited as possible, not to drastically effect each sub-cluster C i  X  X  coherency with the original cluster C [1]. Overall, N (random) sub-clusters C  X  = { C 1 , C 2 , ..., C sampled.

For a given sub-cluster C i  X  C  X  , let L [ k ] ( C i ) be the corre-sponding list of top-k labels suggested by labeler L for C Inspired by the idea of cluster consensus [10], the labeler L  X  X  decisiveness with respect to a given label l  X  L [ k ] (position) choice is derived by measuring the amount of agreement among the sampled sub-clusters X  top-k label lists L [ k ] ( C i ) with that label (position) choice. The higher the agreement, the more we claim that labeler L is decisive with respect to its original choice of l as the label of cluster C .
Following [10], the extent of agreement is measured by averaging the pairwise agreements between N ( N  X  1) / 2 possible pairs of the sampled sub-clusters X  top-k label lists L [ k ] ( C i ). Lets now assume that a given label l  X  L [ k ] ranked by labeler L at some position q (i.e., r l ( L [ k ] For a given pair of sub-clusters C i , C j  X  C  X  , the pairwise agreement between the two corresponding top-k sub-cluster is confirmed by checking that: (1) label l is also included in both top-k label lists L [ k ] ( C i ) and L [ k ] ( C is further positioned at most at position q in both lists agreements are gathered for label l , the more it implies that labeler L may be decisive with respect to that specific label choice.

Noting that a  X  X ocal X  measurement of the pairwise-label list agreement based on a single label X  X  position may not be robust enough by itself, we further measure the (overall) expected agreement between the two lists. For that, we adapt the stability index of [8], previously suggested in the context of sequential forward selection (SFS) methods [8]. Following [8], the expected agreement between any pair of label lists L [ k ] ( C i ) and L [ k ] ( C j ) is measured relatively to their intersection size. Such intersection was shown to follow an hypergeometric distribution and the expected agreement is derived according to the (normalized) difference between the expected and the observed intersection size [8].
For a given label position 1  X  q  X  k , let L [ q ] ( C i,j L [ q ] ( C i )  X  L [ q ] ( C j ) denote the intersection between the pair of (ranked) label lists, considering only those labels that are ranked at some position 1  X  q  X   X  q . Let I n l  X  L [ q ] be an indicator, given the value of 1 iff label l is included in the intersection L [ q ] ( C i,j ) (i.e., when positioned in both lists at most at position q ), otherwise 0. Further following [8], for any pair of sub-clusters C i , C j  X  C  X  labeled by labeler L , the corresponding expected (overall) agreement between their corresponding top-k label lists L [ k ] ( C i ) and L given by:
No te that, in the case of a full agreement (i.e., | L [ k ] k ):  X  L i,j ( k ) = 1; while in the case of no agreement:  X   X  1 as k  X  n L 2 .

Fina lly, the cluster labeler L  X  X  decisiveness with respect to a given label choice l  X  L [ k ] ( C ) at position r l ( L is given by the average pairwise-list agreements:
Therefore, a label l that has a high consensus about its specific position in L [ k ] ( C ) among highly agreeable pairs of label for cluster C based on labeler L  X  X  decisions.
We now shortly describe how the new estimate can be used to combine several cluster labelers within state-of-the-art fusion methods.

Let L [ k ] ( C ) = S L  X  X  L [ k ] ( C ) denote the overall label pool based on the union of all top-k scored labels suggested by each labeler L  X  L for cluster C . Our goal, is therefore, to find a combined cluster labeling (fusion) score, such that the top-k labels returned by scoring labels l  X  L [ k ] ( C ) according to that score may result in a better cluster label suggestion.
As a proof of concept , we now introduce two baseline state-of-the-art data fusion methods, frequently used for var-ious information retrieval tasks, namely the CombSUM and CombMNZ fusion methods [14].
 note its normalized score. The CombSUM fusion method then simply sums over the normalized label scores given by the various labelers in L [14]: where for any labeler L  X  L , if l 6 X  L [ k ] ( C ), then S 0 [14].

The CombMNZ method further boosts labels based on the number of top-k label lists that include each label [14]: CombMNZ ( l |L [ k ] ( C )) = # n l  X  L [ k ] ( C ) o  X  X
Finally, the two baseline fusion methods are now extended by further boosting the original (normalized) label score of each labeler according to the labeler X  X  estimated decisiveness as follows 1 :
We evaluated the proposed cluster labeling fusion meth-ods using two sources of clusters data, previously also used in other works on cluster labeling [13, 2]. The first is based on the 20 News Group (20NG) collection, containing docu-ments that were manually classified into 20 different cate-gories (each category with about 1000 documents). The sec-ond is a data collection that was gathered using the Open Directory Project (ODP) RDF dump 2 . For that, a ran-dom sample of documents from 150 different ODP categories (each category with about 30-100 documents) was obtained by crawling their contents from the web. Gathered ODP clusters (categories) have diverse topics, including among others topics related to arts, technology, business, science, etc.
We closely followed previous cluster labeling evaluation frameworks [13, 2]. Therefore, for each given cluster, its ground truth labels used for the evaluation were obtained by manual (human) labeling. According to [13, 2], a label suggested by some labeler for some cluster should be consid-ered as correct if it is  X  identical, an inflection, or a Wordnet synonym of the cluster X  X  correct label  X  [2].

The Match@k and MRR@k (Mean Reciprocal Rank) label quality measures were used for the evaluation [13, 2]. The two measures evaluate a given labeler X  X  capability of providing a single correct label for a given cluster, which best describes the cluster X  X  main topic. The Match@k mea-sure returns 1 iff at least one correct label is located among the top-k labels proposed by the labeler. The MRR@k mea-sure, on the other hand, returns the inverse of the rank of the first correct label in the top-k list. Otherwise, both mea-sures return the zero value.
To evaluate the relative performance of the various cluster labeling fusion methods that were described in Section 2.2.2, two baseline cluster labelers were implemented. The first is a direct cluster labeler, termed hereinafter as the JSD method , previously employed by [2] and is based on the query difficulty model of [3]. Cluster terms are scored by the JSD method according to their relative contribution to the Jensen-Shannon divergence between the cluster and the whole collection [3, 2]. The top-k scored terms are then suggested as the cluster X  X  labels [2]. The JSD method has been shown to be superior to several other state-of-the-art direct cluster labelers [2].

The second, termed hereinafter the Score Propagation ( SP ) method , is an indirect cluster labeler proposed by [2] which utilizes the Wikipedia X  X  categories for cluster label-ing. The SP method was shown to provide a superior per-formance to that of several other direct and indirect clus-ter labelers [2]; and among those, to that to of the JSD
CLD in itials stand for  X  X luster Labeler Decisiveness X  http://rdf.dmoz.org/ method. The core idea behind the SP method is to map im-portant terms that were extracted by a given direct labeler (e.g., JSD terms) and are supposed to represent the clus-ter, to Wikipedia categories that may better capture the cluster X  X  main topic [2]. Such mapping is done by first sub-mitting the list of top-k important cluster terms as a query to an inverted index of Wikipedia documents. Then, us-ing a voting approach, cluster labels are chosen by picking those categories that obtained the highest votes, relatively to the scores propagated from relevant Wikipedia documents to their associated categories [2]. Cluster labels obtained from Wikipedia X  X  categories were shown to better agree with hu-man labelers, sometimes even providing labels that cannot be found in the content of the cluster X  X  documents [2]. The top-k labels suggested by each labeler (i.e., JSD and SP methods) were further combined using the various base-line and extended fusion methods that were described in Section 2.2.2. As additional baselines, we choose the Comb-MAX and Borda-Count fusion methods [14].

Recall that, a cluster labeler X  X  decisiveness estimation de-pends on two parameters which are  X  (the amount of cluster noise) and N (the number of random sub-cluster samples). Trying to keep the evaluation as robust as possible, the two parameters were tuned using the (relatively small) 20NG col-lection, while the large ODP collection (with 150 clusters) was left untouched for testing purposes only. The best pa-rameter configuration was therefore:  X  = 0 . 05 and N = 20.
Finally, for each ODP cluster, the top-20 (i.e., k = 20) labels suggested by each cluster labeling (fusion) method were judged for correctness.
The results of our evaluation are depicted in Fig. 1. The two extended fusion methods are further named as Comb-SUM(CLD) and CombMNZ(CLD) in Fig. 1. Overall, the extended fusion methods provided the best performance for both label quality measures. The CombMNZ(CLD) method was the most superior among all methods, providing a sta-tistically significant improvement 3 over the best perform-ing baseline cluster labelers (i.e., JSD or SP), with an aver-age improvement (over k ) of 6 . 5(  X  0 . 4)% and 8(  X  1 . 6)% for the MRR@k and Match@k measures, respectively.

We can further observe that, the overall cluster labeling quality of the two baseline labelers (i.e., JSD and SP) varies with k , the number of top suggested labels. For the MRR@k measure, the SP method demonstrated a consistent superi-ority over the JSD method, supporting similar results that were previously reported by [2] for this measure. On the other end, we observe that, a similar superiority of the SP method over the JSD method that was also previously re-ported for the Match@k measure in [2] is not supported by our evaluation. While for k  X  5, the SP method provided a better performance, for k  X  6, we observe an opposite trend 4 .

Such inconclusive result of which baseline cluster labeler to prefer (i.e., JSD or SP) actually serves as the main mo-tivation of our work. As can be further observed in Fig. 1, no  X  X raditional X  baseline fusion method has managed to provide consistent improvements over the baseline cluster la-pair ed t-test, p-value &lt; 10  X  11 .
We note that, such differences in the reported results are actually possible, as we may have used a different (and a larger set by 50%) collection of ODP clusters to that of [2]. methods are statistically significant (paired t-test, p-value &lt; 10 belers compared to the new extended fusion methods. This serves as another evidence of the usefulness of using the new cluster labeler decisiveness (CLD) estimate for boosting the cluster labeling performance. [1] CharuC. Aggarwal and ChengXiang Zhai. A survey of [2] David Carmel, Haggai Roitman, and Naama [3] David Carmel, Elad Yom-Tov, Adam Darlow, and [4] Jackie Chi Kit Cheung and Xiao Li. Sequence [5] Douglass R. Cutting, David R. Karger, Jan O.
 [6] Eric Glover, David M. Pennock, Steve Lawrence, and [7] Ioana Hulpus, Conor Hayes, Marcel Karnstedt, and [8] Ludmila I. Kuncheva. A stability index for feature [9] Christopher D. Manning, Prabhakar Raghavan, and [10] Nam Nguyen and Rich Caruana. Consensus [11] Zareen Saba Syed, Tim Finin, and Anupam Joshi. In [12] Hiroyuki Toda and Ryoji Kataoka. A clustering [13] Pucktada Treeratpituk and Jamie Callan.
 [14] Shengli Wu. Data fusion in information retrieval ,
