 etc. Almost all these techniques try to map data to lower dime nsional spaces while approximately preserving useful information. However, most of these tech niques do not assume anything about the data other than that they are imbedded in some high dimens ional Euclidean space endowed with some distance/similarity function.
 excellent example of automated motion capture in which a lar ge number of points on the body of body (which causes each captured frame to lie in a very high di mensional space), these points are nevertheless constrained by the degrees of freedom offered by the human body which are very few. Algorithms that try to exploit such non-linear structure in data have been studied extensively re-sulting in a large number of Manifold Learning algorithms for example [3, 4, 5]. These techniques sampling of points that is  X  X ufficiently X  dense with respect to some manifold parameters. Recently in [1], Dasgupta and Freund proposed space partiti oning algorithms that adapt to the in-[7], spectral clustering [8], face recognition [9] and imag e super-resolution [10]. 1.1 Contributions as typical guarantees given by these data structures are of the following types : These guarantees play a crucial role in algorithms for fast a pproximate nearest neighbor searches in [1]. Next, we prove an  X  X ffective X  aspect ratio bound for R PT REE -M AX . Given the randomized we prove a weaker result that can nevertheless be exploited t o give a packing lemma of the kind cell in the RPT REE -M AX that completely contains B .
 structure adapts to the Local Covariance Dimension of data (see Section 5 for a definition). By showing that low-dimensional manifolds have bounded local covariance dimension, we show its Dimension (this paper).
 Due to lack of space we relegate some proofs to the Supplementary Material document and present the intrinsic dimensionality of data and by D , the ambient dimensionality (typically d  X  D ). low-dimensional manifolds have low doubling dimension (se e [1] Theorem 22) hence the structure adapts to manifold dimension as well.
 Definition 1. The doubling dimension of a set S  X  R D is the smallest integer d such that for any ball B ( x, r )  X  R D , the set B ( x, r )  X  S can be covered by 2 d balls of radius r/ 2 . The RPT REE -M AX algorithm is presented data imbedded in R D having doubling dimension d . The algorithm splits data lying in a cell C of radius  X  by first choosing a random direction v  X  R D , 6 X  / point x  X  C and using the estimate  X   X  = max( {k x  X  y k : y  X  C } ) .
 The following result is proven in [1] : Fact 2 (Theorem 3 in [1]) . There is a constant c M AX is built using a data set S  X  R D . Pick any cell C in the RPT REE -M AX ; suppose that constructing the subtree rooted at C ), every descendant C  X  more than c radius ( C  X  )  X  radius ( C ) / 2 .
 In Sections 2, 3 and 4, we shall always assume that the data has doubling dimension d and shall factor of 2 after c we expect that after c possible to argue that after c the basic size reduction result in [1]. We omit the proof of th is extension. This gives us a way to boost the confidence and do the following : go down L = c Afterward, go an additional L  X  = c of Theorem 4. There is a constant c least 1  X  1 / 4 , every descendant C  X  which is more than c radius ( C ) /s .
 Proof. Refer to Supplementary Material Notice that the dependence on the factor s is linear in the above result whereas one expects it to poly-logarithmic in the size reduction factor s . In this section we prove the following theorem : Theorem 5 ( Main ) . There is a constant c is built using data set S  X  R D . Pick any cell C in the RPT REE -M AX ; suppose that S  X  C c 3 log s d log sd RPT REE -M AX that contains a dataset S having doubling dimension  X  d . Then for any  X  &gt; 0 , a of radius  X   X  . We will cover S  X  C using balls of radius  X  suffice. Now consider all pairs of these balls, the distance b etween whose centers is  X   X  We fix such a pair of balls calling them B with respect to this pair if it sends points inside B and points inside B otherwise (See Figure 1). We have the following properties o f a random split : Lemma 6. Let B = B ( x,  X  ) be a ball contained inside an RPT REE -M AX cell of radius  X  that Proof. Refer to Supplementary Material Lemma 7. Let B Proof. Refer to Supplementary Material. Proof similar to that of Le mma 9 of [1]. Lemma 8. Let B Proof. The proof of a similar result in [1] uses a conditional probab ility argument. However the result then follows from an application of Lemma 6.
 balls whose centers are well separated (which are O ( sd ) 2 d in number) and conclude the proof. Proof. (of Theorem 5) Consider a cell C of radius  X  in the RPT REE -M AX and fix a pair of balls contained inside C with radii  X  / 960 s p contains data points from both the balls. Then the following holds : Lemma 9. p 0 Proof. Refer to Supplementary Material. Proof similar to that of Le mma 11 of [1]. Note that this gives us p 0 to go down k =  X ( sd log( sd )) levels before p 0 become more frequent.
 all descendants go down by a factor s . Denote by p l l and by p l the radius of every cell at level l  X  is less than  X  Notice that now, for any m &gt; 0 , we have p l  X  which gives us the desired result on solving the recurrence i .e. L ( s ) = O ( d log s log sd ) . In this section we prove a probabilistic packing lemma for RP T REE -M AX . A formal statement of the result follows : M
AX cells of radius greater than r that intersect B is at most R Data structures such as BBD-trees give a bound of the form O R inscribed in an RPT REE -M AX cell C of radius no more than O Rd  X  d log d . Thus the number of C with this radius. To bound this number we then invoke Theorem 5 and conclude the proof. 4.1 An effective aspect ratio bound for RPT REE -M AX cells
Figure 2: Balls B  X  / 512 annulus centered at B of mean radius  X  / 2 and thickness  X  / 512 Without loss of generality assume that the centers of all the se balls lie in C . lie in a cell of radius &lt;  X  / 2 . Fix a B it separates B from B Lemma 11. There exists a constant c radius  X  getting split before it lands up in a cell of radius  X  / 2 is at most c 5 Rd  X  d log d Proof. Refer to Supplementary Material We now state our result on the  X  X ffective X  bound on aspect rat ios of RPT REE -M AX cells. Theorem 12. There exists a constant c B of radius R will be completely inscribed in an RPT REE -M AX cell C of radius no more than c Proof. Refer to Supplementary Material Proof. (of Theorem 10) Given a ball B of radius R , Theorem 12 shows that with probability at least 3 / 4 , B will lie in a cell C of radius at most R  X  = O Rd descendants of C of radius no less than r . We know from Theorem 5 that with probability at least observing that the RPT REE -M AX is a binary tree and hence the number of children can be at most 2 The second variant of RPT REE , namely RPT REE -M EAN , adapts to the local covariance dimension be contained in a cell of radius c improvement albeit in expectation whereas RPT REE -M AX gives improvement in the worst case but after a certain number of levels.
 We will prove that a d -dimensional Riemannian submanifold M of R D has bounded local covari-ance dimension thus proving that RPT REE -M EAN adapts to manifold dimension as well. M of R D under which the set S when restricted to any ball of radius r has a covariance matrix for which some d diagonal elements contribute a (1  X   X  ) fraction of its trace.
 a dimensions. This is trivially true when M is a d -dimensional affine set. However we also expect that for small neighborhoods on smooth manifolds, most of th e energy would be concentrated in the tangent plane at a point in that neighborhood (see Figure 3). Indeed, we can show the following : Theorem 14 ( Main ) . Given a data set S  X  X  where M is a d -dimensional Riemannian manifold with condition number  X  , then for any  X   X  1 For manifolds, the local curvature decides how small a neigh borhood should one take in order to  X  of M (introduced in [16]) which restricts the amount by which the manifold can curve locally. The condition number is related to more prevalent notions of local curvature such as the second fundamental form [17] in that the inverse of the condition nu mber upper bounds the norm of the second fundamental form [16]. Informally, if we restrict ou rselves to regions of the manifold of For any hyperplane T  X  R D and a vector v  X  R d , let v Fact 15 (Implicit in Lemma 5.3 of [16]) . Suppose M is a Riemannian manifold with condition number  X  . For any p  X  X  and r  X   X   X  X ,  X   X  1 tangent space at p . Then for any x, y  X  X   X  , k x This already seems to give us what we want -a large fraction of the length between any two points to show that for some d -dimensional plane P , P as  X  X roxies X  for the mean and provide a workaround to the prob lem.
 Proof. (of Theorem 14) Refer to Supplementary Material In this paper we considered the two random projection trees p roposed in [1]. For the RPT REE -M
AX data structure, we provided an improved bound (Theorem 5) on the number of levels required to decrease the size of the tree cells by any factor s  X  2 . However the bound we proved is poly-improve the packing lemma (Theorem 10) as well. More specific ally the packing bound would As far as dependence on d is concerned, there is room for improvement in the packing le mma. We have shown that the smallest cell in the RPT REE -M AX that completely contains a fixed ball B of radius R has an aspect ratio no more than O d it and can be circumscribed by a ball of radius no more than O Rd  X  d log d . Any improvement in lemma.
 Moving on to our results for the RPT REE -M EAN , we demonstrated that it adapts to manifold di-mension as well. However the constants involved in our guara ntee are pessimistic. For instance, the radius parameter in the local covariance dimension is gi ven as  X   X  X  g : x  X  X 7 X  X  X k x  X  k attains a local extrema.
 We conclude with a word on the applications of our results. As we already mentioned, packing tree having depth  X ( n ) where n is the number of data points.
 of the points into any of the children thus ensuring a depth th at is logarithmic in the number of M
AX used in that paper. However it remains to be seen if the same tr ick can be used to bound the depth of RPT REE -M AX while maintaining the packing guarantees because although such  X  X pace partitioning X  splits do not seem to hinder Theorem 5, they do hinder Theorem 10 (more specifically they hinder Theorem 11).
 We leave open the question of a possible augmentation of the R PT REE -M AX structure, or a better analysis, that can simultaneously give the following guara ntees : Acknowledgments The authors thank James Lee for pointing out an incorrect usa ge of the term Assouad dimension in sions and for his help with the proofs of the Theorems 5 and 10. Purushottam is supported by the Research I Foundation of the Department of Computer Science and Engineering, IIT Kanpur. References
