 Department of Computer Science, Faculty of Science, Kasetsart University, Bangkok, Thailand 1. Introduction
The classification based on the imbalanced training datasets is one of the most important problems in data mining, machine learning, and pattern recognition [8,19,20,34,71]. The classification problems on imbalanced data are categorized into two-class problem and multiclass problem. To solve imbalance problem, there are two categories of techniques: modifying the data distribution (data level) [5,48] and modifying the classifier (algorithm level) [3,71,72].

In two-class imbalanced dataset, the problem occurs when the number of instances of one class (ma-jority/negative class) hugely outnumbers another class (minority/positive class). The classification on imbalanced data always causes problems because skewed data distribution among classes, small sample size and small disjuncts, class overlapping, dataset shift and etc. [57,67]. Therefore, traditional clas-sification algorithms tend to be overwhelmed by the majority class and ignore the minority class. The predictions of the majority class have a high possibility to get good performance, whereas the predictions of minority classes generally have poor performance. Class imbalance is prevalent in many real-world applications [12,40,41] such as bioinformatics, anomaly detection, intrusion detection, fraud detection and especially in medical diagnosis. These applications usually focus on the minority class. For ex-ample, in medical applications, the numbers of instance in normal cases outnumber the instances from disease cases (the most important class) [31]. Therefore, improving the classification performance on imbalanced dataset is challenging and can contribute to the society.
This paper is concerned with improving the classification performance on multiclass imbalanced dataset, which is even more complicated. Moreover, the higher degree of class imbalance may increase the difficulty of multiclass classification. Solutions for two-class problems are not directly applicable to multiclass cases. One of the famous methods is decomposition technique, which is decompose the multiclass dataset into a series of binary classification problems and then use a two-class learner for a classification task [13,18,32,34] such as One-Against-One (OAO) [60], One-Against-All (OAA) [7]. Several decomposition methods use ensemble approach to combine the models obtained from the binary class classifiers. However, using decomposition with sampling technique is not practical for this prob-lem because it is time consuming. Moreover, in case OAA, results of each class label assignment are not comparable due to the decision can be made differently for different classes [54]. Hence, reducing the number of classes and comparing labels becomes a key issue for applying the resampling technique in multiclass cases.

In this paper, we develop a resampling algorithm for multiclass imbalance problem based on clustering approach namely C-MIEN. Firstly, k-means is used to split the set of instances into two clusters. For each cluster, hybird sampling methods are used. Then, final training sets (classes are balanced) are used to build an emsemble. Finally, the prediction is obtained by combining the results from both clusters through a majority vote. C-MIEN is an extension of our previous works [42 X 44] that focused on different classifiers in the classification part. In our previous works [42,43], we did not apply ensemble in the classification part. The re-balancing process was different from this paper. Moreover, we carefully design the experiments and analyze the behavior of C-MIEN with different parameters (imbalance ratio and number of classifiers). C-MIEN is investigated by adjusting the training process and the training set are different from our previous works. We evaluate C-MIEN on many multiclass datasets from the UCI using decision tree as a classification algorithm. The performance is measured based on G-mean, F-measure and Minimum Sensitivity. The experimental results show that C-MIEN achieved better performance than baseline algorithms.

The rest of this paper is organized as follows: Section 2 presents some of the approaches previously applied to deal with the class imbalance problem. Section 3 describes our approach, Section 4 describe our benchmark datasets, details of experimental parameters and evaluation metrics. Section 5 shows the experimental design, reports the experimental results and also includes a brief discussion. Finally, a conclusion is presented in Section 6. 2. Related work 2.1. The class imbalance problem
Recently, many real world applications face the imbalanced class distribution problem such as text classification, fraud detection, information retrieval, etc. Researchers have proposed many algorithms to solve this problem such as decision tree [45,66], k-nearest neighbor [10,37,59], and support vector machines [3,60]. They found that the classification performance of the majority classes are high whereas the classification performance of the minority classes tends to be low, however the prediction of minor-ity class is more significant in some domains. There are two different approaches to solve the class imbalance problem which are data level and algorithm level methods. Data level methods aim to solve problems by manipulate the class distribution of a training set, including oversampling and undersam-pling methods. Algorithm level methods adapt existing learning algorithms to pay more attention to the minority classes. Both methods decrease the degree of class imbalance. Note that we will focus on the class imbalance problem at the data level methods.

Oversampling method reduces the degree of imbalanced class distribution by increase the size of minority class either by duplicates or interpolates minority instances. The basic oversampling method namely random oversampling (ROS) balances the class distribution by randomly duplicates minor-ity instances into the minority class. Japkowicz et al. [24] showed that ROS does not help to im-prove the classification performance. SMOTE is one of the famous oversampling methods proposed by Chawla et al. [5]. SMOTE produces synthetic minority class instances by interpolating between mi-nority examples that lie together. It makes the decision regions larger towards majority class and less specific. Synthetic examples are introduced along the line segment between each minority class exam-ple and one of its k minority class nearest neighbors. SMOTE reduces the imbalanced class distribution without causing overfitting as shown in many studies [5,6].

Jo et al. [27] proposed cluster-based oversampling algorithm that creates the independent clusters from the minority and majority classes, and then randomly does oversampling for each of the majority clusters, except the largest cluster. This is done with replacement until all of the majority clusters contain the same number of instances as the largest cluster. The algorithm then oversamples each of the minority clusters with replacement until the number of instances in each minority cluster is equal to the number of instances in a majority cluster after oversampling divided by the number of minority clusters. Another method is Cluster Based Synthetic Oversampling algorithm (CBSO) [2], which creates a new synthetic instances using a weight distribution based on the existing synthetic oversampling techniques. Unlike the existing synthetic oversampling techniques, CBSO generates a new synthetic instances using clustering approach (average-linkage agglomerative clustering, a hierarchical clustering algorithm).
On the other hand, undersampling is supposed to reduce the number of instances from the majority class in order to achieve a more balanced class distribution. The simple undersampling method namely random undersampling (RUS) randomly discards instances of a majority class until the ratio between the minority and majority class is at the desired level. Tomek [61] proposed a data learning approach namely Tomek Link to reduce the number of instances in the majority classes. Given two examples E i and E j be-Another method (Yan et al. [70]) uses partitioning and various techniques to break the majority class into n disjoint partitions, and combining these n models to make a final classification. Yen et al. [72] proposed a cluster-based undersampling to determine the number of selected majority class samples in each cluster by using expression, and then randomly select the majority class samples in each cluster. After that, the algorithm randomly selects the majority class samples from each cluster and combines them with the minority class samples to form a new dataset.

Hybrid sampling method [48] uses a combination of two sampling techniques such as random over-sampling and random undersampling to obtain a balanced dataset. Another method combine both over-sampling and undersampling methods by weighting imbalance compensation techniques [46]. The al-gorithm extends one-class classifier providing balance in extreme situations when one of the classes is ignored completely and the algorithm is accomplished using examples from a single class. 2.2. Ensemble classifier for imbalanced datasets
In recent years, ensemble learning is used to improve the performance of the imbalanced classifica-tion [30,38,56,60,73]. Two well-known ensemble methods are Bagging [4] and Boosting [14], which are very successful in improving the accuracy of the certain classifiers. In imbalanced problems, there are several methods that combine both ensemble learning algorithms and resampling techniques. Chawla et al. proposed the SMOTEBoost algorithm [6]. In each iteration of boosting, it utilizes SMOTE to add the new minority class and increases the sampling weights for the minority class instance. Another method is SMOTEBagging [52]. This method combines three popular resampling methods; undersampling, oversampling, and SMOTE; into the ensemble model based on Bagging for diversity analysis. Yang et al. proposed an algorithm namely EnSVM [71] to improve the performance of the Support Vector Machines (SVMs) on imbalanced datasets. It integrates two types of sampling methods by starting with oversampling the minority class to a moderate extent. For undersampling, it uses the bootstrap sampling approach. The size of the new majority class is the same as that of the minority class obtained from SMOTE. The ensemble of SVMs is employed to boost the performance.

Another approach using ensemble learning was introduced by Tian et al. [60]. This method applies the resampling to increases the generalization ability on both minority and majority classes. They proposed the MSK clustering algorithm to split the majority class into clusters for improving the generalization ability of the SVM ensemble. Yun et al. [73] proposed a new ensemble classifier model called SCECM. SCECM adapts a differentiated sampling rate algorithm (DSRA) based on an improved Adaboost algo-rithm. The algorithm employs unique classifier-selection strategy, novel classifier integration approach and original classification decision-making method to enhances the classic structure of integrated clas-sifiers. 2.3. Multiclass classification on imbalanced datasets
Many researches related to the imbalanced dataset concentrated on two-class classification [17,35, 50,71,72]. In case of multiclass datasets, there are two or more minority classes with respect to one majority class. Therefore, this problem can be solved in multiple ways. One typical way is the decompo-sition techniques, which decompose the multiclass classification into several binary classifications such as One-Against-One and One-Against-All. However, some two-class techniques were not useful when applied to multiclass problem directly, especially in the case of imbalanced datasets [74].
Consider the decomposition method, there are some me thods that combine both resampling and binary classification approaches. One of these methods was introduced by Fernndez et al. [13]. They applied an oversampling step before the pair-wise learning process. The quality of this method was tested using the linguistic fuzzy rule based classification system and fuzzy hybrid genetics-based machine learn-ing algorithm. RAMOBoost [7] is another method that solves the multiclass imbalanced dataset using OAA approach. This method used the idea of adaptive synthetic data generation in an ensemble learning system. It adaptively ranks minority class instances at each learning iteration according to a sampling probability distribution that is bas ed on the underlying data distribu tion. Moreover, RAMOBoost adapts an iterative learning procedure that assesses the hypothesis developed at each boosting iteration to adap-tively shift the decision boundary to focus more on those difficult-to-learn instances of both the majority and the minority classes.

Another approach is One-Against-Higher-Order ( OAHO) [32]. They solve the problem of neural net-works, which is biased towards the majority class by sorting the training set based on the class size. The classes with smaller training sizes are used together as negative training examples against the training data of a larger class. The method produces k  X  1 binary classifiers for k -classes dataset. Resampling with binary classification was proposed by [18]. Using resampling techniques is efficient for imbalanced datasets with binary classes by adjusting classification borderlines. But, complex decision regions in multiclass tasks make those methods ineffective [64]. Eve n class decomposition simplifies the multiclass imbalance problem, each individual classifier is trained without full data knowledge. It can cause classi-fication ambiguity of uncovered data regions with respect to each type of decomposition [26,51,58,62]. Moreover, combining the results from classifier learned from different subproblems can cause hidden classification errors [26,51,62].

Research works that avoid using class decomposition technique to solve multiclass imbalance prob-lem are also found in the literature. Navarro et al. proposed a dynamic oversampling method that in-corporated into a memetic algorithm (MA) and uses RBFNNS as the classification model [34]. They introduced two different methods which were the static smote radial basis function (SSRBF) and the dynamic smote radial basis function (DSRBF). DSRBF modifies the oversampling procedure within the learning process. Sun [54] developed a cost-sensitive boosting algorithm to improve the classification performance of multiclass imbalanced dataset namely AdaC2.M1. AdaC2.M1 extended the original Ad-aBoost [15] and AdaC2 [53] algorithms to multiclass cases. Moreover, Genetic Algorithm was applied to find the optimum parameters. Another method was proposed by Shuo et al. [52], who explored the impact of diversity on each class and overall performance. They combined undersampling, oversam-pling and SMOTE methods into ensemble model based on both two-class and multiclass datasets. In multiclass dataset, the algorithm applied the resampling rate of majority class and other classes to con-trol the algorithm. Therefore, for each class, i th , it resample instances with replacement at the rate of ( N C /N i ) a %, where N C is the number of instances in majority classes, N i is the number of instances in class i th , a % is the resampling rate. 3. Method In this section, we present a new resampling method based on clustering approach called C-MIEN. The algorithm does Cluster-based with sampling for Multiclass Imbalanced datasets using Ensemble. C-MIEN aims to improve the performance of multiclass learning from an imbalanced dataset which should have at least three classes. C-MIEN is the data level approach because the algorithm operates on the dataset in order to obtain the balance class distribution. Note that for the multiclass imbalanced dataset, it is more difficult to define the majority and minority classes. Therefore, we need to reduce the number of classes in the multiclass training set without the decomposition method. The process consists of three steps. The first step is a reclustering process using the k-means algorithm. We use k-means because it is simple, fast, and efficient if the number of clusters is known beforehand. When k-means clustering is used, we get two new training sets that the set of instances in the same cluster are assumed to have similar characteristics. Second, for each cluster, we combine oversampling and undersampling in order to rebalance the class distribution (the data re-balancing process). Several works have presented that the combination of two sampling methods generally provides better results that a single technique [25,71]. The benefit of doing two resampling methods in C-MIEN is to mitigate the overfitting and information loss problems. The final step is to classify the class of data of the new training set for each cluster. In this step, we setup two experiments to analyze the behavior of C-MIEN. First, we train a classifier in each cluster. Second, we train base classifiers independently on every subsets of the new training set for each cluster. Then, for each cluster, we improve the classification performance of C-MIEN by using the ensemble learning method and then further combine all models using a new majority vote from both clusters. Although, combination of multiple classifiers will increase the computation time, it reduces either the bias or variance of a learner. The framework of C-MIEN is shown in Fig. 1 and the C-MIEN algorithm is detailed in Algorithm 1. 3.1. Reclustering process
In this step, we use unsupervised learning algorithm to decompose the problem into smaller parts. We assume that the problem can be solved easier since splitting training sets can decrease complicated sam-pling in multiclass datasets. In addition, applying this algorithm on multiclass datasets may improve the performance of the classifiers; because the members in the cluster have similar characteristics. However, in C-MIEN, the training set is separated only once unlike other decomposition techniques. Given the multiclass training set, the reclustering process is performed using k-means algorithm. The main idea of this step is to split all instances into certain number of clusters fixed a priori. C-MIEN divides all instances into two clusters by setting k to be 2. In order to measure the distance between the instance and the centroid, we use the Euclidean distance, which is the simplest.
 Consider the instances in each cluster, let N y i denotes the number of instance of class y i in training Algorithm 1 The pseudo-code of C-MIEN algorithm Require: Given S { ( x 1 ,y 1 ) ,..., ( x n ,y n ) } x i  X  X with labels y i  X  Y = { 1 ...L } ; C = Kmean ( S, k ) ; let C 1 = cluster1, C 2 = cluster2; foreach {classLabel y i } do end temp = C 2 ; //temp contains all instances in cluster 2 for k = 1to2 end Result: The output hypothesis H  X  is calculated as follows: sets of the samples, each of which contains different classes. Note that each class of the dataset will be located in either S 1 or S 2 . After that, the classes from both clusters are combined using relabeling of second cluster are combined with all classes in the first cluster that were relabeled ( R 1 ) as well. The Table 1 shows an example on pageblocks dataset, which is adjusted in the reclustering process. From Table 1, the original pageblock dataset has five classes. After using k-mean, we determine the movement of each class in the re-clustering process and we get two clusters ( C 1 , C 2 ). The number of instances for each class are shown in the third column. After that, two clusters are combined based on relabeling of the class group and we get two new sample sets ( S 1 , S 2 ). The fifth column shows class labels in each cluster that consist of the original classes and the new relabeling classes ( R 1 and R 2 ). The last column concludes the number of instances per class.

Note that the number of clusters is set to be 2. If k is set more than 2, then some clusters may not have majority instance that will affect to the next step of C-MIEN. For example, if we set k to be 3 on 628 instances (Class ACC = 319, Class GOOD = 53, Class UNACC = 216, and Class VGOOD = 40). Cluster 2 ( C 2 ) contains 663 instances (Class ACC = 18, Class GOOD = 17, Class UNACC = 615, and Class VGOOD = 13). Cluster 3 ( C 3 ) contains 437 instances (Class ACC = 47, Class GOOD = 9, Class UNACC = 369, and Class VGOOD = 12). For each class, the instances with highest number occurrences is fixed to the cluster then the classes which have less number of occurrence are moved to the fixed cluster (see Fig. 2(b)). We found that cluster 3 has no instance left. This lead to the problem since C-MIEN will not be able to relabel the instance. Therefore using k =2 can solve this problem and continue to the next process of C-MIEN.

In order to analyze the performance of the selected clustering algorithm, we use the cluster purity and overall purity as evaluation criteria. This measure has been used in many studies [36,55]. Purity measures the purity of the clusters with respect to the given class label. Purity focuses on the frequency of the most common category in each cluster [55]. The purity of a cluster is defined as: cluster j . The overall purity of the clustering is defined as the weighted sum of the individual cluster purities and it computed as follow: Where k is clusters of dataset D. According to this measure, if all clusters consist of objects with the same class, the overall purity is equal to 1 [22]. Table 2 reports the purity and overall purity of two clusters obtained from k-means. The result shows that k-means produces high quality clusters in terms of purity and overall purity measures on most datasets. However, there are two datasets (glass and yeast) that the overall purity of k-means is less than 0.5. 3.2. Data rebalancing process
After the re-clustering process is finished, the data rebalancing process is started. We get two new set of instances, S 1 and S 2 . In order to rebalance the class distribution, we integrate two sampling techniques, SMOTE and random undersampling. The benefit of SMOTE is to alleviates the overfitting problem. Moreover, it generally shows better performance than new intelligent sampling approaches as shown in many previous works [20,49]. Given a training set in k cluster ( k =2 ){ x i ,y i }, i = 1to n ,where x i  X  classes are sorted by the number of instances in the class. Therefore, N y L is the number of instances of class having the largest number of instances called  X  X ver majority class (OM) X . The minority class with the smallest number of instances is called  X  X nder minority class X . Suppose that there are H minority classes, SMOTE algorithm will be processed in C-MIEN (L-H) times.

Imbalance ratio (IR) [13,39] is used to control the data rebalancing process. It is defined as the fraction class distribution), the oversampling method is applied for instances of class y ik . We got new synthetic reduce d instances of the over majority class, where d is the different number of instances among the over majority class obtained from the rebalancing process (see Eq. (3)).
Note that OM is the over majority class. If IR th is equal to 1.5 then the class distribution of the training set is balanced. The example of pageblock dataset is applied in data rebalancing process as shown in Table 3 (suppose that IR th is equal to 1.5). From Table 3, five minority classes (graphic, picture, R 1 , horiz, and vert) are increased using SMOTE (see the fourth column) until the IR is equal to 1.5. In the last column, the number of instances per class are equal. We will demonstrate the impact of IR th on each 3.3. Classification process
We improve the performance of classifier using an ensemble approach that can reduces the variance and/or bias of a set of classifiers. Moreover, the generalization ability of sampling technique with a single classifier is always unsatisfactory and robustness are often poor [19]. For each cluster, C-MIEN builds M bootstrap samples that randomly select instances with replacement. Therefore, M bootstrap samples are trained with M different training sets. In the training process, we get two new training sets ( T 1 ,T 2 ) with different classes. If they are located in both clusters, some instances might have different class label. Therefore, the class of an instance is assigned through the majority vote from two clusters. For example, if we build 3 classifiers as ensemble members for each cluster. We get totally six hypotheses from two clusters. In this paper, we demonstrate the performance of C-MIEN which is applied with different number of classifiers (3, 5, 10, 15, 20, and 30 classifiers), as shown in Section 5.
The classification is done using majority vote from all hypotheses of two clusters. The details of majority vote are implemented as follows: Given a test example, if the final prediction obtained from the majority vote among the three hypotheses of T 1 is equal to R 2 then the classification is depend on the majority vote of the hypotheses of T 2 . Otherwise, the prediction will rely on the majority vote of the three hypotheses of T 1 and the second cluster ( C 2 ) will not be processed. Therefore, in the worst case, C-MIEN will generate totally M 2 bootstrap samples. The final prediction of C-MIEN algorithm is detailed in Table 4. 4. Experimental setup and design
This section describes the experimental setup used to test the performance of our algorithm. We first introduce the datasets used for experiments in Section 4.1. Next we present the evaluation measures in Section 4.2.
 4.1. Benchmark datasets C-MIEN is applied to 7 imbalanced datasets taken from the UCI Repository for Machine Learning [1]. These datasets are imbalanced in term of the number of instances between classes. Three of them (ecoli, pageblocks and yeast) are highly imbalanced datasets whereas the imbalance ratios of the rest four datasets (balance-scale, car, glass, and new-thyroid) are low. Table 5 lists the information of each dataset, with some relevant statistics, such as the number of instances per class and imbalance ratios. 4.2. Evaluation measures
In the imbalanced learning scenario, the overall accuracy is no longer a proper measure because it is strongly biased to the majority class. Since, the classifier predicts all cases as the majority class and performs very poor on the minority class. The result is that a classifier will achieve the high accuracy rate. Therefore, overall accuracy can provide misleading conclusions. For example, a two class dataset consists of 100 instances. 2 of them are a minority class and the remaining instances (98) are a majority class. A simple approach classifies all minority instances as the majority class and it achieves the high accuracy rate of 98%. It is a very high performance, whereas the classifier failed completely to predict all minority class instances, which is more importance in some application domains such as fraud detection, illness detection, etc. Therefore, we need alternative metrics which are not sensitive to class distributions. F-measure, Area Under an ROC Curve (AUC), and G-mean are desirable to measure the classification performance with the class imbalance problem.
 In our experiments, we used three evaluation measures: F-measure, Geometric mean (G-mean), and Minimum Sensitivity (MS). Since we focus on multiclass classification, the confusion matrix has been applied as shown in Table 6. Where C i denotes the class label of the i th class and k is the number of classes. The evaluation measure of multiclass classification was proposed by Sun [54] as shown in Table 7. F-measure is used to measure the overall performance. It is the harmonic mean of precision and recall. Kubat et al. [29] suggested to use the G-mean as the geometric means of recall values of two classes. In multiclass cases, Sun et al. [54] defined G-mean of recall values of every classes as shown in Table 7. As the recall value determines the classification performance of a specific class equally, G-mean is capable to measure the balanced performance among classes of a classification output. The G-mean and F-measure value are in the [0, 1] range. If G-mean value is equal to 1, it means that all minority class instances are identified. On the other hand, if its value is equal to 0, it means that none of the minority class instances are predicted correctly.

In general, the area under the ROC curve (AUC) is the most commonly used measure for class imbal-ance datasets [13,18] and two-class problem. However, the AUC have been applied for multiclass prob-lems based on the one-against-one approach namely MAUC [21]. The results of this approach are shown in terms of probabilistic AUC. However, our approach does not use decomposition method. Therefore, MAUC is not appropriate for our classifiers. In this paper, we use the Minimum Sensitivity [47] to eval-uate the performance of classifier. This measure has been used in [34]. The MS is the minimum value of the sensitivity among classes in the dataset (see Eq. (4)).
 Where S i is the sensitivity of class i and L is the number of classes. 4.3. Comparison with other methods
In this paper, decision tree (C4.5) is used in all experiments because it is sensitive to the amount of negative training examples. The tree is constructed using only those best attributes that are able to differentiate the concepts of the target class. Each node in the tree is an attribute selected from the training set using highest information gain. The C-MIEN method is compared to different algorithms, which are separated into two groups as follow. 4.3.1. The single baseline algorithms and baseline with resampling algorithms  X  Decision tree (C4.5).  X  One-Against-One (OAO).  X  One-Against-All (OAA).  X  Decision tree with Resampling (RC4.5).  X  One-Against-One with Resampling (ROAO).  X  One-Against-All with Resampling (ROAA). 4.3.2. Ensemble with baseline algorithms and resampling algorithms  X  Bagging with Decision tree (BC4.5).  X  Bagging with One-Against-One (BOAO).  X  Bagging with One-Against-All (BOAA).  X  Bagging of Decision tree with Resampling (BRC4.5).  X  Bagging of One-Against-One with Resampling (BROAO).  X  Bagging of One-Against-All with Resampling (BROAA).  X  AdaboostM1 [14].  X  MultiBoosting [65].

Note that, in order to be fair, we apply the data rebalancing process as the resampling techniques for all resampling algorithms.

In order to test the significance of the differences among classifiers, we use Friedman test [16] and the post-hoc Nemenyi test [33] at 95% confidence level to compare among different classifiers. Both statistical tests have been used to test on the classification results in many studies [9,23,28,69]. The null-hypothesis for Friedman test is that all methods are equal and the ranks are same. The Friedman test is a nonparametric test for comparing a number of models over several data sets using their rank. Ranking is done by giving the best a rank of 1, the second best 2, etc. Then, average rank of each method is calculated. Let r i j be the rank of the j th of k algorithms on the i th of N datasets. The Friedman test needs the computation of average ranks of algorithms, R j = 1 N i r j i . The Friedman statistic is defined as: (see Eqs (5) and (6)).
The Friedman statistic is distributed according to the F distribution with k  X  1 and ( k  X  1)( N  X  1) degrees of freedom. Where N is the number of datasets, k is the number of method.

If the null-hypothesis of the Friedman test is rejected, Demzar [11] recommended the Nemenyi post hoc test, which checks for each pair of methods whether there is a significant different in performance. The performance of two methods is significantly different which the difference between their average rank is greater or equal to the critical difference CD (see Eq. (7)), otherwise it means the two methods are similar in the ranks.

In this paper,  X  is set to 0.05 and q  X  obtained from the significance level  X  and the number of models ( k ) by looking at the table of critical values for Nemenyi test [11]. 4.4. Experimental setup for C-MIEN
We setup many experiments to see the behavior of C-MIEN as shown in Table 8. Note that decision tree is used in all experiments because it is sensitive to the amount of negative training examples. Our approach was developed based on WEKA 3.6.0 [68]. All experiments were tested using a 10-fold cross validation strategy. Euclidean distance was used to compute the distance between instances and cluster in the k-means algorithm.

In order to see the impact of the parameter used in data re-balancing process, we test our algorithm (C-MIEN1) using different imbalance ratios ranging from 1.0 to 2.0. For C-MIEN2, it is only focused on the re-clustering process (see Fig. 1(a)). For C-MIEN3, the data re-balancing process (see Fig. 1(b)) is applied only to either S 1 or S 2 , which consists of the under minority class. In this table, we assume that S 1 contains the under minority class. For C-MIEN4, the data re-balancing process is applied to both sample sets. Finally, C-MIEN5 is comprised of re-clustering process, data re-balancing process and ensemble learning.
Consider C-MIEN without ensemble approach (C-MIEN1 to C-MIEN4), after the data re-balancing process is finished, all instances from each cluster are used to train only one classifier. There are totally two classifiers, each of which learns from different cluster. Given a test instance, if it classifies the in-stance as R 2 , the final classification will depend on the hypothesis of the second classifier. Otherwise, the prediction will rely on the hypothesis of the first classifier. We design our algorithms without ensem-ble approach because we want to show the efficiency of two main processes of C-MIEN (re-clustering and re-balancing processes). However, C-MIEN with ensemble (C-MIEN5) achieves the highest perfor-mance. 5. Experimental results
In this section, The performance of C-MIEN is compared to other methods on seven imbalanced dataset. We explore the behavior of C-MIEN on four issues which are impact of imbalance ratios, char-acteristics of C-MIEN on imbalanced data, comparison with ensemble method, and results discussion. 5.1. Impact of imbalance ratios (C-MIEN1)
C-MIEN1 is setup to study the impact of different criteria of imbalance ratios used in our resampling technique. The objective of this experiment is to answer the question that using the data re-balancing process to get the balance class distribution is enough for the classification performance or not. We vary the parameter of imbalance ratios ranging from 1.1 to 2.0. For example, if the imbalance ratio is equal to 1.5, we found that the datasets are balanced because we first increase instances of minority classes until the imbalanced ratio is equal to 1.5. Next, we reduce the over majority class using random undersampling with d instances (see Eq. (1)) so that the number of instances per class are equal. C-MIEN1 is compared to three algorithms which are RC4.5, ROAO, and ROAA.

The experimental results from Fig. 3 show that C-MIEN1 outperforms other methods. It is confirmed that C-MIEN1 achieves the highest performance for all ranges of imbalance ratio parameter when the dataset has high imbalance ratio and large number of classes (ecoli, pageblock and yeast). For the datasets that are low imbalance (balance-scale, glass and new-thyroid), ROAA and RC4.5 obtain the highest F-measure values at the 1.1 level on balance-scale and glass datasets respectively. For new-thyroid dataset, the F-measure of C-MIEN1 is a bit less than ROAA at the level of 1.1 and 1.2. We found that the imbalance ratio value at the level of 1.1 gets the highest F-measure on three datasets (balance-scale, car, glass, and yeast). On ecoli and pageblock datasets, the optimal imbalance ratio is equal to 2.0. For new-thyroid and car datasets, most methods have the optimal imbalance ratio at the level of 1.5. Therefore, the average imbalance ratio getting the highest F-measure is 1.1.

Consider the learning curve in Fig. 3, although dataset is balanced, all methods obtain best perfor-mance on new-thyroid and car datasets, which has low imbalance ratio and a minimum number of class. In addition, applying SMOTE increases minority class instances at low imbalance ratio level (1.1). It gives F-measure score better than increasing minimun the number of minority class instances (at 2.0 level) for some datasets. It means that if we use SMOTE until the ratio between all minority and over majority class is 1.1, then the classifier will achieve the good performance on the multiclass imbalance problem. However, we do not suggest to use IR at the level of 1.1 because over majority class instances are eliminated too much ( d has maximum value). Moreover, the overgeneralization problem will oc-cur [63] when the number of instances in the minority class are increase too much especially when the dataset has highly skewed class distributions. Consequently, we choose the imbalanced ratio at the level of 1.5 for the remaining experiments because, it is not only balance the dataset, but also alleviate the information loss problem. 5.2. Characteristics of C-MIEN on imbalanced data
In this section, we investigate behavior and adjust the training process of C-MIEN to demonstrate performance of each process. We will answer two questions. The first question is how the classifier per-formance would change when we focus on only the re-clustering process (C-MIEN2). Next question, if the re-balancing process is only applied to a sample set that consists of the under minority class (C-MIEN3), how is the performance of C-MIEN3 compared to C-MIEN4 (The re-balancing process have been applied to both sample sets)? Note that the imbalance ratio is set to 1.5. We compare the perfor-mance of C-MIEN with Decision Tree-based method: C4.5, OAO, OAA, RC4.5, ROAO, and ROAA.
 All baseline algorithms with resampling are applied with our re-balancing technique. The results are summarized in Tables 9 X 11.

The results show that C-MIEN4 mitigates the imbalanced data problem and achieves the highest F-measure score in most datasets. Consider the results from Table 9, the F-measure of C-MIEN2 is higher than the baseline algorithms on two datasets (balance-scale, and pageblocks). Moreover, the F-measure of C-MIEN2 is better than the baseline algorithms without sampling method (C4.5, OAO, and OAA) on most datasets except for OAO and OAA which outperform C-MIEN2 on newthyroid and car datasets. These results indicate that using only the re-clustering process (C-MIEN2) gets better performance than those algorithms.

C-MIEN3 outperforms other methods in three out of seven datasets (balance-scale, ecoli, and page-blocks). Consider the pageblocks dataset which has the highest imbalance ratio, we found that applying only the resampling method cannot improve the performance of the baseline classifier. On the other hand, the resampling method slightly reduces the classification performance. From Table 9, C-MIEN2 to C-MIEN4 work better on two datasets (balance-scale and pageblock) compared to other methods. It means that using only re-clustering process of C-MIEN can improve the performance of classifier compared to the baseline algorithms on these datasets.

Table 10 presents the performance of all methods measured in terms of G-mean. The results show that C-MIEN4 performs better than other algorithms on most datasets. There are only one dataset that the G-mean of C-MIEN4 is lower than ROAA method which is car dataset. Consider the yeast dataset, G-mean value of C-MIEN4 is much better than that of other methods. Therefore, it is confirmed that, C-MIEN4 performs very well on the minority class of yeast dataset. C-MIEN2 and C-MIEN3 do not works well on the minority class since there are multiple minority classes in multiclass dataset, because increasing minority class instances of C-MIEN2 and C-MIEN3 are incomplete. Therefore, both methods do not work efficiently compared with C-MIEN4.

As shown in Table 11, we found that C-MIEN4 obtained the best MS on five datasets. ROAA method obtains the best result for car and glass datasets. Among three datasets which have small number of minority class instances (balance-scale, ecoli, and yeast), MS values of baseline algorithms (C4.5, OAO and OAA) are equal to 0.00, these results indicate that these methods predict very poor on the minority class instances. While, algorithms with sampling method can sharply improve the classifier performance on these datasets.

In addition, it is interesting that C-MIEN2 gets the average of F-measure as 0.866, whereas the average of its value of C-MIEN3 and C-MIEN4 are 0.882 and 0.898 respectively. It means that all concepts of C-MIEN is better than ROAO, which gets 0.861 (which is the fourth-best performance). Moreover, these experiments indicate that C-MIEN4 and C-MIEN3 mitigate the multiclass imbalance problem and improve the performance of classification compared to C-MIEN2. The improvement in F-measure by 3.94 and 2.54 percent implies that applying the re-balancing process can obviously boost the predictive performance of re-clustering process for all datasets.
In order to investigate the significant difference between the performance of all methods, the Friedman test and the Nemenyi test are performed in all experiments. From Table 9, we calculate the Friedman statistic on 9 ( k =9) algorithms for 7 ( N =7) datasets. We found that,  X  2 F is equal to 31.428, which results in F F =7 . 674 . F F is distributed according to the F distribution with 9  X  1=8 and (9  X  1)  X  (7  X  1) = 48 degrees of freedom. The critical value of F(8,48) for  X  = 0.05 is 2.138. It means that we reject the null-hypothesis, which states that all algorithms have an equal performance. From Table 10, null-hypothesis can be rejected. From Table 11, the  X  2 F is 24.502 and the F F is 4.667. The critical value of F(8,48) is 2.138, so we reject the null-hypothesis as well. From all results, we found that, the null-hypothesis of the Friedman test are rejected. It means that, all measures of performance of all algorithms are different.

After that, we continue with the Nemenyi test, which use the critical distance CD to decide whether the performance of two algorithms is significantly different. We set  X  = 0.05 and obtain q 0 . 05 = 4.679 with k = 9 (see Eq. (7)). The results of Nemenyi test from Tables 9 X 11 are shown in Figs 4 X 6, respectively. From Figs 4 to 6, C-MIEN4 obtained the best rank, whereas C4.5 and OAA obtained the worse rank. Figure 4 shows that C-MIEN4 is significantly different with C4.5, OAA, OAO (group of algorithms are not connected). However, the remaining algorithms (C-MIEN3, ROAO, RC4.5, and ROAA) have no significant different with C-MIEN4 (group of algorithms are connected). Figures 5 and 6 show that the algorithms examined fall into two categories. The group of best-performing methods consists of C-MIEN4, ROAO, ROAA, C-MIEN3 and RC4.5. The other group consists of C-MIEN2, C4.5, OAO and OAA. Both figures indicate that C-MIEN4 is significant different with OAA, C4.5, OAO, and C-MIEN2, whereas there is no significant different between C-MEIN4 and the remaining algorithms (C-MIEN4, ROAO, ROAA, C-MIEN3 and RC4.5). 5.3. Comparison with ensemble method
We conducted another set of experiments using Ensemble method with bagging and boosting. Ensem-ble is used to expand our method (C-MIEN5), which is compared to many ensemble techniques includ-ing BC4.5,BOAO, BOAA, BRC4.5, BROAO, BROAA, AdaboostM1, MultiBoosting, and C-MIEN4.
 All methods use Decision Tree as a base classifier and use the value of imbalance ratio equal to 1.5. In this experiment, we use 20 classifiers as suggested by Optiz et al. [38] for ensemble learning. For C-MIEN5, we build 20 classifiers for each clusters. Therefore, we get totally forty hypotheses from both clusters. Tables 12 X 14 represent the F-measure, G-mean, Minimum Sensitivity obtained from each method respectively.

As shown in Table 12, we found that C-MIEN5 obtained the best F-measure on six datasets. On car dataset, BROAA outperforms other methods. These results indiciate that our method is the most suitable algorithm for multiclass imbalanced datasets when ensemble technique is applied. It is also shown that all methods have similar performance on three low imbalance datasets (balance-scale, glass, and newthy-roid). Among three datasets with highly imbalance, the contribution of C-MIEN5 is more obvious than other methods especially on yeast dataset, which has the maximum number of classes (10 classes) and has high imbalance ratio (92.10). On yeast dataset, C-MIEN5 obtains 79.3%, whereas BROAA gets 77.9% on F-measure value which is the second-best results. Furthermore, the performance of two boost-ing techniques is lower than bagging on four datasets which are balance scale, ecoli, pageblocks, and yeast. For pageblock dataset, bagging with the resampling techniques (BRC4.5, BROAO and BROAA) are less than three bagging techniques (BC4.5, BOAO and BOAA).

Consider the performance measured in terms of G-mean (see Table 13), we found that C-MIEN5 outperforms the state-of-the-art methods on four datasets. The best performance of new-thyroid and pageblocks datasets are obtained from C-MIEN4. However, BROAA obtained the best result on car dataset. These results indicate that C-MIEN4 and C-MIEN5 can get more correct prediction on the minority class than other methods.

In addition, the results shown in Table 12 are interesting because the performance of C-MIEN4 is better than all methods in two datasets in term of F-measure value (glass and pageblock). From Table 13, G-mean value of C-MIEN4 is better than the rest of the methods on four datasets (glass, new-thyroid, pageblock, and yeast). These results indicate that C-MIEN4 (C-MIEN without Ensemble technqiue) obtained the best results on most of datasets compare to other algorithms with Ensemble approach.
Table 14 presents the performance of all methods measured in terms of Minimum Sensitivity. The results show that C-MIEN5 performs better than other methods on most datasets and C-MIEN4 gets better performance than the state-of-the-art methods on four datasets. However, BROAO obtained the best result on glass dataset and BROAA obtained the best result on car dataset. On new-thyroid, page-blocks, and yeast datasets. the MS of C-MIEN4 and C-MIEN5 are equal. It is confirmed that C-MIEN5 cannot improve the classification performance compared to C-MIEN4 based on MS measure. Consider the new-thyroid dataset, the MS of the algorithms with resampling method are equal (9.70). These re-sults indicate that using resampling method on this dataset can improve the classification performance equally and it shows that the types of base classifier do not have any influence on the performance.
From Table 12, the Friedman statistic is calculated with 10 algorithms and 7 datasets. So,  X  2 F is equal to 30.070 and F F is equal to 5.479. F F is distributed according to the F distribution with 10  X  1=9 and (10  X  1)  X  (7  X  1) = 54 degrees of freedom. The critical value of F(9,54) for  X  = 0.05 is 2.059. It means that the null-hypothesis is rejected because the F F value (5.479) is greater than the critical value (2.059). From Table 13, The  X  2 F is equal to 36.399 and the F F is equal to 8.21. In this case, F F &gt; F(9,54). It indicates that the null-hypothesis can be rejected. From Table 14, the  X  2 F is 17.496 and the F F is 2.307. that the distribution of performance measures of all algorithms different.

When the null-hypothesis of the Friedman test is rejected, the Nemenyi test is computed. We ob-tain q 0 . 05 = 5.277 ( k = 10) . The results of Nemenyi test from Tables 12 X 14 are shown in Figs 7 X 9, respectively. For the classification results, C-MIEN5 ranks the first in all cases. However, C-MIEN4 ob-tained the second-best rank in term of G-mean and Minimum Sensitivity, whereas BROAA obtained the second-best rank in term of F-measure. All figures show that C-MIEN5 is significantly different with MultiBoosting, BOAA, BC4 .5, BOAO, whereas AdaboostM1 is signi ficantly different with C-MIEN5 in term of F-measure and G-mean. However, the remaining algorithms (C-MIEN4, BROAA, BROAO and BRC4.5) have no significant different with C-MIEN5.

Moreover, we perform additional experiments to further investigate the appropriate size of an ensem-ble. Figure 10 shows the F-measure over all of 7 datasets using diffierent number of classifiers (3, 5, 10, 15, 20, 25, and 30). The tendency of performance obtained from most methods are the same. The mean of F-measure values of C-MIEN5 is higher than other methods using different number of classi-fiers. BROAA, BROAO, and BRC4.5 obtained the second, third, and fourth of the mean of F-measure results, respectively. Using 20 to 25 classifiers in ensemble contribute to the best performance. Ensemble with 25 classifiers have shown superior performance as reported in many papers [14,38]. However, only AdaboostM1 can achives the best performance with 15 classifiers. 5.4. Discussions on overall results
In this section, we present the overall results of C-MIEN that can improve the performance of clas-sifier in multiclass imbalanced dataset. The experimental results show that C-MIEN achieves the best performances in all datasets in terms of F-measure. In addition, G-mean results show that the prediction performance of C-MIEN is better than state-of-the-art methods in the minority class on most datasets. C-MIEN always ranks the first among the competitors and significant differences can be observed in some cases. All experimental results illustrate the robustness of C-MIEN when revealed to different im-balance ratio (oversampling ratio, imbalance class ratio) and number of classifiers configuration. The results show that C-MIEN outperforms the current multiclass imbalanced data problem solving methods especially in case of multiclass and high imbalance ratio datasets.

In order to compare the performance of C-MIEN and SMOTE measured in term of F-measure, all datasets are tested through 10-fold cross validation and decision tree classifier. On most datasets, the tendency of performance obtained from C-MIEN are the same. For the ease of understanding, we select the dataset namely balance-scale to represent the characteristics of instances obtained from C-MIEN (the data rebalancing process: T 1 and T 2 ) and compare to those instances obtained from SMOTE (See Fig. 11). Figure 11(a) shows the original balance-scale dataset, and Fig. 11(b) shows the result after using respectively, after running the data rebalancing process in C-MIEN. These results confirm that C-MIEN can improve the classification performance ( F -measure =0 . 845) because a training set obtained from the group of classes with different characteristic (class L) (see Fig. 11(d)). Therefore, the classifier can easily learn the different concept and get good performance.

Moreover, C-MIEN generated both training sets ( T 1 and T 2 ) which consist of the group of classes T other hand, the performance of C-MIEN will dropped (see car and glass datasets) when R 1 or R 2 has the lowest number of instance in T 2 or T 1 . Therefore, the oversampling method is trigger to generate the synthetic data for R 1 or R 2 . Then, the quality of synthetic instances are affected because they were generated from R 1 or R 2 , which consist of too many classes. However, we believe that this event may not be occurred frequently. Since the newclass ( R 1 or R 2 ) comes from a group of different classes that should have high number of instances. In addition, we also make the following observation in this study.  X  Due to the operation of our reclustering process, C-MIEN can be applied on the multiclass im- X  The best imbalance ratio of C-MIEN is equal to 1.1. However, this value is not practical because  X  Using resampling technique (Fig. 1(b)) to balance the class distribution is better than a baseline  X  We found that between the ensemble and resampling techniques, resampling performs better in  X  C-MIEN5 outperforms all methods in the most of datasets especially when the dataset has high  X  Between C-MIEN4 and C-MIEN5, the performance of C-MIEN5 is a bit higher than C-MIEN4 but  X  The suitable number of base classifiers in ensemble of C-MIEN should be 20 to 25.  X  C-MIEN without ensemble (C-MIEN4) obtained the best result compared to most state-of-the-art 6. Conclusion
In this research, we develop and study C-MIEN for multiclass imbalanced dataset based on clustering and hybrid sampling approaches. In our approach, k-means is employed to separate all instances into two clusters in order to reduce the complicated sampling in multiclass dataset. After that, hybrid sampling approach is used to reduce the degree of imbalanced distribution in sub training set. Finally, we proposed to use ensembles of decision tree to enhance the prediction performance. The findings from several UCI multiclass imbalanced datasets indicate that C-MIEN is a very promising algorithm.

The main contributions of this research are: 1) C-MIEN algorithm has been developed by reducing the number of classes without decom position technique to minimize the c omplexity of decision regions in multiclass cases using clustering and relabeling approaches. This process is crucial for resampling in multiclass cases. 2) C-MIEN built multiple component cl assifiers with different class labels that were comparable based on a new implementation of the majority vote and; 3) C-MIEN is capable to adjust the class distribution of a dataset (which is adapted until it is balanced) and inherits the strength of two strategies; ensemble and SMOTE.

From the experimental result, we found that C-MIEN obtained a big improvement of classification performance when the dataset has high imbalance ratio and large the number of classes. In addition, the results reveal that choosing the threshold (imbalance ratio) is an important issue to increase the performance of C-MIEN algorithm. We found that the optimal thresholds for C-MIEN in this study is equal to 1.5 and the number of base classifiers in ensemble should be 20. However, C-MIEN without ensemble technique make an impressive improvement in prediction performance as well.
 Acknowledgement This research is supported by the Department of Computer Science, Faculty of Science, Kasetsart University and National Science and Technology Development Agency under Ministry of Science and Technology of Thailand.
 References
