 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Design, Exp erimen tation cross-language text classi cation, topic classi cation
Our goal in cross-language text classi cation (CL TC) is to use English training data to classify Czec h documen ts (although the concepts presen ted here are applicable to any language pair). CLTC is an o -line problem, and the au-thors are una ware of any previous work in this area.
CLTC is motiv ated by both the non-a vailabilit y of Czec h training data (the case, presen tly, in our dataset) and the possibilit y of leveraging di eren t topic distributions in di er-ent languages to impro ve overall classi cation for informa-tion retriev al. Consider, for example, that English speak ers tend to con tribute more to some topics than their Czec h coun terparts (e.g., to discuss London more than Prague), so that, having only documen ts in English, we may exp ect to do poorly at iden tifying topics like Prague . Czec h speak ers, on the other hand, often talk about Prague, so that by lever-aging Czec h data, we migh t exp ect to impro ve on detecting the topic Prague in English speak ers; and Prague in English speak ers is exactly the sort of thesaurus lab el whic h infor-mation seekers are most interested in|b ecause it is rare . Accordingly , while a lack of Czec h training data presen tly necessitates CLTC, we would have no reason to warran t the metho d's abandonmen t if suc h data were to suddenly be-come available.

Our dataset is a collection of man ually transcrib ed, spon-taneous, con versational speech in English and Czec h. En-glish transcripts have human assigned lab els from a hierar-chical thesaurus of appro ximately 40,000 lab els. Presen tly, lab eled Czec h data is not available for classi er training. The hierarc hy may be divided into two principle branc hes, con taining 1) concept lab els (e.g., educ ation ) and 2) pre-coordinated place-date lab els (e.g., Germany, 1914 { 1918 ). of translation) and the exp ectation that most of the seman-tic information asso ciated with words (from whic h we infer thesaurus lab els) is as presen t in their base forms as it is in their in ections.

The base of the probabilistic dictionary is tak en from ver-sion 1.0 of the Prague Cze ch-English Dep endency Treebank (PCEDT) [4], whic h con tains conditional word-translation probabilities for 46,150 word translation pairs. The dictio-nary has been deriv ed from a parallel Czec h-English corpus based on Reader's Digest stories, technical texts, and the translation of the Penn Treebank's WSJ portion into Czec h. IBM mo del 3 has been used in the extraction, and data has been subsequen tly ltered [2] to avoid most of the noise caused by relativ ely small datasets.

Indexing pro ceeds on the English documen ts by rst chec k-ing if the term is already presen t in the probabilistic dictio-nary . If it is, the term's frequency is incremen ted. If the base form for term w is not presen t in the dictionary , we hop e that the term migh t be a relev ant feature sans trans-lation, and therefore augmen t E with P ( e w j c w ) = 1 before incremen ting w 's term frequency . We then index the docu-men ts in Czec h, although here it is unnecessary to augmen t the dictionary for previously unseen words (i.e., words not seen in the training documen ts), as we do not exp ect to infer a thesaurus lab el from features nev er observ ed in training. The indexed Czec h vectors are probabilistically translated via left matrix multiplication of E and classi ed using k NN with symmetric-Ok api. From informal monolingual trials on held out English data, we determined a reasonable choice to be k = 20. There is curren tly no lab eled Czec h data in our dataset. To evaluate our implemen tation, English sided classi cation was run on three disjoin t segmen ts of 25 Czec h sen tences eac h. The segmen t size was chosen to have roughly 400 words (the average num ber of words in three min utes of in-terview). The segmen ts and their ten highest rank ed lab els were then given to a nativ e Czec h speak er for man ual rele-vance assessmen t. Using the same training set, monolingual English classi cation was run on four similarly partitioned test segmen ts. The relev ance of man y lab els could not be determined by insp ection (e.g., Poland, 1945 was hypothe-sized and, while the text made no explicit men tion of Poland in 1945, the lab el was not ruled out). These questionable la-belings were all simply assumed to be non-relev ant. Table 1 lists precision calculations for both the English sided Czec h exp erimen ts and monolingual English exp erimen ts. Preci-sion was calculated over the ve and ten highest rank ed the-saurus lab els (the complete set) as well as the ve highest concept lab els alone (that is, without the pre-co ordinated place-date lab els). Place-date lab els may reasonably be ex-cluded from consideration because it is nearly alw ays im-possible to assess their relev ance to short text segmen ts. On concept lab els, the cross-language system performed at 73% of the monolingual precision.

Consider every lab el assignmen t to be an indep enden t trial with probabilit y of success p . Now, p will vary across the-saurus lab els, but the largest p , p L , will corresp ond to the lab el most commonly seen in the training data. If we were to randomly assign any one of the lab els to a segmen t, p L would represen t an upp er bound on the probabilit y of this lab el being relev ant. In this spirit, we can consider p L to be
