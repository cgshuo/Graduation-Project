 Tensors are a natural representation for multidimensional data. In recent years, CANDECOMP/PARAFAC (CP) de-composition, one of the most popular tools for analyzing multi-way data, has been extensively studied and widely applied. However, today X  X  datasets are often dynamically changing over time. Tracking the CP decomposition for such dynamic tensors is a crucial but challenging task, due to the large scale of the tensor and the velocity of new data ar-riving. Traditional techniques, such as Alternating Least Squares (ALS), cannot be directly applied to this prob-lem because of their poor scalability in terms of time and memory. Additionally, existing online approaches have only partially addressed this problem and can only be deployed on third-order tensors. To fill this gap, we propose an ef-ficient online algorithm that can incrementally track the CP decompositions of dynamic tensors with an arbitrary number of dimensions. In terms of effectiveness, our algo-rithm demonstrates comparable results with the most ac-curate algorithm, ALS, whilst being computationally much more efficient. Specifically, on small and moderate datasets, our approach is tens to hundreds of times faster than ALS, while for large-scale datasets, the speedup can be more than 3,000 times. Compared to other state-of-the-art online ap-proaches, our method shows not only significantly better decomposition quality, but also better performance in terms of stability, efficiency and scalability.
 Tensor Decomposition; CP Decomposition; Online Learning
Numerous types of data are naturally represented as multi-dimensional structures. The Tensor , a multi-way generaliza-tion of the matrix, is useful for representing such data. Sim-ilar to matrix analysis tools, such as PCA and SVD, tensor decomposition (TD) is a popular approach for feature extrac-tion, dimensionality reduction and knowledge discovery on multi-way data. It has been extensively studied and widely applied in various fields of science, including chemometrics [1], signal processing [7], computer vision [14, 29], graph and network analysis [10, 17] and time series analysis [5].
In the era of big data, data is often dynamically changing over time, and a large volume of new data can be gener-ated at high velocity. In such dynamic environments, a data tensor may be expanded, shrunk or modified on any of its dimensions. For example, given a network monitoring ten-sor structured as source  X  destination  X  port  X  time , a large number of network transactions are generated every second, which can be recorded by appending new slices to the tensor on its time mode. Additionally, new IP addresses may be added and invalid addresses may be removed from the data tensor. Overall, this data tensor is highly dynamic.
As TD is usually the first and necessary step for analyzing multi-way data, in this work, we aim to address the problem of how to adaptively track the decompositions for such time-evolving tensors. Specifically, we are particularly interested in dynamic tensors that are incrementally growing over time, while the other dimensions remain unchanged. These are the most common type of dynamic tensors that occur in practice. We refer to such tensors as online tensors ,also known as tensor streams and incremental tensors [27, 28].
Finding the decompositions for large-scale online tensors is challenging. The difficulty mainly arises from two factors. First, as online tensors are growing with time, their overall size is potentially unbounded. Thus, TD techniques for such tensors need to be highly efficient and scalable, from both time and space perspectives. Second, a high data generation rate demands decomposition methods providing real-time or near real-time performance [6]. However, traditional TD techniques, such as Tucker and CANDECOMP/PARAFAC (CP) decompositions, cannot be directly applied to this sce-nario because: (i) they require the availability of the full data for the decomposition, thus having a large memory requirement; and (ii) their fitting algorithms, Higher-Order SVD (HOSVD) for Tucker [9], and Alternating Least Squares (ALS) or other variants for CP [8], are usually computation-ally too expensive for large-scale tensors.

A recipe for addressing the above challenges is to adapt existing approaches using online techniques. In recent years, several studies have been conducted on tracking the Tucker decomposition of online tensors by incorporating online tech-niques, such as incremental SVD [14, 18, 26], and incremen-tal update of covariance matrices [27, 28]. However, there is a limited amount of work on tracking the CP decomposition of an online tensor. The only work in the literature, pro-posed by Nion and Sidiropoulos [20], specifically only deals with third-order tensors and there is no provision for higher-order tensors with more than 3 dimensions. To fill this gap, we propose an efficient algorithm to find the CP decomposi-tion of large-scale high-order online tensors, with low space and time usage. We summarize our contributions as follows:
The rest of this paper is organized as follows. Section 2 gives a review of current techniques and Section 3 introduces background knowledge. Our proposal is discussed in Section 4. We start from third-order tensors and then extend this model to general tensors that have an arbitrary number of dimensions. After that, the performance of our approach is evaluated on both real world and synthetic datasets in Section 5. Lastly, Section 6 concludes and discusses future research directions.
The problem of decomposing online tensors was originally proposed by Sun et al. [27, 28], wherein they refer to this problem as Incremental Tensor Analysis (ITA). Three vari-ants of ITA are discussed in their work: (1) dynamic ten-sor analysis (DTA) modifies the covariance matrices calcu-lation step in typical HOSVD in an incremental fashion; (2) stream tensor analysis (STA) is an approximation of DTA by the SPIRIT algorithm [21]; and (3) window-based tensor analysis (WTA) uses a sliding window strategy to improve the efficiency of DTA. The main issue of these techniques is that they have not fully optimized the most time consuming step, i.e., diagonalizing the covariance matrix for each mode, which limits their efficiency. To overcome this issue, Liu et al. [17] propose an efficient algorithm that enforces the diag-onalization on the core tensors only. Additionally, another trend for improving the efficiency of HOSVD on online ten-sors is to replace SVD with incremental SVD algorithms. Several applications of this idea can be found in computer vision [14, 18, 26] and anomaly dectection [25] fields.
The major difference between the aforementioned tech-niques and our approach is that they are online versions of Tucker decomposition. Although CP decomposition can be viewed as a special case of Tucker with super-diagonal core tensor, none of the above methods provides a way to enforce this constraint. As a result, these algorithms are not suitable for tracking the CP decompositions of online tensors.
Unlike the existing extensive studies on online Tucker de-composition, there is a limited research reported for online CP decomposition. The most related work to ours was pro-posed by Nion and Sidiropoulos [20], which introduced two adaptive algorithms that specifically focus on CP decompo-sition: Simultaneous Diagonalization Tracking (SDT) that incrementally tracks the SVD of the unfolded tensor; and Recursive Least Squares Tracking (RLST), which recursively updates the decomposition factors by minimizing the mean squared error. However, the major drawback of this work is that they work on third-order tensors only, while in contrast we propose a general approach that can incrementally track the CP decompositions of tensors with arbitrary dimensions.
In another related area, among the studies that focus on improving CP decomposition for handling large-scale ten-sors, GridTF, a grid-based tensor factorization algorithm [22] is particularly related to our problem. The main idea of GridTF is to partition the large tensor into a number of small grids. These grids are then factorized by a typical ALS algorithm in parallel. Finally, the resulting decompositions of these sub-tensors are combined together using an iterative approach. In fact, as stated by the authors, if such partition-ing is enforced on the time mode only, then GridTF can be used for tracking the CP decomposition of tensor streams.
Following the notation in [16], vectors are denoted by boldface lowercase letters, e.g., a , matrices by boldface up-percase letters, e.g., A , and tensors by boldface Euler script letters, e.g., X X X .The order of a tensor, also known as the number of ways or modes , is its number of dimensions. For example, vectors and matrices are tensors of order 1 and 2. Atensor X X X P R I 1  X   X   X   X  X  I N is an N th -order one consisting of real numbers and the cardinality of its i -th order, i Pr 1 ,N s is I i . We refer to tensors with more than 3 modes as higher -order ones. The elements of a tensor are retrieved by their indices, and a slice of an N th -ordertensorisan p N  X  1 q order tensor with the index of a particular mode fixed.
Let A J , A  X  1 , A : and A denote the transpose, in-verse, Moore-Penrose pseudoinverse and Frobenius norm of A .Let A p 1 q , A p 2 q ,..., A p N q represent a sequence of N ma-trices. The Khatri-Rao and Hadamard products [16] and element-wise division are denoted by d , f and m ,respec-tively. Furthermore, the Khatri-Rao and Hadamard prod-ucts of a sequence of N matrices A p N q , A p N  X  1 q ,..., A in the sequence are inverted and the subscript i  X  n is used when the n -th matrix is not included in above operations,
Tensor unfolding ,or matricization , is a process to trans-form a tensor into a matrix [15]. Generally, given an N th X X X as r I n ,I 1 ,...,I n  X  1 ,I n ` 1 ,...,I N s and then reshaping the permuted tensor into a matrix of size I n  X 
CP decomposition is a widely used technique for exploring and extracting the underlying structure of the multi-way data. Basically, given an N th -order tensor X X X P R I 1 CP decomposition approximates this tensor by N loading matrices A p 1 q ,..., A p N q , such that where  X  is defined as the CP decomposition operator and each loading matrices A p i q ,i Pr 1 ,N s is of size I i R is the tensor rank, indicating the number of latent factors. To find the CP decomposition A p 1 q ,..., A p N q for an N th -order tensor X X X , the objective is to minimize the esti-mation error L , which is defined as However, directly minimizing L over A p 1 q ,..., A p N q cult, since L is not convex w.r.t. A p 1 q ,..., A p N q . As a result, a widely applied approach is ALS. The main idea is to di-vide the above optimization problem into N sub-problems and the n -th one, n Pr 1 ,N s fixes all variables but A p then minimizes the convex objective L w.r.t. A p n q , that is Here we briefly introduce the main idea of existing online CP decomposition algorithms. A third-order online tensor X X X X X X sidering that in most online systems, the size of the new incoming data is usually much smaller than that of all ex-isting historical data, thus we assume t new ! t old .TheCP decomposition of X X X old is written as A old , B old , C the aim is to find the CP decomposition A , B , C of X X X
SDT and RLST [20]: Both SDT and RLST transform the online tensor decomposition problem into an incremental matrix factorization problem, by letting D  X  B d A ,so that equation (1) can be written as X p 3 q  X  CD J . Then the problem is how to estimate C and D .

Different strategies are used in SDT and RLST for cal-culating C and D . SDTchoosestodothisbymakinguse will always be a matrix W old that C old  X  U old W  X  1 old D to make C  X  UW  X  1 and D  X  V X W J , where U X V J is the SVD of X p 3 q , which can be efficiently calculated by incremental SVD algorithms. Furthermore, the authors as-sume that there is only a tiny difference between D and D old so that the first t old rows of C are approximately equal to C old . Under this assumption, W  X  1 can be calculated as r U
U old W  X  1 old , where r U is the first t old rows of U .Conse-quently, W , C and D can be obtained.

In contrast, RLST follows a more direct approach to get C and D . Recall that X p 3 q  X  CD J , firstly, C new is calculated C old . Then D is incrementally estimated with X new p 3 q and C new based on the matrix inversion and pseudo-inversion lemmas. Due to the page limit, we refer interested readers to the original papers [20] for more details.
 After getting C and D , the last step for both SDT and RLST is to estimate A and B from D . This process is done by applying SVD on the matrix formed by each column of D , and then putting the left and right principal singular vectors into A and B , respectively.

Overall, SDT and RLST both deal with the online CP de-composition problem by flattening the non-temporal modes. However, this is the main limitation to their performance. Firstly, it is time consuming due to the cost of SVD. Al-though the authors replaced the traditional SVD with the Bi-SVD algorithm, the complexity of this is still O p R 2 which limits their applications on large-scale tensors. Addi-tionally, this flattening process makes SDT and RLST not easy to extend to higher-order tensors, since the flattened matrix will be much larger and it has to be recursively de-composed to loading matrices in the end, which is also costly. GridTF [22]: As mentioned earlier, the basic idea of GridTF is to partition the whole tensor into smaller tensors and then combine their CP decompositions together. In re-gards to the example here, X X X is the online tensor, X X X X X X new are the two partitions. To obtain the CP decompo-sition of X X X , the first step of GridTF is to decompose by ALS as A new , B new , C new , while the decomposition of X X X old is already known from the last time step.

The combination step is a recursive update procedure such that in every iteration, each mode is updated with a modi-fied ALS rule, until the whole estimation converges, or the maximum number of iterations has been reached. In our no-tation, the update rules are given as follows, of which further details can be found in [22]. 1) For non-temporal modes A and B 2) For temporal mode C where A , B , C are randomly initialized at the beginning and P p B new B qfp C
The main issue of applying GridTF to online CP decom-position is its efficiency. Firstly, even though only the new data need to be decomposed, this is still expensive, espe-cially when the size of new data is large. Secondly, for es-timating C and calculating P old and Q , C J old C needs to be calculated, costing R 2 t old operations. This means the time complexity of the update procedure is linear in the length of the existing data, t old , which can be huge, thus significantly limiting its ability for processing online tensors. In this section, we introduce our proposal for tracking the CP decomposition of online multi-way data in an incremen-tal setting. For presentation clarity, initially a third-order case will be discussed. Then, we further extend to more general situations, where our proposed algorithm is able to handle tensors that have arbitrary number of modes. With-out loss of generality, we assume the last mode of a tensor is always the one growing over time, while the size of the other modes are kept unchanged with time.
Following the same notation introduced in Section 3.3, similar to the classic ALS algorithm, our approach handles the problem in an alternating update fashion. That is, we first fix A and B ,toupdate C , and then sequentially update A and B ,byfixingtheothertwo. By fixing A and B , from (2) we have It is clear that the norm of the first row is minimized with C old ,since A and B are fixed as A old and B old from the last time step. The optimal solution to minimize the second row appending the projection C new of X new p 3 q via the loading matrices A and B of previous time step, to C old ,i.e.,
First, we update A .Byfixing B and C , the estimations error L can be written as 1 2 X p 1 q  X  A p C d B q J 2 , and the derivative of L w.r.t. A is By setting the derivative to zero and letting P  X  X p 1 q p B q and Q  X  X  C d B q J p C d B q ,wehave Directly calculating P and Q is costly. This is mainly be-cause the output of p C d B q is a huge matrix of size J p t t new q X  R , where R is the tensor rank. It further results in O p RIJ p t old ` t new qq and O p R 2 J p t old ` t new qq operations to get P and Q , respectively. Although for Q , the Khatri-Rao product can be avoided by calculating it as p C J C qfp B [16], which has a complexity of O p R 2 p J ` t old ` t new is still expensive since t old is usually quite large. As a result, in order to improve the efficiency, we need a faster approach.
Firstly,letuslookat P . By representing X p 1 q and C with the old and new components, we have recall that B hasbeenfixedas B old , so that the first part of the last line of equation (6) only contains components from the previous time step. Suppose we know this part already and denote it by P old ,then(6)canberewrittenas This means that by keeping a record of the previous P , the large computation can be avoided and it can be effi-ciently updated in an incremental way. Specifically, suppose P is initialized with a small partition X X X p  X  qP R I  X  J  X   X  contains the first  X  slices of the data, where  X  ! t old ,we only need O p RIJ X  q operations to construct P . Afterwards, whenever new data comes, P can be efficiently updated at the cost of O p RIJt new q , which is independent to t old Likewise, Q can be estimated as
Thus, by storing the information of previous decomposi-tion with complementary matrices P and Q ,weachievethe update rule for A as follows, The update rule for B can be derived in a similar way as where U  X  X p 2 q p C d A q , V  X  X  C d A q J p C d A q are the two complementary matrices of mode 2.

To sum up : For a third-order tensor that grows with time, we propose an efficient algorithm for tracking its CP decomposition on the fly. We name this algorithm as On-lineCP , comprising the following two stages: 1) Initialization stage: for non-temporal modes, com-plementary matrices P , Q , U and V are initialized with the initial tensor X X X init and its CP decomposition A , B , C as 2) Update stage: for each new incoming data chunk X X X new , it is processed as a) for the temporal mode 3, C is updated with (4) b) for non-temporal modes 1 and 2, A is updated with (9) and B is updated with (10), respectively.
We now show how to extend our approach to higher-order
A old ,..., A mode be the time. A new tensor X X X new P R I 1  X   X   X   X  X  added to X X X old to form a tensor X X X P R I 1  X   X   X   X  X  where t old " t new . In addition, two sets of complementary where P p n q and Q p n q ,n Pr 1 ,N  X  1 s , are the complementary matrices for mode n . We are interested in finding the CP
Similar to the third-order case, the loading matrix of the time mode, A p N q , is updated at first by fixing the other loading matrices and minimizing the estimation error L Basically, the above equation has the same structure as (3), so we have a similar update rule for A p N q
For each non-temporal mode n Pr 1 ,N  X  1 s ,theestimation error L on mode n is 1 2 X p n q  X  A p n q p d N i  X  n A similar update rule as equation (9) can be applied, that is where we denote the Khatri-Rao product of the first N  X  1
In fact, if we were to compute every K p n q for each n P r 1 ,N  X  1 s , there would be some redundant computation among them. Take a 5 th -order tensor for example, where K K is clear that both K p 1 q and K p 2 q have computed A p 4 q and K p 3 q and K p 4 q share a common computation A p 2 q These redundant Khatri-Rao products are computationally expensive to calculate, and more importantly, the amount of redundancy will dramatically increase with the number of modes N , since more common components are shared.
To overcome this issue, we use a dynamic programming strategy to compute all the K p n q  X  X  in one run, by making good use of the intermediate results and avoiding duplicated operations. This process is detailed in Algorithm 1 and an illustrating example of a 6 th -order tensor is given in Figure 1. The main idea is to go through the loading matrix list A reaches the results of K p 1 q and K p N  X  1 q (lines 3 to 8). After that, for the rest of K p i q where i Pr 2 ,N  X  2 s , they are computed as the Khatri-Rao products of the intermediate results from the last loop (lines 11 to 15).

For the H p n q  X  X , it is obvious that calculating each individ-ual H p n q by itself is inefficient. Exploiting the fact that for @ i, j Pr 1 ,N  X  1 s , H p i q fp A p i q H , in each round of update, H is calculated first, then each H p n q is obtained as H mp A p n q J A p n q q , where m is the element-wise division.

Finally, by putting everything together, we obtain the gen-eral version of our OnlineCP algorithm 1 , as presented in Algorithm 2 and 3.
Following the same notation as Section 4.2, let R be the tensor rank, S  X  a new chunk of data X X X new ,ittakesupto p N  X  1 q S oper-ations to get all the K p n q ,n Pr 1 ,N  X  1 s ,and H can be obtained in R 2 J `p N  X  2 q R 2 operations (lines 1 and 2 in
We provide our Matlab implementation of OnlineCP at http://shuo-zhou.info .
 Algorithm 1: Get a list of Khatri-Rao products
Input : A list of loading matrices r A p N  X  1 q ,..., A
Output : A list of Khatri-Rao products 3 if N  X  3 then 4 for n  X  2 to N  X  2 do 5 left r n s X  left r n  X  1 sd A p N  X  n q 6 right r n s X  A p n q d right r n  X  1 s 9 K p 1 q  X  left r N  X  2 s 11 if N  X  3 then 12 for n  X  2 to N  X  2 do 13 K p n q  X  left r N  X  n  X  1 sd right r n  X  1 s Figure 1: A 6 th -order example to get all K p n q  X  X  together. A Khatri-Rao product is represented by two arrows, of which the solid one linked to the first input. The two lists, left and right , are indicated by the two columns on the graph. Algorithm 3). To update the time mode, RS , St new ,and RSt new ` R 2 t new ` R 3 operations are required to get K X pseudoinverse pp K p N q q J q : canbereplacedby K p N q H p A d B q :  X  X p A J A qfp B J B qq : p A d B q J [16]. For each non-temporal mode n (lines7to10), St new , RSt new { I n (  X  St new ,since R is usually smaller than I n ), RSt new RI n operations are required for the unfolding, Khatri-Rao, multiplication and addition in the step to update P p n q Q n q takes R 2 I n ` R 2 t new ` 3 R 2 operations to update; then the updated A p n q can be calculated in R 3 ` R 2 I n opera-tions. Thus, to update the loading matrix A p n q of mode n , p 2 R 2 ` R q I n `p R ` 2 q St new ` R 3 `p 3 ` t new q R required and the whole update procedure for non-temporal modes takes p 2 R 2 ` R q J `p N  X  1 qp R ` 2 q St new `p N  X  1 qp R 3 `p 3 ` t new q R 2 q operations. Overall, as S is usually much larger than other factors, the time complexity of On-lineCP can be written as O p NRSt new q , which is constant w.r.t. the length of processed data t old .

In terms of space consumption, unlike ALS that needs to store all the data, OnlineCP is quite efficient since only the new data, previous loading matrices and complementary matrices need to be recorded. Hence, the total cost of space is St new `p 2 J ` t old q R `p N  X  1 q R 2 . new `p 2 J ` t old q R `p N  X  1 q R Algorithm 2: Initialization stage of OnlineCP Input : Initial tensor X X X init , loading matrices
Output : complementary matrices P p 1 q ,..., P p N  X  1 q 3 for n  X  1 to N  X  1 do
We summarize the complexity of our approach in Table 1, along with other existing approaches. Note that the com-plexities of SDT and RLST are based on the exponential window [20], which considers all existing data while lever-ages their importance by a forgetting factor  X  . In addition, as they only work on third-order tensors, when other meth-ods are compared to them, N should be set to 3. Another remark is that the time complexities of ALS and GridTF are based on one iteration only, in reality they would take a few iterations until convergence.
In this section, we evaluate our OnlineCP algorithm, com-pared to existing techniques. We first examine their effec-tiveness and efficiency on seven real world datasets. After that, based on the investigation on synthetic tensors, we further analyze the critical factors that can affect the per-formance of our approach, along with other baselines.
Datasets: The experiments are conducted on seven real world datasets of varying characteristics, all are naturally of multi-way structures. These are two image datasets: (i) Columbia Object Image Library (COIL); (ii) ORL Database of Faces (FACE); three human activity datasets: (iii) Daily and Sports Activities Data Set (DSA); (iv) University of Southern California Human Activity Dataset (HAD); (v) Daphnet Freezing of Gait Data Set (FOG); one chemical laboratory dataset: (vi) Gas sensor array under dynamic gas mixtures Data Set (GAS); and a (vii) road traffic dataset collected from loop detectors in Victoria, Australia (ROAD).
Each dataset is represented by a tensor with its most natu-ral structure. For instance, FACE is represented by a pixel  X  pixel  X  shot third-order tensor, while DSA is stored as an Algorithm 3: Update stage of OnlineCP
Input : Loading matrices A p 1 q ,..., A p N q ,
Output : Updated loading matrices A p 1 q ,..., A p N q , // update A p N q // update other modes 6 for n  X  1 to N  X  1 do 4 th -order tensor of subject  X  trail  X  sensor  X  time . Further-more, since some of our baselines can only work with third-order tensors, for tensors with higher-order, DSA, GAS, and HAD, we randomly extract third-order sub-tensors from them. Conversely, to enlarge the number of higher-order tensors, image datasets, COIL and FACE have been trans-formed into 4 th -order tensors by treating each image as a collection of small patches , which forms the extra order. As a result, there are five datasets having two versions of rep-resentation: a third-order one, indicated by suffix 3D ,and a higher-order form with suffix HD . The details of these datasets can be found in Table 2.

Baselines: In this experiment, five baselines have been selected as the competitors to evaluate the performance. (i) Batch Cold: an implementation of ALS algorithm in Tensor Toolbox [4] without special initialization. (ii) Batch Hot: the same ALS algorithm as above but the CP decomposition of the last time step is used as the initialization for decomposing the current tensor. (iii) SDT [20]: an adaptive algorithm based on incremen-tally tracking the SVD of the unfolded tensor. (iv) RLST: another online approach proposed in [20]. In-stead of tracking the SVD, recursive updates are performed to minimize the mean squared error on new data. Datasets Size Slice Size Source COIL-3D 128  X  128  X  240 16,384 [19] COIL-HD 64  X  64  X  25  X  240 102,400 DSA-3D 8  X  45  X  750 360 [2] DSA-HD 19  X  8  X  45  X  750 6,840 FACE-3D 112  X  92  X  400 10,304 [23] FACE-HD 28  X  23  X  16  X  400 10,304 FOG 10  X  9  X  1000 90 [3] GAS-3D 30  X  8  X  2970 240 [12] GAS-HD 30  X  6  X  8  X  2970 1,440 HAD-3D 14  X  6  X  500 64 [30] HAD-HD 14  X  12  X  5  X  6  X  500 3,840 ROAD 4666  X  96  X  1826 447,936 [24] (v) GridTF [22]: an divide-and-conqure based algorithm. To find CP decompositions for online tensors, the partition-ing is enforced on the time mode only.

Evaluation metrics: Two performance metrics are used in our evaluation. Fitness is the effectiveness measurement defined as where X X X is the ground truth,  X  X X X is the estimation and  X  de-notes the Frobenius norm. In addition, the average running time for processing one data slice, measured in seconds, is used to validate the time efficiency of an algorithm.
Experimental setup: The experiments are divided into two parts. The first part is to decompose the third-order tensors with all baselines. For the second part, only Batch Hot, GridTF and our approach are used. This is because both SDT and RLST work on third-order tensors only, and Batch Cold does not show better performance compared to Batch Hot, while taking a much longer time to run.
Apart from the difference in the number of competitors, the experimental protocol is the same for both third and higher order tests. Specifically, for a given dataset, the first 20% of the data is decomposed by ALS and its CP decom-position is used to initialize all algorithms. After that, the remaining 80% of the data is appended to the existing tensor by one slice at a time. At each time step, after processing the appended data slice, all methods calculate the fitness of their current decomposition with their updated loading matrices, as well as their processing time for this new slice. The same experiment is replicated 10 times for all datasets on a workstation with dual Intel Xeon processors, 64 GB RAM. The final results are averaged over these 10 runs.
There are some settings of parameters that need to be clarified. Firstly, since we only care about the relative per-formance comparison among different algorithms, it is not necessary to pursue the best rank decomposition for each dataset. As a result, the rank R is fixed to 5 for all datasets. Additionally, for the initial CP decomposition, the tolerance  X  is set to 1 e  X  8 and the maximum number of iterations maxiters is set to 100 to ensure a good start, as the perfor-mance of all online algorithms depends on the quality of the initial decomposition.

In terms of method-specific parameters, for the two batch algorithms, the default settings,  X   X  1 e  X  4and maxiters  X  50 are used. For GridTF, which contains an ALS procedure for the new data slice and a recursively update procedure for estimating the whole current tensor, the same default parameters are chosen for the ALS step; while  X   X  1 e  X  2and maxiters  X  50 are used for the update phase. Additionally, since batch algorithms do not provide a weighting strategy to differentiate the importance of data, in order to make a fair comparison, all the data slices are equally treated and there is no difference between older and newer ones in terms of their weights, which means the exponential window is used with  X   X  1 in SDT and RLST.
Given a particular dataset and a specific algorithm, its fitness and processing time are two time series (averaged over 10 runs). We take the mean values of them and report the results for third-order tensors in Table 3 and the higher-order tensors in Table 4. In addition, for the four online approaches, SDT, RLST, GridTF and OnlineCP, their rela-tive performances compared to Batch Hot are also shown in the parenthesis. Finally, the best results among these four are indicated by boldface.

As can be seen from Table 3, for the two batch methods, there is no significant difference on their effectiveness. How-ever, on all third-order datasets, the fitness of Batch Cold is slightlyworsethanthatofBatchHot. Themainreasonis that using the previous results as initialization can provide the ALS algorithm with a descent seeding point. In con-trast, every time Batch Cold totally discards this useful in-formation and starts to optimize from the beginning, which cannot guarantee a better or even same-quality estimation in the end. In fact, this also results in the longer running time of Batch Cold compared with Batch Hot, where the former is usually more than 10 times slower than the latter. On the other hand, even though Batch Hot improves the ef-ficiency, its time cost is still considerably high, especially for large-scale datasets. For example, on average it takes more than 20 seconds to process one additional data slice on the ROAD dataset, while OnlineCP takes only 0.0068 seconds. As the earliest studies of online CP decomposition, both SDT and RLST address this efficiency issue very well. Com-pared with Batch Hot, they shorten the mean running time by up to 400 times. RLST, in particular, was the most efficient online algorithm on 4 out of 7 third-order tensor datasets. In fact, the efficiency of SDT is quite close to RLST, except for the GAS dataset, whose length of time mode is significantly higher than other datasets. This shows that SDT is more sensitive to the growth of time. However, the main issue of SDT and RLST is their estimation accu-racy. For some datasets, such as COIL and HAD, they work fine, while for some others like DSA, they exhibit fairly poor accuracy, achieving only nearly half of the fitness of batch methods. The same accuracy problem can be observed in GridTF as well. In terms of efficiency, there is no signifi-cant difference between GridTF and Batch Hot, at least on the small size datasets. In fact, we notice that a substantial amount of time of GridTF is consumed by decomposing the new data slice and this cost is particularly dominant when the tensor size is not large enough. This can be confirmed by observing its generally better efficiency on higher-order datasets, compared to the third-order ones.
Table 4: Experimental results of higher-order datasets. (b) Mean running time of higher-order datasets for process-ing one data slice (in seconds). For GridTF and OnlineCP, the ratios between the running time of Batch Hot and theirs are shown in parenthesis. Boldface indicates the best result between these two online approaches.
 Datasets Batch Hot GridTF OnlineCP COIL-HD 2.1264 0.1935(10.99) 0.0076(280.44) DSA-HD 0.2217 0.0896(2.48) 0.0029(75.43) FACE-HD 0.3795 0.1438(2.64) 0.0040(94.15) GAS-HD 0.3154 0.1807(1.75) 0.0016(203.47) HAD-HD 0.1750 0.0922(1.90) 0.0041(42.23)
Our proposed algorithm, OnlineCP, shows very promising results in both accuracy and speed. On every dataset, both third-order and higher-order ones, our method reaches the best fitness among all online algorithms. More importantly, the estimation performance of our approach is quite sta-ble and very comparable to the results of batch techniques. In most of the cases, the fitness of OnlineCP is less than 3% lower than that of the most accurate algorithm, Batch Hot. However, the speed of OnlineCP is orders of magni-tudes faster than Batch Hot. On small and moderate size datasets, OnlineCP can be tens to hundreds of times faster than Batch Hot; and on the largest dataset, ROAD, On-lineCP improves the efficiency of Batch Hot by more than 3,000 times. Additionally, compared with another fast ap-proach, RLST, although OnlineCP is outperformed on four datasets, its speed on these datasets is quite close to the best. On the other hand, we notice that all these datasets have fairly small slice size. In contrast, on those datasets with larger slices, such as COIL and FACE, the time con-sumption of our method clearly grows slower than that of RLST, showing that OnlineCP is less sensitive to the size of the data, and thus, having better scalability.
Throughout our experiments, an interesting observation was made: for all adaptive algorithms that make use of the previous step results, namely Batch Hot, SDT, RLST, GridTF, and OnlineCP, their best results are usually linked to a good initial fitness, while poor-quality initializations of-ten lead them to subsequent under-fitting. To explore the impact of initialization to each algorithm, the following ex-Table 5: The final fitness averaged over 200 runs with dif-ferent initial fitness. Results are displayed as mean  X  std , where mean is the average final fitness and std is the stan-dard deviation, both in % (the higher the values the better). periment has been conducted. We generate a synthetic ten-sor X X X P R 20  X  20  X  100 by constructing from random loading matrices and then downgrade it by a Gaussian noise with a Signal-to-Interference Rate (SIR) of 20 dB. The best fitness to
X X X in 10 runs of ALS is 90 . 14%. Thistensoristhenrepeat-edly decomposed by the above five methods for 200 times. At the beginning of each run, half of the data is used for initialization by ALS with a random tolerance from 9 e  X  1 to 1 e  X  4, to produce different level of initial fitness. Then the rest of data is sequentially added and processed by each online algorithm. The averaged final fitness over all runs is used as the effectiveness indicator, as well as the stan-dard deviation. Table 5 shows the experimental results with average initial fitness as 65.78% and standard deviation as 15.3704%.

As shown in Table 5, overall, the low quality initialization has a negative impact on all algorithms. Even the most pow-erful one, Batch Hot, cannot always reach the best fitness and shows a decline of 10%. For SDT and RLST, it turns out that both algorithms are significantly dependent on the initial fitness. When the initial fitness is lower than the best value, their performance can quickly drop to an unaccept-able level. In addition, their results are also highly unstable, as demonstrated by a large variance. While both GridTF and OnlineCP exhibit much more stable performance, the final fitness of GridTF is considerably lower than our ap-proach OnlineCP. This experimental evidence demonstrates that the proposed algorithm, OnlineCP, is less sensitive to the quality of the initialization, compared with exiting online methods. However, it can be seen that good initialization still plays an important role to our algorithm. Thus, for applying our method, we suggest to validate the goodness of the initialization at the beginning, in order to obtain the best subsequent effectiveness.
According to Section 4.3, the time complexity of each al-gorithm is mainly determined by the slice size and the length of processed data. To confirm our analysis and evaluate the scalability of our algorithm, firstly, a tensor X X X P R 20  X  20  X  10 of small slice size but long time dimension is decomposed. After initializing with data of the first 100 timestamps, each method X  X  running time for processing one data slice at each time step is measured and displayed in Figure 2. In addi-tion, to examine the impact of slice size to efficiency, we fix the time mode to 100, and generate a group of tensors of different slice sizes, ranging from 100 to 9  X  10 6 .Foreach tensor, its first 20% of data is used for initialization and the average running time for processing the rest data slices is Figure 2: Running time (in seconds) for adding one slice to a20  X  20  X p t  X  1 q tensor at time t . Two figure represents the same information, differing only in the y-axis scale. Figure 3: Running time (in seconds) for processing different size of tensors. Two figure represents the same information, differing only in the y-axis scale. shown in Figure 3. For better comparison, both Batch Hot and GridTF are forced to execute 1 iteration only in these two experiments. Note that the y-axis of Figures 2a and 3a is displayed in log scale and in Figure 2b, Batch Hot has been removed for better visibility.

As can be seen from Figure 2, both RLST and OnlineCP show constant complexities and the increasing length of pro-cessed data has no impact on them. For the other ap-proaches, a clear linear growth with time can be observed in Batch Hot and SDT, which makes them less feasible for online learning purposes. The change of time consumption in GridTF is less obvious compared with Batch Hot and SDT. However, after removing the time used by its inner ALS procedure, similar linear trend can be seen, marked as GridTF-update in the figure.

In terms of slice size, it turns out that the time consump-tion of all approaches are linearly increasing as the slice size grows. However, their slopes vary. Both Batch Hot and SDT show quicker growth compared to others. This is reasonable since the impact of slice size to them is also leveraged by the time mode. On the other hand, GridTF outperforms SDT and RLST when the slice gets larger. This is because the growth of slice size has impact only on its ALS proce-dure, which is scaled by R times, while the coefficients in the complexities of SDT and RLST w.r.t. slice size contain an R 2 term. Once again, our proposed algorithm illustrates the best performance in this experiment and even a large 3000  X  3000 data slice can be efficiently processed in 0.1 second.
To conclude, in this paper, we address the problem of tracking the CP decomposition of online tensors. An online algorithm, OnlineCP, is proposed, which can efficiently track the new decomposition by using complementary matrices to temporally store the useful information of the previous time step. Furthermore, our method is not only applicable to third-order tensors, but also suitable for higher-order tensors that have more than 3 modes. As evaluated on both real world and synthetic datasets, our algorithm demonstrates comparable effectiveness with the most accurate batch tech-niques, while significantly outperforms them in terms of ef-ficiency. Additionally, compared with the state-of-art on-line techniques, the proposed algorithm shows advantages in many aspects, including effectiveness, efficiency, stability and scalability.

There is still room for improving our method. One direc-tion is to further extend it for more general dynamic ten-sors that may be changed on any modes [11]. Another po-tential direction is to incorporate constraints, such as non-negativity [13], so that our method can be more suitable for applications such as computer vision.
 This work is supported by the Australian Research Council via grant number DP140101969. [1] E. Acar, et al. Scalable tensor factorizations for [2] K. Altun, et al. Comparative study on classifying [3] M. B  X  achlin, et al. Wearable assistant for parkinson X  X  [4] B. W. Bader, T. G. Kolda, et al. Matlab tensor [5] Y. Cai, et al. Facets: Fast comprehensive mining of [6] A. Cichocki. Era of big data processing: a new [7] A. Cichocki, et al. Tensor decompositions for signal [8] P. Comon, X. Luciani, and A. L. De Almeida. Tensor [9] L.DeLathauwer,etal.Onthebestrank-1and [10] D. M. Dunlavy, T. G. Kolda, and E. Acar. Temporal [11] H. Fanaee-T and J. Gama. Multi-aspect-streaming [12] J. Fonollosa, et al. Reservoir computing compensates [13] C. Hu, et al. Scalable bayesian non-negative tensor [14] W. Hu, et al. Incremental tensor subspace learning [15] T. G. Kolda. Multilinear operators for higher-order [16] T. G. Kolda and B. W. Bader. Tensor decompositions [17] W. Liu, et al. Utilizing common substructures to [18] X. Ma, et al. Dynamic updating and downdating [19] S. A. Nene, et al. Columbia Object Image Library [20] D. Nion, et al. Adaptive algorithms to track the [21] S. Papadimitriou, et al. Streaming pattern discovery [22] A. H. Phan, et al. Parafac algorithms for large-scale [23] F. S. Samaria, et al. Parameterisation of a stochastic [24] F. Schimbinschi, et al. Traffic forecasting in complex [25] L. Shi, et al. Stensr: Spatio-temporal tensor streams [26] A. Sobral, et al. Incremental and multi-feature tensor [27] J. Sun, D. Tao, and C. Faloutsos. Beyond streams and [28] J. Sun, et al. Incremental tensor analysis: Theory and [29] M. A. O. Vasilescu, et al. Multilinear analysis of image [30] M. Zhang and A. A. Sawchuk. Usc-had: A daily
