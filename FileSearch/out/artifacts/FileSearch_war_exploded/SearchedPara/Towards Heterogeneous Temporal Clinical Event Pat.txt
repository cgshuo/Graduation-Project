 Large collections of electronic clinical records today provide us with a vast source of information on medical practice. However, the utilization of those data for exploratory anal-ysis to support clinical decisions is still limited. Extract-ing useful patterns from such data is particularly challeng-ing because it is longitudinal , sparse and heterogeneous . In this paper, we propose a Nonnegative Matrix Factorization (NMF) based framework using a convolutional approach for open-ended temporal pattern discovery over large collections of clinical records. We call the method One-Sided Convo-lutional NMF (OSC-NMF). Our framework can mine com-mon as well as individual shift-invariant temporal patterns from heterogeneous events over different patient groups, and handle sparsity as well as scalability problems well. Further-more, we use an event matrix based representation that can encode quantitatively all key temporal concepts including order, concurrency and synchronicity. We derive efficient multiplicative update rules for OSC-NMF, and also prove theoretically its convergence. Finally, the experimental re-sults on both synthetic and real world electronic patient data are presented to demonstrate the effectiveness of the proposed method.
 J.3 [ Life and Medical Sciences ]: Health; I.5 [ Pattern Recognition ]: Design Technology X  Pattern analysis Agorithms Pattern Discovery, NMF, Convolution
Electronic Health Records (EHR) are systematic collec-tions of longitudinal patient health information generated by one or more encounters in any care delivery setting. In-cluded in this information are patient demographics, en-Figure 1: An example of a diabetic patient X  X  elec-tronic record over one year. The x-axis corresponds to the day index, the y-axis represents different types of recorded events, which can be categorized into 4 groups including procedures (CPTs), lab re-sults (LABs), visits to primary care physician (PCP) and visits to specialists (SPEC). The dots in the fig-ure indicate the corresponding events happening at corresponding dates. counter records such as claims, progress notes, problems, medications, vital signs, immunizations, laboratory data and radiology reports, etc. Fig.1 illustrates an example of a temporal event record of a diabetic patient over one year, where 30 key event factors are recorded, including proce-dures (CPTs), lab results (LABs), visits to primary care physician (PCP) and various specialists (SPEC).

In this paper, we study Temporal Pattern Discovery (TPD) for EHR data, which aims at finding temporal patterns of one or more groups of patients. TPD is an open-ended prob-lem in the sense that the mined patterns can be utilized in various scenarios such as predictive modeling [1], informa-tion visualization [29] and comparative effectiveness research [25]. TPD is also an active research direction that has at-tracted a lot of interests from data mining related applica-tions including financial marketing [6], video content anal-ysis [4] and social network analysis [19]. Many challenges in TPD are shared by these applications, however some are particularly pronounced in the medical domain when per-forming TPD from medical data. These include (1) Shift-Invariance . EHR for all patients are not tempo-rally aligned. Moreover, due to various complexities such as comorbidities, the trajectories for different patients are very different over a long time period. However, it is possible to extract time-invariant patterns within a shorter timeframe across patients. Thus an appropriate TPD approach should not be affected by the absolute time stamps. (2) Heterogeneity . The EHR data contain multiple types of events (e.g., diagnosis, medication, lab). The method needs to be able to mine patterns from the combination of all types of events and capture the relationship among them. (2) Sparsity and Irregularity . The EHR data are usually very sparse with irregular intervals, as most of the patients do not have frequent events (e.g., the patient shown in Fig.1 only has around 20 events in a year) or with high regularity. (4) Quantitative Nature . In clinical settings qualitative relations such are event A is followed by event B is impor-tant but typically insufficient. Quantitative measures of the duration of a given event and the interval between multiple events are often of key importance. (5) Scalability . We may face a large patient population, and each patient may has a long longitudinal record (e.g., chronic disease) and many different event factors. The al-gorithm needs to be able to efficiently learn patterns from such a large volume of data.

We propose a novel geometric framework for EHR repre-sentation and perform the TPD task based on that. Specif-ically, we model the EHR record as an image matrix like Fig.1, where the x-axis corresponds to the time stamps and y-axis corresponds to the event values. Note that different events can have different value ranges and types (e.g., blood pressure has continuous values, while PCP visits has non-negative integer values) 1 . Furthermore, each event could be either instantaneous (represented by a single pixel), or with a certain duration (represented by a line segment in the image). This provides a succinct representation that can effectively encode a large range of temporal information in-cluding event value, time and duration, relationships among different events, and intervals between pairwise events using an image. We call such a representation an event matrix .
Based on the event matrix representation, we propose a novel approach, One-Sided Convolutional Nonnegative Ma-trix Factorization ( OSC-NMF ), to detect temporal patterns from EHR. NMF is a powerful tool for identifying under-line structures in a matrix through regularized decompo-sition and has been successfully applied to many applica-tions including clustering, metric learning, and classification [13][14]. In order to apply this tool to our problem set-ting, where each patient is represented by an event matrix with fix number of rows (determined by the events of inter-ested) but varying number of columns (determined by the length of the longitudinal record of the patient), we adapt a convolutional approach. Our approach assumes that each patient matrix is generated by the superposition and con-catenation of a set of temporal pattern matrices over the time axis. The method is called one-sided because the con-volution only occurs along the time axis but not on event side. Each pattern matrix essentially encodes a composite temporal pattern with the inherent order, concurrency and synchronicity relations among different events.

To carry out this convolutional decomposition approach we introduce a methodology to minimize the  X  -divergence [9] between the convoluted matrix and the original patient matrix to obtain the optimal pattern matrices under non-negativity constraints.  X  -divergence is a general divergence measure that includes many common measures such as KL-
In this paper, we only consider binary event values, i.e., the ( i,j )-th element of the patient matrix is 1 if the i -th event happens at time j , otherwise its value would be 0. divergence and Euclidean distance as special cases. We pro-vide efficient multiplicative update rules for solving the op-timal patterns based on this general measure, and rigorous proofs for the algorithm convergence. Experimental results on applying OSC-NMF to both synthetic and real world data are presented to demonstrate its effectiveness.
It is worthwhile to highlight the strength of OSC-NMF. (1) The mined patterns are shift invariant . Because of the convolutional nature of OSC-NMF, the mined temporal patterns are independent of the absolute time stamps. (2) The mined patterns are comprehensive . The mined pattern matrices represent relationships among all different types of events recorded in the patient matrices. (3) OSC-NMF can incorporate sparsity constraints . OSC-NMF can easily handle the high sparsity in the data by adding sparsity regularization terms in the objective. (4) The mined patterns are quantitative . The pat-tern matrices can naturally encode quantitative relation-ships among all different events, including duration of events as well as interval and overlap between events. (5) OSC-NMF can handle large scale data set . We provide an efficient stochastic learning framework for OSC-NMF, which processes one or a small portion of the data matrices each time, thus results in a constant memory cost.
The rest of this paper is organized as follows. Section 2 in-troduces related work. Algorithm details and extensions are described in section 3. Section 4 presents the experimental results, is followed by the conclusion in section 5.
In this section we briefly review some previous work that are closely related to our work in this paper.

A lot of work has been done for temporal sequence repre-sentation and mining. For example, Keogh et al. proposed symbolic aggregate approximation (SAX) [15] to represent time series using symbolic sequences. However, SAX can-not take into account the relationships among heterogeneous time sequences. [17] proposed a temporal knowledge repre-sentation method with symbolic languages and grammars. [5] proposed a TPD approach based on first-order temporal logic under regular expression constraints. These methods is that they specify some explicit symbolic languages and temporal grammars according to prior knowledge. Frequent item set [22][11] or sub-sequence [30] mining are also closely related to the work in this paper. However, in these ap-proaches, the time intervals between pairwise events are not considered. In our case, this pairwise event intervals are of key importance (e.g., two events happen in a week and a year are completely different disease condition signals).
In medical domain, [20] proposed a statistical approach for summarizing and visualizing the temporal associations between the prescription of a drug and the occurrence of a medical event. [24] proposed a temporal abstraction ap-proach for medical TPD. Similar to [17], this method also requires predefined temporal grammar and logic with prior knowledge. [8] proposed a visual interface for finding tem-poral patterns in multivariate temporal clinical data. The interface was further used in [23] for searching temporal pat-terns in patient histories, but the user needs to specify the structure of the pattern on the interface.

On the methodology side, Nonnegative Matrix Factoriza-tion (NMF) [13][14], which aims at factorizing a nonnegative Figure 2: A graphical illustration of one-side convo-lution. The top left figure shows temporal pattern, and the top right figure is the time axis where we use green bars to represent the position where the pattern appears. The bottom figure is the one-side convolution result, where each dotted line rectangle corresponds to a pattern. matrix into the product of two low-rank nonnegative matri-ces, has attracted considerable interests from data mining in recent years. There are also a lot of NMF variants that are related to our work. For instance, [12][7] proposed to en-force sparsity regularizations on the decomposed matrices to obtain sparse solutions. [10], [21], [26] and [18] proposed con-volutional sparse NMF to discover the shift-invariant tem-poral patterns from acoustic signals and images. However their approach is designed for time series data and is not ap-plicable to heterogeneous event sequences. Furthermore, all prior methods measure the factorization quality using ma-trix Frobenius norm, and obtain a common set of patterns by batch learning methods. On the contrary, our method pro-posed in this paper (1) is based on a general  X  -divergence loss; (2) can detect common and individual patterns from different data groups, and (3) can be trained with efficient stochastic learning scheme. We now describe the One-Sided Convolutional NMF (OSC-NMF) algorithm in detail.
Suppose we have a patient matrix X  X  R n  X  t , where n is the number of event factors, t is the length of the patient clinical history. As mentioned in section 1, we assume X is the superposition of the one-side convolution of a set of hidden patterns F = { F ( r ) } R r =1 across the time axis. We define the one-side convolutional operator  X  as follows. Definition 1. (One-Sided Convolution). The one-sided convolution of F  X  R n  X  m and g  X  R t  X  1 is an n  X  t ma-trix with Note that g j = 0 if j 6 0 or j &gt; t , and F ik = 0 if k &gt; m .
Thus we can see that one-side convolution is the operation between a matrix and a vector. This operator is specially designed for our scenario on TPD from electronic clinical records. As in our case, we are interested in patterns com-posed of all events, thus there is no convolution on the ver-tical axis. Fig.2 gives us an intuitive graphical illustration of the procedure of one-side convolution, where the bottom image is obtained through the one-side convolution of the pattern top-left and the time vector top-right.
 Another important definition is the matrix  X  -divergence. Definition 2. (  X  -divergence [9]) The  X  -divergence between two matrices A and B with the same size is where  X  &gt; 0 is a constant .

For completeness, by making use of the limit theory, we define d  X  ( A , B ) for  X  = 0 and  X  = 1 as follows.  X  -divergence is a very general divergence: d 0 ( A , B ), d d ( A , B ) correspond to the Itakura-Saito distance , general-ized Kullback-Leighbler divergence and Euclidean distance .
Now coming back to our problem, we first introduce how to make use of OSC-NMF to detect temporal patterns from a single patient X  X  EHR. Second, we extend OSC-NMF to detect patterns from the EHR of multiple groups of patients.
Recall we suppose the patient EHR matrix X is con-structed by the superposition of the one-side convolution of a set of patterns F = { F ( r ) } R r =1 across the time axis. Then we propose to detect them by minimizing where g ( r )  X  R t is the coding matrix for pattern F ( r ) problem our algorithm aims to solve is Since the patient matrix X is nonnegative, we also require { F ( r ) , g ( r ) } R r =1 to be nonnegative. With the definition of  X  divergence (Eq.(2)), we have where we define Combining Eq.(1) and Eq.(8), we have  X  X  ij / X  X  ( r ) ik = g Thus we can update F ( r ) ik by where  X  (  X  ) is the learning rate defined as On the other hand, we have We have the following theorem (which is proved in the Ap-pendix) to guarantee the convergence of the updates. Theorem 1. Starting from some initial guess on { F ( r ) , g and iteratively update them with Eq.(9) and Eq.(11) will fi-nally converge to a stationary point.
 Complexity Analysis For the storage complexity, during the iterations, it is good to hold X and Y in the memory, which costs O ( s X + s Y ) space, where s X and s Y are the number of nonzero elements in X and Y . We also need to hold F ( r ) and g ( r ) when up-dating themselves, which brings an additional O (  X  s space. Here  X  s F and  X  s g are the averaged number of nonzero complexity is O ( s X + s Y +  X  s F +  X  s g ).

For computational complexity, we need O (  X  s F  X  s g ) time to compute Y , O (2  X  s F  X  s g ) time to update each F ( r ) eration, thus update all F = { F ( r ) } R r =1 over one step costs O ((2 R + 1)  X  s F  X  s g ) time, and the complexity for updating all G = { g ( r ) } R r =1 over one iteration is the same. Thus the total computational complexity for OSC-NMF over T iterations is O ((4 R + 2) T  X  s F  X  s g ).
 Imposing the Sparsity Constraints As shown in Fig.1, the patient EHR matrices are very sparse. Therefore it is natural to assume that the learned temporal pattern matrices and the convolutional coefficients are also sparse. Similar to [12] and [7], we can enforce the sparsity constraints by adding ` 1 regularization terms to the objec-tive in Eq.(5). As a consequence, we can solve for the opti-mal patterns and codes by minimizing
J 1 = d  X  X , where  X  1 &gt; 0 and  X  2 &gt; 0 are the regularization parameters. Then the problem we want to solve becomes Similar to the previous subsection, we can get the update rules for F and g as follows.

We can also observe that the storage and computational complexities of OSC-NMF after imposing those sparsity con-straints remains the same as simple OSC-NMF.

However, as pointed out by [7], purely solving problem (13) may cause a scaling problem, as we can always scale F and G to get the same cost function value. To avoid this, we propose an normalization invariant formulation of problem (13) in the following.
 Normalization Invariant Formulation For the normalization invariant sparse OSC-NMF, we need to minimize the following objective with nonnegativity con-straints.
 where b F ( r ) is the r -th normalized pattern matrix. In this paper, we will consider two types of normalization. Using the same trick as in [7], we can update F and G by
We can see that this normalization invariant formulation does not bring any extra storage burden, but brings an extra O (2 R  X  s F ) computational overhead at each iteration.
In the medical domain, patients are often characterized by multiple groups based on characteristics such as diag-nosis or treatments. More formally we consider the case where the patient matrices are composed of C groups. We group, with X c l representing the l -th data point in this group. n c is the number of patient in the c -th group. In many real world applications we are also interested in find-ing patterns hidden in those groups. In this section we will extend our one-side convolutional NMF to these scenarios. (1). TPD From One Group We first consider the case of detecting common patterns from one group, i.e., C = 1, which is the same setting as in group sparse coding [2]. If we still denote the hidden pattern set as F = { F ( r ) } R r =1 , then the problem we want to solve becomes (here we directly give the sparsity con-strained objective as the non-sparse case just correspond to  X  1 =  X  2 = 0) where G = { g ( r ) l } n 1 i =1 is the convolution coefficients for the data, n 1 is the size of the group. Then the objective we want to minimize is rules for F and G as follows.
 If we want to find normalized patterns, we can use the same trick as in [7] and derive the following update rules Complexity Analysis Similar to the simple OSC-NMF case, we can analyze that the storage complexity of group OSC-NMF is O ( n 1 (  X  s  X  s Y +  X   X  s g ) +  X  s F ), where n 1 is the size of the group,  X  s the averaged number of nonzero elements in { X l } n extra O (2 R  X  s F ) time for pattern normalization. A Stochastic Learning Scheme We can see that group OSC-NMF is storage and time con-suming if the group size n 1 is very large. In this case, we can adopt the stochastic (online) learning scheme in [16][3][28], i.e., at each time t , the algorithm only (randomly) receives one or a small number of matrices X t from the data pool, then proceeds the following steps: (1) Estimate the convolution coefficients G t for X t based on the current F t . This can be done by starting from some random of G t , then iterating with Eq.(20) (or its normalized version) several times. (2) Integrating X t and G t with the previously received data and their estimated convolution coeffients to update F with Eq.(19) (or its normalized version) only once .
 With this scheme, when estimating G t at step t , we need usually n t n 1 . We also need O ( n t (2 R + 1)  X  s F  X  tational time. For updating F from Eq.(19) (or Eq.(21)), we need to sum over all received data matrices for both nu-merator and denominator, thus we can save the summation results on the nominator and denominator in the previous step. Therefor, we just need to compute the corresponding summation terms on X t . For each round of updating F , we need O ( n t (  X  s X +  X  s Y +  X   X  s g )+2  X  s F ) space and O ( n time. To conclude, the total storage complexity for this on-line scheme is O ( n t (  X  s X +  X  s Y +  X   X  s g ) + 3  X  s computational complexity is O ((4 R + 2) Tn t  X  s F  X   X  s malized cases, we just need to add additional O (2 R  X  s putational time for pattern normalization. (2). TPD From Multiple Data Groups Now assume there are C ( C &gt; 1) data groups, and we want to find a common pattern dictionary F S across all data groups, as well as an individual pattern dictionary {F I c for each data group, then we need to solve where we use r to index the common patterns (whose total number is R ), v to index the individual patterns in the c -th group (whose total number is V c ), and l to index the data within each group. The objective we want to minimize is get the update rules for unnormalized case and { b F I c } are normalized basis, then we have the following updating rules for normalized cases The complexity of this multi-group OSC-NMF can be ana-lyzed similarly as our analysis in previous sections, thus we omit the details here. Note that when facing with large data groups, we can also adopt the stochastic learning scheme.
In this section we present the experimental evaluation re-sults for OSC-NMF and its variants. Figure 3: Synthetic data set I. There are three samples { X
We generated two synthetic data sets to validate the effec-tiveness of the proposed methods. The first one is designed to test whether Group OSC-NMF series methods can detect common temporal patterns contained in the data samples. The data set is illustrated in Fig.3, which is composed of one group of three data samples with size 30  X  120. There are four types of common patterns present in the data sam-ples indicated by windows of different color in Fig.3. These samples are binary, with black dots representing 1.
The following algorithms were applied to this first syn-thetic data set to evaluate their effectiveness. (1) Group OSC-NMF ( GOSC-NMF ). The algorithm is introduced in section 3.3 with  X  = 0 . 5, R = 11,  X  1 =  X  (2) Group OSC-NMF with Individual Normalization ( GOSC-NMF-IN ). The algorithm is the same as in GOSC-NMF except that we use normalization invariant updates with individual normalization introduced in section 3.3, and  X 
S =  X  I = 0 . 5. (3) Group OSC-NMF with Total Normalization ( GOSC-NMF-TN ). The algorithm is the same as in GOSC-NMF-IN except we use normalization invariant updates with total normalization introduced in section 3.3, and  X  S =  X  I = 0 . 5.
For all three algorithms, we set the window length to m = 7 and the number of iterations to T = 100.

Fig.4 shows the learned patterns by those algorithms. Fig.4(a) shows the patterns learned by simple GOSC-NMF, from which we can see that all of them are null patterns. This is because the three original data samples are all very sparse. By convolving those null patterns over the time axis we get a zero matrix, and the total  X  -divergence (  X  = 0 . 5) between the data samples to this zero matrix is very small. This makes GOSC-NMF trapped in this local optimum.

Fig.4(b) demonstrates that sparse GOSC-NMG with indi-vidual normalization correctly learns two repeating patterns appearing in the original data samples, while Fig.4(c) shows that sparse GOSC-NMG with total normalization correctly learns all temporal patterns. It can be observed that by adding the sparsity regularizations, the learned patterns are much better. More interestingly, we can see that GOSC-NMF-TN identify all 4 patterns.
 Figure 6: Group Patterns Discovery: MGOSC-NMF-TN can successfully identify all patterns in-cluding shared pattern (red, first row) and all indi-vidual patterns from each group (row 2-4).

The second data set is designed to test whether our multi-group OSC-NMF series algorithms introduced in section 3.3 can detect both common and individual temporal patterns contained in different data groups. The data is shown in Fig.5. We tested three algorithms: (1) MGOSC-NMF . Simple multi-group OSC-NMF with  X  S =  X  I = 0; (2) MGOSC-NMF-IN . MGOSC-NMF with individual normalization, and  X 
S =  X  I = 0 . 5; (3) MGOSC-NMF-TN . MGOSC-NMF with total normalization, and  X  S =  X  I = 0 . 5. For all three methods, we set  X  = 0 . 5, T = 100, R = V = 4. All pattern images and convolution coefficients are randomly initialized. The results are shown in Fig.6, from which we can make sim-ilar observations as in Fig.4. We do not show the learned patterns from simple MGOSC-NMF because all of them are zero. MGOSC-NMF-IN can learn a rich set of pattern im-ages, but not all of them are correct. Finally MGOSC-NMF-TN correctly learns all individual and common patterns. pattern shaded in different colors.
The real-world dataset consists of records from 21K di-abetes patients collected over a period of up to one year. The patients are stratified into three groups A, B, and C based on their specific type of diabetes diagnosis using ICD9 code. Group A (with size 16K) consists of patients with no complications, group B (with size 4,925) consists of patients with chronic disease complications, and group C has patients (with size 254) with acute complications. To evaluate the clinical relevance of the temporal patterns mined by our al-gorithm, we treat the diagnoses as labels. We then use the mined temporal patterns as additional features for predict-ing the diagnoses, and compare the performance against a baseline classifier using the aggregate clinical features with-out consideration of any temporal relations. The hypothesis is that if the temporal patterns mined by our algorithm in-deed contain useful clinical information, then their inclusion should improve the classification performance.

For all three groups, 30 different event conditions were selected as being relevant to the progress of diabetes based on consultations with physicians. The events fall into four different groups: medical procedures (CPTs), lab results (LABS), primary care physician visits (PCP), and visits to various specialists (SPEC). One typical patient EHR exam-ple is shown in Fig.1. We show some examples of repeating patterns (with one week window length) for each group in Fig.7, which have been identified manually by domain ex-perts. Note that in this case, each patient is represented by a 30  X  T matrix, where T = 365, and the total patient pop-ulation is represented by 21k such matrices, and we adopt the stochastic learning strategy for learning the patterns.
To quantitatively evaluate the performance, we randomly selected 70% of the data samples from each group to form the training set, and used the rest data for testing. In this experiment, we set  X  = 0 . 5 and T = 10000. The mini-batch size when performing stochastic learning was set to 20. We applied OSC-NMF series methods to construct different feature representations for the data and then used Nearest Neighbor (NN) classifier (with Euclidean distance) to clas-sify the test samples. We repeated the experiments 50 times using random partitioning, and report the average classifi-cation accuracy compared against the baseline (which is the performance using aggregate clinical features alone, with no considerations of any temporal relations).

Both single group (GOSC-NFM-IN and GOSC-NMF-TN) and multi-group (MGOSC-NMF-IN and MGOSC-NMF-TN) Figure 7: Patient samples from three groups. Shaded windows are manually identified clinical patterns. Red are common patterns across three groups. The other colors are group specific patterns. series were tested. For GOSC-NMF-IN and GOSC-NMF-TN, the algorithms were applied to all training data each time and R = 30 patterns were learned (null patterns were discarded). Each sample was then represented by a 30 (or less if there are zero patterns) dimensional vector with the value on each dimension equal to the sum of the convo-lution coefficients g of the corresponding pattern on this sample. This is very similar to the bag-of-words represen-tation for text data. For MGOSC-NMF-IN and NGOSC-NMF-TN, we learned both common and individual patterns for all groups, and discarded the common patterns (since they are not important for classification across groups), us-ing only the individual patterns to construct the dictionary. We set the number of patterns R = V = 30 and discarded the null patterns. Thus each sample was represented by a 90 (or less) dimensional vector. For comparison purpose, we also implemented Group and Multi-Group PrefixScan [22] (G-PrefixScan and MG-PrefixScan), i.e., we use a sliding window (with the same length as we used for OSC-NMF methods) to segment the patient record sequence into a set of overlapping transactions, and then apply PrefixScan to mine frequent item sets from all these transactions. For G-PrefixScan, we mine 30 most frequent patterns from all training data, while for MG-PrefixScan, we mine 30 most frequent patterns for the training data in each class. Then we also construct the bag-of-pattern matrix for each patient Figure 8: Common and individual patterns are correctly identified by MGOSC-NMF-TN with one week window length. Row 1 are two common pat-terns, and row 2-4 are group specific patterns. Be-sides the 5 known patterns, MGOSC-NMF-TN also reveals some unknown patterns, which can poten-tially lead to new clinical discovery. (each patient is a 30 dimensional vector with the value on each dimension representing the number of times the cor-responding pattern appears within the patient records) for classification.

Table 1 shows the averaged classification performance mea-sured by Areas Under the Curve (AUC) with pattern window length set to one week, two weeks and one month. The re-sults show that (1) the classification performances with the inclusion of temporal pattern based features are indeed much better compared to the baseline representation; (2) longer window patterns are more effective, which is likely due to the fact that the progression of diabetes is slow, making the patterns more salient when we increase the window length; (3) multi-group methods tend to perform better, as they ex-tract more discriminative patterns for each group; (4) our matrix approximation based approaches perform better than traditional PrefixScan type methods.
In this paper we propose an One-Sided Convolutional Non-negative Matrix Factorization (OSC-NMF) approach for tem-poral pattern discovery in longitudinal clinical records. We present how to adapt OSC-NMF to extract patterns from one data sample, a group of data samples and multiple groups of data samples. The experimental results on both synthetic and real world data sets are presented to demon-strate the effectiveness of the proposed approaches.
