
Privacy-Preserving Data Mining is an important area that studies privacy issues of data mining. When the goal is to share data mining results, two privacy-related prob-lems may arise. The first one is how to compute the data-mining results among several parties without sharing the data. Cryptography-based primitives are the basic tool used to develop ad-hoc secure multi-party computation pro-tocols that share information as less as possible during the computation under different adversary models. The sec-ond one is how to produce data mining results that prov-ably do not contain threats to the anonymity of individu-als. The concept of k -anonymity has been used to discover anonymity-preserving frequent patterns, and centralized al-gorithms have been developed. In this paper and for the first time, we study how to produce anonymity-preserving data mining results in a distributed environment. We present two privacy-preserving strategies and show their feasibility through experimental analysis.
Building models and learning patterns from a collection of data are essential tasks for decision making and dissem-ination of knowledge during today X  X  information age. The field of data mining has been developing tools to facilitate these tasks when data can be collected freely. However, tra-ditional mining techniques cannot be applied under the situ-ation where data are distributed across multiple sources and cannot be combined directly because of privacy concerns.
Due to vast improvements in networking and rapid in-crease of storage capacity, the full data about an individual are typically partitioned into several sub-data sets (credit history, medical records, earnings, etc), each stored at an independent site. The distributed setting is likely to remain, partially because of performance and accessibility, but more importantly because of autonomy of the independent sites. This autonomy provides a measure of protection for the in-dividual data: if two attributes in combination reveal private information (e.g., airline and train travel records indicating likely attendance at political rallies), but when the attributes are stored at different sites, a lack of cooperation between the sites ensures that neither is able to violate privacy.
Although data cannot be shared directly under cer-tain situations, building models and learning trends across multiple sources are still possible by utilizing privacy-preserving data mining (PPDM) techniques. The concept of PPDM appeared first in [2, 16]. Since then, a number of protocols have been developed from association rule min-ing [24] to clustering [23], and others. Nevertheless, when the goal is to share data mining results, two privacy-related problems may arise. The first one is how to compute the data-mining results among several parties without sharing the data. Crypto-based primitives are the basic tool used to develop ad-hoc PPDM protocols that share information as less as possible during the computation under different adversary models. The second one is how to produce data mining results that provably do not contain threats to indi-viduals X  anonymity. Even though data mining results con-tain general information about a population, data mining re-sults could violate individual privacy as illustrated in [14].
A more specific example is given in [3, 4] regarding min-ing frequent itemsets, where it was shown that a set of fre-quent patterns could violate the anonymity (privacy) of in-dividuals recorded in the source data.
 Example 1 Suppose we have the following association rule (or a boolean pattern): a 1  X  a 2  X  a 3  X  a 4 [ sup =80 ,conf =98 . 7%] where sup and conf are the usual interestingness measures of support and confidence defined in [1]. Since the given rule holds for a number of individuals (80), which seems large enough to protect individual privacy, one may con-clude that the given rule can be safely disclosed. However, we can easily derive the support of the premise of the rule: Given the pattern a 1  X  a 2  X  a 3  X  a 4 holds for 80 individuals and the pattern a 1  X  a 2  X  a 3 holds for 81 individuals, we can infer that there is only one individual in the dataset for whom the pattern a 1  X  a 2  X  a 3  X  X  a 4 holds. The knowledge inferred poses potential a threat to the anonymity of that individual.
 Even though solutions proposed in [4, 3, 8] can be adopted to identify and remove the patterns causing privacy breach, the solutions only focus on single data source and cannot be applied when data are distributed and cannot be com-bined due to privacy concerns. Therefore, under the condi-tion that data are distributed across multiple parties and can-not be shared, this paper, for the first time, presents secure multi-party protocols to produce frequent itemsets with no such inference problems described previously. Especially, utilizing the concept of k -anonymity, we assure that each possible information inferable from these frequent itemsets regards at least k -individuals. We term these itemsets as k -anonymous frequent itemsets.

In the context of this paper, we assume data are binary and represented by a relational table, where each row indi-cates an individual data record and each column represents an attribute of data records. In addition, data are assumed to be vertically partitioned and stored at two sites, and the original data could be reconstructed by a one-to-one join on a common key. The terms privacy-preserving ( privacy ) and secure ( security ) are interchangeable for the rest of the pa-per, and our goal is to produce a set of globally frequent itemsets across the two partitions in a privacy-preserving way such that the set of patterns cannot be used to infer a pattern less k -anonymous.
The term privacy-preserving under the context of this pa-per is related to the security definition of Secure Multi-party Computation (SMC). We also assume that parties are semi-honest in that they follow the execution requirement of the protocol but may use what they see during the execution to compute more than they need to know. Details of the secu-rity definitions and underlying models can be found in [10]. Definition 1 Let T i be the input of party i , i ( f ) be the party i  X  X  execution image of the protocol f and s be the re-sult computed from f . f is secure if i ( f ) can be simulated from &lt;T i ,s &gt; and distribution of the simulated image is computationally indistinguishable from i ( f ) .

While it has been shown that for any polynomial time al-gorithm, there exists a polynomial time secure protocol that achieves the same functionality, generic solutions presented in [11, 25] require representing a problem as a boolean cir-cuit. On a large dataset, it is computationally impractical to adopt the pure circuit-based generic solution. Therefore, the key challenge in designing a secure and efficient pro-tocol is to avoid using large circuits. Instead, the generic approach must be used only for small circuits (i.e., simple functionalities with compact inputs).
In this paper, we present two privacy-preserving strate-gies to mine k -anonymous frequent itemsets between two parties. The first one is based on the observation that if the dataset is k -anonymous, its corresponding frequent itemsets are also k -anonymous, and consequently, there does not ex-ist a violation of individual anonymity. Initially, both parties locally generalize their datasets until the join of their local datasets reaches a globally k -anonymization. This can be achieved using the D k A framework proposed in [13] such that no party sees the other X  X  dataset or even the anonymous dataset. Then, both parties utilize a secure finding frequent itemsets (FFI) protocol to mine all the frequent itemsets. The second solution is more direct: first to generate all fre-quent itemsets using a variation of the FFI protocol. Then securely remove those patterns that pose anonymity threat.
The paper is organized as follows: Section 2 introduces the fundamental concepts of k -anonymity, k -anonymous patterns and crypto primitives. Section 3 presents the first solution based on the D k A framework. Section 4 presents the second solution. For each of the two solutions, we also provide correctness analysis, security analysis, and a dis-cussion of the computational and communication complex-ity. Section 5 provides empirical results that demonstrates the effectiveness of the proposed solutions. Section 6 con-cludes the paper with future research directions. 2.1. k -Anonymity
In recent years, [19, 20, 22] introduced an impor-tant method for protecting individual privacy named k -anonymity , a notion establishing that the cardinality of the answer to any possible query should be at least k . Those work showed that protection of individual sources does not guarantee protection when sources are cross-examined: a sensitive medical record, for instance, can be uniquely linkedtoa named voter record in a publicly available voter list through some shared attributes. The objective of k -anonymity is to eliminate such opportunities of inferring private information through cross linkage. In particular, this is obtained by a  X  X anitization X  of the source data that is transformed in such a way that, for all possible queries, at least k tuples will be returned. Such a sanitization is ob-tained via value generalization and suppression [19, 21].
Let T indicate a dataset, A = { A 1 ,A 2 ,...,A m } be the set of m attributes related to T , QI  X  A be quasi-identifier set, T [ QI ] be a projection of T to the set of attributes con-tained in QI , and T k [ QI ] be the k -anonymous data gener-ated from T with respect to QI .

Table 1. A binary dataset T , k-anonymous dataset T and notations for patterns and frequent itemsets Definition 2 T k [ QI ] satisfies k-anonymity if and only if each record in it appears at least k times.
 Let T be Table 1(a), QI = { a, b, c, d, e, f, g, h } and T Table 1(b). 1 Then based on Definition 2, T k is 2-anonymous because T k can be divided as: { t 1 ,t 4 } , { t 2 ,t { t we do not distinguish between quasi-identifiers and sensi-tive attributes and assume A = QI for the rest of the paper. We conclude k -anonymity with a useful theorem [21]: Theorem 1 If T k [ A ] is k -anonymous, then T k [ A ] is also k -anonymous, where A  X  A . 2.2. k -Anonymous Patterns
We start by defining patterns following the notations in [12], and the definitions presented here will be used exten-sively for the rest of this paper.
 Definition 3 A pattern over a dataset T [ A ] (or over the variables/items in A , also indicated with I ) is a logical (propositional) sentence built by AN D (  X  ), OR (  X  ) and NOT (  X  ) logical connectives, on variables in I . The do-main of all possible patterns is denoted P at ( I ) . Definition 4 Given a dataset T , a transaction t  X  T and a pattern p , we write p ( t ) if t makes p true. The support of p in T is given by the number of records which make p true 2 sup Definition 5 The set of all itemsets 2 I , is a pattern class consisting of all possible conjunctions of the form i 1  X   X  X  X  X  i the set of  X  -frequent itemsets in T is denoted F ( T, X  )= { X, sup T ( X ) | X  X  2 I  X  sup T ( X )  X   X  } .
 Itemsets are usually denoted in the form of set of the items in the conjunction. Different notations used for general pat-terns and itemsets can be found in Table 1(c)-(d), whose statistics are computed based on Table 1(a).
The problem addressed in this paper is given by the pos-sibility of inferring from the output of frequent itemset min-ing , i.e, F ( T, X  ) , the existence of patterns with very low support that poses a threat for the anonymity of the individ-uals about which they are true.

Given a dataset T and an anonymity threshold k , a pat-tern p is said to be non k -anonymous if 0 &lt; sup T ( p ) &lt;k . We want to block any opportunity of inferring the sup-port of such dangerous patterns. The support of a pat-tern p = i 1  X   X  X  X   X  i m  X  X  a 1  X   X  X  X   X   X  a n can be in-ferred if we know the support of itemsets I = { i 1 ,...,i J = I  X  X  a 1 ,...,a n } , and every itemset X such that I  X  X  X  J : Following the notation in [7], we denote the right-hand side of Equation (1) as f J I ( T ) .
 Definition 6 Given a dataset T and two itemsets I  X  J  X  2 , the set of itemsets C = { X | I  X  X  X  J } is called a channel, and the size C is defined as | J | .If 0 &lt;f J then C is an inference channel.
 Example 2 Consider T in Table 1(a), and suppose k =3 . let C = { b , bd , be , bde } , and we have that sup T ( b  X  d  X  X  e )= f bde b ( T )= sup T ( b )  X  sup T ( bd )  X  sup sup channel of support 1.
 Note that an itemset with support less than k is itself a non k -anonymous, and thus dangerous pattern. However, since we can safely assume (as we will do in the rest of this paper) that  X  k , such pattern would be discarded by the usual mining algorithms.
Secure dot product (SDP) protocol has been used exten-sively to mine frequent itemsets in a distributed environ-ment [9, 26]. Let v 1 ,v 2 be two vectors with size n of parties P1 and P2 respectively, and v j [ i ] denotes the i th bit of v Formally, define SDP ( v 1 ,v 2 )  X  v 1  X  v 2 .

Table 2. A vertically partitioned dataset dis-tributed between P1 and P2 (left and right)
Refer to table 2 where the dataset (Table 1(a)) is verti-cally partitioned between P1 and P2, and it can be recon-structed via one-to-one join on the global identifier attribute Tr#. Assume P1 and P2 want to know if { abf } is a fre-quent itemset. P1 first creates the vector v 1 = a (111111110001)  X  (111111100001)= (111111100001) , where a, b are the column vectors related to attribute a, b of P1 X  X  dataset and dicates the logic AND operator. P2 creates v 2 = f = (100100011011) . After applying the SDP protocol, both parties get v 1  X  v 2 =3 without disclosing the private vectors v 1 and v 2 to each other. If the minimum support is 2, then { abf } is one of the frequent itemsets.

Since SDP returns the actual support of an itemset, it cannot be used directly as a building block for our proposed protocols. However, we utilize one of its variations: thresh-old SDP defined as SDP  X  ( v 1 ,v 2 , X  )  X  b , where  X  is pub-licly known parameter (e.g., minimum support): b =1 ,if v 1  X  v 2  X   X  ; b =0 , otherwise. Refer to the SSI proto-col in [13] for implementation details and security analy-sis regarding SDP  X  . Based on SDP  X  and Apriori algorithm [1], a finding frequent itemsets (FFI r ) protocol can be eas-ily implemented. Let T 1 ,T 2 be two vertically partitioned datasets of P1,P2 respectively and  X  be a minimum support:  X  FFI F r ( i = 1 or 2) has the following format, for instance: r ( T, 8) = { a, r 2 1 , b, r 2 2 ,... } , where r 1 1 ,r 2 1 and r 1 2 distributed across a large group (e.g., modulo N , a 1024-bit integer in practice).
 Example 3 Let N =17 and refer to Table 3. To compute the support of a and b , we calculate: r 1 1 + r 2 1 =3+6 mod 17 = 9 and r 1 2 + r 2 2 =9+16 mod17=8 .

Note that each party knows the actual supports of all frequent itemsets related to its partition. For instance, P1 knows the actual support of a among others, and likewise, P2 knows the actual support of e . However, for presenta-tion purpose, we adopt an uniform format for each itemset regardless it is locally owned or shared (e.g., cde ). With very minor modification, this does not affect the correctness of the proposed protocols. Thus, for the rest of the paper, we adopt the format as presented in Table 3.

The FFI r protocol is secure in that any information re-garding T 1 and T 2 are not disclosed during protocol exe-cution. FFI r will be used as subroutines later in the paper.
Before detailing the protocol, We first prove the follow-ing claim: Claim 1 If a dataset T is k -anonymous, then there does not exist a set of frequent itemsets that contributes to an inference channel (Definition 6).

P ROOF . Suppose the claim is not true, and without loss of generality, assume an inference channel consists of { a , ab } . Then we have 0 &lt;sup T ( a )  X  sup T ( ab ) &lt;k according to Equation 1; in other words, 0 &lt;sup T  X  b ) &lt;k . This implies that there are less than k tuples in T whose T [ A ] ( A = { a, b } ) values are equal to [1 , 0] . There-fore, corresponding to Theorem 1, T is not k -anonymous, which leads to a contradiction. Thus, the claim is valid. The above claim leads to the design of the first protocol: 1. k -Anonymize T  X  T 1 T 2 , where T 1 and T 2 are 2. Use FFI r to mine all frequent itemsets related to T . Now the question is without disclosing T 1 and T 2 ,howP1 and P2 can achieve the first step stated above. To do this, we can utilize the D k A framework proposed in [13].
We adopt the following notations to describe the frame-work: D k A ( T 1 ,T 2 ,k,f )  X  ( T 1 k ,T 2 k ) , where T 1 and T 2 are locally k -anonymous and private inputs of P1 and P2, k defines the degree of anonymization, f is an ap-plication dependent suppression algorithm (we will clar-ify this later). Both k and f are known by both parties. T 1 k and T 2 k are private outputs of P1 and P2 respec-tively, and T 1 k T 2 k produces a globally k -anonymous dataset. The actual D k A framework presented in [13] re-turns T 1 k T 2 k to both parties. Since we do not want to actually compute T 1 k T 2 k , in our protocol, we omit the last step of D k A, and this simple modification does not violate the security of the framework.

Before applying D k A, two things need to be done: each party Pi (i = 1 or 2) locally and independently generalizes Ti until Ti becomes k -anonymous, and both parties need to agree on the f algorithm. We next show how to achieve both objectives.
Afew k -anonymization algorithm exist [5, 15, 21] etc, but they are not designed specificly for boolean values, and consequently, they are not suitable for our problem do-main. 3 Before introducing the customized k -anonymization algorithm, we first define several functions:  X  Is Kanon ( T,k ) : Given a dataset T andadegreeof  X  Get Kanon ( T,k ) : Given a dataset T and a degree of  X  Gen Freq ( T, X  ) : Given a dataset T and a min support  X  Freq Attrs ( F ) : Given a set of frequent itemsets F ,  X  Supp Attr ( T,A  X  Supp Firstz ( T,z ) (assume | T | z ): Given a  X  Supp F urther ( T,z ) (assume | T | z ): Given a Example 4 Let T refer to Table 1(b), then Is Kanon ( T, 2) returns true since Table 1(b) repre-sents a 2-anonymous dataset. Let T refer to Figure 1(a) for the rest of this example, Get Kanon ( T, 2) returns { t 5 Algorithm 1 Supp F urther because t 5 and t 6 are identical, and Gen Freq ( T, 8) returns F ( T, 8) (Figure 1(c)). Freq Attrs ( F ( T, 8)) produces { a, b, c, d, e } . Supp Attr ( T,h ) modifies the column h of T into the one as the column h of Ta-ble 1(b). Supp Firstz ( T, 2) returns { t 1 ,t 2 } , where t = t 2 =(11111010) .
 The size of T ( | T | ) determines the termination of the Supp F urther function. Since the size of T is always re-duced by z at step 4 in Algorithm 1, the while-loop will eventually terminate, and consequently, this will lead to the termination of Supp F urther .

Based on these functions, we can define the FIBA proto-col used to make each party X  X  dataset locally k -anonymous. Since the ultimate goal is to produce a set of frequent item-sets without inference channels, we need to preserve as many frequent itemsets as possible. This observation guides the design of the FIBA protocol. Algorithm 2 provides the key steps. Steps 4-6 suppress any attribute which is not a part of any frequent itemset. This makes sense because such attributes do not play any role in the final result. After this, if T is still not k -anonymous, we apply Supp F urther on data in T which are not k -anonymous. The termination of FIBA depends on the size of T . As long as | T | is bounded, Supp F urther will always terminate, which leads to the termination of the FIBA protocol.

Note that the optimal k -anonymization problem is NP-hard [17]. We do not claim that the FIBA protocol is the best k -anonymization algorithm to preserve as many frequent itemsets as possible. Although steps 9-11 of Algorithm 2 is not very intuitive, our hypothesis is that after steps 1-7, most data in T are already k -anonymous (we will validate this in Section 5). Since to design the best k -anonymization algorithm (or the best Supp F urther function) is not the focal point of this paper, we leave it as part of future work. 3.2. The D k A-SAPM Protocol Once both parties k -anonymize their local datasets via FIBA, they can utilize the D k A framework to further gen-eralize their local datasets until they know thejoinofthe two local datasets creates a globally k -anonymous dataset. During this process, nothing regarding the private (local) datasets is disclosed. Finally, they can use the FFI r protocol (mentioned in Section 2.3) to mine all the frequent itemsets. Algorithm 2 Frequent Itemset based Anonymization (FIBA) Algorithm 3 D k A-SAPM
Key steps of D k A based secure k -anonymous pattern mining (D k A-SAPM) protocol is presented in Algorithm 3 written from P1 X  X  point of view. Based on previous dis-cussion, the algorithm is self-evident, but note that steps 3-4 need to be executed collaboratively between P1 and P2. In addition, in order for D k A to behave correctly, the parties should agree on how the parameters of the Supp F urther ( Ti,z ) function change from one iteration to the next. For instance, the z value should be incremented during each iteration so that the termination of D k A is guar-anteed. (In our implementation, the initial z value is set to k , then we double it during each iteration.) Moreover, be-cause the actual support of each frequent itemset in F 1 r distributed between P1 and P2, P1 can compute these sup-port values after receiving the corresponding shares from P2 at step 6, and vice versa. We next show D k A-SAPM is privacy-preserving. 3.2.1 Security Analysis Claim 2 D k A-SAPM is secure under the semi-honest defi-nition of Secure Multi-party Computation.

P ROOF . The interactions between P1 and P2 only occur at step 3 and step 4, and both D k A and FFI r satisfies the security definition of SMC under the semi-honest model. Therefore, there exist simulators for both protocols such that the execution image is computationally indistinguish-able from the simulated execution image at these two steps. In addition, P1, using its output, can compute the r 2 j values received from P2. Therefore, using the two simulators for D k A and FFI r , plus the final output of D k A-SAPM, P1 can construct a simulator such that the simulated execution im-age is computationally indistinguishable from the real exe-cution image of D k A-SAPM. 3.2.2 Complexity Analysis Giving a formal complexity analysis on D k A-SAPM is not easy because the complexity of D k A and FFI r not only de-pends on the size of the dataset but also depends on the char-acteristics of the data. For instance, D k A adopts an iterative process, and the number of iterations is decided by the data itself and the local k -anonymization algorithm. The size of the intermediate data becomes smaller after each itera-tion (since the portion of the data that is already globally k -anonymous is removed before next iteration in a privacy-preserving way). Because FFI r is an iterative algorithm and the complexity of each iteration is decided by the size of the shared candidate set, here we provide an expected result.
Let q be the number of iterations and p j ( 1  X  j  X  q ) be the size of the intermediate dataset during the j th itera-tion of D k A. According to the analysis in [13], the number of encryptions and communication complexity of D k Aare bounded by O (  X  ) and O (  X   X  log N ) , where  X  = q j =1 and log N is the number of bits of a ciphertext. Next, let v be the number of iterations, u j be the size of the shared candidate set during the j th iteration of the FFI protocol, and w be the size of the underlying dataset. By shared candidate set, we mean the set of candidate item-sets whose items are shared across the two parties (e.g., the itemset bde is shared across P1 and P2 regarding Table 2). Since the number of encryptions and the communica-tion complexity of SDP  X  (refer the SSI t protocol in [13]) is bounded by O ( w ) and O ( w  X  log N ) , the complexity of FFI r is bounded by O (  X  ) encryptions and O (  X   X  log N ) bits, where  X  = w  X  v j =1 u j . Based on these statistics, we can conclude that the number of encryptions and communica-tion complexity of D k A-SAPM is bounded by O (  X  +  X  ) and O ((  X  +  X  )  X  log N ) respectively.

In practice, log N is about 1024, and q, v are small num-bers (less than 15). Thus, the magnitude of p j , u j and w actually determines the complexity of D k A-SAPM.
In this section, we define the second protocol which first utilizes the FFI r protocol to find a set of frequent itemsets. Then we remove all the frequent itemsets that contribute to any inference channel. Now the key is how to securely identify an inference channel, given a subset in FFI r .
Let Ch i z denote a set of channels (Definition 6), and the size of each channel C i is equal to z , where the superscript i  X  X  1 , 2 } indicates whether the symbol represents infor-mation from P1 or from P2. In addition to the basic char-acteristics stated in Definition 6, we associate each itemset in C i with a random number such that the actual support of the itemset can be computed from the two corresponding random numbers distributed between P1 and P2. Ch i z can be computed from F i r .
 Example 5 Refer F i r in Table 3, we can compute: Ch 1 1 = {{ a, 3 } , { b, 9 } , { c, 7 } , { d, 13 } , { e, 15 Ch 2 1 = {{ a, 6 } , { b, 16 } , { c, 2 } , { d, 14 } , { The number of channels in Ch i 1 is 5. Similarly, we can get: Ch 1 3 = {{ e, 15 , ce, 8 , de, 5 , cde, 16 }} ; Ch 2 3 = {{ e, 13 , ce, 1 , de, 5 , cde, 10 }} . The number of channels in Ch i 3 is 1.
 Next, we define several functions (following the notations used in Section 2.2):  X  Get Itemset ( Ch i  X  Rm SItemset ( F i  X  Gen Ch ( Ch i  X  Support ( C i  X  Ch i  X  Secure COM (( r 1 ,k ) , ( r 2 ,k )) : Given two random  X  Get ICh ( Ch i Algorithm 4 Get ICh Protocol Example 6 Follow from Example 5: Get Itemset ( Ch 1 1 ) = { a, 3 , b, 9 , c, 7 , d, 13 , e, 15 } . Rm SItemset ( Gen Ch (  X  , F 1 r )= Ch 1 1 , and Gen Ch ( {{ a, 3 }} , F 1 {{ a, 3 ab, 7 } , { a, 3 ae, 10 }} . According to Equation 1, to compute Support ( C i  X  Ch i 3 ) is straight forward. Each party can compute its own share independently: P1 sets r 1 =15  X  8  X  5 + 16 mod 17 = 1 .P2sets r 2 =13  X  1  X  5 + 10 mod 17 = 0 . Therefore, r 1 + r 2 mod 17 = 1 consistent with direct computation on F ( T, 8) (presented in Table 1(d)).
 Once each party gets a random share from the Support ( C i ) function, they can utilize Secure COM to jointly and securely test if C i is actually an inference chan-nel. In this example, Secure COM (( r 1 , 3) , ( r 2 , 3)) re-turns 0 because the C i  X  Ch i 3 is an inference chan-nel. Assuming we know the size of the underlying dataset, Get ICh ( Ch 1 1 , 3) = {{ d, 13 } , { e, 15 }} .
 Based on these functions, we can define a protocol Remove ICh that securely identifies and removes any in-ference channel in F i r . Its key steps are presented in Al-gorithm 11 written from P1 X  X  point of view. We adopt a bottom-up approach: during the first execution of the while-loop , at step 3, a set of channels Ch 1 1 with size equal to 1 is generated. Step 4 securely identifies a set of inference channels ICh in Ch 1 1 , and then ICh is remove from Ch 1
Now every frequent itemsets related to the modified Ch 1 1 is part of the output  X  F 1 r . Step 7 computes a set of itemsets contributing to an inference channel during current itera-tion. In other words, these itemsets are added at the begin-ning of current iteration to create larger channels. These itemsets along with their supersets are removed from F 1 r The reason to have such pruning process is that the final out-put should be consistent. For instance, given an inference channel { a , ab } ,byremoving a , ab itself may not be an inference channel. However, since ab is frequent, it does not make sense not to include a as part of output. As a result, if a is removed, any of its superset should be removed as well. The remaining non-inference channel in Ch 1 1 will be used to build channels with size equal to 2, and repeat the process until channels with all possible sizes have been examined and pruned.
 Algorithm 5 Remove ICh Protocol Algorithm 6 IC-SAPM
The inference channel based, secure k -anonymous pat-tern mining protocol (IC-SAPM) is presented in Algorithm 6 written from P1 X  X  point of view. At step 2, P1 and P2 collaboratively execute the FFI r protocol to get a set of fre-quent itemsets F 1 r . Inference channels are removed from r at step 3, using the Remove ICh protocol. Since the actual supports of frequent itemsets in  X  F 1 r are distributed between P1 and P2, P1 can compute these support values after receiving the corresponding shares from P2, and vice versa. The correctness of the IC-SAPM protocol can be an-alyzed from FFI r and Remove ICh . We next analyze the security of IC-SAPM. 4.1.1 Security Analysis Claim 3 IC-SAPM is secure under the semi-honest defini-tion of Secure Multi-party Computation provided that F  X  is a part of the final result, where F  X  = F 1 r  X   X  F 1 r . The proof is trivial, and similar argument as the security proof of D k A-SAPM in Section 3.2.1 can be adopted. How-ever, people may question that why F  X  needs to be a part of the output. The answer is that it is not possible to design a simulator using  X  F 1 r to simulate F  X  . Unlike the D k A-SAPM protocol, since no intermediate results are shared by both parties, the final output plus the input are sufficient to build a simulator for D k A-SAPM. Nevertheless, because the sup-port value for each itemset in F  X  are two uniformly distrib-uted values shared between P1 and P2, the real support val-ues regarding all frequent itemsets in F  X  are not disclosed to either party. Therefore, the possible privacy-leak posed by F  X  is negligible in practice. 4.1.2 Complexity Analysis The complexity of IC-SAPM is bounded by the complexity of both FFI r and Remove ICh (steps 2-3 of Algorithm 6). The complexity of Remove ICh is bounded by the num-ber of calls to the Secure COM function, and the num-ber of calls is bounded by the size of F i r (the input of Remove ICh ). In general the number of encryptions re-quired to securely evaluate Secure COM is bounded by O( log N ) (see [13] for more detail). Let  X  = |F i r | X  and adopt the same notations and the complexity analy-sisofFFI r in Section 3.2.2, the number of encryption and communication complexity of IC-SAPM is bounded by O (  X  +  X  ) and O ((  X  +  X  )  X  log N ) respectively, where  X  = w  X  v j =1 u j . In practice, log N is about 1024 and v is a small positive integer, so the magnitude of u , w and |F determines the complexity of IC-SAPM. In this section, we analyze how D k A-SAPM and IC-SAPM behave based on various support (  X  ) values and de-grees of k -anonymization. Especially, we focus on how dif-ferent the outcomes are between the two protocols and on their estimated complexity based on the number of encryp-tions. With high speed connections, communication cost is relative small comparing to computation cost. Thus, we estimate the complexity for both protocols on the time re-quired to perform an expected number of encryptions.
We conducted our experiments on the Mushroom data-base from the UC Irvine Machine Learning Repository [6], which has 8124 tuples and 119 attributes. The main reason to adopt such dataset is that Mushroom is a binary dataset and it has a large number of attributes. Therefore, more fre-quent itemsets are expected, and since this leads to larger variations among the outputs, we can get more clear picture regarding the behaviors of the proposed protocols.
For fair empirical results, the dataset is partitioned be-tween P1 and P2 as follows: Given  X  value, we first find the frequent items or attributes. Then we distribute these frequent items evenly between the two parties. Since the size of a shared candidate set is one of the main factors to determine the complexity of the two protocols, this parti-tion will most likely create larger shared candidate sets, and consequently, it leads to unbiased cost estimates.
Since D k A-SAPM and IC-SAPM adopt different ap-proaches, here we compare how results vary between the two protocols. Because of mining frequent patterns is one of our main concerns, for the rest of this section, the term data distortion means the percentage of frequent patterns lost after the execution of the proposed protocols. We use it as a quality measure to evaluate the two protocols.
One disadvantage of k -anonymization is the distortion of the original dataset. If the dataset is distorted so much, it may no longer have much value in practice. For example, for frequent pattern mining, many patterns may lose after the dataset is suppressed to satisfy k -anonymity. The D k A-SAPM protocol is based on the concept of k -anonymity, so to validate it, we need to show how effective the protocol can preserve the frequent patterns or itemsets.

Figure 1(a) provides certain insights, where x , y and z axes represent support  X  , degree of anonymization k and distortion rate respectively. For instance, given k =50 and  X  = 55% , less than 10 percent of all frequent item-sets related to the original dataset was lost after the k -anonymization. According to the figure, we can conclude that the distortion rate increases as k increases and  X  de-creases. With  X   X  55% and k  X  50 ,D k A-SAPM virtu-ally does not distort the data. Although the  X  and k values are application dependent, by showing the tradeoffs among  X  , k and the distortion rate, Figure 1(a) does provide some guidelines for choosing the  X  and k values when D k A-SAPM is adopted in real life.

The IC-SAPM protocol does not utilize k -anonymization. Instead, it directly removes all the inference channels from the set of frequent itemsets in a bottom-up fashion. Figure 1(b) shows the distortion rate with different k and  X  values. In general, when  X  decreases, more patterns are removed because there are more large frequent patterns which are more likely to contribute to an inference channel. When k increases, more inference channels are expected. Figure 1(b) certainly shows this. Based on the two figures, for large  X  and smaller k , D k A-SAPM produces better results in term of distortion rate. Due to suppression, support values for frequent item-sets may change a bit. Therefore, this change allows D k A-SAPM preserves more frequent itemsets than IC-SAPM. However, when k gets larger, k -anonymization distorts the dataset too much, and most of frequent itemsets were lost during the anonymization process. As a consequence, for larger k and smaller  X  , the IC-SAPM protocol performs sig-nificantly better.

Figure 1(c) presents an average distortion that combines the changes of frequent itemsets and the changes of support values. The average distortion metric is defined as [4]: This figure presents similar results as discussed above. For small k and large  X  ,D k A-SAPM is better in term of average distortion rate. Otherwise, IC-SAPM should be utilized to mine frequent patterns without inference channels. Here we estimate the practical cost of D k A-SAPM and IC-SAPM. The primary cost is encryption; by computing the number of encryptions required, we can estimate the total cost based on implementation of the encryption tech-nique used. As stated in Section 3.2.2, The number of en-cryptions of D k A-SAPM is determined by  X  +  X  .

Since both D k A and FFI r require a homomorphic en-cryption scheme. We first estimate the cost to perform ho-momorphic encryptions. Most values that need to be en-crypted are either 0 or 1; therefore, the simulation adopts the homomorphic encryption scheme proposed in [18] (ef-ficient for 0 or 1 encryptions):  X  Public-Key : ( n, g, h, k ) , where n = p 2 q , g  X  ( Z  X  Secret-Key : ( p, q ) , where | p | = | q | = k .  X  Encryption : C = g m h r mod n , where m is the plain-We use the same parameters as those adopted in [18], especially the size of n = 1024 bits (commonly used in public key encryption, and r is random chosen from { 0 ,..., 2 130 } ). Next we present the cost in terms of the number of encryptions performed in 1 second:  X  Estimated cost -about 1546 homomorphic encryptions  X  Platform: Intel R Xeon TM 3 GHz processor, with 1 GB Because of the Supp F urther function, inside the D k A, only one iteration is required. Therefore, the  X  value is always the same regardless the various values of k and  X  . Since the size of the Mushroom dataset is 8124, we have  X  = 8124 2 = 65999376 . Based on our observation,  X  always dominate  X  , and the largest  X  value for k varying from 2 to 100 and  X  varying from 95% to 50% is 1332336 (  X  0 . 02  X   X  ). As a result,  X  alone is sufficient to estimate the time it takes to run D k A-SAPM: 1546 encryptions / s  X  X  X  12 hours to execute D k A-SAPM.

For IC-SAPM, we estimate the  X  +  X  values. Figure 2 shows that the number of encryptions increases as  X  de-creases. This is because with when support value is small, more itemsets are frequent. Consequently, the size of shared candidate set increases. In addition, the k value also deter-mines the size of  X  +  X  . When k increases,  X  is expected to decrease because the pruning process occurred at step 8 of Algorithm 11 will eliminate more frequent itemsets from F , so the number of calls to Secure COM decreases. Our estimates on  X  and  X  were based on the smallest support value (35%) used for the experiment. We also estimated that the average value for  X  +  X  is about 2477587. Therefore, we can calculate the expected time to perform IC-SAPM: 1546 encryptions / s  X  execution time is  X  0 . 5 hours. 5.4. D k A-SAPM vs. IC-SAPM
Here, we summarize certain key differences between the two protocols. For D k A-SAPM, a subset of data whose size smaller than k may be removed from the dataset due to suppression. These data can be considered as outliers, so by removing them from the dataset, more frequent itemsets can be preserved. As previously shown, for smaller k and larger  X  , we expect D k A-SAPM to produce better result. With large k values, k -anonymization generally distort the data too much. Under this situation, we prefer the second protocol IC-SAPM.

The complexity of D k A-SAPM increases quadratically as the size of the underlying data increases. Thus, D k A-SAPM does not scale well. On the other hand, if the size of F i r is not much bigger than the size of the underlying dataset, the complexity of IC-SAMP grows linearly on the size of the database.

From privacy-preserving perspective, D k A-SAPM is more secure than IC-SAPM. Nevertheless, since IC-SAPM only discloses a small set of frequent itemsets without ac-tual support values, such disclosure is very limited.
Two different and independent/orthogonal threats to in-dividual privacy may arise when sharing data mining results across multiple parties. One is how to collaboratively com-pute results without sharing actual (private) data, and the assuring that each possible information inferable from the output regards at least a given ( k parameter) number of in-dividuals. Although solutions for both problems have been studied and given separately, they are not directly composi-tional. Therefore, the problem of computing k -anonymous patterns in a distributed setting is challenging.

In this paper, we proposed two solutions: one is based on the concept of k -anonymous dataset and the other is based on the elimination of patterns imposing anonymity threat. We validated the two protocols through extensive empirical analyses. As for future research direction, it is useful and interesting to design a k -anonymization technique that pre-serves frequent itemsets. and to extend both D k A-SAPM and IC-SAPM to satisfy the security definition of a mali-cious adversary. The proposed protocols are not applicable when data is horizontally partitioned. Finding solutions un-der different environment is worthwhile for future pursuit. Acknowledgment The first author X  X  work is supported by the National Science Foundation under Grant Nos. 0312357 and 0428168. The second author X  X  work is funded by the EU project GeoP-KDD (IST-6FP-014915) . The authors wish to thank anony-mous reviewers for their valuable suggestions, as well as Fosca Giannotti, Dino Pedreschi and Franco Turini for their encouragement and support.

