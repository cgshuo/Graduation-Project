 Text summarization is a data reduc tion process. The use of text summarization enables users to reduce the amount of text that must be read while still assimilating the core information. The data reduction offered by text summarizati on is particularly useful in the biomedical domain, where physicians must continuously find clinical trial study information to incorporate into their patient treatment efforts. Such efforts are often hampered by the high-volume of publications. Our contribu tion is two-fold: 1) to propose the frequency of domain concepts as a method to identify important sentences within a full-text; and 2) propose a novel frequency distribution model and algorithm for identifying important sentences based on term or concept frequency distribution. An evaluation of several existing summarization syst ems using biomedical texts is presented in order to determine a performance baseline. For domain concept comparison, a recent high-performing frequency-based algorithm using terms is adapted to use concepts and evaluated using both terms and concepts. It is shown that the use of concepts performs closely with the use of terms for sentence selection. Our proposed frequency distribution model and algorithm outperforms a state-of-the-art approach. I.2.7 [ Natural Language Processing ]: Language Parsing and Understanding, Text analysis.
 Algorithms, Measurement, Performance, Experimentation. Text summarization, concept frequency, biomedicine. Text summarization is a data reduc tion process. The use of text summarization allows a user to get a sense of the content of a full-text, or to know its informati on content, without reading all sentences within the full-text. Th e reduction in the amount of data has the advantage of increasing scale by 1) allowing users to find relevant full-text sources more quickly, and 2) assimilating only essential information from many texts with reduced effort. There are two different approach es to generating summaries from text: extractive and abstractive [1]. The extractive approach extracts sentences or parts of sentences ve rbatim from text, and is the most common way to perform summa rization. The second and substantially more difficult approach is called abstractive , and involves generating summa ry text using natural language processing techniques. Our approach and evaluation uses the extractive approach. A set of identified sentences is used to form a final summary. The task of sentence selection can be considered an information retrieval task, where th e set of all sentences within a text are evaluated (scored), and the highest scoring sentences are selected as being the most relevant to a user. The data reduction offered by text summarization is particularly useful in the biomedical domain. The research presented here is motivated by the task of generating extractive text summaries useful to practicing oncologists, who must continuously find clinical trial study information related to their specialty, evaluate the study for its strength, and then possibly incor porate the new study information into their patient treatment efforts [2], [3]. The U.S. National Institutes of Health Clinical Trials database contains information on over 13,500 clinical trials [4]. In addition, treatment information may be found in databases such as PUBMED, which contains in excess of 12 million citations from over 4,800 journals [5]. These two sources alone make it impossible for a single physician to review every text and assimilate the information contained in them. The contributions of this work are: 1) to propose the frequency of domain-specific concepts as a feature for identifying salient sentences in biomedical texts; 2) the development of a new frequency distribution model a nd a corresponding algorithm which outperforms a state-of-the-art approach; and 3) the use of full-text biomedical sources rather than abstracts. We evaluate several existing, publicly-available summarization systems to determine a performance baseline with biom edical texts using existing approaches. We then evaluate two summarizers using both terms and concepts as unit items to show the use of concepts performs as well as or better than terms. The paper is organized as follows. Section 2 provides background on text summarization using item fre quency as a scoring feature. Section 3 presents a new mode l and algorithm using frequency distribution to score sentences. Sec tion 4 describes an evaluation of both existing summarization systems as well as recent algorithms using both term and concept frequency as a feature for sentence selection. Section 5 discusses the re sults of the evaluation. Section 6 provides concluding rema rks and suggests areas for future work. Clinical trial studies and other sc ientific publications usually supply a summary of the paper in the form of an abstract produced by the author(s) of a study. We have identified at least five reasons for wanting to generate text summaries from a full-text source even in the presence of the author X  X  abstract. 1) There exists no  X  X deal X  summary. An ideal summary is dependent on each user, including factors such as information need and domain background. An author X  X  abstract is one view of an ideal summary, but users may want alternative summaries. 2) The abstract may be missing content from the full-text [6]. 3) Customized summaries can be useful in question-answering systems where they provide personalized information. 4) The use of auto matic or semi-automatic summary generation by commercial abstract services may allow them to scale the number of published texts they can evaluate. 5) The generation and evaluation of summaries allows for evaluation of sentence selection methods that may be useful for use in multi-document summarization. The idea is that if sentence selection methods do not work well for single-document summarization, it is unlikely they will identify important data across multiple documents. One way to provide meaning to biomedical documents is by creating ontologies, and then linking information within each document to specifications contained in the ontology using a markup language [7]. Ontologies are conceptualizations of a domain that typically are represented using domain vocabulary [8]. Automatic semantic annotation is the process of mapping instance data to an ontology [9] [10]. The resulting annotations from the semantic annotation processing ar e what provide the link between information stored within a docum ent and the ontology [7]. In our work, the annotations are then used to identify important areas of a text useful for generating a text summary. In the biomedical domain, the National Library of Medi cine (http://www.nlm.nih.gov/) provides resources for identifying c oncepts and their relationships under the framework of the Unif ied Medical Language System (UMLS) [11]. UMLS contains ma ny sub-components, but we use only two: Metathesaurus and MetaMap Transfer. The UMLS Metathesaurus contains concepts and real-world instances of the concepts, including a concept name and its synonyms, lexical variants, and tran slations [12]. The Metathesaurus is derived from over 100 different vocabulary sources. Table 1 shows the example concept  X  X ultiple Myeloma X  taken from the Metathesaurus, and displays several of the concept instances associated with the concept. The instances are derived from the vocabulary sources. The key idea is that a single concept may have multiple ways of being expressed (instances). The Metathesaurus organizes the concept instances. The MetaMap Transfer (MMTx) application [13] maps biomedical text to concepts stored in the Metathesaurus as follows. The text-to-concept mapping in the MMTx application is done through a natural language processing approach. Sentences are first identified, and then noun phrases are extracted from each sentence. MMTx proceeds through several stages to map a noun phrase to one or more concepts. Term variants of the phrase are generated, candidate concepts are generated, and a scoring process is done for each candidate concept. The highest scoring concept is then selected as the concept for the phrase. It is possible a noun phrase can map to more than one concept. In this case, no disambiguation step is performed, and MMTx returns multiple concepts. Figure 1 shows an example of MMTx mapping of the phrase  X  X rotein kinase CK2 X . The output shows the phrase, the concept candidates preceded by their score ( X  X eta Candidates X ), and the final mapping of the phrase ( X  X eta Mapping X ). There are si x candidate mappings, shown in descending score order. The final mapping takes the highest scoring Meta Candidate (1000). In cases where a phrase cannot be successfully disambiguated, it is possible for MMTx to generate a final mapping consisting of more than one concept. Figure 1. MetaMap Transfer mappi ng of the phrase  X  X rotein kinase CK2. X  Term frequency was first used in extractive text summarization in the late 1950 X  X  [14]. A follow-up study of an analysis of five term frequency methods showed high ag reement in sentence selection among the methods [15]. Subseque nt research using frequency methods focused on the use of frequency as one feature among many for identifying important sentences, such as cue phrases [16] [17]. Summarization using larger units of text has also been researched. The LAKE system uses keyphrases for summarization [18]. The SUMMARIST system [19] uses WordNet [20] concept counting not for identifying salient sentences, but for topic interpretation. In topic interpreta tion, concept frequency counting is used to find a node in the concept hierarchy which sufficiently generalizes more specific concepts (e.g., {pear, apple}  X  fruit). The SUMMARIST authors cite the lack of domain-specific resources as a serious drawback to this approach. Our work uses domain-specific resources exclusivel y, but we have not used these resources for topic interpretation, only with sentence identification. Most recently, the SumBasic algorithm uses term frequency as part of a context-sensitive approach to identifying important sentences while reducing information redundanc y [21]. The use of frequency as a feature in locating important areas of a text has been proven useful in the literature [14] [15] [16] [17]. This is most likely due to reiteration, where authors state im portant information in several different ways, in order to reinforce main points [22]. Frequency-based summarization a pproaches count the appearance of items within the text, and then use the item counts to identify data that has been repeated within a text, which is presumed to be important because it appears multiple times. We call the unit to be counted a unit item . A unit item is frequently a term, but can also be another unit, such as a phrase or a concept. Our work focuses on the use of concepts as the unit items. In the evaluation phase described in Section 4, the unit items are c oncepts as well as terms (words excluding stop words) for the summarizers we implement. For publicly available summarizers in the evaluation, the term unit item is a word. Extractive approaches to text summarization usually follow a model of scoring sentences based on a set of features. The highest scoring sentences are then extracted to form a summary. When using frequency as the only feature, unit items are counted and then each sentence is given a score based on the frequency count of each unit item in the sentence. A key probl em in generating summaries is reducing redundancy. Each new se ntence in the summary should add new information rather than repeating already included information. Using the highest fre quency terms will likely result in the same information repeatedly be ing selected, with the chance that some additional information is included. In the SumBasic [21] frequency approach, a probability distribution model is first generated, and as each term is used to select sentences, the term probabilities are reduced so that lower probability terms have a better chance of selecting sentences with new information content. This approach is called context sens itivity. This is also related to the idea of finding Maximal Marginal Relevance (MMR), where marginal relevance is defined as finding relevant sentences which contain minimal similarity to previously selected sentences [23]. In this paper, we present a cont ext sensitive approach to scoring sentences based on a frequency dist ribution model rather than a probability distribution model. The rationale of our approach is that the frequency distribution of terms or concepts ought to appear in the generated summary as closely as possible to the source text. That is, the frequency distributi on models of the source and its summary should be as similar as possible. It is well known that terms in a text follows a Zipf distribution [24]. UMLS resources allow for working at the level of domain-specific concepts rather than terms. In order to use concepts within a frequency distribution model we firs t show that concepts within a biomedical text also follow a Zipfian distribution. To do this, we first used a corpus of biomedical full-text sources and extracted concepts from abstracts and their corresponding full-text using MetaMap Transfer. The corpus used includes 24 biomedical papers and is described in section 4.1. We used the paper abstracts as an ideal summary, and then compared the distribution models of concepts in the abstract vs. concep ts in the full-text. Figure 2 shows the two frequency distribution models. Figure 2(a) shows the distribution of 488 discovered con cepts across 24 paper abstracts, while Figure 2(b) shows 2,317 discovered concepts across 24 full-text papers corresponding to the 24 abstracts. As can be seen, both distributions can be characterized as Zipfian distributions. With the observation that both a version of an ideal summary and its corresponding full-text have the sa me frequency distribution form, we propose an algorithm to generate a summary based on the frequency distribution of the unit items (i.e., terms or concepts) within a full-text. Figure 2. Biomedical text concept distribution across 24 papers. (a) Distribution of 488 discovered biomedical concepts within the paper abstracts. (b) Dist ribution of 2,317 discovered biomedical concepts within the full-text of the papers. Figure 3 shows an outline of our algorithm ( X  X reqDist X ) to generate a summary given the full-text of some source (source text) using a frequency distribution approach. There are two stages: Initialization and Summary Generation. In the initialization stage, the unit items (terms, concepts, etc.) of the s ource text are counted to form a frequency distribution model of th e text, and a pool of sentences from the source text is created. A summary frequency distribution model is created from the unit ite ms found in the source text, and their frequency counts are initialized to zero. In the Summary Generation stage, new sentences are selected to be added to the summary. Identifying the next sentence to be added to the summary is accomplished by finding the sentence which most closely aligns the frequency distribution of the summary to the frequency distribution of the original source text. For each sentence in the sentence pool, a candidate summary is first initialized to the summary generated so far, and th en the sentence is added to the candidate summary. The candidate summary frequency distribution is then compared for similarity to the original source text frequency distribution. This similarity score is assigned to the sentence. After all sentences from the sentence pool have been evaluated for their contribution to the candidate summa ry, the highest scoring sentence is added to the summary and removed from the sentence pool. This process is iterative, and repeats until the desired length of the summary is reached. Figure 3: FreqDist: an algorithm for generating summaries using a frequency distribution approach. We compared five similarity functions to find which type of function worked best to evaluate a candidate summary X  X  frequency distribution to the original source text frequency distribution. Each frequency distribution (candidate su mmary and original source text) is modeled as a vector of unit ite ms. Similarity functions are then applied to the two vectors. Figur e 4 shows the five similarity functions used. The nota tions are as follows: ui is unit item; srcUIs and sryUIs are all unit items in source text or candidate summary, respectively; src(ui) and sry(ui) are indexed unit item in the source text or candidate summary, respec tively. Cosine similarity [25], Dice X  X  coefficient [26], Euclidean distance and vector subtraction [27] are all well-known vector comparison methods. In addition, an approach to vector model comparison considering only unit item frequency was tried [28]. Cosine si milarity uses the cosine angle value between the vectors for simila rity. Dice X  X  coefficient looks at the number of common terms between the two vectors. Euclidean distance measures the distance be tween the vectors in Euclidean space. For vector subtraction, the absolute value of the difference of each unit item in each vector is summed to form a distance score. The unit item frequency approach attempts to simulate cosine similarity without the computational complexity by only considering unit item frequency [28]. Figure 4: Similarity functions to evaluate a candidate summary X  X  frequency distribution to the original source text frequency distribution : (a) cosine similarity, (b) Dice X  X  coefficient, (c) Euclidean distance (d) unit item frequency, and e) vector subtraction. Notations used: ui is unit item; srcUIs and sryUIs are all unit items in source text and candidate summary, respectively; src(ui) and sry(ui) are indexed unit item in the source text or candidate summary, respectively. The purpose of the evaluation is to 1) evaluate the usefulness of concept frequency as a sole feature for identifying salient sentences for extractive text summarization, and 2) evaluate our proposed frequency distribution algorithm  X  X reqD ist X  described in Section 3. The evaluation was done by first asking three domain experts to manually generate extractive summa ries from 24 biomedical texts (see Section 4.1). A series of automated summarizers (in section 4.5) then generated summaries of the biomedical texts. The output of each summarizer is automatically compared using an automated tool called ROUGE [29] (see S ection 4.3). ROUGE generates several scores for each summary. The results are detailed in Section 5. The rest of this section gives details on the evaluation implementation. A corpus of 24 biomedical text s was generated from a citation database of oncology clinical tria l papers. The database contains approximately 1,200 papers physicians feel are important to the field [2]. Of the 1,200 papers cite d, 24 were randomly selected. The PDF versions of these papers were then obtained and converted to plain-text format. The papers we re manually processed to remove graphics, tables, figures, captions , citation references, and the bibliography section. The resulti ng text was further split into an abstract text and a full-text source text (without the abstract). The number of papers chosen ( 24) was based on the minimum requirements of the ROUGE summary evaluation tool [30] as well as the resources available to complete the manual processing of each paper. Our domain is biomedical text, sp ecifically oncology clinical trial result papers. The Unified Medi cal Language System (UMLS) Metathesaurus [12] is used as the semantic resource. Concept annotation of each paper is perfo rmed using the UMLS MetaMap Transfer tool [13] to perform te xt-to-concept mapping, as described in Section 2.2. When concepts ar e used in summary generation, it takes place in two stages: 1) biomedical concept annotation of the source text, and 2) summary gene ration from the concept-annotated text using the discovered concepts. The ROUGE (Recall-Oriented Understudy for Gisting Evaluation ) tool (version 1.5.5) [31] devel oped by the Information Science Institute at the University of S outhern California was used. ROUGE is an automated tool which compares a generated summary from an automated system with one or more ideal summaries. The ideal summaries are called models. ROUGE uses N-grams to determine the overlap between a summary and the models. An N-gram can be considered as 1 or more consecutive words. ROUGE was used in the 2004 and 2005 Document Understanding Conferences (DUC) [32] as the evaluation tool. We used the following parameters from the DUC 2005 conference: Two recall scores are extracted from the output of ROUGE to measure each summarizer: ROUGE-2 and ROUGE-SU4. ROUGE-2 evaluates bigram co-occurrence while ROUGE-SU4 evaluates  X  X kip bigrams X  with a maximum distance of 4 words. ROUGE-2 and ROUGE-SU4 are also the m easures used by DUC 2005. The recall scores indicate the N-gram overlap between the source text and the model summaries. It is difficult to compare ROUGE results outside of the corpus and model su mmaries used in the evaluation. For this reason, we gathered several summarizers from publicly-available sources in order to pr ovide some meaningful comparison among them using the same corpus and set of model summaries. To compare summaries generated automatically from systems, we used four models (i.e., four ideal summaries) for each of the 24 papers. The models represent differe nt versions of ideal summaries. The first model is the abstract of the paper (author X  X  summary). In addition, three models from thr ee different domain experts were generated. The domain experts are medical students in their final year. Each was given the task of performing extractive text summarization by selecting 20% of the sentences within a paper which formed the best summary for that paper. In this evaluation, six extractive summarizers are used. The BaseLine, FreqDist, and SumBasic summarizers were implemented for this evaluation, and each have multiple variations. The MEAD, Microsoft Word, and SWESUM summarizers are publicly available, and were randomly selected base d on their availability. MEAD and SWESUM are research prototypes, while the AutoSummarize feature in Microsoft Word is a commercial application. Each summarizer generated a summary th at was equal to 20% of the length of the source text. For exampl e, if a source text consists of 100 sentences, then 20 sentences are selected by the summarizer and presented as the summary. Selecting a summary size was problematic. The news summariza tion domain typically selects a size of less than five sentences. Th is represents about 20% of the size of a typical news story [33]. It has been generally thought that a summary should be no shorter than 15% and no longer than 35% of the source text [34]. The following is a brief description of the approaches used by each summarizer. The purpose of the baseline summarizers is to give some indication of the level of performance of a na X ve summarization implementation. Two baseline summarizers were implemented. The first baseline summarizer is called LEAD, and it sequentially selects the first 20% of sentences in th e source text. The second baseline summarizer is called RANDOM, and it randomly selects 20% of the sentences in the source text. Our FreqDist summarizer implements the algorithm described in Section 3. It can be used to select terms or concepts as the unit to perform frequency analysis on. There are five variations of the FreqDist summarizer. Each variation implements the same FreqDist algorithm in Figure 3, but uses a different vector similarity algorithm in Figure 4 to determine the similarity of unit item frequency distributions of the sour ce text and candidate summaries. When terms were used as unit items, a stop list was applied so that words having low information conten t (such as  X  X or X ) were removed. For the implementation using con cepts, the UMLS Metathesaurus was used as the domain-specific resource. MEAD [35] is a single-and multiple-document summarizer using multiple features to score sentences . Some of the features include position of sentence within the text , overlap of sentence with the first sentence, sentence length, and a centroid method based on a cluster of related documents. Fo r the evaluation, we used the http://tangra.si.umich.edu/clair/md/demo.cgi. No domain specific knowledge sources were provided to the summarizer. The AutoSummarize is a feature of the Microsoft Word [36] word processing software. AutoSummari ze is based on a word frequency algorithm. Each sentence in a document is given a score based on the words the sentence contains. Although the exact details of the algorithm are not documented, the online help for the product states that sentences using frequently-use d words are given a higher score than sentences containing low fre quency words. No domain specific knowledge sources were provided to the summarizer. The SumBasic algorithm [21] is a recent frequency-based algorithm. The original algorithm works using terms. For this evaluation, we have modified it so that the unit items can be terms or concepts. SumBasic incorporates a component for ensuring coverage of weaker concepts within a text. Ther e are four steps in the algorithm. The first is to determine the proba bility distribution of all concepts found within a source text by com puting the number of times a unit item appears in the text divided it by the total number of unit items found in the text. The second step is to score each sentence by summing the probabilities of all unit items within a sentence. The third step determines the sentence to be extracted by finding the highest-scoring sentence. The fourth step then reduces the probability of each unit item appeari ng in future extracted sentences by multiplying each probability of each unit item in the last extracted sentence by itself. The implementation using terms as unit items first had a stop word list applied. The stop list was the same list used for the FreqDist summarizer. For the implementation using concepts, the UMLS Metathesaurus was used as the domain-specific resource. This was done to compare the SumBasic approach with our proposed FreqDist algorithm, which can also use concepts as unit items. SweSum [37] is a multi-lingual summarizer for Swedish and English text. SweSum uses multiple features for scoring sentences, such as sentence position and numerical data identification. Sentences located earlier in a text are scored higher than sentences at the end of the text. Sentences containing numerical data are given additional weight. User-specified ke ywords can also be provided to boost sentence scores for those se ntences containing the keywords. For the evaluation we used the online version located at http://swesum.nada.kth.se/index-eng-adv.html. The text type was set to  X  X cademic X  and the summarization size was to 20%. No other parameters were set, and no domain specific knowledge sources were provided to the summarizer. The results of the evaluation usi ng ROUGE are shown in Tables 2 and 3. Each table is sorted in descending order based on the ROUGE score used. The best performing summarizer in each table is the first entry, while the lowest performing summarizer is listed as the last entry in each table. For the SumBasic and our FreqDist summarizer, two types of entries are listed: one entry using terms as unit items and the other entry usi ng biomedical concepts as unit items. Table 2 shows the ROUGE-2 scores for each summarizer. The best performing summarizes are the c ontext-based SumBasic and our FreqDist. The FreqDist summarizer, when using Dice X  X  coefficient for its similarity measure, outperforms all of the other summarizers using both terms and concepts as unit items. The performance of FreqDist using concepts and terms is close. This means that our FreqDist will also work well in a general domain that usually does not provide a way to find concepts due to lack of ontologies (or knowledge resources). The SumBas ic summarizer performs better using terms rather than concepts, where the use of terms scored one percentage point better than the use of concepts. Our FreqDist summarizer performs best when using Dice X  X  coefficient as the similarity measure between the summary and the source text. Dice is a measure of the common membership of unit items in the summary and source text. Other similarity measures, such as cosine, take into consideration not only membership, but also the weight (frequency) of each unit item. This leads us to conclude that our frequency distribution model approach (described in Section 3) requires no additional weighting of unit items to obtain good results. However, the use of frequency we ights for comparing source text and candidate summaries also pe rforms above both the baseline and general-purpose summarizers us ing Cosine and Unit Item Frequency. The use of frequency weights does not outperform the use of simple unit item membership. The worst performing summarizers are the ones based on the FreqDist algorithm using the Vector Subtraction and the Euclidean distance similarity measures (see Section 3 for details). These two similarity measures do not work well regardless of the unit items (i.e., terms or concepts). However, we note that in both methods, the use of concepts outperfo rms the use of terms The MEAD summarizer, which employs a combination of features (see Section 4.5.1.3) to identify significant sentences, outperformed the Random sentence and Lead se ntence baseline summarizers, and in fact fell just below the SumBasic and FreqDist summarizers in the performance table. The general purpose summarizers AutoSummarize and SweSum performed comparably, performing below the Random sentence baseline but above the Lead sentence baseline. This suggests to us th at the simple use of frequency without either additional features (MEAD) or context sensitivity (SumBasic/FreqDist) is not effective with the summarization of biomedical text. Table 3 shows the ROUGE-SU4 scores for each summarizer. In general, the ordering of the summarizer performance is about the same as in ROUGE-2. The best performing summarizers are the same as in ROUGE-2: our FreqDist and SumBasic. In both cases, the use of terms outperforms the use of concepts, but only by a margin of about 0.75 percentage points in both cases. Our FreqDist summarizer again performs best when using Dice X  X  coefficient as the similarity measure between the summary and the source text. The Cosine and Unit Frequency al so performed above the baseline and general-purpose summarizers. The use of the Vector Subtraction and Euclidean dist ance similarity methods with FreqDist was at the bottom of the performance list, as in ROUGE-2. The MEAD and FreqDist with Cosi ne similarity performed about the same using terms. The AutoSummarize and SweSum summarizers also performed closely, and were not much better than the Lead sentence summarizer. The Lead sentence baseline summarizer gave the worst performance when excluding the Vector Subtraction and Euclidean versions of FreqDist. The Random sentence baseline summarizer was in the middle of the performance table. It is interesting to note the baseline summarizer using random sentence selection performed nearly in the middle of the performance rankings for both ROUGE-2 and ROUGE-SU4. We are not sure how to interpret such high performance of random sentence selection. However, we do see that context sensitive methods such as SumBasic and our FreqDist methods significantly outperform the random baseline. Excluding the FreqDist summarizers using the Vector Subtraction and Euclidean distance methods, the use of the lead sentences (i.e., Baseline-Lead in Tables 2 and 3) of a biomedical text generates the worst performance. This is important to note, because in text summarization work using the news genre, the lead sentence method often generates a very good summary [33]. This is because news stories are usually written so that the most important information appears at the beginning of the text, and the least important information at the end. Ho wever, in biomedical texts this assumption is invalid, as shown in Tables 2 and 3. Using context-sensitive frequency methods, the use of concepts does not outperform the use of term s. However, terms and concepts perform closely. We find this va luable for building personalized summarizers that allow a user to select domain-specific concepts important to the user and then gene rate summaries for the user. It is easier for the user to select important concepts to summarize than important terms. This is because the concepts are defined for a domain, whereas terms are selected by author(s) of a paper and used in the text of the paper. To personalize a summary without domain-specific concepts, the user need s to know the important terms appearing in a text. In general, it is not easy for users to know terms in papers in advance before they read these papers. We proposed the frequency of domain-specific concepts as a feature for identifying salient sentences in biomedical texts. We presented an evaluation of several exis ting summarization systems to determine a performance baseline. We then evaluated a state-of-the-art frequency algorithm using bot h terms and concepts as item units to show the use of the frequenc y of concepts is as effective, and sometimes an improvement over, the use of frequency of terms. We developed a new algorithm based on frequency distribution modeling and evaluate it using terms as well as concepts. In either case, our frequency distribution algorithm outperforms a current state-of-the-art frequency-based algorithm at the cost of higher computational complexity. The use of concepts can be more useful in generating personalized summaries . An envisioned system allows a user to select domain-specific concepts important to the user, and then have the summarizer generate a summary where those concepts are more highly weighted than the concepts appearing in the source text. There are several areas of future work. We would like to determine an optimum size of a biomedical text summary. While much work has been done in the news domain, little work has been done in the biomedical domain, where the source text size is much larger and has multiple sections, each of which has varying importance to the overall content. We would also like to incorporate unit item frequency as an additional scoring feature into our existing summarization work based on lexical chaining of concepts [38]. For future evaluation work, we will include additional baseline summarizers to select sentences from throughout the text. For example, from the first sentence of each paragraph, each section, and so forth. Finally, we would like to use the FreqDist algorithm in the summarization of multiple biomedical source documents on the same topic. [1] S. D. Afantenos, V. Ka rkaletsis and P. Stamatopoulos, [2] A. D. Brooks and I. Sulima noff,  X  X vidence-based oncology [3] D. P. Jaques, Surgical Oncology Clinics of North America: [4] United States National Library of Medicine, [5] United States National Library of Medicine,  X  X ubMed, X  2005. [6] A. M. Cohen and W. R. Hersh,  X  X  survey of current work in [7] T. Berners-Lee, J. Hendler and O. Lassila,  X  X he Semantic Web, X  [8] B. Chandrasekaran, J. R. Jose phson and V. R. Benjamins,  X  X hat [9] L. Reeve and H. Han,  X  X  urvey of semantic annotation [10] L. Reeve and H. Han,  X  X  comparison of semantic annotation [11] United States National Librar y of Medicine,  X  X nified Medical [12] United States National Library of Medicine,  X  X MLS [13] United States National Library of Medicine,  X  X etaMap [14] H. P. Luhn,  X  X he Automatic Cr eation of Literature Abstracts, X  [15] G. J. Rath, A. Resnick a nd R. Savage. The formation of [16] J. J. Pollock and A. Zamora ,  X  X utomatic Abstracting Research [17] H. P. Edmundson,  X  X ew methods in automatic extracting, X  in I. [18] E. D X  X vanzo, B. Magnini and A. Vallin,  X  X eyphrase extraction [19] E. Hovy and C. Lin,  X  X  utomated text summarization in [20] C. Fellbaum, WORDNET: An Electroni c Lexical Database. [21] A. Nenkova and L. Vanderwe nde,  X  X he impact of frequency on [22] K. Sparck Jones,  X  X utom atic summarizing: Factors and [23] J. Carbonell and J. Goldstei n,  X  X he use of MMR, diversity-[24] G. Zipf, Human Behavior and the Principle of Least Effort. [25] R. Baeza-Yates and B. Ribeiro-Neto, Modern Information [26] L. R. Dice,  X  X easures of the amount of ecologic association [27] S. Subhash, Applied Multivariate Techniques. ,1st ed.USA: [28] D. L. Lee, H. Chuang a nd K. Seamons,  X  X ocument ranking [29] C. Lin,  X  X ecall-Oriented Understudy for Gisting Evaluation [30] C. Lin,  X  X ooking for a few good metrics: Automatic [31] C. Lin and E. H. Hovy,  X  X  utomatic evaluation of summaries [32] National Institute of Standards and Technology (NIST), [33] J. Goldstein, M. Kantrow itz, V. Mittal and J. Carbonell, [34] E. H. Hovy,  X  X utomated text summarization, X  in The Oxford [35] D. Radev, T. Allison, S. Blair-Goldensohn, J. Blitzer, A. [36] Microsoft Coporation,  X  X icrosoft Word 2002, X  2002. [37] H. Dalianis,  X  X weSum -A text summarizer for swedish, X  [38] L. Reeve, H. Han and A. D. Brooks,  X  X ioChain: Using lexical 
