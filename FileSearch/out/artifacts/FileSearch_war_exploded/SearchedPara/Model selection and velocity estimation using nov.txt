 As an observer moves through the environment, the retinal image changes over time to create mul-tiple complex motion flows, including translational, circular and radial motion. Human observers are able to process different motion patterns and infer ego motion and global structure of the world. However, the inherent ambiguity of local motion signals requires the visual system to employ an ef-ficient integration strategy to combine many local measurements in order to perceive global motion. Psychophysical experiments have identified a variety of phenomena, such as motion capture and motion cooperativity [11], which appear to be consequences of such integration. A number of com-putational Bayesian models have been proposed to explain these effects based on prior assumptions about motion. In particular, it has been shown that a slow-and-smooth prior, and related models, can qualitatively account for a range of experimental results [17, 15, 16] and can quantitatively account for others [7, 12].
 However, the integration strategy modeled by the slow-and-smooth prior may not generalize to more complex motion types, such as circular and radial motion, which are critically important for estimat-ing ego motion. In this paper we are concerned with two questions. (1) What integration priors should be used for a particular motion input? (2) How can local motion measurements be combined with the proper priors to estimate motion flow? Within the framework of Bayesian inference, the answers to these two questions are respectively based on model selection and parameter estimation. In the field of motion perception, most work has focused on the second question, using parame-ter estimation to estimate motion flow. However, Stocker and Simoncelli [13] recently proposed a conditioned Bayesian model in which strong biases in precise motion direction estimates arise as a consequence of a preceding decision about a particular hypothesis (left vs. right motion). The goal of this paper is to provide a computational explanation for both of the above questions using Bayesian inference. To address the first question, we develop new prior models for smooth rotation and expansion motion. To address the second, we propose that the human visual system has available multiple models of motion integration appropriate for different motion patterns. The visual system decides the best integration strategy based upon the perceived motion information, and this choice in turn affects the estimation of motion flow.
 comparing its predictions with human performance in psychophysical experiments, in which sub-We employ two commonly used stimuli, random dot patterns and moving gratings, to show that the model can apply to a variety of inputs. There is an enormous literature on visual motion phenomena and there is only room to summarize the work most relevant to this paper. Our computational model relates most closely to work [17, 15, 7] that formulates motion perception as Bayesian inference with a prior probability biasing towards slow-and-smooth motion. But psychophysical [4, 8, 1, 6], physiological [14, 3] and fMRI data [9] expansion. In particular, Lee et al [6] demonstrated that human performance on discrimination tasks smooth theory (our simulations independently verify this result). Instead, we propose that human motion perception is performed at two levels of inference: (i) model selection, and (ii) estimating the velocity with the selected model. The concept of model selection has been described in the literature, see [5], but has only recently been applied to model motion phenomena [13]. Our new motion models for rotation and expansion are formulated very similarly to the original slow-and-smooth model [17] and similar mathematical analysis [2] is used to obtain the forms of the solutions in terms of Greens functions of the differential operators used in the priors. 3.1 Bayesian Framework We formulate motion perception as a problem of Bayesian inference with two parts. The first part selects a model that best explains the observed motion pattern. The second part estimates motion properties using the selected model.
 1 ,...N } by maximizing The prior differs for different models M and is discussed in section 3.2.
 The likelihood function depends on the measurement process and is discussed in section 3.3.
 The best model that explains measurement { ~u } is chosen by maximizing the model evidence which is equivalent to maximizing the posterior probability of the model M (assuming uniform prior on the models): 3.2 The Priors expansion. For each motion type, we encourage slowness and smoothness. The prior for translation is very similar to the slow-and-smooth prior [17] except we drop the higher-order derivative terms and introduce an extra parameter (to ensure that all three models have similar degrees of freedom). M  X  { t,r,e } , where t,r,e denote translation, rotation, and expansion respectively. (We note that the prior for expansion will also account for contraction). and are common to all models. The first derivative term gives the differences among the models. The translation model prefers constant translation motion with ~v constant, since  X  ~v = 0 for this type of motion. The rotation model prefers rigid rotation and expansion, respectively, of ideal form { (again independent of ( x 0 ,y 0 ) and e ).
 The translation model is similar to the first three terms of the slow-and-smooth energy function similar to the slow-and-smooth model. 3.3 The Likelihood Functions The likelihood function differs for the two classes of stimuli we examined: (i) For the moving dot gratings stimuli [10], there is only enough information to estimate one component of the velocity field.
 For the dot stimuli, the energy term in the likelihood function is set to be For the gratings stimuli, see 2, the likelihood function uses the energy function gradient. 3.4 MAP estimator of velocities The MAP estimate of the velocities for each model is obtained by solving For the slow-and-smooth model [17], it was shown using regularization analysis [2] that this solution which imposes the slow-and-smoothness constraint (the precise form of this constraint was chosen so that G was a Gaussian).
 We can obtain similar results for the three types of models M  X  X  t,r,e } we have introduced in this paper. The main difference is that the models require two vector valued Green functions ~ G M 1 = ( G vector-valued Green functions are required to perform the coupling between the different velocity component required for rotation and expansion, see figure (1). For the translation model there is no coupling required and so G M 2 x = G M 1 y = 0 .
 G of rotation and expansion. Recall that G M 1 y = G M 2 x and G M 2 y = G M 1 x .
 The estimated velocity for the M model is of the form: For the dot stimuli, the {  X  } , {  X  } are obtained by solving the linear equations: g spectively, then we can express these linear equations as: Similarly for the gratings stimuli, similarly for  X  g M 1 y ,  X  g M 2 x and  X  g M 2 y . 3.5 Model Selection We re-express model evidence p ( { ~u }| M ) in terms of ( A,B ) : We introduce new notation in the form of 2 N  X  2 N matrices: g M =  X  g The model evidence for the dot stimuli can be computed analytically (exploiting properties of multi-dimensional Gaussians) to obtain: Similarly, for the gratings stimuli we obtain: where  X   X  = (  X  g M ) T  X  g M + g M . We first investigate motion perception with the moving dots stimuli used by Freeman and Harris [4], as shown in figure (2). The stimuli consist of 128 moving dots in a random spatial pattern. All the dots have the same speed in all three motion patterns, including translation, rotation and expansion. Our simulations first select the correct model for each stimulus and then estimate the speed threshold of detection for each type of motion. The parameter values used are  X  = 0 . 001 ,  X  = 12 . 5 ,  X  = 78 . 125 and T = 0 . 0054 . expansion. 4.1 Model selection evidence decreases for all models. This is due to slowness term in all model priors. Nevertheless the Figure 3: Model selection results with random dot motion. Plots the log probability of the model as expansion stimuli. Green curves with cross are from translation model. Red curves with circles are from rotation model. Blue curves with squares are from expansion model. 4.2 Speed threshold of Detection As reported in [4], humans have lower speed threshold in detecting rotation/expansion than trans-lation motion. The experiment is formulated as a model selection task with an additional  X  X tatic X  motion prior. The  X  X tatic X  motion prior is modeled as a translation prior with  X  = 0 and  X  sig-nificantly large to emphasize slowness. In the simulation,  X  = 0 . 3 for this  X  X tatic X  model, while  X  = 0 . 001 for all other models.
 At low speed, the  X  X tatic X  model is favored due to its stronger bias towards slowness, as stimulus motion patterns can be seen from the model evidence plots in figure (4), and they are lower for rotation/expansion than translation. The threshold values are about 0.05 for rotation and expansion and 0.1 for translation. This is consistent with experimental result in [4]. Upper right panel: model evidence plot for rotation stimuli. Lower left panel: model eviddence plot for expansion stimuli. Lower right panel: bar graph of speed thresholds. 5.1 Stimuli When randomly oriented grating elements drift behind apertures, the perceived direction of motion tures. Recently, Nishida and his colleagues developed a novel global motion stimulus consisting of a number of gratings elements, each with randomly assigned orientation [10]. A coherent motion is perceived when the drifting velocities of all elements are consistent with a given velocity. Ex-amples of the stimuli used in these psychophysical experiments are shown in left side of figure (6). The stimuli consisted of 728 gratings (drifting sine-wave gratings windowed by stationary Gaus-sians). The orientations of the gratings were randomly assigned, and their drifting velocities were determined by a specified global motion flow pattern. The motions of signal grating elements were consistent with global motion, but the motions of noise grating elements were randomized. The clockwise/counterclockwise for rotation, and inward/outward for expansion. Motion sensitivity was measured by the coherence threshold, defined as the proportion of signal elements that yielded a performance level of 75% correct.
 Similar stimuli with 328 gratings were generated to test our computational models. The input for the models is the velocity component perpendicular to the assigned orientation for each grating, as illustrated in the upper two panels of figure (5). Figure 5: Randomly-oriented grating stimuli and estimated motion flow. Upper left panel: rotation stimulus (with 75% coherence ratio). Upper right panel: expansion stimulus (with 75% coherence ratio). Lower left panel: motion flow estimated from stimulus in first panel with rotation model. Lower right panel: motion flow estimated from stimulus in second panel with expansion model. 5.2 Result The results of psychophysical experiments (middle panel of figure 6) showed worse performance for perceiving translation than rotation/expansion motion [6]. Clearly, as shown in the third panel of the same figure, the model performs best for rotation and expansion, and is worst for translation. This finding agrees with human performance in psychophysical experiments. Humans motion sensitivities depend on the motion patterns (translation/rotation/expansion). We propose a computational model in which different prior motions compete to fit the data by levels drifting velocity of each grating. Middle panel: human coherence thresholds for different motion stimuli. Right panel: Model prediction of coherence thresholds which are consistent with human trends. of inference. This analysis involves formulating two new prior models for rotation and expansion model and deriving their properties. This competitive prior approach gives good fits to the empirical data and accounts for the dominant trends reported in [4, 6].
 Our current work aims to extend these findings to a range of different motions (e.g. affine motion) and to use increasingly naturalistic appearance/intensity models. It is also important to determine if motion patterns to which humans are sensitive correspond to those appearing regularly in natural motion sequences.

