 Search result diversi cation aims at returning diversi ed document lists to cover different user intents for ambigu-ous or broad queries. Existing diversity measures assume that user intents are independent or exclusive, and do not consider the relationships among the intents. In this paper, we introduce intent hierarchies to model the relationships among intents. Based on intent hierarchies, we propose sev-eral hierarchical measures that can consider the relation-ships among intents. We demonstrate the feasibility of hi-erarchical measures by using a new test collection based on TREC Web Track 2009-2013 diversity test collections. Our main experimental ndings are: (1) Hierarchical measures are generally more discriminative and intuitive than exist-ing measures using at lists of intents; (2) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more im-provement in discriminative power; (3) Hierarchical mea-sures are more intuitive in terms of diversity or relevance. The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.
 Ambiguity; Diversity; Evaluation; Novelty; Hierarchy
Nowadays, people tend to meet their daily information needs by typing keywords into search engines like Google and Bing. However, these keywords, also known as queries, are often ambiguous or broad [14, 15, 28, 10]. The queries usually have several interpretations or aspects, also known as subtopics or user intents. When users submit the same query to retrieval systems, they may want different informa-tion returned to ful ll their information needs. This poses Corre sponding author a challenge to search engines when the targeted user intent cannot be known in advance.

To tackle this problem, a wide range of search result di-versi cation algorithms ([1, 2, 5, 13, 18, 26, 27, 31, 25, 12, 11]) have been proposed over the past years. They aim at returning a diversi ed ranked document list that covers dif-ferent intents of the queries. In the meantime, some re-searchers have introduced a variety of diversity measures, such as I-rec [22], -nDCG [9], Intent-Aware measures [1], D  X  -measures [24], etc. These measures evaluate ranked lists in terms of both diversity and relevance, and indicate which diversi cation algorithms are better to use. Existing diver-sity measures assume that the users' information need could be represented by a single layer of intents and these intents are either independent or exclusive. However, some of the intents are not independent and are related to each other. We use the query \bobcat", which is a topic (No. 77) in Text Retrieval Conference(TREC) 2010 Web Track [8], as an example. This query is ambiguous because of the pol-ysemy of \bobcat": one interpretation is a company called \bobcat company" whose core business is about tractors; another interpretation is a kind of wild animals called \wild bobcat." We show its official intents, marked by i 1 -i 4 Figure 1(a). The gure shows that except intent i 2 that is about \wild bobcat," the remaining ones, i 1 , i 3 , and i all about \bobcat company." This indicates that i 1 , i 3 i are more related to each other, but are less related to i Even within the three intents about \bobcat company," i 1 and i 3 are closer because they are about the trade involving tractors of the company, whereas i 4 is about homepage the company. We argue that this kind of relationships among intents should be modeled when evaluating search result di-versity. However, none of existing measures considers this.
Speci cally, we nd two submitted runs for the query, cmuFuTop10D and THUIR10DvNov , in TREC Web Track 2010 diversity task. cmuFuTop10D covers i 1 , i 3 , and i while THUIR10DvNov covers i 1 , i 2 , and i 4 in their top ten ranks. Since i 1 , i 3 , and i 4 are all about \bobcat company," cmuFuTop10D misses another interpretation of bobcat, i.e. \wild bobcat," but THUIR10DvNov covers both interpreta-tions. In this sense, the latter is more diversi ed but I-rec [22] treats them as equally good because they cover the same number of intents. Some other existing measures also have similar problems, which will be illustrated in Section 3.3.1. We think that this is due to their lack of recognition of the relationships among intents.

In light of the above observation, we introduce intent hi-erarchies to represent the relationships among intents. We 77 query \bobcat" in TREC Web Track 2010. design hierarchical measures using the intent hierarchies to solve the problems mentioned above. The main contribu-tions of this paper are: (1) To the best of our knowledge, this is the rst work on modeling user intents as intent hierarchies and using the intent hierarchies for evaluating search result diversity. (2) We propose hierarchical measures using intent hierar-chies, including Layer-Aware measures, N-rec, LD  X  -measures, LAD  X  -measures, and HD  X  -measures. We show several cases where hierarchical measures outperform existing measures in terms of discriminative power and intuitiveness. (3) We present a method for creating intent hierarchies from existing diversity test collections, and reusing the rel-evance assessments. We create a new dataset based on the TREC Web Track 2009-2013 diversity test collections. The new dataset can be assessed online 1 . (4) We compare our measures with existing measures. We nd that (i) Hierarchical measures are generally more dis-criminative and intuitive than existing measures, especially when using the intent hierarchies whose leaf nodes have the same depth; (ii) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to ex-isting measures, but can get more improvement in discrimi-native power; (iii) The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.

The remainder of this paper is organized as follows. Sec-tion 2 describes some existing diversity measures and the methods for testing evaluation measures. In Section 3, we introduce intent hierarchies, and our method for creating a new test collection based on TREC Web Track 2009-2013 di-versity test collections. We then propose several new diver-sity measures that can utilize the intent hierarchies. Section 4 describes experimental results and analysis. We conclude our work in Section 5.
Given a query q , most existing measures evaluate a ranked document list by modeling users' information need as a at list of intents f i g . Some measures can handle intent prob-ability P r ( i j q ) and graded relevance assessments but some cannot. In this section, we brie y summarize the previous work on designing and testing diversity measures. h ttp://www.playbigdata.com/dou/heval/
Intent recall(I-rec) [22], also known as subtopic recall [30] is the proportion of intents covered by a ranking list. Let d denote the document at rank r , and let I ( d r ) denote the set of intents to which document d r is relevant. Then, I -rec for a certain cutoff K can be expressed as:
No te that I-rec does not take the positions of relevant doc-uments into account, and cannot handle intent probability and graded relevance assessments.
In order to balance both relevance and diversity of ranked lists, -nDCG [9] is de ned as: where N G ( r ) is N G ( r ) in the ideal ranked list; J i 1 if the document at rank r is relevant to intent i , and 0 otherwise; C i ( r ) = documents to intent i within top r ; and is a parameter. -nDCG tends to disregard unpopular intents and hence can be counterintuitive sometimes [24].
Intent-Aware measures ( IA measures ) [1] is a general framework to evaluate ranked document lists. Assuming that where M i is the per-intent version of measure M. Measure M can be nDCG [16], ERR [4], nERR [7], etc.
D  X  -measures [24] aim to boost intent recall, and to reward documents that are highly relevant to more popular intents. Assume that g i ( r ) is the gain value of the document at rank r for intent i , and g i ( r ) is calculated based on per-intent relevance assessments. Then the global gain at rank r is given by:
Let CGG ( r ) = global gain at rank r . Further, let GG ( r ) and CGG ( r ) denote the global gain and the cumulative global gain re-spectively at rank r in the ideal ranked list. The ideal list is obtained by listing up all relevant documents in descending order of global gains. Let J ( r ) = 1 if the document at rank r is relevant to any of the intents f i g , and J ( r ) = 0 otherwise. Let C ( r ) = uments within top r . D -nDCG and D -Q at document cutoff K are de ned as: where R is the number of judged relevant documents. Then D X  -measure is de ned as: where D -measure can be D-nDCG or D-Q, and is a pa-rameter controlling the tradeoff between diversity and rel-evance. D  X  -measures are free of the under-normalization problem of -nDCG and IA measures.

The diversity measures mentioned above are widely used in several tasks of TREC Web Track 2 or NII Testbeds and Community for Information access Research (NTCIR) 3 , but they do not take the relationships among intents into con-sideration , which is what we aim to deal with in this paper.
Given a certain signi cance level, discriminative power measures the stability of measures across queries and ex-periments based on signi cance tests, e.g. paired bootstrap test [20], Tukey's Honestly Signi cant Differences(HSD) [3] test, etc. Discriminative power can be used to estimate the performance difference required to achieve statistical signif-icance between two retrieval systems [21].

Concordance test [21] is proposed to quantify the intuitive-ness of diversity measures. In concordance test, one or more gold standard measures are chosen and assumed to truly rep-resent intuitiveness. Given two diversity measures M 1 and M 2 , the relative intuitiveness of M 1 (or M 2 ) is measured in terms of preference agreement with the gold standard mea-sures. The preference agreement is that M 1 (or M 2 ) agrees with the gold standard measure(s) about which one of two ranked lists should be preferred.

Rank correlation compares two rankings, which are two ranked system lists in our case. Kendall's [17] is a widely-used statistic to measure rank correlation. However lacks the property of top heaviness, which means the exchanges near the top of a ranked list and those near the bottom are treated equally, even though the swaps near the top is generally more important in the context of IR evaluation. ap [29] is proposed to deal with the problem. Note that is symmetric but ap is not. However, a symmetric ap can h ttp://plg.uwaterloo.ca/~trecweb/ http://research.nii.ac.jp/ntcir/index-en.html be obtained by averaging two ap values when each list is treated as the former one. Both and ap range from -1, which implies two ranked lists perfectly disagree, to 1, which implies two ranked lists are identical.

In this paper, we use discriminative power, concordance test, and rank correlation to evaluate diversity measures.
In this section, we de ne two types of intent hierarchies to represent the relationships among user intents and dis-cuss their properties. We then introduce our method for creating such intent hierarchies and obtaining relevance as-sessments for the intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Last, we propose several diversity measures based on intent hierarchies, and demonstrate that in some cases, the new measures outper-form their corresponding existing measures.
Given a query q , the users' information need is represented as a set of intents f i g . We assume these intents cannot be further subdivided, and refer to them as atomic intents . We aim to build an intent hierarchy based on the semantic similarity or relatedness of the intents. The intent hierarchy should possess some basic properties as follows:
Property 1. The intent hierarchy is in a tree structure, where every child has only one parent.

Property 2. The root of intent hierarchy is denoted by q itself, which stands for the user's information need as a whole. The root is a dummy node only for the completeness of the tree, and is not considered in our measures.
Property 3. When q is broad, the intent hierarchy is built in such a way that a parent node refers to a more general concept than its children, and a child node refers to one aspect of its parent. When q is ambiguous, each child node of the root is one interpretation of the query, and each of its subtrees is built in the same way as a broad query.
Property 4. These atomic intents, i.e. f i g , correspond one to one with leaves of the intent hierarchy. This means the number of leaves in the intent hierarchy is the same as the number of the atomic intents.
 We call an intent hierarchy that satis es the properties spec-i ed above is called an original intent hierarchy ( OIH ). OIH can be extended so as to satisfy an extra property as:
Property 5. These atomic intents are in the same layer of the intent hierarchy. In other words, all leaf nodes of the intent hierarchy have the same depth because the atomic in-tents correspond to leaves of the intent hierarchy (see Prop-erty 4).
 An intent hierarchies that satis es all ve properties are called an extended intent hierarchy ( EIH ). If a query's OIH satis es Property 5, then its EIH is the same as the OIH.
We consider the root of an intent hierarchy as the zeroth layer, the child nodes of the root as the rst layer and so forth. If an intent hierarchy only has the zeroth layer and the rst layer, the height of the intent hierarchy is one. In the paper, a single-layer intent hierarchy refers to an in-tent hierarchy whose height is one, while a multilayer intent hierarchy refers to that whose height is greater than one. In this paper, we create intent hierarchies based on TREC Web Track 2009-2013 diversity test collections. Note that for each query in TREC Web Track 2010-2013, the description of its rst intent is the same as the description of the query itself. We nd that although the descriptions are the same, if a query has several different interpretations, the rst intent is just one of these interpretations. A query's rst intent does not refer to a more general concept than the other intents. So we do not treat the rst intent differently.
We use the official intents as atomic intents to avoid re-assessing relevance of the documents. First we create origi-nal intent hierarchies (OIH) by manually grouping the offi-cial intents based on their semantic similarity or relatedness. Then, we extend them to extended intent hierarchies (EIH). Figure 1 illustrates how we create OIH and EIH for the query \bobcat"in TREC 2010 Web Track. It can be seen from Fig-ure 1(a) that this query has four official intents and intent i and i 3 are related to the trade involving tractors of the \bobcat company." So we create a new node n 1 that stands for \bobcat tractors" as their parent node. Similarly, n 1 i are related to \bobcat company," hence we create another new node n 2 representing\bobcat company"as their parent. Finally, since n 2 (\bobcat company") and i 2 (\wild bobcat") are two distinct interpretations of query \bobcat," they are considered as the child nodes of the root node. The resul-tant OIH is shown in solid boxes in the left of Figure 1(b). Further, we extend the OIH by adding more child nodes to i 2 and i 4 to make sure that all the leaf nodes have the same height. The resultant EIH is shown in solid boxes plus dashed boxes in the left of Figure 1(b).

For a leaf node, we use its original weight of the corre-sponding official intent as its initial weight. For an inter-mediate node, we set its original weight to the sum of its child node weights. We then normalize the weights for each layer to make sure that these weights sum to 1. For TREC Web Track 2009-2013 test collections, because of the lack of official intent weights, we assume that each official intent for a query is equally important.

As for the OIH or EIH shown in Figure 1(b): (1) It is in a tree structure (Property 1); (2) Its root is query \bob-cat" itself (Property 2); (3) The query is ambiguous, so the child nodes of root are its two different interpretations, i.e. \bobcat company" and \wild bobcat." A parent node refers to a more general concept than its children (Property 3), e.g. \bobcat company" is more general than \bobcat com-pany homepage;" (4) The leaf nodes are exactly the official intents of query \bobcat" (Property 4). Further, the depth of all the leaf nodes in EIH is three (Property 5).
Note that we only have document relevance assessments for the original intents appeared in TREC Web Track di-versity test collections. In other words, for the intent hi-erarchies we create, document relevance judgments are just available for their leaf intents. We do not have document relevance assessments for intermediate intents. As assess-ing document relevance is usually very time-consuming, it is not desirable to reassess the documents for intermediate nodes of the intent hierarchies. Fortunately, according to Property 3, a parent node of an intent hierarchy stands for a more general concept than its child nodes. Hence it is rea-sonable to assume that if a document is relevant to a node, it would be relevant to the node's parent. This means that we can derive relevance assessments for the intermediate nodes starting from the leaves. In this paper, we simply let: where L d ( n ) is the relevance rating assigned to document d for node n , and C ( n ) is the set of child nodes of n .
We show an actual document (denoted by d in the follow-ing) from TREC Web Track 2010 diversity test collection in Figure 1(b). In the table, the officially provided relevance assessments are marked in blue, e.g. the relevance rating of d for i 1 is 1. Firstly, node n 1 has two child nodes, i and i 3 , and the relevance ratings of d for them are 1 and 0. According to Equation (8), the relevance rating of d for n 1 is 1. Similarly, we can derive the relevance rating for n based on its child node i 4 and n 1 . These derived relevance assessments are shown in red in the table of Figure 1(b).
To conclude, we create a new dataset containing intent hierarchies by manually grouping the official intents from TREC Web track test collections. The good news is that we do not need to reassess document relevance with regards to the intent hierarchies. We directly leverage document relevance assessments for the leaf intents, and automatically assign relevance ratings for the intermediate intents. This also implies that when we want to create hierarchical intents for evaluating diversity, we just need to assess document relevance for the leaf nodes or atomic intents.

The new test collection has 250 queries, and 105 topics have multilayer intent hierarchies. Most of the time of creat-ing the new dataset is spent on grouping the original intents. On average, we spend about three minutes per query mainly in understanding the original intents with the assistance of search engines such as Bing and Google.
Given a query q and its intent hierarchy, our rst proposal for evaluating a ranked list is to rst evaluate the ranked list for each layer using existing measures, then combine the evaluation scores.
 Let H denote the height of the intent hierarchy, and let de ne Layer-Aware measures ( LA measures ) at document cutoff K as the follows.

Here, w i is the weight of layer l i , where and M i is the evaluation score of measure M by using the intents of layer l i . For example, ERR-IA-LA is computed as follows: (1) For each layer, compute the per-layer scores of ERR-IA; (2) Compute the weighted average of the per-layer scores using Equation (9).

We nd that the combination of measures over layers of intent hierarchies could outperform the original measures using a at list of intents. We use the query \defender", which is a topic (No. 20) in TREC Web Track 2009 [6], as an example. We choose this query because it has a relatively simple intent hierarchy. Its extended intent hierarchy (EIH) is shown in the left of Figure 2(b). Suppose we have three documents, d 1 -d 3 , and each of them can be viewed as a ranked list containing only one document. Their relevance assessments for the EIH are displayed in blue in the right of of EIH and subscript 2 means only using the second layer. subscript the original I-rec is equal to I-rec 2 .
 Figure 2(b). Note that the nodes that receive no relevant documents within the documents are not displayed to save space. Assume d is the rst document within the ideal rank list and it is relevant to every node displayed. In the right of Figure 2(b), D  X  -nDCG 1 @1 is the evaluation score when only using the rst layer of the EIH, D  X  -nDCG 2 @1 means only using the second layer, and D  X  -nDCG-LA E @1 is the average of D  X  -nDCG 1 @1 and D  X  -nDCG 2 @1. Note that the original D  X  -nDCG is equal to D  X  -nDCG 2 . We use the measures to score d 1 to d 3 , which is equivalent of evaluating at document cutoff 1. We show the evaluation results in Figure 2(b), e.g. d gets 0.35 when using D  X  -nDCG 1 @1.

We nd that d 1 &gt;d 2 = d 3 in terms of D  X  -nDCG 1 @1, d in terms of D  X  -nDCG 2 @1, whereas d 1 &gt;d 2 &gt;d 3 in terms of D  X  -nDCG-LA E @1. Here, \ &gt; " means the former document is preferred compared with the latter when evaluating them at rank 1, and\="means neither is preferred. The real pref-erence should be d 1 &gt;d 2 &gt;d 3 . This is because (1) d diversi ed than d 2 because d 1 refers to two interpretations of query \defender", i.e. \windows defender" and \defender arcade game online," while d 2 only refers to the former; (2) d 2 is more diversi ed than d 3 because d 2 refers to two as-pects of \windows defender", i.e. \windows defender home-page" and \windows defender reports" while d 3 just refers to the former. Here, only D  X  -nDCG-LA E @1 is consistent with the real preference. D  X  -nDCG 1 @1 fails to tell the difference between d 2 and d 3 , whereas D  X  -nDCG 2 @1 fails to tell the difference between d 1 and d 2 . This indicates that the com-bination over layers has higher potential to re ect real user satisfaction than the use of a at list of intents in some cases.
Given a query q , let V denote the nodes in its intent hi-erarchy except for its root. Let d r denote the document at rank r , and let N ( d r ) denote the set of nodes in V to which d r is relevant. Given a document cutoff K , we de ne node recall ( N -rec ) as: wh ich is the proportion of nodes in the hierarchy covered by the top K documents. N-rec is a natural generalization of I-rec when using the intent hierarchy rather than a at list of intents. They both are rank-insensitive and cannot handle graded relevance assessments.

We use an example to show that N-rec is able to outper-form I-rec in terms of discriminative power. In the right of Figure 2(b), I-rec 1 @1 means only using the rst layer, I-rec 2 @1 means only using the second layer, and N-rec E means using the extended intent hierarchy (EIH) when com-puting N-rec. These measures are computed at rank 1. Note that the original I-rec is equal to I-rec 2 . We nd that d &gt;d 2 = d 3 according to I-rec 1 @1, d 1 = d 2 &gt;d 3 according to I-rec 2 @1, whereas d 1 &gt;d 2 &gt;d 3 according to N-rec we discussed in Section 3.3.1, The real preference should be d &gt;d 2 &gt;d 3 . I-rec 1 @1 fails to tell the difference between d and d 3 , while I-rec 2 @1 fails to distinguish between d d . Only N-rec E @1 can tell the difference between the three documents, and thus is more discriminative than I-rec.
Another point worth noting is that the types of intent hierarchies are crucial to N-rec. In the right of Figure 2(b), N-rec O @1 means using the original intent hierarchy (OIH) instead of EIH. We nd that N-rec O @1 cannot determine which one of d 1 and d 2 is better because they have exactly the same score. This indicates that using EIH has higher discriminative power than using OIH.

We aim to retrieve documents that cover as many nodes of intent hierarchies as possible. At the same time, we pre-fer the documents that are highly relevant to more popular nodes and layers. N-rec mainly rewards wide coverage of different nodes of intent hierarchies in the top ranks. In the following, we discuss some measures to complement N-rec. We use the leaf nodes of intent hierarchies to compute D-measures. Then, LD X  -measure is de ned as: where is a parameter controlling the tradeoff between di-versity and relevance. Since D-measures only use the leaves of intent hierarchies, LD  X  -measures reward high relevance with more popular leaves, but do not reward high relevance with more popular intermediate nodes. Also, LD  X  -measures cannot handle the weights of layers. To tackle these, we pro-pose HD  X  -measures and LAD  X  -measures in the next section.
Inspired by D  X  -measures, we de ne the global gain for an intent hierarchy at rank r as: where w i is the weight of layer l i and GG i ( r ) is the global gain for layer l i at rank r . Let CGG h ( r ) = which is the cumulative global gain for the intent hierarchy at rank r . Further, let GG h ( r ) and CGG h ( r ) denote the global gain and the cumulative global gain for the intent hierarchy at rank r in the ideal ranked list. The ideal list is obtained by listing up all the judged documents in de-scending order of global gains for the intent hierarchy. Let J ( r ) = 1 if the document at rank r is relevant to the intent hierarchy, and J ( r ) = 0 otherwise. Let C ( r ) = We de ne HD -nDCG and HD -Q at document cutoff K as: where R is the number of judged documents relevant to the intent hierarchy. We de ne HD X  -measure as: where HD -measure can be HD-nDCG or HD-Q, and is a parameter controlling the tradeoff between diversity and relevance. Besides, We de ne LAD X  -measure as: where is a parameter balancing diversity with relevance, and D-measure-LA is the LA version of D-measure.

To measure the relevance of ranked lists, HD  X  -measures use HD-measures, while LAD  X  -measures use D-measures-LA. HD-measures and D-measures-LA reward high relevance to more popular nodes, and can handle layer weights. The difference between them is what to combine over layers: HD-measures combine the global gain for each layer while D-measures-LA combine D-measures for each layer. Take HD-nDCG and D-nDCG-LA as an example: where GG i ( r ) is the global gain for layer l i at rank r , and D -nDCG i means only using the nodes of layer l i . Fi gure 3: Relationships of D  X  -measures, LD  X  -measures, HD  X  -measures, and LAD  X  -measures.
Since our measures use intent hierarchies, we call them hierarchical measures . Each of D  X  -measures, LD  X  -measures, HD  X  -measures and LAD  X  -measures is a linear combination of two measures: one measure mainly rewards the diversity of ranked lists, whereas another measure mainly rewards the relevance. We show their relationships in Figure 3. It can be seen that (1) To reward the diversity, LD  X  -measures, HD  X  -measures and LAD  X  -measures use the whole intent hi-erarchy, whereas D  X  -measures only use the leaf nodes; (2) To reward the relevance, HD  X  -measures and LAD  X  -measures use the whole intent hierarchy, whereas D  X  -measures and LD  X  -measures only use the leaf nodes. We experiment with the proposed measures on the TREC Web Track 2009-2013 diversity test collections and the new test collection mentioned in Section 3.2. The new test col-lection has two types of intent hierarchies, i.e. the original intent hierarchies (OIH), and the extended intent hierarchies (EIH). The results of our measures using OIH are different from those using EIH. In the following, subscript O means using the OIH, while subscript E means using the EIH. We use uniform probabilities for official intents like in TREC Web Track 2009-2013 diversity task. We use uni-form layer weights when computing our measures, and leave the investigation of nonuniform weights to future. Unless stated otherwise, we use document cutoff K = 20 for all measures, and = 0 : 5 in Equation (7, 11, 15, and 16).
Following the previous work [19, 20, 23, 24, 21], we use the paired bootstrap test and set B = 1 ; 000 (B is the number of bootstrap samples). When the queries have single-layer in-tent hierarchies: (1) LA measures are reduced to their corre-sponding existing measures. For example, D  X  -measures-LA are reduced to D  X  -measures; (2) LD  X  -measures, HD  X  -measures, and LAD  X  -measures are reduced to D  X  -measures. We con-duct the experiments as follows: (1) Sampling 20 submitted runs every year (2009-2013), which produces 950 pairs of each row, the greatest value is in bold. T able 2: Discriminative power (shown in columns A) and performance  X  (shown in columns B) of diver-sity measures ranked by their discriminative power based on the paired bootstrap test at = 0 : 05 . Base-line measures are marked by . sa mpled runs in total; (2) With the 950 pairs of sampled runs, computing the discriminative power and performance  X  using all 250 queries in TREC Web Track 2009-2013 diver-sity test collections; (3) With the 950 pairs of sampled runs, computing the discriminative power and performance  X  us-ing the 105 queries that have multilayer intent hierarchies. Performance  X  is the required value to achieve statistical signi cance, and is computed following [21]. The results are shown in Table 1 and Table 2.

By comparing the discriminative power scores of exist-ing measures and their corresponding LA measures based on OIH or EIH in each row of Table 1, we nd that: (1) Except -nDCG-LA, LA measures using EIH are more dis-criminative than their corresponding existing measures, es-pecially in the case of IA measures. For example, when experimenting with 105 queries that have multilayer intent hierarchies, Q-IA-LA E (22.4%) outperforms Q-IA (20.2%) in terms of discriminative power; (2) The measures using OIH are less discriminative than the measures using EIH. For example, nDCG-IA-LA O is 29.2% while nDCG-IA-LA E is 32.3% when experimenting with 105 queries that have multilayer intent hierarchies.
 By comparing the discriminative power results of D  X  -measures, LD  X  -measures, HD  X  -measures, and LAD  X  -measures (each block in Table 2), we nd that: (1) The measures using EIH are generally more discriminative than the measures using OIH; (2) When using EIH, LD  X  -measures, HD  X  -measures and LAD  X  -measures are better than (or at least as good as) D  X  -measures in terms of discriminative power. By comparing the results using all 250 queries in TREC Web Track 2009-2013 (shown in Table 1(a) or Table 2(a)) and the results only using the queries that have multilayer intent hierarchies (shown in Table 1(b) or Table 2(b)), we nd that hierarchical measures have greater improvement of discriminative power than existing measures for queries that have multilayer intent hierarchies. This is reasonable be-cause our measures have potential to recognize the difference between ranked lists by utilizing the hierarchies whereas ex-isting measures cannot. Another justi cation is that our measures are equivalent to existing measures when the queries only have single-layer intent hierarchies.
 The above observations suggest that it is preferable to use EIH when computing hierarchical measures. We think that the hierarchical measures using EIH have higher discrimi-native power than the hierarchical measures using OIH. For example, Figure 2(b) shows that d 1 is more diversi ed than d because d 1 refers to two interpretations of the query, while d 2 only refers to one of them. N-rec E agrees with this but N-rec O cannot tell which one is more diversi ed.
The hierarchical measures using EIH are more intuitive than using OIH in terms of diversity. Following the previous work [21], we use I-rec as the gold standard measure for the diversity because it does not depend on intent hierarchies OIH and EIH. Table 3 shows the intuitiveness when using all the queries in TREC Web Track 2009-2013 diversity test collections. We nd that for a document cutoff K = 10, the hierarchical measures using EIH are more intuitive than using OIH. For a document cutoff K = 20, there is only one exception (LD  X  -nDCG@20).

This is because the hierarchical measures using OIH may reward high relevance to some official intents, and fail to T able 3: Intuitiveness based on preference agree-ment with I-rec. For each measure pair (using OIH or EIH), the higher score is shown in bold and the numbers of disagreements between this pair are shown in parentheses below. rew ard wide coverage of the official intents. Take the OIH in Figure 2 as an example. Since we assume that the docu-ments that are relevant to a node are relevant to its parent node, the relevance assessments for intent i 1 or i 5 are re-ected in the relevance assessments for their parent node n . Though the rst layer of the OIH excludes i 1 or i 5 , it indirectly considers them through their parent node n 1 . By including the other four intents, the rst layer considers all six official intents, but the second layer of the OIH only has i or i 5 . When combining the two layers, the relevance as-sessments for i 1 or i 5 are considered twice, once in the rst layer and again in the second layer. However, the relevance assessments for the other four intents are only considered once in the rst layer. This means that when using the OIH, hierarchical measures mainly reward higher relevance to i 1 and i 5 than other intents. The EIH in Figure 2 solves this problem by extending i 2 , i 3 , i 4 , and i 6 to the second layer so that every official intent can be considered in each layer when evaluating the ranking quality.

In the remaining part of the section, we will only report experimental results using EIH due to space limitation. In most experiments, using EIH yields higher discriminative power and intuitiveness than OIH.
In Section 4.2, we show that LD  X  -nDCG E , HD  X  -nDCG E , and LAD  X  -nDCG E are highly discriminative among hierar-chical measures. In this section, we further compare their in-tuitiveness with some existing measures, including -nDCG, ERR-IA, and D  X  -nDCG. We do the concordance test based on all the queries in TREC Web Track 2009-2013 diversity test collections, and show the results in Table 4. In Table 4(a) and Table 4(b), we use N-rec E and Precision as the gold standard measure respectively, whereas in Table 4(c), both N-rec E and Precision are used as the gold standard mea-sures. We use N-rec E as a gold standard measure in terms of the diversity because: (1) It is a simple binary measures; (2) It measures diversity better than I-rec, which is tradi-tionally used as the gold standard measure for diversity. Table 4 shows that (1) In terms of the diversity, LD  X  -nDCG HD  X  -nDCG E , and LAD  X  -nDCG E are more intuitive than existing measures. This is expected because these hierarchi-cal measures directly depend on N-rec E by means of Equa-tion (11) and the like; (2) In terms of diversity, LD  X  -nDCG is most intuitive; (3) In terms of relevance, HD  X  -nDCG E most intuitive; (4) In terms of both diversity and relevance, LAD  X  -nDCG E is the most intuitive measure.

Table 4 shows that using the whole intent hierarchies in-stead of only using the leaf nodes can improve the intuitive-ness of measures. HD  X  -nDCG E and LAD  X  -nDCG E use the Table 4: Intuitiveness based on preference agree-ment with gold standard measures. For each mea-sure pair, the higher score is shown in bold and the numbers of disagreements between this pair are shown in parentheses below. wh ole intent hierarchy to measure both diversity and rele-vance of ranked lists. LD  X  -nDCG E uses the whole intent hi-erarchy to measure the diversity but only uses the leaf nodes to measure the relevance. D  X  -nDCG only uses the leaf nodes to measure the diversity and relevance. Table 4 shows that LD  X  -nDCG E , HD  X  -nDCG E and LAD  X  -nDCG E are more in-tuitive than D  X  -nDCG in terms of diversity. HD  X  -nDCG E and LAD  X  -nDCG E are more intuitive than D  X  -nDCG and LD  X  -nDCG E in terms of relevance. We get the same result when both diversity and relevance are considered.
D  X  -nDCG, LD  X  -nDCG E , HD  X  -nDCG E , and LAD  X  -nDCG E are closely related (shown in Section 3.3.5 and Section 4.4). We examine their differences in terms of intuitiveness by looking at some real examples from the submitted runs in TREC Web Track 2009-2013 diversity task.
 Speci cally, we select ve pairs of real ranked lists from TREC Web Track diversity runs in Table 5, and refer to them as Case A-E . For example, Case A stands for two runs cmuFuTop10D and THUIR10DvNov for No. 77 query; The middle column shows the relevance assessments of the top ten documents in each run (e.g. the rst document retrieved by cmuFuTop10D is relevant to intent i 4 with a relevance rating 1); The last four columns show the  X 's for each query (e.g. score of cmuFuTop10D minus that of THUIR10DvNov ) where arrows indicate which run has higher score under each measure. Note that in this section, the measures are computed for a document cutoff K = 10 be-cause we only have space to show top 10 documents in Table 5. We categorize ve cases into two classes from the view-point of diversity ( Case A-C ) or relevance ( Case D-E ). using each measure and arrows point to its preferred run.
In Cas e A , we argue that D  X  -nDCG is less intuitive than the other three. THUIR10DvNov covers both \bobcat com-pany"and\wild bobcat"while cmuFuTop10D only covers the former (Please refer to the detailed description for the official intents of No. 77 query shown in Figure 1) although both runs cover three leaf intents. In this sense, THUIR10DvNov is more diversi ed than cmuFuTop10D and should be pre-ferred. Note that this is also a case where I-rec cannot tell which run is better but N-rec E can. The rightmost col-umn of Table 5 shows that only D  X  -nDCG disagrees with this intuition. In Case B , we argue that D  X  -nDCG and HD  X  -nDCG E are less intuitive than the other two. Similar to Case A , UAMSD10aSRfu covers both \bobcat company" and \wild bobcat," whereas THUIR10DvQEW fails to cover the latter. So UAMSD10aSRfu should be preferred, and only LAD  X  -nDCG E and LD  X  -nDCG E agree with this. In Case C , we argue that LD  X  -nDCG E is the most intuitive among the four measures. In this case, both msrsv2div and qirdc-suog3 cover \bobcat company" and \wild bobcat". However, Figure 1 shows that msrsv2div covers both \bobcat tractors" and \bobcat company homepage," which are sub intents of \bobcat company," while qirdcsuog3 does not cover \bobcat company homepage." Because of this, msrsv2div should be preferred and only LD  X  -nDCG E agrees with this.
In summary, from the viewpoint of diversity, LD  X  -nDCG E is the most intuitive measure. HD  X  -nDCG E is less intuitive than LAD  X  -nDCG E , but is more intuitive than D  X  -nDCG. The two runs in Case D and in Case E have the same I-rec and N-rec E , hence the measures' preference is deter-mined by their Precision part (e.g. D-nDCG if it is D  X  -nDCG, and HD-nDCG E if it is HD  X  -nDCG E ). In Case D , we ar-gue that D  X  -nDCG and LD  X  -nDCG E are less intuitive than the other two. No matter whether measuring by I-rec or by N-rec E , qutir11a and uwBBadhoc are equally good in terms of diversity. However, qutir11a should be preferred because its top ten documents are all relevant, whereas uwBBad-hoc only has three. From the rightmost column of Table 5, we nd that D  X  -nDCG and LD  X  -nDCG E fail to re ect this. In Case E , we argue that HD  X  -nDCG E is the most intuitive among the four measures. UWatMDSdm should be preferred because it returns much more relevant documents than 2011SiftR2 . In this case, only HD  X  -nDCG E successfully recognizes this.
 Table 6: Kendall's / Symmetric ap by averaging over TREC Web track 2009-2013. Values greater than .950 are shown in bold.
Gen erally, from the viewpoint of relevance, LAD  X  -nDCG E is more intuitive than LD  X  -nDCG E . LAD  X  -nDCG E is able to measure the relevance of ranked lists more accurately by considering the whole intent hierarchy, and thus make the measures more consistent with Precision than LD  X  -nDCG E
We compute Kendall's and ap for different pairs of measures to check the correlation between these measures. Results are shown in Table 6. The table shows that: (1) LD  X  -nDCG E , HD  X  -nDCG E and LAD  X  -nDCG E are less cor-related to existing measures, especially when only using the queries that have multilayer intent hierarchies. This is be-cause our measures are able to recognize the subtle difference between ranked lists when multilayer intent hierarchies are used, whereas the existing measures may not. This indicates that our measures are useful and could be supplementary to the existing measures; (2) LD  X  -nDCG E , HD  X  -nDCG E as well as LAD  X  -nDCG E are more correlated to D  X  -nDCG than -nDCG and ERR-IA. This is because they are differ-ent kinds of extensions of D  X  -nDCG. Similar to D  X  -nDCG, they model diversity and relevance in different components separately. They yield the same evaluation results when the queries only have single-layer intent hierarchies. (3) LD  X  -nDCG E and HD  X  -nDCG E are less correlated. As dis-cussed in 4.3, LD  X  -nDCG E prefers highly diversi ed ranked lists, whereas HD  X  -nDCG E prefers highly relevant ranked lists.
In this paper, we argued that user intents of a query could be hierarchical. We described the concept of hierarchical intents and proposed hierarchical measures that could work with intent hierarchies. We created a new test collection con-taining intent hierarchies based on the existing TREC Web Track 2009-2013 diversity test collections by grouping the official intents into original intent hierarchies and extending them to extended intent hierarchies. Our experimental re-sults showed that our proposed hierarchical measures can be more discriminative than existing measures which use a at list of intents and assume the independence among intents. We revealed that LD  X  -nDCG should be used when the di-versity of search results is more valued than the relevance, whereas HD  X  -nDCG should be used when the relevance is more important. LAD  X  -nDCG is a better choice when both diversity and relevance are important.

In this paper, we simply assume that the official intents provided in TREC Web Track 2009-2013 diversity test col-lections are atomic intents. It is possible that some of these intents can be further divided into sub intents. We will in-vestigate this in the future.
This work was supported by the National Key Basic Re-search Program (973 Program) of China under grant No. 2014CB340403, and the Fundamental Research Funds for the Central Universities, the Research Funds of Renmin Uni-versity of China No. 15XNLF03, the National Natural Sci-ence Foundation of China (Grant No. 61502501, 61502502, and 61502503) [1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. [2] J. Carbonell and J. Goldstein. The use of MMR, [3] B. A. Carterette. Multiple testing in statistical [4] O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. [5] H. Chen and D. R. Karger. Less is more: probabilistic [6] C. L. Clarke, N. Craswell, and I. Soboroff. Overview of [7] C. L. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. [8] C. L. Clarke, N. Craswell, I. Soboroff, and G. V. [9] C. L. Clarke, M. Kolla, G. V. Cormack, [10] C. L. Clarke, M. Kolla, and O. Vechtomova. An [11] V. Dang and B. W. Croft. Term level search result [12] V. Dang and W. B. Croft. Diversity by [13] Z. Dou, S. Hu, K. Chen, R. Song, and J.-R. Wen. [14] Z. Dou, R. Song, and J.-R. Wen. A large-scale [15] B. J. Jansen, A. Spink, and T. Saracevic. Real life, [16] K. J  X  arvelin and J. Kek  X  al  X  ainen. Ir evaluation methods [17] M. G. Kendall. A new measure of rank correlation. [18] F. Radlinski and S. Dumais. Improving personalized [19] T. Sakai. Bootstrap-based comparisons of ir metrics [20] T. Sakai. Evaluating evaluation metrics based on the [21] T. Sakai. Evaluation with informational and [22] T. Sakai, N. Craswell, R. Song, S. Robertson, Z. Dou, [23] T. Sakai and S. Robertson. Modelling a user [24] T. Sakai and R. Song. Evaluating diversi ed search [25] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting [26] R. L. Santos, C. Macdonald, and I. Ounis. Selectively [27] R. L. Santos, C. Macdonald, and I. Ounis.
 [28] C. Silverstein, H. Marais, M. Henzinger, and [29] E. Yilmaz, J. A. Aslam, and S. Robertson. A new [30] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond [31] X. Zhu, A. B. Goldberg, J. Van Gael, and
