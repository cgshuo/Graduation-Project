  X  There was of course no way of knowing whether you were being watched at any given moment.... It was even conceivable that they watched everybody all the time . X  In order to run a country effectively, a government must understand the needs and wishes of its people. In order to run a corporation profitably, the directors must understand the customers and the products or services they require. This point, this need for understanding, applies to any orga nization. It applies to health service providers, to security services, to transport planners, to education authorities, and so on. Because of such needs, information about every individual at this conference is stored in countless commercial, government, and other databases . Some of this information is collected explicitly: when you take an examination or fill in an appli-cation form, you expect the data to be entered into a database. But the vast majority of it is collected implicitly: details of what you bought in a supermarket, of your credit card transactions, satellite monitoring of vehicle locations, automatic photo-graphs of vehicle registration plates, RF ID systems which identify objects and people at a distance, is all collected and stored without you being aware of it. 
Once the information has been collected, it can be used to answer the question it was intended for, but it can also be used to answer other questions. But there is more than this. If individual data sets can be used to answer new, as yet unposed, ques-tions, then analyzing merged data sets can be even more powerful. In general, data merging, data linking, or data fusion from both governmental and non-governmental sources is becoming increasingly widespread . For example, information on electoral rolls, censuses, and surveys by national statistical offices can be linked to information on purchasing patterns, banking transaction patterns, medical records, cellphone re-cords, websurfing traces, and so on. By such means, your interests can be identified and your behaviour modeled, and predicted , to an unprecedented degree. Thus the London Times of August 5th 2005 reports that  X  X BOS, Britain X  X  biggest mortgage lender, is pressing the Government to force local authorities to provide banks with deciding who is a good and bad financial risk, is conceptually similar to insurance, so might not insurance companies similarly request direct access to medical records? Let us take this example further. Imagine a system which matched peoples X  medical records to their eating habits, as deduced from stored data describing their weekly supermarket food purchases. Now link the results to their home address via the num-ber of the credit card used to make the food purchases, and an insurance company could decide automatically to withdraw insurance cover from customers whom it thought were eating a diet which predisposed them to illness. from harm by enabling us to predict what the future might bring unless we intervene in some way. But data mining is a powerful technology. All powerful technologies The second part of the paper illustrates how data mining tools can be misused, to invade our privacy. In parallel with the discussion concerning the social impact of data mining, running throughout the paper there is a technical theme: that the statistics used for pattern discovery data mining must be simple because of the sheer amount of computation required. There are two broadly distinct aspects to data mining. One is concerned with high level data summary  X  with model building. The aim here is to create a broad descrip-tion of a data set, to identify its main features. Thus, for example, one might partition a data set describing customers into distinct behaviour classes using cluster analysis. Or one might build a neural network model to predict how objects will behave in the future. There is an unlimited number of ways in which one might summarise a set of data, but, their aim is to identify the major characterising structures in the data. 
The other aspect of data mining is pattern discovery. Patterns are small local fea-tures in a data set  X  a departure from a model. They may consist of single points (as in outlier detection), small groups of points (as in detecting the start of an epidemic), small sets of variables which behave unexpectedly (as in microarray analysis), or some other small-scale depart ure from what is expected. 
Whereas the theory and methods of model building have been extensively devel-oped by statisticians throughout the twentieth century, pattern detection and discovery is relatively unexplored. Tools have been developed for particular application areas, and for particular types of problems, but this tends to have been in isolation. It is only recently, a consequence of the increasing number of very large data sets and the com-puter power to manipulate and search them quickly, that researchers have begun to think about a unified theory of pattern discovery. 
In pattern discovery, the aim is to detect data points or groups of data points which deviate noticeably from the expected  X  that is, from a background model. Examples of such problems are given below, and some people regard this kind of problem as the core of data mining  X  the attempt to find unexpected  X  X uggets X  of information. Pat-tern discovery requires the construction of a background model, a measure of devia-tion from that model (and deviation may be of many kinds), a search algorithm, and inference to decide if the devia tion should have been expected. 
Pattern discovery presents some theoretical and practical challenges. In particu-ments in the database . This is rather different from model building: for most pur-poses, a summary model built on a sample of 5000 cases will be as effective as a model built on all five million cases. But if one X  X  aim is to detect which cases are anomalous then there is no alternative to looking at each individual case. So, for example, in mining telecoms data, one can construct an effective segmentation into usage type (a model) using just a sample of a few thousand customers, but if one is trying to identify which customers are perpetrating frauds there is no alternative to examining each record. This suggests that pattern discovery exercises have an important property: the calculations involved in analyzing each case must be quick to perform. Each case cannot involve lengthy iterative computations, for example. I illustrate this in my examples, showing how pattern discovery is often a kind of feature selection exercise, with the requirement that the features must be computed from relatively simple formulae. 
In commercial applications, data mining is often sold as a magic tool which will lead to the discovery of information without the user having to do any thinking. This, risms such as  X  X hance favours the prepared mind X  and  X  X he harder I work, the luckier I get X . The truth is that the more you know about your data, about the problem, and about the sort of pattern you are looking for, the more likely you are to find something useful. In the context of pattern discovery, the more you know about these things, the more precisely you can formulate the mathema tical shape of the patterns to be found. The bottom line is that computing power does not replace brain power. They work hand in hand. The data miner who uses both will be the one who finds the interesting and valuable structures in the data. protect us from harm. 
Disease and illness are one type of harm, and an important class of data mining tools seeks to detect small local clusters of people suffering from a disease  X  perhaps because they have been exposed to a common cause, or perhaps because a contagious disease is spreading locally. In such situations the clusters are two-dimensional, with geography providing the two dimensions. Global clustering statistics, such as the Mantel-Bailar statistic, tells us whether the data points tend to suggest clustering, but they do not tell us where the clusters are. Such measures are really a diagnostic mod-eling tool. To detect clusters it is necessary to scan the distribution of points, looking at each point of the space and comparing the local clustering tendency with what one would expect. Here,  X  X hat one would expect X  will be based on the underlying popu-lation distribution. For example, one might assume that each person was equally likely to contract a disease, and then locate those regions where more than the ex-pected number have the disease. The simple statistics here are based on comparing counts of numbers of cases within a region of gradually increasing radius, with counts of numbers in the population within the region. 
This example has the property that information about the expected background dis-tribution was obtained from another source  X  the distribution of the population. In many problems, however, there is no other source. An illustration is provided by a study we carried out to detect student cheating. Plagiarism by students, assisted by the web, has been much in the news recently, but our problem was rather different. We were especially concerned to detect students who had copied their coursework from each other. Our simple statistic was a measure of similarity between pairs of students. The background model here is a distribution which has the same multivari-ate characteristics as the distribution of scores obtained by the students. 
Another, again slightly different example is given by pharmacovigilance. This is a post-marketing exercise carried out by phar maceutical companies, aimed at detecting drug-induced side effects. In principle th e background distribution is straightforward incomplete, and some other way to derive a background distribution is needed. Often fairly simple models are used  X  such as the assumption that the distribution of inci-dents over drug and the distribution of incidents over side effects are independent. We have been experimenting with a more elaborate approach which takes into ac-exist in a space in which closeness is determined by chemical similarity. In all cases, however, a simple statistic based on the difference between the observed counts and the expected of incidents under the background model is used. 
Disease clustering and the other problems described above is concerned with detect-ing local groups in space. Such clusters represent an anomaly in the underlying density anomaly in a univariate or multivariate sequence of observations over time. Change point problems are examples of such. Taking disease outbreaks as an example again, one might have a natural background rate of infection, and will seek to detect, as early based on comparing estimates of the rates before and after a putative change point. Further complications arise, of course, since often one wants to detect that a change has occurred as soon as possible. In the case of disease outbreaks, early detection can mean factors such as incubation time: if the symptoms of the disease manifest themselves after the organism has become infectious, for example. 
There are many other problems in which mining the data for change points, per-fault detection, and fraud detection, provide other important examples. For fault de-tection, careful on line monitoring of information from complex machinery, such as nuclear reactors or space missions, is vital to ensure that any peculiarities are detected early on. In fraud detection, we developed a tool for credit card fraud detection which we called peer group analysis , in which one identifies the customers who have previ-ously behaved most similarly to a target customer, and then monitors to see if and when the target starts to behave differently. Since it is generally not known which customers should be the target, the fact that one has to do the computation for all customers hints at the amount of computation which such methods can involve. Once again, we see the necessity of simple formulae. 
Although I have outlined spatial clustering and change point detection separately, they become especially powerful when combined. Now we can see when a spatial cluster suddenly appears, or when incidents of ATM theft suddenly begin. Once again, quick detection is often vital. The recent cases of SARS, BSE, and now Avian Flu illustrate just how important these sorts of tools are. 
Change points are one kind of anomaly. They occur when individuals suddenly begin to behave differently. But even univariate time series can demonstrate other anomalies. The case of Harold Shipman is an illustration. Harold Shipman is a contender for the title of the world X  X  most prolific serial killer. He was a family doctor, respected and admired by his patients. But over a period of 1978 and 1998, primarily elderly women patients, for example by giving them over-doses of painkillers. Detection came in 1998 when an apparently healthy 81 year-old died suddenly on 24th June. Her daughter, a lawyer, became suspicious when she realized that her mother had apparently signed a new will without her knowledge, leaving everything to Shipman. Things ra pidly escalated from there, and eventually Shipman was tried and found guilty on 15 counts of murder. 
At first glance this looks like a straight forward statistical problem, using control charts, cusums, or more elaborate tools. In deed, a retrospective cumulative plot of the mortality amongst females aged over 64 in Shipman X  X  practice shows a gradual in-crease and even an anomalous sudden increase in the death rate around 1994. Appli-cation of formal statistical tools detects that something unusual is going on here, and would flag this medical practice up for closer examination. But, of course, if such statistics which are quick to calculate is indicated. 
So far I have talked in terms of the statistics used to detect anomalous patterns and structures in data sets. I have stressed the need for these statistics to be simple, since often massive search is involved. But strange structures do arise by chance. Not only do we need to be able to locate such structur es, but we need to assess how likely it is that they are merely chance events. That is, as well as the algorithmic aspects implicit in search, we need the statistical aspects implicit in inference. 
This brings me to what I call the fundamental problem of pattern inference in data mining . It is the multiplicity problem. We will be searching over a large collection of some such configurations to arise by chance. The more data points we consider, the more likely such false positives are. To allow for this we have to bring to bear ideas of scan statistics and false discovery rate. Substantial theoretical advances have been made in these areas in recent years. The mathematics underlying these advances is often quite difficult, and I believe there are significant opportunities for computational approaches. In the introduction, I mentioned the power resulting from combining data sources. So let me finish this section illustrating the tremendous potential benefits of data min-ing by citing the Australian study which linked records of long haul flights to records of deep vein thromboembolisms, to reveal that the annual risk of thromboembolism is increased by 12% if one such flight is taken annually. Data mining has an immense amount to offer for improving the human condition. potential for immense good by protecting us from harm from a variety of causes. However, there is a downside. In this section I want to examine just a few examples of the dangers of data mining. 4.1 Elections My first example involves elections. Elections are often very close run things. In a sense, this means they may be intrinsically unstable systems. In the 2004 US Presi-dential election, the roughly equal proportions of votes in the Electoral College of 53% favouring Bush and 47% favouring Kerry translated into 100% election of Bush reversal of the outcome. Similarly, in the German election of 2005, although Angel Merkel won 35.2% of the vote, and Gerhard Schr X der won 34.3%, only one of them could be Chancellor, and in the 2005 UK General Election, the Labour Party won 35% of the votes and the Conservatives won 32%. In both of these cases it seems as if a slight change in the proportions could have resulted in a dramatic difference to the outcome. (In fact, in the UK case, these ro ughly equal proportions of votes translated into 55% of the seats going to Labour, and only 30% going to the Conservatives, but that X  X  a different story.) 
Now, of course, the distribution of votes across electoral seats varies. Some seats futile spending a lot of campaigning effort in seats where the ratio is traditionally 80:20. One has a far better chance of changing the outcome of the 51:49 seat. So this is where the effort should be made, and this is where data mining comes in. Data mining allows one to target the particular individuals, in the marginal seats, who might be swayed  X  the floating voters, those who have not definitely made up their minds. 
But there X  X  even more than this. People are different. They may agree with your position on immigration, but disagree with your position on taxes. And if you know this, if you have enough information on an individual voter, you can target your vote to match their interests. You can gloss over your tax plans and play up your immigra-tion policy when canvassing. If you know that the crucial voters tend to watch a par-ticular TV channel, then you can target your advertisements appropriately. 
This is a very radical change, brought about entirely by the possibilities provided by data mining. While what the voters know about the candidates is still crucial, what the voters know, which voters knows what, and which voters are provided with more information can be strategically chosen by the candidates. Data mining has changed the nature of elections. The candidate with the most astute data mining team has the winning hand. No elections at national level in the UK or US are now fought without a back room of data miners guiding actions, and the tools of data mining are used more and more extensively in modern elections in the West. Sometimes they go un-der the names of microtargeting or political sharpshooting . One might even go so far as to say that nowadays, if you do not employ a data mining team, you will lose. 4.2 False Positives, False Negatives My second example will probably be familiar to many of you, but its familiarity should not detract from its importance. It is the problem arising from unbalanced type of data mining problem, and in many areas the relative numbers of objects be-longing to the different classes are substantially different. In retail banking fraud, for example, generally less than 1 in a 1000 transactions are fraudulent, and in screening for rare medical conditions the rate can be even lower. This has serious implications for the effectiveness of classification rules, and for business operations. This can be seen from the following simple example. 
Suppose that a classifier correctly identifies 1 in 100 fraudulent transactions, and correctly identifies 1 in 100 legitimate transactions. This sounds like excellent per-formance. However, if only 1 in 1000 transactions are fraudulent, then 91% of those transactions flagged as suspect frauds are really legitimate. This matters because operational decisions must be made. To take an extreme case  X  if one decided to put a stop on all credit cards with suspect transactions one would have many irate legiti-are needed: one of our data sets had just 1530 fraudulent accounts amongst over 830,000 accounts altogether  X  all of which had to be examined. 
A less severe illustration of this sort of problem arose in the US system for screen-ing potential terrorists on aircraft, when Senator Edward M. Kennedy was prevented from boarding his US Airways Washington to Boston flight because he was mistak-enly matched to someone on a list of suspicious persons. Later he was also automati-cally flagged for observation by a system which looks for suspicious behaviour such failed 100 percent of the time to detect counterfeit identity documents being used by agents from the General Accounting Office testing the system by trying to enter the US illegally. 
The most effective way to tackle the particular problem of unbalanced classes seems to be to use a multistage approach. Eliminate as many as possible of the clearly legitimate cases, so one can use more elaborate methods to focus on the re-maining data. Methods based on sampling from the larger class or on duplicating samples from the smaller class are not recommended. 
The overall point is that blind application of data mining techniques, without tak-ing account of the practical requirements of the problem, can have adverse conse-quences. Thoughtless data mining carries a risk. 4.3 Insurance One of the aims of commercial data mining is to be able to predict the behaviour and likely future of people. In insurance, for example, the more accurately you can pre-dict which people will have an automobile accident, or who will die early of a certain disease, the more profitably you are able to run your company for your shareholders. The aim is thus to make individual-specifi c predictions. Often, however, the informa-tion in the potential predictor variables is insufficient to allow very accurate predic-tion rules, so averages are calculated for groups of similar people. The predictions then represent a compromise between potential bias in the predictive model and accu-racy in terms of variance reduction. 
But medical and data mining technology is changing that. For example, genomic data permit increasingly accurate predictions of who will die early of different dis-eases. Data mining tools are being increasingly heavily used in bioinformatics to extract precisely this kind of information. In some cases, the predictive accuracy will be such that certain individuals will be revealed to be very high risk  X  and will conse-quently be unable to obtain insurance. In fact, such situations have already occurred, also because of progress in medical scien ce. A positive AIDS test, for example, can make obtaining life insurance difficult, so there is a clear benefit in not taking a test, even if you suspect you may be positive. Moreover, the taking of a test, even if the results are negative, can be interpreted by an insurance company as an indication that missing is predictive in itself. 4.4 Other Areas: Data Quality, Iden tity Theft, Disclosure Control and Beyond There are other areas of risk associated with data mining, and I briefly touch on just a few of them in this section. 
Textbook descriptions of data mining tools, and articles extolling the potential gains to be achieved by applying data mining techniques gloss over some of the diffi-culties. One difficulty which is all pervasive, and which has major consequences for almost all data mining tasks, is that data are very seldom perfect. This matters be-cause governmental and corporate decisions assume the data are correct. But I feel confident that everyone in this room has experienced data problems at some time. Perhaps your computer has crashed at a critical moment, a program might not do exactly what it was intended to do, perhaps the system cannot handle unusual custom-ers or cases, perhaps software maintenance has introduced bugs, perhaps data have been entered incorrectly, and so on endlessly. I have countless examples of problems of this kind, but a very simple one involved retired bus driver Frank Hughes. An oversimple data-matching exercise meant that another man with the same name was matched to Frank Hughes the bus driver. His former workmates were then shocked to see him walking down the street  X  since they had recently attended his funeral. 
This was a shock for his friends and a surprise for Mr Hughes, but perhaps it was from the TAPAC report, which says (p37-38):  X  X ne of the most significant of these issues concerns the significant difficulties of integrating data accurately. Business and government have long struggled with how to ensure that information about one per-son is correctly attributed to that individual and only to th at individual ... According to the General Accounting Office, the government already suffers significant financial losses from its inability to integrate its own data accurately. X  
Identity theft describes the actions of a criminal who obtains personal information about you, and uses this to open bank accounts, obtain credit cards, bank loans, car finance, passports, a driving license, telecoms services, and other such instruments masquerading as you. Worse still, such stolen identities can then be used for activi-ties such as money laundering, immigration fraud, tax fraud, and worse. Once such a theft has been detected, it can take years to sort it all out. During this time, you may not be able to obtain loans, get a mortgage , buy a car or insurance, obtain credit cards, and so on. It is estimated that each year about 100,000 such thefts occur in the UK, and that it costs the UK economy about  X 1.7bn. 
To commit identity theft, criminals have to collect information about you. This in-formation can come from various sources. One significant danger is that separate items of information which are innocuous in themselves may be merged to produce something which acts as a key. Traditional obvious sources include simple thefts of wallets or driving licences, discarded bills , credit card receipts or bank statements reclaimed from a rubbish bin. More elabor ate tools include strategies such as phish-ing  X  persuading people to divulge security information or PIN numbers over the internet in the mistaken belief that it is a security check. The internet is a new tech-nology, and one which is changing its shape and form all the time. It contains in-creasing amounts of information about people, permitting all sorts of discoveries (for example that of the adopted teenage boy who manage to locate his sperm donor natu-ral father with just two clever web searches). And mining the internet has become a specialized area of data mining in its own right. 
With identity theft in mind, you should always shred any financial documents, You should use different PIN numbers and passwords, irritating though that may be, and you should never store PIN numbers with the cards to which they refer. You should never divulge personal information to people who ring you on the phone (even if they claim to be from your bank). Always ring them back on a number you know to be correct. Always check banks statements for suspicious transactions. Don X  X  tell others your PIN numbers or passwords. Clearly all this is a tremendous hassle  X  but it is nothing compared with the difficulties if you become a victim. 
Privacy on the internet can be protected to some extent by coding stored and trans-tools cannot be applied. For example, the information governments collect about researchers and administrators. But this involves a risk. Tools of disclosure control have been developed to prevent people from being able to identify individuals in large datasets. Some of these tools involve modifying the data, so that it retains its statisti-cal properties but loses information on individuals; others involve randomly perturb-ing the data. There is a basic principle of personal data confidentiality: that  X  personal data should be used only for the purpose for which it was collected, unless explicit permission is given  X . Unless this is respected, public confidence will be shaken. The consequence will be that and conclusions, and hence to less effective government and less profitable corpora-tions. Privacy of personal data lies at the foundation of effective societies. 
For these reasons, the principle of data confidentiality has been enshrined in vari-ous legal ways, varying between countries. Many of them permit individuals to ex-identity theft, it is a good idea to periodically check your records with credit reference agencies.) 
I said in the introduction that all advanced technologies are ethically neutral . They can be used for good or bad. This is as true for data mining as it is for nuclear tech-nology and biological disciplines  X  the technology that the people in this room are involved in is just as sophisticated as th ose technologies. This means that criticisms of such a technology should be focused on the (mis)use to which it is put, not on the counts. 
As far as data mining is concerned, the genie is out of the bag. These advanced methods for discovering the unexpected in data exist, and are being used more and more often on more and more data sets. We cannot pretend that they no longer exist. The technology has the power to bring immense good, but if used the wrong way, it can also bring harm. As Jerrold Nadler said when he appeared before the United State X  X  Technology and Privacy Advisory Committee in November 2003: the  X  X ues-tion isn X  X  whether technology will be developed, but rather whether it will be used 
