 Many event monitoring systems rely on counting known key-words in streaming text data to detect sudden spikes in fre-quency. But the dynamic and conversational nature of Twit-ter makes it hard to select known keywords for monitoring. Here we consider a method of automatically finding noun phrases (NPs) as keywords for event monitoring in Twitter. Finding NPs has two aspects, identifying the boundaries for the subsequence of words which represent the NP, and clas-sifying the NP to a specific broad category such as politics, sports, etc. To classify an NP, we define the feature vector for the NP using not just the words but also the author X  X  behavior and social activities. Our results show that we can classify many NPs by using a sample of training data from a knowledge-base.
 H.2.8 [ Database Applications ]: [Data Mining]; I.2.7 [ Natural Language Processing ]: [Text analysis] Measurement, Experimentation Social Media, Noun Phrases, Twitter, Named Entities  X 
This work was completed when the author was a visiting student at Carnegie Mellon University.

Twitter , a micro-blogging website has very wide coverage in people X  X  life. Snippets of text, which we call tweets ,are written by Twitter users commenting on their sentiments to-ward consumer products, political opinions, sports and daily mundane activities. To understand a tweet X  X  meaning, im-portant key words such as noun phrases ( NPs ) need to be recognized in the tweet. Each noun phrase ( NP ) represents a consecutive sequence of words that mentions a specific noun or entity.

A direct application of NP recognition is event-monitoring in real time Twitter streams. Prior research by Sakaki et al. have shown that by monitoring specific known keywords in Twitter, it is possible to perform event detection [10]. These event-monitoring systems usually track a fixed set of manu-ally chosen NPs. But given the dynamic nature of Twitter, we often do not know what NPs should be monitored. Some important NPs that describe the subject of the tweet might be n-grams where the value of n varies widely. Users on social media are also often inventing new words and NPs to comment on recent events. Such dynamically changing vocabulary means that a fixed dictionary of monitored key-words are unlikely to capture recent events.

Problem Definition : Recognizing NPs has two aspects. 1) Identify the boundaries of the word subsequence that rep-resents each NP. 2) Given the NPs, classify each NP into a pre-defined set of categories such as politics or sports. For example, in the tweets mentioned previously, we want to classify the NP a balance budget amendment as political and a shitty NFL team as sports. In order to perform classifica-tion, we propose to use the features of a NP based on the author X  X  behavior and community preferences. (a) Word Co-occurrences For example in Figure 1(a), authors a 1 and a 2 share a NP in tweet 2 and tweet 3 respectively and this NP has been classified to a category. From that classified NP, in-formation of the category can propagate to other NPs that a 1 and a 2 have written, thus allowing us to infer the other unclassified NPs. Although author a 3 does not have any classified NP, the information from the classified NP of a and a 2 can propagate through the common NP of a 2 and a 3 from tweets 4 and 5 respectively. If most NPs are un-igrams, dimension reduction algorithms such as Singular Valued Decomposition (SVD), Non-Negative Matrix Factor-ization (NNMF) or Latent Dirichlet Allocation (LDA) can model the co-occurrences of words with different authors. Since most NPs are not unigrams, we propose an extension of LDA called NP+LDA to handle n-grams. These dimen-sion reduction algorithms use such co-occurrences to reduce the authors and NPs into a latent space with significantly lower dimension.

The structure in Figure 1(b) shows author a 3 who has no common NP with either a 1 or a 2 . In this case, the typical dimension reduction algorithms will not be able to capture the necessary information for inferring the categories of NPs from a 3 . But information from the classified NP could prop-agate through the social link which connects a 2 and a 3 .So then the dimension reduction algorithm to find the feature vector should consider the social link between a 2 and a 3 The Role Author Recipient Topic Model (RART) [7] which models unigrams from conversation based corpus does con-sider the authors X  social dimensions. Similar to LDA, we propose an extension NP+RART to handle n-grams of NPs. Instead of having a topic distribution for each author, we could first find the communities each author belongs to and define a topic distribution for the communities.
Challenges : When modeling n-grams of NPs using topic models such as LDA, it is tempting to assume that we can treat each different NP as a single word token. But that causes an inflated number of unique  X  X ords X  in the model. For example, given that an NP has n unique words, there are a total of n ! different variations of that NP. Too many unique words in the model causes the data to be extremely sparse because of low occurrences for each variation of the NP. So we need a model that handles n-grams of NP which also considers the individual word tokens in the NP. We use NP+LDA, which is previously proposed by Wallach [11]. NP+LDA considers n-grams instead of individual word to-kens for inferring the latent topics for each NP.
Much of traditional text analysis has focused on exploit-ing language semantics and grammar structure in text for extracting information. But tweets often have the following problems, 1) Tweet length is usually short with less than 30 words. This makes it harder to infer the context of the NPs in tweets. 2) Spelling and grammar are usually wrong despite the high literary rates in modern societies. The vari-ation in spelling makes it hard to compare against a dic-tionary. The grammar idiosyncracy makes it hard to use linguistic rules to infer where the NPs are. 3)Many tweets offer little information and impact on society, for example, the last tweet in the examples earlier does not tell us very much about the author. As a result, we may waste unnec-essary time on processing uninformative tweets.
 Instead of using the well-explored semantics in Natural Language Processing, Twitter provides additional features for text analysis. In Twitter, users follow other users to track and subscribe to the tweets other users write. Users also retweet (cite other users X  tweets) from other users. These follow and retweet relationships result in formation of com-munities of Twitter users who focused on discussing certain categories of topics. But no prior work has ever attempted to use the social features or community-based information for classifying NPs.

We propose a method of identifying NPs in tweets using its Part-of-Speech (POS) tags. After we have identified the boundaries of where the NPs are, classification is formulated as a set of binary classification problems to infer whether these NPs belong to a set of categories that we want to find (e.g. politics, sports). We obtain the feature vectors for classification using the authors X  topic preferences and their communities membership.

Our contributions are as follows, 1) We show that find-ing the NPs can be performed easily by using Regular Ex-pressions on the Part-of-Speech (POS) tags of the words in tweets. We POS-tagged a total of 2.9 million tweets using the annotated Twitter data set by Gimpel et al. [4]. 2) We use a sentence reader trained on an existing knowledge base, the Never Ending Language Learner (NELL) and ClueWeb corpus for classifying these NPs. 3) Because the sentence reader is only able to classify a small proportion of the NPs with high confidence, we use a second classifier which derives feature vectors from two models NP+LDA and NP+RART. 4) Using NP+LDA, we learn the topic distributions of the authors to find the topics of words that authors frequently tweet about. Then using the topic distributions of authors and n-grams as feature vectors for supervised learning, we perform classification on these NPs using the categories of a partially known set of NPs from the Never Ending Language Learner (NELL) X  X  knowledge base [2]. 5) From NP+LDA and Role Author Recipient Topic Model (RART) [7], we further extend and propose NP+RART to show that we can improve the classification of NPs using the community information in Twitter.

We discuss some related and prior work in the area of noun phrase and named entity recognition (NER) in Section 2. Section 3 describes our methods and models in detail. Then we evaluate our work in Section 4. Finally we end our paper in Section 5 with a conclusion of what we have done and some possible future work. Ritter et al. built an NLP pipeline for performing Named Entity Recognition (NER) in tweets [9]. The pipeline begins with Part of Speech (POS) tagging of tweets using a su-pervised learning approach, followed by text chunking then classification using an annotated set of tweets.
Liu et al. proposed an alternating two-step approach to perform the NER task in tweets [6]. The two-step approach alternates between the KNN classifier and CRF labeler. The KNN classifier models global features which span over long range of words. The CRF models the localized features among consecutive words. To train these two learning al-gorithms, 12,245 tweets were manually annotated by two independent annotators.

The work of Michelson and Macskassy is closely related to ours [8]. Michelson and Macskassy proposed a two step process to understand a tweet T content in order to profile the authors X  topic interests. The first step identifies and disambiguates possible named entities as candidates in tweet T . The second step uses the hierarchical classification in Wikipedia to profile the authors X  topic interests.
Li et al. [5] proposed an unsupervised method of finding named entities in Twitter using Wikipedia and Microsoft N-gram data as knowledge-base. Li et al. approach is to find the optimal segments of word as named entities using a dynamic programming approach. However, unlike our ap-proach, they do not classify the named entities into its re-spective categories.

Our use of topic distributions as feature vectors for super-vised learning is inspired by previous work on Supervised Topics Models by Wang et al. [1, 12]. The topic distribu-tions are used as feature vectors for a Logistic Regression classifier without the bias intercept. However, Wang et al. use the topic distributions for classifying documents while we use it for a more fine grain classification of noun phrases in the documents.
Let us first examine the list of features in the data set and the tools we have. 1) Retweets in Twitter data set give us a hint that the retweeted tweets contain meaningful informa-tion for extraction. 2) Gimpel et al. has a set of annotated POS tweets [4], which we can use for training a POS Tag-ger 3) Each tweet is associated with at least an author and the author is likely to focus on a few specific topics. 4) Replies and Retweets give us a hint of the active and im-plicit social network beneath the passive and explicit follow relationships. 5) Knowledge bases such as NELL provide entities disambiguation subjected to whether the entity and its context pattern exist in NELL X  X  knowledge base.
In summary, we used POS tagging and regular expressions to segment the boundaries of NPs in every tweet. We au-tomatically classify a small set of NPs using NELL X  X  knowl-edge base (KB). Then we derive feature vectors on the KB-classified and KB-unclassified NPs using two models; NP+LDA and NP+RART. We train a classifier using the categories and feature vectors of KB-classified NPs, then use the clas-sifier on the feature vectors of KB-unclassified NPs to obtain broad-level categories.
To extract NPs, we use the POS Tagger provided by Gim-pel et al. [4] to tag the tweets. From the POS tags of the words in each tweet, we use a lexical analysis program lex , to recognize the regular expression for obtaining NPs. The following regular expressions are used to obtain the NPs,
The regular expression rules we described here can be in-terpreted as follows: a base noun phrase (BASE NP) can have zero or one determiner, zero or non-zero adjectives and at least one or more nouns. A conjunctive noun phrase (Conj NP) is made up of one or more base NPs, e.g.  X  X he student of computer science X .

Once we have the NPs, we can derive a feature vector to represent each NP. The feature vector represents the au-thor X  X  writing preferences or her belonging to a community base on her social activity in Twitter. If we also have known information for the categories of some NPs, we can use these partial information to classify the categories of other un-known NPs.
NELL 1 is a knowledge base that stores two pairs of infor-mation for NP classification [2, 3]. 1) The noun phrase and 2) words that come before and after the NP known as the contextual patterns .

To utilize NELL X  X  knowledge base for classifying noun phrases, we obtained a sentence-level semantic category rec-ognizer (SentReg) for many different categories. We fol-low the basic approach described by Whitelaw el al. with a few variations [14]. SentReg was trained using NELL X  X  knowledge base on the ClueWeb corpus 2 . However, Sen-tReg does not have high recall on Twitter data for these reasons. 1) SentReg was trained on ClueWeb, which has better grammatical structure and language semantics than Twitter. 2) Many Twitter tweets are related to very recent events and NELL X  X  knowledge base is unlikely to have the contextual patterns for the new NPs. 3) Twitter data does not have many NP contextual pattern for SentReg to recog-nize. Therefore, we only use NPs classified by SentReg with high confidence and this results in a very small set of NPs as compared to all the NPs we have.
After SentReg classifies a small set of NPs, we need to represent these NPs in the form of a feature vector to be used in a supervised classification algorithm. We can either have a feature vector which represents the NP, or the edge connecting the NP and the author.

Figure 2(a) shows two authors a 1 and a 2 . Author a 1 writes tweet 1 which contains the NP android . Tweet 2 written by a 1 has the NPs phone and apple . Similarly, a 2 writes tweet 3 that contains apple and vitamins . Tweet 4 written by a 2 contains only one NP oranges . We can proceed to learn the meanings of the NPs by classifying each word to a specific category. However, observe that the NP apple can belong to the category company or fruit depending on which author wrote the NP. The NP apple written by a 1 is inferred as company while the NP apple written by a 2 should be classified as fruit. Therefore, it is more specific to classify the edge which connects the author and NP instead of the NP itself. Figure 2(b) shows the result of classifying the author -NP edges. This is the goal of our proposed models, to find feature vectors connecting the author and NP, then classify the edge to some category.
 Since most tweets are short and contain only one to three NPs, it will be easier to learn the topic distribution of the authors by aggregating all the NPs tweeted by the authors as opposed to treating each tweet as an individual document, this approach was previously applied in TwitterRank [13]. http://rtw.ml.cmu.edu http://lemurproject.org/clueweb09.php/
Formally, given a set of tweets T a written by an author a , for each tweet t  X  T a , suppose we have the noun phrases NP t in tweet t ,Foreach n  X  NP t , obtain the feature vector  X  t,n representing the noun phrase from tweet t written by author a and associate a category c t,n if the noun phrase has been previously recognized by SentReg. Figure 3: Topic Models with Noun Phrases (NP) Figure 3(a) shows the graphical model of NP+LDA model. We denote the tweets written by author a as T a . Each tweet is represented as t ,where t  X  T a .EachNPof t as n and words in the NP as w t,n,i . Instead of generating each word from each latent variable z , we generate a noun phrase which consists of a set of words. This way, we can ensure that all words from a noun phrase belong to the same topic. This assumption should be reasonable because a noun phrase is too short to contain a mixture of topics. Interested readers may refer to Wallach [11] for more details.
Recall that in Figure 1(b), we wanted to use the social links between pair of authors as an additional piece of in-formation to infer the category of NPs. Since Twitter is a community-based type of social media platform we can group different users into communities as shown in Figure 4. Each community talks about a certain topic (e.g. poli-tics, sports). Based on the community membership of the users, and the topic preferences of the communities, we can derive a feature vector for the author -community -NP triplet that contains more information than the author -NP feature vector by NP+LDA.

Refer to Figure 3(b) for the NP+RART model modified for noun phrases. NP+RART is a hybrid of our NP+LDA and Role Author Recipient Topic Model (RART) from Mc-Callum et al. [7]. Similar to NP+LDA, each noun phrase is generated by a single latent variable z t,n . The NP+RART model has another set of latent variables x i and x j .Thela-tent variable x i denotes the community membership of the author who retweets and x j represents the community mem-bership of the author who is retweeted. Given a tweet, the x i and x j are constrained to be the same for all the noun phrases in the same tweet. This helps to ensure that authors always act in the same  X  X ole X  when writing or retweeting. Based on the small average number of 3.7 noun phrases for each tweet, it should be reasonable to assume that authors always act in the same  X  X ole X  in a single tweet. The gen-erative process is as follows, 1) Each topic z samples the word distribution from a symmetric Dirichlet distribution. 2) For each Retweet t , the retweeter i and the original author j samples their community membership from a symmetric Dirichlet distribution. 3) For each Retweet, the retweeter i and the original author j samples a latent community mem-bership variable x t,i and x t,j from their own community membership distribution  X  i and  X  j respectively. The pair of sampled community membership refers to a block out of H  X  H number of blocks in the model. 4) Each block (g,h) samples their topic distribution from a symmetric Dirichlet distribution. 5) For each noun phrase n in retweet t ,the block (g,h) samples a single latent variable z t,n for the noun phrase n from the topic distribution of the block (g,h),  X  6) The block (g, h) then samples each noun phrase n for tweet t using a single latent variable z t,n = k and the topic word distribution  X  k,v .
Given noun phrase n from tweet t , we can derive the fea-ture vector  X  n to represent n in the latent space.  X  n is the K dimensional feature vector which we can derive from NP+LDA or NP+RART, where K is the number of topics used in both models. In  X  n ,eachelement  X  n,k corresponds to the probability of n belonging to the topic of k .Inother words,  X  n is a normalized probability vector which sums to 1, derived from the parameters of NP+LDA (  X , X  )and NP+RART (  X , X , X  ).

Given that the classification step is separate from the in-ference process of NP+LDA and NP+RART, we can use any classifier such as Support Vector Machines, Decision Trees, K-Nearest Neighbor etc. We have chosen to use Lo-gistic Regression because its probabilistic nature could al-low for joint inference with the probabilistic topic models of NP+LDA/NP+RART in future work.
We developed our Noun Phrase recognition on a small col-lection of tweets which we crawled from Twitter. We first selected a core set of 16 Twitter users mainly consisting of American politicians from Democratic Party and Republi-can Party. We expanded this core set of users by including the users who follow at least 3 out of these 16 core users. In total, we have 171,384 users from this expanded set. Then starting from September 28th 2011 (09/28/2011), we ob-tained 3,200 tweets that were published before 09/28/2011 and continue crawling their tweets daily until December 31th 2011 (12/31/2011). Over a period of approximately 3 months, we ended our crawl with a total of 110,667,693 tweets.

As many of such tweets describe mundane activities and gibberish text, we only retained tweets that have been retweeted and whose original authors are from the expanded set. Af-ter filtering, we obtained a small sample of 7,414,570 tweets with an average of 18.0 words per tweet. We derive the feature vectors from NP+RART for the NPs by using 50 topics and 100 communities.
 Table 1: List of Ten Most Probable Political Noun Phrases From NP+RART
Noun Phrase Political Prob passage of balanced budget amdt 0.952 passage of a balanced budget amdt 0.952 gop co-chair of deficit commission decries inability of washington boehner debt deal plan 0.952 balanced budget amdt 0.952 a balanced budget amdt 0.952 support reid debt limit 0.952 short-term debt deal 0.952 oppose balanced budget 0.952 house rejects reids debt ceiling pro-posal
Table 1 shows the top ten list of NPs returned by the clas-sifier with features from NP+RART. The list of NPs from Table 1 do indicate that NP+RART is able to classify politi-cal NPs. To compare the performance of NP+RART against NP+LDA, we sampled 200 NPs on which NP+RART and NP+LDA disagree. We manually annotate the disagreed set of NPs (disagreement set). The annotation results showed that NP+RART has a better accuracy than NP+LDA in classifying political NPs. We find that whenever NP+LDA or NP+RART classifies a NP as political, the probability of NP+LDA being correct is in the range of [0.604, 0.8], while NP+RART has a probability range of [0.725, 0.921].
We proposed a noun phrase (NP) classification method using the authors X  behavior and social information in Twit-ter. We showed that our first model NP+LDA could classify NPs into political categories more accurately than state of the art tagger (SentReg) based on a large knowledge base. By incorporating community information in NP+RART, we further improve the accuracy of our classifier. Finally, we show that we are also able to classify sports NPs in a polit-ical dominated Twitter data set.

There are many possible extensions from here. Joint infer-ence between the classification and topic models is one area to explore. Another possibility is to find categories that are likely to co-occur in the same tweet, then use collective classification to classify the NPs base on the categories of neighboring NPs in the same tweet.
This research/project is supported by the Singapore Na-tional Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. The research is also partly funded by Google. Freddy will like to thank Nelman Lubis Ibrahim for his help in crawling the data, Ramnath Balasub-ramanyan, Bryan Kisiel, Partha Talukdar, Kathryn Rivard, Dana Movshovitz-Attias, Brendan O X  X onnor and all other members of the Read the Web team for their help during his stay at CMU. [1] D. Blei and J. McAuliffe. Supervised topic models. In [2] A. Carlson, J. Betteridge, B. Kisiel, B. Settles, [3] A. Carlson, J. Betteridge, R. C. Wang, E. R. [4] K. Gimpel, N. Schneider, B. O X  X onnor, D. Das, [5] C. L. Li, J. Weng, Q. He, Y. Yao, A. Datta, A. Sun, [6] X. Liu, S. Zhang, F. Wei, and M. Zhou. Recognizing [7] A. McCallum, X. Wang, and A. Corrada-Emmanuel. [8] M. Michelson and S. A. Macskassy. Discovering users X  [9] A. Ritter, S. Clark, Mausam, and O. Etzioni. Named [10] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake [11] H. M. Wallach. Topic modeling: beyond bag-of-words. [12] C. Wang, D. M. Blei, and F.-F. Li. Simultaneous [13] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: [14] C. Whitelaw, A. Kehlenbeck, N. Petrovic, and
