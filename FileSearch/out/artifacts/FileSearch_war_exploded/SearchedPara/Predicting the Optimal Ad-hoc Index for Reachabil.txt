 Due to the recent advances in graph databases, a large number of ad-hoc indexes for a fundame ntal query, namely, reachability query, have been proposed. The structures and performances of these indexes on different graphs have known to be very differ-ent. Worst still, deriving an accurate cost model for selecting the optimal index of a graph database has been a daunting task. In this paper, we propose a hierarchical prediction framework, based on neural networks and a set of graph features and a knowledge base on past predictions, to select the optimal index for a graph database. For ease of presentation, we discuss our framework with three structurally distinguishable indexes. Our preliminary exper-iments show that our framework is 90% accurate on thousands of synthetic graphs.
 Categories and Subject Descriptors: H.2.4 [Systems]: Query processing General Terms: Experimentation, Performance Keywords: Graph indexing, Neural networks, Reachability queries Recent applications on graph data, for example, social networks, Web ontology, the Semantic Web and XML, have sparked a re-newed interest on graph-structured databases. For example, there has been work on XML repositories [6], biological databases [5], ontology data on the Web [8], graph networks [2] and classical graph databases with recursive query language support.

A fundamental query on graphs is reachability queries. Specifi-cally, given two nodes u and v of a graph, the query returns true if and only if v is reachable from u . For all the reasons that reacha-bility queries are important in classical graph databases, there has been a large body of work on its recent applications. For instance, the descendant axis ( X // X ) in XPath, a query language for XML, can be considered as a special application of reachability queries. The descendant axis in XPath can be readily implemented by extending the reachability query to support sets of nodes, e.g., [7]. In addi-tion, reachability queries have also been one of the components in querying the Semantic Web [9]: Information on resources on Se-mantic Web can be naturally represented as a graph with Resource Description Framework (RDF) [10]. Query languages for the Se-mantic Web, e.g., SPARQL (a W3C recommendation), involve sub-graph matching, where reachability queries are intrinsically a part of the matching.

A wide range of indexes has been proposed for optimizing the performance of reachability queries, which includes interval label-ing [1], 2-hop labeling [4] and prime labeling [7, 11], among oth-ers. These indexes are often very different in structure and often appear to be fairly ad-hoc. In addition, the asymptotic analysis of the indexes might tell little a bout the actual performance. For ex-ample, the interval labeling X  X  query time is O ( n ) andindexsize is
O ( n 2 ) ; and 2-hop labeling X  X  query time is O ( size O ( n ber in graphs, respectively. Worst still, since the structure of these indexes/labels are fairly different, deriving an accurate cost model for the relative performances of the indexes has been a daunting task. A concrete example from our preliminary experiments is that given 100 random reach ability queries, 2-hop labeling can be 2 times slower than interval labeling in one data graph but 1.74 times faster in another. As more ad-hoc indexes are proposed, the selec-tion of the optimal index can be expected increasingly challenging. Therefore, what is desirable is an accurate and practical method to determine the optimal index for a given graph database.

In this paper, we leverage machine learning technology to solve an important problem in databases. Specifically, we leverage ar-tificial neuron networks (a.k.a neural networks) to predict the op-timal labeling based on some graph features, where the networks are trained offline and the features are presented in the original pro-posals of the indexes used. A unique challenge of our prediction problem is that our framework may adapt to predict new graphs, whose features may not be encountered before. Instead of using online neural networks as a black box, we propose a hierarchical framework with a knowledge base of past predictions, which gives more flexibility and extensibility in adapting to recent predictions.
In all, the contributions of the paper are summarized as follows. (i) We propose a framework for predicting the optimal index for reachability queries of a given graph database on-the-fly; and (ii) We conduct an experimental comparison of performance among three structurally-distinguishable indexes under different circum-stances.
A large number of indexes has been proposed recently to support reachability queries on trees or arbitrary graphs. (Since indexes of-ten associate labels with nodes, we may use the term indexes and labels interchangeably.) Here, we review three selected indexes for two major reasons. Firstly, the indexes are clearly structurally distinguishable, which show the d ifficulties in deriving an accurate formula to dictate their relative performances. Secondly, the imple-mentation of the indexes are available for our experiments. (1) Interval labeling has been widely used for trees possibly be-cause of its query efficiency and ease for implementation. The con-struction involves a traversal on an input tree and labels each node with an interval ( i, j ) ,where i is the node X  X  preorder number and is its postorder number. Node w is reachable from node v interval contains w  X  X  interval. [1] proposes to extend this labeling to support reachab ility queries on DAGs. In particular, each node may be associated with multiple intervals, as there may be multiple paths between any two nodes. Ho wever, determ ining reachability query could then be potentially time-consuming. (2) 2-hop labeling [4] is a popular i ndex to test reach ability on arbi-trary graphs. 2-hop labeling associates each node v with two labels L in ( v ) and L out ( v ) ,where L in ( v ) contains some nodes that can reach v and similarly, L out ( v ) consists of some nodes that reach. Node v can reach node w ,iff L out ( v )  X  L in ( w ) =  X  termining the 2-hop labeling with the minimum size is NP-hard, and its approximate construction is often computation intensive as well. However, its desirable index size still makes it a reasonable choice for large (cyclic) graphs applications. (3) Prime number labeling (or simply prime labeling) [11] uses prime numbers to encode reachability information of trees. A sub-sequent work [7] extends this work to support reachability test on arbitrary graphs. Prime labeling associates each node with a prod-uct of prime numbers and node w is reachable from node v ,iff label is divisible by w  X  X  label. In comparison to 2-hop labeling, prime labeling of graphs could be efficiently constructed. How-ever, for graphs with large depth, prime labeling may results in large product, which leads to large labeling size. We begin with the definitions and notations used in this paper. Data Model and Queries. In this paper, we study directed rooted data graphs, or simply graphs in the subsequent discussions. A graph can be defined as G =( V,E,r,  X  , X  ) ,where V is a set of nodes and E : V  X  V is a set of edges, r  X  V is a root node, a set of tags and  X  : V  X   X  is a function that returns the tag of a node. For simplicity, we may denote a graph as ( V,E ) when others are irrelevant. Also, we may use query to refer to reachability query as it is often clear from the context. In this paper, we often use the expected query time (EQT) of a particular labeling (defined below) to refer to query performance.
 Definition 3.1: Given a graph G and its label L G ,the expected query time (EQT) of L G is the average time of all possible reacha-bility queries on G .
 Next, we are ready to present the problem studied in this paper. Problem statement. Given a graph and a set of labeling tech-niques, we want to predict the labeling technique for the graph that results in the smallest EQT .
 Artificial Neuron Network. This paper adopts Artificial Neuron Network (ANN), or simply neural network, to predict an optimal index. The ANN takes feature vectors of user-interested objects as input and produces predictions, for example, class labels of objects, as output. The task of ANN learning is to find a satisfactory assign-ment of its weighted variables, based on training samples, such that prediction error is minimized. The objects of our interest is graph databases and the prediction is labeling types.
 Features of Graphs. The structure of a graph database is repre-sented by a set of features for training an ANN. There have been admittedly many possible features which cannot be included in this paper. We however study the performance analysis (both asymptot-ical and experimental) of the index proposals to summarize a num-ber of features, which have been considered relevant by the inven-tors of the indexes. Specifically, the features of graph G =( V,E ) are the following: (i) the number of nodes, | V | ; (ii) the number of edges, | E | ; (iii) the number of strongly connected components ( SCCs ) ; (iv) the acyclicity: if a graph contains at least one cy-cle, we say the acyclicity of the graph is false; it is true, otherwise; (v) the average fan-out of nodes: the fan-out of a node is the number of outgoing edges; (vi) the depth: the depth of a graph is defined to be of the  X  X eepest X  spanning tree of the graph (vii) the non-tree density: ( | E | X  X  V | X  1) / | E | (viii) the graph density: (ix) the cut nodes density: the number of cut nodes divided by the number of nodes; and (x) the  X  X ycle-edge X  density: the number of edges that are on at least one cycle over the number of edges.
In this section, we present the details of the basic prediction model. In a nutshell, the model has two components. The first com-ponent contains a single neural network namely the basic predictor, denoted as N 1 , and the second component consists of a knowledge base, denoted as B , and two neural networks, namely the verifier and the adjusted predictor, denoted as N 2 and N 3 , respectively. We illustrate the overall framework with Fig. 1.

The first component takes the features of a graph G as input and produces a prediction for the optimal index on G as output. This prediction may be accepted as the final prediction. However, when the graphs for prediction have not been encountered in training, the first component alone may no longer be accurate. To address these, we introduce the second component to assess the prediction and if necessary, to adjust the prediction based on previous predictions. In the following, we discuss the details of these two components.
The basic predictor is a single neural network N 1 . Its input layer has ten neurons, each of which represents a graph feature. The hidden layer has m neurons, where m is a tunable parameter to balance prediction accuracy and computational cost. The output layer has a neuron for each labeling to determine the confidence of being selected as output. We may simply take the labeling with the highest confidence as the optimal index prediction. In this pa-per, we used three labelings for illustration and therefore the output layer consists of three neurons.
The second component performs two tasks. The first task is to verify the correctness of the prediction of N 1 . The other task is to adjust the prediction, if the prediction of N 1 cannot pass the as-sessment. Fig. 1 shows that this component comprises two neural networks N 2 and N 3 and a knowledge base B 1 .Theverifier takes the prediction of N 1 combining with graph features as input and predicts whether N 1  X  X  prediction is correct or not. If it is cor-rect, N 1  X  X  prediction is final. Otherwise, N 2 passes graph features to N 3 for an adjusted prediction.

To construct the second component, we maintain the knowledge base B 1 to record the correctness of previous predictions. The Table 1: Possible predictions of the basic prediction model correctness of previous predictions can be either directly provided by users or verified by experiments offline. Subsequently, trained with the knowledge base and N 3 is trained with the cases where N 2 declared N 1 incorrect. The accuracy of N 1 may drop when the graph features in the input graph have not been encoun-tered before, which are required to identify by N 2 . We remark that the prediction of the verifier N 2 is much simpler than that of which only involves a binary output. In addition, N 3 is specially trained to adjust incorrect predictions.
 Error Analysis. Next, we analyze the expected prediction error of the basic prediction model and compare it with that of a naive method. We first define some notations for the analysis. Abusing the notations slightly, we use N 1 , N 2 and N 3 to denote the cor-rectness of the prediction of the neural networks N 1 , N respectively. We use the value 0, e.g., N i = 0, to denote a correct prediction of N i ,where i  X  {1,2,3}. Similarly, an incorrect pre-diction of N i is denoted as N i = 1. Since we have three neural networks in the basic prediction model, we have eight cases, listed in Tab. 1. In Tab. 1, the four cases of the LHS (respectively, the RHS) shows that the final prediction of the model is correct (re-spectively, incorrect). For instance, in the case where N 2 =0 , N 3 =0 , N 1 predicts incorrectly, N 2 detects the incorrect prediction and N 3 determines the correct prediction to users. Proposition 4.1: Suppose P ( N i =0) &gt;k, 1  X  k&gt; 0 . 5 ,i = { 1 , 2 , 3 } , the basic prediction model outperforms a naive method (i.e., a single neural network) and the performance improvement increases with the growth of k .

P ROOF .Let P 1 denote the error probability of the naive method and P 2 that of the basic append model. P 1 and P 2 are as follows: It follows that
For simplicity, let x, y, z denote P ( N 1 =0) , P ( N 2 =0) P ( N 3 =0) , respectively. (1) is rewritten as
Let the LHS of (2) be 0. We obtain a surface in the 3-d space:
Since P ( N i =0)  X  (0 , 1) , i ={1,2,3}, it is evident that the proba-bility of P 1 &gt;P 2 is the volume above the surface of the cube:
Since x, y &gt; k, k  X  (0 . 5 , 1) by assumption, the space volume above the surface in the cuboid x, y  X  ( k, 1) ,z  X  (0 , 1) and the cuboid X  X  volume is (1  X  k ) 2 . Therefore, the probability of P 1 &gt;P 2 is And if we restrict z&gt;k , it follows
To simplify calculation, we rewrite the surface (3) as and alter integration variables from x, y to y,z . (7) becomes
Since the differential of Formula (9) with respect to k is positive when k&gt; 0.5, P ( P 1  X  P 2 &gt; 0) increases as k increases.
In the context of graph databases, it is often unrealistic to assume the training data graphs are always representative enough. That is, one may need to determine the optimal index for data graphs that have not been encountered in training. Such new graphs often no-tably reduce the accuracy of any prediction model. In this section, we generalize the basic prediction model in order to further en-hance the prediction accuracy.

In a nutshell, we organize the second component of the basic prediction model in a hierarchy. An overview of the hierarchical model is illustrated in Fig. 2. Specifically, the verifier at level noted as N i 2 ) is connected from the hierarchical prediction model at level i  X  1 (i.e., M i  X  1 )and M 0 is simply the second component of the basic prediction model. Such an organization of neural net-works allows the prediction of the model at the lower level to be adjusted by that at the upper level.

More specifically, M i is composed of three elements: (i) two neural networks N i 2 and N i 3 , (ii) the prediction model at the lower level M i  X  1 and (iii) a knowledge base B i to record the prediction correctness of M i  X  1 . Similar to the basic model, N i 2 prediction as input and assesses its prediction. If the assessment passes, M i  X  1  X  X  prediction is delivered to the user. Otherwise, the prediction together with grap h features are delivered to ther adjustment. The adjusted prediction is delivered to the user.
We remark that our approach has a flexibility on the levels of the hierarchy needed for prediction and the refresh frequency of verifiers and adjusted predictors. In comparison, adopting an online neural network (as a black box) doe s not give us su ch a flexibility. Error Analysis. Similar to the analysis on the basic model, we analyze the accuracy of the hierarchical model below.
 Proposition 5.1: Suppose the neural networks X  accuracies are larger than k ,where 0 . 5 &lt;k  X  1 , prediction accuracy increases with the hierarchy level i .
P ROOF . To prove the proposition, we need to argue M i outper-forms M i  X  1 ,forany i  X  1 . Similar to the proof of Proposition 1, we calculate the error probabilities of model with M i  X  1 respectively, as and where M i =1 means  X  M i produces erroneous result X . It follows that
It is of the same form of Equation (1). Hence, we can readily draw the conclusion that P ( P 1  X  P 2 &gt; 0) is larger than 0.5 and increases monotonously with the increase of the accuracy lower bound of
This section presents a preliminary experiment that verifies the effectiveness of our proposed method.
 Hardware and software. We ran our experiments on a machine with a Core2 Quad 2.33GHz CPU and 4GB RAM running Win-dows Vista. We used the interval labeling implementation from Zhu et al [12] written in C, prime labeling implementation from Peng et al [7] written in Java and the 2-hop labeling implementa-tion from Bramandia et al [3] written in C++. We used JDK 1.6 and Microsoft Visual Studio 2008 as the running environment. Datasets and query workload. We used the synthetic graph gen-erator from Zhu et al [12]. We generated 8000 graphs with vertices and fanouts ranging from 1000 to 5000 and from 5 to 20, respec-tively. We divided the graphs randomly into two sets: (i) 5000 for training and (ii) 3000 for testing. For each graph, we estimated the EQT of each indexing technique by measuring the runtime of 100 random reachab ility queries. We then use d the graph features together with the EQT of each index to train the basic prediction model. The correctness of the prediction is compared with the real optimal one. The prediction times were negligible (less than 20 milliseconds) and therefore omitted here.
 Performance results. We first tested the accuracy of the basic pre-dictor. The accuracy is given in terms of of the average accuracy among the testing graphs so far. We refer the accuracy as the aver-age accumulative accuracy . The result is shown in Fig. 3(a). The figure shows that the average accumulative accuracy of the basic prediction model is often higher than 85% for the testing graphs.
Next, we conducted an experiment on the hierarchy prediction model. We trained and tested the accuracies of 1-level, 2-level and 3-level models. The results are shown in Fig. 3(b). The perfor-mances of 2-level and 3-level are 5% more accurate than that of the basic predictor. However, in our particular experiment settings, the improvement of introducing the third level was not significant, as we only tested the hierarchical framework with 3000 graphs. The graphs for training the third level (the knowledge base B ing the adjusted predictor at the third level are relatively small.
Finally, to illustrate that there are in fact some important fea-tures for our index selection problem, we trained the ANN by using classical feature selection algorithm. In particular, we trained our model with the important features, which are | E | , | V | density, and the average fanout. The accuracy of the model is re-ported in Fig. 3(c). It shows that the accuracy is still high when compared to Fig. 3(a) and Fig. 3(c) shows that the model trained without these five features are clearly inaccurate.
In this paper, we propose a hierarchical model to predict the opti-mal index for reachability queries of a graph database and evaluate it with our preliminary experiments. As for future work, we are ex-tending the experiments and analysis on more features, graphs and queries. We are studying how this model is extended to the indexes of other query formalisms, e.g., subgraph isomorphism.

Acknowledgement. This work is partly supported by FRG2/08-09/091 and FRG2/09-10/054. We are thankful to the members of the Database Group of Hong Kong Baptist University for helpful discussions. We are grateful to Rui Shi for her initial implementa-tions.
