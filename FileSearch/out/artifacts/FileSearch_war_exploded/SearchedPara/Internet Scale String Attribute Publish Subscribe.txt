 With this work we aim to make a three-fold contribution. We first address the issue of supporting efficiently queries over string-attributes involving prefix, suffix, containment, and equality operators in large-scale data networks. Our first design decision is to employ distributed hash tables (DHTs) for the data network X  X  topology, harnessing their desirable properties. Our next design decision is to derive DHT-independent solutions, treating DHT as a black box.
Second, we exploit this infrastructure to develop efficient content based publish/subscribe systems. The main con-tribution here are algorithms for the efficient processing of queries (subscriptions) and events (publications). Specifi-cally, we show that our subscription processing algorithms require O ( logN ) messages for a N-node network, and our event processing algorithms require O ( l  X  logN ) messages (with l being the average string length).

Third, we develop algorithms for optimizing the proces-sing of multi-dimensional events, involving several string at-tributes. Further to our analysis, we provide simulation-based experiments showing promising performance results in terms of number of messages, required bandwidth, load balancing, and response times.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  information filtering ; C.2.4 [ Compu-ter-Communication Networks ]: Distributed Systems X  distributed applications Algorithms, Performance DHT networks, publish-subscribe paradigm, string-attribute queries over DHTs, performance
P2P systems are completely decentralized, scalable, and self-organizing. All participating nodes have equal oppor-tunities and all communication exchange is symmetric. A popular class of P2P systems is the  X  X tructured X  P2P sys-tems where the data placement and topology are tightly controlled. The most prominent of these systems are built using Distributed Hash Tables (DHT [17, 15, 19, 29, 1]). DHTs are mechanisms that provide scalable resource look-up and routing.

A large body of recent and current research is target-ing in the extension and employment of P2P data network architectures over either unstructured or DHT-based P2P networks ([27, 25, 14, 8, 12, 9, 11, 5, 7, 28, 13]). This related work has provided solutions for a large number of problems, from architectures and algorithms for searching relevant data, to range query processing and data integra-tion, and has started to examine how to support join and aggregate queries. This fact testifies to the importance our community is giving to being able to support data-intensive applications over large-scale network infrastructures.
Supporting rich queries over string attributes (queries in-volving prefix, suffix, containment and equality predicates) in P2P data networks may be very useful to a number of ap-plications. A representative class of such distributed appli-cations is data management systems built using the publish-subscribe (pub/sub) paradigm.

With our work in this paper we first contribute an infras-tructure, we call DHTStrings that can support rich queries over string attributes on top of a DHT-based data network. We expect this infrastructure to be useful for many emerg-ing applications. Given the popularity of the pub/sub tech-nology, we subsequently show how to utilize DHTStrings in order to build pub/sub systems which are significantly more efficient than the state of the art in current distributed pub/sub systems, for both subscription and event process-ing. Finally, we develop (and experiment with) three dif-ferent optimization algorithms for processing multi dimen-sional events (involving several string attributes).
The rest of the paper is organized as follows: in sec-tion 2 we introduce briefly the background work on DHTs and pub/sub systems. In section 3, we present our solu-tion for supporting queries with string attributes in a DHT-independent infrastructure within the scope of the pub/sub paradigm. In section 4 we present optimizations for multi-dimensional event processing and in section 5 we evaluate the performance of key aspects of our proposal.
Distributed Hash Tables (DHTs [17, 15, 19, 29, 1]) are be-coming increasingly popular for structuring overlay topolo-gies of large-scale data networks. In a DHT each node has a unique identifier (nodeID) selected from a very large address space. Each data item can be associated with a key which is a unique identifier of the same type as nodeID. DHTs can efficiently locate and route a &lt;dataitem,key&gt; pair based on the key identifier. DHTs ensure that routing requires O ( logN ) messages to locate/store a data item in an N -node network.

As an example of a popular DHT we outline how Chord [19] operates. Compared to unstructured P2P networks where neighbors of peers are defined in rather ad-hoc ways, Chord is  X  X tructured X  because of the way peers define their neighbors, forming a ring topology. Chord provides an exact mapping between node identifiers (nodeID) and keys asso-ciated with data items using consistent hashing. NodeIDs and keys are mapped to a large circular identifier space, e.g. [0 , 2 160 ) for 160-bit IDs. Values in this space can be viewed as positions in the ring defining the name/identifier space. Thus, given a key, Chord maps it to the (ring position) node whose nodeID is equal to the key. If this node does not ex-ist, the key is mapped to the first successor of this node on the ring.

Similarly to all DHT-based networks, Chord has a bound-ed performance in terms of messages needed for routing. It efficiently determines the successor of an identifier (key) with O ( logN ) messages in the worst case. Each node main-tains routing information for up to O ( logN ) other nodes. Adding or removing a node from the network can be achieved at a cost of O ( log 2 N ) messages.
In the publish/subscribe paradigm (also known as infor-mation filtering) users express their interests with subscrip-tions . Whenever a certain event of interest appears, the user having issued the subscription is notified. Currently, there are two popular types of publish/ subscribe systems: i) topic-based and ii) content-based . Topic-based systems are much like newsgroups. Content-based systems are preferable as they give users the ability to express their interest by is-suing subscriptions , specifying predicates over the values of a number of well defined attributes, and thus the matching of publications (a.k.a. events )to subscriptions ( interests )is done based on the attributes X  content.

The main challenge in a distributed pub/sub system is the development of an efficient infrastructure to expedite the distributed matching process. Distributed solutions have been provided for topic-based pub/sub systems [4, 16, 30]. More recently, some attempts on distributed content-based pub/sub systems use routing trees to disseminate the events to interested users based on multicast techniques [2, 3, 6, 21, 11, 23]. Typically, processing subscriptions and/or events in these approaches requires one or both of the following: (i) setting up some type of broadcast tree and having the event traverse it in order to reach all possibly relevant sub-scriptions stored at all nodes, and/or (ii) multicasting the subscriptions to all nodes. Thus, invariably event and/or subscription processing requires O ( N ) messages in N -node networks. However, there exist techniques for subscription summarization that may significantly reduce the constant in O ( N ) complexity [24].

Some approaches have also considered the coupling of topic-based and content-based systems. The authors in [20] used a topic-based system (Scribe [4]) that is implemented in a decentralized manner using a DHT (Pastry [17]). In their approach the publications and the subscriptions are automatically classified in topics, using an appropriate ap-plication specific schema. A potential drawback of this ap-proach is the design of the domain schema as it plays a fundamental role in the system X  X  performance. Moreover, it is likely that false positives may occur. The work reported in [22] had the same motivation with this work, but for the much simpler case of numeric attributes and equality and range predicates in a DHT-based event broker network. In [18] keyword searching is supported by applying a multi-level partitioning scheme with inverted indices on top of the Skip-Net P2P infrastructure [10]. SkipNet uses a prefix scheme for node naming, but remains an open issue how this char-acteristic can be used for supporting prefix/suffix matching on string attributes.

Finally, some techniques found in the literature for string indexing may also be relevant to our goals. The most promis-ing is the technique relying on n-grams [9] which can be ap-plied for substring matching. However, they appear to have serious limitations that make them difficult to be applied in a highly dynamic and distributed environment. Decid-ing on the right value of n of n-grams is difficult. At one end of the spectrum, smaller values of n (e.g. bi-grams) introduce larger distributed indexes and a lot of false pos-itives, which in turn costs in network bandwidth and large post-processing chores for filtering the false positives. At the other end, with larger values of n , substring matching withstringsoflessthan n characters is problematic. Thus, typically, several values of n are used, which has a multi-plicative effect on the overheads associated with n-grams. A relevant to our proposal work is presented in [26] where pub-lish/subscribe functionality is offered on top of the Chord DHT using an attribute-value model, called AWPS .
Our first design decision was to employ DHTs as the un-derlying network overlay so as to allow ourselves the luxury of not having to be concerned with the development of an infrastructure that provides dynamic topology maintenance, fault tolerance, scalability, and efficient routing. Until now, it still remains an open problem to leverage DHTs as a dom-inating technology for constructing efficient scalable overlay networks to provide support for rich string attribute queries. Our first contribution, DHTStrings fills this gap. A second key design decision is to be DHT-independent. In this way DHTStrings is easily applicable over any DHT that can efficiently locate an object based on its key iden-tifier. With our second contribution we show how to ex-ploit the DHTStrings infrastructure to build internet-scale content-based pub/sub systems with string attributes. In particular, subscriptions with string attributes are stored using the DHTStrings and exploiting this, an efficient dis-tributed event processing algorithm is presented. We show that in this way the efficiency for subscription processing requires only O ( logN ) messages in an N -node network and O ( l  X  logN ) messages per event attribute for event process-ing (where l is the average length of string values defined for each attribute), compared to the O ( N ) messages required by the state of the art.

Third, we address the issue of optimizing the processing of multi-dimensional events developing two additional novel event-processing algorithms. Up to now, this issue has been largely overlooked.

Finally, we study the performance of our proposals. In particular, we focus on the load balancing characteristics of our subscription storing strategy with DHTStrings and the performance of the three multi-dimensional event process-ing algorithms in terms of bandwidth requirements, network messages, and latency during event processing.
In this section we will show how a pub/sub system may be built on top of a any DHT while supporting a rich set of predicates over string-typed attributes. We will on occasion use Chord for presenting our algorithms due to its popu-larity, simplicity and good performance. Our proposal for this, coined DHTStrings , is a simple, fully functional, and efficient DHT-independent infrastructure for content-based pub/sub systems.
The Event/Subscription Schema . The event/subscri-ption schema is a set of A string attributes ( a i ,1  X  i Each attribute a i consists of a name, and a value v ( a i In this work we will focus on string-typed attributes. We are going to exemplify our approach using a news feed sys-tem. An event (news headlines) is defined to be a set of k &lt; attribute,value &gt; pairs ( k  X  A ), while a subscription (users X  interests) is defined through an appropriate set of constraints on attributes X  values ((i) prefix: the NewsAgency attribute in Sub1, (ii) suffix: the Title attribute in Sub1, and (iii) equality.) over a subset of the A attributes of the schema. An event matches a subscription if and only if all the attribute predicates/constraints of the subscription are satisfied. For example Sub1, matches Event1. An event-subscription example follows:
Sub1= { SubID 1 :: NewsAgency : X  X NN  X   X , Title : X   X  Debuts X  Event1 = { NewsAgency :  X  X NN X , Title :  X  X 380 Debuts X  }
In addition to prefix and suffix predicates, our scheme can also support the  X  X ontainment X  constraint (e.g.  X  X *N X ). This containment operator can be easily decomposed to pre-fix/suffix operations. The main idea is that, for example,  X  X *N X  can be viewed both as prefix (i.e.  X  X * X ) and suffix (i.e.  X *N X ) constraints and with appropriate post-processing we can conclude on possible matching. Due to space limi-tations we omit the detailed methodology for this, which is straightforward given support for prefix/suffix.

Each subscription in our approach is identified by the subscription identifier (SubID) which is the concatenation of three parts: c 1 , c 2 ,and c 3 . c 1 represents the id of the node where the subscription arrived (termed the origin or coordinator node) from a connected to that node client and keeps metadata information about the subscription, c 2 refers to the key of the subscription for identifying it among the stored ones at the origin node, and c 3 is the number of de-clared attributes in the subscription.

System Architecture . Figure 1 depicts the intended pub/sub architecture. Client nodes are producers or con-Figure 1: A network of nodes on top of which lies the DHTStrings infrastructure. sumers, issuing events or subscriptions, respectively. Each client is  X  X ttached X  to a broker node using any appropri-ate such mechanism (e.g., hashing the client X  X  port and IP address with the DHTs hashing scheme). A broker node is a DHT node and is added/deleted from the DHT following the specific DHT related algorithms.

Moreover, we should note that for every subscription there is a node in the DHT network storing metadata information for it. That node is identified by the c 1 field of the sub-scription id and it keeps metadata information about the subscription .
The main idea behind DHTStrings is to store the sub-scription ids (SubIDs) at those nodes of the network that were selected by appropriately hashing the values of the at-tributes in the subscriptions. Then, the matching of an in-coming event can be performed simply by asking those nodes for stored subscription ids.

Hashing is performed with the DHT-specific hash func-tion. For example in Chord, this hash function h() (i.e., SHA-1) returns an identifier quasi-uniformly distributed in the address space used for the node identifiers. Thus, the result (say n ) of this hash function for the value v ( a the attribute a i is quasi-uniformly distributed in the nodes X  identifier address space (where n = h ( v ( a i )) ). The storing procedure requires the storage of the subscription id at the node whose id is the least id equal or greater to n = h ( v ( a (that is successor ( n ) from the Chord API). We maintain three lists (initially empty) for storing SubIDs in every node for every attribute a i of our schema. These are the L ai  X  pref L ai  X  suff ,and L ai where we store the SubIDs of the sub-scriptions that contain prefix, suffix, or equality constraints, respectively, over the attribute a i . The procedure of storing subscriptions can be seen in Table 1.
 Example 1. Storing Subscriptions. Suppose that a user expresses her interests with the following subscriptions:
Sub1= { SubID 1 :: NewsAgency : X   X  N X , Title : X  X ebuts  X   X 
Sub2= { SubID 2 :: NewsAgency : X  X NN X , Title : X  X oncept  X   X  As you can see, in Sub1 the NewsAgency attribute ( a 1 )is defined as a suffix with value  X   X  N X . The storing procedure for this subscription involves the storage of SubID 1 in the list L a 1  X  suff of the node with nodeID= successor ( h ( X  X  X )). Sim-ilarly, for the Title attribute ( a 2 ) with prefix value  X  X ebuts we store the SubID 1 at the L a 2  X  pref list of the succes-sor ( h ( X  X ebuts X )) node. In Sub2 the NewsAgency attribute Storing Subscriptions Notation Table 1: The procedure of storing subscription ids. is declared as an equality operation with value  X  X NN X  re-sulting in storing SubID 2 in the L a 1 list of the node succes-sor ( h ( X  X NN X )). By processing accordingly the a 2 attribute we are done with the storing procedure.
We define the functions prefix (string x, integer j) and suf-fix (string x, integer j) that return the j-characters-long pre-fix and suffix substring of the string x, respectively. For example, prefix ( X  X NN X , 2) =  X  X N X . Suppose now, that an event arrives. The SubID Lists Collection Phase (Table 2) starts by processing each attribute separately. It first tries to find the node which stores SubIDs with equality constraints for the value v ( a i ) of the attribute a i (e.g., in Chord n= successor ( h ( v ( a i ))). The algorithm, then, retrieves the list of unique SubIDs found to be stored there, in the list L ai and stores it in the L ai  X  EQUALITY list in order to inform the interested users for a possible matching 1 .

Apart from the equality operation, the algorithm must also check for any possible matches with subscriptions that have defined prefix and suffix predicates. In order to find the subscriptions that may have declared a prefix operation on the attribute a i we should ask the nodes in the DHT in a way that is similar to that when dealing with equality constraints. For example, in a Chord DHT, we ask those nodes that have nodeID= successor ( prefix ( v ( a i ), j ))for j ranging from 1 to l (where l is the length of string v ( a From those nodes we retrieve the L ai  X  pref lists. The same procedure is performed for the suffix operation, applying the suffix () function and we finally collect the lL ai  X  suff lists. We then merge all the L ai  X  suff and L ai  X  pref into the L
The next step Matching Phase (Table 2), is actually the event-subscriptions matching process. Until now, we have collected three lists with subscription identifiers for each one of the a i attribute defined in the event. Suppose, now, that a subscription SubID i is found to be in some collected list(s) and that this subscription involves N a  X  sub  X  i attributes. It can easily be shown that the subscription matches the event only if it appears in exactly N a  X  sub  X  i lists. The matched
It should be noted that in the L ai  X  X  X  lists we store the (SubID, v ( a i )) pairs so as to collect only those SubIDs that are stored there because of the value v ( a i ). Have in mind that a node may be  X  X esponsible X  for a number of different values.
 Event Processing and Matching
Notation
SubID Lists Collection Phase
Matching Phase
Delivery Phase Table 2: Collecting and Matching the SubIDs of sub-scriptions that are candidate for matching the event. subscription identifiers are further processed in order to in-form subscribers ( Delivery Phase ,Table 2).
 Example 2: Matching Events with Subscriptions. Sup-pose that we have the following two subscriptions stored in DHTStrings and an event arrives with the following values defined:
Sub1= { SubID 1 :: NewsAgency : X   X  N X , Title : X   X  Debuts X 
Sub2= { SubID 2 :: NewsAgency : X  X NN X , Title : X  X oncept  X   X  Event1 = { NewsAgency :  X  X NN X , Title :  X  X 380 Debuts X  }
We start processing the event with the attribute NewsAge-ncy ( a 1 ) and we try to locate the subscriptions that de-clared an equality constraint. Thus, we retrieve the list L from node successor ( h ( X  X NN X )). This list contains SubID We continue by collecting the prefix and suffix lists (the L whose ids are equal to the hashing value of  X  X  X ,  X  X N X , and  X  X NN X  for their stored prefix lists. All of them appear to be empty since none of the two subscriptions have declared a prefix value. We then ask the appropriate nodes by hashing values  X  X  X ,  X  X N X , and  X  X NN X , for their stored suffix lists and we get SubID 1 from node successor ( h ( X  X  X )). Thus after ex-amining both attributes we get the following lists:
Now we continue to the matching phase determining which one of the collected subscriptions are indeed matching the incoming event. From the c 3 part of the identifier of sub-scriptions 1 and 2 we can find out that both subscriptions involve two attributes. Since SubID 1 is found in two lists, a match is implied and so we keep SubID 1 in order to inform the interested user. On the other hand, subscription 2 is found to be in one list and thus we do not have a match for it.
During the subscription storage procedure, O ( logN )hops are required to store the subscription id for each one of the defined attributes. The matching process and more precisely the SubID Lists Collection Phase , is more complicated and requires contacting more nodes. More precisely, for every attribute in the event, we should contact one node in order to retrieve the lists of SubIDs that have declared the equal-ity constraint. Now, suppose that the string length of the attribute a i is l i . Theninordertocollecttheprefixand suffix lists we should contact 2  X  l i nodes which results in 2  X  l i  X  O ( logN ) hops for every attribute. In general for each attribute in the event O ( l  X  logN ) hops are required in the worst case where l is the average length of string values.
Compared to existing systems where the subscription pro-pagation and/or the event matching phase requires O ( N ) hops, our approach is obviously preferable.
The optimizations that follow aim to reduce the process-ing cost during the matching phase at the origin node (the broker node where the incoming event arrived) in order to compute and deliver the matched events to interested users. Our motivation is to distribute when possible/profitable the matching phase to a number of involved DHTStrings nodes.
The algorithm presented in the previous section starts by processing each attribute, a i , of the event separately, by contacting a subset of nodes and retrieving the SubID lists as you can see in Figure 2. It is clear that the matching process is performed at the coordinator node (the broker where the event arrived).

Depending on the characteristics of the system (attribute and value popularities etc.) a significant number of the col-lected subscription ids are going to be dropped as the re-sult of not matching the event. The propagation of those SubIDs, however, is responsible for overloading the network (and increasing the complexity of the matching algorithm at the coordinator node).
A first idea trying to ameliorate the above problem is to perform the matching process in a distributed, step-by-step way, as can be seen in Figure 3. The key idea is to order the events X  attribute-values based on their expected selec-tivity 2 . This selectivity (i.e., the size of the SubID lists with
The problem of identifying the selectivity of an event X  X  at-tribute value is a formidable one in general. However, an ex-tra communication phase between one node per each event attribute and the coordinator node, would allow the coordi-subIDs matching the event X  X  attribute value) depends on the popularity of the attribute (i.e., how many subscriptions are involving this attribute) as well as on the attribute values X  popularity.

This kind of ordering will lead to first processing the at-tributes that are likely to return a small result set and pass those relatively small lists to subsequent nodes in order to perform the matching. At each step i of Distributed Match-ing we ask a subset of nodes for the attribute/value un-der consideration and we merge all lists collected into the list LocalList i . The lists of SubIDs that are sent from the previously examined node-subset are appropriately merged with LocalList i into GlobalList i and are sent to the next subset. Now, at each step i we examine LocalList i and GlobalList i  X  1 .From LocalList i we drop all those SubIDs that have defined 3 an attribute already examined and are not present in GlobalList i  X  1 .From GlobalList i  X  1 we drop those SubIDs that have defined the current attribute and are not present in LocalList i . The remaining SubIDs are merged into GlobalList i and are propagated to the next node. This process continues for the rest attributes.
The weakness of Distributing Matching is that it is pos-sible that many SubIDs, already matching the event, will be sent several times through the DHT network until they finally reach the origin node. Fortunately, often a node has enough information to determine whether it is at all possible that any SubID in a partial result set could possibly be sent back to the origin node and considered as matched. This is the case when the subscription does not declare any of the attributes that are going to be checked in later steps of the distributed matching process.

Hybrid Matching takes advantage of this fact. When we reach a point in the distributed matching where all the de-clared attributes of a subscription are already checked, the subscription matches the event and it is returned back di-rectly to the origin node (Figure 4).
In most real-world environments, attribute value and ac-cess popularity distributions are not uniform. Such skewness may in general create storage and access load imbalances. To study this aspect we conducted a series of experiments varying the skewness of the zipf popularity distribution.
The intuition behind our conjecture that load imbalances are not a significant problem is based on the following ob-servation: even though a skewed value/access distribution of an attribute can create load imbalances, in real world applications there will be tens of attributes. Further, each pub/sub infrastructure is expected to support several appli-cations (each with many attributes). As the total number of supported attributes increases, the load imbalances are disappearing (intuitively, nodes which are heavily hit for nator to know exactly all per-attribute result sizes.
This can be achieved by replacing the c 3 field of the sub-scription identifier with an A-bit vector and mapping each defined attribute in the subscription with 1 in that vector. Figure 2: Coordinated matching. Figure 5: Storage load balancing for five different  X  values of attribute X  X  popularity distribution. storing popular values for one attribute will be less hit for other attributes).

We performed a number of experiments in a simulated 128-node network, generating 20,000 subscriptions with the total number of attributes varying from 1 to 35. As the skewness of the values X  distribution plays a key role here, we varied zipf X  X  popularity distribution parameter  X  from 0.6 (medium skewness) to 1.4 (very high skewness -the worst tested case for load balancing). The string length was set to 6 characters. Figure 5 reports the results. As the number of attributes increases, the load imbalance ratio (i.e. maximum to minimum number of stored subscriptions) drops under the value of 5 even in the case of  X  =1.4, which models a rather extreme skewness. It should be obvious that the same results will be obtained regardless of whether the skewed access distributions refer to value-occurrences (i.e., storage load) or value-accesses (i.e., access load).
Number of Messages . By straightforward analysis one can easily find that Distributed Matching is the best in terms of number of messages. Suppose an event arrives at the system that involves the communication of k broker nodes. In general, under the Coordinated Matching algorithm, the origin broker node (where the event arrives) has to send one DHT message to each one of the k nodes and each of them has to send back a message with the SubID lists stored there. Thus, with Coordinated Matching ,wehavetoperform2  X  k DHT node lookups.
 Figure 6: Varying the skewness of values X  popularity distribution.

Under Distributed Matching , k+1 DHT lookups in to-tal are needed. They are fewer compared to Coordinated Matching by k-1 ,because Distributed Matching avoids the communication of each node with the origin node, except the last one. Finally, with the Hybrid Matching we have to perform 2  X  k lookups, exactly the same as in Coordinated Matching (however, with the already matched subscription ids returned to the origin node).

Network Bandwidth . Perhaps a more important met-ric is the total result sizes that are being transmitted over the DHT, since network bandwidth is a scarce resource. Our specific performance metric here is the total number of SubIDs sent for the processing of each incoming event (when a SubID is sent r times, it is counted as r SubIDs).
In order to find out how the system performs, we con-ducted a series of experiments with a simulated 128-broker network with 10,000 subscriptions and 30,000 generated ev-ents. We varied the skewness of the popularity distributions of attributes (which controls which attributes an event in-volves). We also in parallel varied the skewness of the val-ues X  distributions. The value domain size of each attribute is large enough compared to the number of nodes. The number of attributes that an event or subscription can have, varies from 1 to 10 attributes (and depends on the attributes X  pop-ularity). The popularities of attributes and the values of each attribute follow a Zipf distribution with parameter  X  , varying from 0.1 (more uniform) to 1.0 (more skewed).
In Figure 6 we vary the skewness of attribute values X  distri-bution while  X  for attributes X  popularity equals 0.6. We see Figure 7: Varying Attribute X  X  popularity distribu-tion skewness with  X  =0.5 for values X  distribution. that the preferred algorithm is the Coordinated Matching , which is slightly better that Hybrid Matching , and consid-erably better than Distributed Matching . Note that, despite that the two best algorithms have similar performance, the matching phase is performed in a distributed manner under Hybrid Matching . This is expected to alleviate bottleneck problems related to performing the whole matching phase centrally at a broker in Coordinated Matching . Distributed Matching is the worst, in general, because, as we mentioned earlier, SubIDs that may already match the event, are re-peatedly sent through the network until the last node.
In the next set of experiments we try to figure out under which circumstances the Distributed and Hybrid Matching algorithms can improve their performance compared to Co-ordinated Matching . We first change the attributes X  popu-larity distribution with  X  varying from 0.1 to 1.0. The val-ues X  popularity distribution remains the same for all value domains with  X  = 0.5. The other parameters of the experi-ment remain unchanged.

As Figure 7 shows, Coordinated Matching is marginally better than Hybrid Matching , in all cases. Our intuitive ex-planation is as follows. First, note that the more uniform the distribution of an attribute X  X  values is, the smaller the result set will be when merging a local result set with that sent by another node. This is because different subIDs would, with a higher probability, have picked different values for com-mon attributes. Thus, this is the best case for the filtering performed at each step of Distributed and Hybrid Matching , since they carry around fewer subIDs at each step. In order to verify this we tuned our experimentation, so that popular attributes have uniform value distributions and less popular attributes have skewed value distributions.

As you can see in Figure 8, for small values of  X  (i.e., when many events and subscriptions have a larger number of attributes), Hybrid Matching performs better compared to Coordinated Matching because there are many filtering steps and the popular attributes with small result sets seem to further help the filtering. As the popularity of attributes becomes more skewed the mean number of attributes per event/subscription decreases and thus there are not enough filtering steps for Hybrid Matching to show its worthiness. As you can see in Figure 8 all three algorithms tend to per-form the same as the attributes X  popularity becomes very skewed. A complementary explanation of the good perfor-Figure 8: Varying Attribute X  X  popularity skewness with  X  =1 . 0 for values of unpopular attributes. mance of Hybrid Matching under the above setup (small  X  values in Figure 8) is the fact that the overlap between the result sets of consecutive filtering steps is small and thus Hybrid Matching is capable of filtering as much as possible.
Event Matching Latency . During event matching, a key functionality is to merge all separate per-attribute result lists in order to identify the sudIDs that match all event attribute constraints. The Distributed Matching and Hybrid Matching algorithms appear to introduce processing-latency savings. We now turn to study this in detail.

We ran a number of experiments in a 128-broker network with 10,000 subscriptions and 30,000 generated events. In these experiments we introduce the overlapping factor pa-rameter, which controls the percentage of SubIDs found in both LocalList i and GlobalList i  X  1 in each step i of the fil-tering process. We varied overlapping f actor from 10% (in-dicating large expected filtering at each step) to 100% (in-dicating no filtering at all) and measured the corresponding response times.
 The response times in Hybrid Matching and Distributed Matching drop below 20% of the response time of Coordi-nated Matching for 10% overlapping. As overlapping in-creases, meaning that filtering is less effective form step to step, as fewer SubIDs are dropped, Distributed Matching approaches the performance of Coordinated Matching while Hybrid Matching stays under 50% since the SubID lists at each step are expected to be smaller (recall that Hybrid sends back to the origin node, those SubIDs that are al-ready matched and are not expected to be found in later steps). We ran also experiments with much larger numbers of subscriptions and events -the results are omitted since the relative performance trends are the same.
Internet-scale information filtering systems are an inter-esting area of research and development. Designing for scal-ability and efficiency in these environments poses a number of difficult problems. In this direction, we first developed a relatively simple solution for supporting efficiently queries over string-attributes involving prefix, suffix, containment, and equality operators. Our design choice was to develop the proposed infrastructure on top of a DHT network, leverag-ing its desirable properties. DHTStrings was designed so as to be DHT-independent, guaranteeing wide applicability.
Subsequently, DHTStrings X  functionality was adopted as infrastructure for a content-based pub/sub environment. For this environment then we presented new algorithms for the distributed matching of events. The proposed approach en-joys definite advantages compared to existing approaches: most notably, subscription processing requires O ( logN )nu-mber of messages while distributed event matching requires O ( l  X  logN ) messages per attribute (where l is the average length of string values in the event), in contrast to the O ( N ) messages of competing approaches.

Our next contribution was the development of appropriate algorithms for optimizing the distributed event processing and matching. Finally, our analysis and experimental per-formance study evaluated the developed event processing algorithms in terms of number of messages, required band-width, and matching latency. Furthermore, it studied the load balancing characteristics of our approach for storing subscriptions. Our results prove the soundness and benefits of the proposed approach.

Future work includes the development of algorithms sup-porting substring matching in addition to the prefix-suffix-containment operators defined here. Also, studying these issues in both a DHT-dependent and DHT-independent set-ting.
This work has been partially supported by the IST Pro-gramme of the European Union number IST-2004-001907 (DELIS) and the European Social Fund (ESF), Operational Program for Educational and Vocational Training II (EPE-AEK II), and particularly the Program PYTHAGORAS. [1] K. Aberer. P-grid: A self-organizing access structure [2] G. Banavar et.al. An efficient multicast protocol for [3] A. Carzaniga and A. Wolf. Forwarding in a [4] M. Castro, P. Druschel, A. Kermarrec, and [5] A. Crespo and H. Garcia-Molina. Routing indices for [6] G. Cugola, E. D. Nitto, and A. Fuggetta. The jedi [7] P. Ganesan, B. Yang, and H. G. Molina. One torus to [8] A. Gupta, O. D. Sahin, D. Agrawal, and A. E.
 [9] M. Harren, J. M. Hellerstein, R. Huebsch, B. T. Loo, [10] N. J. A. Harvey, M. B. Jones, S. Saroiu, M. Theimer, [11] R. Huebsch, J. M. Hellerstein, N. Lanham, B. T. Loo, [12] G. Koloniari and E. Pitoura. Content-based routing of [13] S.W.Ng,B.C.Ooi,K.L.Tan,andA.Zhou.Peerdb: [14] V. Papadimos, D. Maier, and K. Tufte. Distributed [15] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and [16] S. Ratnasamy, M. Handley, R. Karp, and S. Shenker. [17] A. Rowstron and P. Druschel. Pastry: Scalable and [18] S. Shi, G. Yang, D. Wang, J. Yu, S. Qu, and M. Chen. [19] I. Stoica, R. Morris, D. Karger, F. Kaashoek, and [20] D. Tam, R. Azimi, and H. Jacobsen. Building [21] W. W. Terpstra, S. Behnel, L. Fiege, A. Zeidler, and [22] P. Triantafillou and I. Aekaterinidis. Publish-subscribe [23] P. Triantafillou and A. Economides. Subscription [24] P. Triantafillou and A. Economidis. Subscription [25] P. Triantafillou, C. Xiruhaki, M. Koubarakis, and [26] C. Tryfonopoulos, S. Idreos, and M. Koubarakis. [27] B. Yang, P. Vinograd, and H. Garcia-Molina.
 [28] G. I. Zachary, N. Khandelwal, A. Kapur, and [29] B. Y. Zhao, A. D. Joseph, and J. D. Kubiatowicz. [30] S. Q. Zhuang et.al. Bayeux: An architecture for
