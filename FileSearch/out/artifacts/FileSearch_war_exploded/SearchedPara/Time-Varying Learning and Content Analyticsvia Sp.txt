 We propose SPARFA-Trace, a new machine learning-based framework for time-varying learning and content analytics for educational applications. We develop a novel message passing-based, blind, approximate Kalman filter for sparse factor analysis (SPARFA) that jointly traces learner con-cept knowledge over time, analyzes learner concept knowl-edge state transitions (induced by interacting with learning resources, such as textbook sections, lecture videos, etc., or the forgetting effect), and estimates the content organiza-tion and difficulty of the questions in assessments. These quantities are estimated solely from binary-valued (cor-rect/incorrect) graded learner response data and the specific actions each learner performs (e.g., answering a question or studying a learning resource) at each time instant. Exper-imental results on two online course datasets demonstrate that SPARFA-Trace is capable of tracing each learner X  X  con-cept knowledge evolution over time, analyzing the quality and content organization of learning resources, and estimat-ing the question X  X oncept associations and the question dif-ficulties. Moreover, we show that SPARFA-Trace achieves comparable or better performance in predicting unobserved learner responses compared to existing collaborative filtering and knowledge tracing methods.
 Expectation maximization, Kalman filter, learning analyt-ics, personalized learning, sparse factor analysis
The traditional  X  X ne-size-fits-all X  approach to education is a major bottleneck to improving learning outcomes world-wide. Fortunately, significant progress has been made over the past few decades on new technologies that provide timely feedback to learners as they follow personalized learning pathways through nonlinearly interconnected learning con-tents. Increasingly, these technologies are based on machine learning algorithms that automatically mine data from a po-tentially large number of learners interacting with learning contents (see [14, 15] for examples).

In our view, a personalized learning system (PLS) con-sists of two key components: (i) learning analytics (LA), which estimate each learner X  X  knowledge state and dynam-ically trace its changes over time, as they either learn by interacting with various learning resources (e.g., textbook sections, lecture videos, labs) and questions (e.g., in quizzes, homework assignments, exams, and other assessments), or forget (see [30]), and (ii) content analytics (CA), which pro-vide insight on the quality, difficulty, and organization of the learning resources and questions.
The recently developed sparse factor analysis (SPARFA) framework [18] proposes a set of statistical model and al-gorithms for machine learning-based LA and CA. SPARFA models Y i,j , the binary-valued graded response of learner j to question i , as a Bernoulli random variable (with 1 repre-senting a correct response and 0 an incorrect one): Here,  X (  X  ) is the inverse logit/probit link function, and the slack variable Z i,j depends on three factors: (i) the question X  concept association vector w i which characterizes how ques-tion i relates to each abstract concept, (ii) the learner con-cept knowledge vector c j of learner j , and (iii) the intrinsic difficulty  X  i of question i . Given a dataset of graded learner response data Y , SPARFA jointly estimates c j ,  X  j to effect LA and w i and  X  i ,  X  i to effect CA.

While powerful, the SPARFA framework has two key lim-itations. First, it assumes that the learners X  concept knowl-edge states remain constant over time; this reduces it X  X  ef-ficacy when applied to scenarios, where learners learn (and forget) concepts over time (weeks, months, years, decades) [4]. Second, SPARFA models only the learners X  interactions with questions, which measure concept knowledge states, and not other kinds of learning opportunities, such as reading a textbook, viewing a lecture video, or conducting a labo-ratory or Gedankenexperiment; this complicates its applica-tion in automatically recommending new resources to indi-vidual learners for remedial or enrichment studies.
In this paper, we extend the SPARFA framework to ad-dress these limitations. We develop SPARFA-Trace , an on-together with question X  X oncept association parameters w and question difficulty parameters  X  i . line estimation algorithm that jointly performs time-varying LA and CA. The core machinery is based on blind approxi-mate Kalman filtering. The working principles of SPARFA-Trace are illustrated in Figure 1. Time-varying LA is per-formed by tracing the evolution of each learner X  X  concept knowledge state vector c ( t ) j over time t , based on observed binary-valued (correct/incorrect) graded learner responses to questions matrix Y and on the learner activity matri-ces R ( t ) . CA is performed by estimating the learner con-cept knowledge state transition parameters D m , d m , and  X  m , the question X  X oncept associations and the question in-trinsic difficulties w i and  X  i , based on the estimated learner concept knowledge states at all time instances.

Tracing the learners X  concept knowledge states over time is non-trivial due to the fact that the observations are noisy, binary-valued graded learner responses to questions. To per-form this on-line estimation process, we develop a novel mes-sage passing-based algorithm in Section 3 that employs an approximate Kalman filter [12]. Furthermore, the underly-ing state-transition and observation parameters are, in gen-eral, unknown in real educational scenarios. Therefore, in Section 4, we introduce a set of novel convex optimization-based algorithms to estimate these parameters directly (and solely) from learner response data.

To test and validate the effectiveness of SPARFA-Trace, we conduct a series of validation experiments in Section 5 us-ing real-world educational datasets collected with OpenStax Tutor [3, 21]. We show that SPARFA-Trace can effectively trace learner concept knowledge, estimate learner concept knowledge state transition parameters, and estimate the question-dependent parameters. Furthermore, we show that it achieves comparable or better performance than existing approaches on predicting unobserved learner responses.
The closest related work to SPARFA-Trace is knowledge tracing (KT), a popular technique for tracing learner knowl-edge evolution over time and for predicting future learner performance (see, e.g., [5, 22]). Powerful as it is, KT suf-fers from three drawbacks. First, KT uses binary learner knowledge state representations, characterizing learners as to whether they have mastered a certain concept or not, which provides limited explanatory power. Second, KT assumes that each question is associated with exactly one concept. This restriction limits KT to very narrow educa-tional domains and prevents it from generalizing to typical courses/assessments involving multiple concepts. Third, KT uses a single  X  X robability of learning X  parameter to charac-terize learner knowledge state transitions. This limits KT X  X  ability to analyze the quality and organization of different learning resources that would lead to different learner knowl-edge state transitions.
We start by extending SPARFA [18] to model learner con-cept knowledge evolution over time. Then, in Section 2.2, we characterize the transitions of a learner X  X  concept knowl-edge states between consecutive time instances as an affine model.
The SPARFA-Trace statistical model characterizes the probability that a learner answers a question correctly at a particular time instance in terms of (i) the learner X  X  knowl-edge on every concept at this particular time instance, (ii) how the question relates to each concept, and (iii) the in-trinsic difficulty of the question. To this end, let N de-note the number of learners, K the number of latent con-cepts in the course/assessment, and T the total number of time instances throughout the course/assessment. We de-fine the K -dimensional vector c ( t ) j  X  R K ,t  X  X  1 ,...,T } ,j  X  { 1 ,...,N } , to represent the latent concept knowledge state of the j th learner at time instance t . Let Q be the to-tal number of questions. We further define the mapping i ( t,j ) : { 1 ,...,T } X { 1 ,...,N } 7 X  { 1 ,...,Q } , which maps learner and time instance indices to question indices; this information can be extracted from the learner activity log. We will use the shorthand notation i ( t ) j = i ( t,j ) to denote the index of the question that the j th learner answers at time instance t as i ( t ) j . Under this notation, we define the K -dimensional vector w question X  X oncept association vector of this question. Fi-nally, we define the scalar  X  culty of question i ( t ) j , with positive values of  X  ing difficult questions, and negative  X  ones.

Given these quantities, we characterize the binary-valued graded response (where 1 denotes a correct response and 0 an incorrect one), of learner j to question i ( t ) j stance t as a Bernoulli random variable: Here, the set  X  obs  X  X  1 ,...,T } X { 1 ,...,N } contains the in-dices associated with the observed graded learner response data, since some responses might not be observed in prac-tice.  X ( z ) denotes the inverse probit link function  X  pro R  X  X  X  N ( t ) d t , where N ( t ) = 1  X  2  X  exp(  X  t normal distribution. (The inverse logit link function could also be used; the inverse probit link function is preferred because it simplifies the calculations in Section 3.2.) The likelihood of an observation Y ( t ) j can, alternatively, be writ-ten as a shorthand expression we will use in what follows.
Following the original SPARFA framework [18], we impose the following model assumptions: (A1) The number of concepts is much smaller than the num-(A2) The vector w i is sparse : This assumption is based (A3) The vector w i has non-negative entries : This assump-
These assumptions are reasonable in most real-world ed-ucational scenarios and alleviate the common identifiability issue inherent to factor analysis (if Z i,j = w T i c have Z i,j = w T i Q T Qc j = e w T i e c j for any orthonormal matrix Q . Hence, the estimation of w i and c j is non-unique up to a unitary transformation). The assumptions also improve the interpretability of the variables w i , c j , and  X  i .
In this section, we propose a latent state transition model that characterizes the learner concept knowledge evolution between two consecutive time instances. We assume here that the concept knowledge state evolves for two primary reasons: (i) A learner may interact with learning resources (e.g., read a section of an assigned textbook, watch a lec-ture video, conduct a lab experiment, run a computer sim-ulation, etc.), all of which are likely to result in an increase of their concept knowledge. (ii) A learner may simply forget a learned concept, resulting in a decrease of their concept knowledge. For the sake of simplicity of exposition, we will treat the forgetting effect [30] as a special learning resource that reduces learners X  concept knowledge over time.
We assume that there are a total of M distinct learning resources. We define the mapping m ( t,j ) : { 1 ,...,T }  X  { 1 ,...,N } 7 X  { 1 ,...,M } from time and learner indices to learning resource indices; this information can be extracted from the learner activity log. We will use the shorthand no-tation m ( t  X  1) j = m ( t  X  1 ,j ) to denote the index of the learn-ing resource that learner j studies between time instance t  X  1 and time instance t . Armed with this notation, the learner activity summary matrices R ( t ) illustrated in Figure 1 are defined by R ( t ) teracted with learning resource m ( t ) j between time instances t and t + 1, and 0 otherwise. We are now ready to model the transition of learner j  X  X  latent concept knowledge state from time instance t  X  1 to t as where N ( x |  X  ,  X  ) represents a multivariate Gaussian distri-bution with mean vector  X  and covariance matrix  X  . I K is the K  X  K identity matrix; D are latent learner concept knowledge state transition param-eters, which define an affine model on the transition of the j th learner X  X  concept knowledge state by interacting with learning resource m ( t  X  1) j between time instances t  X  1 and t . D The covariance matrix  X  induced in the learner concept knowledge state transition by interacting with learning resource m ( t  X  1) j .

In order to reduce the number of parameters and to im-prove identifiability of the parameters D  X  learner knowledge state transition matrix D (A4) D (A5) D (A6) D
In contrast to the learner concept knowledge transition matrix D properties on the intrinsic learner concept knowledge state transition vector d to model cases of poorly designed, misleading, or off-topic learning resources that distract or confuse learners. Note that the forgetting effect can be modeled as a learning re-source with negative entries in d the number of parameters, we assume that the covariance matrix  X 
Time-varying LA requires an on-line algorithm [13] that traces the evolution of learner concept knowledge over time. Designing such an algorithm is complicated by the fact that the binary-valued graded learner responses correspond to a non-linear and non-Gaussian observation model. The parti-cle filter [6] is an on-line state estimation algorithm in non-linear and non-Gaussian systems, which uses a set of Monte-Carlo particles to approximate the latent state distribution. However, its excessive computational complexity prevents it from being applied to personalized learning at large scale (especially if immediate feedback is required). On the con-trary, the Kalman filter [12] is an efficient on-line state esti-mation algorithm for linear dynamical systems (LDSs) with Gaussian observations, but it cannot be directly applied to time-varying LA because of the non-linear, non-Gaussian observation model (1).

In order to recast the time-varying LA problem as an ap-proximate Kalman filter, we next introduce a set of approx-imations that build upon ideas in expectation propagation [20, 23]. We begin in Section 3.1 by reviewing the key ele-ments of the Kalman filtering and smoothing approach, and then detail our approximate Kalman filter in Section 3.2. For notational simplicity, we will omit the learner index j in this section, i.e., the quantities D
The Kalman filter [9, 12] solves the problem of state es-timation in LDSs, where the system consist of a series of continuous latent state variables that are separated by lin-ear state transitions; the state observations are corrupted by Gaussian noise. We briefly summarize the main find-ings from [19]. Let the LDS consists of a series of T latent state variables c ( t ) ,t = 1 ,...,T , and observations y ( t ) ,t = 1 ,...,T . The factor graph [17, 28] associated to this LDS is visualized in Figure 2. The latent states (denoted by dashed circles) form a Markov chain, mean-ing that the next state only depends on the current state Figure 2: Factor graph message passing algorithm for the estimation of a set of T latent state variables with Markovian transition properties from (possibly noisy) observations. but not on previous ones. The Kalman filter estimation procedure of the variables c ( t ) ,  X  t based on the observa-tions y ( t ) ,  X  t (denoted by solid circles) can be formulated as a message-passing algorithm that consists of two phases. First, a forward message passing phase (i.e., the Kalman filtering phase) is performed. Then, using the estimates ob-tained during the Kalman filtering phase, a backward mes-sage passing phase X  X ften referred to as Kalman smoothing or Rauch-Tung-Streibel (RTS) smoothing X  X s performed.
In the forward message passing phase (see Figure 2), the goal is to estimate latent state variables c ( t ) based on the previous observations y (1) ,..., y ( t ) . In other words, the can be obtained via a left-right message passing algorithm outlined in Figure 2.

In Figure 2, the outgoing message  X  ( c ( t ) ) from variable node c ( t ) is given by [19] We can see that a scaled version of  X  ( c ( t ) ), Q interest, which can be obtained in recursive fashion via b
The key to obtaining a tractable and efficient estimator p ( c ( t ) | c ( t  X  1) ) and the observation likelihood p ( y satisfy certain properties such that the messages b  X  ( c b  X  ( c ( t  X  1) ) take on the same functional form, just with differ-ent parameters. A LDS satisfies this requirement, in which the transition probability and the observation likelihood are (multivariate) Gaussians of the following form: Here,  X  m ( t  X  1) is the covariance matrix for state transition, W i ( t ) is the measurement matrix, and  X  i ( t ) is the covari-ance matrix for the multivariate observation of the system. The functional form of the messages is also Gaussian, i.e., b forward message passing recursion (3) is given by with the parameters b ( t ) , m ( t ) and V ( t ) given by in which the matrices K ( t ) and P ( t  X  1) are The recursion starts with p ( c (1) ) = N ( c (1) | m where we assume c (1) to be m (0) = 0 K and V (0) =  X  2 0
Kalman smoothing uses future observations y (  X  ) , X  &gt; t to obtain a better estimate of the latent state at time in-stance t . In other words, the value of interest is now set of backward recursions similar to the set of forward re-cursions (3) can be used: recursively as a backward message passing process, given the estimates (4) following the completion of the forward message passing process detailed above.

Specifically, in an LDS, the recursions take the form: b m b
V
J
The basic Kalman filtering and smoothing, i.e., (4) and (6) are only suitable for applications with a Gaussian latent state transition model and a Gaussian observation model, while the forward and backward recursions (3) and (5) hold for arbitrary state transition and observation models. When attempting to trace latent learner concept knowledge states under the SPARFA model, it is not possible to make Gaus-sian observations of these states. Concretely, we have only binary-valued graded learner responses as our observations. We will now detail approximations that enable the estima-tion of latent learner concept knowledge states for our model.
As introduced in Section 2, the observation model at time t is given by (1) and the state transition model is given by (2). Therefore, the recursion formula for the forward message passing process (3) becomes b D
Equation 7 shows that, b  X  ( c ( t ) ) is no longer Gaussian even if b  X  ( c ( t  X  1) ) is Gaussian, under the probit binary observation model. Thus, the closed-form updates in (4) and (6) can no longer be applied. Therefore, we have to perform an approximate message passing approach within the Kalman filtering framework to arrive at a tractable estimator of c
A number of approaches has been proposed to approxi-mate b  X  ( c ( t ) ) by a Gaussian distribution N c ( t ) here, the bar on the variables denote the means and covari-ances of the approximated Gaussian messages. These ap-proaches include the extended Kalman filter (EKF) [7, 10], which uses a linear approximation of the likelihood term around the point e m ( t ) , and thus reduce the non-Gaussian observation model to a Gaussian one; the unscented Kalman filter (UKF) [11, 27], which uses the unscented transform (UT) to create a set of  X  X igma vectors X  from p ( c ( t  X  1) uses them to approximate the mean and covariance of b  X  ( c after the non-Gaussian observation; and Laplace approxi-mation [23, 31], which use an iterative algorithm to find the mate the mean and covariance of the approximated Gaus-sian messages. We will employ an approximation approach first introduced in the expectation propagation (EP) litera-ture [20].

It is known that the specific values for m ( t ) and V that minimize the Kullback-Leibler (KL) divergence be-are the first and second moments of q ( c ) [23]. For-tuneately, for the probit observation model p ( Y ( t ) | c closed-form expressions (details omitted for simplicity): with and e m ( t ) , e V ( t ) as given by (7).
The inverse probit link function is preferred over the in-verse logit link function, due to the existence of the closed-form first and second moments described above. Therefore, we will focus on the inverse probit link function in the sequel. Armed with the efficient approximation (8), the forward Kalman filtering and backward Kalman smoothing message passing scheme described in Section 3.1 can be applied to the problem at hand. Using these recursions, estimates of the efficiently, providing a way for learner concept knowledge tracing under the model (1).
So far, we have described an approximate Kalman fil-tering and smoothing approach for learner concept knowl-edge tracing, i.e., to estimate p ( c ( t ) j | y (1) The method proposed in Section 3 is only able to provide these estimates if all learner initial knowledge parameters m j , V tion parameters D m , d m , and  X  m ,  X  m , and all question parameters, w i and  X  i ,  X  i , are given a priori.
However, in a typical PLS, these parameters are unknown and need to be estimated from the observed data. We now detail a set of convex optimization-based techniques to esti-mate the parameters D m , d m , and  X  m ,  X  m , and w i ,  X  given the estimates of the latent learner concept knowledge states c ( t ) j obtained from the approximate Kalman filtering approach described in Section 3. The techniques we detail in this chapter allows SPARFA-Trace to jointly trace learner concept knowledge and estimate learner, learning resource, and question-dependent parameters, using an expectation-maximization (EM) approach.
EM has been widely used in the Kalman filtering frame-work to estimate the parameters of interest in the system (see [2, Chap. 13] and [9] for more details) due to numerous practical advantages [24]. SPARFA-Trace performs param-eter estimation in an iterative fashion in the EM framework. All parameters are initialized by random values, and then each iteration of the algorithm consist of two phases: (i) the current parameter estimates are used to estimate the la-tent state distributions p ( c ( t ) j | y (1) j ,..., y ( T ) these latent state estimates are then used to maximize the expected joint log-likelihood of all the observed and latent state variables, i.e., d in order to obtain new parameter estimates. SPARFA-Trace alternates between these two phases until convergence, i.e., a maximum number of iterations is reached or the change in the estimated parameters between two consecutive iterations falls below a given threshold.
The estimation of the learner initial knowledge parameters m j , V
We start by estimating the latent learner concept knowl-edge state transition (i.e., learning resource) parameters D m , d m , and  X  m ,  X  m . To this end, define M m as the set containing time and learner indices ( t,j ) indicating that learner j studies the m th learning resource between time in-stances t  X  1 and t . With this definition, we aim to maximize the expected log-likelihood (9) with respect to D m and d subject to the assumptions (A4) X (A6). We start by estimat-ing D m and d m given  X  m . In order to induce sparsity on D to take (A6) into account, we impose an ` 1 -norm penalty on D m , which is defined as the sum of the absolute values of all entries of D m [8]. Taking only the terms containing D m d m , we can formulate the following augmented optimization problem: (P ( e where L + denotes the set of lower-triangular matrices with non-negative entries. For notational simplicity, we have written [ D m d m ] as e D m . We also write the augmented by e D m , correspondingly. Note that the ` 1 -norm penalty only applies to the matrix D m in this notation.

The problem (P d ) is convex in e D m , and hence, can be solved efficiently. In particular, we use the iterative fast iter-ative shrinkage and thresholding algorithm (FISTA) frame-work [1]. In each iteration ` = 1 , 2 ,...,L max , the algorithm performs two steps. First, a gradient step that aims to lower the objective function performs where f ( e D m ) corresponds to the differentiable part of the objective function (excluding the ` 1 -norm penalty) in (P The quantity  X  ` is a step size parameter for iteration ` . De-tails on how to choose  X  ` can be found in [1]. The gradient  X  f ( e D m ) in (10) is given by  X  f ( e D m ) =  X   X   X  1 m X are obtained from the backward recursions in (6). Next, the FISTA algorithm performs a projection step, which takes into account the sparsifying regularizer  X  k D m k 1 , and the assumptions (A4) and (A5): where P L + (  X  ) corresponds to the projection onto the set of lower-triangular matrices by setting all entries in the upper triangular part of D ` +1 m to zero. The maximum operator acts element-wise on D ` +1 m . The updates (10) and (11) are repeated until convergence, eventually providing a new esti-mate e D new m for [ D m d m ].
Using these new estimates, the update for  X  m can be com-puted in closed form, which will be omitted for simplicity.
We next show how to estimate the question-dependent parameters w i ,  X  i ,  X  i . To this end, we define Q collection set of time and learner indices ( t,j ) that learner j answered the i th question at time instance t . We then minimize the expected negative log-likelihood of all the ob-served binary-valued graded learner responses (1) for the i question, subject to (A2) and (A3). In order to impose spar-sity on w i , we add an ` 1 -norm penalty to the cost function, which leads to the following optimization problem: The problem (P w ) is convex in w i , thanks to the fact that the negative log-likelihood of the observation likelihood is convex and the linearity of the expectation operator (see [18] for details). However, the inverse probit link function pro-hibits us from obtaining a simple form of this expectation. In order to develop a tractable algorithm to approximately solve this problem, we utilize the unscented transform (UT) [27] to approximate the cost function of (P w ).

Following the paradigms of the UT, we generate a set of sigma vectors { ( e c ( t ) j ) n } and a corresponding set of weights { u n } , n  X  X  1 ,..., 2 K + 1 } , for each latent state vector c tion in the optimization problem (P w ) can now be approxi-mated by a weighted average of the cost function evaluated using the FISTA framework [1]. The gradient step is given by The gradient  X  f ( w i ) is given by  X  f ( w i ) =  X  f C i is a (2 K + 1) |Q i | X  1 vector r i = [ a 1 i ..., a |Q i a i is defined by a in which ( t q ,j q ) represents the q th time X  X earner index pair in Q i . The K  X  (2 K + 1) |Q i | matrix e C i is defined as ( G i ) 1 ,..., ( G i ) |Q i | , where the K  X  (2 K + 1) matrix ( G is given by
The projection step is given by For simplicity of exposition, the question intrinsic difficul-ties  X  i are omitted in the derivations above, as they can be included as an additional entry in w i as [ w T i  X  i ] T sponding latent learner concept knowledge state vectors c are augmented accordingly as [( c ( t ) j ) T  X  1] T . Table 1: Comparisons of SPARFA-Trace against knowledge tracing (KT) on predicting responses for new learners using using Dataset 1. SPARFA-Trace slightly outperforms KT on all three metrics.

We now demonstrate the efficacy of SPARFA-Trace using real-world educational datasets. We begin by comparing SPARFA-Trace against two established methods on predict-ing unobserved binary-valued learner response data, namely knowledge tracing (KT) [5, 22] and SPARFA [18]. Then, we show how SPARFA-Trace is able to visualize learners X  con-cept knowledge state evolution over time, and the learning resource and question quality and their content organiza-tion. The regularization parameters  X  and  X  are chosen via cross-validation [8], and all experiments are repeated for 25 independent Monte X  X arlo trials.
We now compare SPARFA-Trace against the KT method described in [22] for predicting responses for new learners that do not have previous recorded response history.
The dataset we use for this experiment is from an under-graduate computer engineering course collected using Open-Stax Tutor (OST) [21]. We will refer to this dataset as  X  X ataset 1 X  in the following experiments. This dataset con-sists of the binary-valued graded response from 92 learners answering 203 questions, with 99 . 5% of the responses ob-served. The course is organized as three independent sec-tions: The first section is on digital logic, the second on data structures, and the third on basic programming con-cepts. The full course consist of 11 assessments, including 8 homework assignments and an exam at the end of each section; we assume that the learners X  concept knowledge state transitions can only happen between two consecutive assignments/exams, due to their interaction with all the lec-tures/readings/exercises.

Since KT is only capable of handling educational datasets that involve a single concept, we partition Dataset 1 into three parts, with each part corresponding to one of the three independent sections. We run KT independently on the three parts, and aggregate the prediction results. We ini-tialize the four parameters of KT (learner prior, learning probability, guessing probability, slipping probability) with the best initial value we find over 5 different initializations. For SPARFA-Trace, we use K = 3, with each concept cor-responding to one section of the dataset.

For cross-validation, we randomly partition Dataset 1 into 5 folds, with each fold consisting of 1 / 5 of the learners an-swering all questions. Four folds of the data are used as the training set and the other fold is used as the test set. We train both KT and SPARFA-Trace on the training set and obtain estimates on all learner, learning resource and question-dependent parameters, and test their prediction performances on the test set. For previously unobserved new learners in the test set, both algorithms make future predictions of Y ( t ) j based on these estimates and observa-tions Y (1) j ,...,Y ( t  X  1) j , for t = 1 ,...,T . Table 2: Comparisons of SPARFA-Trace against SPARFA-M on predicting unobserved learner re-sponses for Dataset 1.

We compare both algorithms on three metrics: prediction accuracy, prediction likelihood, and area under the receiver operation characteristic (ROC) curve. The prediction ac-curacy corresponds to the percentage of correctly predicted responses; the prediction likelihood corresponds to the av-erage the predicted likelihood of the unobserved responses, is the set of unobserved learner responses in the test set; the area under the ROC curve is a commonly-used performance metric for binary classifiers (see [22] for details).
The means and standard deviations of all three metrics covering multiple cross-validation trials are shown in Ta-ble 1. We can see that SPARFA-Trace slightly outperforms KT on all performance metrics for Dataset 1. We also em-phasize that SPARFA-Trace is capable of achieving superior prediction performance while simultaneously estimating the quality and content organization parameters of all learning resources and questions. We now compare SPARFA-Trace against the original SPARFA framework [18], which offers state-of-the-art col-laborative filtering performance on predicting unobserved binary-valued graded learner responses.

We will use two datasets in this experiment. The first dataset is the full Dataset 1 with 92 learners answering 203 questions, explained in Section 5.1. The second dataset we use is from a signals and systems undergraduate course on OST, consisting of 41 learners answering 143 questions, with 97 . 1% of the responses observed. We will refer to this dataset as  X  X ataset 2 X  in the following experiments. All the questions were manually labeled with a number of K = 4 concepts, with the concepts being listed in Figure 5(b). The full course consist of 14 assessments, including 12 assign-ments and 2 exams.

We randomly partition the 143  X  43 (or 203  X  92) matrix Y of observed graded learner responses into 5 folds for cross-validation. Four folds of the data are used as the training set and the other fold is used as the test set. We train both the probit variant of SPARFA-M and SPARFA-Trace on the training set to obtain estimates of all model parameters and then use these estimates to predict unobserved held-out re-sponses in the test set.

The means and standard deviations of the prediction ac-curacy and prediction likelihood metrics covering multiple cross-validation trials are shown in Tables 1 and 2. We see that SPARFA-Trace achieves comparable or better perfor-mance than the static SPARFA-M on both datasets. In this section, we showcase another advantage of SPARFA-Trace over existing KT and collaborative filtering methods, i.e., the visualization of both learner knowledge Figure 3: Estimated latent learner concept knowl-edge states for all time instances, for Dataset 1. (a) Learner 1 X  X  latent concept knowledge state evolu-tion; (b) Average learner latent concept knowledge states evolution. state evolution over time and the estimated learning resource and question quality and content organization parameters.
Figure 3(a) shows the estimated latent learner concept knowledge states at all time instances for Learner 1 in Dataset 1. We can see that their knowledge on Concepts 2 and 3 gradually improve over time, while their knowledge on Concept 1 does not. Therefore, recommending Learner 1 remedial material on Concept 1 seems necessary, which is verified by the fact that Learner 1 often responds incorrectly on questions covering Concept 1 towards the end of the course. Hence, SPARFA-Trace can enable a PLS to provide timely feedback to individual learners on the their concept knowledge at all times, which reveals the learning progress of the learners. Figure 3(b) shows the average learner concept knowledge states over the entire class at all time instances for Dataset 1. Using this information, SPARFA-Trace can also inform instructors on the trend of the concept knowl-edge state evolution of the entire class, in order to help them make timely adjustments to their course plans.

Figure 4(a) and Figure 4(b) show the quality and content organization of learning resources 3 and 9 for Dataset 2. These figures visualize the leaners X  concept knowledge state transitions induced by interacting with Learning Resources 3 and 9. Circular nodes represent concepts; the leftmost set of dashed nodes represent the concept knowledge state vector c ( t  X  1) , which are the learners X  concept knowledge states be-fore interacting with these learning resources, and the right-most set of solid nodes represent the concept knowledge state vector c ( t ) , which are the learners X  concept knowledge states after interacting with these learning resources. Arrows rep-resent the the learner concept knowledge state transition matrix D m , the intrinsic quality vector of the learning re-source d m , and their transformation effects on learners X  con-cept knowledge states. Dotted arrows represent unchanged learner concept knowledge states; these arrows correspond to zero entries in D m and d m . Solid arrows represent the intrinsic knowledge gain of some concepts, characterized by large, positive entries in d m . Dashed arrows represent the change in knowledge of advanced concepts due to their pre-requisite concepts, characterized by non-zero entries in D High knowledge level on pre-requisite concepts can result in improved understanding and an increase on knowledge of advanced concepts, while low knowledge level on these pre-requisite concepts can result in confusion and a decrease on knowledge of advanced concepts.

As shown in Figure 4(a), Learning Resource 3 is used in early stage of the course, and we can see that this learn-t-1 t Figure 4: Visualized learner knowledge state tran-sition effect of two distinct learning resources for Dataset 2. (a) Learner knowledge state transition effect for Learning Resource 3; (b) Learner knowl-edge state transition effect for Learning resource 9. ing resource gives the learners a positive knowledge gain of Concept 2, while also helping on the more advanced Con-cepts 3 and 4. As shown in Figure 4(b), Learning resource 9 is used in later stage of the course, and we can see that it uses the learners X  knowledge on all previous concepts to im-prove their knowledge on Concept 4, while also providing a positive knowledge gain on Concepts 3 and 4.

By analyzing the content organization of learning re-sources and their effects on learner concept knowledge state transitions, SPARFA-Trace enables a PLS to automati-cally recommend corresponding learning resources to learn-ers based on their strengths and weaknesses. The estimated learning resource quality information also helps course in-structors to distinguish between effective learning resources, and poorly-designed, off-topic, or misleading learning re-sources, thus helping them to manage these learning re-sources more easily.

Figure 5 shows the question X  X oncept association graph obtained from Dataset 2. Circle nodes represent concept nodes, while square, box nodes represent question nodes. Each question box is labeled with the time instance at which it is assigned and its estimated intrinsic difficulty. From the graph we can see time-evolving effects, as questions assigned in the early stages of the course cover basic concepts (Con-cepts 1 and 2), while questions assigned in later stages cover more advanced concepts (Concepts 3 and 4). Some ques-tions are associated with multiple concepts, and they mostly correspond to the final exam questions (boxes with dashed boundaries) where the entire course is covered.

Thus, by estimating the intrinsic difficulty and content or-ganization of each question, SPARFA-Trace allows a PLS to generate feedback to instructors on the underlying knowl-edge structure of questions, which enables them to identify ill-posed or off-topic questions (such as questions that are not associated to any concepts in Figure 5(a)).
We have proposed SPARFA-Trace, a novel blind approx-imate Kalman filtering approach for time-varying learning and content analytics. The proposed method jointly traces latent learner concept knowledge evolution over time and si-multaneously estimates the quality and content organization of the corresponding learning resources (such as textbook sections or lecture videos) and the questions in assessment sets. Being able to trace learners X  concept knowledge evo-lution over time will enable a PLS to make timely feedback Figure 5: (a) Question X  X oncept association graph and concept labels for Dataset 2. (a) Question X  concept association graph. Note that for the vi-sualization to be compact, we show only 1 / 3 of all questions in the dataset; (b) Label of each concept. to learners on their strengths and weaknesses. Furthermore, the estimated content-dependent parameters provide rich in-formation on the knowledge structure and quality of learning resources. Together with the question parameters estimated, a PLS would be able to operate in an autonomous manner, requiring only minimal human input and intervention; this paves the way of applying SPARFA-Trace to MOOC-scale education scenarios, where the massive amount of data pre-cludes manual intervention.

We note that SPARFA-Trace has potential to be applied to a wide range of other datasets, including (but not neces-sarily limited to) the analysis of temporal evolution in leg-islative voting data [29], and the study of temporal effects in general collaborative filtering settings [16, 25, 26, 32]. Thanks to Kim Davenport and JP Slavinsky for providing the OpenStax Tutor (OST) data and Andrew Waters and Ryan Ning for helpful discussions. This work was supported by the National Science Foundation under Cyberlearning grant IIS-1124535, the Air Force Office of Scientific Research under grant FA9550-09-1-0432, and the Google Faculty Re-search Award program. Visit the website www.sparfa.com , where you can learn more about the SPARFA project and purchase t-shirts and other merchandise. [1] A. Beck and M. Teboulle. A fast iterative shrinkage-[2] C. M. Bishop and N. M. Nasrabadi. Pattern Recognition [3] A. C. Butler, E. J. Marsh, J. P. Slavinsky, and R. G. [4] M. Carrier and H. Pashler. The influence of retrieval on [5] A. T. Corbett and J. R. Anderson. Knowledge tracing: [6] A. Doucet, N. De Freitas, K. Murphy, and S. Rus-[7] G. A. Einicke and L. B. White. Robust extended [8] T. Hastie, R. Tibshirani, and J. Friedman. The Ele-[9] S. S. Haykin. Kalman Filtering and Neural Networks . [10] A. H. Jazwinski. Stochastic Processes and Filtering [11] S. J. Julier and J. K. Uhlmann. New extension of the [12] R. E. Kalman. A new approach to linear filtering and [13] S. P. Kasiviswanathan, H. Wang, A. Banerjee, and [14] G. Kennedy, I. Ioannou, Y. Zhou, J. Bailey, and [15] Knewton. Knewton adaptive learning: Building the [16] Y. Koren and J. Sill. OrdRec: an ordinal model for [17] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger. [18] A. S. Lan, A. E. Waters, C. Studer, and R. G. Bara-[19] T. P. Minka. From hidden Markov models to linear [20] T. P. Minka. Expectation propagation for approximate [21] OpenStaxTutor. https://openstaxtutor.org/, 2013. [22] Z. A. Pardos and N. T. Heffernan. Modeling individ-[23] C. E. Rasmussen and C. K. I. Williams. Gaussian Pro-[24] S. Roweis and Z. Ghahramani. Learning nonlinear dy-[25] J. Silva and L. Carin. Active learning for online [26] N. Thai-Nghe, T. Horvath, and L. Schmidt-Thieme. [27] E. A. Wan and R. Van Der Merwe. The unscented [28] C. Wang, J. Tang, J. Sun, and J. Han. Dynamic so-[29] E. Wang, E. Salazar, D. Dunson, and L. Carin. Spatio-[30] B. Weiner and H. Reed. Effects of the instructional [31] R. Wolfinger. Laplace X  X  approximation for nonlinear [32] H. Yu et al. Feature engineering and classifier ensemble
