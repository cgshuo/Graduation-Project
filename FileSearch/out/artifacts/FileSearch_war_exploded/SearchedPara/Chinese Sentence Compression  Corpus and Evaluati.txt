 {zhangcl, huminghan, xiaotong, zhujingbo}mail.neu.edu.cn; Recent years have seen increasing interests in automatic sentence compression among the natural language pro c essing researchers for a wide range of practical applications, such as text summarization, machine translation, and question answering. In general, the task of sentence compression can be described as creating a shorter form of a se n-tence while retaining the most important information and remaining grammaticality [8] . To date, many statistical models have be en developed in sentence compression , showing continuous improvements on several tasks ([3 -4], [7], [10 -11], [18], [21 -22]). relies on manually ann o tated corpora for training model parameters (in a supervised manner), system tuning, and evaluation of final results. However, the scarcity of such data restricts most work in English compre s sion ta sks (e.g., the Ziff -Davis corpus ) and it is rare to see efforts in other languages.
 most popular languages other than English. We regard sentence compression as a task of ident ifying the selection word sequence of a sentence. In this way a compressed sentence is in principle a backbone of the original sentence and can be gene r ated by removing all  X  unimportant  X  words. The co n tributions of this work are two -fold:  X  We manually devel op a Chinese sentence compression corpus consisting of 3 , 308 sentences from the Penn Chinese Treebank. For each sentence, there is at least one annotation. In addition , we provide three annot a tions for a sub -set of 563 sentences, which can be used as bench mark for evaluation of Chinese sentence compression system s . To the best of our knowledge, this is the first -ever manually annotated corpus for Ch i nese sentence compression.  X  We study various evaluation metrics on the developed system for Chinese sentence compression . We find that 1) using multiple reference s is more helpful for aut o-matic evaluation of the system performance than using the single -reference , as the strategy adopted in previous stud ies ; 2) four evaluation metrics, grammatical rel a-tions F1, mWE R, mPER and GTM , have good co -relations with human judgments when used to measure the performance of the compression systems in terms of grammaticality and importance, and , therefore, are more desir able for automatic evaluation of Chinese sentence co m press ion.
 automatic system output and human judgments) is accessible to public 1 and can be used in further study and system development for this task. We believe that the deve l-oped corpus would motivate more studies on identifying the skeleton/main structure of Chinese sentences and would thus benefit many downstream NLP applications , such as machine translation and text summarization . Most previous work addresses the sentence compression task on English corpora. The most f a mous of these is the Ziff -Davis corpus [9] , a collection of 1,067 sentences created automatically by matching sentences in a news article with sentences co n-tained in its abstract. Yamangil and Nelken [20] collected a large -scale co r pus of over 380,000 sentence pairs by mining the Wikipedia revision history of the articles and picking out those se n tences with the record of word addition or deletion . B ut their work was based on a n a s sumption that all th e edits retain the core meaning of the sentence. T here are two corpora manually created for English sentence compre s sion [2] , one is a 1,433 -sentence dataset built from the British National Corpus and the American News Text Corpus, and the other is a 1,370 -sentence dataset from the HUB -4 1996 English Broadcast News Corpus. Ho w ever, to our knowledge, there is no such data in Chinese for sentence compression r e search. 3.1 Data Selection The original data in this work comes from the source -lang uage side of the Penn Para l-lel Chinese -English Tre e bank ( LDC2003E07 ). We choose this data set for annotation because all the sentences in the Penn Chinese Treebank (CTB) are of very good qua l i-ty[19]. As these CTB sentences have been manually annotated wit h word segment a-tion, POS tags and syntactic structures, we believe they will be useful in studying the sentence co m pression problem on different conditions, e.g., comparison of the results obtained on gold -standard and aut o matic word segmentations/ syntacti c trees. Besides, our dataset in Chinese parallels with its English counterpart, and thus can be used in future studies of bilingual sentence compression or applying compression results in m a chine translation. 1 -8 consist of articles 001 -270 and are with one annotation. Part 9 and Part 10 consist of articles 271 -300 and articles 301 -325 respectively, and both are with three annot a-tions.
 3.2 Annotation Guideline This study focuses on Chinese s entence compression mainly for identifying the main structure of the Ch i nese sentence . We view sentence compression as a task of keeping the most important grammat i cally -motivated items of a sentence and removing all unimportant items. So in this work the result of sentence compression is in esse n tial a grammatically -motivated skeleton of the input se n tence . sentences only with word segmentation 2 and are required to compres s the sentences by deleting the unimportant words while remai n ing sentence grammaticality.
 the complement. The subject, the predicate, and the object are primary constituents, and the attributive, the adverbial, and the compl e ment are secondary ones. constituents in a sentence, and then to remove the secondary constituents and retain the primary ones, because we believe the primary co n stituent s constitute the structural backbone and carry the most valuable info rmation in a sentence, and the seco n dary constituents just act as modifiers of one primary constituent and carry unimportant information. As shown in Fig.1 3 , the annotators should first decompose the se n tence into different constituents: the subject(sub.), the predicative(pred.), the object(obj.), the attrib u tive(attr.), and the adverbial(adv.). Note that this Chinese sentence includes three auxiliary words: two structur e -auxiliary words 4  X   X  (DE1)  X  and  X   X  (DE2)  X  , which mark the pr e ceding constituents as the attributive and the adverbial respectively, and one aspect -auxiliary word  X   X  (ZHE)  X  5 , which is a t tached to the preceding verb sentence constituents are identified, the sentence compression is done by deleting the attrib u tive  X   X  X  X  (noon)  X  , the adverbial  X   X  X  X  X  (fiery)  X  and their attached structural auxiliary words,  X   X  (DE1)  X  and  X   X  (DE2)  X  . level. To save space, we list only a few critical annotation rules here 6 .
 structural auxiliary  X   X  (DE1)  X  . Besides, the degree adverbs, such as  X   X  (very)  X  and  X   X  X  X  X  (a little)  X  , will be deleted if they modify an adjective, as the phrase  X   X   X  (very beautiful)  X  is compressed as an adje c tive  X   X  (beautiful)  X  . phrase and the prepositional phra se. For the noun phrase comprised of a succession of nouns, some nouns will be d e leted if they modify the other nouns, as the noun phrase  X   X  X  X   X  X  X   X  X  X   X   X  X  (CNN correspon d ent)  X  is compressed as the noun  X   X  X  ( correspondent )  X  , for human annotators can eas i ly dist inguish the two units of the phrase, the unit of a proper noun,  X   X  X  X   X  X  X   X  X  X   X  (CNN)  X  , modifying the unit of a noun  X   X  X  ( correspondent )  X  . Another kind of noun phrase is that it contains two cor e-ferents, like the phrase  X   X  X   X  X   X  X  X   X  X  X  X  (Chinese president Xi Jinping )  X  , where  X  X   X  X   X  X   X  X  X  (Chinese president)  X  , the job title, and  X   X  X  X  X  (Xi Jinping)  X  , the person  X  s name, corefer to each other. I n such a case, the compression is done by deleting one of them ( usually retaining the proper noun). For the prepositional phrase, it will be deleted when it functions as the adverbial in the se n tence, as the phrase  X   X   X  X  X  X   X   X  X  X   X   X  X  X  (study for a beautiful tomorrow)  X  is compressed as  X   X  X  X  ( study )  X  by deleting the prepositional phrase  X   X  X  X  X  X  X   X   X  X  X  (for a beautiful t o-morrow)  X  .
 compres sion, as in Fig. 2, the parenthesis  X   X   X  X  X  (it is reported)  X  , which shows the source of information for the following statement, is deleted for sentence compre s-sion because it seems to be an independent element from the other parts of the se n-tence.
 of Chinese sentence co m pression, we list them in table 2 with examples. 3.3 Quality Control Three annotators 9 part icipate in this task . To guarantee high annotation quality, we implement a two -phase pro c ess: phase 1 is a multi -round pilot annotation on small -size datasets for training and phase 2 is a formal annot a tion on the full size dataset . tor X  X  work and Fleiss X  K a p pa [6] for the inter -annotator agreement . After each round of annotation, the manual is revised based on our review of th e inter -annotation i n-consistencies and discussion about the ambiguous cases. Only after Fleiss X  K appa indicat es the inter -annotator agreement is satisfactory and remains stable will the pilot annotation stop and the fo r mal -run annotation start.
 sentence s) , providing one reference result for each source sentence. To further check the inter -annotator consistency, the three annotators work on Part 9 and Part 10 r e-spectively , and thu s each sentence in these two datasets has three reference compre s-sion result s . Using the corpus presented above, we develop a Chinese sentence compression sy s-tem and study various evalu a tion methods for this task. 4.1 Automatic Sentence Compre s sion We use Tree Transducer Toolkit (T3) 10 to build a Chinese sentence compression sy s-tem . T3 is a tree -to -tree transduction model based on synchronous tree -substitution grammar s (STSG s ) , which achieves state -of -the -art performance in the English se n-tence compression task s [4] . To enable T3 to perform on the Chinese data, we modify the head -finding rules according to the Chinese head rules described in [1] . We use the data of Parts 1 -8 as the training set, Part 9 as tuning set and Part 10 as the test set. To obtain the n -gram feature, we train a tri -gram language model on the Xinhua and AFP Portions of the GIGAWORD Chinese corpus . Since T3 requires CTB -style trees, we use the Berkeley parser 11 to parse all the sentences 12 . By default we choose the asymm etric hamming distance loss function for the large margin training of the sy s-tem. 4.2 Evaluation Metrics Like in English sentence compression tasks, we choose grammatical relation F1 as one of the evalu a tion metrics , which allows us to measure the semantic asp ects of summarization quality in terms of grammatical -functional information [14] . We use the ZPar dependency parser 13 [23] to extract Chinese grammatical relations for all the se n tences in the test set and gold references .
 sentence against its gold reference(s), which is similar to the evaluation of MT sy s-tems, especially when no paraphrasing is performed in co m pression as we do in this work. Therefore, we adopt addition al MT ev aluation metrics in our exper i-ment .Specifically w e choose three n -gram and similarity -based metrics, BLEU [13] , NIST [5] and GTM [17] , which are very popular in automatic evaluation methods in MT . Besides, w e use three Levenshtein distance based metrics, mWER [12] , mPER [16] , and TER [15] , which regard the evaluation problem as pai r wise string alignment between the output string and the gold re f erence 14 .
 judgments , we also conduct human e valuation on the same data. Judges are required to separately rate along a 5 -point scale how much information the compressed se n-tence retains against the source sentence (i.e., i m portance ) and how grammatical the compression is without the presence of the source sentence (i.e., g rammaticality ). 4.3 Results and Analysis Table 6 shows the automatic evaluation results on t he test set with single and multiple and show i rregular var i ance by different measures. We attribute this to the ambiguity of sentence compression tasks, that is, even though annotators can get agre e ment in most cases, there exists some cases with more than one correct answer. This explan a-tion is further co n firmed when we switch to the multi -reference evaluation. By the 3 -reference result, all measures show significant di f ferent scores (or better performance) with the single -reference counterparts, indicating that the sentence co m pression task has some natural ambiguities which cannot be eliminated , even for well -trained n a tive language annotators. T herefore, for reliabl e estimation of the compression system performance, it is necessary to conduct evalu a tion with more than one reference. This finding is actually somewhat similar to that in machine translation where correct translations are plenty and the evaluation agains t a single reference is very u n reliable [ 13] .
 To conduct evaluation on diverse compression results , we generate five outputs with different loss functions used in the T3 toolkit 15 . 7 Ch i nese native -language judges participate in the evaluation and score each system output by the rating schema pr e-sented in Section 4.2 . Table 6 shows that compression rate is an important factor for a success ful Chinese sentence compression system. For e xample, the best result (output 3) is achieved when the compression rate is clo s est to those of the references, while the worst result (output 2) corresponds with a compression rate that is the fa r thest from the reference rates as shown in Table 4 .
 scores 16 . As shown in Fig . 3 , most of these measures correlate well with the human judgments on ou t puts 1, 2, 3 and 5 . However, they cannot distinguis h well between output 1 and output 4 which are quite close in human evaluation. This pheno m enon reflects a limited ability of current automatic metrics in prediction on similar co m-pression results. Furthermore, we use the Pearson Correl a tion Coefficients t o estimate the correlation degree. Table 7 shows that relatio n al F1 correlates best with judges (around 0.90), which agrees with the observation seen in the English task s [3] . More interestingly, it is observed that GTM, mWER and mPER obtain very good corre l a-tion scores (abs o lute value &gt; 0.8 7 ), followed by BLEU and NIST (absolute value &gt; 0. 79 ). These r e sults indicate a very promising application of MT evaluation methods in Chinese se n tence compression tasks.
 We have presented a first -ever manually -built Chinese sentence compression corpus. By using this corpus, we develop a n automatic sentence compression syst em and stud y various evaluation methods on this task. We find that 1) using multiple refe r-ences is necessary for automatic evaluation; and 2) besides relational F1, some MT evaluation measures are also well correlates with human judgments, and are very pro mising for the evaluation of sentence compression sy s tems.
 by annotating the other parts of the CTB data and apply the corpus to some NLP tasks like machine tran s lation.
 This work was supported in part by the National Science Foundation of China (61073140; 61272376), Specialized Research Fund for the Doctoral Program of Higher Education (20100042110031) and the Fund a mental Research Funds for the Central Univers ities (N100204002).
 thank Yue Zhang for his a s sistance with the ZPar statistical parser. Finally we thank Matt Snover for assisting us to use the TER metric in our Chinese sentenc e compre s-sion eva l uation work. 
