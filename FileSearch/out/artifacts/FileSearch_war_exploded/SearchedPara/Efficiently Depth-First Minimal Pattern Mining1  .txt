 Minimality is an essential concept of pattern mining. Given a function f and a language L , a minimal pattern X is one of the smallest pattern with respect to the set inclusion in L satisfying the property f ( X ). Interestingly, the whole set of minimal patterns forms a condensed representation of L adequate to f :it is possible to retrieve f ( Y ) for any pattern of Y in L . Typically, the set of free itemsets [1] (also called generators or key itemsets [2]) is a co ndensed representa-tion of all itemsets (here, f and L are respectively the frequency and the itemset language). Of course, it is often more effici ent to extract minimal patterns rather than all patterns because they are less numerous. In addition, minimal patterns have a lot of useful applications including higher KDD tasks: producing the most relevant association rules [3], building classifiers [4] or generating minimal traversals [5]. Minimality has been studied in the case of different functions (like frequency [6] and condensable functions [ 7]) and different languages (e.g., item-sets [1] and sequences [8]). Although the minimality has obvious advantages [9], very few studies are related to the minimality while maximality (i.e., closed pat-terns) has been widely studied. In particu lar, to the best of our knowledge, there is no framework as general as those proposed for maximality [10].

We think that a current major drawback of minimal patterns lies in their inef-ficient extraction. This low efficiency co mes mainly from the fact that most exist-ing algorithms use a levelwise approach [1,7,11] (i.e., breadth-first search/generate and test method). As they store all candidates in memory during the generation phase, the extraction may fail due to memory lack. To tackle this memory pitfall, it seems preferable to adopt a depth-first t raversal which often consumes less mem-ory and is still very fast. However, check whether the minimality is satisfied or not is very difficult in a depth-first traversal. In the case of frequency with itemsets, the best way for evaluating the minimality for a pattern (saying abc )istocompare its frequency with that of all its direct subsets (here, ab , ac and bc ). But, when the pattern abc is achieved by a depth-first tra versal, only frequencies of a and ab have previously been calculated. As the frequency of ac and bc are unknown, it is im-possible to check whether the frequency of abc is strictly less than that of ac and bc . To cope with this problem, [11,12] have adopted a different traversal with re-ordered items. For instance, when the itemset abc is reached by this new traversal, c , b , bc , a , ac and bc were previously scanned and their frequency are known for checking whether abc is minimal. Unfortunately, such a method requires to store all the patterns in memory (here, c , b , bc and so on) using a trie [11] or an hash table [12]. For this reason, existing DFS proposals [11,12] do not solve the low memory consumption issue as expected.

Contributions. The main goal of this paper is to present a generic and efficient framework for minimal pattern mining by providing a depth-first search algo-rithm. We introduce the notion of minimizable set system which is at the core of the definition of this framework. This latter covers a broad spectrum of minimal patterns including all the languages and measures investigated in [7,10]. Fast minimality checking in a depth-first traversal is achieved thanks to the notion of critical objects which depends on the minimizable set system. Based on this new technique, we propose the DeFMe algorithm. It mines the minimal patterns for any minimizable set system using a depth-first search algorithm. To the best of our knowledge, this is the first algorithm that enumerates minimal patterns in polynomial delay and in linear space with respect to the dataset.

The outline of this paper is as follows. In Section 2, we propose our generic framework for minimal pattern mining based on set systems. We introduce our fast minimality checking method in Section 3 and we indicate how to use it by sketching the DeFMe algorithm. Section 4 provides experimental results. In Section 5, we discuss some related work in light of our framework. 2.1 Basic Definitions A set system ( F ,E ) is a collection F of subsets of a ground set E (i.e. F is a subset of the power set of E ). A member of F is called a feasible set .A strongly accessible set system ( F ,E ) is a set system where for every feasible sets X , Y satisfying X  X  Y , there is an element e  X  Y \ X such that Xe  X  X  1 . Obviously, itemsets fits this framework with the set system (2 I , I )where I is the set of items. (2 I , I ) is even strongly accessible. But the notion of set system allows con-sidering more sophisticated languages. For instance, it is easy to build a family set F S denoting the collection of substrings of S = abracadabra by encoding each sytem ( F S ,E S = F S ) is also strongly accessible. The set system formalism has already been used to describe pattern mini ng problems (see for instance [10]).
Intuitively, a pattern always describes a set of objects. This set of objects is obtained from the pattern by means of a cover operator formalized as follows: Definition 1 (Cover operator). Given a set of objects O , a cover operator cov :2 E  X  2 O is a function satisfying cov ( X  X  Y )= cov ( X )  X  cov ( Y ) for every X  X  2 E and Y  X  2 E .

This definition indicates that the coverage of the union of two patterns is exactly the intersection of their two cover s. For itemsets, a natural cover operator is the extensive function of an itemset X that returns the set of tuple identifiers supported by X : cov I ( X )= { o  X  X | X  X  o } . But, in general, the cover is not the final aim: the cardinality of cov I ( X ) corresponds to the frequency of X . In the context of strings, the index list of a string X also define a cover with the string S = abracadabra , it is not difficult to compute the index lists
For some languages, the same pattern is described by several distinct sets and then it is necessary to have a canonical form. For example, consider the encodes the same string br as { ( b, 1) , ( r, 2) } . The latter is the canonical form of the string br . To retrieve the canonical form of a pattern, we introduce the notion of canonical operator: Definition 2 (Canonical operator). Given two set systems ( F ,E ) and ( G ,E ) , a canonical operator  X  : F X  X   X  X  is a function satisfying (i) X  X  Y  X   X  ( X )  X   X  ( Y ) and (ii) X  X  X  X   X  ( X )= X for all sets X,Y  X  X  .

In this definition, the property (i) ensures us that the canonical forms of two comparable sets with respect to the inclusion remain comparable. The property (ii) means that the set system ( F ,E ) includes all canonical forms. Continuing form of the string { ( b, 2) , ( r, 3) } which is { ( b, 1) , ( r, 2) } . 2.2 Minimizable Set System Rather than considering an entire set sy stem, it is wise to select a smaller part that provides the same information (w.r.t . a cover operator). For this, it is neces-sary that this set system plus the cover operator form a minimizable set system: Definition 3 (Minimizable set system). A minimizable set system is a tuple (
F ,E ) , G ,cov, X  where:  X  ( F ,E ) is a finite, strongly accessible set system. A feasible set in F is called  X  ( G ,E ) is a finite, strongly accessible set system satisfying for every feasible  X  cov :2 E  X  2 O is a cover operator.  X   X  : F X  X  X  X  is a canonical operator such that for every feasible set X  X  X  , Let us now illustrate the role of G compared to F in the case of strings. In fact, G S gathers all the suffixes of any pattern of In addition, it is not difficult to see that G S satisfies the desired property with respect to F S : for every feasible set X,Y  X  X  S such that X  X  Y and element e  X  E it means that e is the first letter. If we consider a specialization of X and we again remove the first letter, we also obtain a suffix belonging to G S . Therefore, ( F
Obviously, a minimizable set system can be reduced to a system of smaller cardinality of which the patterns are called the minimal patterns : Definition 4 (Minimal pattern). A pattern X is minimal for (
F ,E ) , G ,cov, X  iff X  X  X  and for every generalization Y  X  X  such that Y  X  X , cov ( Y ) = cov ( X ) . M ( S ) denotes the set of all minimal patterns.
Definition 4 means that a pattern is minimal whenever its cover differs from that of any generalization. For example, for the cover operator cov S , the minimal patterns have a strictly smaller cover than their gen eralizations. The string ab is { 0 , 7 } . For our running example, the whole collection of minimal strings is M ( S S )= { a, b, r, c, d, ca, ra, da } .

Given a minimizable set system S = ( F ,E ) , G ,cov, X  , the minimal pattern mining problem consists in enumerating all the minimal pat-terns for S . This section aims at effectively mining all the minimal patterns in a depth-first search manner (Section 3.3). To do this, we rely on two key ideas: the pruning of the search space (Section 3.1) and the fast minimality checking (Section 3.2).
Before, it is important to recall that the minimal patterns are sufficient to induce the cover of any pattern. From now, we consider a minimizable set system S = ( F ,E ) , G ,cov, X  . The minimal patterns M ( S ) is a lossless representation of all patterns of F in the sense we can find the cover of any pattern. Theorem 1 (Condensed representation). The set of minimal patterns is a concise representation of F adequate to cov : for any pattern X  X  X  ,thereexists Y  X  X such that  X  ( Y )  X  X  ( S ) and cov (  X  ( Y )) = cov ( X ) .

Theorem 1 means that M ( S ) is really a condensed representation of S because the minimal pattern mining enables us to infer the cover of any pattern in S .For { 0 , 7 } . It is preferable to extract M ( S ) instead of S because its size is lower (and, in general, much lower) than the total number of patterns. 3.1 Search Space Pruning The first problem we face is fairly cla ssical. Given a minimizable set system S = (
F ,E ) , G ,cov, X  , the number of patterns |F| is huge in general (in the worst case, it reaches 2 | E | patterns). So, it is absolutely necessary not to completely scan the search space for focusing on the minimal patterns. Effective techniques can be used to prune the search space due to the downward closure of M ( S ): Theorem 2 (Independence system). If a pattern X is minimal for S ,then any pattern Y  X  X  satisfying Y  X  X is also minimal for S .

The proof of this theorem strongly relies on a key lemma saying that a non-minimal pattern has a direct generalization having the same cover (proofs are omitted due to lack of space): Lemma 1. If X is not mininal, there exists e  X  X such that X \{ e } X  X  and cov ( X )= cov ( X \{ e } ) .

For instance, as the string da is minimal, the substrings d and a are also minimal. More interestingly, as ab is not minimal, the string abr is not minimal. It means that the string ab is a cut-off point in the search space. In practice, anti-monotone pruning is recognized as a very powerful tool whatever the traversal of the search space (level by level or in depth).
 3.2 Fast Minimality Checking The main difficulty in extracting the mi nimal patterns is to test whether a pattern is minimal or not. As we mentioned earlier, this is particularly difficult in a depth-first traversal because all subs ets have not yet been enumerated. Indeed, depth-first approaches only have access t o the first parent branch contrary to levelwise approaches. To overcome this difficulty, we introduce the concept of critical objects inspired from critical edges in case of minimal traversals [13]. Intuitively, the critical objects of an element e for a pattern X are objects that are not covered by X due to the element e . We now give a formal definition of the critical objects derived from any cover operator: Definition 5 (Critical objects). For a pattern X , the critical objects of an element e  X  X , denoted by cov ( X,e ) is the set of objects that belongs to the cover of X without e and not to the cover of e : cov ( X,e )= cov ( X \ e ) \ cov ( e ) .
Let us illustrate the critical objects with our running example. For {  X  (= { 0 , 7 }\{ 0 , 3 , 5 , 7 , 10 } ). It means that the addition of a to b has no impact on the cover of ab . At the opposite, for the same pattern, the critical objects of does not cover the objects { 3 , 5 , 10 } .

The critical objects are central in our proposition for the following reasons: 1) the critical objects easily characterize the minimal patterns; and 2) the critical objects can efficiently be computed in a depth-first sea rch algorithm.
The converse of Lemma 1 says that a pattern is minimal if its cover differs from that of its generalization. We can reformulate this definition thanks to the notion of critical objects as follows: Property 1 (Minimality). X  X  X  is minimal if  X  e  X  X such that X \ e  X  X  , cov ( X,e ) =  X  .

Typically, as b is a generalization of the string ab and at the same time, cov ( ab, a ) is empty, ab is not minimal. Property 1 means that checking whether a candidate X is minimal only requires to know the critical objects of all the elements in X .Un-like the usual definition, no information is required on the subsets. Therefore, the critical objects allow us to design a depth-first algorithm if (and only if) computing the critical objects does not also require information on the subsets.
In a depth-first traversal, we want to update the critical objects of an element e for the pattern X when a new element e is added to X . In such case, we now show that the critical objects can efficien tly be computed by intersecting the old set of critical objects cov ( X,e ) with the cover of the new element e : Property 2. The following equality holds for any pattern X  X  X  and any two elements e, e  X  E : cov ( Xe ,e )= cov ( X,e )  X  cov ( e ).
 { { 0 , 7 } =  X  . Interestingly, Property 2 allows us to compute the critical objects of any element included in a pattern X having information on a single branch. This is an ideal situation for a depth-first search algorithm. 3.3 Algorithm DeFMe The algorithm DeFMe takes as inputs the current pattern and the current tail (the list of the remaining items to be checked) and it returns all the minimal patterns containing X (based on tail ). More precisely, Line 1 checks whether X is minimal or not. If X is minimal, it is output (Line 2). Lines 3-14 explores the subtree containing X based on the tail. For each element e where Xe is a pattern of F (Line 4) (Property 1), the branch is built with all the necessary information. Line 7 updates the cover and Lines 8-11 updates the critical objects using Property 2. Finally, the function DeFMe is recursively called at Line 12 with the updated tail (Line 5).
 Algorithm 1. DeFMe ( X,tail )
Theorems 3 and 4 demonstrate that the algorithm DeFMe has an efficient be-havior both in space and time. This efficiency mainly stems from the inexpensive handling of covers/critical objects as explained by the following property: Property 3. The following inequality holds for any pattern X  X  X  :
Property 3 means that for a pattern, the storage of its cover plus that of all the critical objects is upper bounded by the number of objects (i.e., | cov (  X  ) | ). Thus, it is straightforward to deduce the memory space required by the algorithm: Theorem 3 (Polynomial-space complexity). M ( S ) is enumerable in O ( | cov (  X  ) | X  m ) space where m is the maximal size of a feasible set in F .
In practice, the used memory s pace is very limited because m is small. In addition, the amount of time between each output pattern is polynomial: Theorem 4 (Polynomial-delay complexity). M ( S ) is enumerable in O ( | E | 2  X | cov (  X  ) | ) time per minimal pattern.

It is not difficult to see that between two output patterns, DeFMe requires a polynomial number of operations assuming that the membership oracle is computable in polytime (Line 4). Indeed, the computation of the cover and that of the critical objects (Lines 7-11) is linear with the number of objects due to Property 3; the loop in Line 3 does not exceed | E | iterations and finally, the number of consecutive backtracks is at most | E | . The aim of our experiments is to quantify the benefit brought by DeFMe both on effectiveness and conciseness. We show it s effectiveness with the problem of free itemset mining for which several prototypes already exist in the literature. Then we instantiate DeFMe to extract the collection of m inimal strings and compare its size with that of closed strings. All tests were performed on a 2.2 GHz Opteron processor with Linux operating system and 200 GB of RAM memory. 4.1 Free Itemset Mining We designed a prototype of DeFMe for itemset mining as a proof of concept and we compared it with two other prototypes: ACminer based on a levelwise algo-rithm [1] and NDI 2 based on a depth-first traversal with reordered items [11]. For this purpose, we conducted experiments on benchmarks coming from the FIMI repository and the 2004 PKDD Discovery Challenge 3 . The first three columns of Table 1 give the characteristics of these datasets. The fourth column gives the used minimal support threshold. The next three columns report the running times and finally, the last three columns indicate the memory consumption.
The best performances are highlighted in bold in Table 1 for both time and space. ACminer is by far the slowest prototype. Its levelwise approach is par-ticularly penalized by the large amount of used memory. Except on the genomic datasets 74x822 and 90x27679 , the running times of NDI clearly outperform those of DeFMe . As a piece of information, Figure 1 details, for various minsup thresholds, the speed of DeFMe . It plots the number of minimal patterns it extracted for each second of computing time.

Concerning memory consumption, DeFMe is (as expected) the most efficient algorithm. In certain cases, the increase of the storage memory would not be sufficient to treat the most difficult datasets. Here, ACminer and NDI are not suitable to process genomic datasets even with 200GB of RAM memory and relatively high thresholds. More pr ecisely, Figure 1 plots the ratio between NDI X  X  and DeFMe  X  X  memory use for various minsup thresholds. It is easy to notice that this ratio quickly leads NDI to go out of memory. DeFMe works with bounded memory and then is not minsup limited.
 4.2 Minimal String Mining In this section, we adopt the formalism of strings stemming from our running ex-ample. We compared our algorithmfor minimal string mining with the maxMotif prototype provided by Takeaki Uno that mines closed strings [10]. Our goal is to compare the size of condensed representations based on minimal strings with those based on all strings and all closed strings. We do not report the execution times because maxMotif developedinJavaismuchslowerthan DeFMe (developed in C++). Experiments are conducted on two datasets: chromosom 4 and msnbc com-ing from the UCI ML repository ( www.ics.uci.edu/ ~ mlearn ).

Figure 2 and 3 report the number of strings/minimal strings/closed strings mined in chromosom and msnbc . Of course, whatever the collection of patterns, the number of patterns increases with the decrease of the minimal frequency threshold. Interestingly, the two condensed representations become particularly useful when the frequency threshold is v ery small. Clearly the number of mini-mal strings is greater than the number of closed strings, but the gap is not as important as it is the case with free and closed itemsets. The collection of minimal patterns is a kind of condensed representations. Let us recall that a condensed representation of the frequent patterns is a set of pat-terns that can regenerate all the patterns that are frequent with their frequency. The success of the condensed representations stems from their undeniable bene-fit to reduce the number of mined patterns by eliminating redundancies. A large number of condensed representations h ave been proposed in literature [6,14]: closed itemsets [2], free itemsets [1], esse ntial itemsets [15], Non-Derivable Item-sets [11], itemsets with negation [16] and so on. Two ideas are at the core of the condensed representations: the closure operator [14] that builds equivalence classes and the principle of inclusion-exclusion. As the inclusion-exclusion prin-ciple only works for the frequency, this paper exclusively focuses on minimal patterns considering equivalence classes. In particular, as indicated above the system S I = (2 I , I ) , 2 I ,cov I ,Id is minimizable and M ( S I ) corresponds ex-actly to the free itemsets (or generator s). The frequency of each itemset is com-puted using the cardinality of the cover. Replace the cover operator cov I by cov I : X  X  X  o  X  X | X  X  o =  X  X  leads to a new minimizable set system (2 I , I ) , 2 I , cov I ,Id of which minimal patterns are essential itemsets [15]. The disjunctive frequency of an itemset X is |O|  X  | cov I ( X ) | .

Minimal pattern mining has a lot of applications and their use is not limited to obtain frequent patterns more efficiently. Their properties are useful for higher KDD tasks. For instance, minimal patterns are used in conjunction of closed pat-terns to produce non-redundant [3] or informative rules [2]. The sequential rules also benefit from minimality [17]. It is also possible to exploit the minimal pat-terns for mining the classification rules that are the key elements of associative classifiers [4]. Our framework is well-adapted for mining all such minimal classi-fication rules that satisfy interestingness criteria involving frequencies.Assuming that the set of objects O is divided into two disjoint classes O = O 1  X  X  2 ,the More generally, it is easy to show that any frequency-based measure (e.g., lift, bond) can be derived from the positive and negative covers. In addition, the essential patterns are useful for deriving minimal traversals that exactly corre-sponds to the maximal patterns of M ( (2 I , I ) , 2 I , cov I ,Id ). Let us recall that the minimal transversal generation is a very important problem which has many applications in Logic (e.g., satisfiability checking), Artificial Intelligence (e.g., model-based diagnosis) and Machine Learning (e.g., exact learning) [5,13].
The condensed representations of minimal patterns are not limited to frequency-based measures or itemsets. Indeed, it is also possible to mine the min-imal patterns adequate to classical aggregate functions like min, max or sum [7]. Minizable set systems are also well-adapted for such measures. For instance, let returns all the possible values of val less than min ( X.val ). This function is a cover operator and (2 I , I ) , 2 I ,cov min ,Id is even a minimizable set system. The minimal patterns adequate to min correspond to the minimal patterns of the previous set system. Furthermore, the value min ( X.val ) could be obtained as follows max( cov min ( X )). A similar approach enables us to deal with max and sum . In parallel, several studies have extended the notion of generators to ad-dress other languages such as sequences [8,18], negative itemsets [19], graphs [20]. Unfortunately no work proposes a generic framework to extend the condensed representations based on minimality to a broad spectrum of languages as it was done with closed patterns [10]. For instance, [1,2,11,12] only address itemsets or [8,18] focus exclusively on sequences . In this paper, we have made the connec-tion between the set systems and only two languages: itemsets and strings due to space limitation. Numerous other languages can be represented using this set system framework. In particular, all the languages depicted by [10] are suitable. By proposing the new notion of minimizable set system , this paper extended the paradigm of minimal patterns to a broad spectrum of functions and languages. This framework encompasses the current methods since the existing condensed representations (e.g., free or essential i temsets) fit to specific cases of our frame-work. Besides, DeFMe efficiently mines such minimal patterns even in difficult datasets, which are intractable by state-of-the-art algorithms. Experiments also showed on strings that the sizes of the minimal patterns are smaller than the total number of patterns.

Of course, we think that there is still room to improve our implementation even if it is difficult to find a compromise between generic method and speed. We especially want to test the ability of the minimal patterns for generating minimal classification rules with new types of data, such as strings. Similarly, it would be interesting to build associative classifiers from minimal patterns. Acknowledgments. This article has been partially funded by the Hybride project (ANR-11-BS02-0002).

