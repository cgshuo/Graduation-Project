 semantic contents is an important research topic in multimedia data mining and has found various real-world applications. Most existing video analysis techniques focus on the low l evel visual features of video data. However, there is a  X  X emantic gap X  between the machine-readable features and the high level human concepts i.e. human understanding of the video content. In this paper, an interactive platform for semantic video mining and retrieval is proposed using Relevance Feedback (RF), a popular technique in the area of Content-based Image Retrieval (CBIR). By tracking semantic objects in a video and then modeling spatio-temporal events bas ed on object trajectories and object interactions, the proposed interactive learning algorithm in the platform is able to mine the spatio-temporal data extracted from the video. An iterative learning process is involved in the proposed platform, which is guided by the user X  X  response to the retrieved results. Although the proposed video retrieval platform is intended for general use and can be tailored to many applications, we focus on its application in traffic surveillance video database retrieval to demonstrate the design details. The effectiveness of the algorithm is demonstrated by our experiments on real-life traffic surveillance videos. Keywords: Multimedia data mining, spatio-temporal data mining, data mining applications generated an urgent need for techniques to process and analyze this special kind of data. Traditional machine learning methods cannot meet the special requirements in understanding the semantic meaning of and extracting knowledge from raw multimedia data. Image, video, audio data are specific multimedia data types. It is inherently hard to make the machine understand the meaning of these data by only reading pixels, frames or signals. There exists a  X  X emantic gap X  between the low level features and the high level semantic meaning. Therefor e, it is necessary that human provide some guidance to the machine. Various techniques exist for such a purpose. In the field of image retrieval, there is a well-known technique  X  Relevance Feedback (RF). It is used to incorporate the user X  X  subjective concept w ith the learning process [1, 2, 3] for Content-Based Image Retrieval (CBIR). The basic idea of Relevance Feedback is to ask the user X  X  opinion on the retrieval result for a user-specified query target. Based on these opinions, the learning mechanism tries to refine the retrieval result in the next iteration. The process iterates until a satisfactory result is obtained for the user. For example, if the user wants to find all the images containing  X  X iger X  and the learning algorithm returns several  X  X all X  images, the user can label these unwanted images  X  X rrelevant X . In this way, the user X  X  knowledge is  X  X ransferred X  to the learning algorithm, which uses it to further refine the retrieval result. As a supervised learning technique, Relevance Feedback has been shown to significantly increase the retrieval accuracy. Feedback from CBIR and apply it to the retrieval of video data. The purpose of the proposed platform is to automatically learn and retrieve semantic scenes from videos according to the use r X  X  query. The motivation is to use RF as a bridge between multimedia processing and information retrieval. It is different from traditional classification pro cess in machine learning, where prior knowledge is required to compose the  X  X raining set X  for each cla ss. In the scenario of information retrieval, especially for large multimedia databases, multiple  X  X elevant X  and  X  X rrelevant X  classes exist according to the different preferences of different users [16]. The data in each  X  X elevant X  class may only constitute a very small portion of the entire database. Thus, in a large-scale multimedia database, it is difficult to pre-define a perfect set of training sets for all  X  X elevant X  classes before query, due to the scarcity of  X  X elevant X  samples and the uncertainty of users X  interest. With RF, the initial query results are returned based on some heuristics i.e. the models of some generally categorized events . The training set for the user X  X  specific query is built up gradually with the help of the user X  X  feedback. Therefore, RF provides more flexibility in information retrieval as it customizes the search engine for the need of individual users. than the problem in image retrieval. Video is composed of running images (frames). We need to not only study the content of individual frames (still images), but also consider the temporal relations among them. With content-based image analysis, the content features of each object (e.g. its spatial location, texture features, shape, and color) in a frame can be extracted. From the perspec tive of each such object, its moving trajectory in consecutive frames is a kind of spatio-temporal data. In this study, the aim of semantic video retrieval is to extract semantic scenes by analyzing the spatio-temporal relations among moving and still objects in the video. The interactive video retrieval platform proposed in this paper first performs the object tracking and segmentation, which extracts content features and moving trajectory of each object in the video. In the learning and retrieval phase, the technique of Relevance Feedback is incorporated, with which the user provides feedback and the learning algorithm learns from it by depressing the  X  X rrelevant X  scenes and promoting  X  X elevant X  scenes. neural network for time series data. Video data is a special kind of time series data as it consists of sequences of values or events changing with time. There are a large amount of literatures [2, 4, 9] on applying neural network in forecasting the behavior of real world time series data, which is popular in such applications as studying the fluctuations of stock market. However, relatively few works [5, 6] have addressed the issue of event detection in time series data with neural network. In this paper, we explore the spatio-temporal models of a neuron for semantic event mining and retrieval from video data. with the user in mining and retrieving user-interested semantic events from video data. Instead of pre-defined  X  X xpert X  knowledge, individual user X  X  subjective view serves as th e guideline for learning. In this platform, the key learning mechanism, neural network, is designed to learn the spatio-temporal characteristics of user-interested video events, which is dynamic rather than static . Since we are not dealing with a prediction problem, the  X  X rediction X  neural network for time series data is adjusted to suit the needs of spatio-temporal se mantic event classification for video data. mining and retrieving data from large video databases, where only raw data is stored. By using users X  feedbacks, human knowledge is then incorporated into such a database. Although this is a video retrieval platform of general use that can be tailored to many fields, we focus mainly on its application in traffic surveillance video database retrieval throughout the paper to demonstrate the design details. The semantic events in such a database are incidents captured by the surveillance video on the road, such as car crash, bumping, U-turn and speeding. Experimental results show the effectiveness of the proposed platform in traffic incident detection. a semantic object extraction and tracking method for traffic videos. Section 3 exemplifies the semantic event modeling. Section 4 demonstrates the design details of the learning and retrieval process. Section 5 provides the experimental results. Section 6 concludes the paper. study in this paper, in this section, we provide some background information on the processing of transportation surveillance videos. In our previous work [15], an unsupervised segmentation method called the Simultaneous Partition and Class Parameter Estimation (SPCPE) algorithm, coupled with a background learning and subtraction method, is used to identify the vehicle obj ects in a traffic video sequence. The technique of background learning and subtraction is used to enhance the basic SPCPE algorithm in order to better identify vehicle objects in traffic surveillance vide os. The Minimal Bounding Rectangle (MBR) of the vehicle as well as its centroid coordinates (x centroid , y centroid ) are recorded to track the positions of vehicles across video frames.
 generated. This provides a basis for video mining and retrieval. In this paper, suitable spatio-temporal models for traffic video data are built to further organize, index and retrieve these information. series of object centroids on successive frames are recorded. We can approxima te the trajectory of the vehicle by using the least-square curve fitting. A k degree polynomial for the curve is: unknowns [ a 0 , a 1 , ... , a k ] can be resolved by n equations through minimizing the squared sum of the deviations of the data from the model. The n equations can be represented as: moving trajectory. It can be described by only a few polynomial coefficients. The first derivative of a polynomial curve is a tangent vector, which represents the velocities of that vehicle at different time. The figure below demonstrates the fitted curve of a group of centroids by a 4 th degree polynomial. The small diamonds around the curve represent the original centroids. 
Figure 1. An example of polynomial curve fitting of the semantic objects can be extracted to build models for specific event types. Take transportation surveillance videos as an example, the general events of interest may include car crashes, illegal U-turns, and overtaking, etc. In this study, we tested our framework on car crash events. sudden stops, crashes onto side walls in a tunnel, and crashes into crowd in car races, etc. For accidents involving a single vehicle, we can often observe sudden changes in vehicle behavior patterns. Along a vehicle trajectory, three pr operties of the vehicle are recorded: velocity, change of velocity, and change of motion vector. After the sampling rate is specified, the velocity at each sampling point can be directly calculated from the fitting curve as shown in Figure 1. The change of velocity at each point can also be easily obtained by subtracting the velocity at the previous sampling point from the current velocity. A motion vector is a two-dimensional vector, or movement, that shows the difference from the vehicle coordinate position in the previous sampling point to the coordinates in the current sampling point. As illustrated in the figure below, the change of motion vector is actually the angle between the current motion vector ( motion vectors.  X  is the absolute angle difference between them. Since we only record the angle difference, there is no need to normalize these motion vectors along the axis. It is worth mentioning that only the absolute value of angl e difference is used for accident detection, as it is sufficient to reflect the sudden change of moving directions during an accident, while the actual value of angle difference is useful for the reasoning of other types of events such as U-turns. As mentioned in Section 1, some heuristics need to be established in order to perform the initial queries. The main heuristic we used is based on the observation that the sudden change of velocity and/or driving direction may indi cate an accident. At the i sampling point, the extracted property vector of a vectors ] ,..., [ 1 n  X   X   X  = are used to represent the trajectory of each vehicle. It is worth mentioning that this single vehicle model may also be adjusted to detect two-vehicle accident s, U-turns, speeding and any other events that involve the abnormal behavior of a single vehicle. multiple cars. Thus, we need a model to capture the relationship between every two vehicle objects. In such a model, both the properties of an individual vehicle and the interaction between two vehicles shall need to be considered. Two properties of the trajectory are extracted. One is velocity and another is the interaction feature between two vehicles as proposed in [10]. There are four steps in getting this feature. 1. First, rotate the motion vectors ( 1 M , 2. Second, get the difference vector diff M = 1 M -
Figure 3. Motion vector rotation and subtraction 3. Third, divide the difference vector diff M by the 4. Fourth, quantize the result from Step 3. The figure 
Figure 4. The quantization schema for the two-interaction feature has 16 categories depending on which region the normalized vector diff M after Step 3 falls into. If two vehicles are close to each other, their normalized difference vector diff M will have a bigger chance of falling into the regi ons outside the circle (see Figure 4) because the distan ce between their centroids is relatively small. The regions outside the circle with labels (2, 4, 6, 8, 10, 12, 14, 16) implicate high accident potential (HAP). series of consecutive frames, the start and the end of these common frames are reco rded. Their trajectories within these common frames ar e analyzed to extract a sequence of interaction features on each sampling point. In this way, for each pa ir of vehicles that ever appear together, we have ] ,..., [ 1 n  X   X   X  = , where [ v 1 diff i , v 2 diff i , cat i ]. v 1 diff i and v 2 diff changes of the two vehicles at the sampling point i . cat is the category number from the result of quantization. It is worth mentioning that cat i is categorical data with partial ordering because the even-number categories (2, 4, 6, 8, 10, 12, 14, 16) indicate a higher accident potential than the odd-number categories (1, 3, 5, 7, 9, 11, 13, 15). model can be extended to model other events that involve two or more vehicles such as overtaking, multi-car crashes and bumping. constructing a complex, nonlinear and parallel computing environment. Knowledge is acquired by the network through a learning process. For most of the neural network analysis, the nonlinear model of a neuron is used. The limitation of this model is that it only accounts for the spatial behavior of a neuron. the neural network method for time series prediction induces the function f in a standard Multilayer Perceptrons (MLP) or Radial Basis Function ( RBF) architecture. This method is often called the sliding window technique as the N-tuple input slides over the full training set. A time series is a sequence of vectors depending on time t : x t , t = 0, 1, .... Figure 5 shows an example of sliding window for time series data. In this example, the input is a 6-tuple extracted from time series data by sliding a window of size 6 one step a time along the time axis t . the prediction or estimation of x k based on the preceding m observed data points x k -m , ..., x k -2 the window size. In prediction, an exact value of x required. Thus, prediction becomes a problem of function approximation which is to find an f that: there is no need to pred ict an exact value for x Instead, only an indication of whether x k will be the event of interest is needed . In this case, the problem turns into a classification problem, mapping a temporal sequence onto the classes of  X  X  elevant X  or  X  X rrelevant X : where C is the set of all class labels. This can be treated as a special case of function approximation, in which the targets are binary values. Classical linear autoregressive models in modeling time series data are rather limited, since they assume linear relationship among consecutive data series. As illustrated in [11], MLP and RBFs offer an extension to the linear model by using a non-linear function, which can be estimated by such learning and optimization techniques as back propagation and conjugate gradient. forward multilayer neural network that incorporates the technique of Relevance Feedback. The structure of the whole network is shown in the Figure 6 below. There are temporal relationships among the inputs ( x t -1, x t -m ) in Figure 6, which are selected by a sliding window. added as a node in the input layer. Other input values include a sequence of vectors selected from where i  X  is the feature vector at each sampling pint as illustrated in Section 3. The number of input nodes corresponds to the window size plus one node for user feedback. The detailed design decisions as to the window size, the numbers of hidden units and hidden layers, weights, and learning algorithms will be described in the following section. 4.2.1. Window size and input nodes. The size of the sliding window determines the number of input nodes. If the window is too small, the sequence in the window is too  X  X hort X  to show the overall pattern of a certain event. On the other hand, if the window is too big, the sequence would be too  X  X eneral X  to reveal the core event characteristic with too many noise data around. In order to find the optimal solution, some researchers suggest an incremental search on the size of the window. As in [12], a method called false nearest neighbor is proposed. series data is that it can be visualized, thus one can have a concrete idea of how the data is organized and flows over time. Therefore, in our platform, the size of the window can be simply decided by the typical length of an event as it can be acquired by the counting the number of frames covering this event. Take car crash as an example, the typical length in terms of number of frames for this kind of events is very short i.e. about 15 frames. Given a sampling rate of 5 frames, 3 sampling points are needed to depict a car crash event. Thus, the window size is 3 in our case. node, excluding the fdk node, is a feature vector extracted according to the event model. In a single-vehicle model, the feature vector i  X  = [ v i , vdiff three dimensional. In a two-vehicle model, the feature vector is i  X  = [ v 1 diff i , v 2 diff i , cat i ]. cat data with (1, 2, ..., 16) signifying one of the 16 categories. Since categorical data cannot be simply treated as numerical values and fed into one input node, we use a 16-dimensional vector to represent each category. Each of such vectors contains 15 zeros and 1 one in the position corresponding to the category it falls into. These zeros are the inserted dummy variables. For example, th e following vector indicates category 3. This makes the input vector for each input node 18-dimensional. 0 0 1 0 ... ... 0 4.2.2. Hidden layer. Most practical neural networks have used just two or three layers. Four or more layers are rarely used. In our platform, we adopt a two-layer neural network  X  one hidden layer having sigmoid transfer function and one output layer having linear transfer function. It has been shown that this network architecture can approximate virtually any functions of interest to any degree of accuracy, provided sufficiently many hidden units are available [7]. As demonstrated by our experiments, this architecture can be trained to approximate the function f well as discussed in Section 4.1. indicating whether the sequence is the desired event or not. The optimal number of units in hidden layer is a decision hard to make. A large number will reduce the convergence rate of learning and have a high generalization error due to overfitting and high variance, while a small number cannot guarantee the approximation accuracy. An appropriate number of hidden units are necessary for adequate performance. One rule of thumb [8] is th at it shall not exceed twice the size of the input nodes. Suppose the size of input is l, in our platform, we tested on the hidden layer the the minimum estimated generalization error. 4.2.3. Activation function. As mentioned above, the transfer function in the first layer (activation function) is sigmoid, which is used to introduce nonlinearity. tanh is the tangent hyperbolic function, a conventional sigmoid function. w i is a weight for each input x i . 4.2.4. Initial weights. Most of the neural networks use random numbers as initial weights. However, since the back propagation is a hill-climbing technique, the randomness of initial weights may result in local optimum. In [13], a multiple linear regression weight initialization method is proposed . It is adopted in our platform. In this method, th e initial weights in the first layer are still uniform random numbers. However, the weights in the second laye r are obtained by multiple linear regression. generated, input nodes and their corresponding weights are fed to the sigmoid function to get the output values for each neuron in the hidden layer. Suppose these transfer function so that where, v i is weight on the second layer. This is a typical multiple linear regression model. R i  X  X  are regressors. v i can be estimated using standard regression method. The least square optimization procedure is used in our platform for such a purpose. 4.2.5. Search algorithm. The basic form of the back propagation algorithm is computationally expensive and its training may take days or weeks. This has encouraged considerable research on methods to accelerate the convergence rate of the algorithm. As training feedforward neural networks to minimize the squared error is simply a numerical optimization problem, some existing numerical optimization techniques have been successfully applied to the training of multilayer perceptrons. Among them are steepest descent, conjugate gradient and Newton X  X  method. Steepest descent is the simplest algorithm, but is often slow in convergence. Newton X  X  method is much faster, but requires th at the Hessian Matrix and its inverse be calculated. The conjugate gradient is a compromise in that it does not require the calculation of second derivatives, yet it still has the quadratic convergence property. In the proposed platform, we choose the conjugate gradient. examples of proper network behavior: { I , O }, where I is a group of inputs and O is the set of the corresponding desire d outputs. As each input is applied to the network, the network output is compared to the desired output. The algorithm then adjusts the weights to minimize the mean square error: current weights. e is the error vector and w is the weight vector. e can be rewritten as e = O  X  Gw, where Gw = ) ( i I  X  and G is a matrix. Then, Compare this with the following quadratic form: we can see that these two are the same with proved that A is positive-definite, in that for every nonzero vector x , x T Ax &gt;0. initial point and search along the conjugate directions to find the point where the network output error reaches its minimum i.e. to minimize F ( w ). In the quadratic form of Equation 8, F ( w ) reaches its minimum at F X  ( w ) = 0 since A is positive-definite. In [14], this is explained in a more intuitive way. As illustrated in Figure 8, the lowest point is where F X  ( w ) = 0. equation can be reduced to: which makes Aw = b being the solution. In this way, the problem of finding the minimum of a quadratic form of Equation 8 equals to solving a linear system. If A is not symmetric, we can use the conjugate gradient to find a solution to the system b w A A T = + ) ( 2 1
Figure 8. The plot of Equation 9 with A being in Figure 8 by stepping along the conjugate directions { d ( i ) }. By updating the weights along the conjugate directions, we have: where s i is the step size: r is the residual. Two vectors d ( i ) and d ( j ) are conjugate if The Conjugate Gram-Schmidt process provides a simple way to generate a set of conjugate search directions { d ( i ) }.  X  can be obtained by Equation (14) and Equation (13): (10)(11)(12)(13)(14)(15) together form the conjugate gradient method in searching the minimum point in Figure 8. interest as the query target. The ultimate goal is to retrieve those video sequences that contain similar semantic events. At this point, no relevance feedback information is provided by the user. Therefore, no training sample set is available that can be used in learning the pattern of user interested events. In order to provide an initial set of video sequences for the user to provide relevance feedback, for each video sequence in the database, we calculate its relevance (or similarity score) to the target query video event according to some event-sp ecific search heuristics. accidents such as crashes onto roadside walls, crashes into crowd in car races, or multi-car accidents which involve dramatic changes of single car trajectories. In this case, the feature vector i  X  = [ v i , vdiff i , i single car model is used. In the initial retrieval, the maximum value of vdiff i i  X   X  at the first sampling point of each video sequence in the database is calculated, and the retrieval results are displayed to the user in descending order of this value. It is assumed that a big velocity change and a sudden change of driving direction signify possible accidents. takes into consideration the interaction feature cat cat i is an even number (2, 4, 6, ..., 16), there might be a higher possibility of an accident for the reason aforementioned. For each pair of vehicles whose cat i is even, its v 1 diff i  X  v 2 diff i is calculated. v 1 diff are the velocity changes of the two vehicles at the sampling point i . The maximum value of such at the first sampling point of each video sequence is used to determine the accident potentia l of that sequence. The initial retrieval results are returned to the user according to this value in a descending order. sequences are presented to the user. In out experiment, the top 20 video sequences are returned for the user X  X  feedback. The user identifie s a returned sequence as  X  X elevant X  if it is of his/her interest; otherwise the user labels it  X  X rrelevant X . With this information at hand, a set of training samples can be gathered. Take single car event as an example, each training sample is in the  X  are the feature vectors at the three consecutive Figure 12. An example of two-vehicle accidents bump into each other. The tr ajectory of the car on the right is traced by yellow dot s. The trajectory of the other car is marked by black dots. traffic surveillance video taken in a tunnel is tested with the proposed system. Five video clips containing accident scenes are extracted with 2504 frames in total. These video clips were taken at a frame rate of 25~29 frms/sec. Our sampling rate is 5 frames per sampling point and the window size is 3, i.e. three sampling points in a window. After sampling and window sliding, there are altogether 497 sequences (15 frames each) in the database. performed for single-car acci dent query -Initial (no feedback), First, Second, Third, Fourth, and Fifth. In each iteration, the top 20 video sequences are returned to the user. In a large-scale information mining and retrieval system (e.g. a global web-based information retrieval system), since there is no prior knowledge as to the total number of  X  X orrect X  objects given a user X  X  query, the traditional data mining performance measurements such as precision and recall are not applicable. Therefore, we use the measure of accuracy for such a purpose. The accuracy rates with different scopes, i.e. the percentage of relevant sequences within the top 5, 10, 15 and 20 returned sequences are calculated. Figure 13 shows the accuracies after the Initial, First, Third, and Fifth round of iterations. accuracy increases acro ss iterations with the incorporation of the user X  X  feedback. In the third iteration, the total accuracy has already reached 85% i.e. 17 out of 20 returned sequences are regarded as  X  X elevant X  by the user. If the user is still not satisfied with the results and wants to continue the process, he/she is able to find 18 relevant sequences after the fifth iteration, making the total retrieval accuracy 90%. Notice that after the third iteration, the accuracy among the top 15 returned results has reached 100%. 
Accurac Figure 13. The accuracies of single-vehicle event surveillance video taken at a street corner is tested. Two clips containing accident scenes are extracted with 1275 frames in total. After sampling and window sliding, 35 sequences which contain at least two vehicles across the time sp an of that sequence are extracted and stored in the database. Figure 14 shows the retrieval results after the Initial, First, Second, and Third round of iterations. 
Accurac
Figure 14. The accuracies of two-vehicle event accident scenes in the surveillance video, the sequences involved in acci dents are sparse and constitute only a small portion of the entire data set. Thus, its accuracy in each itera tion is smaller than that of the single-vehicle even t retrieval because the problem gets more difficult when the positive class is small. However, it still can be seen that the accuracy increases through iterations with relevance feedback. and retrieval platform is proposed. Given a set of raw videos, the semantic objects are tracked and the corresponding trajectories are modeled and recorded in the database. Some spatio-t emporal event models are then constructed. In the learning and retrieval phase, with the top returned seque nces in each iteration, the user provides feedback to the relevance of each video sequence. The learning algorithm then refines the retrieval results with the user X  X  feedbacks. This platform successfully inco rporates the Relevance Feedback technique in mining video data, which is a well studied topic in Content Based Image Retrieval but needs significant extensions (e.g. the modeling and incorporation of spatio-tem poral characteristics) when applied to video data retrieval. For learning and retrieval, the neural network for time series prediction identification for video data. The platform shows its effectiveness as demonstrated by our experiments on live transportation surveillance videos. be constructed and tested with the proposed platform. Currently, the platform only supports the user X  X  query by specified event types (single-vehicle or two-vehicle events). We will extend this to include query by example, query by sket ches, and a customized combination of different query types. by SBE-0245090 and the UAB ADVANCE program of the Office for the Advancement of Women in Science and Engineering. 
