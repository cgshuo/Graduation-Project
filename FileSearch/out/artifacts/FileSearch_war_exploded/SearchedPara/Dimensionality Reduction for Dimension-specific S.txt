 Dimensionality reduction plays an important role in effi-cient similarity search, which is often based on k-nearest neighbor ( k -NN) queries over a high-dimensional feature space. In this paper, we introduce a novel type of k -NN query, namely conditional k-NN ( ck -NN), which considers dimension-specific constraint in addition to the inter-point distances. However, existing dimensionality reduction meth-ods are not applicable to this new type of queries. We pro-pose a novel Mean-Std(standard deviation) guided Dimen-sionality Reduction (MSDR) to support a pruning based efficient ck -NN query processing strategy. Our preliminary experimental results on 3D pro tein structure data demon-strate that the MSDR method is promising.
 Ca teg o ri es a nd Subject Des cri pto rs H.3.3 [ Information Search and Retrieval ]: Retrieval models; H.2.8 [ Database Applications ]: Scientific databases GeneralTerms: Algor ithms
The k nearest neighbor ( k -NN) similarity search plays an central role in a wide range of applications, such as multi-media retrieval, molecular biology, medical imaging. Data objects are represented by automatically extracted content features which are points (vectors) in a high dimensional space. Similarity query processing is to find the data objects similar to a query, often the nearest k neighboring points of the query object in the high dimensional space, by measur-ing distance (often Euclidean distance) between each point in the database and the query point.

Conditional k-NN. Recently, there has been an emerg-ing demand of a new type of queries, which take into ac-count not only inter-point distances (as in the conventional k  X  NN ), but also certain local constraints that two objects must match within certain tolerance threshold along certain individual dimensions. This is meaningful for many practi-cal applications. For example, in protein structure analysis, two structures which are close in terms of their Euclidean distance but have a very large difference along certain sin-gle dimension may potentially lead to completely different biological functions [6]. We refer such type of query to as conditional k -NN query ( ck -NN query).
 ues alone each dimension for all points and represents each dimension as a 2 D point (  X  ,  X  ) . The original space X is then transformed to a 2 D X  - X  space with D points corresponding to the original D dimensions.
 Clustering: The K-means algorithm is employed in  X  - X  space to classify the D points into D clusters ( D = K ), each of which is described by its centroid c .
 Generate the subspace: It is natural to combine the di-mensions in each cluster into one, resulting in a new D -dimensional space X .Eachobjectin X is mapped onto X whereitsvalueoneachnewdimensionisthemeanvalueof the dimensions in X that form the new one.
An intuitive way for ck -NN query processing is to prune the data space by first performing conditional pruning along individual dimensions to form a candidate set, and then fur-ther prune the candidate set by the global similarities, or vice versa. However, it will generate a relatively large num-ber of intermediate candidates which is strongly undesirable for large scale data.

We propose a novel hybrid ck -NN query processing strat-egy which cooperates conditional pruning and k -NN pruning concurrently. The basic index structure is to maintain a sep-arate table (objects-values) for each dimension. The tables are accessed one by one in certain order. After a dimension is accessed, the lower and upper bounds of candidates are updated correspondingly. The candidates are then sorted by their upper bounds in an ascending order. For each can-didate, it is first checked by the condition rule and removed from the candidate set if the condition is violated, followed by k -NN pruning. If the current candidate X  X  lower bound is greater than the k th largest upper bound, it can be safely pruned. In the next iteration, the same process is performed and the candidate set is further reduced, until all dimensions have been processed since the measure of similar patches re-quires pair-wise comparisons on all dimensions. Due to the pagelimi t,wewillnotgivetheforma ldescri ptionofup -per/lower bound in this paper.
This section reports our preliminary performance study on our MSDR algorithm. As mentioned previously, the existing dimensionality reduction methods[3] and high-dimensional indexing methods [2] are not applicable to the ck -NN prob-lem, and thus not directly comparable with the proposed MSDR approach. MSDR derives a lower dimensional space X and therefore will lose information. Average precision is used as the effectiveness indicator, with ck -NN search re-sults from the original space as ground truth. The efficiency of our hybrid ck -NN algorithm is measured by the Pruning Power (PP) which is defined as the ratio of the number of pruned objects to the total number of objects. Clearly, a larger PP corresponds to a more powerful pruning strategy, hence a faster response.
 We conduct experiments on 3D protein structure data. The feature space is constructed based on a compact data representation model, which represent each structure as a high dimensional point[5][4]. From a total number of 1,100 sample protein structures in the Protein Data Bank [1], we build a dataset of 2,207,018 53-dimensional points (feature vectors). 100 points are randomly selected as queries. k is set to 10. The distance tolerance  X  along each dimension is settobe1.5  X  A tobebiologicall ymeaningful.
