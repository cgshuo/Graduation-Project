 Discovering frequent patterns from data is a popular exploratory technique in data mining. However, if the data are sensitive ( e.g. , pa-tient health records, user behavior records) releasing information about significant patterns or trends carries significant risk to pri-vacy. This paper shows how one can accurately discover and re-lease the most significant patterns along with their frequencies in a data set containing sensitive information, while providing rigor-ous guarantees of privacy for the individuals whose information is stored there.

We present two efficient algorithms for discovering the k most frequent patterns in a data set of sensitive records. Our algorithms satisfy differential privacy , a recently introduced definition that pro-vides meaningful privacy guarantees in the presence of arbitrary external information. Differentially private algorithms require a degree of uncertainty in their output to preserve privacy. Our al-gorithms handle this by returning  X  X oisy X  lists of patterns that are close to the actual list of k most frequent patterns in the data. We define a new notion of utility that quantifies the output accuracy of private top-k pattern mining algorithms. In typical data sets, our utility criterion implies low false positive and false negative rates in the reported lists. We prove that our methods meet the new utility criterion; we also demonstrate the performance of our algorithms through extensive experiments on the transaction data sets from the FIMI repository. While the paper focuses on frequent pattern min-ing, the techniques developed here are relevant whenever the data mining output is a list of elements ordered according to an appro-priately  X  X obust X  measure of interest.
 H.2.0 [ Information Systems ]: Database Management-General Management, Security, Theory  X  A full version of this paper is available online [8].
 Differential privacy, frequent itemsets, frequent patterns, expon en-tial mechanism, privacy
Frequent Pattern Mining (FPM) is a fundamental problem in data mining [17, 16]. Patterns (e.g. itemsets [4] and sequential patterns [5] in transactions data, subgraphs [26] in graphical data, episodes in event streams [20]) are local structures in data that capture cor-relations among a small number of attributes or variables. Given some notion of frequency (or support) for a pattern, the goal in FPM is to discover patterns that occur frequently in the data. For example, in frequent itemsets mining (FIM) the data records are transactions (sets of items purchased in one visit to a store), the patterns (or itemsets) are just small collections of items and the frequency (or support) of a pattern is the fraction (or number) of transactions in the data that contain it. One way to control the size of FPM output is for the user to specify a positive number k and for the algorithm to output the top k (most-frequent) patterns in the data. (Another way is for the user to specify a threshold on the frequency of patterns, but we do not consider this case here). In typical application scenarios, FPM algorithms report the list of top k patterns in the data along with the corresponding pattern frequen-cies.

Many compelling applications of frequent pattern mining deal with sensitive data. For example, discovering strong correlations, trends and rules from medical records can be a valuable source of information for society [14, 18]; understanding common user behavior can provide useful information for pricing advertising. However, releasing information about sensitive data carries serious risks to privacy. While there is extensive work on privacy breach when the complete data set is published [25, 3, 7], studying privacy breach when only certain statistics about data are revealed is rela-tively new [11, 10]. Despite the hardness of inverse frequent set mining [24] the release of frequent pattern statistics can leak sen-sitive (or specific) information about some individual record. For instance, consecutive FIM outputs on slowly changing data set (say, before and after a user X  X  data is added) can leak very fine-grained information (such as presence or absence of specific items in the recently added user X  X  record).

Hiding information about individuals requires modifying the data or limiting access to it. This creates a tension between utility and privacy : privacy comes at a cost to accuracy (the utility of the re-leased statistics). The fundamental problem is to understand where exactly the trade off lies between these two.
We present two efficient algorithms for discovering frequent pat-terns in sensitive data sets. Both algorithms satisfy differential privacy [11, 10], a recently introduced definition which provides meaningful privacy guarantees in the presence of arbitrary exter-nal information. Differential privacy imposes a condition on the algorithm that releases some statistics about a data set x . Roughly, it states that small changes to x should not be noticeable to the users (or adversaries) who view the released statistics. This implies that no matter what the adversary knows ahead of time, he learns the same thing about Alice whether or not her data is actually included in the data set x [10, 13].

We quantify the notion of utility (accuracy) needed for the al-gorithms X  analysis and give rigorous accuracy bounds. Our exper-iments show that both our algorithms perform well on a standard suite of data sets. Our algorithms are based on different techniques, but have similar performance guarantees. Nevertheless, they are in-comparable: one is more accurate, the other simpler.
 Quantifying  X  X tility X  for FPM. Because differentially private al-gorithms must treat nearby inputs indistinguishably, they can at best return approximate answers. Thus, our algorithms produce a noisy list of patterns which is  X  X lose X  to the list of the top k patterns with high probability. (Our algorithms also release the approximate frequency of each of the patterns in the output.)
To quantify the algorithms X  utility, we introduce a natural notion of approximation for frequent pattern mining. Roughly, we require that the patterns in the output have frequencies within a small addi-tive error of those of the k most frequent patterns. Specifically, let f be the frequency of the k th most frequent pattern in the input. Given an accuracy parameter  X   X  [0 , 1] , we require that with high probability (a) every pattern with frequency greater than f output and (b) no pattern with frequency below f k  X   X  is output. Equivalently, the algorithm must output the top k patterns of an input in which all frequencies have been changed by up to  X  . Evaluating Utility. We present a rigorous analysis of the privacy and accuracy of both algorithms. For a given level of differential privacy, quantified by the parameter  X  , we prove high-probability bounds on how far the reported patterns can be from the true top k patterns. The  X  parameter of both algorithms is O ( k log | U | /n X  ) , where k is the number of patterns reported, n is the total number of records in the data set and U is the collection of patterns under consideration ( e.g., for sets of  X  items among m possibilities, | U | is  X  and log | U | is O (  X  log m ) ).

We also provide an extensive experimental evaluation of both algorithms on all the data sets from the FIMI repository [2]. First, we calculate the concrete bounds implied by our utility theorems, and find that the bounds correspond to meaningful error rates on the FIMI data sets. The empirical error we observe in experiments is even lower than the theoretical bounds.
 Evaluating Efficiency. In both our algorithms, there is a prepro-cessing phase which extracts the top k  X  &gt; k patterns using an ex-isting non-private algorithm (such as Apriori or fp-growth [16]). The preprocessing phase takes time roughly proportional to k where n is the number of records in the data set. Here k  X  number of patterns with frequency greater than f k  X   X  , where  X  is the utility parameter. After preprocessing, both of our algorithms require time only O ( k  X  + k log k  X  + nk ) to produce the final output. Since k and k  X  are typically much smaller than n , the non-private pattern mining is the efficiency bottleneck. This observation was borne out by our experiments.
 Techniques. The main difference between our two algorithms is technique. Our first algorithm is based on the exponential mecha-nism of McSherry and Talwar [23]. Our main contribution is to give an efficient algorithm for this case of the exponential mechanism (a priori, the mechanism requires exponential time). The second al-gorithm is based on a new analysis for the established technique of adding Laplace noise to released functions [11, 19, 15]; we show that in some settings one can add much less noise than was pos-sible with previous analyses. A more detailed discussion of our techniques relative to previous work can be found in Sec. 5.
The paper is organized as follows. In Sec. 2 we review the defi-nition of differential privacy. Our new privacy preserving frequen t pattern mining algorithms are presented in Sec. 3. The experimen-tal evaluation of these methods (in the context of frequent itemsets mining) is presented in Sec. 4.We review related work in Sec. 5 and conclude in Sec. 6.
Our algorithms satisfy differential privacy [11], which bounds the effect that any single record has on the distribution of the re-leased information. Let D n be the space of data sets containing n records.
 ized algorithm A is  X  -differentially private if for all data sets T,T D n differing in at most one record and all events O  X  Range ( A ) : Example: Laplace noise. Differentially private algorithms must be randomized, since they must blur the distinction between two neighboring inputs T,T  X  even when T and T  X  are known to the adversary. A common technique to introduce randomness is the addition of Laplace noise to outputs. Suppose that we would like to release (an approximation to) a vector of real-valued statistics. That is, for some function f : D n  X  R d , we would like to release an approximation close to f ( T ) . Dwork et al. [11] showed that it suffices to add noise proportional to the sensitivity of the function f . Sensitivity measures the maximum possible change in the value of f when one record from the data set is changed.

D EFINITION 2 (S ENSITIVITY [11]). The sensitivity of a function f : D n  X  R d is the smallest number  X  f such that for all inputs T,T  X   X  D n which differ in a single entry (record), || f ( T )  X  f ( T  X  ) || 1  X   X  f .

Consider the randomized algorithm A f that computes f ( T ) and releases  X  f ( T ) = f ( T ) + Lap  X  f  X  d , where Lap (  X  ) vector of d i.i.d. samples from the Laplace distribution Lap (  X  ) . Recall that Lap (  X  ) is the distribution on R with density at y given by 1  X  exp(  X  X  y | / X  ) . Dwork et al. [11] showed that A tially private. The standard deviation of Lap (  X  ) is  X  algorithm adds noise proportional to  X  f/ X  .

Noise addition is not directly relevant to FPM because the output cannot be described by a single low-sensitivity real-valued func-tion. However, we will use this technique for reporting the fre-quencies of the patterns we output.
 The Exponential Mechanism. McSherry et al. [23] proposed a technique, the exponential mechanism , for designing differentially private algorithms for non-real valued outputs. The exponential mechanism is parametrized by a finite set R of possible outputs (called the range ) and a real-valued function q : D n  X  R  X  R that assigns each possible output r a score q ( T,r ) based on the in-put T . Given R , q , T and  X  , the goal is to produce an output with as high a score as possible, while satisfying  X  -differential privacy. The algorithm draws a single sample from the distribution on R which assigns each element r  X  R probability mass proportional to exp(  X q ( T,r ) / 2 X  q ) . Here  X  q is the maximum of the sensitivi-ties (Def. 2) of the functions q ( ,r ) . That is,  X  q is the maximum over r and neighboring data sets T,T  X  of | q ( r,T )  X  q ( r,T tuitively, the mechanism is useful since it assigns high mass to el-ements r with high scores. McSherry and Talwar [23] showed that this algorithm is  X  -differentially private. We adapt their technique to FPM in our first algorithm (Section 3.2).
The output of frequent pattern mining algorithms is typically a list of patterns together with their supports or frequencies. Modi-fying such an algorithm to satisfy differential privacy requires in-troducing uncertainty into the output. There are two natural ap-proaches to doing this: we can first construct a noisy list of patterns ( i.e. by including some  X  X nfrequent X  patterns in the list, while leav-ing out some  X  X requent X  ones) and then perturb the frequencies of those patterns, or we can first add noise to the frequencies of all patterns and then select the patterns with the highest noisy frequen-cies. In this paper, we present algorithms which illustrate each of these approaches. Our first algorithm is based on the exponential mechanism of [23]; the second, on the Laplace noise model of [11].
To quantify our algorithms X  utility, we introduce a natural notion of approximation for frequent pattern mining. Given an input data set T , the true frequency of a pattern refers to the proportion of records in T in which the pattern actually occurs; in contrast, the reported , or noisy , frequency refers to the estimate reported by the algorithm.

D EFINITION 3 (A PPROXIMATE TOP -k FPM). Let T be a set of n records and U be a collection of patterns. Consider an al-gorithm that reports a list of k patterns together with an estimated frequency for each pattern. Let f k denote the frequency of the k most frequent pattern from U in T . For positive real parameters  X , X , X  , we say the algorithm is (  X , X , X  ) -useful if, with probability at least (1  X   X  ) , the output satisfies: Soundness: No pattern in the output has true frequency less than Completeness: Every pattern in U with true frequency greater than Precision: For every pattern in the output list, the reported fre-
To design our algorithms, we cast Frequent Pattern Mining in the following abstract framework, which generalizes the problem addressed by the exponential mechanism and which we call pri-vate selection . Let U = { 1 , ,u } be a collection of u elements. Given a data set T  X  D n , each element r is assigned a score q ( T,r ) . The goal is to output k distinct elements with scores as high as possible. In the case of FPM, the elements are patterns and an element X  X  score is its frequency in the underlying database. This abstraction of FPM ignores any relationships between patterns: for example, our algorithms do not use the fact that overlapping subsets are likely to have close scores.

The abstraction has two significant benefits. First, our algorithms apply to any problem which fits the private selection framework. For example, we might modify the score function to take into ac-count set size or a measure statistical significance. Alternatively, our algorithms could be applied to similar problems such as that of mining search logs privately (see Section 5). The algorithms and utility statements would then change slightly: in general,  X  q , the maximum sensitivity of q ( ,r ) , replaces 1 /n , the sensitivity of the frequency. Second, the data structures we use to achieve an effi-cient implementation are simpler to explain in the abstract setting. Below, we explain our algorithms in the specific context of FPM, but we return to the abstract setting for some of the implementation discussion.
 Avoiding Exponential Time: Truncated Frequencies. One diffi-culty with this abstraction is that in FPM, the set U of patterns we wish to consider can be exponentially large in the problem param-eters. For example, if U is the collection of all sets of size  X  among m possibilities, | U | = m  X  . A naive approach to the general selec-tion problem requires time O ( | U | ) .

In both of our algorithms, a key step is to only explicitly treat those patterns with frequencies above f k  X   X  (where f k is the k highest frequency of a pattern and  X  is the accuracy parameter). All other patterns are treated implicitly : if S 0  X  U is the set of patterns with frequency at most f k  X   X  , we create a virtual  X  X uper-pattern X  which represents all the patterns in S 0 . This super-pattern is handled differently in the two algorithms, but in both cases the operations take time independent of the size of S 0 . Thus, below we mostly work with the truncated frequency of an element, defined as  X  f = max( f,f k  X   X  ) , where f is the true frequency.
In this section we show how the exponential mechanism de-scribed above can be adapted, with some work, to FPM.

At a high level, our first algorithm consists of k applications of the exponential mechanism. In each round i , we sample a pattern I from the set of patterns R i = U \ {I 1 ,..., I i  X  1 } not selected so far. Given a data set T , the score of a pattern is its truncated frequency  X  f = max( f,f k  X   X  ) . The analysis of privacy relies on bounding the sensitivity of the truncated frequency. Getting the algorithm to run quickly requires a careful implementation of the sampling step.
 Algorithm 1 Exponential sampling-based FPM Input: Data set T , privacy parameter  X  , collection of patterns U , 1: Preprocessing: Compute  X  = 4 k  X n ln k  X  + ln | U | . Run a 2: Sampling: Sample k patterns from U without replacement 3: Perturbation: Perturb the true frequencies of the patterns 4: return The sampled k patterns and their noisy frequencies.
In Algorithm 1, we describe our exponential sampling-based FPM algorithm. The algorithm takes the data set T , the data set size n , the collection of patterns U , the number of desired patterns k , the privacy parameter  X  and the confidence parameter  X  as input. In the preprocessing step,  X  is computed as 4 k  X n ln k  X  + ln | U | (see Lemma 5). A FPM algorithm is used to obtain all patterns with frequency  X  f k  X   X  .
In the sampling step, the truncated frequencies are used to sam-ple k patterns such that the probability of selecting a pattern is pro-portional to exp(  X n 4 k b f ( I )) . We give details in the next section. In the perturbation step, the true frequencies of the k sampled pat-terns are perturbed by a zero mean Laplace noise with parameter  X n before being output. In order to compute the true frequencies of all the k patterns, in the worst case, O ( k n ) additional work may be required. The noise addition step itself has complexity O ( k ) .
Let k  X  ( &gt; k ) denote the number of patterns mined by the FPM algorithm in the preprocessing step. Existing (non-private) FPM algorithms, such as Apriori , run in time  X ( k  X  n ) , and no better run-ning time is possible in some cases. We show that the FPM running time is the dominant term in the overall running time of the algo-rithm. The perturbation step runs in time O ( k n ) . Next, we analyze the complexity of the sampling step.

In any particular round of sampling, let S 1 be the collection of patterns with true frequencies &gt; f k  X   X  and S 0 = U \ S collection of patterns with true frequencies  X  f k  X   X  . Because we sample without replacement, the sets change with each round of sampling. For any pattern I  X  S 1 , the associated probability mass is 1 C exp(  X n b f ( I ) 4 k ) , where the normalization constant C = P ity mass associated with the patterns in S 0 is | S 0 | C Rather than handling patterns in S 0 explicitly, we create one  X  X uper-the super-element in S 0 is sampled, we output a uniformly random member of S 0 (this is efficient as long as generating uniformly ran-dom members of U is efficient).

A simple implementation of the sampling step is to partition the real number line [0 , 1] into | S 1 | + 1 segments (one each for an pat-tern in S 1 and the last one for all patterns in S 0 ) according to the probability masses defined above. Then we sample a number uni-formly at random within the interval [0 , 1] . The partition in which the random number falls decides the pattern that we pick. This technique is inefficient because every time a pattern is picked, one has to recompute a large fraction of the partition; the time complex-ity is O ( k k  X  ) . One can significantly improve this running time, using a data structure of Matias et al. [21] for updating and sam-pling from a dynamic distribution on k  X  elements in amortized time O (log  X  k  X  ) per operation.

L EMMA 1. The sampling step of Algorithm 1 can be imple-mented to run in time O ( k  X  + k log  X  ( k  X  )) .

We found in our experiments that a simpler, linked-list-based data structure (Fig. 1) performed well on our data sets though it has poor worst-case performance. Specifically, suppose we wish to sample without replacement from U = { 1 , ,u } , where the probability of picking the element i element is proportional to its weight A i . Sort the elements by weight so that A 1  X  A 2 Create a linked list, where the i -th node stores B i = To pick an element, traverse the list starting at node 1 . When at the i -th node, stop and pick element i with probability P i = A or we move to node i + 1 with probability 1  X  P i . The probability of picking an element i in a traversal is equal to (1  X  P P ement i , we remove the corresponding node from the linked list (in our application, the node corresponding to S 0 has its weight slightly decreased rather than being removed). We then update the B  X  X  for nodes 1 , ,i  X  1 by subtracting A i . We start the next round of sampling in an exactly same manner as the previous round of sampling, but this time with the new linked list. We repeat this process k times.

If the A i  X  X  are highly skewed then in each round of sampling one need not go far in the linked list before an element is picked. (For example, if the ratios A i /A i +1 are all at least 2, then the expected depth on any run is at most 2.)
From Lemma 1, we know that the sampling step can be imple-mented in time O ( k  X  + k log  X  ( k  X  )) . Further, the perturbation step takes O ( kn ) running time. Therefore, in total steps 2 and 3 of the algorithm runs in O ( k  X  + k log  X  ( k  X  ) + kn ) . Earlier in the analysis we saw that the preprocessing of the algorithm takes time  X ( k Hence, we can conclude that for data sets with reasonably large n , the preprocessing step is the performance bottleneck.
In this section, we prove that Algorithm 1 is  X  -differentially pri-vate. First, we claim that the sensitivity of truncated frequency of any pattern is bounded (see the full version [8] for a proof).
L EMMA 2. For any pattern I , the truncated frequency of I has sensitivity 1 n .

The sampling step consists of k applications of the exponen-tial mechanism, using the truncated frequencies as score function. Hence, by Lemma 2, the sensitivity of the score function is 1 /n . From the analysis of the exponential mechanism [23] (see Sec-tion 2), each round of the sampling step guarantees  X  2 k privacy. In the perturbation step, we use the Laplace noise addi-tion technique (described in Section 2) independently on the true frequencies of the k patterns chosen in the sampling step. The scaling parameter for the Laplace distribution used is 2 k the noise addition step guarantees  X  2 k -differential privacy. We can now apply the following composition lemma:
L EMMA 3 (C OMPOSITION L EMMA [11]). Let A be the ran-domized algorithm that, on input T , runs k algorithms A 1 A , where each algorithm is  X  i -differentially private, and outputs ( A 1 ( T ) , , A k ( T )) . Then A is ( The composition lemma guarantees that the overall algorithm is at most 2 k  X   X  2 k =  X  -differentially private. This proves:
T HEOREM 1. Algorithm 1 is  X  -differentially private.
In this section, we provide theoretical guarantees for the utility of our algorithm. Intuitively, Theorem 2 guarantees that with high probability, the k patterns output by our algorithm are close to the actual top k patterns. Theorem 3 guarantees that with high prob-ability, the reported frequencies of the patterns output are close to their true frequencies. The main steps of the proof of Theorem 2 are stated here as Lemmas 4, 5, 6.

We include only a proof of the first lemma here; the remaining proofs can be found in the full paper [8].
L EMMA 4. At each round of sampling during the sampling step, if there exists an unsampled pattern with true frequency  X  f , then the probability of picking any pattern with true frequency  X  f  X   X  is at most | U | exp  X   X n X  4 k .

P ROOF . Conditioned on the fact that a pattern with true fre-quency f is still present, the probability of picking a pattern with true frequency  X  f  X   X  is  X  e
Since, there are at most | U | patterns with true frequency  X  f  X   X  therefore, by union bound the probability of picking a pattern with true frequency  X  f  X   X  is at most | U | exp(  X   X n X  4 k ) . Let S be the collection of patterns sampled in the sampling step.
L EMMA 5. For all  X  &gt; 0 : with probability at least 1  X   X  , the true frequencies of all the patterns in S are &gt; f k  X   X  , where  X  =
L EMMA 6. For all  X  &gt; 0 : with probability at least 1  X   X  , all patterns in U with true frequency &gt; f k +  X  are present in S , where  X  = 4 k  X n ln k  X  + ln | U | . When  X  is constant,  X  =
T HEOREM 2. For all  X  &gt; 0 : with probability at least 1  X   X  , all output patterns have their true frequencies &gt; f k  X   X  , and all patterns in | U | with true frequency &gt; f k +  X  are output, where  X  = 4 k  X n ln 2 k  X  + ln | U | . When  X  is constant,
T HEOREM 3. For all  X  &gt; 0 : with probability at least 1  X   X  , all noisy frequencies differ by at most  X  from their corresponding true frequencies, where  X  = 2 k n X  ln k  X  .
Our second algorithm is much simpler to implement and under-stand than the first. The second algorithm X  X  utility bounds are sim-ilar to the first one X  X , though slightly worse (by a factor of roughly 2). Nevertheless, the second algorithms X  simplicity may make it preferable in some settings. Moreover, the analysis of privacy re-quires a proof technique which may be of independent interest. In-dependently of our development of this algorithm, McSherry used a similar idea (for k = 1 ) in the PInQ query language prototype (the idea is not described in the accompanying paper [22], but was used in the implementation).

Our approach is specified in Algorithm 2. The basic idea of the algorithm is to add independent Laplace noise to the frequencies of all patterns and select the k patterns with the highest perturbed frequencies. A na X ve sensitivity analysis suggests that we must add However, we show that it suffices to add noise only O ( k/ (  X n )) to the frequencies. Additional work is required to get an efficient im-plementation; in particular, we use the idea of truncated frequencies from the previous algorithm.
Steps 1 and 3 of the algorithm are straightforward. However, the noise addition and sampling step requires care to perform effi-ciently. As in the first algorithm, we give an implementation which runs in time proportional to k  X  , the number of patterns found in Step Algorithm 2 Score perturbation-based FPM Input: Data set T , privacy parameter  X  , collection of patterns U , 1: Preprocessing: Compute  X  = 8 k  X n ln | U |  X  . Run a (non-2: Noise addition and sampling: Add Lap 4 k  X n to the truncated 3: Perturbation: Perturb the true frequencies of the patterns in S 4: return The set S and the corresponding final noisy frequen-1 of algorithm; typically, k  X  is much smaller than | U | . Following the notation of the previous section, let S 1 be the set of patterns with true frequencies greater than f k  X   X  (this set has size k S 0 = U  X  S 1 be the set of patterns with true frequencies at most f  X   X  .

In Step 2, we add noise to the frequencies of patterns in S and store the results explicitly. However, we handle the patterns in U  X  S 1 implicitly. Specifically, let  X  be the k th largest noisy fre-quency in the set S 1 .If a pattern whose true frequency is less than  X  = f k  X   X  makes it to the final output then its noisy frequency must be at least  X  . We can generate the list of the k largest noisy frequencies greater than  X  without exhaustively generating all the noisy frequencies for patterns in S 0 .

Conceptually, the simplest way to do this is to generate the k largest values from a sequence of | S 0 | independent Laplace vari-ables. (It is possible to do this in time O ( k log k ) , regardless of | S 0 | , using standard techniques.) By symmetry, the patterns asso-ciated with those k highest scores will be uniformly distributed in S (since all patterns in S 0 have the same truncated frequency). So we can quickly generate a set V of the patterns in S 0 with highest noisy frequencies among all those in S 0 . Finally, we pick the k patterns with the largest noisy frequencies from the set S pass them on to the the perturbation step. We obtain: L EMMA 7. With probability at least 1  X   X  , Steps 2 and 3 of Algorithm 2 can be implemented to run in time O ( k  X  + k log k ) , where k  X  is the number of patterns returned by the FPM algorithm.
In our experiments we used a simpler algorithm for generating V which does not come with worst-case running time guarantees but performed well. To understand our approach, consider a pattern I in S 0 . Assuming that  X   X   X  , the probability that I has noisy frequency greater than  X  (and hence has a chance to appear in the which have noisy frequency greater than  X  thus follows a Binomial distribution with parameters | S 0 | and p . We now pick a random number X according to this Binomial distribution and pick at set V of X patterns uniformly at random from the set S 0 . Assume that  X   X   X  and that X  X  k  X  . (In our experiments, these conditions always held.) Conditioned on the event that there are X patterns in S 0 with true frequencies  X   X  whose noisy frequencies are greater than  X  , the distribution of these X noisy frequencies follows an ex-ponential distribution with mean  X  + 4 k  X n and standard deviation This follows from the memorylessness property of the exponential distribution. Thus, we select the noisy frequencies of the patterns in V i.i.d. from the correct exponential distribution. T HEOREM 4. The algorithm is  X  -differentially private.

We first state a useful fact about the algorithm X  X  output. Let X = h X 1 , ,X u i be a vector of random variables such that for all i , X i = a i + Lap (  X  ) , where a i  X  R and  X  is the scaling parameter of the Laplace distribution. Let X j 1 , ,X j k be the k largest entries in X and let Z = { j 1 , ,j k } denote the corresponding indices.
C LAIM 1 (T RANSLATION I NVARIANCE ). The probability dis-tribution over the random variable Z remains the same if all the a  X  X  are shifted by a constant  X   X  R .

P ROOF OF T HEOREM 4. We first prove that the results of Step 2 (the noise addition and sampling step) preserve  X  2 -differential pri-vacy. Given the results of Step 2, releasing the final noisy frequen-cies is  X  2 -differentially private by the reasoning of Dwork et al. [11]. By the composition property (Lemma 3), the algorithm as a whole is  X  -differentially private.

Let W be a set of k patterns. Let T,T  X   X  D n be any two data sets differing in exactly one record. We want to first show that Pr [ A ( T ) = W ]  X  e  X  2 Pr [ A ( T  X  ) = W ] . (This is an abuse of no-tation as the output of A is the collection of itemsets and their fre-quencies, however we use it for simplicity.) To denote the noisy frequency of a pattern I in Step 2 of the algorithm, we use
Given values v 1 ,...,v k for the noisy frequencies of the elements in W , the set W can be output only if all other noisy frequencies are less than min { v 1 ,...,v k } . Thus: Pr[ A ( T ) = W ] = We use the notation pdf T [ ] , Pr T [] to describe the probability den-sity function and the probability mass function on data set T . lower bound for the denominator. Recall that each true truncated frequency differs by at most 1 n between T and T  X  . For fixed T , we can lower bound the probability that A ( T  X  ) = W by considering a  X  X ictional X  data set in which T  X  X  in which  X  f I ( T  X  X  if I  X  W and  X  f I ( T  X  X  ) =  X  f I ( T ) + 1 n if I 6 X  W . Note that there may not exist a data set T  X  X  with these exact frequencies; however, using the frequencies in (1) gives a well-defined upper bound on Pr[ A ( T  X  ) = W ] . Note that the behavior of algorithm A depends only on the truncated frequencies of the patterns, not on any rela-tionships between the patterns.

From Claim 1, we know that A will behave the same (in terms of outputting the patterns) on a (fictional) data set T  X  X  X  haves on T  X  X  where all the truncated frequencies of the patterns in T  X  X  are shifted by 1 or decrease all) to form T  X  X  X  . Again, for the purpose of analysis we can use T  X  X  X  because Pr[ A ( T  X  X  X  ) = W ] = Pr[ A ( T (more precesiely, the values one gets from (1) are the same). There-fore, we can bound the denominator above using the frequencies:  X  f ( T  X  X  X  ) =  X  f I ( T )  X  2 n if I  X  W and  X  f I ( T  X  X  X  ) =
Data set n m | t | accidents 340183 469 34.81 chess 3196 76 38 connect 67557 130 44 kosarak 990002 41270 8.09 mushroom 8124 120 24 pumsb 49046 2114 75 pumsb-star 49046 2089 51.48 retail 88162 16471 11.31 T10I4D100K 100000 871 11.1 T40I10D100K 100000 943 40.61 Table 1: Data sets characteristics: Number of transactions N , size of alphabet m , average size of transaction, | t | . changing b f I by at most 2 n ). Since in each term in the integration of the expression for Pr[ A ( T  X  ) = W ] , there are exactly k terms which has I  X  W , when we change from T to T  X  X  X  each term in the integration changes by at most 2 k n X  . Crucially, the term involv-ing min { v 1 ,...,v k } remains the same from T to T  X  X  X 
Setting  X  = 4 k n X  guarantees  X  2 -differential privacy for the noise addition and sampling step of the algorithm. This completes the proof.

T HEOREM 5. For all  X  &gt; 0 : with probability at least 1  X   X  , all patterns output have their true frequencies &gt; f k  X   X  , and all patterns in | U | with true frequency &gt; f k +  X  are output, where
T HEOREM 6. For all  X  &gt; 0 : with probability at least 1  X   X  , all noisy frequencies differ by at most  X  from their corresponding true frequencies, where  X  = 2 k n X  ln k  X  .
In this section, we present the results of several experiments we performed to evaluate the performance of the above proposed algo-rithms. All the experiments are in the context of frequent itemset mining (FIM). Let M be a universe of m items. In the context of FIM, a pattern (itemset) of size  X  is a subset of M with cardinality  X  . In our experiments U refers to the collection of all itemsets of a given length  X  . Hence, the cardinality of U is m  X  . A transaction refers to a subset of M and the length of a transaction is the number of items in it. A transaction data set T contains n records, where each record is a transaction.
 We first describe the data sets on which we ran our algorithms. Then we present the relationships between the different parameters ( e.g. ,  X  ,  X  ,  X  ,  X  ) that we obtain by applying the theoretical results to these data sets. We also study extensively the utility of our algo-rithms for these data sets under a wide range of parameters.
For the evaluation of our experiments, we use data sets publicly available at the FIMI repository [2]. These data sets are listed in Ta-ble 1. This collection of data sets contains both real-world and syn-thetic data sets, and have widely varying characteristics like num-ber of transactions n , number of items m and average transaction length | t | .

Summary of the results: a) Theoretical guarantees result in useful parameter ranges on these data sets -We show that our theorems about privacy and util-ity, when applied to these data sets yield a useful range for all the parameters of the system. In particular, the efficiency of our al-gorithms greatly depends on the threshold at which the underlying FIM algorithm runs. The threshold we provide to the FIM algo-rithm is f k  X   X  . A small  X  implies that the privacy overhead in terms of the running time of the FIM algorithm is not too high. We a threshold we have to provide to the FIM algorithm for various choices of other parameters. Our plots show that for most data sets, at typical values of the parameters (  X  2 = 0 . 7 ,  X  = 0 . 1 , l = 3 , k = 10 ),  X  is a small fraction of f k . The other theoretical guar-antee that we provide is about  X  , which is the difference between the reported frequencies of the output itemsets and their true fre-quencies. For these data sets, we show that the actual value of  X  obtained is a small fraction of f k . Note that we plot variation of  X  and  X  against  X  2 to emphasize that the final privacy parameter is  X  when both the itemsets and their frequency are output. b) For a wide range of parameters, the algorithms give good utility on these data sets -For the same set of parameter ranges as in (a), we run our algorithms on these data sets and plot the False Negative Rate (FNR) for the output. Note that False Positive Rate (FPR) is essentially small for this output as the number of infre-quent itemsets are typically high compared to the total number of frequent itemsets (since k  X  m  X  ). In these data sets, the highest possible FPR that can be achieved is 0.03 (this is assuming that all the top k itemsets are false positives). Our plots show that, again for typical values of the parameters, FNR is under 0.2 for eight data sets (while for 6 of them it is close to 0.02). We also show that the running time of our algorithms is very comparable to the FIM run-ning time for most data sets for a reasonable range of the privacy parameter.

In our first set of experiments, we study the behavior of varies from 0.04-2, k varies from 10-100 and  X  varies from 2-6. In an experiment, while one parameter varies, the other three remain fixed. These fixed values are  X  2 = 0 . 7 ,  X  = 0 . 1 , k = 10 and l = 3 . Figure 2 shows the plot of  X  f (note x axis is in log scale) for Algorithm 1. We clamp the y-axis at 1, as  X  f f  X   X  &lt; 0 . Whenever the theoretical requirement causes f become negative, one of the utility guarantees (namely, soundness) becomes trivial. Also note, that when  X  f  X  1 , f k +  X  becomes greater than 1. In this case, the other utility Figure 3: Variation of  X  f itemsets  X  vary. guarantee (namely, completeness) becomes trivial. Thus whenever trivial. In the figures, the arrowhead on the y-axis indicate for each data set. For some data sets, 1 f does not show up in the plots. For Algorithm 1, at  X  2 = 0 . 7 , for all data sets except chess and T10I4D100K, both the utility guarantees (soundness and completeness) are non-trivial as the obtained less than min(1 , 1 f privacy requirement  X  is relaxed. Figure 3(a) shows the variation of for data sets which have either a large alphabet size m ( e.g. , retail) or a low f k ( e.g. , T10I4D100K and T40I10D100K) or a small n ( e.g. , chess and mushroom). Note that for kosarak the rise is not that rapid despite having a big m as n is also quite large for it. Figure 3(b) shows the variation of  X  f trend in this plot is quite similar to the one in 3(a).

In the same set of experiments we also study the noise added to the frequencies of the output items. We show the variation of with  X  2 in figure 4. We see that at  X  2 = 0 . 7 , the ratio 0.1 for all data sets. We skip the plots of  X  f to lack of space.

In our next set of experiments we study the False Negative Rate (FNR) produced in the output as we vary the parameters over the
Figure 4: Variation of (  X  f
Figure 5: Variation of FNR with the privacy parameter  X  2 same ranges as in the earlier set of experiments. The underlying FIM algorithm employed was the "fp-growth" version of Ferenc Bodon X  X  implementation [1]. It was run on a machine with an In-tel(R) Xeon(R) CPU E5345 @2.33 GHz with 16 GB of RAM. In our experiments, we found the running time of the underlying FIM algorithm as the dominant term in the overall running time. Thus, to have a reasonable check on the running time of the complete ex-periment, we decided to discard all experiment runs in which the underlying FIM algorithm ran for more than 5 minutes or produced an itemset output file of size greater than 5GB. Thus, if for a certain choice of parameters, the f k  X   X  value was such that the FIM algo-rithm run violated the above constraints, we don X  X  report the FNR. This does not mean that our algorithms fail to terminate for that choice of parameters. In fact, under such stringent computational constraints, the algorithms continue to provide good results for a wide range of parameters. Each FNR reading reported in this set of experiments is averaged over 10 runs of the experiment. The stan-dard deviation in the FNR was always under 0.2. We don X  X  show the standard deviations to make the plots more readable.
Figure 5 shows the plot of FNR against  X  2 . At  X  2 = 0 . 7 , except data sets chess and T10I4D100K, all others have a FNR of under 0.2. In fact for most data sets (6 of them) the FNR is close to 0.02. We skip FNR v/s  X  plot due to lack of space. In Figs. 6(a)-6(b) the FNR seems to rise with increasing K or  X  . Note, for some data sets including T10I4D100K, T40I10D100K, chess and retail, there are a lot of missing points as the underlying FIM algorithm run violated our computational constraints often. For all other data sets, the FNR continues to remain low.

In Table 2, we compare the run-time of Algorithm 1 with the run-time of FIM ("fp-growth" version of Ferenc Bodon X  X  imple-mentation) for three different values of the privacy parameter. For each data set, the first column lists the time (in milliseconds, aver-aged over 10 runs) taken by the FIM algorithm. The second, third and fourth columns list the average run-times of Algorithm 1 for = 0 . 06 , 0 . 7 and 1 . 3 respectively. The quantity within parentheses is the ratio of the running time of Algorithm 1 to that of FIM. In most cases ( e.g. , accidents, connect and kosarak) the running times of FIM and Algorithm 1 were very close, implying that our privacy mechanisms do not introduce significant run-time overheads. In other cases (such as mushroom, T10I4D100K and T40I10D100K) the two run-times are initially far apart and then become similar as the privacy parameter is relaxed. Also, some entries are missing in the table ( e.g. , for  X  2 = 0 . 06 in chess and retail) since either the resulting output files were larger than 5 GB or the run-times were bigger than 5 minutes. Finally, in a small number of cases, the standard deviations in FIM run-times were as much as 100 mil-liseconds. Because of this, when f k and f k  X   X  were nearly same ( e.g. ,  X  2 = 0 . 7 in accidents and mushroom) we observed marginally smaller running times for Algorithm 1 compared to FIM.
Data FIM Algorithm 1 (ms) sets (ms)  X  2 = 0 . 06  X  2 = 0 . 7  X  2 = 1 . 3 accidents 897 878(1.0) 875(1.0) 895(1.0) chess 61 -77(1.3) 89(1.4) connect 273 364(1.3) 284(1.0) 300(1.1) kosarak 1077 1073(1.0) 1084(1.0) 1058(0.98) mush 105 10542(100.1) 78(0.8) 125(1.2) pumsb 386 834(2.2) 393(1.0) 389(1.0) pumsb* 288 317(1.1) 288(1.0) 289(1.0) retail 150 -183(1.2) 172(1.2) T10 530 -6912(13.1) 1339(2.5)
T40 6191 -33006(5.3) 14190(2.3)
In the following sections we present our comparison to related work mostly in the context of frequent itemset mining (FIM). Re-viewing some of the notation from FIM, m represents the size of the universe of items,  X  represent the size of an item set ( i.e. , the number of items in it) and n is the number of transactions in the transaction data set T (where a transaction is a collection of items).
One approach to privacy preserving data mining is randomized response. In this approach each entry in the data set is indepen-dently randomized before allowing the data mining algorithm to access it. Evfimievski et al. [12] and Agrawal et al. [6] consid-ered randomized response in the context of FIM. They consider the threshold variant where the goal is to return all the itemsets of length  X  whose frequencies are greater than a predefined threshold  X  . They define the term amplification factor which quantifies the privacy guarantee of the mining algorithm. The amplification fac-tor directly corresponds to e  X  , where  X  is the differential privacy parameter. The work of [6] is an improvement over [12].

We compare our Algorithms 1 and 2 to the algorithms of [6] on the same CENSUS data set used by [6] from the UCI repository http://archive.ics.uci.edu/ml/ . To enable compari-son, we set the parameters of our algorithms as follows: First, we set k so that f k equals the threshold  X  used by [6]. Second, they use amplification factor e  X  = 19 , where as we set it to e (that is, we impose an even stronger privacy guarantee). Third, we set the confidence parameter  X  for our algorithms to 0 . 05 ; there is no analogous parameter in [6].

To measure utility, [6] used the false negative rate (FNR). We compared the FNR of our algorithms to those of the two best-performing algorithms from [6] (RAN-GD and DET-GD) for vari-ous itemset lengths; the results are plotted in Figure 7. We find that both of our algorithms have consistently lower FNR. The FNR for RAN-GD and DET-GD were taken from Agrawal et al. [6, Figures 1(a) and 2(a)].

G X tz et al. [15] and Korolova et al. [19] independently presented algorithms for releasing search log statistics in a differentially pri-vate manner. Both algorithms are similar to each other. We can adapt them to provide differentially private algorithms for FPM.
It is difficult to compare the performance of these two algorithms against our algorithms because they were optimized for the search log setting. Specifically, the algorithms add Lap (  X  ) noise to fre-Figure 7: FNR obtained while comparing our algorithms 1 and 2 with the FRAPP framework quencies of the patterns from the collection U , and outputs all the patterns from U and their corresponding noisy frequencies which exceed a specified threshold  X   X  . In contrast, we output the top k patterns from U and add noise independently.

If we consider the FIM setting, a single transaction can poten-tially change the frequencies of m  X  length- X  itemsets. In the exper-imental settings we consider, the value of m  X  is far higher than the maximum value  X  (i.e., the number of itemsets whose frequencies change by changing one transaction in the data set) used by [15] and [19]. In order to make their assumption reasonable for FIM, we impose a bound t on the number of itemsets any particular transac-tion of the data set can support. We can map the parameter  X  from the search log setting to t  X  in FIM setting.

G X tz et al. [15, Theorem 1] state the value of  X  (i.e. the scaling parameter of Laplace noise) and  X   X  sufficient to guarantee (  X , X  ) -differential privacy for algorithms by [15] and [19] respectively. ( (  X , X  ) -differential privacy is a relaxation to the definition of  X  -differential privacy allowing a small additive error of  X  .) Adapt-ing this theorem to our setting we get,  X  = 2 ( t  X  ) n X  and  X   X  for the different data sets we have considered in our experiments. We have set  X  = 1 , X  = 0 . 05 and  X  = 3 . In all but for the acci-dent data set,  X   X  is greater than one. In order to output the k most frequent itemsets, we would like to have  X   X  be at most f makes the algorithms by G X tz et al. and Korolova et al. unreason-able for our experimental setup. Note that in cases where t and  X  are small, their approach might indeed work well. However, in terms of privacy guarantee they provide (  X , X  ) -differential privacy guarantee which is strictly worse than the guarantee we provide.
Blum et al. [9] provided a method to output a synthetic data set e T , which provides near accurate answers for frequency queries (i.e . close to the frequencies in the original data set T ). This data set can be output in a  X  -differentially private manner. In the context rithm due to Blum et al. and our algorithms 1 and 2 are similar. Recall that that in our algorithms, we need  X   X   X  O k X   X n experimental settings we consider, n X  is far larger than k , hence the lower bound on  X  in our case is better. However, in settings where k is larger than m 1 3 ( n X  ) 2 3 , the algorithm of [9] gives a better bound on  X  . Even in these settings, our approach may be prefer-able for efficiency. The only known implementation of [9] runs in time 2 e O resources available.
In this paper we presented two efficient differentially private al-gorithms for top-k frequent pattern mining. In our algorithms we adapted the exponential mechanism and the Laplace noise-addition mechanism by introducing techniques that are efficient in the con-text of frequent pattern mining. We introduced a new notion of util-ity for top-k pattern mining and provided theoretical analysis of our methods under this criterion. We also presented extensive experi-mental results that demonstrate the effectiveness of our methods on the FIMI benchmark data sets. Though we present our algorithms for the problem of frequent pattern mining, our techniques are ap-plicable in the general problem of private ranking as well. For ex-ample, our algorithms can be used in the settings of [15] and [19], where they analyze the problem of releasing search log statistics privately.

The utility guarantees we provide in Theorems 2 and 5 are de-pendent on the size of the collection of patterns U . In some cases, U can be large ( e.g. , FIM), resulting in large run-times as well as loose utility guarantees. A possible future direction is to devise techniques that remove this dependency on the size of the collection of patterns, thereby extending the applicability of the algorithms to bigger and more complex data sets.
 Acknowledgements. A.S. and A.T. are partly supported by NSF grants #0747294, 0729171. We thank Daniel Kifer and Frank Mc-Sherry for helpful comments. [1] Apriori implementation of Ferenc Bodon. [2] Frequent itemset mining implementations repository. [3] C. Aggarwal, C. C. Aggarwal, and P. S. Yu. A condensation [4] R. Agrawal, T. Imielinski, and A. Swami. Mining association [5] R. Agrawal and R. Srikant. Mining sequential patterns. In [6] S. Agrawal and J. R. Haritsa. A framework for high-accuracy [7] M. Barbaro and T. Zeller. A face is exposed for aol searcher [8] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta.
 [9] A. Blum, K. Ligett, and A. Roth. A learning theory approach [10] C. Dwork. Differential privacy. In ICALP , LNCS, pages [11] C. Dwork, F. McSherry, K. Nissim, and A. Smith.
 [12] A. V. Evfimievski, J. Gehrke, and R. Srikant. Limiting [13] S. R. Ganta, S. P. Kasiviswanathan, and A. Smith.
 [14] N. G.N., B. A., H. J., S. K., and E. I.R. Temporal pattern [15] M. G X tz, A. Machanavajjhala, G. Wang, X. Xiao, and [16] J. Han and M. Kamber. Data mining: Concepts and [17] D. Hand, H. Mannila, and P. Smyth. Principles of data [18] V. Hristidis, editor. Information Discovery on Electronic [19] A. Korolova, K. Kenthapadi, N. Mishra, and A. Ntoulas. [20] H. Mannila, H. Toivonen, and A. I. Verkamo. Discovery of [21] Y. Matias, J. S. Vitter, and W.-C. Ni. Dynamic generation of [22] F. McSherry. Privacy integrated queries: an extensible [23] F. McSherry and K. Talwar. Mechanism design via [24] T. Mielik X inen. On inverse frequent set mining. In 2nd [25] L. Sweeney. k -anonymity: A model for protecting privacy. [26] T. Washio and H. Motoda. State of the art of graph-based
