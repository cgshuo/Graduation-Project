 1. Introduction
Multimedia objects, including image, video and audio files are growing in number on the Web. General studies and statistics on Web searching appear regularly ( Spink &amp; Jansen, 2004 ). People frequently search the Web for multimedia using general Web search engines that generally require the entry of query terms.
A simple image search algorithm locates multimedia files by searching for file extensions and matching the filename to query terms. Some Web search services have provided multimedia searching, e.g., Excite ( http://www.excite.com ), Alta Vista ( http://www.altavista.digital.com ) and Yahoo ( http://www.yahoo.com ). Users can often use file extensions, such as avi, wav or gif, to search for multimedia.

Many studies have analyzed different aspects of multimedia Web search and explored image, audio and video retrieval ( Spink &amp; Jansen, 2004 ). Image queries are the most common Web multimedia searches with longer sessions than video and audio sessions. Audio queries were longer than image or video queries. Ozmu-tlu, Spink, and Ozmutlu (2003), and Spink and Jansen (2004) show trends in multimedia Web searching.
Despite the presence of the multimedia buttons on some Web search engines, many users did not use the but-media queries, including terms such as  X  X  X ictures X  X  or  X  X  X mage X  X . Spink and Jansen (2006) found differences in users X  Web searching patterns as they access various federated content collections on the Dogpile.com Web meta-search engine. Dogpile users X  entered 2 X 3 terms per query and examined only the first pages of results.
Web, news and audio queries were longer sessions but shorter queries. More users X  seeking images and videos sought systems assistance.

However, limited studies have examined the state of multimedia Web search and the multimedia search functions offered by major Web search engines. In this paper we first examine the degree of multimedia search-ing functionality offered by major Web search engines. We then compare the functionalities of each Web search engine which is significant for the development of more effective multimedia IR systems. 2. Related studies
Multimedia files are proliferating on the Web, as networking technologies mature and support large-band-width media. Multimedia searching has become an important research field, particularly for understanding e-commerce and entertainment Web search. However, there is a major need for new multimedia Web search ticated Web search engines. Due to the rapidly increasing usage of digital multimedia data, a single piece of information can often be richly conveyed using multiple correlated media, thus enabling users to concurrently receive information from multiple sources.

Swain (1999) examined WebSeer and AltaVista photo finder to discuss the supports for image searching on the Web. Based on their findings, the main three techniques used by multimedia search engines are: text in
HTML, category selection based on the attributes, and similarity to other images. To search audio and video, duration, bandwidth and key frames information are useful. They believe that the future of multimedia Web search should benefit from speech recognition for audio/video classification, skin detection and word spotting for family-screening, finding near duplicate images, and scalable document-clustering techniques. 2.1. Image search
Text is currently one of the most intuitive method for searching images since most of the available search of text) to write queries. Current Web search engines, such as Google Image ( http://images.google.com ), MSN image ( http://search.msn.com/images ), and Yahoo! Image ( http://images.search.yahoo.com ), has been fixed at the point of text analysis relevant to the multimedia material. However, the major limitation of this approach is the tedious and ineffective nature of manually annotating every (temporal) segments of a video or every region of interests in an image. Moreover, the process of automatic annotation by mapping low-level
For example, systems can use modelled domain knowledge to make sense and interpret the semantic meaning of video data by observing visual, aural and text features ( Duan, Xu, Chua, Qi, &amp; Xu, 2003 ).
The followings will describe some major drawbacks which can already be expected from using texts to man-age multimedia data. First, keywords/free text selection is subjective and often depends on application and domain requirements. For example, day-to-day users may annotate a bird image using simple English words
Second, an image often worth a thousand words X , which means that a few keywords often cannot fully describe a non-temporal data like image; therefore words are further insufficient to describe video and audio which both has temporal-related contents. Third, when users do not know how to explain what they want using words, it is often the case that they would like to query based on a similar image or sound. A recent survey ( Deuel, 2004 ) shows that most of multimedia content is not searchable as we still depend on text, whereas most of multimedia contents do not have a lot of useful text around it compared to a web page.
Kherfi, Ziou, and Bernardi (2004) provided a comprehensive discussion on the issues, techniques and sys-tems of image retrieval from the Web and reviewed some prototypes. Content-based retrieval from multimedia databases is an important key application ( Gevers &amp; Smeulders, 2004; Sebe, Lew, Zhou, Huang, &amp; Bakker, 2003 ). Query by Example (QBE) is widely used, such as in Blobworld ( Carson, Belongie, Greenspan, &amp; Malik, 2002 ), VisualSeek ( Smith &amp; Shih-Fu, 1996 ) and QBIC ( Lee et al., 1994 ). Color, texture and shape are key retrieval features for similarity-based image search ( Li, Chen, Shyu, &amp; Furht, 2002 ). Content-based audio retrieval (CBAR) leads to a more accurate classification than what can be achieved by CBIR systems. For example, audio stream can be classified into music, speech, and noise, as well as some semantic details like cheering, applause, and laughter ( Lie, Cai, &amp; Hanjalic, 2005 ).

In some cases, such as for medical images and family filtering, QBE can be very effective such as trying to find cancer in human limbs or to find human skins in pornographic images. However, in general multimedia documents should to be automatically annotated to support semantic-content-based queries. This raises a challenge for bridging the gaps between low-level features and high-level semantic. Combination of features can be used to automatically annotate MM documents.

Fig. 1 shows an example of processing from raw multimedia data to the high-level semantics. This dia-gram X  X  purpose is to show the complexity in automatic annotation of multimedia documents.

Low-level features can be extracted directly from multimedia data using signal processing algorithms and computer vision techniques. Mid-level features need to be interpreted from a combination of one or more low-level features using some knowledge, rules or thresholds into more meaningful features such as human skins (from color and texture). High-level semantic is the highest abstract contents which can be automatically extracted using pattern recognition and training, such as detecting persons in a video by localizing human skins, face shape (image) and human voices (audio). 2.2. Video search
Video conveys a rich semantic presentation through the synchronized audio, visual and text presentations over a period of time. In the early days of content-based video retrieval (CBVR) research, most efforts have simply borrowed/extended systems and algorithms from image, text and sound retrieval as these types of media have been commonly used much earlier than that of video. Although this strategy has gained some tic, rules, and formats. Since video understanding is strongly dependent on the context and domain, CBVR needs to support different requirements from users and applications, as well as the associated browsing and search strategies. For example, color-texture-shape (i.e. image) based indexing is generally not effective when users need to search particular news video events, such as  X  X ar in Iraq X .

Based on the level of content abstraction that can be automatically extracted, current video retrieval systems can be distinguished by their usage of low-level features or high-level semantic . Yoshitaka and
Ichikawa (1999) surveyed query methods that utilize low-level features from image such as shape, spatial rela-tion, color and texture; and video, including object motion, spatio-temporal relations. They have compared these features-based queries with semantic-based and knowledge-assisted retrievals including  X  X uery-by-sub-ject X  (i.e. keyword) and  X  X uery-by-subject/object X  (i.e. derivation knowledge). The emerging applications and services from these types of retrievals include: finding images that are visually similar to a chosen picture or son; and producing a two-minute skim of an hour-long program ( Chang, Eleftheriadis, &amp; McClintock, 1998 ).
To overcome the wide varieties of video retrieval techniques, Hampapur and Jain (1998) and Elgmagarmid et al. (1997) proposed a classification scheme for video queries based on the nature of video content that is
It is important to note that the Aural and Visual (AV) components of video data are not always equally important in conveying the semantic content, depending on the purpose and use of the video data. Depending on how the video was produced, many different AV features can represent the same semantic content; and vice versa, the same AV features can represent different semantic contents due to subjective point of views of the annotators. Therefore, just like human X  X  perception on video document, the semantic content in video should be more accurately received when more channels are perceived. 2.3. Summary
In summary, multimedia retrieval on the Web is a major challenge involving multi-disciplinary fields, including CBIR, CBAR, and CBVR, as well as text retrieval. Multimedia has recently emerged on the Web and the search capabilities on each media is not equivalently mature. Text is still currently the most widely used method to search for multimedia as text is the oldest type of media on the Internet. To fully support mul-timedia search, however, Web search engines should not be based on text alone, as some users and applica-tions may not know what the usable keywords are. As different Web domains can use certain keywords for various purposes, a single keyword could be easily misinterpreted. For example, when users search for  X  X  X at X  X  images, the search engines may return animal (bat) and baseball (bat) images. Unless the Website that contains the image can give some additional hints, or the image itself has the right caption; users cannot sim-ply search on  X  X  X at and not baseball X  X  to get just the animal (bat) images. On the other hand, if query based on similar images is supported, it can effectively remove baseball (bat) as they have distinguishable features and characteristics, such as shape, color and texture. 3. Research questions
Our research goal was to determine how many major Web search engines are offering multimedia search functionality.

Specifically, the research questions we investigated are: 1. What is the prevalence and level of multimedia search functionality on major Web search engines? 2. What is the level of support for search personalization or customization  X  often accessible as advanced search?
We qualitatively and quantitatively analyzed the existence and extent of multimedia search functionality on 102 commercial Web search engines. 4. Research design 4.1. Data collection
We examined 102 Web search engine sites identified on Searchengines.com to assess their multimedia search functionality ( Fig. 2 ). Multimedia data types examined were based on work by Pazandak and Srivast-ava (1997), and Yoshitaka and Ichikawa (1999) : Images (I): pictures and photographs, which includes: Video (V): sequence of photographic images with synchronised audio to capture real-life events. Audio (A): sequenced data from aural recording, which includes: 4.2. Data analysis
We qualitatively analyzed the absence or presence of multimedia search features for each Web search engine. We examined the following multimedia search functionalities ( Chang et al., 1998; Johnson, 1999; Mukherjea, Hirata, &amp; Hara, 1997 ), which are summarized in Table 1 .
 Text-based Search: text can be obtained from: Content-based Search , which includes:
Interactive browsing : leisure users may not have the specific ideas on the image or video. Instead, they can use image/video icons, key frame.
 Taxonomy of contents and derived semantic.

Relevance feedback: future queries can be improved by asking users to tag search results as  X  X  X elevant X  X ,  X  X  X ot relevant X  X , or  X  X  X eutral X  X .

Search with agent software : high-level search gateway to hide users from complex details (e.g. meta-search).

We qualitatively examined each search engine Web site to investigate the multimedia features to their fullest extent. This involved registering at each multimedia Web search sites, logging into them, and testing each of the multimedia features.

To further describe the extent of multimedia search functionality supported by current Web search engines, we also examined the support of multimedia customization features as listed below. Selected personalization features are combined from all (superset) features, which are supported by all of the examined Web search engines. These features support each aspect of the multimedia functionalities (as described in Table 1 ).

Keywords, size, file format, color, and duration support text-based search. Viewing and delivery method such as pay-per-download and thumbnail supports interactive browsing. Taxonomy of contents supports interactive browsing; and it can support content-based search if they are based on semantic. Content filtering protects users from browsing offensive (unwanted) materials, such as violence or pornography. During our discussions below, it should be noted that we introduce some abbreviations on the extent of personalization.
These abbreviations will be used in our reporting (i.e. as depicted Tables 3 and 4 ). For example, manual formula in keywords is abbreviated to M .
 Keywords : Size : File format or type : Taxonomy of contents : Color : Types of domain : Content filtering : Duration : Viewing or delivery method and some descriptions on the media : 5. Results
We examined 102 Web search engines, of which 65 engines were general Web search engines and 37 were multimedia specialized Web search engines which search on a particular multimedia collection or database.
The comparative study (between general and specialized search engines) is important to extend the MM func-tionalities of current Web search engines. Specialized Web search engines are expected to be superior and more thorough in terms of the MM functionalities. Overall, the key finding was that most general Web search engines do not yet support multimedia search.

Out of 65 general Web search engines, some 43 engines (i.e. nearly 70%) only support text-media search. To provide multimedia search capability, general search engines simply support text-based search on a particular multimedia data. Thus it is expected that the specialized search engines would perform some extra more supe-rior functionalities and features that are specific for multimedia data.

Table 2 summarizes the extent of support for search features by general MM-enabled Web search engines. The list of features in this table is the super-set of all features supported by the Web search engines.

A total of 59 (22 general, 37 specialized) Web search engines supporting multimedia retrieval. We tabular-ized the data in Tables 2 X 4 where the rows are the Web search engines and the columns are the personalizable features. Each row represents the level of supports on each feature for the particular search engine. These tables show if a multimedia feature is not supported by the engine or no personalization is accessible for this feature, or that the feature is not applicable to the engine.

Tables 3 and 4 summarize the extent of support for search features by specialized MM-enabled Web search engines.
 Overall, the results show that: All Web search engines still rely on file metadata such as file format and size and the characteristics of the Website containing the multimedia documents.

Content-based search is still very limited as only 5 out of the 102 examined Web search engines support this feature. Even when content-based search is supported, users can only use low-and mid-level features such as color, texture and shape.
 Semantic concepts are still very limited to keywords without a structured vocabulary.

Similarly, query by example is still not available as Users are not able to determine the importance of multi-ple features (e.g. by using weighting), and they cannot use their own sample video/images (e.g. by uploading the sample image). To supports users X  interaction with the search results, most Web search engines provide key frame or thumbnails for a single document summary.
 Clustering on multiple documents , such as by grouping similar color or concepts, is not generally available. Relevance feedback and searching with agent software are still not supported.

Family friendly filtering is not fully supported as the multimedia contents are not actually examined. When users want to filter out explicit, offensive, or violence materials, most search engines make use of the con-textual information (i.e. the web page which contains the multimedia data) without actually performing automatic content analysis on the image, sound, or video.

Some 11 out of 59 (20%) Web search engines only support keyword search without any customization on size, format, background, color, domain, filter, and duration. General search engines that support this feature are: All the Web Audio, AOL (pictures, video, audio), Lycos, Excite. Specialized engines which support this feature are: Pixsy, I-Film, Search for Video, AtomFilms, Youtube, American Memory, WavCentral.
Most of the video-specialized search engines do not provide customization on file format as this feature is perhaps irrelevant; as long as users can be provided with the right software to open the media. In fact, most of the current software for video playback provides easy to use  X  X  X ne click X  X  button to download the required components (i.e. plug-ins or codec X  X ) to play any video format. 5.1. Semantic-based browsing
Only specialized search engines provide high-level semantic summary on the search results on each docu-ment (which is particularly useful for temporal data). This shows that it is difficult to generate semantic annotation from a large collection such as WWW. The time for processing automatic annotation has to be taken into account too as most users expect fresh pages (from crawling). However, 11 (30%) specialized engines are yet to provide high-level semantic summary on each media, including Getty , Webshots , Smith-sonian , free images , goGraph , Timelife , FindSounds , Animation Factory ,and Gifart , as well as the two pro-totypes: Webseek , Look That Up . Single document summary is very important to enable users to browse (search results) quickly and effectively to determine relevant materials.

For semantic-based descriptions, there should be a standardized multimedia descriptions or ontology to unify the indexes. Manual annotation can only be useful depending on what the users/creators input. How-more useful than search by examples since many users share similar interests and characteristics with others.
A well-developed folksonomy (community-based taxonomy) can act as a shared vocabulary that is both originated-by and familiar-to its primary users to make information increasingly easier to search, discover, and navigate over time. Folksonomy is becoming popular for an unstructured and large collection of informa-tion such as in YouTube and Flickr ( Lew, Sebe, Djeraba, &amp; Jain, 2006 ). As folksonomies are developed in social Web-based environments, users can generally discover who created a particular folksonomy tag, and user who tends to interpret and tag content in a way that makes sense to them, thus increasing their capacity to find related contents.

For a narrower-collection of multimedia database, users would start with navigation, instead of searching as they would not know what is available for them. Most of general search engines emphasize on search, while most of specialized engines provide semantic-based browsing. One of the key reasons is that, collection-based search engines can provide users with narrow-enough topics and quantity of documents to be browsed. Hence, multi-document summaries such as topic-based clustering of related videos will be very useful to assist users in navigating the multimedia collections. 5.2. Specific multimedia functionality
Tables 5 X 9 outline the statistics of Web search engines in terms of their supports for specific multimedia functionality and customization.
 5.3. Multimedia types: image, audio and video
Table 5 shows that Image is still the most popular supported media by Web search engines, followed by audio and video.

Out of 22 general Web search engines that support multimedia search, 22 (i.e. 100%) provides image search functionality. This is consistent with the fact that image requires less bandwidth, thus more affordable by users, while audio is more affordable than video. However, this phenomenon will rapidly change as more devices can capture video and larger network bandwidth has become much cheaper and widely available in the past 3 years. 5.4. Filtering and domain personalization
Table 6 shows that filtering and domain personalization is the most widely available features provided by general Web search engines (i.e. 68% and 36% respectively).

They often can be used to provide more control and censorship upon the contents to be delivered to chil-dren and employee. However, for specialized search engines, the support becomes less important since the col-lections are narrower and more controllable. The specialized search engines usually have a particular domain address which can be used to predict what type of contents are available for users. Hence, filtering (for offen-sive materials) is not an important issue on collections-based search engines as the database contains specific types of images and presumably kept under control by the administrator. Whereas, MM crawled from the
Web may come from different type of collections. 5.5. Format and size personalization
Table 6 also shows that file format and size personalization are not widely supported and may become even less important in the future since most of the current multimedia-viewer software can play multiple file formats and most broadband Internet providers can supply limitless downloads and uploads for affordable price. However, format and size supports should be retained as they can be useful for many purposes. For example, video format such as .mpg and .divx may have the same file size, but since their compression rate is different it can be expected that .mpg will contain less duration. Likewise, users may only want to search for images and video which has at least 1024 * 768 resolutions since high definition TVs and monitors are becoming popular. However, most file format is predefined (e.g. jpg, mp3) and users cannot enter their own. 5.6. Semantic summary
Table 7 shows that only 3 general Web search provide some semantic summary for the multimedia docu-ment (i.e. Google image, Yahoo video, and All the Web video).

Only 7 general Web search (i.e. Yahoo, AOL, Ask Image, Lycos, Excite, Dogpile, Search) provides some taxonomy on the collections. Most of them support  X  X  X opular X  X ,  X  X  X eatured X  X  and  X  X  X ample contents X  X ; while only 2 of these 7 (i.e. Excite and Dogpile) supports  X  X  X elated topics X  X  which represents more semantic supports. 5.7. Customization of duration
Table 8 shows that supports for customization of duration for temporal data (i.e. audio and video) are still very limited.

Less than 30% of the studied engines provide access to this feature. 5.8. Color and background
Table 9 shows that customization of color and background for spatial data (i.e. image and video) receives the least support.

Only 5% from general Web search engines and 0% of specialized Web search engines support search over background. 5.9. Summary Overall, our findings show that despite the growing level of interest in multimedia Web search ( Spink &amp;
Jansen, 2006 ), most major Web search engines currently offer limited multimedia search functionality. Key-words are still used as the only mean of multimedia retrieval, while other methods such as  X  X  X uery by example X  X  are offered by less than 1% from the Web search engines examined. 6. Discussion Our study has contributed to the research into the multimedia search functionality of Web search engines.
Our findings show that despite the high level of interest in multimedia Web search most major Web search engines currently offer limited multimedia search functionality. Keywords are still used as the only mean of multimedia retrieval, while other methods such as  X  X  X uery by example X  X  are offered by less than 1% from the Web search engines examined.

Key issues include discerning what features are most effective to search for multimedia and determining the best techniques for the development of multimedia search features. Keyword is still the standard method to search for multimedia documents from the Web and most users regard information in this manner. However, event, topics, concepts, and objects. Currently, textual annotation of multimedia data on the Web is very limited and most contents providers have not provided much useful information.
 The customization of (advanced) search in multimedia Web search does not cover a wide range of options. There is still a very big gap in the amount of support for multimedia search between different search engines. Thus, users cannot expect almost equivalent level of multimedia retrieval from different Web search engines. Our findings clearly show that despite the rapid growth of multimedia data that are available from the World
Wide Web, current search engines have yet to provide an exciting, intuitive and users-centered set of function-alities that will support and sustain this phenomenon. Despite the rapidly growing promises and research directions on multimedia information retrieval (started around 1990s), Web search engines currently provide limited multimedia-specific search functionalities (such as content-based, color, duration, etc.). The develop-ment of a new generation specialised multimedia Web search engines will drive new search trends. However, new search trends depend on users X  capability in Web searching. Thus we need to study how many users would prefer simple textual searches rather than complex, rule-based, and rich searches. Text-based search will remain dominant for the near future, especially because current Internet communities like to use forums and blog to add rich text-based semantic metadata and descriptions on multimedia content.

Query by Example (QBE) is currently not a popular solution for current search engines. Out of the 102 examined engines (shown in Fig. 1 ), none of the general Web search engines provide QBE. Only 5 specialized search engines have such capability: Findsounds (for audio), IBM Marvel (video), Lookthatup (image), Yoto-foto (image) and State Hermitage (image). It is because image and sound similarity matching is still a major challenge, yet to be fully solved reliably. Video which contains the combination of synchronized audio and sequence of images presents a more difficult challenge.

Recent studies suggest that most users only use one Web search engine during a search session ( Nielsen, 2004; Sherman, 2004 ). Meta-search combines results from several Web search engines, thus helping users to find more results without the need of searching on multiple Web search engines. However, it remains a chal-lenge whether general Web search engines should also unify results from collection-based database (since most of them are not free). Some Web search engines like Yotofoto is already combining results from various col-lection-based search engines. If Yotofoto can be combined with other general Web meta-search engines sup-porting multimedia search, users will be presented with a very wide range (i.e. more complete) multimedia collections on the Web.

Hierarchical ontology should be used to classify and visualize keywords, topics, and other metadata that users and applications generate. A well-defined annotation dictionary (such as MPEG-7) is desired as it allows the standardization of various multimedia contents descriptions. For search formulation, ontology-based clas-vera  X  X , users can be suggested to search on  X  X  green plants  X  X . Moreover, a unified indexing on keywords and semantic summaries will enable search engines to support users in finding related topics. 7. Conclusion and further research
For future work, the knowledge of user X  X  current needs and goals, or even better, what users X  will need or want in the future is invaluable information for many application domains, especially where the user is a potential consumer. Although not restricted to Internet, its growing popularity for e-commerce has contributed to an increase in an interest in user modeling. Query by example should be studied more thoroughly in terms of its usefulness and intuitiveness for users in searching multimedia data. The use of users generated annotations such as comments, discussions, and rating should be encouraged as this will enrich the metadata for searching.
A study on the quality of keywords, which are driven by folksonomies to assign/describe multimedia con-tent, should be conducted so that search engines X  algorithms can improve the effectiveness of keywords based multimedia searches. The catalog of multimedia search functionalities (e.g. size and file format) can be used to analyze large sets of web log data. This study will be useful to determine the popularity of each function, how often they are used by users, and to what extent of customization that users would go in order to improve their MM search.
 References
