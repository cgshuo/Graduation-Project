 data to stimuli or the behaviors of animals. HMMs are suitable for such situations. Poisson distribution can incorporate correlation at arbitrary time intervals. including HMMs [9].
 computationally demanding.
 anesthetized songbird. 2.1 HMM with multivariate Poisson distribution  X  trial is denoted by x n,t { state, Y = { y n,t } N,T process whose state transition matrix is a = { a the initial state probability is  X  = {  X  a at the t th window of the n th trial is k , then y n,t assumed to be generated according to p ( x n,t ( s , l  X   X   X  { 1 , 2 , 3 , 12 , 13 , 23 , 123 } which satisfies Each s Due to the reproducing properties of the Poisson distribution, each x Poisson distribution with parameter  X  vector of this distribution is (  X  (
T denotes the transposition) and its variance-covariance matrix is given by ( s 1 , s 2 , ..., s L ) T B of choosing j from C elements. Vector x = ( x tivariate Poisson distribution. In the above trivariate example, S = ( s and B = [ B
We can also consider only the second-order correlation model by setting B = [ B ( s S = ( s 1 , s 2 , s 3 , s 123 ) T . The probability mass function of x is given by (i.e., B = B special case of CP-HMM. The complete log-likelihood for CP-HMM is where  X  = (  X , a ,  X  ) and 1 2.2 Variational Bayes distribution: where D (  X  ) is defined as D ( { a the parameter of the Poisson mean,  X  = {  X  is where G (  X  ) denotes the Gamma distribution defined as G (  X  |  X ,  X  ) =  X   X  iments we discuss in the following, we set the hyperparameters as u (  X  )  X  0 = 0 . 1 ,  X  0 = 0 . 1 where  X  X  X  minimizing KL divergence is equivalent to minimizing variational free energy Q ( Z ) is called the VB-E step, and the VB-M step for r (  X  ) . VB-E step By using the Lagrange multiplier method, the VB-E step is derived as where C  X  y  X  a where  X  P ( s where distribution (See the Appendix). The calculation of the posterior for S is given as: VB-M step By again using the Lagrange multiplier method, the VB-M step is derived as of state k staying at window t denoted by  X  y t for hidden variables s t energy calculated for all models. where C where 10 different initializations to avoid a poor local minimum solution. order correlation whose Poisson mean depends on periods as: (a)  X  for t  X  [1 , 10] , (b)  X   X  123 = 1 . 0  X  i +  X  123 = 1 . 5 Table 1: Results of model selection for spike trains from HVC for all states. posterior mean for { s t the contribution of the independent factor and correlation factor on spike counts x t common factor s t Thus, we can select the optimal model based on F , at least in this example. elsewhere [16].
 trains may be better captured by using an independent Poisson model. data under the posterior mean  X   X   X  classical Poisson-HMMs. The full-CP-HMM include 2nd-order CP-HMM, but shows lower pre-avoiding over-fitting. models. correlation case, where B = [ B definition of the multivariate Poisson random vector, x such that x =  X  , denote a l th column of matrix B . Let us define vector  X   X  = (  X   X  x  X   X  By using the quantities obtained in this calculation,  X  s n,t [5] H. Nakahara, and S. Amari, Neural Computation 14:2269-2316, 2002. [6] E. Schneidman, M. J. Berry, R. Segev and W. Bialek, Nature 440:1007-1012, 2006. [8] M. Danoczy and R. Hahnloser, Advances in NIPS , 18, 2005. [9] K. Yamazaki and S. Watanabe, Neurocomputing 69:62-84, 2005. [12] S. Watanabe, Y. Minami, A. Nakamura, and N. Ueda, Advances in NIPS , 15, 2002. [13] K. Kano and K. Kawamura, Communications in Statistics , 20:165-178, 1991. [14] L. Meligkotsidou, Statistics and Computing , 17:93-107, 2007 [15] A.C. Yu and D. Margoliash, Science , 273:1871-1875, 1996. [16] J. Nishikawa and K. Okanoya, in preparation . [17] G. Uchida, M. Fukuda, and M. Tanifuji, Physical Review E , 73:031910, 2006
