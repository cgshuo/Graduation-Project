 1. Introduction
Near-duplicate video (NDV) detection in large multimedia collections is very important for digital rights management the video content is distributed in a continuous stream that cannot be easily segmented for comparison, making these ing. During video editing, some inappropriate shots could be deleted and commercial breaks could be inserted. However, they either ignore the temporal dimension or simplify the query model. NDV detection requires models for video sequence-to-sequence matching incorporating the temporal order inherent in video data. For sequence matching to be  X  based on proposing to view a sequence of video frames as a string and use direct comparison between the sequence of shot-based index structure viewed as a string and then apply string matching algorithms to solve the problem of shot alignment. The main programming paradigm used in the literature for computing sequence alignment, dynamic program-
Furthermore, dynamic programming measures, in terms of edit distance, how mismatching two videos are rather than how similar they are.

In this paper, we propose a near-duplicate video detection framework based on signature-based index structures featur-by frame rate conversions and editing, which abundantly exist in real-world applications. texture) concepts and evaluate the prototype on 286 videos from the TRECVID 02, 03 and 04 corpora against two dynamic programming frameworks.

The remainder of this paper is organized as follows: Section 2 introduces the related work on NDV detection. Section 3 the N -gram matching and scoring framework. Experimental results are reported in Section 7. 2. Related works Many existing approaches support near-duplicate key-frame (image) detection such as presented in Ke, Sukthankar, and Huston (2004), Lowe (2003), Wu, Hauptmann, and Ngo (2007), Zhang and Chang (2004) and Zhao, Ngo, Tan, and Wu (2007) . use a dynamic programming-based matching algorithm to compute detection scores. They demonstrate video degradation gramming is not on par with that of more computationally intensive approaches (e.g. those based on frame-by-frame comparison of visual features). We use an equivalent dynamic programming-based technique as a baseline for our experi-ments in Section 7.
For video scoring, dynamic programming-based methods are directly influenced by the shot duration features and the tion (centroids of edge points within frame blocks), and the second order central moments of Canny edges within frames each of them, and counting the number of blocks in each quantized motion direction. 3. System architecture
Fig. 1 demonstrates the system architecture where a re-broadcasted video can be used as a query into the system. The between query and index videos.

We detail the components of our video near-duplicate detection architecture as highlighted in Fig. 1 : 1. A broadcasted video is captured and stored in a video corpus. index base. 3. A query video broadcast is processed by the video segmentation unit for abrupt and gradual edits detection. 4. The query video edit patterns are then labeled and its shots numbered. 5. The feature extraction unit highlights a query structure consisting of temporal, color and texture signatures. 6. The matching module compares video query and index signatures. video. 8. The retrieval results are finally displayed through the system interface. 4. Temporal video segmentation widely used color feature representations.

We make use of algorithms and techniques on both compressed and uncompressed video data. For the uncompressed domain (i.e., in our experimental corpus, 380 TV-show episodes recorded from two German TV stations) we apply various compressed domain (i.e. the TRECVID data in MPEG-1 format), we consider the state-of-the-art method mentioned in Eic-frames which constitute the video shot. To resolve the possible frame-rate variations between a video and an NDV, we use shot durations instead of number of frames. The algorithm computes the duration between the successive key-frames, with many new inserted commercials is considered). 5. Index and query representations
The choice of the video representative features and their integration within index and query structures is crucial for developing a successful matching and scoring framework since its performance and robustness largely depend in turn on characterizations presented in Section 5.1, s color and s perceptual symbolic descriptors, i.e. the color and texture concepts, through processes mapping them to the extracted low-level features. 5.1. Duration-based features tween a video and an NDV, we use shot durations instead of number of frames. The algorithm computes the duration be-tween the successive key-frames of a shot, and stores them in the signature s video clip using only nine scalar values: [1170, 2610, 1020, 8320, 19640, 20220, 23230, 27310, 16480]. 5.2. Color-based features and observations, eleven color concepts: black (cc 1 ), blue (cc
Characterizing the aforementioned perceptual color concepts involves algorithmically transforming the extracted low-values in the perceptually uniform HVC space. This step is detailed in the experimental Section 8.1.1. tion of a video shot. The value s color [ i ]( i 2 [1, 11]) is the pixel percentage of color concept cc 5.3. Texture-based features
Although several works have proposed the identification of low-level features and the development of algorithms and techniques for texture computation, few attempts have been made to propose an ontology for texture symbolic character-the characterized texture is proposed.
 by the texture concept disordered (tc 3 ). C 4 gathers structured textures with a weave-like structure. Textures in C is represented by the texture concept lined (tc 5 ). The category C form a weave. It is represented by the texture concept netlike (tc is characterized by the texture concept smeared (tc 8 ) denoting negative aesthetics. Texture category C spotted (tc 9 ). The tenth texture category C 10 refers to uniform (tc in this category, which was the case for textures in category C tures. It is represented by the texture concept whirly (tc in Section 8.1.2.
 tribution of a video shot. The value s texture [ i ]( i 2 [1, 11]) is a boolean translating that texture concept tc smeared:1, spotted:0, uniform:0, whirly:0 i corresponds to a distribution with bumpy, cracked and smeared textures. 6. A matching and scoring framework based on logical inference
The matching framework is based on a logical inference model where the relevance of an index video I with respect to a query Q is given by the product of the exhaustivity measure E and the specificity measure S :
We detail the exhaustivity and specificity functions below. 6.1. Exhaustivity
Exhaustivity measures to which extent the video document satisfies the query through a logical implication and its value N is determined experimentally).
 the current offset and the corresponding number of matches. 3. Slide the index windows S steps forward, repeat step 2. 4. For each complete scan of the index video, retrieve the offset such that the number of matched shots is maximal ( max ( number_of_matched_shots )) and the corresponding position in the query video. 5. Slide the query windows S steps forward. imum number of matches and their offset. 7. Starting from this position, count the number of equal pairs and assign a score to the index video. uation of their similarity. It is given by the exhaustivity value between query signature Q and index signature I :
The Cpt_Match function is the Kullback X  X eibler divergence between the probabilities of: (i) texture concepts in the query texture signature s texture_ q (ii) color concepts in the query color signature s color_ q Fig. 2 illustrates the N -gram sliding window technique for query and index video matching and scoring.
Moreover, lattices organizing color and texture signatures are defined by mathematical partial orders and consequently signature lattices for effective query processing. 6.2. Specificity
The specificity function takes into account the importance of the query elements within the index document. We assume account the query degradation phenomenon by relating more closely texture signatures with the most common number compute path lengths in lattices between matching index and query signatures.

The specificity value measures the importance of the query themes within the index document by minimizing path lengths between texture and color signatures of a query signature Q and those of an index signature I : nization of lattices processing texture and color signatures. 7. Organization of lattices for fast matching 7.1. Processing texture signatures 7.1.1. Lattice description
This texture distribution is represented by the highlighted texture index signature ( t signaturesrepresentingsuchdistributionsaredescendantsof t 8 a , b index texture signatures, a 6 text b ( ) a  X ? text 7.1.2. Path Lengths
In this lattice, we furthermore derive the path length between the minimum element \ element is equal to 0.

We prove that this path length is equal to 11 n t by induction on the number n itself being 0.  X  We assume that the property is verified at rank i .  X  At rank i + 1, we consider an index texture signature t a number of null components equal to i . The path length between these two elements is equal to 1. The path length between t 2 and the minimum element \ text is by recurrence hypothesis equal to 11 (11 i ), i.e. i . Consequently, the path length between t 1 and \ text is equal to i +1=11 (11 ( i + 1)). The property is therefore verified at rank i +1. 7.2. Processing color signatures At Most and At Least lattices.
 ple:0, red:0, skin:0, white:0, yellow:0 i . 7.2.1.  X  X t Most X  lattice
The organization of the lattice takes into account dominant color concepts (i.e. concepts mentioned in a query as they to include one additional dimension corresponding to a component summing pixel percentages of secondary color con-cepts noted P at most . This novel structure, supported by a vector s where d at_most is the set of dominant color concepts. The s el percentages of dominant color concepts and the s at_most secondary color concepts ranked in ascending order. By construction, s as highlighted in Fig. 4 .

Formally, sub-lattices of signatures with dominant d at most account the set d at most of dominant color concepts: 8 a , b signatures with dominant d at most, , a 6 at most Sub-lattices of signatures with components corresponding to dominant color concepts being equal (framed structure in
Fig. 4 ) are partially ordered by 6 at most_eq : 8 a , b signatures with dominant d at most having components that correspond to dominant color concepts being equal, a 6 7.2.2.  X  X t Least X  lattice concepts.
 include one additional dimension corresponding to a component summing pixel percentages of secondary color concepts noted P at least . This novel structure, supported by a vector s t_least is the set of dominant color concepts. The s at_least ages of dominant color concepts and the s at_least [ j ] j 2 [1,12] concepts ranked in ascending order. By construction, P is the maximum value among the s equivalent color signature with dominant {black}: h 50 ,5,5,5,5,5,5,5,5,5,5,50 i as highlighted in Fig. 5 .
Formally, sub-lattices of signatures with dominant d at_least account the set d at_least of dominant color concepts: 8 a , b signatures with dominant d at_least, , a 6 at least b 6 a  X  j 6 100 .
 Sub-lattices of signatures with components corresponding to dominant color concepts being equal (framed structure in
Fig. 5 ) are partially ordered by 6 at_least_eq : 8 a , b signatures with dominant d at_least having components that correspond to dominant color concepts being 7.2.3. Path lengths framed structure in Fig. 4 ) which consists of elements corresponding to dominant color concepts being equal.
It is equal to the number of partitions Part( p , n c Card( d 11 Card( d at most ) secondary color concepts as a sum from one to 11 Card( d titions is associated a color signature with dominant d at most integer 2 as a sum from one to 10 positive integers equals 2. Indeed: the structure depth.

From this result, we can therefore establish the path length in the sub-lattice from the minimum element \ is assumed uniformly distributed. It is equal to: [ P i  X  1 ; ... ; P
With a similar reasoning in the At Least lattice, the path length in the sub-lattice from the minimum element \ cepts is assumed uniformly distributed. It is equal to: [ 8. Experiments the evaluation of the full framework for near-duplicate video detection. 8.1. Automatic characterization of the perceptual visual features 8.1.1. Highlighting color concepts process for characterizing this information in the HVC space.
 taken into account. Consequently, the color information is conveyed in the HVC perceptual space, which is moreover uniform.

Components H, V and C correspond respectively to the values of tonality, luminosity and saturation. They are then mapped to the eleven color concepts introduced in Section 5.2.
 a given color concept. 8.1.2. Characterization of texture concepts vector, with each dimension corresponding to a Gabor energy. tribution, we have a set of points { x 1 , ... , x i ... }inan n -dimensional input space S set of labels { y 1 , ... , y i ... } such that the y i value equals 1 if x used and support vector machines are then based on the resolution of the following optimization problem: min w . Support vector machines then determine a separating linear hyperplane in this space. K  X  x tion, sigmoid, etc.), we choose the radial basis function: K  X  x traditionally used in the case of non-linearity between the class labels and the input attributes. training data.
To determine the performance of the mapping, we first use sets of equal size. Sequentially, one subset is tested using the classifier trained on the remaining given in Table 1 . 8.2. Evaluation of the near-duplicate video architecture
In this section we explore the effectiveness of the proposed N -gram sliding window technique for video matching and scoring compared to two state-of-the-art dynamic programming approaches with two experiments. The first experiment ing framework on long query videos of different nature with multiple edited contents. The second experiment tests our architecture on short-length query videos, i.e. segments of videos in the index corpus. 8.2.1. Index, query collections and parameter settings
Times Bad Times (230 episodes) and Home Improvement (100 episodes), recorded from two German TV stations. The dura-collections are proposed for the first experiment: for the initial version of the video in the index corpus).
 seconds to several minutes and covering at most 20% of the video length.
 the index corpus. We furthermore propose in Table 2 the parameter settings used for the N -gram based detection framework. 8.2.2. Experimental results
In both experiments, we compare our system to a state of the art system based on edit distance computation and repre-edit distance implementation as described in Vidal et al. (1995), Arslan and Egecioglu (1999) . that are recognized by the system.
 systems. The mean average precision for all queries was computed for each compared system as: and Q3 respectively. The results obtained for the three compared systems are as follows: MAP mately 11.3% higher over the average precision of the edit distance based framework and approximately 7.2% higher over the average precision of the system based on normalized edit distance.

In the second experiment, we compare the effectiveness of the proposed framework compared to the dynamic program-around 0.8), the precision is itself high around 0.8.

We compute the MAP as in the previous experiment with the logical inference matching framework providing results that tively drop by 15.9% and 14.9% with MAP edit_dist = 0.634 and MAP er over the average precision of the system implementing the normalized edit distance. 9. Conclusion and future works two dynamic programming-based systems: one relies on edit distance computation and the second implements a normal-ized edit distance.

Our framework can be potentially used in many commercial applications: commercial and broadcast-stream monitoring, speech features within our framework.
 References
