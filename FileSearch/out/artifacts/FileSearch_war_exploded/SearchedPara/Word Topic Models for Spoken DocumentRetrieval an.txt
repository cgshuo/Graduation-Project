 BERLIN CHEN National Taiwan Normal University 1. INTRODUCTION Statistical language modeling (LM), which aims to capture t he regularities in human natural language and quantify the acceptability of a given word sequence, has continuously been a focus of active research i n the speech and language processing community over the past three decades. For example, the n -gram modeling (especially the bigram and trigram modeling ) approach, which determines the probability of a word given the precedi ng n -1 word history, is most prominently used [Jelinek and Mercer 1980; Rosenfeld 2000; Bellegarda 2004]. This statistical paradigm was first intro duced for the in-formation retrieval (IR) problems by Ponte and Croft [1998] , Song and Croft [1999], and Miller et al. [1999], indicating very good poten tial, and was then ex-tended in a number of publications [Berger and Lafferty 1999 ; Hoffmann 1999; Lafferty and Zhai 2001; Chen et al. 2004b]. In these approach es, the relevance measure between a query Q and a document D is expressed as P ( D | Q ) ; that is, the probability that D is relevant given that the query Q is posed. Based on the Bayes theorem and some assumptions, this relevance me asure can be approximated by P ( Q | D ) , or the probability of the query Q being posed, under the hypothesis that document D is relevant. Documents in the collection therefore can be ranked on the basis of this relevance measur e.
 different matching strategies, namely, literal term match ing and concept matching [Lee and Chen 2005]. The n -gram-based [Ponte and Croft 1998; Song and Croft 1999] and hidden Markov model (HMM)-based [Miller et al. 1999; Chen et al. 2004b] approaches are the most popular examples f or literal term matching. In these approaches, each document is interprete d as a generative model composed of a mixture of n -gram probability distributions for observing a query, while the query is considered as observations, expr essed as a sequence of indexing terms (or words). However, most of these approac hes often suffer from the problem of word usage diversity (or so-called vocab ulary mismatch), which will make the retrieval performance degrade severely as a given query and its relevant documents are using quite a different set of words. In con-trast, concept matching tries to discover the latent topica l information inher-ent in the query and documents, based on which the retrieval i s performed; the probabilistic latent semantic analysis (PLSA) [Hoffmann 1 999], referred to as the document topic model (DTM) in this article, is often cons idered as a rep-resentative of this category. PLSA introduces a set of laten t topic variables to characterize the  X  X ord-document X  co-occurrence relation ships: typically, docu-ments are mixtures of topics, where each topic has a probabil ity distribution over words of the language. Therefore, the relevance measur e of a query and a document is not computed directly based on the frequency of t he query words occurring in a document, but instead based on the frequency o f these words in the latent topics as well as the likelihood that the docume nt generates the respective topics, which in fact exhibits some sort of conce pt matching. PLSA is usually trained in an unsupervised way [Hoffmann 2001] by maximizing the total log-likelihood of the document collection. Excel lent survey articles of using statistical language modeling approaches for inform ation retrieval can be found in Croft and Lafferty [2003], Allan et al. [2003], Li u and Croft [2005], and Steyvers and Griffiths [2007].
 large volumes of real-world spoken documents, such as broad cast radio and television programs, digital libraries and so on, are now be ing accumulated and made available to the public. Substantial efforts and ve ry encouraging results on speech recognition of spoken documents have been reported in the last few years [Woodland 2002; Byrne et al. 2004]. However, f or complicated speech recognition tasks such as broadcast news transcript ion, it is still ex-tremely difficult to build well-estimated language models, because the subject matters and lexical characteristics for the linguistic con tents of news articles are very diverse and are often changing with time. Various at tempts have been made to adapt the language model by making use of either the co ntemporane-ous corpus or the recognition hypotheses observed so far [Je linek et al. 1991; Federico and Bertoldi 2001]. Two of the most widespread appr oaches to lan-guage model adaptation are count merging and model interpol ation, each of which can be respectively viewed as a maximum a posteriori (M AP) language model adaptation with a different parameterization of the p rior distribution, and can be easily integrated into the n -gram modeling framework to capture the local regularities of word usage in the new task domain [B acchiani and Roark 2003]. In the recent past, the probabilistic latent to pic modeling ap-proaches, which were originally formulated in IR, have been introduced to dy-namic language model adaptation and investigated to comple ment the n -gram models as well. Among them, PLSA [Gildea and Hoffmann 1999] h as been widely studied and demonstrated effective in a few speech re cognition tasks. However, it merely targets on maximizing the collection lik elihood but not di-rectly on its language model prediction capability, and it a lso suffers from the problem that part of its model parameters have to be dynamica lly estimated on the fly during the speech recognition process, which would be time-consuming and makes it impractical for realistic speech recognition a pplications. Inter-ested readers may refer to Bellegarda [2004] for a comprehen sive overview of the major language model adaptation approaches that have be en successfully developed and applied to speech recognition.
 proposed to explore the co-occurrence relationship betwee n words, as well as the underlying global topic information, for language mode ling in spoken doc-ument retrieval and transcription. Each word of the languag e is treated as a WTM model for predicting the occurrences of the other words, while the corre-sponding model parameters can be estimated by leveraging th e vicinity infor-mation of all occurrences of the word in the document collect ion. The document or the search history as a whole thus is represented as a compo site WTM model for generating the newly observed word. The underlying char acteristics and different kinds of model structures are investigated, whil e the performance of WTM is analyzed and compared with PLSA and the other models.
 the structural characteristics of the word topic model and i ts applications to information retrieval and dynamic language model adaptati on, as well as its comparison to the probabilistic latent semantic analysis. Section 3 describes the speech and language corpora used in this article, as well as the experimen-tal setup. The experiments on spoken document retrieval and transcription are presented in Sections 4 and 5, respectively. Finally, Se ction 6 concludes this article with future work. 2. DOCUMENT AND WORD TOPIC MODELS In this section, the probabilistic latent semantic analysi s (PLSA), namely the document topic model (DTM), is reviewed, followed by an intr oduction of our proposed word topic model (WTM). We will concentrate on eluc idating and comparing the structural characteristics of PLSA and WTM, a s well as their applications to information retrieval and language model a daptation. 2.1 PLSA for Information Retrieval In information retrieval (IR), the relevance measure betwe en a query Q and a document D can be expressed as P ( D | Q ) , that is, the probability that the document D is relevant given that the query Q was posed, which can be trans-formed to the following equation by applying the Bayes theor em: where P ( Q | D ) is the probability of the query Q being generated by the doc-ument D , P ( D ) is the prior probability of document D being relevant, and P ( Q ) is the prior probability of query Q being posed. P ( Q ) in Equation (1) can be eliminated because it is identical for all documents a nd will not affect the ranking of the documents. Furthermore, because the way t o estimate the probability P ( D ) is still under active study [Miller et al. 1999; Liu and Croft 2005], we may simply assume that P ( D ) is uniformly distributed, or identical for all documents. In this way, the documents can be ranked by means of the probability P ( Q | D ) instead of using the probability P ( D | Q ) . If the query Q is treated as a sequence of input observations (words or term s), Q = w 1 w 2 ...w N , where the query words are assumed to be conditionally indepe ndent given the document D and their order is also assumed to be of no importance (i.e., t he so-called  X  X ag-of-words X  assumption), the relevance meas ure P ( Q | D ) can be decomposed as a product of the probabilities of the query wor ds generated by the document: where c ( w i , Q ) is the number of times that each distinct word w i occurs in Q . be interpreted as a generative document topic model (DTM), d enoted as M D , in which a set of K latent topics characterized with unigram (or multinomial) distributions are used to predict the query terms, and each o f the latent topics is associated with a document-specific weight. That is, each document D can belong to many topics and the probability of a query word w i generated by D is expressed by where P ( w i | T k ) denotes the probability of a query word w i occurring in a spe-cific latent topic T k , and P ( T k | M D ) is the posterior probability (or weight) of the topic T k conditioned on the document model M D , with the constraint P k =1 P ( T k | M D ) = 1 imposed. More precisely, the topical unigram distribu-tions, e.g., P ( w i | T k ) , are shared among the entire DTM models, while each model M D has its own probability distribution over the latent topics , for exam-ple, P ( T k | M D ) . The key idea we wish to illustrate here is that the relevance measure of a query word w i and a document D is not computed directly based on the frequency of w i occurring in D , but instead based on the frequency of w i in the latent topic T k as well as the likelihood that D generates the respective topic T k , which in fact exhibits some sort of concept matching [Lee an d Chen 2005]. The likelihood of a query Q generated by D is thus represented by In the practical implementation of PLSA [Hoffmann 2001], th e correspond-ing DTM models are usually trained in an unsupervised way by m aximizing the total log-likelihood of the document collection D in terms of the unigram P
PLSA ( w i | M D ) of all words w i observed in the document collection, or more specifically, the total log-likelihood of all documents gen erated by their own DTM models: The optimization of Equation (5) can be conducted iterative ly via the following three expectation-maximization (EM) update equations [De mpster et al. 1977; Rabiner 1989]: query word w i and the document model M D , which is computed using the prob-iteration.
 supervised training of PLSA (or the corresponding DTM model s) in this article. Given a training set of query exemplars Q TrainSet and their associated query-document relevance information, the DTM models can be optim ized by in-stead finding the model parameters that can maximize the tota l log-likelihood of the training set of query exemplars Q TrainSet generated by their relevant documents: where D R to Q denotes the set of documents that are relevant to a specific training query exemplar Q . This leads to the following two EM update equations: where Q  X  Q TrainSet st. D  X  D R to Q means that the query exemplar Q in the training query set can satisfy the condition that the d ocument D in the collection is relevant to it; and P ( T k | w s , M D ) can be computed using Equation (8). 2.2 WTM for Information Retrieval In this article, we present an alternative probabilistic la tent topic approach for information retrieval. Instead of treating each document i n the collection as a document topic model, we regard each word w j of the language as a word topic model (WTM) M w where P ( w i | T k ) and P T k | M w occurring in a specific latent topic T k and the probability of the topic T k conditioned on M w the associated WTM models of the words involved in a document D to form a composite WTM model for D , and the likelihood of a query Q being generated by D can be expressed by where the weighting coefficient  X  j , D is set to be in proportion to the frequency of w j occurring in D and summed to 1 ( P w evance measure between a query and document is determined by the product of a weighted sum of the probabilities that the respective WT M models of the words involved in the document generating each query word, a nd the docu-ments having the highest probabilities expressed by Equati on (13) are there-fore believed to be more relevant to Q .
 supervision or without supervision. For unsupervised trai ning of WTM, each WTM model M w a vicinity of, or a context window of size S ( S is experimentally set to 21 in this study) around, each occurrence of w j , which are postulated to be relevant to w j , in the spoken documents collection to form a relevant observ ation sequence Q w j for training M w j . The words in Q w j are also assumed to be condition-ally independent given M w vocabulary set w can be estimated by maximizing the total log-likelihood of their corresponding relevant observation sequences respe ctively generated by themselves: The parameters of the WTM models hence can be optimized itera tively using the following three EM update equations: where P T k w i , M w the word w i and the word model M w bility quantities P ( w i | T k ) and P T k M w iteration.
 similar way as that of PLSA described previously. That is, gi ven a training set of query exemplars with the corresponding query-docume nt relevance in-formation that is available, the model parameters of WTM can be estimated by maximizing the total log-likelihood of the training set o f query exemplars Q
TrainSet generated by their relevant documents: The EM update equations for supervised training of WTM are om itted here for brevity.
 plars and the respective query-document relevance informa tion (or the click-through information that to some extent reflects users X  rela tive preferences of document relevance) also has been extensively studied fo r training various machine-learning-based retrieval models like SVM (Suppor t Vector Machines) [Joachims and Radlinski 2007]. Such a training approach in e ssence has the ability to associate documents with a query exemplar even th ough they do not share any of the query words. 2.3 PLSA for Language Model Adaptation The task of language modeling in speech recognition can be in terpreted as cal-culating the probability P w i H w one of its possible search histories. When PLSA is applied to language model adaptation in speech recognition, for a decoded word w i , we can conceptually regard it as a (single-word) query and each of its correspond ing search histo-ries H w dicting the occurrence probability of w i [Gildea and Hoffmann 1999; Mrva and Woodland 2004]: However, the search histories are not known in advance and th eir number could be enormous and varying during speech recognition. Th us, the corre-sponding DTM model of a search history has to be estimated on t he fly. One possible solution is that we can collect a set of contemporan eous (or in-domain) supervised manner beforehand, by treating each individual document in the collection as a relevant observation sequence to train its o wn DTM model, as earlier illustrated in Equations (6) to (8). Then, during th e speech recognition process, we can keep the topic-specific unigram P ( w i | T k ) unchanged, but let the search history X  X  probability distribution over the lat ent topics P ( T k | M H be gradually updated as path extension is performed, by trea ting the history itself as a relevant observation sequence of words and using the following two EM update formulas [Gildea and Hoffmann 1999]: and where c w j , H w 2.4 WTM for Language Model Adaptation The WTM model previously introduced in Section 2.2 for infor mation retrieval also can be applied for language model adaptation [Chiu and C hen 2007]. Each WTM model M w within a vicinity of, or a context window of size S around each occurrence of w j , which are postulated to be relevant to w j , in the contemporaneous (or in-domain) collection to form a relevant observation se quence of words O w for training M w During the speech recognition process, for a decoded word w i , we can again interpret it as a single-word observation; while for each of its search histories H ciated WTM models of the words occurring in H w model for predicting w i : where the values of the nonnegative weighting coefficients  X  j are empirically set to be exponentially decayed as the word w j is being apart from w i and summed to 1 ( P i  X  1 j =1  X  j = 1), which have the form: where  X  j is set to a fixed value (between 0 and 1) for j = 2 , , i  X  1, and set to 1 for j = 1; and  X  j will be equal to  X  j when j = i  X  1. The search history X  X  prob-ability distribution over the latent topics P  X  T k M H have the advantage of taking account of the whole search hist ory of a word irrespective of the length of the search history, and to some extent can dynam-ically capture the underlying global topical information o f the search history. On the other hand, the background n -gram language probability can provide the general constraint information of lexical regularitie s. Thus, there is good reason to combine the PLSA or WTM language model with the back ground n -gram (e.g., trigram) language model to form an adaptive lan guage model for guiding the speech recognition process:  X   X  model probabilities of the PLSA and WTM models, P BG ( w i | w i  X  2 w i  X  1 ) is the background trigram language model probability, and  X  1 and  X  2 are tunable weighting parameters. 2.5 Theoretical Analysis of WTM and PLSA WTM and PLSA can be analyzed from several perspectives. Firs t, PLSA mod-els the co-occurrence relationship between words and docum ents (or search histories), while WTM directly models the co-occurrence re lationship between words in the collection. We may be able to view PLSA in a differ ent way by regarding it as nonnegative (or probabilistic) matrix fact orization. Given a vo-cabulary set of V distinct words and a collection of N documents, PLSA starts with a V  X  N  X  X erm-document X  matrix A where each column n (1  X  n  X  N ) represents a document D n in the document collection, and each entity of it, denoted by a i , n (1  X  i  X  V ), is conceptualized as the probability that a word w i would occur in D n , that is, P PLSA w i M D n . Then, matrix factorization of A will result in an approximation of A by a product of two nonnegative matrices: where G is a V  X  K matrix ( K  X  min ( V , N ) ), each entity g i , k (1  X  k  X  K ) of which accounts for the probability of a word w i that would be generated by a which accounts for the probability that a document D n will generate a latent topic T k , that is, P T k M D each entity a i , n of A can be efficiently approximated through the inner product of two vectors with probabilistic entities represented by t he i -th row of G and the n -th row of H , respectively. Such matrix factorization in fact is analog ous to the singular value decomposition (SVD) procedure performe d by the algebraic (or nonprobabilistic) counterpart of PLSA, namely, the lat ent semantic analy-sis (LSA) [Furnas et al. 1988]. Along a similar vein, we can al so treat WTM as nonnegative (or probabilistic) matrix factorization, s tarting with a V  X  V  X  X erm-term X  matrix B where each column j encodes the vicinity information of all occurrences of a word w j (1  X  j  X  V ) in the document collection. More that another word w i would also appear in the vicinity of each occurrence of w j in the collection, that is, P WTM w i M w lead to an approximation of B by a product of two nonnegative matrices: where Q is a V  X  K ( K  X  V ) matrix and each entity q i , k of Q accounts for Q  X  is an V  X  K matrix, each entity q  X  j , k of which accounts for the probability that a latent topic T k would be chosen given the vicinity information of w j in the collection is known, that is, P T k M w can be efficiently approximated through the inner product of two vectors with probabilistic entities represented by the i -th row of Q and the j -th row of Q  X  , respectively. Figure 1 shows a schematic comparison for the matrix factoriza-tions of PLSA and WTM.
 PLSA for a new document D have to be estimated online using EM training, no matter whether the training is conducted in a supervised o r unsupervised manner; on the contrary, the topic mixture weights P ( T k | M D ) of WTM can be efficiently estimated on the basis of the topic mixture wei ghts P T k M w of words w j involved in the document without using the time-consuming E M training procedure. For language model adaptation, PLSA ag ain needs to per-form EM training to estimate topic mixture weights P T k M H history H w WTM [cf. Equation (22)] can be obtained on the basis of the top ic mixture weights P T k M w stead trained in an offline manner. That is, unlike PLSA where the topic mixture weights trained with the contemporaneous (or in-do main) collection are entirely discarded during the speech recognition proce ss, the topic mixture weights of WTM models are instead retained and exploited for language model adaptation. For our speech recognition test data, it was exp erimentally shown that the language model access time of WTM was roughly 1/30 of that of PLSA for language model adaptation, as the iteration number of th e online EM esti-mation of P T k M H seems to indicate that WTM is more feasible than PLSA for prac tical speech recognition tasks.
 rameters; as shown previously, V denotes the size of the vocabulary set, N denotes the number of the documents, and K denotes the number of the latent topics used for training the IR or language models. It is obvi ous that the para-meter number of WTM will be larger than that of PLSA, when the n umber of training documents in the collection is less than the number of distinct words in the vocabulary ( N &lt; V ). The parameter number of PLSA grows linearly with the number of documents used for training PLSA; the para meter num-ber of WTM instead remains the same regardless of the number o f training documents, as the IR or speech recognition systems adopt a cl osed set of vocab-ulary. Recently, a latent Dirichlet allocation (LDA) metho d [Blei et al. 2003; Steyvers and Griffiths 2007] has been developed to address th e above issue for PLSA. However, such a method still requires an iterative var iational inference [Jordan 1999] procedure for online estimating the associat ed parameters of a newly observed document or search history.
 window for capturing the vicinity information of WTM is redu ced to one word ( S = 1), WTM can be either degenerated to a unigram model as the la tent topic number K is set to 1, or viewed as analogous to a bigram model as K = V , or an aggregate Markov model as 1 &lt; K &lt; V [Saul and Pereira 1997]. Thus, with the appropriate values of S and K being chosen, WTM seems to be a good way to approximate the bigram or skip-bigram models for sparse data. On the other hand, WTM can be regarded as close in spirit to the class-based model (CBM) as well, by relating the latent topics of the form er to the word classes of the latter [Brown et al. 1992]. WTM differs from CB M in that WTM disregards word order information and contains word co-occ urrence data from longer spans of the context window, whereas most of the appro aches to using CBM are based purely on modeling word bigram sequences. This might mean that latent topics of WTM are semantic clusters whereas the c lasses of CBM are based on distributional clusters. 3. EXPERIMENTAL SETUP 3.1 Spoken Document Retrieval We used two Topic Detection and Tracking (TDT) collections [ LDC 2000] for the spoken document retrieval (SDR) task. TDT is a DARPA-sponsored program, where participating sites tackle tasks such as ide ntifying the first time a news story is reported on a given topic, or grouping new s stories with similar topics from the audio and textual streams of newswir e data. Both the English and Mandarin Chinese corpora have been studied in th e recent past. The TDT corpora have also been used for cross-language spoke n document retrieval (CL-SDR) in the Mandarin English Information (ME I) Project [Meng et al. 2004]. In this article we use the Mandarin Chinese coll ection of the TDT corpora for the retrospective retrieval task, such that the statistics for the entire document collection is obtainable. The Chinese news stories (text) from Xinhua News Agency are used as our test queries (or train ing query exemplars). The Mandarin news stories (audio) from Voice of America news broadcasts are used as the spoken documents. All news storie s are exhaus-tively tagged with event-based topic labels, which serve as the relevance judg-ments for performance evaluation. Table I describes the det ails for the corpora used in this article. The TDT-2 collection is taken as the dev elopment set, which forms the basis for tuning the parameters in various re trieval models, including the dimensionality of the latent vector space in L SA, the weight-ing parameter between unigram and bigram probabilities in t he HMM-based retrieval model, and the number of topical mixtures in the PL SA and WTM retrieval models. The TDT-3 collection is taken as the evalu ation set; that is, all the experiments performed on it were conducted followin g the parameter setting that was optimized based on the TDT-2 development se t. Therefore, the experimental results can validate the effectiveness of the proposed approaches on comparable real-world data.
 1999] provided Chinese word transcripts for our Mandarin au dio collections (TDT-2 and TDT-3). To assess the performance level of the rec ognizer, we spot-checked a fraction of the TDT-2 development set (about 39.90 hours) by comparing the Dragon recognition hypotheses with manual tr anscripts, and obtained a word error rate (WER) of 35.38%. Spot-checking ap proximately 76 hours of the TDT-3 test set gave a WER of 36.97%. Notice that Dragon X  X  recognition output contains word boundaries (tokenizatio ns) resulting from its own language models and vocabulary definition, while the man ual transcripts are running texts without word boundaries. Since Dragon X  X  l exicon is not available, we augmented the LDC Mandarin Chinese Lexicon wi th 24k words extracted from Dragon X  X  word recognition output, and for co mputing error rates used the augmented LDC lexicon (about 51,000 words) to tokenize the manual transcripts. We also used this augmented LDC lexicon to tokenize the text training and test queries in the retrieval experiments .
 uments to be retrieved (denoted TD, text documents, in the ta bles below) are known, are also shown for reference, compared to the resu lts when only the erroneous transcripts by speech recognition are availa ble (denoted SD, spoken documents, below). The retrieval results are expres sed in terms of non-interpolated mean average precision ( m AP) following the TREC evalua-tion [Harman 1995; Baeza-Yates and Ribeiro-Neto 1999], whi ch is computed by the following equation: where L is the number of test queries, N i is the total number of documents that are relevant to query Q i , and r i , j is the position (rank) of the j  X  th document that is relevant to query Q i , counting down from the top of the ranked list. vance between a query Q and a document D for IR, we additionally incorporate the unigram probabilities of a query term occurring in the do cument P ( w i | D ) and a general text corpus P ( w i | Corpus ) into PLSA and WTM, respectively, for probability smoothing and better performance. For example , the probability of a word w i generated by the WTM model of a word w j involved in D  X  P Similar treatments also have been studied for the PLSA-[Hof fmann 1999] and the LDA-based [Wei and Croft 2006] retrieval models. The abo ve two kinds of mated using the maximum likelihood (ML) criterion, while th eir corresponding weights, that is,  X  1 and  X  2 , can be further optimized using the EM algorithm [Chen et al. 2004b]. 3.2 Spoken Document Transcription The speech data set consists of about 112 hours of FM radio bro adcast news [Chen et al. 2002], which were collected from several radio s tations located at Taipei during November 1998 to April 2004. All the speech mat erials were manually segmented into separate stories, and each of them i s a news abstract pronounced by one anchor speaker. Some of these stories cont ain background noise and music. Only 7.7 hours of speech data have correspon ding ortho-graphic transcripts, of which approximately 4.0 hours coll ected during 1998 to 1999 are used to bootstrap the acoustic training and the ot her 3.7 hours (506 stories) collected in September 2002 are used for testi ng. The remaining 104.3 hours of untranscribed speech data (about 18,600 stor ies) are reserved for unsupervised acoustic model training and unsupervised language model adaptation [Chen et al. 2004a].
 nant analysis-based [Duda and Hart 1973] feature extractio n approach. The states of each HMM were taken as the unit for class assignment . The out-puts of 18 Mel-frequency filter banks are chosen as the basic v ector. The basic vectors from every nine successive frames were spliced toge ther to form the spliced vectors for the construction of a transformation ma trix, which was then used to project the spliced vectors to a lower feature space f or better discrim-ination. The dimension of the resultant vectors was set to 39 [Lee and Chen 2008]. The recognition lexicon consists of about 72,000 wor ds. The language models used in this article consist of unigram, bigram, and t rigram models, which were estimated using a text corpus consisting of 170 mi llion Chinese characters collected from Central News Agency (CNA) (the Ch inese Gigaword Corpus released by LDC). The n -gram language models were trained with the SRI language modeling toolkit (SRILM) [Stolcke 2000]. The s peech recog-nizer was implemented with a left-to-right frame-synchron ous Viterbi tree search as well as a lexical prefix tree organization of the lex icon. The recogni-tion hypotheses were organized into a word graph for further language model rescoring.
 ated in terms of character error rate (CER), defined as the sum of the insertion ( Ins ), deletion ( Del ), and substitution ( Sub ) errors between the recognized and reference Chinese character strings, divided by the total n umber of Chinese characters in the reference string ( Ref ): 4. EXPERIMENTS ON SPOKEN DOCUMENT RETRIEVAL 4.1 Retrieval Results of WTM We first evaluate the retrieval performance of the word topic models trained with supervision (denoted as WTM-S) and varying model compl exities on the TDT-2 development set. The model parameters were trained us ing the 819 training query exemplars with their corresponding query-d ocument relevance information to the TDT-2 development set [Chen et al. 2004b] . It should be borne in mind that from now on, unless otherwise stated, the r etrieval results reported in m AP were obtained by evaluating the ranked list of documents returned by the retrieval models in response to each of the te st queries (but not the training query exemplars). The retrieval results of WTM-S are shown in the upper part of Table II, where each column illustrates t he retrieval results in both the TD and SD cases by using different numbers of latent topics for modeling WTM-S. As can be seen, the retrieval perf ormance is steadily improved as the topic number increases. The best re trieval result of 0.7852 is obtained for the TD case when the topic number is set to 256, while the best result is 0.7858 for the SD case with the same topic mi xture num-ber. Notice that although the word error rate (WER) for the sp oken document collection is higher than 35%, the average degradation in re trieval perfor-mance is much smaller, especially when the topic mixture num ber becomes larger. Such an observation indicates that the WER does not c ause much adverse effect on retrieval performance, which is quite in p arallel with those reported by other groups [Renals et al. 2000; Srinivasan and Petkovic 2000]. For example, most of the retrieval systems participating in the TREC-SDR evaluations had declared that the retrieval performance ob tained by using the automatic transcripts of the spoken documents was flat wi th respect to the WER variations in the range of 15% to 30%, and they had also reported that no severe degradation was observed when evaluating the retrieval perfor-mance using the automatic transcripts of spoken documents c ompared to that using the manual transcripts [Garofolo et al. 2000; Chelba e t al. 2008]. One possible reason is that a query word (or phrase) might occur r epeatedly (more than once) within a broadcast news story and it is not always t he case that all the occurrences of the word would be misrecognized totally a s other words. For example, a word spoken by the studio anchor might have higher recognition accuracy than the same word spoken by the field reporter or the interviewee, which is mainly because for the anchor speech, the correspon ding bandwidth variability, recording environment and speaking style, as well as the amount of acoustic training data, can be well controlled. Therefor e, the true meaning of the word occurring within the spoken document could be sti ll preserved for the following retrieval process.
 systems can have query exemplars correctly labeled with the query-document relevance information to be used for model training. Thus, i n this article, we study unsupervised model training for WTM (denoted as WTM -U). The retrieval results for the experiments carried out on the TDT -2 collection are shown in the upper part of Table III. As it can be seen, the resu lts are not always improved as the topic number increases. The best resu lt of 0.6395 for the TD case is obtained when the document topic number is s et to 128, while the best result of 0.5767 for the SD case when document t opic number is 64. When comparing with the best results achieved in super vised training, there are at most about 0.15 (0.7852 vs. 0.6395) and 0.21 (0.7 858 vs. 0.5767) decreases in precision, respectively, for the TD and SD case s.
 exemplars with the corresponding query-document relevanc e information, the retrieval results obtained based on the supervised trai ning approach (WTM-S) are much better than those based on the unsupervised approach (WTM-U). Our hope is that, given a set of real user queries and the associated click-through information about the retrieved relevant do cuments, the perfor-mance of retrieval systems might be incrementally improved through use. 4.2 Comparison of WTM and PLSA In an attempt to assess the performance level of WTM as well as the asso-ciated approaches for model training and relevance measure , we study here the use of PLSA [Hoffmann 2001] for Chinese spoken document r etrieval. The conventional PLSA retrieval model is trained in a purely uns upervised man-ner. The retrieval results of such a modeling approach (deno ted as PLSA-U) on the TDT-2 collection are shown in the lower part of Table II I, where each column illustrates the retrieval results in both the TD and SD cases by using a different number of latent topics for PLSA modeling. The best retrieval result of 0.6332 is obtained for the TD case when the latent to pic number is set to 4, while the best result is 0.5831 for the SD case with 256 to pic mixtures. They are comparable to those achieved by WTM trained without supervision (WTM-U, cf. Table III), but considerably worse than those ac hieved by WTM trained with supervision (WTM-S, cf. Table II).
 PLSA-S), as described in Section 2.1. The same set of 819 quer y exemplars and their corresponding query-document relevance informa tion to the TDT-2 development set are employed here again to iteratively esti mate parameters of PLSA by using Equations (10) and (11). The retrieval resul ts of such an ap-proach on the TDT-2 collection are shown in the lower part of T able II, in which the best result of 0.7794 is obtained for the TD case when the d ocument topic number is set to 256 and the best result of 0.6652 is obtained f or the SD case with 128 topics. Such results are better than those obtained by using either WTM or PLSA trained in an unsupervised manner (WTM-U or PLSA-U), but are considerably worse than those obtained by using the WTM t rained in a su-pervised manner (WTM-S). We can thus conclude that for the Ch inese spoken document retrieval task studied here, WTM is truly a good alt ernative to PLSA when the retrieval models are trained either with or without supervision. 4.3 Comparison of WTM and Other Retrieval Models Moreover, we also compare WTM with three other popular retri eval models: the vector space model (VSM) [Salton and McGill 1983], the la tent seman-tic analysis (LSA) [Furnas et al. 1988], and HMM [Miller et al . 1999; Chen et al. 2004b]. The retrieval results of these three models on the TDT-2 collec-tion are listed in Table IV for comparison. VSM and LSA are imp lemented with the best parameter settings; while for HMM, both the uni gram and bi-gram modeling strategies are used, and the corresponding mo dels are trained with the same set of 819 query exemplars in a supervised manne r [Chen et al. 2004b]. As compared with the results in Tables II and III, it c an be observed that WTM significantly outperforms all these three retrieva l models when su-pervised learning is adopted (WTM-S). Even though WTM is tra ined in an unsupervised manner (WTM-U), its retrieval performance is still apparently better than that of VSM and LSA, and achieves quite competiti ve results to that of the HMM trained in a supervised manner. It is intere sting that the retrieval performance of HMM degrades as the model struc ture becomes more sophisticated (e.g., from unigram to bigram modeling) , whereas the re-trieval performance of WTM and PLSA tends to become better as the topic number increased, when both models were trained in a supervi sed manner. Since the number of distinct words (51,000) is large, the est imation of bigram probabilities for the HMM inherently suffers from the spars e data problem [Chen et al. 2004b]. 4.4 Further Evaluation on the TDT-3 Collection Finally, in order to validate the effectiveness of the propo sed WTM re-trieval model on comparable real-world data, we further con ducted a series of corresponding information retrieval experiments on the TD T-3 evaluation set. The retrieval results achieved by using WTM and PLSA are show n in Table V, while the results achieved by using the other retrieval mode ls, such as HMM, VSM, and LSA, are shown in Table VI. For WTM, PLSA, and HMM, the train-ing settings and model complexities for different experime ntal conditions (TD and SD cases) are set with the same configurations as those opt imized using the TDT-2 collection; while for VSM and LSA, the model parame ters are also set at the same optimum values tuned based on the TDT-2 collec tion as well. The retrieval results are shown in the second column of Table V, in which the document models were respectively trained by another tr aining query set consisting of 731 query exemplars together with the corr esponding query-document relevance information to the TDT-3 evaluation set . A retrieval re-sult of 0.8009 for the TD case is obtained with the document to pic number set to 256, while a result of 0.7858 for the SD case with the same to pic number. Comparatively speaking, these results are comparable to th e results achieved by the PLSA (as respectively shown in the third (PLSA-S) and r ightmost (PLSA-U) columns of Table V), and substantially better than those obtained by the other retrieval models (as shown in Table VI).
 supervision (WTM-U). It is worth mentioning that both the pr obabilities P ( w i | T k ) and P T k | M w tion were directly adopted from that of the TDT-2 collection , as opposed to PLSA where P ( w i | T k ) and P ( T k | M D ) had to be re-estimated using the EM algorithm for either supervised or unsupervised training. According to the results shown in the fourth column (WTM-U) of Table V, WTM tra ined in an unsupervised manner is considerably worse than PLSA tr ained with supervision (PLSA-S); however, it still is comparable to PL SA trained with-out supervision (PLSA-U) and achieves better retrieval per formance than the other models in most retrieval conditions, though the di fferences are not significant.
 sections, it has been clearly demonstrated that the WTM trai ned in a super-vised manner does achieve better performance than the other conventional retrieval models for the Chinese spoken document retrieval task studied here. All the IR experiments throughout this article have been car efully designed to avoid  X  X esting on training X ; that is, all the training (or pa rameter) settings and model complexities are tuned or optimized by using the TDT-2 development set and tested on both the TDT-2 development set and the TDT-3 eva luation set. Generally speaking, the training settings and model comple xities tuned from the TDT-2 development set perform rather well in the TDT-3 ev aluation set. 5. EXPERIMENTS ON SPOKEN DOCUMENT TRANSCRIPTION As mentioned earlier in Section 3.2, a set of 506 broadcast ne ws stories collected in September 2002 is used for testing. On the other hand, a set of about 39,000 text news stories collected from CNA during Aug ust to October 2002 is taken as the contemporaneous adaptation data, while another set of about 18,600 automatic transcripts (3.2 million Chinese ch aracters) as the in-domain adaptation corpus. These two sets of corpora are p ostulated to be either temporally or stylistically consistent with the bro adcast news speech to be tested, and therefore can be used to explore the global t opical and local contextual information which might be helpful for speech re cognition. 5.1 Comparison of WTM and PLSA The baseline system results in a character error rate (CER) o f 15.22% and a perplexity (PP) of 752.49 on the test set. We first compare th e perfor-mance levels of WTM and PLSA for language model adaptation by varying the model complexities (the number of latent topics ranged from 16 to 256) and using either the contemporaneous newswire texts (denoted a s Texts) or the in-domain automatic transcripts (denoted as Automatic Tra nscripts). The con- X  2 in Equations (25) and (26) were respectively set at optimum v alues (  X  j =0.6, ferent form the test set. As can be seen from Table VII, for the se two variants of latent topic approaches, both CER and PP are steadily redu ced as the topic mixture number increases, when the contemporaneous texts w ere used for lan-guage model adaptation. For PLSA, the best result of CER of 14 .47% (4.93% relative reduction) and PP of 510.20 (32.20% relative reduc tion) is obtained when the topic number is set to 256, while for WTM, the best res ult of CER of 14.38% (5.52% relative reduction) and PP of 508.29 (32.45% r elative reduction) is obtained with the same topic number. Though the performan ce seems not to be saturated yet, these results clearly demonstrate the eff ectiveness of these two latent topic approaches for dynamic language model adap tation. WTM performs comparably to PLSA in most cases when the contempor aneous texts were used for language model adaptation; however, it has the advantage of not needing to use the EM update formulas [as illustrated in Equa tions (19), (20), and (21)] to iteratively update the weights of search histor ies over the latent topics during the speech recognition process. Therefore, W TM is believed to be more efficient than PLSA for the speech recognition task st udied here (cf. Section 2.5).
 used for language model adaptation, for PLSA, the best resul t of CER of 14.82% (2.62% relative reduction) is achieved when the topi c number is 64, and the best result of PP of 562.45 (25.28% relative reduction) i s achieved when the topic number is 256; while for WTM, the best result of CER of 14 .81% (2.69% relative reduction) and PP of 563.25 (25.15% relative reduc tion) is achieved when 128 topics are used. However, when comparing the result s obtained with different model complexities, it can be found that WTM is qui te comparable with PLSA such that the differences between WTM and PLSA are a lmost neg-ligible as the in-domain automatic transcripts were exploi ted. By and large, language model adaptation using the in-domain automatic tr anscripts is quite competitive with that using the contemporaneous newswire t exts in PP reduc-tion, but only reaches about half of the CER reduction as that provided by using the contemporaneous newswire texts.
 1990] also have been conducted on the speech recognition res ults of both the WTM and PLSA adaptation approaches, and they all indicat ed the sta-tistical significance of CER improvements (with P -value &lt; 0.001) over the baseline trigram system when either the contemporaneous ne wswire texts or the in-domain automatic transcripts were adopted as the ada ptation corpus. However, the influence of the recognition errors of the autom atic transcripts on language model adaptation using the probabilistic laten t topical informa-tion is still under extensive investigation.
 5.2 Fusion of Topical and Contextual Information Though WTM and PLSA, aiming at exploring the long-span laten t topical in-formation of the search histories, have been shown effectiv e for language model adaptation, the local word regularity information inheren t in the adaptation corpus is still vital and worthy of being taken into account w hen performing language model adaptation. Therefore, we investigate here the integration of WTM or PLSA with two variants of the widely-used n -gram language model adaptation approach, that is, count merging and model inter polation, each of which can be respectively viewed as maximum a posteriori (MA P) language model adaptation [Bacchiani and Roark 2003] with a differen t parameteriza-tion of the prior distribution and can be used to capture the l ocal regularities of word usage in the new task domain. The integration is perform ed through sim-ple linear model interpolation, and the contemporaneous ne wswire texts and in-domain automatic transcripts, as well as their combinat ion, were exploited as well. More specifically, PLSA and WTM are combined with the count merg-ing approach through the following two equations, respecti vely:  X  P  X  P the background language model training corpus either with t hat of the con-temporaneous news text, or the in-domain automatic transcr ipts, or the com-bination of the both. The values for  X  1 and  X  2 in Equations (32) and (33) were respectively set at optimum values (  X  1 =0.1 and  X  2 =0.3), using the held-out set. On the other hand, PLSA and WTM were combined with the model in terpola-tion approach through the following two equations, respect ively: where P CONT ( w i | w i  X  2 w i  X  1 ) was trained using either the contemporaneous news text, or the in-domain automatic transcripts, or the co mbination of both. at optimum values (  X  1 =0.1,  X  1 =0.4,  X  2 =0.3 and  X  2 =0.35) using the held-out set as well.
 two variants of the MAP-based approaches (count merging and model interpo-lation) are shown in Table VIII. As can be observed, fusion of these two kinds of information sources does provide additional gains in mos t experimental con-ditions. Moreover, the combination of WTM with the MAP-base d approaches yields slightly worse results than the combination of PLSA w ith the MAP-based ones, though WTM has been previously shown to yield bet ter results than PLSA when the contemporaneous newswire texts are explo ited and to be competitive with PLSA when in-domain automatic transcript s are exploited. The combination of the latent topic approach (PLSA with 256 t opics) with the count merging approach, as shown in the last row of Table VIII , achieves the best result of CER of 13.23% (13.07% relative reduction) and PP of 313.20 (58.38% relative reduction). On the other hand, attempts al so have been made to combine PLSA with WTM, and the results are shown in Table IX . However, no significant performance gain is observed in word error rat e as well as perplexity reductions compared to the results obtained by c ombining either WTM or PLSA with the two variants of MAP-based approaches, re spectively. 6. CONCLUSIONS In this article, we have proposed a word topic model (WTM) to e xplore the co-occurrence relationship between words, as well as th e long-span latent topical information, for language modeling in spoken docum ent retrieval and transcription. The document or the search history as a whole is modeled as a composite WTM model for predicting the newly observed word . The un-derlying characteristics and different kinds of model stru ctures were exten-sively investigated, while the performance of WTM was analy zed and verified by comparison with the well-known probabilistic latent sem antic analysis (PLSA) model as well as the other models. Experimental resul ts on the Man-darin spoken document retrieval and transcription tasks bo th demonstrate WTM is indeed a feasible alternative to the existing models. Future work on the WTM-based approaches includes better model inferenc e or adaptation of WTM [Blei et al. 2003; Steyvers and Griffiths 2007], discri minative training of WTM [Chen et al. 2004b; Kuo and Chen 2005; Gao et al. 2006], a nd applying WTM to spoken document summarization [Chen et al. 2009].
 The authors would like to thank the reviewers for valuable co mments that greatly improved the quality of this article.

