 1. Introduction
Conventional point sensors, such as temperature sensors or analyzers of CO 2 emissions, have dif fi culties to detect smoke in large open areas because they require a close proximity to smoke and/or fi re to take samples of temperature or smoke particles.
Disadvantages of point sensors are that (1) a point sensor only takes samples at one point in space, (2) a highly populated distribution of point sensors in a vast area is impractical, and (3) continuous battery charge in wireless sensor networks is a dif fi cult challenge. Samples are transported from the fi re site to the detecting point with a high probability that these samples will not reach that point so that an alarm will not be activated.
Eventually, samples will arrive to the sparsely distributed sensing points but the longer the time between fi re inception and detec-tion the more dif fi cult to extinguish fi re and the more environ-mental damage.

Satellite based monitoring systems are not point detectors and can scan extensive areas but these systems have serious dif because of obstructions due to weather conditions such as clouds, a lack of continuous scanning, a large economical investment and low-resolution. All of these disadvantages make early fi re detec-tion a dif fi cult task unless fi re has covered a very large extension.
Out of different possible detection methods for forest fi most reliable, effective and accurate is the procedure based on video surveillance cameras which are volume sensors that can monitor large areas so that detection of forest fi res in early stages is possible as well as the minimization of extinguishing efforts and environmental damage. In video-based forest fi re detection there is a search for smoke columns because of the fact that smoke appears before fl ames and early detection is a priority. Video cameras can be spatially distributed in strategic locations (long-itude, latitude) over vast forest areas and they must be placed at the highest point in communication towers. Digital camera tech-nology has evolved very fast so that digital cameras are available in the market with low prices and high resolution. Besides contin-uous battery charge of battery-powered cameras is possible by connecting them to photovoltaic systems. Surveillance cameras can be directly connected to access points so that video signals are transmitted over full-duplex wireless links or through internet protocol (IP) to control and processing units where captured images and videos are analyzed and stored. Computer vision, machine learning, pattern recognition and digital camera technol-ogy play a very promising role to effectively replace previous and conventional forest fi re detection systems. Fig. 1 shows the components of a monitoring system for forest fi re detection based on video signal processing.

Smoke detection based on video signal processing has its dis-advantages since its current performance, in terms of detection rate point detectors, mainly due to the variability in smoke density, scene illumination, diverse landscapes, changing of the scenery over the months, interfering objects, weather conditions, camera movement, the fact that clouds look like smoke and mainly because smoke is dif fi cult to model ( Xiong et al., 2007 ).

There are several existing video processing techniques that have been applied to detect smoke such as wavelets ( Gonz X lez-
Gonz X lez et al., 2010 ), fuzzy systems ( Celik et al., 2007 ), color processing ( Vipin, 2012 ), change detection ( Kim and Wang, 2009 ), spatial and temporal models ( Liu and Ahuja, 2004 ), optical ( Kolesov et al., 2010 ), etc. The work reported in this paper is based on applying classi fi ers built with over-redundant learned diction-aries for sparse representation of signals. The problem is approached using the promising framework of dictionary learning for sparse representation , early addressed by Olshausen and Field (1997) , with the motivation that modeling of signals by their sparse representation is a natural and fundamental concept and there are no reports of smoke detection using this framework which has been very useful in different applications such as image denoising ( Protter and Elad, 2009 ), handwritten digit classi ( Bach et al., 2012 ), face recognition ( Wright et al., 2008; Wright color image restoration ( Mairal et al., 2008a ), endocardium seg-mentation in echocardiographic images ( Rosas-Romero and
Tagare, 2013 ), human action recognition ( Castrodad and Sapiro, 2012 ). Dictionary learning for sparse representation focuses on the development of algorithms to learn dictionaries with elements, called atoms , so that a signal of interest can be represented as a linear combination of very few atoms where the new representa-tion possesses an implicit discriminative nature by choosing the subset of atoms that gives the best compact reconstruction of the signal, and discarding other representations. Unlike previous works on smoke detection, the proposed approach does not use a pre-processing block for image enhancement previous to feature extraction.

We approach the problem of segmenting the smoke regions on sequences of video signals by snippet extraction (subset of images sampled from the entire video sequence) followed by dividing a sampled frame in patches , and classifying a patch as belonging to one of three classes or regions, smoke or sky or ground . Patch classi is accomplished through local feature vector extraction and patch classi fi cation. Classi fi cation is performed by a two-stage classi consisting of a non-linear transformation as the fi rst stage and a set of fi xed perceptrons as the last stage. After segmentation there is a presence of misclassi fi ed patches which impairs the performance in terms of the false alarm rate . The proposed approach accounts for spatial and temporal interaction of neighboring patches in snippet sequences to allow the reduction of isolated misclassi fi clusters of misclassi fi ed patches.

The rest of the paper is organized as follows. Section 2 reviews the relevant and recent related work in video-based forest detection and learned dictionaries. Section 3 gives a detailed overview of the framework of dictionary learning for sparse repre-sentation of signals highlighting those aspects relevant to the application presented by this paper. Section 4 presents a descrip-tion of the proposed approach for video-based forest fi re detec-tion. Section 5 provides the experimental results obtained by following strategies for dictionary learning as well as comparisons.
Conclusions are presented in Section 6 . 2. Recent related work
Prior work on smoke detection from outdoor forest video sequences consists in performing the stationary wavelet transform (SWT) to each frame to remove high frequency details, then the inverse SWT is applied to the fi ltered frame and fi nally the transformed image is compared to a non-smoke scene to deter-mine possible regions of interest (ROI) ( Gonz X lez-Gonz X lez et al., 2010 ). After segmentation, the number of misclassi fi ed ROIs is reduced by a sub-sequent algorithm that determines whether or not the area of a ROI is increasing or not. Previous to segmentation and detection, there is a pre-processing step for image enhance-ment. The previous described method is based on the key idea by
Toreyin et al. (2006) that smoke gradually smoothens edges on a scene allowing the segmentation of edge-blurring and moving regions. A novel smoke detection method based on wavelet energy and optical fl ow is proposed in Li et al., 2013 . Another algorithm for video based fi re detection makes use of spectral, spatial and temporal features by fi rst extracting potential fi re regions on frames using spectral and spatial models, then representing detected regions boundaries using Fourier coef fi cients, followed by estimation of the parameters of an auto-regressive model for each region, and in the last step the Fourier coef fi cients and the AR model parameters are used as region features in a classi fi recognizes fi re regions ( Liu and Ahuja, 2004 ). Other proposed methods are based on scene change detection. In Kim and Wang (2009) areas of change in the current input frame are extracted from a background image with changed regions being represented by blobs and blobs in close proximity being merged. Finally, temporal features, such as color and shape, are extracted from each blob to determine if this is smoke. A crucial challenge is the motion of the camera so that this method does not perform segmentation as long as the camera is moving which is deter-mined by another algorithm. Color is also used for fl ame detection in forest fi re videos. In Vipin (2012) seven rules are de color spaces RGB and YC b C r so that if a pixel satis fi fuzzy inference system is used for fi re detection with a set of 16 rules and membership functions de fi ned in the YC b C r space whereas smoke is detected by using a set of rules de fi ned in the
RGB space. The work in Ravichandran and Soatto (2012) combines generic priors from short-time scale, modeling of nuisance for known distractors such as sun, and learning of the residual variability with optical fl ow features. In the work of Ko et al. (2009) , candidate fi re regions are detected using modi fi of related methods, such as detection of moving regions and colored pixels. Next, a luminance map is made and used to remove non-fi re pixels. Thereafter, a temporal fi re model with wavelet coef fi cients is created and applied to a two-class support vector machines (SVM) classi fi er with a radial basis function (RBF) kernel.
Fern X ndez-Berni et al. presented a work targeting a vision-enabled wireless sensor network node for the reliable, early on-site detection of forest fi res. The tasks carried out ranged from devising a robust vision algorithm for smoke detection to the design and physical implementation of a power-ef fi cient smart imager tai-lored to the characteristics of such an algorithm. By integrating this smart imager with a commercial wireless platform, they endowed the resulting system with vision capabilities and radio communication. The contributions by Wang et al. (2011) are using the hidden Markov model (HMM) based on spatio-temporal features and the variance of luminance maps motivated by visual attention, and combining both for fi re detection. Zhu et al. (2013) use motion region detection, color-based fi re detection and region re fi nement to propose a fi re detection method for monitor-ing of self-service banks.

Sparse representation of signals has received considerable attention as a tool to solve different problems in Computer Vision.
An extensive survey of the challenges, motivation, approaches and applications of the main algorithms in the fi eld of dictionary learning for sparse representation is presented by Tosic and
Frossard (2011) and Elad (2012) . Aharon et al. (2006) proposed the groundbreaking K-SVD algorithm for adapting dictionaries to achieve the best sparse reconstruction for each member of a set of signals under sparsity conditions, which is an iterative method that alternates between sparse coding of the signals over the current dictionary and a process of updating the dictionary to better fi t the set of signals. Mairal et al. (2008b) introduced two different algorithms to perform an ef fi cient optimization of an energy function to learn dictionaries which are explicitly opti-mized to be both reconstructive and discriminative. Beckouche et al. (2013) introduced the centered dictionary learning method , which is applied in astronomical image denoising and shown to outperform wavelet and classic dictionary learning denoising techniques on astronomical images. Mairal et al. (2008c) pre-sented a multi-scale discriminative framework based on learned sparse representations to solve the problem of edge detection which is proven to greatly improve the results obtained with a contour based classi fi er. Rubinstein et al. (2010) proposed a model to learn dictionary atoms over a fi xed base dictionary bridging the gap between implicit dictionaries, which have ef fi cient implemen-tations yet lack adaptability, and explicit dictionaries, which are adaptable but costly to deploy and demonstrating the advantages of the proposed model for image denoising. An ef fi cient imple-mentation of the K-SVD algorithm is discussed in Rubinstein et al. (2008) which accelerates it and reduces memory requirements with the use of the Batch-OMP method to perform sparse coding.
A greedy adaptive dictionary learning algorithm to fi nd atoms for sparse representation and denoising of speech signals is presented in Jafari and Plumbley (2011) . Bar and Sapiro (2011) introduced a framework based on a hierarchical architecture of dictionary learning for sparse representation in a cortical space combined with a pooling operator to attain rotation and scale invariance with promising results in 2D shape classi fi cation, texture recogni-tion and object detection. Learning of class structured dictionaries to encode actions of interest for classi fi cation of human actions from video is developed by Castrodad and Sapiro (2012) , where the class assigned to a video come from the optimal sparse linear combination of learned atoms representing action primitives.
An image sequence denoising algorithm based on sparse and redundant representations was proposed by Protter and Elad (2009) where spatio-temporal atoms are used, dictionary learning is coupled with few training operations, and there is an extended patch set for dictionary training and image cleaning. A sparse representation based framework is used to classify human ges-tures captured as multivariate time series by introducing a new approach to kernelize sparse representations ( Zhou et al., 2013 ).
In Meng et al. (2013) a dictionary learning method is proposed to impose global sparsity constraint on the coef fi cient matrix of all training signals instead of enforcing sparsity constraint on the coef fi cient vector of each signal, which makes this method capable of assigning atoms for representing various signals and fi signal structures at global scale. A multi-scale learned representa-tion is proposed in Mairal et al. (2007) , by using an ef tree decomposition of the learned dictionary and overlapping image patches with applications in image enhancement and restoration. Sparse representation and dictionary learning are used in Zeyde et al. (2012) to scale-up an image while preserving edges and small details. A new dictionary, called Image Signature Dictionary , is presented by Aharon and Elad (2008) , which is a small image such that every patch is an atom used for sparse representation. The work in Rosas-Romero and Tagare (2013) highlights important aspects of the application of the theory of sparse representation and dictionary learning to the problem of ultrasound image segmentation. A multi-scale learned dictionary is constructed in Ophir et al. (2011) by combining the multi-scale properties of the Wavelet Transform with the data matching capabilities of the learned dictionaries.

Computer vision based algorithms for fi re detection require the extraction and segmentation of regions of interest (ROI) to obtain candidates for smoke regions, by at least two different criteria, color information analysis and region motion detection . Then, a classi fi er is applied to categorize features within candidates for smoke (abnormal) and non-candidates (normal). All these meth-ods are divided into at least two separate stages for extraction of ROIs, one based on analysis of color information and the other based on region motion detection . From the review, it is also learnt that one of the most important challenges to be faced in the application of interest is the dynamic nature of the scenery (background) due to changes of illumination, noise, weather conditions or motion. Despite the fact that the scenery dynamics is very slow if compared with that of smoke and/or fi re, this time-varying nature implies an adaptive processing to learn the most recent background to subtract ROIs from the background. Unlike other methods for smoke detection, the proposed approach simultaneously incorporates pixel color and motion information into one single feature vector, so that a classi fi er, based on K-SVD learned dictionaries, uses integrated features for fi re detection. To the best of our knowledge, so far there has not been a work that explores the application of the framework of sparse representation and dictionary learning to the problem of forest fi re detection. 3. Sparse representation and dictionary learning 3.1. Bases and signal reconstruction
Discrete Signals x are vectors in the N-dimensional Euclidean space denoted by  X  N . The set of atomic signals D  X f d i atoms , are linearly independent and span X . This implies that each signal in X can be uniquely reconstructed by one single linear combination of the atoms in D , x  X   X  K where D A  X  NxK is a matrix composed of K columns D  X   X  d ; d 2 ; ... ; d K and the entries of the vector  X   X  X   X  1 ;  X  are the coef fi cients of this linear combination. If the elements of the basis D are mutually orthonormal, that is d T i d j  X  0if i each atom lies in the hyper-sphere d T i d i  X  1( D T D  X  I ), then the basis is complete such as the case of the Fourier basis.
By allowing the use of linearly dependent atoms , a basis D and the respective dictionary matrix D become over-redundant , and there exist multiple choices for vector  X  for reconstruction of the signal x according to x  X  D  X  . We say that the signal x admits a sparse representation over the basis D when it is concisely reconstructed with very few atoms; and the signal is characterized by a sparsity factor L when its sparse representation  X  has at most L non-zero entries (  X  0 -norm), :  X  : r L  X  2  X 
The resulting representation is a powerful model for reduction of storage and transmission, and this model suggests that optimal over-redundant dictionaries exist for different classes of signals. 3.2. Learned over-redundant dictionaries
Instead of using prede fi ned dictionaries , such as wavelets, for sparse reconstruction of signals, dictionaries can be adapted to fi t a set of training signals . Letting the columns of matrix X  X   X  x ; x 2 ; ... ; x J A  X  NxJ be the set of J training signals, of one parti-cular class, to be sparsely reconstructed through an optimal over-redundant dictionary D , the dictionary learning task is described by the following minimization problem.  X  D ; A  X  arg min where the columns of matrix A  X  X   X  1 ;  X  2 ; ... ;  X  J A  X  KxJ
Different approaches to dictionary learning have been developed and they are based on a two-step process where the fi rst step consists in fi nding the sparse representation A of the training signals X based on the current fi xed dictionary D through a pursuit algorithm such as Matching Pursuit (MP) ( Mallat and Zhang,1993 )or
Orthogonal Matching Pursuit (OMP) ( Pati et al., 1993 ). During the second step, the atomic signals are updated assuming fi xed recon-struction coef fi cients. One suitable algorithm to adapt dictionaries for sparse representation is the K-SVD method (K  X  Singular Value
Decomposition ) proposed by Aharon et al. (2006) . The key idea of the K-SVD method consists in expressing the total reconstruction error function , given by the Frobenius norm in (3), as where atom d i is the i th column of D and  X  T i is the i th row of A .
K-SVD is an iterative two-step process to train a dictionary. In each iteration, the fi rst step consists in estimating the sparse representa-tion A according to A  X  arg min
In the second step, each atom d i and corresponding row  X  T found by using SVD ( Singular Value Decomposition ) according to  X  d ;  X  T j  X  arg min d where matrix  X  j shrinks E j by keeping only those columns which have non-zero reconstruction coef fi cients (entries) in  X  T SVD, matrix E j  X  j can be approximated by a rank-1 matrix,
E
 X   X   X  where d j  X  u 1 , and  X  T j  X  s 1 v T 1 . 3.3. Classi fi cation of signals based on learned dictionaries
Dictionary Learning has been successfully applied to different classi fi cation tasks. Letting dictionary D i A  X  NxK be trained to sparsely reconstruct a set of signals X i A  X  NxJ belonging to the by fi rst estimating the set of residuals f r i  X  x ; D i  X g P i  X  1 residual corresponds to the sparse reconstruction of the signal over one dictionary, r  X  x ; D i  X  X  min  X   X  : x D i  X  : 2 2  X   X  :  X  : 0 ; i  X  1 ; ... ; and then a class is assigned by fi nding the smallest residual, class  X  arg min 3.4. Learning of discriminative dictionaries
Mairal et al. (2008b) proposed an energy formulation with both sparse reconstruction and class discrimination components jointly optimized during dictionary learning. Instead of independent learning of P dictionaries just for reconstruction of signals by repetition of the K-SVD method, a discriminative dictionary learning algorithm simultaneously builds P dictionaries which are not only good at reconstructing signals of their own class (through the use of residuals r i as discriminants) but also bad at representing signals from other classes. Discriminative dictionaries , f D for representation of a set of P classes of training signals ff x i g learned so that a residual feature vector r  X  X  r 1  X  x ; D r  X  x ;
D P  X  T is located further away from the hyper-plane compared with its location according to pure reconstructive dictionaries. This enhanced discriminative capability is possible according to the following energy minimization,  X  D  X  where residual r i is still used as a discriminant and the softmax power. Simultaneous minimization of the reconstruction residual r and the softmax function takes place in Eq. (10) , with the last one implying minimization of exponentials e b which are close to zero when r i is the smallest among residuals f r j g p j  X  1 . 4. Proposed approach for smoke detection from video signals 4.1. Overview of the proposed approach
An overview of the proposed method is depicted in Fig. 2 . The method generates an input video sub-sequence, known as snippet , by uniform sampling of the original video sequence. On each sampled frame there is a partition into three different regions (smoke, sky and ground) which is performed with a patch-by-patch classi fi cation process. Each image patch is classi extraction of a feature vector from the patch, and processing of the feature vector to assign a class to the patch. Some of the features come from patches with temporal adjacency to the patch of interest. The image segmentation process can also be executed in a pixel-by-pixel fashion, by processing the patch around the pixel of interest, but at the expense of increased computational time. After frame segmentation, a re-classi fi cation of a patch is performed by considering spatial and temporal interaction among neighboring patches ( spatio-temporal cuboid of patches). 4.2. Feature extraction
The dictionary framework is fl exible in the sense that it is easy to consider different types of features. The color intensity values in a patch are used as features by concatenation of the RGB planes of the patch into a single vector, multiplying by 3 the dimensionality of the patch. The use of color information as features is crucial to discriminate among smoke, sky and ground regions. Even though a feature vector is extracted from an image patch, part of its informa-tion comes from other patches with temporal adjacency to account for temporal information. The inclusion of temporal information is based on the fact that motion in smoke regions and steadiness of sky and ground regions are embedded in temporal features.
A feature vector can be seen as the concatenation of a spatio-temporal cuboid of color pixels into a single one-dimensional vector. Statistical information is also included as features by computing the mean and variance of each color plane in a patch.
A feature vector x i  X  s i ; t j  X  A  X  N is associated to an image patch p  X  s i ; t j  X  at spatial location s i and at temporal location t in a snippet sequence). The N entries of a feature vector consist of (1) the intensity color values on the three RGB planes of the patch p  X  s i ; t j  X  (a 3 stacked as a column vector y  X  s i ; t j  X  X  X  y R  X  s i ; t j  X  T ; y G  X  s i ; t j  X  T ; y (2) intensity color values from other patches with temporal adjacency and located on frames at time instances t j 1 and t  X  y  X  s i ; t j 1  X  T ; y  X  s i ; t j  X  1  X  T T  X  X  y R  X  s (3) the mean of the intensity values on each color RGB plane at spatial location s i and at different instances of time t  X   X  y R  X  s i ; t j 1  X  ; y G  X  s i ; t j 1  X  ; y B  X  s i ; y R  X  s i ; t j  X  ; y G  X  s i ; t j  X  ; y B  X  s i ; t j  X  and (4) the variance of the intensities on each color plane at spatial location s i and at different instances of time t j 1 , t r Given all this information, a feature vector is constructed, x  X  s i ; t j  X  X  X  y  X  s i ; t j 1  X  T ; y  X  s i ; t j  X  T ; The number of entries in each feature vector is given by N  X  3  X  3  X  and temporal information they become very high dimensional and this is the motivation for choosing a patch of small size n  X  3 3. 4.3. Classi fi cation
The classi fi er based on learned dictionaries is a cascade connec-tion of two systems as it is shown in Fig. 3 . The fi rst stage (enclosed by a blue dashed rectangle) is a non-linear signal transformation, T :  X  N - X  p , with the testing feature vector x
A  X  N as input and the residual feature vector r  X  X  r 1  X  x r in r are non-negative, then the result of this stage is a transformed feature vector r lying in the fi rst hyper-quadrant in the P -dimen-sional space. The second stage (enclosed by a red dashed rectan-gle) consists of a set of P classi fi ers with r as the input feature vector, with synaptic weights values in the set { 1, 1}, and with the unit step function u  X  v  X  as the activation function . The hyper-plane for the i th classi fi er lies in the fi rst hyper-quadrant in the
P  X  dimensional space and is given by,  X   X  r  X  x ; D i  X  r j  X  x ; D j  X  X  0 :  X  16  X 
Residual features at the output of the transformation stage are found by solving the sparse decomposition problem in Eq. (8) .
Different methods exist in the sparse coding literature such as active set methods, soft-thresholding based methods, homotopy and greedy procedures. Since fi nding the sparsest representation is an NP-hard problem approximate solutions are considered with the Matching Pursuit (MP) ( Mallat and Zhang, 1993 ) and the
Orthogonal Matching Pursuit (OMP) ( Pati et al., 1993 ) algorithms being the simplest ones. Matching Pursuit consists of three different steps: (1) Initialization of  X   X  0 , r  X  x ; and an iterative two-step process where (2) there is a selection of the atom d the highest correlation with the residual max an update of the residual r  X  r  X  d T i r  X  d i and the sparse coef sparsity condition jj  X  jj 0 o L is satis fi ed. 4.4. Spatial and temporal interaction for reduction of misclassi fi ed patches
The entries of a transformed feature vector f r i  X  x ; D errors of the sparse representations of the corresponding feature vector x over different dictionaries f D i g P i  X  1 . After transformed features are used for patch classi fi cation during smoke detection in snippet sequences, one problem that arises is the presence of misclassi fi ed patches. In order to further improve segmentation, a patch re-classi fi cation process is performed by accounting for spatial and temporal interaction among neighboring patches, in the same way that low-pass fi ltering uses multiple neighboring pixels to compute one new pixel value, allowing the reduction of misclassi fi ed pixels. Label re-assignment of a classi fi now accomplished by fi nding its nearest neighboring patches in the spatial and temporal domains ( spatio-temporal cuboid of patches), as it shown in Fig. 4 , and the new class to be assigned is the one with the highest frequency of appearance inside the spatio-temporal cuboid of patches.

To re-classify a patch of interest  X  i ; j ; t k  X  (where i and j stand for spatial location of the patch and t k stands for its temporal location), a spatio-temporal cuboid of patches is built P j 7 q ; t k 7 q  X  ; q  X  0 ; 1 ; ... ; Q g with adjacency among neighbors over space and time. The problem consists in assigning a new label having the same label  X  m and with n  X  P  X  m  X  being the cardinality of the sub-set P  X  m that is the number of patch elements that contains. The new label for P  X  i ; j ; t k  X  is assigned according to,  X   X  arg max 4.5. Dictionary learning
The training of the classi fi er based on learned dictionaries consists in fi nding the set of dictionaries f D i g P i  X  1 of parameters in the transformation stage of the classi fi in Fig. 3 . There are three dictionaries ( P  X  3) to be learned for sparse representation of feature vectors extracted from smoke, sky and ground regions. For each surveillance camera, a dictionary is initialized by populating it with feature vectors extracted from the region of interest. Instead of learning and storing very large dictionaries for sparse representation of feature vectors extracted from multiple scenarios (for each scenario there is a monitoring camera), small dictionaries are independently learned for each camera. The training sets for dictionary learning are generated with samples taken from scenes of the landscape of interest captured by one surveillance camera in the same way that dictionaries are initialized.

Given three training sets of observations from smoke, sky and ground and the initial version for dictionaries D 1 , D 2 dictionaries are trained using K-SVD methods ( Aharon et al., 2006;
Mairal et al., 2008b ), which are an extension of the K-means algorithm to dictionary learning. The K-SVD method was chosen since it offers advantages over the MOD method ( Engan et al., 1999 ). K-SVD and MOD can work with any pursuit technique; however, MOD requires matrix inversion which makes it imprac-tical when the number of atoms is very large. 4.6. Description of issues and challenges related to the implementation of the forest fi re monitoring system 4.6.1. Communication and energy issues of the implementation of the proposed monitoring system
The following implementation description is based on the forest fi re monitoring system which has been operated by the
Mexican Ministry of Environment since 2006. In this monitoring system, multiple surveillance cameras send video signals to a central site where these signals are displayed on high-de (HD) displays and continuously analyzed by human operators with the impossibility of keeping a constant eye on every single camera and this is why there is a need for arti fi cial intelligence to support the operators at the central site. The set of multiple IP (Internet
Protocol) video security cameras are located at strategic outdoor positions, connected to an already established wide area network (WAN) through an IP address, and powered with AC voltage.
This setup is possible because of the fact that the cameras are IP end-devices (manufactured by PELCO by Schneider Electric) and they are installed in telecommunication towers where there is availability of connectivity and AC power without a real need for photovoltaic systems. Obstructions in the environment do not limit communication over wireless links since base stations in communication towers were already installed at positions where there is an unobstructed and clear line of sight (LOS) between the end points of the link. The telecommunications infrastructure that supports monitoring services for the Mexican Ministry of environ-ment consists of WiMax base stations which operate with a bandwidth of 50 MHz (3.300  X  3.350 GHz), 23 dBm of power, antenna heights from 21 m to 45 m, and T-R separation distances from 10 km to 20 km. The links connected to a base station have OFDM technology, bit rates of 21 Mbps, and a channel bandwidth of 7 MHz for each subscriber, including surveillance cameras. The future for the proposed implementation, based on IP security cameras, is promising since it takes advantage of an already established telecommunications infrastructure and because of the fact that the most recent IP network camera models provide new features such as high-quality color HD video, con-venient network connectivity, power over Ethernet (PoE), and patch under re-
H.264 compression for optimized image quality and minimized bandwidth. 4.6.2. Issues and challenges related to an implementation based on wireless camera networks
Recent research efforts in wireless camera networks (WCNs) are oriented at replacing high-cost and high-performance camera network devices with low-cost and low-complexity embedded devices organized in distributed systems to enable monitoring of events. However, low-complexity camera network devices are strongly constrained in terms of deployment to guarantee cover-age, battery recharging for energy consumption, memory, multi-media signal processing capability, the fact that capturing and digitizing of images sequences require a signi fi cant percentage of energy consumption, and achievable data rate for the multi-media content to be delivered. Indeed, because of these severe limitations, quality of service (QoS) is a challenging task. Battery is the main power source in a sensor node, and secondary power supplies that absorb energy from the environment, such as solar panels, must be added to the node. To support multimedia based applications in WCNs, different research projects have prototyped embedded devices suited for image acquisition, processing, and transmission ( Akyildiz et al., 2006; Salvadori et al., 2013; Fern X ndez-Berni et al., 2012 ). A comprehensive survey is given by
Yick et al. (2008) . 4.6.3. Video coding The discussed surveillance cameras (PELCO by Schneider
Electric) have an embedded coding system where video signals are sequentially separated into frames which are independently recorded in JPEG format. Remote access to the set of frames comprising video signals is done by querying the IP security video system to retrieve a JPEG (Joint Photographic Expert Group) per frame. To achieve high ef fi ciency in fi re detection, some issues have to be considered during selection of IP surveillance cameras such as the dynamic range of the color spaces, de fi nition (standard or high) of the video signal, and the video coding embedded in the camera. There is research focused on working inside video codecs to optimize encoding for speci fi c purposes besides storage and bandwidth, typically to optimize visual quality for human users, such as the work by Masala et al. (2009) ; however, there is de fi nitely a need to conduct more research to optimize encoding by looking at the need of the video signal processing, by privile-ging regions of interest during encoding, and by considering that in the near future many videos (either compressed or compressed plus transmitted) will be consumed by algorithms, and not by humans, such as the current application or that presented by
Masala (2008) . 4.6.4. Parallel processing
The need of performing complex image analysis in multiple dimensions increases the computational requirements. Therefore, to achieve optimal processing speed in the real-time implementa-tion of the fi re detection algorithm, image analysis and processing have to be parallelized by exploiting the power of processor clusters in servers and the introduction of concurrent processes in the software implementation of the proposed algorithm. Since many identical computations are required, it is natural to think about replicating instruction execution, for each patch to be classi fi ed or for each dictionary to be retrieved during matching pursuit or for each JPEG fi le per frame to be downloaded from a surveillance video camera through the use of single instruction multiple data (SIMD) and multiple instruction multiple data (MIMD) computer systems which have a number of independent proces-sors to operate upon separate data concurrently. The algorithm should satisfy different requirements: (1) there should be a set of parallel threads, concurrently retrieving consecutive JPEG from a distant video camera, which is proportional to the number of frames used in spatio-temporal cuboids; (2) there should be parallel processes for patch classi fi cation by using a number of parallel threads which is proportional to the number of patches into which a frame is divided; (3) there should be three parallel threads to perform matching pursuit of the feature vector of an image patch over three different redundant dictionaries; (4) the algorithm should require synchronization among parallel threads to ensure correct and fast execution; (5) another hint to paralle-lization is the use of speci fi c programming languages speci tailored for parallel image processing such as Apply and Adapt. 4.6.5. Sampling of rare events
Fire detection algorithms build a response from video sequ-enceswithanextremelysmallnumberofforest fi re events happen-analyzed video sequences in whic h the number of frames without fi re events far exceeds the number of frames with fi re events. Processing and analyzing all those frames without fi re events is costly in terms of computational complexity and energy consump-tion so that the implementation of fi re detection algorithms could be further enriched by adopting some sampling technique for rare events and thereby reducing computational cost. In a probabilistic model, a fi re event has a very small probability of occurrence, but when it happens there are catastrophic losses. Therefore, it is a critical issue to evaluate the probability of fi re events which is a function of some environmental parameters such as the season of the year, day time, weather conditions (rain, snow), temperature, and moisture. The frame sampling rate for fi re events should be a time-varying function dependent on the probability of the event occurrence. The proposed framework, for future work, is based on type of stochastic signal model, namely Markov models ( Rabiner, 1989 ), where the concept of state will be related to the state of the environment (early morning during a rainy season, afternoon during an extremely hot and dry season, etc.), and where the observation ( fi re event and non-fi re event) is a probabilistic function of the state. The Markov model to design is characterized by the following parameters: (1) the number of states which will not be hidden as opposed to hidden Markov models (HMM), (2) two distinct observa-probability distribution which is dependent on environmental vari-ables and time, and (4) the observation probability distribution which is the most crucial element and the required output of the model. The challenge of the model design is to determine a method to adjust its parameters to estimate the probability of the observation given that the environmental and time state are known. 5. Experiments and results
Experimental analyses were carried out to explore the discri-minative power of dictionaries during segmentation of smoke on outdoor video sequences. The data set was provided by the Forest Fire Monitoring Center of the Ministry of Environment in Mexico and it consists of 26 video sequences corresponding to a forest event and taken by surveillance cameras with different lengths and conditions in terms of luminosity, scenarios, season, and presence or absence of fi re incidents. Some of these sequences were captured by surveillance cameras currently used for forest fi re monitoring. A real-time implementation will require periodic training intervals to learn the time-varying scenery features which change slower than those of smoke regions. This learning should be done by collecting a training set consisting of frames captured at periodic sampling intervals and this is why training data sets in our implementation were extracted from the fi rst frames in snippet sequences with corresponding subsequent frames used for testing. In most cases, cameras scan vast areas which are located further away from the fi re event and the fi rst wild is smoke. These issues are the reasons for using video sequences where smoke, and not fl ames, appears in the landscape. The purpose of the proposed algorithm is to detect smoke and not fl ames.

A dictionary is learned for each region (smoke, sky and ground). There is a vast diversity in artifacts in ground regions (there could be vegetation, hills, plains, man-made structures, mountains) which are dependent on the location of the camera.
Instead of learning one very large dictionary for sparse represen-tation of ground regions at all possible places under monitoring by different video cameras, a dictionary is independently learned for each camera, avoiding the need of a huge number of atoms as ground primitives and as a consequence reducing segmentation time. Reconstructive and discriminative dictionaries were tested in different cases with similar performance.

Prior to learning, dictionaries are initialized by an automatic and random extraction of atoms from manually traced bounding boxes that contain the class of interest. Atom information is generated from 3 3 sized image patches. The total number of entries per atom is N  X  99 which includes (1) 27 intensity values from the three RGB planes contained in the patch, (2) 54 addi-tional intensity color values from patches on one previous and one subsequent frames which accounts for temporal information (spatio-temporal cuboid), and (3) statistical information (mean and variance) for each color plane and each temporal location which amounts to 18 additional entries. After initialization, dic-tionaries are trained in a supervised fashion by building sets of training feature vectors with a guided extraction process similar to that for dictionary initialization.

Fig. 5 shows a short fragment of the segmentation of a snippet sequence corresponding to a fi re event. Separation time between snippet frames is 1 s and the size of each frame is 326 484 pixels.
This test was performed using 200 atoms per dictionary and 120 training feature vectors for supervised dictionary learning with 90 iterations of the K-SVD method and a sparsity factor L  X  3. Average computational time for supervised dictionary learning is 34.5 s in a
MATLABR 2010a implementation on an Intel Core2 DUO processor at 2.8 GHz. Average computational time during segmentation of one frame is 107 s. To reduce segmentation time, a crucial issue in real time signal processing, dictionaries are pruned by eliminating those atoms without adjustment during learning. Average compu-tational time during segmentation of one frame with pruned dictionaries is 81.3 s. Patches, classi fi ed as being part of smoke or sky or ground regions, are shown in Fig. 5 in black, gray and white respectively. Computational time varies upon the frame under segmentation due to the extensive use of matching pursuit which has a variable computational time. Misclassi fi ed smoke patches ( False Positives ) are those black patches inside white and gray regions. To reduce the presence of misclassi fi ed patches on a raw segmented frame, a spatio-temporal cuboid of patches is extracted for each patch. The central patch in the cuboid is re-classi taking a majority vote inside the cuboid.

Tests were performed on video sequences showing controlled forest fi re experiments. In these cases, after raw segmentation and patch re-classi fi cation, an additional smoke veri fi cation algorithm ( Gonz X lez-Gonz X lez et al., 2010 ) is used to track area changes in
Regions of Interest (ROI). If the ROI area is increasing over subsequent frames then the ROI is con fi rmed as a smoke region since it is considered that smoke regions grow. The search for ROIs on the fi rst snippet frame is carried out on the whole frame through a scan from the four edges towards the center until the edges of the smallest Bounding Box enclosing a ROI are found. For the case of subsequent frames, the bounding box is determined by an approximation based on the bounding box on previous frames. Tracking of area changes in ROIs helps to reduce false alarms.
Fig. 6 shows the results of smoke detection in two frames of a controlled-fi re snippet sequence before and after fi re inception with an elapsed time of 4 min between both frames. This test was performed using 480 atoms per dictionary and 96 training feature vectors, an average computation time of 33 s for supervised dictionary learning, sparsity factor of L  X  3, and an average com-putation time of 93 s for raw segmentation of each snippet frame.
The detection algorithm was proven to be useful on snippet sequences with frames under conditions that make its segmenta-tion a dif fi cult task such as high illumination in the environment, a common case in outdoor scenarios, as it is shown in Fig. 7 ;or scenarios with man-made structures as it is shown in Fig. 8 .
The detection performance is evaluated by computing the recall , the false alarm rate (FAR), and the false positive rate (FPR).
The frames, used for training, are not used to measure perfor-mance. The recall is obtained by considering all those frames, from different snippet sequences, which show a fi re incident and this rate is de fi ned as where the number of frames with true positives (TP) is 483 and the number of frames with false negatives (FN) is zero, which gives a recall of 100%. The true challenge faced by the smoke detection algorithm emerges with the false alarm rate de fi ned as where the number of frames with false positives (FP) is consider-ably reduced to 6 after the use of spatio-temporal interaction among neighboring patches and tracking of area changes in ROIs to obtain a FAR of 5.7% in those frames without a fi re incident (FP  X  TN), where the number of true negatives (TN) was 99. The number of false positives (FP) is also compared with the total number of detections (FP  X  TP) to obtain a false positive rate (FPR) of 1.22% according to, In general, performance evaluation of a forest fi re detection system is challenging because there are few standard datasets, the research community has been using different datasets (for training and testing) with different numbers of video sequences (movies) and variable resolution, development of algorithms for fi tion has been conducted for different purposes (outdoor vs. indoor fi re detection, smoke vs. fl ame detection, forest fi re events vs. non-wild fi re events), and there are no widely  X  agree-upon  X  evaluation criteria. Some of the parameters used to measure the effectiveness of different approaches in terms of accurate fi re detection are the the rate of false detections ( false positive rate ), the overall detection rate including true positives and false positives ( preci-alarm or false negative rate or false reject rate ), the performance when the false positive rate is equal to the false negative rate ( equal error rate ), and another issue in terms of timely is detection time which determines how long the video analysis takes before an alarm is activated. Table 1 shows the performance of different methods, including the proposed one, in terms of recall and false alarm rate, where different datasets were used. The table also shows the purpose of the method ( fl ame detection or smoke detection) and the framework behind the algorithm. 6. Conclusions
This paper shows the results of a proposed method based on the application of sparse representation and over-redundant dictionary learning to the problem of segmentation of smoke in video signals from surveillance cameras for early and remote detection of forest fi res. Unlike previous works on smoke detec-tion, the proposed approach does not use a pre-processing block for image enhancement previous to feature extraction. There are three dictionaries to be learned for sparse representation of feature vectors extracted from image patches on smoke, sky and ground regions. Instead of generating a dictionary for sparse reconstruction of the ground regions in all the possible monitored scenarios, we propose to learn a ground dictionary independently for each landscape under monitoring by one single camera so that the use of a very large number of atoms as ground primitives is avoided. Color, temporal and statistical features play a signi role when facing the challenge of smoke detection in video sequences captured under different conditions in terms of lumin-osity, weather, time, and season. On the other hand, temporal features multiply at least by three the dimensionality of an image patch with the consequence of increasing the length of feature vectors as well as the computational time during segmentation which is a critical issue in real-time video signal processing. As a consequence of the last implication, values for the patch size and the number atoms per dictionary should be chosen as small as possible. One way to reduce the number of features is to replace temporal information with other features such as the location of the patch (two features, row and column) and the orientation of the surveillance camera (two features, polar angle and azimuth angle). Pruning of dictionaries by elimination of those atoms which are not adjusted during learning reduces the dictionary size and as a consequence computational time during smoke detection.
After raw segmentation, a patch re-classi fi cation process is under-taken to reduce the number of misclassi fi ed patches by introdu-cing spatial and temporal interaction among multiple patches in a neighborhood (construction of spatio-temporal cuboids) and con-sidering the class with the highest frequency inside the cuboid (majority vote). The construction of spatio-temporal cuboids of patches requires the segmentation of multiple frames at different instances of time which impairs segmentation speed. Further-more, matching pursuit to fi nd the sparse representations of an extracted feature vector over each of three dictionaries also requires signi fi cant computational complexity. Therefore, efforts should be invested in obtaining faster hardware and software implementations of the algorithm as well as video cameras of high quality. The proposed method was validated on a data set with a recall of 100% and a rate of false alarm of 5.7%; however, there should be further research to develop fast algorithms for reduction of false positives such as the case of algorithms to verify the increase of area of regions of interest or algorithms to discriminate between clouds and smoke. Future work should also be focused on modeling the frame sampling rate as a time-varying function to reduce computational complexity and energy consumption. Acknowledgments This research was possible because of the support of a Fulbright Scholarship.
 References
