 Peresia and Bialek [1] , provides a hierarchical clustering framework. But, in searching  X  X ottom-up X  agglomerative clustering procedure, known as AIB [2] , and which has can be found in [3-7] . But the Monte-Carlo simulation formula which is adopted for IB principle can be depicted as follows [1][2] : Assume a signal xX  X  provides clustering X is in fact the average of this distortion measure [2] : Optimizing the minimization problem yields the self-consistent equations [1] . minimum mutual information loss [2] . 462 S. Song, Q. Yang, and Y. Zhan 
ALA || log log , With Gauss mixtures, Bhattacharyya distance can be written below [11] : 464 S. Song, Q. Yang, and Y. Zhan was fitted by EM [10] , to the samples extracted from each image. Then, Gauss 1. Tishby, N., Pereira, F., Bialek, W.: The information bottleneck method. In: Proc.of the 37-2. Slonim, N., Tishby, N.: Agglomerative Information Bottleneck. In: Proceedings of NIPS-3. Goldberger, J., Greenspan, H., Gordon, S.: Unsupervised Image Clustering Using the 5. Goldberger, J., Gordon, S., Greenspan, H.: An information theoretic framework for 6. Goldberger, J., Roweis, S.: Hierarchical Clustering of a Mixture Model. In: Neural 7. Goldberger, J., Greenspan, H., Gordon, S.: An efficient similarity measure based on 10. Dempster, A., Laird, N., Rubin, D.: Maximum likelihood from incomplete data via the EM 11. Bian, Z.Q., Zhang, X.G.: Pattern Recognition, 2nd edn. Tsinghua University Press, China 
