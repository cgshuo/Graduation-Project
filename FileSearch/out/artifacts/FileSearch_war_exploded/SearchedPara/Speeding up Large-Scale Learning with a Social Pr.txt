 Slow convergence and poor initial accuracy are two prob-lems that plague efforts to use very large feature sets in online learning. This is especially true when only a few fea-tures are X  X ctive X  X n any training example, and the frequency of activations of different features is skewed. We show how these problems can be mitigated if a graph of relationships between features is known. We study this problem in a fully Bayesian setting, focusing on the problem of using Face-book user-IDs as features, with the social network giving the relationship structure. Our analysis uncovers significant problems with the obvious regularizations, and motivates a two-component mixture-model  X  X ocial prior X  that is prov-ably better. Empirical results on large-scale click prediction problems show that our algorithm can learn as well as the baseline with 12 M fewer training examples, and continu-ously outperforms it for over 60 M examples. On a second problem using binned features, our model outperforms the baseline even after the latter sees 5x as much data. I.2.6 [ Learning ]: Parameter Learning Social Prior, Mixture Model
Large-scale online learning faces two challenges. The first is the huge number of features whose weights must be learnt. The second is sparsity and skew: any one training example typically X  X ctivates X  X nly a few features, and the frequency of activation of various features can be heavily skewed. SVMs can deal with large (indeed,  X  X nfinite X ) dimensional feature spaces, but only when these features are of a very particular form (e.g., all monomials of a given degree, for polynomial kernels) and only by making computational complexity de-pend strongly on the number of training examples N ;how-ever, the features in large-scale learning can be arbitrary, and N is always very large. Linear models (including lin-ear SVMs) are often the best tools in such situations, but even they converge only slowly. Due to skewed activations, learning the weights of rare features is particularly slow.
Consider, for instance, the problem of predicting clicks by users on any form of online content (e.g., news-feeds or ads) on large websites such as Yahoo! or Facebook. In addition to the  X  X sual X  features (say, user age or gender), the user X  X  ID itself could be a binary feature  X  1 if the user viewing the content has this particular ID, and 0 otherwise  X  potentially adding  X  10 9 binary features of the form { user-ID= x } to the learning problem. The weight learnt for such a feature is then the user-specific bias that is left over after all other features are accounted for. Another example would be the { user-ID= x , content-category= y } binary feature, which encodes the residual propensity of user x to click on content from category y that is unexplained by other features. Each training example involves the action (click or not) of only one user when shown one particular piece of content, and hence only one of these features is activated. Clearly, learning the entire set of weights will be very slow.

However, there are many situations where features are known to be related or  X  X lose X . In the example above, we may know the social network between users, and could rea-sonably claim that users are generally X  X lose X  X o their friends and show similar biases. If so, the weights for { user-ID= u and { user-ID= v } should be similar whenever u and v are friends. Thus, any updates to one weight (say, due to new training examples) can be propagated to other weights in its neighborhood; in effect, each training example affects mul-tiple weights even though only one weight is activated. This should speed up the learning process, as long as our original assumption of closeness of weights was correct.

Another situation with related weights occurs when an ordinal variable (say, average time spent on website per day) is binned into non-overlapping intervals, and the user X  X  bin becomes a binary feature { bin= x } . Normally, the weight for each such feature would be learnt independently. However, by construction, adjacent bins are related. Indeed, if the response variable (say, click or not) is a smooth function of the original ordinal variable (average time spent) and the bin-size is small enough, we expect adjacent bins to have similar weights. This insight can lead to faster learning.
While this problem exhibits superficial similarity with la-bel propagation, the problems are actually orthogonal. La-bel propagation assumes that feature values for similar items are close, and uses this to predict missing feature values. Our problem is to learn weights for { feature value= x } , where these weights denote how different values affect a given response variable (say, clicking behavior). The un-derlying assumption here is that similar feature values af-fect the response variable in similar way, and hence have weights that are close. Thus, weights are inherently tied to a specific prediction problem, while values are immutable (if unknown) properties of the items themselves. The same problem setting may exhibit both situations: we may need to impute missing values for some users (say, the age), and also the effects of these values on the click-through rate.
We formalize this similar-weights intuition into a model that places  X  X ocial prior X  on the feature weights. The sim-plest version places a N (0 , X  2 ) prior on the difference be-tween the weights of every pair of related features. While appropriate for certain situations, this formulation runs into severe problems when applied to the social network of user-IDs: in brief, some weights are forced to have tiny variances even before any training examples are observed. We ana-lyze the reasons for this, and present a better model that provably avoids these issues.

Our contributions are as follows: (1) We show that users in a large social network are in-deed similar to their friends, in the context of clicking on ads. This effect exists even after accounting for important covariates such as the type of ad, and the context in which the ad is displayed. (2) We propose Bayesian models that formalize this notion of feature weight similarity via a social prior. We analyze these models and show a basic problem afflicting a broad class of such models: prior variances of some weights can become too small even before any data is seen. This analysis leads us to a model that avoids this pitfall. (3) In addition to the social network setting, we show how our proposed methods are applicable in a broad range of problems, such as when features are derived from histograms or trees. Such cascading of features  X  using the results of a related algorithm as input features for the learning problem  X  is a common technique in practice, and the proposed methodcanleadtofasterlearninginsuchcasesaswell. (4) We empirically demonstrate the significantly faster convergence of our proposed method. For a click-prediction problem with user-ID features, the use of the Facebook social network achieves an accuracy that would otherwise require 12 M extra training examples. These gains are primarily observed in the initial stages of learning, which is precisely where large-scale learning suffers the most. On a second real-world problem the social prior model outperforms the baseline model even when the latter sees five time as many training examples.

This paper is organized as follows. Section 2 discusses prior work. The usefulness of the social network for click-prediction is validated in Section 3. The proposed method is presented in Section 4, followed by a discussion of broader applications (Section 5) and experiments (Section 6). We conclude in Section 7.
We split this discussion into two parts: (a) learning al-gorithms using a network among features, and (b) work in-volving social networks in particular.
 Network-based Learning. There are three major threads in this category. Network structure has been used directly via random walks with restarts in recommendation prob-lems, and have been shown to outperform standard collabo-rative filtering [9]. Networks of features have also been used as regularizers, with a penalty being assessed on dissimi-lar weights that are connected in the network [13, 11, 15]. Regularization in a more Bayesian setting has also been pro-posed [5]. Finally, the network has been used as an aid in achieving sparsity of the weight vector, with a regularization term that pushes connected weights to be either both zero or both non-zero [8].

Our work is closest to the work on regularization, but our goal is to infer the weight distributions instead of optimal point-estimates. Also, there is no obvious sparsity require-ment that can be used to reduce the dimensionality of the weight vector. While our first model is indeed similar to some in prior work, we show that it, in fact, is particularly poor in problems involving large social networks. We believe that our work is to first to formally analyze the reasons be-hind its poor performance, and to offer a solution that actu-ally works well on a large social network and O (10 8 ) training examples.
 Utility of Social Networks. Social networks have seen recent use in a variety of problems, with varying success. It has been useful in collaborative filtering situations [9], in re-view quality prediction [10], and in increasing user clicks via targeted  X  X ocial ads X  [2]. On the other hand, Goel et al. [6] show that the social network offers less than 2% lift in CTR prediction overall, though it is more useful in other problem settings. Bao et al. [3] found that  X  X nfluential X  users rarely click on ads, but they can be useful for CTR prediction for other users, if we mine their data to find  X  X ints X  that are (a) propagated to other users, and then (b) used in the CTR es-timation algorithm. Such hints can be mined separately for users and ads, and can then be used for matching, without explicitly using the social network itself [14, 17].
Thus, while social networks have been useful in general, evidence of their utility in the problem of click prediction is more ambiguous. Our focus is on using the social network to speed up convergence of the learning algorithm, which couldleadtoeasierexplorationofthistopic.
Our underlying assumption was that the social network is informative in predicting user clicks on online content, even after accounting for the most common effects such as the type of content and the context in which the content is shown. Before we can proceed, we must justify this assump-tion.

If users are similar to their friends, then we should ex-pect a user X  X  click-through rate (CTR) to be correlated with the average CTR of her friends. However, simply calculat-ing correlations between aggregate CTRs may not suffice, for two reasons. First, CTR can vary widely depending on aspects of the content (e.g., the content creator, such as the owner of a Facebook page for page posts, or the adver-tiser for an online ad) and the context in which the content was shown (e.g., desktop or mobile, news-feed or user-profile page, etc.). Hence, we compute CTR correlations only be-tween CTR user ( A, C ) and the average CTR friend ( A, C )for all content by content creator A shown in context C for which both the user and some friends have enough impres-sions 1 . Second, there might be unknown biases due to the content-serving system, such as implicit connections between the number and kind of content a viewer sees and the num-ber of friends in her social network. Hence, we need a baseline correlation that abstracts out just the Facebook so-cial network while leaving other variables unchanged. We achieve this by computing correlations on randomly gener-ated graphs where each user has the same number of friends as in the Facebook social network, but the friend-list is ran-dom [1].

We present correlations computed specifically for the case of ads shown on Facebook. Based on data collected over a short period in 2012, there were around 45 M users who had at least 50 impressions on some ( A, C ) pair, and the induced subgraph had 2 . 3 B friendship edges. We found a correla-tion of 0 . 273 for this subgraph, but only 0 . 167  X  0 . 002 for the random graphs (correlations were calculated over many randomly generated graphs to get the 95% confidence inter-vals). The significantly higher correlations as compared to the baseline can only be due to the actual choices made by users in forming the social network, and it implies that ad clicking behavior of users and their friends are similar. This motivates our efforts to exploit such similarity in the click prediction problem, which we discuss next.
Our goal here is to speed up large-scale learning in the presence of related features, under conditions of feature skew and sparsity: any single training example is likely to have only a few  X  X ctive X  features, and the frequency of activations of various features is likely to be very skewed over an entire training corpus. For the sake of concreteness, we shall fo-cus on binary features of the form { value= x } , where the valuecouldbeuser-IDwithanassociatedsocialnetwork, or a histogram bin for the case of a binned ordinal variable such as average time spent on Facebook, etc. In large-scale learning, the cardinality of such feature sets is by definition very large, which leads to slow learning. Sparsity limits tra-ditional learning methods to updates of only a few features at a time, and skew implies that a large fraction of features might receive relatively little training data overall, both of which only accentuate the problem. This emphasizes the need of the solution we propose.

Our solution can be applied to any model linking feature weights to the response variable, as long as it uses distri-butions on the weights instead of point estimates. This is because confidence intervals on the weights can be very dif-ferent due to skew in the training data, and without knowing these confidences (equivalently, variances of the weights), it is impossible to correctly propagate information between re-lated weights, or analyze the resulting algorithm. For our experiments, we use the following model [7]: Here, y is the response variable (say, click or not), x the binary feature vector, w the weight vector, and  X  aknown
An impression is one instance of showing the content to a user. We require at least 50 impressions of content cre-ated by A to be shown on context C for inclusion in the correlation calculation. scaling factor. This is a probit model where the components w i of the weight vector are marginally independent. Call this model NoSocial .
 Now, suppose features u and v are known to be related. In the interest of clear exposition, we resume our running example of ad click prediction in the social network: u and v could refer to users who are friends (henceforth, u  X  v ), for which we have already established a positive correlation in Section 3. This observed correlation can be incorporated into the model by positing dependence between w u and w v Specifically, we can add in an extra  X  X ocial prior X  in the marginal of w : p ( w )= N 0 , diag  X  2  X   X  u  X  v N w u  X  w v ;0 , X  2 sp (3) Call this model SocialPrior . Here,  X  2 sp is a constant  X  X ocial prior variance X ; smaller values lead to tighter coupling of weights, with  X  2 sp = 0 implying identical weights for neigh-bors. We emphasize that this formulation can be extended to any setting where a similarity graph between features is available, and we shall discuss examples of these in Section 5. Learning the weights. To learn the weights, we turn to a message-passing schedule: whenever a weight is updated (e.g., when new data becomes available), a corresponding message is passed to its  X  X eighboring X  weights (see [4] for an introduction on the topic). However, computation of the exact posterior is intractable, for two reasons: (1) the form of Equation 1 makes the determination of the exact message from the data y to the weights w i difficult, and (2) the presence of loops in the social friendship graph means that message-passing need not converge, and need not yield the correct posterior variance even if it does converge [16].
The solution is to use approximations instead of the exact posterior. The first problem (which exists even in NoSocial ) can be approached by using an approximation based on Ex-pectation Propagation, as in [7]. For the second problem, we perform message-passing on a restricted set of links such that convergence is guaranteed but the results are again approxi-mate. In particular, if user u is being shown the content, we only perform message passing on edges u  X  v .Thissetof edges is singly-connected so the message-passing algorithm converges, but it ignores (a) any links to users that are not direct friends of u , and (b) any links v  X  v where both v and v are friend of u . Note, however, that every link partic-ipates in message-passing at one time or another unless both users at its X  endpoints never see new content, and ignoring completely inactive users is intuitively reasonable. In this way, both problems mentioned above can be addressed by a message-passing solution that takes O ( X  K ) time, where K is the maximum number of active weights for any training example, and  X  the maximum neighborhood size.

However, there is another inherent problem with this model  X  either the social prior variance  X  2 sp must be large, or the variance of w i must be small (in a sense that we will soon make precise). The former would imply that the compo-nents of w draw very little  X  X trength X  from their neighbors, defeating the very purpose of a social prior, while the latter renders the model inflexible even before any data is observed. Next, we state these notions precisely.
Formally, our model may be represented as a weighted graph G =( V,E ) where V is the set w i ,eachhavingastan-dalone X  X rior X  X actor N (0 , X  2 i ), and E = { ( i  X  j,  X  2 is a set of edges as discussed above, along with a corre-sponding social prior variance  X  2 ij (this is a generalization of Eq. 3). This weighted graph corresponds to the graphi-cal model of Eq. 3. As marginal inference in an arbitrary graphical model is difficult, and especially so in the presence of loops that we expect in social graphs, we develop bounds on marginals for the social prior model. Let G =( V,E )be such a graphical model, and G  X  be an extension of G that increases the precision (i.e., inverse variance) on edge i 1 / X  2 ij ( G  X  )=1 / X  2 ij ( G )+  X  (if the edge does not exist in G , it is created in G  X  ). Let p i = p ( w i ) be the marginal of node i (corresponding to w i ), and let  X  2 i be the corresponding variance. Then, we have the following lemma.

Lemma 1. For any k  X  V and  X &gt; 0 ,  X  2 k ( G  X  ) &lt; X  2
Proof. Clearly, p ( w ; G ) is a multivariate normal. De-note by A the inverse covariance matrix of p ( w ; G ). Then, expanding Eq. 3, we can show: Let M i and M j be the i th and j th columns of A  X  1 . Then, the covariance matrix A  X  1  X  for G  X  depends on  X  as follows: Thus, the variance of any k  X  V is a non-increasing function of  X  . From the smoothness of matrix inversion, the result follows.

This implies that addition of extra factors reduces node variances, so:
Corollary 1. For any G =( V,E ) and G =( V ,E ) such that V = V and E  X  E ,  X  2 k ( G )  X   X  2 k ( G ) . In particular, consider the subgraph G of G that consists of only the edges incident on i . This is a  X  X tar X  graph, which is singly-connected and hence the sum-product message-passing algorithm is guaranteed to converge and be correct.
On this star graph G ,let m ji be the precision of the message from j to i at convergence 2 .Let  X  i represent the precision of node i :  X  i =1 / X  2 i . Then, we can show the following:
Lemma 2. For G , we have:
More formally, if f represents the factor node connecting j and i , then there are messages from j  X  f and f  X  i ;we refer to the precision of f  X  i as m ji .

Proof Sketch. Standard message-passing formulas yield: The result follows from the solution of this equation.
We now have the tools to understand the problem inherent in the SocialPrior model. Consider a basic scenario where all social prior links are equally strong  X  2 ij =  X  2 sp ,andwewant every node to have the same marginal  X  i =  X  before any data becomes available. Noting that precisions in G are greater than those in the subgraph G (Lemma 1) yields the following basic corollaries.

Corollary 2. If all nodes have the same precision  X  i =  X &gt; 0 ,andnode i has degree deg( i )  X  2 , then:
Proof. Setting y =  X  2 ij  X  and using Lemma 2: This is a quadratic equation that is satisfied only when
Corollary 3. If all nodes have the same precision  X  i =  X &gt; 0 , all social prior variances are identical  X  2 ij where  X  is the maximum degree of the graph and  X   X  2 . Note that, by Lemma 1, these results hold for G even though they were proved using the subgraph G .

The implication is that for a large social graph, the prod-uct of the social prior variance and the marginal precisions must be large ( X   X  5000 for Facebook). A model can spec-ify either a small  X  2 sp or a small  X  , but not both. A large  X  sp means that inter-node ties are weak, and nullifies the reasons for using a social prior, while a small precision  X  makes the model inflexible even before any data has been observed. Clearly, both situations are undesirable.
Even if the individual precisions  X  i are different, a similar result holds if all priors are the same  X  i =  X &gt; 0.
Corollary 4.  X  i  X  Proof Sketch. Use  X  j  X  1 / X  2 in Eq. 4.
 Again, either  X  2 sp must be large, or  X  i .

Another way to see the problem is in terms of the influence of new data on the marginals. As above, consider the case of  X  i =  X  and  X  2 ij =  X  2 sp . Suppose node i receives a message with precision  X  X  due to new observations.

Lemma 3. The change in precision of the neighbors of i in G (with  X   X  2 )duetoa  X  X  precision message to i is given by:
Proof Sketch. When  X  i =  X  , Lemma 2 yields m ji = m for all i, j and some constant m ,and  X   X   X  m .Now,the influence of the incoming message on some neighbor j of i is given by: The result follows from analysis of this expression. Thus, the effect of new data at any node propagates mini-mally through the graph, irrespective of the model X  X  exact specifications. Qualitatively similar results hold even for dis-tinct  X  2 ij and  X  i ,aslongasthesum  X  i =1 / X  2 i + j  X  i is not dominated by any O (1) subset of the neighbors of i . Note that this result is not restricted to one particular form of the prior; while Eq. 3 corresponds to an L 2 regularization, any norm will face similar problems due to the equivalence of norms.
 Intuition. The social prior is essentially a set of con-straints: where w jk  X  w i . If the neighboring weights w j 1 ...w jn known, then w i could simply be estimated as the average of these; by the Central Limit Theorem, the variance in this estimate would asymptotically be  X  2 sp /n . Since the variance is just 1 / X  i ,weseethat  X  2 sp  X  i  X  n =deg( i ) asymptotically, and Corollary 3 is exactly the finite-size form of this result. The generality of the Central Limit Theorem reinforces our previous remark regarding the result being unaffected by the exact model specifications. The above discussion highlighted two problems with the SocialPrior model: limited flexibility in picking  X  2 sp and  X  , and limited propagation of influence. We now propose a model which alleviates the first problem, and also provides a useful parametrization for social priors.

Ideally, we would like to keep  X  2 sp small, so that social links have a strong effect on the joint distribution. How-ever, as we have seen, this leads to high precision  X  ,which leads to extremely low data likelihood if the means of the w i distributions are even slightly incorrect. To fix this, we introduce a new  X  X hadow X  variable w i for each w i ;thesocial prior is placed on the shadows w i while the X  X rue X  X eights w are drawn from their shadows with an additional variance: p ( w | w )  X  X  diag ( 0 ) , diag  X  2  X   X  u N w u  X  w The model can be generalized to set different values of  X  and  X  in the different terms; we call this model ShadowPrior .
It might seem as if ShadowPrior is merely a reparametriza-tion of SocialPrior , and that if we marginalized out the shadow variables, we would get an instantiation of SocialPrior with specific  X  2 ij values. However, this is not so.

Lemma 4. ShadowPrior is strictly more general than So-cialPrior .

Proof. Every SocialPrior model can be trivially encoded as a ShadowPrior by setting all  X  i =0. Toseethat Shad-owPrior is a strict superset, consider a node i and two of its neighbors j and k .Bysetting  X  i  X  X  X  in ShadowPrior ,we can have w j ,w k  X  w i . In particular, if  X  j =  X  k =  X   X  i k =0,thenweget w j = w k for any value of w i . This is impossible in SocialPrior ;tohave w j = w k ,wemustset  X 
In ShadowPrior , only the shadow variables are involved in the social prior and hence can have high precisions  X  i  X , but the precisions  X  i of the  X  X rue X  weights w i can be different: This is an increasing function of  X  i  X , but with an upper bound of  X  i =1 / X  2 +1 / X  2 for very large  X  i  X . Thus, the precision of the true weights is always under control, and the data likelihood does not fall too low.

However, this still does not solve the problem of limited influence propagation.

Lemma 5. In ShadowPrior , the change in precision of a neighbor j of i in G (with  X   X  2 )duetoa  X  X  precision message to i (with deg( i )  X  2 )is: influence  X   X  X   X  (  X  ) 1 where  X  =  X 
Thus, the shadow variables enable us to have strong so-cial links (low  X  2 sp ) and still have relatively wide marginal precisions  X  i , which was impossible under SocialPrior .How-ever, this is achieved only by breaking the direct connection between the weights w i ; now, the weights corresponding to i  X  j are connected via a long path w i  X  w so the problem of poor influence propagation remains. The problem is that we have not fixed the underlying cause  X  the constraints placed by the Central Limit Theorem. For this, we must try a very different approach, discussed next.
All models discussed above suffer from the problem of poor influence propagation: a increase in precision of  X  X  causes only O (1 / deg 2 ) change in the neighboring precisions. This would cease to be a problem if we could only restrict the degrees of the nodes, e.g., by deleting all but the top-k most  X  X mportant X  social links for each node. Recalling the intuition from the analysis of SocialPrior , if only a constant k links are active, then the Central Limit Theorem does not apply, and hence the ill-effects on precisions do not mate-rialize. The top-k neighbors may be picked manually, but they might not be optimal for the learning algorithm. Ide-ally, the algorithm should learn the top-k edgesaswell;this motivates our next model.

Instead of the normal social prior N w u  X  w v ;0 , X  2 sp the MixturePrior model uses a Gaussian mixture to represent social links: where  X  uv is the mixing proportion, and L is some large number that we will later send to infinity. Intuitively, the link is  X  X resent X  only when the hidden variable z uv =0,and the probability of this occurrence can be tuned via  X  uv .For example, to retain at most k edges for every node, set: Computing the messages. While MixturePrior expands the expressiveness of the basic model, the marginal distri-butions and the update messages are no longer Gaussian, but instead are Gaussian mixtures; a node with degree d will have a marginal distribution composed of 2 d Gaussians. Clearly, approximations are required, and we choose to ap-proximate the marginals (and hence the messages across the social links) as Gaussians. However, instead of approximat-ing each message independently, we use Expectation Prop-agation to jointly approximate the messages [12]. This has the property that for any single social link, the approximate messages for that link are the best approximation to the ac-tual Gaussian mixture for that link, given the approximate messages for all other social links.

Paraphrasing Eqs. 6-8, the social link between each pair of neighbors i and j is represented by a factor:  X  ( w i ,w j )=  X  ij N ( w i  X  w j ;0 ,L 2 )+(1  X   X  ij ) N We approximate this factor as  X  ( w i ,w j )  X  t ( i ) ij where the two terms on the right are Gaussians that depend only on w i or w j respectively. The joint distribution of Eq. 3 is then approximated by p ( w )= N diag (  X  ) , diag  X  2  X  ij  X  ( w i ,w j ) (10)
Intuitively, the approximate factors t ( i ) ij ( w i )and t correspond to Gaussian messages sent from j to i and vice versa (i.e., m ji and m ij respectively). In Expectation Prop-agation, we set the their parameters iteratively; given the current approximations for all other factors, t ( i ) ij ( w t ij ( w j ) should be set so as to minimize the KL-divergence between (a) the distribution obtained by replacing the prod-and (b) the approximate joint of Eq. 11.

For ease of notation, we shall use N  X  1 ( . )todenotethe normal distribution in terms of its X  X recision X  X nd X  X recision-mean X ; N  X  1 ( x, y )= N ( x/y, 1 /y ). Then, let N  X  1 ( w be the product of all terms in Eq. 11 that depend on w i , except t ( i ) ij ( w i ); these consist of the prior term the approximate messages from all other neighbors of i .Let N that the products are Gaussian due to the assumed normal-ity of the approximate messages. Then, as we take L  X  X  X  (i.e., remove the link between i and j with probability  X  Expectation Propagation leads to the following equations: The precision and precision-mean of t ( j ) ij ( w j )canbecom-puted similarly.

As a sanity check, consider the case of  X  ij =0,which corresponds to having all social links be connected in the social prior. In this case, we find: which is exactly the message that would be computed for a social link under SocialPrior . Conversely, when  X  ij = 1 (i.e., no social link), we find p = pm =0 , just as expected.
We can also compute the message as a function of the marginal precisions  X  i .

Lemma 6. If  X  i =  X   X  i and  X  ij &gt; 0 , Proof Sketch. Proved using Eqs. 12-15.

Note that, for consistency, the marginal precision must be at least the sum of the incoming messages: which can be achieved for any degree deg( i )bysetting  X  ij close enough to 1. This allows flexibility in setting  X  2  X  , which was one of the weaknesses of SocialPrior .
As for the earlier models, we can compute the influence propagated from one node to another.

Lemma 7. In MixturePrior , with the mixing proportions  X  ij set as in Eq. 9, the change in precision of a neighbor j of i in G due to a  X  X  precision message to i ( deg( i )  X  Proof. The proof follows easily from Eq. 13.

Note that this O (1 / deg( i )) rate compares favorably with the O 1 / deg 2 ( i ) rate obtained from previous models.
Thus, we have finally achieved our desiderata: we can combine strong social priors (low  X  2 sp ) with relatively wide marginals (small  X  i ), and still have much better influence propagation than SocialPrior or ShadowPrior .Thisisbe-cause, intuitively, only a constant k of the links are active for any node in the social graph, so the corresponding k mes-sages dominate the rest. Hence, the Central Limit Theorem no longer applies, freeing us from its strict constraint.
There is one final issue that affects all versions of the social prior discussed above. Typically, the effect of a prior dimin-ishes over time, and eventually vanishes as enough data be-comes available. However, this process is much slower with the social prior: stronger evidence from data is countered by stronger messages from neighbors, since the neighbors get new data as well. Thus, for any one feature, the social prior and the evidence from data remain roughly balanced throughout.

Since the goal of the social prior was to speed up learning, it should be X  X isengaged X  X nce enough data is available to de-termine the feature weights from evidence alone. Hence, we stop performing message updates to weights whose variance drops below a threshold, allowing it to change henceforth only through evidence from data.
For our experiments, we implemented all the social prior models as part of an online learning system: for each new example, the algorithm first predicts the outcome (click or not), and then uses the true outcome to train. Model pa-rameters must ensure that the initial precisions  X  are small enough, or else learning from data would be too slow; we set  X  = 1. By Corollary 2, this lower-bounds  X  2 ij for both SocialPrior and ShadowPrior ; in fact, if we want  X  2 ij =  X  then  X  2 sp  X   X  / X  = 5000 for Facebook (Corollary 3). Only for a line graph ( X  = 2) places no constraints on  X  2 sp .
On the other hand, this problem never arises for Mix-turePrior , as we saw from the discussion after Lemma 6. Here, we can use any combination of  X  and  X  2 sp ,aslong as  X  ij is set as in Eq. 9; we use k = 3, meaning only 3 top social links will be (probabilistically)  X  X ctive X .
While the discussion until now has focused on the social-features context, the methods we derived are far more widely applicable. Indeed, what we have is a framework for learn-ing feature weights with known pairwise relationships. We shall look at two such cases, with features derived from (a) histograms bins, and (b) trees.
Continuous-valued features, such as a user X  X  age or average time spent on a web portal, can be incorporated in a learning framework by converting them into categorical features by binning them, and then learning a separate weight for each bin. If the number of bins is large enough, this can closely approximate the true effect of the feature. However, the weight for each bin must be learned independently. This forces a trade-off between time to convergence (better with fewer bins) against prediction accuracy (better with more bins). In fact, this problem exists for any ordinal feature that is used as a categorical variable.

The root cause of the problem is that the ordering of the bins is forgotten, and the smoothness of feature weights as a function of feature values is ignored. However, our methods can be easily applied here: each bin is linked to its adja-cent bins (its  X  X riends X ) by the social prior. This creates a line graph, with correspondingly simple message-passing updates. In fact, message-passing is guaranteed to converge correctly on this graph.
Histogram bins are simply intervals in feature space on which pairwise distances can be specified. Intervals can be easily generalized to  X  X egions X  of feature space, as long as some reasonable distance between regions exists.

Forexample,ifonlinecontentcanbeplacedintoaknown taxonomy, then the leaves of the taxonomy represent such regions, with the tree metric giving a distance between them. Thus, each leaf of the taxonomy becomes a feature, and a  X  X ocial X  prior can connect close leaves, with the prior vari-ance  X  2 sp depending on the distance metric.

A similar idea holds for, say, leaves of a random forest or boosted decision trees created using some historical data. These leaves can then be used as extra features in a learning algorithm, possibly in addition to the features on which the trees were originally built. However, in this case, leaves from the same tree should not be connected, since the tree construction algorithm specifically tries to find regions in feature space that are maximally distinct. Thus, the tree metric is inapplicable, and we need some metric between leaves of different trees.

Noting that each leaf in a decision tree corresponds to a set of (possibly open-ended) feature intervals, we propose using the fraction of overlap between these intervals as a measure of similarity between leaves. Only leaves that reference the same set of features are comparable in this manner; how-ever, evidence from a large real-world content-serving sys-tem shows that even with this restriction, many leaf pairs show significant overlap. The  X  X ocial graph X  between leaves is no longer a simple line graph, as with the histogram bins above, but is rather close to a set of quasi-cliques. Another related distance measure is the closest L 1 distance between any two points from the two leaves, with the distance being 0 for overlapping leaves. In our experiments, we find that both these distance measures yield similar results.
The primary purpose of the social prior was to speed up the learning process, and this is the question we investi-gate next. We present experiments on two problem settings. The first, called F eeds, involves predicting clicks on Face-book news-feed stories, with the user-ID as a feature. The data consists of a sample of around 100 M stories presented toa3 . 5 M -strong subset of Facebook users, with around 410 M undirected friendship edges between them. The sec-ond, called A ds, involves predicting clicks on ads using 18 different ordinal features bucketed into 100 bins each. In both problems, training and prediction are performed on-line: for each new example, the algorithm first predicts the outcome (click or not), and then uses the true outcome to train. Clicks, non-clicks, and the set of users are all sampled separately, so the reported accuracy should not be thought of as the  X  X rue X  accuracy of the current Facebook systems.
We measure accuracy with Normalized Entropy (NE), de-fined as the ratio of model log-likelihood to the observed entropyofoutcomes(clickornot).ANEof1.0corresponds to a random predictor that knows the correct fraction of clicks in the dataset, and lower values are better. Accuracy on F eeds.

For F eeds, the weights for the user-ID features are related via the social network which has a maximum degree of  X  = 5000. As discussed in Section 4.5, we must have  X  2 sp &gt;  X  / X  for both SocialPrior and ShadowPrior , and even a modest initial marginal precision of  X  =1 . 0implies  X  2 sp &gt; 5000, and translates into almost no influence of a weight on its neighbors (Lemmas 3 and 5). Indeed, in our experiments on F eeds, the results from SocialPrior and ShadowPrior were in-distinguishable from NoSocial , even after using the smallest  X  ij allowable by Corollary 2; hence, we do not separately show their results here. Only MixturePrior can reasonably decouple  X  and  X  2 sp , and is the only applicable model.
Figure 1(a) shows the results for various settings of  X  2 F eeds. We observe that any social prior at all is better than NoSocial ,with  X  2 sp =0 . 01 being the best (  X  2 sp =0 . 001 is also almost identical). The benefits of a social prior are greatest when the fewest training examples have been seen, which is when there is the least evidence from data. The gain can be characterized by the number of extra training examples needed by NoSocial to replicate the accuracy of MixturePrior : in F eeds, this is around 12 M training examples. Indeed, MixturePrior remains better than NoSocial even after 60 M examples. Both of these demonstrate the impressive utility of the social prior.

Also, below a certain  X  2 sp (  X  0 . 01), there are very little dif-ferences. Thus, choosing the  X  X ptimal X   X  2 sp is not necessary as long as it is in the right range. Figure 3: NE against the variance threshold for F eeds: Without a threshold, the social prior is too restrictive when enough data becomes available.
 Accuracy on A ds. Recall that the A ds problem has binned features, whose relationship structure is given by a line graph (each bin is similar to its adjacent bins). Since the maximum degree  X  = 2, the constraint of Corollary 3 is always sat-isfied, so SocialPrior can use any  X  2 sp . Hence, in this case, we report results using SocialPrior ; the more complicated models can offer no further gains.

Figure 1(b) shows the results. Once again, the social prior leads to significantly faster learning, with  X  2 sp =0 . 001 be-ing optimal but  X  2 sp =0 . 01 being almost as good, implying that picking the optimal value is not as important as be-ing in the correct range. Note that NoSocial does not reach the accuracy for SocialPrior with  X  2 sp =0 . 01 even after 1 M training examples, and its rate of improvement is very slow. Thus, we can conclude that the social prior yields significant speed-up not only in the initial stages of learning, but also in reaching convergence.
 Sensitivity to the top k . Figure 2 plots NE as a function of the top k important edges used in the mixing proportion  X  ij in MixturePrior (Eq. 9). The experiments are for F eeds, with  X  2 sp =0 . 01 everywhere. We see that k =3isnearly optimal, and there is not much gained by increasing k . This suggests that at least 3  X  X lose X  friends are needed to infer a user X  X  interests, and all our experiments use k =3. Importance of disengagement. Figure 3 shows the im-portance of the variance threshold below which the social prior is  X  X isengaged. X  Without any threshold, the NE de-creases the fastest initially, but stops improving far too early; this is because the social prior forces neighboring weights to move in lockstep, even if data indicates otherwise. Con-versely, a high threshold makes the model equivalent to NoSocial , which performs poorly initially. In our case, a variance threshold of 0.3 performs best.
 Effect of farther propagation. Instead of propagating messages from a node receiving new training data to its im-mediate neighbors only, we could also propagating further. However, this could slow down training, and hence the pre-diction throughput, in our online prediction setting. Hence, we consider two alternatives where propagation is done in a separate thread: (a) either all propagation of messages could be done in a separate thread, or (b) messages to immediate neighbors could be spread immediately, with further prop-agation being performed in a thread. Figure 4 shows the results for A ds. We see that (a) any form of propagation greatly outperforms the NoSocial case, and (b) propagating to just the immediate neighbors is almost as good as further propagations, while requiring the least CPU. This justifies the approach taken in the previous experiments. Figure 4: Propagating messages to immediate neigh-bors is almost as beneficial as propagating further. Smoothing of Weights. The social prior pulls related features closer together. To verify this, we plot the mean weight as a function of the bin number for several binned features in A ds (Figure 5). Since the binned features in A ds form a line graph, we expect a strong social prior (i.e., smaller values of  X  2 sp ) to lead to weights that vary smoothly as a function of bin number, and this is indeed observed.
Large-scale learning can be speeded up considerably if we can utilize known relationships between features; if two fea-tures are similar, then any new data affecting one can be propagated to improve our knowledge of the other. We proposed a  X  X ocial prior X  to achieve this in a Bayesian set-ting. Via analysis of this model, we showed that obvious instantiations of such a prior suffer from a significant weak-ness: any reasonably strong link between features forces the marginal variances to become too small, even in the ab-sence of data. We showed how a two-component mixture model can solve this problem, and presented update equa-tions based on Expectation Propagation for learning under this model. Experiments on large real-world click predic-tion problems on a subset of the Facebook social network shows that our method can save 12 M training examples in the initial part of the learning. On a separate problem, a social prior on binned features converges in less than a fifth of the time required by the baseline model. This clearly demonstrates the utility of the social prior. [1] W. Aiello, F. Chung, and L. Lu. A random graph [2] E. Bakshy, D. Eckles, R. Yan, and I. Rosenn. Effects [3] H. Bao and E. Chang. Adheat: An influence-based [4] D. Barber. Bayesian Reasoning and Machine [5] M. Gartrell, U. Paquet, and R. Herbrich. A bayesian [6] S. Goel and D. Goldstein. Predicting individual [7] T.Graepel,J.Q.Candela,T.Borchert,and [8] J. M. Hernandez-Lobato, D. Hernandez-Lobato, and [9] I. Konstas, V. Stathopoulos, and J. Jose. On social [10] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. [11] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King. [12] T. Minka. A family of algorithms for approximate [13] T. Sandler, P. P. Talukdar, L. H. Ungar, and [14] C. Wang, R. Raina, D. Fong, D. Zhou, J. Han, and [15] S. Wang, L. Yuan, Y.-C. Lai, X. Shen, P. Wonka, and [16] Y. Weiss and W. T. Freeman. Correctness of belief [17] Z. Wen and C.-Y. Lin. On the quality of inferring
