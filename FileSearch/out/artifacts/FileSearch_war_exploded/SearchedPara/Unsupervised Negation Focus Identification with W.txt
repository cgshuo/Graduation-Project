 Negation is used to reverse the polarity of part of statements that are otherwise affirmative by de-fault (Blanco and Moldovan, 2011), which is common in natural language. Negation focus is defined as the special part in sentence, which is most prominently or explicitly negated by a neg-ative expression. For example, sentence (1) could be interpreted as He stopped, but not until he got to Jackson Hole with a positive part he stopped and a negative part until he got to Jackson Hole . (1) He did n't stop until he got to Jackson Hole.
Our previous work (Zou et al., 2014) showed that contextual information plays a critical role on negation focus identification. For better illus-tration of this conclusion, they manually analyze the evidences for 100 negation focuses. It is sur-prising that 77 focuses can be identified with help of contextual information. This indicates that negation focus is often related with what authors repeatedly states in context. In this paper, we thus focus on graph-based ranking methods (Mihalcea and Tarau, 2004) which first build a word graph according to word co-occurrences within document, and then use random walk al-gorithms (e.g., PageRank) to measure word im-portance. 
However, for negation focus identification, the graph-based methods may suffer from the fol-lowing two problems: (a) the words in graph-based methods are strongly connected by co-occurrence rather than semantic content, which do not necessarily guarantee that they are rele-vant to the negation focus in context; and (b) identifying a negation focus may be affected by not only the relatedness of surrounding words but also its importance in current document which is not considered in standard random walk algorithms. 
To address the above problems, we propose a word-topic graph model by adding a topical layer on the original word layer to capture the seman-tic clues from both lexical and topic perspectives. Besides, a document-sensitive PageRank algo-rithm is also proposed to optimize the graph model by considering the document X  X  major top-ics. Experimental results indicate that our word-topic graph model outperforms other baseline methods. Moreover, our model is unsupervised and requires only un-annotated text for training. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 introduces our word-topic graph model with con-textual discourse information. Section 4 reports the experimental results and analysis. Finally, we conclude our work in Section 5. So far there is little work on negation focus iden-tification, which was pioneered by Blanco and Moldovan (2011) who investigated the negation phenomenon in semantic relations and proposed a supervised learning approach to identify the focus of a negation expression. However, alt-hough Morante and Blanco (2012) proposed ne-gation focus identification as one of the *SEM X 2012 shared tasks, only one team (Rosen-berg and Bergler, 2012) participated in. They identified negation focus by three heuristic rules. 
Our previous work (Zou et al., 2014) demon-strates the effectiveness of contextual infor-mation for negation focus identification. On this basis, we further optimize the graph model in both the topical layer and the PageRank algo-rithm in this paper. 
In recent years, many algorithms are widely used to incorporate word graph models and topi-cal information within random walk. Our work is originally inspired by Liu et al. (2010). Their method runs decomposed Topical PageRank (TPR) for each topic separ ately, and then calcu-lates the word scores with respect to different topics. When setting the edge weights, only word co-occurrence is considered. Different from their work, our word-topic graph model runs on a two-layers (word layer and topical layer) graph model and sets the edge weights by measuring both word similarity and topic distribution. The word-topic graph model consists of word layer and topical layer, as shown in Figure 1. While the word layer is constructed according to word co-occurrence within a sliding window, which expresses the cohesion relationship be-tween words in the context, the topical layer is to refine the graph model over the discourse con-textual information. 3.1 Constructing Word Layer The word layer is constructed according to word co-occurrence within a sliding window, which expresses the cohesion relationship between words in the context. It can be denoted as L word set of words in one document and link set E w ={ e ij | w i , w j  X  W } represents the set of directed edges between these words. Note that only con-tent words are considered. Namely, we consider nouns, verbs, adjectives, and adverbs. 
The link directions are added from the first word pointing to other words within a sliding s -width sentence window. Directed edge ew ij is weighted to represent the relatedness between word w i and word w j in a document with transi-malized as follows: where the denominator represents the out-degree of vertex w i , and sim ( w i , w j ) denotes the similari-ty between word w i and w j . In this paper, both corpus-based and knowledge-based methods are evaluated to calculate the similarity between words.  X  Word co-occurrence. If word w i and word w j  X  WordNet similarity (Miller, 1995). In this 
Note that sim ( w i ,w i ) = 0 to avoid self-transition, and sim ( w i ,w j ) and sim ( w j ,w i ) may not be equal. 3.2 Preliminaries for Topical Layer To infer the latent topic distributions of words, Latent Dirichlet Allocation (LDA) (Blei et al., 2003), a typical of topic model, is directly ap-plied. By the set of topics which derive from a corpus, we can obtain:  X  P ( t|w ), the probability of topic t given word  X  P ( t|d ), the probability of topic t given doc-
Then, the similarity between two words or be-tween word w i and document d can be measured by the similarity between their corresponding topic distributions. Formally, we denote a topic distribution as  X  , and measure the similarity by using:  X  Dot-product. We consider the topic distribu- X  Kullback Leibler (KL) divergence (Lin, 3.3 Word-Topic Graph Model The word layer can well capture the relatedness between words, but just partially model the nega-tion focus since it is more directly related with topic than content. Therefore, we add one more layer to refine the graph model over the topical information, as shown in Figure 1. Formally, the word-topic graph is defined as G topic ( W, T, E w , E t where vertex set T ={ t i } represents the set of top-ics in all of documents in corpus and link set E ={ et ij | w i  X  W , t j  X  T } represents the set of undi-rected edges between words and topics. 
Considering that the topical layer can provide more contextual semantic information, we refine the relatedness between words by using a topical transition probability P t ( j|i ) which is calculated by two kinds of measurements: Here, the similarity is measured by the dot-product or the KL divergence (using reciprocals). On this basis, the word transition probability P ( j|i ) is updated as following: where  X   X  [0,1] is the coefficient controlling the relative contributions from the lexical infor-mation and the topical information. 
Moreover, the weights of word vertices are calculated by a PageRank algorithm. In standard PageRank (Page et al., 1998), words are set to be the same value, which indicates there is equal importance to all of words in a document. How-ever, intuitively, we should allocate higher weights to those words with high relevance to the document. Therefore, we assign a document-sensitive value to word w i : and calculate the weights of word vertices itera-tively by using a biased PageRank algorithm: 
All of the PageRank algorithms are terminated when the number of iterations reaches 100 or the difference of each vertex between consecutive iterations is less than 0.001. 
Finally, according to the annotation guidelines (Blanco and Moldovan, 2011), the focus is al-ways a full text of a semantic role. Thus, we se-lect all of semantic roles in sentence as candidate focuses for ranking. The ranking score of a can-didate focus f is computed by averaging the scores of all words inside the candidate: where count ( f , X ) denotes the number of content words within the candidate. Then the top ranked candidate is chosen as the negation focus. To evaluate the performance of our word-topic graph model for negation focus identification, we carry out experiments on the *SEM'2012 shared task corpus 2 . As a freely downloadable resource, the corpus is annotated on top of PropBank, which uses the WSJ section of the Penn Tree-Bank. In particular, negation focus annotation on this corpus is restricted to verbal negations (Blanco and Moldovan, 2011). In total, this cor-pus provides 3,544 instances of negation focus annotations. Although for each instance, the cor-pus only provides the cu rrent sentence, the pre-vious and next sentences as its context, we sort to the Penn TreeBank 3 to obtain the corresponding document as its discourse context. For fair com-parison, we adopt the same partition as *SEM X 2012 shared task in our experiments. We evaluate our results in terms of accuracy. To see whether an improvement is statistically significant, we conduct significance testing using the paired t-test. 
For estimating the topical transition probabil-ity P t ( j | i ) and the document-sensitive value R d ( w we employ GibbsLDA++ 4 , an LDA model using Gibbs Sampling technique for parameter estima-tion and inference (Griffiths, 2002). We set the parameters  X  = 50/ T and  X  = 0.1 as Griffiths and Steyvers (2004) suggested. 4.1 Influences of Parameters There are two major parameters in our models that may influence the performance, including: (a) the damping factor  X  of the word transition prob-ability P  X  w ( j|i ) (Eq.(7)) and (b) the damping fac-tor  X  of the word-topic graph model (Eq.(9)). 
Figure 2 shows the accuracy when varying  X  from 0.1 to 0.9 with an interval of 0.1 and when varying  X  from 0.05 to 1 with an interval of 0.05. We notice that the best performance is achieved when  X  =0.6. It indicates that the direct lexical information contributes slightly more than the topical information. The results also show the complementarity between these two kinds of in-formation on negation focus identification. 
For  X  , it has very little, if any, effect on per-formance, when  X  is set from 0.5 to 0.85. It indi-cates that the contextual information (the first term in Eq.(9)) contributes more than the docu-ment information (the second term in Eq.(9)) on negation focus identification. Figure 2. Influence of the damping factors  X  and  X  . 
Moreover, the results also show that these two parameters have little impact in a certain range on performance (  X  :0.4~0.6;  X  :0.5~0.85), which suggests that the approach is robust to a certain extent. Therefore, we set  X  =0.6 and  X  =0.7 in the following experiments. 
Besides, we also evaluate the other minor pa-rameters in our model. Due to space limit, we do not report all of results he re and set parameters to the following values: setting window size s =1 (the previous and next sentences) and the number of topic T =40, adopting the word co-occurrence similarity to calculate the similarity between words, and using dot-product to measure both P ( j | i ) and R d ( w i ). 4.2 Comparison with Other Methods In the word-topic graph models, two primary improvements are proposed: (a) updating the word transition probability P w ( j | i ) by adding a topical layer ( X  X L X ), and (b) assigning a docu-ment-sensitive value to word node ( X  X S X ). 
Table 1. Performance of the word-topic graph 
Table 1 shows that the word-topic graph mod-el (WTGM) is significantly better (+16.78%, p &lt;0.01) than the graph model with only word layer (WLM), which justifies the effectiveness of the topical layer. In addition, the results also in-dicate that the word-topic graph model not only takes the topical information into account ( X  X L X ), but also considers the semantic relationship in current document ( X  X S X ). 
We select two supervised baseline methods to compare with our word-topic graph model. One is a decision tree-based system described in Blanco and Moldovan (2011), and the other one is a SVM-based system which takes advantage of both syntactic features and contextual features (Zou et al., 2014). 
Table 2 shows that our word-topic graph model performs significantly better than the two others by 6.19% (p&lt;0.01) and 2.25% (p&lt;0.01), respectively. The results support our viewpoint that the topical information in context can help to find the negation focus, and the word-topic graph model we proposed is effective. Moreo-ver, it is also worth noting that our method is unsupervised, which does not need the prior knowledge for training, while the other two su-pervised baselines employ the golden features, such as the POS tag, constituent tree, and de-pendency tree. In this paper, we propose an unsupervised word-topic graph model, which represents and measures the word importance by using contex-tual information from both lexical and topical perspectives. And then, we propose a document-sensitive biased PageRank algorithm to calculate the ranking scores of negation focus candidates. Experimental results show that our method achieves better performan ce than other baselines without any annotated data. 
The main shortcoming of our method is that not all of negation focus can be identified by the context. As our statistics, at least 17% of samples are hard to be determined by human beings when ignoring the information in current sentence. Therefore, in future work, we will focus on in-vestigating an effective method to integrate the local lexical/syntactic information and the global contextual discourse information. This research is supported by the National Natu-ral Science Foundation of China, No.61272260, No.61331011, No.61273320, and the Major Pro-ject of College Natural Science Foundation of Jiangsu Province, No.11KJA520003. The au-thors would like to thank the anonymous review-ers for their insightful comments and suggestions. 
