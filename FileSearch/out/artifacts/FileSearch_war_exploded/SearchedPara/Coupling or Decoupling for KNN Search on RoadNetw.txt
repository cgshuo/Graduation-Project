 We explore in this paper a new KNN algorithm, called the SQUARE algorithm, for searching spatial objects on road networks. Recent works in the literature discussed the ne-cessity to support object updates for promising location-based services. Among them, the decoupling spatial search algorithms, which separate the handle of the network tra-versal and the object lookup, has been recognized as the most effective approach to cut the maintenance overhead from updates. However, the queue-based network traversal needs to be performed from scratch for each KNN query un-til the KNN objects are exactly identified, indicating that the query complexity is in proportion to the number of vis-ited network nodes. The query efficiency is concerned for online LBS applications since they only allow lightweight operations for minimizing the query latency. To improve the query scalability while supporting data updates, SQUARE constructs the network index similar to the way used in de-coupling models, and meanwhile exploit the coupling idea to maintain the KNN information relative to hot regions in the network index. The hot region denotes the area with fre-quent queries discovered in the query history. Inspired from the prevalently observed 80-20 rule, SQUARE can maxi-mize the query throughput by returning KNN results in the quasi-constant time for 80% queries that are roughly issued within 20% area (hot regions). As validated in our exper-imental results, SQUARE outperforms previous works and achieves the significant performance improvement without sacrifice on the maintenance overhead for object updates. KNN query, Spatial databases H.2.8 [Database Applications]: Spatial databases and GIS Algorithms, Management Figure 1: Categorization of previous studies on Location Dependent Spatial Queries. As the number of mobile users is growing at rapid pace, Location-Based services (LBS) are becoming an area of in-creasing interests in recent years. Among them, the Location Dependent Spatial Queries (LDSQ for short), especially the most recognized LDSQ for searching k-nearest neighbors (KNN), has been deemed as an essential means to the suc-cess of LBS applications [17]. Research advances in the literature particularly concentrate on the consideration of user trajectories in road networks, which allows users seek-ing nearby objects in the metric of the network distance or the traveling time. An example of such LDSQ may like "Q: find five hotels with the shortest walking distance from the conference venue."
To achieve KNN queries on road networks, numerous ap-proaches have been explored [4][11][12][17][18]. Formally, these prior works can be classified into two major categories according to their manners of associating two basic oper-ations in processing LDSQ, namely, network traversal and object lookup [12]. The first category, as shown in Figure 1, is named as the "Coupling" approach, which indicates that the object information is intrinsically embedded in the network index structure. For example, the Distance Index algorithm [4] precomputes the distance signatures for all net-work nodes, where the distance signatures encode the infor-mation of paths towards individual objects. As such, the KNN result can be efficiently obtained by merely looking relative signatures. Clearly, since paths to objects can be precomputed and sophisticatedly indexed in such coupling methodologies, the required searching steps for some specific queries could be minimized, achieving the high efficiency for LDSQ.

Recent LBS applications call for the need of supporting data updates such as the insertion of new activities, the deletion of expired information, and the movement of on-going events. Unfortunately, aforementioned coupling tech-niques inevitably incur the prohibitively expensive mainte-nance overhead in such requirements due to the tight asso-ciation between the initial network topology and the object location [18]. The research direction thus turns to explore the alternative "Decoupling" methodologies [12][17][18], i.e., the second category in Figure 1. Essentially, the construc-tion of network index in this kind of algorithms is orthog-onal to the object locations. This property allows object updates in LDSQ applications without a significant perfor-mance sacrifice for the index reconstruction. Note that due to the lacks of object information in the network structure, the major concern in the decoupling model is how to avoid the blind node-by-node network expansion until KNN ob-jects are identified [12][18], as the way of the traditional Dijkstra X  X  algorithm [2].

The ROAD framework is the state-of-the-art decoupling framework for LDSQ [12], which explored a level-wise net-work structure, called the Rnet hierarchy, to facilitate cut-ting the overhead of the network expansion. Specifically, ROAD partitions the whole road network into a set of dis-jointed regional sub-networks, denoted as Rnets, in a pre-computing stage. Without taking the object distribution into consideration, the network partitioning procedure mainly follows the criterion that the interconnection between Rnets could be minimized. Each Rnet is equipped with two essen-tial functionalities for LDSQ: (1) check the object repository and answer whether the Rnet contains objects of interest; and (2) return all shortcuts, i.e., shortest paths between two border nodes of the Rnet, in the constant time, where a border is a network node connecting with nodes in an-other Rnet. Suppose that a Rnet does not contain can-didate objects of a KNN query, indicating that this Rnet can be logically viewed as a single node with outside edges equal to its set of shortcuts. The thorough network tra-versal within the Rnet can be bypassed and substituted by the set of shortcuts, thus leading to the better efficiency in comparison with the blind network expansion. More impor-tantly, supporting object updates is straightforward in the ROAD framework. Only the lightweight update operation in the object database is required, showing the robustness of decoupling models against the update effect.

However, the query latency still needs the further im-provement in current decoupling algorithms such as ROAD. The queue-based network traversal for verifying candidate KNN objects is necessary for each query. Clearly, the more network traversals and object lookups are involved, the larger the query processing overhead is incurred. The query effi-ciency cannot be guaranteed close to the constant time, indi-cating its performance concern for online LBS applications.
Therefore, we in this paper further explore the solution to support data updates while also minimizing the query over-head. Note that as compared to coupling approaches, decou-pling approaches is capable of supporting data updates with-out the need of the index reconstruction. However, using the decoupling concept inevitably compromises the chance to minimize the query overhead by referring to the object distribution. As thus, we consider to combine advantages of both models in this paper. A hybrid framework, called the SQUARE algorithm (stands for Spatial Query with User-pattern awAREness), is proposed in this paper. Specifi-cally, SQUARE builds the network hierarchy with borders and shortcuts which is used in the decoupling model ROAD. But the construction of the network index will further con-sider the query patterns to identify the hot regions with frequent queries in the history. For these specific partitions, we follow the coupling concept to embed the related KNN information in the network index. In light of the famous 80-20 rule [10], we can expect that 80% queries will be roughly issued within 20% area, i.e., these hot regions with frequent queries. SQUARE is devised with the capability to return KNN results of the majority of queries, i.e., queries issued within these hot regions, in the quasi-constant time, thus leading to the higher throughput as compared to previous works. In addition, same as decoupling models, SQUARE has the advantage to avoid the network reconstruction with respect to data updates. SQUARE requires another mainte-nance overhead to ensure that the maintained KNN informa-tion is up-to-date. With the help of some filtering strategies, the maintenance overhead of SQUARE will be inexpensive and comparable to that of the decoupling models.

The contributions of this work can be summarized as fol-lows: (1) While previous works generally need to initiate an expensive queue-based network search for every query with-out the bounded time cost, we consider a solution which can answer the majority of queries in the quasi-constant time. (2) SQUARE is the first paper considering the query pat-tern into the object search on road networks. Utilizing the 80-20 behavior shown in query patterns can facilitate the query processing. (3) We have devised in SQUARE good filtering properties and criteria to execute KNN recalcula-tion while data are updated. As such, SQUARE is capable of handling data updates with affordable maintenance over-head. (4) The result demonstrates that, instead of only pro-viding the flexibility of striking a compromise between the update support and the query efficiency, SQUARE can both achieve high query performance and low update cost, show-ing its prominent advantages to be the capability of online LBS applications.

The rest of this paper is organized as follows. Section 2 gives preliminaries including related works and the prob-lem description. In Section 3, we describe the design of the SQUARE algorithm. Section 4 discusses the handle for data updates. The experimental results are shown in Section 5. Finally, this paper concludes with Section 6.
We present related works in Section 2.1 and formalize the discussed problem in Section 2.2. Note that we focus on KNN queries in the metric of network distance. For the or-thogonal problem to retrieve KNN objects in the Euclidean space, interested readers can refer to [19][20] for details.
In recent years, a considerable number of studies have been proposed to retrieve KNN objects on road networks [1][6][11][17]. Among them, the INE (incremental network expansion) algorithm first exposes the issue and extends the Dijkstra X  X  algorithm to search KNN objects by gradually ex-panding the network space, and check if the objects associ-ated to the visited network nodes belong to the KNN result [17]. The procedure of network expansions is terminated while all KNN objects are identified. To further improve the query efficiency, a heuristic alternative is also devised in [17] to prune the unnecessary expansion of the search space according to the Euclidean lower bound properties, which state that the Euclidean distance is the lower bound of the network distance. However, the blind node-by-node query expansion in INE will inevitably face the performance issue in a huge spatial network.

Recent works thus moved to the direction of using some precomputed structures to facilitate the search of KNN ob-jects [1][4][5][11]. Note that two major operations are gener-ally involved in processing the KNN search, namely network traversal and object lookup. The operation of network tra-versal is used to visit network nodes according to network proximity, and object lookup is used to discover objects lo-cated in traversed network nodes and checks if the objects match the search criteria. Essentially, previous precompu-tation based approaches can be categorized as coupling ap-proaches and decoupling approaches according to their man-ners to associate network traversal and object lookup. We individually discuss these two approaches below Coupling Approaches: Intrinsically, the coupling approaches embed the object information in the index for network tra-versals. As shown in Figure 1, the coupling approaches can be further categorized as NN-embedded approaches and KNN maintenance approaches. In general, the NN-embedded methods embed the information of the nearest object for each network node in the network index, such as VN 3 [11], UNICONS [1], and SPIE [5]. Specifically, the VN 3 algorithm [11] generates network Voronoi polygons (NVP) for each ob-ject such that the object is the nearest neighbor for all net-work nodes inside the NVP. The KNN objects can be quickly obtained by checking NVPs around the NVP that the query is issued. The UNICONS algorithm [1] obtains KNN ob-jects by precomputing nearest objects for some condensed points, where condensed points are nodes with large fanouts. When the network search reaches a condensed point, the pre-computed NN lists can be retrieved directly to reduce the search space. In the SPIE algorithm [5], a network reduc-tion approach is used to reduce the road network to a set of interconnected trees. The nearest object for each node in the tree is then precomputed. In this method, the KNN objects can be obtained by traversing the tree without using the network expansion like the Dijkstra X  X  algorithm. Distance Index [4] is one of KNN maintenance approaches. It precomputes distance signatures for all network nodes. The distance signatures encode the information of all paths from each node towards individual objects. Therefore, the KNN results can be efficiently obtained by decoding the rel-ative signatures. Moreover, a cache based query algorithm is discussed in [7], which utilizes the LRU cache-replacement to maintain previous KNN results for future queries.
However, the coupling model is infeasible to support data updates for web-based LBS applications. Note that the net-work index is built based on the object locations. The up-date of objects will make the initial index invalid for KNN queries, and the reconstruction of the network index in-evitably incurs the expensive maintenance overhead. Decoupling Approaches: Recently, the object search on road networks turns to use decoupling approaches, which gener-ally do not consider the object distribution while construct-ing the network index. Such a property enables the decou-pling approach to support data updates without the need of the index reconstruction. Basically, the aforementioned INE approach is a kind of decoupling algorithms, i.e., the Euclidean distance bound approach as shown in Figure 1. In addition, the distance browsing algorithm exploits the phe-nomenon of path coherence to maintain the shortest paths between all nodes [18]. A non-incremental best-first algo-rithm is then used to retrieve KNN without blind network traversals. However, as discussed in [12], this method pays for the expensive precomputation overhead for all-pair short-est paths. In addition, the KNN search in this work still needs a node-by-node fashion until KNN objects are identi-fied.

The ROAD algorithm is the state-of-the-art decoupling framework [12], which exploits the network hop concept to avoid blind node-by-node expansions for KNN queries. In ROAD, the whole road network is initially partitioned into a set of disjointed regional sub-networks, called Rnets. The network partitioning procedure follows the criterion that the interconnection between Rnets could be minimized. After-ward, the set of borders in each Rnet is identified, where a border is a network node connecting with nodes in another Rnet. In the meanwhile the shortest paths of all pairs of borders within a Rnet, called as shortcuts, are precomputed and maintained. While a KNN query is issued, operations of the network expansion within a Rnet can be skipped and completely substituted by shortcuts if no required object is located within the Rnet. Essentially, the search space prun-ing in the ROAD algorithm is specifically favorable to the huge network with the relatively small set of objects. While objects are densely distributed in the network, such as the case of restaurants in the metropolis, all KNN objects are likely to locate within the Rnet of the query or its neighbor Rnet. The search space will not be effectively reduced by the hop across Rnets. In worse cases, ROAD is degenerated to the INE algorithm without valid space pruning.
We introduce the notations and definitions used hereafter and then formalize the problem. Suppose that a road net-work is modeled as a graph G consisting of a pair ( N, E ) , where N is a set of nodes, and E is a set of edges connect-ing the nodes. A node n  X  N represents a road junction or a starting/ending point of a road segment, and an edge e = ( u, v )  X  E represents a road segment that connects node u and node v . The weight of the edge, denoted by edges ( p i , p i +1 )  X  E for 1  X  i  X  l  X  1 . The weight of this path is defined as the sum of the weights of its constituent edges, i.e., | p | = l  X  1 have more than one path between two network nodes u and v . In this model, the shortest path is used to represent the network distance between two nodes u and v , which is de-noted by d N ( u, v ) (here the suffix symbol N means that the distance is the network distance). The Euclidean distance between u and v is notated as d E ( u, v ) correspondingly.
Consider a set of data objects O = { o 1 , o 2 , ..., o m where each object contains the information of its location and its active time period. Note that the time information of objects is requisite in the model of supporting data updates. For simplicity, we present the model based on the static objects in Section 2 and Section 3. The update and time issues will be discussed in Section 4. Specifically, we can logically transform the location of the object o i to be the location of node v plus d E ( v, o i ) , where d E ( v, o Euclidean distance between v and o i , and v is the nearest node of o i . Therefore, the location of the object o i can be generality, we can associate the node v for o i in the object repository.

The spatial query q j for KNN objects consists of two pa-rameters k and loc ( q j ) , where k is the number of nearest objects to discover and loc ( q j ) denotes the location of q Similar to the handle of object locations, loc ( q j nearest node of q j . For ease of exposition, we simply assume the query q j is issued in the node v . It is a matter of im-plementation to precisely calculate the distance by further checking d E ( v, q j ) .

Inspired by the ROAD algorithm [12], we also consider to build the network index as a form of the graph hierarchy, which can benefit to prune the search space hierarchically. Here we first give the definitions of subgraphs and the graph partitioning below.
 Definition 1 (Subgraph): Let a subgraph G s = ( N s be a subset of road network G, where N s  X  N and E s { ( u, v ) | u, v  X  N s  X  ( u, v )  X  E } .
 Definition 2 (Graph partitioning): A graph G = ( N, E ) can be partitioned into a set of disjointed subgraphs { G ( N definition for the graph partition is stated as follows. 1) N 1  X  ...  X  N k = N , and N i  X  N j =  X  for 1  X  i, j  X  k , i = j . 2) E i = { ( u, v ) | u  X  N i , v  X  N i } , and E 1  X  E 2 3) E B = { ( u, v ) | u  X  N i , v  X  N j , where i = j } , and E 4) E 1  X  E 2  X  ...  X  E k  X  E B = E
Several graph-partitioning methods have been proposed to achieve graph partitioning [8][9]. The general criterion used in these graph partitioning methods is to separate the graph into subsets of roughly the same size and the connections between the subgraphs are as minimal as possible.

Formally, by recursively applying the graph-partitioning algorithm in a top-down manner, we can generate the graph hierarchy. Two parameters, i.e., l and p , are thus consid-ered when constructing the graph hierarchy, where l de-notes the number of levels in the hierarchy, and p denotes the partition factor. Initially, the graph hierarchy is con-structed by setting the whole graph as the root. We then apply the graph partitioning algorithm to segment the par-ent graphs/subgraphs to p smaller child subgraphs recur-sively. An example of the graph hierarchy with l = 2 , p = 3 is shown in Figure 2. The root level, i.e., level 0 in Figure 2, represents the entire network graph. Three subgraphs in level 1 are generated by partitioning the entire graph in level 0. Each of the subgraphs in the level 1 is further divided into three smaller subgraphs in level 2.

We state below the important concept of borders and shortcuts, which are used in the graph hierarchy to efficiently prune the search expansion in the subgraph.
 Definition 3 (Borders): In a subgraph G s = ( N s , E s set of border nodes V b is a subset of N s , where V b = { u | u  X  N s  X  X  X  (u,v) /  X  E s , v /  X  N s }.
 Definition 4 (ShortCuts): For a subgraph G s = ( N s with the border set V b , the shortest path between two bor-ders v i and v j is referred to as shortcut s i,j , i.e., s d ( v i , v j ) . Shortcuts in G s is thus defined as SP ( G { s
Consider the example in Figure 2. The subgraph G 2 2 con-tains three borders, i.e., a , b , and c . In addition, the sub-graph G 1 2 in level 1 contains two borders g and h , which connect G 2 2 to other subgraphs G 2 3 and G 2 7 . Note that the borders and shortcuts in each subgraph can be identified and calculated after the network partitioning is completed. As discussed in [12], we can traverse the graph hierarchy and utilize the shortcuts to skip the network expansion in the subgraph. We roughly present the concept in the following example. The formal discussion can be found in [12]. Example 1: Consider the graph in Figure 2. Suppose an ob-ject is located in G 2 7 and a query is issued at G 2 3 . A priority queue is initiated for the network traversal. The search is gradually expanded until reaching the border node f of G 2 In generally, the KNN search needs 3 hops for G 2 4 , G 2 G 6 before reaching G 2 7 . But since we can check the parent subgraph G 1 2 and find it does not contain objects, the short-cut between g and h in G 1 2 can be used to substitute for the full network expansion in G 1 2 . Finally, one hop is sufficient for searching toward G 2 7 . Clearly, the KNN search can be achieved by checking only a partial nodes in G 2 3 and G 2
Based on the foregoing, our objective to search KNN ob-jects on road networks can be further transformed to search objects on the graph hierarchy. In Section 3, we will discuss how to embed the KNN information in the graph hierarchy for further improving the KNN search efficiency.
In this paper, we explore a new framework for KNN spa-tial queries, called the SQUARE framework. SQUARE stands for Spatial Query with User-pattern awAREness, indicating that we take the user query history into consideration. The overview of the framework is illustrated in Figure 3. Three major components are included in the frameworks, namely (1) graph hierarchy construction; (2) graph hierarchy main-tenance, and (3) the KNN search functionality. We describe the graph hierarchy construction and the KNN search in this section. The graph hierarchy maintenance will be discussed in Section 4.
Since the first observation of the power-law relationship in [21], the skewness phenomenon has been successively discov-ered in many real data [3]. The phenomenon is also famous as the name "80-20 rule" [10]. The existence of the 80-20 rule has been identified and applied to geographic applica-tions [16], which stated that 80% data are roughly located within less than 20% area 1 . Inspired by such a nature of geographic data, we apply the query history to identify so-called hot query subgraphs which contain frequent queries in the history.
 Definition 5 (Hot Query Subgraph): Given the frequency threshold  X  and the maximum node number within a hot query subgraph  X  , we have the hot query subgraph G ( N h ,E h )  X  G s , where N h = { u | f u  X   X  } , E h = { ( u , v ) | u,v  X  N h } , | N h |  X   X  , and f u is the number of queries issued in u .
For ease of exposition, the hot query subgraph is abbre-viated as HQgraph in the sequel. It is expected that the majority of future queries will issue within all discovered HQgraph. Essentially, we can precompute the KNN results for all network nodes in HQgraph. For cases that objects are not updated, the answer for queries issued within a HQ-graph can be straightforwardly returned, resulting in high throughput and constant-time query efficiency. Note that such a solution is generally used in coupling models. How-ever, when objects are inserted or deleted frequently, the overhead to maintain up-to-date KNN data is computation-ally expensive. Even worse, nearby nodes are likely to have similar KNN data [18]. The information redundancy in-evitably incurs the unnecessary storage cost.

To provide the flexibility of striking a compromise be-tween the query efficiency and the maintenance overhead, only KNN information of borders in HQgraph are precom-puted and maintained in the SQUARE framework. For cases that queries are issued in the interior node of a HQgraph, Lemma 1 shows the property to conduct their KNN results. Lemma 1: Suppose that we have a HQgraph G h with the border set V b ={v 1 , v 2 , ..v p } and a query q issued in node u in the HQgraph, where u /  X  V b . The KNN result of q is the subset of the union set of K 1 , K 2 , ..., K p , O h the KNN result of the border v i and O h is the set of objects located in G h .
 Proof: (Proof by Contradiction) Assume o i belongs to KNN objects of q , and o i /  X  { K 1  X  K 2  X  ...  X  K p  X  O h } . The network distance between o i and q is d N ( v b , q ) . Let v b be the border which has minimum d N ( v b , q )+ d N ( v b , o i ) . According to the shortcut property, we have d N ( v b , q ) = d N ( v b , q )+ d In addition, since o i does not belong to the KNN result of v , we have d N ( v b , q ) + d N ( v b , o b j ) &lt; d N is one of the KNN result of v b for 1  X  j  X  k . Note that
The skewness phenomenon can also be found in many pub-lic websites for geographic data. For example: http://www.cs.fsu.edu/~lifeifei/SpatialDataset.htm Figure 4: Examples of Hot Query subgraphs and condensed graphs. we have d N ( o b j , q )  X  d N ( v b , q ) + d N ( v b , o d ( o b j , q ) &lt; d N ( v b , q ) for 1  X  j  X  k . Since the number of o j is k, it is not possible to include o i into the KNN set of q and thus contradicts our assumption. Q.E.D.
 Procedure: HQgraph_construction():
In light of Lemma 1, for a query issued in the interior node of a HQgraph G h , we could return the KNN result by traversing nodes in G h plus the KNN data of borders in G While the size of G h is relatively smaller than the size of general subgraphs, using HQgraph can help to achieve the quasi-constant query efficiency. We defer the discussion on the maximum number of network nodes in a HQgraph to Section 4.

An illustrative example of HQgraphs is given in Figure 4(a), which contains two HQgraphs G h 1 and G h 2 . For G we need to precompute the KNN objects of two border nodes. The other three interior nodes in G h 1 can utilize the KNN results of borders instead of precomputing their own KNN objects.
 The procedure to find hot query subgraphs is outlined in Procedure HQgraph_construction. There are three algo-rithm inputs: the graph G , the query logs Q , the frequency threshold  X  and the maximum number of nodes in a HQ-graphs  X  . Initially, the query frequency of each node in G is calculated by checking Q . We can obtain the node set S where the query frequency of the node is higher than  X  . To generate a hot query subgraph, we start by randomly remov-ing a node u from S , and execute network expansion from u . Each unvisited neighbor node d of u is checked whether it is an element of S or not. If d also belongs to S , we add d into the same subgraph, and insert d to the queue while also removing d from S . The first element of the queue is iteratively popped up and checked until the queue is empty. After the HQgraph is identified, a node from S is randomly selected again to find other hot query subgraphs until the S is empty.
Here we present the construction of User-Pattern-Aware graph hierarchy, called the UPA hierarchy, by integrating HQgraph into the general graph hierarchy discussed in Sec-tion 2. Specifically, to ensure the integrity of the HQgraph, each HQgraph is treated as a predetermined leaf subgraph. For partitioning the graph into the intermediate level, the HQgraph can be logically condensed to a node with the number of fanouts equal to its number of borders. Note that graph partitioning methods [8][9] generally include two criteria to separate the graph: (1) generating subgraphs of roughly the same node size and (2) the connections between the subgraphs are as minimal as possible. To smoothly in-corporate the handle of HQgraphs into general graph parti-tioning models, we can specifically process the HQgraph as the single node with the number of nodes equal to the node size in the HQgraph.
 Procedure: UPA_hierarchy_construction():
As such, we can apply the well-known graph partition-ing method to construct the UPA hierarchy in a top-down manner. Note that several graph-partitioning methods have been proposed to achieve graph partitioning [8][9]. In this work, we adopt the METIS framework [8], which imple-ments a multilevel graph partitioning algorithm and has been shown to have the partitioning quality better than the traditional Kernighan-Lin algorithm [9].
 We outline the construction in UPA_hierarchy_construction. In the first step, the graph G is transformed to a condensed graph G  X  . The graph in Figure 4(b) is an example of the con-densed graph transforming from the graph in Figure 4(a). The HQgraph is represented as a weighted node with the weight equal to the number of nodes in this HQgraph. The weights of other nodes in the condensed graph are set as 1. Afterward, the condensed graph G  X  is partitioned into p sub-graphs by utilizing the METIS algorithm. The partitioning procedure is repeated for level 0 to level  X   X  1 . Note that in the leaf level  X  , each HQgraph is already a predetermined graph set. Suppose that there are i HQgraphs involved in a subgraph of level  X   X  1 , the complement of HQgraphs is used to generate p  X  i leaf subgraphs.
 Procedure: knn_search():
In the final step, shortcuts and KNN results of border nodes in all HQgraphs are computed. For other leaf sub-graphs, only border and their shortcuts are calculated. Fol-lowing the same approach discussed in the ROAD algorithm, the borders and shortcuts of intermediate subgraphs can be determined by referring shortcuts of their child subgraphs without the need of traversing the corresponding graph.
Note that another major component in the SQUARE frame-work is the object repository, i.e., the object index shown in Figure 3. Essentially, the Association Directory structure proposed in the ROAD algorithm [12] can be directly ap-plied in SQUARE. Interested readers can refer to [12] for such an object index structure used to decouple the associ-ation between the network graph and the object locations.
In this section, we present how to achieve the KNN search by traversing the UPA hierarchy. Specifically, the KNN search can be categorized into two search scenarios: (1) queries is-sued in a HQgraph, and (2) queries issued in a non-HQgraph. Queries issued in HQgraph: Two situations can be further considered. First, for the query issued in a border of HQ-graph, we can return the KNN result in the constant time since it is maintained. Second, for queries issued in the in-terior node of the HQgraph, we apply the traditional Dijk-stra X  X  algorithm to obtain the shortest paths to borders and to objects in the HQgraph. In light of Lemma 1, we use a priority queue to sort the network distances of objects in the HQgraph and KNN objects of borders. Finally, the top-k objects are returned as the KNN results.
 Queries issued in non-HQgraph: For such situations, the KNN search is similar to the search in the ROAD algorithm. But we can further improve the search efficiency by exploit-ing the information embedded in HQgraphs. Specifically, when the network traversal reaches a border of a HQgraph, the insertion of the border to the search queue can be re-placed as the insertion of its KNN objects to the queue, thus further reducing the search spaces.

The procedure of the KNN search is outlined in the pro-cedure knn_search. There are four algorithm inputs: the UPA hierarchy UPA , the object index OI , the number of KNN objects k , and the query point q . The knn_search procedure will return the KNN result, i.e. ANS . Q and C are priority queues. In Q , the element ( v, v.dist ) represents a node and its distance from the query point. Similarly, the element ( o, o.dist ) in C represents an object and its distance from the query point. The elements in Q and C are sorted by the distances in the ascending order. The dequeuing op-eration will remove an element from Q or C that has the smallest distance. The procedure begins by enqueuing ( q, 0) onto Q . An element ( v, v.dist ) is dequeued repeatedly from Q until Q is empty or top-k objects are identified. After an element is dequeued, three operations are executed: (1) Check the dequeued node if it is visited. If the dequeued node is visited, further network expansion from the node is not necessary. The search procedure continues dequeuing the next element from Q . (2) Dequeue objects from C . The element is dequeued from C continuously until the element in C with the distance is larger than the distance of node v or the size of ANS is larger than k . These elements dequeued from C belong to KNN objects and are inserted to the set ANS . (3) Enqueue candidate objects retrieved from v into C and enqueue following nodes that should be explored from v into Q . If the node v is a border of a HQgraph, its KNN objects are enqueued into C . Otherwise, nodes that should be explored from v are enqueued into Q . Figure 5: Example of the UPA Hierarchy with HQgraph G 2 2
In the KNN search, we use FindSubgraph( v , UPA ) to iden-tify the highest subgraph which contains node v as its bor-der. In addition, HaveObjects( s , OI ) and HaveHQ( s , UPA ) will check OI and UPA if the subgraph s contains objects and HQgraphs. If no object and no HQgraph are included in s , each border on the another side of shortcuts of v are enqueued into Q . When the subgraphs in the leaf level are checked, all nodes connecting to v are enqueued into Q . If v is not a border, the attached objects of v are enqueued into C , and the connecting nodes of v are enqueued into Q . Finally, the process is terminated when the size of ANS is k .
 Example 2: As shown in Figure 5, the UPA hierarchy con-tains a HQgraph G 2 2 . Suppose a query q is issued in G find KNN with k = 3 . The precomputed KNN results of the border a are { o 3 , o 2 , o 1 } , where d N ( a, o 3 ) = 5 , d 7 , d N ( a, o ) = 8 . The precomputed KNN of border c are { o 3 , o 4 , o 2 } , where d N ( c, o 3 ) = 6 , d N ( c, o 4 15 . We first calculate the network distance between q and the object in G 2 2 , i.e., d N ( q, o 3 ) = 2 . The network distances between q and borders a and c are also computed in the same network expansion procedure, and get d N ( q, a ) = 3 , d ( q, c ) = 5 . Then, we can derive d N ( q, o 3 : a ) = 8 , d ( q, o 2 : a ) = 10 , d N ( q, o 1 : a ) = 11 , d N ( q, o 11 , d N ( q, o 4 : c ) = 18 , and d N ( q, o 2 : c ) = 20 , where d ( u, v : m ) denotes the network distance between node u and v passing through node m . Finally, we can obtain the candidate objects of q sorting by their network distances, i.e., { o 3 , o 2 , o 1 , o 4 } and the corresponding travel distances { 2 , 10 , 11 , 18 } . The KNN of q are { o 3 , o 2 , o compared to the ROAD algorithm, the network expansions in G 2 1 and G 2 3 can be fully omitted. The query time can be bounded with respect to the size of G 2 2 , which is in gen-eral small and controlled by the parameter  X  . In cases of queries issued in node a or c in G 2 2 , we can straightforwardly return their KNN without invoking the network expansion procedure, thus showing the search efficiency of SQUARE. Note that for queries issued within other leaf subgraph, the search process is as same as that in ROAD, which is stated in Example 1 in Section 2.
In this section, we discuss the maintenance issue when data or the road network are updated. Note that updates may affect the correctness of the precomputed information. The general goal is to identify the minimum set of informa-tion which requires recomputation. In the SQUARE frame-work, the precomputed data include KNN results of borders in HQgraphs and the shortcuts between borders in each sub-graph. The procedure to maintain shortcuts due to network Figure 6: Example of filtering insert-check candidates by Remark 2. update is as same as the procedure discussed in the ROAD algorithm.
When an object is inserted, it is necessary to recalcu-late some precomputed KNN to ensure the KNN data are update-to-date. Intuitively, we can calculate the distances between the new object and all borders in HQgraphs. Sup-pose that d k ( b i ) is the distance between a border b i graph and its k th nearest object. If the distance between b and the new object is smaller than d k ( b i ) , the KNN objects of b i need to be updated by removing the k th nearest ob-ject and adding the new object. However, checking updates for all borders is time-consuming, indicating the impracti-cability of the naive method especially in web-based LBS applications with frequent updates.

We thus propose a novel filtering method that utilizes the Euclidean lower-bound property [17] to avoid checking unnecessary borders. Consider the example of an object o and a border b i . According to the Euclidean lower-bound property, the Euclidean distance d E ( o, b i ) is smaller than d ( o, b i ) . Therefore, if d E ( o, b i ) &gt; d k ( b be larger than d k ( b i ) , indicating that o does not belong to KNN results of b i . The precomputed KNN results of b remain valid. In contrast, if d E ( o, b i )  X  d k ( b i have d N ( o, b i ) smaller than or equal to d k ( b i ) . In such cases, we have to verify their KNN results with respect to the ob-ject insertion. Based on the foregoing, we describe Remark 1 below that help to filter unnecessary border check. Remark 1: Let { b 1 , b 2 , ..., b n } be the set of borders in HQ-graphs and o is a newly inserted object. Suppose dk _ max = max b i ( d k ( b i )) . Let "insert-check candidates" C be the set of borders whose KNN results may be altered. We have C = { b i | d E ( o, b i )  X  dk _ max } .

Specifically, to identify insert-check candidates, we main-tain the global dk _ max in the SQUARE framework, which can be calculated after the initial construction of the UPA hierarchy. While a data insertion happens, the global dk _ max can be used to identify the insert-checking candidates. More importantly, we can extend Remark 1 to be a multiple fil-tering strategy for further reducing the set of insert-check candidates.
 Remark 2: Let C = { b 1 , b 2 , ..., b n } be the insert-check candi-dates which is identified by the global dk _ max . We remove from C for the border with d E ( o, b i ) = dk _ max , and insert the border into the set of "must-check candidates". After-ward, we can further use the dk _ max  X  = max b i ( d for b i  X  C , to reduce the insert-check candidates. That is C  X  = { b i | d E ( o, b i )  X  dk _ max  X  } . The border in C d ( o, b i ) = dk _ max  X  will be removed from C  X  and insert into must-check candidates. The iteration can be repeated until insert-check candidates are reduced to a empty set. Finally, only the border in must-check candidates needs to check if its KNN result is changed.

Figure 6 shows an example to illustrate the multiple filter-ing strategy in Remark 2. In the example, the object o is the newly inserted object and there are 8 border nodes included. Suppose d k ( b 1 ) = 12 , d k ( b 2 ) = 9 , d k ( b 3 ) = 5 , d 15 , d k ( b 5 ) = 5 , d k ( b 6 ) = 13 , d k ( b 7 ) = 11 , d and the Euclidean distance d E ( b 1 , o ) = 18 , d E ( b d ( b 3 , o ) = 8 , d E ( b 4 , o ) = 11 , d E ( b 5 , o ) = 17 , d d ( b 7 , o ) = 20 , d E ( b 8 , o ) = 18 . In this case, the global dk _ max = 15 and the first-step insert-check candidates are those borders located within the shadow area in Figure 6(a), i.e. C = { b 2 , b 3 , b 4 } . Since in C , b 4 has d k ( b b is removed from C and included into the must-check can-didate M = { b 4 } . In the second step, dk _ max = 9 , which equals to d k ( b 2 ) . As shown in Figure 6(b), only b 3 in the shadow area and d k ( b 3 ) = dk _ max . Therefore, the set of must-check candidates is unchanged. Now C = { b 3 and dk _ max = 5 for the third step. As shown in Figure 6(c), no border is located in the shadow area, leading to the empty set of C . The filtering process is thus terminated. Finally, we only need to check the shortest path related to the border in M , i.e., b 4 .
The maintenance operation for the object deletion is rel-atively simple as compared to the object insertion. Specifi-cally, each object maintains the set of borders which involve the object as the KNN result. For deleting objects with the empty set of affected borders, the object deletion will not invoke any KNN recalculation. On the other hand, the dele-tion will invoke KNN recalculation for the affected borders.
Note that the nature of data skewness will make the num-ber of HQgraphs is much smaller than the number of leaf subgraphs. Moreover, reducing the number of borders in HQgraphs is the goal of graph partitioning methods. We generally have a small set of borders with precomputed KNN, indicating that the number of KNN recalculation from the deletion is small and the overhead is acceptable.
In this section, we evaluate the performance of SQUARE by checking (1) index overhead (2) KNN query performance, and (3) update overhead. We used three real road net-works: CA, NA, and SF, obtained from [14][15]. These datasets are widely utilized to evaluate the query perfor-mance [13]. Specifically, CA represents California road net-work containing 21,048 nodes and 21,693 edges. NA rep-resents road network of North America with 175,813 nodes and 179,179 edges. SF represents San Francisco road net-work with 174,956 nodes and 223,001 edges. The simulation was implemented by Java1.5 in Windows 7, and experiments are executed on 2.4GHz Core 2 CPU and 4GB RAM. Note that we synthetically identify the total number of nodes be-longing to HQgraph as 800 in all experiments. The value of  X  is fixed by making the ratio (node number in a HQ-graph over node number in a leaf subgraph) be 0.2. We also implement INE [17] and ROAD [13] for the comparison.
We first evaluate the index size and the construction time of all three approaches under different networks. Because the index overhead of INE is relatively smaller than other two methods, we only compare the results of ROAD and SQUARE. Figure 7(a) reveals the results with respect to the memory usage and the construction time in three data sets. We also show the cardinality ratios. In column 3, the ratio means the difference in memory usage between SQUARE and ROAD over the memory usage of ROAD. In column 4, the ratio represents the difference in index con-struction time between SQUARE and ROAD over the index construction time of ROAD. As shown, the memory usage and construction time increase as the size of road networks increases. Note that the numbers of nodes in NA and SF are similar and the road network of SF is more complicated. More memory and time are required to construct the index structure in the SF case. We can also observe that the ex-tra overhead of SQUARE is relatively small as compared to ROAD. SQUARE only requires small resources to keep additional information which can facilitate the KNN search.
Figure 7(b) shows the effect of varying k on the index size and construction time of SQUARE. The cardinality ratios (i.e., the memory usage of HQgraph over the memory usage of UPA hierarchy, and the construction time of HQgraph over the construction time of UPA hierarchy) are specified in columns 3 and 5. We first observe that the memory usage and index construction increase as k increases. The increase is caused by the precomputed KNN in HQgraph. Moreover, we can find that the overhead of precomputed KNN is af-fordable even when k is large. The experimental results on the index overhead demonstrate that the overhead of the index in the SQUARE framework is acceptable.
Before evaluating the query performance of all approaches, we first discuss the parameter settings in SQUARE. In Fig-ure 8(a), we show the query processing time in terms of varying the similarity ratio of query distribution in the eval-uated query sequence. The similarity ratio is the number of queries issued at HQgraphs over the total number of queries in the query sequence. One means all queries are issued at HQgraphs, whereas zero means all queries are issued at non-HQgraphs. To compare the performance of SQUARE and ROAD, we apply the same query sequence to these two approaches. As expected, the query processing time sig-nificantly decreases when the similarity ratio increases in SQUARE. Clearly, the figure illustrates that if the distribu-tion of following queries is close to that in the history query logs, the query performance of SQUARE is extremely ef-ficient as compared to ROAD. Note that ROAD does not take the object distribution into consideration during the index construction, thus leading to the query performance orthogonal to the query behavior. Figure 8: Evaluation of varying parameters in SQUARE.
We then examine the effect of different maximum sizes of HQgraphs, and the result is shown in Figure 8(b). The size of leaf subgraphs for CA is close to 80. In the figure, the cardinality ratio in x-axis is the size of a HQgraph over the size of leaf subgraph, which varies from 0.2 to 1. The experimental results show that smaller HQgraphs has better performance while needs more memory storage.

We conduct experiments to evaluate the query perfor-mance of three algorithms over various k, various number of objects and various networks, respectively. The results are shown in Figure 9. We run the experiments on 1000 queries that are randomly generated and show the total query time in terms of CPU processing time. In Figure 9(a), the value of k varies from 1 to 30. It can be clearly found that, SQUARE outperforms ROAD and INE for various k setting, thus demonstrating its effectiveness of using precomputed KNN in HQgraphs. Figure 9(b) shows the results by vary-ing object number from 50 to 900. As expected, SQUARE has the better performance. It is noted that we can observe that when the object number is larger than 300, INE outper-forms ROAD. The reason is that the search space pruning in ROAD is decreased as the object number increases, since many subgraphs contain objects. In worse cases that each subgraph contains objects, the network traversal in ROAD is similar to INE, but ROAD needs extra traversal in the graph hierarchy. In contrast, queries in HQgraphs can be answered in the quasi-constant time in SQUARE, which is orthogonal to the impact of object counts, thus showing the robustness of SQUARE. We also show the query time on various networks in Figure 9(c). For better comparison, we construct the graph hierarchy of NA and SF networks by setting partition level to 5 and 6 to obtain almost equal size of leaf subgraphs as that generated in the CA network. INE has the worse performance as expected. In the SF data set, which contains extremely many edges, the cost of query processing time is high without the use of search space prun-ing. The experiment demonstrates the efficiency of search space pruning of ROAD and SQUARE in large networks. Node that SQUARE still has the better efficiency, showing the feasibility of HQgraphs in various network topologies.
In this section, we measure the maintenance overhead caused by object update over different number of updates. We execute 1000 random queries and the number of object updates varies from 200 up to 1000 to observe the processing time of the query system, where the updates contain object insertion and object deletion. In Figure 10(a) the processing time of query time plus update time are shown. Although SQUARE pays for more time for updates, the processing time is still better to that of ROAD. In Figure 10(b), we show the update overhead as the number of updates in-creases. The update cost of SQUARE is still similar and comparable to that of ROAD. This demonstrates the effi-ciency of SQUARE while the objects are updated frequently. We discussed in this paper an efficient search algorithm for KNN objects on road networks. The SQUARE algorithm is the first work considering the query patterns. Specifically, SQUARE is devised based on the well-known power-law phe-nomenon, which states that 80% queries will be roughly is-sued within 20% regions, i.e., hot query regions. As such, SQUARE especially maintains the KNN information rela-tive to hot query regions which contain frequent queries, and queries issued within such regions can be answered in the quasi-constant time. In addition to its high query ef-ficiency, the SQUARE algorithm can also handle the issue of data updates. The maintenance overhead is comparable to that of the state-of-the-art algorithm. As validated by our empirical studies, SQUARE can efficiently obtain the update-to-date KNN set, showing its prominent advantage of being an component of online LBS applications. This paper was supported in part by National Science Council of Taiwan under Contract NSC 97-2221-E-002-172-MY3.
