 sense disambiguation using contextual knowledge. For exam ple, does  X  X ar X  represents a rod or a place where drinks are served? While a combined semantic and s yntactical model could be used sufficient for contextual analysis in text [14, 15].
 We use analogous reasoning to suggest a similar dichotomy in representing object structure and context in vision. Our approach combines bag-of-words and s patial models to capture semantics bag-of-words approach suffices (See Figure 1 (a) and (b)).
 Learning such a model from weakly labeled data requires labe ling the features in an image as be-Problem: Approach: the foreground model.
 allows us to learn object models from images where there is si gnificant clutter and in which the based on how well they separate foreground and background fe atures. This is followed by a shape matching step which identifies the object boundary contours based on their expected shape. This step prunes many contours and provides a better estimate of o bject boundaries. These boundaries iteration of Gibbs sampling. Figure 2 shows the system flow of our  X  X hape Aware X  approach. 1.1 Related Work Many graphical models for object recognition [11] have been inspired by models of text documents such as LDA [6] and pLSA [7]. These models are computationall y efficient because they ignore However, ignoring spatial relationships between features leads to problems (See Figure 1(a)). In correspondence between image and object features.
 There has been recent work in applying spatial constraints t o topic models which enforce neigh-from weakly labeled data. This was achieved by marginalizin g object locations and scale. Each object location hypothesis provides a foreground segmenta tion which can be used for learning the images.
 Our goal is to simultaneously learn an object model and its co ntext model from weakly labeled vironment (high clutter and small objects). We present a  X  X h ape aware X  feature based model for exemplar. Shape based models [1] have been used previously f or object recognition. However, contours from the set of all edges that match the shape model. Approximate approaches such as MCMC are not applicable since matching is very closely coupl ed with selection. We propose an of features. Each visual word is analogous to a word and an image is treated analogous to a document. We start with random assignments of words to topics and autho rs. This is followed by a Gibbs subsequently analyzed to identify the object  X  X enters X  and final object contours by matching with to each word are reassigned and the model is retrained using t he new assignment. 2.1 Generative Model -Syntax and Semantics Author-Topic Model: Our model is motivated by the author-topic model [13] and the model pre-The author-topic model is used to model documents for which a set of authors is given. For each word in the document, an author ( x topic ( z (  X  ) prior. Figure 3: (a) Author-Topic Model (b) Our Model (Spatial Auth or-Topic Model). Our model extends the author topic model by including the spatial(syntactica l) relationship between features. Spatial-Author Topic Model: Our model is shown in figure 3(b). Our goal is not only to model t he the image is described by its type w x which is described by its type o sources. Topic z o and a word w chosen from a symmetric Dirichlet (  X  ) prior.
 The location of each feature, l distribution: by topic ( z spatial location of a feature is specific to the topic z on the locations of the features generated by topics from con text, we set  X  to a constant when o corresponds to the context of some object. 2.2 Gibbs Sampling We use Gibbs sampling to estimate z assignments x , other topic assignments z where n z i represents the total number of features assigned to topic z that are assigned to topic z assigned to author o n represents the total number of features from object type o words and T represents number of topic types.
 Similarly, given the features ( w, l ) , topic assignments z , other author assignments x hyperparameters, each x where n o i and n o i represents the total number of features from object o second term is replaced by a constant. R represents the number of possible reference locations. 2.3  X  X hape Aware X  Model The generative model presented in section 2.1 can be learned using the Gibbs sampling approach lower. The labeling performance can, however, be improved i f contour cues are utilized. We do foreground and background is not only governed by co-occurr ence and structural information, but also by shape similarity. We refer to this as a  X  X hape aware X  m odel.
 boundaries consistent with the shape model by matching. (c) Using new boundaries to determine new labels for features.
 Extracting Object Boundary Contours from Feature Labels: We first determine the edges using and group them into contours using the approach presented in [16]. Each contour c of 2D points ( p of the number of foreground and background features on each s ide of an image contour provides measure the number of foreground and background features th at lie on each side of the contour cl j = 1 where n S 1 is total number of features on side S 1 .
 Shape Matching: Given the probabilities of each contour being a part of the ob ject boundary, we the object where the weight of the vote is determined based on how well the contour matches the boundary of the object. Figure 4 shows an example of the votin g process and boundary contours extracted using this approach.
 Extracting New Labels: These boundaries are then used to relabel the image features into fore-ground and background. We use the same separation principle to label new features. Each boundary that the feature i is labeled as foreground is given by P j  X  j  X  ij contour j is on object boundary and  X  same side of contour c initialization point for the Gibbs sampling based learning of the feature model. We randomly selected 45 images for training the model from th e LabelMe dataset. A potential compared the performance of our system against the author-t opic model and the author-topic model learning. Figure 6 show some of the cases where both author-t opic and author-topic model with dataset. The  X  X hape aware X  model, however, shows better loc alization performance as compared to the other two. Figure 7 shows a quantitative comparison of the  X  X hape aware  X  model to the author-topic and the performance of the  X  X hape aware X  model on test dataset.

