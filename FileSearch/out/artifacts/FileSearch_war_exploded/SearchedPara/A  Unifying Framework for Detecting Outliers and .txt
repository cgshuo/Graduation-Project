 become one of the issues receiving scant attention in data mining, which is recognized as event change detection [5] and closely related to activity monitoring [4]. 
Let us illustrate these issues by using network access log analysis as an example. Suppose that you have a data stream of network access logs, each of which is specified by numerical variables including access time, duration, etc. We may first [earn a statistical regularity from the data, then detect outliers by investigating how much each data is deviated from the regularity. Identifying such outliers may lead to network intrusion detection since criminal or sus-picious activities may often induce statistical outliers (see e.g., [3],[15]). The problem of change point detection is here to identify the time when a significant change of statistical behavior of the access pattern has occurred. 
Specifically we make the following requirements on the outlier/change point detection algorithm: A) The detection process should be on-line. That is, an out-lier or a change point should be detected immediately after it appeared, mad B) The detection should be adaptive to non-stationary data sources. That is, an outlier or a change point should be detected even if the nature of the data source may change over time. The major contribution of this paper is to propose a lmifying framework for detecting outliers and change points under the above requirements A) and B). 
In [15],[16], we proposed a general framework for sta-tistical outlier detection, under the assumption that the data source is non-stationary and each data is independently drawn according to it. In this framework, we employed a Ganssian mixture model as a statistical model for continu-ous variables while a histogram density as that for discrete variables. We developed an algorithm for on-line discounting learning of the model, where it can track the changing data source adaptively by gradually forgetting the effect of past data. Outliers are detected relative to the learned statisti-cal model. Then for a new input data, its score is calculated as its deviation from the learned model, with a high score indicating a high possibility of being a statistical outlier. 
In this paper we extend the framework in [15],[16] toward the following two directions: 1) dealing with time series data, and 2) detecting change points in a data stream. 
As for 1), we replace a finite mixture model employed in the previous framework in [15] with the AR (autoregression) model (see e.g., [1]) in order to represent the underlying mechanism of generating time series data, and propose a new algorithm for on-line discounting learning of the AR model. We then employ this algorithm to detect outliers function of xt represented by the AR model is given by where w = w(xtt:~ -,) + ,. We set 0 = (Wl,..., wk, p, ~). 
We first review a standard batch algorithm for estimating parameters of AR model according to [13]. Define: Eq.(2) denotes an estimate of p and Eq.(3) denotes an es-timate of a covariance function of the Xl,.'. ,xt. Further the coefficients wl,"  X  tak of the AR model are calculated by solving the following linear equation: calculated as Note that in the above algorithm of learning AR models it is assumed that the data source is stationary and the parameters are estimated after we see the entire data. 
We introduce here the SDAR(sequentially discounting AR model learning.) algorithmby modifying the above algorithm in the following two regards: 1) On-line estimation; that is, the parameters are updated every time a data is observed, and 2) Discounting property; introducing a discounting parame-ter r makes the statistics exponentially decay with a multi-plicative factor (1 -r) as the time goes on. This enables us to deal with the non-stationary source. SDAR algorithm is described as follows: SDAR Algorithm (0 &lt; r &lt; h given) Step 1. Initialization Set ~0,Cj,&amp;j (j = 1,... ,k),~. Step 2. Parameter Updating 
For each time t(= 1,2-.. ,), read xt, proceed: 
Solve the following equation: 
Letting the solution to Eq.(6) be &amp;l,"" tbk, then calculate 
For each time t, the SDAR algorithm updates the esti-mates of parameters with a weighted average depending on (8) (9) (12) in which variance as well as mean change over time. 
As shown in Fig. 4, the change points occur at time x x 1,000 (x = 1,2,... ,9) and the standard deviation is de-fined as 0.1/(0.01 + tirne/lO, O00). We denote the ratio of the change size at the xth change point to the standard de-viation as R(x), which we call the change-noise ratio. In this dataset, we set R(x) ,~ x (x = 1, 2,... ,9). that SDAR1 was able to detect change points accurately even if the variance changes over time. rate and the recall for SDAR1, where the false alarm rate is defined as the percentage of non-change points classified as a change point while the recall is defined as the ratio of change points correctly detected to the total number of change points that should have been detected. We prepared three datasets with various change-noise ratios. For each dataset 100,000 records are generated according to the AR model (12). For each dataset, change points occur at time x  X  1,000 (x = 1, 2,..-, 9). The change-noise ratios for three dataset are respectively R(x) = 20, I0, 5 for every change point x. The detection is considered to be correct if a de-tected change point is located within 50 records after the true change point. Fig. 6 shows the false alarm-recall curves (what we call ROC curve) for the two datasets. Fig. 6 shows that SDAR1 works well when the value of R is not less than 
