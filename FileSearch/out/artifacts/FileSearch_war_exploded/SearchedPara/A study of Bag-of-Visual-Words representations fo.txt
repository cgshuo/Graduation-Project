 ORIGINAL PAPER David Aldavert 1  X  Mar X al Rusi X ol 1  X  Ricardo Toledo 1  X  Josep Llad X s 1 Abstract The Bag-of-Visual-Words (BoVW) framework has gained popularity among the document image analysis community, specifically as a representation of handwritten words for recognition or spotting purposes. Although in the computer vision field the BoVW method has been greatly improved, most of the approaches in the document image analysis domain still rely on the basic implementation of the BoVW method disregarding such latest refinements. In this paper, we present a review of those improvements and its application to the keyword spotting task. We thoroughly eval-uate their impact against a baseline system in the well-known George Washington dataset and compare the obtained results against nine state-of-the-art keyword spotting methods. In addition, we also compare both the baseline and improved systems with the methods presented at the Handwritten Key-word Spotting Competition 2014.
 Keywords Bag-of-Visual-Words  X  Keyword spotting  X  Handwritten documents  X  Performance evaluation Keyword spotting can be defined as the pattern recognition task aimed at locating and retrieving a particular keyword within a document image collection without explicitly tran-scribing the whole corpus. Its use is particularly interesting when applied in scenarios where Optical Character Recog-nition (OCR) performs poorly or cannot be used at all, such as in historical document collections and handwritten docu-ments. Being a mature research problem [ 30 ], many different keyword spotting approaches have been proposed thorough the years.

In the document image analysis literature, we can dis-tinguish two different families of keyword spotting meth-ods depending on the representation of the handwritten words [ 26 ]. On the one hand, sequential word representa-tions [ 35 ] describe handwritten words as a time series by using a sliding window in the writing direction. On the other hand, holistic word representations [ 29 ] extract a single fea-ture vector of fixed dimensionality that characterizes the word as a whole.

Sequential word representations exploit the sequential nature of handwritten words formed by the concatenation of individual characters. However, since the size of the word X  X  descriptors will depend on the width of the word, two differ-ent words cannot be directly compared by means of a distance between points, but some sort of alignment technique has to be used instead. The seminal work by Ko X cz et al. [ 19 ] achieved a breakthrough in the handwritten keyword spotting domain by proposing the use of the Dynamic Time Warping (DTW) method (often used in speech analysis) for nonlinear sequence alignment. The use of DTW together with profile features was popularized by the well-known works by Rath and Manmatha [ 37 , 38 ] and Rath et al. [ 39 ] and many fla-vors of DTW-based handwritten keyword spotting methods appeared since those publications. Adamek et al. proposed in [ 1 ] to use DTW to align convexity and concavity features extracted from contours. Khurshid et al. presented in [ 18 ]a method that first aligned features at character level by DTW and then the resulting character prototypes are aligned at word level. Papandreou et al. [ 33 ] proposed an adaptive zon-ing description that can be matched by DTW. Besides direct matching strategies, learning-based methods have also been proposed over the years. Hidden Markov Models are the most widely used techniques to model the keywords X  sequen-tial features [ 12 , 41  X  44 ], although other machine learning approaches such as neural networks [ 13 ] have also been used in the keyword spotting domain.

Holistic word representations have also received some attention thorough the years. Their main advantage is that by representing handwritten words by feature vectors of fixed size, the alignment step (which usually is very time consum-ing) is bypassed, and thus, two handwritten words can be compared using standard distances, or any statistical pattern recognition technique. We can find many different holistic word descriptions used in the literature for keyword spot-ting tasks. For example, simplified versions of the shape context descriptor have been used in example-based key-word spotting architectures by Llad X s and S X nchez [ 27 ]or by Fern X ndez et al. [ 11 ]. Zoning-based characteristics have also been widely used to represent word images holistically, e.g., [ 17 , 20 ]. A combination of Histogram of Oriented Gra-dients (HOG) and Local Binary Pattern descriptors has been proposed by Kovalchuk et al. in [ 21 ] in a segmentation-free keyword spotting scenario. A set of biologically inspired fea-tures formed by a cascade of Gabor descriptors was proposed by van der Zant and Schomaker in [ 57 ]. The combination of gradient, structural and concavity features was proposed by Srihari and Ball in [ 54 ]. All of these word representations present their strengths and weaknesses and it is hard to argue that a set of features is steadily better than another, although in the latest years a trend toward using gradient-based fea-tures can be appreciated [ 40 ]. 1.1 Keyword spotting as an object recognition task Since the publication of the SIFT method [ 28 ], the computer vision task of recognizing and finding objects in cluttered scenes has been driven by methods extracting local descrip-tors that are further matched between the query model and the scene images. Many authors from the document analysis field, understanding keyword spotting as being a particular case of the object recognition task, started to apply such keypoint matching techniques to the problem of keyword spotting [ 23 , 48 , 56 , 58 ]. Such matching techniques have been either used to directly estimate similarities between word images, or by searching the query model image within full pages in segmentation-free scenarios. However, the keypoint matching framework presents the same disadvantage than the sequential methods since an alignment between the keypoint sets has to be computed.

In order to avoid exhaustively matching all the keypoints among them, the classic bag-of-words paradigm from the information retrieval field was reformulated as the Bag-of-Visual-Words (BoVW) [ 8 , 53 ]. Such paradigm yields an holistic and fixed-length image representation while keeping the discriminative power of local descriptors such as SIFT.
Soon enough, researchers from the document image analysis domain adapted such BoVW representations to the keyword spotting problem [ 5 , 10 , 44 , 46 , 47 , 49  X  51 ], obtain-ing very competitive results. However, we have the feeling that although the computer vision community kept propos-ing improvements on the BoVW framework in the last years, in the document analysis field, such improvements are still scarcely used. As an exception, it is worth to cite the works from Shekhar and Jawahar [ 52 ], or our last contribution [ 2 ], where more complex BoVW setups are used for the keyword spotting task. 1.2 Contributions and outline of the paper In this paper, we will review some of the latest improve-ments over the BoVW framework, namely sparse coding, spatial pyramids, and power normalization and its appli-cation to the keyword spotting task. We will thoroughly evaluate the impact of such improvements as well as the different parameters of the BoVW method by comparing their performances against a baseline system. We will finally compare the obtained results against nine state-of-the-art segmentation-based keyword spotting methods by using the well-known George Washington dataset. In addition, we also compare both the baseline and improved systems with the methods presented at the handwritten keyword spotting com-petition 2014.

The paper is structured as follows: In Sect. 2 , the dif-ferent parts of the BoVW pipeline used to characterize the word images are presented. Then, the effects that each BoVW enhancement has in the performance of a keyword spotting system are evaluated in Sect. 3 , and the results obtained by the system are compared with the state of the art in Sect. 4 . Finally, we review the most important conclusions of the paper in Sect. 5 . In order to spot keywords in document images, we start by a layout analysis step devoted to segment the docu-ment images into individual words. The interested reader is referred to [ 25 , 31 ]. Once the words are segmented, a visual signature is computed for each of them. The keyword spot-ting will be then performed by calculating the similarity between the description of the query word and all the descrip-tors of the words in the corpus. These visual signatures are created using a Bag-of-Visual-Words (BoVW) framework which has obtained good performances in keyword spotting tasks [ 47 , 51 ].

The BoVW framework has many variants in the litera-ture, but all of them can be roughly divided into four basic steps: sampling , description , encoding and pooling . In order to increase the retrieval performance of the spotting system, we need to carefully select the methods used at each step. In this paper, we will mainly focus on the BoVW improve-ments that bring better word representations for recognition or spotting tasks. 2.1 Sampling The first step is to select the regions of the image which con-tain meaningful information to describe the word snippets. Although covariant or salient region detectors can be used, it has been proven that the performance of BoVW representa-tions is correlated with the number of sampled regions. For instance, Nowak et al. [ 32 ] demonstrate in that the larger the number of regions, the better the results. They show that the combination of several region detectors usually improves the performance of the BoVW framework, but this performance gain is related to the number of regions rather than the kind of sampled regions. Therefore, for our baseline implementa-tion, we decided to densely sample regions at different scales over the image instead of using a keypoint detector.
Regions are densely sampled using a fixed step and at dif-ferent scales. The different scales are selected so that words are going to be modeled at different levels of detail: Small regions will model portions of characters, while large regions will model the relationships between characters. 2.2 Description Once regions have been sampled, we need to characterize them with a local descriptor. Although descriptors specifi-cally tailored for document analysis can be used, gradient-based descriptors have recently shown better performances in keyword spotting tasks [ 2 , 3 , 47 ].

We are going to use the HOG descriptor [ 9 ] to characterize the regions. This descriptor is derived from the SIFT descrip-tor [ 28 ], but it is more suited for dense sampling scenarios whenrotationinvarianceisnotneeded.Inourcase,itissafeto assume that the orientation of the word images has been cor-rected by the word segmentation algorithm or intermediate slant correction steps. The HOG algorithm takes advantage of the information redundancy between overlapping regions, so that descriptors can be calculated at a much lower com-putational cost [ 14 , 59 ].

Although the dense sampling strategy will generate a large amount of HOG descriptors, only reliable descriptors are eventually accepted. Since HOG descriptors are based on gradient information, descriptors are more reliable when gradient vectors have a large module. Therefore, the norm of the descriptor can be used as a reliability indicator. For instance, Fig. 1 shows the norm of the HOG descriptors calculated at each pixel of the image. It can be appreci-ated that descriptors calculated near character locations have a high norm, while descriptors sampled over other image regions have a low norm. Therefore, the BoVW signature can focus on the visual information from characters by fil-tering the descriptors depending on the value of their norm. The bold contours in the Fig. 1 encircle the zones where the descriptors have a norm higher than the threshold used in the paper. Descriptors that have a value lower than this threshold, i.e., descriptors outside the contours, are simply disregarded. 2.3 Encoding After calculating the descriptors, we have to encode them into visual words. First, we need a codebook which quantizes the descriptorspaceintoanarbitrarysetof m salientregions.This codebook is created by randomly sampling descriptors from the indexed word snippets and using the k -means algorithm to calculate m clusters. Then, a descriptor d i is encoded by a vector W i  X  R m which weights the contribution of each codeword (i.e., cluster centroid). The most straightforward methodtocalculate W i istousehardassignment[ 53 ],i.e.,the weight vector has a single nonzero element corresponding to the nearest codeword to the descriptor.

This encoding approach has problems near the bound-aries between codewords. Small changes in the descriptor may lead to a completely different visual words vector W i This problem can be alleviated by using soft assignment instead, i.e., encoding a descriptor using a weighted com-bination of codewords. Besides, combining the information of several codewords also reduces the information loss result-ing of the descriptor quantization. Therefore, we decided to encode descriptors using the sparse coding technique pro-posed in [ 55 ], known as Locality-constrained Linear Coding (LLC). This method generates a compact BoVW signature that have a higher discriminative power than more complex representations [ 6 ].

Given a descriptor d i , the LLC method tries to find the linear combination of codewords which better approximates the original descriptor: d  X  where C j is the j -th codeword and w j its associated weight. Unlike other sparse coding algorithms, LLC emphases local-ity over sparsity and it only uses the t nearest codewords to encode a descriptor. This ensures that the resulting encod-ing is locally smooth, so that similar descriptors are likely to be encoded using the same codewords. Therefore, the LLC encoding is more robust compared to other sparse coding solutions. Another advantage is that the weights (w computational cost is drastically reduced compared to other sparse coding algorithms which require computationally demanding optimization procedures to find a solution. Then, a descriptor d i is encoded by searching the t nearest code-words and using the LLC algorithm to calculate the weights vector W i = (w 1 ,w 2 ,...,w m ) .

An example of the codebook creation and descriptor steps is summarized in Fig. 2 . The randomly sampled descrip-tors of Fig. 2 a are clustered into eight clusters in Fig. 2 b. In Fig. 2 c, we can see that the closest codewords to the descriptors d i are C 4 , C 5 and C 7 . Using hard assignment, the descriptor will be encoded as W i = ( 0 , 0 , 0 , 0 , as its nearest centroid is C 5 . On the other hand, the LLC algorithm will calculate the weights w 4 ,w 5 and w 7 so that d  X  w descriptor is close to a boundary between codewords, so that a small variation of the descriptor can shift the closest codeword from C 5 to C 7 . This would result in a completely different encoding when hard assignment is used. In contrast, the LLC algorithm will generate a similar weight vector W since it still uses the same codewords and the weights w 4 and w 7 are slightly different. 2.4 Pooling Once descriptors are encoded into visual words, the BoVW signature is obtained by simply accumulating the weight vec-tors W i : s = where N is the number of valid descriptors extracted from the word image. In the following, we are going to see how to improve this representation. 2.4.1 Spatial information In Eq. 2 , visual words are accumulated without taking into account their spatial location, so the signature lacks any spatial information. However, spatial information is quite important in keyword spotting tasks since it helps to reduce the perceptual aliasing problem. Different instances of the same character are expected to be represented by similar visual words. Hence, the obtained BoVW signatures mostly depend on the characters that form the word, and it is possible that dissimilar words are represented by similar signatures when spatial information is not taken into account. For instance, anagrams will obtain a very similar visual signa-ture in this scenario.

This problem can be addressed by using the Spatial Pyra-mid Matching (SPM) technique proposed by Lazebnik et al. in [ 22 ] in order to add some spatial information into the unstructured BoVW model. This method roughly takes into account the visual word distribution over the image by cre-ating a pyramid of spatial bins.

The spatial pyramid defines an initial set of horizontal P and vertical P 0 y partitions which create P 0 x  X  P 0 y spatial bins. Then, these spatial bins are further divided into P x horizon-tal and P y vertical partitions at each level of the pyramid. Therefore, a spatial pyramid of L levels creates a collection of overlapping D sp spatial bins, where D
The final BoVW signature W i is created by independently accumulating the visual words for each spatial bin obtaining a D W = mD sp dimensions descriptor. The amount of visual words assigned to each bin is lower at higher levels of the pyramid, due to the fact that the spatial bins are smaller. This is compensatedbymultiplyingthecontributionof eachvisual word to each spatial bin by the factor s l = P 0 x P 0 y ( 2.4.2 Normalization Once we have obtained W i , we can normalize the con-tribution of each visual word in order to obtain a better representation. First, we can reduce the importance of over-represented visual words by using the method proposed by Perronnin et al. in [ 34 ], which applies the following normal-ization function to each bin of the signature: g ( x ) = sign ( x ) | x |  X  , (4) where 0 &lt; X &lt; 1 is the power normalization factor. The power normalization improves the BoVW model since it removes the assumption that visual words come from an identically and independently distributed population [ 7 ]. Avoiding the i.i.d. assumption is important in keyword spot-ting as the frequency of visual words is highly correlated with the characters forming the word. For instance, the visual words modeling the character e will be overrepresented in words like freeze or exceed , and hence, their visual signa-ture is going to be somehow similar. Therefore, by lessening the contribution of the overrepresented visual words, we are highlighting the other visual words and making both signa-tures more dissimilar.

Finally, the BoVW signature is 2 -normalized to account that the amount of visual words accumulated in W i may change between two instances of the same word due to scale difference or image noise. In order to evaluate the different parameters of the BoVW signature in a keyword spotting framework, we use a straight-forward method to index and retrieve the word snippets from a database. The image signatures are indexed using an inverted file structure, taking advantage that the BoVW representation is sparse, specially when SPM is used. The system is evaluated by calculating the mean Average Preci-sion (mAP) score from the ranked list obtained by sorting in ascending order the Euclidean distances between the query and the indexed signatures. 3.1 Experimental Setup The keyword spotting system is evaluated in the George Washington dataset described in [ 38 ]. This dataset consists of 20 handwritten pages with a total of 4860 words written by several Washington X  X  secretaries. Although it was writ-ten by several authors, the writing style is pretty uniform and showslessvariationthantypicalmulti-writercollections.The database provides a set of word bounding boxes with their transcription. These bounding boxes are obtained using the segmentation algorithm proposed in [ 31 ] by Manmatha and Rothfeder.
 The baseline BoVW configuration densely samples the HOG descriptors at every five pixels and at three different scales: 20-, 30-and 45-pixel-wide regions. The codebook has m = 1024 codewords, and the histogram is created without using any improvement, i.e., descriptors are encoded using hard assignment, no spatial information is added and the power normalization is not used (i.e.,  X  = 1). At each step of the experimental evaluation, we are going to assess the effects that a single improvement has on the spotting per-formance of the system. These evaluations are conducted by calculating the mAP score using two different setups:  X  Setup A : Use as queries all words in the collection which  X  Setup B : Use as queries only words which have at least
The configuration setup A is defined to use all possible word snippets as queries, while the configuration setup B cast queries which are more likely to be used in a real-world scenario (e.g., avoiding short queries such as  X  a  X  X r X  to  X ).
In both setups, word snippets that have been discarded as queries are still used as distractors in the database. Therefore, the system has a 100 % recall since it always returns a ranked list with all the 4859 elements, corresponding to all indexed images except the query. 3.2 LLC encoding First, we evaluate the effects of using a different amount of nearest neighbors t in the LLC encoding step. The mAP scores obtained while testing from 1 to 16 nearest neighbors are shown in Fig. 3 . Note that using a single nearest neigh-bor corresponds to hard-assignment encoding, since only the closest codeword is used.

The results show that using LLC encoding slightly increases the performance of the word spotting system. The best results are obtained when three nearest neighbors are used to encode the descriptors: For setup A , the mAP score improves from 22.13 to 25.15% while for setup B the score raises from 22.74 to a 26.04%. Although the selected num-ber of neighbors may seem small, this result is coherent with the results shown in the original LLC paper [ 55 ] where using a small number of neighbors results in a better performance than when a large number of neighbors is employed. In the remaining experiments, we are going to use three nearest neighbors for the encoding step with LLC. 3.3 Spatial pyramids After evaluating the encoding, we are going to evaluate the importance of spatial information in the BoVW signature. In Table 1 , we can see that the addition of spatial informa-tion greatly increases the performance of the system. In both setups, the mAP score increases two and a half times between the orderless representation and the best spatial pyramid configuration. From the obtained results, we can see that hor-izontal partitions are more important than vertical partitions. This is to be expected as adding more horizontal partitions helps to increase the representation of the word characters. For instance, in Fig. 4 , we can see an example of the spatial bins defined by a two-level spatial pyramid. In the first level, spatial bins roughly model syllables, while in the second level bins are smaller and they model individual characters.
After evaluating the obtained results, we have selected a two-level SPM with 3  X  2 spatial bins in the first level and 9  X  2 in the second (row in bold in Table 1 ) as the SPM configuration used in the following experiments. With this configuration, the retrieval performance grows from 22 . 15 to 61 . 33 % using setup A and from 26 . 04 to 64 . 75 % in setup B . Although there is another configuration which obtains better results, the selected configuration offers a better compromise between performance and dimensionality growth. Addition-ally, we have re-checked the effects of LLC by disabling it andtheperformanceisslightlyreducedto60 . 62 and64 . 16 %, respectively. 3.4 Power normalization Concerning power normalization, the retrieval performance obtained using different  X  power values can be found in Fig. 5 . The results show that the use of power normalization also obtains an important boost of performance of the sys-tem. It attains the maximum performance of 68 . 27 % mAP at  X  = 0 . 4for setup A and of 72 . 20 % mAP at  X  = 0 . 3for setup B . Since the performance is pretty similar for  X  = and  X  = 0 . 4, we are going to use a power normalization of  X  = 0 . 35 for both setups in the following experiments. 3.5 Codebook size All the experiments until now have used a relatively small codebook of 1024 codewords. Since the performance usually increases as larger codebook is used, we compare the effects of different codebook sizes in Fig. 6 .
The performance of the system keeps improving until it saturates for the m = 8192 codebook. For larger codebooks, the performance degrades, because descriptor quantization errors start to be too frequent. Since the mAP score increase is marginal between codebooks of m = 4096 and m = 8192, we decided to use the 4096-codebook for the last experiment.
It is worth noting that the mAP score attained by the small-est codebook (with m = 32 codewords) in Fig. 6 doubles the score obtained by the baseline configuration: 45 . 85 % against 22 . 13 % for setup A and 52 . 07 % versus 22 . 74 % for setup B . Although the BoVW signature is more compact and it has 768 dimensions compared to the 1024 dimensions of the baseline configuration, the use of LLC, SPM and power nor-malization greatly increase the spotting capabilities of the system. 3.6 Descriptor sampling Subsequently, we evaluate in Table 2 the effects of using different descriptor sampling parameters. We have evaluated the use of larger regions to check which information is more important to characterize word images. The results show that it is more important that visual words model character frag-ments rather than the relationships among them. We have alsoevaluatedthesamplingdensity,observingthattheperfor-mance increases as the descriptors are sampled more densely. Since the performance gap between the two configurations is quiteimportant,itissafetoassumethatworksthatusedlarger regions (e.g., our previous segmentation-free keyword spot-ting method [ 47 ]) will improve their performance by simply using smaller regions. 3.7 Summary of the Results Finally, we present in Table 3 a summary of the results obtained by the different improvements over the baseline BoVW implementation. Besides the performance gains for each of the improvements, we also report the extra cost that each of the different steps might have. Both using sparse cod-ing through LLC and tuning the descriptor sampling stage have a minimal cost in terms of computational complexity. In the encoding step, the weights of the LLC have to be calculated instead of just using a hard-assignment strategy. When using denser and smaller HOG descriptors, the amount of descriptors to process per word image is increased, and thus, the whole encoding and pooling steps are more complex to compute. When using an SPM configuration, the dimen-sionality of the word descriptors is exponentially increased, so one has to find a good trade-off between discriminative power and efficiency of the overall system in terms of speed and memory usages. The same goes for the codebook size, although we have seen that in that case, the system X  X  perfor-mance degrades when starting to use too large dictionaries. Finally, the use of power normalization has no extra cost with regard to the baseline BoVW implementation. After the final experiment, the performance of the system has increased a 230 % (from 22 . 13 to 72 . 98 %) in setup A and a 236 % (from 22 . 74 to 76 . 45 %) in setup B . Now that we have shown that the performance of the BoVW model greatly varies depending on the methods used to cre-ate the signature, and we can compare the baseline and enhanced BoVW implementations with the state of the art. In order to demonstrate that the enhanced BoVW implemen-tation is competitive against most spotting methods, we are going to compare it against method which used the popular George Washington dataset and the H-KWS 2014 Competi-tion benchmark [ 36 ] to assess their performance. 4.1 George Washington dataset The George Washington dataset has become a de facto standard to evaluate handwritten recognition and keyword spotting methods. In order to conduct this comparison, we will only focus on segmentation-based methods to focus only on the performance of the word snippet descriptor. Segmentation-free and line-based methods follow a more general approach that is likely to obtain worse results due to processing a larger amount of information or due to errors introduced while locating words in the document image.

Although the George Washington dataset is widely used, there is not an standard experimental setup, and each work adapts it to the needs of their proposed algorithm. For instance, learning-based algorithm usually uses cross-validation to avoid evaluating the method on the same data used to fit their model. This reduces the amount of queries since query words must appear both in train and test folds. Also, the number of distractors is reduced as the number of putative results is trimmed. These changes make that a direct comparison between methods is not possible. Therefore, we have recalculated the results obtained by the proposed method employing the experimental setup used in each paper.

A brief summary of the experimental setup and the per-formance comparisons are shown in Table 4 . We can see that all exemplar-based algorithms but the method pro-posed by Howe [ 15 ] do not use cross-validation. In [ 15 ], the author compares his method with the learning-based method proposed by Frinken et al. in [ 13 ], hence the use of cross-validation. Also, most works use mAP to asses their performance, and only Liang et al. [ 24 ] and Howe [ 15 ]use other measures. In [ 24 ], the mAP is calculated only using the ten best results of each query. In [ 15 ], the author first calculates the mean of the precision and recall curves for all the queries and then reports the area under this curve and the precision at full recall. Finally, learning-based methods use the training set as queries, except the work by Almaz X n et al. [ 4 ]. In this work, the authors use the test set as a completely new database so that both query and indexed images have not been seen in the training phase of the algorithm.

In the comparison table, we can see that the obtained results using the baseline BoVW implementation are sig-nificantly worse than the compared works. Only in Wang et al. [ 56 ] the baseline implementation obtains a better result. On the other hand, the results attained by the system when using the enhanced BoVW implementation are significantly better than most of the compared works. The proposed BoVW signature is only outperformed by the method pro-posed by Almaz X n et al. [ 4 ], while Howe [ 15 ] has comparable results. It is worth to note that the method from [ 4 ]usesa canonical correlation analysis step over a BoVW signature, aimed at finding correlations between visual words and word transcriptions. Obviously, the integration of machine learn-ing techniques over BoVW representations is expected to produce better results than a simple distance among descrip-tors [ 2 ]. Concerning the method by Howe [ 15 ], we have to consider the computational complexity of the keyword spot-ting system. The vectorial nature of BoVW allows applying standard indexation techniques for an efficient retrieval. In addition, [ 15 ] needs an alignment step to compute the simi-larity between the query and the document X  X  words. 4.2 H-KWS 2014 Competition The H-KWS 2014 [ 36 ] is a recently proposed benchmark dataset to compare the advances in keyword spotting. It analyzes both segmentation-based and segmentation-free algorithms using performance measures frequently found in the literature. This benchmark is composed by the Bentham and Modern datasets. The Bentham dataset is a collection of 50 images written by Jeremy Bentham himself as well as his secretarial staff. This collection is similar to the George Washington dataset in the sense that the calligraphic dif-ferences between different instances of the same word are minimal. The Modern dataset is a collection of 100 hand-written pages written by several writers. The writers were asked to copy a text written in English, German, French or Greek. Therefore, this dataset has a high calligraphic variety and it uses different scripts.

The comparison between the results obtained by the pro-posed basic and enhanced configurations and the methods which participated in the segmentation-based track of the H-KWS 2014 competition are shown in Table 5 . The results of this table have been obtained using the evaluation tool provided with the benchmark. 1 As we have seen in the George Washington comparison, Kovalchuk et al. [ 21 ] and Howe [ 15 ] are exemplar based, while Almaz X n et al. [ 4 ]isa learning-based algorithm. This algorithm is trained using the annotations of George Washington dataset while creating the model for the Bentham dataset and using the IAM dataset for the Modern dataset.

In Table 5 , we can see that the baseline configuration obtains rather bad results, whereas the enhanced configura-tion is competitive when compared with the other methods. Specifically, looking at the mAP indicator, the enhanced con-figuration only obtains slightly better results than Howe [ 15 ] in the Bentham dataset, while in the Modern dataset it is only surpassed by Almaz X n et al. [ 4 ].

The results obtained in both comparisons stress the fact that the use of simple improvements of the BoVW signatures can lead to a great boost in performance of keyword spotting systems and that it is possible to attain better results than more complex solutions. In this paper, we have studied the effects of different BoVW representations for a handwritten word spotting task. Although the use of BoVW has gained attention as a way to represent segmented handwritten words, most of the literature still uses a basic implementation of the BoVW framework, neglecting the latest improvements of such method.

We have reviewed in this paper the improvements that we believe are more suitable for word representation and seen that applying them can lead to a huge boost on the spotting performance of the system. Some of those improvements have in addition no extra or negligible cost in the whole representation, such as using sparse coding instead of hard assignment or performing a power normalization to each bin of the final descriptor.

Overall, the most important increase in performance came from the use of spatial pyramids, specifically when select-ing a configuration that split the handwritten words across the horizontal axis. We believe that such performance boost comes from the fact that this SPM configuration led the descriptor to encode sequential information of the word, i.e., which character comes before another, mimicking the infor-mation that is encoded in sequential word representations, but while preserving the advantage of holistic word repre-sentations.

