 Community detection is an important task for mining the structure and function of complex networks. Generally, there are several different kinds of nodes in a network which are cluster nodes densely connected within communities, as well as some special nodes like hubs bridging multiple commu-nities and outliers marginally connected with a community. In addition, it has been shown that there is a hierarchical structure in complex networks with communities embedded within other communities. Therefore, a good algorithm is desirable to be able to not only detect hierarchical com-munities, but also identify hubs and outliers. In this pa-per, we propose a parameter-free hierarchical network clus-tering algorithm SHRINK by combining the advantages of density-based clustering and modularity optimization meth-ods. Based on the structural connectivity information, the proposed algorithm can effectively reveal the embedded hier-archical community structure with multiresolution in large-scale weighted undirected networks, and identify hubs and outliers as well. Moreover, it overcomes the sensitive thresh-old problem of density-based clustering algorithms and the resolution limit possessed by other modularity-based meth-ods. To illustrate our methodology, we conduct experiments with both real-world and synthetic datasets for community detection, and compare with many other baseline methods. Experimental results demonstrate that SHRINK achieves the best performance with consistent improvements. H.2.8 [ Database Applications ]: Data Mining; G.2.2 [ Graph Theory ]: Graph Algorithms; I.5.3 [ Clustering ]: Algorithms Algorithms, Design, Performance Hierarchical Community Discovery, Graph Clustering, Hubs and Outliers
Nowadays, many real-world networks possess intrinsic com-munity structure, such as large social networks, Web graphs, and biological networks. A community (also referred to as a module or cluster) is typically thought of a group of nodes with dense connections within groups and sparse connec-tions between groups as well. Detecting communities in a network can provide insight into how network function and topology affect each other and has received a great deal of attention in recent years. For example, communities in a co-authorship network might imply researchers working to-gether with the same interests, and communities in a cita-tion network might indicate related papers on a single topic, meanwhile communities on the Web graph might represent pages of related topics.

Finding communities in complex networks is a nontriv-ial task, since the number of communities in the network is typically unknown and the communities are often of unequal size or density. Moreover, it has been shown that there is a hierarchical structure of complex networks with communi-ties embedded within other communities. Essentially, small communities group together to form larger ones, which in turn group together to form even larger ones [16]. Taking the co-authorship network extracted from DBLP in Figure 1 as an example, a research field can be composed of many research groups with the same academic interests. For ex-ample, there are many groups in DM research field, while a group may consist of several subgroups like  X  X ata stream mining X ,  X  X raph mining X , X  X ining moving object X  and so on.
Besides the general nodes that are densely connected with communities, there are some special nodes like hubs (de-noted as red diamonds) and outliers (denoted as white tri-angles) in Figure 1. For example, some researchers, like  X  X i-Figure 1: Community structure and node roles for an example of co-authorship network extracted from DBLP. awei Han X  X nd X  X hilip S. Yu X , have published a large amount of papers in collaboration with people from various research communities. These nodes should be considered as hubs that are closely related to different communities, forming over-lapping communities. As we know, hubs play special and important roles in many real-world networks. For example, hubs in the WWW could be utilized to improve the search engine rankings for relevant authoritative Web pages [14], and hubs in viral marketing [7] and epidemiology [5] could be central nodes for spreading ideas or diseases. Further-more, there are some nodes that are marginally connected with the community members, such as the white triangles in Figure 1. In reality, a visiting scholar who only publishes one paper with researchers in the hosted group should not be considered as a member of the group, and meanwhile it is better to be regarded as an outlier. Since outliers have little or no influence in a community, they may be isolated as noise in the network. Therefore, how to detect hierarchi-cal communities as well as hubs and outliers in a network becomes an interesting and challenging problem. However, most existing approaches only study the community detec-tion without considering hubs and outliers. In this paper, we propose a parameter-free hierarchical network clustering algorithm SHRINK by combining the advantages of density-based clustering and modularity-based methods. The main contributions are summarized in the following: 1. We propose a novel parameter-free network cluster-2. Our algorithm can find the communities with various 3. By combining the advantages of density-based cluster-
The rest of the paper is organized as follows. First we briefly review some related work in Section 2. In section 3, we formulize the notion of hierarchical structural-connected clusters. In section 4, we describe the algorithms in detail. In section 5, we report the experimental results. Finally, we summarize our conclusions and suggest future work in section 6.
Community discovery in complex networks has been stud-ied for years in multiple fields, particularly computer science and physics. Traditional graph partitioning methods, such as Kernighan-Lin algorithm [13], Girvan-Newman algorithm [11], normalized cut [24], and spectral bisection methods [25] have been widely applied to find network communities. Re-cently, significant progress has been archived in this research field and many approaches have been presented for detecting communities in networks.

Modularity-based methods: For evaluating the qual-ity of network partitions, Newman and Girvan proposed the modularity measure Q [20] which has been widely used in community discovery. Modularity-based methods assume that high values of modularity indicate good partitions. But it has been proven that modularity optimization is an NP-complete problem. Most of the modularity-based algorithms find good approximation of the modularity maximum with high computational complexity such as SA (Simulated An-nealing) [12], FN [19], and CNM [6]. Recently, Blondel et al. proposed a greedy modularity-based algorithm, called BGLL[3], for finding communities in weighted networks. This algorithm has a low computational complexity and can dis-cover hierarchical communities. However, the results of the algorithm depend on the order in which the nodes are vis-ited. Actually, the methods of greedy optimization of mod-ularity often tend to form large communities through com-bination of small ones. Recent research shows that modu-larity is not a scale-invariant measure, and hence, by rely-ing on its maximization, detection of communities smaller than a certain size is impossible. This serious problem is famously known as the resolution limit of modularity-based algorithms [10]. Compared with the traditional modularity-based methods, our work use the modularity as a quality function to guide the selection of optimal hierarchical com-munities.

Hierarchical and Overlapping methods: In the pres-ence of hierarchy, the concept of community structure be-comes richer. Agglomerative or divisive hierarchical cluster-ing are well-known techniques to solve this problem [19, 11]. Starting from a partition in which each node is its own com-munity, or all nodes are in the same community, one merges or splits clusters according to a topological measure of sim-ilarity between nodes. In this way, one builds a hierarchical tree of partitions. Though this type of methods naturally produces a hierarchy of partitions, it needs a metric to stop the algorithm. Recently, some work focused on the problem of identifying meaningful community hierarchies [23] and de-tecting multiresolution levels [2, 16, 22].

The issue of finding overlapping communities has become a hot topic. Palla et al . proposed a clique percolation method (CPM) [21]. A complete sub-graph of k nodes, called k -clique, is rolled over the network through other cliques with k  X  1 common nodes. In this way, a set of nodes can be reached, which is regarded as a community. One node can belong to more than one community; therefore, overlaps naturally occur. The CPM algorithm is limited by its as-sumption that the graph has a large number of cliques. Fur-thermore, the method is not suitable to detect hierarchical structure. Recently, Nepusz et al. considered the problem of fuzzy community detection in networks, which expands the concept of overlapping community structure [18]. Ev-ery node is allowed to belong to multiple communities with different degrees of membership. A measure was introduced to identify regular nodes in a community, hubs that have significant membership in more than one single community, and outliers that do not belong to any of the communities.
In real networks, communities are usually both hierar-chical and overlapping. Most existing methods investigate these two phenomena separately. Our work is one of the few methods that try to discover both hierarchical communities and overlapping nodes in a given network.

Density-based methods: Density-based clustering ap-proaches (e.g., DBSCAN [8] and OPTICS [1]) have been widely used in data mining owing to their ability of find-ing clusters of arbitrary shape even in the presence of noise. Recently, Xu et al. proposed an efficient structural net-work clustering algorithm SCAN [26] through extension of the DBSCAN [8]. This algorithm can find communities as well as hubs and outliers in a network. However, it requires a minimum similarity parameter " and a minimum cluster size to define clusters, and is sensitive to the parame-ter " which is difficult to determine automatically. To deal with this problem, Bortner et al . proposed a new algorithm, called SCOT+HintClus [4], to detect the hierarchical cluster boundaries of network by extending the algorithm OPTICS [1]. However, it does not find the global clustering result and needs an additional pruning process to expose the reasonable hierarchical structure of the networks. Our work tries to de-velop a parameter-free method to explore the hierarchy of structural-connected communities with multiresolution lev-els in networks.
The goals of our algorithm are not only to cluster networks hierarchically but also to identify two kinds of special nodes: hubs and outliers. Therefore, local connectivity structure of the network is used in our optimal clustering. In this section, we formalize some notions and properties of the hierarchical structure-connected clusters.

Definition 1. (Structural Similarity) Let G = ( V; E; w ) be a weighted undirected network and w ( e ) be the weight of the edge e . For a node u  X  V , we define w ( { u; u } ) = 1. The structure neighborhood of a node u is the set  X ( u ) containing u and its adjacent nodes which are incident with a common edge with u :  X ( u ) = { v  X  V |{ u; v } X  E } X  X  u } . The structural similarity between two adjacent nodes u and v is then Figure 2: A segment of similarity-plot for the DBLP co-authorship network.

The above structural similarity is extended from a cosine similarity used in [26] which effectively denotes the local connectivity density of any two adjacent nodes in a weighted network. It can be replaced by other similarity definitions such as Jaccard similarity, and our experimental results show that the cosine similarity is better.

The density-based clustering algorithm OPTICS [1] shows that the hierarchical cluster structure of a dataset can be obtained from the reachability-similarity values plotted for each object in the cluster-ordering. Here we intend to design a parameter-free algorithm, and we do not use the minimum similarity threshold " and the minimum cluster size any more. Actually, the reachability-similarity of any adjacent nodes u and v are equal to their structural similarity when = 2 and the clustering results are not sensitive to the parameter . In Figure 2, we give a segment of ordered similarity-plot extracted from the DBLP co-authorship net-work. It is able to observe that the similarity distribution describes the intrinsic clustering structure accurately with high similarity regions surrounded by low similarity regions. The clusters are clearly discernible as  X  X ountains X  in the plot, and the hubs and outliers are located in the low re-gions between the mountains. Thus, if we explore the clus-ters from the top of each mountain to the plain, we would find not only the nested cluster structure, but also clusters with a variety of densities. Each local maximum of the sim-ilarity in the plot corresponds to a densely connected node pair.

Definition 2. (Dense Pair) Given a network G = ( V; E ), ( u; v ) is the structural similarity of nodes u and v . If ( u; v ) is the largest similarity between nodes u; v and their adjacent neighbor nodes: ( u; v ) = max { ( x; y ) | ( x = u; y  X   X ( u ) { u } )  X  ( x = v; y  X   X ( v )  X  X  v } ) } , then { u; v } is called a dense pair in G , denoted by u  X  " v , where " = ( u; v ) is the density of pair { u; v } .

A dense pair is a pair of nodes with the largest similarity from each other. That is to say, the connectivity density of the two nodes is not less than their surrounding links. As shown in Figure 3, { 9 ; 13 } is a dense pair with density 0.8165 in the example network.

Definition 3. (Micro-community) Given a network G = ( V; E ), C ( a ) = ( V  X  ; E  X  ; " ) is a connected sub-graph of G represented by a node a . C ( a ) is a local micro-community iff 1) a  X  V  X  ; 2)for all u  X  V  X  ,  X  v  X  V  X  ( u  X  " v ); 3) Figure 3: The micro-communities in an example net-work weighted by structural similarity.
 V ( u  X  " v  X  u  X  V  X   X  v =  X  V  X  ). " is the density of the micro-community C ( a ).

The micro-community is an isolated node or a sub-graph that consists of one or more connected dense pairs with cer-tain density " . As shown in Figure 3, the single node set forms a micro-community with density 1 and the nodes set { 8 ; 11 ; 12 } forms a micro-community with density 0.8 in the toy network. For any node v  X  V , v must be in the same micro-community with itself. Obviously, it is symmetric and transitive for the relation of nodes being in the same micro-community. Thus, a network will be partitioned into one or more local micro-communities by this equivalence relation. The involved properties are introduced in the following the-orems.

Theorem 1. Given a network G = ( V; E ) , C ( a ) = ( V  X  is a micro-community in G . For all u  X  V , C ( u ) = C ( a ) iff u  X  V  X  .

Theorem 2. Given a network G = ( V; E ) , C = ( V  X  ; E  X  is a micro-community with density " in G . If u  X  V  X  and v  X   X ( u )  X  X  u } , then ( u; v )  X  " .

According to the partitioning by micro-communities, the original network can be reduced into a smaller super-graph by shrinking the micro-communities into super-nodes. Then a dense micro-community can be regarded as a single node in the following process.

Definition 4. (Super-network) Given a network G = ( V; E; ),  X  V = { V 1 ; V 2 ;  X  X  X  ; V k } is a partition of the node set V and  X 
V i  X   X  V , the sub-network G i = ( V i ; E i ) induced by the node set V i is a local micro-community in G . Define  X  E = {{
V i ; V j }| X  u  X  V i ;  X  v  X  V j ; { u; v } X  E } and  X  ( V max { ( u; v ) | u  X  V i ; v  X  V j } ; then  X  G = (  X  V ; super-network of G .

When a hierarchical tree of local micro-communities has been built, the following Theorem 3 shows that the density of a local micro-community is not less than the density of the bigger micro-community in which it is embedded.
Theorem 3. Given a network G = ( V; E; ) and its super-in  X 
G , and V  X   X   X  V  X  , then  X  "  X  " .
In this section, we describe the hierarchical clustering al-gorithm SHRINK-H which reveals the densely connected clusters, hubs and outliers in networks. A similarity-based modularity gain is adopted to evaluate the quality of micro-communities and to stop the algorithm. In order to re-duce the running time, we also introduce a greedy algorithm SHRINK-G which is more efficient with almost the same clustering results.
A metric is necessary for our algorithm to measure the goodness of the discovered hierarchical communities. Many quality functions have been proposed, such as modularity, fitness, etc . Here we select the modularity measure Q as the quality function because of its effectiveness in practice and efficiency for calculation. We use the similarity-based modularity function Q s proposed by Feng et al. in [9]. It is extended from the connection-based modularity Q and has a better ability to deal with hubs and outliers. Given a cluster CR = { C 1 ; C 2 ;  X  X  X  ; C k } of the network G = ( V; E ), the function Q s is defined as follows: where k is the number of clusters, IS i = is the total similarity of nodes within cluster C i , DS i u  X  C i ;v  X  V ( u; v ) is the total similarity between nodes in cluster C i and any node in the network, and T S = is the total similarity between any two nodes in the network.
To enhance the efficiency of the algorithm, we calculate the modularity Q s incrementally. Given two adjacent mod-ule C i and C j , the modularity gain  X  Q s can be computed by where U S ij = the links between two modules C i and C j .

Based on the equation (3), the gain of modularity Q s for merging a micro-community C = { c 1 ; c 2 ;  X  X  X  ; c k a super-node can be easily computed as
The similarity-based modularity described above is a met-ric to evaluate the quality of a partition. Here we use the gain of modularity to control the shrinkage of the micro-communities. If the modularity gain  X  Q s of a micro-community C is positive, we argue that the nodes of C should be clus-tered in the same community. Thus, given a network G , the task of our community discovery algorithms is to find a higher modularity solution under the principle of density-based clustering, rather than to search a partition greedily maximizing the modularity Q s .
The pseudo-code of our hierarchical clustering algorithm, called SHRINK-H, is given in Algorithm 1. The main pro-cess can be divided into two phases that are repeated iter-atively, as shown in Figure 4(a). Given a network with n nodes, first we initialize each node with a different commu-nity label. In this initial partition, the number of communi-ties is the same as the number of nodes. Then, for each node i we find its local micro-community. This process is applied sequentially for all nodes. We record all the different micro-communities which represent a partition of the network and then the first phase is completed. The second phase of the algorithm is to build a super-network. We evaluate the gain of Q s for the shrinkage of the micro-communities found dur-ing the first phase. If the gain is positive, the corresponding local community is replaced by a super-node. The above two phases are executed in turns until there is no micro-community with positive modularity gain. Then the hier-archy of communities naturally occurs, as shown in Figure 4(b). This algorithm is efficient because the size of the net-work is reduced rapidly in the process. In each iteration, a node is visited only once and the corresponding local micro-communities do not depend on the order in which the nodes are visited.

If one wants to get traditional non-overlapping partitions or overlapping communities without hubs and outliers, a post-process can be employed to deal with the  X  X omeless X  nodes: hubs and outliers. The homeless nodes whose neigh-bors are within at most one cluster are outliers. Each out-lier can be assigned to its adjacent cluster as a border node. Other homeless nodes are regarded as hubs. If overlapping communities are considered, the hubs can be assigned to their adjacent communities as border nodes shown in Fig-ure 4(c). Otherwise, they can be assigned to the adjacent community that harvests the largest positive gain of Q s .
To enhance the efficiency, we propose a modified greedy al-gorithm SHRINK-G. Compared with micro-community, the dense pair is a smaller unit which has the largest density among its surrounding links. If we do not consider the hi-erarchical structure of communities, we can cluster the net-work via greedy shrinkage of the dense pairs. Thus, each dense pair in a micro-community is considered separately. Starting with an arbitrary node u in a network G , we find the dense pair containing u . If there is a node v adjacent to u that forms a dense pair { u; v } and its modularity gain is positive, we merge node v and u to form a super-node u  X  . Then we check whether there exists a dense pair containing u and try to shrink it. The above process is repeated until there does not exist a shrinkable dense pair containing cur-rent node. Then the algorithm continues with next unvisited node. The clustering is accomplished when all the nodes in the network G are visited. The pseudo-code of this clus-tering algorithm is given in Algorithm 2, called SHRINK-G. Since this algorithm needs to visit all the nodes in a network only once, it is much faster than the SHRINK-H. However, the clustering result may rely on the visiting sequence of the nodes. Nevertheless, our experimental results on a large amount of networks show that the clustering results of the above two algorithms are the same in most cases.
In this section, we evaluate the proposed algorithm SHRINK using some real-world datasets and synthetic benchmark datasets. We compare our algorithms with the density-based network clustering algorithm SCAN and two representative modularity-based methods: CNM [6] and BGLL [3]. Our algorithms are implemented in ANSI C++. All the experi-ments were conducted on a PC with a 2.4 GHz Pentium IV processor and 2GB of RAM.
In our experiments, we adopt Normalized Mutual Infor-mation (NMI), an information-theoretic based measurement, Algorithm 1 : SHRINK-H Algorithm 2 : SHRINK-G to evaluate the quality of clusters generated by different methods. It is currently widely used in measuring the per-formance of network clustering algorithms [15]. Formally, the measurement metric NMI can be defined as where N is the confusion matrix, N ij is the number of nodes in both cluster X i and Y j , N i: is the sum over row i of N and N :j is the sum over column j of N . Note that the value of NMI ranges between 0.0 (total disagreement) and 1.0 (total agreement).
To assess the performance of the proposed method in terms of accuracy, we conduct experiments on the DBLP Co-authorship network and two popular real-world networks from Newman 1 .
The DBLP Co-authorship network in four research fields (i.e., DB, IR, DM and ML) was extracted from the DBLP computer science bibliographical dataset. We only consider the authors who have published more than twenty papers. Then we obtain a weighted undirected network with 1,547 nodes and 7,789 edges, in which each node corresponds to a distinct author and the edge between two nodes represents their co-author relationship. The integral weight of an edge denotes the number of papers co-authored by these two au-thors.

Our algorithms SHRINK-H and SHRINK-G get the same clustering result on this network, where 172 communities as well as 162 hubs and 47 outliers are found. Due to the limited space, we can not present all the extracted commu-nities. We then select six representative communities and list no more than ten cluster members along with two rep-resentative hubs and outliers in Table 1. Each community represents a group of scientists with the same research in-terests, such as machine learning community (36) and in-formation retrieval community (147) in Table 1. Here we are able to observe that SHRINK can discover meaning-ful co-authorship communities from a large amount of real academic associations. The identified hubs indicate some famous researchers who have published a large number of papers in collaboration with a variety of research groups. On the contrary, the identified outliers always correspond to those researchers who may only publish one or few pa-pers coauthored with other scholars. Based on the results, we can see that SHRINK is effective to find the meaningful hubs and outliers from the research communities.
The Zachary X  X  karate network [27] consists of 34 nodes and 78 edges as shown in Figure 5. This network can be separated into two distinct groups by the dashed line since there is a conflict between one of the administrator (repre-sented by node 1) and the instructor (represented by node 33) of the club.
 As shown in Figure 5, our algorithms SHRINK-H and SHRINK-G can find four communities in this network rep-resented by different colors. The roles of nodes are repre-http://www-personal.umich.edu/  X  mejn/netdata/ Figure 5: The clustering result of SHRINK on the Zachary X  X  karate network. sented by different shapes: two hubs denoted by diamonds, six outliers denoted by triangles in the network, and oth-ers are general cluster members. In our algorithms, nodes 10 and 20 are identified as hubs. The reason is that these two nodes connected with two adjacent communities in the same way. Hence, it is better for them to be considered as shared nodes (i.e., hubs). Due to the sparse links of this network, nodes 12, 15, 16, 19, 21 and 23 are identified as outliers which are loosely connected with the communities. In short, the SHRINK algorithm can successfully detect the community and identify the hubs and outliers.

Although this partition of four communities in Figure 5 does not match the ground truth of the dataset, many other methods obtain the same result which indicates that it is topologically meaningful. The SCAN algorithm get the same clustering result as our algorithms by using manually detected parameters ( " = 0 : 527, = 3). The BGLL algo-rithm also find four communities in this network, but it can not find the hubs and outliers and it assigns the nodes 10 and 20 to the community of administrator. We also cluster this network using the CNM algorithm, but it only detects three communities in this network, among which the group of ad-ministrator is divided into two unreasonable sub-groups: { 5, 6, 7, 11, 12, 17, 20 } and { 2, 3, 4, 8, 10, 14, 18, 22 result of CNM indicates that the agglomerative hierarchical performs badly in greedy modularity maximization.
The National Collegiate Athletic Association (NCAA) College-football is a social network with communities (or confer-ences) of American college football teams. In total, there are 115 college football teams, which are divided into eleven conferences and five independent teams (Utah State, Navy, Notre Dame, Connecticut and Central Florida) that do not belong to any conference. The network, representing the schedule of Division I-A games for the 2000 season, con-tains 115 nodes and 613 edges. Now the question is to find out the communities from the graph. Figure 6(a) illustrates the football network with each vertex represents a school team. The teams belonging to a conference and the indepen-dent teams are denoted by circles and diamonds respectively, and teams in the same conference are identified by the same color. There is a link between two teams if they played a game together. The number of teams in a conference ranges from seven to thirteen. Each team plays about ten games in the season. Consequently, the inner link density of each conference is different.
 The clustering result of our algorithms SHRINK-H and SHRINK-G is presented in Figure 6(b). We obtain eleven clusters in this network which demonstrates a good match with the original conference system. Four independent teams are correctly identified as hubs. Although there is an inde-pendent team that is falsely merged into a conference, and three misclassified teams (i.e., Louisiana Monroe, Louisiana Lafayette, and Louisiana Tech), our algorithm still performs much better than other methods including the SCAN, CNM and BGLL algorithms, which will be described as follows.
The SCAN algorithm finds thirteen communities as its best result in this dataset with parameters ( " = 0 : 53, = 2). The teams in the conference denoted by black circles in Figure 6(a) are divided into two clusters. Meanwhile, five hubs are identified including four correct independent teams: CentralFlorida, Connecticut, Navy, and NotreDame. An-other independent team UtahState is misclassified into a conference. The accuracy of SCAN is worse than our algo-rithm, because it is hard for the SCAN algorithm to detect communities with various densities by using a global den-sity threshold " . The modularity-based algorithm CNM and BGLL discover seven and ten communities in this network respectively. The algorithm CNM only finds four clusters matching with the conferences. For the five independent teams, they are assigned to three different clusters.
In summary, SHRINK generates promising clustering re-sults along with hubs and outliers in community detection, consistently outperforming baseline methods including the SCAN, CNM and BGLL algorithms. Table 2: The parameters of the computer-generated datasets for performance evaluation.

So far, we have presented the experimental results of our algorithms using several real-world networks. Now we also use the Lancichinetti-Fortunato-Radicchi (LFR) benchmark graphs [17, 15] to evaluate the performance of our algo-rithms. By varying the parameters of the networks, we can analyze the behavior of the algorithms in detail. Some im-portant parameters of the benchmark networks are given in Table 2. We generate several weighted undirected bench-mark networks with the number of nodes n = 5,000 and 50,000. For each n , two individual networks are generated with different ranges of the community sizes, where S means that the sizes of the communities in the dataset are relatively small and B means that the sizes of communities are rela-tively big. For each type of dataset, we range the mixing parameter mu from 0.1 to 0.8 with a span of 0.05 and get fifteen networks. Generally, the higher the mixture param-eter of a network is, the more difficult it is to reveal the community structure. Some important parameters of the benchmark networks are:  X  n : number of nodes  X  m : average number of edges  X  k : average degree of the nodes  X  maxk : maximum degree  X  mu : mixing parameter, each node shares a fraction mu of its edges with nodes in other communities  X  minc : minimum for the community sizes  X  maxc : maximum for the community sizes
Due to the difficulty of detecting the parameter " in the benchmark networks for the algorithm SCAN, we only com-pare our algorithm with two baseline methods of modular-ity optimization: CNM and BGLL. Because these two al-gorithms both assign each node to just one community, a post-process is used in our algorithms to assign the homeless nodes into the community with largest positive modularity gain. The clustering results of our algorithms SHRINK-H and SHRINK-G are almost the same or only slightly differ-Figure 7: Test of the accuracy of SHRINK, BGLL, and CNM algorithms on the computer-generated benchmark networks. ent in all generated networks. Thus, we report the average values of these two algorithms. The NMI scores of the three methods are plotted in Figure 7. On most of the benchmark datasets, our algorithm gets NMI = 1 when mu &lt; 0 : 5, which means a perfect match with the original network structure. We can see that the performances of SHRINK are better than that of BGLL on the generated networks in most cases, because the BGLL algorithm tends to produce small number of big communities on the large-scale networks, due to the well known resolution limit of modularity [10]. For the pure modularity optimization algorithm CNM, it performs worse than both BGLL and SHRINK algorithms. However, the performance of our algorithm is decreased when mu &gt; 0 : 5, especially in the small-scale network with big communities (e.g. 5000B). This is because our algorithms have to deal with more and more isolated hubs and outliers with the in-creasing of parameter mu .
Despite the good performance of the modularity measure on many practical networks, it may lead to apparently un-Figure 8: Two schematic networks (the numbers on the edge represent the structural similarity): (a) the Ring network made out of identical cliques con-nected by single links, and (b) the Pairwise network with four identical cliques.
 Table 3: The number of communities on Ring and Pairwise datasets found by SA, CNM, BGLL, and SHRINK.
 reasonable partitions in some cases. It has been shown that modularity contains an intrinsic scale that depends on the total number of links in the network. Communities that are smaller than this intrinsic scale may not be resolved, even in the extreme case where they are complete graphs connected by some single bridges. The resolution limit of modularity actually depends on the degree of interconnect-edness between pairs of communities and can reach values of the order of the size for the whole network [10].
In Figure 8(a), we show a network consisting of a ring of several cliques, connected through single links. Each clique is a complete graph with n nodes and n ( n  X  1) = 2 links. Sup-pose there are c cliques (with c even), the network has a total of N = nc nodes and M = cn ( n  X  1) = 2 + c edges. According to [10], modularity optimization would lead to a partition where the cliques are combined into groups of two or more (represented by dotted lines). Here, we use a syn-thetic dataset with n = 5 and c = 30, called Ring. Another synthetic network is shown in Figure 8 (b). In this network, the larger circles represent cliques with n nodes, denoted as K n , and the small cliques with p nodes. According to [10], we set n = 20, p = 5 and get the network called Pairwise. Modularity optimization merges the two smallest communi-ties into one (shown with a dotted line).

We present the clustering results on the above two datasets in Table 3, where n is the number of node, m is the number of edges, and c is the correct number of communities. Our al-gorithms SHRINK-H and SHRINK-G find the exact commu-nities. For the Ring and Pairwise datasets, the modularity-based algorithms SA (optimized by simulated annealing), CNM, and BGLL all possess the resolution limit problem which result in merging two small cliques into one cluster. Following [10], we also conduct experiments on five exam-Table 4: The real-world datasets for analyzing reso-lution limit of the modularity-based algorithms and the clustering results by SA, CNM, BGLL, and SHRINK.
 ples of real-world networks: Yeast 2 , E. coli 2 , Elect. circuit Social 2 , and C. elegans 3 . We consider the above five net-works as undirected. The datasets and clustering results are listed in Table 4. In most cases, the numbers of com-munities obtained by our algorithms are the most accurate results, which are very close to the ground truth.
The reason that our algorithms can overcome the reso-lution limit is that it combines the density-based clustering principle and the modularity measure. The connected nodes with higher similarity will be considered preferentially as in the same community than the lower ones. Moreover, all of the adjacent nodes with equal similarities will be merged in one community or be staying alone.
Finally, we analyze the computational complexity of our algorithm SHRINK. The running time of SHRINK-H is mainly consumed by finding micro-communities and merging the nodes in them in each iteration. The time complexity is O ( m ) for the network with m edges. If there are h steps for the algorithm to terminate, the time complexity of is O ( m  X  h ). Our tests show that h is always linear in loga-rithm of the number of nodes n (i.e., log n ), which results in an overall time complexity of O ( m log n ).
 To illustrate the running time of the proposed algorithms SHRINK-H and SHRINK-G, we generate seven networks with the number of nodes n ranging from 1,000 to 300,000. For each network, the number of edges m is ten times of the number of nodes. The running time for SHRINK-H and SHRINK-G are plotted as a function of the number of nodes in Figure 9, respectively. It shows that our algo-rithm SHRINK-H can process the network of 300,000 nodes within an hour. The greedy clustering algorithm SHRINK-G is faster than the hierarchical one. Actually, we are able to reduce more than half running time of SHRINK-H with the similar performance.
In this paper we present a novel parameter-free network clustering algorithm SHRINK by combining the advantages of density-based clustering and modularity optimization meth-ods. Based on the structural connectivity information, the proposed algorithm can effectively reveal the embedded hi-erarchical community structure in large-scale weighted undi-rected networks, and identify hubs and outliers as well. More-over, it overcomes the sensitive threshold problem of density-based clustering algorithms and the resolution limit pos-sessed by other modularity-based methods. Experimental www.weizmann.ac.il/mcb/UriAlon/groupNetworksData.html http://toreopsahl.com/datasets/ Figure 9: Running time for SHRINK with varying network sizes. results on the real-world and synthetic datasets show that our algorithm achieves the best performance when compared with the baseline methods. It is efficient with time complex-ity O ( m log n ). In the future, it is interesting to investigate the local communities in large-scale online networks, and to use our method to analyze complex networks in various applications.
The authors would like to thank Andrea Lancichinetti for his valuable comments of the manuscript. The work was supported in part by the National Science Foundation of China grants 60933009/F0205, Natural Science Basic Re-search Plan in Shaanxi Province of China grants SJ08-ZT14, the U.S. National Science Foundation grants IIS-09-05215, IIS-08-42769, CCF-0905014, and BDI-07-Movebank. Any opinions, findings, and conclusions expressed here are those of the authors and do not necessarily reflect the views of the funding agencies. [1] M. Ankerst, M. M. Breunig, H.-P. Kriegel, and [2] A. Arenas, A. Fernandez, and S. Gomez. Analysis of [3] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and [4] D. Bortner and J. Han. Progressive clustering of [5] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and [6] A. Clauset, M. E. J. Newman, and C. Moore. Finding [7] P. Domingos and M. Richardson. Mining the network [8] M. Ester, H. Kriegel, J. Sander, and X. Xu. A [9] Z. Feng, X. Xu, N. Yuruk, and T. A. J. Schweiger. A [10] S. Fortunato and M. Barth  X elemy. Resolution limit in [11] M. Girvan and M. E. J. Newman. Community [12] R. Guimer`a and L. A. Nunes Amaral. Functional [13] B. W. Kernighan and S. Lin. An efficient heuristic [14] J. Kleinberg. Authoritative sources in a hyperlinked [15] A. Lancichinetti and S. Fortunato. Community [16] A. Lancichinetti, S. Fortunato, and J. Kertesz. [17] A. Lancichinetti, S. Fortunato, and F. Radicchi. [18] T. Nepusz, A. Petr  X oczi, L. N  X egyessy, and F. Bazs  X o. [19] M. E. J. Newman. Fast algorithm for detecting [20] M. E. J. Newman and M. Girvan. Finding and [21] G. Palla, I. Derenyi, I. Farkas, and T. Vicsek. [22] P. Ronhovde and Z. Nussinov. Multiresolution [23] M. Sales-Pardo, R. Guimera, A. A. Moreira, and [24] J. Shi and J. Malik. Normalized cuts and image [25] S. White and P. Smyth. A spectral clustering [26] X. Xu, N. Yuruk, Z. Feng, and T. Schweiger. SCAN: a [27] W. W. Zachary. An information flow model for
