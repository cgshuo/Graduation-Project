 We study the problem of active learning for multilabel clas-sification. We focus on the real-world scenario where the average number of positive (relevant) labels per data point is small leading to positive label sparsity. Carrying out mu-tual information based near-optimal active learning in this setting is a challenging task since the computational com-plexity involved is exponential in the total number of la-bels. We propose a novel inference algorithm for the sparse Bayesian multilabel model of [17]. The benefit of this alter-nate inference scheme is that it enables a natural approxi-mation of the mutual information objective. We prove that the approximation leads to an identical solution to the exact optimization problem but at a fraction of the optimization cost. This allows us to carry out e cient, non-myopic, and near-optimal active learning for sparse multilabel classifica-tion. Extensive experiments reveal the e  X  ectiveness of the method.
 I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Performance, Machine Learning, Optimization Multi-label Learning; Active Learning; Mutual Information
The goal in multilabel classification is to learn a classi-fier which can automatically tag a data point with the most relevant set of labels. This is in contrast to multi-class clas-sification where only a single label needs to be predicted per data point. Our objective, in this paper, is to develop an e cient, non-myopic and near-optimal active learning algorithm for multilabel classification employing a mutual information based data point selection criterion.
There has been much recent interest in sparse multilabel learning [2, 15, 17]. In this scenario, each data point ex-hibits positive label sparsity in that only a small fraction of any point X  X  labels are ever marked as positive or relevant. Note that this is a typical setting in most real world ap-plications  X  the average number of positive labels per data point ranges from less than 5% on most UCI data sets to less than 0.001% on Wikipedia and other web data sets [2]. Sparse multilabel learning therefore presents an important, real-world and novel challenge to active learning techniques.
Traditional active learning techniques for multilabel learn-ing do not take positive label sparsity into account [11, 13, 20,21,31]. Furthermore, these techniques are myopic and ac-tively select only a single data point at a time for annotation. As a result, there is no provable guarantee that the final set of annotated points is optimal or even near-optimal. While mutual information based data sampling can provide near-optimal guarantees in certain regression settings [18,19], it is non-trivial to extend those to the active multilabel setting.
In this paper, we first develop an alternate inference tech-nique for the sparse Bayesian multi-label graphical model of [17] which allows us to carry out e cient mutual infor-mation based active learning. We develop an approximation to the mutual information which is tightly coupled to our in-ference algorithm and which can be optimized much more e ciently than the exact mutual information. This approxi-mation allows us to develop an active learning strategy that has the following desirable properties:
Our main technical contribution is Theorem 1 where we prove that, at any given data point selection step, our ap-proximation leads to an identical solution as would have been obtained using exact mutual information in the limit-ing case, but at a fraction of the optimization cost. Further-more, by performing inference in a sparse Gaussian Process regression model, we can leverage the mutual information guarantees to provably show that the entire subset of data points selected for annotation by our proposed algorithm is near-optimal. This enables us to carry out active sparse multilabel learning in an e cient, non-myopic and theoret-ically principled fashion. Finally, as a natural extension of our method, the matrix inversions necessary for traditional active learning can be carried out in time that is independent of the size of the label vector for a point.

Extensive experiments reveal that our proposed active learning strategy consistently outperforms the state-of-the-art approaches based on variance sampling, SVM based ac-tive learning proposed in [20] and random sampling base-lines. Furthermore, we demonstrate that our inference pro-cedure leads to a better estimate of the variance needed for Bayesian active learning as compared to existing techniques. We also show that our method has significant gains (20 times gain over the delicious dataset with 983 labels) in time consumption over the state-of-the-art [20] as the number of labels increases. Finally, we demonstrate that our proposed approach can also be used to sample both labels as well as data points, thereby allowing learning at an even lower annotation cost as compared to existing techniques which have so far focussed on all the labels being annotated for a selected data point.

Our main contributions are as follows: (a) a novel infer-ence procedure for the Bayesian sparse multilabel graphical model of [17]; (b) an approximation to the mutual infor-mation which follows naturally from our proposed inference procedure; (c) a proof that our proposed approximation se-lects the same data point as would have been chosen by op-timizing mutual information (in the limiting case); and (d) an extensive evaluation of the proposed scheme on a diverse range of real world datasets to prove the gains obtained by our algorithm. These contributions allow us to carry out e cient mutual information based active sparse multilabel learning for the first time (to the best of our knowledge).
Past work in active learning has primarily focused on sin-gle label classification tasks [24]. However, multilabel clas-sification has received wide interest in recent times [2,3,5,8, 10, 12, 15 X 17, 28 X 30, 32, 33]. Active learning is more advan-tageous in this setting as label acquisition costs are higher for multilabel scenario. However, research in active learning for multilabel classification is still in its preliminary stage. Current multilabel active learning strategies train a binary SVM classifier for each label and combine the SVM margins using di  X  erent heuristics to select the training set from a pool of available data for annotation [11, 21, 27]. [27] takes the average of the SVM uncertainties obtained by Platt scal-ing [23] and uses it as a selection criterion for greedily select-ing the set of points to be annotated. [21] uses Mean Max Loss(MML) and Max Loss(ML) as two separate selection criteria for annotation of points. [31] uses logistic regression to predict the number of positive labels for each point and uses another SVM based heuristic to minimize expected loss for point selection. The state-of-the-art method [20] uses a combination of deviation from mean label cardinality and an SVM-based loss function for active learning. To the best of our knowledge, all these works are myopic and do not provide any theoretical guarantees on the optimality of the selected set.

On the other hand, mutual information has proved to be a very useful criterion for active learning with Gaussian Pro-cesses [18,19,26], both empirically and theoretically. In these schemes, each point is selected from a pool of available unla-beled data, so as to maximize the information gain over the remaining unlabeled data. The approximate submodularity of mutual information ensures that a set of points selected greedily based on this criterion will be near-optimal [19]. However, extending mutual information to multilabel clas-sification is non-trivial as a straightforward computation of mutual information over the label space is exponential in the number of labels.

The Bayesian compressed sensing model proposed in [17] is closest to our work, in the sense that it models the multil-abel classification task as a Gaussian Process. However, the approximations made in [17], for the inference procedure to be tractable, do not preserve the covariance matrix across labels and hence, render mutual information based active learning infeasible. The inference procedure proposed in sec-tion 4, however, preserves this covariance matrix and allows for e cient mutual information based active learning.
Our work builds upon a recently proposed Bayesian ar-chitecture for multilabel classification [17]. We briefly sum-marize this framework here. Given a set of N data points X = { x i } and the corresponding sparse l -dimensional bi-nary label vectors Y = { y i } , the key idea was to first reduce the classification task to a lower multidimensional regression task via a random projection matrix , and then during test time, infer the labels for an unseen point via approximate Bayesian inference.

Specifically, a factor graph corresponding to the model consists of three potential functions: (1) the first poten-sion function from each input point x i to the k -dimensional latent variable z i via W . (2) The second potential term g ( y i , z i )=exp[ || y i z i || 2 2 2 ] corresponds to the transfor-mation of l -dimensional labels y i to the real-valued com-pressed space z i via a k  X  l , where k  X  l , random projec-tion matrix . (3) Finally, the third potential h  X  i ( y i Q zero mean-Gaussian prior on each of the labels with preci-sion  X  j i , which in turn are Gamma distributed. Formally, the joint probability distribution takes the following form: Here, Z is the partition function (normalization term), p ( W )= Q i =1 N ( w i , 0 ,I ) is the spherical Gaussian prior on the lin-ear regression functions, and p (  X  i )= the product of Gamma priors on each individual label. Intu-itively, the function f x i aligns the latent variable z i output of the linear regression functions, and the function g favors compatibility with the compressed label vector corresponding to y i . Finally, h  X  i enforces sparsity over the labels.

Using Y L to denote labeled instances, inferring the exact posterior P ( Y U | Y L , X , )overlabels Y U for test points X U is prohibitive due to the product of Gaussian and non-Gaussian terms in the joint distribution. The approach in [17] resorts to variational inference by approximating the posterior over Y U as a Gaussian distribution. While this showed good performance in terms of classification accuracy, there is a significant disadvantage of using the same inference procedure for active learning tasks. The derived variational inference equations lead to loss in information about the variances between updates across the di  X  erent layers of the graphical model. Specifically, the procedure approximates the posterior over y i as a Gaussian, but the variance of the random variable y i is completely independent of the variance of the random variable z i . Similarly, the variance of z turn independent of the variance of the random variable W . The variance related to the Gaussian random variables is central to the use of mutual information in selective sampling tasks; hence, with the given inference procedure, mutual information cannot be optimally used as an active learning strategy.
There are two key ingredients to our framework: first is an alternate approximate inference scheme that preserves variances due to the regression part of the graphical model. Given this inference scheme, the second part focuses on de-riving an e cient near-optimal selective sampling strategy.
Our goal here is to derive an inference scheme that would preserve the variances of the latent random variables and propagate correct uncertainties to Y , thereby enabling an e  X  ective active learning strategy. The key observation here is the fact that such variances can in fact be preserved if instead of directly applying variational approximation, we first analytically integrate out the latent variables Z and W from the joint distribution (Eq. 1). Such analytic integra-tion is feasible due to the form of potential functions f and the Gaussian Process prior p ( W ). This results in a joint distribution over Y and  X  that is a product of a Gaussian and a Gamma distribution. Formally, Here the label vector Y is an Nl -dimensional vector obtained by appending all l -dimensional y 0 i s one after the other. Sim-ilarly, Z is an Nk -dimensional vector resulting from stacking all k -dimensional z 0 i s . Further, the term  X  Y takes the fol-lowing form: Here, the Nk  X  Nk -dimensional matrix  X  Z is a special block matrix, where K ij is the i th row and j th column entry of K =( X T X + 2 I ) 1 and I k is the k  X  k identity matrix. Fi-nally,  X  is another Nk  X  Nl block diagonal matrix with all the N diagonal entries set to . Further, we X  X  like to explic-itly point out that the matrix  X  Y 1 is a precision matrix and is not full-rank. Note that such non-invertible precision matrices are in-line with use of improper un-normalizable Gaussian distributions in Bayesian inference [9, 34] and do not pose any theoretical or practical problems.

The above mentioned marginalization preserves all the in-formation about uncertainty due to the Gaussian Process re-gression part of the graphical model and is succinctly repre-sented in the term  X  Y . We propose to use variational infer-ence and obtain an approximate posterior distribution over the label matrix Y that is a product of Gaussian terms and the corresponding Gamma terms over  X  . If we denote the approximation at the t th iteration as q t ( Y )= N (  X  t and q t ([  X  ]) = following: Given observed labels and q ( Y ), the posterior distribution q ( Y U ) over unobserved labels is simply the conditional Gaus-sian distribution obtained by using standard Gaussian iden-tities. We X  X  like to point out that unlike the previous ap-proach [17], the cross co-variances across all the labels for all the points are preserved in  X  1 Y . Further note that this al-gorithm results in the final variance over the label vectors in terms of the kernel function over the input features X . This is a direct consequence of the fact that uncertainty from the regression part of the network has already been propagated to Y and sets a basis for an active learning scheme that is e  X  ective.
 Selecting Hyperparameters a 0 and b o : The choice of the hyperparameters a 0 and b 0 is critical to induce sparsity, as arbitrary assignments can lead to non-sparse solutions. To see this, consider the joint distribution p ( Y , [  X  i and analytically marginalize over [  X  i ] N i =1 . This results in a distribution of the following form:
The above marginalization leads to a very intuitive interpre-tation where the term  X  Y 1 arises due to the regression part
Extension to non-linear kernel is straightforward by replac-ing X T X with an appropriate kernel function. Figure 1: Plot of the sparsity inducing prior term desirable shape of the prior term is shown in bottom-left corner (indicated by a green X ) and occurs when a 0 and b 0 are set to 10 3 .Thebottom-rightfigure characterizes the shape as a function of a 0 and b 0 and highlights that the shape is undesirably concave when of the framework and the terms (1+ y 2 ij 2 b sity in the solution. Note that in the sparsity term, higher values of y ij lead to a lower value of the potential, thereby penalizing non-zero instantiations. However, the shape of the penalty term critically depends upon the values of a 0 and b 0 . Figure 1 plots these penalty prior functions for dif-ferent values of a 0 and b 0 . Figure 1 shows several shapes corresponding to di  X  erent hyperparameter settings. Most of the shapes shown in the figure are undesirable for inducing sparsity due to their non-convexity localized around a large range near zero (highlighted by a red  X  ). The bottom-right panel on the other hand shows what a desirable penalty function should look like ( a 0 = b 0 =10 3 ) (denoted by a green X ).

The bottom-right subpanel in figure 1 characterizes the shape of the function in terms of the hyperparameters. In particular, the function can decomposed into three regions: (1) y&lt; y&lt; ond derivative of the function will always be greater than zero for region (1) and (2), thereby implying a nice locally convex behavior leading to a desirable shape of the penalty function. The region (3) on the other hand has the second derivative less than zero, thus leading to a shape with a flat-ter penalty structure. Consequently, in order to induce an appropriate sparsity inducing prior it is desirable to mini-mize the range where region (3) occurs. This is achieved when either a 0 takes a very high value or when b 0 tends to zero. However, setting a 0 to a high value will result in a very peaky penalty function (see figure 1 bottom-middle panel). A peaky penalty function is undesirable as it will override the potential arising due to the regression term in the over-all mutilabel framework. Thus, a desirable prior can only be achieved when we select a very small value for both a 0 and b . It is no surprise that in prior research on Bayesian com-pressed sensing [6, 17, 25], a 0 and b 0 were set to very small values. Our analysis above validates such choices in order to incorporate a reasonable sparsity inducing prior. This ob-servation about requiring a 0 and b 0 to be close to zero will be critical in the next section where we discuss non-myopic active learning.
The goal of active learning is to select a set of points A to label from the available pool of unlabeled data U under budget constraints, |A| = n , such that the resulting clas-sifier is most accurate. Intuitively, we want to sample the n most informative points with respect to the classification task. Two potential criteria for the task are entropy and mu-tual information. Selecting points with maximum entropy boils down to choosing a set of points that jointly have the maximum uncertainty on their labels. The mutual infor-mation criterion [7], on the other hand, chooses A so that the uncertainty over the labels of remaining points is maxi-mally reduced after the labels of A are incorporated in the predictive model.

The mutual information based criterion is the best of the two heuristics as the entropy criterion tends to select points that are far apart from each other in the feature space and hence ends up selecting points on the boundary. Since a point usually provides information about points in its nearby region, selecting points on the boundary wastes information gathering e  X  ort. In this paper, we present results in the con-text of mutual information as a criterion. Formally, if H (  X  ) denotes the entropy, then we write the non-myopic subset selection problem as: We call this problem non-myopic due to the fact that the goal is to reason about the entire set A at once. This is dif-ferent from the other schemes for active classification where a single point is chosen for querying a label, the model up-dated after observing the label and the process repeated for atotalof n rounds. This non-myopic subset selection prob-lem is NP-complete as shown below:
Proposition 1. The subset selection problem defined in equation 5 is NP-complete for the density p ( Y , [  X  i ] This proposition can easily be established by observing that, when the random variables  X  are completely observed, the distribution reduces to the form of a multivariate Gaussian density. The proof simply follows from the fact that the subset selection problem for mutual information criterion has been previously shown to be NP-complete [19].
Given the hardness of this problem, we resort to a greedy approximation algorithm following recent ideas in submod-ular optimization. Specifically, if we can show that the objective (eq. 5) being optimized is submodular and non-decreasing, then we can derive a greedy strategy that se-quentially selects data points based on marginal improve-ment of the objective. Note that the mutual information criterion is not submodular in general, but under some weak conditions, both submodularity and its non-decreasing prop-erty can be established. Formally, [18] have proved the fol-lowing proposition for random variables S and U in a graph-ical model:
Proposition 2. [18] Let S , U be disjoint subsets of random variables such that the variables in S are indepen-dent given U .Letinformationgainbe F ( A )= H ( U ) H ( U\A|A ) ,where A  X  U .Then F is submodular and non-decreasing on U ,and F ( ; )=0 .
 The following observation identifies the graphical model cor-responding to the joint distribution p ( Y , [  X  i ] N i =1 special case of the above, thus establishing the submodular-ity and non-decreasing characteristic of our objective func-tion.

Corollary 1. Let S =[  X  ] n i =1 and U = Y U ,thendue to the form of h  X  i and p (  X  i ) ,wehave [  X  i ] N i =1 given Y U .Consequently,theobjectiveinequation5issub-modular and non-decreasing.
 Given this observation, we can now propose a greedy al-gorithm that repeatedly picks the points with the highest increase in mutual information and adds them to the subset A . The point x  X  2 U selected to be added to the subset A is such that x  X  = arg max x ( MI ( A [ x ) MI ( A )). Here, MI ( A )= H ( Y U\A ) H ( Y U\A | Y A ) and it has been proved earlier that this algorithm selects the subset A  X  such that the value of the objective function will at least be (1 1 times the optimal solution [19,22].

While the above mentioned corollary shows the existence of a greedy algorithm that has a good approximation guaran-tee, it is still non-trivial to compute the mutual information MI ( A ) for the multilabel classification model. Specifically, in order to compute mutual information, we need to solve exact inference, which itself is non-trivial in our model. Here also, in order to derive an implementable solution, we need to establish a similar approximation  X  MI to mutual informa-tion such that that the set of selected points A  X  does not change when the approximated mutual information is used instead of the exact one. Formally, we prove the following theorem which in turn will imply that such an approxima-tion is feasible:
Theorem 1. Let  X  MI denote the mutual information of any set A computed over the probability distribution, p ( Y ) / exp[ Y T  X  1 Y Y / 2] ,where  X  1 Y is as defined in eq. 3, then for any x 2 U : Proof Sketch: To prove this theorem, we first use the fact that MI ( A [ x ) MI ( A ) can be written as H ( x |A ) H ( x |U\ x ) [19]. Next, we consider the joint distribution over Y given in eq. (4) that arises after analytically marginalizing over [  X  i ] N i =1 . It is easy to show that given A , the conditional predictive distribution of x takes a similar form: The above reduction follows from simple algebraic manipu-lation where the terms corresponding to the set A are col-lected by using matrix inversion lemma. A similar form also can be derived for the conditional predictive distribu-tion of x given U\ x . Let us denote the conditional en-tropy of x given A computed via the Gaussian distribu-tion as  X  H ( x |A ). The proof then follows from the fact that for the above statement is provided in appendix A.
The implication of the above theorem is that the greedy selection strategy described above will yield nearly the same subset when  X  MI is used instead of the true mutual infor-mation, as a 0 and b 0 are set to very small values in our algorithm. This is due to the fact that the greedy proce-dure seeks to include x such that ( MI ( A [ x ) MI ( A )) is maximized at each step and the above theorem guarantees that the order of selecting the points will not change when MI is replaced by  X  MI . This result enables us to derive an algorithm based on the approximate inference procedure de-scribed earlier in the paper. Note that the  X  MI is defined over a Gaussian Process; thus, prior work [19] on near-optimal se-lective sampling can be directly applied here. Also, note that the discussion above only focuses where the Gaussian term has a zero mean for clarity purposes. It is fairly straightfor-ward to extend the analysis to non-zero mean cases.
One of the surprising by-products of our result is the fact that, similar to Gaussian Process regression models, the ob-served labels do not a  X  ect the order in which the points should be selected, which in turn allows us to do non-myopic selection of points. Intuitively this is feasible by realizing that the mapping of the discrete label vectors to the con-tinuous space via the matrix is almost 1-to-1 [15]. So, any subset selection via Gaussian Process regression on the continuous space, which is independent of observations, au-tomatically transfers to the discrete labeled space. We wish to point out explicitly that  X  1 Y is not full-rank; however, the computation over Gaussian mutual information is still feasible in such cases [14].

The proposed compressed sensing framework compresses the information about the labels, Y into the compressed space, Z and then couples the Z in a single covariance ma-trix, hence allowing us to do mutual information based ac-tive learning in time that is independent of the number of labels. The compressed sensing formulation also enables us to train lesser number of classifiers for the training process and reduce the training time significantly. Finally, note that the mutual information computation need not be done from scratch after each iteration of the active learner. We use lazy evaluations proposed in [19] to drastically reduce the computational cost for selection of subsequent points to be annotated.
It is interesting to note that selective sampling via  X  MI can accommodate many di  X  erent scenarios of selective sampling. The most popular setting in literature considers revealing all the labels for selected data points. Alternatively, in active diagnosis, di  X  erent labels can be probed for one particular test case only. Finally, in the most general case, individual labels from di  X  erent input points can be selected (general-ized active learning).
In traditional active learning, we select a subset of points from the available data points for which all labels are re-vealed. Ideally, the goal is to choose a subset of size n that leads to maximum decrease in entropy over the remain-ing unlabeled points as described in equation 5. However, proposition 2 and corollary 1 allow us to greedily select points to be annotated so as to maximize the mutual in-formation at each step. Algorithm 1 shows the outline of the method that allows e cient sampling of points based Algorithm 1 Mutual information based active learning over the compressed space Input: Input features X and budget n Output: A : The set of points to be labeled Compute C =  X  Z + 2 I using  X  Z defined in eq. 3
A for i 1to n do end on mutual information. Note that, for this case, when all the labels are revealed per data point, we can be far more e cient in computation by directly using the Kernel matrix defined over the points alone.
Such an active learning scenario is more specific to multi-label active learning, where obtaining each label for a point has significant cost associated with it. For example, in in-dustrial or medical settings, where each label may be ob-tained as a result of an expensive test, it is wiser to se-lect the labels which you want to be annotated for a se-lected point to decrease the overall cost, as opposed to an-notating all the labels. If we denote the label vector as y = { y 1 ,y 2 ,y 3 ,...y l } , then the active diagnosis problem is to select a subset of labels, l 0  X  { 1 , 2 ,...l } , which need to be annotated. This scenario can be easily handled by our model as we obtain the complete covariance matrix over the labels and the mutual information criterion  X  MI treats each label independently. We can follow a greedy algorithm similar to the one followed in algorithm 1 to sample la-bels, wherein at each step, we select the label with index, i = arg max i 2 U  X  MI ( y L [ i )  X  MI ( y L ) to be labeled, where U and L denote the unlabeled and labeled indices respectively, as before. We present evaluation of our scheme for active diagnosis in the results section.
A combination of the above active learning scenarios leads to a general active learning problem, wherein the goal is to select both the points and the labels to be annotated within a given active learning budget. Given the budget to obtain n annotations, we select n document-label pairs from the set documents with l labels each. To achieve this objective, we consider the information gain computed using  X  MI obtained over the complete label matrix Y . Once again, we use the greedy strategy to pick each pair. However, computing this metric over the entire space of document-label pairs is ex-pensive and we resort to a two-way approach, wherein we first select the document to be annotated based on algorithm 1 and then select, the label to be revealed similar to active diagnosis. Note that, both active diagnosis and generalized active learning are novel active learning scenarios which are specific to the multilabel classification problem and can X  X  be handled by SVM based state-of-the-art methods.
In this section, we present empirical results to demon-strate a) how the proposed approximate inference proce-dure compares to the prior work [17](denoted as BML-CS) in terms of accuracy as well as the capability to estimate variances, b) the comparison of mutual information based sampling with the state-of-the-art SVM based active learn-ing method proposed in [20], uncertainity sampling and ran-dom sampling baselines, and c) performance of the method on novel active learning scenarios like active diagnosis and generalized active learning which are specific to multilabel classification. Datasets: We used the datasets listed in Table 1 to eval-uate our algorithm. As can be seen from the table, the datasets exhibit a wide range in type, feature vector size and label vector size. For each of the datasets, 4000 randomly sampled points were used as the active learning pool from which points had to be selected for training based on the di  X  erent active learning strategies compared. Another set of 2000 points was used as the test data. For datasets with fewer than 6000 points ( enron , medical , MSRC and yeast ), the entire set was selected as the active learning pool and testing was done on the points not selected for training. All the results are reported after averaging over 5 such splits. For all the methods, an initial seed of 500 randomly sam-pled points was provided to the algorithms to start with (50 points, in case of MSRC , and 200, in case of enron , medi-cal and yeast ), as has been done in standard active learn-ing literature. For all our experiments, we used features downloaded from the Mulan multilabel datasets [1]. For MSRC , we used 1024 bit features generated using the Picodes scheme [4].

Baselines We compare the following methods for the evaluation of the proposed active learning strategy:
Parameters: For MIML and Uncert, the dimension of the compressed label space k was set to half of the number of labels for all datasets. The hyperparameters 2 and 2 in MIML and Uncert were selected via evidence maximization and a 0 and b 0 were set to 10 6 , which lead to fairly un-informative priors. The Li-Adaptive mechanism proposed in [20] has a hyperparameter , which was selected from a Cross validation was done for all other parameters.
Performance Metric: Typically, the goal in multilabel classification is to predict the top k labels for each point. So, we use precision at 1, 2 and 3 to quantify the perfor-mance of di  X  erent active learning schemes, which is in line with previous work. Precision at k is defined as the frac-tion of true positives over the top k predicted labels for each point. For novel active learning scenarios like gen-eralized active learning and active diagnosis, the ultimate goal is to recover the whole label set of each single test point. So, we quantify our results using the F-1 measure which depends on all labels, rather than on the few top
We first consider a toy dataset before assessing the per-formance of the di  X  erent schemes on real-world datasets in 6.4. The toy dataset is created as follows: We create L =35 two-dimensional Gaussians and assign a unique identifier to each of them. Their mean and standard deviation is ran-domly selected from a fixed interval such that the contours of the Gaussians, drawn for C standard deviation away from the mean, overlap with each other. Points are generated from each of the L Gaussians. The feature vector is just the 2-dimensional coordinate of the point and the labels are the Gaussians whose mean is no more than C standard de-viations away from the point. For the experiments, C was selected such that each point belongs to 7 classes on aver-age. To visualise the dataset, we plot the dataset generated by setting L = 5, i.e. a dataset generated with 5 Gaussians in Figure 2(a). For our experiments, we use L = 35 and start with a randomly sampled set of 20 points. We, then, select 25 more points based on di  X  erent schemes from a pool of 1000 data points. The performance is averaged over 50 di  X  erent runs and compared across all methods mentioned in section 6.1.

The precision at 1, precision at 2 and precision at 3 is shown in figure 2. As can be seen in the figure, the mu-tual information criterion quickly fills the training set with points that are helpful to the model. Uncertainty sampling on our model outperforms Li-Adaptive as points are added. In fact, Li-adaptive baseline performs worse than the ran-dom sampling baseline in this case. Intuitively, MIML starts by picking points across di  X  erent Gaussians in order to max-imize mutual information and hence leads to better predic-tion. On the other hand, the uncertainty sampling criterion picks points closer to the boundaries, hence missing out on information.
In order to explore the properties of inference procedures (BML-CS [17] and proposed method(ML-OSS)), we com-pare the performance of both algorithms on the MSRC dataset, which has 23 labels. We used 1024-bit Picodes [4] image de-scriptors as features.

The results of the experiments are shown in Figure 4(a) and 4(b). Figure 4(a) plots the means of the labels inferred by both the methods for five randomly sampled test points and highlights that the means inferred by both the meth-ods are highly correlated indicating that they are equally capable of modeling the means of the posterior distribution. However, similar correlation is not observed for variance es-timates. Figure 4(b) plots the variances for the first label of all the test images inferred by the proposed method vs BML-CS on a negative log scale. Variances inferred by our inference method have a much wider spread indicating that BML-CS underestimates variances due to its limitation in propagating variances across the graphical model.
We compared the performance of the proposed mutual information (MIML) strategy with the strategy proposed in [20], uncertainty sampling (UNCERT) and random sam-pling (Rand). In these experiments, at every active learning round, all the labels corresponding to an input data point were revealed. Figure 3 shows the average of precision at 1,2 and 3 achieved on di  X  erent datasets. Note that this is a significant metric as all our datasets except delicious have less than 3 positive labels per document on average. baseline in one or the other dataset.
 Table 2: Time complexity analysis: Time taken to select 250 points from a pool of 4000 points for di  X  erent datasets for our method (MIML) and the state-of-the-art SVM based approach [20]. For Yeast, the pool is 2000 points and other smaller datasets have been excluded. MIML scales much better than Li-Adaptive with the number of labels and achieves nearly 20x gain for Delicious.
 We observe that the MIML criterion proposed in this pa-per outperforms all the compared methods consistently, on all the datasets. No other method beats the other methods across all datasets. For instance, Li-adaptive performs worse than random sampling on almost half of the datasets.
Evaluation of time complexity: Table 2 shows the time taken by the proposed method (MIML) and Li-adaptive, to select 250 points to be annotated from a pool of 4000 points. We do not include smaller datasets in this analy-sis. For Yeast , the pool is 2000 points as the dataset has only 2417 points. All these experiments were performed on a standard desktop PC with a 4 core, hyper-threaded Intel Core-i7 3.4GHz processor and 16GB RAM. As can be seen, the SVM based approach scales badly (even though train-ing of binary classifiers per label was parallelized) with the number of labels and takes approximately 20 times the time taken by MIML on delicious . The only overhead in MIML with increasing number of labels is because of the time taken to learn the Gaussian process over the labels with an initial set of points. All other updates can be performed incremen-tally and hence, MIML is extremely time-e cient.

Active Diagnosis and Generalized Active Learn-ing: Next, we demonstrate two active learning strategies specific to multilabel classification and show the benefits of our mutual information based strategy in these scenar-ios. As described before, in active diagnosis, one label per round is revealed for the test set based on the selection criteria. This scenario cannot be straightforwardly tack-led by the method of [20], whereas it naturally fits in our model, as the employed joint distribution correlates both points and labels. Thus, we compare our results against the UNCERT and random sampling baselines. Since the ulti-mate goal is to recover the whole label set of each single test point, we quantify our results using the F-1 measure which depends on all labels, rather than on the few top sults of this experiment on the RCV1 dataset; we randomly selected n  X  =30pointscollectedinatestset Y  X  for which we did active diagnosis by selectively sampling their labels. Each test point has an unknown label vector of size l =101 and the active diagnosis procedure was given a budget of advantageous over the other methods. m = 30 labels to select per point. An initial fully observed training set of 100 points kick started the experiment.
Fig. 4(c) summarizes the results in a plot averaged over 35 runs. We observe that the proposed criterion selects much more useful labels to reveal right from the start. The di  X  er-ence in the performance compared to the baselines is even larger than for the traditional active learning task. This is due to the fact that output labels within a data point are far more correlated than across data instances. For example, a test data corresponding to an article tagged as  X  X nvestment X  is very likely to also fall into the category  X  X anking X .
Generalized Active Learning is the scenario when both the input point and the label to be queried are selected based on the selection criteria. Since the goal here is to learn as much information as possible for the whole test set, we use the following criterion to evaluate the performance: after se-lecting m = 30 labels for each of the chosen data points, we compute the F-measure of the whole test set given the par-tially revealed label vectors of the current and all other data points already in the active set. We ran this experiment 35 times and present the averaged results for F-measure with number of points in the active set in figure 4(d). Note that, both active diagnosis and generalized active learning are en-abled by the fact that our multilabel classification model can train on partially labelled datasets.
We presented a novel mutual information based active learning framework for multilabel classification, that enables a theoretically principled and non-myopic approach. We ex-tensively evaluated our algorithm across various datasets in traditional active learning settings as well as active diagnosis and generalized active learning (which are specific to multi-label classification) and showed that it consistently outper-forms the state-of-the-art, both in terms of time-e ciency and precision. Possible future work includes integration of the framework with other multilabel classification tech-niques. [1] Mulan Multilabel Datasets. [2] R. Agrawal, A. Gupta, Y. Prabhu, and M. Varma. [3] K. Balasubramanian and G. Lebanon. The Landmark [4] A. Bergamo, L. Torresani, and A. W. Fitzgibbon. [5] W. Bi and J. T.-Y. Kwok. E cient Multi-label [6] C. M. Bishop and M. E. Tipping. Variational [7] W. Caselton and J. Zidek. Optimal monitoring [8] Y.-N. Chen and H.-T. Lin. Feature-aware Label Space [9] W. Chu, V. Sindhwani, Z. Ghahramani, and [10] M. Ciss  X e, N. Usunier, T. Arti`eres, and P. Gallinari. [11] A. Esuli and F. Sebastiani. Active Learning Strategies [12] C.-S. Feng and H.-T. Lin. Multi-label Classification [13] A. Goldberg, X. Zhu, A. Furger, and J. Xu. OASIS: [14] A. Gretton, R. Herbrich, and A. Hyv  X  arinen. Kernel [15] D. Hsu, S. Kakade, J. Langford, and T. Zhang. [16] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting Shared [17] A. Kapoor, R. Viswanathan, and P. Jain. Multilabel [18] A. Krause and C. Guestrin. Near-optimal Nonmyopic [19] A. Krause, A. Singh, and C. Guestrin. Near-Optimal [20] X. Li and Y. Guo. Active Learning with Multi-label [21] X. Li, L. Wang, and E. Sung. Multi-label SVM Active [22] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis [23] J. C. Platt. Probabilistic Outputs for Support Vector [24] B. Settles. Active learning literature survey. Technical [25] Shihao, Y. Xue, and L. Carin. Bayesian Compressive [26] A. Singh, A. Krause, C. Guestrin, and W. J. Kaiser. [27] M. Singh, E. Curran, and P. Cunningham. Active [28] F. Tai and H.-T. Lin. Multi-label Classification with [29] J. Weston, S. Bengio, and N. Usunier. Wsabie: Scaling [30] J. Weston, A. Makadia, and H. Yee. Label [31] B. Yang, J. Sun, T. Wang, and Z. Chen. E  X  ective [32] H.-F. Yu, P. Jain, and I. S. Dhillon. Large-scale [33] Y. Zhang and J. G. Schneider. Multi-Label Output [34] X. Zhu, J. La  X  erty, and Z. Ghahramani.
 By definition H ( x |A )= E Y A [ H ( x | Y A )] (also for E
Y A [  X  ] is the expectation over the labels Y A at the active sites A under the distribution in eq. 4. Now, Here, Z and  X  Z are the corresponding normalizing constants. Now as a 0 ! 0, the term a 0 log(1 + x 2 2 b using the binomial expansion [1 + x 2 2 b show:
The required proof follows directly by using the binomial expansion and seeing that as a 0 ! 0, the expression  X  Z Z and the above quantity evaluates to zero.
