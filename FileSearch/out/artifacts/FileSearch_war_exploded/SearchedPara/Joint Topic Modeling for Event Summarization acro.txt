  X  Social media streams such as Twitter are regarded as faster first-hand sources of information generated by massive users. The con-tent diffused through this channel, although noisy, provides impor-tant complement and sometimes even a substitute to the traditional news media reporting. In this paper, we propose a novel unsu-pervised approach based on topic modeling to summarize trending subjects by jointly discovering the representative and complemen-tary information from news and tweets. Our method captures the content that enriches the subject matter by reinforcing the iden-tification of complementary sentence-tweet pairs. To valuate the complementarity of a pair, we leverage topic modeling formalism by combining a two-dimensional topic-aspect model and a cross-collection approach in the multi-document summarization litera-ture. The final summaries are generated by co-ranking the news sentences and tweets in both sides simultaneously. Experiments give promising results as compared to state-of-the-art baselines. H.4 [ Information Systems Applications ]: Miscellaneous; I.2.7 [ Natural Language Processing ]: Text analysis Algorithms, Experimentation, Performance Cross-collection topic-aspect model, LDA, Gibbs sampling, Com-plementary summary
User-generated content such as microblogs play important roles in the ever-developing Web ecosystem on a par with the main-stream news media. Twitter is one of the dominant social me- X  This work was done when the author worked as an intern at Qatar Computing Research Institute with Qa tar Foundation.
 dia streams characterized as an instant, colloquial and influential source of information. Although bearing free and noisy style, infor-mation diffused through this channel provides invaluable comple-ment and sometimes even a substitute to the news media reporting. The competing-complementary role between social media and tra-ditional media become more and more evident recently in different scenarios, such as natural disasters like the 2011 tsunami in Japan, civil unrests in the Middle East and news sourcing of the killing of Osama Bin Laden are reported [14]. For example, during the event of Bin Laden X  X  death, Sohaib Athar, a resident of Abbottabad in Pakistan, is the first person who inadvertently recorded the U.S. attack on the world X  X  most wanted terrorist by tweeting about heli-copters circling overhead and a mysterious blast. This source was widely reported later on in the news, being an appealing instance reflecting the cross-media complementarity.

In this paper, we propose a novel approach to summarize the given subject matter by jointly extracting important and comple-mentary pieces of information across news media and Twitter. Gen-erally, the genre of news and Twitter texts (i.e., tweets) is charac-terized as salient stylistic and organizational distinctions: news are typically well-crafted and fact-oriented long stories written by pro-fessionals based on the latest past events, while tweets are mostly personalized and more opinionated free-style short messages posted by the average persons in real time. The topics or perspectives could be shared across the two media for the same subject matter, but the knowledge conveyed from either side tend to be additional each other. In particular, news may emphasize some general or ob-jective aspects of an event, while tweets may express more specific and subjective information, which would be naturally supplemen-tary. Table 1 shows two summaries, one based on news and the other based on tweets, as to the same subject of  X  X gyptian Revo-lution X , which suggests that such complement could be even dis-covered at sentence level considering different topics and aspects of the event.

The complementary and distinct characteristics of the two media would be presumably instrumental for generating useful summaries of interested subject matter. Tweets usually disclose more specific and update-to-date information which news media cannot cover. It can be expected that readers would benefit not only from the ef-ficiency gain due to the compression effect of summary, but more importantly from the diversity and enrichment brought by differ-ent perspectives, viewpoints and highlights in virtue of cross-media complementarity. The major challenge is how to identify and mea-sure the complementary information in order to extract them from different media streams given a subject matter. For this purpose, we propose a balanced complementary measure for the sentence-tweet pair by leveraging topic modeling approach based on a variant of mentary with respect to the corresponding topics and aspects of the event. cross-collection LDA (ccLDA) [15]. For computing the value of complementary measure given a pair, our model infers the general and media-specific word distributions with respect to the topics as well as perspectives (or aspects) to capture the supplementary elements in different dimensions of the subject. This is realized by the in-depth combination of ccLDA and the two-dimensional topic-aspect model [ 16]. The underlying intu ition is tha t the gen-eral topic/aspect models independent of a particular media would be natural for estimating sentence-tweet commonality, while the media-specific models would be suitable for estimating the differ-ence of the pair, and our method effectively interleave both factors for finding the complementary tweets for the corresponding news sentences. The summaries are generated by co-ranking the com-plementary sentences and tweets at either side using random walk on a bipartite graph which reinfor ces the strength of connection be-tween the pair. Experimental results show that the news summary as well as the tweets summary are significantly better than those generated by state-of-the-art summarization approaches.
In a nutshell, our contributions are listed as follows: 1. We put forward a novel problem of generating complemen-2. We proposed a principled measure to assess the extent of 3. We present a topic modeling approach called cross-collection 4. We manually construct a gold-standard dataset of comple-
The rest of the paper is organized as follows: Section 2 reviews the related work; Section 3 defines our problem and the cross-media complementary measure; Section 4 describes cross-collection topic-aspect model for estimating general/specific word distribu-tions; Section 5 presents the random walk model for generating complementary summaries; Section 6 discusses experiments and results; Finally, we give conclusions and future work in Section 7.
Our cross-media complementary summarization is related to cross-collection text mining problems [17, 21]. Zhai et al. [21] proposed a cross-collection mixture (ccMix) model based on probabilistic latent semantic indexing (pLSA) [9]. The goal is to discover the common themes across all collections and the ones unique to each collection. Paul et al. [17] extended ccMix to ccLDA model based on LDA [2] for cross-cultural topic analysis with blogs and fo-rums. None of these work can generate complementary summaries as ours.

Constrastive summarization [10, 11, 17] was recently studied to generate summaries for opinionated text, which aims to highlight the differences between the entities or viewpoints. The main con-cern is to find the contrastive representative opinions from multiple viewpoints. Kim et al. [10] defined the objective as maximizing a linear combination of contrastiveness and representativeness scores of an opinion summary, and then used greedy search to find an approximate solution. Paul et al. [17] scored different viewpoints based on a similar balancing strategy however using an unsuper-vised approach. Lerman and McDonald [11] based their contrastive measure on KL-divergence between the model induced for a poten-tial summary and the model for the original opinionated texts. Our work differs from these works in two folds: (1) We focused on sum-marizing text in the news context (i.e., news and tweets) rather than opinionated context; (2) We attempt to generate complementary summaries across two media where the complementarity is more general and harder to measure since it is considered broader and more subjective than contrastiveness.

Yang et al. [20] proposed an interesting supervised model called dual wing factor graph (DWFG) to simultaneously summarize Web documents and tweets based on in-depth structural mining of social context. Their model encourages similar summaries to be gener-ated. In contrast, we aim to produce complementary summaries jointly from both sides, and also our approach is unsupervised con-sidering the appropriate training data for the task is not available and is difficult to get.

LDA-based summarization models in the general textual context are extensively studied [3, 4, 8, 16, 18]. The closely related one is the topic-aspect model (TAM) [16] that simultaneously identifies topics and aspects to find multi-faceted topics. We try to incorpo-rate such a mixture model in the cross-collection setting for finding complementary information across distinct media. LDA was also applied for tweets, but not having been used for summarization pur-pose. Zhao et al. [22] proposed a T witter-LDA model to discover topics from a Twitter corpus and compared them quantitatively with the news topics identified from New York Time corpus.

Sentence ranking based on bipartite graph has been applied in many applications including summarization. Erkan and Radev [6] introduced LexRank and incorporated random walk on graph. Paul et al. [17] modified the jumping probability for LexRank to favor selecting contrastive viewpoints. Deng et al. [5] proposed a gener-alized Co-HITS algorithm based on bipartite graph for query sug-gestion. In our work, we used the variant of Co-HITS to co-rank news sentences and tweet for generating the summaries.
To the best of our knowledge, the concept of complementary summary has never been defined in the literature. Our task is there-fore a new one. We first introduce some useful definitions.
D EFINITION 1(S UBJECT ). A subject is an event or subject matter whose relevant information could be found on both online news media and Twitter. This primarily refers to current affairs such as  X  X ussian presidential election X ,  X  X eath of Marie Colvin X  and  X  X oland rail crash X , which are widely discussed across differ-ent media.

D EFINITION 2(T OPIC ). A topic refers to some essential ele-ments that make up of the complete description of the concerned subject, such as what, when, where, who, why, progress, numbers, countermeasures, etc.

D EFINITION 3(A SPECT ). An aspect is an underlying theme, perspective or viewpoint as to the topics of a subject. Each aspect spans all topics in a subject and may affect all topics in a similar manner. For example, in the subject of  X  X sraeli-Palestinian con-flict X , the main aspects usually consist of Israeli, Palestinian and/or US government in the different topics regarding this subject. ject, let N = { n 1 ,n 2 ,  X  X  X  ,n m n } denote the set of all sentences from relevant news and T = { t 1 ,t 2 ,  X  X  X  ,t n t } denote the set of all relevant tweets. The complementary relation is the set of sentence-tweet pairs satisfying certain conditions described as fol-lows: { ( n i ,t j ) | 1  X  i  X  m n ;1  X  j  X  n t ; I comp ( n where I comp ( x, y ) is the complementary measure between text seg-ments x and y described in Section 4.
 of complementary relation R = { ( n i ,t j ) k } K k =1 regarding a sub-ject, the complementary summaries consist of two sets of excerpts S
N and S T from R ,where S N = { n i } and S T = { t j } are ex-tracted respectively from the news portion and tweets portion of R according to the co-ranking measure described in Section 5 in such a way that the top sentences and tweets are selected until the predefined length threshold of the summaries is met.

The concepts defined above will be used throughout the rest of the paper.
People can often perceptually recognize the pieces of informa-tion that appears complementary to each other, such as the case of the complementarity implied in the cross-media excerpts given in Table 1. But not like the pure relations such as similarity and con-trast, the relation of complementarity seems rather broad and sub-jective in a sense that it is something just in-between and becomes Figure 1: Illustration of the generative modeling that produces an example sentence-tweet pair, where M G , M N and M T are the general, news-specific and tweet-specific topic models, re-spectively. kind of imprecise. Therefore, it would be difficult, if not impos-sible, to define and measure accurately. To the best of our knowl-edge, no study has been done for proposing such kind of measure quantitatively, although the problem is essential and interesting.
We empirically hypothesize that the degree of complementar-ity between a sentence and a tweet can be determined by two cor-related and distinct factors, namely commonality and difference. Suppose we have three topic models regarding a subject for gen-erating media streams, where one of them is a general model that is independent of news media and social media and two others are media-specific. Given any sentence-tweet pair, we can imagine that the common part of the pair is most likely generated by the general model while the different portions are most likely produced by the two specific models. Therefore, the news sentence and tweet in the pair can be considered as a mixture of word distributions based on the general model and their corresponding media-specific model. The generative process is illustrated as Figure 1.

Given any sentence-tweet pair ( n i ,t j ) , we define the comple-mentarity measure I comp of n i and t j as a continuous piecewise function with respect to the strength of their commonality I and that of their difference I diff (see Section 4.1 for the definition): where I comp , I comm and I diff are all functions with respect to ( n ranging from 0 to 1. It is easy to find that the value of function I reaches the peak when I comm = I diff and it approaches to 0 when the sentence and the tweet are either very similar or very different. As a result, the function encourages the sentence and tweet in the pair to be moderately similar and penalizes extreme cases where they are excessively common or different. The straightforward in-tuition behind Eq. 1 is as the following: When the pair bears large difference (thus with small commonality  X  I comm  X  I diff is proportional to I comm and inversely proportional to I implies that higher commonality leads to higher complementarity; similarly, when the pair is largely common (thus with small differ-ence  X  I comm &gt;I diff ), we would like to encourage the difference, for which I comp is made proportional to I diff yet inversely propor-tional to I comm .

The problem now turns out to be how to derive I comm and I based on the generative model as shown in Figure 1. The most naive approach would be using similarity functions like cosine to directly calculate the commonality and difference. However, it is not technically sound since deep word correlations and the hidden structures cannot be appropriately captured and utilized for mea-suring the relation precisely. For this reason, we resort to topic modeling approach.
Suppose we have three uni gram probability dist ributions obtained by topic models, namely general word distribution  X  , news-specific word distribution  X  n and Twitter-specific word distribution  X  responding to M G , M N and M T in Figure 1, respectively. We calculate I comm and I diff as follows: where Norm ( . ) is a normalization function to cast I comm into the same range of values, p ( e | f ) denotes the probability of sentence or tweet e (i.e., n i or t j ) generated from a topic model f (i.e.,  X  ,  X  n ,or  X  t ).

Eq. 2 encourages the pairs in which more similar sentence and tweet are produced since the general model  X  is used to generate them. The intuition of Eq. 3 is that for a pair ( n i ,t j to be amplified by the multiplication. This is because the probabil-ity of generating the news sentence given  X  n tends to be higher than that of generating the tweet, and similarly, the probability of generating the tweet given  X  t tends to be higher than that of gener-ating the news sentence. As a consequence, the more different n and t j are, the higher the value of Eq. 3 is.

So far, we did not differentiate topics and aspects. In practice, we utilize the two-dimensional topic-aspect model [16] to divide the topics into aspects to embody deeper news-tweet correlations (see Section 4.2). Intuitively, this is beneficial for discovering com-plementary relations from multi-facet topics, perspectives or an-gles. Given multiple number of topics and aspects, let z and y denote the indices of topic and aspect, respectively. As a result, each word distribution has three different versions, i.e.,  X  and  X  zy , corresponding to the topic, aspect and topic-aspect mix-ture, respectively. Considering the general model and two media-specific models, the composition will result in 9 different distribu-tions in total, that is,  X  z ,  X  y ,  X  zy ,  X  t z ,  X  t y Therefore, Eq. 1 can be examined under 5 different configurations { z,y,zy,z + y,z + y + zy } ,inwhich z + y + zy is the full config-uration. Without the loss of gener ality, under the full configuration, the calculation of I comm and I diff can be formulated as follows based on Eq. 2 and 3:
We now present our ccTAM model for producing different word distributions with respect to topic, aspect and their mixture. We assume that these distributions are multinomial following the gen-eral assumption of the topic-aspect model [16]. Suppose there is a background model  X  b that generates words frequently used in all documents (e.g., stop words). Suppose there are K number of top-ics and A number of aspects including both general and specific correspondences. There are two collections, each corresponding to a different media, and D is the number of documents in the corre-sponding collection. At Twitter sid e, note that we aggregate all the relevant tweets of each user as single document like previous stud-ies [19]. All these word distributions are assumed having a uniform Dirichlet prior with parameter  X  .

We introduce a level distribution  X  l used to control how often we choose a word from background level, cross-collection level or collection-specific level. Given document d and word i ,variable l d,i is drawn from  X  l which takes the possible control value of 0, 1 and 2 accordingly. And we also introduce a route distribute  X  to control how often we choose a word from the background dis-tribution, topic distribution, aspect distribution or the topic-aspect mixture distribution. Correspondingly, variable x d,i is drawn from  X  x to take the value of 0, 1, 2, 3.

Given a subject, Figure 2 describes the process of generating the whole set of collections. The plate notation of the ccTAM model is shown in Figure 3. A summary of notations used in the figure is provided in Table 2.
We combine two collections together to form the single set of vocabulary of all words { w d,i } . The goal of inference is to estimate the 9 word distributions  X  z ,  X  y ,  X  zy ,  X  t z ,  X  t y Table 2: A summary of notations used in the ccTAM model shown in Figure 3.
 Gibbs sampling [7], a Markov Chain Monte Carlo method [1], is used to estimate each one of the distributions.

Due to the similar forms, here we just need to elaborate how to draw general and specific topics given word i in document d ,and without extra mention otherwise, the analogous inference method also applies to draw aspects and topic-aspect mixture. The follow-ing two formulas are used to infer the general topic-word distribu-tion  X  z : where k , i , d and c is the index of topic, word, document and col-lection, respectively. Eq. 6 describes the estimate of the general topic-word distribution  X  z given the control parameters, where is the number of words from d assigned to k , C d (  X  ) is the total num-ber of words from d , C w d,i k is the number of times w d,i assigned to topic k , C k (  X  ) is the total number of words assigned to k , and V is the size of vocabulary. Note that Eq. 7 is used to draw the control parameters to control how the word w d,i is sampled from the general topic-word distribution, where C d ( l of words from d assigned to level l d,i =1 , C k ( l number of words that has been assigned to k controlled by l at level l d,i =1 . The inference procedure iterates between Eq. 6 and 7 until the stationary state is reached [7].
 Similarly, the following two formulas are used to iteratively es-
Figure 3: The cross-collection topic-aspect model (ccTAM). timate the collection-specific topic-word distribution  X  c where C c,d k is the number of words from d in collection c assigned to k , C c,d (  X  ) is the number of words from d in collection c , the number of times that w d,i in c has been assigned to k ,and is the total number of words assigned to k in collection c .
In our experiments, we empirically set the hyper-parameters  X  = 10 ,  X  =0 . 01 ,  X  x =10 ,  X  l =10 and  X  =10 . We run 100 burn-in iterations through all documents to stabilize the distribution of z , y , l and x before sampling starts. For each distribution, we take 10 samples with a gap of 10 iterations between two sampling, and average over these 10 samples to get the estimation for the distributions.
With the complementary measure (see Eq. 1) based on ccTAM model (see Section 4.2), our goal is to extract the representative and complementary sentences and tweets for generating summaries. We adopt a bipartite-graph-based ranking algorithm for the task, where the nodes at one side correspond to sentences and those at the other side correspond to tweets. Note that although there may be cou-pling of sentences and tweets when the algorithm is performed, the final summaries should be output and displayed in such a way that news summary and tweet summary are well separated at either side.
Let G =( N  X  T,E ) denote the bipartite graph, where N = { n 1 ,n 2 ,  X  X  X  ,n m n } is the set of news sentences, T = { t } is the set of tweets, and E = { ( p ( n i | t j ) ,p ( t m n ; j =1 ,  X  X  X  ,n t } is the set of directed edges between two sets of nodes whose values are node-t o-node jumping probabilities.
We first initialize the graph nodes (i.e., sentences and tweets) with LexRank [6] scores to take into account representativeness factor. Then we perform biased random walk based on the tran-sition probability to ite ratively reinforce the co-ranking of nodes at two sides. Based on the two ranks at both sides, we adopt two methods to generate the complementary summaries according to different granularities of complementarity. First, we just consider to produce summary-level complementarity, which means that the two summaries are complementary as a whole. Secondly, we con-sider sentence-level complementarity, aiming to produce strict cor-respondence between news sentences and tweets that constitute their respective summary. We describe the algorithm with more details in this section.
We define the jumping probability based on the normalized idf-modified-cosine similarity [6], which is then modified using the complementarity score I comp in order to favor visiting complemen-tary nodes: where  X  ( n i ,t j )= sim ( n i ,t j )  X  I comp ( n i ,t j idf-modified-cosine similarity [6].
With the jumping probability, w e then apply the biased random walk to iteratively reinforce the ranking of the nodes at each side. The iterative reinforcement procedure is similar to the generalized Co-HITS algorithm [5].

For ranking nodes on either side, we define x 0 i and y 0 tial ranking value of n i and t j , respectively. Both values are set as their corresponding LexRank scores for the sake of representative-ness. Then we construct the transition matrix W T  X  N whose en-tries consist of { p ( n i | t j ) } and the transition matrix W entries consist of { p ( t j | n i ) } .

The propagation of ranking score is an iterative process. Follow-ing Deng et al. [5], we define the ranking scores x i for n for t j for the iteration as follows: where  X  and  X  are the tradeoff parameters ranging from 0 to 1, which is used to determine the extent to which the model relies on the propagated relations. Here we empirically set  X  =  X  =0 . 5 and did not employ regularization for simplicity.

In each iteration, the score y j is propagated from t j to n scores are propagated from other nodes of T to n i .Then n is updated to get a new value x i . The iterative updating procedure continues until convergence.
After ranking the sentences and tweets on both sides, we used two methods to generate complementary summaries considering the nature of complementarity of different granularities. Since both of the representativeness and complementarity measure have been considered during the co-ranking of sentences and tweets, the top ranked sentences and tweets are expected to be the most informa-tive and the most likely to have the complementary counterparts at the other side.
For summary-level complementarity, we can simply cut out the top ranked sentences and tweets at both sides to generate the news summary and tweet summary in such a way that the predefined length of the summaries are met. Note that there is not necessar-ily one-to-one correspondence of complementarity between news sentences and tweets, but as a whole, the two summaries are com-plementary due to the effect of the complementarity-based jumping probability in the co-ranking.
For achieving sentence-level complementarity, we start from the top ranked sentences. For each sentence following the order, we then look up the transition matrix W N  X  T to obtain the neighboring tweets of the chosen sentences w hose transition probability is non-zero, from which the tweet with the highest complementarity score is selected to match the sentence. We gradually add the selected sentence-tweet pairs until the length of the summary is met.
Actually, the selection of complementary pairs could be done in other possible ways. For example, it could be the other way round by first following the order of the top ranked tweets, for each of which we then select the most complementary sentence at news side. Or one could also alternately picks up a sentence and a tweet from the respective ranking lists and select the most complemen-tary counterpart for the pickup just in between the alternation. For simplicity, in this paper, we just adopt the sentence-first approach and leave the tweet-first approach and the interleave approach for future study.
Because we study a non-standard summarization task, there is no benchmark data sets available. Therefore, we collected a dataset containing the news sentences and tweets for 10 trending subject matter and manually composed the gold-standard summaries for these subjects. The dataset was used for automatic evaluation pur-pose.
First, we collected 10 trending subjects that are popularly dis-cussed on both traditional news media and Twitter during the first half year of 2012, as shown in Table 3.

Then we manually constructed human readable summaries for news side as well as tweets side, where the complementarity is con-sidered across the two summaries for each of the subjects which will be used as the gold-standard summaries. Specifically, the cre-ation of gold standard was done as the following: The news sum-maries were taken from English Wikipedia 1 and Wikinews 2 first one or two paragraphs of an Wikipedia or Wikinews article usually contain a brief description of the subject which could be considered as a summary. However, Wikipedia and Wikinews ed-itors are inclined to refer to traditional news materials when com-posing the articles. Therefore, little complementarity information from social media could be found in this resource. For construct-ing tweets summaries that are complementary to the news counter-parts, we searched Twitter using the given subjects as queries, from the search results we manually selected the relevant tweets that appear complementary to the corresponding news sentences and added them into the tweets summaries. Note that although we were unable to ensure that complementary tweets could be found for ev-ery news sentence, most of the sentences (nearly 85%) can still end http://en.wikipedia.org/wiki/Main_Page http://en.wikinews.org/wiki/Main_Page Table 3: The statistics of the data set. S T is the total number of tweets, S N is total number of news sentences, SU N is the length (the number of words) of standard news summary and SU T is the length (the number of words) of standard tweets summary. up with some complementary tweets, from which we chose up to 2 tweets appearing the most complementary to each sentences. For example, for the subject  X  X eath of Marie Colvin X , we treated the paragraph in Wikipedia talking about her death as the news sum-mary. Then we found the relevant tweets via Twitter search inter-face (choose  X  X op X   X  rank by relevance). For each sentence in the news summary, we looked for at most 2 tweets that are comple-mentary to it.

Finally, we collected a set of test corpus (as the input of sum-marizer) for these 10 subjects by (1) referring to the news articles listed in the references of Wikipedia or Wikinews article about the subject, and (2) searching Twitter and collecting all the top ranked tweets. The news sentences and tweets in the standard summaries were excluded from the test corpus. Some statistics of the corpus are also given in Table 3.
Since we X  X e dealing with a new summarization problem, there is not a previous approach that we can compete directly. But some existing methods can be modified and/or performed on our data set.
We performed LexRank [6] on the test corpus of the two me-dia. LexRank simply did not take into account any complementar-ity features. From the two resulted ranking lists, we extracted and output the top ranked sentences and tweets as the summaries since the ranking score reflects their representativeness.
Our work is related to the contrastive summarization of opin-ions proposed by [10, 11, 17]. We can modify their approaches for adapting to our task. Inspired by Lerman and McDonald [11], we used a model-based algorithm to optimize an objective function for generating complementary summaries. Figure 4 illustrates the basic idea of this method, where T X and T Y denote the original corpora, S X and S Y denote their corresponding summaries, and the lines crossing X and Y represent the contrastive correlation between two corpora. To make the summaries complementary, we modified the original objective function by explicitly taking into ac-count rough complementarity to replace the contrastiveness terms in the original objective function. The modified objective function Figure 4: Joint model for complementary summarization based on Lerman and McDonald [11]. is given as below: where KL ( . ) is the KL-divergence between two distributions and P ( . ) is a language model with respect to the given text, for which we used the unigram model based on the word distributions es-timated from our ccTAM model. Note that in order for comple-mentary summaries instead of contrastive ones, we used the ad-dition for KL ( P ( T X ) ,P ( S Y )) and KL ( P ( T Y ) ,P ( S place the subtraction in Lerman and McDonald [11]. We also used the greedy hill climbing algorithm for summary generation follow-ing [11]. The final summaries are just S X and S Y . This method is referred to as KLD in the rest of the paper.
One simple approach is to define the jumping probability p ( n and p ( t j | n i ) without including the complementarity score I (thus ccTAM is not used). Therefore, p ( n i | t j ) and p ( t reduced to be similarity-based. This model, referred to as Cosine , prefers jumping across similar excerpts rather than complementary ones, in which we used idf-modified-cosine [6] as the similarity function.

We also tried to replace the Cosine with KL-divergence-based distance function, which is often used in language-modeling-based retrieval [13] and the method is named as LM : where  X  n i and  X  t j are the unigram language models for the given sentence and tweet respectively. Then we estimate p ( w | Bayesian smoothing, where s represents n i or t j , C is the corpus,  X  S is a smoothing parameter, and tf w,s is term frequency of w in s .
This baseline extended the BL-0 by taking into account our com-plementarity score for choosing the corresponding tweets given the ranked news sentences. Instead of ranking tweets with LexRank separately, we chose the most complementary tweets for each sen-tence in the LexRank-generated news summary. It is also a simpli-fied version of our method for generating the sentence-level com-plementary summaries (see Section 5.3.2) by removing the random-walk-based co-ranking procedure. Figure 5: Effectiveness of the complementary measure in terms of ROUGE-1 recall under different configurations of topics and aspects. z: topic model only; y: aspect model only; zy: topic-aspect model; z+y: topic model+aspect model; z+y+zy: topic model + aspect model + topic-aspect model.
We used the ROUGE metric [12] for automatically comparing the summaries produced with gold standard summaries. The re-call values based on ROUGE-1, ROUGE-2 and ROUGE-SU4 were computed by running ROUGE-1.5.5. During the preprocessing of the test corpus, we performed stemming but did not remove stop words, and the news articles were split into sentences using an on-line sentence split tool 3 .
Here we examine the effectiveness of I comp for capturing the complementarity in multi-facet t opics under 5 configurations based on different topic and aspect combinations: z,y,zy,z + y,z + y + zy (see Section 4.1). Figure 5 shows the results.

The result is quite intuitive. Basically, the performance using aspect model ( y ) is better than using topic model ( z ) because as-pect model can capture the complement among different perspec-tives in multi-facet topics. Topic-aspect model ( zy ) performs bet-ter than topic or aspect model alone since vocabulary words hav-ing high probability in both dimensions are captured by the mix-ture. Sentence-tweet pairs containing such words are more com-plementary and are encouraged by the model. This is comparable with the combination of topic and aspect model ( z + y ). Combin-ing the all dimensions of topics, aspects and their mixture leads to the best results. This is because the summation of the production of probability-based scores from multiple topic-/aspect models in Eq. 4 and 5 strengthens the commonality and difference measures in a sense that the different models themselves are complementary.
For fair comparison, all the methods to be compared were set up to generate summaries which have the same length limit. Each method was run for 10 times, and we took the average recall of the 10 runs over 10 subjects for the comparison among different methods. Based on the total 100 runs over the 10 subjects, we can also conduct statistical significance test using the 100 recall values. We used the full configuration z + y + zy where appropriate. Table 4 and 5 shows the ROUGE recall of different methods on news summary and tweets summary, respectively.

In Table 4, we have the following observations and findings: http://code.google.com/p/splitta/ BL-0 LexRank 0.3662 0.2178 0.2173 BL-1 KLD 0.4975 0.2975 0.3010 BL-2 Cosine 0.4018 0.2313 0.2358 BL-3 LexComp 0.3662 0.2178 0.2173 Ours SumLevel 0.5533 0.3271 0.3325 Table 4: ROUGE evaluation results of news summarization. The improvements made by our method over the baselines are all statistically significant at 95% confidence level ( p &lt;0.05). BL-0 LexRank 0 . 5034  X  0 . 3632  X  0 . 3366  X  BL-1 KLD 0 . 6298  X  0 . 4340  X  0 . 4156  X  BL-2 Cosine 0 . 5581  X  0 . 3893  X  0 . 3704  X  BL-3 LexComp 0 . 6300  X  0 . 4444  X  0 . 4271  X  Ours SumLevel 0.6643 0.4539 0.4425 Table 5: ROUGE evaluation results of tweets summarization. The improvements made by our method over the baselines are all statistically significant.  X   X  95% confidence level ( p &lt;0.05);  X   X  90% confidence level ( p &lt;0.1)
From Table 5, we have the following findings: subject  X  X ussian jet crash X  compared to the gold standard summaries.
Among others, BL-0 (LexRank) performed worst since no com-plementarity is considered. LM is better than Cosine since lan-guage model focuses more on the distance at semantic level than lexical matching.
Table 6 presents the output summaries of the subject  X  X ussian jet crash X  generated by our method (SumLevel) with the gold-standard summaries and the summaries generated by BL-0. We observe that the complementary correlation of the two sets of summaries gen-erated by our method is obviously clearer than those generated by LexRank. Comparing against the gold standard summaries, some interesting complementarity details are also captured by our model. Our method can capture additional information from tweets to sup-plement the news summary. Such information is like  X  X he crashed plane carried eight Russian X ,  X  X he crash puts Indonesian sales in limbo X ,  X  X ussa X  X  aircraft industry is struggling for surival X ,  X 12 bodies are found in the crash X ,  X  X et crash bodies were sent for iden-tification X , etc.. Overall, the quality of the summaries at both sides appear much better than those of BL-0 since the complementarity is explicitly taken into account and the co-ranking jointly reinforces the identification of complementary sentence-tweet pairs.
On the other hand, we realize that discovering sentence-level complementarity is very challenging as we are unable to find much sentence-tweet complementary correspondence from the results. In the gold-standard summaries, it is even not clear-cut to tell which tweets are complementary to specific news sentences, reflecting the difficulty for human summarizers to judge complementarity pre-cisely. But overall, the gain by reading the complementary sum-maries appears helpful and beneficial to users. In this regard, user experience study should be conducted in the future.
In this paper, we study the task of generating complementary summarization from News and Tweets. We propose a novel unsu-pervised approach to summarize trending subjects by jointly dis-covering the relevant complementary information from both sides. To measure the complementary sentence-tweet candidate pairs, we defined a scoring function and built the ccTAM model, which com-bined topic-aspect model and cross-collection topic model, for es-timating the complementarity score. A random walk model was used to reinforce the candidate selection based on a bipartite graph by modifying the jumping probability with this complementarity score. Evaluation was conducted using manually created data sets. We found that our method obtained significantly better ROUGE scores than four state-of-the-art baseline methods.

Given the difficulty of our problem, there are a number of direc-tions we plan to explore in the future. First, we will quantitatively evaluate ccTAM to study how it is related to the complementarity score. Second, we may study complementary measure based on the linguistic and semantic formalisms. Third, we will improve the quality of our data sets for more accurate ground truth. [1] C. Andrieu, N. Freitas, A. Doucet, and M. Jordan. An [2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. [3] C. Chemudugunta, P. Smyth, and M. Steyvers. Modeling [4] H. Daum X  III and D. Marcu . Bayesian query-focused [5] H. Deng, M. Lyu, and I. King. A generalized Co-HITS [6] G. Erkan and D. Radev. LexRank: Graph-based lexical [7] S. German and D. German. Stochastic relaxation, Gibbs [8] A. Haghighi and L. Vanderwende. Exploring content models [9] T. Hofmann. Probabilistic latent semantic indexing. In [10] H. Kim and C. Zhai. Generating comparative summaries of [11] K. Lerman and R. McDonald. Contrastive summarization: an [12] C. Lin and E. Hovy. Automatic evaluation of summaries [13] D. Metzler, S. Dumais, and C. Meek. Similarity measures for [14] S. Palekar and D. Sedera. The competing-complmentarity [15] M. Paul and R. Girju. Cross-cultural analysis of blogs and [16] M. Paul and R. Girju. A two-dimensional topic-aspect model [17] M. J. Paul, C. Zhai, and R. Girju. Summarizing contrastive [18] I. Titov and R. McDonald. A joint model of text and aspect [19] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: finding [20] Z. Yang, K. Cai, J. Tang, L. Zhang, Z. Su, and J. Li. Social [21] C. Zhai, A. Velivelli, and B. Yu. A cross-collection mixture [22] W. Zhao, J. Jiang, J. Weng, J. He, E. Lim, H. Yan, and X. Li.
