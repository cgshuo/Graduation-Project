 Informal Mathematical Discourse (IMD) is characterized by the mixture of natural language and symbolic expressions in the context of textbooks, publications in mathematics and mathematical proof. We focused the IMD processing at the low level of discourse. In this paper, we proposed the prepro-cessing phase before the IMD structure analysis within the context of Controlled Natural Language (CNL). Our con-tribution is defined in context of the IMD processing and the use of machine learning; first, we present a CNL, a pure corpus and Matemathical Treebank for processing IMD; sec-ond, we present a preprocessing phase for IMD analysis with connectives disambiguation and verbs treatment, finally, we found a satisfactory result on input text parsing using a sta-tistical parsing model. We will propagate these results for classification of argumentative informal practices via the low level discourse in IMD processing.
 I.2 [ Artificial Intelligence ]: Natural Language Process-ing X  Language parsing and understanding Algorithms, Experimentation, Languages Controlled Natural Language, Informal Mathematical Dis-course, Connective Tagging, Statistical Parsing, Corpus
Informal Mathematical Discourse (IMD) is characterized by a mixture of natural language and symbolic expressions in the context of textbooks, publications in mathematics, and mathematical proof. Linguistically, processing informal mathematical discourse is addressed under three aspects, as stated in [15]: (i) the linguistic, domain, and notational con-text, (ii) the imprecision of informal language, and (iii) the mixture of symbolic language and natural language. Com-putationally, it is expensive to formalize mathematical texts, some of the reasons stated in [10] are: (1) the texts may con-tain some complex and rich linguistic features of NL like the use of anaphoric pronouns and references, rephrasing, dis-tributive vs. collective readings, etc; (2) the texts could be inherently ambiguous if not written carefully; and (3) math-ematical proofs may contain reasoning gaps, which are hard to fill by using automated theorem proving (ATP). In this context, there is interest on the use of informal argumen-tative practices in mathematical proof to soften the formal meaning in high school and university levels. In order to in-vestigate about automatically processing informal argumen-tative practices, we propose an automatic characterization by using machine learning and corpus linguistics within the context of CNL.
 In this paper, we present the Mathematical Treebank, a syn-tactically annotated corpus in which sentences are provided by a pure corpus. The pure corpus consist of a standard set of informal deductive proofs written in a CNL. In ad-dition, the pure corpus consists of mathematical proofs in which their sentences are well-formed with a informal deduc-tive character embedded in a CNL. As a preprocessing step before discourse structure analysis, we propose connective tagging and parsing of test data (input text) on the Mathe-matical Treebank. Figure 1 shows the basic workflow of the preprocessing phase. The input text was first segmented into sentences; second, the split text was tagged sentence by sentence; third, the already split and tagged text was parsed by using a statistical parsing model; finally, we obtained the parsed text from the input text. This paper is organized as follows: first, we present an introduction on CNL into IMD in  X  2; then, in  X  3 we describe the experiment we per-formed to define our pure corpus; next, in  X  4 we show the annotation scheme of the Mathematical Treebank; finally, we explain the preprocessing phase in  X  5 and we state our conclusions in  X  6.
Controlled Natural Languages within IMD are subsets of natural languages whose grammars and dictionaries have been restricted to reduce or eliminate both ambiguity and complexity. We developed a controlled natural language for mathematics, which is a defined subset of Spanish with re-stricted grammar and dictionary. As in Naproche CNL [8], we distinguish between macrostructure (argumentation text structure) and microstructure (grammatical structure in a sentence).
Our CNL macrostructure is structured by a set of sen-tences like: assumptions, statements, justifications and de-ductions . For example, an argumentation model is presented as a demonstration that begins with an assumption, and then follows with a statement followed a justification and ending up with a deduction. All argumentation models have an deductive order and are known as proof acts . We defined 15 proof models or proof acts characterized by those starting with one assumption and those starting with two assump-tions. The proof remainder, in its order, is statements, jus-tifications, and deductions. Assumptions are always intro-duced by an assumption trigger or clue word (e.g., sea, sea que, suponga, and suponga que ). A statement always starts with connectives like: entonces, por lo tanto, de modo que, as  X  X  que, en particular, etc. Justifications always start with connectives like: porque, debido a que. Deductions always starts with words like: por lo tanto and en consecuencia, followed by a clue word se deduce que .
Mathematical language of sentences is a CNL that ex-presses formality in informal manner. In our CNL microstruc-ture, the use of nouns, adjectives, verbs, articles, determin-ers, connectives ( entonces, por lo tanto, porque, or, etc ) and morphological information operates as in natural Spanish. Sentences in CNL microstructure always start with words like: entonces, suponga que, de modo que, por lo tanto, etc. In the CNL microstruture is also explicit the use of subordi-nate and coordinated clauses, as well as anaphoric pronouns and references are replaced by justifications. Our approach presents a very constrained CNL microstructure for mathe-matics in which complex linguistic phenomena are avoided; rather, we are interested in the structure of informal deduc-tive practices through processing the linguistics of a more natural than symbolic CNL.
The development of a corpus is an expensive task. How-ever, little is known about the use of linguistics corpus in processing IMD; this is due to the lack of empirical data. Therefore, some approaches agree with the need to research on linguistic phenomena occurring in IMD [16, 17]. The original corpus is a compilation of 240 mathematical proofs performed by both engineering and mathematics students. In order to build the original corpus, an experiment was de-signed and applied to obtain a representative data set. This set provided us the use of cases of different forms of argumen-tation in mathematical proofs. The 120 students from the courses of Discrete Mathematics and Mathematics partici-pated in the experiment and were instructed in the impor-tance of theorem proving without predisposing them in the kind of argument they could use. We were inspired by the experimentation model defined in [16] and we conducted an experiment where students were tested to demonstrate two theorems of set theory: (1) si A  X  B entonces U  X  A  X  B ; (2) P ( A  X  B ) = P ( A )  X  P ( B ). So the original corpus was categorized into four types of argumentative practices pro-posed in [13]: formal deductive argumentation, explicative argumentation, empirical-inductive argumentation, and in-formal deductive argumentation. Despite the argumentative practices proposed, we chose to work only informal deduc-tive argumentation due to its closeness with IMD. The pure corpus is composed of a standard set of 150 proofs in which their sentences are well-formed within CNL microstructure. These proofs were chosen among 240 proofs from the orig-inal corpus. We characterized 15 proof types as informal deductive proofs. Sentences and argumentations expressed in a mixture of natural and symbolic language were changed for the natural language sentences.
In this section, we present the Mathematical Treebank, a corpus manually annotated with syntactic structures to sup-port studying and analyzing IMD phenomena in low-level discourse. The Mathematical Treebank is a corpus in Span-ish, which is a resource with about 748 sentence/tree pairs and 10,648 words included within 150 mathematical argu-mentations of pure corpus. The annotation scheme basically follows the Penn Treebank II (PTB) scheme [1], human-annotated. From PTB, we use the clausal structure, as well as most of the labels. From the UAM Spanish Tree-bank [14] scheme we adapted the annotation structure of the connectives, as well as the annotation scheme for mor-phological information. The set of morphological features was adapted from Freeling 2.2 [12]. In addition, we added a set of novel labels with mathematical information. Labels such as  X  X eD X ,  X  X nD X ,  X  X PU X ,  X  X PI X ,  X  X PC  X ,  X  X PP  X  will support the extraction tasks on processing IDM. We anno-tated syntactic categories (i.e., parts-of-speech like nouns, adjectives, articles, determiners, etc.) syntactic functions (e.g.,  X  X eD X ,  X  X nD X ) and syntactic features (i.e., number, gender, person, tense, etc). At the level of clauses, we add the novel label  X  X OORD X . We annotated all coordinated phrases with the label  X  X OORD X ; in addition, if there were coordinating conjunctions like ( y [and], o [or], con [with] , etc), we added the label  X  X C X  (Coordinating Conjunction). If there were coordinated clauses, we put the label  X  X ONN-CC X  (connectives) instead of the label  X  X C X . Subordinate clauses are annotated with the label  X  X BAR X . Other com-mon tags are:  X  X  X  (sentence),  X  X P X  (noun phrase),  X  X P X  (prepositional phrase), and  X  X P X  (verbal phrase). At word level, we defined the following labels:  X  X N X  (noun),  X  X A X  (article),  X  X T X  (determiner),  X  X AR X  (variable),  X  X J X  (adjec-tive). We also incorporated the morphological information in tagset. In summary, we manually annotated mathemat-ical proofs to the PTB format, merging its with the POS-tagging annotation of our mathematical corpus.
In this section, we detailed our approach for the prepro-cessing of input text (informal argumentative proof) based on the Mathematical Treebank-trained, and using a gold-standard parser, a sentence splitter and the Brill tagger for connectives tagging. To our knowledge, our approach is the first to restrict the input text to a CNL microstructue before being preprocessed. Input texts are mathematical proofs written in a CNL, according to an informal deductive NL argumentation written originally by students from a dis-crete mathematics course. In addition, some students were trained to use the controlled language to write argumen-tations. The problem of sentence boundary identification (or sentence splitting) is the first step in text preprocess-ing. We defined a very simple splitter, which evaluate the input text within CNL. Our sentence splitter is based on Clough X  X  splitter [4]. Under this approach, the sentences boundaries are determined as either sentence-break or non-sentence-break. The regular expression [.!?][() X  X +[A-Z] is called sentence break in which the classifier of [.!?] trained a dictionary of capital letters. Second, we described a simple baseline approach; to training the Brill tagger to identify connectives. Finally, we described the first-ever results of applying statistical parsing models to our small Mathemat-ical Treebank.
In this part, as in [9] we propose connective tagging by us-ing a baseline approach based on the Brill tagger. However, our approach emphasizes on rewriting rules without retrain-ing the tagger. Our results indicate that with the baseline approach we can obtain disambiguation of connectives. We concluded that our connective disambiguation improves the performance of the parsing phase. In connective tagging, we examined the use of the Brill tagger, a known POS tagger to perform the disambiguation task. We assigned the  X  X ONN X  tag to all words used as discourse connectives. Training the Brill tagger involves various steps. Initially, we defined a lex-icon that records for each word its most frequent POS tag. In lexicon, there are words with multi-POS tags (e.g, the word  X  X  [and] X  is labeled with  X  X C X  or  X  X ONN-CC X  ). Next, the tagger obtains rules for guessing the POS tags of the un-known words. After tokenizing each of sentences, the tagger assigns predefined tags to unknown words. We chose  X  X N X  as the initial tag for all words. The tagger runs on input text by using rewriting rules. These rules resort to prefixes or suffixes of the unknown words to determine their correct tag, as well as for adjacent words and their tags to rewrite the incorrect tags. In Spanish, many connectives are multi-words such as:  X  X n particular [ in particular ] X ,  X  X or lo tanto [ therefore ] X ,  X  X e modo que [ so that ] X , etc, (A good lexicon of connectives is found in Spanish Treebank [14]). In particu-lar, we defined a set rewriting rules to convert both discourse and non-discourse expressions to a single label connective. Finally, we defined rewriting rules to treat contractions like ( X  X el [de el] X , X  X l [a el] X ). In our experiments, we tested a set of 328 input texts (proof texts) with 1.300 sentences, and with an average of 6 connectives per proof. The tagger gave maximum accuracy for each category (determiners, articles, verbs, connectives, etc.) for each particular proof, including ambiguity situations. The tagger was not evaluated with Table 1: The head rules used by the parser. In the first column, the Non-Terminal is the left-hand-side of a rule. Direction the specifies whether search starts from the left or right end of rule, and third column are the Head child .
 measures as PARSEVAL because our interest focused on in-put text and its POS tagging.
The data-driven parsing in corpus has been the backbone in discourse analysis for many investigations. On the other hand, data-driven parsing has been successfully applied to Spanish [3, 7]. In this section, we present a data-driven parsing model and we use statistical parsing to train a set of input texts. For training, we defined a human-annotated Mathematical Treebank, along with labeled examples of cor-rect parse structures ( X  X old trees X ). We created a new lan-guage package within the possibilities provided by Bikel X  X  statistical parser [2]. We trained the Mathematical Treebank by using Bikel X  X  parser to obtain the parse tree of the input text. Bikel X  X  parsing engine has been developed supporting a wide range of head-driven parsing models, including the BBN X  X  SIFT system [11], as well as both Collins Models 2 and 3 [5]. We built a language package based on the four required classes: Treebank, Training, Headfinder and WordFeatures (for more details see [2] ). Finally, we spec-ify data and methods on the Mathematical Treebank and merged our head rules with Cowan X  X  head rules for Spanish [7, 6]. In Table 1, we show the set of head-findings rules used in the Mathematical Treebank parsing model. This set of deterministic head rules specifies which child is the head of its parent. The head rules identify the headchild for each non-terminal. Any non-terminal not in this list takes the left-most child as its head.
In the Mathematical Treebank, coordinating clauses and coordinating conjunctions are placed as sister nodes on a flat structure. As in [7] we represented the coordinating clauses Figure 2: a) Coordinating conjuntion. b) Coordi-nating clauses with a flat structure and placed the label  X  X ONN-CC X  as head of  X  X OORD X  (Figure 2(b)). We placed coordinating conjunctions as sister nodes of ( X  X eDs X  or  X  X Ps X ), for exam-ple, in the expression:  X  X  el conjunto complemento de A o a el conjunto A X  [ to the complement of set A or to set A ] (Figure 2(a)), the head of  X  X OORD X  is  X  X C X .
We considered three cases as subordinate clauses: rela-tive pronouns, conditionals, and justifications. If there is a relative pronoun, then  X  X BAR X  selects as head node the node  X  X RR X  (Figure 3(a)). If there is a conditional, then  X  X BAR X  selects as head the node  X  X OND X  (Figure 3(b)). If there is a justification, then  X  X BAR X  selects as head node the node  X  X RO X  (Figure 3(c)). In the three cases, we de-fined headwords for each type of clauses, for example, we defined  X  X orque X  X nd  X  X ebido a que X  as headwords of  X  X RO X . Figure 3: a) Relative pronoun b) Subordinate con-ditional c) Subordinate justification
In [17], the definite descriptions are employed as anaphoric objects, which reference to propositions, formulae, and com-plete sub-proofs. We annotated indefinite and definite de-scriptions with an extraction purpose rather than an anaphoric purpose. We annotated indefinite and definite descriptions as noun phrases; if the noun phrase is a definite description, then  X  X P X  selects as head node the node  X  X eD X  (Definite Description); if the noun phrase is an indefinite description then  X  X P X  selects as head node the node  X  X nD X  (Indefinite Description). Other definite descriptions are the set opera-tions.
The Mathematical Treebank is a small manually anno-tated corpus of 150 proofs from our pure corpus; with 748 sentence/tree pairs, which we used to training our model. The average sentence length is 33 tokens. These sentences are part of the 150 proofs of our pure corpus. On average, each proof has 132 tokens. The treebank trees contain infor-mation about the constituency and syntactic structure, as well as connective annotations, morphological information, indefinite and definite descriptions annotation. With respect to test data, we collected 328 proofs with an average of 1300 sentences, namely, the unlabeled data are far more than the labeled data. We trained and evaluated Bikel X  X  parser on two empirical models for each input text. In Table 2, we show the results of the two models on the test set; first, we defined a baseline model that identifies indefinite and def-inite descriptions, without morphological information; sec-ond, we defined a model that identifies indefinite and definite descriptions, with morphological information. We used our baseline model to evaluate the efects of using morphology. Unlike the morphological model used by [7], our POS tagset can be considered as an overall morphological model with all attributes. For these two models, we trained the Mathemat-ical Treebank to see the effects of POS tagging, parser and the types of sentences within CNL. In addtion, we look the effect of morphological information in two cases; first, when one sentence has two verbs: one principal and other subordi-nate; second, when one sentence has two nouns of the same gender that must agree; for example,  X  X a uni  X on X  and  X  X st  X a contenida X . In general, we found that, gender and number in articles, determiners, nouns and adjectives had a sligth variation with reference to the performance of the baseline model; we also found that, types and modes of verbs had the same performance with respect to baseline model. Our morphological model uses all attributes on the test data (Un-labeled proofs). We found, however, that adding morpholog-ical information leads sometimes to a considerable variation (for example, the dependencies 4 and 6 in Table 3). We con-clude that adding morphological information to training had not important effects; first, because our training data are a few, and second, because our treebank language is within CNL. In training, we observed a strong relation between de-pendencies and linguistics phenomena in IMD [7]. These dependencies represent paraphrased linguistics phenomena like: union between sets, intersection between sets, expla-nations, conditionals, etc. We saw a relative gain in the recovery of some these dependencies when we added mor-phological information. Specifically, in subordinate clauses when the head is a relative pronoun. We found that the gain is due to the fact we annotated verbs with type and mode information. Although, our baseline model was able to dis-tinguish between principal, subordinate, and auxiliary verbs within subordinate clauses. In general, all dependencies that we shown in Table 3 were not difficult for the parser. A rea-son for the success is that the training CNL is the same of the input text. We launched a statistical parsing model for Mathematical Treebank in Spanish, and we trained two models within the CNL context. In both models, we exploited natural condi-Table 3: The first column shows the type and sub-type, where the subtype is specified by tuples of the constituents { parent non-terminal, head non-terminal, modifier non-terminal } ; in the second col-umn the model BL is the baseline, and MOR is the morphological model. The third column represents the accuracy of each one of the input texts in train-ing.
 tions of IMD. The baseline model achieves an F1 score of 85.04%; the second model achieves an F1 score of 85.14%. For the latter model, we performed a slight variation on the baseline model by using morphological information. In both models, we found that our approach explicitly represents the linguistic IMD phenomena (eg., conditionals, definite descriptions, operations, etc.,). We experimented a training model with a few data to accomplish a suitable structure for extraction of features in processing IMD. The big difference between training data and test data lies in the amount of data, but not in the structure of sentences and mathemat-ical information. We shall consider adding more theorems of set theory. We conclude that good results at the input texts parsing are because the training and testing data were made within the CNL context. In this work our aim was to fully analyze the input text rather than to test the treebank as a large training corpus. Our test data will always be in CNL context. Finally, we will use the input text parsing for extraction tasks as an important resource in lexical and syn-tactic features characterization. We will use these features for classification of argumentative informal practices via the low level discourse in IMD processing. [1] A. Beis, M. Ferguson, K. Katz, and R. Mac-Intire. [2] D. M. Bikel. Design of a multilingual, parallel [3] G. Chrupala and J. V. Genabith. Using [4] P. Clough. A perl program for sentence splitting using [5] M. Collins. Head-Driven Statistical Models for Natural [6] B. Cowan. A Tree-to-Tree Model for Statistical [7] B. Cowan and M. Collins. Morphology and reranking [8] M. Cramer, B. Fisseni, P. Koepke, D. Kuhlwein, [9] S. Dipper and M. Stede. Disambiguating potential [10] M. Humayoun and C. Raffalli. Mathabs: a [11] S. Millerand, H. Fox, L. Ramshaw, and R. Weischedel. [12] L. Padr  X o. Freeling 3.0: An open source suite of [13] A. Recio. La demostraci  X on en matem  X atica. una [14] S. Ruesga, A. Sandoval, and L. Le  X on. Spanish [15] M. Wolska. A language engineering architecture for [16] M. Wolska, B. Q. Vo, D. Tsovaltzi, [17] C. Zinn. Understanding Informal Mathematical
