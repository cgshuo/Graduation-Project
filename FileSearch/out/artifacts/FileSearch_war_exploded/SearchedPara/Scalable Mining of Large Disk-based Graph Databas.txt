 Mining frequent structural patterns from graph databases is an interesting problem with broad applications. Most of the previous studies focus on pruning unfruitful search subspaces effectively, but few of them address the mining on large, disk-based databases. As many graph databases in applications cannot be held into main memory, scalable mining of large, disk-based graph databases remains a chal-lenging problem. In this paper, we develop an effective index structure, ADI (for ad jacency i ndex), to support mining var-ious graph patterns over large databases that cannot be held into main memory. The index is simple and efficient to build. Moreover, the new index structure can be easily adopted in various existing graph pattern mining algorithms. As an ex-ample, we adapt the well-known gSpan algorithm by using the ADI structure. The experimental results show that the new index structure enables the scalable graph pattern min-ing over large databases. In one set of the experiments, the new disk-based method can mine graph databases with one million graphs, while the original gSpan algorithm can only handle databases of up to 300 thousand graphs. Moreover, our new method is faster than gSpan when both can run in main memory.
 Categories and Subject Descriptors: H.2.8 [Database Applications]: Data Mining General Terms: Algorithms, Performances.
 Keywords: Graph mining, index, graph database, frequent graph pattern.
Mining frequent graph patterns is an interesting research problem with broad applications, including mining struc-
This research is supported in part by NSF grant IIS-0308001 and National Natural Science Foundation of China (No. 60303008). All opinions, findings, conclusions and rec-ommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. tural patterns from chemical compound databases, plan databases, XML documents, web logs, citation networks, and so forth. Several efficient algorithms have been pro-posed in the previous studies [2, 5, 6, 8, 11, 9], ranging from mining graph patterns, with and without constraints, to mining closed graph patterns.

Most of the existing methods assume implicitly or explic-itly that the databases are not very large, and the graphs in the database are relatively simple. That is, either the databases or the major part of them can fit into main mem-ory, and the number of possible labels in the graphs [6] is small. For example, [11] reports the performance of gSpan , an efficient frequent graph pattern mining algorithm, on data sets of size up to 320 KB, using a computer with 448 MB main memory. Clearly, the graph database and the projected databases can be easily accommodated into main memory.

Under the large main memory assumption, the computa-tion is CPU-bounded instead of I/O-bounded. Then, the algorithms focus on effective heuristics to prune the search space. Few of them address the concern of handling large graph databases that cannot be held in main memory.
While the previous studies have made excellent progress in mining graph databases of moderate size, mining large, disk-based graph databases remains a challenging problem. When mining a graph database that cannot fit into main memory, the algorithms have to scan the database and nav-igate the graphs repeatedly. The computation becomes I/O-bounded.

For example, we obtain the executable of gSpan from the authors and test its scalability. In one of our experiments we increase the number of graphs in the database to test the scalability of gSpan on the database size. gSpan can only handle up to 300 thousand graphs. In another exper-iment, we increase the number of possible labels in graphs. We observe that the runtime of gSpan increases exponen-tially. It finishes a data set of 300 thousand graphs with 636 seconds when there are only 10 possible labels, but needs 15 hours for a data set with the same size but the number of possible labels is 45! This result is consistent with the results reported in [11].

Are there any real-life applications that need to mine large graph databases? The answer is yes. For example, in data integration of XML documents or mining semantic web, it is often required to find the common substructures from a huge collection of XML documents. It is easy to see applications with collections of millions of XML documents. There are
Details will be provided in Section 6 hundreds of even thousands of different labels. As another example, chemical structures can be modeled as graphs. A chemical database for drug development can contain millions of different chemical structures, and the number of different labels in the graphs can easily go to up to 100. These large databases are disk-based and often cannot be held into main memory.

Why is mining large disk-based graph databases so chal-lenging? In most of the previous studies, the major data structures are designed for being held in main memory .For example, the adjacency-list or adjacency-matrix representa-tions are often used to represent graphs. Moreover, most of the previous methods are based on efficient random accesses to elements (e.g., edges and their adjacent edges) in graphs. However, if the adjacency-list or adjacency-matrix represen-tations cannot be held in main memory, the random accesses to them become very expensive. For disk-based data, with-out any index, random accesses can be extremely costly.
Can we make mining large, disk-based graph databases fea-sible and scalable? This is the motivation of our study.
Since the bottleneck is the random accesses to the large disk-based graph databases, a natural idea is to index the graph databases properly. Designing effective and efficient index structures is one of the most invaluable exercises in database research. A good index structure can support a general category of data access operations. Particularly, a good index should be efficient and scalable in construction and maintenance, and fast for data access.

Instead of inventing new algorithms to mine large, disk-based graph patterns, can we devise an efficient index struc-ture for graph databases so that mining various graph pat-terns can be conducted scalably? Moreover, the index struc-ture should be easy to be adopted in various existing meth-ods with minor adaptations.

Stimulated by the above thinking, in this paper, we study the problem of efficient index for scalable mining of large, disk-based graph databases, and make the following contri-butions.
The remainder of the paper is organized as follows. We define the problem of frequent graph pattern mining in Sec-tion 2. The idea of minimum DFS code and algorithm gSpan are reviewed in Section 3, and the major data access opera-tions in graph mining are also identified. The ADI structure is developed in Section 4. The efficient algorithm ADI-Mine for mining large, disk-based graph databases using ADI is presented in Section 5. The experimental results are re-ported in Section 6. The related work is discussed in Sec-tion 7. Section 8 concludes the paper. Inthispaper, wefocusonundirectedlabeledsimplegraphs. A labeled graph is a 4-tuple G =( V, E, L, l ), where V is a set of vertices , E  X  V  X  V is a set of edges , L is a set of labels , and l : V  X  E  X  L is a labeling function that assigns a label to an edge or a vertex. We denote the vertex set and the edge set of a graph G by V ( G )and E ( G ), respectively. Agraph G is called connected if for any vertices u, v  X  V ( G ), there exist vertices w 1 ,...,w n  X  V ( G ) such that { ( u, w 1 ) , ( w 1 ,w 2 ) ,..., ( w n  X  1 ,w n ) , ( w n ,v )
Frequent patterns in graphs are defined based on subgraph isomorphism.
 Definition 1 (Subgraph isomorphism). Givengraphs G =( V, E, L, l )and G =( V ,E ,L ,l ). An injective func-tion f : V  X  V is called a subgraph isomorphism from G to G if (1) for any vertex u  X  V , f ( u )  X  V and l ( u )= l ( f ( u )); and (2) for any edge ( u, v )  X  E ,( f ( u ) ,f ( v ))  X  E and l ( u, v )= l ( f ( u ) ,f ( v )).
 If there exists a subgraph isomorphism from G to G ,then G is called a subgraph of G and G is called a supergraph of G ,denotedas G G .
 For example, the graph G in Figure 1(b) is a subgraph of G in Figure 1(a).

A graph database is a set of tuples ( gid, G ), where gid is a graph identity and G is a graph. Given a graph database GDB ,the support ofagraph G in GDB , denotedas sup ( G ) for short, is the number of graphs in the database that are supergraphs of G , i.e., |{ ( gid, G )  X  GDB | G G }| .
For a support threshold min sup (0  X  min sup  X | GDB | ), agraph G is called a frequent graph pattern if sup ( G )  X  min sup . In many applications, users are only interested in the frequent recurring components of graphs. Thus, we put a constraint on the graph patterns: we only find the frequent graph patterns that are connected.
 Problem definition. Given a graph database GDB and a support threshold min sup . The problem of mining fre-quent connected graph patterns is to find the complete set of connected graphs that are frequent in GDB .
In [11], Yan and Han developed the lexicographic order-ing technique to facilitate the graph pattern mining. They also propose an efficient algorithm, gSpan , one of the most efficient graph pattern mining algorithms so far. In this section, we review the essential ideas of gSpan ,andpoint out the bottlenecks in the graph pattern mining from large disk-based databases.
In order to enumerate all frequent graph patterns effi-ciently, we want to identify a linear order on a representation of all graph patterns such that if two graphs are in identical representation, then they are isomorphic. Moreover, all the (possible) graph patterns can be enumerated in the order without any redundancy.

The depth-first search tree ( DFS-tree for short) [3] is pop-ularly used for navigating connected graphs. Thus, it is natural to encode the edges and vertices in a graph based on its DFS-tree. All the vertices in G can be encoded in the pre-order of T . However, the DFS-tree is generally not unique for a graph. That is, there can be multiple DFS-trees corresponding to a given graph.

For example, Figures 1(c) and 1(d) show two DFS-trees of the graph G in Figure 1(a). The thick edges in Figures 1(c) and 1(d) are those in the DFS-trees, and are called forward edges , while the thin edges are those not in the DFS-trees, and are called backward edges . The vertices in the graph are encoded v 0 to v 3 according to the pre-order of the cor-responding DFS-trees.

To solve the uniqueness problem, a minimum DFS code notation is proposed in [11].
 For any connected graph G , let T be a DFS-tree of G . Then, an edge is always listed as ( v i ,v j ) such that i&lt;j .A linear order  X  on the edges in G canbedefinedasfollows. Given edges e =( v i ,v j )and e =( v i ,v j ). e  X  e if (1) when both e and e are forward edges (i.e., in DFS-tree T ), j&lt;j or ( i&gt;i  X  j = j ); (2) when both e and e are backward edges (i.e., edges not in DFS-tree T ), i&lt;i or ( i = i  X  j&lt;j ); (3) when e is a forward edge and e is a backward edge, j  X  i ;or(4)when e is a backward edge and e is a forward edge, i&lt;j .
 For a graph G and a DFS-tree T , a list of all edges in E ( G )inorder  X  is called the DFS code of G with respect to T , denoted as code ( G, T ). For example, the DFS code with respect to the DFS-tree T 1 in Figure 1(c) is code ( G, T ( v 0 ,v 1 ,x,a,x )-( v 1 ,v 2 ,x,a,z )-( v 2 ,v 0 ,z,b,x )-( v where an edge ( v i ,v j ) is written as ( v i , v j , l ( v l ( v j )), i.e., the labels are included. Similarly, the DFS code with respect to the DFS-tree T 2 in Figure 1(d) is code ( G, T 2 )= ( v 0 ,v 1 ,y,b,x )-( v 1 ,v 2 ,x,a,x )-( v ( v 3 ,v 1 ,z,a,x ) .

Suppose there is a linear order over the label set L . Then, for DFS-trees T 1 and T 2 on the same graph G , their DFS codes can be compared lexically according to the labels of the edges. For example, we have code ( G, T 1 ) &lt;code ( G, T in Figures 1(c) and 1(d).

The lexically minimum DFS code is selected as the repre-sentation of the graph, denoted as min ( G ). In our example in Figure 1, min ( G )= code ( G, T 1 ).

Minimum DFS code has a nice property: two graphs G and G are isomorphic if and only if min ( G )= min ( G ). Moreover, with the minimum DFS code of graphs, the prob-Input: aDFScode s , a graph database GDB and min sup Output: the frequent graph patterns Method: lem of mining frequent graph patterns is reduced to mining frequent minimum DFS codes, which are sequences, with some constraints that preserve the connectivity of the graph patterns.
Based on the minimum DFS codes of graphs, a depth-first search, pattern-growth algorithm, gSpan , is developed in [11], as shown in Figure 2. The central idea is to con-duct a depth-first search of minimum DFS codes of possi-ble graph patterns, and obtain longer DFS codes of larger graph patterns by attaching new edges to the end of the minimum DFS code of the existing graph pattern. The anti-monotonicity of frequent graph patterns, i.e., any super pattern of an infrequent graph pattern cannot be frequent ,is used to prune.

Comparing to the previous methods on graph pattern mining, gSpan is efficient, since gSpan employs the smart idea of minimum DFS codes of graph patterns that facili-tates the isomorphism test and pattern enumeration. More-over, gSpan inherits the depth-first search, pattern-growth methodologytoavoidanycandidate-generation-and-test. As reported in [11], the advantages of gSpan are verified by the experimentalresultsonbothrealdatasetsandsynthetic data sets.
Algorithm gSpan is efficient when the database can be held into main memory. For example, in [11], gSpan is scal-able for databases of size up to 320 KB using a computer with 448 MB main memory. However, it may encounter dif-ficulties when mining large databases. The major overhead is that gSpan has to randomly access elements (e.g., edges and vertices) in the graph database as well as the projec-tions of the graph database many times . For databases that cannot be held into main memory, the mining becomes I/O bounded and thus is costly.

Randomaccessestoelementsingraphdatabasesandcheck-ing the isomorphism are not unique to gSpan . Instead, such operations are extensive in many graph pattern mining al-gorithms, such as FSG [6] (another efficient frequent graph pattern mining algorithm) and CloseGraph [9] (an efficient algorithm for mining frequent closed graph patterns).
In mining frequent graph patterns, the major data access operations are as follows. OP1: Edge support checking. Find the support of an OP2: Edge-host graph checking. For an edge e = OP3: Adjacent edge checking. For an edge e =
Each of the above operations may happen many times during the mining of frequent graph patterns. Without an appropriate index, each of the above operations may have to scan the graph database or its projections. If the database and its projections cannot fit into main memory, the scan-ning and checking can be very costly.

Can we devise an index structure so that the related in-formation can be kept and all the above operations can be achieved using the index only, and thus without scanning the graph database and checking the graphs? This motivates the design of the ADI structure. In this section we will devise an effective data structure, ADI (for ad jacency i ndex), to facilitate the scalable mining of frequent graph patterns from disk-based graph databases.
The ADI index structure is a three-level index for edges, graph-ids and adjacency information. An example is shown in Figure 3, where two graphs, G 1 and G 2 , are indexed.
There can be many edges in a graph database. The edges are often retrieved by the labels during the graph pattern mining, such as in the operations identified in Section 3.3. Therefore, the edges are indexed by their labels in the ADI structure.

In ADI ,anedge e =( u, v ) is recorded as a tuple labels of the vertices, i.e., l ( u )and l ( v ), and the label of the edge itself, i.e., l ( u, v ). Each edge appears only once in the edge table, no matter how many times it appears in the graphs. For example, in Figure 3, edge ( A, d, C )appears once in graph G 1 and twice in graph G 2 .However,there is only one entry for the edge in the edge table in the ADI structure.
 All edges in the edge table in the ADI structure are sorted. When the edge table is stored on disk, a B+-tree is built on the edges. When part of the edge table is loaded into main memory, it is organized as a sorted list. Thus, binary search can be conducted.
For each edge e , the identities of the graphs that contain e form a linked list of graph-ids . Graph-id G i is in the list of edge e if and only if there exists at least one instance of e in G i . For example, in Figure 3, both G 1 and G 2 appear in the list of edge ( A, d, C ), since the edge appears in G and in G 2 twice. Please note that the identity of graph G appears in the linked list of edge e only once if e appears in G , no matter how many times edge e appears in G i .
Alistofgraph-idsofanedgearestoredtogether.There-fore, given an edge, it is efficient to retrieve all the identities of graphs that contain the edge.

Every entry in the edge table is linked to its graph-id linked list. By this linkage, the operation OP2: edge-host graph checking can be conducted efficiently. Moreover, to facilitate operation OP1: edge support checking, the length of the graph-id linked list, i.e., the support of an edge, is registered in the edge table.
The edges in a graph are stored as a list of the edges encoded. Adjacent edges are linked together by the common vertices, as shown in Figure 3. For example, in block 1, all the vertices having the same label (e.g., 1) are linked together as a list. Since each edge has two vertices, only two pointers are needed for each edge.

Moreover, all the edges in a graph are physically stored in one block on disk (or on consecutive blocks if more space is needed), so that the information about a graph can be retrieved by reading one or several consecutive blocks from disk. Often, when the graph is not large, a disk-page (e.g., of size 4k) can hold more than one graph.

Encoded edges recording the adjacency information are linked to the graph-ids that are further associated with the edges in the edge table.
The storage of an ADI structure is flexible. If the graph database is small, then the whole index can be held into main memory. On the other hand, if the graph database is large and thus the ADI structure cannot fit into main memory, some levels can be stored on disk. The level of adjacency information is the most detailed and can be put on disk. If the main memory is too small to hold the graph-id linked lists, they can also be accommodated on disk. In the extreme case, even the edge table can be held on disk and a B+-tree or hash index can be built on the edge table. Theorem 1 (Space complexity). For graph database GDB = { G 1 ,...,G n } , the space complexity is Proof. The space complexity is determined by the following facts. (1) The number of tuples in the edge table is equal to the number of distinct edges in the graph database, which is bounded by n i =1 | E ( G i ) | ; (2) The number of entries in the graph-id linked lists in the worst case is the number of edges in the graph database, i.e., n i =1 | E ( G i ) | again; and (3) The adjacency information part records every edge exactly once.
Please note that, in many application, it is reasonable to assume that the edge table can be held into main memory. For example, suppose we have 1 , 000 distinct vertex labels and 1 , 000 distinct edge labels. There can be up to 1000 999  X  2  X  1000 = 4 . 995  X  10 8 different edges, i.e., all possible combinations of vertex and edge labels. Suppose up to 1% edges are frequent, there are only less than 5 million different edges, and thus the edge table can be easily held into main memory.

In real applications, the graphs are often sparse, that is, not all possible combinations of vertex and edge labels ap-pear in the graphs as an edge. Moreover, users are often interested in only those frequent edges. That shrinks the edge table substantially.
Now, let us examine how the ADI structure can facilitate the major data access operations in graph pattern mining that are identified in Section 3.3.
 OP1: Edge support checking Once an ADI structure is OP2: Edge-host graph checking Weonlyneedtosearch OP3: Adjacent edge checking Again, we start from an Input: a graph database GDB and min sup Output: the ADI structure Method:
The algorithms for the above operations are simple. Lim-ited by space, we omit the details here. As can be seen, once the ADI structure is constructed, there is no need to scan the database for any of the above operations. That is, the ADI structure can support the random accesses and the mining efficiently.
Given a graph database, the corresponding ADI structure is easy to construct by scanning the database only twice.
Inthefirstscan,thefrequentedgesareidentified.Accord-ing to the apriori property of frequent graph patterns, only those frequent edges can appear in frequent graph patterns and thus should be indexed in the ADI structure. After the first scan, the edge table of frequent edges is initialized.
In the second scan, graphs in the database are read and processed one by one. For each graph, the vertices are en-coded according to the DFS-tree in the minimum DFS code, as described in [11] and Section 3. Only the vertices involved in some frequent edges should be encoded. Then, for each frequent edge, the graph-id is inserted into the correspond-ing linked list, and the adjacency information is stored. The sketch of the algorithm is shown in Figure 4.
 There are two major costs in the ADI construction: writing the adjacency information and updating the linked lists of graph-ids. Since all edges in a graph will reside on a disk page or several consecutive disk pages, the writing of adja-cency information is sequential. Thus, the cost of writing adjacency information is comparable to that of making a Figure 5: The adjacency-list and adjacency-matrix representations of graphs. copy of the original database plus some bookkeeping.
Updating the linked lists of graph-ids requires random accesses to the edge table and the linked lists. In many cases, the edge table can be held into main memory, but not the linked list. Therefore, it is important to cache the linked lists of graph-ids in a buffer. The linked lists can be cached according to the frequency of the corresponding edges.
Constructing ADI for large, disk-based graph database may not be cheap. However, the ADI structure can be built once and used by the mining many times. That is, we can build an ADI structure using a very low support threshold, or even set min sup =1. 2 Theindexisstoredondisk. Then, the mining in the future can use the index directly, as long as the support threshold is no less than the one that is used in the ADI structure construction.
Many depth-first search, pattern-growth algorithms uti-lizeproperprojecteddatabases. Duringthedepth-firstsearch in graph pattern mining, the graphs containing the cur-rent graph pattern P should be collected and form the P -projected database . Then, the further search of larger graph patterns having P as the prefix of their minimum DFS codes can be achieved by searching only the P -projected database.
Interestingly, the projected databases can be constructed using ADI structures. A projected database can be stored in the form of an ADI structure. In fact, only the edge table and the list of graph-ids should be constructed for a new projected database and the adjacency information residing on disk can be shared by all projected databases. That can save a lot of time and space when mining large graph databases that contain many graph patterns, where many projected databases may have to be constructed.
In most of the previous methods for graph pattern mining, the adjacency-list or adjacency-matrix representations are used to represent graphs. Each graph is represented by an adjacency-matrix or a set of adjacency-lists. An example is shown in Figure 5.
If min sup = 1, then the ADI structure can be constructed by scanning the graph database only once. We do not need to find frequent edges, since every edge appearing in the graph database is frequent.

In Figure 5(a), the adjacency-lists have 8 nodes and 8 pointers. It stores the same information as Block 1 in Fig-ure 3, where the block has 4 nodes and 12 pointers.
The space requirements of adjacency-lists and ADI struc-ture are comparable. From the figure, we can see that each edge in a graph has to be stored twice: one instance for each vertex. (If we want to remove this redundancy, the tradeoff is the substantial increase of cost in finding adja-cency information). In general, for a graph of n edges, the adjacency-list representation needs 2 n nodes and 2 n point-ers. An ADI structure stores each edge once, and use the linkage among the edges from the same vertex to record the adjacency information. In general, for a graph of n edges, it needs n nodes and 3 n pointers.

Then, what is the advantage of ADI structure against adjacency-list representation? The key advantage is that the ADI structure extracts the information about containments of edges in graphs in the first two levels (i.e., the edge table and the linked list of graph-ids). Therefore, in many opera-tions, such as the edge support checking and edge-host graph checking, there is no need to visit the adjacency information at all. To the contrast, if the adjacency-list representation is used, every operation has to check the linked lists. When the database is large so that either the adjacency-lists of all graphs or the adjacency information in the ADI structure cannot be accommodated into main memory, using the first two levels of the ADI structure can save many calls to the adjacency information, while the adjacency-lists of various graphs have to be transferred between the main memory and the disk many times.

Usually, the adjacency-matrix is sparse. The adjacency-matrix representation is inefficient in space and thus is not used.
With the help from the ADI structure, how can we im-prove the scalability and efficiency of frequent graph pattern mining? Here, we present a pattern-growth algorithm ADI-Mine , which is an improvement of algorithm gSpan .The algorithm is shown in Figure 6.

If the ADI structure is unavailable, then the algorithm scans the graph database and constructs the index. Other-wise, it just uses the ADI structure on the disk.
The frequent edges can be obtained from the edge table in the ADI structure. Each frequent edge is one of the smallest frequent graph patterns and thus should be output. Then, the frequent edges should be used as the  X  X eeds X  to grow larger frequent graph patterns, and the frequent adjacent edges of e should be used in the pattern-growth. An edge e is a frequent adjacent edge of e if e is an adjacent edge of e in at least min sup graphs. The set of frequent adjacent edges can be retrieved efficiently from the ADI structure since the identities of the graphs containing e are indexed as a linked-list, and the adjacent edges are also indexed in the adjacency information part in the ADI structure.
The pattern growth is implemented as calls to procedure subgraph-mine . Procedure subgraph-mine tries every fre-quent adjacent edge e (i.e., edges in set F e )andchecks whether e can be added into the current frequent graph pat-tern G to form a larger pattern G .WeusetheDFScodeto test the redundancy. Only the patterns G whose DFS code is minimum is output and further grown. All other patterns G are either found before or will be found later at other Input: a graph database GDB and min sup Output: the complete set of frequent graph patterns Method: Procedure subgraph-mine Parameters: a frequent graph pattern G ,and Method: branches. The correctness of this step is guaranteed by the property of DFS code [11].

Once a larger pattern G is found, the set of adjacent edges of the current pattern should be updated, since the adjacent edges of the newly inserted edge should also be considered in the future growth from G . This update operation can be implemented efficiently, since the identities of graphs that contain an edge e are linked together in the ADI structure, and the adjacency information is also indexed and linked according to the graph-ids.
 At high level, the structure as well as the search strategies of ADI-Mine and gSpan are similar. The critical difference is on the storage structure for graphs X  ADI-Mine uses ADI structure and gSpan uses adjacency-list representation.
In the recursive mining, the critical operation is find-ing the graphs that contain the current graph pattern (i.e., the test of subgraph isomorphism) and finding the adjacent edges to grow larger graph patterns. The current graph pattern is recorded using the labels. Thus, the edges are searched using the labels of the vertices and that of the edges.

In gSpan , the test of subgraph isomorphism is achieved by scanning the current (projected) database. Since the graphs are stored in adjacency-list representation, and one label may appear more than once in a graph, the search can be costly. For example, in graph G 2 in Figure 3, in order to find an edge ( C, d, A ), the adjacency-list for vertices 4 and 6 may have to be searched. If the graph is large and the labels appear multiple times in a graph, there may be many adjacency-lists for vertices of the same label, and the adjacency-lists are long.

Moreover, for large graph database that cannot be held into main memory, the adjacency-list representation of a graph has to be loaded into main memory before the graph can be searched.
 In ADI-Mine , the graphs are stored in the ADI structure. The edges are indexed by their labels. Then, the graphs that contain the edges can be retrieved immediately. Moreover, all edges with the same labels are linked together by the links between the graph-id and the instances. That helps the test of subgraph isomorphism substantially.

Furthermore, using the index of edges by their labels, only the graphs that contain the specific edge will be loaded into main memory for further subgraph isomorphism test. Irrel-evant graphs can be filtered out immediately by the index. When the database is too large to fit into main memory, it saves a substantial part of transfers of graphs between disk and main memory.
In this section, we report a systematic performance study on the ADI structure and a comparison of gSpan and ADI-Mine on mining both small, memory-based databases and large, disk-based databases. We obtain the executable of gSpan from the authors. The ADI structure and algorithm ADI-Mine are implemented using C/C++.
All the experiments are conducted on an IBM NetFinity 5100 machine with an Intel PIII 733MHz CPU, 512M RAM and 18G hard disk. The speed of the hard disk is 10 , 000 RPM. The operating system is Redhat Linux 9.0.

We implement a synthetic data generator following the procedure described in [6]. The data generator takes five parameters as follows.
 D : the total number of graphs in the data set T : the average number of edges in graphs
I : the average number of edges in potentially fre-L : the number of potentially frequent kernels N : the number of possible labels Please refer to [6] for the details of the data generator. For example, a data set D 10 kN 4 I 10 T 20 L 200 means that the data set contains 10k graphs; there are 4 possible labels; the average number of edges in the frequent kernel graphs is 10; the average number of edges in the graphs is 20; and the number of potentially frequent kernels is 200. Hereafter in this section, when we say  X  X arameters X , it means the parameters for the data generator to create the data sets. In [11], L is fixed to 200. In our experiments, we also set L = 200 as the default value, but will test the scalability of our algorithm on L as well.
 Please note that, in all experiments, the runtime of ADI-Mine includes both the ADI construction time and the min-ing time.
In this set of experiments, both gSpan and ADI-Mine run in main memory.
We test the scalability of gSpan and ADI-Mine on the min-imum support threshold. Data set D 100 kN 30 I 5 T 20 L 200 is used. The minimum support threshold varies from 4% to 10%. The results are shown in Figure 7(a).

As can be seen, both gSpan and ADI-Mine are scalable, but ADI-Mine is about 10 times faster. We discussed the result with Mr. X. Yan, the author of gSpan .Heconfirms that counting frequent edges in gSpan is time consuming. On the other hand, the construction of ADI structure is relatively efficient. When the minimum support threshold is set to 1, i.e., all edges are indexed, the ADI structure uses approximately 57M main memory and costs 86 seconds in construction.
We test the scalability of gSpan and ADI-Mine on the size of databases. We fix the parameters N = 30, I =5, T =20and L = 200, and vary the number of graphs in database from 50 thousand to 100 thousand. The minimum support threshold is set to 1% of the number of graphs in the database. The results are shown in Figure 7(b). The construction time of ADI structure is also plotted in the figure.

Both the algorithms and the construction of ADI struc-ture are linearly scalable on the size of databases. ADI-Mine is faster. We observe that the size of ADI structure is also scalable. For example, it uses 28M when the database has 50 thousand graphs, and 57M when the database has 100 thou-sand graphs. This observation concurs with Theorem 1.
We test the scalability of the two algorithms on param-eter N  X  X he number of possible labels. We use data set D 100 kN 20-50 I 5 T 20 L 200, that is, the N value varies from 20 to 50. The minimum support threshold is fixed at 1%. The results are shown in Figure 7(c). Please note that the Y -axis is in logarithmic scale.

We can observe that the runtime of gSpan increases ex-ponentially as N increases. This result is consistent with the result reported in [11]. 3 When there are many possible labels in the database, the search without index becomes dramatically more costly. Interestingly, both ADI-Mine and the construction of ADI structure are linearly scalable on N . As discussed before, the edge table in ADI structure only in-dexes the unique edges in a graph database. Searching using the indexed edge table is efficient. The time complexity of searching an edge by labels is O (log n ), where n is the num-ber of distinct edges in the database. This is not affected by the increase of the possible labels. As expected, the size of the ADI structure is stable, about 57M in this experiment.
We use data set D 100 kN 30 I 5 T 10-30 L 200 to test the scal-ability of the two algorithms on parameter T  X  X he average number of edges in a graph. The minimum support thresh-old is set to 1%. The results are shown in Figure 7(d).
As the number of edges increases, the graph becomes more complex. The cost of storing and searching the graph also increases accordingly. As shown in the figure, both algo-rithms and the construction of ADI are linearly scalable.
We also test the effects of other parameters. The experi-mental results show that both gSpan and ADI-Mine are not
Please refer to Figures 5(b) and 5(c) in the UIUC technical report version of [11]. sensitive to I  X  X he average number of edges in potentially frequent graph patterns X  X nd L  X  X he number of potentially frequent kernels. The construction time and space cost of ADI structures are also stable. The reason is that the ef-fects of those two parameters on the distribution in the data sets are minor. Similar observations have been reported by previous studies on mining frequent itemsets and sequential patterns. Limited by space, we omit the details here.
Now, we report the experimental results on mining large, disk-based databases. In this set of experiments, we reserve a block of main memory of fixed size for ADI structure. When the size is too small for the ADI-structure , some levels of the ADI structure are accommodated on disk. On the other hand, we do not confine the memory usage for gSpan .
We test the scalability of both gSpan and ADI-Mine on the sizeofdatabases. Weusedataset D 100 k -1 mN 30 I 5 T 20 L 200. The number of graphs in the database is varied from 100 thousand to 1 million. The main memory block for ADI structure is limited to 250M. The results are shown in Fig-ure 8(a). The construction time of ADI structure is also plotted. Please note that the Y -axis is in logarithmic scale.
The construction runtime of ADI structure is approxi-mately linear on the database size. That is, the construc-tion of the ADI index is highly scalable. We also measure thesizeof ADI structure. The results are shown in Fig-ure 8(b). We can observe that the size of the ADI structure is linear to the database size. In this experiment, the ratio size of ADI structure in megabytes number of graphs in thousands is about 0 . 6. When the database size is 1 million, the size of ADI structure is 601M, which exceeds the main memory size of our machine. Even in such case, the construction runtime is still linear.
As explained before, the construction of ADI structure makes sequential scans of the database and conducts a se-quential write of the adjacency information. The overhead of construction of edge table and the linked lists of graph-ids is relatively small and thus has a minor effect on the construction time.

While gSpan can handle databases of only up to 300 thou-sand graphs in this experiment, ADI-Mine can handle databases of 1 million graphs. The curve of the runtime of ADI-Mine can be divided into three stages.

First, when the database has up to 300 thousand graphs, the ADI structure can be fully accommodated in main mem-ory. ADI-Mine is faster than gSpan .

Second, whenthedatabasehas300to600thousandgraphs, gSpan cannot finish. The ADI structure cannot be fully held in main memory. Some part of the adjacency information is put on disk. We see a significant jump in the runtime curve of ADI-Mine between the databases of 300 thousand graphs and 400 thousand graphs.

Last, when the database has 800 thousand or more graphs, even the linked lists of graph-ids cannot be fully put into main memory. Thus, another significant jump in the run-time curve can be observed.
It is interesting to examine the tradeoff between efficiency and size of available main memory. We use data set D 100 kN 30 I 5 T 20 L 200, set the minimum support threshold to 1%, vary the main memory limit from 10M to 150M for ADI structure, and measure the runtime of ADI-Mine .The results are shown in Figure 8(c). In this experiment, the size of ADI structure is 57M. The construction time is 86 seconds. The highest watermark of main memory usage for gSpan in mining this data set is 87M. gSpan uses 1161 sec-onds in the mining if it has sufficient main memory.
When the ADI structure can be completely loaded into main memory (57M or larger), ADI-Mine runs fast. Further increase of the available main memory cannot reduce the runtime.

When the ADI structure cannot be fully put into main memory, the runtime increases. The more main memory, the faster ADI-Mine runs.

When the available main memory is too small to even hold the linked lists of graph-ids, the runtime of ADI-Mine increases substantially. However, it still can finish the min-ing with 10M main memory limit in 2 hours.
In addition to runtime, the efficiency of mining large disk-based databases can also be measured by the number of disk block read operations.

Figure 9(a) shows the number of disk block reads versus the minimum support threshold. When the support thresh-old is high (e.g., 9% or up), the number of frequent edges is small. The ADI structure can be held into main memory and thus the I/O cost is very low. As the support threshold goes down, larger and larger part of the ADI structure is stored on disk, and the I/O cost increases. This curve is consistent with the trend in Figure 7(a).

Figure 9(b) shows the number of disk block reads versus the number of graphs in the database. As the database size goes up, the I/O cost increases exponentially. This explains the curve of ADI-Mine in Figure 8(a).

We also test the I/O cost on available main memory. The result is shown in Figure 9(c), which is consistent with the trend of runtime curve in Figure 8(c).
We also test the effects of the other parameters on the efficiency. We observe similar trends as in mining memory-based databases. Limited by space, we omit the details here.
The extensive performance study clearly shows the fol-lowing. First, both gSpan and ADI-Mine are scalable when database can be held into main memory. ADI-Mine is faster than gSpan . Second, ADI-Mine can mine very large graph databases by accommodating the ADI structure on disk. The performance of ADI-Mine on mining large disk-based databases is highly scalable. Third, the size of ADI struc-ture is linearly scalable with respect to the size of databases. Fourth, we can control the tradeoff between the mining effi-ciency and the main memory consumption. Last, ADI-Mine is more scalable than gSpan in mining complex graphs X  X he graphs that have many different kinds of labels.
The problem of finding frequent common structures has been studied since early 1990s. For example, [1, 7] study the the problem of finding common substructures from chemi-cal compounds. SUBDUE [4] proposes an approximate al-gorithm to identify some , instead of the complete set of, frequent substructures. However, these methods do not aim at scalable algorithms for mining large graph databases.
The problem of mining the complete set of frequent graph patterns is firstly explored by Inokuchi et al. [5]. An Apriori-like algorithm AGM is proposed. Kuramochi and Karypis [6] develop an efficient algorithm, FSG , for graph pattern min-ing. The major idea is to utilize an effective graph repre-sentation, and conduct the edge-growth mining instead of vertex-growth mining. Both AGM and FSG adopt breadth-first search.

Recently, Yan and Han propose the depth-first search ap-proach, gSpan [11] for graph mining. They also investigate the problem of mining frequent closed graphs [9], which is a non-redundant representation of frequent graph patterns. As a latest result, Yan et al. [10] uses frequent graph pat-terns to index graphs.

As a special case of graph mining, tree mining also re-ceives intensive research recently. Zaki [12] proposes the first algorithm for mining frequent tree patterns.
Although there are quite a few studies on the efficient min-ing of frequent graph patterns, none of them addresses the problem of effective index structure for mining large disk-based graph databases. When the database is too large to fit into main memory, the mining becomes I/O bounded, and the appropriate index structure becomes very critical for the scalability.
In this paper, we study the problem of scalable mining of large disk-based graph database. The ADI structure, an effective index structure, is developed. Taking gSpan as a concrete example, we propose ADI-Mine , an efficient algo-rithm adopting the ADI structure, to improve the scalability of the frequent graph mining substantially.

The ADI-Mine structure is a general index for graph min-ing. As future work, it is interesting to examine the effect of theindexstructureonimprovingothergraphpatternmining methods, such as mining frequent closed graphs and mining graphs with constraints. Furthermore, devising index struc-tures to support scalable data mining on large disk-based databases is an important and interesting research problem with extensive applications and industrial values. We are very grateful to Mr. Xifeng Yan and Dr. Jiawei Han for kindly providing us the executable of gSpan and answer-ing our questions promptly. We would like to thank the anonymous reviewers for their insightful comments, which help to improve the quality of the paper.
