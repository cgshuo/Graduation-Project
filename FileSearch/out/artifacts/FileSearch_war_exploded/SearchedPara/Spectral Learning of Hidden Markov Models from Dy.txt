 Tzu-Kuo Huang tzukuoh@cs.cmu.edu Machine Learning Department, Carnegie Mellon University Jeff Schneider schneide@cs.cmu.edu Robotics Institute, Carnegie Mellon University Hidden Markov Models (HMMs) ( Rabiner , 1989 ) are a useful class of tools for analyzing time series data whose dynamic behavior depends on some unobserved variables, referred to as hidden states, and have found many applications. Due to the hidden states, the widely-used Expectation-Maximization (EM) based estimation has long suffered from ambiguities caused by highly multi-modal estimation objectives. Recently there has been an emerging line of work that pro-poses spectral algorithms for learning HMMs with dis-crete ( Hsu et al. , 2009 ; Siddiqi et al. , 2010 ) and con-tinuous observations ( Siddiqi et al. , 2010 ; Song et al. , 2010 ). In contrast to EM, these algorithms give unique and, under mild conditions, provably consistent esti-mates of the full joint distribution of an observation sequence, as well as the predictive distribution. They have also been shown to outperform EM-based learn-ing methods in some challenging dynamic modelling tasks ( Song et al. , 2010 ).
 While good models and learning algorithms play a crucial role in time series analysis, a major challenge in quite a few scientific dynamic modeling tasks, as pointed out by Huang and Schneider ( 2011 ), turns out to be collecting reliable time series data. In some situations, the dynamic process of interest may evolve slowly over time, such as the progression of Alzheimer X  X  disease, and it may take months or even years to obtain enough time series data for analysis. In other situations, it may be very difficult to measure the dynamic process of interest repetitively, due to the destructive nature of the measurement technique. One such example is gene expression time series. Although obtaining reliable time series, or dynamic data, can be difficult, it is often easier to collect static, order-less snapshots of the dynamic process of interest. For example, doctors can collect many samples from a cur-rent pool of Alzheimer X  X  patients in possibly different stages of the disease, and scientists can easily obtain large amounts of static gene expression data from mul-tiple experiments. Huang and Schneider ( 2011 ) pro-pose an estimator for the vector autoregressive (VAR) model that uses both dynamic and static data , and de-rive a simple gradient-descent algorithm to minimize its non-convex estimation objective. Through simula-tions and experiments on video data, they demonstrate that static data does help to improve estimation, es-pecially when the amount of dynamic data is small. We propose to incorporate static data into spectral learning algorithms for HMMs, following a similar principle: minimizing a squared error function on the dynamic data augmented with a regularization term based on static data . Somewhat surprisingly, the pro-posed optimization problems for estimation turn out to be convex, thanks to the unique estimates from spec-tral algorithms. We conduct simulations and exper-iments on real Inertia-Measurement Unit recordings of human activities, and demonstrate that, as with VARs, static data also improves estimation of HMMs. Unlike most spectral algorithms which rely only on Singular Value Decomposition (SVD), our method uses both SVD and convex optimization. Similar ideas have been proposed recently. Among others, Balle et al. ( 2012 ) solve a convex program in place of SVD, while Balle and Mohri ( 2012 ) use convex optimization to obtain input matrices to spectral algorithms. We organize the paper as follows. Section 2 briefly re-views spectral learning algorithms, and Section 3 de-tails the proposed algorithms, followed by experiments and results in Section 4 and conclusions in Section 5 . We begin with discrete observations, and mainly fol-low the exposition by Siddiqi et al. ( 2010 ). Instead of learning the original model parameters, i.e., initial state probabilities, state transition probabilities, and state-conditioned observation probabilities, the spec-tral algorithm learns an observable representation of the HMM, which consists of the following parameters: where  X  denotes the pseudo inverse, N is the number of observation symbols, p is the stationary distribution of observations, and P 2 , 1 and P 3 ,x, 1 are joint observation probability matrices such that for 1  X  i, x, j  X  N , x t being the observation symbol at time t , and U  X  lar vectors of P 2 , 1 . As the name suggests, the observ-able representation parameters ( 1 ) to ( 3 ) only depend on observable quantities, leading naturally to the esti-b P b P 2 , 1 . These estimates allow us to perform inferences on a new sequence of observations y 1 , . . . , y t :  X  Predict whole sequence probability:  X  Internal state update: b b t +1 := b B y  X  Conditional probability of y t given y 1 , . . . , y t  X  1 Under some mild conditions, of which the most crit-ical being that both the state transition and state-conditioned observation probability matrices are of rank k , Siddiqi et al. ( 2010 ) showed that the whole sequence probability estimate ( 5 ) is consistent (with high probability) and gives a finite-sample bound on the estimation error.
 Based on the same idea, Song et al. ( 2010 ) developed a spectral algorithm for learning HMMs with continuous observations. Instead of operating on probability dis-tributions directly, their algorithm operates on Hilbert space embeddings of distributions of observable quan-tities (assuming stationarity of the HMM): where x t denotes the continuous observation vector at time t ,  X  ( ) maps the real observation space to a Repro-ducing Kernel Hilbert Space (RKHS),  X  denotes the tensor product, and C 3 , 1 | 2 := C x tional embedding operator ( Song et al. , 2009 ). Using these embeddings, they derived an observable repre-sentation of the embedded HMM, which consists of the following parameters: where U is the top-k left singular vectors of C 2 , 1 . They then showed that the embedding of the pre-of discrete observations, proposed estimates based on empirical averages b 1 , b C 2 , 1 , b C 3 , x , 1 , and b top-k left singular vectors of b C 2 , 1 . Using the kernel trick and techniques from Kernel Principle Compo-nent Analysis ( Sch  X olkopf et al. , 1998 ), they gave an estimation procedure that operates solely on finite-dimensional quantities. Moreover, to avoid the diffi-culty of partitioning the observation space required by estimation of B x , they proposed to estimate instead which is only a fixed multiplicative factor P ( x ) away from B x , and have x  X  established the consistency (with high probability) of their estimator for x sample bound on the estimation error.
 In addition to estimation, Song et al. ( 2010 ) also dis-cussed possible ways to carry out prediction. In par-ticular, they showed that in the case of Gaussian RBF kernel, b x density estimator after proper normalization, and one may choose, from training data or a pool of samples, the observation with the highest predictive density as the prediction. Suppose in addition to dynamic data, which can be time series of observations or triples of consecutive ob-servations, we also have a set of static data points , which are drawn independently from the stationary distribution of the underlying HMM. We propose to improve the estimation of the observable representa-tion of HMMs by solving regularized least square prob-lems, which minimize a squared error term on the dy-namic data and a regularization term based on the static data. As in existing work on spectral learning of HMMs, we assume that the dynamic data are ob-served after the HMM has fully mixed. 3.1. Discrete Observations Our method has two main steps. We first estimate P 2 , 1 , and then b 1 , b  X  , and B x  X  X . Let N denote the number of unique observation symbols. To make use of static data in estimating P 2 , 1 , we note that the marginal of P 2 , 1 is the stationary distribution of the discrete HMM. Moreover, from spectral learning meth-ods we have the assumption of P 2 , 1 being low-rank. We thus propose the following estimator e P 2 , 1 defined as where e p is the empirical observation distribution of both the dynamic and the static data , W is an indi-cator matrix such that W ij = 1  X  X  X  ( b P 2 , 1 ) ij &gt; 0,  X  denotes the Hadamard product, kk  X  denotes the matrix nuclear norm, a standard convex relaxation of matrix rank, 1 is a vector of ones, and u,  X  &gt; 0 are regularization parameters. The objective in ( 14 ) min-imizes the squared error from the dynamic-only esti-mate b P 2 , 1 while penalizing the rank and the deviation from the marginal e p . It is easy to see that ( 14 ) is a convex but non-smooth problem due to the matrix nuclear norm. Projected sub-gradient descent meth-ods are a common way to solve such problems, but are known to suffer from slow convergence ( Bertsekas , 1999 ). We solve ( 14 ) by a variant of the smoothing proximal gradient (SPG) method proposed by Chen et al. ( 2012 ), which achieves a provably faster conver-gence rate than projected sub-gradient methods but has a similar per-iteration time complexity. In Section 3.2 we use SPG to solve the continuous version of the estimation problem, which has a more general form, and hence describe more details there.
 To set  X  in the right scale, we use the following fact about matrix norms: where r is the rank of P 2 , 1 , and kk  X  and kk 1 de-note matrix  X  -norm and 1-norm, respectively. As-suming stationarity, we have k P 2 , 1 k  X  = k P 2 , 1 k 1 max i p i , where p is the stationary distribution of ob-servations. Therefore, P 2 , 1  X  X  average singular value is O ((max i p i ) /N ). As shown by Cai et al. ( 2010 ),  X  has an effect of soft-thresholding singular values of P 2 , 1 we let  X  =  X  max i e p i /N and tune  X  instead. We then compute the SVD of e P 2 , 1 , denoting its top-k left singular vectors as an N -by-k matrix e U , and obtain estimates of b 1 and b  X  in the same ways as ( 1 ) and B x , we first note that the original estimator based on ( 3 ) is the solution to the following problem: showing that b B x is a low-dimensional representation of b P 3 ,x, 1 . As in ( 14 ), we aim to regularize the least-square problem ( 16 ) with static data. Instead of construct-ing a regularization term directly from static data, we use our new estimator e P 2 , 1 based on the fact that ( 1 the marginals of { P 3 ,x, 1 } are equal to P 2 , 1 . We thus propose the following estimator { e B x } defined as arg min where W x is an indicator matrix such that ( W x ) ij &gt; not only add regularization terms but also constrain the fitted matrices { e U B x e V  X  } to lie on a simplex aiming to reduce negative values in the predictive dis-tribution ( 6 ) during inference.
 Eq. ( 17 ) is a quadratic program of k 2 N variables under one linear equality constraint and N 3 linear inequality constraints. When N is on the order of a few hundreds and k is a few tens, a reformula-tion that takes advantage of the block-diagonal struc-ture in the Hessian of ( 17 ) can be solved quite ef-ficiently with state-of-the art optimization software, such as MOSEK ( www.mosek.com ). For larger prob-lems, one possible solution is the Alternating Direc-tion Method of Multipliers ( Boyd et al. , 2011 ), which handles constraints by minimizing the original objec-tive augmented with a iteratively-refined constraint vi-olation term. Our experiments in Section 4.1 have N = 100, so we solve ( 17 ) with MOSEK. 3.2. Continuous Observations Our method for continuous observations builds on the Hilbert space embedding approach by Song et al. ( 2010 ), and consists of two main steps: estimating the feature covariance C 2 , 1 and then the observable repre-sentation  X  1 ,  X   X  , and B x . Let the feature mappings of the dynamic data be organized into three matrices  X  ,  X  2 , and  X  3 such that their i -th columns  X  i 1 ,  X  i and  X  i 3 are consecutive and going forward in time. By the definition of the feature covariance ( 8 ), we have C set of feature points grouped column-wise as a feature matrix  X , and know exactly which pairs of points are consecutive in time via a (normalized) temporal adja-cency matrix T 2 , 1 , we may then compute the quantity an estimator. To incorporate static data into our esti-mation procedure, we denote its feature matrix by Z and consider another special case: where Z 1 := [ X  1 Z ] and Z 2 := [ X  2 Z ]. It then suffices to estimate P subject to 1  X  P 1 = 1 and P ij  X  0. Similar to Section 3.1 , our estimation objective con-sists of three terms: the squared error between e C 2 , 1 e C 2 , 1  X  X  marginal from the mean of the stationary dis-tribution. The last term is based on the fact that, un-der the assumption of stationarity, C 2 , 1 f = E [  X  ( X )] holds for some constant function f in G such that f ( x ) = f  X   X  ( x ) = 1  X  x . Formally, our estimator e is the solution to the following convex program: min s.t. 1  X  P 1 = 1 , P ij  X  0 , where we introduce S and m S to denote the feature matrix and the size of the entire set of static data and let Z denote a sub-sample of it, mainly to limit the number of variables when the static dataset is very large. As shown in Appendix A , using the kernel trick and properties of the matrix trace and nuclear norm, we re-write the objective function in ( 19 ) as follows (dropping constants): 1 2 u 2 where Tr( ) is the matrix trace, M i := Z  X  i Z i ,  X  i := that M i = L i L  X  i . To set  X  in a proper scale, we use an inequality similar to ( 15 ) to upper-bound the average singular value of L  X  2 P L 1 , and then replace the unknown P by the uniform distribution to have  X  := (  X /m 3 )( k L  X  2 11  X  L 1 k  X  k L  X  2 11  X  L 1 k 1 is the size of P and  X  &gt; 0 takes values in some reason-able range.
 As mentioned in Section 3.1 , we solve ( 19 ) with a vari-ant of the smoothing proximal gradient (SPG) method outlined in Algorithm 1 , which minimizes f  X  ( P ), a smooth approximation of ( 20 ) that approximates the non-smooth regularization  X  k L  X  2 P L 1 k  X  by g  X  ( P ) := max where  X  0 is a smoothing parameter, kk 2 and kk F denote the matrix spectral and Frobenius norms, re-spectively. Nesterov ( 2005 ) shows that ( 21 ) is contin-uously differentiable in P and  X  g  X  ( P ) =  X  L 2 Y  X  L  X  where Y  X  is the optimal solution to ( 21 ) obtained by projecting (  X  / ) L  X  2 P L 1 to the unit spectral-norm ball, i.e., truncating its singular values at 1. The update ( 22 ) for P ( t +1) requires projection onto a simplex, for which several efficient algorithms exist, such as the sorting-based method proposed by Duchi et al. ( 2008 ). Algorithm 1 Smoothing Proximal Gradient for ( 19 ) Initialize Y (0) = P (0) to some feasible point.
Set t := 0 ,  X  (0) := 1 ,  X  := 10, and  X  (0) := 1. repeat until convergence or t = T max , an iteration limit. The convergence theory of Chen et al. ( 2012 ) sug-gests setting 2 =  X /m , m being the column dimen-sion of Z 2 , so that the objective values ( 20 ) converge in O (1 / X  2 ) iterations to at most  X  plus the minimum. We then compute the top k left singular vectors of e C 2 , 1 in a similar way to Kernel Principle Component Analysis ( Sch  X olkopf et al. , 1998 ), starting with the fact that any left singular vector of e C 2 , 1 = Z 2 e P Z  X  1 be expressed as Z 2  X  for some  X   X  R m , and any left singular vector of e C 2 , 1 is an Eigenvector of e C 2 , 1 and vice versa. Thus we have  X  X  X  M 2 e P M 1 e P  X  M 2  X  =  X M 2  X  , (23) which is a generalized Eigensystem. Let  X  denote the diagonal matrix formed by the top k generalized Eigen-values of ( 23 ), and A denote the column concatenation of the corresponding generalized Eigenvectors. It is then clear that D := ( A  X  M 2 A )  X  1 / 2 is diagonal, and we obtain a concise form of e C 2 , 1  X  X  top k left singular vectors e U = Z 2 AD . We also have the following useful identity: Next we describe our estimators for the observable rep-resentation. First we have e  X  1 := e U  X  S 1 /m S = DA  X   X  2 , (25) e by using the identity ( e U  X  e C 2 , 1 )  X  = Z 1 e P  X  M established from properties of pseudo inverse, ( 24 ), and the definition of D . To derive our estimator for  X  B x defined in ( 13 ), we start from the conditional co-variance operator defined by Song et al. ( 2009 ) C C
C Using a similar idea to ( 18 ), we encode the empirical distribution of triples of consecutive observations by a third-order tensor Q and have the following estimator e C where Z 3 := [ X  3 Z ],  X  &gt; 0 is a regularization parame-ter, and superscripts denote column indices. We then define our estimator for  X  B x as where B l  X  R k  X  k is a linear transformation of Q l  X  Note that in the usual setting of learning from dy-namic data, the third-order tensor Q is diagonal and B l becomes a rank-one matrix, so ( 28 ) reduces to the estimator proposed by Song et al. ( 2010 ).
 The definitions above naturally lead to an estimation procedure that first estimates Q and then applies ( 29 ) to estimate B l . However, such a procedure involves m 3 variables when the quantities of interest consist of only km 2 variables. We thus propose to estimate B l  X  X  directly. Viewing ( 29 ) as the solution to
U := ( e U  X  Z 3 )  X  = ( DA  X  Z  X  2 Z 3 )  X  = ( DA  X  M 23 we propose to estimate B l  X  X  by the following: u 2 in which e
C e e Again, our estimation objective consists of a squared error term on the observed tri-variance and two reg-ularization terms on the deviation of the marginals e C As shown in Appendix B , we use kernel tricks to re-write the objective function ( 30 ) in terms of finite-dimensional quantities. Moreover, by re-defining the notation B to be a k 2 -by-m matrix whose l -th column denotes the column concatenation of the k -by-k ma-trix B l , we obtain the following succinct form of ( 30 ) (dropping constants): with an analytical solution C  X  1 JM  X  1 2 , where C and J are defined 3 in Appendix B . We compare our proposed methods with the original spectral algorithms (Section 2 ) that only use dynamic data. In the case of discrete observations we conduct a simulation study, and we apply the algorithms for con-tinuous observations to an activity monitoring dataset. 4.1. Simulation We create a discrete HMM with 20 states and 100 observation symbols. The state transition probabil-ity matrix is of rank nearly 7. The heatmaps of the state transition probability and the state-conditioned observation probability matrices are in Figures 1(a) and 1(b) . From this HMM we generate 50 datasets, each containing a training sequence of length 1000 initialized from the stationary distribution as the dy-namic data, a set of 10000 observations independently drawn from the stationary distribution as the static data, and a testing sequence of length 1000, also ini-tialized from the stationary distribution. We set the dimension k = 7, and for the proposed estimate set u = 100 and  X  = 15. We then perform filtering and prediction along the testing sequence. To give bounds on the prediction performance, we also give prediction results by the true observable representation and the stationary distribution.
 Figure 2 shows the median testing log-likelihood over 50 experiments at each testing time point. The pro-posed estimator outperforms the dynamic-only esti-mator at most time points. For each pair among the four predictions, we performed paired t-tests of their testing likelihoods at all time points, and counted the number of time points at which one prediction outper-forms the other statistically significantly. The results are in Table 1 . The proposed estimator predicts bet-ter than the dynamic-only estimator at all time points and the stationary distribution at many time points, but these two other methods never predict significantly better than the proposed method. It is surprising that the dynamic-only estimator performs even worse than the stationary distribution. As pointed out by Siddiqi et al. ( 2010 ), the filtering and prediction steps ( 6 ) do not guarantee non-negativity of the probability esti-mates, especially when, as in the current experiment, there is few dynamic data. Indeed, we observe quite a few negative values in the dynamic-only estimates and replace them with 10  X  12 . This is an indication of un-reliable estimates leading to poor prediction. On the contrary, the proposed estimates almost always take non-negative values.
 4.2. IMU Measurements of Human Activities The PAMAP2 physical activity monitoring dataset ( Reiss &amp; Stricker , 2012 ) contains recordings of 18 dif-ferent physical activities performed by 9 subjects wear-ing 3 inertial measurement units (IMUs) and a heart-rate monitor. Each subject follows a protocol to per-form a sequence of activities with breaks in between. For our experiment we use data collected from subject 101 while walking and running. We focus our experi-ment on recordings from the three IMUs, and for each IMU only use the 3D-acceleration data (ms  X  2 ) with scale  X  16g, as recommended by the authors, and the 3D-gyroscope data (rad/s), resulting in an observation space of 6  X  3 = 18 dimensions. Subject 101 performs walking and running for approximately 3.5 minutes each, and we discard the first and the last 10 seconds of data to remove transitioning between activities. To make the experiment more interesting, we break the IMU recordings into short segments of 10 seconds each and interleave the walking segments with the running ones to generate a sequence of alternating activities. The IMUs operate at a sampling frequency of 100Hz, so each segment has 1000 data points and the entire sequence has 39265 data points. We normalize each of the 18 dimensions to be zero-mean and standard devi-ation 1. Figure 3 shows one of the dimensions from the first 2000 data points, revealing significant differences between walking and running.
 We take the last 4256 data points as the testing se-quence, and generate 10 training datasets as follows. We randomly sample n triples of consecutive observa-tions from the first 35000 data points as the dynamic data, and another non-overlapping set of m + m S sin-gle observations as the static data, in which m points are used to form Z and the rest m S points consti-tute S in the proposed algorithm. The values of n, m, and m S = 4000. We use the Gaussian RBF kernel of the median squared pairwise distances of the dy-namic data. The dimension k , i.e., the number of top left singular vectors, is set to 20 for n = 25 and 50 for the rest. The proposed algorithm has three reg-ularization parameters: u P and  X  in ( 19 ) and u B in ( 34 ). We determine these parameters by mini-mizing 5-fold 4 cross validation error on the dynamic data over a cube of values (log 2 u P , log 2  X , log 2 u B After learning the model parameters, we perform fil-tering and prediction along the testing sequence. As mentioned in Section 2 , the Hilbert space embedding of the predictive distribution takes the form of a non-parametric density estimator thanks to the Gaussian RBF kernel, and we predict the next observation by selecting from S , the m S static data points, the one with the highest predictive density. For each predicted observation we compute the squared error against the true observation, and for each predicted sequence we take the median and the mean of the squared predic-tion errors as sequence-wise performance indicators. Figure 4(a) gives the boxplot of the 10 median pre-diction errors, showing that the proposed method of incorporating static data improves on the prediction performance more significantly when the dynamic data size n is small. Figure 4(b) gives the boxplot of the 10 means, demonstrating a similar trend of improvement except when n = 50. Looking more into that result, we find that it is the running part of the testing se-quence the proposed method fails to predict better, possibly due to the more extreme values and changes in its IMU readings, as shown in Figure 3 . We propose spectral learning algorithms for HMMs that incorporate static data as regularization. Exper-iments on synthetic and real human activities data demonstrate a clear advantage of using static data when dynamic data is limited. Theoretical guarantees for our methods are still unclear and worth further in-vestigation. Also interesting is applying the proposed methods to dynamic modeling tasks where dynamic data is much more difficult to obtain than static data. Using properties of the matrix trace and the kernel trick, we immediately have 1 2 u 2  X  Let  X  i ( ) denotes the i -th Eigenvalue of a matrix. We then rewrite the nuclear norm term: We begin by defining some notations: H := e U  X  M 3 e U , R := e V  X  M 1 e V , u := e U  X  1 , v := F 1 :=  X   X  1 Z 1 e V , F 2 := Let vec( X ) be the vector resulting from column con-catenation of a matrix X , diag( x ) be the diagonal ma-trix with the vector x being its main diagonal. Super-scripts denote column indices. Using properties of the matrix trace and the kernel trick, we re-write the three terms in ( 34 ) as follows. For the first term we have  X 
X 2 =Tr and then for the second term k e
C Tr B 1 v B m v  X  H B 1 v B m v M 2  X  2Tr B 1 v B m v  X  e U  X  M 32 e P M 12 = Tr and finally for the third term k e 2Tr B  X  1 u B  X  m u M 2 e P M 1 e V = Tr To further simplify these expressions, we re-define the notation B to be a k 2 -by-m matrix whose l -th column B l denotes column concatenation of the k -by-k matrix B l in the above expressions. With the new notation and the identity: where  X  denotes the Kronecker product, we obtain the succinct form ( 34 ) in which C := R  X  H + u (( vv  X  )  X  H + R  X  ( uu  X  )) , J := ( F 1  X  F 3 )  X  vec(diag( F 1 2 )) vec(diag( F m 2 )) + u v  X  ( e U  X  M 32 e P ) M 12 + ( e V  X  M 1 e P  X  )  X  u M Balle, Borja and Mohri, Mehryar. Spectral learning of general weighted automata via constrained ma-trix completion. In Advances in Neural Information Processing Systems 25 , pp. 2168 X 2176, 2012.
 Balle, Borja, Quattoni, Ariadna, and Carreras, Xavier.
Local loss optimization in operator models: A new insight into spectral learning. In Proceedings of the 29th International Conference on Machine Learning (ICML-12) , pp. 1879 X 1886, 2012.
 Bertsekas, Dimitri P. Nonlinear Programming . Athena
Scientific, Belmont, MA 02178-9998, second edition, 1999.
 Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eck-stein, J. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends R in Machine Learning , 3(1):1 X 122, 2011.
 Cai, J.F., Cand`es, E.J., and Shen, Z. A singular value thresholding algorithm for matrix completion.
SIAM Journal on Optimization , 20(4):1956 X 1982, 2010.
 Chen, X., Lin, Q., Kim, S., Carbonell, J.G., and Xing,
E.P. Smoothing proximal gradient method for gen-eral structured sparse regression. The Annals of Ap-plied Statistics , 6(2):719 X 752, 2012.
 Duchi, John, Shalev-Shwartz, Shai, Singer, Yoram, and Chandra, Tushar. Efficient projections onto the  X  1 -ball for learning in high dimensions. In Proceed-ings of the 25th International Conference on Ma-chine Learning , pp. 272 X 279, 2008.
 Hsu, Daniel, Kakade, Sham M., and Zhang, Tong. A spectral algorithm for learning hidden Markov mod-els. In Proceedings of the Twenty-Second Annual Conference on Learning Theory , 2009.
 Huang, Tzu-Kuo and Schneider, Jeff. Learning auto-regressive models from sequence and non-sequence data. In Advances in Neural Information Processing Systems 24 , pp. 1548 X 1556. 2011.
 Nesterov, Y. Smooth minimization of non-smooth functions. Mathematical Programming , 103(1):127 X  152, 2005.
 Rabiner, Lawrence R. A tutorial on hidden Markov models and selected applications in speech recogni-tion. Proceedings of the IEEE , 77(2):257 X 285, 1989. Reiss, A. and Stricker, D. Introducing a new bench-marked dataset for activity monitoring. In Wearable
Computers (ISWC), 2012 16th International Sym-posium on , pp. 108 X 109. IEEE, 2012.
 Sch  X olkopf, B., Smola, A., and M  X uller, K.R. Nonlinear component analysis as a kernel eigenvalue problem. Neural computation , 10(5):1299 X 1319, 1998.
 Siddiqi, Sajid M., Boots, Byron, and Gordon, Geof-frey J. Reduced-rank hidden Markov models. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics , 2010. Song, Le, Huang, Jonathan, Smola, Alex, and Fuku-mizu, Kenji. Hilbert space embeddings of condi-tional distributions with applications to dynamical systems. In Proceedings of the 26th International Conference on Machine Learning , 2009.
 Song, Le, Boots, Byron, Siddiqi, Sajid, Gordon, Geof-frey, and Smola, Alex. Hilbert space embeddings of hidden Markov models. In Proceedings of the 27th International Conference on Machine Learn-
