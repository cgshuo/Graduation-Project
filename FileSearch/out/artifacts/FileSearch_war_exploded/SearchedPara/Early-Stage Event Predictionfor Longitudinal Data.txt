 Developing effective prediction models to estimate the outcome of a particular event of interest is a critical challenge in various application domains such as healthcare, reliability, engineering, etc. [ 12 ]. In longitudinal studies, event pre-diction is an important area of research where the goal is to predict the event occurrence during a specific time period of interest [ 9 ]. Obtaining training data for such a time-to-event problem is a daunting task. As opposed to the standard supervised learning problems where a domain expert can provide labels in a rea-sonable amount of time, training data for longitudinal studies must be obtained only by waiting for the occurrence of sufficient number of events. Therefore, the ability to leverage only a limited amount of available information at early stages of longitudinal studies to forecast the event occurrence at future time points is an important and challenging research task.
 Let us consider an illustrative example shown in Fig. 1 . In this example, a longitudinal study is conducted on 5 subjects and the information for event occurrence until time t c is recorded, where only subjects B and E have experi-enced the event. The goal of our paper is to predict the event occurrence by the time t f where t f is much greater than t c . It can be seen that, except subjects B and E, all the remaining subjects are considered to be censored at t red  X  X  X ) and the event will occur for subject A within the time period t nario is applicable for many real-world applications where it is critical to obtain early stage time-to-event predictions. For example, in the healthcare domain, let us say that there is a new treatment option (or drug) which is available and one would like to study the effect of such a treatment on a particular group of patients in order to understand the efficacy of the treatment. This patient group is monitored over a period of time and an event here corresponds to the patient being hospitalized (or occurrence of death) because the treatment has failed. The effectiveness of this treatment must be estimated as early as possible when there are only a few hospitalized patients.
 This practical problem clearly emphasizes the need to build algorithms that can effectively predict events using the training data that contains only the event information at an early stage of a longitudinal study. It should be noted that the previous research in the field of statistics mainly focuses on the prediction of survivability up to a certain specific time point. Predicting events at future timepoints using the available information at the initial phases of the study remains to be a relatively unexplored area of research. Thus, in this paper, we develop prediction models using the data collected at earlier time points in longitudinal studies. More specifically, the contributions of this paper are as follows:  X  X roposean E arly S tage P rediction (ESP) framework which estimates the probability of event occurrence for a future timepoint using different extrap-olation techniques.  X  Develop a probabilistic algorithms based on Naive Bayes and Tree-Augmented
Naive Bayes (TAN), called ESP-NB and ESP-TAN, respectively, for early-stage event prediction by modifying the posterior probability of event occur-rence.  X  Evaluate the proposed algorithms using several synthetic and real-world benchmark datasets.
 This paper is organized as follows. In Sect. 2 , we present a summary of existing works on using survival analysis and machine learning methods for longitudinal data. In Sect. 3 , we explain the problem formulation and describe two proba-bilistic classifiers, namely, Naive Bayes and Tree-Augmented Naive Bayes. In Sect. 4 , we introduce the proposed extrapolation methods and then explain our novel Early Stage Prediction (ESP) framework based on Naive Bayes and TAN algorithms. In Sect. 5 , the results of the proposed methods along with those of the competing algorithms on various synthetic and real-world datasets are pre-sented. In the last section, we conclude our paper with a summary of the main results of the proposed work. Survival analysis is a subfield of statistics where a wide range of techniques have been proposed to model time-to-event data (e.g., failure, death, admission to hospital, emergence of disease, etc.) [ 13 ]. For such a time-to-event prediction problem, there have also been many attempts using different machine learning methodologies that were modified and applied to this problem [ 19 , 21 ]. On the other hand, longitudinal data cannot be modeled solely using traditional clas-sification or regression approaches since certain observations have event status and the rest have an unknown status up until that specific time of study. cept of censoring in survival data [ 15 ]. Modifications of decision trees [ 8 , 17 ], of the works on this topic. Another popular choice in the predictive modeling literature is the Bayesian approach. However, there was only a little work in the literature using Bayesian methods for survival data [ 1 , 14 , 20 ]. the above mentioned algorithms since none of the existing works perform fore-casting of event occurrence at future points in the context of survival data. They basically use the training data that is collected at the same time point as the test data. The basic idea of the proposed model is to develop Naive Bayes and its extension Tree-Augmented Naive Bayes (TAN), to build a predictive prob-abilistic model which will allow us to adapt the prior probability of events for forecasting the event occurrence at different points of time in the future. It is important to note that discriminative models are not suitable for the forecasting framework due to the lack of the prior probability component. The aim of our work is to address the following question:  X  X hen will a subject in longitudinal study experience an event? X  The fundamental challenge here is to determine which subject in the study will experience the event at a certain timepoint based on event occurrence information that is available only until prior points of time (usually much earlier than the timepoint used during estimation). Before describing the details of the proposed model, we formalize the problem and transform it to a binary classification task. Then, we describe two well-known probabilistic classification approaches, namely, Naive Bayes and Tree-Augmented Naive Bayes (TAN). Table 1 describes the notations used in this paper.
 3.1 Problem Formulation Let us consider a longitudinal study where the data about n independent subjects are available. Let the feature vector for sample i be represented by x we can define T i as the event time, and C i as the last follow-up time or censoring time (the time after which the subject has left the study). For all the subjects i = { 1 , ..., n } , O i denotes the observed time which is defined as min ( T Then, the event status can be defined as  X  i = I { T i  X  C dataset can be represented as ( x i ,T i , X  i ) where x i It should be noted that we only have the information for few events until the time t c . Our aim is to predict the event status at time t Let us define y i ( t c ) as event status for subject i at time t less than the observation time since we aim to forecast the event occurrence at early stage of the study. Suppose, among n subjects in the study, only n ( t experience the event at time t c . For each subject i we can define In this transformed formulation, given the training data ( x a binary classifier using y i ( t c ) as the class label. If y noted that a new classifier will have to be built to estimate the probability of event occurrence at t f based on the training data that is available at t 3.2 Naive Bayes Method Naive Bayes is a well-known probabilistic model in the machine learning domain. Assume we have a training set in Fig. 1 where the event occurrence information is available up to time t c . Based on the binary classification transformation explained above, using Naive Bayes algorithm, the event probability can be esti-mated as follows: The first component of the numerator is the prior probability of the event occur-rence at time t c . The second component is a conditional probability distribution which can be estimated as follows: where x ij is the value of attribute j for subject i . Thus, it is a natural estimate for the likelihood function in Naive Bayes to count the number of times that event occurred at time t c in conjunction with j th attribute that takes a value of x . Then we count the number of times the event occurred at time t and finally take the ratio of these two terms. This formula is valid for discrete attributes; However, it can be easily adapted for continues variables as well [ 10 ]. 3.3 Tree-Augmented Naive Bayes Method A prominent extension of Naive Bayes is the Tree-Augmented Naive Bayes (TAN) where the independence assumption between the attributes is relaxed [ 7 ]. The TAN algorithm imposes a tree structure on the Naive Bayes model by restricting the interaction between the variables to a single level. This method allows every attribute x j to depend upon the class as well as at most one other dependency in Naive Bayes and TAN is shown in Fig. 2 . Given the training set ( x ,y ( t c )), firstly the tree for the TAN model should be constructed based on the conditional mutual information between two attributes [ 7 ].
 I x j , x k | y ( t c ) = Then, a complete undirected graph in which the vertices correspond to the attributes x j is constructed. Using Eq. ( 3 ), the weight of all the edges can be computed. A maximum weighted spanning tree is built and finally, an undirected tree is transformed into a directed one by randomly choosing a root variable and setting the direction of all the edges outward from the root. After the construc-tion of the tree, the conditional probability of each attribute on its parent and the class label is calculated and stored. Hence, the probability of event at time t , can be defined as follows: P y ( t c )=1 | x ,t  X  t c = The numerator consists of two components; the prior probability of the event occurrence at time t c and the conditional probability distributions which can be estimated using the maximum likelihood estimation (MLE). In this section, we describe the proposed E arly S tage P rediction (ESP) frame-work. First, we describe our proposed prior probability extrapolation based method using different distributions and then we will introduce ESP-NB and ESP-TAN algorithms which utilize the extrapolation method. 4.1 Prior Probability Extrapolation In order to predict event occurrence in longitudinal data, we develop a technique that can estimate the ratio of event occurrence beyond the original observation range or in other words, compute the extrapolation for prior probability of event occurrence . This extrapolation approach will be based on Weibull and Lognormal distributions which are used widely in the literature for modeling the time-to-event data [ 3 , 16 ]. We will integrate such extrapolated values later with the proposed learning algorithms in order to make predictions at future timepoints. Weibull: We estimate the shape and scale parameters,  X  t distribution, by fitting the distribution to data obtained until t making the following extrapolation Lognormal: We can also assume that the time to event follows a log-normal 4.2 The ESP Algorithm We will now describe the ESP Algorithm which consists of two phases. In the first phase, the conditional probability distribution is estimated using training data which is obtained until time t c (see Sects. 3.2 and 3.3 ). In the second phase, we extrapolate the prior probability of event occurrence for time t beyond the observed time using different extrapolation techniques as follows: the posterior probability for event occurrences at time t ESP-NB: ESP-TAN: for each attribute j , the algorithm estimates the conditional probability using the data available until time t c . In the second phase, a probabilistic model is built to predict the event occurrence at t f . In lines 5 X 7, the prior probability for event occurrence at time t f is estimated using different extrapolation techniques. Then, in lines 8 X 12, for each subject i , we adapt the posterior probability of event occurrence at time t f . The time complexity of the ESP algorithm follows the time complexity of the learning method that is chosen. It should be noted that the complexity of the extrapolation component is a constant and does not depend on either m or n . Hence, for ESP-NB, the overall complexity is O ( mn ) and for ESP-TAN, it is O ( m 2 n ), where n is the total number of subjects and m is the number of features in the dataset. In this section, we will describe the datasets that are used for evaluating the proposed methods along with the comparisons of the proposed algorithms with various baseline prediction methods. 5.1 Dataset Description We evaluated the performance of the models using both synthetic and real-world survival datasets which are summarized in Table 2 .
 Synthetic Datasets: We generated synthetic dataset in which the feature vec-tors x are generated based on a normal distribution N (0 , 1). Covariate coefficient vector  X  is generated based on a uniform distribution Unif (0 , 1). Thus, T can be generated using the method described in [ 2 ]. Given the observed covariates x for observation i , the failure time can be generated by In our experiments, we set  X  =0 . 01 and  X  =2.
 Real-World Survival Datasets: Several real-world survival benchmark datasets were used in our experiments. We used primary biliary cirrhosis (PBC), breast and colon cancer datasets (available in the survival data repository which are widely used in evaluating longitudinal studies. We also used Framing-ham heart study dataset which is publicly available [ 4 ]. In addition, we also used two in-house proprietary datasets. One is the electronic health record (EHR) data from heart failure patients collected at the Henry Ford Health System in Detroit, Michigan. This data contains patient X  X  clinical information such as pro-cedures, medications, lab results and demographics and the goal here is to predict the number of days for the next readmission after the patient is discharged from the hospital. Another dataset was obtained from Kickstarter, a popular crowd-funding platform. Each project has been tracked for a specific period of time. If the project reaches the desired funding goal within deadline date then it is considered to be a success (or event occurred). On the other hand, the project is considered to be censored if it fails to reach its goal within the deadline date. 5.2 Performance Evaluation The performance of the proposed models is measured using following metrics,  X 
AUC is the area under the receiver operating characteristic (ROC) curve. The curve is generated by plotting the true positive rate (TPR) against the false positive rate (FPR) by varying the threshold value.  X 
F-measure is defined as a harmonic mean of precision and recall. A high value of F -measure indicates that both precision and recall are reasonably high. Implementation Details: The proposed ESP-NB and ESP-TAN methods are implemented using e1071 package available in the R programming language [ 5 ]. The same package used for comparison results from Naive Bayes and TAN clas-sification model. The coxph model in the survival package is employed to train the Cox model. The source code of the proposed algorithms in R programming environment is available at http://dmkd.cs.wayne.edu/codes/ESP . 5.3 Results and Discussion For performance benchmarking, we compare the proposed ESP-NB and ESP-TAN algorithms using Weibull and Lognormal distributions as extrapolation techniques with Cox regression, Naive Bayes (NB) and Tree-Augmented Naive Bayes (TAN) classification methods which are trained at time when only 50 % of events have occurred and the event prediction is done at the end of study. Tables 3 and 4 summarize the comparison result in AUC and F-measure evalu-ation metrics, respectively. We used stratified 10-fold cross-validation and aver-age values (along with the standard deviations) of the results on all the ten folds are being reported. For all of the datasets, our results evidently show that the proposed ESP-based methods using either Weibull or lognormal distribu-tion will provide significantly better prediction results compared to the other methods. The choice of the optimal distribution will depend on the nature of the dataset being considered, in particular, the distribution that the event occur-rence follows. Furthermore, ESP-NB build on independence assumption between the attributes which does not hold in many survival applications. Thus, the intro-duced ESP-TAN relaxed the independence assumption which leads to improved AUC and F-measure values in almost all of the results.
 The results clearly show that our models can obtain practically useful results using the data collected at an early stage of the study. This is due to the fact that classification methods do not have the ability to predict the event occurrence for a time beyond the observation time. Also, in the Cox regression model, the baseline hazard is undefined after the observation time t experiments, we can conclude that the proposed framework is able to obtain practically useful results at the initial phases of a longitudinal study and can provide good insights about the event occurrence by the end of the study. In Fig. 3 , we present the prediction performance of different methods by vary-ing the percentage of event occurrence information that is available to train the model for the PBC dataset. For example, 20 % on the x-axis corresponds to the training data obtained when only 20 % of the events have occurred and predic-tion of the event occurrences was made for the end of the study period. From this plot we can see that the AUC values improve when there is more information on the event occurrence in the training data. For all the cases, our proposed ESP framework gives better prediction performance compared to other techniques. Furthermore, it should be noted that the improvements of the proposed meth-ods are more significant over the baseline methods when there is only a limited amount (20 % or 40 %) of training data. Also, when 100 % of the training data is available, the performance of the proposed methods will converge to that of the standard Naive Bayes and TAN methods since the prior probabilities in both scenarios will be the same and fitting a distribution will not have any impact when evaluated at the end of the study. The proposed prediction framework is an extremely useful tool for domains where one has to wait for a significant period of time to collect sufficient amount of training data. The practical implication of this result is the fact that using the proposed models, one can obtain an approximate result and gain insights about the problem within the early stage of the study. Thus, it is not needed to wait until the end of the study to obtain the model performance. Also, we can observe that, in many real-world datasets, 50 % of the events typically occur within 25 % of the total study time. Such an early stage model building is an extremely useful tool for domains where one has to wait for longer time periods to collect the required training data. In many real-world application domains, it is important to be able to forecast the occurrence of future events by only using the data collected at early stages in longitudinal studies. In this paper, we developed event prediction algorithms by extending Bayesian methods through fitting a statistical distribution to time-to-event data with fewer available events at the early stages. This enables us to have a reliable prediction of event occurrence for future time points. Our extensive experiments using both synthetic and real datasets demonstrate that the proposed ESP-based algorithms are more effective than Cox model and other classification methods in forecasting events at future time points. Also, we investigated different kinds of extrapolation approaches by fitting various distributions such as Weibull and log-normal. Though motivated by biomedical and healthcare application scenarios (primarily for estimating survival), the pro-posed algorithms are also applicable to various other domains where one needs to predict event occurrences at early stage of analysis when there are only a relatively fewer set of events that have occurred until a certain time point.
