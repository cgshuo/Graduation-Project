 on a website. The process of analyzing clickstream data and taking actions as a result of that analysis can be viewed as a circular process (see Figure 1) [7]. There are many open problems in this process. For example, the data integrity problem between the first step and the second step, the problem of measuring the "interestingness" of a pat-tern between the second and the third step, the problem of assessing the significance of a pattern between the third step and the fourth step, and the final problem of how to close the loop. 
The quality of the pattern discovery and analysis step depends on the quality of the data that is produced after the data pre-processing step [1]. Missing data in server side due to the use of the  X  X ack X  button in the browser, which does not show in the server side clickstream data. Consequently, some of the user X  X  browsing patterns may be misinterpreted due to the missing data. 
In this paper, we describe a series of experiments that show how clickstream data is lost at the server side. We examine the effects of different browsers, different ISPs and different proxy servers and propose a pattern restoration method (PRM) to over-come the caching problem caused by use of the browser X  X  "back" button. 
The structure of this paper is as follows. Some related literature is discussed in sec-tion 2. Section 3 briefly describes the concept of a footstep graph, the experiment de-sign and results. Section 4 describes the concept and the process of the PRM algo-rithm in detail and section 5 evaluates the efficiency and accuracy of the PRM algorithm. Section 6 concludes the paper. In web usage mining, there are three main sources of usage data. These are client side data, intermediate data and server side data [8]. Client side data is normally collected web page. No data is lost in this process and the data is complete [5]. 
However, server side data is the most common source of data for web mining, as it is easy to collect. Unfortunately, raw server side data contains much noise and is usu-ally incomplete [6]. Therefore, research has focused on pre-processing server side data to improve it X  X  quality. The pre-processing is an essential step but one that consumes a large proportion of the processing time in web usage mining [4]. Colley et al. [3] have developed a series of steps for data pre-processing for web usage mining. These in-clude data cleaning, user identification, session identification and data formatting. 
In recent years, the use of "bots" (search engine robots and web crawlers) has be-come widespread and a single bot can visit a website many times. However, these vis-its do not represent  X  X eal X  users and are simply seen as noise in the server logs. There-when mining server side data. In [2], two problems that cause the loss of information in server side clickstream data have been pointed out. based website. Such a website may cause errors in user browsing time measurements, because every page of the framesets is treated as a single page and an independent re-quest in the server side data. This problem has been solved by Spiliopoulou et al., who use a referrer-based heuristic algorithm to reconstruct the incomplete session record [9]. Others have used the web site structure to reconstruct incomplete session data [1]. 
The second is the problem caused by web page caching, e.g. when the  X  X ack X  func-tion of a browser is used. When the "back button" is used, the browser does not send a request to the server and consequently the us er X  X  browsing behavior is not recorded in server's logs. However, the user X  X  backward browsing is important information for web usage mining, and this kind of missing data problem will affect the quality of any patterns discovered. In this paper, we propose a method for restoring this lost data by using referrer infor-mation from the clickstream data and website structure. However, first we present the results of a series of experiments to investigate the missing data problem. In order to visualize the user X  X  browsing behavior, we use footstep graphs [11]. A footstep graph represents the nodes (i.e. pages) on the user X  X  browsing route. Horizontal distance in this graph represents the time between two nodes, and changes in the vertical axis in-dicate a transition from one node to another node (See figure 2). An Upstairs pattern in the footstep graph is found when the user only moves forward. A Mountain pattern occurs when a Downstairs pattern follows an Upstairs pattern. A Valley pattern oc-curs after the user goes back to a page they visited and then goes to another new page. A Fingers pattern in a footstep graph indicates that a user is in a browsing loop. 3.1 Design of an Experiment to Find the Scope of the Missing Data Problem The goal of the experiment is to look at the difference between browsing patterns as they appear at the client and server side in order to identify what data is lost in differ-ent user browsing environments. Three different browsing environments were chosen for the experiments using different browsers, ISPs and proxy servers. Additionally, four browsing routes representing the Upstairs (figure 2a), Mountain (figure 2c), Fin-gers (figure 2e) and Valley pattern (figure 2g) were used. Three widely used browsers were chosen for the experiments: Microsoft Internet Explorer, Netscape Navigator and Opera. Diffe rent users, using different ISPs to ac-cess the web site, were asked to follow a predetermined browsing route. The tests were repeated using different proxy server settings. 3.2 The Results 3.2.1 Using Different Browsers The main purpose of this test is to see if there is any difference in the server side data when different browsers are used to browse a predetermined route. We used the de-fault setting for the cache and did not set a proxy server in this part of the experiment. Internet Explorer &amp; Netscape Navigator. Internet Explorer &amp; Netscape Navigator both use the same default cache setting. The default setting is that when the user uses the backward and forward function, the browser does not sent the request to the server but use the cached webpage. Thus, server side data is lost if the user clicks the back-data for all other patterns are lost due to caching. Opera. Opera browser does not send a request to the website server when the user opens a web page that has been browsed within the last five minutes. Thus, much of the server side information is lost. For example, figure 3b should be a Mountain pat-tern, but there is no server side data because all of the web pages had been requested before. Figure 3c has been affected in the same way. 3.2.2 Using Different ISPs Again, users were asked to follow a pre-defined route through a given web site. Here only Internet Explorer or Netscape Navigator, without proxy server settings, were used. The commercial ISPs used in this experiment (Onetel, Hinet, SeedNet, BT and AOL) did not cache the experimental web pages and all of these ISPs created the ex-pected patterns in server side data. However, some server side data was lost when us-ing Loughboro ugh University as an ISP as Loughborough appeared to cache web server side appeared similar to the pattern produced by the Opera browser. 3.2.3 Using Different Proxy Servers server side image of the user X  X  browsing pattern depends on the proxy server X  X  type. If the proxy server caches web pages for the user but does not send a request to the web-site server, some server side clickstream records will be lost and the server side pattern sends a request to the website server, the server side pattern will suffer no losses. Having identified the potential scope of the problem, we now turn to a possible solu-tion. Below we describe a method to restore the lost data that we call the pattern re-store method (PRM). The basic idea behind the PRM algorithm is to use referrer in-formation and the web site structure to restore the lost data. The PRM algorithm has two phases, the details of which are presented below. 4.1 The First Phase of the PRM Algorithm 4.1.1 The Process and Algorithm of the First Phase PRM Algorithm Before we discuss the PRM algorithm, the general description of a clickstream format after pattern restoration is defined as: C : [U i , T i , L i , R i , Mark] C : C i denotes the ith clickstream in one user session U T : T i denotes the timestamp of i th clickstream in one user session L : L i denotes the requested URL of i th clickstream in one user session. R : R i denotes the referrer information of the i th clickstream in one user session Mark: Mark is used to distinguish original from restored clickstream data. 
The first phase of the PRM algorithm uses the referrer information to restore the missing clickstream data. First, the algorithm checks the first clickstream record in a an example of original clickstream data in a session and Figure 5 shows the restored data for the same session. 
The next step of the first phase of the PRM algorithm compares the referrer URL in each clickstream record with the target UR L from the previous record. If they are from one URL (e.g. record 1 in figure 5) to another (e.g. record 2 in figure 5). Thus, it is assumed that there is no missing data and no need to perform pattern restoration. been lost before the current record (e.g . between record 2 and 3 in figure 5). 
In this case, the algorithm will restore a record using the information in the current record. The IP address of the restored record is set to the same as the current record and the timestamp is set to be midway between the time between the current record and the previous record (i.e. midway between the times of record 2 and 3 in figure 5). The target URL of the restored record is taken from the referrer of the current record and the referrer of the restored record is set to null. Finally, the marker of this record is set to  X  X estored X . The general description of the restored clickstream record in this step is C i X  [U 1 , (T i-1 +T i )/2, R i , -, Mark] . 
Record (3) in figure 6 is an example of a restored record created by comparing re-session has been processed. The pseudo code of the first phase of the PRM algorithm is given in figure 7. 4.1.2 Server Side Browsing Pattern s After the First Phase of the PRM After the first phase of the PRM algorithm, Fingers patterns and Valley patterns have been restored. Figure 8(a) shows an example of a Fingers pattern recorded in a client side; Figure 8(b) shows the corresponding pattern in the server side log. The pattern function has been lost. Figure 8(c) shows the restored pattern after the first phase of the PRM algorithm has been run. Figures 9(a) to 9(c) show a similar restoration proc-ess with a Valley pattern. 
Although the algorithm works with Fingers and Valley patterns, Mountain patterns cannot be restored using this method. Figure 10(a) shows a Mountain pattern in the data. The data lost by backward browsing cannot be restored and the pattern after the first phase of the PRM algorithm looks the same as in figure 10(b). 4.2 The Second Phase of the PRM Algorithm 4.2.1 The Process and Algorithm of the Second Phase of the PRM Algorithm As described above, the Downstairs part of Mountain patterns cannot be restored by the first phase of the PRM algorithm. Theref ore, a second phase is needed to replace the missing data. The second phase of the PRM algorithm uses information from the website X  X  link structure to insert the "most probable" browsing path of the user. To do this, a list of pages and the link structure for the site must be maintained. 
Figure 11 shows a simple example of how this algorithm works; the Downstairs will look like pattern 1 in figure 11. If node E does not have a direct link to node A, it from the nodes before node E to find the closest node that has a direct link to it. For example, the closest node to node E in figure 11 is node D, which has a direct link to The algorithm will continue to loop until it finds a node that has a direct link to node A or the node is equal to A. The pseudo code for the second phase of the PRM algorithm is shown as figure 12. Here, m denotes the total records before the current record, and k is used to count the total number of restored records in a single restoration session. 4.2.2 The User X  X  Browsing Pattern After the Second Phase of the PRM be restored. For example, figure 13(a) shows how a Mountain pattern appears in the server side logs; figure 13(b) shows the restored Mountain pattern. 
Unfortunately, there is a weakness of the second phase of the PRM algorithm: when attempting to restore a Valley pattern, some errors may occur. 
Figure 14(a) shows how a Valley pattern appears in the server side log. After the second phase of the PRM algorithm, the pattern becomes that shown in figure 14(b). However, the original pattern was as shown in figure 14(c), not figure 14(b). To evaluate the performance of the PRM algorithm, we tested the processing time of the PRM algorithm under different restoration rates (i.e. the number of restored re-different user X  X  browsing patterns. The evaluation was performed under Windows XP operation system, 512Mb RAM, 2.4 GHz Intel Pentium 4 CPU. 5.1 The Evaluation of the Processing Time of the PRM Algorithm The tested number of original records ranged from 10 records (about 2 Kbytes file size) to 51200 (About 30 Mbytes file size). The results are shown in figure 15. 
This shows that the rate of increase in processing time is similar under different restoration rates. When running the first phase of the PRM algorithm to process needed is not particularly high, even when given a large amount of data. 
The same testing method is also be used to evaluate the second phase of the PRM algorithm; the results are shown in figure16. Here, the processing time with a restora-tion rate of 10 % is quite low and does not increase very much as the number of re-cords processed increases. 
When the restoration rate has reached 30%, the time / number of records slope has creases, the algorithm needs to check the structure table many times. Thus, the proc-essing time increases as the restoration ra te and the number of records increases. 5.2 The Evaluation of the Accuracy of the PRM Algorithm In order to evaluate the accuracy of the algorithm, we designed ten different browsing algorithm on each of the resultant sets of server side data, and compared the result to the original pattern. 
Table 1, shows the restoration accuracy of the first phase of the PRM algorithm when restoring Fingers , Valley and Mountain patterns. Although the restoration accu-racy for the Fingers and Valley is high, restoring Mountain patterns is only about 60% accurate, as the first phase of the PRM algorithm cannot deal with the Downstairs part of Mountain patterns. 
In table 2, the restoration accuracy rate of Mountain patterns has been increased by about 30%, but the restoration accuracy rate of Valley patterns has been decreased by now restored as Mountain patterns (see figure 14). This paper describes a series of experiments to examine the differences between click-some data is lost. We subsequently developed and evaluated an algorithm for restoring that by using the PRM algorithm the accuracy of the pattern discovery can be increased. 
