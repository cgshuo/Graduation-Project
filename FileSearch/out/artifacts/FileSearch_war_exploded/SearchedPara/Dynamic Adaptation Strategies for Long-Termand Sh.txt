 With the advent of the era of the informat ion explosion, never before have there been so many information sources availa bly indexed by search engines on the In-ternet. Ideally, users should be able to take advantage of the wide range of the valu-able information while being able to find only those which are appealing to them. On the contrary, it becomes more difficult than ever to obtain desired results due to the ambiguity of user needs. Moreover , present search engines generally han-dle search queries without considering us er preferences or contexts in which users submit their queries. For example, suppose that a database researcher who wants to search for information about a conference on Mobile Data Management and a banker who is interested in searching for the MDM bank, both input  X  X DM X  on Google. Regardless of the different intentions of the two users on the same query, the results turn out to be a multimedia so ftware company, a broadband services company, a national obser vatory, a conference on mo bile data management, and so on. Current search engines prove unfortunately inadequate for this situation.
To address this problem , personalized search ha s recently become an active on-going research field. Studies [2, 14] have focused on requiring users to ex-plicitly enter their contextual preferen ces including interest topics, bookmarks, etc., and these contextual preferences ar e used to expand user queries or re-rank search results. Forcing users to submit their contextual preferences would be a task that few users would be willing to do. Furthermore, it is very difficult for users to define their own contextual pref erences accurately. Much attention has been paid in [13, 16, 18, 19] to learn user preferences transpar ently without any extra effort from users. These studies place emphasis on modelling user profiles or user representations to indicate user preferences automa tically. Speretta et al. [18] created user profiles by classifying some information into concepts from the ODP [12] taxonomic hierarchy and then re-ranked search results based on the conceptual similarity between the web page and the user profile. The au-thors, however, have not taken the hierarchy structure of the ODP into account when calculating the co nceptual similarity.

In this paper, we focus on studying learning user profiles and utilizing the learned user profiles to re-rank search results. Most studies on learning user profiles have deemed user profiles to be static. A relat ed problem occurs when user preferences change over time. For instance, if a user changes her vocation from being an IT specialist to a lawyer, her interests will naturally shift with this change. It becomes important to keep the user profile up-to-date, and for a search engine to adapt ac-cordingly. In addition, a user profile covers both short-term and long-term user preferences, which may increase or reduce r espectively and co-relatedly with time. Using one model to represent two differen tly featured parts of the user profile will be far from perfect. Accordin gly, suitable strategies are needed to capture the ac-cumulation and degradation of changes of user preferences, and then adapt the content and the structure of a user profile to these changes. For re-ranking search results, our rank mechanism is similar to that proposed by [2] in which a semantic similarity measure is introduced with consideration to the hierarchy of the ODP structure. Meanwhile, the technique proposed in [2] suffers from the problem of re-quiring users to select topics which best fit their interests from the ODP, and other shortcomings we will address in Section 4.

Our contributions in this paper could be summarized as follows. (1) We devise independent models for long-term and short-term user preferences. (2) Dynamic adaptation strategies for modelling user profiles automatically are (3) When user preferences change, our user profiles, not only in contents, but (4) Finally, we propose a novel rank mech anism by measuring hierarchy semantic
The rest of this paper is organized as follows. In Section 2, we review the related work. In Section 3 we describe two independent models and dynamic adaptation strategies for user profiles. Rank mechanisms and evaluation metrics are addressed in Section 4. Sect ion 5 presents the experim ental results. Finally, we conclude in Section 6 with some directions for future work. 2.1 Context Search Kraft et al. [8] state that the context, in its general form, refers to any additional information associated with the query in the web search field, and also present three different algorithms to implement the contextual search instead of mod-elling user profiles. Generally speaking, if the context information is provided by an individual user in any form, whether automatically or manually, explicitly or implicitly, the search engine can use the context to custom-tailor search results. The process is named as a personalized search.

In this way, such a personalized search co uld be either server-based or client-based. The system in [4] is an available server-based search engine that unifies a hierarchical web-snippet clustering system with a web interface for the person-alized search. Google and Yahoo! also supply personalized search services. With the cost of running a large search engine already very high, however, it is likely that the server-based full-scale personalization is too expensive for the major search engines at present.

On a client-based personalized search, studies [3, 16, 19] focus on capturing all the documents edited or viewed by users through computation-consuming procedures. Allowing for scalability, the client-based personalized search could learn user contexts more accurately than the server-based per sonalized search, while it is unavoidable that keeping track of user contexts has to be realized by a middleware in the proxy server or the clie nt. Users, however, may feel unsafe to install such a kind of softwares even if they are guaranteed to be non-invasive, and may intend to enjoy the services provided by search engines instead. Moreover, if a user at home uses her private computer which is different from that in her office, keeping her contexts consistent b ecomes a problem. Therefore, our work is server-based.

In this paper, we focus on the use of suitable strategies to learn user profiles in a trade-off between scalability and accuracy for the server-based personalized search. 2.2 User Profile There have been vast schemes of learning u ser profiles to figure user preferences from text documents. We notice that most of them model user profiles repre-sented by bags of words without considering term correlations [1, 9, 17, 20]. To overcome the drawbacks of the bag of words, the taxonomic hierarchy, partic-ularly constructed as a tr ee structure, has been widely accepted in [2, 11, 15]. Schickel-ZuberF et al.[15] score user pr eferences and concept similarity based on the structure of ontology. But their wor k needs users to express their preferences by rating a given number of items explicitly.
 Meanwhile, these studies omit that user interests could change with time. Some topics will become more interesting to the user, while the user will com-pletely or to varying degrees, lose inter est in other topics. Studies [1, 9, 20] suggest that relevance feedback and machine learning techniques show promise in adapting to changes of user interests and reducing user involvements, while still overseeing what users dislike and th eir interest degradation. In [9] a two-level approach is proposed to learn user profiles for information filtering. While the lower level learns the stationary us er preferences, the higher level detects changes of user preferences. In [20] a mult iple three-descriptor representation is introduced to learn changes in multiple interest categories, and it also needs positive and negative relevance fee dback provided by users explicitly.
Our work, particularly our dynamic adaptation strategies for user profiles, are based on the idea that sufficient contextual information is already hidden in the web log with little overhead, and all the v isited pages can be considered as user preferences to various deg rees because the users hav e accessed them. This con-textual information motivates us to capture the accumulation and degradation changes of user preferences implicitly, to learn user profiles automatically. As indicated in [20], for user profiles, l ong-term user preferences generally hold user preferences and the degree of prefer ences accumulated by experiences over a long time period. Hence it is fairly stable. On the other hand, short-term user preferences are unstable by nature. For instance, interests in current hot topics could change on a day-to-day basis. It is crucial to design a temporal structure for shot-term user preferences. Based on these features, we propose two novel models for long-term and short-term user preferences respectively and discuss them together with the adaptation strategies for their close correlations. Our strategies are in accord with the cha nges of user preferences in nature. 3.1 Long-Term Model of User Profile The taxonomic hierarchy for our long-term model is a part of the Google Direc-tory [5]. This part is composed of topics that have only been associated with the clicked search results, instead of the whole Google Directory. And these topics are linked as a tree structure to form our long-term model that is also called the user topic tree from now on. In other words, each node in the user topic tree means a topic in the Google Directory. We use search results and web pages in-terchangeably when referring to the URLs returned from the web search engine on a specific query.

In the Google Directory, each web page is classified into a topic 1 .Inthe  X  X dding X  operation, topics associated with the clicked pages are added into the user topic tree click by click. Moreover, each node in the user topic tree has a value of the number of times the node has been visited. This value is called the  X  TopicCount  X , and represents the degree of pr eferences. The  X  X eleting X  oper-ation is effected by the changes of the s hort-term model. It will be addressed in Section 3.2. Figure 1 illustrates the schema of the user topic tree. For ex-ample, node C is represented by the [ Internet, 18] which means one user has clicked a page associated with the topic  X  Internet  X  and the user has visited the  X  Internet  X  18 times before this search. In our experiments node C is actually stored as the [ \ Root \ Compuetr \ Internet, 18] with a full path in the Google Directory. 3.2 Short-Term Model of User Profile We frame the Page-History Buffer (PHB) for the short-term model. The PHB caches the most recently clicked pages with a fixed size that is determined by the ability of the search engine. We now meet the same problem as the cache in the processor, and that is how to kick off the  X  X ld X  pages in time to keep up with the changes of short-term user preferences. As it is known, in the cache management, there are popular cache replacement al gorithms that are all designed for the processor, the web cache and the database disk buffering. No such research could be available in the personalized search, especially in the short-term model of the user profile. Our goal, keeping track of the most recent accesses of search results in the PHB, is basically similar to that in the cache management. As a result, the LFU (Least Frequently Used), one of thes e replacement algor ithms, is adjusted to our scheme, which is named the Least Frequently Used Page Replacement (LFUPR). The details are shown in Table 1. The LFUPR reflects the changes of the short-term model, including how to add (line 3  X  line 6) and replace (line 10  X  line 12) web pages in the PHB.

From Figure 1 and the LFUPR algorithm in Table 1, our dynamic adaptation strategies maintain user profiles such that the short-term model is updated by the LFUPR (line 1  X  line 15), while the degree of preferences in the long-term model could be degraded (line 13) when the page in the PHB is replaced, and could be accumulated when the user clicks the page ( X  X dding X  operation). On the other hand, if the user accesses the web page whose associated topic is not in the current user topic tree, the new node could be added into the tree ( X  X dding X  operation). From line 16 to line 18, if the  X  TopicCount  X  of one node becomes zero, the node would be deleted f rom the tree. This procedure is called the  X  X eleting X  operation. The  X  X dding X  and  X  X eleting X  operations dynamically adapt the structure of the long-term model to the user click behaviors. Although we design independent models for short-term and long-term user preferences, our strategies ensure that the inherent corre lations between them are not ignored, and that the changes of the short-term model have an even influence on the long-term model. Here, the meaning of  X  X ven X  is that we degrade the  X  TopicCount  X  not on an hour-to-hour or a day-to-day basis, only after a period of time during which the user has not accessed the topic in the whole search process. 4.1 Distance Metrics The tree distance which we deal with, is the distance between each search result and the user topic tree, as described in [2]. The search result with the shorter distance, meaning the higher similarity to user preferences, should be put in the topmost position of the ranking list. For each search result, there is an associated node in the Google Directory. The user topic tree is also composed of nodes. The distance computation is actually how the distance between two nodes in the tree structure is measured.

Chirita et al. [2] point out that the main drawback of the na  X   X ve tree distance is that it overlooks the depth of the subsumer (the deepest node common to two nodes). With the help of Figure 1, let us explain the problem clearly. sub i,j represents the subsumer of the node i and the node j . Edges ( i, sub i,j )represents the number of edges between the node i and the node sub i,j . The na  X   X ve distance is defined as Distance ( A, B )is2,whichisthesameas Distance ( C, D ), making it difficult to re-order search results by Equation (1). 4.2 Hierarchy Semantic Similarity Li et al. [10] takes the depth of the subsumer h and the na  X   X ve distance between two nodes l into the calculation.  X  and  X  are the parameters scaling the contri-bution of the na  X   X ve distance and the depth respectively. The semantic similarity is defined as Their experiment results show that th e optimized values of the two parame-ters are,  X  =0.2 and  X  =0.6. For example, Sim ( A, B ) is unequal to Sim ( C, D ) based on Equation (2). Because the subsumer of A and B, i.e.,  X  Root  X , is in the different level from the subsumer of C and D, i.e.,  X  Computer  X . However, Equation (2) only solves problem partially. Let us see another example. Due to the same value (i.e., 3) between Distance ( A, C )and Distance ( B, F ), and the same subsumer (i.e.,  X  X oot X ) between the pairs (A, C) and (B,F), Sim ( A, C )is equal to Sim ( B, F ).

Under this situation, Chirita et al. [2] separate l into l 1 and l 2 ,andthengives different weights to the two variables through the parameter  X  defined as Equation (3) can work well for common cases. However, we find that the pa-rameter  X  is sensitive to the semantic meanings between the two topics, as illus-trated in [2]. Furthermore, even if we co mpute the similarity by Equation (3), Sim ( C, D ) is still equal to Sim ( E, D ) because of the same value between l 1 and l . In our system, we extend Equation (2) in another way, as the  X  TopicCount  X  has much better effect on the overall performance than the weak parameter  X  . Comparative experim ents are in Section 5. 4.3 Our Rank Mechanism When a user submits a query to the search engine, the search results are re-ranked by our semantic similarity defined as the degree by which the search result is similar to the user profile. i is a node in the user topic tree ( i =1 , 2 ,  X  X  X  ,size ( UserTopics )). j is the associated node with preferences of a node in the us er topic tree. The larger the WT is, the more inter-ested the user is in one topic. For one search result, the number of the CSim val-ues is size ( UserTopics ) in Equation (4). One user topic tree represents one user. We define the semantic similarity between one search result and the user topic tree as the maximum value among all the values ( i =1 , 2 ,  X  X  X  ,size ( UserTopics )) expressed as To keep our rank mechanism from missing the high quality pages in Google, Equation (5) is integrated with PageRank as Here  X  is a parameter in [0,1] which blends the two ranking measures. The user could vary the value of  X  to merge our rank mechanism and PageRank in different weights. In our experiments,  X  is set to 0.5, which gives equal weight to the two measures. 4.4 Evaluation Metrics Accuracy of User Profile. It is natural to evaluate our user profiles by com-puting the difference between the real user topic tree and the modelled user topic tree. Equation (2) is suitable for this task and the relative error between the two user profiles is shown as where Sim ( M, R ) is denoted by K j =1 Max ( Sim ( j, i )) .R means the vector of topics in the real user topic tree. M means the vector of topics in the modelled user topic tree. i is a node in R ( i =1 , 2 ,  X  X  X  ,N  X  size ( R )). j is a node in M ( j =1 , 2 ,  X  X  X  ,K  X  size ( M )). A smaller value of Error ( M ) means a higher accuracy of our modelled user profile.
 Quality of Our Personalized Search System. Whether a personalized sys-tem is successful or not is determined by t he user satisfaction. An effective rank mechanism should place relevant pages close to the top of the rank list. We ask the users to select the pages they considers relevant to their preferences for our evaluation. The quality of our system is measured as Here S denotes the set of the pages selected by user u for query q , R ( p )is the position of page p in the ranking list, and Count ( p ) is the number of selected pages. A smaller AveRank represents better quality. 5.1 Experimental Setup Our rank mechanism could be combined with any search engine. In this study we choose the Google Directory Search [5] as our baseline in that Google applies its patented PageRank technology on the Google Directory to rank the sites based on their importance. It is convenient for us to combine and evaluate our rank mechanism with Google. The necessa ry steps are depicted in Table 2. Main modules in the experiments are listed as follows. (1) Google API module: Given a query, we are offered titles, snippets, and page-(2) Log module: We monitor user click b ehaviors, recording the query time, (3) User profile: It has been described in Section 3.

In our experiments, due to the large size of the whole Google Directory, only the top 4 levels are encoded into the user topic tree. The size of the PHB is 20 pages. Ideally if we could cache all the clicked web pages in the PHB and utilize the whole levels of the Googe Directory, it would be much easier to personalize a search. 5.2 Dataset For each search, the Google API module got the order of the top 20 Google results due to the limited number of the Google API licenses we have. We ran-domized the order of the results before returning the 20 results to the user at run-time. For evaluation, 12 subjects are invited to search through our system. The 12 subjects are graduate students (5 females and 7 males) researching in several fields, i.e., computer, chemistry , food engineering, el ectrical engineering, art design, medical, math, architecture, and law. These subjects are divided into three types:  X  Clear User, searching on queries that usually have one meaning,  X  Semi-ambiguous User, searching on queries that have two or three meanings,  X  Ambiguous User, searching on queries that have more than three meanings.
Our search interface was available on t he Internet, and convenient for the subjects to access it at any time. They were asked to query topics closely re-lated to their interests and majors. In the first four days, subjects input the queries on their majors, and then in the next three days the queries on their hobbies were searched. Finally, in the last three days, the subjects were required to repeat some queries done before. This repeated procedure gave a clear perfor-mance comparison between the current and earlier systems, as user profiles were updated search by search. After the da ta were collected over a ten-day period (From October 23nd, 2006, to November 1st, 2006), we got a log of about 300 queries averaging 25 queries per subject and about 1200 records of the pages the subjects clicked in total. 5.3 Experimental Results Results of Accuracy of User Profile. From Figure 2, we see that as the days went on, the relative errors of our user profiles generally kept decreasing. In the last three days they even appare ntly stopped decreasing. The trend was expected because the subjects were asked to repeat some queries done earlier for comparison. Without a new query for a search, we are not able to learn more about the user preferences. Moreover, re lative errors got even slightly larger on these days. Because the subjects mig ht click pages different from those of the early search on the same query. This further indicates the importance of adaptation strategies to learn the changes in user preferences. Figure 2 also shows that it is easier and quicker to learn the user profile of a  X  X lear User X  than that of a  X  X emi-ambiguous User X  and slowest to learn the user profile of an  X  X mbiguous User X . For example, when day=4, Error(Clear User)=0.3, Error(Semi-ambiguous User)=0.6, and Error(Ambiguous User)=0.8. Although the learning procedure of the  X  X mbiguous User X  is slower than the other two kinds of users, as long as its user profile is converged relatively, it yields the best improvement in terms of quality among all the three kinds of users. Results of Quality of Personalized Search System. Now, we compare the performance improvements of the following three ranking mechanisms:  X  the Google Directory Search (GDS), using the Google API,  X  the Personalized Google Directory Search (PGDS3), combing Equation (3)  X  the Personalized Google D irectory Search (PGDS6), using Equation (6). Evaluated by Equation (8), how they performed day by day is shown in Figure 3. By using the GDS as a baselin e, the performance improvement of our PGDS6 in Figure 3(b) is 42.37 %, which outperforms those in both Fig-ure 3(a) (i.e., 28.86%) and Figure 3(c)(i.e., 16.27%). The little improvement in Figure 3(c) indicates that GDS has done well with the  X  X lear User X . However, for the  X  X emi-ambiguous User X  and the  X  X mbiguous User X , the significant im-provements in Figure 3(a) and Figure 3(b)illustrates that GDS works worse than our strategies.

Figure 3(d) illustrates the average improvement over all users. As a result of requiring the subjects to change queries from their majors to hobbies, we see that from the fourth day to the fifth day, the values of AveRank experience a sudden increase. But after three days on learning the changes, our PGDS6 shows better results than the GDS and the PGDS3. More accurately, compared with the GDS, our PGDS6 outperforms the PGDS3 with a 60% improvement for the tenth day, while for the fifth day the improvement is only around 2%. This difference demonstrates that the changes of user pr eferences will lower the improvement that our strategy could achieve. Nevertheless, our rank mechanism still greatly improves over the GDS and the PGDS3 o verall. The average improvements of our PGDS6 and the PGDS3 over the GDS, are 29.14% and 7.36% respectively. In this paper we introduced how to capture the changes of user profiles from click-history data and how to use the user profiles to re-rank the search results, thus creating personalized views of the web. First, we designed independent models for short-term and long-term user preferences to consist of a user profile. Then, we adapted the user profile, including the content and the structure, to the accumulation and degradation changes of user preferences by our dynamic strategies. Finally, we proposed a novel rank mechanism to re-rank search results. Experimental results on real data demonstrate that our dynamic adaptation strategies are effective and our persona lized search system performs better than the selected rank mechanisms, especially for the  X  X emi-ambiguous User X  and the  X  X mbiguous User X .

In the future, we plan to do some comp arative experiments when the user varies the value of  X  in Equation (6). In addition, when computing for the node distance in the tree, we plan to consider the edge distance, assigning a different weight for each edge, because each pair of two nodes linked by an edge has dif-ferent semantic similarity. As Kelly et al. [7] summarize key papers that cover a range of approaches on implicit feedback techniques, we will study more user im-plicit information to construct the user profile, such as the time interval between two clicks, browsing patterns, and so on.

