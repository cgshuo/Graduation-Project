 The key algorithmic problem in viral marketing is to identify a set of influential users (called seeds ) in a social network, who, when convinced to adopt a product, shall influence other users in the net-work, leading to a large number of adoptions. When two or more players compete with similar products on the same network we talk about competitive viral marketing , which so far has been studied exclusively from the perspective of one of the competing players.
In this paper we propose and study the novel problem of compet-itive viral marketing from the perspective of the host , i.e., the owner of the social network platform. The host sells viral marketing cam-paigns as a service to its customers, keeping control of the selection of seeds. Each company specifies its budget and the host allocates the seeds accordingly. From the host X  X  perspective, it is important not only to choose the seeds to maximize the collective expected spread, but also to assign seeds to companies so that it guarantees the  X  X ang for the buck X  for all companies is nearly identical, which we formalize as the fair seed allocation problem.

We propose a new propagation model capturing the competitive nature of viral marketing. Our model is intuitive and retains the de-sired properties of monotonicity and submodularity. We show that the fair seed allocation problem is NP-hard, and develop an effi-cient algorithm called Needy Greedy . We run experiments on three real-world social networks, showing that our algorithm is effective and scalable.
 H.2.8 [ Database Applications ]: Data mining Social networks, influence propagation, viral marketing
Recent years have witnessed tremendous interest in social in-fluence and the phenomenon of influence-driven propagations in social networks, fueled by a variety of applications, among which the most prominent one is viral marketing . The key computational problem behind viral marketing is the identification of a set of influential users, whom should be  X  X argeted X  by a viral marketing campaign. Here, targeting means giving free (or price discounted) samples of a product and k represents the company X  X  budget. The targeted users, also called seeds , should be those that are well po-sitioned to create word-of-mouth driven cascades, so to transitively convince the largest number of other users to adopt the product.
The bulk of research in this field assumes that there is one com-pany, introducing one product in the market. In other words, there is no competition. However, in the real world, typically multiple players compete with comparable products over the same market. For example, consider consumer technologies such as videogame consoles (X-Box vs. Playstation), digital SLR cameras (Canon vs. Nikon) or smartphones (Android vs. iPhone): since the adoption of these consumer technologies is not free, it is very unlikely that an average consumer will adopt more than one of the competing products. Recognizing this, there has been some recent work on competitive viral marketing , where two or more players compete with similar products for the same market. The majority of these studies focus on the best strategy for one of the players [1 X 4,11,15].
Our motivating observation is that social network platforms are owned by third party such as Facebook and LiveJournal. The owner keeps the proprietary social graph secret 1 for obvious reasons of the company benefits, as well as due to privacy legislation. We call the owner the host . Companies that want to run viral campaigns are the host X  X  clients . The clients typically do not have direct access to the network and thus cannot choose seeds for their campaign on their own. Any campaign would need the host X  X  permission and privilege to run. Take Facebook as an example, business owners can set up a Facebook Page and create display ads or promoted posts to reach users 2 , but they are not able to effectively implement a viral marketing campaign which directly reaches individual users, due to the lack of access to the network graph and privacy concerns.
Motivated by this observation, we propose and study the novel problem of competitive viral marketing from the host perspective . We consider a new business model where the host offers viral mar-keting as a service, for a price. It allows the clients to run cam-paigns by specifying a seed budget, i.e., number of seeds desired. The host controls the selection of seeds and their allocation to com-panies. Once seeds are allocated, companies compete for adopters of their products on the common network.

In classical non-competitive influ ence maximization, the objec-tive is to choose the seeds so as to maximize the expected number of adopters. However, in a competitive setting, from the host X  X  per-spective, it is important not only to choose the seeds to maximize my-precious-social-graph/ the collective expected number of adoptions across all companies, but also to allocate seeds to companies in a way that guarantees the  X  bang for the buck  X  for all companies is nearly the same. In-tuitively, the bang for the buck for a company is the cost benefit ratio between the expected number of adopters of its product over its number of seeds. We call this the amplification factor ,asitre-flects how investing in a small number of seeds gets amplified by the network effect. If the host allocates the seeds carelessly to its clients, it can result in a wide variance in the amplification factors, leading to resentful clients. Consider the following hypothetical scenario. Suppose Canon and Nikon are two clients with seed bud-gets 20 and 30 , and Facebook, as host, selects 50 seeds. If those 50 seeds are allocated in such a way that Canon ends up getting ex-pected spread of 400 ( X  X ang for the buck X  being 20 ), while Nikon gets 300 ( X  X ang for the buck X  being 10 ), this allocation is unfair and may lead to Nikon to feel resentful.

Motivated by the above, we propose a new propagation model called K -LT by extending the classical Linear Threshold (LT) model [13] to capture the competitive aspect in viral marketing. Intuitively, propagation in our model consists of two phases. A node (user) is in one of three states: inactive , influenced ,or active . It adopts a product only in the active state. In the first phase, inac-tive nodes may become influenced (to adopt a product) as a result of influence coming in from their neighbors. In the second phase, an influenced node makes its choice to adopt one of the products (i.e., becomes active) based on the relative strengths of incoming influence for different products. The model is intuitive and retains the desired properties of monotonicity and submodularity.
We then define the fair seed allocation problem whose goal is to allocate seeds to the companies such that their amplification factors are as close to each other as possible, while the total expected num-ber of adoptions over all companies is maximized. The problem is NP-hard and we devise an efficient and effective greedy heuristic to tackle it. To summarize, we make the following contributions:  X  We study competitive viral marketing from a campaign host X  X   X  We define the problem of Fair Seed Allocation (FSA) and dis- X  We show that FSA under K -LT model is NP-hard ( X 4.1).  X  We develop an efficient heuristic algorithm, Needy Greedy ,a  X  We conduct extensive experiments on three real-world net-
The next section reviews necessary background and related work. In  X 6, we summarize the pap er and discuss future work.
Kempe et al. [13] modeled viral marketing as a discrete opti-mization problem, named influence maximization , and focusing on two fundamental propagation models: Independent Cascade (IC) and Linear Threshold (LT). In both models, we are given a directed social graph G =( V,E ) with edges ( u, v )  X  E labeled by influ-ence weights p u,v  X  (0 , 1] .If ( u, v )  X  E ,define p u,v given time step, each node is either active (an adopter of product) or inactive. An active node never becomes inactive. Initially all nodes are inactive, and at time 0 ,aset S of seeds are activated. In the LT model, the sum of incoming weights to v is no more than 1 . Each node v chooses a threshold  X  v uniformly at random from [0 , 1] . If at time t , the total weight from the active neighbors of at least  X  v ,then v becomes active.
 Given a propagation model (e.g., IC or LT) and a seed set the expected number of active nodes at the end of the process or the (expected) spread is denoted by  X  ( S ) .The influence maximization problem asks for a set S  X  V , | S | = k , such that  X  ( S mum, where k is an input parameter. Under both IC and LT models, the problem is NP-hard [13]. Kempe et al., however, show that the function  X  ( S ) is monotone (i.e.,  X  ( S )  X   X  ( T ) whenever and submodular (i.e.,  X  ( S  X  X  w } )  X   X  ( S )  X   X  ( T  X  X  w } whenever S  X  T ,and w  X  V \ T ). When equipped with such properties, the simple greedy algorithm that at each iteration greed-ily extends the current set of seeds S with the node w p roviding the largest marginal gain  X  ( S  X  X  w } )  X   X  ( S ) ,givesa (1 approximation to the optimum [13,17] (for any &gt; 0 ). After [13], considerable work has been done on developing more efficient and scalable influence maximization algorithms [5,6,9,10,16]. Competitive viral marketing. There have been some recent stud-ies on competitive viral marketing, by extending the IC or the LT model. A common theme among all of them is that they all focus on the client perspective as opposed to the host perspective.
Bharathi et al. [1] and Carnes et al. [4] study the problem from the  X  X ollower X  X  perspective X . The follower is the player trying to introduce a new product into an environment where a competing product already exists. Both studies show that the problem for the follower maintains the desired properties of monotonicity and sub-modularity and thus the greedy algorithm can be applied to provide approximation guarantees.

Kostka et al. [15] study competiti ve influence diffusions under a game-theoretic framework and show that finding the optimal strat-egy of both the first and second player is NP-Complete. Budak et al. [3] and Chen et al. [11] study the problem of influence blocking maximization, where one entity tries to block the influence propa-gation of its competitor as much as possible, under extended IC and LT models, respectively. Pathak et al. [18] propose an extension of the voter model to study multiple cascades. Borodin et al. [2] pro-pose extensions to the LT model to deal with competing products. Their work is also from the perspective of one of the competing players. As this work is the most related to our proposal, we present it in greater detail in the next section.
In this section we present the propagation model underlying our work and provide the problem statement. We first introduce our extended LT model (dubbed K -LT) that captures competition, and then provide conceptual justifications of the model. Then we high-light the difference between K -LT and the Weighted-Proportional Competitive (WPCLT) model by Borodin et al. [2]. Let K be the number of competing companies (or colors) 3 .Let C i and S i with i  X  X  1 , 2 ,...,K } , denote the i -th company and its seed set, respectively. Each node v  X  V picks an activation threshold  X  v uniformly at random from [0 , 1] . Initially, all nodes are inactive. At time 0 , for each color C i , a seed set
We use the two terms interchangeably. (with disjoint seed sets for different colors). This means that if u  X  S i ,then u becomes active with color C i at time 0 .
At any time t  X  1 , the activation of a node takes place in two phases. First, an inactive node v becomes influenced when the total incoming influence weight from its in-neighbors (denoted N in ( v ) ) which are active (regardless of colors) reaches time t ), v becomes active by picking a color out of those of its in-neighbors that activated at t  X  1 .
 Let A i t  X  1 denote the set of nodes that are active with color C i at the end of time t  X  1 and A t  X  1 denote the set of nodes that are active at the end of time t  X  1 , w.r.t. any color. Hence, v becomes active at time t with color C i with probabil-comes active, it remains active and will not switch colors. The diffusion process continues until no more nodes can be activated.
The K -LT model reflects several phenomena of competitive in-fluence propagation that match our daily experience as well as stud-ies in the literature. While the first phase models the threshold be-havior in influence propagation, as in the original LT model, the second phase incorporates the recency effect in the final decision among competing products. Indeed, it has been recognized in var-ious studies that influence decays very quickly in time, and thus customers are more likely to rely on recent information than on old information, when choosing which product to adopt [12,19,20]. Comparisons with the WPCLT model. In the WPCLT model [2], the first phase in which a node is influenced remains exactly the same as in K -LT. The difference lies in the second phase, i.e., the way in which newly influenced nodes decides the color to adopt. In WPCLT, a node v picks a certain C i with probability equal to the ratio between the total weight from the C i -active in-neighbors and that from all active in-neighbors. That is, all past exposure are accounted for adoption. Thus, v becomes active with color
To fully understand the difference between the WPCLT model and our K -LT, we first need to define the expected spread of in-fluence. Let S = { S 1 , ..., S K } be the set of seeds sets for the various colors, i.e., S corresponds to a seed set allocation. We use S S use  X  i ( S i , S  X  i ) to denote the expected number of active nodes, or the expected spread , w.r.t. C i , given seed set allocation the overall expected spread , denoted  X  all = def K i =1  X  to be the expected number of active nodes w.r.t. any color.
As we will show in Theorem 1 ( X 4.1),  X  i ( S i , S  X  i ) is monotone and submodular in S i under the K -LT model, while this property does not hold in WPCLT, which is somewhat counter-intuitive as noted by the authors that proposed it (cf. [2]). Indeed,  X  being non-monotone means that adding a new seed x to S i may pany expects the influence spread to go up when it increases its bud-get. These counter-intuitive phenomena stem fro m the possibility that a certain graph structure will allow the seeding of some nodes to trigger multiple  X  X ctivation attempts X  for seeds of a different company, which we show by an example below. For more detailed examples illustrating non-monot onicity and non-submodularity of the WPCLT model, we refer the reader to [2].
 E XAMPLE 1(A CTIVATION IN WPCLT). Consider Figure 1.
 Suppose that there are two colors with seed sets S 1 = { u } S 2 = { w } . Also suppose that  X  v and  X  x fall into the inter-val (0 . 5 , 1) . At time step 1, v becomes active w.r.t. color 2 (as p w,v =1 &gt; X  v ), while x remains inactive (as p u,x =0 . Subsequently, at time step 2, x first gets influenced as the total in-coming influence weight is now 1 . Then, x will activate w.r.t. color 1 with probability 0 . 5 and color 2 with probability 0 .
In this example, although u (in color 1 ) fails to activate step 1 , x may still adopt color 1 under WPCLT. The reason is that x gets additional influence from v which has color 2 ! Thus, seed-ing w for color 2 ends up  X  X elping X  the competitor color 1 : a second chance at activating x after failing at first. However, this phenomenon will not occur in K -LT: at time step 2, after getting in-fluenced, x will activate w.r.t. color 2 exclusively, with probability 0 . 5 / 0 . 5=1 .
We are ready to provide the formal problem statement of fair competitive viral marketing from the host perspective. We will fo-cus on the K -LT model hereinafter, unless otherwise specified. As-sume that there are K companies, as clients of the host H ing with similar products (one product each). Before the campaign anditisassumedthat b 1 + b 2 + ... + b K &lt; | V | . As its business model, H charges every company a fixed amount of money per requested seed, as well as surcharges proportional to the expected spread achieved. Before defining the problem, we first introduce the important notion of amplification factor .
 C
Intuitively, after receiving budgets from all companies, H allocate each company C i a seed set S i , | S i | = b i , such that (1) the overall influence spread,  X  all (Definition 1) is maximized, and (2) the expected influence spread across all companies is as  X  X al-anced X  as possible, i.e., the amplification factor of each company is as close as possible. Formally, we define the problem of com-petitive influence maximization from the host X  X  perspective, which consists of two subproblems, as follows.
 Given a directed graph G =( V,E ) with pair-wise edge weights, numbers b 1 ,b 2 ,...,b K  X  Z + with K i =1 b i  X | V | , select a seed set S  X  V of size K i =1 b i , such that  X  all is maximized.
A first observation is that, under both K -LT and WPCLT models, the first phase of activation follows the activation condition of the classic LT model. Therefore, we have the following proposition.
P ROPOSITION 1. Given a directed graph G =( V,E ) with edge weights, and K pair-wise disjoint subsets S 1 ,S 2 ,...,S V , then under both the K -LT model and the WPCLT model, letting S = S 1  X  ...  X  S K , we have
This implies that once a seed set S is given, no matter how it gets partitioned into K disjoint subsets,  X  all remains the same, i.e, is invariant under any K -partition of S . Another consequence of Proposition 1 is that under both K -LT and WPCLT models, Prob-lem 1 is equivalent to the original influence maximization under the LT model, and hence is NP-hard. By the same token, since  X  monotone and submodular, selecting the set of seeds S can be done using the classic greedy algorithm outlined in the introduction as for the original LT model, giving a (1  X  1 /e  X  ) -approximate so-lution to the optimum selection of seeds. In the rest of the paper, we assume that the seeds are selected in this way, and focus on their allocation to the companies.
 The goal of our second problem is to allocate seeds among the K clients such that the amplification factor of all companies is as close as possible, so as to maximize fairness. We have various op-tions to formalize this notion of  X  X o be as close as possible X . In the following problem statement and hereinafter we adopt as objective function to minimize the maximum amplification factor  X  max .In-tuitively, when the maximum amplification factor is minimized, it balances out all the amplification factors. We believe this min-max objective is a natural choice, as it is widely recognized and adopted in the literature of resource allocation and load balancing [14]. A discussion on several other alternatives is provided in  X 3.3. directed graph G =( V,E ) with pair-wise edge weights, numbers b ,b 2 ,...,b K  X  Z + ,aset S  X  V with | S | = K i partition of S into K disjoint subsets S 1 ,S 2 ,...,S K  X  S that | S i | = b i , i  X  [1 ,K ] , and the maximum amplification factor of any color is minimized.

Note that although the two problems are formulated separately, the host H needs to solve both in a sequential order to achieve its goals. In other words, the output of Problem 1, i.e., the union seed set S , is given as input for Problem 2.
Our goal while partitioning the seed set S is to make the am-plification factors as close as possible, so as to maximize the fair-ness. To achieve this goal, in Problem 2, we defined the objective function as minimizing the maximum amplification factor  X  One can offer similar alternative objective functions, while trying to achieve the same goal. For instance, one can ask for maximizing the minimimun amplification factor  X  min . Similarly, another ob-jective could be to minimize the difference  X  max  X   X  min ,orthe based on L 1 or L 2 norms. In general, the objective function based on which we may want to minimize. A comprehensive theoretical analysis of these various objective functions would be an interest-ing exercise, but it is not the focus of this paper. In the experiments section, we show that our algorithm performs well w.r.t. essentially all of these objectives.
Before we develop the algorithms for Problem 2, we take a deeper look in the properties of our K -LT model, which will allow us to characterize the complexity of FSA under K -LT and develop efficient and effective seed allocation algorithms.
We first show that the expected spread function for individual colors is monotone and submodular (Theorem 1) in the K -LT model. To prove this result, we employ a plot similar to the one in Kempe et al. [13], by establishing the equivalence between the LT model and a competitive version of the  X  X ive-edge X  model (Def-inition 3). This, importantly, will in turn help us derive a closed-form expression for the spread function (Theorem 2), which will play a pivotal role in the design of our algorithms and characteriz-ing the complexity of FSA: it is NP-hard in general (Theorem 3), but can be solved in polynomial time for K =2 .

We start by introducing the competitive live-edge model, by ex-tending the live-edge model defined in [13].
 Given a directed graph G =( V,E ) with edges labeled by influence weights, we can obtain a possible world X as follows. Each node v picks at most one of its incoming edges at random, selecting edge ( u, v ) with probability p u,v and selecting no edge declared  X  X ive X , while others  X  X locked X . By definition, incoming edges to nodes in the seed set S are blocked. We call a directed path a live-edge path if it consists entirely of live edges.
In a possible world X , we say a node is C i -reachable ,ifthere exists a live-edge path from a node in S i to v . Note that a node v has at most one incoming live edge, thus there is at most one live-edge path from S to v . Thus, the notion of color rechability is well-defined.

It is easy to see that the spread function under the competitive live-edge model is monotone and submodular. Clearly, each pos-sible world X is a deterministic graph. Let R X ( { u } ) be the set of reachable nodes from a particular node u on live-edge paths, in
X . Then the set of nodes reachable from S i is R X ( S i  X  submodular. Finally, the expected number of C i -reachable nodes according to the live-edge model, X Pr[ X ]  X | R X ( S i ) negative linear combination of monotone submodular functions, and thus is monotone and submodular (in S i ). Here, Pr[ X probability of the possible world X , which is determined by the choice of live/blocked edges. We now state the submodularity re-sult for K -LT:
T HEOREM 1. Under K -LT model, for any color C i ,theex-pected spread of influence  X  i ( S i , S  X  i ) is monotone and submodu-
P ROOF . We prove this result by establishing the equivalence be-tween the K -LT model and the competitive live-edge model (Defi-nition 3). We show : Given K colors and their corresponding seed two distributions over sets of nodes are equivalent : (1) The distri-to completion from S 1 ,S 2 ,...,S K , and (2) The distribution over sets of C i -reachable nodes according to the live-edge model. The theorem follows from this claim. We next prove the claim. If a node v has not become active after time step t , then the probability that it becomes C i -active at t +1 is 1 where the former quantity is the probability that v becomes active at t +1 , and the latter is the probability that v adopts color given that v gets activated.
For the competitive live-edge model, we start the  X  X each-out X  process with seed sets S 1 ,S 2 ,...,S K . In the first stage, if a node v  X  X  selected live-edge is incident on S i ,then v is C i -reachable general, let A i t denote the set of nodes which are found to be C obtain sets A i 2 ,A i 3 ,... . Similarly, we can also obtain sets t =1 , 2 , 3 ,... , which represent the set of nodes reachable from S  X  S 2  X  ...  X  S K in stage t . Now, if a node v has not yet been deter-mined C i -reachable by the end of stage t , then the probability that v will be determined C i -reachable at stage t +1 is the chance that Given that, the probability that v proceeds to become C i -reachable will be determined to be C i -reachable at stage t +1 , given that it is not already so determined, is u  X  A
Applying induction on time steps (stages), it is easy to see that the distributions over A i t and A i t are identical, and the same holds for A t and A t ,  X  t . This was to be shown.
 Closed-form expression for  X  i ( S i , S  X  i ) . We first introduce the needed notation. By virtue of the equivalence shown in Theorem 1,  X  ( S i , S  X  i ) is equal to the expected number of C i -reachable nodes under the competitive live-edge model. Let X be a possible world. For simplicity, we write V  X  S for V \ S and V  X  S + u for (
V \ S )  X  X  u } hereinafter. With node-sets as superscripts, we denote the corresponding induced subgraph: e.g.,  X  W LT ( S ) ,where V , denotes the expected spread of the seed set S in the subgraph of
G induced by the nodes W . When there is no superscript, the entire graph G is meant by default.

We now derive the closed-form expression by establishing con-nections to the classical LT model. Let I V  X  S  X  i X ( S cator function which takes 1 if there exists a node s in S from s to v , in a possible world X for the subgraph of G on sible world X . Then, because any live-edge path from any node u  X  S i to v must not go through any node w  X  S  X  i , as all incom-model (in other words, it has the effect of removing nodes in from G and hence from the possible world X ), we have S v in the subgraph induced by V  X  S  X  i .Since S i is the seed set active on the corresponding subgraph. Note that the indicator func-tion depends only the seed set S i and the subgraph W , and not on the seeds for other colors. Therefore,  X  W S i ,v is equal to the prob-ability that v is activated in the subgraph induced by V  X  S under classical LT model , with seed set S i .
 Adjusted marginal gain. Next, we introduce the notion of ad-justed marginal gain ,whichis key to solving Problem 2. S of seeds, for any u  X  S ,the adjusted marginal gain of u ,de-induced by V  X  S + u under the classical LT model. That is,  X 
Consider the example in Fig. 2. Suppose S = { u 1 ,u 2 } is the seed set. Then, one can verify that  X  u 1 is the expected spread of on graph consisting of u 1 and u 3 only, which is 1+0 . 3=1
Next, we show the following useful result for the K -LT model, which says that given a set of seeds S selected by the host, the ex-pected spread for company C i only depends on the seeds S cated it, and not on how the remaining seeds S  X  S i are distributed among the other companies.

T HEOREM 2. Consider an allocation of seed sets, where the seed set S i  X  S is assigned to company C i and the remaining by
P ROOF (T HEOREM 2). Consider the right hand side of the equation. Since S is the set of all seeds, that is, S = S have by Definition 4, given seed set { u } , on the subgraph induced by the nodes S  X  i  X  S + u , under LT model. We next make use of the proof of Theorem 1 of [10]. There, it is shown that, under LT model,  X   X  the subgraph induced by the nodes W  X  S i + u .Let W = V  X  S then by switching the summations and applying this result, we get
From the equivalence with the live-edge model, and Eq. 4, the theorem follows.

Consider again the example shown in Fig. 2. Suppose there are two companies with S 1 = { u 1 } and S 2 = { u 2 } . Then,  X  ( S 1 , S  X  1 )=  X  u 1 =1 . 3 . Similarly,  X  2 ( S 1 , S  X  Also, note that  X  all =  X  LT ( { u 1 ,u 2 } )=2 . 8 .
Having established the notion of adjusted marginal gain, we are ready to prove the complexity of Problem 2 (Fair Seed Allocation). T HEOREM 3. The Fair Seed Allocation problem under the K -LT model is NP-hard.
 P ROOF . We prove the theorem by reduction from 3-PARTITION [7]. In 3-PARTITION, we are given a set A of 3  X  m elements, and a size s ( a )  X  Z + for each element. Let Y be the sum of sizes of all elements, i.e., Y = a s ( a ) , then the question is whether there exists a partition of A disjoint subsets A 1 , ..., A m , each with exactly 3 elements, such that the sum of sizes of elements in each subset is the same, i.e., a  X  A i s ( a )= Y/m . This problem is known to be strongly NP-hard [7]. Recall that a problem is strongly NP-hard if it remains NP-hard even when the numerical parameters of the problem are bounded by a polynomial of the input size. In the context of 3-PARTITION problem, it implies that the problem remains NP-hard even when Y is bounded by a polynomial in
Let I be an instance of 3-PARTITION. We reduce it to an in-stance J of FSA as follows. Create m companies, and for each element a  X  A with size s ( a ) , create a seed u a in instance its adjusted marginal gain set to  X  u a := s ( a ) . Set the seed budget of each company to 3 . Suppose there exists a polynomial time algo-rithm A that provides an optimal solution to FSA. Then by running this algorithm on instance J and checking whether the maximum amplification factor is exactly Y/ 3 m or not, we can separate the YES-instances from the NO-instances of 3-PARTITION, which is not possible unless P = NP.

Above, we performed the reduction entirely in terms of adjusted marginal gains, instead of creating a graph, which is a required input to FSA. It is easy to create an input graph whose seed nodes u disjoint trees, each rooted at a node u a . The root u a has exactly s ( a )  X  1 children, with influence weights on all edges set to 1 . Since the trees are disjoint,  X  u a = s ( a ) . Notice this reduction is polynomial time in m since Y is a polynomial in m .

When K =2 , the FSA problem resembles the PARTITION problem, which is weakly NP-hard and admits an exact dynamic programming algorithm in pseudo-polynomial time. We can adapt it to solve FSA. In our case, the dynamic programming algorithm (See  X 4.3) is truly polynomial in the size of the input, since the number of nodes is a natural bound on all adjusted marginal gains.
Suppose there are K companies approaching a host for running a competitive viral campaign and each company C i specified a seed How can the host effectively find seeds and allocate them to the K companies? As pointed out by Proposition 1 , the host can se-lect B seeds using the classic greedy algorithm. Let S be this set. The real challenge is in fi nding a good pa rtition of S into disjoint minimizes the maximum amplification factor. Given the hardness result above, a natural question is whether we can devise efficient heuristic algorithms that work well in practice. In this section, we develop an algorithm called Needy Greedy ( NG for short), which works for any K . Later, in  X 4.4, we will give an algorithm based on dynamic programming, for K =2 .

The Needy Greedy algorithm takes advantage of Theorem 2, which says that given the set S of seeds, the expected spread of C marginal gains of the seeds in S i in appropriate subgraphs. Thus, we first find all seeds S using the classic greedy algorithm. Then we determine the adjusted marginal gains  X  u of the seeds (Defini-tion 4) and keep seeds sorted in non-increasing order of the gains. Algorithm 1: N EEDY -G REEDY ( NG )
Input : S (with  X  u ,  X  u  X  S )and b i ,  X  i  X  X  1 ,...,K }
Output :A K -partition of S , with | S i | = b i ,  X  i .
Initialize S i =  X  ,  X  i ; for each u  X  S do 3 T  X  X  i | i  X  X  1 , 2 ,...,K } , | S i | &lt;b i } ; 5 S j  X  S j  X  X  u } ;
Needy Greedy (Algorithm 1) takes as input the seeds with ad-justed marginal gain sorted In addition, it is given the budgets of various companies. It starts by initializing all seed sets empty (line 1). Then, we process each seed u  X  S (line 2). Let be the set of of companies for which the budget has not yet been seed only to such companies. In line 4, we find the company which has the least amplification factor. Finally, we add the seed to deal with other objective functions ( L p -norms) for FSA. Time complexity. The time complexity of NG is O ( B log K as there are | S | = B iterations, in each of which the algorithm examines each company to determine i  X  . Using a min-heap, we can perform the search and update in O (log K ) time.
In the special case of K =2 (only two competing companies), the FSA problem can be solved exactly by a dynamic programming ( DP ) algorithm in polynomial time 4 . Also note that when can also be shown that the minimizing the objective function based on the L p -norm,  X  p  X  1 (Eq. 3), is all equivalent to minimizing the maximum amplification factor .

FSA with K =2 resembles the partition problem ,inwhich we are given a collection of positive integers, and the question is whether there exists a partition of two subcollections such that the sum of elements in the two subcollections is the same. While there is some similarity among the two problems, FSA comes with car-dinality constraints, in the form of seed set budgets. In addition, while the partition problem involves integers, FSA involves ad-justed marginal gains of seeds which are real numbers, and thus we should pay attention to precision.

The dynamic programming algorithm is set up as follows. First, let the seed set be S = { u 1 ,u 2 ,...,u B } (recall B = and let S j denote the  X  X artial X  seed set { u 1 , ..., u j { 1 , 2 ,...,B } . Then, we define P ( j,  X , )= 1 , if  X  Q  X  S j : | Q | = and  X  1 ( Q, S j  X  Q Here j keeps track of the horizon, i.e., which seeds from been explored; is the size of a seed set Q , such that with cated to C 1 and S j  X  Q allocated to C 2 ,  X  1 ( Q, S j  X  Q  X  . The size of Q is bounded by b 1 , the budget of C 1 .
Since  X  represents the spread, it virtually can take any real value in [1 , X  all ] . To keep the DP table size finite, we can round the spread  X  at any level of precision desired. E.g., if we want preci-sion up to two decimal places, all we need to do is amplify all real numbers involved in the calculation, namely the adjusted marginal gains  X  u and the spread  X  by 100 and round all results to the nearest
For any fixed precision of the real numbers involved. integer. In the rest of this section, we assume some fixed precision and that the appropriate amplification and rounding are done. Dynamic programming formulation. Notice that there is a subset of
S j of size , which when allocated to C 1 , yields the spread if and only if one of the following is true: (1) There is a subset of Q  X  S j  X  1 of size , which when allocated to C 1 , yields spread  X  ; or (2) There is a subset of S j  X  1 of size  X  1 , which does not give spread  X  for C 1 itself, but will if we add u j to C More formally, P ( j,  X , )=1 if P ( j  X  1 , X , )=1 ,or P ( 1 , X   X   X  u programming equation:
P ( j,  X , )=max { P ( j  X  1 , X , ) ,P ( j  X  1 , X   X   X  u with the base case P (1 , 0 , 0) = 1 .

Notice that, in the ideal partition, the spread of C 1 would be exactly Z = b 1 B  X   X  all . This is the best possible allocation w.r.t. minimizing maximum amplification factor. Thus, after the entire DP table is populated, to obtain the partition, we can set our target be the number t obtained by amplifying and rounding the number as outlined earlier. Modulo our precision, if P ( B,t,b 1 we have found this ideal partition; if not, find the number that P ( B,t ,b 1 )=1 and | t  X  t | is minimized. This represents the optimal solution at the chosen level of precision.
 Time complexity. From the ranges for j ,  X  ,and , the size of the Note that typically, b 1 and b 2 are much smaller than | V | implementation, we apply a couple of optimizations. First, there is no need to populate cells with &gt;j , Second, if  X &lt; X  u no need to examine the second argument in the RHS of the dynamic programming equation.
To evaluate the effectiveness of our proposed algorithms ( NG and DP ) developed for FSA and compare them with several base-lines, we conduct simulations on three real-world networks  X  Epin-ions , Flixster ,and NetHEPT . Table 1 presents the statistics of the datasets. We use the classic greedy algorithm to select the union seed set S , and following Kempe et al. [13], 10 , 000 iterations of Monte Carlo (MC) simulations are run to estimate influence spread. This is an expensive step and limits the size of the graph we can work on. The scale can be extended by using scalable heuristic al-gorithms for the LT model [6, 10], but this is not the focus of our experiments, which is on testing seed allocation algorithms. Imple-mentations are in C++ and all experiments were run on a Windows 7 machine with 2 . 66 GHz Intel i5 CPU and 6GB RAM.
 Preparation of datasets. We use models in [8] to compute edge weights. For Epinions, we apply both the Bernoulli and Jaccard models and then normalize the weights. In Bernoulli, the influence weight on edge ( u, v ) is calculated as p u,v = A u 2 v /A A is the total number of actions u performed. In Jaccard, p A 2 v /A u | v where A u | v is the number of actions either performed. After computing these weights, we normalize them to ensure that the sum of incoming weights to any node is 1 . NetHEPT is a collaboration network from the High Energy Physics Theory section on arXiv.org with nodes representing authors and edges representing co-author relationships. We calcu-papers u and v co-authored. Flixster is a friendship network from Table 2: Test cases with varying budget distribution. (N,F): NetHEPT &amp; Flixster. (E): Epinions.
 social movie site Flixster.com ,forwhich A u,v is the num-ber of movies rated by both u and v . In both datasets, N normalizing factor to ensure the sum of weights incoming to Baselines. We compare our algorithms with two simple baselines: Random and Alternating .In Random , seeds are assigned uni-formly at random to different companies (with budget constraints obeyed). The Alternating heuristic first fixes a random permuta-tion of the K companies, and then allocates seeds to the companies in a round-robin fashion according to that order.
 Competition settings. We vary K , the number of competing enti-ties, to be 2 , 3 and 6 . For NetHEPT and Flixster, we take 60 seeds, while for the much larger Epinions dataset, we take 30 seeds so that MC simulations can finish within a reasonable amount of time ( 48 hours). The budget distributions we choose to test are summarized in Table 2. For instance, for K =3 , we consider  X  X qual budgets X  cases, where each company has a budget of 20 (on NetHEPT and Flixster) or 10 (on Epinions). Likewise, we also consider  X  X nequal budgets X  cases where the three companies have budgets of 10, 20 and 30 (on NetHEPT and Flixster) or 5, 10 and 15 (on Epinions). We believe these various cases are representative.

After the seeds are chosen, we compute the adjusted marginal gain of all seeds (Definition 4), whose statistics are presented in Table 3. As can be seen, the variance is much larger in both Epin-ions graphs than in NetHEPT and Flixster. Especially, NetHEPT has the most concentrated values. We run NG , Random ,and Al-ternating for all settings, and also DP for the cases of K Evaluation metrics. To compare accuracy (i.e., quality of par-tition), we obtain the maximum amplification factor (denoted by  X  max ) output by the algorithm and calculate its relative error w.r.t. the theoretical lower bound  X  all /B (in which case the allocation is perfectly fair, with every company having the same amplification factor). The relative error is defined as follows.
 By definition, it is nonnegative as  X  max  X   X  all /B always holds:  X  all /B is the average spread-to-budget ratio, while  X  max is the maximum ratio in a solution.
 Comparing relative errors. The relative errors of the maximum amplification factor achieved by NG , Random and Alternating the X-axis, 2(eq) refers to the setting of K =2 , budgets equal, while (neq) refers to unequal budgets.
 solutions are illustrated in Fig. 3. As can be seen, NG consistently outperform the two baselines, achieving significantly smaller errors in all cases. In fact, the errors of NG never exceed 5 . 1% in all cases. By contrast, the errors by Random and Alternating can be as bad as 59 . 8% and 48 . 8% , respectively.

In most of the cases when K =2 or 3 , the error by NG is un-der 2 . 0% .Thelargest NG error is 5 . 02% , observed on Epinions (Jaccard) with 6(eq) , while the smallest is 0 . 01% , achieved on NetHEPT with 2(eq) , in which case Random ( 5 . 5% )and Al-ternating ( 1 . 4% ) both have errors two orders of magnitude larger. As another example, on Epinions (Bernoulli) with 6(neq) , NG , Random ,and Alternating have an error of 1 . 83% , 35 . 7% ,and 43 . 9% , respectively. These results straightaway establish the effec-tiveness of our Needy Greedy algorithm.
 A deeper look into NG solutions. We graphically summarize the amplification factors using the box-and-whisker diagram in Fig. 4. In the plot, a box (shown in color blue) represents a subset of the data points from the lower quartile to the the upper quartile. The red line inside the box is the median. Two black bars outside the box correspond to the minimum and maximum, and a red plus sign means the extremum could be considered as an  X  X utlier X . Intu-itively, the more  X  X ompressed X  the box is, the more balanced the partition is. The green line i s the theoretical lower bound,
As can be seen from Fig. 4, in all cases, the difference between maximum amplification factor  X  max and the minimum amplifica-with 6(eq) ,  X  max  X   X  min =24 . 8 (or 7 . 8% of  X  min ,which is 318 . 4 ). Similarly, on NetHEPT and Flixster, with 6(neq) ,  X  max  X   X  min is 0 . 72 ( 2 . 7% of  X  min )and 3 . 56 ( 4 . respectively. We also observe that the error tends to enlarge when K increases. Besides, the difference is relatively higher for Epin-ions, and we believe this is because the size of the whole seed set is small (which is 30, compared to 60 on other datasets). Dynamic programming. We next consider the special case when only two companies compete ( K =2 ). The DP algorithm, being theoretically optimal, must produce the best partitions, and as ex-pected, its accuracy is better than NG : the relative errors are very close to zero on all datasets, as shown in Table 4. For instance, on NetHEPT with 2(eq) , DP (with precision up to two decimal places) achieves an error of 0 . 0004% , while NG achieves 0 Table 4: Relative error of the maximum amplification factor for Dynamic Programming (with precision up to 2 decimal places) For the same case, if the precision drops to one and zero decimal place, the error increases to 0 . 007% and 0 . 23% , respectively. The trend is similar for other cases, and hence we omit them here. Running time. The running time of DP is reasonable: it finishes within 1 . 2 seconds in all cases. NG is three orders of magnitude faster, completing within 5 millis econds in all cases, while produc-ing allocations with quality comparably close to those of DP . Ran-dom and Alternating have similar running time as NG  X  X . We also note that all algorithms require adjusted marginal gains as input, whose computational overhead, however, is much smaller com-pared to the greedy algorithm for selecting seeds. For example, on Epinions (Jaccard), computing adjusted marginal gains for all seeds takes only 3 minutes , compared to 48 hours taken by the greedy algorithm to select 30 seeds.
 Extended results: NG with L p -norms. As mentioned in  X 3.3, the fair allocation objective can also be defined using the (Eq. 3). Our algorithm NG is easily extensible to L p -norms. The adapted NG iterates through every seed, and in any iteration it assigns the seed to the company whose deviation |  X  i (  X   X  all | p is the largest among those with budget not yet exhausted. Here  X  i ( S i , S  X  i ) is the value by the end of iteration power function is monotone, 5 the allocation choice made by NG is essentially the same for all p , and thus it suffices to test only
In Fig. 5, we compare the objectives of using L 1 -norms and of using  X  max 6 . When the budgets are equal, NG with both objec-tives has exactly the same performance, but when the budgets are unequal, NG does better on minimizing the maximum amplifica-tion factor than it does on minimizing the L 1 -norm. For instance, on Epinions (Bernoulli) with 6(neq) , the relative error (Eq. 6) is 1 . 8% and 4 . 4% for the  X  max and L 1 -norm objectives, respectively. It implies that our choice of objective function, which is minimiz-ing the maximum amplification factor, is a better one.

In sum, we have demonstrated the effectiveness and efficiency of our proposed algorithms ( NG and DP ) for the FSA problem. We show that NG , while not optimal, produces partitions comparable to those by DP , with very small errors, and it is significantly better than the Random and Alternating baselines. We also show that NG performs reasonably well for various other objective functions.
Note that it X  X  the absolute value that is raised to power
We only show results on two Epinions graphs with K =3 and 6 ; the results for other cases are similar, and hence omitted. (c) Epinions (Jaccard), K =3 (d) Epinions (Jaccard), K =6
Influence maximization has received significant attention re-cently. However, there is a gap between this problem and real-world viral marketing, and we believe this paper takes a step to-wards closing this gap by studying influence maximization under a more realistic setting, in which: (i) there is competition, and (ii) the network is owned by a host as in real life, and the competing companies cannot just autonomously set up their campaigns, but have to buy viral marketing as a service from the host.
We posed the novel problem of Fair Seed Allocation in which the host must allocate influential users to competing companies to guarantee  X  X he bang for the buck X  for the competitors is as balanced as possible. We proved that the problem is in general NP-hard, and developed two algorithms for it: Needy-Greedy and dynamic pro-gramming (for the case of two companies). We performed simu-lations on real world networks and showed that our algorithms are both effective and efficient.

Investigation of competitive influence propagation and fair seed allocation under other propagation models (e.g., in which the viral-ity of different products may vary), other business models for the host and for the companies, and game-theoretic aspects are three examples of many fruitful directions for further research. Acknowledgments. This research is supported by a grant from the Business Intelligence Network (BIN) of the Natural Sciences and Engineering Research Council (NSERC) of Canada, and also in part by the Institute for Compu ting, Information and Cognitive Systems (ICICS) at the University of British Columbia.
