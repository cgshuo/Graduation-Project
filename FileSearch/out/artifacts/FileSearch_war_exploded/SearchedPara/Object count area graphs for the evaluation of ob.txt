 ORIGINAL PAPER Christian Wolf  X  Jean-Michel Jolion Abstract Evaluation of object detection algorithms is a non-trivial task: a detection result is usually evaluated by comparing the bounding box of the detected object with the bounding box of the ground truth object. The commonly used precision and recall measures are computed from the overlap area of these two rectangles. However, these mea-sures have several drawbacks: they don X  X  give intuitive infor-mation about the proportion of the correctly detected objects and the number of false alarms, and they cannot be accu-mulated across multiple images without creating ambiguity in their interpretation. Furthermore, quantitative and quali-tative evaluation is often mixed resulting in ambiguous mea-sures.
 les these problems. The performance of a detection algo-rithm is illustrated intuitively by performance graphs which present object level precision and recall depending on con-straints on detection quality. In order to compare different detection algorithms, a representative single performance value is computed from the graphs. The influence of the test database on the detection performance is illustrated by per-formance/generality graphs. The evaluation method can be applied to different types of object detection algorithms. It has been tested on different text detection algorithms, among which are the participants of the ICDAR 2003 text detection competition.
 Keywords Evaluation  X  Object detection  X  Text detection 1 Introduction In the past, computer vision (CV) as a research domain has frequently been criticized for a lack of experimental culture [ 4 , 8 , 10 , 17 ], which has been explained by the young age of the discipline. However, experimental evaluation of the the-oretical advances is indispensable in all scientific work. We are currently trying very hard to establish a real experimen-tal culture, and the need of strict experimental procedures in applying and evaluating algorithms is widely recognized [ 16 , 17 ].
 databases and ground truth, which makes the comparison of different algorithms difficult. In some areas common test databases did emerge, as for instance the Brodatz test database for texture analysis, the NIST database for charac-ter recognition etc. However, the tuning of image processing algorithms to a small set of test databases is not undisputed. As Bowyer et al. put it [ 4 ],  X  the world is rich enough to pro-vide infinitely interesting imagery . X  ciplines, scientific competitions made their appearance dur-ing the last years. We may cite for example the TREC Video Track, 1 a competition in the field of content based video in-dexing organized by NIST and held annually. The goal of the conference series is to encourage research in informa-tion retrieval from large amounts of text and video sequences by providing a large test collection, uniform scoring proce-dures, and a forum for organizations interested in comparing their results. The test collections are changed each year in order to avoid specialization to a single test database. segmentation competitions [ 3 ], the ICDAR text detection competitions [ 13 ] and the GREC competition for line and arc detection [ 21 ] should be mentioned (see Sect. 3 ). largely with the emergence of the field of visual information retrieval. As a consequence, the first techniques have been naturally inspired by tools from this domain, as for instance precision/recall graphs which are frequently used in infor-mation retrieval. However, visual information has its own specificities, which need to be taken into account. This is the goal of this work.
 more specifically on the design of evaluation measures. Evaluation is a process which is often neglected by scien-tists, who spend most of their valuable time conceiving the-ories and designing solutions. However, in computer vision, a successful evaluation algorithm is rarely simple to design. Often it is necessary to conceive non-trivial algorithms in order to ensure an evaluation satisfying scientific require-ments:  X  A simple and intuitive interpretation of the obtained  X  An objective comparison between the different algo- X  A good correspondence between the obtained measures The latter point is particularly important. Aloimonos and Rosenfeld emphasize the purpose in CV [ 1 ]:  X  If we con-sider biological organisms that possess vision, we find that the visual system tends to be well matched to the environ-ment of the organism and to the tasks that the organism per-forms. The paradigm purposive vision suggests that pur-pose should be a guiding principle in our study of vision . X  If we design CV systems according to a specific purpose, then it should be natural that we evaluate their performance ac-cording to this same purpose. This is the objective of  X  X oal oriented evaluation. X  ready given birth to a multitude of solutions is the problem of detecting objects in images. In this document, we intro-duce a new performance measure designed for the evaluation of object detection algorithms. In this context, by detection we also mean localization, thus tackling a two-part problem. We keep the general evaluation framework independent of the object type, defining an object as a visual entity with a spatial reality, and illustrate the concepts with experiments and examples from the field of text detection.
 problem is the one of document page segmentation. As in object detection, or more specifically in text detection, lists of rectangles need to be compared in order to evaluate these algorithms. However, although the two evaluation problems may be similar from a theoretical viewpoint, practically we need to emphasize some differences between page segmen-tation and text/object detection:  X  The density of relevant information ( X  X enerality X , see  X  In the page segmentation context, regions are possi-The second point restricts the proposed evaluation systems to objects which are well represented by rectangles, which is the case for text, faces, people, generally speaking, com-pound objects. We therefore focus on these kind of prob-lems, which are mostly encountered when evaluating sys-tems working on natural scenes and video, but also systems which extract text from complex journals.
 encountered in document image analysis, notably curves as lines and arcs. These objects may overlap, therefore a single rectangle may contain several objects. While the general phi-losophy of the proposed system is applicable, i.e., the sep-aration of detection quality and quantity and its representa-tion as graphs, the object matching part itself is restricted to rectangle based representations.
 ing issues:  X  The separation of detection quality and detection quan- X  The influence of the data base is evaluated, i.e., the rela- X  The derivation of a single performance value which does The reminder of this document is organized as follows. Section 2 gives an introduction to the problem and presents different evaluation modes on a hierarchy of different levels, which is formed by the different possible result represen-tations. Section 3 presents a survey on the previous work on the evaluation of object detection algorithms. Section 4 introduces new performance graphs for an easy and intu-itive interpretation of the detection performance as well as a new performance measure. Section 5 demonstrates the de-pendence of evaluation algorithms on the structure of the test database and introduces a new evaluation graph which illustrates this dependence. Section 6 applies the evaluation measure to two different text detection algorithms and illus-trates its intuitive usage. Finally, Sect. 7 concludes. 2 Evaluation levels Traditionally, object detection algorithms are evaluated us-ing techniques developed for information retrieval systems. More specifically, the measures of precision and recall are widely used, since they intuitively convey the quality of the results: R P In order to have a single performance value for the ranking of methods, the two measures are often linearly combined. The harmonic mean of precision and recall has been intro-duced by the information retrieval community [ 19 ]. Its ad-vantage is that the minimum of the two performance values is emphasized: Perf IR = 2 For the object detection problem, the measures of recall and precision are not directly applicable, since the decision whether an object has been detected or not is not a binary one. Object detection algorithms may be evaluated at dif-ferent levels w.r.t. the representation of the detection results, corresponding to different phases of the detection algorithms (see Fig. 1 ). The evaluation measures of the different levels differ in their relevance to the goal of the application and in their coverage, i.e., in the detection phases which are evalu-ated by the measure:  X  Feature discriminance at pixel level :Atthislevel,the  X  Classification at pixel level : Once the classification de- X  Detection at rectangle level : From the end user X  X  point of  X  Goal oriented evaluation : In many applications, object The evaluation level to choose depends on the application and the purpose of the evaluation. The pixel based evalu-ation measures are easy to calculate and easy to interpret. However, they lack relevance to the goal of the process and are not very accurate. Very often they are used to guide the choice of features used for detection, since they are not in-fluenced by later steps of the detection algorithm. ploy for the final evaluation of the algorithm X  X  performance. They directly measure the success which can be expected by the algorithm. However, very often the localization of the object is the final goal of the application. For instance, in the case of face detection or text detection, recognition of the object might be impossible because of low data quality. In image and video indexing applications, the presence of a face or of text is valuable information which can be ex-ploited. In this context, goal directed evaluation is equivalent with evaluation on rectangle level (Fig. 1 c).
 and easy to interpret, since they treat  X  X tems X  which are directly comparable (pixels and characters, respectively). On the other hand, rectangle based evaluation (level (c)) is a non-trivial task: as the detection result is rarely exactly equivalent to the object as specified in the ground truth, we cannot easily say whether an object has been correctly de-tected or not. In the reminder of this work, we concentrate on the problem of evaluation on rectangle level. 3 Previous work The goal of a rectangle based object detection evaluation scheme is to take a list G of ground truth object rectangles G , i = 1 ,..., | G | and a list D of detected object rectangles D between the two lists. The quality measure should penalize information loss, which occurs if objects or parts of objects have not been detected, and it should penalize information clutter, i.e., false alarms or detections which are larger than necessary. 2 and precision measures which are calculated on the area of two rectangles G i and D i and on the area of the overlapping region: R P Recall illustrates the proportion of the ground truth rectangle which has been correctly detected, and precision decreases if the amount of additional incorrectly detected area increases. In the reminder of this work, we call these measures  X  X rea recall X  and  X  X rea precision, X  respectively.
 sult and ground truth rectangles is straightforward, the ex-tension to the realistic case of two lists of rectangles is not as easy. The existing evaluation methods differ in the way they treat the correspondence problem between the two rect-angle lists, i.e., whether they consider single matches only or multiple matches, and in the way they combine the figures in order to generate a single measure for multiple rectangles and multiple images. and evaluation system with a graphical java interface [ 5 ]for video segmentation. Their system also takes into account temporal matching of objects in videos and provides differ-ent temporal matching levels. However, the spatial matching algorithms supported by the tool are rather simple. measures, among which are the area measures on rectan-gle bases given in Eq. ( 5 ) as well as measures on pixel level. Several extensions to multiple rectangles are sug-gested: summing up thresholded values of these measures, which introduces a dependence on a threshold, and directly calculating the measures on sets of rectangles by combining the rectangles to larger surfaces, which gives rise to ambigu-ity problems (see Sect. 4 ).
 comparing lists of rectangles [ 2 ] in the context of document page segmentation. Each ground truth rectangle or poly-gon is extended up to the borders of the surrounding rect-angles or the page border and checks whether segmented rectangles fall into these  X  X aximized ground truth poly-gons. X   X  X artial misses, X   X  X isses X  and  X  X erges X  are consid-ered. However, this approach may pose problems in the case of text/object detection, where there are not always surrounding text/object rectangles. Furthermore, the evalu-ation algorithm focuses on reporting the accuracy the de-tection/classification of each rectangle, the authors do not provide performance measures for a whole document.
 the systems participating at the text locating competition in the framework of the 7th International Conference on Doc-ument Analysis and Recognition (ICDAR) 2003 [ 13 ]. Each rectangle in one list is matched with the best match in the opposing list: R P where BestMatch G and BestMatch D are functions which de-liver the quality of the closest match of a rectangle in the opposing list:
BestMatch G ( G i ) = max BestMatch D ( D j ) = max If a rectangle is matched perfectly by another rectangle in the opposing list, then the match functions evaluate to 1, else they evaluate to a value &lt; 1. Therefore, the original measures taken from the information retrieval community, given by ( 1 ), are upper bounds for the new measures given by ( 6 ). Both, precision and recall given by ( 6 ), are low if the overlap region of the corresponding rectangles is small.
 only one-to-one matches are considered. However, in real-ity sometimes one ground truth rectangle is  X  X plit X  into sev-eral object rectangles or several ground truth rectangles are  X  X erged X  into a single detected object rectangle. This is a problem the authors themselves report in [ 13 ]. The prob-lem is generally encountered in detection evaluation frame-works, which is due to the fact that we are interested in eval-uating the solution of a detection problem but the ground truth is specified as the  X  X orrect X  solution of a segmenta-tion problem. However, an over-or under segmented solu-tion may very well be a correct detection.
 ment structure extraction algorithms [ 12 ]. From the two lists G and D of detected rectangles and ground truth rectan-gles, they create two overlap matrices  X  and  X  . The lines i = 1 ,..., | G | of the matrices correspond to the ground truth rectangles and the columns j = 1 ,..., | D | correspond to the detected rectangles. The values of these matrices cor-respond, respectively, to area recall and area precision be-tween the row rectangle G i and the column rectangle D j :  X   X  Matching rectangles is done by thresholding the values in the two matrices and clustering them into groups. Differ-ent match types are supported: one-to-one matches, one-to-many matches (splits) and many-to-one matches (merges). See Fig. 2 for an illustration of these concepts.
 They introduce two measures:  X  X etection quality X , which re-lates to recall, and  X  X alse alarm rate X  which relates to (1-precision). However, each measure is calculated as product of two factors: a factor which depends on the surface ratios X  X imilar to the ICDAR solution X  X nd a factor which measures the rectangle fragmentation. The latter factor de-creases in the case of splits and merges.
 difficulty value, which is estimated from the ground truth image. It takes into account the rectangle size and the vari-ance of the character height. The overall detection perfor-mance is weighted by a detection importance value, which is part of the ground truth.
 segmentation contest [ 3 ] is based on the same principles as Liang X  X  method. The overlap matrices (they call them  X  X atchScore tables X ) are used to match ground truth enti-ties to detected entities, where an entity (i.e., a region) may contain text, graphics, line-art, a separator or noise, which makes an adaptation of the overlap matrices necessary in or-der to evaluate the classification of each region. Splits and merges are supported. For each match, a performance value is calculated as the harmonic mean of a recall type measure and a precision type measure. The global performance value for all entities is a computed as a weighted sum of the indi-vidual scores.
 other rectangle methods described above, in particular to Liang X  X  method, the difference being the evaluation of the region type classifier and some details in the computation of the recall and precision measures. However, it suffers from the same drawbacks: the lack of intuitivity and the ambigu-ity of the response due to the mixture of detection quality and detection quantity.
 not based on the overlap information [ 11 ]: they consider a pair of detected/groundtruth rectangles as matching if and only if the centroid of one rectangle is contained in the other rectangle. Although this solution is tempting since it avoids the usage of parameters, it tends to accept matches with very low area recall and/or precision and it does not give an in-formation on the quality of the detection.
 (GREC) competitions, algorithms for the detection of lines and arcs are evaluated. Although these graphics objects are different from rectangles, the proposed evaluation algo-rithms do share common features with the algorithms de-signed for rectangle matching. In [ 21 ], the GREC organizers describe two evaluation types, one on pixel level and one on vector level. The latter matches lines and arcs by compar-ing their endpoints and placing thresholds on the distances between these endpoints and the curves. For each matching pair of line/arc segments, a complex quality measure is pro-posed, which combines measures of endpoint distance, line overlap, line with quality, line style quality and line shape quality. For the ensemble of lines and arcs these measures are combined in order to form two classical measures: vec-tor detection rate, which corresponds to a sort of recall mea-sure, and vector false alarm rate, which relates to a sort of precision measure. rithm combines detection quality and detection quantity in a single measure, which makes it hard to understand the be-havior of the algorithm to evaluate. Furthermore, the com-plexity of the quality measure is at the same time its main drawback: the performance values are difficult to under-stand. 4 Object count/area graphs Area recall and area precision are easy to interpret as long as there are only two rectangles involved: a single ground truth rectangle and a single detection result rectangle. However, in the case of multiple images or a single image with mul-tiple text rectangles, a combination of the measures is not straightforward.
 schemes described in the previous section: the way the over-lap information is accumulated during the calculation of the evaluation measures leaves room for ambiguity. For in-stance, a recall of 50% could mean that 50% of the ground truth rectangles have been matched perfectly, or that all ground truth rectangles have been found but only with an overlap of 50%, or anything in between these two extremes. As a consequence, these recall and precision measures are not very intuitive: it is impossible to determine, how many text rectangles have been detected. Similarly, the quality of the detection is not apparent. 4.1 Requirements of an evaluation algorithm We developed an evaluation scheme which addresses these problems. Its design has been guided by the following goals: 1. The approach should provide a quantitative evaluation: 2. The approach should provide a qualitative evaluation: it 3. It should support one-to-one matches, one-to-many 4. The measure must scale up to multiple images without The most important constraint of our design goals is the con-tradiction between goal (2), to be able to count the number of detected rectangles, and goal (2), to be able to measure de-tection quality. Indeed, the two goals are related: the num-ber of rectangles we consider as detected depends on the quality requirements which we impose for a single rectan-gle in order to be considered as detected. For this reason we propose a natural way to combine these two measures: two-dimensional plots which illustrate their dependence. More precisely, on the y -axis we plot the two measures which are the most interesting for us: object counts, i.e., the measures related to goal ( 4.1 ): R P As stated above, these two measures depend on the qual-ity requirements, which are imposed using two measures: area recall and area precision. In other words, the detec-tion performance is illustrated using two diagrams, where the first shows the dependence on area recall and the sec-ond shows the dependence on area precision. Each diagram, on the other hand, contains two graphs: one plots object re-call, the other one object precision (see Fig. 5 in the results section for an example).
 ject recall and object precision are calculated given fixed constraints on area recall and area precision. 4.2 Rectangle matching The computation of the measures given in ( 9 ) requires for each ground truth rectangle G i the determination whether it has been detected or not, and for each rectangle D i in the de-tection result the determination whether its detection is cor-rect or not. These decisions are taken based on constraints imposed on the detection quality, i.e. the overlap between detection result and ground truth. In order to take into ac-count one-to-one as well as one-to-many matches (splits) and many-to-one matches (merges), we calculate the over-lap matrices  X  and  X  introduced by Liang et al. in [ 12 ], as described in Sect. 3 .
 respondences between the two rectangle lists. In general, a non zero value in an element with indices ( i , j ) indicates, that ground truth rectangle G i overlaps with result rectan-gle D j . However, the two rectangles are matched only if the overlap satisfies the quality constraints, i.e., if area recall and area precision are higher than the respective constraint: ( a ) X  ( b ) X  where t r  X  X  0 , 1 ] is the constraint on area recall and t [ 0 , 1 ] is the constraint on area precision. In detail, the differ-ent matches are determined as follows: one-to-one matches: one ground truth rectangle G i matches one-to-many matches (splits): one ground truth rectangle many-to-one matches (merges): one result rectangle D many-to-many matches (splits and merges): this match Based on this matching strategy, the recall and precision measures which we intuitively described in ( 9 ), can be fi-nally defined as follows: R P where Match G and Match D are functions which take into account the different types of matches described above and which evaluate to the quality of the match:
Match G ( G i , D , t r , t p )
Match D ( D j , G , t r , t p ) where f sc ( k ) is a parameter function of the evaluation scheme which controls the amount of punishment which is inflicted in case of scattering, i.e., splits or merges. If it eval-uates to 1, then no punishment is given, lower values punish more. In our experiments we set it to a constant value of 0.8. tions in the expressions Match G and Match D in order to punish over segmentation differently than under segmenta-tion. This might be useful if text detection is followed by text recognition. Furthermore, more scattering might be pun-ished more severely by adding a dependence to the num-ber of rectangles k , for instance by setting f sc ( k ) = 1 which corresponds to the fragmentation index suggested by Mariano et al. [ 15 ].
 partly detected and therefore not matched against a ground truth rectangle, will correctly decrease the precision mea-sure, in contrast to the ICDAR evaluation scheme described in Sect. 3 . 4.3 Multiple images In the case of N images, we compare several lists G G , k = 1 ,..., N of ground truth rectangles with several lists D k  X  D , k = 1 ,..., N of result rectangles. As in in-formation retrieval, the results on multiple images may not be accumulated by summing the recall or precision values. Instead, object recall and object precision are defined as fol-lows: R P 4.4 Constructing the graphs As explained before, the object related measures introduced in Eq. ( 12 ) depend on two constraints t r and t p which impose constraints on the detection quality. The performance dia-grams are produced by fixing one constraint to a set value, varying the second one (assigned to the x -axis) and plot-ting object recall and object precision on the y -axis of two graphs.
 of the two diagrams obtained this way. The diagram shown in Fig. 5 a is generated by varying the constraint on area recall, t r , while constraint t p is held to a fixed value. The diagram is composed of three graphs: object recall, object precision and the harmonic mean of the two measures. Similarly, Fig. 5 b is created varying constraint t p constraint t r is fixed.
 namics of the graphs: in this particular example, the fact that object recall never drops to zero when area recall approaches 1 means, that most of the text rectangles are detected with an area coverage of 100%, i.e., the detection rarely cuts parts of the ground truth rectangle. On the other hand, the fact that object recall does drop to zero when area preci-sion approaches 1, means that all result rectangles exceed the ground truth boundaries. The particular amount of area which is detected additionally can be seen by the point/range where the object recall dramatically drops when area preci-sion increases.
 the two constraints is held fixed. The particular values as-signed to the fixed constraints have been chosen empirically. However, we decided to pick different values for the two dif-ferent constraints: while t r is fixed to 0 . 8, we chose the lower value of 0 . 4 for constraint t p . This decision is motivated by the fact that a detection result which cuts parts of the text rectangle is more disturbing than a detection which results in a too large rectangle. The value of 0 . 4 might seem very low, but keep in mind that the area of a rectangle grows with the square of the its side lengths. This fact is illustrated in Fig. 3 , which shows a detection result with 50% area preci-sion. The detected rectangle is twice as large as the ground truth rectangle, although the difference in the corner coor-dinates is quite small. Please refer to the discussion section for some remarks on the implications of this situation to text detection algorithms. 4.5 Three-dimensional graphs An alternative presentation of the performance measures are three-dimensional plots of the three object related measures (recall, precision and the harmonic mean), respectively, on the z -axis, whereas t r is assigned to the x -axis and t signed to the y -axis. Figure 6 shows an example of such a set of plots.
 for each combination of thresholds t r and t p , i.e., for each conceivable combination of quality constraints, we are able to read the performance of the detection algorithm. How-ever, this advantage is bought with several drawbacks, which severely hamper the usability of the plot:  X  The 3D plots are more difficult and less intuitive to read.  X  The different object related performance measures can- X  The interpretation of a 3D graph is only possible if the  X  The complexity of the calculations needed for the 3D In general, we think that the gain in additional information is small compared to the drawbacks of the 3D plots. 4.6 A single performance value The performance diagrams introduced above are an easy and intuitive way to illustrate the performance of an object detec-tion algorithm. However, very often it is useful and desirable to determine a single performance value for an algorithm, ei-ther for direct comparison of the performances of different algorithms, or to optimize the parameters of the detection algorithm, or to control the algorithm, for instance in a rein-forcement learning environment [ 18 ].
 ison of the algorithms by a single scalar value is difficult, up to impossible. A single value is hardly able to characterize the complex behavior of a detection algorithm, which makes it necessary to resort to compromises. At first sight, a simple solution might be to hold the quality constraints t p and t fixed values, calculate object recall and object precision and combine them in a harmonic mean. However, this evalua-tion would depend heavily on the particular chosen values. One algorithm could outperform another one for given qual-ity constraints, while it could show a weaker performance for other constraints.
 the curves ( t p = 1and t r = 1, respectively). As for any other fixed value of t p and t r , this solution ignores the behavior of the algorithm for other detection quality constraints. It is im-mediately clear that this behavior is important when we look at Fig. 8 . H.W. David X  X  algorithm (displayed in the top row) and Todoran X  X  algorithm (displayed in the 4th row) share the same end point in the right diagram: Recall = Precision = 0for t r = 1. This means, that both algorithms detect rectan-gles which are larger than the ground truth rectangles, since not a single rectangle is considered as found if a precision of 100% is required. However, looking at the rest of the curve, we can see the difference in the behavior of the two detec-tion algorithms: H.W. David X  X  algorithm features a Recall of almost 60% across a large section of the precision qual-ity constraint. Recall only drops rather sharply when a qual-ity constraint of about 55% is reached. Summing it up, we might say that H.W. David X  X  algorithm detects 60% of the rectangles with realistic assumptions on detection precision. On the other hand, Todoran X  X  algorithm shows an almost lin-ear dependance of Recall on detection quality. This tells us, that the differences in size between the ground truth rectan-gles and the detected rectangles are more equally distributed, the algorithm X  X  behavior is therefore less predictable. evaluated algorithm across a whole range of quality con-straints. We therefore propose the proportion of the graph area which is beneath the performance graphs as a reliable and objective measure, which is equivalent to the mean value of object measures over all possible constraint values. separately for object recall and object precision: R P two measures: Perf OV = 2 The parameter T is a granularity parameter which controls the trade-off between the computational complexity of the evaluation algorithm and the precision of the integration ap-proximation. However, it is not likely that the object re-lated measures change sharply after changing the quality constraints in very small steps. Consequently, in our experi-ments, we set the parameter to T = 20. 5 Evaluating the influence of the test database As for information retrieval (IR) tasks, the measured perfor-mance of an object detection algorithm highly depends on the test database. It is obvious, that the nature of the images determines the performance of the algorithm. As an exam-ple we could think of the object type (different poses for face detection, artificial text or scene text for text detection), its size, the image quality, noise, compression artifacts etc. For this reason, an objective comparison between different algo-rithms will only be possible if the respective communities decide on shared common test databases. Alternatively, we recommend tackling this problem partly by performing dif-ferent experiments for different test databases with different difficulties.
 only variable which determines the influence of the test database on the detection performance. The structure of the data, i.e., the ratio between the relevant data and the irrele-vant data, is a major factor which influences the results. This simple but important fact has been overlooked by the infor-mation retrieval community for a long time.
 adapt the well known precision/recall graphs in order to link them to the notion of generality for an IR system, which is defined as follows: Generality IR = Very large databases with low generality, i.e., much irrele-vant clutter compared to the relevant material, produce re-sults with lower precision than databases with higher gen-erality. This makes sense, since the probability to retrieve a relevant item is lower if there is more irrelevant noise present in the database. A standard IR system presents the retrieved items to the user in a result set of predefined size. Since this size is fixed, with falling generality the amount of relevant material in the result set X  X hus the recall X  X ill tend to be smaller. Thus, recall and precision depend on the general-ity of the database. In IR one is interested in the retrieval performance with respect to the generality as well as with respect to the size of the result set, which determines the search effort for the user. The dependence on two parame-ters makes three-dimensional performance graphs necessary. Alternatively, Huijsmans proposes two-dimensional graphs, which corresponds to a plane of the 3D space defined by Precision = Recall. Therefore, the graph plots Precision = Recall on the y -axis against generality on the x -axis. not work with items (images, videos or documents). Instead, images (or videos) are used as input, and object rectangles are retrieved. Nevertheless, a notion of generality can be de-fined as the amount of objects which are present in the im-ages of the database. We define it to be Generality = Note, that using this definition, generality may attain val-ues 1. This is not a problem since the value is interpreted by humans or used in plots (see Sect. 6.1 ). sult set window, because all detected items are returned to the user. Therefore, the generality of the database does in-fluence precision, but not recall. Thus, the influence of the database structure on the system performance can be shown with simple two-dimensional precision/generality graphs. The graphs introduced by Huijsmans are displayed on a log-arithmic scale, since the generality in very large IR databases may attain very low values. On the other hand, the amount of objects per image (or per video frame) should remain rel-atively high, therefore we decided to display the graphs on a linear scale.
 level of the database when result tables or graphs are dis-played which contain a fixed level of generality. In other words, it is necessary to decide how many images with zero ground truth (no object present) should be included in the database. The exact amount depends on the particular appli-cation. The apriori probability of an image to contain ex-otic objects, as for instance water falls or fire might be very low. Another determining factor is the type of medium. In most cases, for applications working on single images the probability is higher than for applications working on video sequences. In this document, where experiments were per-formed on images containing text objects (see Sect. 6 ), we chose a mixture of 50% images with relevant objects and 50% images without relevant objects. 6 Experimental results We tested our new evaluation metric on two different sets of text detection algorithms which have been applied to differ-ent image test databases, respectively. 6.1 Evaluating text detection in video frames The first test dataset contains two algorithms, which have been developed by the authors. Details are given in [ 22 , 23 ], respectively. For the sake of brevity, in the reminder of this paper we call them algorithm 1 and algorithm 2 .Thetwo methods have been applied to a small set of video frames in the CIF format (384  X  288 pixels), which have been pro-vided by INA 3 and France T  X  el  X  ecom. This small database contains only 14 images, which makes it possible to visually show the detection results superimposed on the images (see Fig. 4 ). Thus, a direct comparison can be made between the detected object rectangles and, respectively, the object/area performance graphs (Fig. 5 ) and the performance/generality graphs (Fig. 7 ). cision depending on the constraints imposed on area recall. Object recall and precision decrease only slowly when t r proaches 1, which means that most of the object rectangles are detected with their entire area. Note, that the object re-call graph drops faster for algorithm 2, illustrating a lack of the algorithm to detect the whole area of each rectangle. This can be confirmed looking at the superimposed results in Fig. 4 a and b, respectively.
 sion depending on the constraints imposed on area precision. Object recall and precision drop to zero when t p approaches 1, illustrating the fact that all object rectangles are larger than the corresponding ground truth rectangles. We can see that algorithm 1 is more precise, since object recall drops slower when the t p is increased. Again, this is confirmed looking at the superimposed results in Fig. 4 .
 the database structure. In order to create graphs falling with lower generality, inverse generality has been assigned to the x -axis. More precisely, the left most value of the graph (1 / Generality = 0 . 2) corresponds to a set with seven im-ages containing text only, whereas the right most value of the graph (1 / Generality = 0 . 4) corresponds to a set with seven images containing text and 7 images not containing text. In order words, the left most value is calculated using only the first column of images in Fig. 4 , and as we traverse the x -axis to left, lowering generality, more and more non-text images taken from column 2 of Fig. 4 are added to the dataset. As we can see, object recall stays constant, since adding non-text images does not add any new ground truth images. However, precision decreases due to false alarms. We note that the graphs for algorithm 2 are flatter, illustrat-ing the fact that this algorithm produces less false alarms in images not containing text X  X onfirmed by the fact that algo-rithm 1 is based on the hypothesis that the images used do contain text [ 23 ].
 the generality graphs are consolidated performance values. For each value on the x -axis, i.e., for each generality value, and for each performance measure, i.e., precision, recall and their harmonic mean, we calculate a single value as given in Eqs (13) and (14). 6.2 The ICDAR 2003 text detection competition results The second dataset consists of the text detection algorithms participating at the text detection competition organized in the framework of the 7th International Conference on Document Analysis and Recognition (ICDAR), 2003 [ 13 ]. Simon Lucas, the organizer of the competition, kindly pro-vided results of the participants in XML format. The test image database consists of various images taken with digital cameras. In contrast to the first database, these images have been acquired in relatively high resolution: the image dimen-sions range between 1600  X  1200 pixels and 1000  X  800 pixels.
 gorithm, H.W. David X  X  algorithm, Wolf X  X  algorithm, and Todoran X  X  algorithm [ 14 ]. The third algorithm, developed by the authors of this document, corresponds to algorithm 2 evaluated in the last section. A fifth virtual participant combines the results of the other four methods using an algorithm proposed by the organizers of the competition. Descriptions of the methods can be found in [ 14 ]. testants. The clear winner seems to be Ashida X  X  algorithm, which shows superior recall and precision across the whole range of quality requirements. Applying the same reasoning as in the last sub section, we clearly see the two leading al-gorithms differ in their detection approach: while Ashida X  X  detected rectangles tend to be too small, H.W. David X  X  de-tected rectangles tend to be too large.
 tion algorithms are well illustrated by the graphs: the propor-tion of  X  X ecalled X  objects and the proportion of false alarms is immediately visible for the quality a user might want to impose. Inflection points in the performance curves show the precision of the detection algorithm. For instance, the inflec-tion at point t r = 0 . 8 of the object recall graph of Ashida X  X  algorithm (top row, left column), illustrates the fact that most objects are detected with about 80% of the object area. If the quality constraints are further increased, the number of ob-jects considered as detected drops.
 rithm compared to the original metric used during the IC-DAR competition, introduced in Sect. 3 . The ranking of the algorithms stayed the same, although there are differ-ences in the different performance values. More important, the interpretation of the values changes: recall according the ICDAR metric corresponds to the area recall, averaged across all images, which results in the ambiguity described in Sect. 4 . On the other hand, the new recall value cor-responds to averaged object recall and may thus be inter-preted as the proportion of correctly detected objects, av-eraged across the whole range quality constraints a user might want to impose. Precision is interpreted in a similar manner. 7 Discussion and conclusion In this paper we have presented a novel method to evaluate object detection algorithms. The proposed method is appli-cable to any kind of object, as long as the detection result may be represented by a list of rectangles.
 graphs which depict measures on object level depending on quality constraints, making easy a clear and intuitive inter-pretation. A clear distinction is made between a quantitative evaluation of the detection algorithm and a qualitative eval-uation. The dynamics of the graphs illustrate the behavior of the detection algorithm against different quality constraints which might be imposed by a user, where inflection points correspond to the fundamental characteristics of the detec-tion algorithm. The proposed evaluation method overcomes several shortcomings of the existing approaches, notably the ambiguity problem which follows from the direct accumu-lation of overlap proportions. Since the performance values are calculated on object level, a user can directly see the number of correctly detected objects and the amount of false alarms.
 have proposed a single performance measure which is di-rectly derived from the performance graphs. The integral of the object level performance across the full range of quality constraints gives an intuitive and objective measure of the detection algorithm X  X  performance.
 detection algorithm X  X  performance on the generality of the test database, i.e., the amount of relevant information in the database. This often overlooked criterion significantly influ-ences the measured performance of any object detection or information retrieval algorithm.
 lap between the ground truth rectangles and the result rect-angles, not on the location of this overlap. In many applica-tions, e.g., in the case of text detection, however, the amount of overlap between two rectangles is not a perceptively valid measure of quality, as can be seen in Fig. 9 . Precision and recall are equivalent for both detection examples, but the de-tection shown in Fig. 9 a might be considered as better, since the additional detected space is distributed over all sides of the ground truth rectangle.
 tion of detection results as the one in Fig. 9 a, the preci-sion constraint t p is set to a very low value. This is nec-essary because the error surface grows with the square of the additional rectangle length (or height). However, we still might want to reject detections as the one illustrated in Fig. 9 b.
 equally distributed could be to estimate the distribution of the angles of the error pixels against the center of the ground truth rectangle. Unfortunately, the angle distribution of a perfectly aligned detection, e.g., the detection shown in Fig. 9 a, is not a uniform distribution but a distribution result-ing after a piecewise application of a tangent function. A sta-tistical test (e.g., a Kolmogorov X  X mirnov test) against such a distribution after an estimation of its parameters would be possible but not very robust.
 be overkill given the fact that the functional form of the error distribution is known and that it depends on four parameters only: the absolute differences of the left (respectively right, upper and lower) coordinates of the rectangle pair. We chose therefore a simpler yet more effective method, which di-rectly checks these parameters: the 4 values described above are checked against thresholds, which are calculated from the size of the rectangle.
 interested in detecting a horizontal disequilibrium. There-fore, we concentrate on two of the differences measures: the absolute differences of the left (respectively right) coordi-nates of the rectangles to match need to be smaller than a constraint which depends on the width of the ground truth rectangle. This constraint, which does not depend on the overlap information, makes sure that a situation depicted in Fig. 9 b is unlikely to occur.
 References
