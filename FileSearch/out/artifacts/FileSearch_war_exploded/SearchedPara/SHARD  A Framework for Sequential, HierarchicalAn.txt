 Anomaly detection has many applications, including fraud detection, outbreak identi-fication, and data scrubbing [13] [4]. Each of these domains contains its own semantic relationships, many of which can be modeled as hierarchical. In this paper, we present a framework that allows users to identify anomalies across different levels of these hier-archical structures. For example, in fraud det ection, users may be interested in detecting fraudulent behavior across different time gra nularities (weeks, month, years) or across different locations (neighborhood, city, state). In this case, both time and location are different examples of seman tic hierarchies that can be us ed to identify recurring or ag-gregated anomalies. Figure 1 shows an example of a sequential, time based hierarchy that we will refer to as an anomaly tree . Each level of the anomaly tree represents a different granularity of time. By viewing these different semantic groups of data hi-erarchically, users can better understand how anomalies propagate through different sequential, hierarchical relationships associ ated with their applications. Are anomalies scattered or recurring? Are some days, months, or years more anomalous than others? In this work, we propose SHARD , a flexible framework for S equential, H ierarchical, A nomaly, R anking, and D etection that supports incorporation of hierarchical semantics across numeric and categorical data into unsupervised, anomaly detection and rank-ing. This work makes the following contributions. First, we present system and design considerations for developing a general fra mework for hierarchi cal anomaly detection. These considerations lead to the decoupling of data formats, outputs, and the definition of  X  X nomalous X  for a given use case. The second contribution is the framework itself, which allows single or multiple anomaly detectors to work together. Most importantly it allows domain experts to drive the anomal y detection process by scripting meaning-ful, hierarchical relationships between the attributes. Finally, we present experiments on synthetic and real world data sets that show similar performance of detailed, micro-level anomaly detection when compared to the baseline detector performance without the framework; the experiments also demonstrate high-order macro-level anomalies that would completely escape the expert X  X  view without the framework.

The remainder of this paper is organized as follows. Section 2 presents related liter-ature. Section 3 presents background concepts. Our framework is presented in section 4, followed by experimental results in section 5, and the conclusions in section 6. A large body of literature on anomaly detectio n exists. For a detailed survey of anomaly detection techniques, we refer you to [4] and [13].
 Anomaly Detection Frameworks: A few anomaly detection frameworks have been proposed in the literature. For example, Chandola [3] proposes a Reference Based Anal-ysis (RBA) framework for analyzing anomalies with numeric and categorical data in sequences and time series. While RBA offers summary visualizations, it does not offer the multi-resolution evaluations, the interactive visualizations, or the plugin detection and ranking algorithms that our framework does. Nemani et al. [12] propose a frame-work for detecting anomalies in spatial-temporal data. This framework supports plugin detection algorithms; yet, it does not app ear to support visualization of multi-granular time series, nor is it clear how customizable other aspects of this framework are. Anomaly Detection Algorithms: A number of approaches for anomaly detection of time series data exist [5], [8], [10]. Antunes and Oliveira [5] transform the time series into forms that can use standard approaches for anomaly detection. Keogh, Lonardi, and Chiu [10] evaluate the frequency of substrings in a time series and compare the re-sulting distribution to a baseline time series. Li and Han [11] explore anomaly detection in multidimensional time series data, identifying the top-k outliers for each detection method and iteratively pruning these sets until a uniform set of anomalies is discov-ered. All of these sequential anomaly detection algorithms focus on single resolution anomaly detection. Instead, this work focuses on a framework that supports integration of many algorithms across multiple resolutions.

Joslyn and Hogan [9] explore similarity metrics in directed acyclic graphs and other hierarchical structures. Their work can be utilized to visualize and find anomalies in ontologies. While the ideas concerning semantic hierarchies that we present are implicit in Joslyn and Hogan X  X  work, their focus is entirely on similarity metrics in these tree structures and not on the full implementation of an anomaly detection framework. Suppose we are given a data set D , containing a set of attributes or features, F = { F ordered list of n values, F i =[ v 1 ,v 2 ,...,v n ] . We define an anomaly, A , as a data point or set of data points that deviate or behave differently than the majority of comparison data , where the comparison data represents values for one or more features in D .We purposely define an anomaly broadly since the type of deviation of interest can vary de-pending on the data type (numeric, categorical, etc.) and/or the domain characteristics.
Even though our framework can handle any data that can be represented sequentially and hierarchically, including natural langua ge (document, sentences, words, syllables, letters) and genetic sequences (DNA, genes, proteins), for ease of exposition and ubiq-uity of data, we focus on time series data and time anomaly trees. In this case, data values exists for each feature in the data set at n time points. We also define a set of semantic resolutons r = { r 1 ...r h } , where each resolution represents a different seman-tic grouping for data in D . The semantic groupings for our example in figure 1 are day, month, and year, r = { day, month, year, all } . These semantic groupings can then be used as the basis for creating a time anomaly tree T of height h ,where h =4 for our example. The resolutions tell us the gra nularity of data associated with each node in a particular level of the tree. The leaf nodes contain statistics about data values at resolu-tion r 1 , the day resolution in our example. The parent nodes of the leaf nodes contain statistics about the data values at resolution r 2 , e.g. the month resolution, and so on. Given this anomaly tree, we define a hierarchical anomaly A ( n l ) to be a node n at level l that deviates significantly from other nodes (or a subset of other nodes) at level l in the anomaly tree, where deviation is measur ed by one or more detectors selected by the user and significance is algorithm specific.

For example, in a stock data domain, a single company can be considered anoma-lous if it has an unlikely, sudden surge and subsequent drop in price, if it has an unlikely surge in price that is maintained for some sustained duration, e.g. month, before drop-ping back to normal, if daily behavior differs drastically from other companies X , or if the company manifests a combination of these unusual behaviors. The specific type of behavior identified depends on the detectors and rankers specified by the user. Our high level algorithm for anomaly tree construction and annotation is presented as Algorithm 1. The input to the algorithm is the data ( D ), an ontology template that specifies the semantic relations of interest (  X  ), the anomaly detectors of interest ( A ), and an anomaly ranker ( R ). Using this information, the framework builds an anomaly tree by assigning data values to the nodes and updating the node summary statistics according to the ontology template, runs di fferent anomaly detectors on the nodes of this tree to obtain a set of anomaly scores for each node, and ranks the anomalies in the tree by computing a score based on criteria s uch as the level of agreement between the anomaly detectors and the anomaly scores o f the child nodes. The resulting tree is then used for an interactive tree visualization tha t can be analyzed by the user. The remainder of this section describes the framework and different design decisions.
 Algorithm 1. Anomaly tree construction and annotation 4.1 Ontology Template The ontological tree template not only decides the hierarchy of where and how feature values are organized and propagated, but a lso determines how the detectors evaluate nodes. Specific considerations are 1) the range of nodes that maintain summary statistics for the detectors to analyze, 2) normalizing or scaling of multivariate combinations, and 3) sorting of temporal or ordinal features. Table 1 shows an example ontology template and the resulting anomaly tree. The XML template describes an application that attempts to find three different semantic hierarchies based on time, industry, and employee education. 4.2 Anomaly Tree Structure The anomaly tree T generated by the ontology templa te consists of multiple node types. Definition 1. The leaf nodes at the lowest level of the tree contain data values. Data from these nodes are aggregated and propagate information to the remaining levels of the tree. Semantic grouping nodes are non-leaf nodes that are associated with a feature and group children nodes according to the feature values. Branching nodes create a branch of nodes to be evaluated for anomalies. These nodes determine how the child values are evaluated and propagated through T . The propagation of leaf node values stops at the branching node.
 Each node type handles individual data values differently. Semantic grouping nodes split on every new value of the attribute specified in the ontology template. Branching nodes are not associated with a value. Instead they store summary statistics of all de-scendant nodes and tell the detectors whether or not to search for anomalies in a partic-ular branch. The branch creation process creates a root node and a set of children nodes, where each child corresponds to a branching node based on attribute values specified in the ontology template. For example, in the tree path industry/company/[PRICE]/Price/ yyyy/mm/dd/price 1 , all nodes are grouping nodes except for [PRICE] and the leaf node price data. The leaf nodes propagate their values upward to the top branching node, which means that every parent node is a summary of all of its child nodes. The XML example has two leaf attribute values, price and education that anomalies will be calcu-lated for.

The branch EDU[c] creates a branching node that maintains summary statistics (e.g. mode ) of the categorical datatype education for each employee in the semantic group-ing node company , so that we can determine the most frequent level of education per company. Likewise, the parent semantic grouping node industry allows the researcher to also evaluate levels of education across industries. Branching node [EDU_PR] ag-gregates prices by the average levels of education across all companies.

Table 1 also shows portions of the anomaly tree for the specified XML template. In this example, there is only one industry, technology, under which there are three nodes, one for each of the companies. 2 The arrows at the bottom of nodes indicate nodes that can be expanded to show their children. As the figure illustrates, the anomaly statis-tics are populated throughout the tree and data statistics from the leaf nodes under a branching node are aggregated as they are pushed up to the branching node, popu-lating the intermediary nodes along the way. Each intermediary node maintains sum-mary statistics of its children nodes. The month level node for the price attribute, for example, maintains the average price for all the children day nodes. Other statistics are also calculated, including median, mode, standard deviation, and entropy. 4.3 Baseline Anomaly Detectors The anomaly detectors use the anomaly tree, T , to determine the degree of anomalous-ness of each node in T . This is accomplished by running each user specified anomaly detection algorithm, e.g. statistical signifi cance or entropy, for each element in the tree. Along with the basic detectors, SHARD includes an ensemble detector that combines the detection results of the individual detectors using a weighted voting algorithm, where the weights are prespecified by the user. Once the anomaly scores are computed by the different detectors, the tree nodes are annotated with this additional information. This is also illustrated in Table 1.

In order to identify an anomaly, a data value must be compared to other data val-ues. When evaluating a particular node in T , we use neighboring nodes as comparison data. However, how these nodes are used differs depending on the particular anomaly detection algorithm. For example, table 1 shows the current node under consideration to be day 6 of month 1 (January) of year 1998 of CA, Inc. The options for comparison data for this example include: 1) all immediat e sister nodes, all nodes in January for this year and company; 2) all prices for all months under the same company; 3) all prices for all months and companies; 4) all the January 6ths X  for the current year across all com-panies; and 5) the averages of the previous days or months. The SHARD framework includes three parameterized defaults: 1) all local siblings (sister) nodes; 2) all nodes at the same tree height for the same attribute; and 3) previous nodes at the same tree height for the same attribute. Other options can be specified at configuration time and new options are straightforward to integrated into framework. 4.4 Ranking Anomalies Once all of the detectors have evaluated the nodes in T , the algorithm then runs a user specified ranking method to assign an ove rall anomaly score to each node. The ranking procedure can compute the anomaly score based on any of the following criteria: 1) the anomaly scores provided by different detectors for a particular node; 2) the percentage of detectors that found a particular node anomalous; 3) the priority of the detectors that found the node to be anomalous; 4) the percentage of child nodes that were found to be anomalous; 5) the importance of the level of granularity in which the anomalous node occurs; and 6) whether anomalies occur in other parallel branches at the same granu-larity. Our intuition is that the level of anomalousness depends on the domain priori-ties, objectives and definitions of comparison data. Therefore, we incorporate a tunable ranker that can be adjusted to these considerations. Ranking based on the percentage of anomalous children is the default ranker in SHARD, although we also provide other ranking procedures that combine different subsets of the mentioned factors. 4.5 Anomaly Tree Visualization SHARD uses the SpaceTree [14] hierarchical visualization application to highlight the most anomalous nodes based on a color heat map. SpaceTree reads in XML and displays an interactive tree of variable dep th and width. This interactive software en-ables users to expand the entire tree or focus on subtrees of different branches of the full tree while hiding other subtrees. Doing this helps the user see where anomalies oc-cur across multiple resolutions. Because our framework is customizable, any amount of detail can be displayed for each node including ranking scores, statistical summaries, individual detector results, and raw data. This interactive visualization supports both an overview and a detailed view, allowing for a more comprehensive analysis of the anomalies. Most of the tree images in this paper were generated using SpaceTree. In this section, we evaluate our framework on synthetic and real world data sets. Our evaluation of the SHARD framework focuse s on detection accuracy and anomalies dis-covered. Specifically, we compare the accu racy of the detectors outside our framework with the same detectors with in the SHARD framework and show that the overall accu-racy is generally maintained, while also offering bigger picture insights. We also discuss these insights at different levels of the anomaly tree and demonstrate the flexibility of our framework.

We experimented with four standard anomaly detection algorithms in our frame-work: 1) the Shewhart algorithm [1], which flags anomalies that are x standard devi-ations away from the mean; 2) the Cumulati ve Sum (cusum) algorithm, which tracks the mean of all previous elements and compa res the values to the current element; 3) entropy (applied to anomalies as described in [7]); and 4) a thresholding version of Bruenig et. al  X  X  [2] Local Outlier Factor (LOF).

The ranking algorithm used in all of the experiments is RankerA .Thisrankerfirst evaluates the children nodes. If at least half are anomalous, the current (parent) node is also considered anomalous. Otherwise, t he sum of all anomaly scores, one from each detector, of a node is divided by the number of children nodes. 5.1 Synthetic Data Experiments For this analysis, we generated three time series with a numeric data value for each day over a six year period, and one categori cal times series. Figure 2 shows each of the numeric time series for a one year period. As illustrated in the figure, each time series has different properties and anomalies. Time series X increases in overall magnitude over time with burst anomalies for 200 random days, one random month of the year (this includes several of the random anomalous days), and one random year (this includes approximately 1/3 of its days being anomalous). Time series Y is similar except that the "normal" comparison values across all 6 years remain relatively steady. Like X ,it contains randomly anomalous days, months and a year-most of which coincide with the anomalies in time series X . Time series Z is mostly independent of the other two time series and illustrates a plateau anomal y that starts and ends with anomalies found in
X and Y . It contains the same anomalous month each year in which all values during this month are consistent for this month, but still much higher than the normal day value for the rest of the year. At the individual day level, the only anomalies are the first day of this month when the values increase and the first of the following month when the values decrease back to normal. We also include a categorical attribute, Color ,thatis dependent on the season in the times series (during months 11,12, 1, 2, 3 { blue, green, purple }; 4, 5, 10 {yellow, orange}; and 6, 7, 8, 9 {red, orange, yellow}). An anomalous instance is an out-of-season color that corresponds with the Y anomalies X  time points. Our ontology template for this data set consists of 5 branches underneath the root. The first three simply aggregate each of the continuous variables by year, month and day independently: [DATE-X]/yyyy/mm/dd/x, [DATE-Y]/yyyy/mm/dd/y, [DATE-Z]/yyyy/mm/dd/z The fourth branch groups all three variables under each unique date: [DATE-XYZ]/yyyy/mm/dd/x,y,z Here, the time series are evaluated together, i n the context of each other. In other words, the most anomalous time periods are when all three time series have anomalous be-havior during the same time period. Note that there are parameters in the XML to nor-malize or scale multiple values under a singl e node. In this run, the configuration was set to Normalize. The final branch, [COLOR][c]/yyyy/mm/color organizes the categor-ical colors by month and year to capture anomalies in the context of different seasons. These various branches show the flexibility of the framework for handling different feature combinations that the user wants to investigate.
 Figure 4(a) shows the scores of the baseline algorithms outside of our framework. The algorithms process each attribute indi vidually and flag indivi dual values as being anomalous, but give no indication of anomalous months or years. Figure 3 shows the results of the baseline algorithms within our framework. The overall scores are com-parable with the record level scores outside of our framework in figure 4(a); however, a richer picture is gained using our framework: Shewhart now correctly identifies z  X  X  anomalous months with much hi gher accuracy, entropy performs well at nearly all reso-lutions of the anomaly tree, and LOF X  X  recall i s higher for most variables. Finally, figure 4(b) shows the results of the ensemble of these detectors. While the overall accuracy and precision is lower than the single detectors in the framework, the interior nodes of the tree have similar or better precision an d accuracy results, demonstrating a potential benefit of a diverse set of detectors f or hierarchical a nomaly detection. 5.2 Event Attendance Data Results We now consider an event data set, the CalIt2 dataset [6], for detecting anomalous events. This data set contains two observation time series (people flowing in and people flowing out of the building) over 15 weeks from July to November. There are 48 time points per day. The  X  X ormal X  behavior of this data set is a periodic, light flow of people going in and out of this building. When a conference is occurring, the flow increases for what is considered normal at that day and time, and an anomaly occurs.

Using the SHARD framework we specified two parallel branches in the ontology template, which offers two different views of the data. The first is Month/Day/Hour/ Count -the intutive hierarchy. The second branch is Hour/DayOf Week/Count/id/Count. This branch first establishes normal data behavior of the 24 hours of the day across the entire dataset, and then sub-aggregates the data by the day of the week and then the counts. So, it might establish that the average count for 9:00 am is 3.5 people, and the average for 9:00 am/Wednesday is 5.0 people. The next groupings id/Count, then establish counts based on individual records.

Inside the SHARD framework with this XML configuration, Shewhart with a thresh-old of 1 scores 24.7% precision, 51.9% recal l on the anomaly tree nodes; Entropy with a threshold of 7.5 scores 39.5% precision, 4.1% recall; LOF where k=5 scores 59% precision and 1.3% recall; and these three d etectors in an ensemble configuration score 63.9% precision and 4.6% recall. Outside of the SHARD framework Shewhard and Entropy perform comparably on the flat data (pr= 24.8%, re=56.3%, and pr=55.7%, re=5.4%, respectively), but LOF scores 0% precision and recall.

We offer a few observations. First, the 0 score of LOF outside of our system is prob-ably due to at least k records with high counts that are not known events. As these points are considered normal comparison data, no points are flagged anomalous when the comparison data consists of all record s. In our framework this happens less because these normal high-count records are dispersed throughout different parts of the anomaly tree. Second, the ensemble run of these three methods produced a higher precision level than any of these three algorithms independently. Third, the SHARD framework pro-duced insight into many different levels of the anomaly tree. Specifically, investigating the SpaceTree nodes that were flagged anomal ous, we determined: November is anoma-lous because it has no events but very high counts, August is anomalous because it has more events than the other months, all Sa turdays are anomalous because they do not have any events, one Sunday is anomalous because it is the only Sunday with an event, and three days are anomalous because they are the only days with multiple events. 5.3 Climatology Data Results Here we use a data set collected by the Pacific Marine Environmental Laboratory to study the El Nino and La Nina phenomena [6]. This data set contains climatology data from 1980-1998, during which there were 6 El Ninos ( 1982 , 1987, 1991 , 1992, 1994, 1997 )and1LaNina( 1988 ). The years in bold were considered very strong. The most anomalous months with unusua lly high temperatures are typically December of that year and January of the following year. There were 178,080 total readings of date, location, trade winds, humidity an d air and sea surface readings.

Using the SHARD framework, we create a n XML template that contains a typical, sequential date hierarchy year /month/day/{attribute} structure for each attribute. Using Entropy, threshold=1, the framework flags the appropriate El Nino and La Nina years with 87.5% precision and 58.3% recall using the ocean surface temperature; 88.9% and 66.7%, respectively, with the air te mperature readings. Because we do not have ground truth weather information to accurate ly label all anomalous months and days, the precision and recall cannot be reported f or the other levels of the anomaly tree.
We pause to mention that this data set contains many missing values since not every buoy was equipped to measure all of these attributes. Our framework can handle missing values by creating tree nodes only for values that are present and then searching for local anomalies within the tree.
 Because of the flexibility of our XML templating, we also considered an alternative XML template that inverts months with years, so that the hierarchy is month/year/day as shown in figure 5. This means that for the month of December we have all year nodes as children and under each year node all Decembe r day measurements. This gives the researcher a very easy way to learn durin g which years December was most anomalous. Using this inverse technique, if we exami ne December, we find 85.7% precision and 77.7% recall at tagging the appropriate year s. More interestingl y, though, the highest ranked nodes correspond very well to the  X  X trong X  El Nino years. 5.4 Stock Data Results In these experiments, we analyze the NASDAQ daily stock quotes from 1998-2009 of 34 companies in the Technology, Financial, Services and Consumer Goods sectors. There is 1 date attribute, 7 numeric attrib utes and 5 categorical attributes for 14,805 records. We chose these years and industries because much happened in this decade: there was the dot.com bubble, followed by a correction year, 9/11, and another cor-rection year following the real estate bubble. With the stock data we decided to study the most anomalous years by industry with the XML template configured as Indus-try/Year/Company Size/Company Name/M onth/Day/Closing Price. We again used a default Entropy detector with a threshold of 1. A brief summary of these results can be found in table 3. Although we found the correlations between anomalies in Asset Management and those in Beverages -Brewers unexpected, the rest of the results seem easily interpretable, Application Software X  X  dot.com boom and correction are rightly noted, the airlines show up in 2001, and many financial anomalies start to show up in 2004-2008. These results are consistent with expectations. 5.5 Discussion The experimental results demonstrate the utility of having a hierarchical anomaly detec-tion framework. Our synthetic and event attendance detection results indicate that the ensemble method has fewer false positives than the individual detection methods and a higher accuracy than any of the individual methods. We believe this results because the ensemble method is able to capture a mor e robust image of the data, whereas the individual algorithms are more suited to detect a particular type of anomaly.
Our results also show that the existence of anomalies at one granularity is not indica-tive of anomalies in other granularities. Figure 5 depicts a feature with many anomalous leaf nodes, but the parents of these nodes are not anomalous as indicated by  X  X noma-lous Nodes Below X . This is consistent with our understanding of point and contextual anomalies, and that one does not imply the other. Higher granularities are more descrip-tive of contextual anomalies, and not simply single point anomalies.

Using the SpaceTree application, we were also able to visualize our results in a meaningful way. The user is able to access relevant statistics about each node, as well as quickly see where anomalies are occurring. This is important in our work as mentally visualizing anomalies at multiple granularities is not an intuitive task. This work introduces SHARD, a framework that supports analysis of complex, multi-dimensional, hierarchical anomalies. Our framework is robust and allows for easy cus-tomization for different applications, as well as easy extensions for adding additional anomaly detectors and rankers. Using our prototype system, we illustrate both the flex-ibility and utility of this framework on both synthetic and real world data sets. Future work includes expanding the detectors in the framework, allowing for streaming analy-sis, demonstrating other semantic hierarchies that are not time based, and reducing the number of user specified parameters. Finally , many of the hierarchical aggregates men-tioned are examples of cuboids. Extending our tree framework to a cube framework is another promising direction.

