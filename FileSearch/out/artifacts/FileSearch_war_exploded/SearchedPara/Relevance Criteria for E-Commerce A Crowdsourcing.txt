 We discuss the concept of relevance criteria in the context of e-Commerce search. A vast body of research literature describes the beyond-topical criteria used to determine the relevance of the document to the need. We argue that in an e-Commerce scenario there are some differences, and novel and different criteria can be used to determine relevance. We experimentally validate this hypothesis by means of Amazon Mechanical Turk using a crowdsourcing approach.
 H.3.4 [ Information Storage and Retrieval ]: Systems and software  X  performance evaluation Measurement, performance, experimentation IR evaluation, relevance, relevance criteria, user study
Relevance is a key notion for information retrieval. It has been extensively studied in the past, as surveyed in [4], and it is still under investigation, see, e.g., [5, 6]. One impor-tant research issue is the set of relevance criteria , i.e., the attributes that determine whether an item is relevant or not. Topicality is the classical relevance criterion; additional cri-teria have been studied extensively in the 90s, and the main outcomes are summarized by Barry and Schamber in [2].
Electronic Commerce, commonly known as e-Commerce, consists of the buying and selling of products or services over the Internet. A large fraction of e-Commerce is performed in customer facing Websites where search is the predominant activity. After all, if the customers can X  X  find an item to buy they are likely to go to a different e-Commerce site.
How can one frame the concept of relevance in the context of e-Commerce? More specifically, are there any differences in beyond topical criteria for e-Commerce search? This ques-tion makes sense when one adopts a historical perspective. After the work by Barry and Schamber in the 90s, since the intersection among the sets of elicited relevance criteria was high, it seemed reasonable to assume that all  X  or almost Needs e-Commerce 659 ( 26 . 90 %) 516 (21 . 06%) 7 workers for each need (query), for a total of 83 HITs (581 assignments). We got 100% of the answers after two days.
The workers performed 2450 criteria selection in total (4 . 2 on average for each assignment), almost equally distributed between e-Commerce and non e-Commerce needs (1175 vs. 1275) and between e-Commerce and non e-Commerce crite-ria (1198 vs. 1252). Criteria distribution is rather uniform: Accuracy was selected 309 times, Availability 264, and any other criteria between 162 and 81 times.

Turning to the hypothesis being tested, the results shown in Tab. 1 quite confirm the hypothesis, as they show that indeed there is a good correspondence: a total of 56 . 94% criteria are classified according to the need kind (i.e., either an e-Commerce criterion was selected for an e-Commerce need or a non e-Commerce criterion was selected for a non e-Commerce need), and 43 . 06% are classified in the opposite way (the two remaining cases). There is a particularly good match for non e-Commerce needs and criteria (30 . 04%).
This is further confirmed by a breakdown analysis on the single criteria, shown in Fig. 1. In the top chart (concern-ing 8 criteria that are not e-Co mmerce) all the criteria have been selected more in non e-Commerce queries than in e-Commerce ones (i.e., blue/darker bars are always higher than yellow/lighter bars). In the second chart (concern-ing 9 criteria that are e-Comme rce), the converse is usually true, but not for all criteria (genre and personal aspects are the exceptions). Accuracy and depth score high for non e-Commerce (also consistent with [2]). The availability, price, and brand name of a product are the driving criteria for e-Commerce. It can be argued that genre and personal as-pects are less e-Commerce than the other ones. However, maybe some of our instructions were not very clear for the workers, so further experimentation needs to be done.
As part of the experiment, workers have the option to leave comments about their task. This was very useful for gathering extra data points that were not covered in the cri-teria presented. We list here some of the most interesting comments, collected from both this experiment and a previ-ous one on a reduced data set, that suggest new criteria or explicitly confirm the classical ones (emphasis added):  X 
About buying boots:  X  X hen looking for a product online there is also the need to see return policy information as well aid to resolve problems should they arise. X   X 
About buying a black polo shirt:  X  X  do not worry about to many things when buying shirts. My primary focus would be on the price and value . X   X 
About buying an engagement ring:  X  X t would be impor-tant for me to know the source is valid and not a spam of phishing attempt . X   X  About buying 2009 Hy undai Genesis:  X  X  trust Hyundai. X 
