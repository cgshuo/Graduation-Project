 University of Cambridge University of Cambridge University of Cambridge
Metaphor is highly frequent in language, which makes its computational processing indis-pensable for real-world NLP applications addressing semantic tasks. Previous approaches to metaphormodelingrelyontask-specifichand-codedknowledgeandoperateonalimiteddomain or a subset of phenomena. We present the first integrated open-domain statistical model of model of metaphor interpretation is compatible with other NLP applications that can benefit parsingandlexicalacquisitiontechnologies(distributionalclusteringandselectionalpreference induction),andoperateswithahighaccuracy. 1. Introduction
Our production and comprehension of language is a multi-layered computational process. Humans carry out high-level semantic tasks effortlessly by subconsciously using a vast inventory of complex linguistic devices, while simultaneously integrating their background knowledge, to reason about reality. An ideal computational model of language understanding would also be capable of performing such high-level se-mantic tasks. With the rapid advances in statistical natural language processing (NLP) and computational lexical semantics, increasingly complex semantic tasks can now be addressed. Tasks that have received much attention so far include, for example, word sense disambiguation (WSD), supervised and unsupervised lexical classification, selectional preference induction, and semantic role labeling. In this article, we take a step further and show that state-of-the-art statistical NLP and computational lexical semantictechniquescanbeusedtosuccessfullymodelcomplexmeaningtransfers,such as metaphor.
Humans often use metaphor to describe abstract concepts through reference to more concrete or physical experiences. Some examples of metaphor include the following.
Metaphoricalexpressionsmaytakeagreatvarietyofforms,rangingfromconventional metaphors,whichweproduceandcomprehendeveryday,forexample,thoseinExam-ples(1) X (3),topoeticandnovelones,suchasExample(4).Inmetaphoricalexpressions, seemingly unrelated features of one concept are attributed to another concept. In Ex-ample (1), a computationalprocess is viewed as something alive and, therefore, its forced termination is associated with the act of killing. In Example (2) Hillary is not literally cleaning the space by sweeping accusations. Instead, the accusations lose their validity inthatsituation,inotherwordsHillary rejects them.Theverbs brushaside and reject both entail the resulting disappearance of their object, which is the shared salient property that makes it possible for this analogy to be lexically expressed as a metaphor. and thus of all types of discourse, metaphor becomes an important problem for NLP.
AsShutovaandTeufel(2010)haveshowninanempiricalstudy,theuseofconventional metaphor is ubiquitous in natural language text (according to their data, on average every third sentence in general-domain text contains a metaphorical expression). This makes metaphor processing essential for automatic text understanding. For example, an NLP application which is unaware that a  X  leaked report X  is a  X  X isclosed report X  and not, for example, a  X  X et report, X  would fail further semantic processing of the piece of discourse in which this phrase appears. A system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable componentofanyreal-worldNLPapplicationthatneedstoaccesssemantics(e.g.,infor-mation retrieval [IR], machine translation [MT], question answering [QA], information extraction [IE], and opinion mining).
 thus often fail to interpret metaphorical data correctly. Consider an example from MT.
Figure 1 shows metaphor translation from English into Russian by a state-of-the-art statistical MT system (Google Translate 1 ). For both sentences the MT system produces tions. This results in otherwise grammatical sentences being semantically infelicitous, poorlyformed,andbarelyunderstandabletoanativespeakerofRussian.Themeaning of stir inFigure1(1)and spill inFigure1(2)wouldnormallyberealizedinRussianonly via their literal interpretation in the given context ( provoke and tell ), as shown under 302 avoid such errors. We conducted a pilot study of the importance of metaphor for MT, by running an English-to-Russian MT system (Google Translate) on the sentences from the data set of Shutova (2010) containing single-word verb metaphors. We found that 27 out of 62 sentences (44%) were translated incorrectly due to metaphoricity. Due to thehighfrequencyofmetaphorintextaccordingtocorpusstudies,suchahighlevelof error becomes important for MT.
 mining, that is, detection of the speaker X  X  attitude to what is said and to the topic.
Consider the following sentences. (5) a. Government looseneditsstrangle-hold on business. (Narayanan 1999) Both sentences describe the same fact. The use of the metaphor loosenedstrangle-hold in
Example (5a) suggests that the speaker opposes government control of economy, how-ever, whereas Example (5b) does not imply this. One can infer the speaker X  X  negative attitudeviathepresenceofanegativeword strangle-hold .Ametaphorprocessingsystem would establish the correct meaning of Example (5a) and thus discover the actual fact towards which the speaker has a negative attitude.
 logical comparisons, the development of a complete and computationally practical account of this phenomenon is a challenging and complex task. Despite the impor-tance of metaphor for NLP systems dealing with semantic interpretation, its automatic processing has received little attention in contemporary NLP, and is far from being a solved problem. The majority of computational approaches to metaphor still exploit ideas articulated twoor threedecades ago (Wilks 1978; Lakoff andJohnson 1980). They often rely on task-specific hand-coded knowledge (Martin 1990; Fass 1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004; Agerri et al. 2007) and reduce the task to reasoning about a limited domain or a subset of phenomena (Gedigian et al. 2006; Krishnakumaran and Zhu 2007). So far there has been no robust statisticalsystemoperatingonunrestrictedtext.State-of-the-artaccurateparsing(Klein andManning2003;Briscoe,Carroll,andWatson2006;ClarkandCurran2007),however, as well as recent work on computational lexical semantics (Schulte im Walde 2006;
Mitchell and Lapata 2008; Davidov, Reichart, and Rappoport 2009; Erk and McCarthy 2009; Sun and Korhonen 2009; Abend and Rappoport 2010;  X  many avenues for the creation of such a system. This is the niche the presented work is intending to fill. 1.1 What Is Metaphor?
Metaphor has traditionally been viewed as an artistic device that lends vividness and distinction to an author X  X  style. This view was first challenged by Lakoff and Johnson (1980), who claimed that it is a productive phenomenon that operates at the level of mental processes. According to Lakoff and Johnson, metaphor is thus not merely a property of language (i.e., a linguistic phenomenon), but rather a property of thought (i.e., a cognitive phenomenon). This view was subsequently adopted and extended by a multitude of approaches (Grady 1997; Narayanan 1997; Fauconnier and Turner 2002; Feldman 2006; Pinker 2007) and the term conceptual metaphor was coined to describe it.
 tensions of individual words, but rather involves reconceptualization of a whole area of experience in terms of another. Thus metaphor always involves two concepts or conceptual domains:the target (alsocalledthe topic or tenor inthelinguisticsliterature) and the source (also called the vehicle ).Consider Examples (6) and (7).
AccordingtoLakoffandJohnson,amappingoftheconceptof argument tothatof war is used in both Examples (6) and (7). The argument , which is the target concept, is viewed intermsofa battle (ora war ),thesourceconcept.Theexistenceofsuchalinkallowsusto talkabout arguments using war terminology,thusgivingrisetoanumberofmetaphors.
Conceptual metaphor, or source X  X arget domain mapping , is thus a generalization over a set of individual metaphorical expressions that covers multiple cases in which ways of reasoning about the source domain systematically correspond to ways of reasoning about the target.
 metaphor (or metaphorical expressions) in a variety of ways. The most common types of linguistic metaphor are lexical metaphor (i.e., metaphor at the level of a single word sense, as in the Examples (1) X (4)), multi-word metaphorical expressions (e.g.,  X  X hetherwe goonpilgrimage withRaleighor putouttosea withTennyson X ),or extended metaphor, that spans over longer discourse fragments.
 conceptual metaphor individual words can be used in entirely novel contexts, which results in the formation of new meanings. Consider the following example. and its meaning adapts accordingly. Metaphor is a productive phenomenon (i.e., its 304 novel examples continue to emerge in language). A large number of metaphorical expressions, however, become conventionalized (e.g.,  X  X  cannot grasp his way of think-ing X ).Althoughmetaphoricalinnature,theirmeaningsaredeeplyentrenchedinevery-day use, and are thus cognitively treated as literal terms. Both novel and conventional metaphors are important for text processing, hence our work is concerned with both types. Fixed non-compositional idiomatic expressions (e.g., kickthebucket , rocktheboat , putadamperon ), however, are left aside, because the mechanisms of their formation are no longer productive in modern language and, as such, they are of little interest for the design of a generalizable computational model of metaphor.
 example of extended metaphor can be found in William Shakespeare X  X  play AsYouLike
It , where he first compares the world to a stage and then in the following discourse describes its inhabitants as players. Extended metaphor often appears in literature in the form of an allegory or a parable , whereby a whole story from one domain is metaphorically transferred onto another in order to highlight certain attributes of the subject or teach a moral lesson. 1.2 Computational Modeling o fMetaphor In this article we focus on lexical metaphor and the computational modeling thereof.
From an NLP viewpoint, not all metaphorical expressions are equally important. A metaphorical expression is interesting for computational modeling if its metaphorical sense is significantly distinct from its original literal sense and cannot be interpreted directly (e.g., by existing word sense disambiguation techniques using a predefined sense inventory). The identification of highly conventionalized metaphors (e.g., the verb impress ,whosemeaningoriginallystemsfromprinting)arenotofinterestforNLP tasks,becausetheirmetaphoricalsenseshavelongbeendominantinlanguageandtheir originalliteralsensesmaynolongerbeused.Anumberofconventionalizedmetaphors, however, require explicit interpretation in order to be understood by computer (e.g.,  X  cast doubt, X   X  polish the thesis, X   X  catch a disease X ), as do all novel metaphors. Thus we are concerned with both novel and conventional metaphors, but only consider the caseswherebytheliteralandmetaphoricalsensesofthewordareinclearoppositionin common use in contemporary language.
 identification ,or recognition (distinguishing between literal and metaphorical language in text); and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). An ideal metaphor processing system should address both of these tasks and provide useful information to support semantic interpretation in real-world NLP applications. In order to be directly applicable to other NLP systems, it should satisfy the following criteria: tasks,resultinginthefirstintegrateddomain-independentcorpus-basedcomputational model of metaphor. The method is designed with the listed criteria in mind. It takes unrestricted text as input and produces textual output. Metaphor identification and interpretation modules, based on the algorithms of Shutova, Sun, and Korhonen (2010) and Shutova (2010), are first evaluated independently, and then combined and evalu-ated together as an integrated system. All components of the method are in principle applicable to all part-of-speech classes and syntactic constructions. In the current ex-periments,however,wetestedthesystemonlyonsingle-wordmetaphorsexpressedby a verb. Verbs are frequent in language and central to conceptual metaphor. Cameron (2003) conducted acorpusstudy oftheuseofmetaphorineducational discourse forall partsofspeech.Shefoundthatverbsaccountforaround50%ofthedata,therestbeing sharedbynouns,adjectives,adverbs,copulaconstructions,andmulti-wordmetaphors.
This suggests that verb metaphors provide a reliable testbed for both linguistic and computational experiments. Restricting the scope to verbs is a methodological step aimedattestingthemainprinciplesoftheproposedapproachinawell-definedsetting.
We would, however, expect the presented methods to scale to other parts of speech and to a wide range of syntactic constructions, because they rely on techniques from computational lexical semantics that have been shown to be effective in modeling not only verb meanings, but also those of nouns and adjectives.
 from a hand-crafted description and applying it to explain the data, we aim to design a statistical model that captures regular patterns of metaphoricity ina large corpus and thus generalizes to unseen examples. Compared to labor-intensive manual efforts, this approach is more robust and, being nearly unsupervised, cost-effective. In contrast to previous statistical approaches, which addressed metaphors of a specific topic or did not consider linguistic metaphor at all (e.g., Mason 2004), the proposed method covers all metaphors in principle, can be applied to unrestricted text, and can be adapted to different domains and genres. 306 sions in unrestricted text. Starting from a small set of metaphorical expressions, the systemlearnstheanalogiesinvolvedintheirproductioninaminimallysupervisedway.
It generalizes over the exemplified analogies by means of verb and noun clustering (i.e., the identification of groups of similar concepts). This generalization allows it to recognize previously unseen metaphorical expressions in text. Consider the following examples:
Having once seen the metaphor  X  stir excitement X  in Example (9) the metaphor identifi-cation system successfully concludes that  X  swallow anger X  in Example (10) is also used metaphorically.
 tation task should be aimed at producing a representation of metaphor understanding thatcanbedirectlyembeddedintootherNLPapplicationsthatcouldbenefitfrommeta-phor resolution. We define metaphor interpretation as a paraphrasing task and build a system that discovers literal meanings of metaphorical expressions in text and pro-ducestheirliteralparaphrases.Forexample,formetaphorsinExamples(11a)and(12a) the system produces the paraphrases in Examples (11b) and (12b), respectively. (11) a. All of this stirred an uncontrollable excitement in her. (12) a. a carelessly leaked report
The paraphrases for metaphorical expressions are acquired in a data-driven manner from a large corpus. Literal paraphrases are then identified using a selectional prefer-ence model.
 phor,thendescribesthedesignoftheidentificationandparaphrasingmodulesandtheir independentevaluation,andconcludeswiththeevaluationoftheintegratedtext-to-text metaphor processing system. The evaluations were carried out with the aid of human subjects.Inthecaseofidentification,thesubjectswereaskedtojudgewhetherasystem-annotated phrase is a metaphor. In case of paraphrasing, they had to decide whether the system-produced paraphrase for the metaphorical expression is correct and literal in the given context. In addition, we created a metaphor paraphrasing gold standard by asking human subjects (not previously exposed to system output) to produce their ownliteralparaphrasesformetaphoricalverbs.Thesystemparaphrasingwasthenalso evaluated against this gold standard. 2. Theoretical and Computational Background 2.1 Metaphor and Polysemy
Theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic ) metaphors (i.e., those that are imaginative), and conventionalized metaphors (i.e., those that are used as a part of an ordinary discourse). According to Nunberg (1987),allmetaphorsemergeasnovel,butovertimetheybecomepartofgeneralusage andtheirrhetoricaleffectvanishes,resultinginconventionalizedmetaphors.Following
Orwell (1946), Nunberg calls such metaphors  X  X ead X  and claims that they are not psychologically distinct from literally used terms. The scheme described by Nunberg demonstrates how metaphorical associations capture patterns governing polysemy, namely,thecapacityofawordtohavemultiplemeanings.Overtimesomeoftheaspects ofthetargetdomainareaddedtothemeaningofaterminthesourcedomain,resulting in a (metaphorical) sense extension of this term. Copestake and Briscoe (1995) discuss sense extension mainly based on metonymic examples and model the phenomenon usinglexicalrulesencodingmetonymicpatterns.Theyalsosuggestthatsimilarmecha-nisms can be used to account for metaphorical processes. According to Copestake and
Briscoe, the conceptual mappings encoded in the sense extension rules would define the limits to the possible shifts in meaning.
 word senses, although unsystematically and without any accompanying semantic an-notation. For example, WordNet 2 (Fellbaum 1998) contains the comprehension sense of grasp , defined as  X  X et the meaning of something, X  and the reading sense of skim , defined as  X  X ead superficially. X  A great deal of metaphorical senses are absent from the current version of WordNet, however. A number of researchers have advocated the necessity of systematic inclusion and mark-up of metaphorical senses in such general-domainlexicalresources(AlongeandCastelli2003;L  X  onnekerandEilts2004)andclaim that this would be beneficial for the computational modeling of metaphor. Metaphor processing systems could then either use this knowledge or be evaluated against it. L  X  onneker (2004) mapped the senses from EuroWordNet 3 to the Hamburg Metaphor
Database (L  X  onneker 2004; Reining and L  X  onneker-Rodman 2007) containing examples of metaphorical expressions in German and French. Currently no explicit information about metaphor is integrated into WordNet for English, however.
 metaphorical senses, it is not viable for novel contextual sense alternations. Because metaphor is a productive phenomenon, all possible cases of contextual meaning alter-nations it results in cannot be described via simple sense enumeration (Pustejovsky 1995). Computational metaphor processing therefore cannot be approached using the standard word sense disambiguation paradigm, whereby the contextual use of a word is classified according to an existing sense inventory. The metaphor interpretation task is inherently more complex and requires generation of new and often uncommon meanings of the metaphorical term based on the context. 2.2 Theoretical Views on Metaphor
The following views on metaphor are prominent in linguistics and philosophy: the comparisonview(e.g.,theStructure-MappingTheoryofGentner[1983]),theinteraction view (Black 1962; Hesse 1966), the selectional restrictions violation view (Wilks 1975, 1978), and conceptual metaphor theory (CMT) (Lakoff and Johnson 1980). All of these 308 approachessharetheideaofaninterconceptualmappingthatunderliestheproduction of metaphorical expressions. Gentner X  X  Structure-Mapping Theory postulates that the ground for metaphor lies in similar properties and relations shared by the two con-cepts (the target and the source). Tourangeau and Sternberg (1982), however, criticize this view by noting that  X  X verything has some feature or category that it shares with everything else, but we cannot combine just any two things in metaphor X  (Tourangeau andSternberg1982,page226).Theinteractionviewfocusesonthesurpriseandnovelty thatmetaphorintroduces.Itsproponentsclaimthatthesourceconcept(ordomain)rep-resents a template for seeing the target concept in an entirely new way. The conceptual metaphor theory of Lakoff and Johnson (1980) takes this idea much further by stating that metaphor operates at the level of thought rather than at the level of language, and thatitisbasedonasetofcognitivemappingsbetweensourceandtargetdomains.Thus
Lakoff and Johnson put the emphasis on the structural aspect of metaphor, rather than its decorative function in language that dominated the preceding theories. The selec-tional restrictions violation view of Wilks (1978) concerns manifestation of metaphor in language. Wilks suggests that metaphor represents a violation of combinatory norms in the linguistic context and that metaphorical expressions can be detected via such violation. 2.2.1 Conceptual Metaphor Theory. Examples (6) and (7) provided a good illustration of CMT. Lakoff and Johnson explain them via the conceptual metaphor ARGUMENT IS
WAR, which is systematically reflected in language in a variety of expressions.
AccordingtoCMT,weconceptualizeandstructureargumentsintermsofbattle,which systematically influences the way we talk about arguments within our culture. In other words, the conceptual structure behind battle (i.e., that one can shoot, demolish, devise a strategy, win, and so on), is metaphorically transferred onto the domain of argument.
 cation. Here are a few other examples of common metaphorical mappings.
 tivescience,andartificialintelligence,includingNLP.Itinspirednovelresearch(Martin 1990,1994;Narayanan1997,1999;BarndenandLee2002;FeldmanandNarayanan2004;
Mason 2004; Martin 2006; Agerri et al. 2007), but was also criticized for the lack of consistency and empirical verification (Murphy 1996; Shalizi 2003; Pinker 2007). The soleevidencewithwhichLakoffandJohnson(1980)supportedtheirtheorywasasetof carefullyselectedexamples.Suchexamples,albeitclearlyillustratingthemaintenetsof the theory, are not representative. They cannot possibly capture the whole spectrum of metaphorical expressions, and thus do not provide evidence that the theory can adequately explain the majority of metaphors in real-world texts. Aiming to verify the latter,ShutovaandTeufel(2010)conductedacorpus-basedanalysisofconceptualmeta-phor in the data from the British National Corpus (BNC) (Burnard 2007). In their study threeindependentparticipantsannotatedbothlinguisticmetaphorsandtheunderlying source X  X arget domainmappings. Theirresultsshowthatalthough theannotators reach some overall agreement on the annotation of interconceptual mappings, they experi-enced a number of difficulties, one of which was the problem of finding the right level of abstraction for the source and target domain categories. The difficulties in category assignmentforconceptualmetaphorsuggestthatitishardtoconsistentlyassignexplicit labels to source and target domains, even though the interconceptual associations exist in some sense and are intuitive to humans. 2.2.2SelectionalRestrictionsViolationView. LakoffandJohnsondonotdiscusshowmeta-phors can be recognized in linguistic data. To date, the most influential account of this issueisthatofWilks(1975,1978).AccordingtoWilks,metaphorsrepresentaviolationof selectional restrictions (or preferences )inagivencontext.Selectionalrestrictionsarethe semantic constraints that a predicate places onto its arguments. Consider the following example. (17) a. My aunt always drinks her tea on the terrace.
The verb drink normally requires a grammatical subject of type ANIMATE and a gram-matical object of type LIQUID, as in Example (17a). Therefore, drink taking a car as a subject in (17b) is an anomaly, which, according to Wilks, indicates a metaphorical use of drink .
 phor recognition (Fass and Wilks 1983; Fass 1991; Krishnakumaran and Zhu 2007), it is important to note that in practice this approach has a number of limitations. Firstly, thereareotherkindsofnon-literalnessoranomalyinlanguagethatcauseaviolationof semantic norm, such as metonymies. Thus the method would overgenerate. Secondly, there are kinds of metaphor that do not represent a violation of selectional restrictions (i.e., the approach may also undergenerate). This would happen, for example, when highly conventionalized metaphorical word senses are more frequent than the original literal senses. Dueto theirfrequency, selectional preference distributions of such words inreal-worlddatawouldbeskewedtowardsthemetaphoricalsenses(e.g., capture may select for ideas rather than captives according to the data). As a result, no selectional preferences violation can be detected in the use of such verbs. Another case where the 310 method does not apply is copula constructions, such as  X  X ll the world X  X  a stage . X  And finally, the method does not take into account the fact that interpretation (of metaphor as well as other linguistic phenomena) is always context-dependent. For example, the phrase  X  X ll men are animals  X  uttered by a biology professor or a feminist would have entirely different interpretations, the latter clearly metaphorical, but without any violation of selectional restrictions. 2.3 Computational Approaches to Metaphor 2.3.1AutomaticMetaphorRecognition. One of the first attempts to automatically identify and interpret metaphorical expressions in text is the approach of Fass (1991). It origi-nates in the idea of Wilks (1978) and utilizes hand-coded knowledge. Fass developed a system called met* , which is capable of discriminating between literalness, metonymy, metaphor, and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selectional preference violation as an indicator. In the case that non-literalness is detected, the respective phrase is tested for being metonymic using hand-coded patterns (such as CONTAINER-FOR-CONTENT). If the system fails torecognizemetonymy,itproceedstosearchtheknowledgebaseforarelevantanalogy in order to discriminate metaphorical relations from anomalous ones. For example, the sentenceinExample(17b)wouldberepresentedinthisframeworkas( car,drink,gasoline ), which does not satisfy the preference ( animal,drink,liquid ), as car is not a hyponym of animal . met* then searches its knowledge base for a triple containing a hypernym of both the actual argument and the desired argument and finds ( thing,use,energy source ), which represents the metaphorical interpretation.
 the presence of a metaphorical expression in running text, such as metaphorically speak-ing,utterly,completely,sotospeak ,and literally . This approach, however, is likely to find onlyasmallproportionofmetaphoricalexpressions,asthevastmajorityofthemappear without any signaling context. We conducted a corpus study in order to investigate the effectivenessoflinguisticcuesasmetaphorindicators.ForeachcuesuggestedbyGoatly (1997), we randomly sampled 50 sentences from the BNC containing it and manually annotated them for metaphoricity. The results are presented in Table 1. The average precision (i.e., the proportion of identified expressions that were metaphorical) of the linguistic cue method according to these data is 0.40, which suggests that the set of metaphors that this method generates contains a great deal of noise. Thus the cues are unlikely to be sufficient for metaphor extraction on their own, but together with some additional filters, they could contribute to a more complex system.
 in lexical resources. They mine WordNet (Fellbaum 1998) for examples of systematic polysemy, which allows them to capture metonymic and metaphorical relations. Their system searches for nodes that are relatively high in the WordNet hierarchy (i.e., are relativelygeneral)andthatshareasetofcommonwordformsamongtheirdescendants.
Peters and Peters found that such nodes often happen to be in a metonymic (e.g., publisher X  X ublication ) or a metaphorical (e.g., theory X  X upportingstructure )relation. target domain mappings automatically. It does this by finding systematic variations in domain-specific selectional preferences, which are inferred from texts on the Web. For example,MasoncollectstextsfromtheLABdomainandtheFINANCEdomain,inboth ofwhich pour wouldbeacharacteristicverb.IntheLABdomain pour hasastrongselec-tionalpreferenceforobjectsoftype liquid ,whereasintheFINANCEdomainitselectsfor money .FromthisMason X  X systeminfersthedomainmappingFINANCE X  X ABandthe conceptmappingMONEYISLIQUID.Hecomparestheoutputofhissystemagainstthe
Master Metaphor List (MML; Lakoff, Espenson, and Schwartz 1991) and reports a per-formance of 77% in terms of accuracy (i.e., proportion of correctly induced mappings). guage recognition, implemented in the TroFi system (Trope Finder). The idea behind their system originates from a similarity-based word sense disambiguation method developed by Karov and Edelman (1998). The latter uses a set of seed sentences anno-tatedwithrespecttowordsense.Thesystemcomputessimilaritybetweenthesentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and
Sarkar adapt this algorithm to perform a two-way classification (literal vs. non-literal), not aiming to distinguish between specific kinds of tropes. An example for the verb pour in their database is shown in Figure 2. They attain a performance of 0.54 in terms of F-measure (van Rijsbergen 1979).
 use. The authors trained a maximum entropy classifier for this purpose. They col-lected their data using FrameNet (Fillmore, Johnson, and Petruck 2003) and PropBank (Kingsbury and Palmer 2002) annotations. FrameNet is a lexical resource for English containing information on words X  semantic and syntactic combinatory possibilities, or valencies, in each of their senses. PropBank is a corpus annotated with verbal propo-sitions and their arguments. Gedigian et al. (2006) extracted the lexical items whose framesarerelatedtoMOTIONandCUREfromFrameNet,thensearchedthePropBank
Wall Street Journal corpus (Kingsbury and Palmer 2002) for sentences containing such lexical items and annotated them with respect to metaphoricity. For example, the verb run in the sentence  X  X exas Air has run into difficulty X  was annotated as metaphorical, and in  X  X  was doing the laundry and nearly broke my neck running upstairs to see X  as literal. Gedigian et al. used PropBank annotation (arguments and their semantic 312 however,only2.22percentagepointshigherthantheperformanceofthenaivebaseline assigningmajorityclasstoallinstances(92.90%).Suchhighperformanceoftheirsystem canbeexplainedbythefactthat92.90%oftheverbsofMOTIONandCUREintheirdata are used metaphorically, thus making the data set unbalanced with respect to target categories and making the task easier.
 expressed by a verb. The approach of Krishnakumaran and Zhu (2007) additionally covers metaphors expressed by nouns and adjectives. Krishnakumaran and Zhu use hyponymy relation in WordNet and word bigram counts to predict metaphors at a sentencelevel.Givenametaphorincopulaconstructions,oranIS-Ametaphor(e.g.,the famous quote by William Shakespeare  X  X ll the world X  X  a stage  X ) they verify if the two nounsinvolvedareinhyponymyrelationinWordNet,otherwisethissentenceistagged as containing a metaphor. They also treat expressions containing a verb or an adjective used metaphorically (e.g.,  X  X e planted good ideas in their minds X  or  X  X e has a fertile imagination X ). For those cases, they calculate bigram probabilities of verb X  X oun and adjective X  X oun pairs (including the hyponyms/hypernyms of the noun in question). If the combination is not observed in the data with sufficient frequency, the system tags the sentence as metaphorical. This idea is a modification of the selectional preference view of Wilks, although applied at the bigram level. Alternatively, one could extract verb X  X bject relations from parsed text. Compared to the latter, Krishnakumaran and
Zhu (2007) lose a great deal of information. The authors evaluated their system on a setofexamplesentencescompiledfromtheMasterMetaphorList,wherebyhighlycon-ventionalizedmetaphorsaretakentobenegativeexamples.Thustheydonotdealwith literalexamplesassuch.Essentially, thedistinctionKrishnakumaran andZhuaremak-ingisbetweenthesensesincludedinWordNet,eveniftheyareconventionalmetaphors (e.g., X  capture anidea X ),andthosenotincludedinWordNet(e.g., X  planted goodideas X ). 2.3.2AutomaticMetaphorInterpretation. Oneofthefirstcomputationalaccountsofmeta-phor interpretation is that of Martin (1990). In his metaphor interpretation, denotation and acquisition system (MIDAS), Martin models the hierarchical organization of con-ventional metaphors. The main assumption underlying this approach is that more spe-cific conventional metaphors (e.g., COMPUTATIONAL PROCESS viewed as a LIVING
BEING in  X  X ow can I kill a process? X ) descend from more general ones (e.g., PROCESS [general,asasequenceofevents]isaLIVINGBEING).Givenanexampleofametaphor-ical expression, MIDAS searches its database for a corresponding conceptual metaphor that would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If a suitable general metaphor is found, it creates a new mapping for its descendant, a more specific metaphor, based on this example. This is also how novel conceptual metaphors are acquired by the system.
The metaphors are then organized into a resource called MetaBank (Martin 1994). The knowledge is represented in MetaBank in the form of metaphor maps (Martin 1988) containingdetailedinformationaboutsource-targetconceptmappingsandempirically derived examples. MIDAS has been integrated with Unix Consultant, a system that answersusers X  X uestionsaboutUnix.Thesystemfirsttriestofindaliteralanswertothe question. If it is not able to, it calls MIDAS, which detects metaphorical expressions via selectionalpreferenceviolationandsearchesitsdatabaseforametaphorexplainingthe anomaly in the question.
 in the source and target domains for the purpose of metaphor interpretation. These include the KARMA system (Narayanan 1997, 1999; Feldman and Narayanan 2004) and the ATT-Meta project (Barnden and Lee 2002; Agerri et al. 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance withCMT.Thereasoningprocessreliesonmanuallycodedknowledgeabouttheworld andoperatesmainlyinthesourcedomain.Theresultsarethenprojectedontothetarget domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states; and reasoning about mental statesisperformedusingfirstorderlogic.Theirsystem,however,doesnottakenatural language sentences as input, but hand-coded logical expressions that are representa-tionsofsmalldiscoursefragments.KARMAinturndealswithabroadrangeofabstract actions and events and takes parsed text as input.
 pretationandgeneration X  X alledTalkingPoints.TalkingPointsisasetofcharacteristics of concepts belonging to source and target domains and related facts about the world which are acquired automatically from WordNet and from the Web. Talking Points are thenorganizedin Slipnet ,aframeworkthatallowsforanumberofinsertions,deletions, andsubstitutionsindefinitionsofsuchcharacteristicsinordertoestablishaconnection between the target and the source concepts. This work builds on the idea of slippage in knowledgerepresentationforunderstandinganalogiesinabstractdomains(Hofstadter and Mitchell 1994; Hofstadter 1995). The following is an example demonstrating how slippage operates to explain the metaphor Make-upisaWesternburqa .
 callywornbywomen X  X othatof X  X ustbewornbyMuslimwomen. X  X husitestablishes a link between the concepts of make-up and burqa . Veale and Hao, however, did not evaluate to what extent their system is able to interpret metaphorical expressions in real-world text.
 identification and interpretation. 3. Metaphor Identification Method and Experiments
The first task for metaphor processing within NLP is its identification in text. As dis-cussed earlier, previous approaches to this problem either utilize hand-coded knowl-edge (Fass 1991; Krishnakumaran and Zhu 2007) or reduce the task to searching for metaphorsofaspecificdomaindefinedapriori(e.g.,MOTIONmetaphors)inaspecific type of discourse (e.g., the Wall Street Journal [Gedigian et al. 2006]). In contrast, the search space in our experiments is the entire BNC and the domain of the expressions identified is unrestricted. In addition, the developed technique does not rely on any hand-crafted lexical or world knowledge, but rather captures metaphoricity by means of verb and noun clustering in a data-driven manner.
 taskliesinCMT.Thepatternsofconceptual metaphor (e.g.,FEELINGSARELIQUIDS) 314 always operate on semantic classes, that is, groups of related concepts, defined by Lakoff and Johnson as conceptual domains (FEELINGS include love, anger, hatred, etc.;
LIQUIDS include water,tea, petrol,beer, etc.). Thus modeling metaphorical mechanisms in accordance with CMT would involve capturing such semantic classes automatically.
Previous research on corpus-based lexical semantics has shown that it is possible to automatically induce semantic word classes from corpus data via clustering of contex-tual cues (Pereira, Tishby, and Lee 1993; Lin 1998; Schulte im Walde 2006). The current consensusisthatthelexicalitemsshowingsimilarbehaviorinalargebodyoftextmost likely have related meanings.
 is suggested by the results of corpus-based studies of conceptual metaphor. The anal-ysis of conceptual mappings in unrestricted text, conducted by Shutova and Teufel (2010),althoughconfirmingsomeaspectsofCMT,uncoveredanumberoffundamental difficulties. One of these is the choice of the level of abstraction and granularity of categories (i.e., labels for source and target domains). This suggests that it is hard to define a comprehensive inventory of labels for source and target domains. Thus a computational model of metaphorical associations should not rely on explicit domain labels. Unsupervised methods allow us to recover patterns in data without assigning any explicit labels to concepts, and thus to model interconceptual mappings implicitly. clustering. Noun clustering, specifically, is central to the approach. It is traditionally assumed that noun clusters produced using distributional clustering contain concepts that are similar to each other. This is true only in part, however. There exist two types of concepts: concrete , those concepts denoting physical entities or physical experiences at any particular time or place, but rather exist as a type of thing or as an idea (e.g., cally, rather than concrete concepts. Humans use metaphor attempting to gain a better understanding of an abstract concept by comparing it to their physical experiences. As a result, abstract concepts expose different distributional behavior in a corpus. This in turn affects the application of clustering techniques and the obtained clusters for concreteandabstractconceptswouldbestructureddifferently.Considertheexamplein
Figure 3. The figure shows a cluster containing concrete concepts (on the right) that are variouskindsofmechanisms;aclustercontainingverbsco-occurringwithmechanisms in the corpus (at the bottom); and a cluster containing abstract concepts (on the left) that tend to co-occur with these verbs. Such abstract concepts, albeit having quite distinctmeanings(e.g., marriage and democracy ),areobservedinsimilarlexico-syntactic environments. This is due to the fact that they are systematically used metaphorically with the verbs from the domain of MECHANISM. Hence, they are automatically assigned to the same cluster. The following examples illustrate this phenomenon in textual data.
Such a structure of the abstract clusters can be explained by the fact that relationships , marriages , collaborations ,and political systems are all cognitively mapped to the same source domain of MECHANISM. In contrast to concrete concepts, such as tea, water, coffee, beer, drink, liquid , that are clustered together when they have similar meanings, abstract concepts tend to be clustered together if they are associated with the same sourcedomain.Wedefinethisphenomenonas clustering by association anditbecomes central to the system design. The expectation is that clustering by association would allow the harvesting of new target domains that are associated with the same source domain, and thus identify new metaphors.
 expressions,thatis,annotatedmetaphors(suchasthoseinExamples(18)or(19)),which serve as training data. Note that seed annotation only concerns linguistic metaphors; metaphorical mappings are not annotated. The system then (1) creates source domains describing these examples by means of verb clustering (such as the verb cluster in
Figure 3); (2) identifies new target domains associated with the same source domain by means of noun clustering (see, e.g., ABSTRACT cluster in Figure 3), and (3) establishes a link between the source and the target clusters based on the seed examples. the associated domains by means of verb and noun clustering. The obtained clusters then represent source and target concepts between which metaphorical associations hold. The knowledge of such associations is then used to identify new metaphorical expressions in a large corpus.
 idea stems from the view of Wilks (1978), but is, however, a modification of it. The filter assumes that the verbs exhibiting weak selectional preferences, namely, verbs co-occurring with any argument class in linguistic data ( remember,influence, etc.) generally have no or only weak potential for being a metaphor. It has been previously shown that it is possible to quantify verb selectional preferences on the basis of corpus data, using, for example, a measure defined by Resnik (1993). Once the candidate metaphors areidentifiedinthecorpususingclusteringmethods,thosedisplayingweakselectional preferences can be filtered out.
 tion of metaphorical associations and then that of metaphorical expressions in text. In 316 summary,thesystem(1)startsfromaseedsetofmetaphoricalexpressionsexemplifying a range of source X  X arget domain mappings; (2) performs noun clustering in order to harvest various target concepts associated with the same source domain; (3) creates a source domain verb lexicon by means of verb clustering; (4) searches the corpus for metaphorical expressions describing the target domain concepts using the verbs from the source domain lexicon; and (5) filters out the candidates exposing weak selectional preference strength as non-metaphorical.
 3.1 Experimental Data
The identification system takes a list of seed phrases as input. Seed phrases contain manually annotated linguistic metaphors. The system generalizes from these linguistic metaphors to the respective conceptual metaphors by means of clustering. This gen-eralization is then used to harvest a large number of new metaphorical expressions in unseentext.Thusthedataneededfortheidentificationexperimentconsistofaseedset, datasetsofverbsandnounsthataresubsequentlyclustered,andanevaluationcorpus. 3.1.1 Metaphor Corpus and Seed Phrases. The data to test the identification module were extractedfromthemetaphorcorpuscreatedbyShutovaandTeufel(2010).Theircorpus is a subset of the BNC (Burnard 2007) and, as such, it provides a suitable platform for testing the metaphor processing system on real-world general-domain expressions in contemporary English. Our data set consists of verb X  X ubject and verb X  X irect object metaphorical expressions. In order to avoid extra noise, we enforced some additional selection criteria. All phrases were included unless they fell in one of the following categories:
The resulting data set consists of 62 phrases that are different single-word metaphors representing verb X  X ubject and verb X  X irect object relations, where a verb is used meta-phorically. The phrases include, for instance,  X  stir excitement, X   X  reflect enthusiasm, X   X  grasp theory, X  X  cast doubt, X  X  suppress memory, X  X  throw remark X (verb X  X irectobjectcon-structions); and  X  X ampaign surged , X   X  X actor shaped [...], X   X  X ension mounted , X   X  X deology embraces , X   X  X xample illustrates  X  (subject X  X erb constructions). This data set was used as a seed set in the identification experiments. The phrases in the data set were manually annotated for grammatical relations. 3.1.2 Verb and Noun Data Sets. The noun data set used for clustering consists of the 2,000 most frequent nouns in the BNC. The 2,000 most frequent nouns cover most common target categories and their linguistic realizations. BNC represents a suitable 318 source for such nouns because the corpus is balanced with respect to genre, style, and theme.
 resourceforgeneral-domainverbsorganizedintosemanticclassesasproposedbyLevin (1993). The data set includes all the verbs in VerbNet with the exception of highly infrequent ones. The frequency of the verbs was estimated from the data collected by
Korhonen, Krymolowski, and Briscoe (2006) for the construction of the V ALEX lexicon, whichtodateisoneofthelargestautomaticallycreatedverbresources.Theverbsfrom
VerbNet that appear less than 150 times in this data were excluded. The resulting data set consists of 1,610 general-domain verbs. 3.1.3 Evaluation Corpus. The evaluation data for metaphor identification was the BNC parsed by the RASP parser (Briscoe, Carroll, and Watson 2006). We used the gram-matical relation (GR) output of RASP for the BNC created by Andersen et al. (2008).
The system searched the corpus for the source and target domain vocabulary within a particular grammatical relation (verb X  X irect object or verb X  X ubject). 3.2 Method
The main components of the method include (1) distributional clustering of verbs and nouns, (2) search through the parsed corpus, and (3) selectional preference-based filtering. 3.2.1 Verb and Noun Clustering Method. The metaphor identification system relies on the clustering method of Sun and Korhonen (2009). They use a rich set of syntactic and semantic features (GRs, verb subcategorization frames [SCFs], and selectional preferences) and spectral clustering, a method particularly suitable for the resulting high dimensional feature space. This algorithm has proved to be effective in previous verb clustering experiments (Brew and Schulte im Walde 2002) and in other NLP tasks involving high dimensional data (Chen et al. 2006).
 of data points, the similarity matrix records similarities between all pairs of points. The system of Sun and Korhonen (2009) constructs similarity matrices using the Jensen-
Shannon divergence as a measure. Jensen-Shannon divergence between two feature vectors w i and w j is defined as follows: where D is the Kullback-Leibler divergence, and m is the average of the w
G over a set of words W . The weights on the edges of G are the similarities S similarity matrix S thus represents the adjacency matrix for G . The clustering problem is then defined as identifying the optimal partition, or cut , of the graph into clusters, such that the intra-cluster weights are high and the inter-cluster weights are low. The system of Sun and Korhonen (2009) uses the MNCut algorithm of Meila and Shi (2001) for this purpose.
 17 Levin classes and obtained an F-measure of 80.4, which is the state-of-the-art performance level. The metaphor identification system uses the method of Sun and
Korhonentoclusterbothverbsandnouns(separately),however,significantlyextending its coverage to unrestricted general-domain data and applying the method to a con-siderably larger data set of 1,610 verbs. 3.2.2FeatureExtractionandClusteringExperiments. Forverbclustering,thebestperform-ing features from Sun and Korhonen (2009) were adopted. These include automatically acquired verbSCFsparameterized bytheirselectional preferences. Thesefeatureswere obtained using the SCF acquisition system of Preiss, Briscoe, and Korhonen (2007). The systemtagsandparsescorpusdatausingtheRASPparser(Briscoe,Carroll,andWatson 2006) and extracts SCFs from the produced grammatical relations using a rule-based classifier which identifies 168 SCF types for English verbs. It produces a lexical entry foreachverbandSCFcombinationoccurringincorpusdata.Theselectionalpreference classes were obtained by clustering nominal arguments appearing in the subject and object slots of verbs in the resulting lexicon.

Bergsma, Lin, and Goebel 2008), grammatical relations were used as features for noun clustering. More specifically, the frequencies of nouns and verb lemmas appearing in the subject, direct object, and indirect object relations in the RASP-parsed BNC were includedinthefeaturevectors.Forexample,thefeaturevectorfor banana wouldcontain the following entries: { eat-dobj n 1 , fry-dobj n 2 , sell-dobj n obtained clusters, and determined that the number of clusters set to 200 is the most suitable setting for both nouns and verbs in our task. This was done by means of qual-itative analysis of the clusters as representations of source and target domains X  X hat is, by judging how complete and homogeneous the verb clusters were as lists of potential sourcedomainvocabularyandhowmanynewtargetdomainsassociatedwiththesame source domain were found correctly in the noun clusters. This analysis was performed on a randomly selected set of 10 clusters taken from different granularity settings and none of the seed expressions were used for it. Examples of such clusters are shown in
Figures6(nouns)and7(verbs),respectively.Thenounclustersrepresenttargetconcepts associated with the same source concept (some suggested source concepts are given in
Figure 6, although the system only captures those implicitly). The verb clusters contain lists of source domain vocabulary. 3.2.3CorpusSearch. Oncetheclustershavebeenobtained,thesystemproceedstosearch the corpus for source and target domain terms within verb X  X bject (both direct and indirect) and verb X  X ubject relations. For each seed expression, a cluster is retrieved for theverbtoformthesourceconcept,andaclusterisretrievedforthenountoformalist of target concepts. The retrieved verb and noun clusters are then linked, and such links representmetaphoricalassociations.Thesystemthenclassifiesgrammaticalrelationsin thecorpusasmetaphorical ifthelexicalitemsinthegrammaticalrelationappearinthe linked source (verb) and target (noun) clusters. This search is performed on the BNC parsedbyRASP.ConsiderthefollowingexamplesentenceextractedfromtheBNC(the
BNC text ID is given in brackets, followed by the hypothetical conceptual metaphor): (21) Few would deny that in the nineteenth century change was greatly accelerated . 320
TherelevantGRsidentifiedbytheparserarepresentedinFigure8.Therelationbetween the verb accelerate and its semantic object change in Example (21) is expressed in the passivevoiceandis,therefore,taggedbyRASPasan ncsubj GR.BecausethisGRcon-tains terminology from associated source (MOTION) and target (CHANGE) domains, it is marked as metaphorical and so is the term accelerate , which belongs to the source domain of MOTION. 3.2.4 Selectional Preference Strength Filter. In the previous step a set of candidate verb metaphors and the associated grammatical relations were extracted from the BNC. These now need to be filtered based on selectional preference strength. To do this, we automatically acquire selectional preference distributions for verb X  X ubject and verb X  direct object relations from the RASP-parsed BNC. The noun clusters obtained using SunandKorhonen X  X methodasdescribedearlierformtheselectionalpreferenceclasses.
To quantify selectional preferences, we adopt the selectional preference strength (SPS) measure of Resnik (1993). Resnik models selectional preferences of a verb in proba-bilistic terms as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position irrespectiveoftheidentityoftheverb.HequantifiesthisdifferenceusingtheKullback-Leibler divergence and defines selectional preference strength as follows: where P ( c ) is the prior probability of the noun class, P ( c ofthenounclassgiventheverb,and R isthegrammatical relationinquestion.Inorder to quantify how well a particular argument class fits the verb, Resnik defines another measure called selectional association : whichstandsforthecontributionofaparticularargumentclasstotheoverallselectional preference strength of a verb.
 intherelation R ,and f ( c )isthenumberoftimestheargumentclassoccursintherelation R regardless of the identity of the predicate.

This measure was used to filter out the verbs with weak selectional preferences. The expectation is that such verbs are unlikely to be used metaphorically. The optimal selectional preference strength threshold was set experimentally for both verb X  X ubject and verb X  X bject relations on a small held-out data set (via qualitative analysis of the data). It approximates to 1.32. The system excludes expressions containing the verbs with preference strength below this threshold from the set of candidate metaphors.
Examples of verbs with weak and strong direct object SPs are shown in Tables 2 and 3, respectively. Given the SPS threshold of 1.32, the filter discards 31% of candidate expressions initially identified in the corpus. 3.3 Evaluation
In order to show that the described metaphor identification method generalizes well over the seed set and that it operates beyond synonymy, its output was compared to 322 that of a baseline using WordNet. In the baseline system, WordNet synsets represent source and target domains. The quality of metaphor identification for both the system and the baseline was evaluated in terms of precision with the aid of human judges.
To compare the coverage of the system to that of the baseline in quantitative terms we assessedhowbroadlytheyexpandontheseedset.Todothis,weestimatedthenumber ofwordsensescapturedbythetwosystemsandtheproportionofidentifiedmetaphors that are not synonymous with any of those seen in the seed set, according to WordNet.
Thistypeofevaluationassesseshowwellclusteringmethodsaresuitedtoidentifynew metaphors not directly related to those in the seed set. 3.3.1 Comparison with WordNet Baseline. The baseline system was implemented using synonymy information from WordNet to expand on the seed set. Source and target domain vocabularies were thus represented as sets of synonyms of verbs and nouns in seed expressions. The baseline system then searched the corpus for phrases composed of lexical items belonging to those vocabularies. For example, given a seed expression stir turmoil, X  and so forth. It is not able to generalize over the concepts to broad semantic classes, however X  X or example, it does not find other FEELINGS such as rage, fear, anger, pleasure . This, however, is necessary to fully characterize the target domain.Similarly,inthesourcedomain,thesystemonlyhasaccesstodirectsynonyms of stir , rather than to other verbs characteristic of the domain of LIQUIDS ( pour, flow, boil, etc.).
 baseline in quantitative terms, we estimated the number of WordNet synsets, that is, different word senses, in the metaphorical expressions captured by the two sys-tems. We found that the baseline system covers only 13% of the data identified using clustering. This is due to the fact that it does not reach beyond the concepts present in the seed set. In contrast, most metaphors tagged by the clustering method (87%) are non-synonymous to those in the seed set and some of them are novel. Together, these metaphors represent a considerably wider range of meanings. Given the seed metaphors  X  stir excitement, throw remark, cast doubt, X  the system identifies previously unseen expressions  X  swallow anger, hurl comment, spark enthusiasm, X  and so on, as metaphorical.Tables4and5showexamplesofhowthesystemandthebaselineexpand on the seed set, respectively. Full sentences containing metaphors annotated by the system are shown in Figure 9. Twenty-one percent of the expressions identified by the systemdonothavetheircorrespondingmetaphoricalsensesincludedinWordNet,such as  X  spark enthusiasm X ; the remaining 79% are, however, more common conventional metaphors. Starting with a seed set of only 62 examples, the system expands signif-icantly on the seed set and identifies a total of 4,456 metaphorical expressions in the
BNC. This suggests that the method has the potential to attain a broad coverage of the corpus given a large and representative seed set. 3.3.2 Evaluation Against Human Judgments. In order to assess the quality of metaphor identification by both systems, their output was assessed by human judgments. For this purpose, we randomly sampled sentences containing metaphorical expressions as annotated by the system and by the baseline and asked human annotators to decide whether these were metaphorical or not.

Participants Five volunteers participated in the experiment. They were all native speakers of English and had no formal training in linguistics. 324
Materials The subjects were presented with a set of 78 randomly sampled sentences annotatedbythetwosystems.Fiftypercentofthedatasetwerethesentencesannotated bytheidentificationsystemandtheremaining50%wereannotatedbythebaseline;and the sentences were randomized. The annotation was done electronically in Microsoft Word. An example of annotated sentences is given in Figure 10.

Task and guidelines The subjects were asked to mark which of the expressions were metaphorical in their judgment. The participants were encouraged to rely on their own intuition of what a metaphor is in the annotation process. Additional guidance, however, in the form of the following definition of metaphor (Pragglejaz Group 2007) wasalsoprovided: 1. For each verb establish its meaning in context and try to imagine a more 2. If you can establish a basic meaning that is distinct from the meaning of 326 Interannotator agreement Reliabilitywasmeasuredat  X  = 0 . 63 ( n = 2, N = 78, k = 5).
The data suggest that the main source of disagreement between the annotators was the presence of conventional metaphors (e.g., verbs such as adopt,convey,decline ).
Results Thesystemperformancewasthenevaluatedagainsttheelicitedjudgmentsin terms of precision. The system output was compared to the gold standard constructed by merging the judgments, whereby the expressions tagged as metaphorical by at least three annotators were considered to be correct. This resulted in P = 0 . 79, with the baseline attaining P = 0 . 44. In addition, the system tagging was compared to that of each annotator pairwise, yielding an average P = 0 . 74 for the system and P = 0 . 41 for the baseline.
 was additionally calculated in terms of precision between the majority gold standard and each judge. This corresponds to an average of P = 0 . 94.
 line, we annotated additional 150 instances identified by both systems for correctness andconductedaone-tailedt-testforindependentsamples.Thedifferenceisstatistically significant with t = 4 . 11 (df = 148,p &lt; 0 . 0005). 3.4 Discussion
We have shown that the method leads to a considerable expansion on the seed set and operates with high precision X  X amely, it produces high quality annotations, and iden-tifies fully novel metaphorical expressions relying only on the knowledge of source X  target domain mappings that it learns automatically. By comparing its coverage to that of a WordNet baseline, we showed that the method reaches beyond synonymy and generalizes well over the source and target domains.
 baseline can be explained by the fact that a large number of metaphorical senses are includedinWordNet.ThismeansthatinWordNetsynsetssourcedomainverbsappear together with more abstract terms. For instance, the metaphorical sense of shape in the phrase  X  shape opinion X  is part of the synset  X (determine, shape, mold, influence, regulate). X  X hisresultsinthelowprecisionofthebaselinesystem,becauseittagsliteral expressions (e.g., influence opinion ) as metaphorical, assuming that all verbs from the synset belong to the source domain. the metaphorical expressions identified by the system (200 sentences, equally covering verb X  X ubject and verb X  X bject constructions). System precision against the additional judgments by one of the authors was measured at 76% (48 instances were tagged incorrectly according to the judgments). The classification of system errors by type is presentedinTable6.Precisionerrorsintheoutputofthesystemwerealsoconcentrated around the problem of conventionality of some metaphorical verbs, such as those in  X  hold views, adopt traditions, tackle a problem. X  This conventionality is reflected in the datainthatsuchverbsarefrequentlyusedintheir X  X etaphorical X  X ontexts.Asaresult, they are clustered together with literally used terms. For instance, the verb tackle is thesystemtagging X  X esolveaproblem X  X smetaphoricalifithaspreviouslyseen X  tackle a problem. X  polysemy and homonymy of both verbs and nouns. For example, the noun passage can mean both  X  X he act of passing from one state or place to the next X  and  X  X  section of text; particularly a section of medium length, X  as defined in WordNet. Sun and
Korhonen X  X  (2009) method performs hard clustering, that is, it does not distinguish between different word senses. Hence the noun passage occurred in only one cluster, and so on. This cluster models the  X  X extual X  meaning of passage . As a result of sense ambiguitywithinthecluster,giventheseedphrase X  X he blocked thethought, X  X hesystem tags such expressions as  X  X lock passage, X   X  X mpede passage, X   X  X bstruct passage, X  and  X  X peed passage X  as metaphorical.
 noun clustering considerably expands the seed set by identifying new associated tar-get concepts (e.g., given the seed metaphor  X  sell soul X  it identifies  X  sell skin X  and  X  launch pulse X  as metaphorical), the verb clusters sometimes miss a certain proportion of source domain vocabulary. For instance, given the seed metaphor  X  X xample illus-trates , X  the system identifies the following expressions:  X  X istory illustrates , X   X  X pisode does not, however, capture obvious verb-based expansions, such as  X  X pisode portrays , X  present in the BNC. This is one of the problems that could lead to a lower recall of the system.
 within the noun clusters used to detect new target domains, but also from dissim-ilar concepts in the verb clusters. Verb clusters produced automatically relying on 328 contextual features may contain lexical items with distinct, or even opposite meanings (e.g., throw and catch , take off and land ). They tend to belong to the same semantic domain, however (e.g., verbs of dealing with LIQUIDS, verbs describing a FIGHT) It is thediversityofverbmeaningswithinthedomainclusterthatallowsthegeneralization from a limited number of seed expressions to a broader spectrum of previously unseen and novel metaphors, non-synonymous with those in the seed set.
 affecting the coverage of the system. Wide coverage is essential for the practical use of the system. At this stage, however, it was impossible for us to reliably measure the recall of the system, because there is no large corpus annotated for metaphor available.
In addition, because the current system was only tested with very few seeds (again, due to the lack of metaphor-annotated data), we expect the current overall recall of the system to be relatively low. In order to obtain a full coverage of the corpus, a large and representative seed set is necessary. Although it is hard to capture the whole variety of metaphorical language in a limited set of examples, it is possible to compile a seed set representativeofallcommonsource X  X argetdomainmappings.Thelearningcapabilities of the system can then be used to expand on those to the whole range of conventional and novel metaphorical mappings and expressions. In addition, because the precision of the system was measured on the data set produced by expanding individual seed expressions, we would expect the expansion of other, new seed expressions to yield a comparablequalityofannotations.Incorporatingnewseedexpressionsisthuslikelyto result in increasing recall without a significant loss in precision.
 expressions from the corpus. These annotations could provide a new platform for the development and testing of other metaphor systems. 4. Metaphor Interpretation Method and Experiments
As is the case in metaphor identification, the majority of existing approaches to meta-phorinterpretationalsorelyontask-specifichand-codedknowledge(Martin1990;Fass 1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004;
Agerri et al. 2007) and produce interpretations in a non-textual format (Veale and Hao 2008). The ultimate objective of automatic metaphor processing, however, is a type of interpretation that can be directly embedded into other systems to enhance their performance. We thus define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. Our method is also distinguished from previous work in that it does notrelyonanyhand-craftedknowledgeaboutmetaphor,butincontrastiscorpus-based and uses automatically induced selectional preferences.
 paraphrases , that is, other ways of expressing the same meaning in a given context, and (2) discriminating between literal and metaphorical paraphrases. Consequently, the proposed approach is theoretically grounded in two ideas underlying each of these subtasks: the selectional preference model for literalness detection. The key difference between the two models is that the former favors the paraphrases that co-occur with the words in the context more frequently than other paraphrases do, and the latter favors the paraphrases that co-occur with the words from the context more frequently than with any other lexical items in the corpus. This is the main intuition behind our approach.
WordNet inventory of senses. The context-based model together with the WordNet filter constitute a metaphor paraphrasing baseline. By comparing the final system to this baseline, we demonstrate that simple context-based substitution, even supplied by extensiveknowledgecontainedinlexicalresources,isnotsufficientformetaphorinter-pretationandthataselectionalpreferencemodelisneededtoestablishtheliteralnessof the paraphrases. 330 and relates these tasks to the problem of metaphor interpretation. It then describes the experimental data used to develop and test the paraphrasing system and the method itself, and finally, concludes with the system evaluation and the presentation of results. 4.1 Paraphrasing and Lexical Substitution
Paraphrasing can be viewed as a text-to-text generation problem, whereby a new piece of text is produced conveying the same meaning as the original text. Paraphrasing can becarriedoutatmultiplelevels(sentence-,phrase-,andword-levels),andmayinvolve bothsyntacticandlexicaltransformations.Paraphrasingbyreplacingindividualwords in a sentence is known as lexical substitution (McCarthy 2002). Because, in this article, we address the phenomenon of metaphor at a single-word level, our task is close in nature to lexical substitution. The task of lexical substitution originates from word sensedisambiguation(WSD).ThekeydifferencebetweenthetwoisthatwhereasWSD makes use of a predefined sense-inventory to characterize the meaning of a word in context,lexicalsubstitutionisaimedatautomaticinductionofmeanings.Thusthegoal of lexical substitution is to generate the set of semantically valid substitutes for the word. Consider the following sentences from Preiss, Coonce, and Baker (2009).
Bright in Example (22) can be replaced by the word intelligent . The same replacement in the context of Example (23) will not produce an appropriate sentence. A lexical substitution system needs to (1) find a set of candidate synonyms for the word and (2) select the candidate that matches the context of the word best.
 range of applications in NLP. These include summarization (Knight and Marcu 2000;
Zhou et al. 2006), information extraction (Shinyama and Sekine 2003), machine trans-lation (Kurohashi 2001; Callison-Burch, Koehn, and Osborne 2006), text simplification (Carroll et al. 1999), question answering (McKeown 1979; Lin and Pantel 2001) and textual entailment (Sekine et al. 2007). Consequently, there has been a plethora of NLPapproaches toparaphrasing (McKeown1979;MeteerandShaked1988;Dras1999;
Barzilay and McKeown 2001; Lin and Pantel 2001; Barzilay and Lee 2003; Bolshakov and Gelbukh 2004; Quirk, Brockett, and Dolan 2004; Kauchak and Barzilay 2006; Zhao etal.2009;KokandBrockett2010)andlexicalsubstitution(McCarthyandNavigli2007, 2009; Erk and Pad  X  o 2009; Preiss, Coonce, and Baker 2009; Toral 2009; McCarthy, Keller, and Navigli 2010).
 whichrelyonasetofhand-crafted(McKeown1979;Zong,Zhang,andYamamoto2001) or automatically learned (Lin and Pantel 2001; Barzilay and Lee 2003; Zhao et al. 2008) paraphrasing patterns; (2) thesaurus-based approaches, which generate paraphrases by substituting words in the sentence by their synonyms (Bolshakov and Gelbukh 2004; Kauchak and Barzilay 2006); (3) natural language generation X  X ased approaches (Kozlowski, McCoy, and Vijay-Shanker 2003; Power and Scott 2005), which transform a sentence into its semantic representation and generate a new sentence from it; and (4) SMT-based methods (Quirk, Brockett, and Dolan 2004), operating as monolingual
MT. A number of approaches to lexical substitution rely on manually constructed thesauri to find sets of candidate synonyms (McCarthy and Navigli 2007), whereas others address the task in a fully unsupervised fashion. In order to derive and rank candidate substitutes, the latter systems make use of distributional similarity measures (Pucci et al. 2009; McCarthy, Keller, and Navigli 2010), vector space models of word meaning(DeCaoandBasili2009;ErkandPad  X  o2009)orstatisticallearningtechniques, such as hidden Markov models and n -grams (Preiss, Coonce, and Baker 2009). impossible to predefine a set of senses of metaphorical words, in particular for novel metaphors. Instead, the correct substitute for the metaphorical term needs to be gen-erated in a data-driven manner, as for lexical substitution. The metaphor paraphrasing task, however, also differs from lexical substitution in the following two ways. Firstly, a suitable substitute needs to be used literally in the target context, or at least more conventionally than the original word. Secondly, by definition, the substitution is not required to be a synonym of the metaphorical word. Moreover, for our task this is not even desired, because there is the danger that synonymous paraphrasing may result in another metaphorical expression, rather than the literal interpretation of the original one. Metaphor paraphrasing therefore presents an additional challenge in comparison to lexical substitution, namely, that of discriminating between literal and metaphorical substitutes. This second, harder, and not previously addressed task is the main focus of the work presented in this section. The remainder of the section is devoted to the description of the metaphor paraphrasing experiment. 4.2 Experimental Data
The paraphrasing system is first tested individually on a set of metaphorical expres-sions extracted from a manually annotated metaphor corpus of Shutova and Teufel (2010). This is the same data set as the one used for seeding the identification module (see Section 3.1.1 for description). Because the paraphrasing evaluation described in this section is conducted independently from the identification experiment, and no part of the paraphrasing system relies on the output of the identification system and vice versa, the use of the same data set does not give any unfair advantage to the systems. In the later experiment (Section 5) when the identification and paraphrasing system are evaluated jointly, again the same seed set will be used for identification; paraphrasing, however, will be performed on the output of the identification system (i.e., the new identified metaphors) and both the identified metaphors and their para-phrases will be evaluated by human judges not used in the previous and the current experiments. 4.3 Method
Thesystemtakesphrasescontainingannotatedsingle-wordmetaphorsasinput;where paraphrases of the verb that can occur in the same context and ranks them according to their likelihood, as derived from the corpus. It then identifies shared features of the paraphrasesandthemetaphoricalverbusingtheWordNethierarchyandremovesunre-latedconcepts.Itthenidentifiestheliteralparaphrasesamongtheremainingcandidates based on the verb X  X  automatically induced selectional preferences and the properties of the context. 332 4.3.1 Context-based Paraphrase Ranking Model. Terms replacing the metaphorical verb v will be called its interpretations i . We model the likelihood L of a particular paraphrase as a joint probability of the following events: the interpretation i co-occurring with the otherlexicalitemsfromitscontext w 1 , ... , w N insyntacticrelations r cally inthesentence. Inthesystem output, thecontext w 1 , ... , w the verb v will be replaced by the interpretation i .

For instance, for a verb that stands in a relation with both a subject and an object, the verb X  X ubject and verb X  X irect object relations are considered to be independent events within the model. The likelihood of an interpretation is then calculated as follows: Theprobabilities can be calculated using maximum likelihood estimation where f ( i )isthefrequencyoftheinterpretationirrespectiveofitsarguments, the number of times its part of speech class is attested in the corpus, and f ( w thenumberoftimestheinterpretationco-occurswithcontextword w performing appropriate substitutions into Equation (7) one obtains phorically in the fixed context according to the data. The parameters of the model were estimated from the RASP-parsed BNC using the grammatical relations output created by Andersen et al. (2008). 4.3.2 WordNet Filter. The context-based model described in Section 4.3.1 overgenerates and hence there is a need to further narrow down the results. It is acknowledged in the linguistics community that metaphor is, to a great extent, based on similarity between the concepts involved (Gentner et al. 2001). We exploit this fact to refine paraphrasing.
After obtaining the initial list of possible substitutes for the metaphorical term, the system filters out the terms whose meanings do not share any common properties with that of the metaphorical term. Consider the computer science metaphor  X  kill a process, X  which stands for  X  X erminate a process. X  The basic sense of kill implies an end  X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X  or termination of life. Thus termination is the shared element of the metaphorical verb and its literal interpretation.

WordNet taxonomy. Within the initial list of paraphrases, the system selects the terms that are hypernyms of the metaphorical term, or share a common hypernym with it. To maximizetheaccuracy,werestrictthehypernymsearchtoadepthofthreelevelsinthe taxomomy. Table 7 shows the filtered lists of paraphrases for some of the test phrases, togetherwiththeirlog-likelihood.Selectingthehighestrankedparaphrasefromthislist as a literal interpretation will serve as a baseline. 4.3.3 Re-ranking Based on Selectional Preferences. The lists which were generated contain some irrelevant paraphrases (e.g.,  X  contain the truth X  for  X  hold back the truth X ) and some paraphrases where the substitute itself is metaphorically used (e.g.,  X  suppress the 334 truth X ). As the task is to identify the literal interpretation, however, the system should remove these.
 ences of the verbs. Verbs used metaphorically are likely to demonstrate semantic pref-erence for the source domain, e.g., suppress would select for MOVEMENTS (political) rather than IDEAS, or TRUT H(the target domain), whereas the ones used literally for the target domain (e.g., conceal ) would select for TRUTH. Selecting the verbs whose preferencesthenouninthemetaphoricalexpressionmatchesbestshouldallowfiltering out non-literalness, as well as unrelated terms.
 paraphrase lists (for verb X  X ubject and verb X  X irect object relations) from the RASP-parsed BNC. As in the identification experiment, we derived selectional preference classes by clustering the 2,000 most frequent nouns in the BNC into 200 clusters us-ing Sun and Korhonen X  X  (2009) algorithm. In order to quantify how well a particular argument class fits the verb, we adopted the selectional association measure proposed by Resnik (1993), identical to the one we used within the selectional preference-based filter for metaphor identification, as described in Section 3.2.4. To remind the reader, selectional association is defined as follows: where P ( c ) is the prior probability of the noun class, P ( c of the noun class given the verb, and S R is the overall selectional preference strength of the verb in the grammatical relation R .
 the paraphrases. The paraphrases are re-ranked based on their selectional association with the noun in the context. Those paraphrases that are not well suited or used meta-phorically are dispreferred within this ranking. The new ranking is shown in Table 8.
The expectation is that the paraphrase in the first rank (i.e., the verb with which the noun in the context has the highest association) represents a literal interpretation. 4.4 Evaluation and Discussion
Asinthecaseofidentification,theparaphrasingsystemwastestedonverb X  X ubjectand verb X  X irect object metaphorical expressions. These were extracted from the manually annotated metaphor corpus of Shutova and Teufel (2010), as described in Section 3.1.1. We compared the output of the final selectional-preference based system to that of the
WordNet filter acting as a baseline. We evaluated the quality of paraphrasing with the help of human judges in two different experimental settings. The first setting involved direct judgments of system output by humans. In the second setting, the subjects did not have access to system output and had to provide their own literal paraphrases for the metaphorical expressions in the data set. The system was then evaluated against human judgments in Setting 1 and a paraphrasing gold standard created by merging annotations in Setting 2. 4.4.1 Setting 1: Direct Judgment of System Output. The subjects were presented with a set of sentences containing metaphorical expressions and the top-ranked paraphrases produced by the system and by the baseline, randomized. They were asked to mark as  X   X   X   X   X   X   X  correct the paraphrases that have the same meaning as the term used metaphorically if they are used literally in the given context.
 speakers of English (one bilingual) and had little or no linguistics expertise. N = 95, k = 7).
 against the subjects X  judgments in terms of Precision at Rank 1, P (1). Precision at Rank (1) measures the proportion of correct literal interpretations among the paraphrases in rank 1. The results are shown in Table 9. The system identifies literal paraphrases
Sign test (Siegel and Castellan 1988) that showed that this difference in performance is statistically significant ( N = 15, x = 1,p &lt; 0 . 001). 336 4.4.2Setting2:CreationofaParaphrasingGoldStandard. Thesubjectswerepresentedwith asetofsentencescontainingmetaphoricalexpressionsandaskedtowritedownallsuit-ableliteralparaphrasesforthehighlightedmetaphoricalverbsthattheycouldthinkof. vious setting participated in this experiment. They were all native speakers of English and some of them had a linguistics background (postgraduate-level degree in English). as a gold standard. For instance, the gold standard for the phrase  X  brushed aside the discarded .
 pared against the gold standard using mean average precision (MAP) as a measure. MAP is defined as follows: where M is the number of metaphorical expressions, N j is the number of correct para-phrases forthemetaphorical expression j , P ji istheprecision ateachcorrect paraphrase (the number of correct paraphrases among the top i ranks). First, average precision is estimated for individual metaphorical expressions, and then the mean is computed across the data set. This measure allows one to assess ranking quality beyond rank 1, as well as the recall of the system. As compared with the gold standard, MAP of the paraphrasing system is 0.62 and that of the baseline is 0.56, as shown in Table 9. 4.4.3 Discussion. Given that the metaphor paraphrasing task is open-ended, any gold standardelicitedonthebasisofitcannotbeexhaustive.Someofthecorrectparaphrases may not occur to subjects during the experiment. As an example, for the phrase  X  stir excitement X  X ostsubjectssuggestedonlyoneparaphrase X  X reateexcitement, X  X hichis foundinrank3,suggestinganaverageprecisionof0.33forthisphrase.Thetopranksof thesystemoutputareoccupiedby provoke and stimulate ,however,whichareintuitively correct,morepreciseparaphrases, despitenoneofthesubjectshavingthoughtofthem.
Such examples contribute to the fact that the system X  X  MAP is significantly lower than itsprecisionatrank1,becauseanumberofcorrectparaphrasesproposedbythesystem are not included in the gold standard.
 precisionatrank1(26%)overthebaseline.Thiscomponentisalsoresponsibleforsome errorsofthesystem,however.Oneofthepotentiallimitationsofselectionalpreference-based approaches to metaphor paraphrasing is the presence of verbs exhibiting weak selectional preferences. This means that these verbs are not strongly associated with any of their argument classes. As noted in Section 3, such verbs tend to be used literally, and are therefore suitable paraphrases. Our selectional preference model de-emphasizes them, however, and, as a result, they are not selected as literal paraphrases despite matching the context. This type of error is exemplified by the phrase  X  mend marriage. X  For this phrase, the system ranking overruns the correct top suggestion of the baseline,  X  X mprove marriage, X  and outputs  X  repair marriage X  as the most likely the fact that improve exposes a moderate selectional preference strength. most common type of error is triggered by the conventionality of certain metaphorical verbs. Because they frequently co-occur with the target noun class in the corpus, they receive a high association score with that noun class. This results in a high ranking of conventional metaphorical paraphrases. Examples of top-ranked metaphorical para-phrasesinclude X  confront aquestion X  X or X  tackle aquestion, X  X  repair marriage X  X or X  mend marriage, X   X  X xample pictures  X  X or  X  X xample illustrates . X  occurring error was paraphrasing with a verb that has a different meaning. One such examplewasthemetaphoricalexpression X  X ension mounted , X  X orwhichthesystempro-ducedaparaphrase X  X ension lifted , X  X hichhastheoppositemeaning.Thiserrorislikely to have been triggered by the WordNet filter, whereby one of the senses of lift would have a common hypernym with the metaphorical verb mount . This results in lift not beingdiscardedbythefilter,andsubsequentlyrankedtopduetotheconventionalityof the expression  X  X ension lifted . X  is the influence of wider context on metaphorical interpretation. The current system processes only the information contained within the GR of interest, discarding the rest of the context. For some cases, however, this is not sufficient and the analysis of a wider context is necessary. For instance, given the phrase  X  X cientists focus  X  X he systemproducesaparaphrase X  X cientiststhink, X  X atherthanthemorelikelyparaphrase  X  X cientists study. X  Such ambiguity of focus could potentially be resolved by taking its wider context into account. The context-based paraphrase ranking model described in
Section 4.3.1 allows for the incorporation of multiple relations of the metaphorical verb in the sentence.

WordNet, it is important to note that metaphor paraphrasing is not restricted to metaphorical senses included in WordNet. Even if a metaphorical sense is absent from WordNet, the system can still identify its correct literal paraphrase relying on the 338 hyponymy relation and similarity between concepts, as described in Section 4.3.2. For example, the metaphorical sense of handcuff in  X  X esearch is handcuffed  X  is not included in Wordnet, although the system correctly identifies its paraphrase confine ( X  X esearch is confined X ). 5. Evaluation o fIntegrated System
Uptonow,theidentificationandtheparaphrasingsystemswereevaluatedindividually as modules. To determine to which extent the presented systems are applicable within
NLP, we then ran the two systems together in a pipeline and evaluated the accuracy of theresultingtext-to-textmetaphorprocessing.First,themetaphoridentificationsystem was applied to naturally occurring text taken from the BNC and then the metaphorical expressions identified in those texts were paraphrased by the paraphrasing system.
Someoftheexpressionsidentifiedandparaphrasedbytheintegratedsystemareshown in Figure 11. The system output was compared against human judgments in two phases. In phase 1, a small sample of sentences containing metaphors identified and paraphrased by the system was judged by multiple judges. In phase 2, a larger sample of phrases was judged by only one judge (one of the authors of this article). Agreement of the judgments of the latter with the other judges was measured on the data from phase 1.
 its usability by other NLP tasks, we assessed its performance in a two-fold fashion.
Instances where metaphors were both correctly identified and paraphrased by the system were considered strictly correct , as they show that the system fully achieved its goals. Instances where the paraphrasing retained the meaning and resulted in a literal paraphrase (including the cases where the identification module tagged a literal expression as a metaphor) were considered correct lenient . The intuition behind this evaluation setting is that correct paraphrasing of literal expressions by other literal expressions,albeitnotdemonstratingthepositivecontributionofmetaphorprocessing, does not lead to any errors in system output and thus does not hamper the overall usability of the integrated system. 5.1 Phase 1: Small Sample, Multiple Judges
Three volunteer subjects participated in the experiment. They were all native speakers of English and had no formal training in linguistics.
 metaphorical expressions identified by the system and their paraphrases, as shown in Figure 12. There were 35 such sentences in the sample. They were asked to do the following: 1. Compare the sentences, decide whether the highlighted expressions have 2. Decide whether the verbs in both sentences are used metaphorically or
For the second task, the same definition of metaphor as in the identification evaluation (cf. Section 3.3.2) was provided for guidance.
 dently for judgments on similarity of paraphrases and their literalness. The inter-annotator agreement on the task of distinguishing metaphoricity from literalness was measuredat  X  = 0 . 53 ( n = 2, N = 70, k = 3).Ontheparaphrase(i.e.,meaningretention) task, reliability was measured at  X  = 0 . 63 ( n = 2, N = 35, k = 3).
 against the subjects X  judgments in terms of accuracy (both strictly correct and correct 340 lenient). Strictly correct accuracy in this task measures the proportion of metaphors both identified and paraphrased correctly in the given set of sentences. Correct lenient accuracy, which demonstrates applicability of the system, is represented by the overall proportion of paraphrases that retained their meaning and resulted in a literal para-phrase (i.e., including literal paraphrasing of literal expressions in original sentences).
Human judgments were merged into a majority gold standard, which consists of those instances that were considered correct (i.e., identified metaphor correctly paraphrased by the system) by at least two judges. Compared to this majority gold standard, the integrated system operates with a strictly correct accuracy of 0 . 66 and correct lenient accuracy of 0 . 71. The average human agreement with the majority gold standard in termsofaccuracyis0 . 80ontheliteralnessjudgmentsand0 . 89onthemeaningretention judgments. 5.2 Phase 2: Larger Sample, One Judge
Thesystemwasalsoevaluatedonalargersampleofautomaticallyannotatedmetaphor-ical expressions (600 sentences) using one person X  X  judgments produced following the procedure from phase 1. We measured how far these judgments agree with the judgesusedinphase1.Theagreementonmeaningretentionwasmeasuredat  X  = 0 . 59 70, k = 4).
 0.67 (correct lenient). The proportions of different tagging cases are shown in Table 11.
Thetable also shows the acceptability of tagging cases. Acceptability indicates whether or not this type of system paraphrasing would cause an error when hypothetically integrated with an external NLP application. Cases where the system produces correct literal paraphrases for metaphorical expressions identified in the text would benefit another NLP application, whereas cases where literal expressions are correctly para-phrasedbyotherliteralexpressionsareconsideredneutral.Bothsuchcasesaredeemed acceptable, because they increase or preserve literalness of the text. All other tagging cases introduce errors, thus they are marked as unacceptable. Examples of different tagging cases are shown in Table 12.
 formative contribution of the system, and the overall accuracy of correct paraphrasing resultinginaliteralexpression(0.67)representsthelevelofitsacceptabilitywithinNLP. 5.3 Discussion and Error Analysis
The results of integrated system evaluation suggest that the system is capable of pro-viding useful information about metaphor for an external text processing application with a reasonable accuracy (0.67). It may, however, also introduce errors in the text by incorrect paraphrasing, as well as by producing metaphorical paraphrases. If the latter errors are rare (0.5%), the errors of the former type are sufficiently frequent (21.5%) to make the metaphor system less desirable for use in NLP. It is therefore important to address such errors.
 error. The identification system tags 28% of all instances incorrectly (170). This yields a component performance of 72%. This result is slightly lower than that obtained in its individual evaluation in a setting with multiple judges (79%). This can be explained by the fact that the integrated system was evaluated by one judge only, rather than using a majority gold standard. When compared with the judgments of each annotator pairwise the system precision was measured at 74% (cf. Section 3.3.2). Some of the literalinstancestaggedasametaphorbytheidentificationcomponentarethencorrectly paraphrased with a literal expression by the paraphrasing component. Such cases do not change the meaning of the text, and hence are considered acceptable. The resulting contributionoftheidentificationcomponenttotheoverallerroroftheintegratedsystem is thus 15%.
 (196 instances out of 600 were paraphrased incorrectly). As mentioned previously, this error can be further split into paraphrasing without meaning retention (21.5%) and metaphorical paraphrasing (11%). Both of these error types are unacceptable and lead to lower performance of the integrated system. This error rate is also higher than that of the paraphrasing system when evaluated individually on a manually created data set(19%).Thereasonsforincorrectparaphrasingbytheintegratedsystemaremanifold 342 andconcernboththemetaphoridentificationandparaphrasingcomponents.Oneofthe centralproblemsstemsfromtheinitialtaggingofliteralexpressionsasmetaphoricalby theidentificationsystem.Theparaphrasingsystemisnotdesignedwithliteral-to-literal paraphrasing in mind. When it receives literal expressions which have been incorrectly identified as input, it searches for a more literal paraphrase for them. Not all literally used words have suitable substitutes in the given context, however. For instance, the literal expression  X  X pprove conclusion X  is incorrectly paraphrased as  X  X valuate conclusion. X  literal paraphrases, for example,  X  X ountry functions according to... X . This is, however, a more fundamental problem for metaphor paraphrasing as a task. In such cases, the system, nonetheless, attempts to produce a substitute with approximately the same meaning, which often leads to either metaphorical or incorrect paraphrasing. For in-stance,  X  X ountry functions  X  is paraphrased by  X  X ountry runs , X  with suggestions with lower rank being  X  X ountry works  X  and  X  X ountry operates . X  word sense ambiguity of certain verbs or nouns. Consider the following paraphras-ing example, where Example (24a) shows an automatically identified metaphor and
Example (24b) its system-derived paraphrase: (24) a. B71 852 Craig Packer and Anne Pusey of the University of Chicago have
Thiserrorresultsfromthefactthattheverb succeed hasahighselectionalpreferencefor in WordNet in another of its senses ( X  X e the successor [of] X ). The system merges these two senses in one, resulting in an incorrect paraphrase.
 metonymy at the interpretation level. In the phrase  X  break word, X  the verb break is used metaphorically (although conventionally) and the noun word is a metonym standing for promise . This affected paraphrasing in that the system searched for verbs denoting actions that could be done with words, rather than promises, and suggested the para-phrase  X  X nterrupt word(s). X  This paraphrase is interpretable in the context of a person giving a speech, but not in the context of a person giving a promise. This was the only case of metonymy in the analyzed data, however.
 the WordNet filter used in the paraphrasing system. Despite being a wide-coverage general-domain database, WordNet does not include information about all possible relationsthatexistbetweenparticularwordsenses.Thismeansthatsomeofthecorrect paraphrases suggested bythecontext-based model get discarded bytheWordNet filter due to missing information in WordNet. For instance, the system produces no para-phrase for the metaphors  X  hurl comment, X   X  spark enthusiasm, X  and  X  magnify thought X  thatitcorrectlyidentified.ThisproblemmotivatestheexplorationofpossibleWordNet-free solutions for similarity detection in the metaphor paraphrasing task. The system couldeitherrelyentirelyonsuchasolution,orbackofftoitincaseswhentheWordNet-based system fails.
 are caused by metaphor conventionality resulting in metaphorical paraphrasing (e.g.,  X  swallow anger  X  suppress anger, X   X  X ork killed him  X  work exhausted him X ), followed by the WordNet filter X  and general polysemy X  X elated errors (e.g.  X  follow lives succeed lives X ), resulting in incorrect paraphrasing or the system not producing any paraphrase at all. Metaphor paraphrasing by another conventional metaphor instead of a literal expression is undesirable, although it may still be useful if the paraphrases are more lexicalized than the original expression. The word sense ambiguity X  and
WordNet-based errors are more problematic, however, and need to be addressed in the future. SP re-ranking is responsible for the majority of incorrect paraphrasing of literal expressions. This may be due to the fact that the model is ignorant of the meaning retention aspect, but rather favors the paraphrases that are used literally (albeit incorrectly) in the given context. This shows that when building an integrated system, it is necessary to adapt the metaphor paraphrasing module to be able to also handle literal expressions, because the identification module is likely to produce at least some of them. 5.4 Comparison to the CorMet System
It is hard to directly compare the performance of the presented system to the other recent approaches to metaphor, because all of these approaches assume different task definitions,andhenceusedatasetsandevaluationtechniquesoftheirown.Amongthe data-driven methods, however, the closest in nature to ours is Mason X  X  (2004) CorMet system. Mason X  X  system does not perform metaphor interpretation or identification of metaphorical expressions in text, but rather focuses on the detection of metaphorical links between distant domains. Our system also involves such detection. Whereas
Mason relies on domain-specific selectional preferences for this purpose, however, our system uses information about verb subcategorization, as well as general selectional preferences, to perform distributional clustering of verbs and nouns and then link the clusters based on metaphorical seeds. Another fundamental difference is that whereas
CorMet assigns explicit domain labels, our system models source and target domains implicitly.IntheevaluationoftheCorMetsystem,theacquiredmetaphoricalmappings arecomparedtothoseinthemanuallycreatedMasterMetaphorListdemonstratingthe accuracy of 77%. In our system, on the contrary, metaphor acquisition is evaluated via extraction of naturally occurring metaphorical expressions, achieving a performance of 79% in terms of precision. In order to compare the new mapping acquisition ability 344 of our system to that of CorMet, however, we performed an additional analysis of the mappingshypothesizedbyournounclustersinrelationtothoseintheMML.Itwasnot possible to compare the new mappings discovered by our system to the MML directly as was done in Mason X  X  experiments, because in our approach source domains are represented by clusters of their characteristic verbs. The analysis of the noun clusters with respect to expansion of the the seed mappings taken from the MML, however, allowedustoevaluatethemappingacquisitionbyoursystemintermsofbothprecision and recall. The goal was to confirm our hypothesis that abstract concepts get clustered togetheriftheyareassociatedwiththesamesourcedomainandtoevaluatethequality of the newly acquired mappings.
 MML and manually extracted all corresponding mappings (42 mappings in total). The categories included SOCIETY, IDEA, LIFE, OPPORTUNITY, CHANGE, LOVE, DIFFICULTY, CREATION, RELATIONSHIP, and COMPETITION. For the concept of OPPORTUNITY, for example, three mappings were present in the MML: OPPORTU-NITIES ARE PHYSICAL OBJECTS, OPPORTUNITIES ARE MOVING ENTITIES, and
OPPORTUNITIES ARE OPEN PATHS, whereas for the concept of COMPETITION the list describes only two mappings: COMPETITION IS A RACE, COMPETITION IS A WAR.
 concepts. Examples of the mappings and the corresponding clusters are shown in
Figure 13. Our goal was to verify whether other concepts in the cluster containing the target concept are associated with the source domains given in the mappings. Each member of these clusters was analyzed for possible association with the respective source domains. For each concept in a cluster, we verified that it is associated with the respective source domain by finding a corresponding metaphorical expression and annotating the concepts accordingly. The degree of association of the members of the clusters with a given source domain was evaluated in terms of precision on the set of hypothesized mappings. The precision of the cluster X  X  association with the source concept was calculated as a proportion of the associated concepts in it. Based on these results we computed the average precision (AP)as follows: where M isthenumberofhypothesizedmappingsand c j istheclusteroftargetconcepts corresponding to mapping j .
 is 0.82. This confirms the hypothesis of clustering by association and shows that our method favorably compares to Mason X  X  system. This is only an approximate compari-son, however. Direct comparison of metaphor acquisition by the two systems was not possible, as they produce the output in different formats and, as mentioned earlier, our system models conceptual mappings implicitly, both within the noun clusters, as well as by linking them to the verb clusters.
 against the MML. For each selected MML mapping, we manually extracted all alter-native target concepts associated with the source domain in the mapping from the
MML. For example, in case of LIFE IS A JOURNEY we identified all target concepts associated with JOURNEY according to the MML and extracted them. These included
LIFE, CAREER, LOVE, and CHANGE. We then verified whether the relevant system-produced noun clusters contained these concepts. The recall was then calculated as a proportionoftheconceptsinthislistwithinonecluster.Forexample,theconceptsLIFE and CAREER are found in the same cluster, but not LOVE and CHANGE. The overall recall of mapping acquisition was measured at 0.50.
 ical connections in the data with high precision. Although the evaluation against the
Master Metaphor List is subjective, it suggests that the use of statistical data-driven methods in general, and distributional clustering in particular, is a promising direction for computational modeling of metaphor. 6. Conclusion and Future Directions
The 1980s and 1990s provided us with a wealth of ideas on the structure and mecha-nismsofmetaphor.Thecomputationalapproachesformulatedbackthenarestillhighly influential, although their use of task-specific hand-coded knowledge is becoming in-creasingly less popular. The last decade witnessed a significant technological leap in natural language computation, whereby manually crafted rules gradually gave way to more robust corpus-based statistical methods. This is also the case for metaphor research.Inthisarticle,wepresentedthefirstintegratedstatisticalsystemformetaphor processinginunrestrictedtext.Ourmethodisdistinguishedfrompreviousworkinthat itdoesnotrelyonanymetaphor-specifichand-codedknowledge(besidestheseedsetin theidentificationexperiments),operatesonopen-domaintext,andproducesinterpreta-tions in textual format. The system, consisting of independent metaphor identification and paraphrasing modules, operates with a high precision (0.79 for identification, 0.81 for paraphrasing, and 0.67 as an integrated system). Although the system has been testedonlyonverb X  X ubjectandverb X  X bjectmetaphorsatthisstage,thedescribediden-tification and paraphrasing methods should be similarly applicable to a wider range of syntactic constructions. This expectation rests on the fact that both distributional 346 clustering and selectional preference induction techniques have been shown to model the meanings of a range of word classes (Hatzivassiloglou and McKeown 1993; Boleda
Torrent and Alonso i Alemany 2003; Brockmann and Lapata 2003; Zapirain, Agirre, andM ` arquez2009).Extendingthesystemtodealwithmetaphorsrepresentedbyother wordclassesandconstructionsaswellasmulti-wordmetaphorsispartoffuturework. seed set exemplifying more syntactic constructions and the corpus search over fur-ther grammatical relations (e.g., verb X  X repositional phrase [PP] complement relations:  X  X illary leapt in the conversation; X  adjectival modifier X  X oun relations  X  slippery mind, deep unease, heavy loss; X  noun X  X P complement relations:  X  X  fraction of self-control, a foot of a mountain; X  verb X  X P complement relations:  X  aching to begin the day; X  and copula constructions:  X  X eath is the sorry end of the human story, not a mysterious prelude to a new one X ). Besides noun and verb clustering, it would also be necessary to perform clustering of adjectives and adverbs. Clusters of verbs, adjectives, adverbs, and concrete nouns would then represent source domains within the model. The data studyofShutovaandTeufel(2010)suggestedthatitissometimesdifficulttochoosethe optimal level of abstraction of domain categories that would generalize well over the data. Although the system does not explicitly assign any domain labels, its domain representation is still restricted by the fixed level of generality of source concepts, defined by the chosen cluster granularity. To relax this constraint, one could attempt to automatically optimize cluster granularity to fit the data more accurately and to ensurethatthegeneratedclustersexplainthemetaphoricalexpressionsinthedatamore comprehensively. A hierarchical clustering algorithm, such as that of Yu, Yu, and Tresp (2006)orSunandKorhonen(2011),couldbeusedforthispurpose.Besidesthis,itwould be desirable to be able to generalize metaphorical associations learned from one type of syntactic construction across all syntactic constructions, without providing explicit seed examples for the latter. For instance, given the seed phrase  X  stir excitement, X  representing the conceptual mapping FEELINGS ARE LIQUIDS, the system should be able to discover not only that phrases such as  X  swallow anger X  are metaphorical, but thatphrasessuchas X  ocean of happiness X  are as well.
 involve the extraction of further grammatical relations from the corpus, such as those listedherein,andtheirincorporationintothecontext-basedparaphraseselectionmodel.
Extending both the identification system and the paraphrasing system would require the application of the selectional preference model to other word classes. Although
Resnik X  X selectionalassociationmeasurehasbeenusedtomodelselectionalpreferences of verbs for their nominal arguments, it is in principle a generalizable measure of word association. Information-theoretic word association measures (e.g., mutual information [Church and Hanks 1990]) have been continuously successfully applied to a range of syntactic constructions in a number of NLP tasks (Hoang, Kim, and Kan 2009; Baldwin and Kim 2010). This suggests that applying a distributional association measure, such as the one proposed by Resnik, to other part-of-speech classes should still result in a realistic model of semantic fitness, which in our terms corresponds to a measure of  X  X iteralness X  of the paraphrases.
 acquisition algorithm that can handle word sense ambiguity (e.g., Rooth et al. 1999;  X 
OS  X  eaghdha 2010; Reisinger and Mooney 2010). The current approach relies on SP classesproducedbyhardclusteringandfailstoaccuratelymodelwordsensesofgener-ally polysemous words. This resulted in a number of errors in metaphor paraphrasing and it therefore needs to be addressed in the future. coded knowledge in the form of WordNet. WordNet has been criticized for a lack of consistency, high granularity of senses, and negligence with respect to some important semantic relations (Lenat, Miller, and Yokoi 1995). In addition, WordNet is a general-domain resource, which is less suitable if one wanted to apply the system to domain-specific data. For all of these reasons it would be preferable to develop a WordNet-free fully automated approach to metaphor resolution. Vector space models of word mean-ing (Erk 2009; Rudolph and Giesbrecht 2010; Van de Cruys, Poibeau, and Korhonen 2011) might provide a solution, as they have proved efficient in general paraphrasing and lexical substitution settings (Erk and Pad  X  o 2009). The feature similarity component of the paraphrasing system that is currently based on WordNet could be replaced by such a model.
 tification system. To enable high usability of the system it is necessary to perform high-recall processing. One way to improve the coverage is the creation of a larger, more diverse seed set. Although it is hardly possible to describe the whole variety of metaphoricallanguage,itispossibletocompileasetrepresentativeof(1)allmostcom-mon source X  X arget domain mappings and (2) all types of syntactic constructions that exhibitmetaphoricity.Theexistingmetaphorresources,primarilytheMasterMetaphor
List (Lakoff, Espenson, and Schwartz 1991), and examples from the linguistic literature about metaphor, couldbeasensiblestartingpointonaroutetosuchadataset.Having a diverse seed set should enable the identification system to attain a broad coverage of the corpus.
 ferable to other NLP tasks and applications that could benefit from the inclusion of a metaphor processing component. Overall, our results suggest that the system can provide useful and accurate information about metaphor to other NLP tasks relying onlexicalsemantics.Inordertoproveitsusefulnessforexternalapplications,however, an extrinsic task-based evaluation is outstanding. In the future, we intend to integrate metaphor processing with NLP applications, exemplified by MT and opinion mining, in order to demonstrate the contribution of this pervasive yet rarely addressed phe-nomenon to natural language semantics.
 Acknowledgments References 348 350 352
