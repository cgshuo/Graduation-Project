 Currently, the number of web pages in the World Wide Web has increased exponen-useful information from the huge number of web pages. However, as more and more web pages are being accumulated day by day, a search engine usually returns a huge number of results corresponding to a single query. Consequently, users may stance, given the query of milk powder , the number of web pages Google returns can with similar or even the same content. This phenomenon is especially common in the necessary to reorganize the search results to facilitate users X  browsing. 
Many researchers have employed the technique of text clustering to reorganize the similarity between two documents, and many similarity metrics heavily rely on the co-occurrence of terms between the two documents. However, the search results are usually composed of short text snippets, such as titles, which make the traditional limited number of common terms among them. 
Intuitively, short texts are usually clustered into groups according to some core terms. For instance, given three sentences: S1: How many products does Google have? S2: How many products does Yahoo! have? S3: Whether Yahoo! is a good web company? S2 and S3 are usually clustered into a group because they are describing the different profiles of the same term Yahoo!, even if S2 shares more common terms with S1 than S3. This shows that the core terms play an important role in short text clustering. 
In this paper, we propose a short text clustering method which can be used to clus-mizing the Mcut criterion [2], in which the collectio n of search results is treated as a similarity graph. A comparative study with the KMeans algorithm as baseline is con-ducted to evaluate our method X  X  clusteri ng accuracy. Experimental results indicate that TermCut obtains a higher accuracy than the baseline. 
The rest of the paper is organized as follows. TermCut , the proposed algorithm, is present the experimental results. Section 4 concludes our work and discusses future work. 2.1 Text Model vector-space model is employed to represent short texts, and each short text d is con-sidered to be a vector in this model. In particular, we employ the TF-IDF term weight-smoothed to be 1 or 0, as Zhang and Lee [4] do in their method. Specifically, if a term appears in the short text, the TF of this term is smoothed to be 1; and 0 otherwise. In addition, the dot product is used to compute the similarity between texts. 2.2 Mcut Criterion The Mcut criterion [2] is a graph based criterion function which models the collection clustering principle X  X inimizing the inter-cluster similarity and maximizing the in-{ C 1 ,C 2 ,...,C k ,...,C K }, their Mcut is defined to be Eq. (1). limited co-occurring terms between two short texts. The Mcut criterion can weaken the impact of the sparseness of short texts by summing up all the pair-wise similarities within a cluster. However, the Mcut criterion has a computational complexity of O(n 2 ) considering that the number of clusters an d the average number of terms in each short text are small and independent of n . Next, we further propose an efficient method to numerator part of the MCut can be calculated as Eq. (2). frequency of t m in C-C k respectively. Hence, Eq. (2) can be further simplified as: 
On the other hand, the denominator part of the Mcut takes into account the intra-similarity. It sums up all the pair-wise similarities between the short texts in C k , which can be calculated as: 
Using Eq. (3) and Eq. (4), the Mcut criterion function can be deduced into Eq. (5). Mcut is O(M). Hence, the complexity of Mcut can be reduced to O(n+M). 2.3 The TermCut Algorithm two clusters X  X ne cluster containing the current core term and the other not. The pseudo-code of TermCut algorithm is given in Fig. 1. 
In the TermCut algorithm, the clustering process begins with a single cluster contain-ing all the short texts. We then find the core term in each iteration based on minimizing replaced by the two new generated clusters from the clusters list. Otherwise, if any core original cluster. The pseudo-code of FindCoreTerm function is shown in Fig. 2. C clusters is calculated, and the term which minimizes the Mcut is selected as the core term candidate. If the decrease between the Mcut criterion value of the original set of clusters and the minimized Mcut is above a threshold , the candidate is returned as the core term; otherwise, the threshold is not satisfied and we simply return null to denote no core term can be found. The threshold is set to a negative number for starting the clustering process, because according to Eq. (1) the initial value of Mcut is 0. In this section, we conduct two experiments to verify the effectiveness of the pro-second one is clustering questions, which are typical short text documents. 3.1 Search Result Clustering We build up a web application which can extract the search results from Google including links and titles corresponding to a given query. These search results are then clustered using TermCut according to their corresponding titles. The resulting clusters are labeled as their corresponding core terms, and the only cluster labeled with the term others as impure cluster and the rest clusters as pure clusters. Any pure clusters containing only one search result are merged into the impure cluster. We hire a three-expert group and randomly choose 50 Chinese queries for testing. relatively good performance for a practical search engine. 3.2 Question Clustering We conduct a comparison between the TermCut and the KMeans algorithm using the engine could return. In total, 453 Chinese questions are selected and manually classi-fied into 4 coarse-grain and 13 fine-grain classes. To test the effectiveness of the pro-posed TermCut method, the FScore measure [1, 3] is employed. We utilize the Macro Averaged FScore and Micro Averaged FScore [5] of the entire clustering result to evaluate a clustering method X  X  performance. 
Performance comparison between our algorithm and KMeans algorithm is shown cluster number of KMeans is 13 which is the same with the number of the fined-grain classes of the ground truth dataset. Since the KMeans algorithm we implemented selects the initial centroid randomly, the result shown in Table 1 is the average result of running 100 times. 
The above experimental results exhibit that KMeans performs badly on clustering short text, like the search result snippets, whereas the proposed method TermCut performs much better on these data collections. We propose a short text clustering method to cluster search results. An algorithm, TermCut , is presented to find the core terms based on minimizing the Mcut and gen-erate clusters according to the core terms. Experiments show that the proposed algorithm can help efficiently and effectively organize the search results. investigate its performance with external semantic knowledge (such as Wikipedia). The work described in this paper was fully supported by a grant from City University of Hong Kong (Project No. 7002336). 
