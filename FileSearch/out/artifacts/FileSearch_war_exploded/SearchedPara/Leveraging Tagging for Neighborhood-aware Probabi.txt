 Collaborative Filtering (CF) is a popular way to build recommender systems and has been successfully employed in many applications. Generally, two kinds of approaches to CF, the local neighborhood methods and the global matrix factorization models, have been widely studied. Though some previous researches target on com-bining the complementary advantages of both approaches, the per-formance is still limited due to the extreme sparsity of the rat-ing data . Therefore, it is necessary to consider more informa-tion for better reflecting user preference and item content. To that end, in this paper, by leveraging the extra tagging data, we pro-pose a novel unified two-stage recommendation framework, named N eighbor h ood-aware P robabilistic M atrix F actorization(NHPMF). Specifically, we first use the tagging data to select neighbors of each user and each item, then add unique Gaussian distributions on each user X  X  (item X  X ) latent feature vector in the matrix factoriza-tion to ensure similar users (items) will have similar latent features . Since the proposed method can effectively explores the external data source (i.e., tagging data) in a unified probabilistic model, it leads to more accurate recommendations. Extensive experimental results on two real world datasets demonstrate that our NHPMF model outperforms the state-of-the-art methods.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Collaborative Filtering, Matrix factorization, Neighborhood method
Collaborative filtering (CF) is a popular way to build recom-mender system [1] and has received significant success in various applications. It infers the interest of active users by collecting past behaviors (e.g,browsing history, click streams or products satisfac-tion expressed in ratings) from similar users or items without re-quiring the creation of explicit user and item profiles.
Generally, there are two kinds of successful approaches to CF: neighborhood methods and matrix factorization models. Neigh-borhood methods (also known as K Nearest Neighbor, or KNN) can be further classified into two categories: user-oriented KNN method (UKNN) [6], and item-oriented KNN method (IKNN) [12]. They produce recommendations from like-minded users (UKNN) or similar items (IKNN). In contrast to neighborhood methods, Matrix Factorization (MF) approaches [9, 11] try to characterize both items and users in the same low latent space inferred from the sparse rating matrix.

In fact, these two kinds of CF approaches focus on exploiting different levels of structure information from the data. Neighbor-hood methods are most effective at detecting very localized rela-tionships (the set of neighbors) to make predictions. Consequently, they are unable to capture the global weak signals encompassed in all of a user X  X  ratings. On the other hand, matrix factorization mod-els are generally effective at estimating the overall structure of the explicit rating matrix. However, these models are poor at detecting strong associations among a small set of closely related neighbor set [2, 8]. Obviously, there are complementary advantages for local neighborhood methods and the global matrix factorization models, and for making better recommendation it is necessary to combine the local information with the global structure of the data.
Though several unified frameworks have been proposed to com-bine KNN and MF models [3, 8, 13], the performance is still lim-ited due to the extreme sparsity of the available data. As a matter of fact, in real world scenarios, the user rating data is very sparse and the density of observed ratings is often less than 1% [12]. Thus, it is hard for rating based KNNs to find the credible near-est neighbors, since they assume users have at least rated some items in common (UKNN) or two items have been co-rated by some users (IKNN). Meanwhile, relying only on the sparse rating data will lead to the over-specification problem for MFs [1]. Luck-ily, with the popularity of Web 2.0, more external information and metadata have emerged on the web, such as the tagging applica-tions in the MovieLens website 1 . These applications allow users to add free, personalized tags to the items. Recently, studies in [10] have made preliminary attempts to analyze the utility of these tags and found that user-generated tags are consistent with the web con-tent and can capture the topics of user interest quite well. There-fore, it would be a very worthwhile endeavor to use tagging data in finding local information for collaborative filtering, especially for those unified CFs .
 Along this line, in this paper, we propose a novel two-stage CF framework named N eighbor h ood-aware P robabilistic M atrix F actorization(NHPMF) to improve recommendation accuracy. In the first stage, we utilize the tagging data to obtain the neighbors http://www.movielens.umn.edu/ of each user and each item. In the second stage, those obtained neighborhood information is incorporated into the factorization of the rating matrix to ensure similar users(items) will have similar la-tent features . To be specific, the combination is achieved by using local neighborhood information in the priors of the matrix factor-ization model, where the latent feature vectors of each user(item) are dependent on those of her(its) neighbor set. To the best of our knowledge, NHPMF is one of the few attempts to explore exter-nal tagging data for bettering incorporating both user neighborhood and item neighborhood into matrix factorization by a unified prob-abilistic framework. Extensive experimental results on two real world datasets show that our model has better performance than the state-of-the-art methods, especially when the active user has only a few rating records.
In this section, we review the literatures related to our work from the following two aspects.

Combining KNN and MF Although KNN and MF methods have been widely studied in CF respectively, only several researches have focused on combining these two methods to improve the rec-ommendation accuracy [2, 3, 5, 8, 13]. During the Netflix compe-tition, researchers have found that there are complementary advan-tages for both local neighborhood methods and global matrix fac-torization models and combining these two methods X  results will improve recommendation accuracy [2]. Researches in [3, 13] have integrated those two approaches, but they suggested using neigh-borhood methods to post-process MF results rather than a unified model. Koren in [8] proposed to combine IKNN and MF into the regularized least squares problem, where item similarities and the latent factors are learned from the data through gradient descent. The experimental results on Netflix data set showed the prediction accuracy is improved by their model. Gu et. al [5] proposed a uni-fied model for CF based on graph regularized weighted nonnegative matrix factorization. They used user demographic and item genre information to constructed neighborhood graphs and incorporated user and item graphs in weighted nonnegative matrix factorization. Nevertheless, in the real world, it X  X  hard to collect the content in-formation of users and items due to the expensive expert labeling efforts and privacy concerns. Our model is more intuitive and gen-eral since users take initiative to annotate web resources, which makes it easier to collect tagging data.

Besides those mentioned above, with the advent of online social networks in recent years, the social network based recommendation has emerged. Some work in this area, such as [7], has combined UKNN and MF for recommendation, where user neighborhood in-formation is learned from the social structure in the social network. Our work has essential difference with their methods since they only focused on combing social friends information into MF. Our work emphasizes to incorporated the UKNN and IKNN together into MF, where the neighborhood information can be learned from rich external data sources (e.g., tagging history, social relationships, user demographic information, item contents).

Utilizing Tagging Data for CF With the development of Web 2.0 applications, tagging techniques have become a popular tool for users to semantically describe web resources. Researchers in [10] have found that tags are good at representing users X  interests and thus reflect the web content quite well. Recently, people have started to consider utilizing tagging data to enhance CF based rec-ommendation accuracies [14, 15]. TagRec is introduced in [15], where a factor analysis model is proposed based on a unified proba-bilistic matrix factorization by utilizing both users X  tagging and rat-ing information. Further, in [14], a regularization term is added to the objective function of probabilistic matrix factorization to make two user latent feature vectors as similar as possible if they have similar tagging history.

In summary, to the best of our knowledge, none of the previous work has unified the complementary advantages of both local user neighborhood, item neighborhood and global matrix factorization models together in the CF in a unified probabilistic model, where the local information is learned by exploiting other data sources.
The main challenge for our model is the way to incorporate the local neighborhood information into the global matrix factoriza-tion of the rating matrix, where the neighborhood information is learned from external data sources. Since previous research work have found that tags can represent user interests and reflect the web content quite accurately [10], it is natural to select neighbors of users and items by the tagging data. In addition, in the real world, the interests and behavior of user i is similar to that of her neigh-bor set N U i , and the attributes of item j are similar to those of its neighbor set N V j . Based on this intuition, in the matrix fac-torization process we should make sure that similar users(items) will have similar latent feature vectors , and in this way the external neighborhood information is incorporated in the global MF of the rating matrix.

Motivated by the above analysis, we propose a novel two-stage framework, N eighbor h ood-aware P robabilistic M atrix F actorization (NHPMF), to improve recommendation accuracy. In the first stage, the user-tag and item-tag interaction matrixes are used to select the neighbor sets of users and items respectively. In the second stage, we add Gaussian priors on users X  and items X  latent feature vectors to ensure each user(item) X  X  latent feature vector is centered around the mean of her(its) neighborhood. The priors will lead to a corre-sponding regularization term that penalizes the latent vector diver-gence of each user(item) from her(its) neighbor set. Table 1 lists the mathematical notations used in this paper.

As stated earlier, it is natural to select neighbors of each user from the user-tag interaction matrix, where P il is the tf*idf weight s ( i, j ) between user i and j , can be measured by computing the cosine similarity of the angle between the two users in the mensional tag space:
After calculating similarities between users, it is easy to select the K nearest neighbors of user i , N U i . Identical steps can be used to characterize the similarity value t ( j, k ) between each pair Figure 1: Graphical representation of NHPMF Framework. For each of item j and k , and the K nearest neighbors of item j are denoted N
V j . For notational convenience in later chapters, we normalize the similarities between each user i and her neighborhood and those between each item j and its neighborhood N V j to ensure
Naturally, the behavior of user i is similar to that of her neighbor set
N U i and the attributes of item j are similar to those of its neigh-bor set N V j . Based on this intuition, we formulate the following equations:
In the above two equations, each user X  X  and item X  X  latent fea-ture vector is composed of two terms. The first term character-izes the group feature of the user(item), which is the weighted av-erage of her(its) neighborhood. The second term emphasizes the uniqueness of each user and item feature vector, which could di-verge from her(its) neighborhood to an extent. The divergence is controlled by the variance parameter  X  2 U and  X  2 V in Eq. (2) and Eq. (3). The smaller the variance, the less possible that the feature vector diverges from that of her(its) neighbor set. When the vari-ance approximates zeros, the second term vanishes. Using simple mathematical transformations, Eq. (2) and Eq. (3) will turn to the following two equations:
Taking the neighborhood information into account does not change the conditional distributions of the observed ratings given the user and item latent feature vectors. Thus, the conditional distribution over the observed rating is:
According to Eq. (4), Eq. ( 5) and Eq. (6), the corresponding graphical representation of our model is shown in Figure 1. Then through Bayesian inference, the log of the posterior distribution over user and item latent factors is given by Eq. (7):
Keeping the hyperparameters (  X  2 , X  2 U and  X  2 V ) fixed, maximizing the log posterior in Eq. (7) is equivalent to minimizing the follow-ing sum-of-squared cost function.
 tive function has three terms and it is smoothed by the parameter  X 
U and  X  V , which naturally fuses local neighborhood information with global matrix factorization in recommender systems. The pa-rameter  X  U controls how much the user neighborhood influences while  X  V controls how much the item neighborhood influences on the error function. With smaller values of  X  U and  X  V , we rely less on neighborhood information.

A local minimum of the objective function Eq. (8) can be found by performing gradient descent on U i and V j for each user each item j given the derivatives below.
The NHPMF model incorporates the tag-based neighborhood in-formation into matrix factorization for recommendation. The intu-ition behind this method is that the latent feature vector of each user(item) is similar to those of her(its) neighbors X . Eq. (4) and Eq. (5) ensure that the latent factor of each user(item) is composed of two parts, one is a weighted sum of her(its) neighbors X  charac-ters, and the other is her(its) own characters. Thus in NHPMF, each user X  X  and each item X  X  latent feature vector has a unique Gaussian distribution, where its mean is learned from the rating data and de-pendent on her(its) neighbors. Therefore, NHPMF is different from related PMF model [11], where it assumes all users and items obey the same zero mean Gaussian distribution, which is too general and rough to capture user X  X  and item X  X  personality when applied to real world applications.

Finally, to get deeper insights, we observe that our NHPMF model is actually a unified framework of KNN and PMF. Under certain circumstances, it degenerates to the following three methods:
In this section, we conduct several experiments on two real world datasets and demonstrate: (1) the effectiveness comparison between NHPMF and other state-of-the-art methods; (2) the influence of the parameter settings in the NHPMF; (3) the performance of the NH-PMF when users have few or even no observed ratings.

Dataset All experiments are performed on two real world datasets containing both rating and tagging data: the public MovieLens dataset 3 , and the Douban dataset 4 that we crawled from the web. Movielens has 10 million ratings and 100,000 tag applications to 10,000 movies by 72,000 users. The initial crawled Douban dataset cotains 10,000 users X  movie ratings and their tagging history. In both datasets, we remove those tags which are annotated by less than five distinct users and five distinct items for the tagging appli-cations. Then we select those users and items that have at least five distinct related tags. Finally we filter out those users and items that have no tagging history at all. More statistics of the pre-processed dataset can be seen in Table 2.
 Table 2: General statistics of the MovieLens and Douban
Baseline Methods and Evaluation Metrics We compare our model with the following baseline methods: UKNN [6], IKNN [12], PMF [11], SVD++ [8],TagiCoFi [14] and TagRec [15]. We choose these methods as baselines because they can be categorized into neighborhood models (UKNN,IKNN), matrix factorization mod-els (PMF, TagiCoFi and TagRec) and the hybrid of the above two (SVD++). Also, these baseline methods can be classified accord-ing to whether they use tagging information or not. TagiCoFi and TagRec use both the tagging information and rating data for rating http://www.epinions.com/ http://www.grouplens.org/node/73 http://www.douban.com/ prediction, the other methods use only the rating matrix. The eval-uation metric we use in our experiments is root mean squared er-ror (RMSE) [8], which is widely used to measure the performance of rating prediction accuracy in CF.

Effectiveness Comparison Table 3 and Table 4 report the RMSE values of all the algorithms under different settings of neighbor set size K and latent feature dimension D respectively. The neighbor set size K in neighborhood methods is set to 30, 50, 70 and 100 respectively while the dimensionality of the latent feature vectors D in matrix factorization methods is set to 5, 10, 20 and 30 respec-tively. As to the other parameters, we perform parameter tuning in advance for each method and use the best settings found in all the experiments for fairness.
 From the comparison, we have the following observations: (1) Our method NHPMF, which incorporates the neighborhood infor-mation into matrix factorization, performs the best in all situa-tions. Generally, NHPMF improves the RMSE of the best results of UKNN, IKNN, PMF, SVD++, TagiCoFi and TagRec by about 7%, 3%, 4.5%, 2.5%, 6% and 4%. (2) The results for Douban are better than the results for MovieLens for all methods, possibly because Douban is a much richer dataset since there are more tagging his-tory and ratings per person and per item (see Table 2). (3) In pure KNN methods, the neighbor set size K plays an important role in model accuracy. Increasing K in a certain range does intend to im-prove the overall recommendation accuracy [4]. However, there X  X  no benefit to increase K in NHPMF, because adding more neigh-bors will cover more global efforts, matrix factorization model can do well. This phenomenon is also noticed in [8]. (4) In matrix factorization models, the parameter of latent dimension D fect the model accuracy. In general, larger values of D will give us more flexibility to represent both users and items in the latent space, leading to better performance. However, due to the time complex-ity of matrix factorization, which is linear with respect to values of D will require more time in training the MF model. Impact of Regularization Parameter Figure 3 compares the RMSE of our model for the different ranges of regularization pa-rameter on MovieLens and Douban dataset. For convenience, we set  X  U =  X  V =  X  , and  X  is set to be 0, 0.1, 1, 5, 10, 20, 30, 40 respectively. The other parameters are set as K =50 and D =20 We observe that the value of  X  impacts the recommendation results significantly, which demonstrates that incorporating neighborhood information actually improves the recommendation accuracy. As  X  increases in the range [0 , 20] , the prediction accuracy improves quickly at first, but when  X  surpasses 20 , the prediction accuracy decreases. Clearly in this figure, the best regularization parameter setting for both datasets is  X  U =  X  V =20 . Performance with Different Sparsity One critical challenge in CF is to provide accurate recommendations when users supply only a few ratings or even have no rating history at all. In order to com-pare our model with the other methods under this situation, we split the 10% of the Douban dataset for training and the remaining for testing. Then we group all of the users based on the number of the observed ratings in the training data and make predictions on different user groups.

Figure 3(a) summarizes the user group distribution of the train-ing data. Obviously, this is a very sparse dataset since 19.18% of the users have at most three rating scores. The total number of rat-ing records in train data is 110,410. On average, each user rates 26.2 items, where there are totally 17,671 items in the dataset. And the density of the training rating data is 110 , 410 / (4213  X  17671) = 0 . 148% . Figure 3: Performance comparison on different user rating scales.

Pure CF methods, which only rely on the rating matrix, can not work well under this situation, since little preference information is available to provide any basis for recommendation. However, NH-PMF can solve this problem to some extent. When user i  X  X  rating information is limited, NHPMF can still rely on her tagging record and neighborhood information to infer her latent feature vector. As shown in Figure 3(b), NHPMF outperforms the other methods un-der all user groups, especially when few user ratings are given.
In this paper, we propose a unified framework to incorporate the complementary advantages of two popular approaches in CF: local neighbor method and global matrix factorization model. Mean-while, we explore the possibility of using external tagging data other than the rating data to capture local relationships for users or items. Specifically, tagging data is first used to find neighbors of each user(item) and the neighborhood information is then in-corporated into the factorization of rating matrix to make similar users(items) have similar latent features. Thus our method can bet-ter capture the local and global relationships of users and items, leading to more accurate recommendations. Experimental results on two real world datasets show that our model outperforms state-of-the-art collaborative filtering methods.

Acknowledgment The work was supported by grants from Nat-ural Science Foundation of China ( No. 61073110 ), the Key Pro-gram of National Natural Science Foundation of China ( No. 60933013 the Research Fund for the Doctoral Program of Higher Education of China ( No. 20093402110017 ) and the National Major Special Science and Technology Projects ( No. 2011 ZX 04016  X  071
