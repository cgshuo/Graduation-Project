 The ACM 14 th International Workshop on Data Warehousing and OLAP (DOLAP 2011), held in Glasgow, Scotland, UK on October 28, 2011, in conjunction with the ACM 20 th International Conference on Information and Knowledge Management (CIKM 2011), presents research on data warehousing and On-Line Analytical Processing (OLAP). The DOLAP 2011 program has three interesting sessions on data warehouse modeling and maintenance, ETL and performance, and OLAP visualization and extensions, and a panel discussi ng analytics in data warehouses. H.2 [Database Management]: H.2.0 General Algorithms, Design, Performance, Theory The 14 th DOLAP Workshop addresses research issues pertinent to creating, populating, and usi ng data warehouses. A data warehouse integrates multiple data sources into a single large repository to enable advanced querying and analysis. On-Line Analytical Processing (OLAP) is the most common type of analysis performed in a data warehouse, represented by exploratory queries and cube aggregations. Techniques for modeling data warehouses, ETL pro cesses, and performing OLAP queries have been proposed by researchers and implemented in industry over the last decade, but new application domains and the changing hardware and soft ware landscape provide fresh challenges with innovative solutions. DOLAP 2011 includes 8 long papers and 6 short papers, accepted out of 27 submissions, grouped into three sessions: data warehouse modeling and maintenance, ETL and performance, and OLAP visualization and extensions. The topics are diverse, including data warehouse modeling and integration, cloud data warehouses, spatial modeling, designing and parallelizing ETL, query optimization, and visuali zation and manipulation of OLAP cubes, among others. The program also includes a panel discussing current topics on an alytics in data warehouses. The DOLAP 2011 papers are organized into three sessions and summarized in the following. This session focuses on the latest research results in the context of modeling methodologies and mainte nance approaches for data warehouses. Iftikhar and Pedersen [9] propose an automated solution to the problem of reducing stored data as it becomes less important over time; their rule-based system computes aggregation at different levels of granularity based on age of the data, replacing hand-coded solutions with an effective, efficient, and more maintainable result. Riazati et al. [10] develop techniques that enforce strictness and reduce false positives for instance matching that occurs when merging dimensions in data warehouse integration; the techniques are shown to effectively support correct aggregation of merged data. Abell X  et al. [1] propose and evaluate different a pproaches for retrieving data cubes using Google X  X  cloud t echnologies BigTable and MapReduce. Sch X tz et al. [12] propose a model for data warehouse schema integration us ing a global common view along with sub-cubes and sub-dimensi ons for local schemas. This object-oriented approach supports different granularities in the source dimensions as well as incr emental integration as schemas evolve. Ruiz Del Aguila et al. [11] introduce the Spatial Data Warehouse Metamodel using UML metaclasses and a mathematical formalism for platform-independent schema modeling and validation; the authors illustrate their accompanying CASE tool with a meteorological case study. This session contains papers on ETL techniques for data warehouses, with respect to both programming paradigms and design methodologies, and algorith ms for managing and querying stream data warehouses efficien tly. Thomsen and Pedersen [13] develop and implement constructs to parallelize typical extract, transform, and load (ETL) tasks to exploit both task and data parallelism. The constructs are straightforward for ETL programmers to employ and are demonstrated to improve the elapsed time of ETL programs. Akkaoui et al. [2] offer a framework for model-driven development of ETL processes. Their approach leverages a pl atform-independent standard, Business Process Modeling Nota tion, and their framework automatically generates code for different vendor-specific platforms. Dyreson and Florez present an efficient algorithm to help users visualize missing data resulting from data sieves that are used to populate multidimensional databases from aggregated data streams [4].Gorawski and Chr X szcz apply and enhance techniques from stream data que ry processing to ETL processing in stream data warehouses [7]. In particular, they consider the interaction between the scheduler and the operator partition and demonstrate that exploiting the synergy can lead to improved performance. This session presents papers on extensions of OLAP data management and query processing, with a particular focus on OLAP visualization techniques. El-Helw et al. [5] show that column-oriented query processing can significantly improve the performance of row-oriented DBMSs by exploiting new operators that leverage index data and technologies such as multicore processors and flash memories. E xperimental results using typical data warehouse queries on a co mmercial row-oriented DBMS demonstrate the effectiveness of their approach. Hsaio et al. [8] describe a functional prototype of a web-based client-centric OLAP data visualization tool with an in-memory data/query engine, including a novel aggregation technique for large data sets represented in a scatter plot. Chen and Ordonez [3] incorporate parametric statistical tests into a tool for 2D interactive visualization of cubes; the visualization identifies significant differences of measures that di ffer by only one dimension. An experimental evaluation with medical data sets illustrates links between diseases and risk factor s. G X mez et al. [6] propose an implementation-independent data model and closed algebra for spatial OLAP. They introduce the notion of a continuous field (i.e., a physical phenomenon that changes continuously in time and/or space) modeled as a cube. Yu et al. describe an efficient algorithm for keyword search over a relational database [14]. They employ a cascading approach that tracks the top-k results at each stage; their performance studies suggest that the approach may be useful for mobile OLAP applications. DOLAP 2011 continues the line of DOLAP workshop series that began in 1998. DOLAP 2011 presents relevant research results and open discussion on next-genera tion research directions that we hope will serve as a valuable and up-to-date reference. [1] Abell X , A., Ferrarons, J., and O. Romero. Building Cubes [2] Akkaoui, Z.E., Zim X nyi, E., Maz X n, J.-N., and J.-C. Trujillo. [3] Chen, Z., and C. Ordonez. Interactive Visualization of OLAP [4] Dyreson, C., and O.U. Florez. Building a Display of Missing [5] El-Helw, A., Ross, K.A., Bhattacharjee, B., Lang, C.A., and [6] G X mez, S., G X mez, L.I., and A.A. Vaismann. Analyzing [7] Gorawski, M., and A. Chr X szcz. Optimization of Operator [8] Hsiao, T., Luk, W.-S., and S. Petchulat. Data Visualization [9] Iftikhar, N., and T.B. Pedersen. A Rule-based Tool for [10] Riazati, D., Thom, J.A., and X. Zhang. Enforcing Strictness [11] Ruiz Del Aguila, P.S., do Nasc imento Fidalgo, R., and A. [12] Sch X tz, C., Schrefl, M., Neumayr, B., and D. Sierninger. [13] Thomsen, C., and T.B. Pedersen . Easy and Effective Parallel [14] Yu, Z., Yu, X., and Y. Liu. Cascading Top-k Keyword 
