 Learning ranking (or preference) functions has been a major issue in the machine learning community and has produced many appli-cations in information retrieval. SVMs (Support Vector Machines) -a classification and regression methodology -have also shown excellent performance in learning ranking functions . They effec-tively learn ranking functions of high generalization based on the  X  X arge-margin X  principle and also systematically support nonlinear ranking by the  X  X ernel trick X . In this paper, we propose an SVM selective sampling technique for learning ranking functions. SVM selective sampling (or active learning with SVM) has been studied in the context of classification . Such techniques reduce the labeling effort in learning classification functions by selecting only the most informative samples to be labeled. However, they are not extend-able to learning ranking functions, as the labeled data in ranking is relative ordering, or partial orders of data. Our proposed sam-pling technique effectively learns an accurate SVM ranking func-tion with fewer partial orders . We apply our sampling technique to the data retrieval application, which enables fuzzy search on re-lational databases by interacting with users for learning their pref-erences. Experimental results show a significant reduction of the labeling effort in inducing accurate ranking functions.
 I.m [ Computing Methodologies ]: Miscellaneous; H.4 [ Information Systems Applications ]: Miscellaneous Algorithms Support vector machine, Ranking, Selective sampling, Active learn-ing Copyright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00.
Learning ranking (or preference) functions has been a major is-sue in the machine learning community [9, 7, 8] and has produced many applications in information retrieval [11, 4]. Targetting infor-mation retrieval applications, we distinguish the task of learning ranking functions from learning classification functions as follows: 1. Unlike classification functions, which output a distinct class 2. While a training set in classification is a set of data objects
There are other types of ranking models. However, this model has produced practical applications in information retrieval [9, 11, 15]. (Section 6 discusses other related ranking models.)
SVMs (Support Vector Machines) have proven effective in learn-ing classification or regression functions [14, 3, 5]. They have also shown excellent performance in learning ranking functions [9, 11, 15]. They effectively learn ranking functions of high generaliza-support nonlinear ranking by the  X  X ernel trick X  [9].

Typically, the SVM ranking (or the large margin-based pref-erence learning) machine learns a function in a supervised batch learning scenario, assuming a training set of samples (i.e., partial orders) is given. In many applications, however, collecting training samples involves human labor which is time-consuming and often expensive. While this has been a major issue in classification ,itis an even more serious problem in ranking [1]; Labeled data in rank-ing denotes partial ordering of data, and thus users must consider relative ordering of data in labeling while in classification users only consider the absolute class of data.

The concept of active learning or selective sampling refers to approaches that aim at reducing the labeling effort by selecting only the most informative samples to be labeled. SVM selective sampling techniques have been developed and proven effective in 1 In the context of ranking, function F of high generalization means that a learned ranking function F not only is concordant with the ordering of the training set (i.e., partial orders) but also generalize well beyond the training set. achieving a high accuracy with fewer examples in many applica-tions [12, 13, 4]. However, they are restricted to classification prob-lems and do not extend to ranking problems. (Section 6 discusses this in detail.)
We propose an SVM selective sampling technique for learning ranking functions (Section 3). That is, using our selective sampling technique, an accurate SVM ranking function can be learned with fewer partial orders . Our method is  X  X ptimal X  in the sense that it selects the most ambiguous set of samples at each round which is considered most informative in SVM ranking. Experimental results show a significant reduction of the labeling effort (Section 5).
We apply our sampling technique to the  X  X ata retrieval X  appli-cation [15], which enables fuzzy search on relational databases by interacting with a user for learning her preference (Section 4). Ex-periments on this application also show consistent results, i.e., our selective sampling method induces ranking functions of high accu-racy with fewer interaction with users.

This paper is organized as follows: We first overview the SVM rank learning in Section 2, present the SVM selective sampling technique for ranking in Section 3, and then present the data re-trieval application in Section 4. We experimentally evaluate our method in Section 5. We discuss related work in Section 6 and conclude our study in Section 7.
To establish the context of our discussion, we first discuss pre-liminaries. We represent data as a vector d , in which each element is a numerical value indicating an attribute value of the data. For instance, a vector d representing a for-sale house from an online real estate company such as realtor.com can be represented by a vector ( age,price,size,beds,baths ) .

We say d i &gt; R d j or ( d i , d j )  X  R if a vector d i than d j in an order R , otherwise, we say ( d i , d stated, we assume for simplicity that R is strict ordering, which means that for all pairs d i and d j in a set D , either d d j &gt; R d i . However, it can be straightforwardly generalized to weak orderings.
 dered perfectly according to user X  X  preference. A ranking function F is evaluated by how closely its ordering R F approximates Kendall X  X   X  has been the most widely used measure for similarity between two orderings R  X  and R F [11]. For two strict orderings R a and R b , Kendall X  X   X  is defined based on the number P of con-cordant pairs and the number Q of discordant pairs. If R  X  and agree in how they order a pair, d i and d j , the pair is concordant, otherwise, it is discordant. For ordering R  X  and R F on a dataset D , we define the similarity function  X  as the following:
To illustrate, suppose R  X  and R F order five vectors d 1 as follow:
In this example,  X  ( R  X  ,R F ) is computed as 0 . 7 , as the number of discordant pairs is 3, i.e., { d 1 , d 2 } , { d 1 , d remaining 7 pairs are concordant.

Using the  X  measure, we evaluate the accuracy of F as the simi-larity of the ordering R F generated by F and the optimal ordering R  X  , i.e. ,  X  ( R F ,R  X  ) .
Using the techniques of SVM, we can learn a global ranking function F from partial orders R  X  R  X  . For now, assume linear ranking function such that:
A weight vector w is adjusted by a learning algorithm. We say a set of partial orders R is linearly rankable if there exists a function F ( i.e. , a weight vector w ) that satisfies Eq.(4) for all
The goal is to learn F which is concordant with the given partial orders R  X  R  X  and also generalize well beyond R . That is to find the weight vector w that satisfies Eq.(4) for most data pairs ( d
Though this problem is known to be NP-hard [6], Reference [9] approximates the solution using SVM techniques by introducing (non-negative) slack variables  X  ij and minimizing the upper bound P  X  ij [9] as follows.

QP 1. minimize : W ( w, X  ij )= 1 2 w  X  w + C subject to :  X  ( d i , d j )  X  R : w  X  d i  X  w  X  d j +1  X  By the constraint (6) and minimizing the upper bound (5), QP 1 satisfies orderings on the training set R with minimal error. By minimizing w  X  w or by maximizing the  X  X argin X  (= 1 it tries to maximize the generalization of the ranking function. We will discuss how maximizing the margin corresponds to increasing the generalization of ranking in Section 2.2.1. C is the soft margin parameter that controls the trade-off between the margin size and training error.

By rearranging the constraint (6) as QP 1 becomes equivalent to that of SVM classification on pairwise difference vectors ( d i  X  d j ). Thus, we can extend an existing SVM implementation to solve the QP.
The support vectors in QP 1 denote the data pairs ( d i , d that w ( d i  X  d j )=1 . Assume that the training data is linearly rankable and thus  X  ij =0 for all ( i, j ) . Then, from Eq.(8), the sup-port vectors are the closest data pairs when projected to Eq.(4), the linear ranking function F w projects data vectors onto a weight vector w . The geometrical distance of the two vectors ( d ometrically, the margin  X  ( = 1 || tion problem, denoting the distance from the support vectors to the boundary -denotes, in the ranking problem , the distance between the closest two projections. This is illustrated in Figure 1: two different linear functions F w 1 and F w 2 project four data vectors { d 1 , d 2 , d 3 , d 4 } onto w 1 and w 2 respectively in a two-dimensional space. Both w 1 and w 2 make the same ordering R for the four vec-closest two projections onto w 1 and w 2 are respectively
QP 1 computes the weight vector w such that it is concordant with the given orders and generalizes beyond it by maximizing the distance of the closest data pairs in ranking. By minimizing w , QP 1 maximizes the margin, i.e., the distance of the closest data vectors in ranking. For instance, in Figure 1, although the two weight vectors w 1 and w 2 make the same ordering, intuitively w 1 generalizes better than w 2 because the distance of the closest vectors in w 1 (i.e.,  X  1 ) is larger than that in w 2 (i.e., to [9, 11] for the detailed discussion on maximizing the margin in ranking.

It can be shown that the learned ranking function F can always be represented as dot products of data vectors, and thus it is possible to use nonlinear kernels to learn nonlinear ranking functions. Refer to [9] for the nonlinear kernel extension of the ranking function.
In this section, we present our SVM selective sampling algorithm for ranking , which reduces the labeling effort by selecting only the most informative samples to be labeled.

While previous SVM selective sampling (or active learning) tech-niques have been studied for binary classi fi cation [12, 13, 4], they are not extendable to learning ranking functions, as selective sam-pling for ranking is more complicated.

The key idea of our selective sampling technique is to select the most ambiguous samples for ranking at each round, so that the user  X  s feedback on those samples will maximize the degree of learning. As discussed in Section 2.2, the support vectors in rank-ing denote the data pairs that are the closest and thus most am-biguous in ranking. Thus, this principle effectively identi fi es the support vectors with fewer labeled data (or partial orders). Our sampling algorithm is  X  optimal  X  in the sense that it selects the most ambiguous set of samples with respect to the learned ranking func-tion at each round.

We fi rst brie fl y overview the selective sampling for classification (Section 3.1) and present our method (Section 3.2).
In a typical setting of selective sampling for binary classi fi ca-tion, it is assumed that acquiring a large number of training data (or labeled data) is hard or expensive, so we want to minimize the total number of samples to label in order to achieve a high accu-racy. The basic idea of SVM selective sampling in classi fi cation is that at each round, the learning machine selects the samples that are the closest to the classi fi cation boundary so that they are the most dif fi cult to classify. Since an SVM classi fi cation function is repre-sented by support vectors that are the data closest to the boundary, this simple selective sampling technique effectively learns an accu-rate function with fewer labeled data [12, 13]. 1. Put the positive and negative data into training set, and build 2. Compute | F ( d ) |  X  the relative distance from a data point 3. User labels (or classi fi es) the selected data. 4. Accumulate the newly labeled data into the training set. 5. Repeat from 2 until the boundary function becomes accurate Figure 2: Selective sampling framework for classification
Figure 2 shows the SVM selective sampling framework for clas-si fi cation which is introduced in [12] to deal with text classi fi ca-tion problems. They assume that they have a few labeled data to start with. The relative distance from a vector d to the boundary is evaluated by | F ( d ) | , where F is an SVM classi fi cation function. At each round, the system selects l unlabeled data that are clos-est to the boundary. The user labels the selected data, which will be included in the training set for the next round. The function becomes more accurate as it iterates. It has been shown that us-ing this selective sampling, the function F becomes accurate with fewer rounds than by using random sampling [12, 13].
Similar to the framework of Figure 2, our framework in Figure 3 starts with l randomly selected samples (Step 1). Once a user orders the samples (Step 2), the learning machine puts the partial orders into the training set and builds an SVM ranking function F the training set by solving the QP 1 (Step 3).
 In Step 4, the learning machine selects another l samples, are most ambiguous for ranking such that | F ( d i  X  d j ) for all ( d i , d j )  X  S . Note that the relative ranking difference be-tween d i and d j is evaluated by | F ( d i  X  d j ) | .

As discussed in Section 2.2, the support vectors in ranking are the data pairs that are the closest and thus most ambiguous for ranking. Thus, this sampling principle quickly identi fi es the sup-port vectors and reduces the total number of labeled data to achieve a high accuracy.

To select the most ambiguous samples in Step 4, we de fi ne the objective function: 1. Randomly select l number of samples. 2. User orders the samples. 3. Accumulate the orders into the training set and build a rank-4. Return F if F is accurate enough. Otherwise, choose another 5. Repeat from 2.
 where C ( S i +1 ) ( i.e. , the cost function of S i +1 ) is the sum of the ranking difference of every data pair in S i +1 , i.e. , i is the number of iterations. F i is the ranking function learned at i th iteration. S i +1 is the target set that we want to select for the next iteration, and it is selected based on the ranking difference according to F i .

The QP 1 in Section 2.2 uses every data pair ( d j , d k ) as training data [9, 11]. Thus, the objective function Eq.(9) mini-mizes the sum of ranking differences of every data pairs within the samples such that their rankings are most ambiguous each other.
A naive way to select S i +1 that minimizes the cost function re-quires | every combination of l data objects in the dataset. However, such a long selection time is often unacceptable in information retrieval applications, including the data retrieval application we will present in Section 4, as most information retrieval applications require a fast response time.

We can reduce the response time by sacri fi cing the accuracy by approximating Eq.(9) as follows. 1. Compute | F ( d j  X  d k ) | for every data pair ( d j 2. Sort the index pairs { ( j, k ) ,... } in ascending order according 3. Take the top l indices I from the index pair list. 4. Select the data d j for j  X  I .

This approximation reduces the number of the function evalua-tions to O ( | However, its results are not optimal because it does not minimize the cost function.
Is it possible to design an  X  X ptimal X  algorithm that minimizes the cost function C ( S i +1 ) and is also efficient? At the end of this section, we present an optimal algorithm that computes S i signed based on Theorem 1, which we will establish. To prove Theorem 1, or to prove the optimality of our algorithm in the sense that it minimizes the cost function, we fi rst introduce lemmas 1 and 2.
 Let R = { d 1 , d 2 , ..., d | to ranking function F i  X  generated at the i th iteration  X  such that d &gt; R d b for a&lt;b .
 be a subset of R . r is consecutive if b  X  a = | r | +1 .
L EMMA 1. Let r = { d a , ..., d b } be a non-consecutive subset of
R having only one empty spot, i.e., b  X  a = | r | , and let the empty spot be d x ( a&lt;x&lt;b ) . Suppose we construct two consecutive subsets r 1 and r 2 from r such that ( | r 1 | = | r 2 | = ing in X  d x and removing the last vector d b and the first vector respectively, as shown in Figure 4. Then,
P ROOF . Let C ( r x ) denote the cost function of r involving only d , i.e. , Let C ( r b ) and C ( r a ) denote the cost function of r d and d a respectively, i.e. , Then, we can denote Let  X  x denote F ( d x  X  d x +1 ) as shown in Figure 4. For instance, F ( d x  X  d x +2 )=  X  x +  X  x +1 . Then, C ( r x ) and C ( r formulated as the following:
C ( r x )=1  X  a +2  X  a +1 + ... +( x  X  a )  X  x  X  1 +( b  X 
C ( r b )=1  X  a +2  X  a +1 + ... +( x  X  a )  X  x  X  1 +( x  X  Thus, In a similar way, If we plug Eq.(14) into Eq.(16), and plug Eq.(15) into Eq.(17)
Lemma 1 implies that for a non-consecutive subset r having one empty spot, we can always build a consecutive subset r such that the cost of the consecutive one (i.e., C ( r ) ) is smaller than that of the non-consecutive one (i.e., C ( r ) ).

L EMMA 2. Let r = { d a ,..., d b } be a non-consecutive subset of
R such that b  X  a +1 &gt; | r | , Then, there exists a consecutive subset r such that | r | = | r | and C ( r ) &lt;C ( r ) .
P ROOF . We can build r new such that C ( r new ) &lt;C ( r ) ing in one empty spot d x and removing either d a or d b : 1. re-number the data in r with d x by its ordering, 2. fi ll in d x and remove either the fi rst or the last data, and 3. reinstate the data numbers. (Either d b or d a is removed.) From Lemma 1, performing the above  X  X i lling-in  X  procedure in Step 2 will generate a new subset C ( r new ) such that C ( r C ( r ) . We repeat this  X  X i lling-in  X  procedure for every empty spot until r new becomes a consecutive set r . Thus, for any non-consecutive set r , we can always build a consecutive set r such that C ( r ) .
 T HEOREM 1. A subset r of R that minimizes the cost function C ( r ) is consecutive .

P ROOF . Suppose some r that minimizes the cost function is not consecutive. Then, from Lemma 2, there exists another consecu-tive set r within r such that C ( r ) &lt;C ( r ) , which contradicts the premise. Therefore, the subset minimizing the cost function must be consecutive.

From Theorem 1, to fi nd an S i +1 that minimizes the cost func-tion, we can search over only consecutive sets in R . Thus, we can design a selective sampling algorithm that scans the dataset twice (
O ( | D | ) ) to compute S i +1  X  one for generating R and the other for computing S i +1 from R  X  as described in Figure 5. 1. Scan D to build R using F i . 2. Set C min := a large number; 3. Read the fi rst l data from R , i.e. , { d 1 ,..., d l 4. Set j := 1 ; 5. Repeat until j + l  X  1 &gt; | R |
This section presents an application of our selective sampling algorithm -data retrieval -which enables fuzzy search on relational databases by, on a  X  front-end  X  , interacting with users to formulate fuzzy queries, and, on a  X  back-end  X  , leveraging a relational query system to process the queries.
 Consider several example scenarios of data retrieval in Figure 6. A user Amy is looking for a house in Chicago. She searches real-tor.com with a few constraints on city,price,beds,baths , which returns 3,581 matching houses. Similarly, when Amy searches froogle.com for digital camera , she is again overwhelmed by a total of 746,000 matches. She will have to sift through and sort out all these matches according to her preference . Or, Amy may real-ize that she must  X  narrow  X  her query. However, if she narrows her search too far, she may well get no hits at all  X  an equally undesir-able extreme. She will likely manually  X  oscillate  X  between these extremes before eventually managing to complete her data search task, if at all.

As another example, consider a biologist Bob, searching for genes related to tumor X from a human genome database like EnsEMBL 2 . Bob knows that tumor X shares some features with cancers A and C . He needs to formulate a query, from his domain knowl-edge, to express the features of A , B and C that are relevant to Formulating such a query is far from trivial for ordinary users like Bob. Furthermore, after retrieval, it will still take him a long time to investigate all candidate genes for possible involvement with Relational databases support the processing of rank queries through ORDER BY and LIMIT clauses in SQL. Amy  X  s query  X  searching for cheap and large houses in Chicago  X  can be formulated in SQL as follows.
 Query Q : SELECT h.id, h.address FROM House h WHERE h.city = Chicago ORDER BY min( f 1 : cheap (h.price), f 2 : large (h.size)) LIMIT 10 Predicate -cheap (h.price): IF (h.price &gt; 500 , 000 ) THEN RETURN 1 . 0  X  h.price ELSE RETURN 1 . 0 Predicate -large (h.size): IF (h.size &gt; 5000 ) THEN RETURN 1 . 0 SQL ranks the results based on the score returned in the ORDER BY clause. Users specify the soft predicates (e.g., cheap , large ) such that the returned scores are between zero and one.

While this score-based ranking model supported in SQL is ex-pressive and ef fi cient, formulating such ranking functions is chal-lenging to users. It is far from trivial for the user to articulate how she evaluates each and every object into an absolute numeric score, that is, to express her preference by de fi ning the soft predicates and function. Note that, unlike typical relational queries usually for-mulated by application developers or DB administrator, common users for data retrieval tasks are ordinary people like Amy. Thus, to accommodate such users, the formulation of ranking must be essentially supported -without which ranking is not usable.
A framework was proposed to provide users with an intuitive way for expressing their preferences into queries [15]: Preference often stems from relative ordering without explicit absolute scores. The framework allows users to specify only relative ordering or partial orders ; it is up to the system to infer the underlying ranking function from the few examples. In other words, it gets qualita-tive feedback from the user and generates a quantitative ranking function which is usable in the existing relational query model.
By learning a scoring function , the SVM ranking machine can be easily adopted in the relational query model. From Eq.(4), function F outputs the ranking score and thus is adoptable in the ORDER BY clause in SQL.

Our selective sampling framework (Figure 3) can be used as a front-end query formulator , as illustrated in Figure 7: Figure 7: Rank formulation and processing for data retrieval.
The rank processing module (Figure 7, bottom) carries out the learned function F for query processing over the database.
The rank formulation module (Figure 7, top) iteratively interacts with the user to learn the desired ranking function. This process operates in rounds , as Figure 3 also presents. In each round, the learning machine selects a sample S of a small number of jects (for l&lt;&lt;D ; e.g. , l =4 or 5 in our study). The user orders these examples by her desired ranking R  X  ; thus she  X  labels  X  these examples as training data. The learning machine will thus learn a function F from the training data; let R F over the latest sample S .At convergence , i.e. , when R F ciently close to R  X  ( i.e. , when F is accurate on S ), the learner will halt and output F as the learned ranking function.

Note that, unlike typical document retrieval tasks, users in data retrieval tasks are often willing to perform many iterations to fur-ther re fi ne the ranking functions . A document retrieval task usually ends as soon as the user fi nds a few satisfying documents. However, users in data retrieval tasks often want to retrieve every possible candidate before they make decisions. For instance, users search-ing for houses or digital camcorders do not easily end their tasks by retrieving a few good samples. Instead, they usually retrieve ev-ery possible candidate that fi ts their preferences before they make purchasing decisions. Spending more time on re fi ning the ranking function is likely to reduce the total time for performing the data retrieval task.
This section reports our extensive experiments for studying the effectiveness of our selective sampling algorithm. Due to the lack of labeled real-world datasets for ranking which are completely ordered, we mostly evaluate our method on arti fi cially generated global orderings R  X  .We fi rst evaluate our method on synthetic data with arti fi cially generated ranking functions (Section 5.1). Then we use real-world data  X  realtor.com  X  to demonstrate the practicality of the method (Section 5.2). We fi nally discuss some issues in ex-tending the selective sampling technique for nonlinear ranking and further possible applications (Section 5.3).

We use Kendall  X  s  X  measure discussed in Section 2.1 for eval-uation. We implemented the SVM ranking (i.e., QP 1) and the selective sampling algorithm using Matlab. Our experiments were conducted with a AMD Athlon 64 2800+ PC with 1GB RAM.
We here evaluate the learning performance of our method against random sampling. We randomly created 1000 data points of 10 dimensions (i.e., 1000-by-10 matrix) such that each element is a random number between zero and one. For evaluation, we arti-fi cially generated ranking functions: First, we generated arbitrary linear functions F ( d )= w  X  d by randomly generating the weight vector w . The global ordering R  X  is constructed from the func-tion. Second, we constructed a second-degree polynomial function F ( d )=( w  X  d +1) 2 by also generating w randomly. Figure 8: Accuracy convergence of random and selective sam-pling (linear function). X-axis: # of iterations; Y-axis: accuracy; RAN: random sampling; SEL: selective sampling. Figure 9: Accuracy convergence of random and selective sam-pling (polynomial function). X-axis: # of iterations; Y-axis: ac-curacy; RAN: random sampling; SEL: selective sampling.

We generated global orderings R  X  from the two types of ranking functions and tested the accuracy of our sampling method against random sampling on the orderings. The results are averaged over 20 runs.

Figure 8 and 9 show the accuracy convergence of random and se-lective sampling for linear and polynomial functions respectively. We use SVM linear and polynomial kernel for them respectively. The selective sampling method consistently outperforms random sampling on both types of functions: The accuracy at the fi rst iter-ation is the same because they start with the same random samples. Selective sampling achieves higher accuracy at each iteration (or each number of training samples). We selected four samples at each iteration (i.e., l =4 ). References [12, 13] observe similar behaviors for classi fi cation problems.
This section performs experiments with a real-life house dataset extracted from realtor.com . We extracted all the for-sale houses in Illinois from realtor.com , resulting in N = 20990 objects for relation house , each with attributes id, price, size (in square feet), # of bedroom, # of bath, zip and city . 3 We use SVM linear kernels in this experiment. We discuss using nonlinear kernels in practice in Section 5.3.
We fi rst synthetically generate queries simulating real situations and evaluate the accuracy and response time of each method. Query 1 shows a scenario of fi nding a house in a big city, Chicago , while Query 2 focuses on a small city, Champaign .
 Query 1: Query 2: Predicates:
The queries in Figure 10 show that the user is interested in cheap and large houses having many beds and baths. The predicate de fi ni-tions in the fi gure illustrate the user  X  s preference in more detail. For instance, the user is willing to trade 200 square feet of size (which
Q1 3 90.60 93.62 92.60 0.003 0.027 9.67
Q2 3 89.90 93.23 91.09 0.004 0.013 0.098 Table 1: Performance results (averaged over 20 runs). R: # of rounds ( l =5 ); Time: average response time; RAN: random sampling; SEL: selective sampling; ASEL: approximated selective sampling; decreases the score of b by 20) for one more bedroom (which in-creases the score of c by the same amount). The ranking function can be formulated as the following linear ranking function: F ( d ) = 100  X  0 . 001  X  price +0 . 1  X  size +20  X  beds +20
We generated user feedback, i.e. , partial orderings, based on the given query. We generated fi ve samples at each iteration. We then measured the accuracy of the learned ranking function and response time at each round, with (1) random sampling (RAN), (2) our se-lective sampling (SEL), and (3) the approximate selective sampling (ASEL) which takes O ( | Section 3.2). Table 1 summarizes the results. The results are aver-aged over 20 runs. We highlight our observations as follow:
Due to the lack of real-world datasets for evaluating ranking, it is dif fi cult to evaluate selective sampling in real situations. Thus, this section focus on presenting the potential of the selective sam-pling method in the applications of data retrieval by demonstrating experiment results with real-life users. We asked 10 ordinary users to test our system with their own house preferences and collected around 100 real queries.
 Note that, in this user-study setting, the perfect ordering user intended remains unclear and thus it is hard to make fair eval-uations; It is infeasible for a user to provide a complete ordering Figure 11: Performance convergence of three sampling meth-ods on Query 1. SEL: selective sampling; ASEL: approximated selective sampling; RAN: random sampling. Figure 12: Performance convergence of three sampling meth-ods on Query 2. SEL: selective sampling; ASEL: approximated selective sampling; RAN: random sampling. on hundreds or thousands of houses. Thus, we evaluated the ac-curacy of the ranking function at this iteration against the partial accuracy of the ranking function F i learned at i th iteration is mea-sured by comparing the similarity of the user  X  s partial ordering on S +1 at the next iteration and the ordering generated by F i l = | S | =5 at each iteration. We call this measure expected ac-curacy , as it is an approximation evaluated over ten pairwise order-ings. (An ordering on fi ve samples generates ten (= 5 C orderings.) That is,  X  100% expected accuracy  X  means it correctly ranks fi ve samples that are randomly chosen.

This measure approximates the generalization performance of ranking functions, as S i +1 is not a part of training data for learning F . Further, using this evaluation method, we can also acquire fair evaluations from users since the users are not aware of whether they are providing feedback or evaluating the functions at each round.
However, this measure severely disfavors selective sampling. In-tuitively, selective sampling will be most effective for learning if the user  X  s ordering on S i +1 is not what is expected from the pre-vious iteration. We thus use random sampling for the user study reported in this section. However, note that selective sampling is expected to be more effective in practice, as demonstrated in our experiments on synthetic data (Section 5.1) and on real data with synthetic queries (Section 5.2.1.)
Figure 13 shows the distribution of user queries generating over 90% and 100% expected accuracy per each iteration. Observe from Figure 13 that most user preferences were captured with 90% ex-Figure 13: Distribution of user queries generating over 90% and 100% expected accuracy Figure 14: Screen shot of our running system. The candidate set: houses in Chicago pected accuracy within the second iteration, and 100% within the third iteration.

Figure 13 implies that, for the real-user preferences, the SVM ranking with random sampling learns an accurate (i.e., expected accuracy  X  90%) ranking function in a couple of communications with a user (i.e., iterations  X  2). Our experiments in previous sec-tions suggest the SVM with selective sampling will achieve higher accuracy with fewer interactions with users. Note that the accuracy here is based on the house dataset. The learning performance could vary depending on the type of data (e.g., the number of attributes.)
To qualitatively demonstrate, Figure 14 shows a screen shot of our system that we used in our user study:
At Round 1, the system showed fi ve randomly selected samples of houses. Each house shows its price, number of beds and baths, zipcode). We have not performed any normalizations of the at-tribute values. Assume that the user prefers cheap and large houses with many beds and baths. Based on this criteria, a user ordered the fi ve houses such that 5 &gt; R  X  2 &gt; R  X  4 &gt; R  X  3 &gt;
At Round 2, the system showed another randomly selected fi ve samples, and the user ordered them as 1 &gt; R  X  2 &gt; ated by F 1 . Thus, the expected accuracy after Round 1 is 100% in the fi gure. Our system printed out the top ten results accord-The top house ranked by the function ( i.e. , PRICE:59000, BEDS:8, BATHS:2, SIZE: 1080, ...) is large and has many bedrooms, but is low in price.

The following is the ranking function generated by our system after the fi rst round.

Observe that the ranking function F 1 from the fi rst iteration cap-tures that the user prefers houses of low price , many large size . In contrast, the weights of baths and latitude low, which implies, from the fi rst round, the machine learns that these two attributes do not contribute much in ranking the data ob-jects. (Note that attributes are not normalized, e.g. , the values of price and size are relatively large compared to the others.)
Nonlinear ranking: We used only SVM linear kernels in the experiments with real queries. Linear functions are simple, yet of-ten expressive enough, and thus have been used as a popular model for rank (or top-k) query processing [2, 10]. However, deploying nonlinear functions might be necessary to deal with complex pref-erences that are not rankable by linear functions. Nonlinear ranking functions can be learned directly using SVM nonlinear kernels [9]. However, tuning the nonlinear kernel parameters online is not triv-ial, as it is hard to perform a validation online.

Further applications: Other than the data retrieval applications, our selective sampling techinque is applicable to any rank or pref-erence learning tasks, as labeling is time-consuming and often ex-pensive in many applications. For instance, this technique can be used to infer a customer  X  s preference by getting a small amount of feedback. Getting a large amount of feedback from customers increases accuracy, but is often cumbersome to the customers.
References [12, 13] present SVM selective sampling techniques for binary classi fi cation. Reference [4] applies the techniques pro-posed in [12, 13], to conduct effective binary relevance feedback for image retrieval. However, these techniques are proposed within the context of binary classi fi cation (of whether the image is rele-vant or not) and thus does not support learning ranking functions from partial orders.
 There is an effort to extend the selective sampling to ranking [1]. It is based on pairwise decomposition [7] and constraint classi fi ca-tion [8]. They extend multi-class classi fi cation to ranking and thus are limited to a fi nite and a priori fi xed set of data and the model is not scalable to the size of the dataset.

Our selective sampling is based on the large-margin ranking which has proven effective in practice for learning global ranking func-tions [9, 11]. This ranking model orders new examplies with re-spect to their ranking scores, and thus is scalable and has produced many practical applications for information retrieval [9, 11, 15].
This paper proposes an SVM selective sampling technique for learning ranking functions . Our method selects the most ambigu-ous set of samples for ranking so that the ordering on the set maxi-mizes the degree of learning. Thus, our sampling technique signi fi -cantly reduces the labeling effort to learn an accurate SVM ranking function. We apply our method to the data retrieval application. Our experiments on synthetic and real datasets show that our sam-pling method learns an accurate ranking function with fewer sam-ples than random sampling and a naive selective sampling method and also is more scalable to large datasets than the naive selective sampling method. [1] K. Brinker. Active learning of label ranking functions. In [2] N. Bruno, L. Gravano, and A. Marian. Evaluating top-k [3] C. J. C. Burges. A tutorial on support vector machines for [4] E. Chang and S. Tong. Support vector machine active [5] N. Christianini and J. Shawe-Taylor. An Introduction to [6] W. W. Cohen, R. E. Schapire, and Y. Singer. Learning to [7] J. Furnkranz and E. Hullermeier. Pairwise preference [8] S. Har-Peled, D. Roth, and D. Zimak. Constraint [9] R. Herbrich, T. Graepel, and K. Obermayer, editors. Large [10] V. Hristidis, N. Koudas, and Y. Papakonstantinou. PREFER: [11] T. Joachims. Optimizing search engines using clickthrough [12] G. Schohn and D. Cohn. Less is more: Active learning with [13] S. Tong and D. Koller. Support vector machine active [14] V. N. Vapnik. Statistical Learning Theory . John Wiley and [15] H. Yu, S. Hwang, and K. C.-C. Chang. Rankfp: A framework
