 ETSIIT. CITIC. University of Granada, Granada, Spain 1. Introduction
When using search heuristics such as evolutionary algorithms (EAs) [1,2], simulated annealing (SA) [3,4] or local search algorithms [5 X 7], specific parameters such as application rates for genetic operators, selection and replacement mechanisms, and the initial population, must first be chosen. The parameters used to apply these elements determine the way they operate and influence the results. There-fore, finding appropriate parameter values is a challenge in the field of metaheuristics, and can be ad-dressed before the run (parameter tuning) or during the run (parameter control) [8 X 10].
Due to the importance of the effect of parameters on the results, a detailed statistical analysis of the influence of each one should be performed, paying special attention to those providing the values that are statistically significant. In this paper, we propose using the ANOVA (ANalysis Of the VAriance) [11] statistical method as a tool to analyze a well known metaheuristic to solve function approximation prob-lems.
This method allows us to determine whether a change in the results (responses) is due to a change in a parameter (variable or factor) or to a random effect, which makes it possible to determine the variables that have statistically significant effect on the method that is being evaluated. The theory and methodology of ANOVA was mainly developed by R.A Fisher during the 1920s [11]. ANOVA examines the effects of one, two or more quantitative or qualitative variables, called factors, on one quantitative response. ANOVA is useful in a range of disciplines when it is suspected that one or more factors might affect a response. It is essentially a method used to analyze the variance to which a which can be identified.

With ANOVA, we test a null hypothesis that all the population means are equal against the alternative hypothesis that there is at least two means that are not equal. We find the sample mean and variance for sample means from the overall mean. This variance is referred to as the variance among the means .The second estimate of the population variance is found by using a weighted average of the sample variances. In order to solve this test, the significance level have been fixed in  X  = 0.05.

After applying ANOVA, if the test shows significant differences, post-hoc tests must be applied to find which levels are causing these differences. Tukey X  X  Honestly Significant Difference (HSD) [12] has been used for this purpose in this paper.
 What we propose in this paper is a methodology based on applying the statistical parametric test ANOVA to determine the most important parameters of an EA in terms of their influence on the results,
By using such a methodology, we might learn which parameters have almost no effect on the perfor-of obtaining the best result, or at least one that does not fall in a local minimum. The main difference from previous approaches is that statistical tools to determine the significance and relative importance of parameters of a search method are used.

The rest of this paper is structured as follows: Section 2 presents a comprehensive review of the ap-proaches found in the bibliography to describe different application parameters and determine the most suitable values for these parameters. Section 3 briefly describes the EA algorithm, and analyzes the pa-rameters we propose to evaluate. This section also presents the experimental setup and the methodology in Section 5. 2. Related work
For years, one of the most common ways of setting design parameters in evolutionary algorithms was ward approach is to generate and test [15]. An alternative is to use a meta-algorithm to optimize the parameters to solve a wide range of optimization problems.

However, as some authors remark, solving specific problems requires specific parameter value sets [8, 17,18] and, as Harik [19] claims, nobody knows the  X  X ptimal X  parameter settings for an arbitrary real-difficult problem.

Traditionally, adjusting the main design parameters has been usually solved either using conventions, ad-hoc choices, intensive experimentation with different values [10,20,21], and even random initializa-tion values [22], that is why new practices, based on well-grounded tuning methods (i.e. robust mathe-matical methods), are needed. Such a methodology is what we propose in this paper.
Evolutionary algorithm users used to adjust their main design parameters (crossover probability, muta-to which values are best is usually made in terms of the most common values or experimental formulae given in the bibliography, or by trial and error [25,26].

Other researchers have proposed the determination of a good set of evolutionary algorithm parameters undertaking a theoretical analysis [19,27,28]. In these works, a set of parameters is found, but instead of finding them by means of intense experimentation, the parameter settings are backed up with theoret-ical work (meaning that these settings are robust). Establishing parameters using these methods means using suitable sets of parameters to solve similar problems; however they do not usually explain how to both an evolutionary [29,30] and simulated annealing algorithm [31] to search for the optimal parameter setting to solve the longest common s ubsequence problem. However, Weyland does not carry out this approach to practice or show how to carry it over to different problems.

Higher level algorithms [32] have been proposed to face the problem of establishing parameter values: several methods of testing and comparing different values before the run (parameter tuning), such as REVAC [33,34], SPOT [35,36], F-Race [37] and ParamILS [38] have been published. In this way, Smit et al. [10] propose improving the CEC2005 EA winner using REVAC as parameter tuning method.
Practical approaches based on setting parameter values on-line (during the run) instead of a previous parameter tuning have been proposed: Montero et al. [39] propose using off-line calibration techniques to detect whether a genetic operator help the evolutionary algorithm to perform his work, while Leung et al. [40] propose a novel adaptive parameter control system to control the parameters of a history-driven EA in an automatic manner. Their method obtains similar results to other methods while sets two EA parameters automatically. Other proposed methods in this line are based on coding the parameters niques (controlled by feedback from the search and optimization process) [20,21,41]. However, control
Recently, there has been a growing interest in the use of different statistical techniques in algorithms comparison [42,43]. In this sense, Shilane et al. [44] proposes a framework for statistical performance comparison of evolutionary computation algorithms. Garc X a et al. [45] presents an analysis of the be-haviour of evolutionary algorithms in optimization problems using parametric and non-parametric sta-improve classical methods [46 X 49]. For example, feature selection [50,51] practitioners have widely ap-plied ANOVA for this purpose in the literature [52 X 54]. Finally, Rojas et al. [55] study the effects of parameters involved in GA design by applying ANOVA, while Castillo et al. [56] use statistical tools to find accurate parameter values involved in the design of a neuro-genetic algorithm. However, methodol-ogy presented in these papers [57], could be improved by means of post-hoc statistical tests.
We propose a complete methodology based on parametric statistical tools to analyze the parameters with a higher influence on the performance for a given optimization method. The motivation of the when designing an optimization method. Our proposal could be helpful to practitioners in designing and analyzing their optimization methods. 3. Experimental setup Proposed methodology has been tested on EAs [1,2], which are widely studied optimization methods. Next, a brief description of the proposed algorithm is presented, focusing on detailing the parameters, the methodology and the problems used. 3.1. Proposed metaheuristic and parameters analysis evolution. Candidate solutions to the optimization problem play the role of individuals in a population, and the fitness (cost) function determines which solutions are more likely to survive through the course of generations. Usually, an initial population of randomly generated candidate solutions comprise the Parents are chosen taking into account the fitness value; they reproduce to generate the offspring and is repeated until a good solution is found or a number of generations is reached.
Several parameters have been identified to configure the proposed optimization method. Our aim is to determine which parameters influence the obtained fitness and to facilitate practitioners some rules to decide which parameters to tune as they influence results in a different manner:  X  Generations ( Gen ): number of generations to apply the evolutionary loop.  X  Population Size ( PS ): number of individuals in the population of candidate solutions.  X  Operators Combination ( Op ): This parameter refers to the percentage of offspring generated using
As can be seen, this algorithm needs some parameters to be given adequate values. In literature, analysis [31]. However, our interest focuses on testing the effectiveness of those values using robust mathematical methods.
 3.2. Methodology
Once the optimization algorithm under study has been presented and the configuration parameters have been determined, the different levels (values) for those parameters have to be set before ANOVA is applied.

The set of values for each parameter was chosen taking into account the common practices that can these parameters using ANOVA. In this case, 10800 runs were carried out for each problem (30 times *6levelsfor Gen *5levelsfor PS *4levelsfor Op *3levelsfor Sel , that represent the possible combinations) to obtain the fitness for each combination.

The application of ANOVA consisted in running the EA optimization method using those parameter combinations to obtain the best fitness. The response variable used to perform the statistical analysis is the fitness at the end of the run. The changes in the response variable are produced when a new combination of parameters is considered. Then, the R 1 tool was used to obtain the ANOVA tables as well as the tables of means and figures for each problem. Appendix I shows how to use R to analyze data to generate tables and figures related to the Ackley problem (as an example). Obtained ANOVA tables (Section 4) show for each factor, the degrees of freedom (FD), the experimental value of the statistical values of this parameter lead to significant differences on the fitness).
 other. In that sense, one of the most widely used post-hoc test is Tukey HSD test [12]. Tukey HSD is a versatile, easily calculated technique that might be used after ANOVA and allows to state exactly where the significant differences are. However, it can only be used when the ANOVA found a significant HSD test compares pairs of the factor values, showing a segment (confidence level) for each difference between means. Additionally, it shows a vertical dotted line (distance equals zero) that intersects some segment (those values compared are significantly different).

This section has described a methodology based on the use of powerful and well known statistical tools. This methodology is supplemented by the detailed statistical study carried out in Section 4 and with the script for using the tools shown in Appendix 1. 3.3. Function approximation problems
In order to evaluate the proposed metaheuristic and their parameters, four well known function ap-proximation problems are used: Griewangk [63], Rastrigin [64], Ackley [65,66] and Rana [67]. These problems are the more representative among those faced in our research.

Next, a detailed description of the four benchmark functions is given:  X  The Griewangk function [63] is a continuous multimodal function with a high number of local  X  The Rastrigin function [64] (see Eq. (2)) is a multimodal real function optimization problem, whose  X  The Ackley function [65,66] (see Eq. (3)) is a multimodal non separable and regular function usu- X  The Rana function [67] (see Eq. (5)) is a non-separable, highly multimodal function, whose global
In all cases, as the optimum is known, the fitness of an individual is calculated as the distance to the optimum for that function, and the goal is to obtain the smallest fitness for the optimized function. 4. Statistical study and obtained results
In this section, the ANOVA and Tukey HSD statistical tools are applied to determine whether the influence on parameter values (factors) is significant in the obtained fitness. ANOVA tables are shown, Table 2 shows the result of applying ANOVA on proposed approximation function problems using the EA. Parameters with a p-value under 0.05 are highlighted in boldface.

The ANOVA analysis shows that Gen and Sel parameters are significant, which indicates that changes results only in Ackley and Rana problems. According to the table, PS parameter is not significant in any of the considered problems. This fact shows how for each problem, different set of parameters can influence results in a different manner [69]. Once the significant p-values have been obtained, Tukey HSD test will help to determine which levels are significantly different.
 Figures 1 to 4 show where the significant differences for those parameters with significant p-value are. Figure 1 shows Tukey HSD multiple comparisons for Gen and Sel factors, and for Griewank function. nificantly different than using higher values (1280, 2560 and 5120). The second level shows significant than using higher values (2560 and 5120). The Sel parameter is shown at the right hand side; the graph shows that all the considered levels are significantly different.
 Figure 2 shows Tukey HSD multiple comparisons for Gen and Sel factors, and for Rastrigin function. As in previous problem (Griewank), there are significant differences between some pairs of values for function, all the considered levels are significantly different.

Figure 3 shows Tukey HSD multiple comparisons for Gen , Op and Sel factors, and for Ackley func-tion. Taking into account the Gen factor, significant differences have been found between first-fifth levels, and between first-sixth levels. Regarding Op parameter, significant differences have been found when comparing X8M2 -X , X8M2 -X9M1 and M -X . As in previous functions (Griewank and Rastrigin), all the considered levels of Sel parameter are significantly different.
 Figure 4 shows Tukey HSD multiple comparisons for Gen , Op and Sel factors, and for Rana function. Paying attention to Gen factor, significant differences have been found between low and high pairs of levels, as in previous functions. As far as the Op parameter is concerned, differences are shown between all pairs of values except X9M1 and M8M2 .Finally,regarding Sel parameter, while there are significant differences between Ra -Ru and Ra -To , no differences between To -Ru have been found.
To summarize, Tukey HSD confidence intervals show significant differences between some pairs of intervals corresponding to the difference of the means of extreme values). Operators combination ( Op ) is significant for Ackley and Rana functions; differences appear when comparing very high application rates of an operator (see Fig. 4). In general, there are clear differences between the tournament and roulette selectors regarding the random selector (confidence segments corresponding to Ra -To and Ra -Ru are far from the vertical line).

After the parameters with greater influence on the results have been determined, accurate parameter values should be established in order to obtain an optimal operation. To do so, tables of means and boxplots (also known as box and whisker diagrams [70]) are obtained to show the effect each level has on the approximation error (see Tables 3 to 6 and Figs 5 to 8).

Table 3 shows the approximation error each level causes on the fitness for Griewangk function. As expected, using high values for Gen leads to bets fitness. Changes on PS factor does not result in large is concerned, using the To level yields best results.
 on the previous problem (Griewank).

Table 5 shows error means for the Ackley function using different factor levels. As in previous prob-lems, increasing Gen yield best results. Taking into account PS parameter, better results are obtained using high levels. Paying attention to the Op parameter, using a high crossover application percentage results in best fitness. Regarding the selector ( Sel ), better results are obtained using To .
Table 6 shows obtained errors using different parameter levels for the Rana function. Regarding Gen , using Ro , although no clear differences regarding To have been found.

Figure 5 shows that increasing Gen leads to solutions closer to the optimum. Likewise, high popula-tion sizes scatter the points, arising extreme cases. The same effect can be seen in the case of the Op parameter. Boxplots in Fig. 6 related to the Rastrigin function show a similar pattern. function is small, thus limiting differences between groups of means (the boxes are narrow). According to ANOVA, only for some specific significant parameter values confidence intervals reach the optimum.
In Fig. 8, the Boxplots for Rana function related to the PS parameter are very similar (no signifi-high application rates the corresponding boxplot is narrow and far from the optimum. As far as the Sel operator is concerned, To and Ro boxes are very similar.

In short, paying attention to the operator combinations ( Op ), using either only mutation or only crossover leads to worse fitness results, which was expected. In general, according to the tables, us-ing a low mutation and high crossover probabilities to generate offspring in each generation yields best ity leads to premature convergence of the population. On the other hand, applying too much mutation affects exploration, leading to random search.

PS has not been reported as significant according to the ANOVA table (Table 2). In general, it is expected to obtain better results when using bigger populations (the bigger the population, the bigger the diversity). However, as tables show, mean across the whole set of experiments, using big population leads to many non-feasible individuals and thus to worse values in average.

Gen has been reported as significant, due to the fact that hard problems need an extra number of a greater diversity of individuals.
Taking into account the Sel parameter, using either Ro or To selectors yields much better results than using a Ra selector. This was expected, due to the fact that a random selection could lead to offspring descending from non-feasible individuals (far from the optimum). Moreover, best individuals are more likely to be selected using Ro to generate offspring, while using To leads to a more diverse population.
Along this discussion, it can be seen that these results are in agreement with those available in bibli-ography [2,30,61,62,71,72]. Moreover, obtained results might help practitioners in adjusting parameters parameters on the fitness through a rigorous statistical study. 5. Conclusions and work in progress Finding appropriate algorithm parameter values is important due to their effect on the results.
This paper proposes a methodology to analyze the parameters with a higher influence on the perfor-mance for a given optimization method. Our approach has been tested using an evolutionary algorithm, a widespread optimization method successfully used by practitioners in many areas. We also report ap-propriate values (among those tested) for these parameters in order to obtain an optimal operation (see Section 4).

A statistical study of the different parameters involved in the design of this optimization method has been carried out by applying ANOVA, which consists of a set of statistical techniques that analyze and the system, and completed with a Tukey HSD test. The motivation of the present statistical study lies in method.

The proposed methodology has been applied to four well-known function approximation problems (Griewangk, Rastrigin, Ackley and Rana), widely used by practitioners, in order to determine which parameters have a higher influence on results (a change on those parameters will affect the algorithm performance).

In that context, results show that accurate results are obtained using the higher value tested for the number of generations parameter ( Gen ), although this increases the number of evaluations and time between small values regarding higher ones. ANOVA has not reported PS as significant parameter. It is (average values across the whole population) show, big populations lead to worse results in average, as many infeasible individuals can be found in a big population. Paying attention to the selector operator leads to premature convergence of the population, while applying too much mutation is like a random search. According to the tables, in general, using a low mutation and high crossover probabilities to generate offspring in each generation is the best option. However, some operators are not suitable for some problems, as in the Rana function, where the crossover operator leads to individuals close to zero although the optimum is located far from that point.

As can be seen, different algorithms or configurations might work better on a problem and worse on another one. This is in agreement with the No Free Lunch theorem [69], according to which there is no algorithm better than all to solve all the problems.

This methodology based on ANOVA and Tukey HSD stati stical tests could be helpful for practitioners in analyzing and adjusting parameters of any optimization method. Moreover, if any of the parameter values tested are not suitable, the statistical analysis will show it and researcher could take actions.
Our work in progress includes the analysis of different optimization methods, such as modified EAs considering several selection schemes, new genetic operators and other meta-heuristics (tabu search, EDAs, UMDA, etc). As future work, the implementation of a parameter control method would be of interest, as proposed by Eiben et al. [20]. In this case, ANOVA could be used to analyze not only the optimization method parameters but also the control strategy parameters.
 under GNU public license.
 Acknowledgements This work has been supported in part by the UGR PR-PP2011-5 project, the Junta de Andaluc X a SIPEsCa (G-GI3000/IDIF) and P08-TIC-03903 projects and the TIN2011-28627-C04-02 project. The authors are very grateful to the anonymous referees whose comments and suggestions have contributed to improve this paper.
 References Appendix 1
This appendix shows an exhaustive review of commands to R used to analyze data obtained after the runs and to obtain tables and figures shown in Section 4. As an example, those commands corresponding to the Ackley function are shown:  X  problemData &lt; -Ackley  X  problemName &lt; - X  X ckley X   X  pathMeans &lt; - X /home/user/EA/R/Medias X   X  pathTukeyHSD &lt; - X /home/user/EA/R/Tukey X   X  pathBoxPlot &lt; - X /home/user/EA/R/BoxPlot X   X  extension &lt; - X .eps X   X  dirTukeyHSD &lt; -paste(pathTukeyHSD,problemName,sep =  X  X )  X  dirMeans &lt; -paste(pathMeans,problemName,sep =  X  X )  X  dirBox &lt; -paste(pathBoxPlot,problemName,sep =  X  X )  X  dirTukeyHSD &lt; -paste(dirTukeyHSD,extension,sep =  X  X )  X  dirMeans &lt; -paste(dirMeans,extension,sep =  X  X )  X  dirBox &lt; -paste(dirBox,extension,sep =  X  X )  X  problemData$Gen &lt; -as.factor(problemData$Gen)  X  problemData$PS &lt; -as.factor(problemData$PS)  X  problemData$Op &lt; -factor(problemData$Op, labels=c( X  X  X , X  X  X , X  X 8M2 X , X  X 9M1 X ))  X  problemData$Sel &lt; -factor(problemData$Sel, labels=c( X  X u X , X  X a X , X  X o X ))  X  shapiro.test(problemData$Fitness)  X  levene.test(problemData$Fitness, problemData$Gen)  X  levene.test(problemData$Fitness, problemData$PS)  X  levene.test(problemData$Fitness, problemData$Op)  X  levene.test(problemData$Fitness, problemData$Sel)  X  summary(anovaGen &lt; -(aov(Fitness-Gen, data=problemData)))  X  summary(anovaPS &lt; -(aov(Fitness-PS, data=problemData)))  X  summary(anovaOp &lt; -(aov(Fitness-Op, data=problemData)))  X  summary(anovaSel &lt; -(aov(Fitness-Sel, data=problemData)))  X  tapply(problemData$Fitness, list(problemData$Gen), mean)  X  tapply(problemData$Fitness, list(problemData$PS), mean)  X  tapply(problemData$Fitness, list(problemData$Op), mean)  X  tapply(problemData$Fitness, list(problemData$Sel), mean)  X  layout(matrix(1:4,1,4))  X  plot(Tukey HSD(anovaGen,  X  X en X ))  X  plot(Tukey HSD(anovaPS,  X  X S X ))  X  plot(Tukey HSD(anovaOp,  X  X p X ))  X  plot(Tukey HSD(anovaSel,  X  X el X ))  X  dev.copy2eps(file=dirTukeyHSD, width=12.0, height=12.0, pointsize=12)  X  layout(matrix(1:4,1,4))  X  boxplot(Fitness-Gen, ylab= X  X itness X , xlab= X  X enerations X , data=problemData)  X  boxplot(Fitness-PS, ylab= X  X itness X , xlab= X  X opulation Size X , data=problemData)  X  boxplot(Fitness-Op, ylab= X  X itness X , xlab= X  X perators X , data=problemData)  X  boxplot(Fitness-Sel, ylab= X  X itness X , xlab= X  X elector X , data=problemData)
