 Query expansion for Information Retrieval is a challenging task. On the one hand, low quality expansion may hurt ei-ther recall, due to vocabulary mismatch, or precision, due to topic drift, and therefore reduce user satisfaction. On the other hand, utilizing a large number of expansion terms for a query may easily lead to resource consumption overhead. As web search engines apply strict constraints on response time, it is essential to estimate the impact of each expansion term on query performance at the pre-retrieval time. Our experimental results confirm that a significant part of expan-sions do not improve query performance, and it is possible to detect such expansions at the pre-retrieval time.
Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Query formulation General Terms: Algorithms, Performance
Keywords: Query expansion, Query performance predic-tion
Search engines aim to find documents to satisfy a user X  X  information need, which is expressed in a query. In most cases, there is more then one possible way to express the same need, and so some relevant documents may easily miss one or more query terms. This is a well-known problem, especially crucial for web search, since the average length of a query submitted to search engine is  X  2.4 terms [2]. Query expansion has always been a traditional way to tackle this problem. Query expansion is a challenging task as several different metrics of the quality of expansion terms have to be taken into account. We would naturally like to add as many highly related terms (e.g. synonyms) as possible to the query in order to overcome the vocabulary mismatch. However, such query rewriting needs to be done by maximizing not only the relatedness of the expansion terms to the query, but also by ultimately maximizing the actual task-specific objective  X  the modified query X  X  performance. At the same time, such optimization needs to respect the requirements to query response time faced by most popular web search engines, what means adding only expansion terms leading to the maximum increase in the result set quality and utilizing only pre-retrieval query performance predictors to estimate the potential increase.

The goal of the current study is to predict the difference between the performance of an expanded query and the orig-inal one in the web search setting. In contrast to the existing works, we do not use any post-retrieval features calculated at a query time. In order to handle the constraints mentioned above, our model combines three types of evidences: (1) the query-independent quality of the expansion term being ap-plied, (2) the similarity between the expanded query and the original one, and (3) the estimation of the performance of the original and an expanded query. For (3) we utilize pre-retrieval characteristics of a query and aggregate some post-retrieval information using the history of the previous issues of the query from the query log.
In general, any expansion method can be considered as a two stage process: candidate mining and expansion se-lection. Candidate mining methods can be roughly divided into two classes  X  local and global techniques. Methods of the first class (e.g. the well-known pseudo-relevance feedback method [12, 3]) involve two stage retrieval. Terms used to expand the initial query are extracted from the top-k doc-uments returned by the search engine in response to that query. While this method shows strong results for ad-hoc text retrieval, its employment in modern web search engines is computationally infeasible and leading to a significant de-lay to query processing due to the requirement of an extra search against a document corpus.

Global techniques are usually less resource demanding as they rely on more efficient data structures than document indexes (for the detailed explanation see, for example, [5]). They compute evidences of term associations using various collections beforehand [6, 14, 5, 8]. In [6] query term to doc-ument term associations are derived from a bipartite query-document graph. In [14] a query log is used to find terms occurring in similar contexts and in successive queries in user search sessions. In [5] phrase and query rewritings are acquired by means of a random walk over a bipartite anchor text-URL graph. In our work candidates are assumed to be acquired from an independent candidate mining method, while we concentrate on the expansion selection stage.
During the last few years direct optimization of a retrieval metric for query expansion has been proposed a few times. In [4] a classifier was trained on a set of term collocation features to distinguish pseudo-relevance feedback expansions that increase the retrieval performance metric (MAP) from useless or harmful expansion terms. Its combination with PRF-based method led to a significant improvement over their baseline. A post-retrieval method to predict the perfor-mance of query expansion terms extracted from ConceptNet is suggested in [10]. While both works demonstrate statis-tically significant improvements over their PRF-based base-lines, they are focused on ad-hoc retrieval on small-scale text collections, and therefore extensively use post-retrieval fea-tures, while ignoring the information that could be extracted from query logs. In [1] a related task of query reduction was under consideration. They try to remove one term from a given query at a time and to predict an altered query per-formance in comparison with the original one relying largely on post-retrieval query performance predictors. Unlike this work, our model focuses on query expansion, does not use post-retrieval features and incorporates semantic informa-tion about the expansion term and the query.

In contrast to the existing approaches, we aim to provide an automatic query expansion solution more suitable for the web search environment. Our model learns to predict the impact of an expansion term by utilizing only features avail-able at the pre-retrieval stage and by extensively relying on interaction-based features extracted from our query logs. Similar features for the task of query performance prediction were first introduced by in [9], and then further extended in [11], but they were never used either for improving query expansion methods, or for predicting the difference in per-formance between two queries instead of predicting a single query X  X  performance.
The expansion pair p = ( orig,exp ) can be applied to the query q if a sequence of terms orig is a subsequence of terms in the query q ; in this case, a search engine can combine the terms of q and the terms of exp to build a new query, which we will refer to as Comb ( q,p ). The phrase orig is the orig-inal part of the expansion pair p , and the phrase exp is the expansion part of the expansion pair p . In order to apply multiple expansions, we can use a set of expansion pairs in-stead of a single pair p . We consider that function Comb implements some kind of weak or operator, i.e. it uses ex-pansion terms with a different weight in comparison with the terms of the original query, similar to #wsyn operator in the Indri query language 1 . So, we focus on extending a query with synonyms in this paper. A set of possible expansions is finite, let E ( q ) = { p 1 ,...,p k } be a set of expansion pairs that can be applied to the query q . So, if we have the query fueling station then we can imagine that after applying 3 expansion pairs (fueling, filling) , (fueling, gas) , (fueling sta-tion, garage) we will have the query ((fueling WEAK OR filling WEAK OR gas) station) WEAK OR garage) X . We assume that there is a ranking algorithm R ( q ) and a target retrieval metric F ( R ( q )). We treat the former as a black box, while metric F can be chosen arbitrary. As ranking algorithm is fixed, we will write F ( q ) rather than F ( R ( q )) for the sake of conciseness and simplicity.
Our goal is to select some subset E  X  ( q ) of possible expan-sion pairs E ( q ) to maximize the target metric, i.e. E  X  arg max This problem requires exhaustive search over the set of pos-sible expansion pairs, to avoid it we make a naive assumption of independence between every pair of expansions. In other words, we assume that  X F ( q,E 0 ) = P F ( q ) . Thus, we are eventually interested in the prediction of the difference in the metric value between the query with a single expansion and the non-expanded one, and that is the primary task we address in this paper.
Although the difference  X F can be predicted in a straight-forward way (i.e. we can predict performance for the ex-panded query and for the original one and take the difference between them), such approach is not optimal and we directly approximate  X F . To estimate impact of the expansion term on the query performance we extract various pre-retrieval features about original query, expanded query and semantic similarity between terms in the expansion pair itself.
Queries with high retrieval quality are unlikely to benefit from the additional query expansion, thus we would like to estimate the performance of the original query q in advance. At the same time one can measure the quality of the expan-sions in terms of the performance of the rewritten query q that is the query obtained from q by replacing the original term with the expanded one. We replace the original term rather than complement it with its synonym in this case, since users never use WEAK OR operators themselves and hence we would not be able to find such queries in the logs.
Following [9] and [11] we extract pre-retrieval features from the query log (see Table 1). Query log contains all user X  X  queries and their behavior on the search engine result page (SERP). The queries of each user are organized into search sessions  X  series of queries issued with the same in-formation need. These features comprise the data derived from the user X  X  behavior on the result page of a query q and on the result pages of other queries co-occurring in the same search sessions with q . User interaction features are known to be among the most important for the problem of query performance prediction (see [9]) and employment of search sessions allows to construct more reliable features for rare queries with only a few occurrences in the log. For unseen queries user interaction data is useless, therefore we supplement the described set of features with simple ones like query likelihood and word count that are available for all queries. All these features are calculated for the original query q and the rewritten query q 0 .
Frequency based features are the simplest category of fea-tures concerned with expansion quality (2.1 -2.6). Such features may help to distinguish a correct spelling from mis-spellings, or a good abbreviation expansion from a noisy one (e.g. ssd may be expanded as either solid state drive or shoe scan device ; and while both expansions are correct, the latter should be used with care).
We utilize two source corpora, i.e. a web document corpus and a list of queries issued by users. For each word n-gram in the web corpus we calculate two numbers, namely, its collection frequency and its host frequency. The latter is the number of different hosts containing the n-gram. Addi-tionally for each n-gram we calculate query log occurrence frequency. Using morphological normalization and simple back-off language model, we estimate host, collection, and query frequencies for the original part and the expansion part of the expansion pair (2.1, 2.2, 2.3). In order to avoid morphological normalization artifacts, we also included a separate group of features (2.4, 2.5, 2.6), that correspond to exact matching against the n-gram frequencies corpora. We calculate frequency features for both parts of each expansion pair independently.

Next class of features may be referred to as phrase shape based features (2.7 -2.15). They do not require any external data, and express knowledge that can be derived from the spelling of an expansion pair. E.g. one can claim that pair gold  X  guy of local dive looks like acronym without any external knowledge.

And the last set of features aims to capture semantic dis-tance between the original term and its expansion (2.15  X  2.20). Features 2.18 express a simple idea: if a user is un-satisfied with SERP, she tries to reformulate the query to achieve a better result, therefore the expansion parts of a good expansion pair often occur in subsequent queries. On the contrary, users tend to write shorter queries, therefore terms with a similar meaning rarely co-occur in the same query. This is expressed by feature 2.20. The 2.15 feature is based on the assumption that for similar queries users click on similar results. Therefore we can align pairs of queries that have clicks on the same URL, and match parts of an expansion pair against such aligned query pairs. A similar approach is used in feature 2.16, except it aligns queries with clicked document titles rather than with other queries. Fea-ture 2.17 measures the context similarity between expansion pair parts using the query log. For a phrase and a query con-taining this phrase, we can extract the left context (a part of the query that precedes the phrase) and the right context (a part of the query that follows the phrase). As the number of expansions and queries is finite, we are able to enumerate all possible contexts. In doing so we can build a couple of context vectors for the original and the expansion parts of any expansion pair, where the i th component is equal to the number of occurrences of the given phrase in the i text. To compute the similarity between these vectors we measure the cosine between them. Finally, we implemented a random walk over the anchor text-URL bipartite graph; and used the probability to reach any node containing the expansion part of the pair from the nodes containing the original part of the pair after a two-step random walk as feature 2.19.
To conduct experiments we had to extract a reasonable set of candidates for expansion pairs. Since a study of can-didate mining techniques is out of the scope of our study, we simply have taken synonym dictionaries and Wikipedia redirects to generate suitable expansion candidates. This resulted into 500K candidates. Then we randomly sampled unique 35K queries from a Yandex search engine query log. For each query we applied one expansion at a time (out of up to 5 candidates). Using relevance judgements for documents retrieved by the search engine, we obtained a training set of 133K triples (query, expansion, value), where the value we try to predict is  X DCG @10 i.e. the difference between the score for documents being retrieved for the query without any expansions and for the query with the expansion. There are 30 labeled documents per query on average. All the met-Figure 1: Dependence of the performance on the portion of applied expansions.  X  = 0 0.1 0.2 0.3 0.4 0.5 F 1 20.3% 19.7% 18.4% 18.3% 16.7% 17.3% Prec 41.4% 38.9% 39.5% 32.7% 36.8% 32.2% Rec 27.2% 26.2% 25.1% 23.5% 23.0% 22.5% Table 2: Binary classification after discretization at  X  . rics are induced , so, applied to condensed document rankings consisting only of labeled documents, following [13].
We found out that in 84% of cases the expansion does not change the original query performance at all. This is not surprising, since most candidate synonyms are unrelated to the context of the query and that is likely to result into low document relevance scores for the variants of the query with the synonyms instead of the original terms (that is due to the specifics of the WEAK OR parameter, which basically sums scores for all variants of the query w.r.t. the document).
We use a proprietary implementation of Friedman X  X  gradi-ent boosted decision tree-based machine learning algorithm [7] and perform 3-fold cross-validation.

We ordered all the expansions according to the predicted value and measured performance on the top N % of expan-sions. The resulting function is represented on Figure 1. The X-axis corresponds to the N  X  the portion of query-expansion pairs with the highest predicted delta under con-sideration. The Y-axis is the average value of the actual performance delta over the whole query set. It is easy to see from the figure that (1) the average performance of ex-pansions at any portion is above zero, thus our initial can-didates from dictionaries and Wikipedia redirects are quite good, (2) we can filter out up to 80% of triples without any loss of quality.

In order to get a numerical value of the predictor quality, we perform a discretization of the original  X DCG @10 and report F 1 -measure, recall and precision of the corresponding classifiers. Namely, we set parameter  X  and consider triples with the  X DCG @10 &gt;  X  as the positive samples and triples with  X DCG @10  X   X  as the negative ones . Our major aim is to distinguish beneficial expansions from others, thus we run classifiers on the set of our features for several values of  X  . The performances of these classifiers are reported in Table 2. Since for all  X  negative class is dominating (it contains all zero samples), F 1 -measure is quite low, and it is rather dif-ficult to filter out exactly negative samples. However, as we can see from Figure 1 we still can filter out large portion of triples with near zero  X DCG @10.
 Original query performance 0 . 79%  X   X  15 . 05% Rewritten query performance 0 . 77%  X   X  16 . 91%  X  Table 3: The change of MSE and Pearson correla-tion coefficient, when a specific type of features is disabled. * stands for 95% statistical significance.
To measure importance of various types of features we per-formed feature ablation, i.e. we learned the same model on 4 sets of features: all, without features about original query performance, without features about rewritten query perfor-mance, without features about expansion pair quality. The degradation of mean square error and Pearson correlation vs. model learned on all features are reported in Table 3. Interestingly, all types of features turned out be almost to equally significant for the quality of the predictor.
In this paper we proposed a method for automatic predic-tion of the impact of the expansion on the performance of the given query. Our experiments show that the predicted value allows to filter out effectively useless expansion pairs reduc-ing the load of the search engine and improving the quality on the expanded queries. However effective screening of neu-tral expansions with zero profit is still quite challenging and is left for a future work.
