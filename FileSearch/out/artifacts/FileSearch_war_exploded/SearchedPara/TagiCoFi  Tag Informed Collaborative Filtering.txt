 Besides the rating information, an increasing number of mod-ern recommender systems also allow the users to add per-sonalized tags to the items. Such tagging information may provide very useful information for item recommendation, because the users X  interests in items can be implicitly re-flected by the tags that they often use. Although some content-based recommender systems have made preliminary attempts recently to utilize tagging information to improve the recommendation performance, few recommender systems based on collaborative filtering (CF) have employed tagging information to help the item recommendation procedure. In this paper, we propose a novel framework, called tag i nformed co llaborative fi ltering (TagiCoFi), to seamlessly in-tegrate tagging information into the CF procedure. Experi-mental results demonstrate that TagiCoFi outperforms its counterpart which discards the tagging information even when it is available, and achieves state-of-the-art perfor-mance.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering ; H.2 [ Database Management ]: Database Application X  Data Mining Algorithms Collaborative filtering, recommender systems, tag
Since the amount of information on the Web is increasing at an astonishing rate that is much faster than our ability to process it, recommendation plays a more and more im-portant role for us to make effective use of the information available. Some representative examples include product recommendation in Amazon.com [14], movie recommenda-tion in Netflix [3] and MovieLens 1 [16], reference recommen-dation in CiteULike 2 , and bookmark recommendation in Del.icio.us 3 . Existing recommender systems can be roughly divided into two major categories [1]. Content-based sys-tems [2, 12, 15] make use of profiles of the users or products to characterize their nature. On the other hand, systems based on collaborative filtering (CF) [4, 9, 16, 17, 19] do not exploit explicit user profiles but only past activities of the users, such as their transaction history or product satisfac-tion expressed in ratings, to predict the future activities of the users. In recent years, CF-based systems have become more and more popular than content-based systems because it is much easier to collect the past activities of users than their profiles due to privacy considerations.

In recent years, besides the ratings on the items given by the users, an increasing number of modern recommender systems also allow the users to add personalized tags 4 , in the form of words or phrases, to the items. For example, users may add tags to movies in MovieLens, to web sites in Del.icio.us and to references in CiteULike. Such tagging in-formation may provide very useful information for item rec-ommendation, because the users X  interests in items can be implicitly reflected by the tags that they often use [21]. For example, if two users often use the tags  X  X scar X  and  X  X om Hanks X , both of them may like the movie  X  X orrest Gump X . In fact, the effectiveness of tags in representing users X  prefer-ence or interests has been validated by Zanardi et al. in the CiteULike dataset [27]. Very recently, some content-based systems , such as those in [6, 22, 23], have made some pre-liminary attempts to utilize tagging information to improve the recommendation performance. However, there has been little work on improving CF-based systems with the help of tagging information. Because CF-based systems have be-come more popular than content-based systems, it would be a very worthwhile endeavor to devise novel CF techniques which can also utilize tagging information for item recom-mendation.

Existing CF methods can be divided into two main cat-http://movielens.umn.edu/ http://www.citeulike.org/ http://delicious.com/
It should be emphasized that the setting in this paper is different from those about tag recommendation [7, 24] in which the recommended objects are tags. The recommended objects in this paper are called items, whereas tags are other objects about the items added by users. egories [10]. Memory-based methods, such as [9, 19], try to predict new ratings by (weighted) averaging the ratings of similar users or items. On the other hand, model-based methods, such as probabilistic matrix factorization (PMF) [17], try to learn a model from data using statistical learning tech-niques. To the best of our knowledge, there exists only one CF method [25] which attempts to utilize tagging informa-tion to improve item recommendation. This method is a memory-based one. The experimental results in [25] show that little improvement could be achieved on item recom-mendation by integrating tagging information into the CF procedure under the memory-based framework.

In this paper, we propose a novel framework, called tag i nformed co llaborative fi ltering (TagiCoFi), to seamlessly in-tegrate tagging information into the model-based CF proce-dure. More specifically, we use tagging information to regu-larize the matrix factorization (MF) procedure of PMF [17] which has been demonstrated to be one of the state-of-the-art CF methods. Some promising properties of TagiCoFi are highlighted here:
The rest of this paper is organized as follows. In Section 2, we will introduce the notations and some preliminaries. Sec-tion 3 describes the details of our model. Experimental re-sults are presented in Section 4 and, finally, we conclude the paper in Section 5.
In this section, we first introduce some notations used in this paper. We then briefly review PMF [17] which is closely related to our work.
We use boldface uppercase letters, such as A , to denote matrices, and boldface lowercase letters, such as b , to denote vectors. The i th row and the j th column of a matrix A are denoted as A i  X  and A  X  j , respectively. The ( i, j )th element of A is denoted as A ij and the i th element of b as b i .
Suppose there are N users, M items and K tags. Let R be the rating matrix in which R ij represents the rating of user i for item j . The matrix R is sparse because many elements are missing, and each such element R ij is assigned the value of 0 to indicate that item j has not been rated by user i . Y is the indicator matrix where Y ij is an indicator variable which is equal to 1 if user i rated item j and 0 otherwise. MF-based methods [17] seek to find two low-rank matrices U  X  R D  X  N and V  X  R D  X  M , where typically D N, M , and use  X  R = U T V to approximate the rating matrix R . The column vectors U  X  i and V  X  j represent the user-specific and item-specific latent feature vectors, respectively.
Let Z be the tagging matrix, and each of its elements Z ik is the tf*idf value of user i and tag k [18, 23]: where tf( i, k ) is the normalized frequency of tag k appeared in user i  X  X  tagging history and df( k ) is the number of users who have used tag k .
PMF [17] seeks to derive the aforementioned low-rank ma-trices U and V by analyzing the rating matrix R in a prob-abilistic framework. The likelihood of the observed ratings R is defined as follows: p ( R | U , V ,  X  2 ) = where N ( x |  X ,  X  2 ) denotes the (univariate) Gaussian distri-bution with mean  X  and variance  X  2 .

Putting zero-mean spherical Gaussian priors on the user-specific and item-specific feature vectors: we can obtain the maximum a posteriori (MAP) estimates of U and V by minimizing the following objective function defined based on the sum of squared errors: where  X  U =  X  2 / X  2 U and  X  V =  X  2 / X  2 V .
Because PMF [17] has achieved state-of-the-art perfor-mance for CF tasks, we use it as the base model to make further enhancement by integrating tagging information in a principled way. The result is our tag i nformed co llaborative fi ltering method, which will be abbreviated as TagiCoFi in the sequel. The key idea of TagiCoFi is to use tagging in-formation to regularize the MF procedure of PMF. More specifically, we seek to make two user-specific latent feature vectors as similar as possible if the two users have similar tagging history.

In the rest of this section, we first introduce some met-rics for characterizing the similarity between users based on tagging information. We then propose our TagiCoFi model based on the computed user similarities.
We introduce several possible measures for characterizing user similarities based on the tagging matrix Z . Here, T denotes the index set of tags which are used by both user i and user j . The cosine similarity is defined as follows:
The Pearson correlation coefficient between two users is defined as follows:  X  1 ( i, j ) = defined as:
The Euclidean distance between two users is defined as follows: The Euclidean-based similarity is then defined as: where  X  is a user-controlled parameter. Like in PMF [17], we adopt a similar MF procedure to find U and V by minimizing the following criterion function: 1 2
X where  X  is a regularization parameter for complexity control.
Furthermore, TagiCoFi employs the user similarities de-fined based on the tagging information to regularize the MF procedure, with the goal to make the user-specific latent fea-ture vectors as similar as possible if the corresponding users have similar tagging history. We can achieve this goal by minimizing the following criterion function: where S ij is the tag-based similarity between user i and user j computed based on one of the measures defined in Section 3.1, L = D  X  S is known as the Laplacian matrix [5] with D being a diagonal matrix whose diagonal elements D ii = P j S ij , and tr(  X  ) denotes the trace of a matrix. To integrate tagging information into the CF procedure, TagiCoFi combines the criteria (9) and (10) to give the fol-lowing objective function for minimization: where  X  is an additional regularization parameter to control the contribution from the tagging information.

The formulation in (11) can be seen as an adaptation of relation regularized matrix factorization (RRMF) [13] which models relational data containing both relation information and content information. The main difference between Tagi-CoFi and RRMF is that TagiCoFi can handle missing data, which is one of the key characteristics of CF.
The objective function in (11) can be rewritten as follows: where I is the identity matrix. We use an alternating gra-dient descent procedure to optimize (12). More specifically, each time we fix one variable ( U or V ) and minimize the objective function with respect to the other one ( V or U ). This procedure is repeated for several iterations until some termination condition is satisfied.

To learn U , we first rewrite (12) as follows: where C is a constant independent of U , and
From (14), we can see that the rows of U in h are decou-pled. Hence, we apply gradient descent to optimize one row of U at a time with the other rows fixed.

Because we have where W is an N  X  N diagonal matrix with W ii = P M j =1 Y and x is an N  X  1 vector with x i = P M j =1 Y ij V dj ( R U
Then, we can get
The learning process of V is different from that of U , because the columns (not rows) of V are decoupled. Hence, we apply gradient descent to optimize one column of V at a time with the other columns fixed. The gradient can be computed as follows:  X  X 
The overall learning procedure of TagiCoFi is summarized in Algorithm 1 below.
 Algorithm 1 Learning procedure of TagiCoFi 1: INPUT: 2: Compute user similarity matrix S based on Z 3: Compute Laplacian matrix L based on S 4: Initialize U 0 , V 0 5: for w = 1 to W do 6: for d = 1 to D do 8: end for 9: for j = 1 to M do 11: end for 12: end for 13: return U W , V W
The main computation of TagiCoFi is to evaluate the gra-dients of the objective function with respect to the latent variables and to compute the user similarities. The time complexity of computing the gradient  X  X   X  U ing the user similarities and L is O ( N 2 K ). Hence, the time complexity of the entire alternating gradient descent proce-dure is O ( W ( N 2 D + N M D ) + N 2 K ).
We have conducted several experiments to compare the performance of our method with that of other methods. Through the experiments, we have tried to answer the fol-lowing questions: 1. How does TagiCoFi perform in real applications when 2. How effective are the different user similarity mea-3. How does tagging information improve collaborative 4. How does the number of latent features used affect the 5. Does TagiCoFi work for users without any training These questions are answered separately: question 1 in Section 4.3, questions 2 X 4 in Section 4.4 as three different subsubsections, and question 5 in Section 4.5.
We evaluate our algorithm on the MovieLens dataset 5 , which, as far as we know, is the only publicly available dataset containing both tagging and rating information.
We first prune the dataset for our analysis. For the tag-ging information, we only keep those tags which are added on at least three distinct movies. As for the users, we only keep those users who used at least 3 distinct tags in their tagging history. For movies, we only keep those movies that are annotated by at least 3 distinct tags. It should be em-phasized that our model still works under situations where there are users or movies with rating information only but no tagging information. For those users without any tag-ging information, the tag-based similarities between them and the other users are 0, which means that the last term in (11) will have no effect on those users. Subsequently, the recommendation result for those users without tagging in-formation only depends on the MF procedure of the rating matrix, which is similar to the result of PMF. As the focus of this paper is on evaluating the effectiveness of tagging information in addition to rating information, we only keep the users who have both rating history and tagging history in the original rating records.

We obtain two kinds of records after pruning, the tag-ging records and the rating records. The tagging records in-clude 13,431 tagging applications 6 contributed by 757 users with 2,271 distinct tags. Based on the tagging records, we construct the tagging matrix Z , whose elements are defined by Equation (1) in Section 2.1. The rating records include 167,474 ratings rated by 757 users (the same as those in the tagging records) on 9,485 movies, and based on these rating records we construct the rating matrix R . More statistics about the rating matrix R are shown in Table 1, where the numbers behind  X  denote the standard deviations. http://www.grouplens.org/node/73
If user i adds tag k on item j , we say this is a tagging application.
For consistency with experiments reported in the litera-ture, we use the Mean Absolute Error (MAE) as evaluation metric. MAE gives the average absolute deviation of predic-tion from the ground truth: where R ij and  X  R ij are the true and predicted rating values, respectively. A smaller value of MAE indicates a better performance.

In our experiments, we randomly split the rating records into two parts, each of which contains 50% of the observa-tions in the rating matrix. One part is used as the test set, which is kept the same for all experiments. The other part is used as a pool from which training sets are generated. For example, a training set size of 20% means that 20% of the records are randomly selected from the pool to form a train-ing set. For each training set size, we randomly generate 10 different training sets based on which 10 experiments are performed and the average result is reported.
In this section, we compare our method with PMF which has been demonstrated to be one of the state-of-the-art CF methods [17]. For fairness, we perform parameter tuning in advance for each method and then use the best settings found in all the experiments. For both methods, we initial-ize the latent features to random numbers in [0 , 1] and set the step size for gradient descent to 0 . 001. The parame-ters specific to our method are set as  X  = 1 and  X  = 50. Actually, we find that the performance will be stable af-ter about 1000 rounds of gradient decent (see Figure 3). Hence, we set W = 1000 for all the following results. Fur-thermore, we adopt the Pearson similarity for all the experi-ments. The performance of other measures will be discussed in Section 4.4.1.

The results reported in Table 2 are the average MAE val-ues of PMF and TagiCoFi and their corresponding standard deviations. The better results are shown in bold. It iss clear that TagiCoFi achieves better performance than PMF.
To evaluate how significant TagiCoFi outperforms PMF, we have conducted paired t-tests [26] on the results of PMF and TagiCoFi. Given two approaches, say A and B, and a set of n experiments, the MAE values are obtained for both approaches, denoted by a i and b i for i = 1 , 2 , . . . , n . Let d i = a i  X  b i denote the difference of a i and b i and hypothesis is  X  d = 0 whereas the alternative hypothesis is  X  d &gt; 0. The p-value is computed using the t-statistic: where s is the standard deviation of d . A small p-value (  X  0 . 01) indicates the existence of statistically significant evidence against the null hypothesis.
 Table 3 shows the p-values obtained in our experiments. It is easily observed that TagiCoFi significantly outperforms PMF. Because the main difference between TagiCoFi and PMF lies in the extra tagging information used by TagiCoFi, we can conclude that the tagging information is very useful and TagiCoFi can utilize it very effectively.

In order to compare TagiCoFi with PMF more thoroughly, we compare their performance on users with different num-bers of observed ratings. The results are shown in Figure 1, from which we can find that TagiCoFi outperforms PMF for all users and the improvement is more significant for users with only few observed ratings. This is a very promising property of TagiCoFi because those users with a small num-ber of ratings are typically new customers who have just started to use the system. If we can provide good recom-mendation to them, we will have a higher chance to keep them as our long-term customers. Otherwise we will likely lose them. Figure 1: Performance improvement of TagiCoFi over that of PMF on different user rating scales (no users in a 20% training set have more than 320 ob-served ratings)
In this section, we conduct a set of experiments to compare the effectiveness of the aforementioned user similarity mea-sures: cosine similarity, Pearson similarity and Euclidean-based similarity. Due to the page limit restriction, we only report results with parameters  X  = 1 ,  X  = 50 , D = 10 in Fig-ure 2. We have also observed the same trend in other param-eter settings. From Figure 2, we see that the Pearson simi-larity always gives the best performance and the Euclidean-based similarity is always the worst. Although the difference between these measures is obvious, Figure 2 shows that the difference decreases as the training set size increases. One may ask if changing the  X  parameter in the Euclidean-based similarity measure will help. We have tuned the parameter by trying different values but cannot make it outperform the other similarity measures. Based on this analysis, we adopt Training Set Size the Pearson similarity as our similarity measure in all other experiments.
As we saw in Section 3, the contribution of tagging in-formation is controlled by the parameter  X  . If  X  = 0, we do not use tagging information at all and hence our method degenerates to a special form of PMF; as  X  increases, we put larger weight on the tagging information. To evaluate the impact of tagging information on collaborative filtering, we carry out a set of experiments by varying the value of  X  . The MAE curves for different  X  values on 20% training sets are plotted in Figure 3. The other parameters are set as  X  = 1 and D = 10.

As we can see from Figure 3, adopting a larger  X  value can help to avoid the overfitting problem suffered by most MF-based CF methods [17]. When  X   X  1, the overfitting problem is apparent. If we set  X   X  10, we do not experience overfitting any more. This phenomenon clearly validates the impact of tagging information, that is, adding more tagging information can improve the generalization ability of the model. Moreover, Figure 3 also shows that the performance might degrade when  X  is too large. So in practice, we should choose a moderate value of  X  . Actually, our method is not sensitive to  X  within a wide range, such as 10  X   X   X  50.
Another important parameter in our method is the num-ber of latent features D . In this section, we conduct a set of experiments on 20% training sets to study how D affects the performance of our model. We use the following parameters:  X  = 1 ,  X  = 50. The MAE values and their standard devia-tions are plotted in Figure 4. We also show the percentage decrease in MAE with respect to that for 10 latent features at the points 20, 30, 40 and 50.

Figure 4 shows that the MAE decreases as the number of latent features increases. This agrees with our assumption, because the more latent features, the more information can be represented by the latent feature vectors. The figure also shows that the improvement in MAE gets smaller as D continues to increase. When D becomes large enough, there is essentially no significant improvement because the useful information has already been represented well by the existing latent features. From Figure 4, we can see that TagiCoFi can achieve good performance with D taking a wide range of values.
One well-known problem of CF systems is the cold-start problem, in which recommendations are required for users or items which have no observed ratings [20, 8, 11]. Pure CF methods, such as PMF, cannot work under a cold-start set-ting, since no preference information is available to form any basis for giving recommendation. Suppose tagging informa-tion is available, TagiCoFi can solve the cold-start problem by seamlessly integrating the tagging information for recom-mendation.

To validate the above speculation, we conduct two sets of experiments based on 20% training sets, where we randomly select 50 and 100 users and discard their ratings. These users, called cold-start users, are quite commonly found in many recommender systems, such as newly registered users in a system. In the experiments, the parameters of our
Figure 4: Impact of the number of latent features model are set as  X  = 1,  X  = 50 and D = 10. In our imple-mentation of PMF, we use the item average to predict the rating of cold-start users for an item, because the original PMF cannot give prediction for those cold-start users. The MAE curves of PMF and TagiCoFi during the first 1000 iterations are plotted in Figure 5.
 Figure 5 shows that TagiCoFi significantly outperforms PMF, validating our speculation that tagging information could be used to perform recommendation for cold-start users. Table 4 shows the MAE values of PMF and TagiCoFi to-gether with their corresponding standard deviations on cold-start users and all users respectively in two different settings. It is clear that TagiCoFi performs better than PMF at all levels.
We have proposed a novel framework, TagiCoFi, to seam-lessly incorporate tagging information into collaborative fil-tering for item recommendation. To the best of our knowl-edge, TagiCoFi is the first work that incorporates tagging information into a model-based CF system for item recom-mendation. One promising property of TagiCoFi is that it can overcome the overfitting problem suffered by most MF-based CF methods. Moreover, TagiCoFi can also solve the cold-start problem for novel users. Experimental results on real data demonstrate that TagiCoFi can significantly out-perform state-of-the-art collaborative filtering algorithms, such as PMF, which discard the tagging information.
One of our future research directions is to extend TagiCoFi by incorporating into it the tagging history of items. Fur-thermore, we plan to extend TagiCoFi to incorporate addi-tional sources of information to further improve the perfor-mance of recommender systems. We thank the GroupLens research lab at the University of Minnesota for their dataset. The research reported in this paper is supported by research grant HIA98/99.EG01 from the Hong Kong University of Science and Technology. [1] G. Adomavicius and A. Tuzhilin. Toward the next [2] M. Balabanovi  X c and Y. Shoham. Fab: content-based, [3] J. Bennett and S. Lanning. The Netflix prize. In [4] J. Breese, D. Heckerman, and C. Kadie. Empirical [5] F. Chung. Spectral Graph Theory . Number 92 in [6] M. de Gemmis, P. Lops, G. Semeraro, and P. Basile. [7] N. Garg and I. Weber. Personalized, interactive tag [8] H. Guo. Soap: live recommendations through social [9] J. L. Herlocker, J. A. Konstan, A. Borchers, and [10] Y. Koren. Factorization meets the neighborhood: a [11] X. N. Lam, T. Vu, T. D. Le, and A. D. Duong. [12] K. Lang. Newsweeder: learning to filter netnews. In [13] W.-J. Li and D.-Y. Yeung. Relation regularized matrix [14] G. Linden, B. Smith, and J. York. Amazon.com [15] R. J. Mooney and L. Roy. Content-based book [16] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [17] R. Salakhutdinov and A. Mnih. Probabilistic matrix [18] G. Salton and C. Buckley. Term-weighting approaches [19] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [20] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. [21] S. Sen, S. K. Lam, A. M. Rashid, D. Cosley, [22] S. Sen, J. Vig, and J. Riedl. Tagommenders: [23] A. Shepitsen, J. Gemmell, B. Mobasher, and R. Burke. [24] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. [25] K. H. L. Tso-Sutter, L. B. Marinho, and [26] Y. Yang and X. Liu. A re-examination of text [27] V. Zanardi and L. Capra. Social ranking: uncovering
