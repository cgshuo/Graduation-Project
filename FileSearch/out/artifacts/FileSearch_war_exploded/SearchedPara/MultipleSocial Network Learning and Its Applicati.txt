 We are living in the era of social networks, where people throughout the world are connected and organized by multiple social networks. The views revealed by different social networks may vary according to the different services they offer. They are complimentary to each other and comprehensively characterize a speci c user from different perspectives. As compared to the scare knowledge conveyed by a single source, appropriate aggregation of multiple social networks offers us a better opportunity for deep user understanding. The challenges, however, co-exist with opportunities. The rst challenge lies in the existence of block-wise missing data, caused by the fact that some users may be very active in certain social networks while inactive in others. The second challenge is how to collaboratively integrate multiple social networks. Towards this end, we rst proposed a novel model for data missing completion by seamlessly exploring the knowledge from multiple sources. We then developed a robust multiple social network learning model, and applied it to the application of volunteerism tendency prediction. Extensive experiments on real world dataset verify the effectiveness of our scheme. The proposed scheme is applicable to many other domains, such as demographic inference and interest prediction.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing Multiple Social Network Learning; Missing Data Completion; Volunteerism Tendency Prediction
With the explosion of social network services, more and more people are involved in multiple social networks for various purposes at the same time. It is reported c  X  that 52% of online adults concurrently use multiple social media services 1 . Different aspects of users are disclosed on different social networks due to their different emphasis. In fact, these views are complementary to each other and essentially characterize the same user from different perspectives. As compared with single social network, appropriate aggregation of multiple social networks provides us a potential to comprehensively understand the given users [1, 29]. For example, we can learn descriptive user representation, build predictive models for user pro les, and recommend prescriptive actions based on complete historical behaviors. Hence, an effective technique for multiple social network learning (MSNL) is highly desired. Distinguished from multi-view learning which maximizes the agreement between views using unlabeled data, MSNL works towards supervised learning.

However, integration of multiple sources is non-trivial [27]. The rst tough challenge lies in how to fuse users' heterogeneous distributed data from multiple social networks effectively. One naive approach is to concatenate the feature spaces generated from different sources into a uni ed feature space. Thereby, traditional machine learning models can be further applied. However, this method simply treats the con dence of all data sources equally and may also lead to the curse of dimensionality. Moreover, it ignores two important facts: 1) different aspects of users are revealed in different social networks and are thus distributed in different feature spaces; and 2) all these aspects tend to characterize the same users. In particular, data from multi-sources describes the same user and thus the results predicted by different sources should be similar. Therefore, it is expected to take the source con dence and source consistency into consideration. Another challenge we are facing is the data missing problem. Although some users have social accounts on multiple social networks, generally they are active on only a few of them. One simple approach to address this challenge is to discard all incomplete subjects. It is apparent that this method will dramatically reduce the training size, thereby result in over tting in the model learning stage. Therefore, accurately completing missing data by jointly utilizing multiple sources is a necessity to enhance the learning performance.
 To address these problems, we present a scheme for MSNL, which co-regulates the source con dence and source consistency. Figure 1 shows our proposed scheme comprising of three components. Given a set of users, we rst crawl A ccording Paw Research Internet Project's Social Media Update 2014: http://www.pewinternet.org/ l -th corresponding label, respectively. their historical contents and all social connections. The rst component extracts the multi-faceted information cues to describe a given user, including demographic information, practical behaviors, historical posts, and pro les of social connections. To deal with the block-wise missing data, the second component attempts to infer the block-wise missing data by learning a latent space shared by different social networks, achieving a complete input to the next component. We nally use the last component to conduct MSNL on the complete data. Particularly, we model the con dence of different data sources and the consistency among them by unifying two regularization terms into our model.
Based upon our proposed scheme, we introduce one application scenario: volunteerism tendency prediction. Volunteerism was de ned in [18] as long-term, planned, prosocial behaviors that occur within organizational settings and can bene t strangers. Persons exhibiting volunteerism are the so-called volunteers, who serve as an important work force in modern society. Traditionally, it is intractable for nonpro t organizations (NPOs) to aimlessly recruit volunteers from the huge crowd. It is thus necessary to develop an automatic volunteerism tendency prediction system to alleviate the dilemma that NPOs are facing. In particular, we take the advantage of users' casually distributed online data, especially from multiple social networks, which can comprehensively reveal users' personal concerns, interests [5, 22] and even personality traits [20, 21]. On the other hand, the real word dataset may contain block-wise missing data due to some users' inactivity in social networks. Moreover, the speci c task also brings us another issue in terms of data collection and ground truth construction. Therefore, the proposed scheme naturally ts this application scenario.
 Our main contributions can be summarized in threefold: The remainder of this paper is structured as follows, Section 2 brie y reviews the related work. Section 3 describes the proposed MSNL model. Missing data completion is introduced in Section 4. Section 5 presents the set of volunteer-oriented features we developed. Section 6 details the experimental results and analysis, followed by our concluding remarks in Section 7.
Although our work is distinguished from multi-view learning, we can still bene t from their efforts. Zhang et al. [28] proposed an inductive multi-view multi-task learning model (regMVMT). regMVMT penalizes the disagreement of models learned from different sources over the unlabeled samples. Besides, the authors also studied the structured missing data, which is completely missing for a source in terms of a task. In other words, if a source is available for a task, then all samples will have data from this source. However, they overlooked the source weights and did not pay attention to the partially structured missing data, which are both what we are concerned with. Yuan et al. [25] introduced an incomplete multi-source feature learning method, avoiding the direct inference of block-wise missing data. Particularly, the authors split the incomplete data into disjoint groups, where they conducted feature learning independently. However, such a mechanism constrains us to conduct source level analysis. Later, Xiang et al. [24] investigated multi-source learning with block-wise missing
Th e compiled dataset is currently publicly accessible via: http://multiplesocialnetworklearning.azurewebsites.net/ d ata with an application of Alzheimer's Disease prediction and proposed the iSFS model. Apart from feature-level analysis, the authors also conducted source-level analysis by introducing the weights of models obtained from different sources. However, ignoring the consistency relationships among different models seems inappropriate. In addition, the authors also adapted the model to handle cases where block-wise missing data exists. Different from their work, we infer the missing data by making full use of the available data before applying MSNL, which is more generalizable to other applications.
This section details our proposed MSNL model and derives an analytic solution by solving the inverse of a linear system, whose invertibility is proved rigorously.
We rst declare some notations. In particular, we use bold capital letters (e.g. X ) and bold lowercase letters (e.g. x ) to denote matrices and vectors, respectively. We employ non-bold letters (e.g. x ) to represent scalars, and Greek letters (e.g. ) as parameters. If not clari ed, all vectors are in column forms.
 Suppose we have a set of N labeled data samples and S 2 social networks. We compile the S social networks with an index set C = f 1 ; 2 ; ; S g . Let D s and N s denote the number of features and samples in the s -th social network, s 2C , respectively. Let X s 2 R N D s denote the feature matrix extracted from the s -th social network. Each row represents a user sample. Then the dimension of features extracted from all these social networks is D =  X  s =1 D s . The whole feature matrix can be written as X = f
X 1 ; X 2 ; ; X S g2 R N D and y = f y 1 ; y 2 ; ; y N g T 2 f 1 ; 1 g N 1 is the corresponding label vector.
Based on a set of data samples with S social networks, we can learn S predictive models, where each model is individually and independently trained on a social network. The nal predictive model can be strengthened via linear combination of these S models. Mathematically, we learn one linear mapping function f s for the s -th social network. In addition, we assume that the mapping functions learned from all social networks agree with one another as much as possible. Particularly, we can formalize this assumption using regularization function. Using the least square loss function, we have the following objective function, min where f ( X ) is the nal predictive model. f s ( X s ) is the prediction results generated from data X s . and are the nonnegative regularization parameters that regulate the sparsity of the solution regarding f s and the disagreement among models learned from different social networks, respectively. If we just treat the con dence of different social networks equally, the nal predictive model can be formalized as follows, However, in reality, different social networks always have different con dence to the nal prediction, and we consider modeling the weights of multiple sources instead of treating all sources equally by introducing the weight vector: = [ 1 ; 2 ; ; S ] T 2 R S 1 , where s controls the weight of model learned from s -th social network. Then the nal model is de ned as follows, where e = [1 ; 1 ; ; 1] T 2 R S 1 . It is worth mentioning that we do not impose the constraint of s 0, as we want to keep both positive and negative weights. Positive weights indicate the positive correlations of social networks with the nal results, while negative weights re ect negative correlations between the given task and different sources, which may contain unreliable and noisy data.

For the s -th social network, we learn a linear mapping function indexed by a model w s 2 R D s 1 . Then the objective function can be rewritten as follows, min where e T = 1 and is the regularization parameter, controlling the sparsity of the solution regarding .
We adopt the alternating optimization strategy to solve the two variables and w s in Eqn. (4). In particular, we optimize one variable while xing the other one in each iteration. We keep this iterative procedure until the objective function converges.
We denote the objective function as . For simplicity, we replace y in Eqn. (4) by ye T , as e T = 1. With the help of Lagrangian, can be rewritten as follows, min 1 where is the nonnegative Lagrange multiplier and W = diag ( w 1 ; w 2 ; ; w S ) 2 R D S . Taking derivative of with respect to , we have, Setting Eqn. (6) to zero, it can be derived that, where S ince e T = 1, we can obtain that, Obviously, M 2 R S S is positive de nite and invertible, according to the de nition. We thus can obtain the analytic solution of as Eqn. (9). Moreover, we note that when the prediction results learned from all social networks are equal, where X 1 w 1 = X 2 w 2 = = X S w S , then same weights will be assigned, i.e., 1 = 2 = = S . In addition, Eqn. (9) tends to assign higher weight s , if smaller difference exists between y and X s w s .
When is xed, we compute the derivative of regarding w s as follows, @ @ w s where I is a D s D s identity matrix. Setting Eqn. (10) to zero and rearranging the terms, all w s 's can be learned jointly by the following linear system, where L 2 R D D is a sparse block matrix with S S blocks, w = [ w T 1 ; w T 2 ; ; w T S ] T 2 R D 1 and t = [ t 1 ; t T 2 ; ; t T S ] T 2 R D 1 are both sparse block vectors with
Technically, t can be treated as a constant matrix as is xed. It is worth noting that L is symmetric as L ss  X  = L If we can prove that L is invertible, then we can derive the closed-form solution of w as follows, We now show L is invertible by proving that L is a positive-de nite matrix. Let h = [ h T 1 ; h T 2 ; ; h T S ] T 2 R D 1  X  an arbitrary block vector, where h i 2 R D i 1 ; i 2C . Then Al gorithm 1 Alternative optimization for solving Eqn. (4) Inp ut: X , y , , ,
Output: , w 1: Initialize ( w ) 0 by tting each source individually on the 2 : for k = 1 ; 2 ; do 3: Compute each ( ) k according to Eqn. (9). 4: Update ( w ) k according to Eqn. (13). 5: if the objective value stops decreasing then 6: return = ( ) k and w = ( w ) k 7: end if 8: end for w e need to prove that h T Lh = = h 2 + 1 + is always larger than zero. In fact, given an arbitrary vector b , we have, Therefore, as S 2, we have the following inequality, Besides, we know that, Based upon Eqn. (16) and Eqn. (17), we have that, As h  X  = 0 , h T Lh is always larger than zero. Consequently, L is invertible. The overall procedures for alternating optimization are summarized in Algorithm 1. As each iteration can decrease , whose lower bound is zero, we can guarantee the convergence of Algorithm 1 [7, 16].
In this section, we deal with a more challenging and realistic situation, where block-wise missing data exists, and propose an approach for multiple social network data completion (MSNDC). In such situations, user samples may n ot be active in all social networks, which leads to the block-wise data missing.

Suppose we have S data sources in total and each sample has at least one data source available. We employ the subset C i C to indicate the presence of each source and the signature of a speci c social network combination. Based on these combinations, all the data samples can be split into multiple exclusive sets, where each set corresponds to a combination. Figure 2 illustrates the incomplete data in our dataset. As can be seen, all users have complete features from SN 1 , while some users miss data in SN 2 or SN 3 . Therefore, our dataset can be split by four exclusive social network combinations: C 1 = f 1 ; 2 g , C 2 = f 1 ; 2 ; 3 C = f 1 ; 3 g , C 4 = f 1 g .

Inspired by [10], we use Non-negative Matrix Factorization (NMF) to explore the latent spaces that are shared by different social networks, and further infer the missing data based upon these latent spaces. It is reasonable to assume that the data from different social networks about the same user shares certain latent features. We employ X C i s 2 social network. It only contains samples that are available in the set of social networks C i , where N C i stands for the number of these samples. We use U s 2 R z D s to represent the latent basis matrix for the s -th social network, and P R N C i z to denote the corresponding latent representation of feature matrix X C i s . z is the dimension of the shared latent space of different social networks. The intuitive assumption is that for the samples available in both the s -th and s social networks, their corresponding latent representations should also be quite similar. In particular, we impose this constraint to NMF as follows, where s  X  = s  X  ; s 2C i , and s  X  2C i . We thus learn the shared subspaces by the following objective function, min where and are the nonnegative tradeoff parameters for the regularizations. Similarly, we employ the alternating optimization strategy to solve the optimization in Eqn. (20). To be more speci c, we rst initialize U s and compute the optimal P s . Afterwards, P s is updated based on the computed U s . We keep this iterative procedure until the objective function converges.

The proposed approach differs from [10] in the following three aspects. First, MSNDC is generalized to handle the more challenging scenario where data samples are extracted from more than two social networks. Second, apart from regulating the latent representation matrix, we also incorporate the regularization on the latent basis matrix. Third, we further derive the original missing data from Fi gure 2: Illustration of the incomplete data from three sources. X C i s denotes the samples generated from social network s that are only available in the social network combination of C i . the latent representation, where the authors in [10] just apply cluster algorithms directly to the latent representation of data instead of the original data. This is due to two considerations. One is that we believe the value of original known data is higher than the latent representation. The other one is that we need to preserve the heterogeneity among data from different sources to t the MSNL model.
In order to increase the efficiency of the iterative procedure, we initialize U s by optimizing the following objective function, min
We then alternatively optimize U s and P s until the objective function converges. Speci cally, we employ the greedy coordinate descent (GCD) approach [9], which has been proven to be tremendously fast to solve NMF decomposition with L1-norm regularization. Finally, we obtain P s ; U s ; s 2C , based on which we can infer the missing data as follows, Algorithm 2 summarizes the overall procedures for alternating optimization.
In this work, we apply the proposed scheme to an application scenario: volunteerism tendency prediction. In modern society, volunteers are extremely crucial to NPOs to sustain their continuing operations. The discovery of users' volunteerism tendency can signi cantly facilitate the recruitment of volunteers for NPOs, which can save considerable cost to nd the potential volunteers. In particular, we cast the problem of volunteerism tendency prediction as a user binary classi cation. If the predicted tendency score of a given user is larger than a pre-de ned A lgorithm 2 Alternative optimization for solving Eqn. (20) Input : X 1 ; X 2 ; X 3 , ,
Output: ^ X 1: Initialize U (0) s according to Eqn. (21). 2: for k = 1 ; 2 ; do 3: for s = 1 ; 2 ; ; S do 4: Compute each P ( k ) s according to Eqn. (20) via GCD 5: Update U ( k ) s according to Eqn. (20) via GCD 6: if the objective value stops decreasing then 8: end if 9: end for 10: end for 11: for j = 1 ; 2 ; ; S do 12: for C q C do 13: if j 2C q then 15: else 16: Infer ^ X C q j according to Eqn. (22). 17: end if 18: end for 19: end for th reshold , we regard this user as a volunteer. In this work, we explore three popular social networks: Twitter, Facebook and LinkedIn, as they are representative of a public, private, and professional social network, respectively. Besides, it is known that users exhibit different aspects on different social networks [1], and the combination of these three social networks would help to better characterize user behaviors on social platforms.
To represent the same users with multiple sources, we need to rst tackle the problem of \Social Account Mapping", which aims to align the same users across different social networks by linking their multiple social accounts [1]. To accurately establish this mapping, we employ the emerging social services such as About.me 3 and Quora 4 , where they encourage users to explicitly list their multiple social accounts on one pro le.
 We proposed two strategies to collect data from About.me. To enlarge our dataset, we also collected candidates from Quora by the breadth-rst-search method. Particularly, we took advantage of both the follower and followee 6 relations h ttps://about.me/ http://quora.com/ http://about.me/developer/api/docs/
If A follows B, then A is B's follower and B is A's followee. provided by Quora. Initially, we selected two popular users as the seed users and then explored all their neighboring connected users. We applied similar exploration approach to all other non-seed users. In the end, we collected 172 ; 235 users' pro les and only retained those who have accounts in Facebook, Twitter and LinkedIn.
Based on these candidates, we launched a crawler to collect their historical social contents, including their basic pro les, social posts and relations. However, the traditional web-based crawler is not applicable to Facebook due to its dynamic loading mechanism. We thus resorted to the Selenium 7 to simulate users' click and scroll operations on a FireFox browser and load users' publicly available information. We limited the access rate to one request per second to avoid being blocked by the robot checkers. It is worth mentioning that the data we collected is all publicly available. On the other hand, due to the privacy constraint, we could not access uses' social relations in Facebook and LinkedIn. We hence only collected users' followee relations in Twitter.

In order to improve the quality of our dataset, we employed three annotators to nalize our ground truth. As users tend to provide more complete and reliable pro les in LinkedIn, we guided the annotators to study the LinkedIn pro les of candidate users, and determine whether they are \volunteers" by majority votes. To ensure a uniformly labeling procedure, we provided them a piece of guideline. Given a user's LinkedIn pro le, we classi ed the user as a volunteer if and only if this user lists his/her volunteer experiences in the section \Volunteer experience &amp; Causes" or section \Experience". Candidates who do not satisfy the above two criteria were tagged as non-volunteers. We focused on LinkedIn to determine whether users are volunteers because the volunteer experiences in LinkedIn are the most straightforward evidence to identify volunteers. It should be noted that those who do not mention their volunteer experiences in LinkedIn are not necessarily classi ed as \non-volunteers". However, the absence of these mentions, at least, reveals their limited interests and low enthusiasm in volunteerism. Therefore, in our work, we broadly de ned users as \non-volunteers" if they do not mention their relevant volunteerism experiences in LinkedIn.

Table 1 lists the statistics of our dataset. We obtained the data for 1 ; 425 volunteers and 4 ; 011 non-volunteers according to the aforementioned strategies. The crawling was conducted between 22nd August to 11th September, 2013. Here we only selected a subset of non-volunteer data and made the dataset balanced to avoid the training bias. To facilitate this line of research, this dataset has been released after certain privacy preservation processing.

However, in reality, not all users are active enough on all social networks. To ensure the data quality, we treated those inactive users as missing with respect to a speci c social network. Therefore, there exists block-wise missing data in our dataset. In particular, we treated a user as missing in Twitter or Facebook, if this user has less than 10 historical social posts. In addition, due to the absence of social post h ttp://docs.seleniumhq.org/download/ Da ta V olunteer No n-volunteer Twi tter pro les 1 : 5 k 4 k Twi tter posts 559 k 1 m Twi tter followees' pro les 902 k 3 m F acebook pro les 1 : 5 k 4 k F acebook posts 83 k 338 k
Li nkedIn pro les 1 : 5 k 4 k mec hanism in LinkedIn, we treated a user as missing 8 in LinkedIn if the word count of this user's pro le is less than 50. Figure 3 shows the statistics of our incomplete data. As can be seen, about 50% of users have complete data from all three social networks. 1% and 47% of users only miss the data either from Facebook and LinkedIn, while 2% of users miss the data from both of them.
 Fi gure 3: Statistics of the incomplete data. Tw: Users with Twitter data only; Tw+Fb: Users with Twitter and Facebook data only; Tw+In: Users with Twitter and Linkedin data only; Tw+Fb+In: Users without missing data.
To capture users' volunteerism tendency, we extracted a rich set of volunteer-oriented features.
The study in [19] reported that some demographic characteristics, such as education and income level, are strong indicators for volunteerism. This study inspires us to extract demographic characteristics from users' pro les, especially the Facebook and LinkedIn pro les. In our work, we explored users' demographic characteristics, including Gender , Relationship status , Education level , and Number of social connections . We also extracted linguistic features, including Linguistic Inquiry and Word Count (LIWC) features, user topics and contextual topics.
 LIWC features. LIWC is widely-used to analyze the psycho-linguistic transparent lexicon. It plays an important role in predicting users' personality [2, 15]. The main component of LIWC is a directory which contains the
Here we exclude the contents of section \Volunteer experience &amp; Causes" and section \Experience". mapping from words to 72 categories 9 . Given a document, LIWC computes the percentage of words in each category and represents it as a vector of 72 dimensions.

To capture the key aspects of LIWC features, we selected the top 5 dimensions as the representative LIWC features according to the information gain ratio. Considering that the emotions for individuals may also affect users' volunteerism tendency, we additionally selected two categories from LIWC: positive emotion and negative emotion. Besides, we also utilized the positive-negative emotion ratio to further re ect users' emotional states. Let L ( ) represent the percentage of users' words in certain LIWC category. The positive-negative emotion ratio is de ned as, where p and n are introduced to avoid the situation: individuals have no positive or negative emotional word. They are both set as 0 : 0001. In total, we have 16 dimension LIWC features, extracted from Twitter and Facebook. User topics. According to our observation, volunteers may have, on average, a higher probability of talking about topics such as social caring or giving back, while the non-volunteers may mention other topics more often. This motivates us to explore the topic distributions of users' social posts to identify volunteers. We generated topic distributions using Latent Dirichlet Allocation (LDA) [4], which has been widely found to be useful in latent topic modeling [8, 23]. Based on perplexity [14] metric frequently utilized to nd the optimal number of hidden topics, we ultimately obtained 52, 26, 42 dimensional topic-level features over users' Twitter, Facebook and LinkedIn data, respectively.
 Contextual topics. We de ne users' contextual topics as the topics of users' connections. We believe that the contextual topics intuitively re ect the contexts of users. \He that lies down with dogs must rise up with eas" tells us that the context signi cantly affects a user's tendency. Particularly, we studied followees and retweeting 10 connections on Twitter because of their intuitive re ection of topics that users concern. As the bio descriptions are usually provided by users to brie y introduce themselves and may indicate users' summarized interests, we integrated the bios of a user's followees or those whose tweets are retweeted by this user into two kinds of bio documents, on which we further applied LDA model. We utilized the perplexity to x the dimensions of topic-level features over followees' bio documents and retweetings' bio documents as 40 and 20, respectively. In this work, we only explored the contextual topics in Twitter, since we were unable to crawl the connections' pro les in LinkedIn and the bio descriptions are usually missing in Facebook.
This kind of features is characterized by users' posting behavior patterns and networking behavior patterns. The former focuses on the written style of users' social posts, while the latter captures their egocentric network features. Posting behavior patterns. Posting behavior patterns have been investigated in many scenarios, spanning from h ttp://www.liwc.net/
If A broadcasts a tweet posted by B, then B is A's a retweeting user. a ge estimation to social spammers discovery [3, 13]. These patterns can be used to depict users' participation in information diffusion, which correlates with volunteerism tendency much.

On one hand, we employed the fraction of users' posts containing certain behaviors, including emoticons, slang words, acronyms, hashtags, URLs, and user mentions, to intuitively re ect users' engagement in topic discussion and social interaction. On the other hand, we observed that users' posting behaviors in social networks can be classi ed into a few categories. For example, posts in Twitter can be classi ed into two categories, C tw = f tweets; retweets while posts in Facebook can roughly be split into eight types: C fb = f share l ink; share sideo; share status; share photo; chang e photo; repost; post; tagged g . The distributions over users' posts on these categories also re ect their participation in information diffusion, revealing whether a given user tend to share information in social networks. When it comes to Linkedin, we utilized the pro le completeness to characterize users' behaviors. Based on our observation, we found that volunteers tend to provide more information for all the sections. This not only re ects volunteers' active participation in LinkedIn but also signals their self-con dence and openness to public. Pro le completeness is de ned as a boolean vector over six dimensions to denote the presence of the six common sections in LinkedIn pro les: summary , interest , language , education , skill and honor . We excluded the sections on experience and volunteer experience &amp; causes , because the ground truth is built on these two sections.
 Egocentric network patterns. We also studied users' social behaviors from their egocentric networks. Intuitively, we believe that users belong to certain class tend to be connected with several class-speci c accounts, as it goes for that\birds of a feather ock together". Therefore, volunteers should interact with some typical accounts in social media. The set of typical accounts is denoted as F V . Inspired by [17], we measured the degree of a user's correlation with volunteerism by three features: the frequency and fraction of a user's \friends" that belong to F V as well as the total number of \friends". In particular, we treated both the followees and retweetings as the\friends"of users in Twitter.
To construct the F V , we utilized the Twitter pro le repository Wefollow 11 , which allows us to nd the most prominent people given a particular category. By crawling prominent users falling into categories of Nonpro t , Charity , Volunteer , NGO , Community Service , Social Welfare and Christian from Wefollow, we obtained 23 ; 285 accounts.
We conducted extensive experiments to comparatively verify our proposed scheme from various angles over a system equipped with Intel i72 : 60 GHz CPU, and 8 GB memory. In particular, we launched 10-fold cross validation for each experiment, and reported the average performance. Each fold involves 2 ; 249 training and 250 testing samples.
We compared MSNL with four baselines. Before that, the data was completed by MSNDC . We also performed signi cant test to validate the effectiveness of MSNL . h ttp://wefollow.com/
SVM : We chose the learning formulation with the kernel of radial-basis function. We implemented this method based on LIBSVM [6].

RLS : Regularized least squares model [11] aims to minimize the objective function of 1 2 N y Xw 2 + 2 w 2 . In fact, the RLS model can be deduced from MSNL via the settings of = [ 1 S ; 1 S ; ; 1 S ] T , = 0 and = 0. iSFS : The third baseline is the incomplete source-feature selection model proposed in [24]. This model only assigns weights to models learned from different social networks but ignores the relationships among them. We can derive iSFS from MSNL by making = 0. regMVMT : The fourth baseline is the regularized multi-view multi-task learning model [28]. This model only regulates the relationships among different views but fails to take the source con dence into account. We can derive regMVMT from MSNL by making = [ 1 S ; 1 S ; ; 1 S ] T . T able 2: Performance of different models(%).
 Ap proaches F 1-measure P-value SV M 83 : 11 0 : 038
RL S 82 : 82 0 : 025 re gMVMT 84 : 07 0.1 73 iS FS 84 : 72 0.2 81 MSN L 85 : 59 -
T able 2 shows the performance comparison between baselines and our proposed MSNL . We noticed that MSNL signi cantly outperforms the SVM and RLS . This implies that the information on multiple social networks are complementary and characterize users' volunteerism tendency consistently. This also proves that the correlations of different social networks with the task of volunteerism tendency prediction cannot be treated equally. In addition, MSNL achieves better performance, as compared with iSFS and regMVMT , which are the derivations of MSNL . This demonstrates that both the source con dence and the source consistency deserve particular attention.
We further evaluated the component for missing data completion with the following three baseline methods.
Remove : This method eliminates all data samples that are not complete.

Average : This method imputes the missing features with the average values of the corresponding feature items.
KNN : The missing data is inferred by averaging its K-nearest neighbors. K is experimentally set as 1. Table 3: Performance of different models over different data completion strategies.

T able 3 shows the performance of different models over different data completion strategies. It can be seen that MSNDC outperforms the other strategies. Additionally, removing all incomplete data samples achieves the worst performance, which may be caused by the fact that it introduces training bias, making the dataset unbalanced and red uces the size of training dataset. We found that the percentage of volunteer samples decreases from 50% to 40% after ltering out all incomplete data samples.
To examine the discriminative features we extracted, we conducted experiments over different kinds of features using MSNL . We also performed signi cant test to validate the advantage of combining multiple social networks. Table 4 comparatively shows the performance of MSNL in terms of different feature con gurations. It can be seen that the linguistic features achieves the best performance, as compared against demographic characteristics and behavior-based features. This reveals that volunteerism tendency is better re ected by their social contents, including their own social posts and the self-descriptions of their social connections. This also implies that users with volunteerism Table 4: Performance of different features(%).
 F eatures F 1-measure Dem ographic characteristics 68 : 43 Li nguistic features 80 : 06 B ehavior-based features 78 : 52 te ndency may talk about related topics and follow or retweet related social accounts. In addition, we found that contextual topics are more discriminative as compared to users' own topics. This may be due to the fact that users' self-descriptions are of more value and contain less noise than users' tweets. Some hot topics discussed by volunteers are given in Table 5. Besides, the egocentric network patterns also play a dominant role in our task. This implies that one's social connections indeed re ect the user's personal concerns to a large extent.
To demonstrate the descriptiveness of multiple social network integration, we conducted experiments over various source combinations. Notably, data from Facebook and LinkedIn is incomplete and we need to infer the block-wise missing data rst taking advantage of the complete data samples from Twitter.

Table 6 shows the performance of MSNL over different social network combinations. We noted that the more sources we incorporate, the better the performance can be achieved. This implies the complementary relationships rather than mutual con icting relationships among the sources. Moreover, we found that aggregating data from all these three social networks can achieve signi cantly better performance as compared to each of the single source. Additionally, as the performance obtained from different single social networks are not the same, this validates that incorporating the con dence of different social networks to MSNL is reasonable. Interestingly, we observed that MSNL over Twitter alone achieves the much better performance, as compared to that over LinkedIn or Facebook alone. This may be caused by the fact that the Table 5: Hot topics discussed by volunteers. Followee and retweeting: contextual topics; Self: user topics.
 Dat a source T opic words
S elf w oman, help, education, child v olunteer, nonpro t, support mo st discriminative features evaluated by Section 6.3 are all extracted from Twitter.
 Table 6: Performance of different social network combinations(%). Facebook and LinkedIn both refer to the complete data, whose missing data is pre-inferred. F1: F1-measure.
 So cial network combinations F1 p -value Twi tter 82 : 35 4 : 2 e -2 F acebook 73 : 53 5 : 0 e -7 Lin kedIn 74 : 49 3 : 1 e -7 Twi tter+Facebook 83 : 67 1 : 1 e -1 Twi tter+LinkedIn 83 : 84 1 : 4 e -1 F acebook +LinkedIn 76 : 29 6 : 0 e -6
Twi tter+Facebook +LinkedIn 85 : 59 -
In order to verify the usefulness of our model on real world dataset, where the volunteers should account for a minority portion of user population, we tuned the fraction of volunteer samples in our dataset. In particular, we fed x %, x 2 [5 ; 50], of volunteer samples to our model with stepsize 5%. Figure 4 shows the F1-measure with respect to different fraction of volunteer samples of different models. As can be seen, our model can achieve satisfactory performance even when volunteer samples only accounts for 5% of the whole samples. This demonstrates that the proposed MSNL model is not sensitive to the percentage of positive samples. Whereas, SVM and RLS are relatively more sensitive to the fraction of volunteer samples in dataset.
 Fi gure 4: F1-measure at different fraction of volunteer samples.
In order to analyze the complexity of MSNL , we need to solve the time complexity in terms of constructing M , L and t as de ned in Eqn. (8) and Eqn. (12), and computing the inverse of M and L . Assume D  X  S , the construction of matrix M has a time complexity of O ( N DS ), and the construction of matrix L has a time complexity of O ( N D 2 ). Due to the fact that the cost of t involved in Eqn. (12) remain the same for all iterations and L is symmetric, we can save much practical time cost. Also, using the standard method, computing the inverse of two core matrices, M and L , has the complexity of O ( S 3 and O ( D 3 ), respectively. Furthermore, using the method of Coppersmith and Winogard, the time cost can be bounded the speed bottleneck lies in the number of features and the number of social networks instead of the number of data samples. As S and D are usually small, especially S , MSNL should be efficient in time complexity.

To validate the practical efficiency of the proposed MSNL model, we conducted a set of experiments. The comparison of average time consumption of different models is shown in Table 7. As can be seen, MSNL shows superiority over SVM in terms of the time cost, which takes only 19% of the time that SVM uses. By careful observation, we observed that MSNL converges very fast, which on average takes about 20 iterations. Even though MSNL takes more time than RLS and regMVMT due to the consideration of source consistency and source con dence, it improves the performance in terms of F1-measure.
 A pproach T otal (s) T rain (s) T est (s) SV M 2 : 0550 1 : 8211 0 : 2339
R LS 0 : 0639 0 : 0631 0 : 0008 re gMVMT 0 : 0605 0 : 0595 0 : 0006 i SFS 0 : 5565 0 : 5557 0 : 0008
MS NL 0 : 3936 0 : 3929 0 : 0007
This paper presented a novel scheme for multiple social network learning. This scheme takes the source con dence and source consistency into consideration by introducing regularization to the objective function. We further demonstrated that the proposed scheme, designed for complete data, is also able to handle the real and more challenging cases where there exists block-wise missing data. In particular, before feeding the data into the proposed MSNL model, we inferred the missing data via NMF technique. Furthermore, we practically evaluated the proposed scheme in an interesting scenario of volunteerism tendency prediction. We developed a set of volunteer-oriented features to characterize users' volunteerism tendency. Experimental results demonstrated the effectiveness of our proposed scheme and veri ed the advantages of utilizing multiple social network over a single source. Currently, we only consider solving a single task in the proposed scheme. In the future, we will extend our work to the context of multiple task learning.
 This research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office.
