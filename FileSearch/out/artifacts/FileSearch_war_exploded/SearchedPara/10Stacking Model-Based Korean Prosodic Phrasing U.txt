 Prosodic phrasing breaks a sentence into small combinations of metered elements and predicts where phrase boundaries will be located within a sentence. One of the crucial problems in achieving natural-sounding speech synthesis is the assignment of appropriate phrase breaks. Although phrase boundaries can be located anywhere in a sentence, most phrase boundaries are located between words; only a very small number of phrase boundaries are located within words 1 . Thus, to simplify the problem, it is assumed that phrase boundaries can only be located between words (Figure 1). The type of phrase boundary must also be considered. According to the ToBI (Tones and Break Indices [Silverman et al. 1992]) convention, a representative system for describing aspects of prosody (a five-level break index that uses numbering from 0 to 4) is used to classify junctures between words. Junctures with break indices of 3 or 4 are usually considered phrase breaks; a value of 3 is assigned to junctures that exhibit a relatively weak break (an intermediate phrase break), and a value of 4 is assigned to junctures that exhibit a strong break (an intonational phrase break). Junctures with break indices of 0 to 2 are considered non-breaks. Thus, according to the problem definition, word junctures can be divided into two classes (non-breaks and breaks) or three classes (non-breaks, minor breaks, and major breaks).

In the K-ToBI (Korean ToBI; [Jun 2000]) labeling convention, a hierarchically orga-nized prosodic structure of Korean was proposed (Figure 2). The intonational structure of Korean has two intonationally defined prosodic units: an intonational phrase and an accentual phrase. An accentual phrase is smaller than an intonational phrase and larger than a phonological word 2 . An intonational phrase can have one or more accen-tual phrases, each of which can contain one or more phonological words. Instead of the five-level break index used in English ToBI, K-ToBI uses a four-level break index with numbering from 0 to 3 to represent the degree of juncture. In K-ToBI, junctures with break indices 2 and 3 are considered phrase breaks; the break index 2 is used for cases with minimal phrasal disjuncture with no strong subjective sense of pause (a minor break), while break index 3 is used for cases featuring a strong phrasal disjuncture with a strong subjective sense of pause (a major break). Junctures with break indices 0 and 1 are considered non-breaks. In Bachenko and Fitzpatrick [1990], several factors that contribute to prosodic phras-ing, namely, syntax, semantics, and phonological length, were investigated. In Jun [1993], these factors were subdivided into the six factors described below. Note that although the examples and descriptions, which are taken from Jun [1993], are related to accentual phrasing, the factors affecting accentual phrasing are the same as those affecting intonational phrasing. 1.1.1. Speech Rate. The number of accentual phrases tends to decrease as speech rate increases. For example, the sentence /i-geon # a-ju # jo-eun # geu-rim-i-ya/  X  X his is a very good picture X  contains four accentual phrases, { i-geon } , { a-ju } , { jo-eun } ,and { geu-rim-i-ya } , when uttered at a normal rate, while the same sentence spoken at a faster rate tends to contain two accentual phrases, { i-geon } and { a-ju # jo-eun # geu-rim-i-ya } . 1.1.2. Phonological Weight. The heaviness of a phrase (the number of syllables within a phrase) affects prosodic phrasing. In general, when an accentual phrase has more than five syllables, it tends to break into two phrases. For example, the sentence /mi-un # gang-i-neun # jag-eun # gyeong-mi-reul # jo-a-hae/  X  X gly Gang-i likes small Gyeongmi X  is spoken with three accentual phrases: { mi-un # gang-i-neun } , { jag-eun # gyeong-mi-reul } ,and { jo-a-hae } . However, when the words /gang-i-neun/  X  X ang-i + a subject particle X  and /gyeong-mi-reul/  X  X yeong-mi + an object particle X  are replaced by /gang-man-i-ne-neun/  X  X ang-man X  X  family + a subject particle X  and /gyeong-man-i-ne-reul/  X  X yeong-man X  X  family + an object particle X , each of the phrases is broken into two phrases, and the resulting sentence is spoken with five accentual phrases: { mi-un } , { gang-man-i-ne-neun } , { jag-eun } , { gyeong-man-i-ne-reul } ,and { jo-a-hae } . 1.1.3. Focus. Focus usually creates a phrase boundary between a focused word and the preceding word and dephrases the words following it. For example, the sentence /gyeo-ur-e # jae-bae-han # o-i-ga # ma-si-dda-neun-de/  X (They said) A cucumber grown in winter is delicious X , which is neutrally focused, is uttered with three accentual phrases: { gyeo-ur-e # jae-bae-han } , { o-i-ga } ,and { ma-si-dda-neun-de } , while the same sentence in which the word  X  X ae-bae-han X  is focused is spoken with three different ac-centual phrases: { gyeo-ur-e } , { jae-bae-han # o-i-ga } ,and { ma-si-dda-neun-de } . 1.1.4. Semantic Weight. The semantic complexity of a lexical item is relevant in prosodic phrasing. When the head noun of a relative clause has a semantically light meaning, such as  X  X erson X ,  X  X lace X , or  X  X hing X , it tends not to form an accentual phrase by itself unless it is focused. For example, the sentence /eo-je # u-ri-ga # man-nan # sa-ram-i # ju-geo-dda-neun-de/  X (They) say the person we met yesterday died X  is uttered with four accentual phrases: { eo-je } , { u-ri-ga } , { man-nan # sa-ram-i } ,and { ju-geo-dda-neun-de } . However, when the word { sa-ram-i }  X  X  man + subject particle X  is replaced by { dae-tong-nyeong-i }  X  X  president + a subject particle X , the sentence is spoken with different four accentual phrases: { eo-je } , { u-ri-ga # man-nan } , { dae-tong-nyeong-i } ,and { ju-geo-dda-neun-de } . 1.1.5. Phrasal Compound. A phrasal compound consists of more than one lexical word but functions as one syntactic word. When a phrasal compound has only two con-stituent lexical words, the two lexical words are generally grouped in one accentual phrase. When a phrasal compound has more than two constituent lexical items, the compound generally forms more than one accentual phrase. In this case, the position of a phrase boundary depends on the internal structure of the compound. For example, the three-word compounds /gu-kwe # eui-won # seon-geo/  X  X arliament X  +  X  X ember X  +  X  X lection X  and /jung-hag-ggyo # gyo-jang # seon-saeng-nim/  X  X unior high school X  +  X  X rin-cipal X  +  X  X ir X  have the structures ((AB)C) and (A(BC)), and these structures correspond to their accentual phrasing. However, the phrasing may not conform to the syntac-tic structure; one finds a set of examples of { A }{ BC } phrasing when the structure is ((AB)C), such as /eo-rin-i # bo-ho # gu-yeok/  X  X hildren X  +  X  X rotection X  +  X  X one X . 1.1.6. Syntactic Constraint. Words that belong to different maximal projections 3 at a higher level tend not to be grouped together to form an accentual phrase. In fact, the boundary between maximal projections is often an intonational phrase boundary (Figure 1). At the same time, for the boundaries within a maximal projection, ac-centual phrasing is not fixed but varies more than the boundary between maximal projections. However, the variability of accentual phrasing is not entirely random. The formal rules for accentual phrase construction can be defined as: (1) every prosodic word may be an accentual phrase, and (2) an accentual phrase can include any number of prosodic words as long as the last prosodic word is not the left element of a branching constituent.

Of the factors cited above, some, such as Speech Rate and Focus, are individually subjective and are not appropriately reflected in a general purpose speech synthesis system. On the other hand, other factors, including Phonological Weight, Semantic Weight, Phrasal Compound, and Syntactic Constraint, are general attributes to be modeled. However, speaker-dependent variability may remain in a labeled corpus due to differences in individual phrasing performance. Several rule-based and data-driven approaches to defining the factors that contribute to prosodic phrasing have been introduced. Both rule-based and data-driven ap-proaches are based on differences between linguistic phrase structure theories and actual performance structure [Gee and Grosjean 1983]. The main difference between the two approaches is whether a mapping rule from the linguistic phrase structure to the actual performance structure is applied beforehand or learned from the data. 1.2.1. Rule-Based Approach. Prosodic phrasing is reproduced by making adjustments to the syntactic parsing of a sentence [Allen et al. 1979; Dommergues and Grosjean 1981; Grosjean et al. 1979]. In Altenberg [1987], reliance upon semantic and dis-course level as well as on syntactic information is investigated for its ability to predict prosodic boundaries in a large corpus, the London-Lund corpus. Proposed syntactico-semantic rules appear to perform fairly well in the prediction of intonational phrase boundaries; these rules show 88.6% success in predicting 554 sentence-level struc-tural junctures, with the strong assumption that data are both correctly part-of-speech tagged and parsed and that semantic and discourse-level distinctions are available. However, phrasing rules of this type cannot be applied to real applications such as speech synthesis because the linguistic analysis is not perfect and may generate erro-neous results. To generate phrasing rules for speech synthesis, the system proposed in Bachenko and Fitzpatrick [1990] considers the only variables that can be inferred from text: a constituent structure, lexical information, and a surface position. However, due to imperfect analysis, this system only predicts 60% of 45 primary boundaries and 44% of 39 secondary boundaries correctly. 1.2.2. Data-Driven Approach. Many researchers have investigated data-driven ap-proaches for prosodic phrasing. An n -gram model, which is a type of probabilistic model widely used in statistical natural language processing such as language modeling, has been proposed in Taylor and Black [1998] and Lee et al. [2002]. The algorithm used in this model predicts the type of boundaries with a window of n -gram part-of-speech tags around each candidate boundary. However, it is difficult to incorporate various lin-guistic features into this algorithm. Several supervised machine-learning techniques for incorporating such features have been proposed; these include classification and re-gression trees [Lee and Oh 1999; Read and Cox 2007; Wang and Hirschberg 1992; Yoon 2006], maximum entropy models [Li et al. 2004; Zheng et al. 2004], conditional ran-dom fields [Kim et al. 2009], and artificial neural networks [Wang et al. 2002]. Given input feature vectors, the above machine-learning algorithms generate a decision tree or a mapping function to output the types of boundaries.

The linguistic features used in previous research can be classified into three cate-gories: morphological, syntactic, and phonological length features. Morphological fea-tures include part-of-speech tags and morpheme identities around candidate bound-aries [Yoon 2006], while syntactic features extracted from the parse tree include phrase labels, the size of phrases, the number of nodes dominated by phrases, and parse depth [Read and Cox 2007]. Phonological length features include the length of words, dis-tance from punctuation marks, distance from the beginning and end of the sentence, and distance from the last prosodic boundary [Wang and Hirschberg 1992]. All of these linguistic features have been successfully employed in machine learning algorithms, and their usefulness has been demonstrated. Some of these features were used in the research presented in this article; they are summarized in Table III. In addition to the linguistic features that have been used in previous research, this ar-ticle proposes a method for incorporating new features to improve performance. Among these new features, forward distance (e.g., distance to the following phrase boundary: DWF and DSF in Table IV) can only be calculated from the future prediction of phrase breaks, and the existing one-step prediction models cannot handle such a case. By us-ing a stacking model, an effective method of incorporating new features along with those used in previous research will be proposed. The detailed experimental results will show the utility of the forward distance features and justify the use of the stacking model.

New machine-learning features based on Korean linguistic knowledge will be in-troduced to the prosodic phrasing: syntactic features (K4, K4A, PCTY, and PDCN in Table IV) and phonological length features (DWF and DSF in Table IV). The syntactic features are designed to model the Phrasal Compound factor (Section 1.1.5) and the Syntactic Constraint factor (Section 1.1.6). The phonological length features are de-signed to model the Phonological Weight factor (Section 1.1.2). Their contribution to prosodic phrasing will be presented in the detailed experimental results.

A single reference corpus that is annotated by one speaker may include speaker-dependent variability that arises from subjective factors as well as from differences in the individual X  X  phrasing performance. However, in designing a general purpose speech synthesis system, it is important to model the general attributes without speaker-dependent variability so that high agreement can be achieved between differ-ent speakers. This article proposes a model to improve such agreement by extracting common features from multiple annotations.

There are some existing corpora for directly comparing phrasing models; these in-clude the MARSEC corpus [Roach et al. 1993] and the Boston University radio news corpus [Ostendorf et al. 1995]. So far, however, there is no freely available Korean cor-pus for comparative research. In previous experimental work, in-house corpora have typically been used; as a result, a direct comparison between the proposed methods is nearly impossible. Thus, the corpus used in this research has been made open for re-search purposes 4 . The corpus used in this article has been manually labeled and is the largest of any corpora used to date in research on the Korean language. Additionally, the size of this corpus (  X  50K words) is comparable to the MARSEC (  X  40K words) and Boston University radio news (  X  30K words) corpora for the English language. The corpus used in this research is a transcription of the SynthFemale01 speech database 5 , which is a read-style speech corpus for prosody synthesis. One professional female announcer recorded 4,392 sentences (55,015 words, 13 words per sentence on average); each sentence is phonetically balanced with respect to triphones. The size of the corpus, as well as the average length of its sentences, is comparable with the size and sentence length of corpora used in previous work 6 . Note that major breaks may not appear in shorter sentences and that syntactic analysis for feature extraction often fails for longer sentences. One unusual feature of the corpus used in this work is that the sentences do not contain punctuation marks; thus, certain features such as the distance to a previous comma cannot be used. 2.1.1. Annotation. Seven annotators were hired to build a training corpus for a phras-ing model. All the annotators were undergraduate students aged 20 to 25 and were native Seoul (standard) Korean male speakers. The transcription was provided to the annotators individually. Before annotation began, the aim of the annotation and the related linguistic background were sufficiently explained. The following instructions were also given and emphasized.  X  As an annotator utters the given transcription, junctures should be marked with one of the three types of labels (non-breaks, minor breaks, and major breaks) according to the strength of breaks in the phrasing.  X  The transcription should be uttered at a normal rate to minimize Speech Rate-related variations. (A sentence can be differently phrased when it is spoken at a faster or a slower rate.)  X  The transcription should be uttered with a neutral focus to minimize Focus-related variations. (Focus raised by the speaker X  X  personal intentions can cause variability in phrasing.)
Of six factors known to affect prosodic phrasing, only the general attribute-related factors should have been reflected in the annotated corpora. However, because speaker-dependent variability was not entirely eliminated, each annotated corpus has different characteristics (Figure 3). 2.1.2. Reducing Speaker-Dependent Variability. By using data from many different speak-ers, speaker-dependent variability can be reduced. This technique has been widely used in speech recognition to capture common acoustic features and can be adapted to capture the general attributes of prosodic phrasing. Thus, a merged reference was created by merging the labeled corpora from the seven annotators, as described in the following procedure. (1) Given a set of phrased sentences, find the phrase boundaries with which all annota-(2) For each chunk between the phrase boundaries found, (3) Return a reference sentence in which the chosen patterns are employed.
The process of creating a reference sentence containing the dominant pattern of in-tonational phrasing is illustrated in Figure 4. This process can be applied in a similar way to find the dominant pattern of accentual phrasing. When merging annotations, most chunks were analogously or equally phrased by the seven annotators (Table I); however, the data shows that the agreement of intonational phrasing is relatively lower than that of accentual phrasing.

The proposed method is a chunk-level majority rule because a word-level majority rule works inappropriately in some cases. For example, in a case in which a sequence of words ABCD is labeled to (A)(BCD), (AB)(CD), and (ABC)(D) by three different anno-tators, the proposed method will select one pattern among the candidates. In contrast, the word-level majority rule will generate the pattern (ABCD) because the majority for each word boundary is non-break, which is not on the candidate list.

The agreement between each individual X  X  annotation and the merged reference was measured using Cohen X  X  kappa coefficient [Cohen 1960] (Table II). The kappa coef-ficients reflecting the agreement between the merged reference and the individual annotations are higher than the kappa coefficients for different individual annota-tions except for the pairs DIH-KST and KMK-YUI (the values indicating the highest agreement for each individual annotation are indicated in Table II by bold type). The higher correlation between most of the individual annotations and the merged refer-ence reflects the fact that disagreement caused by speaker-dependent variability was reduced by employing dominant patterns. Note that the distribution of labels for LSH, for whom agreement with others X  annotations is low, is also much different from that of the others (Figure 3). The small proportion of non-breaks shows that LSH spoke at a slower rate than did the other annotators. The linguistic feature variables used to train a phrasing model are summarized in Tables III and IV. These two tables respectively present the linguistic features used in previous research and the new features used in this research. The tables also include motivation and mutual information I 7 . Note that the mutual information term measures how much knowing one variable reduces uncertainty about the other. If two variables are independent, knowing one variable does not give any additional infor-mation (zero mutual information); such feature variables do not have discriminative ability. The mutual information was calculated on the training set (Section 3.1).
Analysis of morphological features was performed using the POSTAG/Sejong pro-gram 8 . In Yoon [2006], morpheme identity features were employed to discriminate cer-tain postpositions and endings. However, such features were not used in the current research because the Sejong part-of-speech tagset (Table V) provides subdivided tags for postpositions and endings. For syntactic features, syntactic analysis was performed using the POSPAR/Sejong program 9 . In Read and Cox [2007], several features were investigated for their usefulness in modeling the relationship between syntactic and prosodic tree structures. For Korean prosodic phrasing, the applicable features among this group of features and new features for modeling the general attribute-related fac-tors described in Section 1.1 were employed. For phonological length features, distance information is encoded to model the effect of Phonological Weight (Section 1.1.2). As distance to the phrase boundary from the current juncture increases, the probability of appearance of a phrase boundary also increases [Kim et al. 2006]. The data flow of a stacking model for prosodic phrasing, in which a given sentence is analyzed using morphological and syntactic analyzers, is illustrated in Figure 5. In the first step, the linguistic features are extracted from the sequence of part-of-speech and the parsed tree, and a maximum entropy classifier predicts the labels for every word in the sentence; the predicted labels are a form of phrase break indices, for example, 0 for non-breaks, 1 for minor breaks, and 2 for major breaks. In the second step, the linguistic features are extracted using the labels from the first step and the output of morphological and syntactic analyzers. For example, the phonological length feature DSF (the distance in syllables to the following prosodic boundary) is calculated by counting the number of syllables from the current position to the next nearest phrase break (minor or major break), which can be determined from the label information. Finally, a maximum entropy classifier produces a phrased sentence 10 . The motivation for adopting this stacking model consists mainly of its incorporation of forward distance features. The incorporation of forward distance features requires the future prediction of phrase breaks, which are predicted in the first step. This approach has been successfully applied to sequential partitioning tasks such as document analysis, video segmentation, and gene finding [Cohen and Carvalho 2005]. The merged reference and seven annotations (Section 2.1) were randomly divided into two portions, a training set (80%) and a test set (20%); the statistics of these sets are shown in Table VI. The training set was used to train maximum entropy models of the first and second steps and to adjust model parameters (Gaussian priors) to resolve an over-fitting problem. The test set was used to evaluate a phrasing model. To build maximum entropy models, the Maximum Entropy Toolkit 11 was used. By incorporating linguistic features (MOR: morphological features, SYN: syntactic fea-tures, and LEN: phonological length features), two prosodic phrasing models were trained using the training set and evaluated using the test set (Table VII). For the evaluation measure, F1 -scores for each class (major, minor, and non-breaks) and their mean scores were used. The best-performing setting described in Section 3.3 was used, and the number of bins in which the continuous feature variables were partitioned was set to eight. The results show that morphological features make the greatest contribu-tion to performance, while syntactic and phonological length features also contribute to performance improvement. In particular, the effect of phonological length features is more apparent than that of syntactic features; the difference in performance be-tween  X  X OR+LEN X  and  X  X OR X  is significant, but the difference in performance be-tween  X  X OR+SYN X  and  X  X OR X  is not. However, this does not necessarily mean that the contribution of syntactic features is limited. By combining syntactic and other features, the performance is significantly improved. Note that an experiment using only phonological length features cannot be performed because at least one of the mor-phological and syntactic features is required to train the phrasing model of the first step. 3.3.1. Morphological Feature Engineering. The part-of-speech tagger POSTAG/Sejong uses 33 different tags (Table V). Because this tagset was developed for descriptive use, some tags may not provide useful information for prosodic phrasing; this can re-sult in noise that degrades performance. In Read and Cox [2007], it was shown that the reduced tagset performed better on the studied task. In addition, though part-of-speech tags with longer contexts may provide more discriminative ability, they face a data sparseness problem. In Taylor and Black [1998], it was shown that performance varies according to the setting of the context window. To find the best part-of-speech tagset for prosodic phrasing and the best-performing setting of the context window, the five-fold cross validation technique was applied to the training set.  X  Reducing Part-of-speech Tagset . The goal of the algorithm (Algorithm 1) is to find the best-performing tagset. For each repeat-until iteration, every pair of tags in the tagset is merged (Merge); using the merged tagset, the performance of phrasing is evaluated (Evaluate) from the mean F1 -score (the harmonic mean of precision and recall) for major, minor, and non-breaks. The merged tagset with the best F1 -score is then selected for the next iteration (greedy search). For each iteration, the number of tags in the tagset decreases by one. The iteration repeats until there are no more pairs in the tagset that can be merged. By inserting a condition that causes the procedure to merge only pairs of tags belonging to the same category, which are dis-tinguished by the first letters of the tag labels, linguistically meaningless merging such as merging noun with verb is prevented. Performance was measured by vary-ing the number of part-of-speech tags (Figure 6). The window size was set to four (two tags before and two tags after), and the n -gram features inside the window were used (Figure 7). The result shows that the best performance was obtained by setting 2-gram features using 19 part-of-speech tags (Table VIII). The performance of the 2-gram features was significantly better than that of the 1-gram features ( p &lt; 0 . 01; tails ( d . f . =1 , 140 , 853). The results show that the 2-gram features are sufficient to model the prosodic phrasing, while the 3-gram and 4-gram features are redundant.
Because the 3-gram and 4-gram features used in the training rarely appear in the evaluation, they do not provide discriminative clues but rather adversely affect the performance. In English, the 6-gram part-of-speech features are suitable for mod-eling prosodic phrasing [Taylor and Black 1998]. However, the feature-encoding method for part-of-speech differs in English and Korean. In English, one part-of-speech tag is assigned to each word, but in Korean, multiple part-of-speech tags are assigned since the tags are for morphemes. On average, in this experiment, 2.16 part-of-speech tags were assigned for each word.
  X  Part-of-speech Context Window . In Taylor and Black [1998], a phrasing model that used a 6-gram part-of-speech context window of the previous two tags and the following one tag showed the best performance. To find such a condition, an exhaustive search method was employed. In addition, back-off features were incorporated to resolve the data sparseness problem. For instance, for a phrasing model using a 3-gram part-of-speech sequence window, 1-gram and 2-gram features were also added; this technique was also applied in the experiment for reducing the part-of-speech tagset (Section 3.3). Using the reduced part-of-speech tagset, performance was measured under conditions of different n -gram and context window size (Table IX). The size of window was varied from one to ten, and n -gram (1-to 10-gram) features inside the window were used. When other conditions were the same, 2-gram features outperformed others. The best result was obtained by setting 2-gram features in a window of size four (two tags before and two tags after). 3.3.2. Syntactic Feature Engineering. Because most syntactic features are continuous variables, features in greater numeric ranges can numerically dominate those in smaller numeric ranges. This problem can be avoided by partitioning data, which provides the same effect of value scaling. To partition the data, each value in a dataset was assigned into bins, and each bin received an equal number of data values (quan-tile discretization 12 ). This procedure also alleviates the data sparseness problem. The measured performance varied according to the number of bins used (Figure 8); the best performance was obtained using a setting of eight bins. In cases in which too small number of bins was used, discriminative ability was limited; when the number of bins was too large, the effect of partitioning was reduced. 3.3.3. Phonological Length Feature Engineering. The distance from sentence beginning and end is not very helpful in predicting phrase boundaries because the position of a given phrase boundary is affected by the surrounding phrase boundaries. Therefore, to reflect such a feature, a more helpful parameter is the distance from the previous and the next boundary. However, in the one-step prediction framework, the forward distance cannot be calculated because it requires the future prediction of phrase breaks. In the stacking model, the forward distance can be obtained by referring to the prediction result in the first step. In addition, like the syntactic features, all phonological length features are partitioned into bins in our model.

For modeling the effect of Phonological Weight (Section 1.1.2), the distance from the beginning to the end of the sentence is not sufficient for the prediction of prosodic phrasing ( X  X rimitive phonological length features X  in Table X). In particular, these primitive phonological length features are not suitable for modeling accentual phras-ing; the reduction of F1 -score for the non-break prediction using the primitive phono-logical length features is significantly high. In addition, without using the stacking model, only the distance to the previous phrase boundary can be extracted with the past prediction of phrase breaks. The experimental result ( X  X xcluding following phono-logical length features X  in Table X) shows that excluding information on the distance to the following phrase boundary adversely affects performance; this justifies the use of the stacking model.

The performance improvements for non-break prediction were relatively higher than those for major and minor break predictions (Table X). This is because the phono-logical length features differently influence the performance due to their different dis-criminative ability. The features DWP and DWF were designed to contribute to the intonational phrase boundary prediction. The candidate junctures of the intonational phrase boundary tended to be predicted for major or minor break. In contrast, the features DSP and DSF were designed to contribute to the accentual phrase bound-ary prediction. Candidate junctures of the accentual phrase boundary tended to be predicted for minor or non-breaks. Thus, the lower improvement in major break pre-diction and the higher improvement in non-break prediction indicate that the features DSP and DSF work better than the features DWP and DWF. Also, the mutual informa-tion of the features supports the above statements ( I DSP &gt; I DW P and I DSF &gt; I DWF ;see Table III). Note that higher mutual information provides more discriminative clues.
In Table X, the morphological and syntactic features were used as a basis. That is, the experiments  X  X o phonological length features X  and  X  X roposed phonological length features X  are identical to the experiments  X  X OR+SYN X  and  X  X OR+SYN+LEN X  in Table VII, respectively. In the experiment  X  X rimitive phonological length features X , two features were used: the distance in syllables from the sentence beginning and end; the distance in words from the sentence beginning and end. In the experiment  X  X xcluding following phonological length features X , the distances in syllables and words to the following boundary were excluded. Reducing speaker-dependent variability leads to an increase in inter-speaker agree-ment (Table II); this increase in agreement contributes to phrasing performance (Table XI). For each test set, the phrasing model obtained using the training data from the same speaker performed the best, except in the case of DIH (in Table XI, the highest F1 -scores obtained for each test set are presented in bold type). However, when the speakers for the training data and the test data were different, performance degraded. This is because speaker-dependent variability results in a mismatch between training and test data. On the other hand, the phrasing model trained using the merged reference, in which speaker-dependent variability is reduced, consistently performed well and achieved the best performance on average. Therefore, for a general purpose speech synthesis system, it is better to train the phrasing model using a merged reference made from many different speakers so that higher agreement with the target listener can be achieved.

For reference, the experiments were conducted to compare training with merged reference labels and training with labels from all speakers as a whole. The model trained with merged reference labels outperformed the model trained with the labels from all speakers (Table XI). This is because summing up the labels from all speakers does not contribute to the increase of Cohen X  X  kappa coefficients. Nevertheless, the model that trained with labels from all speakers achieved a comparable result because the machine learning algorithm could capture common features via a larger training dataset. In case that involve more than one dominant phrasing pattern when creating the merged reference, one phrasing pattern is randomly chosen to break the tie (proce-dure 2(b) in Section 2.1.2). In the experiment, the number of random choices was 939 for prosodic phrasing (2.2% of the total number of choices for prosodic phrasing). Such a large number of the random choices affected the final annotation results, and thus the performance of phrasing model was also affected. However, the validity of the proposed method holds (Table XII).

To avoid such random choices, one way to break the tie is by excluding unreliable data from the list of candidates. The reliability of data can be decided by the annota-tion agreement rates (Table II); the lower the agreement rate to the other annotations, the lower the reliability. However, the experimental results show that this heuristic is not beneficial (Table XII). Because either method of prosodic phrasing is possible, how the tie is broken does not considerably affect the performance. The random division of training and test sets slightly affects prosodic phrasing per-formance (Table XIII). However, for all of the results, the difference in performance between  X  X roposed phonological length features X  and the others was statistically sig-nificant. This shows that the experiments for checking the validity of the proposed method were not affected by the data partition. In these experiments, the test sets were mutually exclusive. The total number of experiments was five because the pro-portion of the test set was 20%. Note that  X  X artition #1 X  in Table XIII is the same as in the last column in Table X. The experiments were conducted to determine the contribution of each feature (Tables III and IV) to prosodic phrasing by excluding each feature from all other features (Table XIV). Most of the differences in performance between  X  X ll X  and the other feature sets were statistically significant, but some were not. This is because the number of appearances of such features was relatively smaller than that of the other features, so the effect on overall performance was small. Of all of the features, the morphological feature (POS) had the greatest contribution to prosodic phrasing, followed by the phonological length features (DWP, DSP, DWF, DSF) and the syntactic features (K0, K0A, LPS, PDD, DNW, K4, K4A, PCTY, PDCN). As described in Section 3.3.3, the features that showed a greater improvement in major and minor break pre-diction contributed to the prediction of the intonational phrase boundary (DWP, DWF, K0, LPS, K4, K4A). In contrast, the features that showed a greater improvement in minor and non-break prediction contributed to the prediction of the accentual phrase boundary (DSP, DSF, K0A, PDD, DNW, PCTY, PDCN). The experiments were conducted to compare the performance of the proposed method with the performance of previous methods: classification and regression trees (CART), maximum entropy models (ME), conditional random fields (CRF), and artificial neural networks (ANN). Because future prediction of phrase breaks is not available in pre-vious work, the forward distance features were excluded in these experiments. The experimental results show that the proposed method outperformed the existing meth-ods (Table XV). This is because the forward distance features favorably affect perfor-mance. Using of the stacking model shows promise as a method for incorporating such features.
 This article proposes a stacking model to incorporate phonological length features that require the future prediction of phrase breaks. Because the position of phrase bound-aries is affected by surrounding phrase boundaries, such features favorably affected the performance, resulting in a mean F1 -score improvement of 1.51% (corresponding to 4.81% relative error reduction).

The machine-learning features used in the experiments were adjusted through fea-ture engineering. Instead of using the full set of part-of-speech, an optimal tagset was selected by the greedy search algorithm; the number of tags in the optimal tagset was 19. The best-performing context window of part-of-speech tags was obtained by an exhaustive search; 2-gram features in a window of size four (two tags before and two tags after) outperformed other combinations of window size and n -gram features. The quantile discretization technique was applied to the continuous feature variables to prevent some features from numerically dominating other features; the optimal num-ber of bins to be partitioned was eight.

By merging labeled corpora from many different speakers, a merged reference was built in which speaker-dependent variability is reduced. Due to the increased agree-ment between the merged reference and annotations, the phrasing model trained using the merged reference outperformed the same model trained using individual annota-tions; compared to the second-best result, a mean improvement of 0.58% in the F1 -score (corresponding to 5.64% relative error reduction) was achieved. This leads to the conclusion that the phrasing model trained using the merged reference will achieve the relatively higher agreement with target listeners that is required for a general purpose speech synthesis system.
 With all these new techniques, we could achieve the state-of-the-art performance on Korean prosodic phrasing. The corpora used in the experiments are open to the public so that they can be used for comparative research on Korean prosodic phrasing. These manually labeled corpora, including the merged reference and annotations from seven speakers, have the largest size of any used to date in research on the Korean language.
Although the experiments were conducted using a Korean corpus, the methods and features presented in this article are not limited to the Korean language. Most of the methods and features can be applied to other languages, with the exception of language-dependent features such PCTY in Table IV.

