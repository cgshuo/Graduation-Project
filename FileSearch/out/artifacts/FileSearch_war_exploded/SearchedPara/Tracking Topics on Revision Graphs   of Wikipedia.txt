 articles, and edit articles by others. The edit history of each Wikipedia article is ac-change, finding errors and vandalism, and improving quality of the article. However, present a large and complex edit history with appropriate summarization. node to the destination node. Merges of revisions correspond to confluences of edges. But in real edit histories, such merges are seldom observed. Therefore, we focus on we call by a branch a subtree that is generated by removing the mainstream , which is the unique directed path from the initial revision to the current revision. 
To easily understand how the content of an article has evolved, we may adopt ex-widely used for topic detection. However, the characteristics of Wikipedia revisions, summaries by utilizing supergrams[5], which are consecutive unchanged term se-simple TF/IDF scoring on unigrams. Let us consider a simple idea of adorning edges of the revision graphs by portions of deltas (revision diffs), to recognize the trends of edits. However, this approach creates a flood of texts, or hard-to-read text fragments. We need to find appropriate summari-zation of deltas, such as phrases that capture topics of deltas should be extracted. Del-but smaller deltas are insufficient to find phrases. In this case, we need to extract text surrounding the small delta. 
Now we discuss extracting phrases from deltas, where deltas are taken from a sion. In Figure 1(a), the nodes in the mainst ream are colored in blue. Let us consider a real example of deltas from article  X  X oston Marathon bombings. X  Four deltas from one branch are shown below. Example 1 D1: Explosion on Boylston Street. D2: Two loud explosions on Boylston Street. D3: Friends said explosion o ccurred on Boylston Street. D4: A news report explosion ripped through Boylston Street. edge represents at least one consecutive occurrence of two terms (a bigram) within the contraction is to merge two adjacent nodes such that one node is the sole destination or origin of another node. 
Some term sequences keep appearing throughout all the deltas within a scope. We can group such unchanged consecutive term sequences into supergrams [5]. through X , and  X  X oylston Street X  satisfy the condition of supergrams and grouped into phrases and reflecting unchanged sequences within the scope. scope of a topic appears in the revision graph:  X 
A popular topic is a topic which is most prominent throughout all the revisions.  X 
A surviving topic is a topic that appears in the mainstream and continues to appear until the latest (current) revision.  X  topics may later become extinct if there are deletes in the current revision. topics is effective. Below, we consider three algorithms for summarizing edit deltas in a given scope, by k terms, where k is a given size parameter for summaries. 1. TF-IDF on deltas (Baseline) , which simply merges deltas within the scope and 2. LDA on merged revisions , which applies LDA[1,6] to the merged text of the 3. TF-IDF on supergrams (proposed method) , which applies TF-IDF scoring on 
There are combinations of applying LDA to deltas or supergrams. But these are not performing well, because the sizes of the deltas or supergrams are sometimes insuffi-cient, which causes that the results of LDA become close to TF. To evaluate the quality of topics generated by the algorithms described in Section 2, we conducted human judgment evaluation. We used Wikipedia article  X  X azi Ger-show a part of the summaries, as shown in Table 1. To evaluate the qualities of the summaries, we asked ten volunteers to rank the results. For each scope, each volun-teer compared the outputs of the three algorithms and assigned symbols  X  X  X ,  X  X  X ,  X  X  X  representing quality ranking, meaning that  X  X  X  is the best, and  X  X  X  is the worst. 
As shown in Table 1, the algorithm by TF-IDF on supergrams has the best score, while LDA on revisions is the worst. As we can observe at the summaries of Scopes 1, 2, and 3, the summaries by TF/IDF on supergrams contain meaningful phrases and indicate topics specific to the scopes. On the other hand, the other two methods pro-duce summaries which are fragmented into terms, and often contain topic terms common to most of scopes, such as  X  X ar X  and  X  X ermany", making difficult to capture specific topics of the scopes. We also observed that if deltas in the scope are small, the rankings become split. 
C(Worst) 4 93 3 In this paper, we proposed a method for generating summaries for deltas of Wikipedia revision graphs, to indicate changes in the revision history of Wikipedia articles. Our plan to conduct more extensive evaluations. 
