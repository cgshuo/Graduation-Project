 1. Introduction
Iris recognition has been regarded as one of the most reliable biometric technologies in recent years ( Daugman, 1993,2003a ). The human iris, an annular portion between the pupil and the white sclera (see Fig. 1 ), has an extraordinary structure and provides many minute interlacing characteristics such as freckles, coronas, stripes and the collarette area, which are unique to each subject ( Daugman, 2003b ). An iris-based recognition system can be noninvasive to the subjects since the iris is an internal organ as well as an externally visible organ, and this is of great importance for real-time applications ( Ma et al., 2003, 2004 ). Daugman (1993, 2003a, 2003b) , Boles and Boashash (1998) , Wildes (1997) , Ma et al. (2003, 2004) , and several other researchers proposed different iris recognition algorithms ( Wildes et al., 1996; Schuckers et al., 2007; Bowyer et al., 2008; Daugman 2007; Vatsa et al., 2008; Shah and Ross 2009; Miyazawa et al., 2008; Liu et al., 2005a, 2005b; Monro et al., 2007; Roy and Bhattacharya, 2007, 2008, 2006; Kong and Zhang, 2001, 2003; Sanchez-Avila and Sanchez-Reillo, 2005; Tisse et al., 2002; Yu et al., 2005; Sung et al., 2004; Son et al., 2004; Masek and Kovesi, 2003 ). Iris scans have been used nowadays in several international airports for the rapid processing of passengers who have pre-registered their iris images ( Daugman, 1993,2003a, 2003b ). It has also been used on returning Afghan refugees by the United Nations High Commission for Refugees (UNHCR) at Pakistan X  X fghanistan border ( United Nations Refugee Agency (UNHCR) ). The iris has been known as biometrics for some time. However, it has gained substantial attention to both the research community and governmental organizations recently. Six crucial factors that influenced the increased interest in the iris biometrics are: (1) unique structure of iris; (2) noninvasiveness; (3) stability of iris pattern throughout the person X  X  lifetime; (4) public acceptance; (5) new user-friendly capture devices with broad improved capabilities; and (6) a wide range of applications. As a result, a large number of new iris encoding and processing techniques have been developed over this short period of time ( Schuckers et al., 2007 ). While most of the literature is focused on preprocessing of the ideal iris images, recently, there have been important new directions identified in iris biometric research. These include processing and recognition of  X  X onideal irises X  and  X  X ris at a distance and on the move X  ( Schuckers et al., 2007 ). Table 1 shows the comparison of several existing iris recognition schemes. A detailed survey of the different iris recognition algorithms can be found in Bowyer et al. (2008 ). In this paper, we mainly focus on improving the performance of the iris recognition scheme by accurate iris segmentation, textural features extraction, optimal features subset selection and classification of iris patterns.
 preprocessing of frontal view iris image of an eye, which is achieved through a stop and stare interface in which a user must align his/her optical axis with the camera X  X  optical axis ( Daugman, 2007 ). It is not practical to assume that a user always aligns his/ her optical axis with the camera X  X  optical axis due to the increasing security issues. For iris segmentation, most of the researchers assume that the iris is circular or elliptical. However, in the case of nonideal iris images, which are captured in an uncontrolled environment, iris may appear as noncircular or nonelliptical ( Daugman, 2007; Vatsa et al., 2008 ). Also, the images where the eyes are not properly opened, highly occluded regions cannot be extracted, and thus, the segmentation performance is deteriorated. The iris images may be affected from the deviated gaze, nonlinear deformations, pupil dilation, head rotation, motion blur, reflections, non-uniform intensity, low image contrast, camera angles and diffusion, and presence of eyelids and eyelashes. In this paper, we use the methodologies to account for the nonideal irises to develop a nonideal iris recognition scheme. We propose a two-stage iris segmentation algorithm, in which we first apply the geometric active contours, i.e., the active using the edge-stopping function for the localization of the inner boundary. In the second stage, we evolve the level set curve again towards the outer boundary using the energy minimization algorithm in order to detect the boundary between iris and sclera ( Chan and Vese, 2001; Malladi et al., 1995; Mumford and Shah, 1989; Sethian and Strain 1992; Tsai et al., 2001 ). Prior to applying the curve evolution approach using the active contours, we deploy the direct least square (DLS) elliptical fitting to approximate the pupil and the iris boundaries. Daubechies wavelet transform (DBWT) is applied to elicit the textural features form the unwrapped image, and this approach is appropriate to analyze the signals in multi-resolution mode.

The selection of the most representative features subset from the original features set with a relative high dimension is another important issue in the field of iris recognition ( Deb, 2004; Goldberg, 1989 ). The iris data usually contains a huge number of textural features and a comparatively small number of samples per subject, and thus, it becomes difficult to classify the iris patterns accurately and reliably ( Gu et al., 2005; Oliveira et al., 2002 ). In general, the feature selection scheme is used to select the most important features from the extracted feature sequence of higher dimension. The traditional feature selection schemes (like the principal components analysis, independent components analysis, singular value decomposition , etc.) require sufficient number of samples per subject to select the salient features sequence. However, it is not always realistic to accumulate a large number of samples due to some security reasons. Also, the feature subset selection presents a multi-criterion optimization problem, e.g. number of features and accuracy of the classification in the context of practical applications such as iris recognition. The genetic algorithms (GAs) suggest a particularly attractive approach to solve this kind of problem since they are generally quite effective in rapid global search of large, non-linear and poorly understood spaces ( Gu et al., 2005 ). Furthermore, different feature selection algorithms based on various theoretical arguments may produce different results on the same data set ( Tan et al., 2006 ). This makes selecting the optimal features subset from the original data set difficult. In this paper, we focus on utilization of the useful information obtained from the different feature selection methods to choose the most prominent features subset and also to improve the matching accuracy. Therefore, we propose GAs to select the significant features subset by combining the valuable outcomes from the multiple feature selection criteria, and the proposed approach provides a convenient way of selecting a better feature subset based on the performance of the different feature selection schemes. To evaluate the proposed scheme, support vector machine (SVM)-recursive feature elimination (RFE), k-nearest neighbour (k-NN), T-statistics, and entropy-based methods are used to provide the candidate features for the selection of optimal features subset using GAs. Our experimental results exhibit that the proposed technique of feature selection using GAs performs reasonably well when the sample proportion between two classes is poorly balanced. Moreover, the proposed GA based scheme shows an outstanding performance with respect to the underlying iris datasets that contain high dimensional features set with relatively a lower sample size.

Support vector machines (SVMs) have been used successfully in a number of classification studies due to its outstanding geometrical interpretation of discriminating one class from the other by a separating hyperplane with the maximum margin for the binary case ( Vapnik, 1998 ). In this paper, we apply asymmetrical SVMs to handle two important issues ( Zhang et al., 2005; Ding et al., 2002 ). First issue is the sample ratio bias. Under some conditions, especially in one-versus-rest, the sample proportion between two classes is highly unbalanced. Second issue is that the different types of misclassification errors may have different costs, which lead to different misclassification losses. The asymmetrical SVMs also influence the trade-off between the cases of false accept and false reject . We also deploy an adaptive algorithm to select the feature vectors (FV) from the support vectors (SV) solutions according to vector correlation principle and greedy method, and this scheme successfully overcomes the problem with the huge computation cost incurred by the large number of SV , thereby speeding up the matching process drastically ( Li et al., 2007 ). Therefore, we combine the asymmetrical approach with the adaptive simplification of the solution for SVMs. The proposed adaptive asymmetrical SVMs (AASVMs) approach is well suited for the iris datasets like ICE ( Iris Challenge Evaluation (ICE) ), WVU ( Iris Dataset ), and UBIRIS Version 1 ( UBIRIS ) in which the number of samples per subject is less and not fixed. Furthermore, to improve the generalization performance of the AASVM, we optimize the parameter values using a tuning algorithm.

The rest of this paper is organized as follows. In Section 2, we describe the iris segmentation technique based on level set methods, and also discuss about the noise detection and unwrapping approaches. The textural features extraction algo-rithm using the DBWT is depicted in Section 3. Section 4 describes the feature selection strategy based on GAs, and Section 5 discusses the method of classifying the iris patterns using AASVMs. The experimental results, comparisons with the state-of-the-art algorithms, and discussions are reported in Section 6. Section 7 provides our conclusions. 2. Level set based iris/pupil localization algorithm
The segmentation of the nonideal iris image is a difficult task because of the noncircular/nonelliptical shape of the pupil and the iris ( Shah and Ross, 2009 ). Several researchers proposed different techniques for segmentation. Daugman (1993, 2003a, 2003b) used the integrodifferential operator to segment the iris. Boles and Boashash (1998) applied the edge detection method and other image processing techniques to localize the iris region. Wildes (1997) employed the binary edge map and the Hough transform to detect the iris and pupil boundaries. Ma et al., (2003, 2004) used the Hough transform to detect the inner and outer boundaries of the iris. Miyazawa et al. (2008 ) deployed a deformable iris model to detect the iris boundary. Most of the current iris recognition schemes process the iris images that are captured on-axis. Recently, researchers have focused on proces-sing of nonideal iris images, which are defined as accounting for the off angle, occluded, blurred and noisy images. Previous techniques of the nonideal iris recognition were not adjusted and designed specifically for the nonideal situation ( Schuckers et al., 2007 ). For iris segmentation, most of the researchers assume that iris is circular or elliptical. However, in the case of nonideal iris images such as the images that are affected by the deviated gaze, eyelids and eyelashes occlusion, non-uniform intensity, motion blur, reflections, etc, an iris may appear as noncircular or nonelliptical. Because the inner boundary may be partially occluded by the reflections, and the outer boundary may be partially occluded by the eyelids, it is important to fit the flexible contour that can stand for such disturbances. Another constraint is that inner and outer boundary models must form a closed curve ( Daugman, 2007 ). Recently, several researchers proposed different nonideal iris segmentation methods. In Daug-man (2007 ), inner and outer boundaries were detected in terms of active contours based on the discrete Fourier series expansions of the contour data. Two approaches were proposed in Schuckers et al. (2007 ) where the first approach compensated for the off angle gaze direction, and the second approach used an angular deformation calibration model. In Vatsa et al. (2008) and Shah and
Ross (2009 ), curve evolution approaches were applied based on active contours to segment the nonideal iris images. The segmentation approaches proposed in Daugman (2007) and Shah and Ross (2009 ) take huge computational time as the curve evolves from the previously obtained pupil boundary to the outer boundary. Also, the parametric active contours based iris segmentation scheme may terminate at certain local minima such as the specular reflections, the thick radial fibres in iris or the crypts in ciliary region. The active contours with an edge stopping function as a halting criteria proposed in Vatsa et al. (2008) and
Shah and Ross (2009 ) may fail to detect the outer boundary accurately since iris is separated from the sclera region by relatively a smooth boundary. Addressing the above problems, we propose a two-stage iris segmentation algorithm, in which we first apply the level set based curve evolution approach using the edge stopping function to detect the inner boundary. In the second stage, we evolve the curve based on the level set method towards the outer boundary using the energy minimization algorithm in order to detect the iris boundary ( Chan and Vese, 2001; Malladi et al., 1995; Mumford and Shah, 1989; Sethian and
Strain, 1992 ). Prior to applying the curve evolution approach using the active contours, we deploy direct least square (DLS) elliptical fitting to obtain an initial approximation of the pupil and the iris boundaries. In the following subsections, first, we segment the iris and pupil boundaries from the eye image and then unwrap the localized iris region to a rectangular block of fixed dimension.
 based elliptical fitting to approximate the pupil boundary.
However, the accuracy of the ellipse fitting process degrades in the presence of the outliers such as eyelashes. Therefore, we apply a morphological operation, namely, the opening to an input image to suppress the interference from the eyelashes. DLS based elliptical fitting returns five parameters ( p 1 , p 2, r horizontal and vertical coordinates of the pupil center ( p length of the major and minor axes ( r 1 , r 2 ), and the orientation of the ellipse j 1 . To approximate the outer boundary, we apply the
DLS based elliptical fitting again, and obtain five parameters ( I
R 1 , R 2, j 2 ): the horizontal and vertical coordinates of the iris center ( I 1 , I 2 ), the length of the major and minor axes ( R the orientation of the ellipse j 2 . This method, thus, provides the rough estimation of iris and pupil boundaries. 2.1. Pupil segmentation boundary, we apply the geometric active contours based on the edge stopping function in a narrow band over the estimated inner boundary since the pupillary region is the darkest part of the eye and is separated by relatively a strong gradient from the iris region ( Vatsa et al., 2008 ). A brief discussion of the level set based curve evolution approach is given as follows: image. Let us consider the evolving curve C in O , as the boundary of an open subset o of O . The main idea is to embed this evolving curve as the zero level set of a higher dimensional function f .We can define the following function: f  X  x , y , t  X  0  X  X  7 d  X  1  X  where d denotes the distance form ( x , y )to C at time t  X  0. The plus (minus) sign is selected if the point ( x , y ) is outside (inside) the curve C. Therefore, in the curve evolution approach for pupil segmentation, we need to solve the partial differential equation (PDE) of the following form ( Osher and Sethian, 1988 ): @ f @ t  X  g  X  I  X  S 1 where S 1 is a constant advection term that forces the curve to expand or contract uniformly based on the its sign, S 2 depends on the curve geometry and is used to smooth out the high curvature g ( I ), an edge stopping function which is used to halt the evolution of the curve at the inner boundary, can be defined as g  X  I  X  X  1 where G s ( x , y ) * I ( x , y ) is the convolution of I with the the finite differences scheme proposed in Sethian and Strain (1992 ). To evolve the curve, we perform the discretization and linearization of Eq. (2) ( Malladi et al., 1995; Sethian and Strain, 1992 )
Malladi et al. (1995 ), an upwind scheme is used to estimate s 1 9 r f 9 of (4) and the term s 2 9 r | 9 depends on curvature K ( K  X  div  X  r and can be estimated as where E is a constant. Now, the active contour f 0 is initialized to the approximated pupil boundary, and the optimal estimate of the inner boundary is measured by evolving the initial contour in a narrow band of 7 10 pixels. Fig. 1 (b) shows segmentation of pupil based on the algorithm mentioned above. 2.2. Iris segmentation use Mumford X  X hah segmentation model with the regularization terms ( Chan and Vese, 2001; Mumford and Shah, 1989 ). There-fore, the main objective is to minimize the length of the curve and the area of the region inside the curve. We introduce the following energy function, E : E  X  C , c 1 , c 2  X  X  m evolving curve, c 1 , c 2 are the averages of iris image I inside and outside of C respectively, f denotes the zero level set of the signed distance function representing C as in (1), H is the Heaviside function, and d is the Dirac measure. In (7), the first and the second terms denote the area and length at f  X  0, respectively.
Therefore, the main goal is to estimate the values of C , c that E ( C , c 1 , c 2 ) is minimized. We parameterize the descent direction by t Z 0, and deduce the Euler X  X agrange PDE from (7) which leads the following active contour model: f  X  d  X  f  X  m div r f = r f v l 1  X  I c 1  X  2  X  l 2  X  I c 2
Now, we regularize the Heaviside function H , and the Dirac measure d as in ( Chan and Vese, 2001 ) H  X  f  X  x , y  X  X  X  thus , d  X  f  X  x , y  X  X  X  1 p : E
From (9), we can observe that the evolution scheme has the tendency to measure the global minimizer with the applied regularizations.

By discretizing and linearizing (7), we obtain f
Now, we use the rough estimation of the iris boundary as the initial contour f ,and the curve is evolved in the narrow band of 7 15 pixels to detect the exact outer boundary. Fig. 1 (c) shows the iris segmentation results.

We deploy the eyelids and the eyelashes detection technique as used in our previous work ( Roy and Bhattacharya, 2007, 2008, 2006 ): (1) Eyelids can be approximated as parabolic curves. Therefore, (2) Separable eyelashes are detected using 1D Gabor filter since a
In order to compensate for the elastic deformation in iris texture, we unwrap the extracted (and localized) iris region to a normalized rectangular block of fixed size 64 512 by converting form the Cartesian coordinates to the polar coordinates using a the localized image, then the polar representation of the form I ( r , y ) can be obtained as follows: r  X  y  X  tan 1 y y i x x where r and y are defined with respect to center coordinates ( x , y i ). The center coordinates values obtained during DLS elliptical fitting are used as the center point for the unwrapping procedure. Fig. 2 (d) shows the normalized image. Since the normalized iris image has a relatively low contrast and may have non-uniform intensity values due to the position of the light sources, a local intensity-based histogram equalization technique is applied to enhance the quality of the contrast of the normalized iris image, thereby increasing the subsequent recognition accuracy. In our method, a local cumulative histogram is applied to the image sub-block of size 10 10 centered at the pixel to be converted. Figs. 2 (e) and 3 also show the effect of enhancement on the normalized iris images. 3. Distinctive features set extraction
Different features extraction algorithms have been proposed by several researchers to extract the most distinctive iris features set from the unwrapped image ( Sanchez-Avila and Sanchez-Reillo 2005; Tisse et al., 2002; Yu et al., 2005 ). Daugman (1993, 2003a, 2003b) applied 2D Gabor wavelets to extract the iris features. Boles and Boashash (1998) developed a 1D representation of the gray level profiles of the iris. This representation was followed by obtaining the wavelet transform of the resulting representation and of the original dissimilarity functions. A method for iris matching using zero crossings of 1D discrete cosine transform (DCT) as a means of feature extraction was proposed by Monro et al. (2007) . Ma et al. (2003, 2004) applied the multichannel even-symmetric Gabor wavelets and the multichannel spatial filters to extract the textural features. Wildes (1997) used a Laplacian pyramid to represent the distinctive spatial character-istics of the human iris. Miyazawa et al. (2008) used the phase components of 2D discrete Fourier transform (DFT) of the given images and introduced 2D Fourier phase code (FPC) to represent the iris information. Vatsa et al. (2008) applied 1D log-Gabor filters to extract the textural features and Euler number to elicit the topological features. A SVM based fusion strategy was then deployed to combine the textural and the topological features. Sung et al. (2004) applied the Daubechies wavelet transform to the unwrapped images for textural features extraction. extract the characteristics values from the normalized (and enhanced) image block of size 64 512 pixels, and this technique is well suited for analyzing the signals in multi-resolution mode.
We first divide the normalized image block into four sub images of size 32 256 and then apply the Daubechies four coefficient wavelet transform to each sub image as shown in Fig. 4 . We also conduct our experimentation using Daubechies wavelet function with eight and more coefficients; however, we do not achieve the higher performance than the Daubechies four coefficients wavelet function. Moreover, the feature extraction process using
Daubechies wavelet function with more coefficients increases the computational cost. Fig.5 shows four-level decomposition using DBWT, and in this figure,  X  X  X  and  X  X  X  denote the low and high frequency components, respectively. We transform each image sub-block using Daubechies wavelet in horizontal and vertical directions and divide the image into four regions LL, HL, LH, and
HH after applying the DBWT. We deploy DBWT on the LL region again since this portion represents the most significant iris information. After applying the DBWT repeatedly, the distinctive feature values of the further reduced regions such as HH 2 and HH 4 are obtained. The values of HH 4 of each sub block are considered as the components of the distinctive features vector, and the region HH 4 contains the information of 2 16  X  32 data for each image sub block. The iris information on HH 1 ,HH
HH 3 are also obtained by calculating the mean value of each such region and assigning to one dimension. This procedure is applied for each image sub-block. Therefore, the normalized image is represented by a distinctive features set of (2 16+3) 4  X  140 components. 4. Feature selection using genetic algorithms
The iris data contains a large number of textural features and a comparatively small number of samples per class, and this makes accurate and reliable classification challenging. A few research works has been accomplished in the area of iris features subset selection. Ma et al., (2003) applied the Fisher linear discriminant to reduce the dimensionality of the feature vector. Gu et al. (2005 ) deployed the GAs to select the optimal features with respect to the objectives, namely, the coupling (the distance between iris samples of different classes) and the cohesion (the distance between iris samples in the same class). While most of the traditional feature selection schemes like principal components analysis, independent components analysis, singular value de-composition, etc. require sufficient number of iris samples per class, GA based feature reduction algorithm performs reasonably well despite the unavailability of sufficient number of iris samples per individual. It has also been found that feature selection through GA is a very powerful tool to find a set of good classifiers ( Gu et al., 2005 ). Besides, it can overcome problems such as scaling and sensitivity towards the weights. In this light, we propose a new scheme for selecting the optimal features based on GA. Moreover, several feature selection schemes produce different results on the same data set because of the feature redundancy, interactions and correlations between features, and the biases in the selection or ranking criteria. Therefore, we propose to apply GAs to select the prominent features based on the valuable outcomes of the four feature selection algorithms, namely, the entropy-based approach, k-NN based method, T-statistics and the SVM-RFE approach ( Tan et al., 2006 ). Generally, the feature selection algorithms based on GA can be divided into two categories: the filter approach and the wrapper approach based on whether the selection is performed independently of the learning algorithm, which is used to construct the classifier. If the feature selection is accomplished independently of the learning algorithm, the technique is denoted as the filter approach. Otherwise, it is referred to as the wrapper approach ( Tan et al., 2006 ). In order to obtain the most significant features subset from the different feature selection algorithms, we propose a hybrid approach as shown in Fig. 6 .

In the feature selection scheme, we adopt GAs to combine multiple feature selection criteria to find the optimal subset of informative features. The GAs search the pool of hypotheses (denoted as population) consisting of complex interaction parts. Each hypothesis or individual of the current population is evaluated based on the specific fitness function. A new population is generated by applying genetic operations like selection, mutation and crossover. In this paper, we provide the top-ranked features obtained from the multiple feature selection algorithms to GA instead of using all the features from the original iris features set to form the collection of candidate features called the feature pool .The selection of features subset from these feature selection algorithms can be subjective to their performance. In order to choose the sets of top ranked features, we deploy four existing feature selection algorithms, two filters (entropy-based, T-statistics) approaches and two wrapper (SVM-RFE, k-NN) approaches to form the feature pool. We apply each algorithm to the extracted features sequence and generate a ranking of those features. Given a ranking of features, we pick a number of top ranked features from each algorithm and provide these features to the feature pool of GA. Here, we briefly describe each of the four feature selection algorithms.
In entropy-based method ( Tan et al., 2006 ), entropy is lower for orderly configurations and higher for disorderly configura-tions. Therefore, when an irrelevant feature is eliminated, the entropy is reduced more than that for a relevant feature. This algorithm ranks the features in descending order of the entropies after removing each feature one at a time. We can estimate the entropy measure of a data set of N instances as follows: E  X  where and a  X  ln 0 : 5 = AD
Here d ij denotes the similarity between two instances x i ,
ED ij is the Euclidean distance between the two, and AD is the average distance among the instances. This approach is used for unsupervised data since no class information is required. the genes that are relevant for cancer classification problem. Here, we adopt this approach to find top ranked iris features form the extracted features sequence. The idea is to eliminate one worst feature (i.e., the one that modified the objective function Obj least after being eliminated) at one time. This method is based on backward sequential selection
Obj  X  : w : 2 = 2  X  14  X  w  X  where N s denotes the number of SV that are defined to be the training samples with0 o a i r C . C is the penalty parameter for the error term. x i and y j are the data instance and its class label, respectively. The modification of Obj is approximated by optimal brain damage (OBD) algorithm so that
D Obj  X  i  X  X  X  D w i  X  2  X  16  X  w 2 i is considered as the ranking criteria. The iterative procedure of RFE is given as follows: labeled with {1, 1}The mean, m 1 i ( m 1 i  X  and the standard devia-tion, d 1 i ( d 1 i ) are calculated for the samples labeled as 1( 1) or each feature f i . Then a score T ( f i ) is obtained as follows:
T  X  f i  X  X  m 1 i m 1 i = where n 1 ( n 1 ) denotes the number of samples labeled as 1 ( 1).
In order to make decision, the features with highest scores are considered as the most distinctive features.
 nonparametric feature-subset-selection evaluation is applied. The evaluation technique denoted as  X  X eave-one-out (LOO) X  method has been used. The main idea of LOO method is given as follows ( Roy and Bhattacharya, 2008 ): feature subset. In the genetic process, we present the choice of a representation for encoding the candidate solutions to be manipulated by the genetic algorithms, and each individual in the population represents a candidate solution to the feature subset selection problem. If n be the total number of features available to represent the patterns to be classified, the individual (chromosome) is represented by a binary vector of dimension, n .If a bit is a 1, it means that the corresponding feature is selected; otherwise the feature is not selected. This is the simplest and most straightforward representation scheme (see Fig. 7 ). minimization of the recognition, the false accept, the false reject rates of the feature subset, and also minimization of the size of the features subset selected. In order to smooth out the fitness function so that small improvement in genetic programs could be reflected, we propose the following fitness function based on the nature of the underlying problem
Fitness  X  W 1 :  X  1 RR  X  X  W 2 : FAR  X  W 3 : FRR where W 1 , W 2 , W 3 and W 4 are constant weighting parameters which reflect the relative importance between recognition rate (RR), false accept rate (FAR), false reject rate (FRR) and feature size .
We expect this fitness function would increase both the efficiency and the effectiveness of the evolutionary search. It will also have a tendency to reduce redundancy, making the programs more comprehensible. We employ the asymmetrical SVM as an induction algorithm in the experiments to separate the cases of false accept and false reject ( Roy and Bhattacharya, 2007, 2008 ).
We use the Roulette wheel selection method to probabilistically select the individuals from a population for latter breeding. The probability of selecting an individual, ind i is estimated as P  X  ind i  X  X  F  X  ind i  X  = tional to its own fitness and is inversely proportional to the fitness classifier of the other competing hypothesis in the current population. In this paper, we use single point crossover, and each individual has a probability, P n , to mutate. The number of n bits is randomly selected to be flipped in every mutation stage. Therefore, we can summarize GA based feature selection process as follows:
Step1: Input the extracted features set obtained by DBWT to four feature selection algorithms.

Step 2: Apply each algorithm to the extracted features set, and generate a ranking of those features.

Step 3: Given a ranking of features, pick a number of top ranked features from each algorithm and provide these features to the feature pool of GA.

Step 4: Select the best ranked features using the genetic process based on the proposed fitness function. 5. Iris pattern matching using adaptive asymmetrical SVMs
Most of the researchers applied the Hamming distance for iris pattern matching ( Bowyer et al., 2008 ). Sung et al. (2004) and Son et al. (2004) employed the traditional SVMs for pattern matching. Gu et al. (2005) used the non-symmetrical SVMs to separate the cases of the false accept and the false reject. In ( Roy and Bhattacharya, 2007 ), we used the asymmetrical SVMs in order to control the misclassi-fication errors. In our previous work ( Roy and Bhattacharya, 2008 ), we proposed the adaptive asymmetrical SVMs (AASVMs) to control the poorly balanced sample proportion between classes and also to reduce the matching time of a test sample. In this paper, we apply the SVMs for iris pattern classification due its remarkable general-ization performance as proposed in our previous work ( Roy and Bhattacharya, 2007, 2008, 2006 ). We apply the asymmetrical SVMs to satisfy several security de mands and also to control the statistically under-presented dat a of a class with respect to other classes. We also apply a new scheme to adaptively select the FV from than that of SV , the substitution of FV for SV greatly improves the sparsity of solution and speeds up the matching time when testing a new sample ( Li et al., 2007 ). Therefore, we combine the asymme-trical approach with the adaptive simplification of the solution for SV and denote this combined approach as  X  X ASVMs X . We briefly state our proposed scheme below. 1. In order to reduce the decision time for a new sample, FV is selected adaptively according to vector correlation principle and greedy algorithm ( Li et al., 2007; Roy and Bhattacharya, 2008 ).
We briefly discuss it as follows: Let ( x i , y i ) 1 r i r l the SV and c be the nonlinear mapping function. If c maps the input space of the SV into a feature Hilbert space HS ,weget c : R N -HS , x -c  X  x  X  X  20  X 
Therefore, mapping the SV set in feature space are of the HS with the dimension up to l . The dimension of this subspace is far lower than l and equal to the number of its base vector. If FV approximates the SV accurately, testing on the original SV will be equal to the test on the FV . To simplify the notation, the mapping of x i , c ( x i ) is denoted as c i of FV ). Let us consider the FV set X F  X f x F 1 , x F 2 , ... , x mapping of any vector x i can be expressed by a linear combination of the X F with the following form: c i  X  a T i c F  X  21  X  where c F  X  X  c F
X F  X f x F 1 , x F 2 , ... , x F P g such that the estimated mapping as close as possible to the original mapping c i e  X 
The e denotes the approximation error between the FV set and the original SV set. In order to select the FV , we need to minimize
The feature set fitness e F and the fitness of each vector e Fi corresponding to the given FV set, X F can be defined as follows:
Where
Now, minimization of (23) is eq uivalent to minimizing the following form: min  X  e F  X  X
A greedy iterative algorithm is used to select the FV .Forselecting the first FV , we pick the samples that provide the minimum e each iteration, we use (24) to estimate the performance of the current feature set and (25) is used to select the next best candidate feature vector. When w e obtain the maximal fitness e for the current feature set, we select it as the next feature vector.
When the current feature set fitness reaches the predefined fitness threshold, the algorithm stops. Therefore, the number of
FV can be controlled adaptively as long as the different approximation errors e F are set. 2. In order to control the misclassification error between the positive and negative classes, we separate the empirical risk,
P
C + and C , corresponding to the empirical risk of positive and negative class, respectively ( Roy and Bhattacharya, 2007 ).
Therefore, we get 1 2 where C ( z i )  X  C + if sample i is from positive, and C ( z sample i is from negative. The statistically under-presented data of a class with respect to other classes can be controlled with the variation of penalty parameter ration, C + and C .
Therefore, it can be inferred that higher the C ( z i ), more the penalty is required to reduce the misclassification error. Here, we consider the cost and asymmetry of samples. 5.1. Tuning of SVMs parameters
It is important to improve the generalization performance by adjusting the ratio of penalty parameter (i. e., the ratio of C C ) for the error term by adjusting the kernel parameters. A careful selection of a training subset and of a validation set with a small number of classes is required to avoid training the SVMs with all classes and to evaluate its performance on the validation set due to its high computational cost when the number of classes is higher. In this paper, the optimal parameter values are selected to tune the SVMs. A modified approach proposed in Dong et al. (2005 ) is applied here to reduce the cost of the selection procedure as well as to adjust the parameters of the SVMs. After assigning the class label to the training data, we divide 70% of the training data of each class depending on the dataset used for training, and the rest of the training data is used for validation.
Here, the Fisher least square linear classifier is used with a low computation cost for each class ( Duda et al., 2001 ). The performance of this linear classifier is evaluated on the validation set, and the confusion matrix, CM is defined as follows:
CM  X  where each row i corresponds to the class w i , and each column j represents the number of classes classified to w j . The number of misclassified iris patterns is estimated for each class as follows: err i  X  1 , 2 , ... , n calculated from (29) in decreasing order, and the sub-scripts i 1 , i 2 , ... , i I are assigned to the top I choices assuming that I { N . Now, we determine the number of classes whose patterns can be classified to the class set f w i 1 , w i on the following confusion matrix:
V  X  [ I validation set to tune the ratio of the penalty parameter and the kernel parameters for the SVMs. After a careful selection of the ratio of C + and C and the kernel parameters, the whole training set with all classes are trained. 6. Experimental results and discussions performance of the proposed scheme and summarize the results.
We describe the datasets that are used to evaluate the performance of the proposed scheme. Our exper imentation is conducted in two stages: first, we evaluate the performance of our proposed algorithms with respect to segmentation, feature extraction, feature selection, and pattern matching, and second, we compare the performance of our method with those of the other state-of-the-art algorithms to show the effectiveness of the proposed scheme.
Extensive experiments on different nonideal ir is image datasets are conducted to evaluate the performance in two modes: verification (one-to-one) and identification (on e-to-many). In verification mode, we measure the performance in terms of genuine accept rate ( GAR ), false accept rate ( FAR ), and equal error rate (EER) with the assumption that a test sample is from a specific subject. In identification mode, we make a one-to-many search in th e entire dataset for a given test sample to find the highest matched template with that test sample ( Masek and Kovesi, 2003 ). Thus, in identification, we use the measure correct recognition rate ( CRR ), which is defined as follows:
CRR  X  Correctly recognized user number Total number of users enrolled 6.1. Datasets used namely, ICE 2005 ( Iris Challenge Evaluation (ICE) ), WVU ( Iris
Dataset ), and UBIRIS Version 1 ( UBIRIS ). We have selected the aforementioned datasets for performance evaluation since these datasets contain nonideal iris images including off angle, occluded, blurred and noisy images that are acquired with different devices under varying conditions to facilitate a compre-hensive performance evaluation in a real word applications level scenario. These datasets also represent different ethnicity ( Vatsa et al., 2008 ).
 6.2. Performance evaluation of the proposed scheme use the three datasets mentioned above. We select a common set of curve evolution parameters values based on level set approach to segment the nonideal iris images accurately. To detect the inner boundary with the edge stopping function, the selected parameters values are D t  X  0.05 and E  X  0 : 015. The selected parameters values to find the outer boundary using energy minimization algorithm are m  X  0 : 00001 , v  X  0 : 02 , l
D t  X  0 : 1 and E  X  1. Fig. 8 shows the segmentation results on the three datasets, and we find form this figure that our segmentation scheme performs well despite the fact that the iris and the sclera regions are separated by a blurred boundary especially in the
WVU and UBIRIS datasets. In order to exhibit the effectiveness of our segmentation approach, we compare the our level set algorithm (LS) with integro-differential operator (IDO) proposed by Daugman (1993) , the Canny edge detection and
Hough transform (CHT) based approach applied in our previous work ( Roy and Bhattacharya, 2007, 2008 ), and the active contour based localization approaches proposed by Vatsa et al. (2008) and
Shah and Ross (2009) on all the datasets. For comparison purpose, we only implement the segmentation approaches proposed in Daugman (1993) , Vatsa et al. (2008) and Shah and Ross (2009 ), and for feature extraction and matching, we apply our proposed algorithms to each of those schemes. However, we do not use feature reduction algorithm for this purpose. ROC curves in Fig. 9 show that the matching performance is improved when the geometric active contours are used for segmentation with edge stopping function and energy minimization algorithm. The pro-posed segmentation scheme shows better performance than the active contour based methods reported by Vatsa et al. (2008) and Shah and Ross (2009) since our level set based segmentation approach uses an energy minimization algorithm for outer boundary detection. Moreover, a morphological operation is applied to an input image to restrain the interference from the eyelashes prior to deploying the DLS based elliptical fitting. The DLS fitting approach provides a reasonable approximation of 70 75 80 85 90 95 100 Genuine Accept Rate (%) 80 82 84 86 88 90 92 94 96 98 100 Genuine Accept Rate (%)
Genuine Accept Rate (%) Genuine Accept Rate (%) the inner and the outer boundaries. Furthermore, the level set curve is evolved over a narrowband and, this process, thus, reduces the segmentation time. The GAR at a fixed FAR of 0.001% is (a) 96.20% in WVU, (b) 98.10% in ICE, and (c) 97.05% in UBIRIS datasets. The GAR on the combined dataset at the fixed FAR of 0.001% is 97.21%. However, the proposed level set based segmentation algorithm fails to perform on some images of
UBIRIS dataset due to huge occlusion as shown in Fig. 10 . Fig. 11 also exhibits that the DLS elliptical fitting strategy fails to detect the outer boundary accurately; however, it provides an initial estimate of the inner and outer boundaries for the final segmentation using level set approach.

Table 2 shows the performance of different kernel functions on the combined dataset. This table exhibits that the highest accuracy is obtained by using the RBF kernel, and thus, this kernel is used in our system for pattern matching with AASVMs.
We also tune the parameter values of AASVMs to improve the generalization performance. In order to reduce the computational cost and to speed up the classification process, the Fisher least square linear classifier is used as a low-cost pre-classifier so that reasonable cumulative recognition accuracy can be achieved to include a true class label for a small number of selected candidates. For the ICE dataset, we first apply the Fisher least square linear classifier to choose ten candidates ( Dong et al., 2005 ). The cumulative recognition accuracy at rank 10 is 98.93%.
The selected cardinal number of sets found from the experi-mentation is 32 by using the tuning algorithm for SVM parameter selection (refer to Section 5.1). As a result, the sizes of the training and validation sets for selecting the optimal values of the ratio of
C + and C and s 2 , are 112(  X  32 5 0.7) and 48(  X  32 5 0.3), respectively. The parameter s 2 is set at 0.6 and the ratio of C
C is set at 18 when the highest accuracy on the validation set is achieved through the RBF kernels for the ICE iris dataset. In this paper, we consider only those classes of the ICE database that have at least 5 probe images in order to select the optimal parameter values. The SVM parameters are also tuned for the WVU iris dataset. Twenty candidates are selected by using the
Fisher least square linear classifier. The cumulative recognition accuracy found at rank 20 is 98.50%. The cardinal number of sets obtained for this dataset is 60. Therefore, the sizes of the training and validation sets for selecting the optimal values of the ratio of penalty parameter and s 2 are 168 (  X  60 4 0.7) and 72 (  X  60 4 0.3), respectively. Finally, the ratio of C + and C is set at 21, and the optimal value of s 2 remains the same as obtained for the ICE dataset. For the WVU iris dataset, only those iris classes that have at least four images are considered. For the UBIRIS dataset, the Fisher least square linear classifier is applied to choose twenty two candidates ( Dong et al., 2005 ). The cumulative recognition accuracy at rank 22 is 99.13%. We select the 40 cardinal sets, and therefore, the sizes of the training and validation sets are 140(  X  40 5 0.7) and 60(  X  40 5 0.3), respectively. The parameter s 2 is set at 0.8 and the ratio of C and C is set at 25. We consider five samples randomly from each class, two irises from the session 1 and three from the session 2, to select the sizes of training and validation sets. For the combined dataset, we also tune the SVM parameter values. Sixty candidates are chosen by using the Fisher least square linear classifier, and the cumulative recognition accuracy at rank 60 is 98.23%. The cardinal number of sets obtained for this dataset is 150. Therefore, the sizes of the training and validation sets for selecting the optimal values of the penalty parameter ratio and s 2 are 420(  X  150 4 0.7) and 180(  X  150 4 0.3), respectively. Based on the training and validation sets obtained for the combined dataset, we select a common set of parameter values and finally, the ratio of C + and C is set at 20, and the optimal value of s 2 is set at 0.65. We summarize these results in Table 3 .
From Fig. 12 , it is observed that when the ratio is below 18, with the increase of the ratio, the error rate is decreased for ICE dataset, which indicates that the ill effect of sample bias is improved. When the ratio is around 18, the best performance is achieved. However, the over-tuning may reduce the accuracy. Similarly, for WVU and UBIRIS datasets, we find that the best classification accuracy is achieved when the ratio is around 21 and 25, respectively. For the combined dataset, the highest accuracy is achieved at the ratio of 20. In reality, it is found that the exact value of penalty parameter also affects the classifier X  X  performance. Fig. 13 shows the comparison of the performance between the traditional SVMs and asymmetrical SVMs with the exact value and the ratio of the penalty parameters. Here, the ratio of C + and C remains the same as obtained previously from Fig. 12 for all the datasets. From Fig. 13 , with the ratio of C C , the performance is low except the cases when the C is small, which indicates that it is the ratio not the exact value that influences the classifier. Therefore, we find asymmetrical SVMs performs relatively well compared with the traditional SVMs. We observe form the above experimentation that the decrease of error rate by counteracting the sample bias is higher than the increase of error rate by the inherent cost relative property of AASVMs. Moreover, the application of AASVMs make the authentication system more configurable, which means that the proper selection of the ratio of C + and C can influence the tradeoff between the cases of false accept and false reject [51]. The application of AASVMs also reduces the matching time of a test sample drastically. Table 4 summarizes the recognition results, and it is found from this table that a drastic reduction of decision time can be achieved when the number of SV is lower. However, the selection of the matching accuracy/testing time is a security requirement trade-off. The selected accuracy with decision time, simplification rate and number of FV is shown in the bold form in Table 4 for the combined dataset.

The proposed GA based feature selection approach is used to reduce the feature dimension without compromising the recogni-tion rate based on the multiple outcomes of four feature selection algorithms. Since the number of samples from most iris research is limited, cross-validation procedure is commonly used to evaluate the performance of a classifier. In k -fold cross validation, the data are divided into k subsets of (approximately) equal size. We train the classifier k times, each time leaving out one of the subsets from training, but using only the omitted subset to compute the classification accuracy. Leave-one-out cross-valida-tion (LOOCV) is a special case of k -fold cross-validation where k equals the sample size. LOOCV is used for ICE dataset, and for
WVU and UBIRIS datasets, we use threefold cross validation to obtain the training accuracy for GAs. Fig. 14 shows the accuracy of
Accuracy (%) Accuracy (%) Cross Validation Accuracy (%) Cross Validation Accuracy (%) the selected feature subsets with a different number of top-ranked features from the four feature selection algorithms on three data sets. Fig. 14 demonstrates the performance of four feature selection algorithms for the first 130 top ranked features. Fig.14 (a) shows that SVM-RFE achieves the better accuracy than the other feature selection methods. In Fig. 14 (b), entropy based approach performs well on WVU dataset whereas the SVM-RFE achieves the better accuracy on the UBIRS dataset as shown in Fig. 14 (c). For the combined dataset, we can see that SVM-RFE finds the better accuracy than the other the algorithms with the 130-top ranked features. Therefore, after obtaining the 130 top-ranked features form different feature reduction algorithms, we input them to the feature pool used by the GAs as demonstrated previously in Fig. 6 . In order to select the optimal features for the improvement of the matching accuracy, GAs involve running the genetic process for several generations as shown in Fig. 15 with different values of weighting parameters in the proposed fitness function. We conduct several experimentations, and select a common set of arguments for the GAs as shown in Table 5 . However, the performance degrades slightly for the common set of parameter values on the combined dataset due to the variations in image contrast and capturing devices, and to the differences in sample population in the three datasets. The parameter values are obtained by using the existing heuristics in genetic process (GP) plus some minor effort on empirical search via experiments. The learning/evolutionary process is run for a fixed number ( max-generations ) of generations, 60 unless it finds a program that solves the problem perfectly (100% detection rate), or there is no increase in the fitness for 10 generations at which point the evolution is terminated early. From experimentation, we find that the proposed GA scheme achieves the highest accuracy of 97.33% at the generation 46 with reduced features subset of 105 for the combined dataset. ROC curves in Fig. 16 demonstrate that the proposed approach reduces the FAR when we apply the GA based hybrid feature selection algorithm. We conducted the above experimentation on a 3.00 GHz Pentium IV PC with 2.5 GB RAM in MATLAB 7.2 environment. The average time consumption of matching an iris image is 958 ms as exhibited in Table 6 . 6.1. Comparison with the other state-of-the-art algorithms
We compare the performance of the proposed algorithm with the other existing iris recognition algorithms. We implement the well known iris recognition algorithms proposed by Daugman (1993) and Ma et al. (2003, 2004) , and compare our approach with those methods on the combined dataset. Fig. 17 exhibits the ROC curves of the proposed algorithms with the level set curve evolution approach on the non-homogeneous combined dataset. ROC curves of the approaches demonstrated in Daugman (1993) and Ma et al. (2003, 2004 ) are also plotted for comparison, and it is observed from this figure that the proposed algorithm achieves higher GAR with a very low EER of 0.48% for the combined dataset. It means that the proposed algorithm achieves higher discriminating capabilities than the approaches proposed in Daugman (1993) and Ma et al. (2003, 2004 ). Moreover, the approaches proposed in Daugman (1993) and Ma et al. (2003, 2004 ) were not adjusted specifically for the nonideal situation. The proposed approach based on the level set curve evolution with edge stopping function and energy minimization algorithm obtains a higher GAR of 97.29% at the fixed FAR of 0.001% on the combined dataset that contains the iris images with the irregularities due to motion blur, off angle gaze, diffusion, and other real-world problems. Therefore, ROC curves in Fig. 17 reveal the effectiveness of the proposed scheme in a nonideal situation.
One of the difficulties which is common to any dataset is the segmentation error. The segmentation approach described in Section 2 works well for most of the cases even with the iris images of deviated gaze. The DLS elliptical fitting provides an initial estimate of the inner and outer boundaries, and the level set based curve evolution approach localizes the iris and pupil region accurately based on that initial estimate.
 In Table 7 , the proposed scheme exhibits the highest CRR for ICE, WVU and UBIRIS datasets. For the combined dataset, we find the CRR of 97.41% which reveals a top class performance with respect to the nonideal datasets under consideration. The EER of the proposed approach is 0.47% on the combined dataset which is encouraging. Moreover, the length of the feature vector is only 105, which is much lower than the feature vector lengths reported in the other existing iris recognition algorithms, thereby, reducing the computational complexities without compromising the recognition rate. 6.2. Discussions following points: Genuine Accept Rate (%) Genuine Accept Rate (%) Genuine Accept Rate (%) 7. Conclusions
The accurate segmentation of the iris plays an important role in iris recognition. In this paper, we present a nonideal iris segmentation scheme using the level set based curve evolution approaches with the edge stopping function and energy mini-mization method. The characteristics features are extracted using the Daubechies wavelets, and GAs are used to find the subset of informative texture features. The proposed GA incorporates four feature selection criterions, namely, the SVM-RFE, the k-NN, the T -statistics, and the entropy-based methods to find the subset of informative texture features that can improve the analysis of iris data. The experimental results show that the proposed method is capable of finding feature subsets with better classification accuracy and/or smaller size than each single individual feature selection algorithm does. In order to increase the feasibility of the SVMs in biometric applications, the SVMs are modified to asymmetrical SVMs. The adopted simplification scheme of solution for the SV also captures the structure of the feature space by approximating a basis of the SV solutions; therefore, the statistical information of the solutions for the SV is preserved. Furthermore, the number of FV is selected adaptively according to the task X  X  need to control the generalization/complexity trade-off directly. We validate the proposed iris recognition scheme on the ICE, the WVU, the UBIRIS, and the nonhomogeneous combined datasets with an encouraging performance.
 Acknowledgements
We have used the iris dataset  X  X  X ris Challenge Evaluation X  X  (ICE) ( Iris Challenge Evaluation (ICE )) owned by the University of Notre Dame, USA. We have also used the WVU ( Iris Dataset ) and the UBIRIS Version 1 ( UBIRIS ) datasets owned by the West Virginia University, USA and the department of computer science, University of Beira Interior, Portugal, respectively. A modified LIBSVM (Library for Support Vector Machines) tool ( Chang and Lin, 2000 ) has been used for iris classification in this paper. This work is funded by NSERC, Canada and Concordia Institute for Information Systems Engineering (CIISE), Concordia University, Canada.
 References 10
