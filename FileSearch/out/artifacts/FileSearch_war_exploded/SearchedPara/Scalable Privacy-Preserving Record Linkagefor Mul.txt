 Privacy-preserving record linkage (PPRL) is the process of identifying records that correspond to the same real-world entities across several databases without revealing any sen-sitive information about these entities. Various techniques have been developed to tackle the problem of PPRL, with the majority of them only considering linking two databases. However, in many real-world applications data from more than two sources need to be linked. In this paper we con-sider the problem of linking data from three or more sources in an efficient and secure way. We propose a protocol that combines the use of Bloom filters, secure summation, and Dice coefficient similarity calculation with the aim to iden-tify all records held by the different data sources that have a similarity above a certain threshold. Our protocol is se-cure in that no party learns any sensitive information about the other parties X  data, but all parties learn which of their records have a high similarity with records held by the other parties. We evaluate our protocol on a large dataset showing the scalability, linkage quality, and privacy of our protocol. H2.7 [ Database Management ]: Database Administration-Security, integrity, and protection Algorithms, Experimentation, Security Record linkage; privacy; security; Bloom filter; multi-party.
Linking records from different databases with the aim to improve data quality or enrich data for further analysis and  X 
Funded by the Australian Research Council under Discov-ery Project DP130101801.
 mining is occurring in an increasing number of application areas including healthcare, government services, crime and fraud detection, and business applications [1]. The anal-ysis of data linked across organizations can, for example, facilitate the detection of infectious diseases early before they spread widely around a country or worldwide, or en-able the accurate identification of fraud, crime, or terrorism suspects [13]. These applications require data from several organizations, such as human health data, consumed drug data, and animal health data for the first of the above ex-amples [3]; while the second above example requires data from law enforcement agencies, Internet service providers, the police, as well as financial institutions.

Today, record linkage not only faces computational chal-lenges due to the increasing size of datasets and quality chal-lenges due to the presence of real-world data errors, but also privacy and confidentiality challenges due to growing pri-vacy concerns by the public. In the absence of unique entity identifiers in the databases that are linked, personal iden-tifying attributes (such as names, addresses, gender, and dates of birth) need to be used for the linkage. Known as quasi-identifiers (QIDs) [12], values in such attributes are in general sufficiently well correlated with entities to allow accurate linkage. Using such personal information however often leads to privacy and confidentiality concerns.
The privacy challenges posed in the record linkage process led to the development of techniques that facilitate  X  X rivacy-preserving record linkage X  (PPRL) [13]. PPRL tackles the problem of how to identify records that refer to the same en-tities in different databases such that only masked (encoded) QIDs have to be revealed. Generally, the original data are transformed (using some encoding function) such that a spe-cific functional relationship exists between the original and the masked data [12], without compromising the privacy and confidentiality of the entities represented by these data.
Many different approaches have been proposed for PPRL [13], but most of these are limited to linking data from two sources. As the example applications described above have shown, linking data from several sources is however com-monly required. We propose an efficient solution for PPRL across multiple parties. While existing multi-party PPRL techniques[5,7,8,9,10]eitherperformonlyexactmatch-ing or use computationally expensive privacy techniques, the novelty of our solution is that it supports approximate matching based on two efficient privacy techniques: Bloom filters [11] and secure summation [6]. We conduct an empir-ical study on a large real dataset to validate the scalability, linkage quality, and privacy of our solution. Various techniques have been developed to address the PPRL research problem [13], but few among these have con-sidered PPRL on multiple databases. The first approach to PPRL [10] links multiple databases by comparing the hash-encoded values (using one-way secure hash algorithms) from all data sources by using a third party. However, this ap-proach only performs exact matching (i.e. a single varia-tion in a QID results in a completely different hash-encoded value). A secure equi-join protocol for multiple database ta-bles was proposed in [5] for exact matching, and a secure multi-party computation based approach using an oblivious transfer protocol was presented in [9] for PPRL on multi-ple databases. While provably secure, the approach is com-putationally expensive compared to perturbation-based pri-vacy techniques. Recently, a multi-party PPRL approach for approximate matching of categorical values based on k-anonymity and game-theoretic concepts was proposed [8].
An efficient multi-party PPRL approach for exact match-ing using Bloom filters was introduced by Lai et al. [7]. In this approach, database values are first converted into a Bloom filter bit array. Each party then partitions its Bloom filter into segments according to the number of parties in-volved in the linkage, and sends these segments to the cor-responding other parties. The segments received by a party are combined using a conjunction (logical AND) operation. The resulting combined Bloom filter segments are then ex-changed between the parties. Each party checks its own full Bloom filter with the final result, and if the membership test is successful then the value is considered to be a match. Though the cost of this approach is low since the computa-tion is completely distributed between the parties and the processing of Bloom filters is very fast, the approach can only perform exact matching. As we describe next, we use Lai et al. X  X  [7] multi-party Bloom filter based approach as a building block for our approximate matching solution.
We now describe our approach to securely and efficiently link databases from three or more parties. We use the fol-lowing notation: P is the number of parties involved in our protocol, where each party p i holds a database D i containing sensitive or confidential identifying information. Database D i contains N i = | D i | records. We assume a set of QID attributes A , which will be used for the linkage, is common to all these databases. Our protocol will calculate the sim-ilarity between sets of records using the values in A .We next describe the building blocks of our protocol, then ex-plain each of the steps in our protocol, and finally analyze the complexity and privacy characteristics of our protocol.
Bloom filter encoding: ABloomfilter b i is a bit array data structure of length l bits where all bits are initially set to 0. k independent hash functions, h 1 ,h 2 ,...,h k with range 1 ,...l , are used to map each of the elements in aset S into the Bloom filter by setting k corresponding bit positions to 1. Bloom filters are one efficient perturbation-based privacy technique that has successfully been used in several privacy-preserving solutions [4, 11, 12].
Schnell et al. [11] were the first to propose a method for ap-proximate matching in PPRL of two databases using Bloom Figure 1: Dice similarity calculation of three Bloom filters (BFs) across three parties. Rows illustrate the BFs generated by the three parties, while columns show which party holds which BF segments. filters. In their work, as in our protocol, the q -grams (sub-strings of length q ) of attribute values in A of each record in the databases to be linked are hash-mapped into Bloom filters using k independent hash functions. The Bloom fil-ters are then sent to a third party that calculates the Dice coefficient [1] similarity of pairs of Bloom filters.
Dice coefficient: Any set-based similarity function can be used to calculate the similarity of pairs or sets of Bloom filters. The Dice coefficient has been used for matching of Bloom filters, since it is insensitive to many matching zeros in long Bloom filters [11]. We calculate the Dice coefficient similarity of P Bloom filters b 1 ,  X  X  X  ,b P as: where c is the number of common bit positions that are set to 1 in all P Bloom filters (common 1-bits), and x i is the number of bit positions set to 1 in b i (1-bits), 1  X  i  X 
Multi-party Bloom filter matching: In our protocol the calculation of the number of common 1-bits ( c )isdis-tributed among the parties, such that c = P i =1 c i .Bloom filters are split into P segments and each party sends its segments to the corresponding other parties. The parties then individually calculate the number of common 1-bits c in their respective segments of the Bloom filters they receive from the other parties for all sets of records. As example, the distributed Dice coefficient calculation of three Bloom filters from three parties is illustrated in Figure 1.
Secure summation: Once each of the P parties has a secure summation protocol [6] can be applied to calculate calculate the Dice similarity of a set of Bloom filters). This protocol uses two vectors R c and R x (of length equal to the number of sets) of large random numbers (values larger than l ) to hide the actual sensitive values c i and x i , and employs a ring-based communication pattern over all parties which allows each party to learn the final values ( c and x ) but no party to learn the sensitive values of the other parties.
We divide the steps of our protocol into three phases: (1) data preparation, (2) distributed matching, and (3) similar-ity calculation. In the initial data preparation phase, 1. the parties agree upon a bit array length l ; k hash-2. each party p i individually applies a private blocking 3. each party p i hash-maps the q -gram values of A of each In the distributed matching phase, for all records and their Bloom filters in each block, each party p i : 4. segments its Bloom filters into P equal sized segments 5. receives the i th segment of Bloom filters from all other 6. applies a logical conjunction (AND) on each set of 7. calculates the number of common 1-bits ( c i )andthe
Finally, in the similarity calculation phase, the parties: 8. use the secure summation protocol to exchange the 9. calculate the Dice coefficient similarity of each set of
We assume P parties participate in the protocol, each hav-ing a database of N records, and we assume B  X  N blocks are being formed by each party [1]. In the first phase, agree-ment of parameters has a constant communication complex-ity, and blocking the databases has O ( N ) computation com-plexity. Finding the intersection of blocks from all parties has a communication complexity of O ( PB ) and a computa-tion complexity of O ( BlogB ) at each party. The creation of Bloom filters using k hash functions for N records is O ( kN ). In the distributed matching phase, each party sends its Bloom filter segments (each of length l/P ) to the other par-ties. If we assume direct communication, P ( P  X  1) mes-sages are required in this step, each of these of size N  X  l/P ( O ( NlP ) total communication). With the simplified assumption that all blocks are of equal size ( N/B ), then in each block ( N/B ) P sets of Bloom filters (i.e. all candi-date sets of records in a block) have to be generated and their logical conjunctions calculated, leading to a total of O ( B ( N/B ) P ) calculations. This combinatorial complexity currently limits our protocol to a small number of parties, or a large number of small blocks (i.e. N/B is small). Our main future research focus is to improve this step of our protocol by efficiently filtering non-matching record sets.
The similarity calculation phase consists of the secure summation of the calculated number of common 1-bits ( c i ) set two integer numbers to be sent in a ring communication ( P messages) over all parties with a total communication of O ( PB ( N/B ) P ), followed by the distribution of the final results which is again O ( PB ( N/B ) P ).

To assess the privacy of our protocol, we assume all parties follow the honest-but-curious adversary model [13], in that they are curious and try to find out as much as possible about the other parties X  data while following the protocol. Since calculations are distributed among the parties, each party only learns l/P bits of each other party X  X  Bloom filters, which reduces with increasing P (and thus privacy improves with increasing P ).

The values for the number of hash functions used ( k )and the length of the Bloom filter ( l ) provide a trade-off between the linkage quality and privacy [11]. The higher the value for k/l , the higher the privacy and the lower the quality of linkage, because the number of q -grams mapped to a single bit increases, which leads to lower linkage quality but makes it more difficult for an adversary to learn the possible q-gram combinations. Hash-mapping several attribute values from each record into one compound Bloom filter [4] makes it even more difficult for an adversary to learn individual attribute values that correspond to a revealed bit pattern.
We have implemented our proposed approach in Python (version 2.7.3), and ran all experiments on a server with 2.4 GHz CPUs, 128 GBytes of main memory and running Ubuntu 12.04. The programs and test datasets are available from the authors. Following other work in PPRL [4, 11], we set the parameters as l =1 , 000, k = 30, s t =[0 . 8 , 0 . 9], and P =[3 , 5 , 7 , 10]. We apply a Soundex based phonetic blocking [1] to improve the scalability of our protocol.
We evaluate the scalability of our protocol measured by runtime, and the quality of the achieved linkage measured by precision and recall [1]. In line with other work in PPRL [12], we evaluate privacy using disclosure risk (DR) measures based on the probability of suspicion, i.e. the likelihood a masked database record can be matched with one or several (masked) record(s) in a publicly available global database. We show mean DR values, as well as marketeer DR values calculated as the proportion of records that match to exactly one record in the global database.
 For all experiments we used the large real-world North Carolina Voter Registration database (named  X  X C X ) as avail-able from ftp://alt.ncsbe.gov/data/ . Wehavedown-loaded this database every second month since October 2011 and built a compound temporal dataset that contains over 8 million records of voter X  X  names and addresses.
To allow evaluation of our protocol with data of different sizes, different quality, and for different number of parties, we used a recently proposed data corruptor [2] to create a variety of datasets with different characteristics. From the full NC dataset we extracted sub-sets of 5,000, 10,000, 50,000, 100,000, 500,000, and 1,000,00 records for each party where the number of matching records is set to 50% (i.e. half of all selected records occur in the datasets of all parties).
To investigate how our protocol deals with dirty data (where attribute values contain errors and variations), we generated several series of datasets with one, two, or three modifications (corruptions) applied to randomly selected at-tribute values. These corruptions consisted of character edit operations (insert, delete, substitute, or transposition), as well as optical character recognition and phonetic modifi-cations based on look-up tables and rules [2]. Because we generated our different datasets we know the true matching records which allows us to calculate linkage accuracy.
Figure 2 (a) shows the scalability of our approach, mea-sured by runtime as averaged over all parties and over all variations of each dataset. Interestingly, runtime decreases with larger number of parties ( P ) because the Bloom fil-ter segments at each party become shorter ( l/P )andthe similarity calculations are distributed among the parties.
The quality of linkage measured by precision and recall is presented in Figure 2 (b) on the NC 5,000 modified and non-modified datasets. As can be seen, precision and recall are high on the non-modified datasets. On the modified datasets the recall drops quite drastically with the number of parties. This is because when records are modified in each dataset the number of missed true matching record sets increases. In future work we will investigate similarity techniques that allow for matching records in sub-sets of parties only.
Finally, the privacy of our protocol, as measured by dis-closure risk (DR) [12] of an exact matching attack using the full NC dataset as the global dataset, is shown in Fig-ure 2 (c). As discussed in Section 3.3, DR decreases (i.e. pri-vacy increases) with an increasing number of parties for the non-modified datasets as the Bloom filter segments become shorter and are therefore matched to more global records. Since all the records in these datasets are non-modified (an unlikely real-world situation) there exist exact matchings of records in the global datasets which leads to higher DR values. For the modified datasets (more likely in real appli-cations), the DR values are lower and most Bloom filter seg-ments match to no global record at all, but as these segments become shorter with more parties an increasing number of segments do match, leading to a slight increase in DR.
We have presented a secure protocol for PPRL across mul-tiple parties based on Bloom filters. Our protocol identifies sets of records that have a high Dice similarity across all par-ties. The protocol has a communication complexity that is linear in the number of parties and the size of the databases that are linked, making the protocol scalable to applications where data from multiple parties need to be linked.
In future work, we plan to improve the scalability of our protocol by using improved private blocking or filtering ap-proaches, and by investigating different communication pat-terns. A second avenue of future work will be to study link-age attacks with approximation of error bounds for privacy evaluation of our protocol. Finally, we plan to investigate improved classification techniques including relational clus-tering and graph-based approaches [1] which are successfully used in non-PPRL applications. Our ultimate aim is to de-velop techniques that allow for large databases to be linked in secure, accurate, and scalable ways across many parties, thereby facilitating data analysis and mining that currently are not feasible due to privacy and confidentiality concerns. [1] P. Christen. Data Matching . Springer, 2012. [2] P. Christen and D. Vatsalan. Flexible and extensible [3] C. Clifton, M. Kantarcioglu, A. Doan, G. Schadow, [4] E. A. Durham, C. Toth, M. Kuzu, M. Kantarcioglu, [5] M. Kantarcioglu, W. Jiang, and B. Malin. A [6] A.F.Karr,X.Lin,A.P.Sanil,andJ.P.Reiter.
 [7] P. Lai, S. Yiu, K. Chow, C. Chong, and L. Hui. An [8] N. Mohammed, B. Fung, and M. Debbabi. Anonymity [9] C.M.O X  X eefe,M.Yung,L.Gu,andR.Baxter.
 [10] C. Quantin, H. Bouzelat, F. Allaert, and et al. How to [11] R. Schnell, T. Bachteler, and J. Reiher. Privacy-[12] D. Vatsalan, P. Christen, C. M. O X  X eefe, and V. S. [13] D. Vatsalan, P. Christen, and V. S. Verykios. A
