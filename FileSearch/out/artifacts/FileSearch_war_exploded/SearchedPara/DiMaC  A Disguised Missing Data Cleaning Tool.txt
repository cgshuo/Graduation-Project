 In some applications such as filling in a customer information form on the web, some missing values may not be explicitly represented as such, but instead appear as potentially valid data values. Such missing values are known as disguised missing data , which may impair the quality of data analy-sis severely. The very limited previous studies on cleaning disguised missing data highly rely on domain background knowledge in specific applications and may not work well for the cases where the disguise values are inliers.
Recently, we have studied the problem of cleaning dis-guised missing data systematically, and proposed an effective heuristic approach [2]. In this paper, we present a demon-stration of DiMaC ,aDi sguised M issing Da ta C leaning tool which can find the frequently used disguise values in data sets without any domain background knowledge. In this demo, we will show (1) the critical techniques of finding sus-picious disguise values; (2) the architecture and user inter-face of DiMaC system; (3) an empirical case study on both real and synthetic data sets, which verifies the effectiveness and the efficiency of the techniques; and (4) some challenges arising from real applications and several direction for future work.
 H.2.8 [ Database Applications ]: Data mining Algorithms, Design, Experimentation Data Quality, Data Cleaning, Disguised Missing Data
Processing missing values is one of the most important tasks in data cleaning. Many methods have been developed  X 
This work was supported in part by an NSERC Discovery grant and an IBM Faculty Award. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.
 to handle explicitly missing values or conduct analysis and data mining on noisy data sets with explicitly missing data.
Interestingly, in many applications, some missing values may not be explicitly represented as such, but instead ap-pear as potentially valid data values. Such missing values are known as disguised missing data [8].

Example 1 (Disguised missing values). Consider the situation where a customer fills in an online applica-tion form of a frequent flyer program. Attribute gender has two choices: male or female . A system may set one of the two values, say male in this example, as the default value. Many customers may not want to disclose this information, or may not want to spend time to fill in the information. The consequence is that many missing values may disguise themselves as the default value, male in this case.
Using system default values is not the only cause trans-lating to disguised missing data. As another example, the attribute birth date is often required in many customer ac-count registration forms. However, many customers do not want to disclose their privacy. Popularly, one may choose January 1 (the first values in the pop-up lists of month and day, respectively) in order to pass. Here, January 1 is a disguise for the missing data.

Disguised missing data exist in real applications, and may impair the quality of data analysis severely. In this demon-stration, we will analyze two real data sets, where disguised missing data are detected. Some simple statistics may shift to some anomalous values due to disguised missing data. Moreover, hypothesis tests, correlation analysis and regres-sions using disguised missing data may give misleading re-sults.

Disguised missing data pose a much more serious challenge for data cleaning than explicitly missing values, since we may not even know the exact missing entries. In the situations illustrated in Example 1, the resulting data set may contain the male customers who did provide the information, and some customers born on January 1. How to distinguish those disguised missing values and those real values is far from trivial.

Recently, we have studied the problem of cleaning dis-guised missing data systematically and made the following contributions [2]. First, we analyze the distribution of dis-guised missing values and identify the important and inter-esting embedded unbiased sample (EUS) heuristic that of-ten holds for disguised missing values. Based on this prop-erty, we propose a general framework to identify suspicious frequently used disguise values. Second, mining frequently used disguise values from large data sets is computationally challenging. We devise efficient and scalable heuristic al-gorithms. Last, we test our approach using both real data sets and synthetic data sets. The experimental results show that our method is effective X  X he frequently used disguise values found by our method match the values identified by the domain experts nicely. Our method is also efficient and scalable for processing large data sets.
 Based on the above techniques, we developed DiMaC (for Di sguised M issing Da ta C leaner), a system that can find the possible values frequently used as disguises. In Section 2, we describe disguised missing data and discuss the critical techniques used in DiMaC . In Section 3, we propose a system demonstration plan.
In this section, we describe disguised missing data and present the embedded unbiased sample heuristic of frequent disguise values. We also propose a framework for cleaning disguised missing data, and analyze the computational chal-lenges.
For a tuple t in a table T ,thevalueof t on attribute A is denoted by t.A , which is also called an entry .Indata collection, for an entry t.A , three situations may arise.
Formally, let T be the truth table and T be the recorded table .If t.A =  X  ,then t.A can be either  X  or a legal value in the domain of A . Particularly, an entry t.A is called disguised missing if t.A =  X  but t.A =  X  .Thevalue t.A is the disguise of the disguised missing entry, or called a disguise value .

In data cleaning, we are given the recorded table T ,the problem of cleaning disguised missing data is to find the values that are frequently used as disguise values, and the set of disguised missing entries.
 Cleaning disguised missing data in general is very difficult. As an extreme example, if the missing values in the truth table are disguised by independent and random values in the domain of the attribute, it is very hard to unmask them without any hints.

There are many previous studies on data mining and data analysis with explicitly missing data [5, 4, 7]. However, cleaning disguised missing data is more challenging. Al-though this problem has been tackled from some angles, the existing approaches often rely on domain knowledge heavily, and are developed for specific applications [6, 1].
If missing values disguise themselves randomly, it is very difficult to identify the disguised missing data. Fortunately, such random disguising often does not happen extensively in practice. Instead, as illustrated in Example 1, a small number of values (typically one or two in an attribute) are frequently used as the disguises. It is practical to make the following assumption.

Assumption 1 (Frequently used disguises). On an attribute, there often exist only a small number of disguises that are frequently used by the disguised missing data.
Under the missing completely at random (MCAR) and missing at random (MAR) models [5], missing data are often distributed randomly in real data sets. Consequently, dis-guised missing entries are often distributed randomly, too, as verified by our experimental results using real data sets.
For a value v on attribute A , the set of tuples in T carrying the value on the attribute is called the projected database of v , denoted by T A = v = { t  X  T | t.A = v } . Hereafter, for the sake of brevity, we assume that the domains of attributes are exclusive, and thus a value belongs to the domain of at most one attribute. Then, we can write T A = v as T v .
We observe the following embedded unbiased sample heuris-tic ( EUS heuristic for short) of disguised missing data. The Embedded Unbiased Sample Heuristic If v is a frequently used disguise value on attribute A ,then T A = v tains a large subset S v  X  T A = v such that S v is an unbiased sample of T except for attribute A .
Since a small number of values may be used frequently as disguises, a critical step in cleaning disguised missing data is to find the disguise values used frequently in attributes .
For each value v on attribute A ,let T v be the set of tuples carrying value v in the truth table. Clearly, T v  X  T v . Then, S v =( T v  X  T v ) is the set of tuples using v as the disguise on attribute A .Wecall S v the disguised missing set of v .
According to the EUS heuristic, S v is an unbiased sample of
T . The larger the size of S v , the more frequently v is used as the disguise value. A value v is called a frequent disguise value if it is frequently used as disguises.

Unfortunately, S v is unknown and cannot be computed accurately from T in general. The EUS heuristic suggests a heuristic way to find those frequent disguise values. Es-sentially, on each attribute, we can find a small number of attribute values whose projected databases contain a large subset as an unbiased sample of the whole table. Such at-tribute values are suspects of frequently used disguise values. The larger the unbiased sample subset, the more likely the value is a disguise value.

Based on the above discussion, we propose a two-phase general framework for cleaning disguised missing data. In the first phase, we analyze each attribute to check whether our heuristic approach is applicable. We find the candidates of frequent disguise values on the applicable attributes. In second phase, those candidates can be verified by domain experts or other data cleaning methods.
DiMaC focuses on the first phase of the framework, which reduces the number of candidates substantially and thus makes the domain experts X  analysis effective. The archi-tecture of DiMaC is shown in Figure 1. The disguise value detection engine finds frequent attribute values on applicable attributes, and then detects disguise values. Some screen-shots of DiMaC are shown in Figure 2. There are some important technical challenges.

First of all, how can we measure whether a set of tuples is an unbiased sample of a table? We propose DV-score ,a correlation-based sample quality score, to measure the qual-ity of a sample. By intuition, correlations can capture the distribution of a data set nicely. Thus, the maximal em-bedded unbiased sample M v is a subset of the projected database T v maximizing the DV-score.

However, the DV-score is not monotonic with respect to the set containment relation, which makes computing the maximal embedded unbiased samples computationally chal-lenging. How can we compute a maximal embedded unbi-ased sample M v from the projected database T v efficiently?
To tackle the problem practically, we adopt a greedy ap-proach. We start with the projected database of an attribute T v as the initial sample. In each iteration, for a tuple t the current sample, we calculate the DV-score gain if t is re-moved from the current sample set. A tuple with the largest positive DV-score gain is removed as the result of the cur-rent iteration. The iteration continues until the DV-score cannot be improved further by removing one tuple from the current sample. The resulting sample is output as the ap-proximation of M v .

A straightforward implementation of the greedy algorithm may still be costly on large databases. Once a tuple is re-moved, the total number of tuples in the current sample is reduced, and thus the correlation between every value pair changes. To address the challenge, we develop some tech-niques to improve the efficiency of the greedy search.
First, since the DV-score of a tuple changes whenever the sample changes, and computing the DV-score gain can be costly, we use a contribution score to guide the greedy search. Comparing to computing DV-score gains, contri-bution scores are often much easier to maintain. Second, we propose an efficient pruning technique to avoid checking each frequent value in an attribute in the greedy algorithm.
Equipped by the above techniques, detecting disguise val-ues is efficient in large data sets. The details of the tech-niques can be found in [2].
The design and development of DiMaC involve a few chal-lenging database and data cleaning issues, including efficient mining of frequent attribute values and testing the quality of large samples.

We will present our prototype system thoroughly in our demo. Particularly, we will focus on the following aspects. [1] D. DesJardins. Outliers, inliers, and just plain liars  X  [2] M. Hua and J. Pei. Cleaning disguised missing data: a [3] B. K  X  egl and L. Wang. Boosting on manifolds: [4] S. L. Lauritzen. The EM algorithm for graphical [5] R. J. A. Little and D. B. Rubin. Statistical Analysis [6] R. Pearson. Mining imperfect data: Dealing with [7] R. K. Pearson. Data mining in the face of [8] R. K. Pearson. The problem of distuised missing data. [9] G. Webb. Further experimental evidence against the
