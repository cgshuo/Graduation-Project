 Process mining is a family of techniques designed to extract insights from busi-ness process event logs [ 1 ]. Process Performance Mining (PPM) is a subset of process mining techniques concerned with the analysis of processes with respect to performance dimensions, chiefly time (how fast a process is executed); cost (how much a process execution costs); quality (how well the process meets cus-tomer requirements and expectations); and flexibility (how rapidly can a process adjust to changes in the environment) [ 2 ].
 understand how the temporal performance of a process evolves over a given For example, a bank manager may wish to know how the waiting times in a loan application process have evolved over the past month in order to adjust the resource allocation policies so as to minimize the effects of bottlenecks. Existing PPM techniques are not designed to address such flow performance questions. Instead, these techniques focus on analyzing process performance in a  X  X napshot X  manner, by taking as input an event log recorded during a period of time and extracting aggregate measures such as mean waiting time, process-ing time or cycle time of the process and its activities. For example, both the Performance Analysis plugins of ProM [ 4 ]andDisco[ 5 ] calculate aggregate per-formance measures (e.g. mean waiting time) over the entire period covered by an event log and display these measures by color-coding the elements of a process model. These tools can also produce animations of the flow of cases along a process model over time. However, extracting flow performance insights from these animations requires close and continuous attention from the analyst in order to detect visual cues of performance trends, bottleneck formation and dissolution, and phase transitions in the process performance. In other words, animation techniques allow analysts to get a broad picture of performance issues, but not to precisely quantify the evolution of process performance over time. In this setting, this paper presents a PPM approach designed to provide a precise and quantifiable picture of flow performance. The approach relies on an abstraction of business processes called Staged Process Flow (SPF). An SPF breaks down a process into a series of queues corresponding to user-defined stages. Each stage is associated with a number of performance characteristics that are computed at each time point in an observation window. The evolution collectively allow flow performance to be analyzed from multiple perspectives in order to address the following questions: Q1. How does the overall process performance evolve over time? Q2. How does the formation and dissolution of bottlenecks affect the overall process performance? Q3. How do changes in demand and capacity affect the overall process perfor-mance? The rest of this paper is organized as follows. Section 2 reviews existing PPM techniques with respect to the problem of flow performance analysis. Section 3 Sect. 5 summarizes the contributions and outlines future work directions. Existing PPM tools support the analysis of entire processes or activities thereof with respect to performance measures such as cycle time, processing time and waiting time. Some PPM tools display the distribution of performance measures in the form of dashboards (e.g. bar charts) alongside aggregate statistics (e.g. mean and median) [ 5 ]. Others overlay the performance measures on top of a process model, for example by replaying the log on the process model [ 4 , 6 ] and calculating aggregate performance measures for each element in the process model during replay. Techniques for enhancing the quality of log replaying based to summarize the performance of the process over the entire time period covered by the event log. They can pinpoint bottlenecks, resource underutilization and other performance issues observed across said time period. However, they do not allow one to analyze how those bottlenecks form and dissolve, and more generally, how the performance of the process varies over time.
 characteristics (incl. performance measures) from event logs. For example, de tics from event logs and to correlate them in order to discriminate for example between the performance of cases that lead to  X  X ositive X  outcomes versus  X  X ega-mance characteristics along the resource perspective. These proposals however are not designed to provide insights into the evolution of process performance over time.
 Log animation displays in a movie-like fashion how cases circulate through the from these animations requires the analyst to: (i) manually look for visual cues in the animation that indicate trends, phase transitions or bottlenecks in the process X  performance; and (ii) run additional queries to locate and quantify the observed performance phenomena.
  X  X ork queues X  from event logs at the level of an entire process or of individual activities. Meanwhile, de Smet [ 13 ] proposes a method to discover collections of queues from event logs. This latter method discovers queues by grouping resources and activities into clusters based on cohesion metrics. The queuing models produced by the above methods are used for prediction (e.g. of wait-ing times) rather than performance analysis. As such these methods are only marginally related to the problem of flow performance analysis.
 analysis techniques from the fields of lean management and agile software engi-neering. The idea of decomposing the process into stages and analyzing flow metrics at each stage can be found in various embodiments in contemporary lean and agile management tools, e.g. Kanban Flow 1 and ActionableAgile concept of SPF formalized in this paper in the context of business process event logs, provides a generic framework that brings together flow performance analy-sis techniques found across these tools. In this section, we introduce the concept of SPF and its formalization before describing our SPF-based approach to process performance mining. 3.1 SPF Overview An SPF is a partitioning of the set of log events into consecutive stages with a precede all events in the subsequent stage (in our example all events in stages, so long as its stages follow the defined order (in our example a trace with s 1 ,s 2 is possible but not a trace with s 1 ,s 2 ,s a queuing system , where the queuing items are cases and the service facility is has an arrival flow via which new cases arrive to the stage in question and a departure flow via which cases depart. In addition, a stage may have exit flows , capturing the fact that a case may leave the process abnormally after being For illustration, we use the loan origination process of a Dutch bank, which a case in this process is a loan application that goes through four stages: Pre-Assess ( s 1 ), Assess ( s 2 ), Negotiate ( s 3 ) and Validate (  X  X re-Assess X  stage, the bank checks the completeness of the loan application and requests the customer to provide sufficient documents before their application can proceed to the next stage. Next, in the  X  X ssess X  stage, the bank checks the eligibility of the loan application. In the  X  X egotiate X  stage, the bank and the customer discuss the terms and conditions of the loan until it is ready for vali-can either be declined by the bank or canceled by the customer, which leads to interrupting the process at that point.
 In this example, each stage has an exit flow consisting of loan applications that are declined or canceled. Thus, a trace recording a loan application that is canceled after the assessment, will only have the first two stages. Flow performance in an SPF is determined by a set of characteristics cap-turing the interplay between the arrival flow on the one hand and the departure and exit flows on the other. One such characteristic is the Cases In Progress (in reference to  X  X ork-in-Progress X ), that is, the set of cases found in a stage at a given point in time. Another characteristic is the Time in Stage : the time between the arrival and the departure/exit of a case for a given stage. Each case spends a certain amount of time waiting in a stage, and another amount of time being processed in that stage. Flow Efficiency is the ratio between the processing time of a case in a stage and the Time in Stage. Below we formally define how an SPF and its characteristics are extracted from an event log. 3.2 SPF Formalization An event log is the starting point of any process mining task. Figure 2 shows an application identified by code c 4 is a case. Each case consists of a sequence of events . An event is the most granular element of a log and is characterized by a associated with the event, which can be human or non-human), and timestamp (the moment when the event occurred). Event type represents the association between an event and its activity X  X  lifecycle, such as  X  X chedule X ,  X  X tart X , and  X  X omplete X . In this paper, we assume that  X  X tart X  and  X  X omplete X  are the only event types associated with activities.
 Formally, an event log EL is a tuple ( E , ET , A , R , C case ), where E is a set of events, ET = { start , complete R is a set of resources, C is a set of cases, time : E  X  IR assigns a timestamp to an event, act : E  X  A is a function that assigns an AID to an event, type : E  X  ET is a function that assigns an event type to an event, res : E  X  R is a function that assigns a resource to an event, and case : relates an event to a case. We write e E e iff time ( e ) In our model, events are associated with stages . For example, a particular  X  X heck application X  event occurs at the  X  X ssess X  stage of a loan application. A completed case is one that passed all stages and has a  X  X omplete X  status, otherwise, the case is considered to have exited the process prematurely and will have the status  X  X ncomplete X .
 Stage-Based Enhancement. In our approach, an event log must firstly be enhanced with stage information. A stage-based enhancement SE of an event log EL =( E, ET ,A,R,C, time , act , type , res , case ) is defined as a tuple ( , stage , status ), where S is a set of stages, CS = { complete case statuses, &lt; S  X  S  X  S a strict total order over S total order), stage : E  X  S assigns stages to events, and status : assigns statuses to cases. For convenience, we write E c,s c  X  stage ( e )= s } to denote the set of all events of case c and E start = { e  X  E | type ( e )= start } is the set of all  X  X tart X  events. While there can be a number of ways to arrive at a stage-based enhancement there must be events associated with all stages preceding The stages covered by a case must observe the defined order Events related to the same activity must belong to the same stage: If a case has a complete status, it should have gone through all the stages:  X  c  X  C [ status ( c )= complete  X  X  X  s  X  S  X  e  X  E [ case ( SPF Characteristics. The start of stage s in case c , T AR min stage s in case c , T For all timestamps t neither t&lt;  X  nor t&gt;  X  holds. The last stage of case laststage ( c, s ), iff  X  (  X  s  X  S  X  e  X  E [ s&lt; S s  X  t , i.e. C AR ( s, t ) { c  X  C | X  e  X  E c,s [ time ( e )  X  t consists of all cases that have gone beyond stage s on or before time C those cases that have completed stage s on or before time beyond stage s , and are considered to be incomplete: C EX E c,s [ time ( e )  X  t ]  X  laststage ( c, s )  X  status ( c average number of cases arriving at/departing from/exiting after a stage unit of time  X  at a given point in time t : It is required that  X  &gt; 0 here and elsewhere, and t  X   X  is not before all case start times in the log, i.e.  X  e  X  E [ time ( e )  X  ( t  X  time t : that one needs to wait to see the number of departing cases from greater than the number of cases that arrived in stage s on or before time Formally, let t be the minimal timestamp such that t = t + | C no such t exists.
 sum of all durations of activities that occurred in that stage and that interval divided by the sum of all case durations for that stage in the said interval. To be able to determine the durations of activities, we have to impose further requirements on an event log: (1) for every activity in the log there is at most one corresponding  X  X tart X  event and one corresponding  X  X omplete X  event, i.e.  X  e  X  E e  X  E [ e = e  X  act ( e )= act ( e )  X  type ( e )= type (  X  e  X  E  X  e  X  E [ act ( e )= act ( e )  X  type ( e ) = type ( its corresponding  X  X tart X  event should occur before its corresponding  X  X omplete X  event, i.e.  X  e  X  E  X  e  X  E [ type ( e )= start  X  type ( e act ( e )  X  time ( e ) &lt; time ( e )]. Then, any activity corresponding  X  X tart X  event e s and exactly one corresponding  X  X omplete X  event e . The duration of a during a closed time interval [ t 1 ,t at stage s within interval [ t 1 ,t 2 ], written dur ( c, s, t [ T Note that at least one case should have events in the interval [ s to avoid the denominator evaluating to zero.
 The formulae above can be illustrated with the example log given in Fig. 2 . First, the log is summarized by stages and cases as shown in Fig. 3 for ease of computation. With t 1 = 09.10 08:15:00 ,t 2 = 09.10 09:15:00 of the SPF characteristics are computed as follows:  X  C  X  C  X  C  X  AR ( s 2 ,t 2 ,  X ) = 2 cases/h , DP ( s 2 ,t 2 ,  X ) = 2 cases/h 1 case/h  X  CIP ( s 2 ,t 2 )=1case , TIS ( s 2 ,t 2 ,  X ) = 1h (at C 3.3 SPF-Based Performance Mining Approach Our approach to process performance mining follows three steps: (i) construct user consumption.
 Construct Flow Cells. First, the log is enhanced with stage information.
 This is currently done via preprocessing, which consists in adding two stage-based attributes: a  X  X tage X  attribute for each event, indicating which stage it belongs to, and a  X  X tatus X  attribute to the case, indicating if the case is complete.
 the intersection of a stage and an interval located at t i in during its lifecycle.
 Measure SPF Characteristics. SPF characteristics are computed first at level). At a particular flow cell located at a stage s and a point in time ( i =0 ...n ), the formulae presented in Sect. 3.2 can be applied as exemplified as a statistic (e.g. max, min, and mean) of the corresponding SPF characteristics Arrival Rate and Departure Rate at the system level are the Arrival Rate at the first stage and Departure Rate at the last stage, respectively.
 Visualize SPF Characteristics. Based on the above formalization, we provide three visualizations to support the analysis of SPF characteristics at different levels of abstraction and periods of time.
 Cumulative Flow Diagram (CFD): A CFD is an area graph used in queueing theory [ 14 ]tovisu-alize the evolution of flow perfor-mance over time. Figure 5 depicts how some SPF characteristics are related to the geometry of the CFD. In our case, each area, encoded with a different color, represents the number of cases queuing for a given process stage ( queue flow ), being worked in that stage ( service flow ) or exit-two sub-stages of a process stage with similar SPF characteristics. The CFD is particularly suitable for examining the flow performance. For example, one can observe the process evolution over time through the development trend of different flows, identify the formation and dissolution of a bottleneck through widening and shrinking areas on a queue and service flow, and detect patterns the process performance. Performance Summary Table (PST): The PST (Fig. 6 ) provides a quick and exact measurement of the flow performance in figures, at the stage and system levels. It also allows one to measure the flow for any time interval of the log. Time Series Charts (TSCs): As most SPF characteristics are time-dependent, TSCs (Fig. 7 ) can be used to investigate the evolution of SPF stage character-istics over time, such as viewing the development of arrival rate, the difference tlenecks over time. Figure 7 gives a multiple-series TSC showing the evolution of various SPF characteristics over time. We implemented our approach as a ProM plugin, namely the  X  X erformance Min-ing With Staged Process Flows X  plugin, as well as a standalone Java application. In the following, we use this implementation to answer the questions raised in Sect. 1 using the BPI Challenge 2012 log, and compare the results with those obtained from two state-of-the-art PPM tools. For space reasons, the results of a report [ 15 ], though they are in line with those reported in this paper. Dutch bank (see Sect. 3 for a description). It contains 13,087 loan applications with a total of 193,208 events occurring from 1 Oct 2011 to 15 Mar 2012. Every case must pass four stages. The completion of each stage is marked by a special event such as A PREACCEPTED, A ACCEPTED, and A ACTIVATED. We preprocessed this log to enhance it with stage information, including adding a  X  X tage X  attribute for events and a  X  X tatus X  attribute for cases.
 Petri net discovered from an event log as input. The net can be obtained by using Miner. PEP can be run to internally replay the log on the Petri net, in order to align the log with the model, compute time-related performance information (capturing states). Arrival rates for these elements are also provided. Moreover, places are color-coded based on the length of the waiting time (blue for short waits, yellow for medium and red for long). The thresholds for the colors can be set automatically or manually by the user. The tool also provides overall performance measures such as arrival rate and statistics on cycle time. process model. The tool takes an event log as input and discovers a Fuzzy net, which provides an abstract representation of the process behavior, by show-ing the process activities and paths connecting these activities. This model is enhanced with frequency information and statistics on performance measures at the level of individual process activities (processing time) and paths (waiting time). The complexity of the discovered model can be adjusted based on case frequency, in order to obtain a simpler process model that abstracts away infre-quent cases. Different types of filters besides frequency can be used to create model projections which can be used to compare process variants on the basis of their performance, e.g. focusing on all cases that have a duration or a num-ber of events within a given range. In addition, Disco can replay the log on the discovered model.
 to interpret data in order to answer a given question. Usefulness on the other hand refers to the extent the tool provides data that allows the user to answer the question in a precise (i.e. quantitatively) and informative manner. Below we evaluate the three tools for each question.
 Q1: How does the overall process performance evolve over time? SPF. The evolution of the process is depicted on a CFD (Fig. 8 ). The shape of the CFD reflects the development of the process at each stage. The characteris-tics, such as arrival rate (AR) and cases in progress (CIP), can be seen at any point in time as a tooltip. The CFD can be zoomed in to investigate patterns can also be viewed on the plot of flow efficiency over time. The PST (Fig. 6 ) provides a summary of the flow performance at any time interval. From these visualizations, we can draw the following observations:  X  The process has a stable trend indicated through the even height of service flows shown in Fig. 8 (bands named as s i -Service). Further evidence is pro-vided by the average arrival and departure rates, which are comparable at each stage in Fig. 6 , and by the fact that there is little variation between the average mean and median value of CIP and TIS.  X  There are strong exit flows throughout the period from (bands named as s i -Exit on the CFD). Apparently, these exit flows contribute to keeping the arrival of cases at each stage on a par with their departure.  X  The CFD and PST show that the waiting queue is negligible at stage starts to emerge at stage s 2 and becomes considerable at stages meaning that the process has slower response in the later stages.  X  The process has very low flow efficiency (3 %), i.e. 97 % of time a case stays idle. The problem seems to be with frequent waits for customer response. As shown above, the SPF proposes an easy way to understand how the overall process performance evolves over time. The output is easy to interpret, as it is based on visual cues and performance measures; precise, as it is supported by numeric measurements; and most importantly, it leads to various insightful observations.
 PEP. An excerpt of the Petri net enhanced with performance information pro-vided by PEP is shown in Fig. 9 . This model was obtained by first discovering a Heuristics net from the log and then converting it to a Petri net. However, in order to obtain a model that is easy to interpret, we had to incrementally to understand. Eventually, we ended up retaining only those events that mark approach. A drawback of this operation is that the fitness of the model decreases as some traces of the log can no longer be replayed on the model. As a result, the performance measures provided by the tool are only approximate, as they only refer to those traces that perfectly fit the model.
 measures, we were unable to answer Q1 as PEP does not offer any support to profile the process evolution over time. We concluded that PEP is unable to answer Q1.
 Disco. Similar to PEP, the model discovered by Disco from the unfiltered log was rather complex, with 50 activities and over 150 paths. Hence, we also decided and 19 paths (Fig. 10 a). Based on this model, we found two ways to answer Q1. One way was using the filter by timeframe provided by Disco to select different process variants by time intervals, e.g. by months from Oct 2011 to Mar 2012. After each interval, we recorded the performance measures manually for each process variant. At the end of this procedure, we obtained a set of monthly performance measures which we could use for trend analysis. While this approach to retrieve and interpret from the figures manually calculated. We were unable to discover any insights because of the limitation of this manual review. Another way was to animate the log on top of the discovered model, to identify any normal and abnormal trends (Fig. 10 b). While the animation was running, we had to keep close attention to the various tokens flowing towards different directions through the model, to identify recurring patterns as well as deviations. To complete the animation for six months, it took approximately four minutes at maximum speed which is a reasonable time. One insight was that the cases seem to flow to the end of the process in batches. However, it was not easy to pinpoint the recurrent timing of these batches during the animation. We were also unable to compute the volume of cases in batches due to the lack of supporting performance figures in the animation. In conclusion, we found that although the animation in Disco can provide some insightful clues w.r.t. to process evolution, it is not possible to precisely characterize this evolution. Q2: How formation and dissolution of bottlenecks affects overall per-formance? SPF. We can observe signs of bottlenecks on the CFD when the queue band and/or service band become wider, meaning that the process has slower response to the arrival of new cases. The formation of bottlenecks can be identified from at the peak points. The exact measurement of these effects is provided via the on-screen tooltips and by the PST with the time interval scale. The formation of bottlenecks generally leads to an increase of CIP and TIS in the queue and service period of a stage and possibly to a decrease of FE. Conversely, these effects gradually diminish when the bottleneck dissolves.
 Although the log exhibits a stable process evolution, there are signs of bottle-necks. For example, Fig. 11 a shows that at stage s 4 , the queue ( from 24 Oct and peaks on 27 Oct (CIP = 120 cases, see Fig. 12 b) and then slowly Fig. 12 a) also shows a fall on 26 and 27 Oct (around 0.55 % fall as measured by the PST). Our measurement also shows that the CIP and TIS of not increase immediately from 26 X 27 Oct (ca. CIP = 27 cases, TIS=20 hours) but only afterwards (ca. CIP = 42 cases, TIS=46 hours from 29 Oct to 6 Nov 2011) as the aftermath of the previous congestion (Fig. 11 a). The bottleneck then slowly s -Service after the bottleneck (from ca. 20 cases/day during 23 X 27 Oct to ca. 24 cases per day during 28 Oct-16 Nov). We observe that the FE has recovered and CIP and TIS have diminished during the period 28 Oct-16 Nov (Fig. 12 a and b). Similar bottleneck phenomena are visible in stage and precise information to answer Q2, deriving information on how bottleneck formation and dissolution affect process performance.
 PEP. Continuing from the enhanced model in Q1, PEP can highlight the bot-tlenecks on the model by coloring the places of the Petri net based on their associated waiting time (see Fig. 9 ). This information is enriched by detailed performance measurements at the level of individual elements (see e.g. Fig. 13 ). ways to reason about the impact of the formation and dissolution of bottlenecks on the process performance as the measures shown on the model are only aggre-gate values over the whole we conclude that PEP is unable to answer Q2. Disco. Continuing from Q1 with the discovered high-level process model, we identified two ways of detecting bottlenecks in Disco. One is displaying perfor-mance measures on the model (Fig. 10 a). Disco can highlight in red the excep-tionally high values of activity and path durations as signs of bottleneck. We found that the paths for canceled cases at stages s 2 , s 21 days at stage s 3 . In addition, the path for cases going from impact of a bottleneck on overall performance (e.g. by measuring how much the average cycle time improves by removing slow cases), based on the process model and the performance measures alone, we did not have enough data to assess the impact of formation and dissolution of bottlenecks on overall performance. Another way of answering Q2 is by watching the replay animation (Fig. 10 b). From this we can observe that there are busy flows of canceled cases at stages s , s 3 and moving slower than those on other paths. However, we were unable to quantify these signs of bottleneck such as number of cases and waiting time, as well as the impact of these bottlenecks.
 Q3: How do changes in demand and capacity affect overall process performance? SPF. The demand and capacity are represented by the arrival (AR) and depar-ture rate (DR), respectively. The arrival rate at the first stage is the customer demand while the departure rates at different stages are their corresponding capacities. They can be observed on the CFD, as well as in the time series overall process performance, including the CIP, TIS and FE of the queue and service periods, and lead to the formation and dissolution of bottlenecks. Overall, the PST in Fig. 6 shows that the process under exam has a much higher AR at s 1 -Queue as customer demand rate (84.73 cases/day), than DR at s -Service as final output rate (18.62 cases/day). However, the process maintains a stable evolution without congestion because there are strong exit flows as shown in Fig. 8 . This mechanism effectively reduces the strain of high customer demand on the process. As such, the impact of demand and capacity is visible locally at a stage only. For example, in relation to the bottleneck reviewed in Q2, the differ-ential chart in Fig. 14 shows that the bottleneck appears due to the stronger dominance of the arrival rate over the departure rate prior to the bot-tleneck period (14 X 24 Oct). The dif-ference between arrival and departure (ca. 14 cases/day) while the departure rate DR is low (ca. 5 cases/day) and spreads over a longer time. This difference explains why there is a permanent the AR and DR at s 2 -Queue are approximately equal with the same distribution (see Fig. 11 b). That is why there is a very minor queue at stage PEP. We found no ways in PEP to investigate the impact of changes in demand and capacity on the process performance since this tool only captures one average value at every place/transition for the whole period. Hence, we are unable to answer Q3.
 Disco. We replayed the animation in Disco while focusing on the speed of the to the flow of tokens departing from the last activity of each stage (Fig. 10 b). However, we found it is very challenging to spot any patterns on the animation, at the same time. We concluded that Disco is unable to answer Q3. We presented an approach to analyze flow performance from event logs based on the concept of SPF, which transpose ideas found in lean management and agile software development to the field of PPM. The evaluation on real-life event logs puts into evidence qualitative advantages of this approach with respect to existing PPM techniques.
 into user-defined stages. In some cases, such stages may be already known (e.g. because they are captured in a process model), but in other scenarios the stages need to be discovered. A direction for future work is to design techniques for automated identification of candidate stages from a log. One possible approach is to cluster activities based on which resources most often perform them, as in [ 17 ] where event types are grouped into clusters (corresponding to candidate sub-processes) based on shared data attributes.
 identify patterns from the stage characteristics and visualizations, particularly patterns associated with formation and dissolution of bottlenecks. There is an opportunity to extend the SPF approach with techniques from statistical process control and change point analysis, such as CUSUM charts [ 18 ], to support the usability evaluation of the SPF approach via controlled experiments in order to validate major design choices, such as the choice of stage characteristics and visualizations.
