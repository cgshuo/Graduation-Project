 Department of Computer Science, Nanjing University it is often assumed that there are sufficient training data. For example, in supervised classification task, the labeled training instances are often assumed to be sufficient to train a good learner that can correctly classify unseen instances. In many practical applications, however, labeled instances are insufficient, because labeling training instances is often expensive, difficult, or time-consuming. Meanwhile, unlabeled instances may be relatively easy to obtain, thus can be used to compensate the lack of labeled instances, which motivates a recent machine learning branch -semi-supervised learning [1]. Due to its importance in practice and theory, semi-supervised learning has received considerable attention. A number of learning methods, including self-training, co-training, graph-based methods, etc., have been proposed to effectively learn from both labeled and unlabeled data. traditional machine learning or semi-supervised learning problems, are under a common assumption: the training and test data are drawn from the same distribution and the same feature space. So, when the distribution changes, most learning methods fail to work well. Therefore, human effort is required to re-collect a large amount of labeled data to re-train a learner to fit the new distribution. Since the labeling process is often expensive, reducing human effort to label new data attracts increasing attention. This motivates another machine learning branch, namely transfer learning [2], which aims to transfer the knowledge in a source domain to solve the learning task in a related target domain, i.e. the domain we are interested in. The source and target domain have different data distributions or even different feature spaces. For example, in web page classification, we can use transfer learning to adapt a classifier for university pages to the classification task on Facebook.com [2]. This is because that although the data distribution between university web and social web pages are quite different, there still exists some common classification knowledge that can be reused to reduce the labeling effort. Even if we still want to classify the university web pages, transfer learning may also help, because the contents on web pages are changing over time, and the training data can be easily outdated (i.e. under a different distribution to the current data). decade, and various approaches have been developed. Most of these approaches can be summarized into two categories, namely instance-transfer and feature-representation-transfer. In instance-transfer, training instances in the source domain are re-weighted according to their impact on the learning in the target domain [3]. While feature-representation-transfer tries to learn a common feature representation across domains to reduce the domain divergence as well as the training error, making knowledge in different domains easy to transfer [4]. of transfer learning have also been studied. There are mainly three settings of transfer learning, namely inductive transfer learning, transductive transfer learning and unsupervised transfer learning [2]. In this paper, we focus on inductive transfer learning, in which only a few labeled data in the target domain are available. Besides, we assume that the source-domain data are also labeled, just the same as several other works like [3], [5]. In a word, our problem setting assumes that a large amount of source-domain data (referred to as diff-distribution data in the following) and a small amount of target-domain data (referred to as same-distribution data) are available. Both the diff-distribution and same-distribution training data are labeled and under the same feature space. However, we should note that although a few same-distribution data are provided, they are still insufficient to train a good learner for the target domain. One intuition to solve the problem is to use the same-distribution data to find out some useful diff-distribution instances and reuse them to improve the learning in the target domain, which exactly follows the instance-transfer strategy. In fact, several instance-based approaches for inductive transfer learning have already been proposed, such as auxiliary-data-based method [5] and boosting method for transfer learning [3], but their generalization ability and robustness still need to be improved. and semi-supervised learning address different problems, they share similarities on their methodologies, thus many approaches for semi-supervised learning can be extended to inductive transfer learning setting. To develop better instance-based methods for inductive transfer learning, this paper attempts to extend methods in semi-supervised learning. The basic idea of the extension is to replace the step of labeling an unlabeled instance by re-weighting a diff-distribution instance. Specifically, this paper extends the co-training method. As an often-used semi-supervised learning method, co-training trains two learners separately on two different views, and uses the predictions of each learner on unlabeled instances to augment the training set of the other learner. Such training style has the advantages of high generalization ability and strong robustness, which has been reported by several research works (for example, refer to [6]). In our CO-training method for Inductive Transfer Learning (COITL), two base learners also learn in a collaborated way, however, the information that one learner gives to the other is the weight of a diff-distribution instance instead of the predicted label of an unlabeled instance. The co-training method uses the weighted k Nearest Neighbor ( k NN) method [7] as the base learner, and implement two learners by setting different values for the parameter k . Moreover, each k NN learner weights a diff-distribution instance according to its influence on the training error. An efficient implementation of COITL is also presented. Experimenting on eight data sets, we show that the proposed method outperforms state-of-the-art approaches in inductive transfer learning, in terms of generalization error and robustness to noise. To summarize, this paper has mainly two contributions. First, it bridges inductive transfer learning and semi-supervised learning, and shows that many semi-supervised learning methods can be extended for inductive transfer learning. Second, it develops a new transfer learning method by extending the co-training method in semi-supervised learning. The rest of this paper is organized as follows. Section II presents the related work. Section III gives the problem statement. Section IV discusses the relationship of the two learning branches. Section V gives the details of COITL. Section VI reports the experimental results. Finally, Section VII concludes. A. Instance-transfer appealing. Although directly reusing the diff-distribution data is unfeasible, there are certain parts of the data that can still be reused to benefit the learning in the target domain [2]. Here we briefly review a few research works with the similar problem setting as ours. auxiliary training data into k NN as well as support vector machine methods. The methodology is to minimize a weighted sum of two loss functions, one for original training data (i.e. same-distribution data) and the other for auxiliary data (i.e. diff-distribution data). Their experiments demonstrated that using auxiliary data can improve the classification performance when the original training data are inadequate. Note that in their work, all diff-distribution training data are given the same weight, yet our method sets the weight for each diff-distribution instance separately. diff-distribution instance to reflect the distribution mismatch. Those auxiliary variables are estimated as a byproduct, along with the classifier. They also incorporated a new active learning method to select unlabeled same-distribution instances to be labeled with the help of diff-distribution data. In our method, however, we perform transfer learning only on labeled data. TrAdaBoost, as an extension of the AdaBoost algorithm. The idea is to use a small number of same-distribution instances to find out useful diff-distribution instances by iteratively adjusting their weights. In each iteration, a base learner is trained on the weighted training data and used to predict the label of each training instance. Moreover, TrAdaBoost uses the same strategy as AdaBoost to update the weights of incorrectly classified same-distribution instances while also adopts a different strategy from AdaBoost to update the weights of misclassified diff-distribution instances. Experimental results verified the high generalization of TrAdaBoost. B. Co-training Mitchell [9], presents a novel learning style: two learners are separately trained on two sufficient and redundant views, and the predictions of each learner on unlabeled instances are used to augment the training set of the other one. Here, the two sufficient and redundant views are two attribute sets which satisfy the following two requirements: second, given the class label, each attribute set is conditionally independent to the other. Later, Dasgupta et al. [10] theoretically showed that when there exist two sufficient and redundant views, the co-trained learners can reduce the generalization error by maximizing their agreement over the unlabeled instances. Although co-training has been successfully utilized in several domains, such as statistical parsing [11] and noun phrase identification [12], in most application scenarios, the requirement of sufficient and redundant views, could not be met. Therefore, some variants of co-training which relax the requirement of sufficient redundancy were proposed. 
Goldman and Zhou [13] developed a relaxing version of the co-training method. Their method employs two different supervised learning algorithms to divide the instance space into a set of equivalence classes, and uses cross validation to help label the unlabeled instances and generate the final hypothesis. Their experimental results demonstrated that although there are no sufficient and redundant views, such co-training version can still achieve excellent performance. Recently, Wang and Zhou [14] theoretically proved that, co-training can be effective if the learners are diverse, which implies that the sufficient and redundant views are actually used to achieve the diversity of the learners, and they are not necessary if the diversity can be achieved from other ways. For example, in [7], the diversity is achieved by setting different parameters for the k NN method, so that even with the same view, i.e. the same attribute set, co-training still outperforms many other methods. 
In this paper, we adopt the same co-training style in [7], that is, our method does not use two views, and achieves the diversity of learners by setting different values for the parameter k in k NN. Clearly, such implementation is more general than the classical version of co-training. 
In our problem setting, the data in the source domain and target domain have the same feature space X and label set Y ( {0,1} Y = ), but they are under different distributions. The training set T consists of two sets of instances: training data in the target domain (denoted by in the source domain (denoted by T and would refer diff-distribution data set. Moreover, we denote the test set as E , which contains a set of unlabeled instances. 
Both the same-distribution data set 
E are from the target domain, thus have the same distribution. While thus their distributions are different. Note that the size of is supposed to be relatively small, so that merely training on T is unable to produce a high-performance learner. However, the size of that it is easy to obtain large amounts of source-domain data. An illustrative example of Figure 1. 
More formally, we define 
The training set in the target domain: of T . 
The training set in the source domain: of T . 
The test set (in the target domain): vector, and r is the size of the test set. 
The objective of inductive transfer learning is to use T and correctly predict the label of instances in the test set E . 
We know that inductive transfer learning and semi-supervised learning are two different machine learning branches for solving different learning problems. They are motivated by the observation that in many application areas, labeling new data is expensive, as it requires the effort of experienced human annotators. Hence both branches attempt to explore a large number of auxiliary data to reduce the labeling effort. Their differences are: a. Inductive transfer learning focuses on learning from auxiliary labeled data, while semi-supervised learning focuses on learning from auxiliary unlabeled data. b. In inductive transfer learning, the auxiliary and original labeled training data are under different distributions or even different feature spaces, while in semi-supervised learning, the auxiliary unlabeled data and original labeled data are drawn from the same distribution. although in inductive transfer learning, labels of auxiliary data are available, they cannot be used directly due to the distribution divergence. Therefore, re-weighting training data is often adopted to reduce the distribution divergence. While in semi-supervised learning, although auxiliary data are unlabeled, their labels can be predicted as they are under the same distribution with the labeled data. can be explored in two levels  X  instance-level and structure-level. In the instance-level, a learning method attempts to select some useful auxiliary instances and add them to the original training set. Typical methods are self-training [15] and co-training [9] [13] in semi-supervised learning, as well as TrAdaBoost [3] in transfer learning. While in the structure-level, a learning method uses the large collection of auxiliary data to help learn the intrinsic structure of the data. Typical methods are harmonic function [16] and manifold regularization [17] in semi-supervised learning, and Eigen-transfer [18] in transfer learning. In the following, we show the connection between the two branches from the instance-level. inductive transfer learning is to calculate the weight of a diff-distribution instance (we only consider instance-transfer here), while the key step in semi-supervised learning is to calculate the label of an unlabeled instance. The basic idea of extending semi-supervised methods for inductive transfer learning is to replace the step of calculating the label of an unlabeled instance with the step of calculating the weight of a diff-distribution instance. This idea is intuitive, since if the weights of diff-distribution instances are determined, the weighted diff-distribution data can be considered under a quite similar distribution to the same-distribution data (this is because, in instance-transfer, re-weighting diff-divergence). Therefore, after re-weighting, a set of labeled instances under the same or at least very similar distribution to the original labeled data are produced, which is equivalent to the result in semi-supervised learning after the labels of unlabeled instanced being predicted. Thus, semi-supervised learning methods such as self-training and co-training can be easily extended for inductive transfer learning. For instance, co-training can be extended so that each learner teaches the other the weights of some diff-distribution instances. We will discuss the details of such method in next section. feasible, a weighting strategy needs to be designed first. It is noteworthy that the weighting strategy can also be inspired by ideas in semi-supervised learning. For instance, in semi-supervised learning methods, the confidence of an unlabeled instance is often estimated, and the most confident instance is labeled with priority. Such labeling confidence is functionally similar to the weight in transfer learning, since it points out the usefulness of an auxiliary instance. In our co-training method, the weighting strategy can be seen as an extension of the confidence measurement strategy in [7]. A. Weighting strategy learner, with two considerations . First, due to the iterative property of co-training, a base learner needs to be re-trained many times. Since k NN is a lazy learner, the training process is just updating its training set, which is very efficient and easy to implement. Second, due to the local property of k NN (i.e. the label of an instance is predicted by local neighbors), calculating the weight of an instance can be efficient. Therefore, the weighting strategy discussed below is particularly suitable for k NN, yet its underlying idea can be generalized to other learners. error . Definition. The neighbor error of an instance is the error between its true label and the predicted label by its neighboring instances. 
Let ( , ) k nearest neighbors are denoted by weight error of the instance ( , ) following equation: Note in the above equation, predicted label of ( , )
The underlying idea of the weighting strategy is to re-weight an instance according to its influence on the training error. If the influence is relatively positive, the instance will data set error is reduced while a number of error is increased. If Otherwise, the instance is simply dropped. We can see that in equation (2), if smallest value 0.5; if 0 weight has the largest value 1. The intuition is that if a diff-distribution instance brings more positive influence and less negative influence, its weight will be higher. What should be pointed out is that the neighbor error of an instance is not exactly the same as the training error of an instance, since the neighbor error is a real value while the training error is usually a binary value (i.e. correct or not). However, using the neighbor error can help evaluate an instance X  X  influence more accurately due to its real-value property. B. COITL 
In this section, the proposed co-training method (COITL) is discussed in detail. As mentioned in Section II, to make co-training effective, two base learners should be diverse. In our implementation of co-training, two learners both are k NN, thus the diversity is achieved by setting different values for the parameter k . Since the weighting strategy is based on the neighboring structure, different k values will result in differences on instances X  weights given by two learners. Such setting also brin gs another profit, as it is usually difficult to decide which k value is better for the learning problem at hand, two learners with different k values might have complementary effects. 
Let corresponding training set, respectively. Note, in co-training, each learner is trained on its own training set, and its training set can be updated by the other learner. Initially, T and T , in which the weights of all instances are set to be 1. In every iterative step, each learner randomly selects an unprocessed diff-distribution instance and judges whether the instance be re-weighted or just dropped. If the diff-distribution instance needs to be re-weighted, then the learner sets the weight for the instance using the weighting strategy discussed in the above subsection, and adds the weighted instance to the training set of the other learner. This training step repeats until all diff-distribution instances are processed. Note that in our method, a learner just selects a random diff-distribution instance and gives it to the other if it can be re-weighted. This implementation differs from the one in semi-supervised learning, where usually the most confident instance is selected. We use the random selection just because it is more efficient than selecting the instance with the maximum weight (analogous to the labeling confidence in semi-supervised learning). 
After co-training, the hypotheses of combined to give the final hypothesis. A simple method is to use the linear combination, that is, constructing a  X  , hypotheses given by calculate error of weighting factor of a learner is larger if it produces less training error on Table I. C. Efficient implementation 
It is noteworthy that the method in [7] also needs to find a set of instances being influenced by an added instance, i.e. having the added instance as a neighboring instance. They stated that finding all influenced instances in the whole training set is time-consuming and proposed an approximation strategy. However, in this subsection, we give an efficient implementation of our method which can accurately find all influenced instances with the same time and space complexity as the approximation strategy. 
Note that in the weighting strategy, to calculate influenced set (denoted by process the influenced set, our method needs to store necessary information. For simplicity, let us first consider The size of ' T is ( ) On m + . For each instance ( , ) we use an array (, ,..., ) ii i . The array is sorted in ascending order according to the distance between ( , ) i.e., the distance between two instances. The largest neighbor distance, i.e., () neighboring structure (denoted by 
It X  X  easy to see that the space complexity of our method k -length array is maintained. For discussing the time complexity, we distinguish two operations, namely searching for the influenced set and updating the influenced set. The first operation is invoked when we want to find out the weight of a diff-distribution instance, while the second operation is performed when we want to add a weighted diff-distribution instance to th e training set. Assume that calculating the distance of two instances takes comparing two real values takes common cases, set, we need first to calculate the distance between the diff-distribution instance to each instance in the training set, which takes the training set, its distance to the diff-distribution instance should be compared with its radius to see whether the instance is influenced, which takes Therefore, the total time complexity for finding the influenced set for one diff-distribution instance is 
Then, let us consider the time complexity for updating the influenced set. Note that the updating operation itself contains two sub-operations: first, the influenced set for the diff-distribution instance should be searched (because in co-training, the weighted instance is added to a new training set); second, the arrays of each instance in the influenced set should be updated. The first sub-operation takes time, as discussed above. For the second sub-operation, since each array has been already sorted, updating one array takes set be Combing the time complexity of the two sub-operations together, the time complexity for updating the influenced set is cO n m c O kn ++ . Let us make another assumption, that is, ( ) / usually m is very large while k is relatively small (in our experiments, m is 1000, k is no more than 5, and to 3 k ). Hence the time complexity for updating the () () () () () cOnm cOkn cOnm cOnm cOnm ++ &lt;+++=+ . The equation holds because time complexity of searching for and updating the influenced set both are 
Now we come to the co-training setting, in which one learner first re-weights a diff-distribution instance (this invokes the operation named searching for the influenced set), and adds the weighted instance to the training set of the other learner (this invokes the operation named updating the influenced set). Thus, the time complexity for one learner to teach the other learner once is 
As mentioned above, in [7], an approximation strategy was proposed to process the influenced set. However, the time complexity of their approximation strategy is still is also the same as ours, which implies that the approximation is actually not necessary. Also, as stated in [7], in some cases the approximation may bring negative effects. This further demons trates the advantage of our efficient implementation. A. Datasets and preprocessing 
In the experiments, we choose eight datasets, four of which (Mushroom 1 , Waveform 2 , Magic 3 , Splice 4 ) are directly obtained from UCI Machine Learning Repository, and the other three are generated by adding noise to the four original datasets. The Mushroom dataset has 8124 instances. Each instance has 22 attributes which describe some properties of a mushroom. All instances can be classified into two classes -poisonous or non-poisonous. We use the mechanism in [3] to construct the training and test set: for each instance, if its attribute stalk-shape is enlarging, then this instance is put into the same -distribution or test data set; datasets, we fix the size of the diff-distribution data set to be 1000, the size of the test data set to be 1000, and the maximum size of the same-distribution data set is 500 (note in experiments, the size of the same-distribution data set has several different values). To show that the construction mechanism is effective, we can calculate the  X  X iff-test error X  by setting the diff-distribution data as the training data and calculate the prediction error on the test data (the underlying learner is k NN with k = 3). For the Mushroom dataset, the diff-test error is 0.659, which implies the large distribution difference in the same-distribution data and the diff-distribution data (note the test data and the same-distribution data are under the same distribution). In the experiments, we are also interested in the robustness of a learning method. Here the robustness evaluates its sensitiveness to noisy instances. Therefore, for each of the four datasets, we also construct its corresponding noisy dataset (for example, the Mushroom-Noise dataset corresponds to the Mushroom dataset). The mechanism to construct the noisy dataset is to flip a diff-distribution instan ce X  X  label with the probability of 0.015. Note that we only add noise to the diff-distribution data. This makes sense, because usually the same-distribution instances are just a few, which are carefully labeled by humans. The diff-distribution data, however, are often large in amounts, which tend to contain noise. The diff-test error of the Mushroom-Noise dataset is 0.666, slightly larger than that of the Mushroom dataset. 
The Waveform dataset has 5000 instances, each of which contains 21 attributes. All instances can be classified into three classes; however, in the experiments we only choose instances from the first two classes. For each chosen instance, if its first attribute value is larger than 0.15 and its second attribute value is larger than 0, it is put into the same-distribution or test data se t; otherwise, it is put into the diff-distribution data set. The diff-test error is 0.301. Similarly, we construct its corresponding noisy dataset by introducing labeling noise with the probability of 0.015. The diff-test error of the Waveform-Noise dataset is 0.405. 
The Magic dataset has 19020 instances, each with 10 attributes. All instances belo ng to two classes. For each added to the same-distribution or test data set; otherwise, it is added to the diff-distribution data set. The diff-test error of the Magic dataset and Magic-Noise dataset are 0.123 and 0.204, respectively. 
The Splice dataset has 3190 instances, each containing 60 attributes. Each instance belongs to one of three classes ( X  X I X ,  X  X E X  and  X  X either X ). Since in this paper, only binary classification problem is addressed, we combine the class  X  X I X  and  X  X E X  to form a single class. Then, for each instance, if the first attribute value is  X  X  X  or  X  X  X , we add it to the same-distribution or test data set; otherwise, we add it to the diff-distribution data set. The diff-test error of the Splice dataset and Splice-Noise dataset are 0.263 and 0.287, respectively. Table II lists the information of the eight datasets. before formatting. Please take note of the following items when proofreading spelling and grammar: B. Experimental results 
In the experiments, four learning methods are chosen to be compared. They are k NN, COITL, Aux-k NN [5] and TrAdaBoost [3]. For k NN, k is set to be 3. For COITL, the two k values are set to be 3 and 5, respectively. The parameter settings for Aux-k NN and TrAdaBoost follow those proposed in literatures. To test the performance of each learning method in different conditions, the size of the same-distribution data varies from 10 to 500. Table III shows the experimental results (test error) on the Mushroom dataset. We can see that, when the size of the same-distribution data set is smaller than 100, transfer learning is effective, as it reduces the generalization error. When the size of the same-distribution data set is larger than 100, the effects of transfer learning are not apparent. 
It may be difficult to assess the rank of each learning method; therefore we provide a meaningful criterion to compare the performance of different methods. The criterion is named the Average Test Error Reduction (ATER), which is the mean of the reduced test error compared to k NN when the size of the same-distribution k NN or TrAdaBoost), its ATER is obtained using the following equation: where to evaluate the performance of other learning methods. Also, it X  X  easy to see that the ATER reveals the average generalization ability of a learning method. 
Table IV lists the ATER of each learning method on the clear datasets. It is evident that COITL significantly outperforms TrAdaBoost and Aux-k NN on all of the four datasets. Also, TrAdaBoost performs better than Aux-k NN on each dataset. 
Figure 2 shows the performance comparisons of different learning methods on clear datasets. Note that when the number of the same-distribution data is quite small (i.e. equals to 10), transfer lear ning methods can significantly improve the test error. For example, in Waveform dataset, the test error is reduced from over 0.4 to about 0.1 when transfer learning is performed. Also note, the curves of the test error are not monotonously descending, because the same-distribution data are so insufficient that adding just a few same-distribution instances may not help to train a better learner. 
Table V lists the ATER of each learning method on the noisy datasets. Again, COITL achieves much higher generalization than the other learning methods. The results also demonstrate the high robustness of COITL. By contrast, the robustness of TrAdaBoost and Aux-k NN are worse. Note that although TrAdaBoost performs better than Aux-k NN on the Mushroom dataset, it makes larger test error on the Mushroom-Noise dataset. Also note, Aux-k NN has negative ATER on the Waveform-Noise dataset, meaning that its transfer learni ng brings bad effects. Those observations reflect th at TrAdaBoost and Aux-k NN are more sensitive to noise than COITL. 
Figure 3 shows the performance comparisons of different learning methods on noisy data sets. It is noteworthy that adding noise to the diff-distribution data may reduce the test error of the transfer learning methods. For instance, in the Mushroom-Noise dataset, th e three transfer learning methods have better performance than that on the Mushroom dataset. This is not strange because those methods always select useful diff-distribution instances based on the same-distribution data. However, in many cases, the introduction of noisy instances can have bad effects. Comparing Table IV with Table V, we can see that TrAdaBoost and Aux-k NN perform worse on the Waveform-Noise and Magic-Noise datasets than on the Waveform and Magic datasets. 
The outstanding performance of COITL can be roughly explained as follows. First, it utilizes the co-training mechanism which helps to generalize well through maximizing the agreement on the diff-distribution data by two learners. Second, the different k values for each k NN allow them to have some compensated effects on different datasets. For example, k NN with a very small value of k tends to perform well when there is little noise in the dataset, while k NN with a relatively large value of k may be more robust on noisy dataset. In our experiments, we found that although k values are sensitive to different datasets, setting them to 3 and 5 may be a robust choice, as it gives good results on each dataset. In practice, one can also use cross-validation to choose more proper k values. 
Inductive transfer learning and semi-supervised learning are two different branches of machine learning. In this paper, we bridge them by showing that many semi-supervised learning methods can be extended for inductive transfer learning, if the step of labeling of an unlabeled instance is replaced by re-weighting a diff-distribution instance. Based on this recognition, we develop the COITL algorithm which extends the co-training method in semi-supervised learning. COITL employs two k NN learners with different values of k . In every learning iteration, each learner re-weights a diff-distribution instance for the other one, where the weight of the instance is determined according to its influence on the training error. The final prediction is made by linearly combining the predictions of both learners. Moreover, an efficient implementation of COITL with relatively low time complexity is discussed. Experimental results show that, compared with two state-of-the-art methods in inductive transfer learning, COITL can have less generalization error and stronger robustness. 
There are three research issues to be explored in the future: first, theoretically analyzing the properties of COITL; second, extending other semi-supervised learning approaches, like the graph methods, for inductive transfer learning; third, extending inductive transfer learning approaches for semi-supervised learning. The third issue is quite interesting, as we believe it will bring more insightful understanding of the relationship between semi-supervised learning and transfer learning. comments. 
