 There exists a large body of work on online drift detec-tion with the goal of dynamically finding and maintaining changes in data streams. In this paper, we adopt a query-based approach to drift detection. Our approach relies on a drift index , a structure that captures drift at different time granularities and enables flexible drift queries . We formalize different drift queries that represent real-world scenarios and develop query evaluation algorithms that use different mate-rializations of the drift index as well as strategies for online index maintenance. We describe a thorough study of the performance of our algorithms on real-world and synthetic datasets with varying change rates.
Monitoring streaming content is a challenging big data analytics problem, given that very large datasets are rarely (if ever) stationary. In several real world monitoring appli-cations (e.g., newsgroup discussions, network connections, etc.) we need to detect significant change points in the un-derlying data distribution (e.g., frequency of words, sessions, etc.) and track the evolution of those changes over time. These change points, depending on the research commu-nity, are referred to as temporal evolution , non stationarity , or concept drift and provide valuable insights on real world events (e.g. a discussion topic, an intrusion) to take a timely action. In this paper, we adopt a query-based approach to drift detection and address the question of processing drift queries over very large datasets. To the best of our knowl-edge, our work is the first to formalize flexible drift queries on streaming datasets with varying change rates.

In the problem of drift detection, given a number of m drifts ordered in time, we need no less than m + 1 inter-vals to detect them. Thus, without any assumption on the underlying distribution, we are interested in exploring how to segment the input stream in order to find a reasonable tradeoff between true positives and false negatives. Existing methods rely on segmenting the input stream, mostly into smaller fixed length intervals [4, 6, 11, 13, 18]. Although some works exist on partitioning the same stream into in-tervals of different granularities [2, 9, 19], they either adopt an offline analysis or they lack the ability of querying his-torical drifts in streams.

A granularity in this case is an interval of time (e.g., every hour) or a number of observed data points (e.g., every 200 points). A drift is then defined as a significant difference in data distributions between two consecutive intervals at the same granularity. To detect drifts either statistical tests are directly applied on the data of two intervals [7, 13] or on their summaries, as for instance provided by a clustering algorithm [1, 4, 5]. To this end, two parameters impact the accuracy and efficiency of drift detection: the granularity of the intervals at which the original data items are clustered and the drift significance threshold used to assess whether or not there is a drift between two consecutive clusterings. In fact, fine-grained intervals can be used to capture the evolution of frequently changing streams. However, they may induce computation overhead for slowly changing ones. In addition, they may cause false positives, i.e., detecting drifts that are too sudden and noisy, hence hurting preci-sion. While a coarser granularity will improve precision, since more data is clustered in each interval, it may incur missing a drift that occurred at a finer granularity. Those misses will negatively affect recall. Moreover, the rate of change of a given dataset may vary over time thereby re-quiring to consider different clustering granularities and drift thresholds for the same dataset.

Understanding the tradeoff between precision (at higher segmentation granularities) and recall (at lower segmenta-tion granularities), and the choice of thresholds to determine what constitutes a drift between two consecutive intervals of the same granularity, are the main objectives of this work. In this paper, we adopt an analytics approach in which we formalize drift queries over both fresh and historical data of arbitrary time granularities, in order to provide flexibility in tracking and analyzing drifts in evolving datasets. For this reason, we propose a flexible drift index to organize past data (or more precisely their summaries) at several granularities. Furthermore. we explore different creation strategies for this index relying on two common clustering approaches, namely independent [8, 15, 20] and cumulative [1, 5]. In indepen-dent clustering, data points belonging to a given interval are considered equally important and clustered independently. In cumulative clustering, data points in a given interval are clustered with all previously occurring points and fresher data is more important than older data. Moreover, we pro-pose different materialization strategies in order to explore the tradeoff between index storage and query response time.
Unlike existing approaches [4, 6, 11, 13, 18] comparing only the last most recent intervals, we exploit this index in order to identify drifts at different granularities. In partic-ular, we formalize three kinds of queries: unary, refinement and synthesis aiming to detect drifts against historical data. A unary query is used to extract all drifts detected at a given granularity. A refinement query explores drifts from a source granularity (e.g., 5,000 points) to a finer target granularity (e.g., 500 points), iteratively. Such a query is useful to provide a more detailed description of drifts that have been detected in a high granularity, resulting in better recall. Synthesis queries, on the other hand, start from a relatively low granularity and summarize them into coarser ones. In this case, some of the particular details might be missed (low recall) in order to get drifts with higher pre-cision. This flexibility in querying drifts allows us to ex-plore, in a declarative fashion, precision and recall tradeoffs at different granularities. Also, it addresses a long standing concern in detecting and tracking drifts in streaming con-tent, namely adaptability of drift detection to different drift arrival rates and types.

The evaluation of declarative drift queries relies on travers-ing the index of historical data summaries and, at each gran-ularity, comparing its nodes pairwise to identify points where clusterings dissimilarity exceeds a threshold  X  . Rather than setting drift thresholds a-priori [6, 17], we learn a  X  -value for each dataset and at each granularity level in the index.
In summary, this paper makes the following contributions: 1. We introduce and formalize drift queries that provide 2. We propose a drift index, a graph structure that cap-3. We propose learning algorithms for learning drift and 4. We perform a thorough study of proposed queries and The paper is organized as follows. Section 2 defines our data model and queries. Section 3 describes the drift index, the online index maintenance algorithms and threshold learning. Section 4 is dedicated to query evaluation algorithms. Sec-tion 5 contains a description of our experiments and findings. The related work is summarized in Section 6. We conclude in Section 7.
We are given a stream of data points D = { d 1 ,...,d i ,... } , d i = ( tc i ,ts i ) where tc i is an r -dimensional vector of at-tributes describing d i and ts i is the timestamp at which tc arrived. For example, on Usenet each attribute represents a term appearing in news feeds, while on KDD Cup X 99 an at-tribute can be any feature (e.g., transmitted bytes, duration of connection) describing a connection record.
Definition 1. Time-Based and Point-Based Granu-larities. A time-based granularity g is an interval of time. For example, g could be hourly, daily, bi-daily, or weekly. A point-based granularity g is an interval containing a fixed number of consecutive data points. For example, g could be 500 points or 1000 points. We assume a total order between granularities and use g  X  X  X  g 0 to denote that g 0 follows g . We also say that g 0 is coarser than g (and g is finer than g ). We write g  X  g 0 to denote that g 0 immediately follows g when there does not exist a granularity between g and g In both cases, g &lt;&gt; g 0 .
 Definition 2. Time-Based and Point-Based Intervals.
 Granularities are used to segment data points in D . A seg-mentation of a dataset D using a time-based or a point-based granularity g , results in a list of consecutives intervals de-or point-based) of granularity g .

For a daily granularity g applied to segment a week start-ing on Sunday, I g 1 corresponds to the time interval of Sunday. Respectively, I g 1 corresponds to the interval containing the first 500 data points when a point granularity g = 500 is used to segment incoming data.

The choice of point-based or time-based intervals to seg-ment a dataset depends on the rate of arrival of data points. The main advantage of point-based intervals is the pro-cessing of data in fixed-size batches (in terms of number of points) although resulting intervals may have different lengths (in terms of time). Time-based intervals on the other hand, give the ability to tune the time granularity of the analysis (e.g., hour, day) resulting in fixed-length intervals (in terms of time) and varying in size (in terms of number of data points). Consequently, in order to generate intervals of comparable size, datasets that exhibit a high changing rate should be segmented with point-based intervals while more stable datasets can be segmented using time-based intervals.
Definition 3. Granularity Clustering. A granularity clustering C g ( D ) is a partitioning of all data points d D into a set of clusterings { C g i ,C g i +1 ,... } corresponding to consecutive, non-overlapping time intervals { I g i ,I g i +1 granularity g . A data point d i = ( tc i ,ts i ) will belong to one with the j -th entry corresponding to the weight of the j-th attribute (e.g., word). Each cluster c  X  C g i has a centroid, center ( c ) which is itself an r -dimensional vector, where the j -th entry is the mean over the j -th entries of all data points in the cluster.

Definition 4. Clustering Dissimilarity. Given two clus-tween a cluster c  X  C g i and a cluster c 0  X  C g j as the Euclidean distance between their centroids: The dissimilarity between cluster c  X  C g i and a clustering C , cdis ( c,C g j ), is defined as the closest cluster to c in C
The dissimilarity between two clusterings, dis ( C g i ,C defined as: where | C g i | is the number of data points belonging to C
Definition 5. Drift. For a dataset D , a granularity g , a threshold  X  , we say that there is a drift between two consec-and C g i +1 , satisfy dis ( C g i ,C g i +1 )  X   X  . We use x to denote the pair of consecutive intervals for which there detected at granularity g .
The goal of drift queries is to compare drifts at different granularities and provide analysts with the ability to explore drift precison and recall across granularities. We study two kinds of queries, refinement and synthesis . Both kinds rely on a simpler unary query defined as follows.

Definition 6. Unary Query. A unary query UQ ( D,g ) returns the set of all drifts X g detected at granularity g for a dataset D .
 Definition 7. Refinement Query. A refinement query RQ ( D,g s ,g t ) admits a source granularity g s and a target one g t s.t. g t  X  X  X  g s , and returns a set of pairs ( x where each drift x g s i  X  X g s at g s is associated to the finest corresponding drift x g j  X  X g at a granularity g no finer than g as follows: { x g j  X  X g ,g t  X  X  X  g  X  X  X  g s  X  g = g t |  X  x i  X  X @ x k  X  X I j  X  ( I max
Refinement queries provide a detailed analysis of drifts it-eratively. For instance, for a source granularity g s = 1000 connections on KDD Cup X 99, selecting a granularity g 500 might result in missing a more insightful analysis occur-ring at granularity g t = 100. On the other hand, selecting g = 100 may result in retrieving false positives which could be avoided at g t = 500. Therefore, the analyst will use the refinement query RQ ( D, 1000 , 100) to obtain details of each drift at g s = 1000 with a tradeoff between false negatives and false positives.
 Definition 8. Synthesis Query. A synthesis query SQ ( D,g s ,g t ) admits a source granularity g s and a target one g t s.t. g s  X  X  X  g t , and returns a set of pairs ( x where each drift x g s i  X  X g s at granularity g s is associated to the coarsest corresponding drift x g j  X  X g at a granularity g no coarser than g t as follows: { x g j  X  X g ,g s  X  X  X  g  X  X  X  g t  X  g = g s |  X  x i  X  X @ x k  X  X
Synthesis queries provide a summary analysis of drifts it-eratively. For instance, for a source granularity g connections on KDD Cup X 99, selecting a granularity g 1000 might result in missing a more precise synthesis occur-ring at g t = 2000. On the other hand, selecting g t = 2000 can result in missing a summary of a drift, which could be obtained at g t = 1000. Therefore, the analyst can use the synthesis query SQ ( D, 100 , 2000) to obtain a summary of each drift at g s = 100 with a tradeoff between false nega-tives and false positives.
The flexibility of querying drift at different granularities requires the design of appropriate data structures able to capture clusterings at different granularities in such a way that queries are evaluated efficiently. In this section, we de-scribe the drift index , an efficient graph data structure that is used to store and compute clusterings at different granu-larities. We first formalize the index and then study several materializations and develop algorithms for incremental in-dex maintenance as data points continue to arrive.

Definition 9. Drift Index. The drift index is an undi-rected graph G = ( V,E ) where each node contains a clus-tering C g i of points in D during interval I g i of granularity g . Given two different granularities g and g 0 s.t. g  X  g and two intervals I g i of granularity g and I g 0 j of granularity g , there exists an edge in G between nodes C g i and C g 0 I
Definition 9 does not necessarily impose an edge between different materializations of the index may be explored. The choice of which nodes to materialize affects three parame-ters: (i) the index size and hence the time it takes to build and maintain it as new data points arrive, (ii) the query re-sponse time, and (iii) the accuracy of query results. Since our approach is to serve queries for any time period, and not only the latest period at which data points arrived, the index continuously grows in size. Therefore, the key question we address in designing the index is: what are possible index materialization strategies, how much space they consume and how do they affect query evaluation (response time and accuracy)? In this section, we study index materialization alternatives. The impact of each index on query evaluation will be discussed in Section 4. In all our indices, the small-est granularity, g min , is used to generate leaf-level nodes. In Section 5, we experiment with different values of g min .
When fully materialized, the drift index is a hierarchical structure where each level contains clusterings of data points inside intervals of the same granularity. Nodes correspond-ing to the finest granularity are leaves in the graph and each node, except nodes at the coarsest granularity, has one or two parents. For example, a node containing a clustering of data points for a 1-day granularity, e.g., Monday, will have two parent nodes each of which corresponds to a two-day granularity, in this case, Sun-Mon and Mon-Tue. Similarly, a node containing 1000 data points will have two parents, one containing it with the previous 1000 points and another containing it with the following 1000 points. More formally, given two granularities g and g 0 s.t. g  X  g 0 , and two inter-vals I g i and I g 0 j , there exists an edge from node C C j iff I
Each node of the index contains a clustering of data points of a given granularity. Thus, an important aspect of index materialization is the selection of a clustering strategy and algorithm to generate the nodes. According to the cluster-ing literature, timestamped datasets can be clustered in one of two ways. The first one, referred to as the independent strategy , encompasses a family of algorithms built upon the idea of visiting consecutive batches of data points by con-sidering them as independent (e.g., one batch for Mon and another for Tue) and equally important in terms of arrival time (e.g., older data points are not penalized against fresher ones) [15, 8, 20]. The second approach, referred to as the cumulative strategy , parses data in a cumulative, single-pass fashion (e.g., data of Tue are clustered with those of Mon), aging older data points in a such a way that fresher data points are given more importance [1, 5]. Our exhaustive in-dex is designed to work with any of the two clustering strate-gies which gives rise to two indices: Independent-Exhaustive (IE) and Cumulative-Exhaustive (CE).
IE is generated using the independent strategy where nodes of the same granularity, e.g., Sun, Mon, Tue, are produced using data points of consecutive, non-overlapping intervals. Nodes at the finest granularity level are produced by clus-tering the arriving data points, while nodes at coarser gran-ularities are produced by summarizing the centroids of clus-terings associated with lower granularities.

Figure 1a illustrates an instance of IE with nodes num-bered in the order they are created. Algorithm 1 summarizes the different steps for building and maintaining the index. The algorithm takes as input the drift index G (empty at the beginning, non-empty in the case of index maintenance), a data stream D , a maximum granularity g max , and an inter-val I g min of minimum granularity g min . For each batch of using an independent clustering algorithm (e.g., DBScan [8] or k -means [10]). Nodes 1 to 6 of Figure 1a are produced by this step. Then, nodes at coarser granularities (e.g., nodes 7-15) are generated by applying the same algorithm over the centroids of clusters at lower granularity (lines 7-12). Algorithm 1 IE Creation &amp; Maintenance Input: Drift index G , Stream of data points D , Max gran-Output: Updated drift index G 0 1: G 0  X  G 2: { I g min 1 ,I g min 2 ,... } X  consecutive intervals at g 4: C g min i  X  clustering in I g min i (e.g., DBScan, k -means) 5: Store C g min i in G 0 at granularity g min 6: end for 7: for all g min  X  g  X  X  X  g max do 8: for all C g i  X  C g do 9: C  X  clustering of the centroids of C g i and C g i +1 10: Store C in G 0 as the right parent of C g i 11: end for 12: end for 13: return G 0
CE is generated using the cumulative strategy where nodes of the same granularity, e.g., Sun-Mon and Mon-Tue, are produced using data points from overlapping intervals. As a result, data points belonging to a given interval are clustered with previously occurring data points.

Figure 1b shows an instance of CE with its nodes num-bered in the order they appear. Algorithm 2 summarizes steps of building and maintaining CE. The algorithm takes as input a drift index G (empty at the beginning, non-empty in the case of index maintenance), a data stream D , as well as the maximum granularity g max , and the minimum gran-ularity interval I g min at g min . After the initialization steps (lines 2-5), each data point is assigned to a cluster (line 7-8). clustering is generated and its centroid is stored in the index (line 11) at granularity g , which is incremented until g Nodes 1, 2 and 4 of Figure 1b are generated by this step. When the maximum granularity g max is reached a new path is initialized starting from the smallest granularity (line 16-21) and the process is repeated. Node 7 initializes this new path. In addition, for every node added in the index, its right sub-path to g min is also produced (line 21). For instance, after the addition of node 4 in Figure 1b, its right sub-path consisting of nodes 5 and 6 is also added. These nodes are produced by applying the subtractive property [1] of clusters (i.e., subtracting clusters centroids). Finally, there is a set of nodes that do not belong to any right sub-path (e.g., nodes 10, 14, 15), forming the inverse triangle of Figure 1b. Each one of these nodes is generated after the addition of its right sibling and its sibling X  X  sub-path. Lines 12-14 of Algorithm 2 illustrate this process using the additive property [1] of clusters (i.e., adding clusters centroids).

To handle infinite streams, several deletion strategies can be provided. A naive approach is to remove x intervals every X data points, including all corresponding nodes. However, Algorithm 2 CE Creation &amp; Maintenance Input: Drift index G , Stream of data points D , Max gran-Output: Updated drift index G 0 1: G 0  X  G 2: if G 0 is empty then 3: C  X  clustering of D (e.g., DBScan, k -means) 4: store C in G 0 5: end if 6: g  X  g min 7: for all d i  X  D do 8: C  X  clustering of d i (e.g., CluStream) 9: if ( ts i  X  ts 1 ) % I g min == 0 then 10: if g  X  X  X  g max then 11: store C in G 0 at g -th granularity 13: Build inverse triangle at g , by merging each 14: end if 15: Move g to immediately following granularity 16: else 17: C 0  X  C  X  C g max j %Initializes path by subtracting 18: Store C 0 in G 0 at granularity g min 19: Move g to granularity immediately following g min 20: end if 21: Create right sub-path of node C 22: end if 23: end for 24: return G 0 this approach misses valuable historical data. For this rea-son, we consider an alternative deletion policy in which for every X data points, the oldest x intervals are deleted and only their highest available node in the index is kept.
Since fully materialized versions of the drift index are ex-pected to consume a lot of space, we propose Independent-Leaf (IL) and Cumulative-Path (CP) two partial index ma-terializations, where fewer nodes are materialized thereby resulting in indices that are smaller in size.

The main idea in IL is to build nodes at the lowest gran-ularity only (black nodes in Figure 1c), corresponding to lines 3-6 of Algorithm 1. All other nodes of higher granu-larities can be extracted from the leaf nodes at query time, if necessary. Respectively, the main idea in CP is to build paths containing all the nodes at higher granularities that include a given leaf node (black nodes in Figure 1d). The algorithm that builds and maintains CP is a modification of Algorithm 2, by ignoring lines 12-14 that build nodes of the inverse triangle and line 21 that builds the right sub-paths. From these nodes, built in partial materialization, all the re-maining nodes (gray nodes in Figure 1d) may be generated at query time, if necessary (more details in Section 4).
The worst-case time complexity of IE and IL is dictated by DBScan, which needs O ( logn ) time to find the neighbors for each of the n data points within an interval. Thus, the time complexity is O ( m  X  n  X  logn ), where m is the number of nodes in the index. Furthermore, each cluster is repre-sented by the statistics ( CF 1; CF 2; n ) where CF 1 and CF 2 are r -dimensional vectors. Particularly, CF 1 (resp, CF 2) maintains, for each dimension, the sum of data values (resp, sum of the squares of data values). Thus, each cluster main-tains 2 r +1 values and the space complexity is O ( K  X  (2 r +1)), where K is the number of clusters for all nodes.

The worst-case time complexity of CE and CP is speci-fied by k -means, O ( n  X  k  X  d  X  i ), where n is the number of r -dimensional data points forming k clusters at each inter-val and i the number of iterations. Furthermore, the space complexity is O ( m  X  k  X  (2  X  r + 3)), where 2 r + 3 values are maintained for each of the k -clusters of all m clustering nodes. These values contain the statistics described for IE and two extra values (details in [1]); the sum and the sum of the squares of the timestamps of input data.
 Finally, the total number of nodes maintained in IE and CE is m = 1 2  X  L  X  (2  X  X  C gmin | X  L + 1), where | C g min | is the number of clustering nodes at g min and L is the number of index levels. The total number of nodes maintained in IL and CP is m = N g
According to Definition 5, when the dissimilarity between two clusterings exceeds a threshold  X  , a drift is detected. Since fixed threshold values are not always appropriate for data with varying drift rates, we are interested in learning  X  experimentally and do so for each granularity of our index.
During the learning phase, a training dataset is used in order to estimate the drift parameter,  X  . The training region is independent from the testing dataset over which queries are to be evaluated. Furthermore, the estimation of  X  is automated and without any a-priori knowledge of the arrival rates of drifts. However, in order to be well-estimated, it should be learned on a long-enough time period to ensure capturing the occurrence of several drifts.

Algorithm 3 summarizes the learning process of  X  g values per granularity level g . The algorithm takes as input a drift index G , as well as minimum g min and maximum g max gran-ularities for which  X  g values need to be estimated. For each granularity g within g min and g max , it extracts the distri-bution of dissimilarities X , based on Definition 4, between each pair of consecutive clusterings at g (line 3). Then, it performs DBScan (i.e., any other algorithm could be used, like k -means) over X , given as the average pairwise simi-larity of the 3-nearest neighbors in X . DBScan is performed 10 times, in order to select the clustering C that optimizes the DunnIndex criterion. The Dunn index aims to identify dense and well-separated clusters. It is defined as the ratio between the minimal inter-cluster to maximal intra-cluster distance. The inter-cluster distance is defined as the aver-age distance between the centroids of the clusters. Similarly, the intra-cluster distance is defined as the average distance of any pair of points inside each cluster. Finally, the value of  X  g is extracted by calculating the average Euclidean dis-tances between clusters in C (line 10).

The precision of  X  estimation could be challenged when the similarity between two consecutive clusterings (see line 3) varies significantly (i.e., bimodal distribution). This is due to the fact that the clustering distance is estimated (see line 10) by using the mean of clusters distribution and assuming a low and constant standard deviation over time. Applying a Z-Score statistical test over all training and testing intervals we observed that the variation of the majority of intervals Algorithm 3 Learning of  X  -parameter Input: Drift index G , Minimum granularity g min , Maxi-Output: Parameter  X  g for each g min  X  X  X  g  X  X  X  g max 1: minPts  X  number of data dimensions 2: for all g min  X  X  X  g  X  X  X  g max do 3: X  X  dissimilarities distribution between consecutive 4:  X  avg pairwise similarity of 3 NN in X 5: for all i  X  [1 , 10] do 6: C  X  DBScan ( X,,minPts ) 7: dunnIndex  X  DunnIndex ( C ) 8: Pick C that maximizes dunnIndex 9: end for 10:  X  g  X  average between clusters similarity of C 11: end for (at least 95%) are less than two times the standard deviation from the mean for all granularities and real datasets.
We also propose a training phase to learn the parame-ter used by DBScan for building IE. Parameter defines a maximum -neighborhood for each cluster. In literature, a common way to choose its value is by plotting all distances to the nearest neighbors and selecting the value where the plot shows a strong bend. A similar approach is followed by our learning process, adapted to each granularity level. For brevity, we omit the algorithm for learning . The param-eter can be estimated without any condition on the period X  X  length. Thus, we propose to estimate both parameters (  X  , ) within the same wide-enough period.

It is worth noticing that the estimation of clustering pa-rameters can quickly become outdated, particularly when dealing with rapidly evolving data distributions. In such cases, parameters re-estimation (e.g., every X intervals) may be useful to periodically adapt their values to data changes.
This section presents our query evaluation algorithms us-ing our proposed indices. Refinement and synthesis queries rely on unary queries that return a set of drifts X g for any g . This is done by comparing the statistics between each pair of consecutive, non-overlapping clusterings at g using threshold  X  g . When a partial index is used (IL or CP), some index nodes (depicted in gray in Figures 1c, 1d) need to be generated on the fly possibly incurring computation over-head. The unary query algorithm is straightforward and is omitted for brevity. The performance of unary queries will be studied in detail in Section 5.

Algorithm 4 illustrates the steps for evaluating a refine-ment query. It takes as input any of the four materialized drift indices G and a range of granularities between g s and g . Initially, it applies a unary query to detect all drifts x i  X  X it detects all corresponding drifts x g j  X  X g at finer granu-larities g, that are no finer than g t (lines 3-11) using the
A synthesis query is evaluated over a drift index G and a granularity range between g s and g t , where g s  X  X  X  g t . The steps of the algorithm are equivalent to Algorithm 4, by sim-ply replacing the condition in line 8 with I g s i  X  ( I g Thus, for any observed drift x g s i at g s , a corresponding drift Algorithm 4 RefinementQuery Input: Drift index G , Granularity range [ g s ,g t ] ( g Output: A set S of drift pairs ( x g s i ,x g j ), g  X  X  X  g 1: S,prev,curr  X  X  X  2: X g s  X  UQ ( D,g s ) 3: for all x g s i  X  X g s do 4: for all g s  X  X  X  g  X  X  X  g t do 5: prev  X  curr ; curr  X  X  X  6: X g  X  UQ ( D,g ) 7: for all x g j  X  X g do 9: curr + = x g j 10: end if 11: end for 12: if curr ==  X  then 13: S + = ( x g s i ,prev ) 14: break 15: end if 16: if g == g t then 17: S + = ( x g s i ,curr ) 18: end if 19: end for 20: end for 21: return S x j at a coarser granularity g , no coarser than g t is returned. The time interval I g j  X  I g j +1 of the corresponding drift x should take place during I g s i where x g s i was observed.
In this section, we provide a thorough investigation of our queries, both from the accuracy and the scalability perspec-tives. All experiments were conducted on a 2 GHz Intel Core i7 processor with 8 GB memory, which runs MAC op-erating system. Our accuracy results are the average of 5 consecutive runs. We learn and  X  on a training dataset covering approximately 30% of the input data. Also, unless mentioned otherwise, we set the k parameter of CE to the average number of clusters produced by IE. Finally, we refer to each granularity level using incremental numbers (e.g., level 1 for the lowest granularity, then 2 etc). For both clus-tering algorithms (Clustream [1] and DBScan [8]), the imple-mentations provided in MOA [3] are used. Some necessary extensions are applied in the implementation of CluStream, in order to provide additive and subtractive properties [1].
We developed a synthetic data generator that provides the flexibility to produce datasets deriving from different distributions (i.e., well-separated, overlapping) and rates of change (i.e., sudden, incremental). Furthermore, the param-eters of clustering are also tuned, including the number and size of clusters, as well as their density.

Specifically, synthetic datasets are produced with data points deriving from two distributions in a low and a high region. Each distribution consists of a number of close clus-terings, that derive from the same region (i.e., low, high). Furthermore, each distribution contains a given number of data points and each clustering is described by k clusters. The total size of synthetic data is generated randomly and the number of drifts is also parameterized.

Three data sets are generated, in order to simulate differ-ent types of drifts. Figure 2 illustrates two examples. Specif-ically, Figure 2a depicts sudden drifts, marked with vertical lines, that occur each time the distribution of data oscillates between low and high region. The distribution of data in low region has values within [2, 4], while the distribution of high within [10, 12] forming well-separated regions. On the contrary, Figure 2b illustrates incremental drifts, occur-ring between low [2,4] and high [3, 5] regions of overlapping values. Finally, a third dataset is generated containing in-cremental drifts of consecutive regions, with values of low region within [2,4] and high within [4, 6].

For the purpose of building the index, the dataset is split into intervals of 200 data points each forming a leaf node at g min . The next granularity consists of 400 points, the third of 600 and the 10th contains intervals of 2000 data points.
Query accuracy was evaluated over two datasets derived from two different application domains. The first collection consists of 5,931 Usenet articles from the 20 Newsgroup col-lection where each article belongs to one of 6 news feeds (e.g., sports, science). A user can subscribe to any of these feeds, showing his interest in receiving relevant articles, or unsubscribe at any time. Each article is represented with a binary vector of 658 attributes, where each attribute indi-cates the absence or presence of a word. Another attribute indicates whether the user is interested in an article or not. Thus, the clustering procedure will result in clusters contain-ing articles that are likely to derive from the same feed (e.g., sports) and interest the user. A drift is the moment where a user decides to unsubscribe from some feeds and subscribe to others and can be computed on the whole data. The ground truth hence is known and encompasses five drifts. Exper-iments on Usenet are performed using a small point-based interval of 100 data points, a maximum index depth of 6 and the number of clusters for CE is k = 3. The training set consists of 2,400 data points, containing 2 drifts.
The second dataset of KDD Cup X 99 is a Network Intru-sion detection stream of 494,020 normal TCP connections and cyber attacks. It contains a variety of intrusions that fall into 4 categories: DOS, R2L, U2R and PROBING. Most of the connections in the dataset are normal but occasionally bursts of attacks appear. Thus, we are interested in detect-ing drifts where realtime attacks occur. Each connection is described by 42 categorical (e.g., type of protocol) or contin-uous (e.g., bytes transmitted) attributes. For our analysis, we use the 34 continuous attributes. In order to create a ground truth for evaluating query accuracy, we consider as drifts the time moments where at least minAttacks = 30 consecutive malicious connections appear. The ground truth hence encompasses 45 drifts on the whole dataset. We set the smallest granularity to 500 points, the index depth to 10, corresponding to an interval length of 5,000 points and k = 4. The training dataset contains 20,500 points.
The smallest granularity is a critical parameter, indicated by the magnitude and arrival rate of drifts. To this end, the parameter settings used in [12] are applied for our experi-ments in Usenet, where 5 drifts exist within 5,931 points. On the contrary, wider intervals are selected for KDD Cup X 99 of lower arrival rate with 45 drifts within 494,020 points.
Our experiments show that unary queries can reach a 79% accuracy on real datasets. They also show that indepen-dent clustering attains a significantly better accuracy than cumulative for incremental changes of overlapping data dis-tributions. They also confirm the usefulness of refinement and synthesis queries, by demonstrating their ability to ex-plore the tradeoff between precision/recall. For instance, using CE, while UQ (KDD , 1) and UQ (KDD , 10) attain 52% and 13% accuracy respectively, SQ (KDD , 1 , 10) attains 74%. Moreover, the scalability evaluation of our indices show a tradeoff between full and partial materializations, in terms of index size and query response time. Fully materialized indices are at least an order of magnitude faster in query re-sponse time than partial. On the contrary, fully materialized indices require at least 4 times more space than partial.
Query accuracy varies between full and partial index ma-terializations. This variation is caused by the random par-titioning of data points during DBScan and k -means clus-tering. However, this variation is minimized with multiple executions and is not statistically significant. Hence we pro-vide accuracy results for exhaustive indices only (IE, CE), assuming a not significantly different performance of partial indices (IL, CP). The accuracy is evaluated by using the tra-ditional F-measure, which is the harmonic mean of precision and recall. A detected drift is considered a true positive if the corresponding real drift is within the compared intervals in the ground truth. This evaluation strategy is also used in [13]. For instance, a detected drift at point 800 extracted by comparing the point-based intervals [400, 800) and [800, 1200) will correspond to a real drift within the region [400, 1200). This drift can, for example, take place at point 1000. However, a drift at point 1000 might also be detected by comparing intervals [800, 1200) and [1200, 1600). Thus, in case of multiple detections of the same drift at a given gran-ularity, we ignore its subsequent detections.
Synthetic Data. The goal of synthetic data evaluation is to understand how different time granularities, as well as clustering strategies (independent, cumulative) affect query accuracy. To this end, we perform unary queries over differ-ent granularity levels and for both CE and IE.

Figure 3a illustrates the accuracy (y-axis) of unary queries for different granularities (x-axis) over the synthetic dataset with sudden drifts (Figure 2a). It shows that accuracy is very good for low granularities. However, recall worsens at higher granularities. Consequently, increasing the resolution of analysis decreases the ability of the algorithm to observe drifts occurring at finer granularities. However, precision remains greater than 0.9 at all levels.

Figure 3b depicts the unary queries behavior when ap-plied on incremental drifts of consecutive data regions. We observe that the algorithm performs badly for very small or very large intervals. Very small intervals are sensitive to subtle changes causing a large number of false positives. Thus, those granularities suffer from low precision but ex-hibit high recall. Similarly, very wide intervals are suscepti-ble to false negatives as they may miss drifts existing within them. On the contrary, intermediate granularities provide intervals that fit data better and improve accuracy.
The last dataset containing incremental drifts of overlap-ping regions (Figure 2b) reveals a statistically significant difference in accuracy (Figure 3c) between IE and CE for all levels greater than 2. The observed difference is due to the design of each index. For instance, CE tends to add in-put data into existing clusters. This addition causes cluster centroids to shift over time and absorb any change, con-sidering it as non-significant. To alleviate that, we ran an experiment varying the number of clusters, k . Although not shown here, we observed no significant improvement in per-formance. Thus, the online and one-pass design of the algo-rithm causes the absorption of incremental changes. On the contrary, IE forms clusters by independently visiting data points in different intervals. The algorithm detects data re-gions of high density and is independent from previously computed clusters. Therefore, IE outperforms CE for over-lapping data regions.

Although accuracy tends to decrease at higher index lev-els, there are some oscillations between levels. These fluc-tuations can be explained if we consider the statistical error introduced by adding and subtracting clusters X  statistics as in [1]. A typical example of this error is illustrated in Fig-ures 3a to 3c regarding the accuracy of CE at levels 9 and 10. Several nodes at level 9 are produced by the additive and subtractive property. On the contrary, none of the nodes at level 10 are generated by these properties. Thus, level 10 has a lower statistical error than level 9 and shows better accuracy despite its wider intervals.

Finally, we provide a comparison of our drift index accu-racy with a state-of-the-art drift detection algorithm, named CUSUM [16]. CUSUM calculates the cumulative sum which detects a drift when the mean of the input data is signifi-cantly different from zero. Results show that our drift in-dex outperforms CUSUM for each granularity and dataset. Specifically, CUSUM reaches a 98% of accuracy for the dataset of sudden drifts, while the accuracy drops in 24% and 16% for consecutive and overlapping datasets respectively.
Real Data. Figure 3d shows the F-Measure results of unary queries (y-axis) on Usenet for each level in the index (x-axis). The main trend observed is an increase in accuracy as the granularity increases. This is not surprising, as the frequency of drifts in this dataset occurs at least every 700 data points. Thus, when the interval length increases (especially to 600 points at g max ) the algorithm performs very well, as there are enough available points to detect the drift. In fact, the unary query at g max reports three different drifts. A user who initially subscribed to electronics and crypt news changed her interests into hockey and sales and then subscribed to motorcycles and space news. It is worth mentioning that the inappropriateness of interval length at the leaf level induces CE to report no drifts.

Tables 1 and 2 illustrate the accuracy (last line) of unary queries for KDD Cup X 99 for each granularity level of IE and CE respectively. Similarly to synthetic data, we observe that the finest and coarsest granularities cause a decrease in accuracy for both indices. Indeed, a low precision and a high recall characterize the leaf level and the inverse is observed at the coarsest granularity.
We designed refinement and synthesis queries to explore precision and recall tradeoffs. For brevity, in Tables 1 and 2 we present only the accuracy results for KDD Cup X 99. Each row (resp. column) corresponds to g s (resp. g t ) which are given as input to the queries. The tables contain every possi-ble combination of levels in an attempt to discuss the impact of each query on accuracy. For example, a refinement query is evaluated over a small range of levels (e.g., RQ ( D, 2 , 1)), as well as on the entire index (e.g., RQ ( D, 10 , 1)). The upper-half of the tables contains the F-Measure of synthesis queries and the lower-half concerns refinement queries. The best accuracy results for each table are mentioned in circles, along with the corresponding unary queries results.

The question we attempt to answer is whether refinement and synthesis queries can attain a tradeoff between accuracy of unary queries at g s or g t . All values mentioned in bold indicate those cases. Thus, in the majority of the queries, the analyst will get a summary of drifts that exploits the tradeoff of precision and recall between g s and g t . However, Table 1: F-Measure for refinement (lower matrix) and syn-thesis (upper matrix) queries over IE , KDD Cup X 99
Table 2: F-Measure for refinement (lower matrix) and syn-thesis (upper matrix) queries over CE , KDD Cup X 99 note that there are few cases where the F-Measure is worse than any of the two levels. These cases are observed espe-cially when refining queries at very low granularities (i.e., first two columns of tables). Low levels have a high rate of false positives, which negatively affects accuracy even when refining only the most precise drifts of higher levels.
We perform an index scalability experiment to study in-dex size and build time and query response time. For this purpose, synthetic datasets of different sizes are produced.
Index size depends exclusively on the number and size of maintained nodes. Therefore, increasing the number of in-dex nodes, for instance by increasing the index depth or the volume of input data or by decreasing the interval length, will inevitably lead to an increase of the index size. More-over, increasing the size of each node, for instance by in-creasing the number of clusters ( k ), will negatively impact index size. We fix the depth to 5 and we test the impact of the other parameters on the scalability of our indices.
Varying Dataset Size . Figure 4a illustrates the drift index size calculated in MBs (y-axis) as a function of input data size calculated in number of points (x-axis). We set the minimum interval size at g min to 100 points for all datasets. The chart is in a log-log scale and we observe a linear trend of all indices as data size increases. We also observe that the lines of cumulative indices have a steeper slope. This is explained by the extra overhead paid for maintaining infor-mation about a cluster X  X  origin. This information describes if a cluster is derived from others and is more likely to increase as the dataset increases. Finally, as expected, partially ma-terialized indices consume at least 5 times less space.
Varying Interval Length . The interval length selected for each granularity has also a critical impact on index scal-ability. Figure 4b shows the result of varying the interval length within [100 , 1000] for a fixed dataset size of 225,000 points. Figure 4b reports a decreasing index size trend for all indices with wider intervals. When the size of an inter-val increases, the size of the clustering inside that interval is not affected. That is because the same clustering statistics are maintained. Thus, wider intervals reduce the number of nodes maintained by the index without affecting the size of each node. This explains the decreasing trend observed.
The most frequent and time consuming operation of drift detection is the computation of clustering dissimilarities for every pair of nodes at each granularity. The cost of this op-eration naturally increases with the number of index nodes as shown in Figure 5a. Figure 5a illustrates the response time of all unary queries applied at each granularity for dif-ferent dataset sizes. It is evident that IL and CP need at least an order of magnitude more time to detect drifts, as they produce missing nodes at query time.

Figure 5b illustrates the build time of each index, provid-ing evidence for the trade-off between index building time and query response time. Figures 5b and 5a indeed show that the more time we spend building the index, the less time we need during query evaluation. Furthermore, Fig-ure 5b illustrates that both independent indices, IE and IL, need more build time than cumulative ones, CE and CP. Despite the fact that IL is a partial index, it needs a higher build time than CE. This could be explained by the fact that IL iteratively visits data points in order to form clusters.
Figure 6a depicts unary query response time (y-axis) per granularity (x-axis) for a synthetic dataset of almost 225K data points. IL shows a sharp increase in drift detection as levels increase, due to generating missing nodes on the fly. On the contrary, IE X  X  response time decreases at higher levels, due to fewer nodes. Thanks to the hierarchical struc-ture of our indices less nodes exist at higher granularities, explaining the almost constant response time after level one for both indices. That also explains the sudden drop in re-sponse time for CP.

The performance of refinement queries is measured start-ing from level g s = 5 until all finer levels of g the x-axis of Figure 6b. We notice that the longer the path from g s to g t , the more time it takes for the query to respond (for all indices). The same behavior is observed on synthesis queries, as shown in Figure 6c, where g s = 1.
Most of the existing drift detection methods rely on seg-menting the input stream into smaller fixed length inter-vals [4, 6, 11, 13, 18]. The comparison of intervals is then based either on statistical tests or on probabilistic measures. In the former case, a null hypothesis of equal distributions is formed [7, 13], while in the latter a user-defined threshold is utilized to detect drifts [6, 18]. However, a drawback of these works derive from the lack of dynamically adapting thresholds to the varying change rates. Furthermore, they suffer from the problem of single granularity, due to fixed length intervals, resulting in low precision/recall.
An attempt to solve the problem of single granularity is made in [14] by providing multi-partition techniques, but it also remains in an offline context. On the contrary, an online drift detection approach that aims to detect the most recent drifts, by comparing the last two intervals, is presented by FLORA2 [19]. FLORA2 dynamically learns interval length. Figure 5: Unary Query Response and Index Build Time A heuristic method shrinks the interval, by forgetting old data points, each time a drift occurs; otherwise, the interval grows. Also, some other approaches exist [2, 9] calculat-ing statistics over sliding and growing intervals in order to detect a drift. However, all these works lack the flexibility of querying historical and fresh data for detecting drifts at different granularities.
Our work introduces a novel form of analytical queries for detecting drifts in streaming content. Their evaluation re-lies on drift indices allowing us to explore, in a declarative fashion, precision and recall tradeoffs introduced by data segmentation at different granularities. We believe that our work lays the foundation for a series of new contributions addressing a long standing concern, namely adaptability of drift detection to different drift arrival rates and types. For fast arrival rates of drifts the detection accuracy could be excelled utilizing fine-grained intervals maintained in the in-dex. On the contrary, for slow rates, coarse-grained inter-vals are preferred, compromising the computation overhead. Furthermore, sudden drifts can be easily detected by sev-eral state-of-the-art clustering techniques, while incremental drift detection is favoured by independent clustering.
One direction we are pursuing is the applicability of our approach to the detection of sales drifts in the retail industry and the ability to compare drifts over time across multiple products and stores.
