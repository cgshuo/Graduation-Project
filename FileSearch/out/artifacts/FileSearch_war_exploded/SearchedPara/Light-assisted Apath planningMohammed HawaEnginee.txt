 1. Introduction
Path planning finds many applications in the field of artificial intelligence, including: controlling movements of mobile robots; controlling movements of virtual characters in computer games; finding a point-to-point path in map-assisted driving; and con-trolling autonomous vehicles for military and civilian applications ( Russell and Norvig, 2010 ; Latombe, 1991 ; Pearl, 1984 ; Vendrell et al., 2001 ; Dougui et al., 2011 ).

Path planning refers to the problem of finding a route ( path ) between a start node and a goal node on a map (grid) ( Li et al., 2008 ). An optimal path is the shortest path (or the minimum-cost path) between these two nodes. A number of path planning algo-rithms have been proposed over the years, the choice amongst them is essentially a trade-off between finding the optimal path and the efficiency in finding this path (i.e., the algorithm runtime and memory requirements). This trade-off depends on the requirements of the application at hand, and is critical to the success of such application.

The guided best-first A n algorithm ( Hart et al., 1968 , 1972 ) is the standard against which other path planning algorithms are compared. This is because of its simplicity and its proven optimality ( Pearl, 1984 ; Dechter and Pearl, 1985 ; Zhang et al., 2010 ). However, a serious drawback of A n is that, in the worst-case, the runtime as well as the amount of memory required increases exponentially with the depth of the search. This has led to used by the algorithm ( Kaindl and Khorsand, 1994 ; Korf and Zhang, 2000 ; Russell, 1992 ; Zhou and Hansen, 2002 , 2003 ), while others reduce runtime by allowing for bounded suboptimality of the resulting solution ( Pohl, 1970 , 1973 ; Ghallab and Allard, 1983 ; Pearl and Kim, 1982 ; Reese, 1999 ; Thayer and Ruml, 2008 , 2010 ).

However, to the best of our knowledge, none of the previous obstacles. This is illustrated later in Fig. 3 where the search space presence of an obstacle (especially a maze-like obstacle). process for the desired path, particularly in scenarios where there are complex-shaped obstacles in the map. Experimental results solutions that are very close to the optimal path (within 3.8% of the optimal solution in the worst case scenario in our tests). The blocked by obstacles much earlier in the algorithm using light assistance, which ensures that the search stays focused on promising paths.

This paper is structured as follows. Section 2 provides the suboptimal heuristic search. In Section 3 , we describe the pro-ality parameter l and the light propagation parameter y ) to vary performance is studied using three types of path planning problems: grid path finding, robot navigation, and random mazes, and the results are reported in Section 4 . Finally, conclusions are presented in Section 5 . 2.1. Background oped over the years. These can be categorized into: cell decom-position methods, roadmaps ( Kavraki et al., 1996 ; Leven and
Hutchinson, 2001 ; Kuffner and Lavalle, 2000 ), and potential fields ( Koditschek, 1989 ; Brock and Khatib, 1999 ; Murphy et al., 1999 ).
Cell decomposition methods are the most popular, in which the moving object is treated as a point moving in a two dimensional x and y coordinate space (i.e., a grid) ( Chen et al., 1995 ; Sleumer and Tschichold-Gurman, 1999 ). The cost of travelling from one grid node to the next is a metric that represents the character-istics of the world around each of the grid nodes (openness, elevation, traversability, energy expenditure and so on) ( Latombe, 1991 ). A path planning algorithm searches through the grid connectivity to generate a path representing the sequence of nodes connecting the start and goal nodes. The path cost (or sometimes path distance ) is the sum of costs of crossing the nodes on that path. The part of the grid investigated by the path planning algorithm is referred to as the search space . rithms such as depth-first , breadth-first or uniform-cost searches to cell decomposition they often explore an unnecessarily large number of nodes in the grid, and hence, take too much time (and memory) doing so ( Russell and Norvig, 2010 ). Introducing heuristics , which represent additional information indicating the proximity to the goal, can improve the efficiency of the search the cost from the start node g and an estimated cost to the goal (the heuristic) h . For convenience, a brief description of A n and its basic notations is provided in the next subsection. nected two-dimensional grid of nodes. The movement from node n to a neighboring node m on such a grid is assigned an associated cost C  X  n , m  X  . Moving to nodes with obstacles is assigned infinity cost. For simplicity and throughout this work, we will normalize the cost of traversing between nodes in the grid to:
C  X  n , m  X  X  which means the cost is related to the distance traveled between the nodes. The 1 : 4 movements as opposed to two combined horizontal and vertical movements.
 path to the goal node using two lists for its search: an O
C LOSED list. For each node n that A n adds to its lists, it computes a cost -plus-heuristic function (denoted by f  X  n  X  for node n )to determine the order in which the search should proceed. The group of all nodes n for which the algorithm calculates the function f  X  n  X  is the algorithm search space. Hence, the search space is the set of nodes in both the O PEN and C LOSED lists. The size of the search space decides the memory requirements and processing power (CPU runtime) needed for the algorithm.
The function f  X  n  X  is the sum of two parts f  X  n  X  X  g  X  n  X  X  h  X  n  X  , where g  X  n  X  is the total cost for moving from the start node all the way to node n (across the minimum-cost path between these two nodes), while the heuristic h  X  n  X  is an estimate of the remaining cost to the goal node from node n . For A n to result in optimal solutions, the heuristic should be a strictly admissible heuristic estimate , which means it must never overestimate the optimal cost to the goal node ( Russell and Norvig, 2010 ; Pearl, 1984 ; Dechter and
Pearl, 1985 ). The A n algorithm is summarized in the pseudo-code of Fig. 1 .
 For all the tests performed in this paper we use the simple
Manhattan distance heuristic slightly modified to allow for diag-onal movements across the grid. This provides us with a strictly admissible heuristic (remember that the cost was normalized as in Eq. (1)) . This heuristic h  X  n  X  for node n is given by h  X  n  X  X  1 : 4 min  X  x , y  X  X  1  X  x  X  y 2 min  X  x , y  X  X   X  2  X  where x is the number of horizontal steps (nodes) between node n and the goal node, and y is the number of vertical steps between node n and the goal node, and where min  X  x , y  X  is the total number of possible diagonal steps on the path between node n and the goal node. 2.3. Suboptimal heuristic search
The problem with the strict admissibility criterion of the to find the optimal one. However, in many practical settings, suboptimal solutions are welcomed if they reduce the runtime or memory required for the search. Bounded suboptimal search algorithms attempt to find a solution quickly while guaranteeing that the resulting path cost does not exceed the optimal value by more than a desired factor E .

Several bounded suboptimal search techniques for accelerat-Weighted A n (DWA n )( Pohl, 1973 ), A E ( Ghallab and Allard, 1983 ), ( Pearl and Kim, 1982 ), AlphA n ( Reese, 1999 ), Optimistic search ( Thayer and Ruml, 2008 ), and Explicit Estimation Search ( Thayer and Ruml, 2010 ). A comprehensive comparison between all bounded suboptimal searches is beyond the scope of this work. Interested readers are referred to literature ( Thayer and Ruml, 2008 , 2010 ) for an excellent treatment of this topic. However, we will briefly explain below the main ideas behind some of these techniques.
 in wide use up to this day ( Thayer and Ruml, 2008 ; Hansen and Zhou, 2007 ). In WA n the strict admissibility criterion is relaxed by to enable the search to stay focused on feasible paths rather than nodes based on the function ^ f  X  n  X  X  g  X  n  X  X  X  1  X  E  X  h  X  n  X  instead of the original function f  X  n  X  of A n . Hence, the search becomes greedier as it is encouraged to progress towards areas with low h  X  n  X  (i.e., those that are closer to the goal). Given that 1970 ), i.e., it always finds a solution whose cost does not exceed the optimal cost by more than a factor of E (see also Section 3.3 ). heuristic function to help find a promising direction more quickly, and then it dynamically weights the heuristic less heavily as the search goes deeper. The latter may help to prevent premature ^ f  X  n  X  X  g  X  n  X  X  1  X  E 1 d  X  n  X  N h  X  n  X  where d  X  n  X  is the depth of node n in the search graph, and N is the optimal solution depth. A problem with DWA n is that N is usually unknown prior to the search. However, an estimate or an upper bound can be used instead. Again, if h  X  n  X  is admissible, DWA n is E -admissible just like WA n .

The Optimistic search algorithm can be thought of as a more aggressive version of WA n (see the pseudo-code in Fig. 2 ). solutions that are closer to the optimal path rather than being closer to the 1  X  E suboptimality bound, and hence tries to inflate the heuristic function h  X  n  X  even further to speed up the search process. Optimistic search provides a strict guarantee that the resulting solution is E -admissible  X  E 4 0  X  . To do that, it involves two steps: the first step is an aggressive expansion of nodes using WA n with a large heuristic weight of 1  X  Optimism E . This is followed by a second step (called the clean up phase) to provide the guarantee of an E -admissible solution (rather than an  X  Optimism E  X  -admissible solution). In this second step, and once nodes are expanded using the help of an extra C LEAN list until either the solution is proven to be E -admissible or an alternative solution (with smaller cost) is found. We will set the Optimism parameter for Optimistic search in this work to 2 as in Thayer and Ruml (2008) . This Optimism parameter decides the aggressiveness
Not all bounded suboptimal search algorithms operate by solely overweighting the heuristic by a factor of  X  1  X  E  X  . For example, A n E ( Pearl and Kim, 1982 ) follows a different approach. list, called the F OCAL list, which maintains a subset of the nodes in the O
PEN list. This subset is the set of those nodes whose f  X  n  X  value does not deviate from the minimal cost of a node on O PEN
A n except that A n E expands the node n from F OCAL with minimal h  X  n  X  value. The function h F  X  n  X  is a second heuristic estimating the computational effort required to complete the search. The nature of h  X  n  X  differs significantly from that of h  X  n  X  since h  X  n  X  estimates the solution cost of the remaining path whereas h F  X  n  X  estimates the remaining time needed to find this solution (for example it could be related to an estimate of the depth between node n and the goal node, i.e., N d  X  n  X  ). Even though A n E suboptimal solutions are bounded, the problem of constant emptying and refilling of the F
OCAL list can result in bad performance in some path planning domains ( Thayer and Ruml, 2010 ).

Finally, we mention that the Explicit Estimation Search (EES) algorithm ( Thayer and Ruml, 2010 ) combines the concepts of F
OCAL and C LEAN lists (just as in A n E and Optimistic search) along addition to g ( n ) and h ( n )) the functions d ( n ), ^ unbiased estimate of the cost to go) and ^ d  X  n  X  (a more informed version of d  X  n  X  ) to perform its search. The authors of EES propose that such values can be supplied by the user, or carefully constructed during the search. The algorithm combines multiple ideas to achieve faster suboptimal search, but of course at the expense of higher algorithm complexity and more memory requirements. and Optimistic search for purposes of comparison to our proposed in that they attempt to speed up the search process by inflating the admissible heuristic, rather than using a distance estimate d  X  n  X  value or a F OCAL list. exhibits poor efficiency, we choose the two clarifying scenarios shown in Fig. 3 . In both cases, the start node (located to the left) and the goal node (located to the right) are separated by obstacles (a solid wall and a maze-like dead-end, respectively). region in both parts of the figure represent the search space fooled into inspecting the direct path between the start and goal nodes since this is theoretically the minimum-cost path between the two nodes. Depending on the obstacle shape, this can result in a dramatic increase in CPU runtime and memory requirements of the algorithm. The trick to a better algorithm is to demote the around the obstacle, not towards it. 3.1. The concept of light man feels his way through darkness along the direct path from the start node to the goal node. Once t his man stumbles upon an obstacle in the way, he attempts to find his way around it (either to the right or to the left) trying to go around the obstacle. The darkness precludes any prior clues to which path to the goal node is feasible. or a flashlight at the goal node before the man embarks on his journey across the dark (now partially lit) room. Because of the characteristics of light propagation and the opacity of obstacles, the man will be able to tell (beforehand) that the direct path to the goal node is blocked, and with the help of light gradients reflecting across the room this man can decide (much quicker) on a feasible path to the goal node.

Implementing the light assistance we just described is not difficult. All is needed is an algorithm to shine a beam of light planning algorithm. 2 The light-shining mechanism (see Figs. 6 X 8 ) is a process in which we calculate, for each node n on the map, a brightness score based on the intensity of light expected at that node. We denote the brightness score for node n by L  X  n  X  . Darker nodes will be assigned higher scores and brighter nodes will be assigned lower scores, the lowest of which is at the goal node. This is because the goal node is the source of the light beam and hence will be the brightest node. 3 can now be encouraged to move towards nodes with lower brightness scores and hence will be directed around obstacles towards the goal node. Due to the assistance of the light beam, much less processing power compared to running the conven-node expansion function f  X  n  X  of the A n algorithm is modified to account for the brightness scores as follows: ^ f  X  n  X  X  g  X  n  X  X  h  X  n  X  X  l L  X  n  X  X  3  X  where l 4 0 is a control parameter that decides how firmly the the LA n algorithm efficiency and suboptimality (see Section 4 ). the quality of the solution path. We do that by ensuring that brightness scores L  X  n  X  are smaller than or equal to the heuristic h  X  n  X  for relevant nodes. This bound will provide the necessary guarantees that the solutions found by LA n are l -admissible solutions, which are no worse than  X  1  X  l  X  times the optimal l -admissible suboptimal search will be provided in Section 3.3 . savings in memory and CPU runtime requirements of the search, while maintaining a solution cost very close to the optimal one.
This is because of its interesting property of being aware of obstacles lying ahead on the grid being searched.

In the next subsection, we discuss the process of calculating the brightness scores across the map under the control of a specific parameter called y , which decides the resulting light robustness and complexity. This light propagation parameter y results in the 90 1 light beam, the 180 1 light beam, and numerous cases in between. In the following discussion, and without loss of generality, we will assume that the start node is located to the left of the map and the goal node is located to the right of the map. 3.2. Light beam propagation following: We start at the goal node, which is assigned the brightness score of B RIGHT (the minimum score, say 0) as shown in Fig. 4 (a). We define S TEP as the drop in light intensity propagates from one node on the map to the next. The goal node brightness affects y nodes to its left, as shown in Fig. 4 (b), where y is an odd number between 3 and the maximum height of the map.
Fig. 4 (a) illustrates the case of y  X  y min  X  3, where three nodes ( a , b and c ) are affected by the brightness score of the goal node, making their brightness score equal to B RIGHT  X  S TEP . Each of these three nodes becomes a new source of light thus affecting the three nodes to their left, but with another drop in brightness of S
TEP . This continues until we reach the end of the map. We call the case of y  X  y min  X  3 the 90 1 light beam propagation pattern.
The value of y can be increased to allow the light to propagate in wider angles up to y  X  y max  X  height of the map , which we call the 180 1 light propagation pattern. In this case, each node affects the brightness score of all nodes to its left, resulting in a beam of light that propagates in a more natural 180 1 angle.

The only time a node X  X  brightness cannot affect adjacent nodes is if there is an obstacle between these nodes. Hence, nodes behind obstacles are assigned a brightness score of D ARK the maximum possible score. This discourages the A n algorithm from investigating nodes so close to obstacles.
 pseudo-code of Fig. 5 . This code needs to be inserted between lines 1 and 2 of the A n algorithm pseudo-code of Fig. 1 to complete
Notice that the light-shining code consists of only two loops and does not require recursive computation to calculate each node X  X  brightness score. This is because in the general case, the brightness of any node in the middle of the grid is determined by the brightness score of only y nodes to its right.
 the 90 1 light beam variant and the more natural 180 1 variant are shown in Figs. 6 and 7 , respectively, for the solid wall and maze-like Notice that the search space (shaded region in the figures) is much smaller compared to the search space in Fig. 3 .ThisisbecauseD and towards the brightest spot on the map (the goal node). It is important to notice that the search space size can be controlled by the l parameter in Eq. (3) , which provides a trade-off between efficiency and solution suboptimality (see Section 4 ).
In this section we derive a mathematical bound on the following, we assume that the heuristic h  X  n  X  is admissible. In addition, the cost of a minimum-cost path from the start node n to node n is denoted by g n  X  n  X  . We will start by reiterating the proof that WA n results in E -admissible solutions (see Pohl, 1970 ) and then use that to understand why LA n is l -admissible. optimal path to the goal node n g . No matter how a best-first search selects nodes for expansion from the O PEN list , we always have f  X  n g n  X  n  X  .

Proof. If an optimal path to n g exists, then by definition node n which lies along the optimal path must also exist. In addition, during the operation of the algorithm, at least one node on the optimal path (which is the start node n s ) must be on O PEN which the node X  X  neighbors are inserted into O PEN , and so on.
Hence, there are nodes on O PEN , one of which is n d . By the definition of n d and the admissibility of h (which always under-estimates the cost to the goal), we have f  X  n d  X  r f  X  n f  X  n  X  X  g n  X  n g  X  , which completes the proof. &amp;
Theorem 1. For any node n expanded by a best-first search guided by ^
Proof. Consider an optimal path to n g , and let n d be the deepest node on O PEN that lies along that optimal path. When the best-first search expands node n , we have ^ f  X  n  X  r ^ f  X  n n was selected for expansion before n d . By algebra we have ^ f  X  n
 X  X  g  X  n d  X  X  X  1  X  E  X  h  X  n d  X  r  X  1  X  E  X  X  g  X  n d  X  X  h  X  n
This means that ^ f  X  n  X  r  X  1  X  E  X  f  X  n d  X  . By Lemma 1, we have ^ f  X  n  X  r  X  1  X  E  X  g n  X  n g  X  . &amp;
Corollary 1. The cost ^ g  X  n g  X  of the solution path returned by WA more than  X  1  X  E  X  the optimal one .

Proof. Because n g is a goal node and h is admissible, h  X  n means that ^ g  X  n g  X  X  f  X  n g  X  X  ^ f  X  n g  X  by the definition of Theorem 1 , ^ g  X  n g  X  X  ^ f  X  n g  X  r  X  1  X  E  X  g n  X  n g proof. &amp; were properly assigned.

Theorem 2. If we are guaranteed that L  X  n  X  r h  X  n  X  for nodes not directly blocked from the goal node by obstacles , then the cost ^ g  X  n of the solution path returned by LA n satisfies ^ g  X  n g Proof. In LA n , nodes blocked from the goal node by obstacles (i.e., D nodes) do not lie on a valid path from the start node to the goal node, and hence whether they are expanded from the O list or not is irrelevant to the obtained solution or its cost. Nodes that are not blocked, however, will receive a brightness score of
L  X  n  X  r h  X  n  X  . This means that the LA n expansion function will be ^ to the WA n expansion function. Hence, by Corollary 1 , the LA n solution satisfies ^ g  X  n g  X  r  X  1  X  l  X  g n  X  n g nodes need to be considered is when the start node n s lies ^ on the minimum g  X  n  X  X  h  X  n  X  value). This continues until the algorithm leaves the D ARK region. Since the standard A n is also l -admissible, the LA n solution remains l -admissible. &amp; example, for the heuristic in Eq. (2) , we set B RIGHT  X  0, and
S TEP r 1. This insures that L ( n ) is less than or equal to the number of horizontal nodes between node n and the goal node, which is always smaller than or equal to the Manhattan distance h  X  n  X  .
Finally, we note that the  X  1  X  l  X  upper bound on the LA n solution represents the worst case scenario, which rarely occurs in real life. Instead, the experimental results (see Section 4 ) show of shining the light beam across the map. This process requires technique. Conveniently, the light propagation parameter y was designed to control this overhead, as a proper selection of y will minimize the time needed for the light shining stage, thus
To understand this, we have to understand the tradeoffs that y presents. On the one hand, if we decrease y , the loops in lines 10 and 15 in the pseudo-code of Fig. 5 will execute in a shorter time, thus reducing the CPU overhead for the light-shining stage. On the other hand, there is a negative effect to a very small y value, which is the possibility of blocking the light beam coming out of the light source due to a large obstacle in the map placed (abnormally) very close to the goal node. This is similar to someone placing his hand very close to a flashlight to block its rays from spreading across the dark room in our earlier analogy. (but never worse) in darkness, as the expanded nodes from the O PEN list now follow the f ( n ) function of A n .

We note that increasing y slightly over y min makes it much more difficult for an obstacle to block light (no matter how large the obstacle is), and yet the resulting increase in the execution time of the light-shining stage remains minimal. We will see in the simulation results of Section 4 (see Fig. 9 ) that there is no need to go to very high y values before the probability of blocking light due to close-by obstacles becomes zero, which means that the light-shining overhead can always be made reasonably small. 4. Experimental results three test problems:
Experiment #1: grid path finding : In this experiment, a 1900 node 1000 node map is used, wherein square-shaped obsta-cles are placed at random locations throughout the map. The start node is placed at the far left of the map and the goal node is placed at the far right of the map. Different cases were considered wherein the obstacles occupy 10% up to 35% of the map. The results were quite similar. We only report here on the case of 25% of cells being blocked by obstacles. For such obstacle density, we constructed 100 random map instances (see Fig. 8 (a) for a sample map), and averaged the results for obstacle densities higher than 35% since this can result in the with excessive number of obstacles has a rare occurrence in practice.

Experiment #2: robot navigation : Again, we use 100 instances of 1900 node 1000 node maps for this experiment. However, obstacles are created this time by scattering 25 straight lines with random orientations across the map, thus representing randomly placed solid walls (see Fig. 8 (b)). Each line is 360 cells in length. Again, the start node is located to the far left of the map and the goal node is located to the far right of the instances.

Experiment #3: mazes : In this scenario, a 15 square 11 square maze is constructed across the 1900 node 1000 node map.
The start node is again placed at the far left of the map and the goal node is placed at the far right of the map. For this experiment, we run the test over 100 random mazes of the
Optimistic and LA n algorithms. An example 11 15 maze is shown in Fig. 8 (c).
 method utilizing the heuristic in Eq. (2) . This is followed by chosen y value), while varying the suboptimality parameter for each one of these algorithms ( E and l ) independently between 0.01 and 3.0. We report on the algorithm memory requirements (by adding the size of all the lists used by the algorithm: O C
LOSED and C LEAN lists). This number increases as the number of nodes expanded by the algorithm increases. We also report on the path cost (to study the algorithm X  X  suboptimality), and the total
CPU runtime required to execute the algorithm on a 2.0 GHz Intel processor. We use an efficient C  X  X  implementation of the above algorithms that utilizes a combination of a hash table and a min X  X ax heap data structure to speed up the operations on the O ,C LOSED and C LEAN lists. The results of the three experiments are explained next. 4.1. Grid path finding
Before we proceed into investigating the performance results on the issue of light-shining overhead. Such overhead CPU time is show in Fig. 9 (a) for the grid path finding experiment. This experiment) was evaluated for different y values between the minimum of 3 and the maximum of 999. In addition, the figure shows the probability of light getting blocked because of a badly located obstacle, calculated as the percentage of maps (out of the 100 random map instances) that has blocked light.

We notice that it was rare to find a case where the light beam coming out of the goal node is blocked, as only one out of 100 randomly generated maps resulted in blocked light at y  X  3, which was due to an oddly shaped cluster of obstacles very close to the source of light. Simply increasing the value of y to 5 quickly drops the light blocking probability to zero. This is reasonable in this experiment, which does not involve large solid walls that block light. However, as shown in Fig. 9 (a), increasing y means that the overhead CPU time necessary to propagate the light beam increases as well. Unlike the next two experiments, the light-shining overhead in the grid path finding experiment stabilizes after y exceeds 49. This is because the map is cluttered with random obstacles, which means there is a high chance that an obstacle will activate the loop breaks in lines 12 and 17 in the light-shining pseudo-code of Fig. 5 .
 a y  X  5 beam in this experiment. Higher y values will require more overhead time for the light-shining stage, while the lower y  X  3 will result in one of the maps staying in darkness. ment using WA n , Optimistic and LA n ( y  X  5 light beam). The figure shows the combined size of the lists used by each algorithm, the algorithm CPU runtime (with an without light-shining overhead), and the obtained solution cost. The results are shown as a optimal solution cost, respectively.
 increases, the search space of all the studied suboptimal searches the suboptimality parameter reaches a certain point and further increase of the suboptimality parameter does not result in any noticeable change. The drop in search space results in a dramatic improvement in memory requirements (necessary to store the various lists) and the CPU runtime of all investigated search overhead). The light-shining overhead is very small as it only Optimistic search.

Optimistic searches, that provide solutions exceeding 10% of the finding being heavily drawn to light which provide clues to promising path early on in the search process.

It is also interesting to mention a few points about Optimistic search. First, Optimistic search expands nodes from two lists simultaneously: the O PEN and C LEAN lists (see pseudo-code in
Fig. 2 ). This means that its combined list sizes is roughly twice space). The Optimistic search sacrifices memory space in order to
This is apparent in Fig. 10 (b) before the 0.1 mark (and more clearly in Fig. 11 (b) later). In such cases a more aggressive WA n actually expands less nodes and provides a pump in search speed. However, after the 0.1 mark (see Fig. 10 (b)), the WA n algorithm reaches the minimum possible number of expanded nodes and being more aggressive does not provide any further improvement has to endure an extra clean-up phase that requires a finite CPU runtime. This is why Optimistic CPU runtime is marginally higher
In terms of the solution cost, the Optimistic solution deviates quickly from the optimal solution all the way to the maximum value. This makes sense because Optimistic search is just a more behavior much earlier in Fig. 10 (c). 4.2. Robot navigation
The tradeoffs in selecting the light propagation parameter y for ment are shown in Fig. 9 (b). Different to the earlier experiment, we notice that the light blocking probability starts at a high value of 21% at y  X  3, as this experiment involves large solid walls that when placed close enough to the light source can block that light. However, once y is increased, this blocking probability drops very quickly to zero. On the other side of the coin, the light-shining stage overhead keeps increasing with the increase of y , and never reaches a steady-state value. This is because the map in this experiment involves wide open spaces, and the loop breaks in lines 12 and 17 of Fig. 5 rarely get invoked. Hence, we use y  X  23 in this experiment, which provides the minimum possible over-head while maintaining zero probability of blocking light.
The path planning results of the robot navigation experiment are shown in Fig. 11 . The true power of LA n shines in the presence of obstacles. Fig. 11 clearly shows that LA n provides the best hands down. The light-shining overhead is so small it is almost negligible.

Since WA n with larger E values provide faster searches in this
CPU runtime, albeit on the expense of more memory and a worse suboptimal solution (around 20% higher than the optimal cost). 4.3. Mazes
The results of the third experiment (random mazes) are shown in Figs. 9 (c) and 12 . Again, the results are expressed as a that we are not trying to introduce a new maze-solving algorithm 0 10 20 30 40 50 20 40 60 80 100 120 140 160 180 here, since there are plenty of methods dedicated to this mission. planning algorithm in a more elaborate test scenario.
 performer (with very high margins) compared to the other algorithms. A dramatic improvement in performance is obtained solution (less than 0.4% of the optimal solution).
 search) is futile in this experiment as it only leads the search better in such scenarios.
 the two earlier experiments. We notice that the light blocking probability drops sharply as y increases, but then stabilizes at 11% after y  X  39. This leftover light-blocked scenarios have nothing to do with large obstacles being close to the goal node; rather, they have to do with zigzag paths that are possible in mazes. One such map instance is illustrated in Fig. 13 , where the zigzag path indicated by the arrow managed to block the light beam, and hence prevented the light from continuing its journey through the rest of the map to assist in finding the solution. As we stated dark region of the map, which increases the overall average drop in performance for such barely lit mazes, 5 the average suboptimal searches (see Fig. 12 ). A method to successfully pro-pagate a light beam through zigzag paths (just like the one in
Fig. 13 ) will be left for future work. 5. Conclusions which a beam of (virtual) light is cast from the goal node and better runtime and require a smaller memory footprint compared problems, while providing near-optimal solutions, and hence, can be used for robotic applications and computer games that require real-time response, and that have a limited amount of memory. in which the brightness score of one node affects the brightness scores of y adjacent nodes located in the direction of light propagation, with light intensity dropping as it propagates from one node on the map to the next. Such brightness scores L  X  n  X  can be thought of as a more informed heuristic compared to a simple distance heuristic h  X  n  X  .

We have seen, through simulation of hundreds of randomly generated maps, that an optimal choice of y results in minimizing choice can significantly reduce the overhead time of the light-shining stage. Based on simulations performed in this work, we recommend y values between 5 and 39 for obtaining a robust and efficient LA n algorithm. In future work, we will study the effects of the map size and the obstacle feature size on the optimal choice of y .

Finally, we mention that several variants of light propagation algorithms can be easily developed, in which certain properties of light can be utilized (or discarded). In addition, the method of light-assistance is quite generic, and it can be combined with other path planning methods to speed them up.
 mainstream computer games, such as Starcraft or Age of Empires, something that can be done by researchers who have access to the source code of such popular titles.
 Acknowledgment
The author would like to sincerely thank Prof. Wheeler Ruml and Jordan Thayer for generously sharing the source code for their Optimistic search algorithm.
 References
