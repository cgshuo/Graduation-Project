 We present a novel contextualization approach for passage retrieval. The core principle is to let any occurrence of a query term in a document affect the passage retrieval score, whether the occurrence is in the passage or not. This ef-fect is controlled by the distance between the term occur-rence and the passage. Empirical evaluation demonstrates the merits of our approach; the resultant retrieval perfor-mance substantially transcends that of previously proposed passage retrieval methods, including those that use various contextualization approaches.

Traditional ad hoc retrieval methods deal with the task of finding the documents that are most relevant to the user query. However, documents might be long and can cover many topics. In such cases, retrieving the most specific query-pertaining text units in the document, i.e. passages , rather than the document as a whole, can be of much merit [17, 10, 3]. Passage retrieval also serves as an intermediate phase in several other tasks such as question answering [18], entity oriented search [6] and text summarization [13].
There is an important difference between relevance esti-mation for documents and for passages. Document relevance can often be effectively estimated independently of other documents in the collection. On the other hand, passages are shorter units of text. Hence, effective passage-relevance estimation calls for contextualization ; that is, the considera-T his work was done while David Carmel was at IBM Haifa Research Lab. This work was done while Anna Shtok interned at IBM Haifa Research Lab.
 tion of the passage context. Several types of contextualiza-tion, typically used for passage retrieval, are the text unit containing the passage, the document the passage belongs to, and reference documents [4, 14, 9, 15].

We present a novel contextualization approach for passage retrieval. The approach leverages the fundamental principle underlying the positional language model (PLM) [12] that was introduced for the document retrieval task. The key idea behind PLM is that any term in a document is repre-sented as a density function which expresses the probability of finding the term at any position in the document. Sim-ilarly, our model estimates the probability of finding the query terms within the passage while considering all term occurrences in the document. Yet, our approach serves for passage retrieval rather than for document retrieval. The method we devise lets any occurrence of a query term in the document affect the passage score regardless of whether the occurrence is actually in the passage. This effect depends on the distance between the query term occurrences and the passage. Thus, the whole document, or more precisely, all query term occurrences in the document, provide context for the passage.

Evaluation performed with the INEX focused-retrieval bench-marks shows that our approach substantially improves over previously proposed passage retrieval methods, including those that use various contextualization techniques.
Several contextualization approaches for passage retrieval were examined in the past. A commonly used context for passages is their containing document [1, 14, 9]; e.g., us-ing term counts in the document for  X  X moothing X  those in the passage. In contrast to our approach, distances between the query terms and the passage at hand are not consid-ered. Furthermore, we show that our method substantially outperforms this approach.

Another type of passage contextualization is considering its neighbor passages in the document [9]. Our approach, which lets query terms in the entire document affect the retrieval score of any passage, is shown to outperform this contextualization method.

The structure of an XML document [4, 15] and hyper-links [15] were also used for passage contextualization. Such approaches are complementary to ours that considers term proximity in unstructured text.

The work most related to ours is that of Beigbeder who ap-plied proximity scoring for focused retrieval [5]. Each posi-tion in the text is assigned with a proximity value depending on its distance from the query terms. These values can be s ummed on any range of text, and therefore can be applied for passage retrieval. The proximity value of a position to a term is determined based on the nearest occurrence of the term to the position, and the proximity value to the query is an aggregation of the position proximity scores to all query terms using fuzzy logic rules. In contrast, to the best of our knowledge, our work is the first to use all occurrences of the query terms in a document, and their distances from the passage at hand, for passage retrieval contextualization. Let q and d denote a query and a document respectively. Let p def = ( p.s, p.e ) be a passage which spans from position p.s to position p.e in the document. A commonly used pas-sage scoring model, referred to here as psg , is based on the well known tf-idf-based ranking approach that was found to be highly effective in the passage retrieval domain, compared to several other ranking alternatives [11, 2]: ber of occurrences of term t in p ; idf ( t ) = log( N N total number of documents in the collection, and N t is the number of documents containing t .

Since passages are short units of text, the potential for vocabulary mismatch between a query and a relevant pas-sage is quite high. Thus, for estimating passage relevance it is beneficial to use information from the passage context in addition to that in the passage itself. Using the document containing the passage is a commonly used contextualiza-tion approach [7, 1, 14]. Specifically, the (normalized) pas-sage score assigned by Equation 1 to passage p is X  X moothed X  with the (normalized) retrieval score of the document d to which p belongs. Formally, the psgDoc method scores p by: Score psgDoc ( p ; q ) def = (1  X   X  ) Score psg  X  is the contextualization parameter; d p is the document containing p ; Score doc ( d ; q ) is document d  X  X  retrieval score which in our experiments is assigned by the state-of-the-art OKAPI-BM25 [16] method; D n is the set of top-n scored documents in the corpus.

The passage context can be further refined by using its surrounding passages in the document [9]. For example, the passage score can be further smoothed with that of its neighbor passages, yielding the psgNeighbor method: where p l and p r are the two neighbor passages of p , from left and right, respectively;  X  l and  X  r are the contextualization parameters. This method can be generalized so as to con-sider the scores of the k &gt; 1 neighbor passages from left and right with the values of the corresponding contextualization parameters decreasing with increasing distance from p .
We consider a novel contextualization approach for pas-sage retrieval that is based on leveraging a fundamental prin-ciple underlying the locality-based similarity [8], and its suc-cessor positional language model (PLM) [12] that were pro-posed for document retrieval. PLM defines for each term po-sition x in document d the probability P r ( t | d, x ) that term t will be generated in this position. For an occurrence of t in position o in d , f t ( o, x ) is the generation probability of t  X  X ropagated X  from o to x . All occurrences of t in d affect the generation probability of t in x based on their distance from x . The more occurrences of t in d , and the closer these occurrences to x , the higher the generation probability of t at x .

For typical propagation functions, often called kernels, f ( o, x ) is estimated based on the inverse of the distance of x from o . A commonly used kernel function is the Gaussian, w here  X  is a free parameter. Note that the value decays with increasing distance from o . This kernel was shown to work well when applied for document retrieval [8, 12]. Another kernel we experimented with is the Trapezoid. The assigned value is 1 if x is in the same passage containing the position o , and otherwise decays linearly with increasing distance from the passage borders. Formally, let p o be the passage containing the term position o . Then, f t ( o, x ) =
For the passage retrieval task that we address, we use the underlying principle of PLM, described above, to estimate the contribution of the occurrences of all query terms in the document to the passage score. Given an occurrence of query term t in position o , we define its contribution to the score of passage p by computing the area under the kernel function between the passage borders. This area can be thought of as reflecting the probability of  X  X enerating X  t in the given passage. The score of passage p for query q is then defined to be the sum of the contributions to p  X  X  score of all query-terms occurrences in the document. This is our PLM method: Occ ( t, d ) is the set of all occurrences of t in d .
For both kernel functions described above, the steepness parameter  X  controls the amount of contextualization. When the value of the steepness parameter is approaching zero, contextualization is reduced as only term occurrences in the passage, or that are very close to the passage, affect its score, while query term occurrences that are far from the passage do not contribute to its score. In contrast, when the value of the steepness parameter grows to infinity, the PLM method scores all passages equally (modulo passage length normal-ization, see details below), as any query term occurrence in the document contributes to all passages equally. Figure 1: Example: Contextualized PLM passage s coring with Gaussian kernels (top) and Trapezoid kernels (bottom). Kernel heights correspond to terms X  importance ( idf ). Paragraph p 2 does not con-tain any of the query terms. However, its score is affected by the two neighbor occurrences of t 1 and the left neighbor occurrence of t 2 .

The PLM method incurs bias in favor of long passages, as they span over large parts of the document. To ameliorate this bias, passage scores should be normalized. The nor-malization approach we applied is to approximate the area under the kernel curve by dividing the passage to k equal length intervals, and summing the kernel values in the k + 1 interval borders; k is fixed and independent of the passage length hence the contribution of a kernel function to the passage score is independent of the passage length.
Figure 1 demonstrates the PLM score computation. The scheme illustrates the case of a two-terms query ( t 1 , t a document with 4 non-overlapping paragraphs. Paragraph p 2 does not contain any of the query terms; however, its score is affected by the two neighbor occurrences of t 1 and by the left neighbor occurrence of t 2 .

Finally, as is the case for the baseline scoring methods from Section 3.1, the (normalized) PLM score is further smoothed with the (normalized) document score to yield the overall passage score used for the final ranking. set of experiments using the INEX dataset for the focused tasks of 2009 and 2010 [10, 3]. The INEX focused task re-quires systems to find the most focused results (i.e., shortest passages) that satisfy an information need, without return-ing overlapping passages. The dataset contains 2 , 666 , 190 English Wikipedia articles, converted to XML format, with 68 judged topics for the 2009 task, and 52 judged topics for the 2010 task. Articles were judged by their relevance to the topics, and relevant parts of the articles were labeled explicitly. A quantification of the character-based overlap between retrieved passages and the labeled parts of the ar-ticles is used for system evaluation. Precision is measured as the portion of retrieved text that was labeled and recall is measured as the portion of all labeled text that has been retrieved. The interpolated precision measure is the preci-sion score at a selected recall level x (iP[x]) and the mean average interpolated precision (MAiP) is the mean over 101 standard recall points. The official focused task measure for system evaluation, in 2009, was the interpolated precision at 1% recall level (iP[.01]) [10]. Statistical significance of performance differences is determined using the two tailed paired t-test at a confidence level of 95%.
 based retrieval approach [10]. First, we create an initial doc-ument set from the 1500 documents that are the most highly ranked for a topic by using the BM25 retrieval method with default parameter settings ( b = 0 . 2 , k 1 = 0 . 6); titles of topics serve for queries. Then, we use the paragraphs in these doc-uments as retrievable passages 1 . These passages are ranked by one of the methods specified below. The 1000 top ranked passages constitute the final result list.

We experimented with several methods for passage scor-ing:  X  psg: The standard tf.idf-based method specified in Equa-tion 1.  X  psgDoc: The method that uses the document retrieval score for smoothing the passage retrieval scores. (See Equa-tion 2.) We tuned the interpolation parameter (with re-spect to values in the range { 0 , 0 . 1 , . . . , 1 } ), and report the performance values for  X  = 0 . 9, which results in optimal performance for both benchmarks.  X  psgNeighbor: The method that smooths the score assigned to the passage by the psgDoc method (  X  = 0 . 9) with the scores assigned by psgDoc to its neighbor passages. (Refer to Equation 3.) We tuned the contextualization parame-ters (with respect to values in the range { 0 , 0 . 25 , . . . , 1 } ), and report the performance for  X  l =  X  r = 0 . 25, a setting that results in improved performance with respect to other settings for the two benchmarks.  X  PLM(G): Our proposed method from Equation 4 employed with the Gaussian kernel. The normalization parame-ter k (the number of dividing intervals of the paragraph where the kernel values are computed) was set to 20. (We experimented with a few other settings for k which re-sulted in similar performance.) Passage scores were fur-ther smoothed with the document score, as in Equation 2, with  X  = 0 . 9. We report the performance for several steepness (  X  ) values.  X  PLM(Tra): Using PLM with the trapezoid kernel, k = 20, and document score smoothing (  X  = 0 . 9). Performance is reported for several steepness (  X  ) values.
Table 1 shows the performance numbers of the different passage scoring methods for the focused task benchmarks of 2009 and 2010. The numbers on the first row are for the
W hile the focused task encourages systems to retrieve short passages, we decided to experiment with Wikipedia para-graphs as our basic retrievable units. The retrieval of other passage types, e.g., sentences or window-based, is left for future research. Table 1: The performance of the passage scoring m ethods over the INEX focused task benchmarks of 2009 and 2010. Boldface marks the best result in a column. Statistically significant improved results over psgDoc are underlined. best INEX run for 2009 as measured by the iP[.01] official measure 2 .

We can see in Table 1 that the performance of psg is very low compared to that of psgDoc. This finding is in accor-dance with previous studies that showed that passage rel-evance cannot be effectively estimated without considering the passage context [7]. Moreover, psgDoc performs equiva-lently to the best run in INEX 2009, which is a strong base-line to compare with. We can also see that the performance of psgNeighbor is almost identical to that of psgDoc. Gen-eralizing this approach by considering k &gt; 1 passages from left and right did not gain any improvement. This finding implies that using the neighbor passages of the passage at hand for score smoothing has no additional benefit on top of using the document score for smoothing.

Both PLM methods yield substantial, and (almost always) statistically significant, improvement over psgDoc when set-ting  X  to large values. The largest gap in performance is observed in iP[.01] which measures the precision of topmost results, at 0 . 01 recall level. The performance differences between the two kernels were found to be statistically in-significant. Interestingly, the optimal performance for PLM was achieved when setting the free contextualization param-eter (  X  ) to a large value for both kernels (  X  = 2000 for PLM(G) and  X  = 1 e 5 for PLM(Tra)). Note that the larger  X  is, the higher the contextualization is, i.e., all query term offsets, regardless of where they appear in the document, contribute to the passage score. On the other hand, when setting the steepness parameter to an extremely large value, performance drops for both kernels. The conclusion is that contextualization based on term positions is important for passage retrieval. That is, query-terms occurrence in a doc-ument should affect the relevance estimation of passages, even if the passages are quite far from the occurrence po-sitions. Yet, this effect should (marginally) decay with the distance.
I n 2010 the focused task was modified; participants were asked to retrieve only 1000 characters per topic, hence the precision results of INEX participants are extremely low, and cannot be compared to those of our method which is based on retrieving full paragraphs.
We presented a novel contextualization approach for pas-sage retrieval. All query term occurrences in a document affect the score assigned to a passage. The effect depends on the proximity of the occurrences of the query terms to the passage. Empirical evaluation showed that our approach posts performance that is substantially better than that of previously proposed passage-based retrieval methods that use various contextualization approaches.
