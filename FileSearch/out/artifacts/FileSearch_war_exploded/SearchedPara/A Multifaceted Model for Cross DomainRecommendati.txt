 With the boosting of online services, recommendation systems (RS) are playing an increasingly important role in filtering information for customers. Since most users are only connected to a small set of items, data sparsity becomes a major bottleneck for building an accurate RS. This is especially true for newly joined users/items, which is known as the cold start problem. To address this problem, researchers have introduced cross domain RSs which can transfer knowledge from some relatively dense source domains to the target domain. They assume that there are some consistent patterns across domains. Take book domain and movie domain for example, users with similar interests in the movie domain may also have similar interest in the book domain (rule of collaborative filtering); and users who like fantasy movies have a higher probability of liking fantasy books than users who do not (rule of content-based filtering). Therefore, when we do not have enough data on the book domain, leveraging the data from movie do-main appropriately can improve the quality of book recommendations.
 ping or not, existing literatures for cross domain RSs can be roughly divided into two categories: with overlap and without overlap. CMF [25], CST [20], TCF [19], MV-DNN [8] and [9] assume the users or/and items from multiple domains are fully or partially aligned, and the knowledge is transferred through the known common user/item factors; On the contrary, CBT [12], RMGM [13] and [6] do not require any overlap of users/items between auxiliary domains and the target domain. They transfer useful knowledge through cluster-level rating patterns. This can be the case when a company owns multiple products but only a few of them provide enough data, while the others X  data are too sparse to build effective models; or when a company wants to promote new services or prod-ucts to its customers, they can leverage customer data on existing services or products. The aforementioned cross domain methods only focus on transferring either content-based filtering or collaborative filtering knowledge. However, mod-els which combine the two algorithms have been widely discussed in the single domain case. Thus we consider the first challenge: will it produce a large amount of improvement if we transfer both content-based filtering and CF across differ-ent domains simultaneously? To address the the question, we propose a unified factorization model to transfer both CF and content-based filtering cross do-mains. The key idea is to learn content embeddings so that the content-based filtering has a same latent factor formulation as model-based CF. Actually we propagate the CF not only to user-item level but also to user-content level. latent factor model [10]. However, there may be some inconsistency between different domains so that the neighborhood built from the source domain may not hold for the target domain. Take news and movie recommendation for in-stance, suppose Bob and David come from the same city, they may be similar in the news domain because they both love to read news related to the city. However, the similarity between them in movie domain may be low, since their interest in movies are not quite related to where they live. Motivated by this, we propose a novel selective mechanism which can iteratively learn a specific weight for each item in the source domain. The goal is to transfer preference on domain-independent items rather than domain-dependent items.
  X  We introduce the multifaceted model for cross domain RSs, which includes  X  We propose a novel selective neighbor model to automatically assign weights  X  We propose a unified factorization model to collectively learn content-based  X  We conduct extensive experiments on two real-world datasets, and the ex-Suppose we have two domains: the target domain and the source domain. For each domain the data are comprised of user-item ratings and item attributes. In the target domain, we denote the user-item ratings as a matrix R (1) = [ r and M (1) denote the number of users and items respectively. The item content is denoted as a matrix A (1) = [ a ik ] M (1)  X  T (1) , where each row represents an item, T (1) is the number of attributes, a ik  X  [0 , 1] is a normalized weight on attribute k , and a ik =0 indicates item i does not have attribute k . Our goal is to predict the missing value in R (1) . For various reasons R (1) is sparse, and we want to improve the model with the help of the auxiliary domain, whose correspond-the users are fully or partially overlapped, and we know the mapping of users between domains. A widely used method in collaborative filtering is latent factor model. It factor-izes the rating matrix R N  X  M into two low-rank matrices, U N  X  D and V M  X  D , as latent factors for users and items. In probabilistic matrix factorization ( PMF ) model [23], these latent factors are assumed to be generated from zero-mean spherical Gaussian distributions, while each rating is generated from a uni-variate Gaussian. Actually, the the PMF model only learns from the user-item rating pairs and makes recommendations through clustering similar rating pat-terns. As revealed in [31], auxiliary signals such as user demographics and restau-rant attributes can help improve the restaurant recommendation model. Thus we want to incorporate item attributes into the model. Since the attribute vector A i for item i is sparse, it is not suitable to use I i to augment the item latent factors directly like IPM model [31]. Motivated by [18], we try to embed the attributes into a shared latent space, and then augment the item latent vector V j with the weighted average of the embedded representation of attributes. tation by B k =  X  b k 1 ,b k 2 ,...,b kL  X  . So we have a attribute embedding matrix B with each row indicates an attribute. The augmented latent vector for item j is denoted by e V j = { V j ,P j } where P j = A j B . The user latent vector is simply extended as e U i = { U ia ,U ib } , where U ia denotes the original CF part while U ib denotes the content preference part. Then the mean rating of user i on item j is changed as follows: and the generative procedure is updated as follows: We name the new model Probabilistic Preference Factorization ( PPF ). Cross Domain Collective Learning . When R (1) is too sparse, the learning of latent factors may be inadequate and thus lead to overfitting on the training set. Next we study how to make use of the data from the auxiliary domain. We adapt the Collective Matrix Factorization ( CMF ) [25] model to our situ-ation. The key idea of CMF is to factorize multiple matrices jointly through a multi-task learning framework. Since we have one-one mapping on the user side between the target domain and source domain, we simply assume the users share the same latent factors across these domains: U = U ( 1 ) = U ( 2 ) , just like the approach in [16]. We also apply the aforementioned PPF generative process to the source domain. This model can be easily extended by introducing priors on the hyperparamenters and applying fully Bayesian methods such as MCMC [22]. However, to avoid high computational cost, here we regard  X  u  X  , X  v , X  r as constant hyperparameters and use grid search to find their best values. The pa-maximize the following Bayesian posterior formulation: Maximizing Eq.(2) is equivalent to minimizing the following loss function: where we replace  X   X  with  X   X  after eliminating some constants for notation sim-plicity. Yehuda ([10]) introduces a multifaceted model to smoothly merge the factor and neighborhood models. Following this idea, we plan to equip the PPF model with a neighborhood module. However, as we have discussed before, in the cross domain situation, the neighborhoods of the same user under different domains may be different. Thus it is questionable to compute the user similarity scores directly through items from the source domain. To address this problem, we propose a selective learning algorithm to assign weight for each item in the source domain. Our goal is to select those domain-free items to build an accurate neighborhood for the target domain. The new prediction rule becomes: Here, b ij represents the prediction of the aforementioned latent factor model. borhood model, and it decreases when the number of rating records of user i in the target domain increases. N m ( i,j ) represents user i  X  X  top m nearest neigh-bors who have rated item j . s ( i,k ) denotes the similarity value between user i and k . Due to the sparsity of target domain, we have to compute s ( i,k ) using the data from source domain. In the traditional neighbor-based CF model, the similarity is static and calculated from their common rated items. Now we as-sign each item in the source domain with some parameters, which determine the weight of the item for the similarity calculation: V ( i,k ) indicates the common items rated by user i and k . D ( i,k,t ) measures the difference of ratings on item t from user i and user k . We assign a small value,  X  , to it when r it equals to r kt :  X  ( t )  X  (0 , 1) represents the weight of item t . We assume that the weight is de-termined via item id and item X  X  content information. So for each item t , there is a corresponding parameter  X  t ; similarly, for each item attribute k , its corre-sponding parameter is denoted by  X  k . We apply a logistic regression process to learn the optimal parameters: Now, with eq.(4) we introduce a Multifaceted model for Cross Domain Recom-mendation Systems ( MCDRS ). Its first part is a collective latent factor model, in which we embed both collaborative filtering and content-based filtering in order to exploit as much knowledge as possible. And its second part is a novel neighborhood model whose main purpose is to learn residuals based on the la-tent factor model.
 Learning There are several groups of parameters in our multifaceted model, i.e. latent factors for CF, latent factors for content, and weights in the neighbor model. It is hard for SGD to learn a good solution due to the fact that it does not discriminate between infrequent and frequent parameters. So we use AdaDelta [29] to automatically adapt the learning rate to the parameters, leading to the update rule: where RMS represents the root mean squared criterion with exponentially de-caying: In the experiments we set  X  =0.9 and =1e-8 . We evaluate the proposed model on two rating datasets: Douban 3 and MovieLens 20M 4 .
 information related to multiple domains such as movies, books and music. Users can rate movies/books/songs on a scale from 1 to 5, and each movie/book/song has a list of tags (tag id,count) indicating how many users have rated the tag id on this item, and the tags can be used as the item X  X  attributes. Thus Douban is an ideal source for our cross domain experiments. We build a distributed crawler to fetch the item information and user-item rating records from Douban. After filtering out users who appear in only one domain or have less than 20 ratings, and movies/books/songs which have fewer than 10 ratings, we randomly sample 100k users, 50k books, 30k movies and 30k music for experiments. Via switching the choice of source domain and target domain, we report the results of three cross domain tasks, i.e.,  X  movie  X  music  X  ,  X  movie  X  book  X  , and  X  book  X  music  X  . In each task we split the target domain into training/valid/test set by 70%/15%/15%. In order to study the performance lift under different sparsity levels, we keep the validation and test set unchanged and randomly sample a subset from the training set with different sparsity levels of 1%, 2%, 5%, 8%, 10% correspondingly.
 widely used benchmark dataset, MovieLens 20M. It is currently the latest stable benchmark dataset from GroupLens Research for new research, and it contains more than 20 million ratings of 27,000 movies by 128,000 users, with rating score from 0.5 to 5.0. Because our proposed model is to study the combination of CF and content-based methods, we filter out the movies which have no tags, and then use tags as the movie attributes.
 two disjointed parts to simulate two different domains. This approach has also rating matrix as R 1  X  N, 1  X  M . We take the first half sub-matrix R 1  X  N, 1  X  M the target domain, while the other half R 1  X  N, M Again we split the target domain into training/valid/test set by 70%/15%/15% and extract several subsets from the training set according to different sparsity levels. 5.1 Baselines and Evaluation Metrics We compare our model with the following methods: Bias Matrix Factorization (BMF) [11]. This is a standard SVD matrix de-composition with user and item bias: indicate the deviations of user u and item i respectively, and U u , V v are latent factor vectors.
 SVDFeature [5]. This is a famous recommendation toolkit for feature-based CF. The authors of the toolkit have used it to win the KDD Cup for two con-secutive years. It can include attributes into CF process and is one of the state-of-the-art recommendation methods for single domain.
 STLCF [16]. This is a selective knowledge transfer method and can outperform some cross domain RSs such as CMF. It applies the AdaBoosting framework in order to capture the consistency across domain in CF settings, and it does not consider the rich content information of items.
 MV-DNN [8]. This is a content-based multiple domain recommendation. It uses deep learning to match rich user features to item features. However, it does not exploit collaborative filtering.
 MCDRS-. This is a variant of our proposed method which removes the neigh-bor model submodule.
 different methods, where R indicates the test set: tried  X   X  from { 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0 } . To reduce computational cost, for all algorithms we use a same fixed latent feature dimension, i.e. we fix the dimensions of BMF, SVDFeature and STLCF to be 16, and fix the size of the last layer in MV-DNN model to be 16 while changing the sizes of previous hidden layers in { 32, 64, 128 } . For our proposed model, we set the CF dimension to be 8 and the content-related dimension to be 8, so that the total size of the latent factors is 16. After running these groups of parameters, we pick the best parameter set for each model according to the validation set. We re-run the experiment pipeline five times for each model by fixing the best parameter set, and report the corresponding average RMSE on the test set. For our model, the best setting is {  X  1 = 0 . 8 , X  3 =  X  5 = 0 . 005 , X  4 =  X  2 = 0 . 1 } . Fig. 1: RMSE evaluation on Douban dataset (a-c) and MovieLens 20M dataset (d). Here,  X  X ovie to book X  represents the source domain is movie and target domain is book. 5.2 Results Figure 1 shows the RMSE results of different algorithms. Generally speaking, due to consistency problem across domains, a small volume of new data in the target domain matches up to a large volume of data from the source domain. And our MCDRS is designed to consider as much knowledge as possible in the target domain, and at the same time transfer knowledge from the source domain. So it is expected to observe the fact that our proposed model consistently outperforms the other models under various tasks.
 as the source domain and take book domain as the target domain. The BMF model is the weakest one because it is a single domain CF algorithm, and it does not consider the rich content information. SVDFeature is the single domain model which combines both CF and content information. It X  X  no surprise that SVDFeature significantly outperforms BMF. STLCF and MV-DNN work better than SVDFeature only under the low sparsity levels, and the superiority trend to disappear when the data become denser. MCDRS-significantly outperforms STLCF and MV-DNN due to its utilization of both collaborative filtering and content-based filtering in the cross domain situation. At last, MCDRS shows a further improvement, which demonstrates the necessary of selective learning part.
 with Figure 1a. Movie and book are two close domains and they share a lot of topics, such as adventure, history fiction, and science fiction. Some movies are even adaptations of famous books. So it will be easier to build cross domain RSs between movie and book domain. However, music domain is relatively not so close with movie or book domain. Thus in Figure 1b and 1c, STLCF and MV-DNN are worse than SVDFeature when the sparsity level is above 5%. MCDRS model works well in the two tasks, which verifies that our designed selective learning module can mitigate the inconsistency problem between domains. domains are actually derived from the original movie domain. So all the cross domain models can easily outperform the single domain models. Comparing MCDRS-with STLCF and MV-DNN, we again observe that it is quite necessary to incorporate both collaborive filtering and content-based filtering in the cross domain RSs. Fig. 2: RMSE improvement of MCDRS against single domain model at various sparsity levels. Here,  X  X ovie2book X  represents the source domain is movie and the target domain is book.
 the SVDFeature. There is a clear pattern that the cross domain RS works well when data in the target domain is severely sparse, and the degree of improvement decreases when the data of target domain becomes denser. Relatively speaking, the MovieLens task shows the greatest improvement as expected. Results of the task movie2book is better than the movie2music because that the inconsistency on the movie-book domain is smaller than that on the movie-music domain. Single domain recommendation systems . In general, recommendation sys-tems can be divided into content-based model, collaborative filtering (CF) mod-els and hybrid models [4]. Content-based models represent user and item under a same feature space and make recommendation according to their similarity [14]. CF models make predictions about the interests of a user by collecting preferences or taste information form many users. Among CF models the latent factor models are the most widely studied methods [7, 23, 22]. Hybrid models try to integrate content-based method and CF method into one unified intelligent system [2, 17, 31, 15, 27]. In the recent years, the great success of deep learning models on computer vision and natural language processing has motivated re-searchers to develop deep learning models for recommender systems [24, 30, 28, 26, 1].
 Cross domain methods with user/item aligned . [3] studies some earliest CDCF models including the cross domain neighbor model. CMF [25] simulta-neously factorizes several matrices while sharing latent factors when an entity participates in multiple relations. CST [20] is an adaptation style tri-factorization algorithm which transfers knowledge from the auxiliary domain to improve per-formance in the target domain. TCF [19] uses the tri-factorization method to collectively learn target and auxiliary matrices. In their case both users and items are aligned between the two matrices. The major advantage of the TCF approach is that through tri-factorization it is able to capture the data-dependent effect when sharing data independent knowledge. [16] proposes a criterion which can be embeded into a boosting framework to perform selective knowledge transfer. [21] suggests a cross domain CF based on CCA to share information between domains. Ali et al [8] introduces a multi-view deep learning model to jointly latent features for users and items from multiple domains. Our paper belongs to this category of cross domain RSs. While the existing works focus on transfer knowledge through collaborative filtering or content-based filtering, we focus on incorporating the advantages of both the two models and further explore how to reduce the inconsistency problem through the rich information.
 Cross Domain methods with latent clusters . CBT [12] studies the cases in which neither users nor items in the two domains overlap. It assumes that both auxiliary and target domains share the cluster-level rating patterns. So it compresses the auxiliary rating matrix into a compact cluster-level rating pat-tern representation referred to as a codebook, and reconstructs the target rating matrix by expanding the codebook. RMGM [13] extends CBT to a generative model and they share the same assumption. [6] exploits tensor factorization to model high dimensional data and transfers knowledge from the auxiliary domain through a shared cluster-level tensor. In this paper, we discuss the scenario in which users of the two domains are well aligned, and thus is different from these hidden cluster-linking approaches. In this paper, we introduce a multifaceted model for cross domain RSs. It in-cludes two parts which are delicately designed for cross domain situation. First we propose a latent factor model to incorporate both collaborative filtering and content-based filtering, and different domains are bridged through the aligned latent user features. Second, we propose a selective neighbor model to reduce the inconsistency problem across domains. Experimental results demonstrate that our proposed model consistently outperforms several state-of-the-art methods on both Douban and MovieLens datasets. For future works, we will explore how to exploit deep learning techniques to learn better representation from the rich content information for cross domain RSs.

