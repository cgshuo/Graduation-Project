 1. Introduction
Transaction logs of electronic information retrieval (IR) environments provide a wealth of data for unob-trusive study of user behaviors. Their popularity has grown since the mid-1990s with the wider adoption of the World Wide Web as a service delivery platform. The broader availability of systems afforded by remote access through the Internet has also made it possible to study significantly larger logs consisting of hundreds of thou-sands to many millions of observations.

Although search facilities for different information retrieval environments on the Internet (online public access catalogues [OPACs], bibliographic databases, Internet search engines) may appear similar, with a search box and execute button, the content to which they provide access can be fundamentally different. Popular search environments such as public search engines provide access to full-text content on a variety of topics. Bibliographic databases provide full text or surrogate access to formally published document sources. OPACs primarily deal with surrogate access to monographic and serial-level sources. Do these differ-ences in content result in differences in search behavior by users, or are the same behaviors observed across systems? Users may or may not treat search facilities (i.e., search boxes) the same way.
 search environments. More specifically, this study aims to explore the following questions: distributions of search characteristics and descriptive statistics of these distributions. 2. Previous studies behavior and mathematical modeling perspectives. User search behaviors in electronic environments, whether from an informetric or user-centered information seeking perspective, have gained considerable research attention with the rise in popularity of the World Wide Web as an information access environment. Transac-tion log studies of IR systems, however, are not just a product of the Web era, as outlined by Tolle (1984) and more recently Peters (1993) . Logs have been studied for decades, although datasets from earlier studies were generally smaller than today X  X  Web-based studies. For example, in earlier studies of OPAC transaction logs (e.g., Millsap &amp; Ferl, 1993; Peters, 1989; Wallace, 1993 ), datasets consisted of fewer than 15000 queries and the authors did not report the same array of descriptive data as has been seen in more recent Web-based system studies. Larson X  X  (1991) study of the University of California X  X  Melvyl system usage, consisting of over five million sessions, is an exception to this.
 has resulted in many studies in which key search characteristics have been reported. Studies of query charac-teristics have included special topic websites such as THOMAS ( Croft, Cook, &amp; Wilder, 1995 ), a university website ( Wang, Berry, &amp; Yang, 2003 ), digital libraries ( Jones, Cunningham, &amp; McNab, 1998; Mahoui &amp;
Cunningham, 2000 ), a Web-based OPAC ( Cooper, 2001 ), bibliographic databases ( Yi, Beheshti, Cole, Leide, Rie &amp; Xie, 2006; Spink, Jansen, Wolfram, &amp; Saracevic, 2002; Spink, Wolfram, Jansen, &amp; Saracevic, 2001;
Wolfram, Spink, Jansen, &amp; Saracevic, 2001 ), Vivisimo ( Koshman, Spink, &amp; Jansen, 2006 ) and federated search systems such as Dogpile ( Spink &amp; Jansen, 2006 ). Across studies that deal with public Internet search engines, investigators have found that users submit queries that consist of only a few terms, rarely use Boolean operators or other query modifiers, view few pages of results, and engage in brief sessions of few queries ( Jan-sen &amp; Pooch, 2001 ). Numerous similar studies have been published since that time using different search ser-vices. Spink and Jansen (2004) summarize many of these findings in their recent monograph on Web searching. For other types of more traditional Web-based search environments, such as OPACs and biblio-graphic databases, higher mean numbers of terms per query than for public search engines were reported, for example, by Cooper and Yi et al. in their studies, respectively.
 have also appeared recently. Spink and Jansen (2006) examined multitasking behaviors within search sessions on a large Alta Vista transaction log. The authors highlighted how Web-based searching serves as an example of interactive IR that incorporates two levels of multitasking involving the interplay of different search tasks.
Suggestions for supporting interactive IR in public search environments were made. Using a more fine-grained approach, Rie and Xie (2006) analyzed a set of 313 multi-query search sessions from an Excite transaction log. The authors develop a model of Web query reformulation based on Saracevic X  X  stratified model of interactive
IR and provide several suggestions for system features that will support interactive IR.
User-centered perspectives represent one approach to the study of transaction log sessions. Web query transaction logs have also been studied from an informetrics perspective, where observed patterns of querying have been reported or modeled mathematically. These models represent generalizations of observed patterns and may serve as a predictive tool for search characteristics if an effective model has been derived. Regularities in the occurrence of text or usage of search systems in electronic environments have been found to exhibit sim-ilar patterns as for print media, following  X  X  X ower laws X  X  or are concluded to be Zipfian in nature due to the highly skewed nature of data distributions. These conclusions are frequently drawn based on a visual inspec-tion of a trend line of logarithmically transformed data. However, a simple Zipf distribution may not ade-quately model the observed characteristics for electronic environment characteristics ( Ajiferuke &amp; Wolfram, 2004 ), particularly for highly skewed, larger datasets representing potentially millions of observations. As a sample dataset increases in size, it becomes increasingly skewed, which influences model fitting and the type of model used for fitting. For large datasets, however, the descriptive characteristics such as mean values for terms used per query and session sizes remain largely the same ( Ajiferuke, Wolfram, &amp; Famoye, 2006 ). Beyond usage of mathematical modeling for general confirmation of conformance to a given distribution, working with large datasets and their cumulative deviations from theoretical models makes effective model-fitting challenging. For this reason, mathematical modeling beyond descriptive measures of distributional characteristics is not carried out in the present study.

To date, there appear to have been no direct comparisons of Web-based IR transaction log outcomes across different environments, although a number of public search engine logs have been compared, for example, Spink and Jansen (2004) , who compare the findings of several search services in their monograph, and more recently they performed a comparison of nine datasets representing five search engines ( Jansen &amp; Spink, 2006 ). Jansen and Pooch (2001) do provide a side-by-side comparison of search data from different IR environments, but the comparison is made based on Web and closed, pre-Web systems with datasets that are not necessarily based on transaction logs collected unobtrusively. The current study performs a direct comparison of several different Web-based environments based on unobtrusive transaction logs. 3. Method 3.1. Dataset descriptions
Transaction log datasets were available from four different types of Web-based IR environments. The amount of data from each system was limited to what was made available to the author by the data providers ( Table 1 ). Datasets represent the following environments:
Bibliographic databank : The University of Wisconsin X  X adison libraries provide access to dozens of general and specialized bibliographic references and full-text databases through their E-resource gateway. Note that the term  X  X  X atabank X  X  is used instead of database because the searches do not represent submissions 3.2. Term and query processing abases. Each record included an identifier for each submission (IP address, session identifier, cookie), time/ date stamp for each query, and the query itself. The data were processed to identify individual sessions, queries and terms. Note that: assumed to represent requests to view the next page of results associated with the initial query. These were not treated as separate queries, but rather as extensions of the same query, representing requests for additional result pages for browsing. 3.3. Session boundary determination resented discrete sets of queries from users X  initial entry to the search site to their departure. Specific session identifiers were not available for the search engine and special search service datasets, which contained IP address and client-side machine cookie identifiers, respectively. Single queries associated with a given identifier represented a session of one query. Two or more queries associated with the same identifier could be part of the same session or might represent different sessions. Session boundary detection was, therefore, not as obvi-ous. A method for session boundary determination, therefore, is needed.
 characteristics of queries. Subject analysis can be performed automatically or manually. Manual analysis can be impractical for large datasets, whereas automatic approaches may be unreliable for short queries, and might not take into account whether users engage in multiple search topics in a given session. The second method for session boundary detection, which relies on timing characteristics, considers temporal cut-off points or probabilistic characteristics of the datasets. The main drawback of this method is that the boundary detection method usually does not take into account the subject content of queries, relying more on temporal patterns of query submission. Murray, Lin, and Chowdhury (2006) , for example, relied on timing character-istics that assume a minimum of 20 queries per identifier from which large gaps in inter-query times (i.e., a long period of time between queries submitted by the same identifier) are located to indicate session boundaries. This method shows promise for large logs where there are many queries associated with a given identifier, but was not practical for the two datasets without session identifiers used in the present research. The number of queries associated with each identifier was far below the needed threshold, with less than 1% of queries by a given identifier qualifying.

General cut-off values based on qualitative assessment of query sets to delineate sessions have been more widely used. Spink and Jansen (2004) concluded that most Web search sessions last about 15 min, with a sub-stantial percentage lasting less than 5 min (p. 121). Similarly Go  X  ker and He (2002) suggested that an optimal session boundary interval was 11 X 15 min. More recently, Jansen, Spink, Blakely, and Koshman (2007) com-pared three methods that rely on data contents using: (1) Internet protocol (IP) addresses and machine cook-ies; (2) IP addresses, cookies and a temporal cut-off point, and (3) IP addresses, cookies, and content changes to queries. The authors concluded that the third method, which combined content change data, provided the best granularity in session identification based on a manual classification of 2000 queries. Both this method and the method that incorporated a temporal cut-off, however, resulted in an accuracy of above 95% when compared to a human judge.

The method for session boundary determination used in the present study for the two datasets without sys-tem-defined session boundaries incorporates a probabilistic approach that considers the distribution of inter-query times for each dataset (i.e., the time between two temporally adjacent queries associated with the same identifier). Initially each distribution was visually inspected to determine if a perceivable gap was present along the distribution. Although there was a gradual decline in the number of observations associated with longer inter-query gaps for both datasets, there was no clear cut-off point. An arbitrary assignment of a cut-off point based on past studies without considering the characteristics of the datasets themselves would have been short-sighted. Two assumptions, therefore, were made. First, sessions were assumed not to span multiple days. This criterion only applied to the specialized information service dataset, which represented one year of data. The data for the Excite search engine were collected on a single day, so this was not an issue. Second, any cut-off point should consider the characteristics of the dataset itself and not only reported values for earlier datasets. More specifically, it should consider the skewing effect of long inter-query times resulting from two temporally adjacent queries containing the same identifier. If submitted far apart in time, they are unlikely to be part of the same session, particularly if the time falls high in the tail-end of the distribution of inter-query times. As Spink and Jansen (2004) noted, the mean session time associated with an identifier was more than 2 h for some search engine datasets, but most sessions lasted less than 15 min. It is conceivable that users may engage in search activities for a lengthy period of time, but if there is a long period of inactivity, the likely explanation is that the session has ended and any subsequent query represents the beginning of a new session.
To determine the effect of different cut-off points on the average session length, query intervals representing the 10th through 90th percentiles of values were selected, with the resulting average session length calculated for the Excite and HealthLink datasets. When graphed using a semi-log plot, there is a notable increase for average session lengths over short query interval increases, but these increases become much smaller with lar-ger cut-off times. The plots for these two datasets appear in Figs. 1 and 2 . The average session values take on an S-shape, with a turning point occurring high in the distribution. These turning points in the distribution signify a slowdown in the increase of the average session size, and occur around or just before the 80th per-centile for these datasets. There is some leeway with the decision for the cut-off point in those differences aris-ing from higher percentile cut-offs. For example, the differences between the 70th and 80th percentile cut-offs for the datasets represent a 2 X 3-fold increase in time, but only result in approximately a 10 X 17% increase in the average session lengths. For the Excite search engine data, the cut-off time was 1074 s (17.9 min). For the spe-cial search service dataset, this cut-off was only 229 s (3.8 min). Although not a perfect solution, this method takes into account the characteristics of each dataset and deals with the obvious inter-query time outliers that extend across many hours, which skew the session sizes and average inter-query times, and overestimate the number of longer sessions. 3.4. Dataset comparisons per query, pages used per query, and number of queries per session. Ajiferuke et al. (2006) demonstrated that the first two measures were not noticeably affected by sample size. The same is true for queries per session when datasets are not sampled at the query level. This cannot be said of average term frequencies, which are highly dependent on the dataset or sample size. Relative frequency distributions based on percentages were tallied for the less variable measures to determine if the observed search characteristics differed for each envi-ronment. Relative distributions also were used because of the differences in sample size for each dataset. 4. Findings
As suggested by Jansen (2006) and Jansen and Pooch (2001) , search data should be analyzed at the term, query, and session (or user identifier) level. A summary of descriptive measures calculated for each dataset appears in Table 2 . 4.1. Term analysis
The 25 most frequently used terms appearing in queries for each dataset appear in Table 3 . The high usage of articles, prepositions, and conjunctions (e.g.,  X  X  X ND X  X  as a Boolean operator or otherwise) is common across all datasets. For the specialized search service, the use of the Boolean  X  X  X ND X  X  operator is not directly supported as a word, but is represented as a plus sign. Frequently used terms highlight popular health topics of interest to searchers. The terms submitted to the bibliographic databank and OPAC are indicative of more academic searching, although the OPAC deals primarily with document surrogates. Searcher interest in multi-media, software, education, and adult-oriented topics are reflected in the high frequency usage of related terms in search engine submissions ( Spink &amp; Jansen, 2004 ).

The low-end of the query term size X  X requency distribution appears in Fig. 3 . Ajiferuke et al. (2006) dem-onstrated that the relative frequency of rarely used terms decreases with the increase in the dataset size. Despite being the largest dataset, the search engine log shows the highest relative usage of infrequently used terms. This is followed by the bibliographic databank, with the OPAC and health information service with just over 50% of the terms appearing only one time. Given the more focused search purpose of each of these sys-tems, this is not unexpected. Note that mean frequencies for term usage are not reported because they are highly dependent on the sample size, according to Ajiferuke et al. The percentages could also be a reflection of the breadth of documents indexed and vocabulary used to access them. Search engines index all conceivable topics. The databank and OPAC limit themselves to published content, but on a variety of topics. The spe-cialized search service has the most focused content, dealing with health-related topics.
 4.2. Query analysis the topic being searched and demonstrate the efforts that the user is willing to exert through query formulation and the number of pages the user is willing to browse. The distributions of terms used per query appear in Fig. 4 . The unimodal, or Poisson-like, shape of the distributions is typical of query submissions, where users are likely to enter slightly more than a minimum number of terms. The highest mean terms used per query is associated with the OPAC dataset, followed by the general search engine. Surprisingly, the specialized search service and bibliographic databank provide the two lowest average numbers of terms, with the most frequent number of terms per query being only one. One would expect the users of an academic resource such as a bib-liographic resource to be more discriminating in the development of their queries.

The number of pages viewed also varies among the datasets. Note that this type of data is not recorded for the specialized search service. These data are reported only briefly because each of the three systems provides a different number of retrieved results per page, which directly affects the number of pages each user might view. The search engine shows the highest mean number of pages viewed per query, which is still argued to be low in previous studies ( Spink et al., 2002 ), but it also displays the lowest number of results per page. The biblio-graphic databank shows the lowest mean value of pages viewed. Unfortunately, the number of returned items viewed cannot be deduced from any of the datasets. 4.3. Session analysis
Session-level data comprise session length and duration characteristics. The truncation of lengthy inter-query times for the search engine and specialized search service reduced the number of lengthier sessions and increased the number of shorter sessions, resulting in a steeper frequency distribution of session sizes. However, even with the relatively short session interval for the specialized search service, it still contained the highest mean number of queries per session. A longer session interval would only increase this value. The bibliographic databank resulted in the highest number of single query sessions, followed by the search engine, OPAC and specialized search service ( Fig. 5 ). This ranking is also reflected in the mean queries sub-mitted per session.

Result viewing times, measured indirectly through the distribution of inter-query times for multi-query ses-sions, reveal that there are also notable differences among the studied environments. As essentially continuous data spanning seconds to many hours, the distribution of query times may be viewed at different levels of gran-ularity. In tallying the data using different levels of aggregation, the most notable differences are apparent at times below 5 min ( Fig. 6 ), and particularly below the 1-min interval ( Fig. 7 ). Beyond the 5-min time frame, all the distributions decline rapidly, with little difference between them. The specialized search service produced the shortest mean inter-query times and highest percentage of viewing times below 1 min. The search engine produces the longest mean time and the lowest percentage of brief queries.
 5. Discussion
Given the differences in the search patterns, it appears that users do engage in different search behaviors and that Web search facilities are not viewed as the same. The one surprising finding was the short query lengths and search sessions for the bibliographic databank. As an example of a more traditional IR environment providing access to formally published resources with more structured searching, one would expect user search behaviors to be more in line with what was observed for the OPAC, where queries were purposeful, longer in length (i.e., greater specificity), with more queries per session and longer inter-query times reflecting the perusal of results. The number of terms per query is similar to the figure of 1.88 reported by Wang et al. (2003) in their study of a university website general search engine transaction log. As noted earlier, transaction logs from OPACs and bibliographic databases, which pre-date Web search engine technologies, have been studied for decades. Internet-based remote access, and particularly Web-based implementations, have made these systems more widely available, thereby allowing larger datasets to be collected. Jansen and Pooch (2001) compared several different studies of pre-Web or non-Web bibliographic database and OPAC search environments. For the bibliographic database studies ( Hsieh-Yee, 1993; Koenemann &amp; Belkin, 1996; Sieg-fried, Bates, &amp; Wilde, 1993 ), the average terms per query were much higher, ranging from 6.4 to 8.8 terms per query. Sessions were also longer, ranging from 7 to 16.7 queries on average. These studies were small, involving between 21 and 64 participants who were primarily novice searchers. The reported OPAC studies ( Millsap &amp; Ferl, 1993; Peters, 1989; Wallace, 1993 ), which relied on transaction logs and possibly remote users, did not provide as detailed query and session data but reported shorter sessions and query submissions, more in line with what was observed in the presently studied OPAC. The mean session size (2.25 queries) is lesser than the three queries per session reported by Cooper (2001) . Similarly, the mean query length observed in the bibliographic databank, is much shorter than the three terms per query observed by Yi et al. (2006) , who also relied on a Web-based environment.

Interface features across each environment could account for some of the observed differences in search characteristics. However, for all of the systems except the OPAC, the default search mode was a general, single purpose search box. Like the OPAC, the interface for the bibliographic databank system did support field searching, but with a general search as the default. Still, with largely similar interfaces, differences did arise. Most searches recorded in the bibliographic databank log did not employ any field-specific parameters. This was not the case for the OPAC data, where field searching was commonly used. The comparative absence of field searching in the bibliographic databank, in a sense, made the searches more comparable to a general search engine environment. Given that sessions were brief, with far shorter inter-query times, users may not have been willing to invest much time or effort in their searches. Alternatively, they may have been able to quickly assess the relevance of their search results based on viewing the bibliographic citation alone without having to view the full text.
 formulation, but longer inter-query times for perusal. This has also been a common theme for other search engine studies carried out over the past decade. The opposite is the case for the specialized search service, which on the surface functions in a similar fashion as the general search engine. Queries and perusal times are shorter, whereas sessions are longer, thus indicating more focused and selective examination of results.
The short sessions and query activities associated with the bibliographic databank could be an indication that users do not recognize the difference in content or search capabilities of this environment in comparison to a general search engine. One could also argue that users of the bibliographic databank and OPAC are more spe-cialized, representing more academic interests and are more quickly able to assess the relevance of outcomes.
Each of these systems is available publicly to any Web user, but may limit access to licensed full-text resources, and each is less likely to be discovered by casual users than a general search engine. Still, search differences were evident even between these seemingly similar environments.
 large-scale search patterns, but cannot explain why these patterns exist. Session boundaries, if not provided, must be estimated if session-level analysis is to be conducted. In the absence of human judgement, which in itself is subjective, automated algorithms for this purpose are needed, or assumptions about the nature of ses-sions must be made. For the two datasets for which system-defined session boundaries were not available, the method used provides a cut-off point based on the datasets. The selected cut-off points occurred around the 80th percentile in these cases, but may differ for other datasets, which could be determined by calculating the different average session outcomes for various cut-off points. With higher percentile values, the differences in average session length become less significant, so this approach is less prone to wide swings in average ses-sion length outcomes. If inter-query times are compared, instead of session lengths, these differences would be much more problematic.
 frames. This is often the case with any system comparison study. Researchers are limited to the data that are made available unless they have direct access to server logs over long periods of time. The different time frames, ranging from one day to one year of data, could also affect outcomes. Each system provides a different interface and access to different types of resources, some more broader than the others, which may attract dif-ferent audiences. Are the session behavior outcomes then comparable? Most definitely. Whether differences arise from dissimilar user groups or content, they should be recognized by service providers and search educators.
 bibliographic database environments attract more of an academic audience. Public search systems, whether specialized (HealthLink) or general (Excite), are likely to attract a broader audience, which can influence out-comes. Regardless, system designers will wish to support observed differences in behavior, whether stemming from demographic factors or the nature of the information need itself. 6. Conclusions ble differences at the term, query, and session levels. Given the audiences to which each type of service caters, the results were not unexpected except, perhaps, for the bibliographic databank environment, where one would anticipate more sophisticated searching based on the nature of the database contents and the audience served.
 sons, as opposed to the more common intra-system comparisons of general search engines, which have appeared to date. Confirmation of these differences among different types of Web-based IR systems will require access to larger numbers of datasets for each type of system to determine whether differences across different types of systems are greater than differences within the different types of systems. Future research will investigate a larger number of examples of these services over a longer period of time to determine if the observed relationships in the present study hold for other examples of each of these systems.
 Acknowledgments
The author thanks the following organizations for providing access to the datasets used in this study: Ex-cite@home, Medical College of Wisconsin, University of Wisconsin X  X adison Library System, and University of Wisconsin X  X ilwaukee Golda Meir Library. Thanks also go to the anonymous referees for their helpful suggestions.
 References
