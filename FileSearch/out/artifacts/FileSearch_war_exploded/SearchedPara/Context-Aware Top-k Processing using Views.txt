 Search applications where queries are dependent on their context are becoming increasingly relevant in today X  X  online applications. For example, the context may be the location of the user in location-aware search or the social network of the query initiator in social-aware search . Processing such queries efficiently is inherently diffi-cult, and requires techniques that go beyond the existing, context-agnostic ones. A promising direction for efficient, online answering  X  especially in the case of top-k queries  X  is to materialize and exploit previous query results (views).

We consider context-aware query optimization based on views, fo-cusing on two important sub-problems. First, handling the possible differences in context between the various views and an input query leads to view results having uncertain scores, i.e., score ranges valid for the new context. As a consequence, current top-k algorithms are no longer directly applicable and need to be adapted to handle such uncertainty in object scores. Second, adapted view selection techniques are needed, which can leverage both the descriptions of queries and statistics over their results. We present algorithms that address these two problems, and illustrate their practical use in two important application scenarios: location-aware search and social-aware search. We validate our approaches via extensive experiments, using both synthetic and real-world datasets.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search Process top-k processing; context-aware applications; social search; spatial search
Retrieving the k best data objects for a given query, under a certain score model, is one of the most common problems in databases and  X  Work done while the authors were affiliated with Institut Mines-T X l X com -T X l X com ParisTech.
 on Web. In many applications, and in particular in current Web search engines, tens of thousands of queries per second need to be answered over massive amounts of data. Significant research effort has been put into addressing the performance of top-k processing, towards optimal algorithms  X  such as TA (Threshold Algorithm) and NRA (No Random Access algorithm) [7, 10]  X  or highly-efficient data structures [21] (e.g., inverted lists). In recent research, the use of pre-computed results (also called views ) was identified as a promising avenue for improving efficiency [11, 6].

At the same time, with the advent of location-aware devices, geo-tagging, or online social applications, as a way to improve the result quality and the user experience, new kinds of top-k search applications are emerging, which can be simply described as context-aware . The context of a query may represent the geo-location where the query was issued or the social identity  X  within a social network  X  of the user who issued it. Generally, it could represent certain score parameters that can be defined or personalized at query time. For example, a query for nice vegetarian restaurants should not give the same results if issued in Miami or in Boston , as it should not give the same results if issued within a social community of culinary reviewers or within a student community.

Unsurprisingly, taking into account the query context in top-k processing is a new source of complexity, and most of the com-mon approaches employed in context-agnostic scenarios must be revisited [5, 16]. Now, query processing usually entails an explo-ration of a  X  X eighborhood X  space for the closest or most relevant objects, which is often interleaved with some of the classic, context independent top-k processing steps, such as scans over inverted lists.
Consequently, materializing and exploiting in searches the results of previous queries can be even more important for efficient, online processing of queries with context. But, in this direction, a broader view-based answering problem than in the context-agnostic setting needs to be addressed, in which the cached results are modeled as unranked lists of objects having only uncertain scores or score ranges . The rationale is that, even when the cached results in views do have exact scores with respect to one context, we should expect these to evolve into score ranges if a context transposition is nec-essary. For example, answers to the previous query, for a Boston context, may be useful  X  but only to a certain extent  X  when the same query is issued in a nearby Cambridge context, as one has to adapt the scores of restaurants from the former perspective to the latter one; this, inherently, introduces uncertainty.

The potential impact of view-based algorithms coping with such uncertainty is highly relevant but not limited to context-aware set-tings. Even when queries are not parameterized by contexts, some of the most efficient algorithms (NRA or TA Z [7]) support early-termination, outputting unranked results with only score ranges. Motivation 1: Location-aware search. Let us consider the spatial-search scenario in Figure 1 (left), in which we have objects at various locations in an euclidian space (objects o 1 ,...,o 5 in the figure, as gray dots). Each object (e.g., a Web document) is characterized by a bag of attributes. For instance, o 5 has attributes t 1 and t 2 , both with a single occurrence.

Now, users located at various points ask for top-k objects w.r.t. a set of attributes. In response, objects are ranked by a combination between the distance of the object w.r.t. the seeker X  X  location and the object X  X  content. While the details of the spatial ranking model will be clarified in Sec. 7, let us assume here that the location relevance of an object contributes 30% to the object X  X  score. The remaining 70% is the weight of its textual score (e.g., tf-idf).

Consider a new query Q in the system, asking for the top-2 items for attributes { t 1 ,t 2 } at the point marked by a white dot in the figure. Intuitively, spatial search algorithms [5], by using indices such as the R-tree [8], would proceed by incrementally increasing the search distance until enough objects are found. However, an alternative execution plan may be possible, if we assume access to cached results of previous queries (initiated at the black dots).
For example, let us assume that v 1 gives the top-3 documents 1 } . Also, sharing the same location, we have v 2 and v 3 . The former gives the top-4 for { t 1 } as { o 2 = 0 . 946 ,o 3 = 0 . 575 ,o 5 = 0 . 500 ,o 4 = 0 . 262 } . The latter gives the top-4 for { t 2 } as { o 4 = 0 . 962 ,o 5 = 0 . 500 ,o 1 = 0 . 437 ,o 2 = 0 . 246 } .

Since v 1 , v 2 and v 3 are closer to Q than any of the objects, it would be tempting to use their lists of pre-computed results, instead of looking for the actual objects.

In particular, one may resort to using only v 1  X  X  results, as it is closest to Q both spatially and textually. For that, we need first to perform a change of context, to account for the fact that objects that were close to v 1 may be even closer to Q , as they may be farther. This will introduce uncertainty in the scores of v 1  X  X  result: knowing that the normalized distance between Q and v 1 is 0 . 175 , for Q  X  X  perspective, v 1  X  X  list should now have objects with score intervals , two attributes (terms); 0 . 3 represents the 30% score weight.)
We can see that v 1  X  X  result is not sufficient to answer Q with certainty, since any object among the three candidates may be in the top-2 . Yet further refinements are enabled by v 2 and v 3 , albeit more distant, if we corroborate their results with the ones of v 1 . Knowing that v 2 and v 3 are at a normalized distance of 0 . 25 w.r.t. Q , the transposed scores would be, for v 2 : { o 2  X  [0 . 871 , 1] ,o 3  X  o 2  X  [0 . 171 , 0 . 321] } . Now, we can conclude, for example, that o 4 is for sure in Q  X  X  top-2 result. This is due to the fact that o 4 cannot be overpassed by o 5 : on one hand, an upper-bound on o 5  X  X  score can be inferred as min(0 . 525 + 0 . 525 , 1 . 167) = 1 . 050 ; on the other hand, a lower bound on o 4 score can be inferred as max(0 . 187 + 0 . 887 , 0 . 954) = 1 . 074 .
 Motivation 2: Social-aware search. As a second motivating ex-ample, we consider the setting of collaborative tagging applications (as Flickr or Del.icio.us). In these applications, users tag (or book-mark) objects from a common pool of objects (e.g., Web sites). Users form a social network, in which relationships are weighted (e.g., a similarity or proximity value). Such a setting is illustrated in Figure 1, right. For example, user u 1 has tagged object o 1 with t and t 2 , and o 2 with t 1 ; he is 0 . 9 -close (or similar) to u 0 . 5 close to v 2 . User v 2 tagged object o 5 with t 1 .
We use the social ranking model introduced by Amer-Yahia et al. [1] and extended by Schenkel et al. [16]. Intuitively, with this model, an object X  X  score (e.g., o 1  X  X ) for a given tag (e.g., t proportional to the sum of the proximities of the taggers (i.e., u and u 2 ) w.r.t. the seeker. An object X  X  score for a set of tags is then computed by aggregating the per-tag scores, e.g., by summation.
Let us now assume that the top-2 items for { t 1 ,t 2 } are requested by user s (the seeker). As in location-aware search, early termina-tion algorithms [16, 13, 14] for social search would incrementally explore the most promising users (and their objects) until the top-k is found. This may lead to the visit of a non-negligible fraction of the network. For our query, an exploration of the network would need to go as far as u 2 to establish a top-2 as { o 1 ,o 5 } .
Yet an alternative, more efficient processing approach may rely on pre-computed results. Let us assume that users v 1 , v 2 have such for { t 1 ,t 2 } as { o 1 = 3 . 42 ,o 5 = 1 . 53 ,o 2 = 1 . 4 ,o 3 = 1 . 31 } .
Knowing that the distance between s and v 1 is 0 . 9 , in similar way to the spatial-aware scenario, a transposition of context from v 1 to s (the formal ranking model will be described in Section 7) leads to the between v 2 and s is 0 . 8 , context transposition leads to the following [1 . 16 , 1 . 81] ,o 4  X  [0 . 36 , 0 . 56] } .

As in the previous scenario, by using only the closest view (from v 1 ) we cannot obtain the top-2 required by s , because: (i) either of o 2 , o 3 and o 5 might enter the top-2 alongside o 1 , and (ii) the objects which are not included in the view might have a score as high as 1 . 45 , meaning they might also be in the top-2. Yet, using also the information in the views of user v 2 enables us to establish just two neighbors of s , v 1 and v 2 .
 Our contributions. We formalize and study in this paper the problem of context-aware top-k processing based on possibly uncer-tain precomputed results, in the form of views over the data.
Most informative answer. Answering such top-k queries using only the information in views, inevitably, requires an adaptation to the fact that the views may now offer objects having only uncertain scores. So there may be view instances from which an exact top-k cannot be extracted with full confidence. When this is the case, we aim to give a most informative answer , in terms of (i) objects G that are guaranteed to be in the top-k result, and (ii) objects P that may appear in the top-k result.

TA adaptation. We formalize this query semantics and describe an adaptation of TA, denoted SR-TA. It handles precomputed lists with score ranges , and is sound and complete , i.e., outputting the ( G,P ) -answer. Intuitively, SR-TA implements the illustrated cor-roboration principle, based on a linear programming formulation.
View selection. As in many applications the set of views may be large, we also consider optimizations for SR-TA, based on selecting some (few) most promising views . Obviously, with fewer views, the most informative answer ( G,P ) may no longer be reached; we are in general presented a trade-off between the number of selected views  X  determining the cost of the top-k algorithm SR-TA  X  and the result X  X   X  X uality X  (a distance with respect to the most informative answer given by all the views).

Applications  X  context transposition. Importantly, our algo-rithms provide a one-size-fits-all solution for many applications that are context-dependent, and we show how they can be directly ap-plied in our two motivating application scenarios for context-aware search, social-aware search and location-aware search.

Extensive experiments on synthetic and real-world datasets show the potential of our techniques  X  enabling high-precision retrieval and important running-time savings. More generally, they illustrate the potential of top-k query optimization based on cached results in a wide range of applications.
 Outline. We discuss the main related work in Section 2. We formalize the context-aware search setting and problems in Section 3. We give the SR-TA adaptation of TA, in Section 4. Our optimization approach by view selection is formulated in Section 5. We study the formal properties of SR-TA, and we give our experimental evaluation in Section 8.
Main research landscape. In addition to the classic TA/NRA [7] algorithms, other techniques for top-k answering using views have been proposed in recent literature: the LPTA algorithm [6] and generalizations of NRA and TA [11], both applicable in settings where aggregation functions are linear combinations of the per-attribute scores. Regarding view selection, the work closest in spirit to ours is [6], whose focus is on finding the optimal top-k execution based on a selection of precomputed views, with all the per-attribute lists being assumed to be part of the view space. Their approach simulates the run of a threshold algorithm over histograms of views. The setting of [6] is fundamentally different from ours. First, any viable selection of views must output the exact, ranked top-k result, which represents a strong limitation for practical purposes. Hence, while their focus is on optimizing the top-k computation, we deal with a different perspective over the view selection problem, towards minimizing the uncertainty of the result. [17] computes top-k answers on uncertain data  X  ranked object lists with score ranges and probability-density functions  X  through a probabilistic ranking model based on partial orders; they do not deal with aggregation of uncertain scores over multiple dimensions.
Other related work. The common data structure for top-k pro-cessing is the inverted index file (see [21] X  X  survey on indexing for top-k processing), over which a key challenge is to optimize response time [19, 20]. Regarding algorithms, among the most cited and used are the early-termination threshold algorithms TA and NRA of [7], which are instance optimal. Many other top-k aggrega-tion algorithms were proposed in recent literature, and we refer the interested reader to the survey [10] and the references therein. The use of precomputed results, either as previous answers to queries [6, 9] or as cached intersection lists [11], has been identified as an im-portant direction for efficiency. A linear programming formulation over score information is first introduced in [6] and extended in [11].
In [17], the authors study top-k processing when only score ranges are known, instead of exact ones, define a probabilistic ranking model based on partial orders and introduce several semantics for ranking queries, but do not deal with aggregation of uncertain scores over multiple dimensions. Another general formulation of ranking in probabilistic databases is presented in [12]. In the area of location-aware retrieval, Cong et al. [5] introduce the concept of L k T queries, for which they include in the ranking model both the distance of a document X  X  location w.r.t. the query point and the textual features of the document. They propose the IR-tree index, consisting of an R-tree [8] in which each node has an inverted list of relevant documents. Other models for top-k location-aware keyword querying have been proposed, for selecting either groups of objects that collectively satisfy a query [3], or the k -best objects scored by the features in their neighborhood [15], or the top-k objects in a given query rectangle [4]. Various approaches for combining textual inverted lists and spatial indexes for keyword retrieval were studied in [4]. In the area of social search, for which bookmarking applications are a popular abstraction, top-k processing using the social network as an integral part of the ranking model has been considered in recent research. [1] is the first to consider this problem, yet under significant restrictions, taking into account only a subset of users and their documents in answers. The C ONTEXT M ERGE algorithm [16] is the first to address the social-aware search without imposing limitations on the exploration space, and they use the ranking model that we adopted in this paper.
Context-aware score model. We assume a finite collection of objects O and a countable collection of attributes T . Under a given context parameter C  X  an abstract notion whose instantiation depends on the application  X  objects o are associated to certain attributes t , by an object-attribute score function sc ( o,t |C ) .
Under a context C , a query Q consists of a set { t 1 ,...,t attributes; its answer is given by objects o  X  X  having the highest scores sc ( o,Q |C ) , computed via a monotone aggregation function h (e.g., sum , max , avg ) over the object-attribute scores: We can formalize the top-k retrieval problem as follows: P ROBLEM 1. Given a query Q = { t 1 ,...,t n } X  X  , a context C , an integer k , and a score model specification ( sc,h ) , retrieve the k objects o  X  X  having the highest scores sc ( o,Q |C ) .

In certain applications, the context may always be empty or may simply be ignored in the sc scores, and, when necessary, we indicate this in our notation by the  X   X   X  context. We use sc ( o,Q ) as short notation for sc ( o,Q | X  ) .

We revisit in this paper the class of early termination top-k algo-rithms known as threshold algorithms . These algorithms, applicable in a context-agnostic setting, find the top-k objects for an input query Q by scanning sequentially (for each attribute) and in parallel (for the attribute set of Q ), relevant per-attribute lists that are or-dered descending by sc values  X  with inverted lists being a notable example  X  denoted in the following L ( t ) , as the list for attribute t . During a run, they maintain a set D of already encountered candi-date objects o , bookkeeping for each candidate (i) an upper-bound on sc ( o,Q )  X  the best possible score that may still be obtained for o  X  denoted hereafter bsc ( o,Q ) , and (ii) a lower-bound on sc ( o,Q )  X  the worst possible score  X  denoted hereafter wsc ( o,Q ) . The objects are ordered in D by their worst scores. hereafter ws ( o,Q ) .
At each iteration, or at certain intervals, threshold algorithms may refine these bounds and compare the worst score of the k th object in D , wsc ( D [ k ] ,Q ) , with the best possible score of either (i) objects o in D outside the top k , bsc ( o,Q ) , or (ii) not yet encountered objects, denoted bsc (  X  ,Q ) . When both these best scores are not greater than the worst score of D [ k ] , the run can terminate, outputting D [1] ,...,D [ k ] as the final top-k .

Views and precomputed results . We extend the classic top-k retrieval setting of TA/NRA by assuming access to precomputed query results, called in the following views . Each view V is assumed to have two components: (i) a definition , def ( V ) , which is a pair query-context def ( V ) = ( Q V , C V ) and (ii) a set ans ( V ) of triples ( o ,wsc i ,bsc i ) , representing the answer to query Q V under context C . Each such triple says that object o i has a score sc ( o within the range [ wsc i ,bsc i ] .

Since we are dealing with cached query results, all objects not appearing in ans ( V )  X  represented explicitly in ans ( V ) , to simplify presentation, by one final wildcard  X  object  X  have with respect to query Q V and context C V a worst score of wsc  X  = 0 and a best possible score of either bsc  X  = min { bsc i | ( o i ans ( V ) } , if V  X  X  result is complete, in the sense that enough objects had a non-zero score w.r.t. Q V , or otherwise 0 .

Context transposition. Intuitively, when a view V and the to-be-answered query Q do not have the same context, a transposition of the exact scores or score ranges in ans ( V ) is needed, to obtain valid ranges for sc ( o i ,Q V |C ) from those for sc ( o particular, in the case of spatial or social search, this transformation will inevitably yield a coarser score range. We detail the specific transposition operation for these application scenarios in Sec. 7.
Exploiting views. Given an input query Q and a context C , from a set of views V sharing the same context  X  as in def ( V ) = ( ..., C )  X  a first opportunity that is raised by the ability to cache results is to compute for objects o  X  X  tighter lower and upper bounds over sc ( o,Q |C )) . This may be useful in threshold algorithms, as a way to refine score ranges. We formalize this task next.
 P ROBLEM 2. Given a query Q = { t 1 ,...,t n } X  X  , a context C , an integer k , a score model specification ( sc,h ) and a set of views V sharing the same context with Q , given an object o  X  O , compute the tightest lower and upper bounds on sc ( o,Q |C ) from the information in V .
 In this paper, consistent with the most common ranking models and related work on view-based top-k answering [6, 11], we assume that the aggregation h is summation. Consequently, Problem 2 can be modeled by the following linear program (LP), whose variables are given in bold, knowing that sc ( o , t l |C )  X  0 ,  X  t l
E XAMPLE 1. Let us consider the views in Table 1, for the location-aware search scenario discussed previously, after context transpo-sition. We have access to the transposed results of the three views, text is now the same for all views and the query Q = { t 1 ,t 2 } . Considering o 4 , for example, we know that:
Then, the lower bound on sc ( o 4 ,Q ) is obtained as by combining the worst scores in v 2 and v 3 . Similarly, combining the best scores of V 2 , V 3 , sc ( o 4 ,Q )  X  X  upper-bound is We now formulate the problem of answering input top-k queries Q using only the information in views, whose semantics needs to be adapted to the fact that views may offer only a partial image of the data. When an exact top-k cannot be extracted with full confidence, a most informative result would consist of two disjunctive, possibly-empty sets of objects from those appearing in V  X  X  answer: (i) a set of all the objects guaranteed to be in Q  X  X  top-k , and (ii) a set of all objects that may also be in Q  X  X  top-k .

Problem 2 gives a way to properly define and identify objects of the former kind  X  the guaranteed ones  X  as the objects o x and at most k  X  1 objects o y can be found such that
Similarly, we can identify objects of the latter kind  X  the possible ones  X  as the objects o x that are not guaranteed and for which at most k  X  1 objects o y can be found s.t. We now formalize the top-k retrieval problem using views .
P ROBLEM 3. Given a query Q = { t 1 ,...,t n } X  X  , a context C , an integer k , and a score model specification ( sc,h ) , given a set of views V having the same context as Q , retrieve from V a most informative answer of the form ( G,P ) , with
In order to solve Problem 3, a na X ve computation of upper and lower bounds for all objects o appearing in the views would suffice, but would undoubtedly be too costly in practice. Instead, we show in Section 4 how we can solve Problem 3 in the style of threshold algorithms, by extending TA.

Over any data instance, the exact top-k can be seen as the set G plus the top-k 0 items from P , for k 0 = k  X  X  G | . To give a most likely result , in a probabilistic sense, based on the object sets G and P , we discuss in Sec. 4 possible approaches for estimating the probability of possible top-k 0 sets from P .

Going further, even when the most promising candidate objects are considered first in SR-TA, their corresponding instances of the linear programs in Eq. (3.1) and Eq. (3.2) may still be too expensive to compute in practice (even when we are dealing with LPs, as in Example 1): the set of views may be too large  X  of the order 2  X  and each view contributes one constraint in the program. In our best-effort approach, which would first select some most promising views  X  V  X  V for the input query (Section 5), we face a trade-off between the size of the subset  X  V  X  which determines the cost of SR-TA  X  and the  X  X uality X  of the result, namely its distance with respect to the most informative answer given by all the views. We quantify the distance between the most informative result by denoted (  X  G,  X  P ) , and the most informative answer ( G,P ) by V as the difference in the number of possible top-k combinations: We also show in Section 5 how a final refinement step over ( based on random accesses in the entire V set, allows us to reach  X  = 0 , i.e., the most informative result by V . We present in this section an adaptation of TA, called SR-TA. It can be applied when the input lists consist of objects with score ranges; SR-TA allows us to solve Problem 3.

Each of the input lists are assumed to be available in two copies, ordered descending by (i) the score lower-bound, and (ii) the score upper-bound. SR-TA will read sequentially in round-robin manner from the former group of lists and, similar to TA, maintains a candidate set D of the objects encountered during the run. At each moment, the read heads of the latter group of lists must give objects that are not yet in D (unseen objects), and sequential accesses are done in SR-TA whenever necessary to maintain this configuration.
D is also ordered descending by score lower-bounds. SR-TA stops when the score of any unseen object  X  threshold  X   X  cannot be greater than the one of the k th object in D .

In our setting,  X  is the solution to the mathematical program (MP) below, under sc ( o , t l |C )  X  0 ,  X  t l  X  X  , taking into account from each view V the score upper-bound of objects in ans ( V )  X  D :
One can note that when (i) we have only views that give answers to singleton queries, and (ii) wsc i = bsc i for each object o lists contain exact scores), we are in the setting of the TA family of algorithms over inverted list inputs. Relaxing condition (i), we have the setting of top-k answering using views investigated in [11, 6]. Both these settings and their corresponding algorithms can guarantee that, at termination, the exact top-k is returned. Our more general setting, however, cannot provide such guarantees, as witnessed by the following example.

E XAMPLE 2. Let us revisit Example 1, for the top-2 query Q = { t 1 ,t 2 } . We will not detail the complete run of the algorithm on this example, instead showing what happens at termination. The algorithm stops at the 5 th iteration, at depth 2 in the input lists. The threshold value  X  = 0 . 849 is obtained by combining the best score in v 3 of the not-yet-candidate (not in D ) item o 1 with the score of the wildcard object  X  in v 2 . The worst score of the 2nd item, o 4 , is 1 . 042 , hence larger than the threshold, enabling termination. This ensures that all the possible candidates for top-k are already present in the list D , as shown below: Yet, within this candidate list, there is no combination of 2 objects that represents the top-k . Instead, we can only divide D into 3 sets: 1. a set G = { o 4 } of guaranteed result objects, 2. a set P = { o 2 ,o 5 } of possible result objects, 3. a set of the remaining object: { o 3 } .

Algorithm 1 details SR-TA. Its general flow is similar to the one of TA, with the notable addition of the generalized computation of bounds and of the threshold value.
 Algorithm 1: SR-TA ( Q,k, V ) 1: D =  X  2: loop 3: for each view V  X  X  in turn do 5: read by random-accesses all other lists V 0  X  X  for tuples 6: wsc  X  solution to the MP in Eq. (3.1) for o i 7: bsc  X  solution to the MP in Eq. (3.2) for o i 9: end for 10:  X   X  the solution to the MP in Eq. (4.1) 13: end loop 15: return G , P
Partition for most informative result. Once SR-TA X  X  main loop terminates, candidates D are passed as input to a sub-routine whose role is to partition it into sets G and P (line 14 in SR-TA). Algorithm 2 details this step: for each object o in D we test the conditions of Eq. (3.3), (3.4), (3.5).
 Algorithm 2: P ARTITION ( D,k ) 1: G  X  X  X  the objects guaranteed to be in the top-k 2: P  X  X  X  the objects that might enter the top-k 7: add o to G 8: else if bsc &gt; wsc t then add o to P 9: end if 10: end for 11: return G , P
At the termination of SR-TA, we are guaranteed that G and P are sound and complete , in the following sense:
P ROPERTY 1. An object o is in the output set G of P ARTITION k ) iff, in all possible data instances, o is the top-k for Q and C .
An object o is in the output set P of P ARTITION ( D,k ) iff, in at least one possible data instance, o is in the top-k for Q and C .
Note G  X  X  size is at most k , while P  X  X  size is at most |O| , hence the need for completeness (maximal G , minimal P ).
 the actual (inaccessible) top-k answer for the input query can also be seen as being composed of two parts: the guaranteed objects G plus a top-k 0 over P , for k 0 = k  X  X  G | . By definition, G and P represent the most informative certain result obtainable from the views: there can be no deterministic way to compute a certain top-k 0 objects, nor a way to further prune the search space towards a more refined P set.

Therefore, we can only hope to improve the quality of the result by a more detailed probabilistic description of it, in which a most likely top-k could be identified from G and P . Since for each object in P we have a lower and upper bound on its exact score, let us assume a known probability-density function (e.g, uniform one) for scores within the known bounds. Based on this, we can reason about the likelihood of a top-k 0 selection over P .

A na X ve way to obtain the most likely top-k 0 would be the follow-ing: enumerate all subsets of P of size k 0 , and compute for each the probability of being the top-k 0 . Each of these | P | values can be easily obtained once we have for each pair of objects o ,o 2  X  P the probability Pr ( o 1 &gt; o 2 ) .

Much more efficient than the na X ve enumeration is to adapt to our setting the sampling-based approach of [17] (for top-k answers on object lists with score ranges having probability-density functions), and we will use this approach in our implementation of the sampling algorithms.
We consider now the view selection problem, which may improve the performance of our threshold algorithm SR-TA, possibly at the risk of yielding results that are less accurate. To address this issue, we discuss at the end of this section how results obtained through view selection can be refined to the most informative one. Throughout this section, we remain in the setting where the query and views are assumed to have the same context.

We argue first that view selection comes as a natural perspective in the computation of score bounds. Recall that, for a given object o  X  O , Problem 2 can be modeled by the linear programs (3.1) and (3.2). Put otherwise, we have as dual of the minimization problem (3.1) the following packing LP: and we have as the dual the maximization problem (3.2) the follow-ing covering LP:
Based on the LPs (5.1), (5.2), for each object o , to obtain its most refined bounds, we would need to first fractionally select views from V  X  as opposed to integral selection  X  s.t. the linear combinations of o  X  X  scores with the coefficients u i and l i are optimal. In other words, for computing the worst or best score of each object, it would suffice to select and take into account only the views V i  X  X  such that (i) l 6 = 0 , for worst scores, or (ii) u i 6 = 0 , for best scores. E XAMPLE 3. Let us consider the views in Table 1, using the LPs (5.1) and (5.2) to illustrate view selection for object o 2 . For the worst score, we need to optimize
The optimal value is reached when l 1 = 0 and l 2 = l 3 = 1 , i.e., relying on the worst scores of o 2 from views v 2 and v 3 .
For the best score, we need to optimize
The optimal value is reached when l 1 = 1 and l 2 = l 3 = 0 , i.e., relying on the best score of o 2 from view v 1 .

Solving the LPs (5.1) and (5.2) for each object, as a means to se-lect only the useful views, would obviously be as expensive as solv-ing directly the LPs (3.1) and (3.2). Instead, it would be preferable to solve these LPs and select some most relevant views independently of any object , i.e., only once, before the run of the threshold algo-rithm. Instead of per-object wsc and bsc values, in an approximate version of the two LPs, each view V i could be represented by two unique values, wsc ( V ) and bsc ( V ) . Our optimization problems would then simplify as follows: and this would enable us to select the  X  X ood X  views in the ini-tialization step of the top-k algorithm, those participating to the computation of the optimal, i.e., views having non-zero u and l coefficients.

Moreover, for each object o encountered in SR-TA X  X  run, we can now replace Eq. (3.1) and (3.2) (lines 5-6 in SR-TA) by the following estimates using only the selected views e V :
This is possible since, by the duality property, we are guaranteed that the feasible solutions represent safe bounds for o  X  X  scores, i.e., g wsc  X  wsc and f bsc  X  bsc . We can similarly simplify Eq. (4.1), for the threshold value (for line 8 in SR-TA).

Candidates for wsc ( V ) and bsc ( V ) . We follow the described approach  X  approximating view selection  X  in two distinct ways. First, per-view score bounds wsc ( V ) and bsc ( V ) could be based solely on the view X  X  definition Q V , and we experimented in this paper with bounds that are defined as wsc ( V ) = bsc ( V ) = | Q for each V  X  X  . The intuition for this choice is that object scores in a view V are proportional to the number of attributes in Q Second, we consider (and experiment with in Section 8) two natural per-view measures that are based on the views X  answers: (i) the average score value, and (ii) the maximum score value.
 Retrieving ( G,P ) after view selection. We now discuss how the most informative result ( G,P )  X  obtainable from the complete set of views V  X  can still be retrieved by refining a result ( obtained on a selection of views  X  V . For that, we need to adopt the following modifications in instances of SR-TA running over a selection of views: when the main loop terminates, compute the optimal bounds for all objects in  X  P by random-accessing their scores in all the views in V , then run for a second time the partition subroutine.

It can be easily shown that, in this way, we obtain the most informative result, i.e., we reach  X  = 0 . Therefore, the  X  X ulk X  of the work could be done only on a selection of views and its result, potentially few candidate objects, could just be refined at the end using the complete V . We describe in Section 8 the impact of this optimization on the running time of SR-TA.
 In summary, we described two sound and complete variants of SR-TA: without view selection (SR-TA nosel ), and with view selection (SR-TA sel ). For view selection variants, our notation convention will be to replace the sel superscript by a def , max or avg one, depending on the selection method being used.
Let A be the class of algorithms, including SR-TA , that deter-ministically output the exact sets P and G , without making  X  X ild guesses X . 1 For a given set of views V , we denote by D ( V ) the class of all instances of answers in those views, i.e., ans ( V ) ,V  X  X  .
Given two algorithms A 1  X  A and A 2  X  A , we write A 1 A iff, for all sets of views V , A 2 is guaranteed to cost at least as much as A 1  X  in terms of I/O accesses (sequential, random or a linear combination of the two)  X  over all instances in D ( V ) . Conversely, we write A 1 6 A 2 iff there exists at least one view set V and an instance in D ( V ) over which A 2 costs less than A 1 . We say that an algorithm A  X  A is instance optimal over A iff A B,  X  B  X  A .
We first consider the question whether one of the two variants of SR-TA is guaranteed to perform better that the other, for all views and answers. The answer to this question is far from obvious: on one hand, SR-TA sel should use fewer views to compute the P and G sets, but it might either go too deep in the selected views or might need additional accesses in other views (see Section 5); on the other hand, SR-TA nosel may go through views that are useless for deriving optimal bounds.

Lemma 1 tells us that neither of the two variants of SR-TA can be instance optimal for all possible sets V . However, we describe next a restricted class of views for which: (i) no refinement step is necessary after selecting a subset of the views, and (ii) SR-TA becomes instance optimal. Let V be the class of sets V of pairwise disjoint views , i.e., s.t. Q V i  X  Q V j =  X  ,  X  V i ,V j We say an algorithm A  X  A is instance optimal over A and V if A B,  X  B  X  A and  X V  X  V .
 T HEOREM 1. SR-TA sel is instance optimal for A and V .

Intuitively, for this class of views, the only way to obtain bounds for a query Q is the following: (i) for lower-bounds, only the views V that have Q V  X  Q are taken into account, while (ii) for upper-bounds all views V that verify Q V  X  Q 6 =  X  are used. Note that this method is in effect the view selection algorithm for the class of pairwise disjoint views. Moreover, for this class of views, the nosel variant will use the same set of views as the sel variants. Hence the final refinement step is no longer needed, as there are no other relevant views which can refine the result ( P,G ) . Note also that the classic setting of [7], i.e. per-attribute lists of exact scores, is strictly subsumed by V . We discussed so far how queries can be answered using pre-computed views, with the important assumption that these share the same context with the input query. We remove now this restriction, con-sidering also views that may have been computed in a different context. We show how we can still answer queries by the techniques discussed so far, by pre-processing views in order to place them in the context of the input query, by what we call context transposition .
We give in this section the details on context transpositions for our two motivating application scenarios: location-aware search and social-aware search. In both applications, one view V  X  X  context C can be seen as consisting of 1. a location (or start point ) C V .l , e.g., geo-coordinates in a mul-
These algorithms do not include in their working buffers (e.g., candidate buffer D ) items that were not yet encountered in the input lists (they cannot guess that an item might be encountered later). 2. a contextual parameter C V . X  , which parameterizes the influ-
Given an input query Q , a context C  X  with C .l and C . X   X  and a view V with a different context (either the location or  X  may differ, or both), in order to be able to use pre-computed results from V , we need to derive from the existing ans ( V ) tuples new score bounds: for each ( o,wsc,bsc )  X  ans ( V ) we want to obtain a new tuple ( o,f w ( wsc ) ,f b ( bsc )) . The functions f w and f b of the context transposition, their role being to map the worst scores and best scores of objects from ans ( V ) to new guaranteed bounds for context C . We detail them next for our application scenarios.
In location-aware or spatial top-k querying [5], a user having a certain location is interested in the top-k objects that are relevant textually and close spatially.

We revisit here one of the most common ranking models [5, 2], in which the per-attribute score objects are a linear combination of spatial relevance and textual relevance. Each object o consists of a bag of attributes o.A and a location o.l . Given an input query Q , with context C having location and C .l and parameter C . X  , the per-attribute score is obtained as follows: where D gives the euclidean distance between Q  X  X  location (start point) and o  X  X  location, maxDist is the maximal distance, TF ( t, o.A ) is the term frequency of t in o.A , and maxTF ( t ) is a maximal term frequency of t over all objects.

Transposing the location. Given a query Q of context C , with location C .l , given of view V of context C V , with location C any object o  X  ans ( V ) , there are two extreme locations at which o can be situated, relative to C .l (see Figure 2, left), as follows: 1. on the line connecting C .l and C V .l , between them or beyond 2. on a line connecting C .l and C V .l , beyond C V .l , giving
We can now derive the following new bounds for each object o from a tuple ( o,wsc,bsc )  X  ans ( V ) , which would be valid in a context C 0 defined by the query X  X  location C .l and the view X  X  C
Transposing the parameter  X  . We consider now the transposi-tion for the  X  component, from C V . X  to C . X  , by which are obtained valid bounds for the input query context C . For space reasons, the detailed steps of this computation are omitted and we give here directly the transposition formulas.
E XAMPLE 4. Returning to the example in Motivation 1, we detail how the bounds are computed. Recall C = ( l = Q, X  = 0 . 3) . From v 3 , with context C v 3 = ( l = v 3 , X  = 0 . 3) , knowing that maxDist = 0 . 25 , we obtain the following bounds for the object o 4 , which had an initial score of 0 . 962 :
We consider now the social-aware setting, and we revisit the ranking model developed in [16, 1]. Besides objects and attributes, we have a set of users U = { u 1 ,...,u n } who can bookmark (or tag) objects with attributes (tags). Also, users form a social network, seen as an undirected weighted graph: a link between two users u 1 , u 2 has a weight,  X  ( u 1 ,u 2 )  X  [0 , 1] , which could stand for proximity, similarity, etc. For pairs of users for which an explicit edge (and proximity) is not given, an extended proximity  X  ( u 1 ,u 2 )  X  [0 , 1] can be computed in the graph by aggregating (e.g., by multiplication) the weights over each path connecting u and u 2 , and taking the maximal aggregated score over all paths (this is reminiscent of how trust or similarity propagate, if interpreted as transitive measures):
A query context C consists now of a seeker C .l (the issuer of the query) and the parameter C . X  . In manner similar to location-aware search, the per-attribute score is a linear combination between the  X  X ocial location X  of the seeker with respect to the taggers of an object and the classic textual score (e.g., tf/idf or BM25).

The social component of the score is computed as the sum of the proximity values of taggers of o with respect to the seeker, while the textual one is the number of taggers who tagged o with t : Transposing the location. For a query Q and seekers C V .l and C .l , let u be a tagger for whom we need to use  X  + ( C .l,u ) in score bounds. As shown in Figure 2 right, the path with the highest score connecting C .l to u may either 1. go through C V .l , and in that case we have: 2. not go through C V .l , and in that case we have:
Now, the influence of the social component in the score of o in ans ( V ) varies inversely with C V . X  . Therefore, the transposition that accounts for the location change should be weighted by its importance in the sc ( o,t | C V ) formula, determined by C follows: when C V . X  = 1 , the lower and upper bounds should not be affected by the location change, while when C V . X  = 0 , they should be affected with weight  X  + ( C .l, C V .l ) and  X  respectively. We can model this by a coefficient function c ( w, X  ) , which applies to a weight w and value  X  : c ( w, X  ) =  X  (1  X  w ) + w .
For each object o of tuples ( o,wsc,bsc )  X  ans ( V ) , we can now derive the following valid bounds for a context C 0 defined by the query X  X  seeker C .l and the view X  X  parameter C V . X  .
Transposing the parameter  X  . We consider now the transposi-tion for the  X  component, from C V . X  to C . X  , yielding valid bounds for the new context, C . Here, the transposition depends on the re-lationship between C . X  and C V . X  , and we obtain the following f and f b (for space reasons the detailed description is omitted):
E XAMPLE 5. Revisiting Motivation 2, recall C = ( l = s, X  = 0) . From v 1 , of context C v 1 = ( l = v 1 , X  = 0) , having  X  0 . 9 , we know that c (  X  + ( s,v 1) , 0) =  X  + ( s,v 1) = 0 . 9 . So no transposition of  X  is needed, as C . X  = C v 1 . X  = 0 . We obtain the following bounds for o 2 , which had an initial score of 1 . 35 :
We performed our experiments on a single core of a i7-860 2.8GHz machine equipped with 8GB of RAM. We implemented our algorithms in Java, and we used this implementation for our tests on synthetic data and social data. We also implemented them in C++, for a more reliable comparison with IR-T REE , for spatial data.
Context-agnostic setting with complete views. Our first series of tests, over synthetic data, concerns a setting in which the input queries and the views share the same context (i.e., context plays no role and is ignored in the computation). We generated exact scores in the range [0 , 100] for 100,000 objects and 10 attributes, with exponential or uniform distributions. Then, we generated all possible combinations of 2 or 3 attributes, each representing one view. For each of the views, we computed the exact (aggregated) scores over all objects; the views are complete in that sense. We then made these lists uncertain by replacing each exact value by a score range, using a gaussian distribution with mean equal to the exact value and standard deviation (std, in short) equal to either 5 , 10 or 20 . the sets of views we obtained, we used 100 randomly-generated input queries consisting of 5 distinct attributes.

We compare in Fig. 3 the SR-TA variants over the two data distributions, for the std values 5 and 10 (to avoid clutter, plots for std 20 are not given). included. We have recorded (i) the relative running-time of the algorithms that use view selection w.r.t. the algorithm using all the views  X  3 selection criteria per 2 std values, for 6 plot lines, (ii) the number of sequential accesses by all 4 variants  X  with the 2 std values, for 8 plot lines, and (iii) the number of random accesses by all 4 variants  X  with the 2 std values, for 8 plot lines.

One can note that the algorithms with view selection achieve significant savings in terms of both running-time and I/O accesses. The algorithm based on max-statistics, SR-TA max , achieves better performance than the one based on view definitions, SR-TA which in turn does better than the one based on average-statistics, SR-TA avg . definitions of the views. Moreover, note that the relative running-time of these algorithms does not depend on the value of k , and the influence of the interval coarseness (by standard deviation) is more important in the exponential distribution. One can also note a  X  X lustering X  effect, by standard deviation, in the case of sequential-access measures; this is likely due to the fact that top-k processing on noisier data needs to go deeper in the views to reach termination.
We also compared the performance of SR-TA sel variants, over score ranges with low noise (std of 5 ), with the one of Fagin X  X  TA over the exact per-attribute inverted lists. We trace two measures: the relative running-time and the minimum precision. (We do not evaluate using NDCG-like measures because the top-k sets we are returning are unranked, for both the sel and nosel variants. Our goal is to return as many of the G objects as possible, and hence precision is the best measure for our purposes.) The latter is computed as | G | /k , i.e., the ratio between the size of the guaranteed set and the required k . The results are presented in Table 2. One can note that Figure 3: Performance comparison for SR-TA variants over synthetic SR-TA sel can have a running-time that is a low fraction of the one of TA (as low as 0 . 296 , with a precision@10 of 0 . 577 ). This is mainly due to the fact that, although inexact, we have aggregated scores pertaining to 2 or 3 query terms, while the noise levels are rather low. While using exact lists of aggregated data for top-k processing would certainly improve efficiency, as shown in [11], our experiments show that even relatively noisy aggregated data can lead to improvements, with reasonable precision.

We give in Table 3 the overhead of the refinement step discussed in Section 5, which uses random-accessing to refine a result ( to the most informative one, ( G , P ). This overhead is measured as the ratio between the running-time of the base algorithm and the one of the refined algorithm. We also report on the  X  measure. Note that, while the number of possible combinations that are  X  X voided X  increases exponentially with the standard deviation, the overhead of additional I/O accesses is small (range 3% -13% ).
 Table 2: Comparison between the SR-TA sel variants and TA (exact scores), for uniform and exponential distributions, for std 5 .
 T able 3: Running-time overhead and  X  , for SR-TA sel with or without the final refinement, for k =100, exponential distribu-tion.
 Location-awar e search. We used in this setting the same Poly-Bot dataset as before, taking into account for each object its 2D coor-dinates. We generated 20 views defined by 2 -term queries at 5 loca-tions, varying the size of their ans lists ( 500 , 1000 and 2000 entries). We used 10 to-be-answered queries at 5 locations (different to the ones of views) and we varied k  X  X  10 , 20 } and  X   X  X  0 . 7 , 0 . 8 , 0 . 9 } (values which are close to those employed in [5]).

The algorithm we use as the baseline in our evaluation is our implementation of the IR-TREE of [5]. It is based on R-tree in-dices [8], whose nodes are enriched with inverted lists consisting of the documents located inside the rectangle defined by the node.
We present in Figure 4 the results for relative running-time and precision. The relative running-time is computed as the ratio be-tween the running-time of SR-TA and the one of IR-TREE . Pre-cision is computed as the percentage of top-k items returned by SR-TA that also appear in the output of IR-TREE . Here, we used the sampling method from Section 4 to obtain the most likely top-k from the ( G , P ) answer, through 1,000 rounds of uniform sampling.
One can note that, for high values of  X  and low values of k , the response time of SR-TA is significantly lower than that of the IR-TREE (in practice, of the order of milliseconds), with reasonably high precision levels (between 0 . 86 and 0 . 92 ). This is because the top-k answer is based on a large set G of guaranteed objects, which reduces the overhead of the sampling procedure. When the uncertainty introduced by coarser score ranges in views leads to larger sets P instead, the sampling procedure is more costly, but overall the running-time remains a small fraction of the one of the IR-TREE , with a precision around 0 . 8 .

Social-aware search. For this application, we used the exist-ing Delicious tagging data of [18]. We selected a random subset, containing 80,000 users, their tagging on 595,811 objects (items) with 198,080 attributes (tags). For assigning weights to links be-tween users, we generated three similarity networks, by computing the Dice coefficients of either (i) common tags in a tag similarity network, (ii) common items in an item similarity network, or (iii) common item-tag pairs in an item-tag similarity network.

For each of the three similarity networks, we randomly chose 5 seekers for our tests. Then, a number of 10 users were randomly chosen, among those having a link with weight of at most 0 . 66 to any of the 5 seekers (to ensure that no view is too  X  X seful X , having too strong an influence on the running-time and precision). For each of these users and for  X   X  { 0 . 0 , 0 . 1 , 0 . 2 , 0 . 3 } , we generated 40 views of 1 and 2 -tag queries, each containing 500 entries.
We tested on a set of ten 3 -tag queries for each of the 5 seekers, varying  X   X  X  0 . 0 , 0 . 1 , 0 . 2 , 0 . 3 } and k  X  X  10 , 20 } .
The baseline algorithm we used for the performance comparison is a direct adaptation of the C ONTEXT M ERGE algorithm of [16]. Depending on the value of  X  , C ONTEXT M ERGE alternates between Figur e 4: Location-aware search: performance &amp; precision of SR-TA sel vs. exact early-termination algorithm (IR-TREE [5]), for various  X  values and list sizes (grey=top-10, white=top-20). Figur e 5: Social-aware search: performance &amp; precision of SR-TA sel vs. exact early-termination algorithm (C ONTEXT M ERGE per-attribute inverted lists of objects and an inverted list containing users ordered descending by their proximity relative to the seeker.
Similar to the location-aware search, we present in Figure 5 the results in terms of relative running-time and precision. One can note that the running-time is still a low fraction of the one of the exact algorithm, while the precision levels are considerably higher than in the case of location-aware search. As expected, the lowest precision levels are obtained when the search relies exclusively on the social component of the score. This is due to the fact that the bounds com-puted by Eq. (7.5) yield coarser score ranges when  X  = 0 , which are source of more uncertainty in the scores and the top-k result. Moreover, due to the skew in proximity values in the network, even when  X  has low non-zero values, the textual component has a strong influence in scores, and thus leads to significant improvements in the top-k estimates (the most likely result).
We formalize and study in this paper the problem of context-aware top-k processing based on uncertain precomputed results, in the form of views over the data. This problem is motivated by search applications in which query results depend on a context, and any result caching or pre-computation mechanism needs to perform certain transformations  X  what we call a context transposition  X  in order to answer new queries, which may pertain to new contexts.
We introduce the query semantics needed for dealing with objects of uncertain scores and describe an algorithm, SR-TA that outputs what we call the most informative result . We also consider optimiza-tions based on selecting some (few) most promising views, instead of using the entire set of views.
 Acknowledgments . This work was partially supported by the EU project ARCOMEM FP7-ICT-270239.
