 Percy Liang pliang@cs.berkeley.edu Michael I. Jordan jordan@cs.berkeley.edu Probabilistic models play a prominent role in domains such as natural language processing, bioinformatics, and computer vision, where they provide methods for jointly reasoning about many interdependent vari-ables. For prediction tasks, one generally models a conditional distribution over outputs given an input. There can be reasons, however, for pursuing alterna-tives to conditional modeling. First, we might be able to leverage additional statistical strength present in the input by using generative methods rather than dis-criminative ones. Second, the exact inference required for a full conditional likelihood could be intractable; in this case, one might turn to computationally more efficient alternatives such as pseudolikelihood (Besag, 1975).
 The generative-discriminative distinction has received much attention in machine learning. The standing in-tuition is that while discriminative methods achieve lower asymptotic error, generative methods might be better when training data are limited. This intuition is supported by the theoretical comparison of Naive Bayes and logistic regression (Ng &amp; Jordan, 2002) and the recent empirical success of hybrid methods (Mc-Callum et al., 2006; Lasserre et al., 2006).
 Computational concerns have also spurred the devel-opment of alternatives to the full likelihood; these methods can be seen as optimizing an alternate objective or performing approximate inference dur-ing optimization. Examples include pseudolikelihood (Besag, 1975), composite likelihood (Lindsay, 1988), tree-reweighted belief propagation (Wainwright et al., 2003), piecewise training (Sutton &amp; McCallum, 2005), agreement-based learning (Liang et al., 2008), and many others (Varin, 2008).
 We can think of all these schemes as simply different estimators operating in a single model family. In this work, we analyze the statistical properties of a class of convex composite likelihood estimators for exponential families, which contains the generative, discriminative, and pseudolikelihood estimators as special cases. The main focus of our analysis is on prediction error. Standard tools from learning theory based on uniform convergence typically only provide upper bounds on this quantity. Moreover, they generally express esti-mation error in terms of the overall complexity of the model family. 1 In our case, since all estimators operate in the same model family, these tools are inadequate for comparing different estimators.
 Instead, we turn to asymptotic analysis, a mainstay of theoretical statistics. There is much relevant sta-tistical work on the estimators that we treat; note in particular that Lindsay (1988) used asymptotic argu-ments to show that composite likelihoods are generally less efficient than the joint likelihood. The majority of these results are, however, focused on parameter esti-mation. In the current paper, our focus is on predic-tion, and we also consider model misspecification. We draw two main conclusions from our analysis: First, when the model is well-specified, conditioning on fewer variables increases statistical efficiency; this to some extent accounts for the better generalization enjoyed by generative estimators and the worse perfor-mance of pseudolikelihood estimators. Second, model misspecification can severely increase both the approx-imation and estimation errors of generative estimators. We confirm our theoretical results by comparing our three estimators on a toy example to verify the asymp-totics and on a Markov model for part-of-speech tag-ging. In structured prediction tasks, we are interested in learning a mapping from an input space X to an out-put space Y . Probabilistic modeling is a common plat-form for solving such tasks, allowing for the natural handling of missing data and the incorporation of la-tent variables.
 In this paper, we focus on regular exponential families, which define distributions over an outcome space Z as follows: where  X  ( z )  X  R d is a vector of sufficient statistics (features),  X   X  R d is a vector of parameters, and tion. In our case, the outcomes are input-output pairs: z = ( x,y ) and Z = X  X Y .
 Exponential families include a wide range of popular models used in machine learning. For example, for a conditional random field (CRF) (Lafferty et al., 2001) defined on a graph G = ( V,E ), we have an output vari-able for each node ( y = { y i } i  X  V ), and the features are From the density p  X  ( z ), we can compute event proba-bilities as follows: tional log-partition function. 2.1. Composite Likelihood Estimators In this paper, we consider a class of composite likeli-hood estimators (Lindsay, 1988), which is incidentally equivalent to the multi-conditional learning framework of McCallum et al. (2006). A composite likelihood con-sists of a weighted sum of component likelihoods, each of which is the probability of one subset of variables conditioned on another. In this work, we only consider the case where the first set is all the variables. We adopt the following more fundamental way of spec-ifying the components: Each component r is defined by a partitioning of the outcome space Z . We represent a partitioning by an associated equivalence function that maps each z  X  X  to its partition: Definition 1 (Equivalence function) . An equivalence function r is a measurable map from Z to measurable subsets of Z such that for each z  X  Z and z 0  X  r ( z ) , r ( z ) = r ( z 0 ) .
 The component likelihood associated with r takes the following form: By maximizing this quantity, we are intuitively taking probability mass away from some neighborhood r ( z ) of z and putting it on z .
 Without loss of generality, assume the component weights sum to 1, so we can think of taking an ex-pectation over a random component R drawn from some fixed distribution P r . We then define the crite-rion function : Given data points Z (1) ,...,Z ( n ) drawn i.i.d. from some true distribution p  X  (not necessarily in the ex-ponential family), the maximum composite likelihood estimator is defined by averaging the criterion function over these data points: We can now place the three estimators of interest in our framework: Generative : We have one component r g ( x,y ) = X  X  Y , which has one partition X  X he whole outcome space. Fully discriminative : We have one component r ( x,y ) = x  X Y . The outcomes in each partition have the same value of x , but different y .
 Pseudolikelihood discriminative : Assume y = { y i } i  X  V . For each i  X  V , we have a component r P r is uniform over these components.
 2.2. Prediction and Evaluation Given a parameter estimate  X   X  , we make predictions based on p  X   X  ( y | x ). In this paper, we evaluate our model according to log-loss; the risk is the expected log-loss: The quality of an estimator is determined by the gap between the risk of the estimate R (  X   X  ) and the Bayes risk R  X  = H ( Y | X ). It will be useful to relate these two via the risk of  X   X  = argmax  X  E Z  X  p  X  m  X  ( Z ), which leads to the following standard decomposition:
R (  X   X  )  X  X   X  | {z } The estimation error is due to having only finite data; the approximation error is due to the intrinsic subop-timality of the estimator. 2 We first compute the asymptotic estimation errors of composite likelihood estimators in general (Sec-tions 3.1 and 3.2). Then we use these results to com-pare the estimators of interest (Sections 3.3 and 3.4). In this paper, we assume that our exponential family is identifiable. 3 Also assume that our estimators con-verge (  X   X  P  X  X  X   X   X  ) and are consistent when the model is well-specified (if p  X  = p  X   X  , then  X   X  =  X   X  ). Note, how-ever, that in general we do not assume that our model is well-specified.
 Our asymptotic analysis is driven by Taylor expan-sions, so we need to compute a few derivatives. The derivatives of the log-partition function are moments of the sufficient statistics (a standard result, see Wain-wright and Jordan (2003)): From these moments, we can obtain the derivatives of m  X   X  and R (to simplify notation, we express these in terms of random variables whose distributions are defined in Table 1): 3.1. Asymptotics of the Parameters We first analyze how fast  X   X  converges to  X   X  by comput-ing the asymptotic distribution of  X   X   X   X   X  . In Section 3.2 we use this result to get the asymptotic distribution of the estimation error R (  X   X  )  X  X  (  X   X  ).
 The following standard lemma will prove to be very useful in our analysis: Lemma 1. For random vectors X,Y,Z , we have var( X | Z ) = E [var( X | Y,Z ) | Z ] + var[ E ( X | Y,Z ) | Z ] .
 The important implication of this lemma is that con-ditioning on another variable Y reduces the variance of X . This lemma already hints at how conditioning on more variables can lead to poorer estimators: con-ditioning reduces the variance of the data, which can make it harder to learn about the parameters.
 The following theorem gives us the asymptotic vari-ance of a general composite likelihood estimator: Theorem 1 (Asymptotic distribution of the parame-ters) . Assume  X   X  P  X  X  X   X   X  . Then The asymptotic variance is where  X  = E var(  X  m | R ( Z )) is the sensitivity, C c E var[ E (  X  m | R ( Z )) | Z ] is the component correction, and C m = E [var(  X  t | Z )  X  var(  X  m | Z )] + E [ E (  X  Z )  X  E (  X  m | Z )]  X  is the misspecification correction. Proof. The standard asymptotic normality result for M-estimators (Theorem 5.21 of van der Vaart (1998)), which includes composite likelihood estimators, gives us the asymptotic variance: The remainder of the proof simply re-expresses  X  in terms of more interpretable quantities. Algebraic ma-nipulation of (10) yields: E  X  m  X   X   X  = E [(  X   X  E (  X  t | Z )) + ( E (  X  t | Z )  X  E Note that cross terms cancel conditioned on Z and that E [  X   X  E (  X  t | Z )]  X  = E [  X  t  X  E (  X  t | Z )]  X  We then apply Lemma 1 to decompose the second term of the right-hand side: E var(  X  m | Z ) = (18) Substitute (18) into (17) to get an expression for E  X  m (11) already provides one for E  X  m  X   X  . Substitute these two expressions into (16) and simplify to get (15). The decomposition in (15) allows us to make sev-eral qualitative judgments. First, the sensitivity  X  = E var(  X  m | R ( Z )) is the expected amount of varia-tion in the features given Z and R (equivalently, given R ( Z )). The larger the sensitivity, the more the data can tell us about the parameters, and thus the lower the asymptotic variance will be.
 The component correction C c intuitively measures how different the feature expectations E (  X  m | R ( Z )) under the various components are. C c is zero for the genera-tive and fully discriminative estimators, but the pseu-dolikelihood discriminative estimator pays a penalty for having more than one component.
 The misspecification correction C m is zero when the model is well-specified (in this case,  X  m | Z d =  X  t | Z ), but is in general nonzero under model misspecification. In this latter case, one incurs a nonzero approximation error (defined in (7)) as expected, but we see that there is also a nonzero effect on estimation error. 3.2. Asymptotics of the Risk The following theorem turns Theorem 1 from a state-ment about the asymptotic distribution of the param-eters into one about the risk: Theorem 2 (Asymptotic distribution of the risk) . Let  X  be the asymptotic variance as defined in (15). De-note  X  R def =  X  R (  X   X  ) and  X  R def =  X  R (  X   X  ) . Then Furthermore, if  X  R = 0 , then where W ( V,n ) is the Wishart distribution with n de-grees of freedom.
 Proof. Perform a Taylor expansion of the risk function around  X   X  : We use a standard argument known as the delta method (van der Vaart, 1998). Multiplying (21) on both sides by Slutsky X  X  theorem, we get (19). However, when  X  R = 0, the first-order term of the expansion (21) is zero, so we must consider the second-order term to get a non-degenerate distribution. Note that  X  R is positive semidefinite. Multiplying (21) by n and rearranging yields the following: n ( R (  X   X  )  X  X  (  X   X  )) = Since  X  R 1 2 continuous mapping theorem with the outer product function yields a Wishart as the limiting distribution. Thus, n ( R (  X   X  )  X  X  (  X   X  )) is asymptotically equal in dis-tribution to 1 2 times the trace of a sample from that Wishart distribution.
 We can also understand (20) in the following way. Let V =  X  R 1 2  X   X  R 1 2 . Note that 1 2 tr W ( V, 1) tr ( V W ( I, 1)), which is the distribution of a weighted sum of independent  X  2 1 variables, where the weights are determined by the diagonal elements of V . The mean of this distribution is 1 2 tr( V ) and the variance is tr( V  X  V ), where  X  denotes elementwise product. An important question is when we obtain the ordi-nary O ( n  X  1 2 ) convergence (19) versus the much better O ( n  X  1 ) convergence (20). A sufficient condition for O ( n  X  1 ) convergence is  X  R (  X   X  ) = 0. When the model is well-specified, this is true for any consistent estimator. Even if the model is misspecified, the fully discrimi-native estimator still achieves the O ( n  X  1 ) rate. The reason is that whenever a training criterion m  X  is the same (up to constants) as the test criterion R (  X  ), vanishes and we obtain the O ( n  X  1 ) rate. This is in concordance with a related observation made by Wain-wright (2006) that it is better to use the same inference procedure at both training and test time.
 When the model is well-specified, there is another ap-pealing property that holds if the training and test criterion are the same up to constants: the asymp-totic distribution of the risk depends on only the di-mensionality of the exponential family, not the actual structure of the model. In particular, for composite likelihood estimators with one component,  X  =  X   X  1 = (  X  n ( R (  X   X  )  X  R (  X   X  )) d  X  X  X  1 2 tr W ( I d , 1) d = 1 the number of parameters. This result is essentially another way of looking at the fact that the likelihood ratio test statistic is asymptotically distributed as  X  2 3.3. Comparing Estimation Errors In the previous section, we analyzed the asymptotics of a single estimator. Now, given two estimators, we would like to be able to tell which one is better. In or-der to compare two estimators, it would be convenient if they converged to the same limit. In this section, we ensure this by assuming that the model is well-specified and that our estimators are consistent. Since all parameter estimates are used in the same way for prediction, it suffices to analyze the relative efficiencies of the parameter estimates. The following theorem says that coarser partitionings of Z generally lead to more efficient estimators: Theorem 3 (Asymptotic relative efficiency) . Let  X   X  1 and  X   X  2 be two consistent estimators with asymptotic variances  X  1 and  X  2 as defined in (15). Assume that R 1 is constant ( R 1 ( z )  X  R 2 ( z ) for all z  X  Z . If the model is well-specified, then  X  1  X  2 (  X   X  1 is no worse than  X   X  2 ). Proof. We first show that  X   X  1 1  X   X  1 2 , where  X  1 and  X  2 are the sensitivities of the two estimators. Because the model is well-specified,  X  k = E var(  X  t | R k ( Z )) for k = 1 , 2. The assumption R 1 ( Z )  X  R 2 ( Z ) means that R 2 ( Z ) provides more information about Z than R 1 ( Z ); formally, the  X  -fields satisfy  X  ( R 1 ( Z ))  X   X  ( R 2 Thus, we can use Lemma 1 to decompose the variance:  X  1 = E var(  X  t | R 2 ( Z )) + E var[ E (  X  t | R 2 ( Z )) | R The first term of the right-hand side is exactly  X  2 and the second term is positive semidefinite, so  X  1  X  2 , Let C c1 and C c2 be the component corrections of the two estimators. Note that C c1 = 0 because the R 1 is constant, so C c1 C c2 . The misspecification cor-rections are both zero. Putting these results together yields the theorem.
 One might wonder if we really need R 1 to be constant. Is it not enough to just assume that R 1 ( z )  X  R (for some coupling of R 1 and R 2 )? The answer is no, as the following counterexample shows: Counterexample Let Z = { 1 , 2 , 3 } . The general shape of the distribution is given by the single feature  X  (1) = 1 , X  (2) = 3 , X  (3) = 2 and a scalar parame-ter  X  controls the peakiness of the distribution. Let the true parameter be  X   X  = 1. Consider two esti-mators:  X   X  1 has two components, r 1 a = {{ 1 , 2 } , { 3 }} and r 1 b = {{ 1 } , { 2 , 3 }} ;  X   X  2 also has two components, r 2 a = {{ 1 , 2 } , { 3 }} and r 2 b = {{ 1 } , { 2 } , { 3 }} . Coupling r 1 a with r 2 a and r 1 b with r 2 b , we have R 1 ( z )  X  R 2 ( z ). However, we computed and found that  X  1 u 4 . 19 and  X  2 u 3 . 15, so  X   X  2 actually has lower asymptotic variance although it has finer partitionings. To explain this, note that the contribution of r 2 b the criterion function is zero, so the second estimator is equivalent to just using the single component r (= r 1 a ), so the first estimator actually suffers by us-ing the additional component r 1 b . In general, while we would still expect coarser partitionings to be bet-ter even for estimators with many components, this counterexample shows that we must exercise caution. 3.4. Comparing Estimators Finally, we use Theorem 3 to compare the estimation and approximation errors of the generative (  X   X  g ), fully discriminative (  X   X  d ), and pseudolikelihood discrimina-tive (  X   X  p ) estimators. The subscripts g , d , p will be at-tached to other variables to refer to the quantities as-sociated with the corresponding estimators. In the fol-lowing corollaries, we use the word  X  X ower X  loosely to mean  X  X o more than, X  although in general we expect the inequality to be strict.
 Corollary 1 (Generative versus fully discriminative) . (1) If the model is well-specified,  X   X  g has lower asymp-totic estimation error than  X   X  d ; both have zero approx-imation error. (2) If the model is misspecified,  X   X  d has lower approximation and asymptotic estimation errors than  X   X  g .
 Proof. For (1), since R d ( z )  X  R g ( z ), we have  X  g  X  by Theorem 3. Zero approximation error follows from consistency. For (2), since the discriminative estimator achieves the minimum risk in the model family, it has the lowest approximation error. Also, by Theorem 2 and the ensuing discussion, it always converges at a O ( n  X  1 ) rate, whereas the generative estimator will in general converge at a O ( n  X  1 2 ) rate.
 Note that there is a qualitative change of asymptotics in going from the well-specified to the misspecified sce-nario. This discontinuity demonstrates one weakness of asymptotic analyses: we would expect that for a very minor model misspecification, the generative es-timator would still dominate the discriminative esti-mator for moderate sample sizes, but even a small misspecification is magnified in the asymptotic limit. In the following toy example where the model is well-specified, we see concretely that the generative estima-tor has smaller asymptotic estimation error: Example Consider a model where x and y are bi-nary variables:  X  ( x,y ) &gt;  X  =  X  0 1 [ x = 0 ,y = 1] +  X  1 [ x = 1 ,y = 1], where the true parameters are  X   X  = (0 , 0). We can compute  X  g = var(  X  ) = 1 16 3  X  1 and  X  R (  X   X  ) =  X  d = E var(  X  | X ) = 1 16 2 0 mean asymptotic estimation error (scaled by n ) of the generative estimator is 1 2 tr( X  d  X   X  1 g ) = 3 4 while that of the discriminative estimator is 1 2 tr( X  d  X   X  1 d ) = 1. We now show that fully discriminative estimators are statistically superior to pseudolikelihood discrimina-tive estimators in all regimes, but of course pseudo-likelihood is computationally more efficient.
 Corollary 2 (Fully discriminative versus pseudolikeli-hood discriminative) . (1) If the model is well-specified,  X   X  d has lower asymptotic estimation error than have zero approximation error. (2) If the model is mis-specified,  X   X  d has lower approximation and asymptotic estimation errors than  X   X  p .
 Proof. For (1), since R p ( z )  X  R d ( z ),  X  d  X  p by The-orem 3. Zero approximation error follows from consis-tency. For (2), the same arguments as the correspond-ing part of the proof of Corollary 1 apply. In this section, we validate our theoretical analysis em-pirically. First, we evaluate the three estimators on a simple graphical model which allows us to plot the real asymptotics of the estimation error (Section 4.1). Then we show that in the non-asymptotic regime, the qualitative predictions of the asymptotic analyses are also valid (Section 4.2). 4.1. A Simple Graphical Model Consider a four-node binary-valued graphical model where z = ( x 1 ,x 2 ,y 1 ,y 2 ). The true model family p  X  is an Markov random field parametrized by  X   X  = (  X   X  , X   X  , X   X  ) as follows:  X  ( z ) &gt;  X  =  X  1 [ y 1 = y 2 ] +  X  ( 1 [ x 1 = y 1 ] + To emulate misspecification, we set  X   X  to be nonzero and force  X  = 0 during parameter estimation.
 In the first experiment, we estimated the variance (by running 10K trials) of the estimation error as we in-creased the number of data points. We set  X   X  =  X   X  = 1 for the true model. When  X   X  = 0 (the model is well-specified), Figures 1(a) X (c) show that scaling the variance by n yields a constant; this implies that all three estimators achieve O ( n  X  1 ) convergence. When the model is misspecified with  X   X  = 0 . 5 (Fig-ures 1(d) X (f)), there is a sharp difference between the rates of the generative and discriminative estima-tors. The fully discriminative estimator still enjoys the O ( n  X  1 ) convergence; scaling by n reveals that the generative and pseudolikelihood discriminative estima-tors are only attaining a O ( n  X  1 2 ) rate as predicted by Theorem 2 (Figure 1(f)). Note that the generative estimator is affected most severely.
 Figures 1(g) X (h) demonstrate the non-asymptotic im-pact of varying the parameters of the graphical model in terms of the total error. In (g), as we increase the amount of misspecification  X  , the error increases for all estimators, but most sharply for the generative es-timator. In (h), as we increase the strength of the edge potential  X  , the pseudolikelihood discriminative estimator suffers, the fully discriminative estimator is unaffected, and the generative estimator actually im-proves. 4.2. Part-of-speech Tagging In this section, we present experiments on part-of-speech (POS) tagging. In POS tagging, the input is a sequence of words x = ( x 1 ,...,x ` ) and the output is a sequence of POS tags y = ( y 1 ,...,y ` ), e.g., noun, verb, etc. (There are 45 tags total.) We consider the follow-ing model, specified by the following features (roughly 2 million total):  X  ( x,y ) = where the node features  X  node ( y i ,x i ) are a vector of indicator functions of the form 1 [ y i = a,x i = b ], and = 1 (c)  X   X  =  X   X  = 1 = 1 (f)  X   X  =  X   X  = 1 the edge features  X  edge ( y i ,y i +1 ) are a vector of indica-tor functions of the form 1 [ y i = a,y i +1 = b ]. Trained generatively, this model is essentially an HMM, but slightly more expressive. Trained (fully) discrimina-tively, this model is a CRF.
 We used the Wall Street Journal (WSJ) portion of the Penn Treebank, with sections 0 X 21 for training (38K sentences) and 22 X 24 for testing (5.5K sentences). Ta-ble 2(a) shows that the discriminative estimators per-form better than the generative one. This is not sur-prising given that the model is misspecified (language does not come from an HMM).
 To verify that the generative estimator is superior when the model is well-specified, we used the learned generative model in the previous experiment to sample 1000 synthetic training and 1000 synthetic test exam-ples. We then applied the estimators as before on this artificial data. Table 2(b) shows that the generative es-timator has an advantage over the fully discriminative estimator, and both are better than the pseudolikeli-hood estimator. We believe our analysis captures the essence of the generative-discriminative distinction: by modeling the input, we reduce the variance of the parameter esti-mates. In related work, Ng and Jordan (2002) showed that Naive Bayes requires exponentially fewer exam-ples than logistic regression to obtain the same esti-mation error. The key property needed in their proof was that the Naive Bayes estimator decouples into d independent closed form optimization problems, which does not seem to be the defining property of genera-tive estimation. In particular, this property does not apply to general globally-normalized generative mod-els, but one would still expect those models to have the advantages of being generative.
 Given that the generative and discriminative estima-tors are complementary, one natural question is how to interpolate between the two to get the benefits of both. Our framework naturally suggests two ways to go about this. First, we could vary the coarseness of the partitioning. Generative and discriminative esti-mators differ only in this coarseness and there is a range of intermediate choices corresponding to condi-tioning on more or fewer of the input variables. Sec-ond, we could take a weighted combination of esti-mators (e.g., Bouchard and Triggs (2004); McCallum et al. (2006)). For one-parameter models, Lindsay (1988) derived the optimal weighting of the component likelihoods, but unfortunately these results cannot be applied directly in practice.
 It would also be interesting to perform a similar asymptotic analysis on other estimators used in prac-tice, for example marginal likelihoods with latent vari-ables, tree-reweighted belief propagation (Wainwright et al., 2003; Wainwright, 2006), piecewise training (Sutton &amp; McCallum, 2005), etc. Another important extension is to curved exponential families, which ac-count for many of the popular generative models based on directed graphical models. We have analyzed the asymptotic distributions of com-posite likelihood estimators in the exponential family. The idea of considering different partitionings of the outcome space allows a clean and intuitive character-ization of the asymptotic variances, which enables us to compare the commonly used generative, discrimina-tive, and pseudolikelihood estimators as special cases. Our work provides new theoretical support for exist-ing intuitions and a basis for developing new estima-tors which balance the tradeoff between computational and statistical efficiency.
 Acknowledgments We thank Peter Bartlett for useful discussions and Simon Lacoste-Julien for com-ments. We also wish to acknowledge NSF grant 0509559 and a grant from Microsoft Research.

