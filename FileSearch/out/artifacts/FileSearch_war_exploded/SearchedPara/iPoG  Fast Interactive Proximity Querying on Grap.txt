 Given an author-conference graph, how do we answer proximity queries (e.g., what are the most related conferences for John Smith? ); how can we tailor the search result if the user provides additional yes/no type of feedback (e.g., what are the most related conferences for John Smith given that he does not like ICML? )? Given the po-tential computational complexity, we mainly devote ourselves to addressing the computational issues in this paper by proposing an efficient solution (referred to as iPoG-B) for bipartite graphs. Our experimental results show that the proposed fast solution (iPoG-B) achieves significant speedup, while leading to the same ranking result.
 H.2.8 [ Database Management ]: Database Applications  X  Data Mining Algorithm,experimentation proximity,scalability, graph mining
Measuring proximity (i.e., relevance/closeness) between nodes on large graphs is a very important aspect in graph mining and has many real applications in ranking, anomaly nodes indentifi-cation, connection subgraphs, pattern matching, etc. Despite the successes of much previous work, most existing proximity mea-surements only consider the link structure of the underlying graph, ignoring any possible feedback information. For example, given an author-conference bipartite graph, existing proximity measure-ments may answer the question: what are the most similar con-ferences to KDD? However, for a particular user, s/he might have Copyright 2009 ACM 978-1-60558-512-3/09/11 ... $ 5.00. her/his own preferences: I dislike ICML or I like SIGIR . These pref-erences are typically localized to a particular search, and may not reflect a global sentiment by the user.

Users X  feedback exist in a wide range of scenarios, both implic-itly or explicitly. For instance, in recommendation systems, feed-back information could be users X  ratings on items (e.g., I like Kung-Fu Panda ). In Blog analysis, it could be opinions and sentiments. Additionally, for many real applications, users X  preferences can be estimated from click-through data. That said, it is thus important to incorporate such feedback information in the proximity measure-ment so that search results are well-tailored to reflect a user X  X  in-dividual preferences. In the earlier example, the question will then become: what are the most similar conferences to KDD, but dis-similar to ICML?
In [ 16], the authors proposed an effective solution for the above problem. The basic idea of their method is to use the feedback information to bias the graph structure, based on which the prox-imity is measured. It has a wide range of applicability as shown in [ 16]. The authors in [ 16] also proposed a fast solution for uni-partite graphs and empirically de monstrated that it achieves a good balance between the on-line cost and off-line cost. However, there are several open questions that were not answered in [ 16]. For example, why should we expect the proposed technique in [ 16]to perform better than some simple heuristics (e.g., linear combina-tion)? How can we develop fast solutions for more general graphs (such as bipartite graphs)? etc.

Given the potential computational complexity, we mainly devote ourselves to addressing the computational issues in this paper by proposing an efficient solution (re ferred to as iPoG-B) for bipartite graphs. Our experimental results show that the proposed fast so-lution (iPoG-B) achieves significant speedup, while leading to the same ranking result.

The rest of the paper is organized as follows. We introduce nota-tions and formally define the problem in Section 2.Wepresentthe fast algorithms in Section 3. We provide experimental evaluations in Section 4 and review the related work in Section 5. Finally, we conclude in Section 6. Table 1 lists the main symbols that we use throughout the paper. We represent a general graph by its adjacency matrix. Following the standard notation, we use capital bold letters for matrices (e.g., A , B ... ), lower case bold letters for vectors (e.g. a ), and calli-the settings with/without feedback. For example, A is the normal-ized adjacency matrix of the graph without feedback; and  X  normalized adjacency matrix of the refined graph by feedback.
We represent the elements in a matrix using a convention similar to Matlab, e.g., A ( i, j ) is the element at the i th row and j of the matrix A ,and A (: ,j ) is the j th column of A ,etc.
We use a running example, depicted in figure 1, to describe the problem statement. There, each node represents a person (e.g., node 1 is  X  X ohn X , node 2 is  X  X mith X , etc.) and the existence of an edge represents some social contact between the two correspond-ing persons (e.g., a phone call). In t raditional settings of proximity measurements, the goal is to quantify the closeness (i.e., relevance) between two nodes (the source and the target) based on the link structure of the underl ying graph. In our settings, we assume the existence of like/dislike type of user feedback. In our running ex-ample, a user might not want to see (i.e., dislike) node 6 but favor (i.e., like) node 4.
 Formally, we represent such feedback information by two sets and N .Theset P contains the node indices that users like (referred to as the positive set), where the corresponding nodes are referred to as positive nodes. The set N contains the node indices that users dislike (referred to as the negative set), where the corresponding nodes are referred to as negative nodes. In our running example, both the positive set P and the negative set N contain one single element, respectively: P = { 4 } and N = { 6 } . Our goal is to incorporate such feedback information to measure the node prox-imity (e.g., the proximity from node 1 to node 3 in our running example).

With the above notations and assumptions in mind, our problem can be formally defined as follows: P ROBLEM 1. (Proximity Search with Feedback) Given: a weighted directed graph A , the source node s and the Find: the proximity score  X  r s,t from the source node s to the target
In Problem 1, if the target node t is absent, we measure the prox-nodes in the graph. If we stack all these scores into a column vector  X r compute the ranking vector  X r s for the source node s .Inthispa-per, we assume that there is no overlap between the positive set and negative set (i.e., P X  X  =  X  ). 1 Also, the positive and negative feedback information does not need to exist simultaneously. For example, if we only have positive feedback, we can simply set the negative set to be empty (i.e., N =  X  ).
In [ 16], the authors proposed an effective algorithm to incorpo-rate users X  feedback. The method is based on well-studied random walk with restart (RWR). Its basic idea is to leverage the feedback information to refine the original graph structure so that the ran-dom particle (1) has higher chances of visiting the positive nodes as well as their neighboring nodes, and (2) has lower chances of visiting the negative nodes as well as their neighboring nodes.
The algorithm (referred to as iPoG), which is the starting point of this paper, is summarized as Alg. 1.
 Algorithm 1 iPoG Input: The adjacency matrix A , the source node s and the target Output: the proximity score  X r s,t from the source s to the target t . 1: initialize  X  A = A 2: if n + &gt; 0 then 3:  X  A (: ,s )= n s / ( n s + n + )  X  A (: ,s ) 4: for each positive node x in P do 5:  X  A ( x, s )=  X  A ( x, s )+1 / ( n s + n + ) . 6: end for 7: end if 8: if n  X  &gt; 0 then 9: for each negative node y in N do 10: decrease the weights of the out-links of node y as well as 11: end for 12: end if 13: solve the equation  X r s = c  X  A  X r s +(1  X  c ) e s . 14: output  X r s,t =  X r s ( t ) .
If this does not hold, we can remove the intersection from both the positive set and the negative set. Algorithm 2 BB LIN (repeated from [25] for completeness) Input: The adjacency matrix B , and the query nodes i and j . Output: The ranking vector r s for node s . 1: Pre-Computate Stage(BB Lin Pre()): 2: normalize for type 1 objects: Br = D  X  1 1  X  B 3: normalize for type 2 objects: Bc = D  X  1 2  X  B 4: compute the core matrix:  X  =( I  X  c 2 Bc  X  Br )  X  1 5: store the matrices: Br , Bc ,and  X  . 6: Query Stage (BB Lin OQ()): 7: let e s =[ y 1 ; y 2 ] ,where y 1 and y 2 are n  X  1 and l 8: compute r 1 = y 1 + c 2  X  Br  X   X   X  Bc  X  y 1 + c Br  X   X   X  y 9: compute r 2 = c  X   X   X  Bc  X  y 1 +  X   X  y 2 ; 10: output r s =(1  X  c )[ r 1 ; r 2 ]
Let B be an n  X  l adjacency matrix for the bipartite graph. One important observation from many real applications is that many real bipartite graphs are often highly skewed. For example, on the entire NetFlix data set, we have about 2 . 7 M users, but only about movies. In [ 14], the authors show that for such skewed, bipartite graphs, we only need to pre-compute and store a matrix inversion of size l  X  l to get all possible proximity scores. BB LIN, which is the starting point for our fast algorithms, is summarized in Alg. 2. In Alg. 2, D 1 = diag ( d 1 (1) , ...d 1 ( n )) ,d 1 ( i )= and D 2 = diag ( d 2 (1) , ...d 2 ( l )) ,d 2 ( j )=
BasedonAlg. 2, we only need to pre-compute and store a matrix inversion  X  of size l  X  l . For skewed bipartite graphs ( l n ), much cheaper to pre-compute and store. For example, on the entire NetFlix user-movie bipartite gr aph, which contains about users, about 18 K movies and more than 100 M edges (see Section 6 for the detailed description of the data set), it takes 1.5 hours to pre-compute the 18 K  X  18 K matrix inversion  X  .Forthepre-compute stage, this is quite acceptable.

On the other hand, in the on-line query stage, we can get any proximity scores quickly. For example, to output a proximity score, we need at most two sparse matrix-vector multiplications. As an example, on the NetFlix data set, it takes less than 1 second to get one proximity score. Note that all possible proximity scores are de-termined by the matrix  X  (together with the normalized adjacency matrices Br and Bc ). We refer to the matrix  X  as the the core matrix .
As for the unipartite graphs , we cannot directly call BB Lin Pre() on the refined graph  X  A in the case where user X  X  feedback is obtained on-line. To deal with this issue, we propose iPoG-B, which is sum-marized in Alg. 3. In iPoG-B, it first calls BB LIN Pre() original adjacency matrix B (step 2). Then it calls BB LIN OQ() to determine the influence of the negative nodes (steps 4-14) and partial influence (i.e., scaling the s th column of the adjacency ma-19), both of which are used to update the core matrix  X   X  28). This way, it avoids directly calling the function BB LIN Pre() on the refined graph  X  A , where it would need to do a multiplica-tion between two big matrices and a matrix inversion of size l both of which are not efficient as on-line costs. Finally, it calls BB LIN OQ() twice (steps 29-31) and combines them as the fi-nal ranking result (step 32). Note that the second call on 31) is used to compensate for the remaining influence of the pos-itive nodes (i.e., adding new links from the source to the positive nodes).
 Algorithm 3 iPoG-B Input: The adjacency matrix B , the source node s , the feedback Output: the ranking vector  X r s for the source node s . 1: Pre-Compute Stage 2: call [ Br ,  X  , Bc ]=BB LIN Pre( B ,c ) 3: On-Line Query (Feedback) Stage 4: initialize i 0 =0 ,i 2 =0 and  X  1 = X  ,  X  2 = X  ; 5: for each negative node y in N do 6: call r y =BB Lin OQ(  X  , Br , Bc , e y ,c ) ;let := the k 7: for each node i s.t. r y,i &gt; = do 8: if i  X  n then 9: i 1 ++ ;set  X  1 ( i 1 , 1) = i ;  X  1 ( i 1 , 2) = 1  X  r 10: else 11: i 2 ++ ;set  X  2 ( i 2 , 1) = i  X  n ;  X  2 ( i 2 , 2) = 1  X  12: end if 13: end for 14: end for 15: if i  X  n then 16: i 1 ++ ;set  X  1 ( i 1 , 1) = s and  X  1 ( i 1 , 2) = n 17: else 18: i 2 ++ ;set  X  2 ( i 2 , 1) = s and  X  2 ( i 2 , 2) = n 19: end if 20: set  X  Br = Br and  X  Bc = Bc 21: set  X  Br (: ,  X  2 (: , 1)) =  X  Br (: ,  X  2 (: , 1))  X  22: set  X  Bc (: ,  X  1 (: , 1)) =  X  Bc (: ,  X  1 (: , 1))  X  23: set Y 1 =  X  Br (  X  1 (: , 1) , :) 24: compute X 1 =  X  c 2  X  Bc (: ,  X  1 (: , 1))  X  diag (1  X   X  25: compute X 2 =  X  c 2  X  Bc  X  Br (: ,  X  2 (: , 1))  X  diag 26: set Y 2 = 0 i 2  X  l ;set Y 2 ( i,  X  2 ( i, 1) = 1( i =1 27: set X =[ X 1 X 2 ] ,and Y =[ Y 1 ; Y 2 ] 28: compute L =( I  X  X X Y )  X  1 ; update  X   X  =  X  +  X YLX X  29: set e + = 0 n  X  1 , e + ( P )=1 / ( n s + n + ) 30: call  X r s =BB Lin OQ(  X   X  ,  X  Br ,  X  Bc , e s ,c ) 31: call u =BB Lin OQ(  X   X  ,  X  Br ,  X  Bc , e + ,c ) 32: output  X r s =  X r s + c  X r s ( s ) / (1  X  c  X  c u ( s
We use four data sets in our experiments, which are summarized in Table 2.

Figure 2 presents the results, where we compare iPoG-B with the iterative method In all the cases, iPoG-B is much faster than the iterative method. For example, iPoG-B is 90x faster (49 seconds vs. 4,423 seconds) on the NetFlix data set. Overall, the proposed iPoG-B achieves 4  X  202x speedup over the iterative method. Note that there is no quality loss in iPoG-B.
One of the most popular proximity measurements is random walk with restart [ 8, 10, 14], which is the baseline of iPoG. Other repre-sentative proximity measurements include the sink-augmented de-livered current [ 5], cycle free effective conductance [ 9], survivable Table 2: Summary of data sets.  X  X  X  for bipartite graphs, and  X  X  X  for unipartite graphs.
 Figure 2: Comparison of speed. The proposed iPoG-B achieves 4  X  202x spee dup. See Section 6 for details. network [ 7], and direction-aware proximity [ 13]. All these meth-ods only consider the graph link structure and ignore the user feed-back. Although we focus on random walk with restart in this pa-per, our approach (i.e., to use the feedback information to refine the graph structure) can be applied to other random walk-based mea-surements, such as [ 5, 13]. In terms of dealing with the feedback on ranking, our work is also related to [ 2], where the goal is to use partial order information to learn the weights of different types of edges. In terms of computation, the fast algorithms (NB LIN and BB LIN) for random walk with restart in [ 14] are the most related to the proposed fast solutions. Our fast solutions differ from that in [14] in the sense that the graph structure in our setting keeps getting changed by the feedback, whereas it is fixed in [ 14]. The core idea behind the proposed fast solutions is to leverage the smoothness between the graph structures with/without feedback. In [ 15], the authors have used the similar idea to track the proximity/centrality on a time-evolving skewed bipartite graph.

Graph proximity is an important building block in many graph mining settings. Representative work includes connection subgraphs [ 5, 9, 11], content-based image retrieval [ 8], cross-modal correlation discovery [ 10], the BANKS system [ 1], pattern matching [ 12], Ob-jectRank [ 3], RelationalRank [ 6] and recommendation system [ 4].
In this paper, we study how to incorporate user X  X  feedback in proximity searching on large graphs. Our approach is based on a recent promising method [ 16]. Our main contribution is to propose an efficient solution for bipartite graphs (iPoG-B), which achieves up to two orders of magnitude speedup, while giving the same rank-ing results. A promising research direction is to parallelize the cur-rent method (e.g., using Hadoop).
This material is based upon work supported by the National Sci-ence Foundation under Grants No. DBI-0640543 IIS-0705359 CNS-0721736 IIS0808661 iCAST and under the auspices of the U.S. Department of Energy by University of California Lawrence Liver-more National Laboratory under contract DE-AC52-07NA27344 (LLNL-CONF-404625), subcontracts B579447, B580840. This work is also partially supported by an IBM Faculty Award, a Ya-hoo Research Alliance Gift, a SPRINT gift, with additional fund-ing from Intel, NTT and Hewlett-Packard. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, or other funding parties. [1] B. Aditya, G. Bhalotia, S. Chakrabarti, A. Hulgeri, C. Nakhe, [2] A. Agarwal, S. Chakrabarti, and S. Aggarwal. Learning to [3] A. Balmin, V. Hristidis, and Y. Papakonstantinou.
 [4] H. Cheng, P.-N. Tan, J. Sticklen, and W. F. Punch. [5] C. Faloutsos, K. S. McCurley, and A. Tomkins. Fast [6] F. Geerts, H. Mannila, and E. Terzi. Relational link-based [7] M. Gr  X  otschel, C. L. Monma, and M. Stoer. Design of [8] J. He, M. Li, H.-J. Zhang, H. Tong, and C. Zhang.
 [9] Y. Koren, S. C. North, and C. Volinsky. Measuring and [10] J.-Y. Pan, H.-J. Yang, C. Faloutsos, and P. Duygulu. [11] H. Tong and C. Faloutsos. Center-piece subgraphs: problem [12] H. Tong, C. Faloutsos, B. Gallagher, and T. Eliassi-Rad. Fast [13] H. Tong, C. Faloutsos, and Y. Koren. Fast direction-aware [14] H. Tong, C. Faloutsos, and J.-Y. Pan. Random walk with [15] H. Tong, S. Papadimitriou, P. S. Yu, and C. Faloutsos. [16] H. Tong, H. Qu, and H. Jamjoom. Measuring proximity on
