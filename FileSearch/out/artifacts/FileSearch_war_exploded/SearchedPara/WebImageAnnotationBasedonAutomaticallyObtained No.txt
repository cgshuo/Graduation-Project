 Nowadays, the digital images have become widely available on World Wide Web (WWW), which has brought great challenges for organizing and searching a large volume of available images. Well-known commercial systems including Google, MSN, and Yahoo! rely on surrounding descriptions of images embedded in the web pages for the image retrieval. Images without clear context descriptions will either be returned as false positives or be totally discarded during the retrieval. Image auto-annotation techniques [1,2,3,6,7,8,12] provide an attainable way to associate the  X  X isuality X  of the images with their semantics, which can be used to search unlabeled image collections, and return more relevant images to the users.

In the previous work, both the generative model [1] and the supervised classi-fication methods [3,12] have been applied to improve the performance of image annotation. Such methods rely heavily on the quality of the present training set. In the web image annotation, one feasible way to obtain sufficient training data is to parse the web content automatically. However, due to the well-known problem of complexity and variety of the web pages, it is difficult to keep the quality of the training data high. Although some efforts have been made to parse the web content intelligently, such as [13,14]. However, the light weight methods, such as DOM, SAX are more widely used in real applications. Due to their unsupervised acquiring processes, the training set obtained automatically is usually impurer than what is required for traditional annotation problems. For example, Fig. 1 lists some training images with labels  X  X oral X  and  X  X olar eclipse X  respectively, which are automatically parsed out from the images X  surrounding text in web pages. It is obvious that images in the right two columns should not be associ-ated with  X  X oral X  and  X  X olar eclipse X  respectively, so called noise images in this paper. In generative model based annotation, if the unlabeled images have high visual similarities with noisy training images, they tend to be wrongly labeled. The previous work [11] demonstrates that the label noise will also impair the classification performance. Some effor ts have been made by adopting some data cleaning procedure [11] or predicting the noisy data probabilistically [10]. How-ever, due to the visual diversity of the w eb image, images in the same class often show different visual content. It is difficult to distinguish the noisy data from the real ones according to the visual difference.

To address this problem, we present a novel web image annotation approach based on multi-modal classification. In our method, image annotation is posed as a multiple class classification problem. We analysis the influence of the noisy data conducted on the multiple hyperplanes, then treat the noisy data as special kind of modals of the class. To implement the multi-modal classification, mixture component based local fisher discrimi nant analysis (MLFDA) is proposed in our approach. Our method works as follows: Firstly, an impure training set is automatically obtained by heuristically judging the relevance between the context of images and their semantics. To reduce the influence of the noisy data and achieve better separability between different classes, kernel-based LFDA is exploited to find an  X  X ptimal X  separable subspace by preserving the local structure between noisy data and the true class samples. Then we learn mixture components for each class in the subspace, where the noisy modals will gain small weights and play less important role in classification. In summary, we make the following contributions in this paper:  X  Based on the noisy training set automatically obtained from web, we propose  X  By using MLFDA-based technique, ou r method can effectively reduce the  X  Experimental results on the real data set of 4000 web images demonstrate The rest of the paper is organized as fo llows. Section 2 introduces the related work. Section 3 presents our MLFDA-bas ed annotation method. We discuss the experimental results in Section 4 . Section 5 concludes this paper. Statistical Annotation Models: Generative model based image annotation approaches such as Relevance Model[1] has shown significant performance im-provements. However, such unsupervised labeling process is strongly influenced by the image with similar visual feature but different semantics. Taking each semantic label as a class, image annotation could be implemented by supervised learning based classification techniques. Model-based [2] and SVM-based ap-proaches [3] have been applied in image annotation. However, the model-based methods usually suffer from the problem of insufficient training data [3]. The SVM based methods need to learn the separate hyper plane for each class, thus may lead to a high computation cost. Furthermore, they often suffer from the imbalanced training set [12]. Namely, the number of negative samples is much larger than that of positive ones, which is very severe in web image annotation. Fisher Discriminant Analysis (FDA) [4] is a traditional statistical method that has proved successful on classification problems. Compared with previous genera-tive model and classification method based image annotation, it has the following advantages: 1). FDA incorporates the discriminant information between differ-ent classes without learning different separating hyper-planes for each class. 2). There are no negative samples, and it is not affected by the imbalanced training samples. In this paper, we exploit the FDA as our basic multi-class classifier. Web Image Annotation: Wang et al. [6] proposed a web image annotation method AnnoSearch using search and data mining techniques. However, in their framework, at least one accurate keyword is required in advance. Hua et al. [7] proposed a system which can automatically acquire semantic knowledge such as description, people, temporal and geographic information for web images. Never-theless, they did not explicitly exploit the visual similarity to label new images. Li et al. [8] proposed a real time computerized annotation system named ALIPR, which uses the available data set: Corel data set as their training set. Fig. 2 presents the overview of our proposed scheme for learning semantics of web images. Two major steps of the proposed method are: web data processing, web image semantic annotation. Web data processing analyzes the relevance be-tween the context of images and their semantics, and then gets a high confidence training sets. Based on the training images, we perform the annotation for the rest web images using MLFDA-based annotation method.
 3.1 Web Data Processing In our system, we use HTML Parser [8] to transform html documents into DOM tree, and then extract the text and image s by traversing through the DOM tree. During this process, we also obtain the correlation information between text and images if the correlation is clearly shown in the web page.
 First, we generate the DOM tree for each web page containing the web images. From the bottom, visual objects like image, text paragraph are identified as basic separate the different content passages. Fig. 3 shows an example. The left part of Fig. 3 shows two paragraphs and one image of a web page about  X  X yramid X . The right part illustrates part of the DOM tree parsed from this web page.
Second, we extract the semantic text information for the images. The ex-tracted information includes:  X  ALT (Alternate) Text  X  The closest title with the images in the DOM tree.
 The ALT text in a web page is used for displaying to replace the associated image in a text-based browser. H ence, it usually represents the semantics of the image concisely. We can obtain the ALT text f rom ALT tag directly. Unfortunately, this information may sometimes be unavailable since many editors are too lazy to fill this field while they were designing the web pages[]. A feasible way is to analysis the context of the web image to obtain the semantic text information of the images. Fig.3 shows that the image and its  X  X earest X  title  X  X yramid X  have clear semantic correlation. Notice that t he title in this paper is used in a general sense, including both paragraph title and the web page title. It indicates that we could measure the  X  X istance X  between the title and the image to judge their semantic correspondence. The DOM tree shows the relevant title and the image are in the same &lt; TABLE &gt; tag in the web page. So we evaluate the  X  X istance X  X y measuring the level difference of the TABLE or DIV tag between the image and the title in the DOM tree. The detailed web data processing steps are as follows:  X  From the TABLE field containing the images, we traverse the DOM tree up- X  Given the title, we measure the distance between the title and the image 3.2 MLFDA-Based Web Images Semantic Annotation After web data processing, we obtain two set of images: training set L ,where the correlation between the semantic keywords and the images is already known; the remaining set of images U , where the correlation is unknown. We propose the MLFDA-based image semantic annotation technique to assign the semantic textual labels to the images in U . As we use FDA as our basic multiple clas-sification classifier, we first give a brief introduction to FDA and analyze how the noisy data damage the separation between different classes in FDA, then introduce our MLFDA-based annotation algorithm.
 Fisher Discriminant Analysis. Generally, each image has more than one annotation words, the image annotation can be posed as multi-class learning problem. Let x denote a training sample, y denote the class label, n i be the number of image samples in class i , c be the number of the classes. We can will be assigned to the i th class. Fisher discriminant analysis finds an  X  X ptimal X  discriminant subspace for separating the different groups, which is defined as: Where  X  T S W  X  is the within class scatter matrix,  X  T S B  X  is the between class scatter matrix, which are all defined in the discriminant subspace. S B and S W correspond to the within and between cl ass scatter matrix in the origin space. g ( x ) can be defined as the monotonic decreasing function of the Mahalanobis distance, which assigns the new samples to the class with centroid closest to it in the subspace. Solving Eqn. 3 is equa l to solving a generalized eigenvalue problem.

Eqn. 3 implys that FDA is to maximize th e between-class scatter as well as minimize the intra-classes scatter. Ho wever, when there are noisy data which have different visual contents with the true class samples as shown in Fig. 1, the above criteria indicates that the noisy training samples and the true samples in the same class will be merged together. Thus, the  X  X ptimal X  separation of the subspace will be weaken. Due to the visual diversity of the image class, images in the same class often have different visual contents. It is hard to distinguish and eliminate the noisy data in advance. Instead of removing the possible noisy data directly, we just regard them as some special modals of the class. It is obvious that keeping the original structure of these modals of the class will increase the separability between different classes when mapping the origin data to the discriminant subspace. We exploit LFDA to achieve this goal, which is originally proposed by Masashi [9] to perform the multi modal dimension reduction. Noise Processing. To preserve the local structure in the class, construct the local structure preservation matrix A. We take a simple way to define A . Specif-ically, let A i,j =1,if x i and x j are in the same class and x j is the k-nearest neighbor of x i . The noise sample x k has different visual features with the other samples of the class they related to, so A  X  ,k tends to be zeros. In the next part, we will show that such images have less influence on defining the separable hyper plane between different classes.
 Local Fisher Discriminant Analysis. Review that in LFDA[9], the local with-class scatter matrix  X  S B and  X  S W are redefined as follows: Applying the local structure preservation matrix A: Because the noisy data is far away with true samples in the class, they have less subspace of LFDA is given by: Similarly, the subspace can also be obtained by solving a generalized eigenvalue problem. Classification Based on Mixture Components. Fisher discriminat analysis can be viewed as a prototype classifier. Ea ch class is represented by its centroid, and the unlabeled sample is classify to the closest one according to Mahalanobis distance measure. It is not difficult to imagine that the noisy data usually forms isolated and small clusters in the discriminant subspace obtained above, thus a single prototype is not sufficient to represent the complex classes, and mixture models are more appropriate. Assume k th class has a mixture Gaussian density, that is: where {  X  kr , X  kr , X  } is parameter set, including weight set {  X  kr } and mixture parameter {  X  kr , X  } . R k is the number of the prototypes of the k th class. Given such a model for each class, the class posterior probabilities are given by: where  X  k represent the class prior probabilities. We estimate the parameters with a maximum likelihood estimates (MLEs) as follows: We followed the EM algorithm to estimate the model parameters with ML cri-terion. EM alternates between the two steps:
E-step: Given the current parameters, compute the weights of the subclasses in each class observations.

M-step: Compute the weighted MLEs for the parameters of each of the component Gaussians within each of the classes, using the weights from the E-step.

A k  X  means clustering method is applied to fit the data in each class to create the initial weight matrix.
 The Summarization of Our Annotation Approach. Kernel function can be used to overcome the limitation of lin ear decision function of FDA. Then, our MLFDA-based annotation approach is summarized in the following steps: 1. Extract the global feature of the images to get the original feature space. 2. Use a nonlinear mapping function  X  : X  X  F, x  X   X  ( x ) to project the 3. Find the optimal discriminant subspace according to Eqn. 8. 4. In the discriminant subspace, learn the mixture components for each class. 5. For unlabeled images, calculate and rank the posterior probability according All the data used in our experiments ar e crawled from Internet. The image data set is obtained by HTML parsing and meaningless small icons are filtered out. The size of the image data set is 4000. After web data processing, we obtain 1600 training images, and the remainin g images with low confidence scores are used to be annotated. There are 70 semantic keywords in the data set. Instead of taking each keyword as the class, we gr oup the most co-occurred keywords as our class. For example, the keyword group  X  X obile phone X  is regarded as one class. The keywords in the class with largest posterior probability are assigned as the annotation of the new images. The global features are 528 dimensions with color and texture features extracted acco rding to MPEG7. We compute the average recall, precision and F 1 to measure the quality of the algorithm. Given a query word w ,let | W G | denote the number of human annotated images with label w in the test set, | W M | denote the number of annotated images with the same label by our algorithm, and | W C | denote the correct annotations by our algorithm. The recall, precision and F 1 are defined as: 4.1 The Effectiveness of Web Data Processing By using our web data processing method to get the training set, there are two adjustable parameters to be decided: C , the threshold to decide whether the text is a title; T , to judge whether the title and the image in the same web page have high semantic correspondence. In our experiments, we choose C =0 . 4. which is because when the text is bold, with larger font size and the length no more than 5, Score ( text )=0 . 4. When the title and the image lie in the same TABLE field, which means Lay ( TABLE )is1,aswellas Count ( TR )  X  10, we assign this title as the semantic label of the given image. Accordingly, we choose T = 1. In this manner, we obtain the training set with 1600 images. Because of the complicated structures of web pages, some incorrect label information is usually introduced when correlation is set up for an image where the title of it is not related to its semantic meanings. Ou r training set contains 340 noise images with false class labels, makes up to about 20% percent. It is obvious that the quality of our training set automatically obtained by our method is below than the manually annotating ones, which bring great challenges for our annotation algorithm.

Because LFDA is effective on multi-mod al problem, in order to differentiate that the performance of image annotation based on MLFDA is improved by alleviating the bias of noise data or by addressing the multi-modal problem, a sub data set with more noise is selected from the global training set. The sub training set consists 6 semantic classes with relatively less modal, and 296 training samples. The noise data makes up to 30% percent, and the noise images all have very different visual features w ith the true samples in the class. In the following, we denote the global training set as DATA1, the sub training set as DATA2. 4.2 The Effectiveness of MLFDA-Based Image Annotation We compare the annotation performance of our MLFDA-based annotation method with generative modal based MBRM[1], SVM, and GDA(Generalized Discriminant Analysis)[4]. In the proposed MLFDA-based annotation method, we set k = 15 for the best performance. The exp erimental results on two training sets are shown in Table 1 and Table 2 respectively.

It is obvious that the F 1 measure of MBRM is much lower than that of other three methods on both training sets, which because MBRM does not exploit the discriminant information between classes and is strongly influenced by the noisy data. When the test images have high visual similarity with noisy data, the class label is easily to be mistaken. Our proposed MLFDA-based method generally performs best on both training set. From Table 1 and Table 2, we can observe that compared with other t hree methods, the improvement of the precision measure by using MLFDA in DATA1 is not as significant as that in DATA2, while the F 1 measure is much more improved in DATA1. This is because in DATA1, there are noisy data as well as the multi-model data, our MLFDA can deal with both problems effectivel y. The excellent performance on DATA2 with more noise demonstrates that our proposed MLFDA-based method can effectively alleviate the influence of noisy data on defining the separable subspace by regarding the them as the multi modal samples of the class. The results in Table 1 and Table 2 also demonstrate that the SVM and the GDA have similar performance, and SVM is slightly better than GDA in our data sets.

Fig. 4 shows some web image examples whose semantic keywords can not be obtained from their context directly, the correct semantic labels provided by our method are also listed in the figure. From Fig. 4, we can see that by using our proposed method, more web images can get their semantic descriptions, which will provide more relevant results for web users.
 In this paper, we proposed a novel web image auto-annotation framework, in which the method of automatically extracting the training samples and a MLFDA-based image annotation algorithm are proposed. The experimental re-sults indicated that our method is effectiv e and outperforms other related meth-ods. In the future, we will design more effective methods to address the noisy data with similar visual content but false labels. We also plan to solve the com-putational problems associ ated with large data sets.

