 Inauthentic file attacks by anonymous malicious peers are common on today X  X  popu-The actual file could be a Trojan Horse program or a virus like the well-known VBS.Gnutella worm [3]. The recent measurement study of KaZaA [1] shows that many popular recent songs being polluted [2]. 
One way to address this uncertainty problem is to develop strategies for establish-ing reputation systems that can assist peers in assessing the level of trust they should place on the quality of resources they are receiving (e.g. [4, 7, 8, 9, 12]). Most exist-ing reputation management systems require a central server for storing and dissemi-nating the reputation information, and it does not accord with the open and distributed nature of these P2P systems. So the very core of the reputation mechanism in a P2P tion. The main challenge of building such a reputation mechanism is how to effec-tively cope with various malicious collectives of peers who know one another and attempt to collectively subvert the system by providing fake or misleading ratings about other peers [8, 9]. 
We present such a scheme, called SimiTrust (the degree a peer trusts another peer X  X  recommendations depends on the simi larity between these two peers in our model), for reputation management in P2P virtual communities. The scheme includes a mathematical model for quantifying the trustworthiness and a distributed algorithm to implement the model over a structured P2P overlay network. The paper has a num-ber of contributions. First, each peer i is assigned a unique trust value by aggregating similarity-weighted recommendations of the peers in the community who has inter-acted with peer i , and an iterative method is given to compute this trust value in our model (section 3); Second, the SimiTrust algorithm is presented to implement the iterative method in a decentralized way (section 4&amp;5); Finally, A series of simulation-based experiments show that the SimiTrust scheme is robust and efficient to cope with various malicious collectives in Section 6. The reputation management systems can be classified into two major categories; those based on micro-payment [7, 12] and those based on recommendation [4, 8, 9]. 
In the eBay Feedback System [4] which is a reputation system currently in use, buyers and sellers can rate each other based on their past transactions with each other. It can be regarded as a recommendation-based local trust model. We call it local trust the recommendations of a few peers (or a few neighbors of the peers) in the commu-nity; that is, it only reflects the peer X  X  local view. Li Xiong [8] presents an elaborate local trust model with five important parameters and a general trust metric combining these parameters for evaluating the trustworthiness of a peer in a P2P community. 
Sepandar D. Kamvar et al proposed the eigentrust [9] algorithm for P2P file-sharing networks and ranked the eigentrust as a global trust model wherein each peer i is assigned a unique global trust value that reflects the experiences of all peers in the value will give the honest recommendations is questionable. A threat model (threat under it [9]. We also argue that the pre-trusted peers (the few peers born with higher gentrust algorithm) may not be available in all cases and we give a more general ap-proach in this paper. and peer j to weight the recommendations of peer j ; That is, the more similar between mendation depends not only on the trust value of j , but also on the similarity between i and j . Further more, we do not need any pre-trusted peers to ensure the convergence still robust under more general conditions (even under threat model DM) and also converges more quickly and decreases the number of inauthentic file downloads more effectively than the eigentrust. In this section, we present a general trust metric and describe the formulas which we use to compute the trust value for each peer in a P2P virtual community. For the ab-section. The community consists of n peers and no peer joins or leaves. The dynamic when we consider the distributed implementation of the trust model. 3.1 Problem Formulation Each peer i rates another peer j with which it tries to make transactions by rating each transaction as either positive or negative, depending on whether i was able to accom-transactions which i has made with j and F ij denotes the number of negative transac-downloaded a file from j and the file is validated by i . Definition 1. A normalized local trust value L ij is defined as follows: convergence of the iterative method for global trust value computation that we de-flects the peer i  X  X  local view on the credibility of the peer j with whom he has directly recommendations of j  X  X  friends and by asking friends of friends. 
One critical step in our model is to compute the similarity between rating opinions of peers and then to weight the peers X  recommendations by that value. The basic idea in similarity computation between the rating opinion of peer i and that of peer j is to first define the rating opinion vector of a peer and then to apply a similarity computa-compute the similarity between vectors [6]. Here we use such a method, called co-sine-based similarity. The similarity between them is measured by computing the cosine of the angle between these two vectors. by C ij , is given by rating opinion of peer i on peer k . B ik is defined as follows: For each peer i , we let B ii = 1 + where is an arbitrarily small positive constant. Definition 3. A global trust value vector , T = [ T 1 , T 2 , ... , T n ] T , is given by where " T " denotes the transpositi on of a vector or a matrix and T i denotes the unique peer i and serves as peer i  X  X  reputation score in the community. And U i denotes the set of those who have interacted with i and have recommended i , given by: 
The global trust value of peer i is the sum of the weighted recommendations of the ( L ki ) is weighted by the similarity ( C ki ) between peer k and peer i , and weighted by the value of every peer k , k U i , is also computed by (4)) of asking friends of friends by using the above formula, T i reflects a view of the entire community. 
The credibility of the recommendations of a peer is different from that of the peer itself, especially under some threat models (e.g. threat model DM in section 6.6). We weight the recommendations of peer k by the similarity between k and i . That means, peers whose rating opinions are similar to him rather than those with high global trust values. Therefore the DM peers (in section 6.6) who act as normal peers in the com-munity and try to increase malicious peers X  global trust value can not take effect when our scheme is activated. This can be written in matrix notation as where R denotes a recommendation matrix . The element of the ith row and jth col-umn of R , R ij , is given by 3.2 An Iterative Method for Global Trust Value Computation We can easily derive an iterative method to get the solution of the linear equation (5): 
We will prove the convergence of the iterative method given in (7) since the matrix norm of the iterative matrix, R T , is less than 1. converges to T n  X  (the solution to (7)). ( n  X  denotes n-dimensional real space). norm [10]. 
Now || R T || 1 =  X   X  is the cosine of the angle between two vectors, B i and B j . Because there is at least one any i and j , i j . Therefore we have | |C ij
So we proved the convergence of the iterative method given in (7). Decentralized and secure trust data management, i.e., how to efficiently and securely important in implementing a P2P trust model such as SimiTrust. We achieve these in over a peer X  X  calculation job on his own trust value, becoming this peer X  X  trust value manager . This can be done by using DHT (Distributed Hash Table) such as Chord to map peers to their trust value managers. Second, adding redundancy to the calcula-tailed methods are not given here due to space constraints. value manager of peer i , M i , shall have the following duties: (1) Storing the trust data global trust value of peer i ; (4) Submitting the trust value, rating opinion vector, etc. of peer i as responses to search requests of other peers in the community. The SimiTrust algorithm is proposed in this section to implement the iterative method given in section 3.2 in a decentralized way. After introducing the trust value manager mechanism, a peer X  X  global trust value is computed by his trust value managers based on the trust data that are collected about the peer. 5.1 Algorithm Description Here we describe the SimiTrust algorithm to compute a global trust value vector. Before the description, we introduce the following two primitives which will be used in the algorithm: meaning will be clear from context; 
Query (ID j , T j , L ji , B j ) querying the global trust value, recommendation, and rating opinion vector of peer j from j  X  X  trust value managers. 
The algorithm consists of two components: the Algorithm1 and Algorithm2 as roles: an ordinary peer who rates, or rated by, other peers, and a trust value manager manager of peer u , i uses the Algorithm2. Algorithm 1. // peer i , as an ordinary peer. 
UpdateAndSubmitTrustdata( ) // submits its rating ( G ij , F ij ) after a transaction with j . { } peer i receives a submit( ) primitive from one of the peers who have interacted with u ; or peer i sets up a threshold, and it is triggered when the number of the received sub-mit( ) primitives reaches the threshold. 5.2 The Overhead of the Algorithm After each transaction, peer i only needs one message to submit its rating to its trust value manager in the Alogrithm1. CalcGlobaltrust( ) only needs to ask, for one round, the peers who have interacted with peer u for their global trust values, recommenda-tions and rating opinion vectors in the Algorithm2. Therefore the message complexity of our algorithm is O ( n ) which is less than that ( O ( n 2 )) of the eigentrust. 
The complexity of the algorithm is also bounded in that the algorithm converges Algorithm 2. // peer i , as a trust value manager of peer u . 
UpdateLocaltrust( ) // updates L uv and B uv after receiving the Submit( ) from u . { } 
CalcGlobaltrust( ) // calculates the global trust value of peer u . { } iterations, i.e., the computed global trust values do not change significantly any more after a low number of iterations. In the simulation of our algorithm, this corresponds more detail). 
Since either trust value store or computation processes in a decentralized manner, every peer only needs to have the knowledge of its neighbors to maintain the underly-ing structured P2P network and to store and compute the trust values of certain peers as a trust value manager. As a trust value manager of peer u , peer i only needs to keep the most recent trust data items about peer u (e.g. the ratings to u in recent 100 trans-actions) using an FIFO-like cache replacement policy. These data items should be the peer j from which he try to make a transaction, a peer i only needs to send a mas-sage to ask j  X  X  trust value manager for j  X  X  global trust value. eigentrust algorithm and to a P2P community where no reputation system is imple-mented, called random peer selection scheme. We call it random since peers ran-domly select a peer to make a transaction in such a community. We shall demonstrate the schemes X  performance under a variety of threat models. 6.1 Simulation Setup simulates a typical peer-to-peer file-sharing community. The global trust values in this community are used to bias download sources. 
Each simulation is divided into query cycles. In each query cycle, any given peer in the community could be issuing a query, inactive, or down and not responding to queries. After issuing a query, a peer waits for incoming responses from the peers that have the file he is looking for, selects a peer, whose global trust value is the highest among those responding, as the download source, and downloads the file. The last bers of authentic and inauthentic downloads observed by each peer are calculated. Then the simulation comes into the next query cycle. Each experiment is run several times and the results of the runs are averaged. 
We set up a community consisting of 500 peers, 10 of which are pre-trusted peers for the eigentrust, and we do not need any pre-trusted peer to ensure the convergence of our algorithm. All peers divided into normal, good peers (peers who are participat-formance). The proportion of malicious peers will be given in the description of each experiment. When they join the community, malicious peers connect to the 6 most highly-connected peers in the community in order to receive as many queries travel-ing though the community as possible. And the good peers only connect to 3 6.2 Threat Models We will consider two strategies of malicious peers to cause inauthentic uploads even when a reputation management scheme is activated, since the main challenge of building a reputation mechanism in a P2P environment is how to effectively cope with various malicious collectives of peers who know one another and attempt to collectively subvert the system. Threat Model IM: Individual malicious peers, called IM peers, always provide an downloads and assigning high local trust values to malicious peers from whom they try to download files. Threat Model DM: Two groups of malicious peers (IM and DM) are present in the community. DM peers provide only authentic files and uses the reputation they gained download source for all queries that they answer. DM peers can get high global trust each peer u DMs sets L uv =1/||IMs|| if peer v IMs. 6.3 Performance Indices We are interested in evaluating the performance of the SimiTrust scheme and in com-paring it with the two mentioned schemes. To facilitate our comparison, we consider the following metrics: 
Proportion of Authentic Downloads (PAD) , the ratio of the number of authentic downloads to the number of all downloads viewed by all good peers, is defined as 
PAD is calculated for all good peers at the end of each experiment. This metric di-rectly measures the effectiveness of the reputation management schemes. In an ideal P2P community where no malicious peers present, we have PAD=1. 
Convergence Time is defined as the least number of query cycles required to approach to 0. If an algorithm for reputation management does work, the good peers can be differentiated from the malicious peers by their global trust values after a few query cycles; that is, the good peers can get the higher trust value than the malicious peers though every peer has the same initial global trust value. The inauthentic downloads in the community then approach to 0 because peers always choose the peer whose trust value is the highest among the peers responding their queries as the downloading source. The less query cycles required to eliminate the inauthentic downloads in the community, the faster an algorithm converges. 6.4 IM Experiments and Discussion IM experiments are carried out in the presence of IM peers. Fig. 1 shows the number the P2P community proceeds from one query cycle to the next. We have IM peers make up 40% of all peers in the community. Using random peer selection scheme, malicious peers succeed in inflicting many inauthentic downloads in the community. Yet, if our scheme is activated, the inauthen tic files downloaded are almost eliminated after the 5th cycle. The Convergence Time , 5, is less than that when using the eigen-scheme is activated, and because of their low trus t values, malicious peers are rarely downloads in the community. 
In the next experiment, we have between 0% and 50% of the peers in the commu-nity be malicious peers, increasing this percentage in steps of 10% for each run of the experiment. The results of the number of inauthentic downloads of each query cycle almost eliminated after 3-6 cycles). Fig. 2 plots the proportion of authentic downloads (PAD) against the percentage of IM peers in the community. The PAD is higher than 80% even if IM peers make up a half of the peers in the community when our scheme is activated. 6.5 DM Experiments and Discussion We assume that malicious peers are so intelligent that IM and DM peers can collabo-rate to subvert the reputation system in the DM experiments. Some experiments were Our experiments show that the eigentrust algorithm does not converge under threat model DM; that is, the good peers can not be differentiated from the malicious peers by their global trust values, even if there are only a few DM peers (less than 4% of all the peers) in the community. The fundamental reason is that DM peers have high global trust values, but they give untrue recommendations. The eigentrust algorithm by peers, and we use the similarity between peers to weight their recommendations so that the recommendations of DM peers can be screened. Therefore the performance of thentic downloads measured for each query cycle when the simulation proceeds from one query cycle to the next. 
When we have more DM peers in the community, the eigentrust does not converge DM peers in the community can influence the performance of the SimiTrust. Fig. 4 shows the number of inauthentic files downloaded in each query cycle when the simu-lation proceeds. We observe an interesting phenomenon that the more DM peers pre-sent, the less inauthentic file downloads occur. Malicious peers operating under threat model DM need to pay cost for uploading inauthentic files: DM peers have to provide some share of authentic files, which is undesirable for them. Suppressed by our considerable share of authentic files. We have presented SimiTrust, a reputation management scheme for quantifying and comparing the trustworthiness of peers in a P2P virtual community. Each peer is as-signed a global trust value which reflects the experience of the community as a whole with the peer. The global trust value for a peer is computed by calculating the similar-ity-weighted recommendations of the peers who have interacted with him, taking into consideration the entire community X  X  history with the peer. In experiments, these trust values are used to bias downloads and this method is successful to reduce the number inauthentic files in a P2P file-sharing community under a variety of threat scenarios. gentrust, especially under threat model DM. 
