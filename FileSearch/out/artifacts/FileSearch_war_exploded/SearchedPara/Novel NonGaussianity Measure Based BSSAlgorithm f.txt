 Blind source separation(BSS) is typically based on the assumption that the observed signals are linear superpositions of underlying hidden source signals. When the source signals are mutual independent, the BSS can be solved by using the so called independent component analysis(ICA) method which has been at-tracted considerable attention in the signal processing and neural network fields and several efficient algorithms have been pr oposed (see for overview, e.g., [1-2]).
Despite the success of using standard ICA in many applications, the basic assumptions of ICA may not hold for some real-world situations, especially in biomedical signal processing and image processing, therefore the standard ICA cannot give the expected results. In fact, by definition, the standard ICA algo-rithms are not able to estimate statistically dependent original sources. Some authors [3] have proposed different approaches which take advantage of the non-stationarity of such sources in order to achieve better performance than the classical methods, but they still require their independence or uncorrelation.
Some extended data models have also been developed to relax the indepen-dence assumption in the standard ICA model, such as multidimensional ICA [4], independent subspace analysis [5] and subband decomposition ICA (SDICA) model [6].

As mentioned in [7], in the dependent sources situations, we can not resort minimization the mutual information(MI), but on the other hand we can maxi-mization of NG to get the dependent sources. In this paper, based on the gen-eralization of the central limit theorem(CLT) to special dependent variables, we will try to track the generalize ICA model-dependent component analysis problem by maximization NG measure. The NG quantity measure of arbitrary standardized probability density is defined by the L 2 norm in the L 2 space of the difference between the given density and the standard normal density. This paper is organized as follows: Section 2 introduces briefly the dependent BSS model and NG measure; Then in sect ion 3, we describe the novel NG mea-sure using Hall distance in detail; In section 4, we use the NG measure to get the proposed separation algorithm and show that it is equivalent to the FastICA al-gorithm; Simulations illustrating the good performance of the proposed method are given in section 5; Finally, section 6 concludes the paper. 2.1 Dependent BSS Model For our purposes, the problem of BSS can be formulated as: x ( t )= As ( t )+ vector. Matrix A  X  R m  X  n is an unknown full column rank mixing matrix and that is assumed to be zero in this paper.

The task of BSS is to estimate the mixing matrix A or its pseudo inverse separating (unmixing) matrix W = A + in order to estimate the original source signals s ( t ), given only a finite number of observation data. There are two inde-terminacies cannot be resolved in BSS without some apriori knowledge: scaling a waveform-preserving relation.

A key factor in BSS is the assumption about the statistical properties of sources such as statistical independen ce. That is the reason why BSS is often confused with ICA. In this paper, we exploit some weaker conditions for sepa-ration of sources assuming that they have statistically dependent properties.
Throughout this paper the following assumptions are made unless stated oth-erwise: 1) The mixing matrix A is of full column rank; 2) Source signals are statistically dependent signals with zero-mean; 3) Additive noises { n ( t ) } =0.
So, the BSS model of this paper is simplified as 2.2 NG Measure In ICA applications, NG measures are used based on the following fundamen-tal idea: the outputs of a linear mixing p rocess that preserves variances, have higher entropies than the inputs [7]. This general statement can be precisely ex-pressed in mathematical terms as CLT which tell us that the linear mixture of N independent signals with finite variances will became asymptotically Gaussian (or more nearly Gaussian).

Since CLT is not valid for any set of dependent variables, we must be aware that we may not always recover the original sources using maximum NG criteria. [7] gives a very special condition on sour ces, for which the linear combinations of dependent signals are not more Gaussian than the components and therefore the maximum NG criteria fails, but fortunately this is not the case in most of real world scenarios.

The NG quantity measure of arbitrary standardized PDF is defined by the L 2 norm in the L 2 space of the difference between the given density and the normal density. This can be interpreted as th e square-distance, with respect to some measure, between the two functions in the space of square integrable functions.
Let x be a random variable with PDF f ( x ), We attempt to compute f  X  X  de-parture from Gaussianity by comparing it with its normal Gaussian counterpart: g ( x )= 1  X  of PDF, the deviation of f from normality may be evaluated by an L 2 metric defined with some positive measure of the real line,  X  ( x ): where the w ( x )isgivenby w ( x )= d X  ( x ) /dx . This definition corresponds to the integrated square-difference between functions f and g ,measuredwiththe weight function w ( x ). Although we leave w ( x ) unspecified at this point, we assume that we choose w such that the integral converges for most reasonable densities.

We expand the function f ( x ) in the integral (2) in terms of Hermite poly-nomials, a set of orthogonal functions on the entire real line with respect to an appropriate Gaussian weight. Following the notation in [8], two distinct families of Hermite polynomials, for n =0 , 1 , 2 ,  X  X  X  , are generated by the derivatives of the Gaussian PDF, and H n ( x )=
Following standard practice, we refer to the first set as Chebyshev-Hermite, and the second as Hermite polynomials. The first few polynomials are: H 0 ( x )=
Chebyshev-Hermite and Hermite polynomials satisfy an orthogonality rela-tionship,  X  with respect to the weight functions g ( x ) for Chebyshev-Hermite polynomi-Gaussianity indices based on the squared functional distance [9]. The index is defined by a different form of orthogonal series expansion for arbitrary density f ( x ), written in terms of either Chebyshe v-Hermite or Hermite polynomials. From the point of view of the L 2 metric space, perhaps t he most natural weight is the uniform function w ( x ) = 1, which treats every point on the entire real line democratically. Hall [9] proposed such an index based on the L 2 Euclidean distance, L 2 (1), from the standard normal, called Hall distance.

If f is a square integrable function ( g certainly is, since g 2 is proportional to a Gaussian with variance 1 / may expand f in terms of Hermite polynomials as follows: tion constant. This form of Hermite ex pansion is sometimes called the Gauss-Hermite series. Unlike the Gram-Charlier series, the polynomials used here are the Hermite polynomials (not Chebyshev-Hermite) and the Gaussian weight appears in both the decomposition and the reconstruction formulae. The Gauss-Hermite coefficients can also be considered as the expectation values, and thus can be estimated from the samples x t . In particular, one expects that by the tails of the Gaussian.

If we substitute the series representation (7) into the L 2 metric formula (6), and use the orthogonality conditions (4), we see that the Hall distance is
Again, the L 2 distance is expressed as the sum of squared Hermite coefficients, with a zeroth order correct ion because the origin is taken to be the standard normal. In general, we do not know a priori the first few terms of the sum as we did in the Gram-Charlier cas e, because the coefficients b n are no longer directly linked to moments. However, this is only a minor computational disadvantage considering the benefit of the robustness gained by this formulation. 4.1 Preprocessing In order to apply the maximum NG method to dependent source separation, the research must restrict the separating matrix W which make the separated signals y i have unit variance. A simple way to do this procedure is to apply first a spatial whitening filter to the mixtures x , and then, to parameterize the new separation matrix as the one composed by unitnorm rows. We implement this spatial filter using Karhunen-Loeve transformation (KLT) [10] reaching to a new set of spatially uncorrelated data, z = V X   X  1 / 2 V T x , where V is a matrix of eigenvectors of the covariance matrix R xx = E [ xx T ]and  X  is a diagonal matrix containing the eigenvalues of R xx which are assumed to be non-zero.
Now, if we define y = Uz , the new separation matrix U , must have the property of having unitnorm rows, which follows from the assumption of unit-variances of variables y i ( R yy = E [ yy T ]= UU T ). The  X  X eal X  (original) separa-tion matrix W can be calculated using y = Uz and (10) as follows:
Note that source estimates may be permuted or sign changed versions of sources (scale ambiguity disappears since it is assumed that the sources have unit-variance). 4.2 The Main Algorithm As mentioned in [7], in the dependent sources situations, we can not resort minimization the MI, but on the other hand we can maximization of NG to get the dependent sources.

So we view BSS algorithms as de-Gaussianization methods which based on other definitions of L 2 measurement, such as the Hal l distances (6). For rea-sons stated above, we choose to use the Euclidean metric L 2 (1) to define a non-Gaussianity index. Note that each component x i is a standardized random measurement is then given by the sum of L 2 (1) NG indices of x i across all n dimensions, where D 2 H ( x i )=( b 0 ( x i )  X  sum by taking only the 0-th order terms for each x i ,wecanshow Here, x i is the standardized random variable with an unknown density f k , z is a standard Gaussian random variable and g is the standard Gaussian PDF. This truncated form of the multidimensional L 2 (1) distance is equivalent to an ICA contrast due to Hyv  X  arinen, and the fixed-point iteration algorithm called FastICA was introduced in [2]. Then the main procedure of the basic form of the one unit FastICA algorithm can be concluded as follows: step1 . Choose an initial (e.g. random) weight vector u . step2 .Let u + = E { z g ( u T z ) } X  E { g ( u T z ) } u . step3 .Let u = u + / u + . step4 . If not converged, go back to step2 .

The one-unit algorithm estimates just one of the components. To estimate several components, we need to run the one-unit FastICA algorithm using sev-eral units (e.g. neurons) with weight vectors u 1 ;  X  X  X  ; u n . To prevent different vectors from converging to the same maxima we must decorrelate the outputs u 1 z ; a deflation scheme based on a Gram-Sc hmidt-like decorrelation. This means that we estimate the components one by one. When we have estimated p com-for u p +1 , and after every iteration step subtract from u p +1 the  X  X rojections X  u In order to confirm the validity of the proposed Hall distance based BSS algo-rithm, simulations using Matlab were given below with four source signals which have different waveforms. The input signals were generated by mixing the four simulated sources with a 4  X  4 random mixing matrix in which the elements were distributed uniformly. The sources and mixtures are displayed in Figs. 1(a) and (b), respectively. The source signals correlation values are shown in Table 1. So the sources are not the i.i.d signals, the proposed NG measurement based BSS algorithm can separate the desired signals properly.

Next, for comparison we execute the mixed signals with different BSS algo-rithms: JADE Algorithm [11], SOBI algorithm [1],TDSEP algorithm [12] and AMUSE algorithm [1]. At the same convergent conditions, the proposed algo-rithm which we call it as NG-FastICA was compared along the criteria statistical whose performance was measured using a p erformance index called cross-talking error index E defined as [1] where P ( p ij )istheentriesof P = WA is the performance ma trix. The separa-tion results of the four different sources are shown in Table 2 for various BSS algorithms(averaged over 100 Monte Carlo simulation).

The waveforms of source signals, mixed signals and the separated signals are shown in Fig. 1(c)(the first 512 observations are given). In this paper, we developed a novel Blind Source Separation (BSS) algorithms from linear mixtures of them, which enable to separate dependent source signals. Most of the proposed algorithms for solving BSS problem rely on independence or at least uncorrelation assumption of source signals that is the independent component analysis algorithm. Here, we show that maximization of the nonGaus-sianity(NG) measure can separate the statistically dependent source signals and the novel NG measure is given by the Hal l Euclidean distance. The proposed separation algorithm can result in the famous FastICA algorithm. Simulation results show that the proposed separation algorithm is able to separate the dependent signals and yield ideal performance.
 This work is partially supported by National Natural Science Foundation of China(Grant No.60672049) and the Science Foundation of Henan University of Technology under Grant No.06XJC032.

