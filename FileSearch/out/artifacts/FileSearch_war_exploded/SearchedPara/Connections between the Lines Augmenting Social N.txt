 Network data is ubiquitous, encoding collections of relation-ships between entities such as people, places, genes, or cor-porations. While many resources for networks of interest-ing entities are emerging, most of these can only annotate connections in a limited fashion. Although relationships be-tween entities are rich, it is impractical to manually devise complete characterizations of these relationships for every pair of entities on large, real-world corpora.

In this paper we present a novel probabilistic topic model to analyze text corpora and infer descriptions of its enti-ties and of relationships between those entities. We develop variational methods for performing approximate inference on our model and demonstrate that our model can be prac-tically deployed on large corpora such as Wikipedia. We show qualitatively and quantitatively that our model can construct and annotate graphs of relationships and make useful predictions.
 H.2.8 [ Database Applications ]: Data mining Algorithms statistical topic models, social network learning, graphical models
Network data X  X ata which express relationships between ensembles of entities X  X re becoming increasingly pervasive. People are connected to each other through a variety of kin-ship, social, and professional relationships; proteins bind to and interact with other proteins; corporations conduct business with other corporations. Understanding the na-ture of these relationships can provide useful mechanisms for suggesting new relationships between entities, character-izing new relationships, and quantifying global properties of naturally occurring network structures [2, 6, 32, 34, 35].
Many corpora of network data have emerged in recent years. Examples of such data include social networks, such as LinkedIn or Facebook, and citation networks, such as CiteSeer, Rexa, or JSTOR. Other networks can be con-structed manually or automatically using texts with people such as the Bible, scientific abstracts with genes, or decisions in legal journals. Characterizing the networks of connections between these entities is of historical, scientific, and practi-cal interest. However, describing every relationship for large, real-world corpora is infeasible. Thus most data sets label edges as merely on or off, or with a small set of fixed, pre-defined connection types. These labellings cannot capture the complexities underlying the relationships and limit the applicability of these data sets.

In this paper we develop a method for augmenting such data sets by analyzing document collections to uncover the relationships encoded in their texts. Text corpora are re-plete with information about relationships, but this infor-mation is out of reach for traditional network analysis tech-niques. We develop Networks Uncovered By Bayesian Infer-ence (Nubbi), a probabilistic topic model of text [5, 12, 30] with hidden variables that represent the patterns of word use which describes the relationships in the text. Given a collection of documents, Nubbi reveals the hidden network of relationships that is encoded in the texts by associating rich descriptions with each entity and its connections. For example, Figure 1 illustrates a subset of the network un-covered from the texts of Wikipedia. Connections between people are depicted by edges, each of which is associated with words that describe the relationship.

First, we describe the intuitions and statistical assump-tions behind Nubbi. Second, we derive efficient algorithms for using Nubbi to analyze large document collections. Fi-nally, we apply Nubbi to the Bible, Wikipedia, and scientific abstracts. We demonstrate that Nubbi can discover sensi-ble descriptions of the network and can make predictions competitive with those made by state of the art models.
The goal of Nubbi is to analyze a corpus to describe the relationships between pairs of entities. Nubbi takes as in-put very lightly annotated data, requiring only that entities within the input text be identified. Nubbi also takes as input the network of entities to be annotated. For some corpora this network is already explicitly encoded as a graph. For http://topics.cs.princeton.edu/nubbi . right panel is repeated for every pair of entities. other text corpora this graph must be constructed. One sim-ple way of constructing this graph is to use a fully-connected network of entities and then prune the edges in this graph using statistics such as entity co-occurrence counts.
From the entities in this network, the text is divided into two different classes of bags of words. First, each entity is associated with an entity context , a bag of words co-located with the entity. Second, each pair of entities is associated with a pair context , a bag of words co-located with the pair. Figure 2 shows an example of the input to the algorithm turned into entity contexts and pair contexts.

Nubbi learns two descriptions of how entities appear in the corpus: entity topics and relationship topics. Following [5], a topic is defined to be a distribution over words. To aid intuitions, we will for the moment assume that these topics are given and have descriptive names. We will describe how the topics and contexts interplay to reveal the network of relationships hidden in the texts. We emphasize, however, that the goal of Nubbi is to analyze the texts to learn both the topics and relationships between entities.

An entity topic is a distribution over words, and each entity is associated with a distribution over entity topics. For example, suppose there are three entity topics: tics , movies , and sports . Ronald Reagan would have a distribution that favors politics and movies , athlete ac-tors like Johnny Weissmuller and Geena Davis would have distributions that favor movies and sports , and special-ized athletes, like Pel  X e, would have distributions that favor sports more than other entity topics. Nubbi uses entity topics to model entity contexts. Because the sports entity topic would contain words like  X  X up, X  X  X in, X  and  X  X oal, X  asso-ciating Pel  X e exclusively with the sports entity topic would be consistent with the words observed in his context.
Relationship topics are distributions over words associ-ated with pairs of entities, rather than individual entities, and each pair of entities is associated with a distribution over relationship topics. Just as the entity topics cluster similar people together (e.g., Ronald Reagan, George Bush, and Bill Clinton all express the politics topic), the relation-ship topics can cluster similar pairs of people. Thus, Romeo and Juliet, Abelard and Heloise, Ruslan and Ludmilla, and Izanami and Izanagi might all share a lovers relationship topic.

Relationship topics are used to explain pair contexts. Each word in a pair context is assumed to express something about either one of the participating entities or something particular to their relationship. For example, consider Jane Wyman and Ronald Reagan. (Jane Wyman, an actress, was actor/president Ronald Reagan X  X  first wife.) Individu-ally, Wyman is associated with the movies entity topic and Reagan is associated with the movies and politics entity topics. In addition, this pair of entities is associated with relationship topics for divorce and costars .

Nubbi hypothesizes that each word describes either one of the entities or their relationship. Consider the pair context for Reagan and Wyman: We have marked the words that are not associated with the relationship topic. Functional words are gray; words that come from a politics topic (associated with Ronald Reagan) are underlined ; and words that come from a movies topic (associated with Jane Wyman) are italicized .
The remaining words,  X 1938, X  X  X o-starred, X  X  X ngaged, X  X  X len-dale, X   X  X iled, X   X  X ivorce, X   X 1948, X   X  X ivorced, X  and  X  X x-wife, X  describe the relationship between Reagan and Wyman. In-deed, it is by deducing which case each word falls into that Nubbi is able to capture the relationships between entities. Examining the relationship topics associated with each pair of entities provides a description of that relationship. The above discussion gives an intuitive picture of how Nubbi explains the observed entity and pair contexts using entity and relationship topics. In data analysis, however, we do not observe the entity topics, pair topics, or the assign-ments of words to topics. Our goal is to discover them.
To do this, we formalize these notions in a generative prob-abilistic model of the texts that uses hidden random vari-ables to encode the hidden structure described above. In posterior inference , we  X  X everse X  the process to discover the latent structure that best explains the documents. (Poste-rior inference is described in the next section.) More for-mally, Nubbi assumes the following statistical model. 1. For each entity topic j and relationship topic k , 2. For each entity e , 3. For each pair of entities e,e 0 , This is depicted in a graphical model in Figure 3.

The hyperparameters of the Nubbi model are Dirichlet pa-rameters  X   X  ,  X   X  , and  X   X  , which govern the entity topic dis-tributions, the relationship distributions, and the entity/pair mixing proportions. The Dirichlet parameters  X   X  and  X   X  priors for each topic X  X  multinomial distribution over terms. There are K  X  per-topic term distributions for entity topics,  X  1: K  X  , and K  X  per-topic term distributions  X  tionship topics.

The words of each entity context are essentially drawn from an LDA model using the entity topics. The words of each pair context are drawn in a more sophisticated way. The topic assignments for the words in the pair context for entity e and entity e 0 are hypothesized to come from the entity topic proportions  X  e , entity topic proportions  X  relationship topic proportions  X  e,e 0 . The switching variable c e,e 0 ,n selects which of these three assignments is used for each word. This selector c e,e 0 ,n is drawn from  X  e,e 0 describes the tendency of words associated with this pair of entities to be ascribed to either of the entities or the pair.
It is  X  e,e 0 that describes what the relationship between entities e and e 0 is. By allowing some of each pair X  X  context words to come from a relationship topic distribution, the model is able to characterize each pair X  X  interaction in terms of the latent relationship topics.
With the model formally defined in terms of hidden and observed random variables, we now turn to deriving the al-gorithms needed to analyze data. Data analysis involves inferring the hidden structure from observed data and mak-ing predictions on future data. In this section, we develop a variational inference procedure for approximating the pos-terior. We then use this procedure to develop a variational expectation-maximization (EM) algorithm for parameter es-timation and for approximating the various predictive dis-tributions of interest.
In posterior inference, we approximate the posterior dis-tribution of the latent variables conditioned on the obser-vations. As for LDA, exact posterior inference for Nubbi is intractable [5]. We appeal to variational methods.
Variational methods posit a family of distributions over the latent variables indexed by free variational parameters. Those parameters are then fit to be close to the true poste-rior, where closeness is measured by relative entropy. See [13]  X  for a review. We use the factorized family where  X   X  is a set of Dirichlet parameters, one for each en-tity;  X   X  and  X   X  are sets of Dirichlet parameters, one for each pair of entities;  X   X  is a set of multinomial parameters, one for each word in each entity;  X  is a set of multinomial parameters, one for each pair of entities; and  X   X  is a set of matrices, one for each word in each entity pair. Each  X   X  contains three rows  X  one which defines a multinomial over topics given that the word comes from  X  e , one which defines a multinomial given that the word comes from  X  e 0 , and one which defines a multinomial given that the word comes from  X  e,e 0 . Note that the variational family we use is not the fully-factorized family; this family fully captures the joint distribution of z e,e 0 ,n and c e,e 0 ,n . We parameterize this pair by  X   X  e,e 0 ,n and  X  e,e 0 ,n which define a multinomial distribution over all 3 K possible values of this pair of variables.
Minimizing the relative entropy is equivalent to maximiz-ing the Jensen X  X  lower bound on the marginal probability of the observations, i.e., the evidence lower bound (ELBO), where sums over e,e 0 iterate over all pairs of entities and and The L e,e 0 term of the ELBO differentiates this model from previous models [5]. The connections between entities affect the objective in posterior inference (and, below, in parame-ter estimation).

Our aim now is to compute each term of the objective function given in Equation 1. After expanding this expres-sion in terms of the variational parameters, we can derive a set of coordinate ascent updates to optimize the ELBO with respect to the variational parameters,  X   X  ,  X   X  ,  X   X  ,  X  Because of space limitations, we must refer the reader to the longer version of this paper for a full derivation of the fol-lowing updates.

The updates for  X   X  e,n assign topic proportions to each word associated with an individual entity, where log  X   X  w n represents the logarithm of column w n of  X  and  X  (  X  ) is the digamma function. (A digamma of a vector is the vector of digammas.) The topic assignments for each word associated with a pair of entities are similar,  X   X   X  where  X  e,e 0 ,n is a vector of normalizing constants. These normalizing constants are then used to estimate the prob-ability that each word associated with a pair of entities is assigned to either an individual or relationship, The topic and entity assignments are then used to estimate the variational Dirichlet parameters which parameterize the latent topic and entity proportions, Finally, the topic and entity assignments for each pair of entities along with the topic assignments for each individual entity are used to update the variational Dirichlet parame-ters which govern the latent topic assignments for each indi-vidual entity. These updates allow us to combine evidence associated with individual entities and evidence associated with entity pairs.
We fit the model by finding maximum likelihood estimates for each of the parameters:  X  e,e 0 ,  X   X  1: K and  X   X  1: K this is intractable so we turn to an approximation. We em-ploy variational expectation-maximization, where we iterate between optimizing the ELBO of Equation 1 with respect to the variational distribution and with respect to the model parameters.

Optimizing with respect to the variational distribution is described in Section 3.1. Optimizing with respect to the model parameters is equivalent to maximum likelihood esti-mation with expected sufficient statistics, where the expec-tation is taken with respect to the variational distribution. The sufficient statistics for the topic vectors  X   X  and  X  sist of all topic-word pairs in the corpus, along with their entity or relationship assignments. Collecting these statis-tics leads to the following updates,
The sufficient statistics for  X  e,e 0 are the number of words ascribed to the first entity, the second entity, and the rela-tionship topic. This results in the update
With a fitted model, we can make judgments about how well the model describes the joint distribution of words as-sociated with previously unseen data. In this section we describe two prediction tasks that we use to compare Nubbi to other models: word prediction and entity prediction.
In word prediction, the model predicts an unseen word as-sociated with an entity pair given the other words associated with that pair, p ( w e,e 0 ,i | w e,e 0 ,  X  i ). This quantity cannot be computed tractably. We instead turn to a variational ap-proximation of this posterior, Here we have replaced the expectation over the true poste-tribution q ( z e,e 0 ,i ) whose parameters are trained by maxi-mizing the evidence bound given w e,e 0 ,  X  i .

In entity prediction, the model must predict which entity pair a set of words is most likely to appear in. By Bayes X  rule, the posterior probability of an entity pair given a set of words is proportional to the probability of the set of words belonging to that entity pair, where the proportionality constant is chosen such that the sum of this probability over all entity pairs is equal to one.
After a qualitative examination of the topics learned from corpora, we use these two prediction methods to compare Nubbi against other models that offer probabilistic frame-works for associating entities with text in Section 4.2.
In this section, we describe a qualitative and quantitative study of Nubbi on three data sets: the bible (characters in the bible), biological (genes, diseases, and proteins in sci-entific abstracts), and wikipedia . For these three corpora, the entities of interest are already annotated. Experts have marked all mentions of people in the Bible [23] and biolog-ical entities in corpora of scientific abstracts [26, 31], and Wikipedia X  X  link structure offers disambiguated mentions. Note that it is also possible to use named entity recogniz-ers to preprocess data for which entities are not previously identified.

The first step in our analysis is to determine the entity and pair contexts. For bible , verses offer an atomic context; any term in a verse with an entity (pair) is associated with that entity (pair). For biological , we use tokens within a fixed distance from mentions of an entity (pair) to build the data used by our model. For wikipedia , we used the same approach as biological for associating words with entity pairs. We associated with individual entities, however, all the terms in his/her Wikipedia entry. For all corpora we removed tokens based on a stop list and stemmed all tokens using the Porter stemmer. Infrequent tokens, entities, and pairs were pruned from the corpora. 1
We first demonstrate that the Nubbi model produces in-terpretable entity topics that describe entity contexts and re-lationship topics that describe pair contexts. We also show that by combining Nubbi X  X  model of language with a net-work automatically estimated through co-occurrence counts, we can construct rich social networks with labeled relation-ships.

Table 1 shows some of the relationship topics learned from the Bible data. (This model has five entity topics and five
After preprocessing, the bible dataset contains a lexicon of size 2411, 523 entities, and 475 entity pairs. The biological dataset contains a lexicon of size 2425, 1566 entities, and 577 entity pairs. The wikipedia dataset contains a lexicon of size 9144, 1918 entities, and 429 entity pairs. Table 1: Examples of relationship topics learned by a five topic Nubbi model trained on the Bible. The upper part of the table shows some of the entity pairs highly associated with that topic. The lower part of the table shows the top terms in that topic X  X  multinomial. relationship topics.) Each column shows the words with the highest weight in that topic X  X  multinomial parameter vector, and above each column are examples of entity pairs associ-ated with that topic. In this example, Relationship Topic 1 corresponds to blood relations, and Relationship Topic 2 refers to antagonists. We emphasize that this structure is uncovered by analyzing the original texts. No prior knowl-edge of the relationships between characters is used in the analysis.

In a more diverse corpus, Nubbi learns broader topics. In a twenty-five topic model trained on the Wikipedia data, the entity topics broadly apply to entities across many time periods and cultures. Artists, monarchs, world politicians, people from American history, and scientists each have a representative topic (see Table 2).

The relationship topics further restrict entities that are specific to an individual country or period (Table 3). In some cases, relationship topics narrow the focus of broader entity topics. For instance, Relationship Topics 1, 5, 6, 9, and 10 in Table 3 help explain the specific historical context of pairs better than the very broad world leader entity Topic 7.
In some cases, these distinctions are very specific. For ex-ample, Relationship Topic 6 contains pairs of post-Hanoverian monarchs of Great Britain and Northern Ireland, while Rela-tionship Topic 5 contains relationships with pre-Hanoverian monarchs of England even though both share words like  X  X ueen X  and  X  X hrone. X  Note also that these topics favor words like  X  X ather X  and  X  X aughter, X  which describe the re-lationships present in these pairs.

The model sometimes groups together pairs of people from radically different contexts. For example, Relationship Topic 8 groups composers with religious scholars (both share terms like  X  X ass X  and  X  X atron X ), revealing a drawback of using a unigram-based method. As another example, Relationship Topic 3 links civil war generals and early Muslim leaders.
The qualitative results of the previous section illustrate that Nubbi is an effective model for exploring and under-standing latent structure in data. In this section, we provide a quantitative evaluation of the predictive mechanisms that Nubbi provides.

As with any probabilistic model, Nubbi defines a proba-bility distribution over unseen data. After fitting the latent variables of our model to data (as described in Section 3.1), we take unseen pair contexts and ask how well the model pre-dicts those held-out words. Models that give higher prob-ability to the held-out words better capture how the two entities participating in that context interact. In a compli-mentary problem, we can ask the fitted model to predict entities given the words in the pair context. (The details of these metrics are defined more precisely in Section 3.3.)
We compare Nubbi to three alternative approaches: a un-igram model, LDA [5], and the Author-Topic model [28]. All of these approaches are models of language which treat in-dividual entities and pairs of entities alike as bags of words. In the Author-Topic model [28], entities are associated with individual contexts and pair contexts, but there are no dis-tinguished pair topics; all words are explained by the topics associated with individuals. In addition, we also compare the model against two baselines: a unigram model (equiv-alent to using no relationship topics and one entity topic) and a mutual information model (equivalent to using one relationship topic and one entity topic).

We use the bootstrap method to create held-out data sets and compute predictive probability [10]. Figure 4 shows the average predictive log likelihood for the three approaches. The results for Nubbi are plotted as a function of the total number of topics K = K  X  + K  X  . The results for LDA and author-topic were also computed with K topics. All models were trained with the same hyperparameters.

Nubbi outperforms both LDA and unigram on all corpora for all numbers of topics K . For word prediction Nubbi performs comparably to Author-Topic on bible , worse on bi-ological , and better on wikipedia . We posit that because the wikipedia corpus contains more tokens per entity and pair of entities, the Nubbi model is able to leverage more data to make better word predictions. Conversely, for biological , individual entities explain pair contexts better than rela-tionship topics, giving the advantage to Author-Topic. For wikipedia , this yields a 19% improvement in average word log likelihood over the unigram model at K = 24.

In contrast, the LDA model is unable to make improved predictions over the unigram model. There are two reasons for this. First, LDA cannot use information about the par-ticipating entities to make predictions about the pair, be-cause it treats entity contexts and pair contexts as indepen-dent bags of words. Second, LDA does not allocate topics to describe relationships alone, whereas Nubbi does learn top-ics which express relationships. This allows Nubbi to make more accurate predictions about the words used to describe relationships. When relationship words do find their way into LDA topics, LDA X  X  performance improves, such as on the bible dataset. Here, LDA obtains a 6% improvement over unigram while Nubbi achieves a 10% improvement.
With the exception of Author-Topic on biological , Nubbi outperforms the other all the other approaches on the en-tity prediction task. For example, on wikipedia , the Nubbi model shows a 32% improvement over the unigram base-line, LDA shows a 7% improvement, and Author-Topic ac-tually performs worse than the unigram baseline. While LDA, Author-Topic, and Nubbi improve monotonically with the number of topics on the word task, they can peak and decrease for the entity prediction task. Recall that an im-proved word likelihood need not imply an improved entity likelihood; if a model assigns a higher word likelihood to other entity pairs in addition to the correct entity pair, the predictive entity likelihood may still decrease. Thus, while each held-out context is associated with a particular pair of entities, it does not follow that that same context could not also be aptly associated with some other entity pair. category.
 these relationships is shown in Figure 1. predict what words occur). Higher is better.
We presented Nubbi, a novel machine learning approach for analyzing free text to extract descriptions of relationships between entities. We applied Nubbi to three corpora X  X he Bible, Wikipedia, and scientific abstracts. We showed that Nubbi provides a state-of-the-art predictive model of entities and relationships and, moreover, is a useful exploratory tool for discovering and understanding network data hidden in plain text.

Analyzing networks of entities has a substantial history [34]; recent work has focused in particular on clustering and com-munity structure [2, 6, 11, 18, 25], deriving models for so-cial networks [15, 16, 19, 32], and applying these analyses to predictive applications [35]. Latent variable approaches to modeling social networks with associated text have also been explored [17, 20, 22, 33]. While the space of potential applications for these models is rich, it is tempered by the need for observed network data as input. Nubbi allows these techniques to augment their network data by leveraging the large body of relationship information encoded in collections of free text.

Previous work in this vein has used either pattern-based approaches or co-occurrence methods. The pattern-based approaches [1, 9, 21, 29] and syntax based approaches [3, 14] require patterns or parsers which are meticulously hand-crafted, often fragile, and typically need several examples of desired relationships limiting the type of relationships that can be discovered. In contrast, Nubbi makes minimal as-sumptions about the input text, and is thus practical for languages and non-linguistic data where parsing is not avail-able or applicable. Co-occurrence methods [7, 8] also make minimal assumptions. However, because Nubbi draws on topic modeling [5], it is able to uncover hidden and seman-tically meaningful groupings of relationships. Through the distinction between relationship topics and entity topics, it can better model the language used to describe relationships.
Finally, while other models have also leveraged the ma-chinery of LDA to understand ensembles of entities and the words associated with them [4, 24, 28] these models only learn hidden topics for individual entities. Nubbi models individual entities and pairs of entities distinctly. By con-trolling for features of individual entities and explicitly re-lationships, Nubbi yields more powerful predictive models and can discover richer descriptions of relationships. We would like to thank David Petrou, Bill Schillit, Casey Whitelaw, and Ryan MacDonald for their advice and sup-port during the development of this work. David M. Blei is supported by ONR 175-6343, NSF CAREER 0745520, and grants from Google and Microsoft. [1] E. Agichtein and L. Gravano. Querying text databases [2] A. Anagnostopoulos, R. Kumar, and M. Mahdian.
 [3] M. Banko, M. J. Cafarella, S. Soderland, [4] I. Bhattacharya, S. Godbole, and S. Joshi. Structured [5] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet [6] D. Cai, Z. Shao, X. He, X. Yan, and J. Han. Mining [7] A. Culotta, R. Bekkerman, and A. McCallum.
 [8] D. Davidov, A. Rappoport, and M. Koppel. Fully [9] C. Diehl, G. M. Namata, and L. Getoor. Relationship [10] B. Efron. Estimating the error rate of a prediction [11] D. Gibson, J. Kleinberg, and P. Raghavan. Inferring [12] T. Hofmann. Probabilistic latent semantic indexing. [13] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and [14] S. Katrenko and P. Adriaans. Learning relations from [15] J. Leskovec, L. Backstrom, R. Kumar, and [16] J. Leskovec, K. Lang, A. Dasgupta, and M. Mahoney. [17] A. McCallum, A. Corrada-Emmanuel, and X. Wang. [18] A. McGovern, L. Friedland, M. Hay, B. Gallagher, [19] E. Meeds, Z. Ghahramani, R. Neal, and S. Roweis. [20] Q. Mei, D. Cai, D. Zhang, and C. Zhai. Topic [21] Q. Mei, D. Xin, H. Cheng, J. Han, and C. Zhai. [22] R. Nallapati, A. Ahmed, E. P. Xing, and W. W. [23] O. J. Nave. Nave X  X  Topical Bible . Thomas Nelson, [24] D. Newman, C. Chemudugunta, and P. Smyth.
 [25] M. E. J. Newman. Modularity and community [26] T. Ohta, Y. Tateisi, and J.-D. Kim. Genia corpus: an [27] M. Rabbat, M. Figueiredo, and R. Nowak. Inferring [28] M. Rosen-Zvi, T. Griffiths, T. Griffiths, M. Steyvers, [29] S. Sahay, S. Mukherjea, E. Agichtein, E. Garcia, [30] M. Steyvers and T. Griffiths. Probabilistic topic [31] L. Tanabe, N. Xie, L. H. Thom, W. Matten, and [32] B. Taskar, M.-F. Wong, P. Abbeel, and D. Koller. [33] X. Wang, N. Mohanty, and A. McCallum. Group and [34] S. Wasserman and P. Pattison. Logit models and [35] D. Zhou, S. Zhu, K. Yu, X. Song, B. Tseng, H. Zha,
