 Part-of-speech (POS) tagging is needed as a pre-processor for various natural language processing (NLP) tasks such as parsing, named entity recogni-tion (NER), and text chunking. Since POS tagging is normally performed in the early step of NLP tasks, the errors in POS tagging are critical in that they affect subsequent steps and often lower the overall performance of NLP tasks.

Previous studies on POS tagging have shown high performance with machine learning techniques (Ratnaparkhi, 1996; Brants, 2000; Lafferty et al., 2001). Among the types of machine learning ap-proaches, supervised machine learning techniques were commonly used in early studies on POS tag-ging. With the characteristics of a language (Rat-naparkhi, 1996; Kudo et al., 2004) and informa-tive features for POS tagging (Toutanova and Man-ning, 2000), the state-of-the-art supervised POS tag-ging achieves over 97% of accuracy (Shen et al., 2007; Manning, 2011). This performance is gen-erally regarded as the maximum performance that can be achieved by supervised machine learning techniques. There have also been many studies on POS tagging with semi-supervised (Subramanya et al., 2010; S X gaard, 2011) or unsupervised machine learning methods (Berg-Kirkpatrick et al., 2010; Das and Petrov, 2011) recently. However, there still exists room to improve supervised POS tagging in terms of error differentiation.

It should be noted that not all errors are equally important in POS tagging. Let us consider the parse trees in Figure 1 as an example. In Figure 1(a), the word  X  plans  X  is mistagged as a noun where it should be a verb. This error results in a wrong parse tree that is severely different from the correct tree shown in Figure 1(b). The verb phrase of the verb  X  plans  X  in Figure 1(b) is discarded in Figure 1(a) and the whole sentence is analyzed as a single noun phrase. Figure 1(c) and (d) show another tagging er-ror and its effect. In Figure 1(c), a noun is tagged as a NNS (plural noun) where its correct tag is NN (sin-gular or mass noun). However, the error in Figure 1(c) affects only locally the noun phrase to which  X  physics  X  belongs. As a result, the general structure of the parse tree in Figure 1(c) is nearly the same as the correct one in Figure 1(d). That is, a sentence analyzed with this type of error would yield a cor-rect or near-correct result in many NLP tasks such as machine translation and text chunking.

The goal of this paper is to differentiate the seri-ous POS tagging errors from the minor errors. POS tagging is generally regarded as a classification task, and zero-one loss is commonly used in learning clas-sifiers (Altun et al., 2003). Since zero-one loss con-siders all errors equally, it can not distinguish error types. Therefore, a new loss is required to incorpo-rate different error types into the learning machines.
This paper proposes two gradient loss functions to reflect differences among POS tagging errors. The functions assign relatively small cost to minor er-rors, while larger cost is given to serious errors. They are applied to learning multiclass support vec-tor machines (Tsochantaridis et al., 2004) which is trained to minimize the serious errors. Overall accu-racy of this SVM is not improved against the state-of-the-art POS tagger, but the serious errors are sig-nificantly reduced with the proposed method. The effect of the fewer serious errors is shown by apply-ing it to the well-known NLP task of text chunking. Experimental results show that the proposed method achieves a higher F1-score compared to other POS taggers.

The rest of the paper is organized as follows. Sec-tion 2 reviews the related studies on POS tagging. In Section 3, serious and minor errors are defined, and it is shown that both errors are observable in a gen-eral corpus. Section 4 proposes two new loss func-tions for discriminating the error types in POS tag-ging. Experimental results are presented in Section 5. Finally, Section 6 draws some conclusions. The POS tagging problem has generally been solved by machine learning methods for sequential label-ing. In early studies, rich linguistic features and su-pervised machine learning techniques are applied by using annotated corpora like the Wall Street Journal corpus (Marcus et al., 1994). For instance, Ratna-parkhi (1996) used a maximum entropy model for POS tagging. In this study, the features for rarely appearing words in a corpus are expanded to im-prove the overall performance. Following this direc-tion, various studies have been proposed to extend informative features for POS tagging (Toutanova and Manning, 2000; Toutanova et al., 2003; Man-ning, 2011). In addition, various supervised meth-ods such as HMMs and CRFs are widely applied to POS tagging. Lafferty et al. (2001) adopted CRFs to predict POS tags. The methods based on CRFs not only have all the advantages of the maximum entropy markov models but also resolve the well-known problem of label bias. Kudo et al. (2004) modified CRFs for non-segmented languages like Japanese which have the problem of word boundary ambiguity.

As a result of these efforts, the performance of state-of-the-art supervised POS tagging shows over 97% of accuracy (Toutanova et al., 2003; Gim  X enez and M`arquez, 2004; Tsuruoka and Tsujii, 2005; Shen et al., 2007; Manning, 2011). Due to the high accuracy of supervised approaches for POS tagging, it has been deemed that there is no room to im-prove the performance on POS tagging in supervised manner. Thus, recent studies on POS tagging focus on semi-supervised (Spoustov  X a et al., 2009; Sub-ramanya et al., 2010; S X gaard, 2011) or unsuper-vised approaches (Haghighi and Klein, 2006; Gold-water and Griffiths, 2007; Johnson, 2007; Graca et al., 2009; Berg-Kirkpatrick et al., 2010; Das and Petrov, 2011). Most previous studies on POS tag-ging have focused on how to extract more linguistic features or how to adopt supervised or unsupervised approaches based on a single evaluation measure, accuracy . However, with a different viewpoint for errors on POS tagging, there is still some room to improve the performance of POS tagging for subse-quent NLP tasks, even though the overall accuracy can not be much improved.

In ordinary studies on POS tagging, costs of er-rors are equally assigned. However, with respect to the performance of NLP tasks relying on the re-sult of POS tagging, errors should be treated differ-ently. In the machine learning community, cost sen-sitive learning has been studied to differentiate costs among errors. By adopting different misclassifica-tion costs for each type of errors, a classifier is op-timized to achieve the lowest expected cost (Elkan, 2001; Cai and Hofmann, 2004; Zhou and Liu, 2006). The effects of POS tagging errors to subsequent NLP tasks vary according to their type. Some errors are serious, while others are not. In this paper, the seriousness of tagging errors is determined by cat-egorical structures of POS tags. Table 1 shows the Penn tree bank POS tags and their categories. There are five categories in this table: substantive , pred-icate , adverbial , determiner , and etc . Serious tag-ging errors are defined as misclassifications among the categories, while minor errors are defined as mis-classifications within a category. This definition fol-lows the fact that POS tags in the same category form similar syntax structures in a sentence (Zhao and Marcus, 2009). That is, inter-category errors are treated as serious errors, while intra-category errors are treated as minor errors.

Table 2 shows the distribution of inter-category and intra-category errors observed in section 22 X  24 of the WSJ corpus (Marcus et al., 1994) that is tagged by the Stanford Log-linear Part-Of-Speech Tagger (Manning, 2011) (trained with WSJ sections 00 X 18). In this table, bold numbers denote inter-category errors while all other numbers show intra-category errors. The number of total errors is 3,471 out of 129,654 words. Among them, 1,881 errors (54.19%) are intra-category, while 1,590 of the er-rors (45.81%) are inter-category. If we can reduce these inter-category errors under the cost of mini-mally increasing intra-category errors, the tagging results would improve in quality.

Generally in POS tagging, all tagging errors are regarded equally in importance. However, inter-category and intra-category errors should be distin-guished. Since a machine learning method is opti-mized by a loss function, inter-category errors can be efficiently reduced if a loss function is designed to handle both types of errors with different cost. We propose two loss functions for POS tagging and they are applied to multiclass Support Vector Machines. POS tagging has been solved as a sequential labeling problem which assumes dependency among words. However, by adopting sequential features such as POS tags of previous words, the dependency can be partially resolved. If it is assumed that words are independent of one another, POS tagging can be re-garded as a multiclass classification problem. One of the best solutions for this problem is by using an SVM. 4.1 Training SVMs with Loss Function Assume that a training data set D = { ( x 1 , y 1 ) , ( x 2 , y 2 ) , . . . , ( x l , y l ) } x is its class label. SVM finds an optimal hyperplane satisfying where w and b are parameters to be estimated from training data D . To estimate the parameters, SVMs minimizes a hinge loss defined as With regularizer || w || 2 to control model complexity, the optimization problem of SVMs is defined as subject to where C is a user parameter to penalize errors. Crammer et al. (2002) expanded the binary-class SVM for multiclass classifications. In multiclass SVMs, by considering all classes the optimization of SVM is generalized as with constraints ( w y where  X  ( x of x i and y i , and K is the set of classes.
Since both binary and multiclass SVMs adopt a hinge loss, the errors between classes have the same cost. To assign different cost to different errors, Tsochantaridis et al. (2004) proposed an efficient way to adopt arbitrary loss function, L ( y returns zero if y Then, the hinge loss  X  of the additional loss between two classes. By scal-ing slack variables with the inverse loss, margin vi-olation with high loss L ( y stricted than that with low loss. Thus, the optimiza-tion problem with L ( y with constraints ( w y i  X   X  ( x i , y i ))  X  ( w k  X   X  ( x i , k ))  X  1  X 
With the Lagrange multiplier  X  , the optimization problem in Equation (1) is easily converted to the following dual quadratic problem.
J ( x i , y i , k i ) J ( x j , y j , k j )  X  with constraints  X   X  0 and X where J ( x 4.2 Loss Functions for POS tagging To design a loss function for POS tagging, this paper adopts categorical structures of POS tags. The sim-plest way to reflect the structure of POS tags shown in Table 1 is to assign larger cost to inter-category errors than to intra-category errors. Thus, the loss function with the categorical structure in Table 1 is defined as L ( y i , y j ) = where 0 &lt;  X  &lt; 1 is a constant to reduce the value of L ( y i , y j ) when y i and y j are similar. As shown in this equation, inter-category errors have larger cost than intra-category errors. This loss L named as category loss .

The loss function L the categories in Table 1. However, the structure of POS tags can be represented as a more complex structure. Let us consider the category, predicate . This category has ten POS tags, and can be further categorized into two sub-categories: verb and ad-ject . Figure 2 represents a categorical structure of POS tags as a tree with five categories of POS tags and their seven sub-categories.

To express the tree structure of Figure 2 as a loss, another loss function L
L t ( y i , y j ) = where P both y turns the number of steps from P parameter  X  is a scaling factor of a unit loss for a single step. This loss L if the distance between y structure, and it is named as tree loss .

As shown in Equation (1), two proposed loss functions adjust margin violation between classes. They basically assign less value for intra-category errors than inter-category errors. Thus, a classi-fier is optimized to strictly keep inter-category er-rors within a smaller boundary. Figure 3 shows a simple example. In this figure, there are three POS tags and two categories. NN (singular or mass noun) and NNS (plural noun) belong to the same cate-gory, while VB (verb, base form) is in another cat-egory. Figure 3(a) shows the decision boundary of NN based on hinge loss. As shown in this figure, a single  X  is applied for the margin violation among all classes. Figure 3(b) also presents the decision boundary of NN, but it is determined with the pro-posed loss function. In this figure, the margin vio-lation is applied differently to inter-category (NN to VB) and intra-category (NN to NNS) errors. It re-sults in reducing errors between NN and VB even if the errors between NN and NNS could be slightly increased. 5.1 Experimental Setting Experiments are performed with a well-known stan-dard data set, the Wall Street Journal (WSJ) corpus. The data is divided into training, development and test sets as in (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Table 3 shows some simple statistics of these data sets. As shown in this table, training data contains 38,219 sentences with 912,344 words. In the development data set, there are 5,527 sentences with about 131,768 words, those in the test set are 5,462 sentences and 129,654 words. The development data set is used only to se-lect  X  in Equation (2) and  X  in Equation (3). Table 4 shows the feature set for our experiments. In this table, w tag for the i -th word in a sentence respectively. We use almost the same feature set as used in (Tsuruoka and Tsujii, 2005) including word features, tag fea-tures, word/tag combination features, prefix and suf-fix features as well as lexical features. The POS tags for words are obtained from a two-pass approach proposed by Nakagawa et al. (2001).

In the experiments, two multiclass SVMs with the proposed loss functions are used. One is CL-MSVM with category loss and the other is TL-MSVM with tree loss. A linear kernel is used for both SVMs. 5.2 Experimental Results CL-MSVM with  X  = 0 . 4 shows the best overall per-formance on the development data where its error rate is as low as 2.71%.  X  = 0 . 4 implies that the cost of intra-category errors is set to 40% of that of inter-category errors. The error rate of TL-MSVM is 2.69% when  X  is 0.6.  X  = 0.4 and  X  = 0.6 are set in the all experiments below.

Table 5 gives the comparison with the previous work and proposed methods on the test data. As can be seen from this table, the best performing algo-rithms achieve near 2.67% error rate (Shen et al., 2007; Manning, 2011). CL-MSVM and TL-MSVM achieve an error rate of 2.69% and 2.68% respec-tively. Although overall error rates of CL-MSVM and TL-MSVM are not improved compared to the previous state-of-the-art methods, they show reason-able performance.

For inter-category error, CL-MSVM achieves the best performance. The number of inter-category er-ror is 1,567, which shows 23 errors reduction com-pared to previous best inter-category result by (Man-ning, 2011). TL-MSVM also makes 16 less inter-category errors than Manning X  X  tagger. When com-pared with Shen X  X  tagger, both CL-MSVM and TL-MSVM make far less inter-category errors even if their overall performance is slightly lower than that of Shen X  X  tagger. However, the intra-category er-ror rate of the proposed methods has some slight increases. The purpose of proposed methods is to minimize inter-category errors but preserving over-all performance. From these results, it can be found that the proposed methods which are trained with the proposed loss functions do differentiate serious and minor POS tagging errors. 5.3 Chunking Experiments The task of chunking is to identify the non-recursive cores for various types of phrases. In chunking, the POS information is one of the most crucial aspects in identifying chunks. Especially inter-category POS errors seriously affect the performance of chunking because they are more likely to mislead the chunk compared to intra-category errors.

Here, chunking experiments are performed with a data set provided for the CoNLL-2000 shared task. The training data contains 8,936 sentences with 211,727 words obtained from sections 15 X 18 of the WSJ. The test data consists of 2,012 sentences and 47,377 words in section 20 of the WSJ. In order to represent chunks, an IOB model is used, where every word is tagged with a chunk label extended with B (the beginning of a chunk), I (inside a chunk), and O (outside a chunk). First, the POS informa-tion in test data are replaced to the result of our POS tagger. Then it is evaluated using trained chunking model. Since CRFs (Conditional Random Fields) has been shown near state-of-the-art performance in text chunking (Fei Sha and Fernando Pereira, 2003; Sun et al., 2008), we use CRF++, an open source CRF implementation by Kudo (2005), with default feature template and parameter settings of the pack-age. For simplicity in the experiments, the values of  X  in Equation (2) and  X  in Equation (3) are set to be 0.4 and 0.6 respectively which are same as the previous section.

Table 6 gives the experimental results of text chunking according to the kinds of POS taggers in-cluding two previous works, CL-MSVM, and TL-MSVM. Shen X  X  tagger and Manning X  X  tagger show nearly the same performance. They achieve an ac-curacy of 96.08% and around 93.9 F1-score. On the other hand, CL-MSVM achieves 96.13% accuracy and 94.00 F1-score. The accuracy and F1-score of TL-MSVM are 96.12% and 94.00. Both CL-MSVM and TL-MSVM show slightly better performances than other POS taggers. As shown in Table 5, both CL-MSVM and TL-MSVM achieve lower accura-cies than other methods, while their inter-category errors are less than that of other experimental meth-ods. Thus, the improvement of CL-MSVM and TL-MSVM implies that, for the subsequent natural lan-guage processing, a POS tagger should considers different cost of tagging errors. In this paper, we have shown that supervised POS tagging can be improved by discriminating inter-category errors from intra-category ones. An inter-category error occurs by mislabeling a word with a totally different tag, while an intra-category error is caused by a similar POS tag. Therefore, inter-category errors affect the performances of subse-quent NLP tasks far more than intra-category errors. This implies that different costs should be consid-ered in training POS tagger according to error types.
As a solution to this problem, we have proposed two gradient loss functions which reflect different costs for two error types. The cost of an error type is set according to (i) categorical difference or (ii) dis-tance in the tree structure of POS tags. Our POS experiment has shown that if these loss functions are applied to multiclass SVMs, they could signif-icantly reduce inter-category errors. Through the text chunking experiment, it is shown that the multi-class SVMs trained with the proposed loss functions which generate fewer inter-category errors achieve higher performance than existing POS taggers.
We have shown that cost sensitive learning can be applied to POS tagging only with multiclass SVMs. However, the proposed loss functions are general enough to be applied to other existing POS taggers. Most supervised machine learning techniques are optimized on their loss functions. Therefore, the performance of POS taggers based on supervised machine learning techniques can be improved by ap-plying the proposed loss functions to learn their clas-sifiers.
 This research was supported by the Converg-ing Research Center Program funded by the Ministry of Education, Science and Technology (2011K000659).

