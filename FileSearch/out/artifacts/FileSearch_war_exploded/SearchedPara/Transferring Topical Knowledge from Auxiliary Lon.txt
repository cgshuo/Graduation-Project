 With the rapid growth of social Web applications such as Twitter and online advertisements, the task of understand-ing short texts is becoming more and more important. Most traditional text mining techniques are designed to handle long text documents. For short text messages, many of the existing techniques are not effective due to the sparseness of text representations. To understand short messages, we observe that it is often possible to find topically related long texts, which can be utilized as the auxiliary data when min-ing the target short texts data. In this article, we present a novel approach to cluster short text messages via transfer learning from auxiliary long text data. We show that while some previous works for enhancing short text clustering with related long texts exist, most of them ignore the semantic and topical inconsistencies between the target and auxil-iary data and may hurt the clustering performance on the short texts. To accommodate the possible inconsistencies between source and target data, we propose a novel topic model -Dual Latent Dirichlet Allocation (DLDA) model, which jointly learns two sets of topics on short and long texts and couples the topic parameters to cope with the potential inconsistencies between data sets. We demonstrate through large-scale clustering experiments on both advertisements and Twitter data that we can obtain superior performance over several state-of-art techniques for clustering short text documents.  X 
Part of this work was done while the first author was a visiting student in Hong Kong University of Science Tech-nology.
 H.3.3 [ Information Storage and retrieval ]: Information Search and Retrieval X  Clustering ; I.2.6 [ Artificial Intelli-gence ]: Learning; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Text analysis Algorithms, Experimentation Short Text, Statistical Generative Models, Unsupervised Learning Short texts play an important role in various emerging Web applications such as online advertisements and micro-blogging. Sponsored search and display advertisements as commonly found on search result pages or general web pages can usually accommodate just a few keywords or sentences. Similarly, the popular micro-blogging service Twitter re-stricts the message length to be less than 140 characters. Effective techniques for mining short texts are crucial to these application domains. While many successful text min-ing techniques have been developed in the past, they have only been designed for and tested on traditional long text corpus such as blogs or newswires. Directly applying these methods on short texts often leads to poor results [12]. Com-pared with long texts, short text mining has to address two inherent difficulties caused by their highly sparse representa-tions: the lack of sufficient word co-occurrence information and the lack of context information in the text.

To alleviate the sparseness of short texts, a common ap-proach is to conduct  X  X seudo relevance feedback X  in order to enrich the original short text corpus with an additional set of auxiliary data consisting of semantically related long texts. This can be achieved by sending the input short texts as queries to a search engine to retrieve a set of most rele-vant results [18]. Another popular method is to match short texts with topics learned from general knowledge reposito-ries such as Wikipedia or ODP [12, 11]. Once the auxiliary data or auxiliary topic is obtained, the data or topics are often directly combined with the original short texts, which are then processed by some traditional text mining models.
While the pseudo relevance feedback based data augmen-tation approach is a promising approach, one should note that such a process is an inherently noisy operation and there is a risk that certain portion of the auxiliary data may in fact be semantically unrelated to the original short texts. Similarly, the unrelated or noisy auxiliary topics may also bring negative result. Therefore, naively combining the short texts with semantically unrelated long texts or topics could hurt the performance on the short texts. The problem can become even more serious for unsupervised learning on short texts as there is no labeling information to guide the selection of auxiliary data and auxiliary topics.

In this paper, we study the problem of enhancing short text clustering by incorporating auxiliary long texts. We propose a class of topic model -Dual Latent Dirichlet Al-location (DLDA), which jointly learns a set of target topics on the short texts and another set of auxiliary topics on the long texts while carefully modeling the attribution to each type of topics when generating documents. In particular, we design and compare two mechanisms for DLDA to accom-modate domain inconsistencies between the two data sets: (1) using two asymmetric priors on the topic mixing pro-portions to control the relative importance of different topic classes for generating short and long texts (2) introducing a latent binary switch variable to control whether each docu-ment should be generated using target or auxiliary topics. Our DLDA model allows topical structure to be shared in a more flexible manner between the collections of short and long texts and could therefore lead to more robust perfor-mance improvement when the auxiliary long texts are only partially related to the input short texts. Clustering exper-iments on two real world data sets consisting of textual ad-vertisements and twitter messages demonstrated consistent improvements over existing methods for short text cluster-ing, especially when there are many irrelevant documents in the auxiliary data set. Due to its importance in popular web applications such as Twitter, short text mining has attracted growing interests in recent years. Hong et al. [4] compared different schemes to train standard topic model on tweets from Twitter. Sri-ram et al. [19] compared some features for classification to conquer the problem coming with the short of tweets. Mi-halcea et al. [8] proposed to measure the similarity of short text snippets by using both corpus-based and knowledge-based measures when acquiring words similarity. Sahami et al. [18] present a novel similarity measure for short text snippets, which utilizes search engines to provide additional context for the given short text, just like query expansion techniques. This similarity measure can also be proven to be a kernel. [21] improved Sahami X  X  work by involving a learning process to make the measure more appropriate for the target corpus. Phan et al. [12, 11] proposed to convert additional knowledge base to topics to improve the repre-sentation of the short texts. The knowledge base is crawled with selected seeds from several topics to avoid noise. Hu et al. [5] proposed a three level framework to utilize both the knowledge from Wikipedia and WordNet. Most of these works focus on how to acquire auxiliary data in order to en-rich short text. They generally make the implicit assump-tion that the auxiliary data are semantically related to the input short texts, which is hardly true in practice due to the noisy nature of the pseudo relevance feedback operation.
A closely related area with our work is that of transfer learning [15] which studies how to transfer knowledge from one related auxiliary domain to the target domain to help the learning task on target domain. However, most exist-ing works in this area focused on supervised [20] or semi-supervised setting [14], whereas we need to solve the problem in a totally unsupervised fashion. A similar setting has been considered by Dai et al. [1], who proposed a co-clustering based solution to enhance clustering on target domain data with the help of an auxiliary data set. However, the model is not designed for handling short texts. Moreover, it makes a strong assumption that the word co-clusters are completely shared between the two domains, which, as we will be shown, is much less effective than our much flexible DLDA model.
Due to its high dimensional yet extremely sparse repre-sentations, clustering short texts directly based on the bag of words representation can be very ineffective as we would demonstrate in the experiments. In this section, we develop a topic modeling based approach to discover some low di-mensional structure that can more effectively capture the semantic relationships between documents. Directly learn-ing topic models on short text is much harder than on tradi-tional long text. For this reason, [12, 11] proposed to train topic models on a collection long text in the same domain and then make inference on short text to help the learn-ing task on short texts. However, in highly dynamic do-mains like Twitter where novel topics and trends constantly emerge, it is not always possible to find strongly related long texts via a search engine or a static knowledge base such as Wikipedia. Furthermore, for application domains like ad-vertisement, short texts and long texts are often used for very different purposes. As a result, they may adopt quite distinct language styles. For example, when merchants ad-vertise a product using short banner Ads, the content often emphasizes on the credibility and price aspects. At the same time, in a Web page for selling the product, merchants may focus more on the branding and product features. Similarly, when comparing Twitter messages and Blog articles posted by the same authors, one can also note significant differences in their content as well as language styles.

In the presence of such inconsistencies between short texts and auxiliary long texts, it would be unreasonable to assume that the topical structure of the two domains is completely identical, as done in several previous works [12, 11, 20]. In this section, we describe a better solution to the problem by designing a novel topic model, referred to as the Dual Latent Dirichlet Allocation (DLDA), which can distinguish between consistent and inconsistent topical structures across domains when learning topics from short texts with an ad-ditional set of auxiliary long texts. In the following sections, we first review the basic LDA model and several related ex-tensions, and then put forward the  X  -DLDA and  X  -DLDA models, which extend the LDA model to cope with domain differences based on two different mechanisms.
Let W tar = { ~w tar m } M tar m =1 denote the set of short texts from the target domain (i.e., domain of interests), which are to be clustered, and let W aux = { ~w aux m } M aux m =1 denote a set of auxiliary documents consisting of long texts. The auxiliary data set could be extracted from general knowledge base, such as Wikipedia, or extracted from some documents rele-vant to the target short texts. In this work, we attempt to transfer the topical knowledge from the auxiliary long texts to help with the unsupervised learning task on target short texts. Any long texts that are topically related to the target short texts can be used as auxiliary data.
A common approach to dealing with data with high di-mensional sparse representation is dimensionality reduction, which has a rich history and literature. A recent trend in di-mensionality reduction is the use of probabilistic models. In particular, Latent Dirichlet Allocation (LDA) is a Bayesian probabilistic graphical model, which models each document as a mixture of underlying topics and generates each word from one topic. The generation process of a document is de-scribed in Table 1, which corresponds to a graphical model as shown in Figure 1. A document ~w d = { w d,n } N d n =1 ciated a document under a specific multinomial distribution Mult ( ~  X  d ) that determines the mixing proportion of differ-ent topics within the document. Then, topic assignment for each word is performed by sampling a particular topic z d,n from a multinomial distribution Mult ( ~  X  d ). Finally, a partic-ular word w d,n is generated by sampling from a multinomial distribution Mult ( ~ X  d,n ) over the words in the corpus.
The LDA model is entirely unsupervised, whereas in many applications one cannot expect to have additional knowledge such as class labels, tags, etc. To incorporate such side infor-mation so as to arm the LDA model with class labels, several extensions of LDA have been proposed by imposing various constraints on the document-specific topic-mixing propor-tions ~  X  d . In the DiscLDA model [7], additional supervisory information in the form of document labels is utilized by learning a class-label dependent linear transformation of with some discriminative criterion.

Similarly, to handle documents annotated with multiple tags such as social bookmarks, the Labeled LDA model [17] learns a topic for each tag and restricts that each document be generated using only those topics corresponding to the set of tags associated with the document. This is achieved by setting a document-specific hyper-parameter vector ~ X  d . The model was later successfully applied on a large collection of twitter messages annotated with hashtags to map the short messages into different categories [16]. Note that although both [16] and our work attempt to apply topic model for characterizing short text document collections, the focus of our works and their objectives are quite different. [16] stud-ies the utility of hashtags, whereas our work is motivated by the use of additional auxiliary long text documents. In practice, both tags and auxiliary long texts are potential data sources that can be exploited. We believe the two ap-proaches are indeed complementary to each other.
Two key ideas are exploited in our work in the DLDA model for coping with domain inconsistencies: 1. We can model two separate sets of topics for auxil-2. We can also use different generative process for aux-To realize the first idea, we can simply split the topics in a LDA model into two groups. In particular, we assume that there are K tar topics with parameters {  X  tar 1 ,..., X  the target domain and K aux topics with parameters {  X  1 ,..., X  aux K aux } in the auxiliary domain.

To realize the second idea, a simple idea is to properly set the hyper-parameter vector ~ X  , which determines the prior distribution for the document specific mixing proportions
Figure 2: Graphical representation of  X  -DLDA ~  X  . Traditionally, without any prior knowledge, the entries of ~ X  are often assumed to be all equal to some small posi-tive value, which corresponds to having no preferences over particular topics. To make the model generate target doc-uments using target topics more often, we can make the entries of ~ X  correspond to the target topics to be greater than those corresponding to auxiliary topics. The same idea can be applied to designate another asymmetric Dirichlet prior for generating the topic mixing proportions for auxil-iary documents. This leads to having two separate asym-metric Dirichlet distributions with parameters and respectively, which corresponds to the generative process de-picted in Figure 2. We refer to this particular variation of DLDA model based on modifying the  X  parameters as the  X  -DLDA model. Note that the inference and learning al-gorithms of the basic LDA model can be easily applied to  X  -DLDA model, which does not change the model structure but only imposes certain settings of the hyperparameters.
The  X  -DLDA model uses asymmetric Dirichlet prior to control the relative importance of target versus auxiliary topics when generating a document. However, the asym-metric Dirichlet prior is imposed on all the documents from each domain. In this section, we develop the  X  -DLDA model, which constrains that each document be generated using ei-ther auxiliary or target topics. This introduces a document-dependent binary-switch variable to be used for choosing between the two types of topics when generating the docu-ment. This new mechanism allows the model to automat-ically capture whether a document should be more related to the target or auxiliary domain.

More specifically, under the  X  -DLDA model, each doc-ument is associated with (1) a binomial distribution over auxiliary topics versus target topics  X  d with Beta prior  X  [  X  aux , X  c tar ] for each corpus c  X  X  aux,tar } , and (2) two multi-nomial distribution over auxiliary topics and target topics  X  aux , X  tar separately, with a symmetric Dirichlet prior  X  . The generative process is shown below, and a graphical rep-resentation of the model is shown in Figure 3.

The Beta prior parameterized by  X  c can be used to capture the prior belief on the consistency between the two domains. Here we constrain that  X  aux aux &gt;  X  aux tar and  X  tar der to ensure that the auxiliary topics and target topics focus more modeling the documents in their respective corpus.
From the generative graphical model, we can write the joint distribution of all known and hidden variables given the hyper parameters:
The likelihood of a document ~w can be obtained by inte-grating out ~  X ,~ X ,  X  and summing over z x m,n : Figure 3: Graphical representation of the proposed  X  -DLDA model
Finally, the likelihood of the whole data set under the
To estimate the parameters, we need to estimate the la-tent variables conditioned on the observed variables; i.e. p ( x , z | w , X , X , X  ), where x , z are vectors of assignments of auxiliary/target topics binary switches and topics for all the words, respectively. We perform approximate inference us-ing Gibbs sampling, a type of Markov Chain Monte Carlo (MCMC) algorithm, with the following updating formulas.
For auxiliary topics z  X  X  1 ,...,K aux } , For target topics z  X  X  1 ,...,K tar } , where n aux,z w,  X  i is the number of times the term w is assigned to an auxiliary topic z . Similarly, n tar,z w,  X  i is the count of w for a target topic z . n aux,z d,  X  i is the number of times a word in document d is assigned to a topic z , while n tar,z d,  X  i is assigned to auxiliary and to target topics, respectively. c denotes the corpus ( aux,tar ) which the current document is Table 3: The statistical information of the two cor-pus ADs 29.06 182209 560.40 99737
TWEETs 9.71 24047 1106.79 4482 drawn from. For all the counts, subscript  X  i indicates that the i-th word is excluded from the computation.

After the Gibbs sampler reaches a burn-in state, we can then harvest samples and count the word assignments in order to estimate the parameters:
After estimating the model parameters and inferring the parameters for new documents, we can represent each doc-ument d by  X  d as: where S x j = P i  X  x i,j ,x  X  X  aux,tar } . We normalize the scale of each feature in order to reduce the importance of some topics that are overly general, such as a topic that represents the functional words and common language. Such topics tend to occur in most documents, but they lack the discrim-inative power.

Another important issue is that we should collect suffi-cient samples of  X  in the sampling. Because the texts are short, the result in one sample may vary much, while the average of multi samples will produce a more robust result. This process may be affected by the label switching problem caused by the MCMC algorithm. But, in practice, we find that this is not a serious problem.

After having the topic based representations for the short text documents, we can apply the traditional clustering meth-ods on them. Since these features have already involved the knowledge from the auxiliary data, clustering on the new representation may achieve better results, as we will demon-strate in the experiments.
In order to evaluate our algorithm DLDA, we conduct experiments on two real data sets, a collection of advertise-ments (ADs) from an online consumer to consumer (C2C) shopping Web site and a collection of tweets (TWEETs) from Twitter.

The short texts in the ADs data set are a collection of text-based display advertisements crawled from an e-commerce Web site of a commercial company. To obtain the auxiliary long texts, we randomly crawled some product web pages listed on the e-commerce site X  X  home page. Each advertise-ment has been labeled with 42 classes according to the prod-uct taxonomy used by the site. To create the TWEETs data set, we crawled 197,535 tweets from 405 Twitter users X  time line. We then filter out 24,047 tweets (12 . 1%) with hashtags (i.e. semantic annotations added by the author of a tweet). In these tweets, there are 4,282 tweets (17 . 8%) containing URLs, we therefore crawled the content of the referenced URLs to form the set of auxiliary long texts. Some statis-tics of these two data sets are shown in the Table 3, from which we can see that the short texts in each data set con-tain a very small fraction of the number of words in the corresponding long texts. Moreover, the short texts in the TWEETs data set contain very few words on average and are much shorter in length when compared with the ADs data set.

We performed standard data preprocessing including stop-word removal on the raw text. For the TWEETs data, we filter out the non-semantic symbols such as mentions of user names (@user), shorted URLs, etc. We also extract hashtags (#tag) from the text, since we rely on the hashtags as the semantic labeling information for evaluating the clustering quality.

It should be noted that our model does not require any correspondence structures between the short texts and the long texts, such as those indicating which tweet contains which URL. This type of correspondence is also not avail-able at all in the ADs data set. The short and long texts in both data sets are of very different nature and are only top-ically related. The crawled Web pages in the ADs data set may not necessarily contain any information related to the products mentioned in the advertisements. Similarly, in the TWEET X  X  data set, the referenced URLs are often news ar-ticles and blogs written by the users themselves, whereas the tweet messages are mostly the users X  subjective comments. Thus, the tweets and the web pages are very likely about the same topics, though the style of the languages can be quite different. In the experiments on the ADs data, we used Entropy , Purity and Normalized Mutual Information (NMI) as the evaluation criterion. Purity is a simple and transparent evaluation measure, which can help us understand the qual-ity of the clustering result directly. Entropy and NMI can be information-theoretically interpreted. NMI allows us to trade off the quality of the clustering against the number of clusters, which the Purity measure cannot achieve. The larger the Purity and NMI values are, the higher the qual-ity of the clustering is. Similarly, a smaller entropy means better performance.

Due to the lack of ground truth of the TWEET X  X  data, we use the hashtags contained in the tweets as their hidden-meaning indicator. Since a lot of tweets are assigned more than one hashtags, we propose to employ Davies-Bouldin Validity Index (DBI) [2] calculated on the hashtags as the evaluation criterion. DBI is a function of the ratio of the sum of within-cluster scatter to between-cluster separation, which is defined as: where n is the number of clusters, Q x is the centroid of cluster x , S n ( Q x ) is the average distance from all elements in cluster x to centroid Q x , and S ( Q i ,Q j ) is the distance between centroids c i and c j . Here we use the Euclidian distance as the distance measure for both functions S and S (  X  ,  X  ). Since the algorithms that produce clusters with Table 4: The performance of all the evaluation meth-ods on ADs low intra-cluster distances (high intra-cluster similarity) and high inter-cluster distances (low inter-cluster similarity) will have a low Davies-Bouldin index, the clustering algorithm that produces a collection of clusters with the smallest DBI is considered the best algorithm based on this criterion. We compare our DLDA with the following methods: Direct Direct clustering method without incorporating aux-LDA-short Learning a LDA from short texts and directly LDA-long Learning a LDA from long texts and then ap-LDA-both Learning a LDA from the combined collection Self-Taught Clustering (STC) This is a state of the art
For LDA-short, LDA-long, LDA-both and our DLDA model, we first build the topic based representations of the short texts following the procedures described in Section 3.3, and then use CLUTO to obtain the document clusters.

For each application of the LDA-based algorithm, we re-peat the step for five times and compute mean. We tune each algorithm to its best parameter setting. For the exper-iments on the ADs data, we set the cluster number to 42, since the data set is labeled with 42 classes. For the experi-ments on the TWEET X  X  data, we set the cluster number to 50.
The experimental results on two corpuses are shown in Ta-ble 4 and Table 5, respectively. As expected, our methods
CLUTO: http://glaros.dtc.umn.edu/gkhome/views/ cluto/
GibbsLDA++: http://gibbslda.sourceforge.net/
Co-clustering: http://www.cse.ust.hk/TL/index.html Table 5: The performance in DBI of all the evalua-tion methods on TWEETs Figure 4: The performance of all the algorithms on ADs with different K  X  -DLDA and  X  -DLDA clearly outperformed all the other baseline methods on both data sets. Due to the high di-mensionality and sparseness of the representations in short texts, directly clustering the short texts gave the poorest performance. LDA-short outperformed Direct on both data sets, which demonstrates the benefit of using topic based low dimensional representation for the short texts.
All methods that utilized auxiliary long texts can be ob-served to significantly outperform both the Direct and LDA-short, which clearly shows the value of transferring knowl-edge from auxiliary long texts. Interestingly, the LDA-long model, which ignores all the short texts, performs better than LDA-short. We believe that this is because learning topic models on short texts is inherently much more diffi-cult.

Both variations of the proposed DLDA model consistently beat the LDA-both and STC algorithms. LDA-both does not distinguish the target domain from the auxiliary domain, and can suffer from domain inconsistencies as a result. The STC model distinguishes target and auxiliary domains, but lacks a document-level mechanism for determining if a doc-ument is more related to the target or the auxiliary domain. The empirical results confirm that the DLDA can effectively address these difficulties.

Finally, when comparing  X  -DLDA with  X  -DLDA, we see that  X  -DLDA treats the documents in each set uniformly. However, for  X  -DLDA, the document-dependent binary-switch Figure 5: The performance of all the algorithms on TWEETs with different K variables may only help select those auxiliary long texts that are related to the target domain. This document level mechanism gives  X  -DLDA an extra flexibility over  X  -DLDA, which can lead to the observed superior performance.
We conduct additional experiments to show the influence of the parameters and auxiliary data. These experiments are done on the ADs corpus with NMI as the evaluation met-ric. Due the stochastic nature of the algorithm, we repeat each algorithm for 5 times and report the mean as well as standard deviation values.

In [3] parameters are set as  X  = 50 /K and  X  = 0 . 01. In  X  big , where  X  small &lt;  X  big . Since the model is not very sensi-tive to this prior, we use  X  small = 0 . 2 and  X  big = 0 . 5 in the experiments.

For  X  -DLDA, we rely on the setting of  X  prior to constrain the topic selection. We have four parameters  X  tar  X  aux ,  X  aux tar to be tuned. We set  X  aux aux = 50 /K and vary the other three in { 0 , 0 . 01 , 0 . 05 , 50 /K } .

The performance of all the LDA-based algorithms on dif-ferent topic numbers is shown in the Figure 4 and 5 ,for both the ADs and TWEETs data sets. For  X  -DLDA and  X  -DLDA, K = K aux + K tar represents the overall complexity of the model. With the same K , the computational com-plexities of these LDA-based methods are nearly the same.
From these results, we can find that the method without any additional information is poor, while the other algo-rithms achieve much better performance. Those topic mod-els with small-sized topics have similar performance, but perform much differently when the number of topics is large. The method that treats auxiliary data and target data dif-Figure 6: The influence of different K aux and K aux + K tar for  X  -DLDA Figure 7: The influence of the number of auxiliary data used ferently can handle a larger number of topics with better result.

We also examine different K aux for  X  -DLDA. The result is shown in the Figure 6. For a set of K values ranging be-tween 60 and 140 , we plot the model performances as K aux goes from 10 to K . The value of K controls the overall complexity of the topic model, whereas tuning K aux allows us to enforce different degrees of topics shared among the target and auxiliary data. Given a fixed K , reducing K aux is equivalent to enforcing more shared topics between the two domains, whereas increasing K aux allows more auxil-iary domain-dependent information to be captured by the auxiliary topics. From Figure 6, we can clearly see that the optimal performance is achieved with neither very small nor very large K aux values, which shows the important tradeoff between topic-sharing and domain inconsistencies.
 Figure 8: The influence of irrelevant data in auxil-iary data Figure 9: The variation of  X  with irrelevant data in auxiliary data
The amount of auxiliary data involved in the learning pro-cess also influences the result. In the second set of experi-ments, we examine such an influence by varying the amount of auxiliary data used for training from 10% to 100%. The result is shown in the Figure 7. We can see that even with a small amount of auxiliary data, the performances of  X  -DLDA and  X  -DLDA are already much better than the other methods. Furthermore, increasing the amount of auxiliary data can lead to consistent improvement. With more flexi-bility,  X  -DLDA begins to perform better when more auxil-iary data is involved.

We also compare the robustness of our algorithms  X  -DLDA and  X  -DLDA with the other two topic model based methods: LDA-long and LDA-both. In this experiment, the auxiliary data is mixed with some documents that are randomly se-lected from a general knowledge base. There are certainly a lot of useful documents in the general knowledge base that share topics with our target documents. But without any filtering, much more irrelevant data can be included. These documents are not strongly related to the target data and can be considered as noise in the auxiliary data. We control the noise level by inserting different number of irrelevant documents into the auxiliary data. The performance of dif-ferent models under different noise levels is shown in the Figure 8. The results of LDA-long and LDA-both are not very stable when more irrelevant documents are added to the auxiliary data whereas our method  X  -DLDA achieved stable performances with different amounts of noise. This proves that, by explicitly considering domain inconsistency, we can effectively improve the robustness of short text clustering with auxiliary long texts.

When dealing with the auxiliary documents without noise, there is no huge difference between  X  -DLDA and  X  -DLDA. In Figure 8, we found that simply treating the documents uniformly will suffer a lot of trouble. Manually adjusting the  X  priors can lighten this problem, but it requires much human effort. Without carefully tuning the  X  priors, the performance can drop dramatically.

The result of  X  -DLDA can also be explained by the follow-ing analysis. We calculate the  X  when mixing the irrelevant data. The  X  is calculated by Then the average value of  X  for auxiliary documents and tar-get documents are calculated separately, as shown in Figure 9. With more irrelevant data, the model automatically ad-justs the relevance between target documents and auxiliary topics. This adaptability helps the model escape from using many irrelevant topics.
In this paper, we presented a type of novel topic model for enhancing short text clustering by incorporating auxil-iary long texts. The model jointly learns two sets of latent topics on short and long texts. When considering the dif-ference between the topics of the auxiliary and target data, our method can robustly improve the result of clustering on target data, even when there are a lot of irrelevant doc-uments in auxiliary data. The experimental result shows that DLDA can outperform many state-of-the-art methods. This helps validate that, by considering the difference be-tween auxiliary data and target data, the clustering quality on short text can be improved.

In the future, we wish to evaluate other forms of domain difference criteria between data sets, and evaluate their per-formance when knowledge transfer is conducted between the data. We will also consider other forms of topic models to enable more effective learning.
We thank the support of Hong Kong RGC project 621010, and Projects of International Cooperation and Exchanges National Natural Science Foundation of China 60931160445. [1] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Self-taught [2] D. L. Davies and D. W. Bouldin. A Cluster Separation [3] T. L. Griffiths and M. Steyvers. Finding scientific [4] L. Hong and B. Davison. Empirical study of topic [5] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting [6] X. Hu, X. Zhang, C. Lu, E. K. Park, and X. Zhou. [7] S. Lacoste-Julien, F. Sha, and M. I. Jordan. Disclda: [8] R. Mihalcea, C. Corley, and C. Strapparava.
 [9] C.-T. Nguyen, X.-H. Phan, S. Horiguchi, T.-T.
 [10] S. J. Pan and Q. Yang. A survey on transfer learning. [11] X.-H. Phan, C.-T. Nguyen, D.-T. Le, L.-M. Nguyen, [12] X.-H. Phan, L.-M. Nguyen, and S. Horiguchi. Learning [13] X. Quan, G. Liu, Z. Lu, X. Ni, and L. Wenyin. Short [14] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng. [15] R. Raina, A. Y. Ng, and D. Koller. Constructing [16] D. Ramage, S. Dumais, and D. Liebling. [17] D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. [18] M. Sahami and T. D. Heilman. A web-based kernel [19] B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu, [20] G.-R. Xue, W. Dai, Q. Yang, and Y. Yu.
 [21] W.-T. Yih and C. Meek. Improving similarity
