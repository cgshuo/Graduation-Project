 With the advent of online social networks, the trust-based approach to recommendation has emerged which exploits the trust network among users and makes recommendations based on the ratings of trusted users in the network. In this paper, we introduce a two di-mensional trust model which dynamically gets updated based on users X  X  feedbacks, in contrast to static trust values in current trust models. Explorability measures the extent to which a user can rely on recommendations returned by the social network of a trusted user. Dependability represents the extent to which a user X  X  own ratings can be trusted by users trusting him directly and indirectly. We propose a method to learn the values of expl orability and de-pendability from raw trust data and feedback expressed by users on the recommendations they receive. Positive feedback will increase the trust and negative feedback will decrease the trust among users. We performed an evaluation on the Epinions dataset, demonstrating that exploiting user feedback results in lower prediction error com-pared to existing trust-based and collaborative filtering approaches. H.3.3 [ Information Search and Retrieval ]: Relevance feedback Algorithms, Experimentation Trust, Recommendation, Feedback
Current collaborative filtering recommender systems predict rat-ings based on the ratings expressed by the target user and other users. The only information available for these types of recom-menders are the ratings already expressed by different users.
Recently, social networking services such as Facebook, MyS-pace, Orkut, Flickr, ... have become very popular. Actually, they play an important role in people X  X  daily interactions with their friends. With the advent of online social networks, the trust-based approach to recommendation has emerged. This approach exploits the trust network among users and makes recommendations based on the ratings of the users that are directly or indirectly trusted by the user seeking a recommendation. The trust network among users is very sparse. So we have to use a trust model which is able to compute trust values among indirectly connected users in the trust network.
In reality, people meet new people and give them some initial trust. Then they update their trust based on the interactions and experiences they make with these trusted friends. However, online social networks such as Facebook, Flickr, Orkut and Epinions not adequately support this real life phenomenon: They neither al-low users to provide their feedback nor use their feedback to update the trust values in the network.

We envision a recommender system where users provide feed-back on the recommendations they receive by telling the system their actual rating. In return, the recommender is able to provide recommendations with higher quality. The system achieves this higher quality by automatically upda ting certain trust values based on the user feedback. In this paper, in the absence of a system that actually allows users to provide feedback online, we simulate users feedback in an offline manner by separating the data set into training set and test set.

In order to incorporate the effect of feedback, we propose a rec-ommendation specific trust model. In this model, we introduce two dimensions for trust: explorability and dependability. Explorability of an edge denotes the reliability of using that edge to explore the trust network and find recommendations. On the other hand, de-pendability of a trust edge denotes the quality of the trusted user X  X  own knowledge for the truster. Note that both explorability and de-pendability are defined specifically for the purpose of recommen-dation. This is one of the features that distinguishes our approach from existing trust-based recommendation systems, which use a generic concept of trust with trust edges, e.g., explicitly constructed by the user or implicitly derived from observed actions such as on-line chats. We introduce a recommendation method which exploits explorability and dependability to pr edict ratings. We also propose a method to learn the values of explorability and dependability from raw trust data and user feedbacks. In other words we update the values of explorability and dependability based on feedbacks ex-pressed by users. Positive feedback will lead to increasing the trust among users and negative feedback will decrease the trust. http://www.epinions.com Typically in a recommendation system there is a set of N users U = { u 1 ,u 2 , ..., u N } and a set of M items I = { i 1 ,i Each user u rates a set of items I u = { i u 1 , ... i u k user u on item i is denoted by r u,i . r u,i can be any real number, but often ratings are integers in the range [1 , 5] . In a trust-based system, we also have a trust network among users. If u trusts v , then t u,v denotes the strength of this trust as a real number in In the following we define basic concepts used in our work.
Definition 1 . Requester :Let u  X  U and item i/  X  I u , when u requests a prediction for the rating on i , we call user u the requester and i the target item.

Definition 2 . Rater :Let u  X  U and i  X  I , we call u a rater for i if i  X  I u .

When a requester u asks for a prediction on target item i ,thefirst task of a recommendation system is to find raters. For this purpose we start searching the trust network from u , adopting a breadth-first search method to search for the raters. We put a maxDepth thresh-old on the breadth first search to stop searching at some points. The method also labels all users visited to prevent cycles. After find-ing all the raters in the neighborhood, we aggregate their ratings to compute a prediction for requester u on target item i ( r a simple weighted average as the aggregation function:
In this equation, r u is the average of ratings expressed by u . w u,v is the weight denoting the effect of rater v on the prediction. This weight should be related to the trust between u and v .We call this weight the trust value between u and v (shown by t Note that trust relationships are not necessarily symmetric, i.e. in general t u,v = t v,u . So, our trust network is directed graph.
Definition 3. Trust Network : represented as a directed graph G = &lt;U,E&gt; which U are users, and E is the set of trust statement (edges) among users and is of the form &lt; u, v &gt;.
Definition 4. Predecessor : v  X  U is a predecessor of u if there are u 1 , ..., u k  X  U and &lt; v, u 1 &gt;, &lt; u
Definition 5. Successor : v  X  U is a successor of u if there are u 1 , ..., u k  X  U and &lt; u, u 1 &gt;, &lt; u
Social scientists have identified three types of trust [1]: disposi-tional, interpersonal, impersonal. Dispositional trust describes the general trusting attitude of the truster which is independent of any trustee or context. Interpersonal trust is the trust one user has in another user directly. And finally, impersonal trust refers to trust that is not based on any property or state of the trustee but rather on the perceived properties or reliance on the system or institution within which that trustee exists. The trust to a news agency is one such example. Inspired by this categorization, we define a two-dimensional trust model for using in recommender systems. In our trust network, each edge has two trust component s: explorability and dependability.

Definition 6. Explorability :If u, v  X  U and &lt; u, v &gt; then the explorability e u,v denotes the extent to which u and its predecessors can rely on recommendations returned by v  X  X  succes-sors. In other words, how useful are v  X  X  successors X  rating for u and its predecessors.

Definition 7. Dependability :If u, v  X  U and &lt; u, v &gt; then the dependability d u,v denotes the extent to which u and its predecessors can depend on v  X  X  own ratings. In other words how useful are v  X  X  own ratings for u and its predecessors.

Definition 8. Trust Statement : A trust statement t (which is a property of an edge) is an ordered pair t ( e, d ) where the first entry e denotes explorability and the second entry d indicates de-pendability of the edge.

The ranges of explorability and dependability are [0,1]. The de-pendability corres ponds to the quality of trustee X  X  own knowledge, while the explorability represents the quality of recommendations returned by trustee X  X  social network.

We need to clarify two issues. The first issue is, "why do we sep-arate the concept of trust into two new concepts?". When we talk about trust in a person, there are two dimensions: trust in his own opinions, and trust in the opinions returned by him coming from his trusted neighbors. The first kind of t rust, dependability, is an inter-personal trust which shows the trust in other user X  X  knowledge, and the second one, explorability, is an impersonal trust which repre-sents the trust in the social network of the trustee.

The second issue is, "why are explorability and dependability are properties of edges and not of node s?". Explorab ility denotes the reliability of using the edge to explore the trust network, while de-pendability denotes the quality of the target user X  X  own knowledge. For a specific user u , different in-links connecting to u may have different values of dependability and explorability, since links may come from different communities of users. For example, in the con-text of book recommendation, a university professor will have high level of dependability in the academic community, since he knows lots of specialized books. However, he will not be a good recom-mender for his daughter about story books, or for his friend about psychology books. So, in the later communities he will have a low level of dependability. This example shows that dependability is community-dependent and so is a property of an edge connecting a user to a community. In the same way, explorability is community-dependent and should be modeled as a property of an edge.
In this subsection, we assume that all the values of explorability and dependability have already been learnt. The learning mecha-nism is discussed in the next subsection.

If the actual trust value between u and v be t u,v ,  X  t u,v estimate of t u,v . There are two situations when we want to estimate the trust value between two users: they are direct friends in the trust network, or they are indirectly connected to each other using a trust path. Considering the first situation, let &lt;u,v&gt; we have explicit values for e u,v and d u,v .  X  t u,v should represent the effect of v  X  X  own rating on the prediction for u . So we assign  X  t
In the second situation, let &lt; u, v &gt; /  X  E , v is a rater found in the neighborhood, there should be some trust paths from u to v in the trust network. First we compute the trust for a single path. Consider apath p = &lt; u,w,v &gt; from u to v .Weassignthetrustofapathas the product of the trust values of the edges on the path. The factors effecting the trust of the path are the explorability of the edge &lt; u, w &gt; and the dependability of the edge &lt;w,v&gt; .Sowehave  X  t u,v = e u,w  X  d w,v . In general, for a path p = &lt;u,u 1 we have:
The intuition behind equation (2) is that your trust to a neighbor X  X  opinion depends on his own knowledge plus the reliability of the trust path connecting him to you. Notice that the trust value for a direct friend is equal to his dependability.

To compute  X  t u,v we need to consider all different paths from u to v . In FeedbackTrust, when the BFS method finds a rater in depth k , no more pathes with length of more than k will be considered. In other words, the search method only finds the shortest paths be-tween the requester and the rater (similar to [2]). So all paths be-tween the requester and the rater have the same length. To obtain a single trust value  X  t u,v , we have to aggregate the trust values of different paths. We use a simple averaging method for aggregation:  X  t u,v =( p  X  P  X  t p u,v ) / | P | ,where P is the set of all paths found by the BFS method which connect requester u to rater v . Notice that if we used max or min instead of taking the average, then paths with outlier trust values could dominate the aggregated trust value. Taking the mean balances the effect of different paths.
So far, we have discussed the recommendation method given the values of explorability and dependability. But how does the system learn the values of e u,v and d u,v for all &lt; u, v &gt; values we need a training set with known ratings (for a subset of item-user pairs) and with known trust edges (but without depend-ability and explorability values). Initially, we set all explorability and dependability values to a default of 0 . 5 . Then we withhold the known ratings (one at a time), predict them and compare the prediction to the actual rating.

More specially, when a requester u asks for a prediction on target item i , the neighborhood around u will be explored to find raters of i . Then, the ratings of raters will be returned along the path between u and the rater. After receiving a recommendation from raters in the neighborhood, the requester provides feedback for each rater by actually rating the target item (the actual rating in the training data being withheld). Based on the similarity of this actual rating and the returned ratings from each rater in the neighborhood, some of the explorab ility and dependability va lues will get updated.
Explorability of a trust edge e u,v will get updated when u re-ceives a recommendation from successors of v . Then, u provides a feedback for the recommendation and this feedback affects e The dependability of the edge, d u,v , will get updated when u or its predecessors receives recommendation from v  X  X  own ratings. In this case, the user who receives this recommendation provides a feedback which affects d u,v . To determine the feedback user v receives from u , we first compute the error of the prediction u re-ceived from v about item i : Err u,i,v =( | r u,i  X  r v,i
In the this equation, Err u,i,v is the normalized error of the pre-diction provided by rater v for requester u about item i , r actual rating of i expressed by u , r v,i is the estimate for the rating of i provided by v ,and Range is the range of possible ratings on items. The value of Err will be in the [0 , 1] range. A low value of error indicates that the recommendation was good, and therefore the requester will give positive feedback. Note that this error is computed for each rater separately, based on his individual rating (not the aggregate rating over all raters). Finally, after computing the error of each trust path &lt;u,u 1 , ..., u k ,v &gt; , FeedbackTrust updates the explorab ility of the first edge, e u,u 1 , and dependability of the last edge, d u k ,v , in that path.

What is the intuitio n behind updating the explorability and de-pendability values of these particular edges? Assume that in the real world you request a recommendation about some item from your friend. He may not have enough information to help you in decision making. So, he asks some friends about it. Finally, he gives you a recommendation about that item. If he gives you a good recommendation, your trust in his social network will be increased, but your trust in other people X  X  networks will not be changed even if you know them. Therefore, we update the explor ability of the edge between the requester and a direct friend. Now, what happens to the actual source of your recommendation? You may not know him, however he provides you with a good recommendation. This shows that he has some good information about that item. Our method tries to highlight him, so that other users can use his in-formation as recommendation. That is the reason for updating the dependability of the edge end to the rater.

For applying user X  X  feedback on the specified explorability and dependability values, we define a modification rate ( MRate for each rater as follows: MRate u,i,v =0 . 5  X  Err u,i,v MRate u,i,v in the range [-0.5,0.5].

As explained before, when the rater X  X  rating is close to the re-quester X  X  rating, the prediction error will be low, otherwise it will be high. Given that the error is in [0 , 1] ,the MRate formula gives us a symmetric distribution of the modification rate centered at zero. We assume that when the error of the prediction is lower that 0.5, it is a good prediction, and so the rater should receive positive feed-back. On the other side, when the prediction error is higher than 0.5, it cannot be a good prediction, and so the requester will send negative feedback.

We define and use a trust updatin g function for e xplorability and dependab ility based on the trust evo lution function proposed by Jonker and Treur in [3]. We use the modification rate as an "in-flation factor" for the trust evolution function.
In equations (3) and (4), the variable t denotes the time. So, e u,u 1 denotes the value of explorability of the edge &lt;u,u before updating, while e t +1 u,u 1 indicates the updated value. d and d t +1 u k ,v show the dependability of the edge &lt;u and after updating, respectively. Note that if there are different paths from u to v , then the modification will be applied to all these paths.
In this section, we present the experiments we have conducted for evaluating the performance of our method. We compared our FeedbackTrust method with MoleTrust presented by Massa, Tidal-Trust proposed by Golbeck, and also the standard user-based col-laborative filtering method. We also evaluate the results of our model when we ignore users X  feedback. We call it BaselineTrust method. In the BaselineTrust me thod all the expl orability and de-pendability values are e qual to 0.5 and never get updated. Basi-cally, we analyze the effect of users X  feedback by comparing Base-lineTrust and FeedbackTrust. In the following, we first describe the dataset used and introduce the evaluation strategy, then we present the experimental results.
The data set used in our experiments is derived from the Epin-ions.com Web site. In Epinions.com users can express their opin-ions about different products and also assign a rate (ranging from 1 to 5) to each item to show the overall quality of a product. They can also express their Web of Trust, i.e. reviewers whose reviews and ratings they have found to be valuable. When a user adds a new reviewer to his Web of Trust, it is equals to issuing a trust statement of value 1 in this reviewer.

This data set 2 contains 49k users, 139k items and 664k ratings expressed by users on different items. Also the trust network in-cludes 487k edges. The sparsity of the rating matrix (user which is equal to the percentage of empty cells, is 99.99%. To evaluate our method, we performed 5-fold cross-validation. Since our method needs to learn trust values using feedbacks, we took one fold of the ratings ("user-item-rate" entries) as test set and used the remaining folds for training the trust network. Typically, the leave-one-out method is used to evaluate recommendation sys-tems [2][4]. This technique involves withholding one rating and http://www.trustlet.org/wiki/Downloaded_Epinions_dataset trying to predict it using the trust network and the remaining rat-ings. Then the predicted rating can be compared with the actual rating and the difference will be considered as the prediction error. We use two evaluation measures:
Mean Absolute Error(MAE) , measures the deviation of predic-tions generated by the Recommender from the true rating values, as they were specified by the user. In recommender system area if the size of the test set be M , and prediction and actual rat-ing represent by p j and r j respectively, MAE will be equal to:
Coverage , is a measure of the percentage of ratings for which, after being hidden, the algorithm can provide predictions. The cov-erage is defined as Coverage =( | T | X  m ) / | T | ,which m is the number of ratings the method could not predict, and | T | of the test set.
Cold start users are those who in total provided less than five rat-ings[4]. In terms of the maximum searching depth in trust network, we report the results for three depths. Finally, to analyze the ef-fect of users X  feedback, we report the results of BaselineTrust and FeedbackTrust separately.

Table 1 and 2 show the MAE and coverage of FeedbackTrust and other methods, for cold start and all users. In each table we show the results of each method for different predefined maximum depth (d = 1, 3, 5). Of course, standard collaborative filtering (CF) and TidalTrust methods are independent form the depth of search.
Comparing the MAE results of cold start users and all users shows that in all models the error of prediction for cold start users is higher than all users X  error. This is due to the fact that less infor-mation is available for cold start users, so the methods are unable to find enough raters to precisely predict the ratings.

The comparison of MAE of BaselineTrust and FeedbackTrust supports our claim that users X  feedback can reduce the prediction error and improve the precision of recommendations. As shown in table 1, using users X  feedback decreases the MAE for both cold start users and all users. The MAE of BaselineTrust is similar to Tidal-Trust X  X , but the FeedbackTrust model performed much better espe-cially when the maximum depth of search increases. Also we can see that trust-based approach generally outperformed the standard collaborative filtering approach. Among trust-based approaches, the results of BaselineTrust method are not as good as TidalTrust, but the FeedbackTrust performs consistently better than TidalTrust, in particular for larger maximum depth values.

Finally, we compare the coverage of all methods. In general, the coverage of cold start users is less than the coverage of all users. Cold start users, who rated few number of items, usually have only small trust networks. So, it is hard for both trust-based methods and collaborative filtering methods to find a rater. However, trust-based methods perform better than CF for cold start users. As soon as a user adds one friend to his trust network, he gets connected to some raters in farther distances.

The coverage of depth-dependent trust-based methods, i.e. Feed-backTrust and MoleTrust, increas es with increasing maximum depth (for both cold start users and all users). Since these two methods use the same search method, they show similar coverage. Finally, the coverage of TidalTrust and CF is fixed and independent from the search depth. TidalTrust has high coverage for both cold start users (51%) and all users (76%). While the coverage of Feedback-Trust for maximum depth 5 is the same as TidalTrust X  X  coverage, for the other two maximum depths it has lower coverage.
In this paper, we proposed a novel trust model which considers two dimensions for trust: explorability and dependability. The ex-plorability of the edge between users u and v denotes how useful the ratings of v  X  X  successors are for u and its predecessors. The de-pendability of that edge denotes how useful v  X  X  own ratings are for u and its predecessors. Both dimensions of trust introduced in this paper are specific to recommendation systems which makes them work better for prediction of ratings.

We introduced a feedback-based method to learn both explorabil-ity and dependability values. Good recommendations, where the recommendation agrees with the user X  X  actual ratings, improve the dependab ility of the trust edge connecting to the rater and also im-prove the explorability of the edge from which we started to explore the network, while bad recommendations decreases these values. We also presented a method to compute the trust between a re-quester and a rater based on the explorability and dependability values along a connecting path.

Exploiting users X  feedback on recommendations they receive en-ables us to highlight those friends who are actually reliable for users. This leads to an improvement of trust-based recommenda-tion. This claim was confirmed in our experiments on the Epin-ions data set. In the absence of a system that actually allows users to provide feedback online, we simulated user feedback in an of-fline manner by separating the data set into training set and test set. However, curresnt recommender system can use this model by constructing a virtual network on top of the user network, and auto-matically generate feedbacks using requesters preferences. Experi-ments showed that FeedbackTrust outperforms existing trust-based recommenders MoleTrust and TidalTrust in terms of MAE. Our experimental results also demonstrated that FeedbackTrust outper-forms the standard user-based CF, due to the fact that Feedback-Trust uses the trust network besides the rating data. [1] A. Abdul-Rahman and S. Hailes. Supporting trust in virtual [2] J. Golbeck. Generating predictive movie recommendations [3] C. M. Jonker and J. Treur. Formal analysis of models for the [4] P. Massa and P. Avesani. Trust-aware recommender systems.
