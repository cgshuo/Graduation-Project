 The concept of similarity is fundamentally important in almost every scientific field. Clustering, distance-based outlier d etection, classificat ion and regression are major data mining techniques which compute the similarities between in-stances and hence choice of a particular similarity measure can turn out to be a major cause of success or failure of the al gorithm. For these tasks, the choice of a similarity measure can be as important as the choice of data representation or feature selection. Most algorithms typically treat the similarity computation as an orthogonal step and can make use of any measure. Similarity measures can be broadly divided in two categories: similarity measures for continuous data and categorical data.

The notion of similarity measure for continuous data is straightforward due to inherent numerical ordering. Minkowski distance and its special case, the Euclidean distance are the two most widely used distance measures for contin-uous data. However, the notion of similarity or distance for categorical data is not as straightforward as for continuous data and hence is a major challenge. This is due to the fact that the different values that a categorical attribute takes are not inherently ordered and hence a notion of direct comparison between two categorical values is not possible. In addition, the notion of similarity can differ depending on the particular domain, dataset, or task at hand.

Although there is no inherent ordering in categorical data, there are other factors like co-occurrence statistics t hat can be effectively used to define what should be considered more similar and vice-versa. This observation has motivated researchers to come up with data-driven similarity measures for categorical at-tributes. Such measures take into account the frequency distribution of different attribute values in a given data set but most of these algorithms fail to capture any other feature in the dataset apart from frequency distribution of different attribute values in a given data set. One solution to the problem is to build a common repository of similarity measur es for all commonly occurring concepts. As an example, let the similarity values for the concept  X  X olor X  be determined. Now, consider 3 colors red, pink and black. Consider the two domains as follows:  X  Domain I: The domain is say determining the response of cones of the eye  X  Domain II: Consider another domain, for example the car sales data. In Thus, the notion of similarity varies from one domain to another and hence the assignment of similarity must involve a thorough understanding of the domain. Ideally, the similarity notion is defined by a domain expert who understands the domain concepts well. However, in many applications domain expertise is not available and the users don X  X  understand the interconnections between objects well enough to formulate exact definitions of similarity or distance.
In the absence of domain expertise i t is conceptually very hard to come up with a domain independent solution for similarity. This makes it necessary to define a similarity measure based on latent knowledge available from data instead of a fit-to-all measure and is the major motivation for this paper.

In this paper we present a new similarity measure for categorical data, DISC  X  Data-Intensive Similarity Measure for Categorical Data. DISC captures the semantics of the data without any help from domain experts for defining sim-ilarity. It achieves this by capturing the relationships that are inherent in the data itself, thus making the similarity measure  X  X ata-intensive X . In addition, it is generic and simple to implement.

The remainder of the paper is organized as follows. In Section 2 we discuss related work and problem formulation in Section 3. We present the DISC algo-rithm in Section 4 followed by experimental evaluation and results in Section 5. Finally, in Section 6, we summarize the conclusions of our study and identify future work. 1.1 Key Contributions  X  Introducing a notion of similarity between two values of a categorical at- X  Defining a valid similarity measure for capturing such a notion which can be  X  Experimentally validating that such a similarity measure provides a signifi-Determining similarity measures for categorical data is a much studied field as there is no explicit notion of ordering among categorical values. Sneath and Sokal were among the first to put together and discuss many of the categorical similarity measures and discuss this in detail in their book [2] on numerical taxonomy.

The specific problem of clustering categorical data has been actively stud-ied. There are several books [3,4,5] on cluster analysis that discuss the problem of determining similarity between categorical attributes. The problem has also been studied recently in [17,18]. However, most of these approaches do not offer solutions to the problem discussed in this paper, and the usual recommenda-tion is to  X  X inarize X  the data and then use similarity measures designed for binary attributes. Most work has been ca rried out on development of clustering algorithms and not similarity functions. Hence these works are only marginally or peripherally related to our work. Wilson and Martinez [6] performed a de-tailed study of heterogeneous distance functions (for categorical and continuous attributes) for instance based learning. The measures in their study are based upon a supervised approach where each data instance has class information in addition to a set of categorical/continuous attributes.

There have been a number of new data mining techniques for categorical data that have been proposed recently. Some of them use notions of similarity which are neighborhood-based [7,8,9], or incorporate the similarity computation into the learning algorithm[10,11]. These measures are useful to compute the neigh-borhood of a point and neighborhood-based measures but not for calculating similarity between a pair of data instances . In the area of information retrieval, Jones et al. [12] and Noreault et. al [13] have studied several similarity measures. Another comparative empirical evaluation for determining similarity between fuzzy sets was performed by Zwick et al. [14], followed by several others [15,16].
In our experiments we have compared our approach with the methods dis-cussed in [1]; which provides a recent exh austive compariso n of similarity mea-sure for categorical data. In this section we discuss the necessary conditions for a valid similarity measure. Later, in Section 4.5 we describe how DISC satisfies these requirements and prove the validity of our algorithm. The following conditions need to hold for a distance metric  X  d  X  X obevalidwhere d ( x, y ) is the distance between x and y . 1. d ( x, y )  X  0 2. d ( x, y ) = 0 if and only if x=y 3. d ( x, y )= d ( y, x ) 4. d ( x, z )  X  d ( x, y )+ d ( y, z ) In order to come up with conditions for a valid similarity measure we use sim = 1+ dist , a distance-similarity mapping used in [1]. Based on this mapping we come up with the following definitions for valid similarity measures: 1. 0  X  Sim ( x, y )  X  1 2. Sim ( x, y ) = 1 if and only if x = y 3. Sim ( x, y )= Sim ( y, x ) Where, Sim ( x, y ) is the similarity between x and y : In this section we present the DISC algorithm. First in Section 4.1 we present the motivation for our algorithm followed by data-structure description in Sec-tion 4.2 and a brief overview of the algor ithm in Section 4.3. We then describe the algorithm for similarity matrix computation in Section 4.4. Finally in Section 4.5 we validate our similarity measure. 4.1 Motivation and Design As can be seen from the related work, cu rrent similarity (distance) measures for categorical data only examine the number of distinct categories and their counts without looking at co-occurrence statistics with other dimensions in the data. Thus, there is a high possibility that, the latent information that comes along is lost during the process of assigning similarities. Consider the example in Table 1, let there be a 3-column dataset where the Brand of a car and Color are independent variables and the Price of the car is a dependant variable. Now there are three brands a , b , c with average price 49.33, 32.33, 45.66. It can be intuitively said that based on the available information that similarity between a and c is greater than that bet ween the categories a and b .Thisistruein real life where a, c, b may represent low, medium and high end cars and hence the similarity between a low-end and a medium-end car will be more than the similarity between a low-end and a high-end car. Now the other independent variable is Color . The average prices corresponding to the three colors namely red , green and blue are 43, 41, 43.33. As can be seen, there is a small difference in their prices which is in line with the fact that the cost of the car is very loosely related to its color.

It is important to note that a notion of similarity for categorical variables has a cognitive component to it and as such each one is debatable. However, the above explained notion of similarity is the one that best exploits the latent information for assigning similarity and will hence give predictors of high accuracy. This claim is validated by the experimental results. Extracting these underlying semantics by studying co-occurrence data forms the motivation for the algorithm presented in this section. 4.2 Data Structure Description We first construct a data structure called the categorical information table (CI). The function of the CI table is to provide a quick-lookup for information re-lated to the co-occurrence statistics. Thus, for the above example CI[Brand:a] [Color:red] = 1, as for only a single instance, Brand:a co-occurs with Color:red . For a categorical-numeric pair, e.g. CI[Brand:a][Price] = 49.33 the value is the mean value of the attribute Price for instances whose value for Brand is a .
Now, for every value v of each categorical attribute A k a representative point  X  ( A k : v ) is defined. The representative point is a vector consisting of the means of all attributes other than A k for instances where attribute A k takes value v : It may be noted that the term  X  ( A k : v, A k ) is skipped in the above expression. As there is no standard notion of mean for categorical attributes we define it as where domain ( A i )= { v i 1 ,...,v in } It can thus be seen that, the mean itself is a point in a n-dimensional space having dimensions as v i 1 ,..., v in with magnitudes: &lt;CI [ A k : v ][ A i : v i 1 ] ,...,CI [ A k : v ][ A i : v in ] &gt; .
Initially all distinct values belonging to the same attribute are conceptually vectors perpendicular to each other an d hence the similarity between them is 0.
For, the given example, the mean for dimension Color when Brand : a is denoted as  X  ( Brand : a, Color ). As defined above, the mean in a categorical dimension is itself a point in a n-dimensional space and hence, the dimensions of mean for the attribute Color are red, blue, green and hence  X  ( Brand : a, Color )= { CI [ Brand : a ][ Color : red ] ,CI [ Brand : a ][ Color : blue ] ,CI [ Brand : a ][ Color : green ] } Similarly,  X  ( Brand : a, P rice )= { CI [ Brand : a ][ Price ] }
Thus the representative point for the value a of attribute Brand is given by,  X  ( Brand : a )= &lt; X  ( Brand : a, Color ) , X  ( Brand : a, P rice ) &gt; 4.3 Algorithm Overview Initially we calculate the representative points for all values of all attributes. We then initialize similarity in a manner similar to the overlap similarity measure where matches are assigned similarity value 1 and the mismatches are assigned similarity value 0. Using the representative points calculated above, we assign a new similarity between each pair of values v , v belonging to the same attribute A k as equal to the average of cosine similarity between their means for each dimension. Now the cosine similarity between v and v in dimension A i is denoted by CS ( v : v ,A i ) and is equal to the cosine si milarity between vectors  X  ( A k : v, A i )and  X  ( A k : v ,A i ). Thus, similarity between A k : v and A k : v is: Thus, for the above example, the similarity between Brand:a and Brand:b is the average of cosine similarity between th eir respective means in dimensions Color
An iteration is said to have been comple ted, when similarity between all pairs of values belonging to the same attribute (for all attributes) are computed using the above methodology. These, new values are used for cosine similarity compu-tation in the next iteration. 4.4 DISC Computation In this section, we describe the DISC algorithm and hence the similarity ma-trix construction. The similarity matrix construction using DISC is described as follows: 1. The similarity matrix is initialized in a manner similar to overlap similarity 2. Consider a training dataset to be consisting of n tuples. The value of the 3. The Sim( v ij , v ik ) (Similarity between categorical values v ij and v ik )isnow 4. The matrix is populated using the above equation for all combinations 5. The step 3 is iterated on again using the new similarity values until the 4.5 Validity of Similarity Measure The similarity measure proposed in this paper is basically a mean of cosine simi-larities derived for individual dimensions in non-orthogonal spaces. The validity of the similarity measure can now be argued as follows: 1. As the similarity measure is a mean of cosine similarities which have a range 2. For the proposed similarity measure Sim ( X, Y ) = 1, if and only if 3. As cosine product is commutative, the third property holds implicitly. 4. It may be noted that the resultant similarity is a mean of similarities com-In this section, we describe the pre-processing steps and the datasets used in Section 5.1 followed by experimental results in Section 5.2. Finally in Section 5.3 we provide a discussion on the experimental results. 5.1 Pre-processing and Experimental Settings For our experiments we used 24 datasets out of which 12 were used for classi-fication and 12 for regression. We compare our approach with the approaches discussed in [1], which provides a recen t exhaustive compa rison of similarity measures for categorical data.

Eleven of the datasets used for classification were purely categorical and one was numeric (Iris). Different methods can be used to handle numeric attributes in datasets like discretizing the numeric variables using the concept of minimum description length [20] or equi-width binning. Another possible way to handle a mixture of attributes is to compute the similarity for continuous and categorical attributes separately, and then do a weighted aggregation. For our experiments we used MDL for discretizing numeric variables for classification datasets.
Nine of the datasets used for regression were purely numeric, two (Abalone and Auto Mpg) were mixed while one (Servo) was purely categorical. It may be noted that the datasets used for regression were discretized using equi-width binning using the following weka setting:  X  weka.f ilters.unsupervised.attribute. Discretize  X  B 10  X  M  X  1 . 0  X  Rf irst  X  last  X  X he k -Nearest Neighbours ( kNN ) was implemented with number of neighbours 10. The weight associated with each neighbour was the similarity between the neighbour and the input tuple. The class with the highest weighted votes was the output class for classification while the output for regression was a weighted sum of the individual responses.
The results have been presented for 10-folds cross-validation. Also, for our experiments we used the entire train set as the validation set. The numbers in brackets indicate the rank of DISC versus all other competing similarity mea-sures. For classification, the values indicate the accuracy of the classifier where a high value corresponds to high percentage accuracy and hence such a similarity measure is assigned a better (higher) rank. On the other hand, for regression Root Mean Square Error (RMSE) value has been presented where a compara-tively low value indicates lower error a nd better performance of the predictor and hence such a similarity measure is assigned a better rank. It may be noted that a rank of 1 indicates best performan ce with the relative performance being poorer for lower ranks. 5.2 Experimental Results The experimental results for classificat ion and regression are presented in Ta-ble 3, 4 and Table 5, 6 respectively. In th ese tables each row represents compet-ing similarity measure and the column represents different datasets. In Table 3 and 4, each cell represents the accuracy for the corresponding dataset and simi-larity measure respectively. In Table 5 and 6, each cell represents the root mean square error (RMSE) for the corresponding dataset and similarity measure re-spectively. 5.3 Discussion of Results As can be seen from the experimental resul ts, DISC is the best similarity measure for classification for all datasets except Lymphography, Primary Tumor and Hayes Roth Test where it is the third best for the first two and the second best for the last one. On the basis of ov erall mean accuracy, DISC outperforms the nearest competitor by about 2.87% where we define overall mean accuracy as as the mean of accuracies over all classification datasets considered for our experiments. For regression, DISC is the best performing similarity measure on the basis of Root Mean Square Error (RMSE) for all datasets.

For classification datasets like Iris, Primary Tumor and Zoo the algorithm halted after the 1 st iteration while for datasets like Balance, Lymphography, Tic-Tac-Toe, Breast Cancer th e algorithm halted after the 2 nd iteration. Also, for Car-Evaluation, Hayes Roth, Teaching Assistant and Nursery the algorithm halted after the 3 rd iteration while it halted after the 4 th iteration for Hayes Roth Test. For regression, the number of iterations was less than 5 for all datasets ex-cept Compressive Strength for which it was 9. Thus, it can be seen that the number of iterations for all datasets is small. Also, the authors observed that the major bulk of the accuracy improvement is achieved with the first iteration and hence for domains with time constraints in training the algorithm can be halted after the first iteration. The reason for the consistently good performance can be attributed to the fact that a similarity computation is a major component in nearest neighbour classification and regression techniques, and DISC captures similarity accurately and efficiently in a data driven manner.

The computational complexity for determining the similarity measure is equiv-alent to the computational complexity of computing cosine similarity for each pair of values belonging to the same categorical attribute. Let the number of pairs of values, the number of tuples, number of attributes and the average number of values per attribute be V , n , d and v respectively. It can be seen that, construction of categorical collection is O(nd). Also, for all pairs of values V, we compute the similarity as the mean of cosine similarity of their representa-tive points for each dimension. This is essentially ( v 2 d ) for each pair and hence the computationally complexity is O( Vv 2 d ) and hence the overall complexity is O( nd + Vv 2 d ). Once, the similarity values ar e computed, using them in any classification, regression or a clustering task is a simple table look up and is hence O(1). In this paper we have presented and evaluated DISC, a similarity measure for categorical data. DISC is data intensive, generic and simple to implement. In addition to these features, it doesn X  X  r equire any domain expert X  X  knowledge. Finally our algorithm was evaluated against 14 competing algorithms on 24 standard real-life datasets, out of which 12 were used for classification and 12 for regression. It outperformed all competing algorithms on almost all datasets. The experimental results are especially significant since it demonstrates a reasonably large improvement in accuracy by changing only the similarity measure while keeping the algorithm and its parameters constant.

Apart from classification and regression, similarity computation is a pivotal step in a number of application such as clustering, distance-based outliers detec-tion and search. Future work includes applying our algorithm for these techniques also. We also intend to develop a weighin g measure for different dimensions for calculating similarity which will make the algorithm more robust.

