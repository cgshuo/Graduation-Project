 HOSSEIN HAJIMIRSADEGHI, MAJID NILI AHMADABADI, BABAK NADJAR ARAABI, Imitation is one of the main methods of social learning. There are also other types of social learning which are somehow similar to imitation like mimicking or sampling, but according to Arbib [2002], Breazeal and Scassellati [2002], and Inamura et al. [2004], imitation is discriminated from others by abstraction, conceptualization, and symbolization. In fact, perfect imitation is accompanied by comprehension and gen-eralization which are attained by abstraction. Hence, skills can be represented in a generalized symbolic level which is desired for high-level cognitive tasks [Billard et al. 2008]. In addition, abstraction helps for efficient memory management, handling the huge real-world search spaces [Inamura et al. 2004], and quick knowledge transfer from an agent to another agent or from a situation to another situation [Kadone and Nakamura 2006a].

In robotics, imitation is a powerful paradigm (in time or energy) to teach compli-cated tasks to complex robots like humanoids. In addition, imitation provides a natu-ral and implicit mechanism for training a robot which is a key point in Human-Robot Interaction (HRI). Recently, symbolization and conceptualization have drawn atten-tion in robot learning by imitation [Inamura et al. 2004; Kadone and Nakamura 2006a, 2006b; Krichmar and Edelman 2002; Mobahi et al. 2007; Samejima et al. 2006; Takano and Nakamura 2006]. However, the majority of previous works are ded-icated to form concepts based on similarity in perceptual characteristics, and there is not enough work to find abstract concepts which share functional properties. We think that, although perceptual categorization is necessary to abstract demonstrations in imitation, there exist skills or knowledge which cannot be transferred merely from perceptual information, like internal intents of the teacher or functional meaning (or effect) of the actions.

In this work, we propose an incremental and gradual learning algorithm for concept acquisition, generalization, recognition, and regeneration of spatio-temporal demon-strations. This is an interactive algorithm in which the agent receives reinforcement signals from the teacher. So, it can form concepts based on the teacher X  X  external infor-mation which conveys functional characteristics of demonstrated behaviors. Percep-tual abstraction of demonstrations is fulfilled stochastically by Hidden Markov Models (HMMs). However, an abstract (relational) concept is obtained as a collection of HMMs which might represent different perceptual features. Generated HMMs are stored in two different memories, Long-Term Memory (LTM), and Working Memory (WM), based on their contents. In the proposed algorithm, the concepts and proto-symbols emerge automatically without explicit human intervention. Also, the algorithm is invariant to the order of incoming demonstrations and acquires the concepts in parallel. Finally, the whole model can make an interface between skill representation in symbolic level and trajectory level which is a significant challenge of integrating discrete symbolic AI planning research and continuous control of robotic systems [Geib et al. 2006]. The last note is that the cognitive terms (e.g., LTM and WM) used throughout this article are based on the proposed bio-inspired model of Mobahi et al. [2007] for conceptual imitation. However, as the biological counterparts are not presented here, we do not make any claims about the work as a cognitive model.

This article is organized as follows. Section 2 discusses related works on imitation and abstraction. In Section 3, some basics and theories about concepts are reviewed. In addition, conceptual imitation is elaborated, and an approach is introduced to teach a concept-oriented agent. Section 4 describes the proposed algorithm for learning and recall phases. In Section 5, two experimental scenarios are introduced to evaluate performance of the model. Also, results of the experiments, including abstraction, recognition, and regeneration of concepts, are presented and compared with results of some baseline algorithms in this section. Finally, conclusions are drawn in Section 6. In the recent years many researchers have addressed the problem of imitation and abstraction. Samejima et al. [2006] proposed an imitation learning model with symbolization of motion patterns. The imitation process was accomplished through a motion recognition and control approach using some controller and predictor mod-ules. However, in the proposed model, abstraction was based on perceptual similarity.
Kadone and Nakamura [2006a, 2006b] introduced an incremental algorithm to learn human motion primitives. Their model was able to automatically segment, ab-stract, memorize, and recognize demonstrated motions, using associative neural net-works. However, like previous works, the obtained symbols were categorized based on perceptual information.

HMMs have been extensively used for development of imitation models in the last decade [Billard et al. 2006; Calinon and Billard 2004; Calinon et al. 2005; Kulic et al. 2008, 2009; Inamura et al. 2004; Lee et al. 2008; Takano and Nakamura 2006]. In fact, HMMs have shown the ability for abstraction, generalization, recognition, and gener-ation of spatio-temporal signals. They can deal simultaneously with the statistical variations in the dynamics and the statistical variations in the observations. Conse-quently, HMMs can provide a unified mathematical model for learning from imitation. In the previous research on imitation learning based on HMM, some issues have been proposed and solved gradually. In the early works, demonstrated motions of different behaviors were grouped manually (or clustered a priori) and next trained with distinct HMMs in an offline manner. So, the number of HMMs which represented different behaviors was also determined a priori. In addition, the models lacked a mechanism for motion generation through HMMs. However, in the advanced works, algorithms were proposed for incremental and autonomous acquisition and learning of human motions from continuous demonstrations [Kulic et al. 2007, 2008, 2009]. Furthermore, several methods introduced to generate smooth motions from HMMs [Billard et al. 2006; Calinon and Billard 2004; Calinon et al. 2005; Inamura et al. 2004; Kulic et al. 2008]. For example, Kulic et al. [2008] developed an algorithm for incremental and autonomous learning, symbolization, recognition, clustering, and hierarchical orga-nization of whole body motion patterns, using Factorial HMMs. They also provide an algorithm for deterministic motion generation. However, in all previous works, abstraction and symbolization are based on similarity in perceptual space, and the proposed approaches cannot tackle abstract concepts showing similar functionalities.
There are very few works on imitation and abstraction based on similarity in func-tional space. One of the main works for conceptual imitation which considers both perceptual and functional properties of action was proposed by Mobahi et al. [2005, 2007] who introduced a bio-inspired model to acquire abstract relational concepts from imitation, using reinforcement learning. However, unlike our procedure which is suit-able for a sequence of observations (e.g., human motion), their proposed algorithm is only applicable for concept acquisition from single observations. Moreover, our al-gorithm makes a stochastic scheme to represent the concepts and also encodes the acquired knowledge into proto-symbols which try to represent all perceptual variants of a concept for both recognition and regeneration.

The final note is that the present article extends our previous work [Hajimirsadeghi et al. 2010] with more elaborations for the learning algorithm and more experiments for motion pattern recognition and generation in order to have better understanding and evaluation of the proposed algorithm and outcomes. As the aim of this article is to extract abstract concepts out of demonstrations, some general basics about concepts are firstly reviewed. According to representational theory of mind, concept is a mental representation of world in the agent X  X  mind. It can be an abstract idea, object, or event generally defined as a unit of meaning or knowl-edge [Zentall et al. 2002]. This unit is constructed based on other units which de-scribe some characteristics about the concept. For example, a special kind of food (e.g., pizza) is described by its physical ingredients, but the general food concept is said to everything eatable (a functional property). In fact, these physical and/or functional characteristics make principles to categorize perceptions from world into concepts. Conceptualization helps to have a more general and smaller representation of the world, which leads to more effective and simpler reasoning and interaction. For con-cept acquisition in natural environments, three points are desired [Davidsson 1994]. First, concepts should be learned gradually as experience of the agent is increasing during the lifetime. Second, the concepts should be learned in parallel to cope with the diversity in type and order of incoming knowledge. Finally, like any learning proce-dure, it is very favorable to learn fast.

Concepts are categorized into three levels of abstraction, namely, perceptual, rela-tional, and associative [Zentall et al. 2002]. Perceptual concepts are formed based on similarity of instances in perceptual space. For example, all species of dog are cate-gorized in one general concept based on similarity in appearance. Relational concepts are formed not only by similarity in perceptual characteristics but also by external information which specifies the functionalities. This information integrates perceptu-ally scattered categories into one concept. For example, kneeling and removing a hat are two different gestures for expressing respect which are separately categorized in perceptual space. But the external information (e.g., the situation) which describes the function of these gestures can link them into the right concept which is  X  X espect X . Finally, in associative concepts, instances of each concept have no obvious physical sim-ilarity, but shared functional characteristics put them into one concept. An illustration of three types of concepts is provided in Figure 1.

An important problem with a concept is how to represent it. Three theories are proposed by Kruschke [2005] to represent the concepts: exemplar, prototype, and rule theories. In exemplar theory, all instances of a concept are memorized. In prototype theory, a summary of instances is derived to represent various instances of a con-cept. This theory is more abstract and efficient to come up with limitations in memory. Finally, rule theory uses a match/mismatch process or boundary specification to repre-sent concepts. In this work, we want to devise an algorithm for autonomous extraction and learning of relational concepts from imitation. In this way, demonstrated spatio-temporal be-haviors are abstracted based on similarity in both perceptual and functional space. To this end, we favor to represent concepts by prototypes. Actually, the ideal situation is when we have the least number but the most general prototypes to understand a concept. Consequently, in the face of new demonstrations, the previously learned con-cepts can be recognized using generated proto-symbols, and there is no need of learning the behavior (motor commands to perform the behavior) from scratch. Also, behaviors which are associated with the same concept can be used alternatively in place of each other according to the robot X  X  comfort or affordance.

The real world is full of spatio-tempral experiences with relational concepts. For example, there are several perceptually different behaviors which represent respect among people like saluting, removing hat, lowering head, bending down, kneeling, etc. In fact, all these behaviors have the same meaning (i.e., respect) for the observers. In addition, there might be different actions that make the same effect in the environ-ment. For example, there are different body gestures that make people laugh. In the real world, we are faced with instances of these concepts permanently. A robot which is an inhabitant of the human environment will also face similar experiences during colocation and interaction with the human over its entire lifespan. Hence, there should be an incremental and gradual mechanism to learn and acquire these concepts. Note that in the recent years, there is an increasing interest to plan technologies for human-robot cohabitation, teaming, and interaction [Cirillo et al. 2010; Talamadupula et al. 2010]. As described in Section 3.1, relational concepts cannot form merely from perceptual observations, and external information should be also provided. This information can unify perceptually scattered prototypes which represent the same concept. However, it is desirable to have a simple process to transfer external information from the un-skilled teacher to the robot. One solution to this problem is same/different judgement. In this method, the learning agent is exposed to two stimuli. It should decide whether they are associated with the same or a different concept. Based on correctness or in-correctness of the answer, the agent receives a reward or punishment signal from the teacher. In this work, a similar approach is used. First, the learning agent observes the teacher X  X  demonstration. In response to the teacher, the agent guesses the concept of the demonstrated behavior. Next, it reproduces a behavior which is linked to that concept in its mind. Now, the teacher issues a reward or punishment signal according to correctness or incorrectness of the learning agent X  X  response. In this way, the learn-ing agent gradually develops abstract concepts to increase its reward. Eventually, the agent will be able to correctly classify novel demonstrations of the learned concepts. In this algorithm, HMMs are used for abstraction and symbolization of spatio-temporal perceptions. As a result, relational concepts are represented by HMM exemplars and prototypes which might encode different perceptual information but demonstrate the same functional properties. The overall sketch of this algorithm is as follows. The learning agent tries to find the concept of the teacher X  X  demonstration out of the available concepts in its mind through deliberative interaction (interactive mode). This interaction is guided by reinforcement signals of the teacher like the way in same/different judgement. If the true concept is found, the agent readjusts this concept by adapting and/or making exemplars and/or prototypes. However, if there is no concept (in the memory) associated with the perceived demonstration, the agent makes a new concept by this new demonstration (noninteractive mode). More detailed biological or theoretical motivations and justifications of this approach have been ex-plained by Mobahi et al. [2007]. People unfamiliar with HMM should refer to Rabiner [1990]. Also, to find the algorithms for motion generation through HMM, one might see Inamura et al. [2004], Kulic et al. [2008], and Billard et al. [2006]. The learning algorithm is an iterative procedure where a cycle is repeated whenever a new demonstration is perceived. To ease explaining the learning algorithm, assume we are at the middle of execution where some concepts have been formed, and some prototypes and exemplars have been stored in the agent X  X  memory. In our algorithm, an exemplar is an HMM made up of only one demonstration. However, prototypes are HMMs formed by unifying perceptually similar exemplars in the memory. Accordingly, we store the exemplars and prototypes in two different sets, namely Working Memory (WM) and Long-Term Memory (LTM), respectively. Finally, each concept is defined as a set of prototypes and exemplars, and all the concepts together make the set of concepts Q .
 However, to have better understanding of the algorithm, the concepts have been em-bodied into symbolic units in Figure 2, and the exemplars and prototypes have been connected to them. In fact, in the proposed algorithm, the exemplars and prototypes membership in the concepts are described by two functions c W and c L which associate exemplar and prototype indexes with concept indexes, respectively.
To clear up these definitions, a real example is provided here. Assume that we have two concepts ( | Q | = 2). The first concept ( q 1 ) is the Respect concept and the second concept ( q 2 ) is the Happiness concept. There are 5 prototypes in the LTM ( | LTM | =5): 3 prototypes for the first concept and 2 prototypes for the second concept. The 1st pro-totype represents a Kneel motion pattern and belongs to the Respect concept c L 1 =1 , the 2nd prototype represents a Dance motion pattern and belongs to the Happiness concept c L 2 =2 , the 3rd prototype represents a Cheer motion pattern and belongs to the Happiness concept c L 3 =2 , the 4th prototype represents a Remove Hat motion pattern and belongs to the Respect concept c L 4 =1 , and the 5th prototype represents a Bend Down motion pattern and belongs to the Respect concept c L 5 =1 . There are also 9 exemplars ( | WM | = 9) in the WM. The 2nd, 5th, 6th, 7th, and 9th exemplars be-long to the Respect concept c W 2 = c W 5 = c W 6 = c W 7 = c W 9 =1 : the 2nd and 7th exemplars encode two demonstrations of the Kneel motion pattern, the 5th exemplar encodes a demonstration of the Bend Down motion pattern, and the 2nd and 9th exemplars en-code two demonstrations of the Remove Hat motion pattern. The 1st, 3rd, 4th, and 8th exemplars belong to the Happiness concept c W 1 = c W 3 = c W 4 = c W 8 =2 : the 1st, 3rd, and 8th exemplars encode three demonstrations of the Cheer motion pattern and the 4th exemplar encodes a demonstration of the Dance motion pattern.

Considering the preceding definitions, the general pseudocode of the algorithm ac-companied by its schematic illustration are provided in Figure 3 and Figure 5. Detailed explanation of this algorithm is presented in the following paragraphs.

A New Demonstration is Perceived (lines 1 to 7 in the pseudocode). Now, assume that a novel demonstration is perceived by the robot. First, Likelihood of this perception se-quence ( x = x 1 x 2  X  X  X  x T ) is computed against the HMM prototypes in the LTM, using the Forward algorithm. Next, the HMM prototype with the highest likelihood is consid-ered, and the concept associated with this HMM is selected according to (7) and (8): where c L i is a simple function that maps a prototype index (i.e., i ) to a concept index (i.e., k ). Then, the motor action for that concept (i.e., y k ) is produced and executed. Afterwards, a reinforcement signal (reward or punishment) from the teacher is issued. Now, it is crucial to specify three processes of concept acquisition in the learning algo-rithm [Schank et al. 1986]: when to make a new concept, when to modify a concept, and how to modify a concept. The description of these procedures are as follows. (1) Reinforcement Signal is Positive and the Likelihood of the Catching Prototype is (2) Reinforcement Signal is Positive, But the Likelihood of the Catching Prototype is (3) Reinforcement Signal is Negative, But there are Still Untried Concepts in the Mem-(4) Reinforcement Signal is Negative, But there are No Untried Concepts in the Mem-(5) Making New Prototypes by Clustering Exemplars and Prototypes of a Concept If demonstrations are perceived by the robot X  X  visual system, these observation se-quences or their generalized perceptual patterns generated by HMMs should be trans-formed to motor space for imitation. To this end, we should use a mechanism for mapping perception to action. If the internal models (forward and inverse models) of the robot are given, they can be simply used to make motor programs; otherwise (e.g., for the robotic marionette in our experiment), the mapping should be learned. It is known that this knowledge is acquired by humans (during infancy) in large part through motor babbling. Actually, infants try to learn the sensory-motor system of their body by performing random primitive movements and following these with inter-esting effects. So, for the purpose of hand-eye coordination by motor babbling, we use the algorithm introduced by Ajallooeian et al. [2009a]. This algorithm is summarized as follows. First, a number of temporary goals are determined on the visual path of the teaching trajectory. The robot starts with an initial joint configuration and makes small perturbations in its joint variables. In this way, the end-effectors sweep all the temporary goals gradually. Next, the sensory-motor information at temporary goals is piled up and a mapping from sensory space to motor space is learned with a feed-forward neural network. For more details, the reader is referred to Ajallooeian et al. [2009a]. In the recall phase, there is no more external information by the teacher. So, the robot should use the acquired knowledge in the learning phase to classify the concept of each novel demonstration and produce appropriate motor actions to realize that concept. For this purpose, HMM prototypes in the LTM are used. So, the likelihood of the perceived motion sequence against HMM prototypes is obtained through the Forward algorithm. Next, the HMM with the largest likelihood is chosen, and eventually, the observed motion is recognized as one of the learned concepts by selecting the concept associated with this HMM. Now, a generalized motion pattern is generated by the selected HMM and transformed into motor commands through motor babbling or the robot X  X  inverse models. However, if the motor program of each concept (or its encoded representation) is stored in the memory during the learning phase, this information can be used to retrieve appropriate motor commands. Finally, the robot uses these motor commands to realize the concept. 4.3.1. Online Recognition of Concepts. As previously explained, in the recall phase, the probability of the perceived demonstration is computed against all the prototypes in the LTM. This probability is simply obtained by a forward algorithm which is based on a dynamic programming approach [Rabiner 1990]. In this algorithm, the forward variable which is the probability of partial observation sequence until time t and state S i given the model  X  , is calculated at each step of dynamic programming induction. The result can be summed at any time according to (18) in order to obtain the probability of observation until that time. In this way, an online procedure for concept recognition is attained, and the agent can specify the most probable prototype at any instance of the observation sequence. Consequently, the agent is not only able to perform recogni-tion but also prediction, since the probability of some prototypes gets decreased very quickly. This predictive capability can also help to fixate the focus of attention in the process of tracking the trajectory of demonstration while being performed by the teacher.
 To test our proposed algorithm for conceptual imitation learning, we set up two ex-perimental scenarios. The first one is conceptual imitation learning of hand gestures demonstrated by human subjects, and the second one is conceptual imitation learning of whole body motion patterns of a humanoid model.
 In this experiment, five people are asked to draw six signs by moving their hands in the air. Signs are  X  X eart X ,  X  X ectangle X ,  X  X nfinity X ,  X  X ick X ,  X  X rc X , and  X  X ight X . The subjects can freely start hand movements from any point, but they have to keep their hand in the view field of the robot X  X  camera. Each sign might be produced with different types of hand trajectories. For example, one subject might sketch the Tick sign from left to right and another one from right to left, but the meaning of both sketches is the same for the subjects. In our experiment, we have one perceptual representation for the Rectangle and one perceptual representation for Infinity but two representations for each remaining sign. These demonstrations are incrementally provided to the robot. Samples of demonstrated hand motion patterns are shown in Figure 7.

The robot is a robotic marionette controlled by 8 servo motors that pull the attached strings. The teacher uses same/different judgment explained in Section 3.3 to provide external information for the robot. More precisely, the teacher issues a rewarding sig-nal if his demonstrated action and the robot X  X  response have the same meaning for the teacher, and a punishing signal if they do not have the same meaning. As previously noted, in our experiment different perceptual representations of hand trajectories per-taining to one sign have the same meaning for the teacher. Hence, each sign is consid-ered as a distinctive concept which might have irregularly scattered representations in the robot X  X  visual space. The robot should understand that these perceptions be-long to one concept and imitate that concept. Note that this problem can be simply solved if we find the overall hand movement, take it as a complete shape, and use al-gorithms for shape classification [Ajallooeian et al. 2009b]. However, instead, we are interested in using a sequence of hand movements as perceptual data. The first reason is to design an experiment to evaluate our conceptual imitation model which is suited for relational concepts. The second reason is that the sequences can be also used for motion generation, which yields to an integrated approach for both recognition and reproduction purposes. The third reason is that tracking hand movements can help to use dynamics of the perceived trajectories to identify the gestures faster and more confidently. 5.1.1. Hand Detection and Tracking. For hand detection, we use a saliency-based model of visual attention. It is a biologically inspired bottom-up model proposed by Itti et al. [1998]. In this model the image is filtered and subsampled to make a Gaussian pyra-mid. The pyramid levels are decomposed into channels from which feature maps are constructed. Accordingly, this model can be used to select specific objects by weighting feature channels. Details of image processing and saliency operations for hand motion extraction from video are described by Ajallooeian et al. [2009b]. In this study, we also take advantage of Kalman filtering to track the hand motion path [Emanuele and Alessandro 1998]. Therefore, a more accurate and smoother trajectory is achieved for the hand. 5.1.2. Results. The experiment was conducted in a natural room environment, that is, no artificial background or other simplifications were used. Perceptions are visual information derived from video frames of demonstrations. The hand motion path is extracted through the visual attention model described in Section 5.1.1. Finally, the trajectory of changes in the hand location specified in the camera coordinate is consid-ered as the input to the learning algorithm. It means that the task space is selected as the relative displacement in the hand trajectory. So, the perception is invariant to the translational and rotational transformations in the camera coordinate. The total number of demonstrations in this experiment was 210, including 43 demonstrations for Heart (22 for type 1 and 21 for type 2), 23 demonstrations for Rectangle, 20 demon-strations for Infinity, 42 demonstrations for Tick (21 for each type), 42 demonstrations for Arc (21 for each type), and 40 demonstrations for Eight (20 for each type). We em-ployed our proposed algorithm to learn the concept of demonstrated hand gestures. In the concept learning algorithm, we chose K cutof f =0 . 5, Num th = 3 , and the number of states for HMMs was set to 10. For initializing state distribution of HMMs (i.e., mean and covariance of the state), a rough clustering of the data is performed, and then a Gaussian Mixture Model (GMM) is estimated by Expectation Maximization (EM), us-ing the k-means clusters at initialization. The minimum number of elements to form a new cluster (HMM prototype) was set based on the following rule. There should be at least one prototype and one exemplar or three exemplars in a candidate cluster to make a new prototype. We used k -fold cross-validation with k = 5 to evaluate the performance of our algorithm for abstraction and recognition of the concepts. So, the experiment was repeated five times with different combinations of demonstrations for training and test.

Results of the experiments are summarized as follows. The reinforcement signals (average of five folds) issued by the teacher during the learning phase for the training data are illustrated in Figure 8. More accurately, this plot shows the first reinforce-ment of the teacher for each incoming demonstration. Note that due to the discrete nature of reinforcements (1 for reward, and  X  1 for punishment), the result in the fig-ure is smoothed with a window length of 10 to clearly reflect the expected behavior. The reason that reinforcement is falling in the first demonstrations is that there are not enough prototypes in the LTM at the beginning. In fact, according to the learning algorithm, the concept of perceived demonstrations is first recognized by the proto-types in the LTM. However, there are not equivalent prototypes for all the previously observed concepts in the LTM during the first demonstrations. So, the false classifi-cation ratio (and consequently number of negative reinforcements) increases. But, by increasing the number of exemplars in the WM, they are gradually clustered into pro-totypes and consolidated in the LTM. Hence, the concepts can be fairly represented by the HMMs in the LTM after a short time.
 Figure 9 shows the average smoothed size of the WM and the LTM during learning. The number of HMM prototypes produced at the end of the learning process of each fold is listed in Table I. In most cases, the algorithm finds the same number of HMM prototypes as the number of perceptual representations of each sign shown in Figure 7. In sum, however, there are always one or two prototypes more than what is expected. For example, in the first fold, three prototypes emerge for the Eight sign, but according to previous explanations, two representations were considered for this sign in the task. This outcome is because the features making perceptions out of demonstrations are not scale invariant, but the subjects can freely sketch the signs. To illustrate this outcome, generated motion trajectories through the HMM prototypes of the first fold are demonstrated in Figure 10. To generate these motion sequences, we firstly used the greedy policy explained by Kulic et al. [2008] for optimum state sequence estimation. Next, the values for the observation distribution of each state were put in a sequence, and finally the points at the middle of each state were interpolated with a cubic spline interpolation tool like the one of Billard et al. [2006]. In this figure, it can be seen that although the generated motion sequences for the Eight1 and Eight3 are perceptually similar at first glance, they are different in scale.

We also illustrate the proto-symbol space of HMMs [Takano and Nakamura 2006] for the first fold in Figure 11. This space is constructed based on distances between all pairs of the HMM prototypes in the LTM, using a classical multidimensional scaling method [Seber 1984]. The distance between each pair of HMMs is obtained according to (12). In Figure 11, the first three principal coordinates of multidimensional scaling are used to visualize dissimilarity of HMMs in the proto-symbol space.

To summarize the performance of our proposed method, recognition accuracy of the algorithm for classifying the test demonstrations is provided in Table II. This table also shows some statistics about the number of generated exemplars and prototypes in the WM and LTM. In addition, Table III demonstrates the average confusion matrix for this experiment. It can be observed that recognition accuracy of the Arc concept is the worst. Actually, we used the same number of states (i.e., 10) to train all the HMMs in this experiment, but the suitable number of states varies according to complexity of each sign (i.e., lesser number of states are needed for the Arc sign which has a simple waveform).

As described in Section 4.3 for the recall phase, observed demonstrations are clas-sified based on the generated HMM prototypes in the LTM. But, another possible approach is to use all the HMMs in both WM and LTM. In Figure 12, recognition accuracy of the concepts by HMM prototypes is compared with recognition accuracy by HMM exemplars and prototypes. It is shown that the recognition accuracy of the latter is 91.38% which is about 5% percent more than what is obtained by the former. However, the number of HMMs used in the latter are about 4 times the number of HMMs in the former. As a result, although using HMM exemplars and prototypes might increase recognition accuracy, the computational complexity of this procedure is much more than the computational complexity of using only HMM prototypes.

To show the ability of HMMs for online concept recognition, the trace of relative log likelihood for samples of observed hand gestures against the HMM prototypes of the first fold is depicted in Figure 13. The vertical axis of this plot is defined by It can be observed in this figure that the concept of some gestures can be recognized (predicted) after only a few frames.

Finally, an example of signs (Infinity) produced by the robotic marionette through the babbling algorithm for hand-eye coordination is demonstrated in Figure 14. 5.1.3. Comparison between the Proposed Algorithm and Some Baseline Algorithms. In this section, we compare our proposed algorithm with some standard batch training algorithms. In the batch training, all the demonstrations should be prepared, grouped, and labeled a priori before the learning phase. We consider three algorithms: (1) batch training with conceptual hidden Markov models; (2) batch training with perceptual hidden Markov models; and (3) the algorithm of Ajallooeian et al. [2009b]. In the first algorithm, all samples of one concept are trained by one HMM. Hence, the number of HMMs is exactly the same as the number of concepts. This algorithm is a very usual algorithm for pattern recognition of spatio-temporal signals. In this algorithm, the resulting HMMs can be used for concept recognition, but they cannot be used indepen-dently for regeneration of relational concepts. Actually, since different perceptual vari-ants of a concept are pushed into one model, their perceptual features are mixed up, and the regenerated trajectory might be perceptually similar to none of the variants. In the second algorithm, samples of the same perceptual type (variant) are trained separately with one HMM, and consequently, each concept is made up of the HMMs representing its perceptual variants. For example, in our experimental scenario, there are two HMMs for the Heart, Tick, Arc, and Eight signs and one HMM for the Rectan-gle and Infinity signs (summing up to 10 HMMs). Contrary to the first algorithm, this algorithm can be used for both recognition and regeneration purposes. Note that in the experiments of this section, we used the same parameters and initializing process for the HMMs of batch training algorithms as those described in Section 5.1.2. The third algorithm is a shape classification algorithm, which can be used only in this case study, where demonstrations of the same concept have similar final shape. In this algorithm, the overall visual trajectory of each demonstration is considered as a complete shape. Next, a feature extraction method is used to code the shapes. Finally, the extracted feature vectors are labeled according to their concepts and used for training Support Vector Machines (SVMs). The resulting SVMs are used to classify the demonstration. This algorithm cannot encode the dynamics of demonstrations and consequently can-not be used for regeneration purposes.

Figure 15 shows the comparison between the recognition results of our proposed learning algorithm and the aforementioned batch training algorithms. It can be observed that although the proposed algorithm is incremental and the perceived demonstrations are not labeled a priori in this algorithm, its recognition accuracy is comparable to those of batch training algorithms with conceptual and perceptual mod-els. In fact, since perceptual features of demonstrations are better reinforced in per-ceptual models, they can lead to more strong and comprehensive representation of the concepts. As a result, our incremental learning algorithm, which fairly detects the per-ceptual variants of a concept automatically, is slightly better (in terms of recognition accuracy) than the batch training algorithm with conceptual models, but it is slightly worse than the holistic algorithm of batch training with perceptual models. On the other hand, because of the strong power of SVMs for classification, the algorithm of Ajallooeian et al. [2009b] outperforms all the other algorithms. However, as previously explained, this approach can be used only in this experimental scenario, and also it cannot be used for regeneration of the motion patterns. In this section, we simulate conceptual imitation learning of body motion patterns. The dataset contains joint angle trajectories of a 20 Degree of Freedom (DoF) humanoid model, obtained by a motion capture system [Kadone and Nakamura 2005]. There are 28 demonstrations for  X  X alking X , 15 demonstrations for  X  X heering X , 7 demonstrations for  X  X ancing X , 19 demonstrations for  X  X icking X , 14 demonstrations for  X  X unching X , 13 demonstrations for the  X  X umo Leg Raise X  motion, 13 demonstrations for the  X  X hrowing X , and 15 demonstrations for  X  X owing X , which sum up to 137 demonstra-tions in total. This dataset has been also used by Kulic et al. [2008] for incremental clustering and hierarchy formation of whole body movements. Since the special abil-ity of our algorithm is learning of relational concepts, we combine demonstrations of some motion patterns to make relational concepts. These concepts are characterized in Table IV. Dance and Cheer motions, which can be used to express happiness, are grouped in one concept. Kick and Punch motions, which can be used for hitting, form a new concept, and Sumo Leg Raise 2 and Bow 3 motions, which are basic exercises used in Japanese martial arts, form the third combined concept.
In the experiment, the 20-dimensional joint angle trajectories are incrementally en-tered to the learning algorithm. Then a virtual teacher, which is simulated by software, issues a positive or negative reinforcement signal if the learning algorithm guesses the concept of the incoming demonstration correctly or incorrectly. In this way, the whole experiment can be simulated without any real teacher and imitator. For the learning algorithm, we use the same settings as explained in Section 5.1.2, that is, K cutof f =0 . 5, Num th = 3, and 10 states for each HMM. Again, the results are evaluated with a 5-fold cross-validation. 5.2.1. Results. The average reinforcement over demonstrations during the learning phase is shown in Figure 16. It can be observed in the figure that the concept of al-most all new demonstrations can be recognized after training by a few demonstrations. In addition, the average smoothed size of the LTM and WM throughout the learning phase is shown in Figure 17.

The number of prototypes produced at the end of learning by each fold is reported in Table V. In most cases, the algorithm finds the same number of prototypes as the number of motion patterns which represent perceptual variants of a concept.
After termination of the learning phase, we use the resulting prototypes of the LTM to recognize the concept of the test demonstrations (according to the explanations in Section 4.3). The outcome is that the algorithm can correctly classify all the test demonstrations. In this study, we introduced a model for conceptual imitation learning through in-teraction with a teacher. The main contribution was to devise an incremental and gradual learning algorithm for autonomous learning and acquisition of relational con-cepts from spatio-temporal demonstrations, using reinforcement signals and inter-active teaching. HMMs were used to abstract spatio-temporal demonstrations into stochastic perceptual prototypes and exemplars. Consequently, relational concepts were formed as a collection of irregularly scattered HMMs unified based on their functional meaning. This abstraction leads to efficient memory management, gener-alization of acquired information, ease of knowledge transfer, and flexibility of choice between different alternatives. Finally, we evaluated the proposed algorithm in two ex-perimental scenarios, namely conceptual imitation learning of real hand gestures and conceptual imitation learning of whole body motion patterns of a humanoid model. Re-sults showed that our algorithm is successful for acquisition of concepts, emergence and self-organization of prototypes, recognition, prediction, and generation of con-cepts. Comparison between the proposed algorithm and some baseline batch training algorithms showed that our incremental algorithm is comparable to standard HMM-based batch training algorithms in recognition results. Moreover, this algorithm can be used for regeneration of different perceptual variants of a concept, which is not possible in some other algorithms.
 We can name at least two problems with the proposed algorithm of this article. First, recognition accuracy of the algorithm decreases at the first demonstrations. This is because the algorithm sets a priority on selection of prototypes over exemplars while it takes some time to have appropriate prototypes made. The second problem is with selection of a suitable number of states for HMMs. Since our algorithm is incremental, it is not possible to use standard algorithms like BIC [Billard et al. 2006] or AIC [Kulic et al. 2007] to estimate the optimal number of states. Hence, the best approach is to adopt an adaptive model size for each concept. One possible solution is to use Factorial Hidden Markov Models (FHMM) according to the explanations of Kulic et al. [2008].
For future work, we are focused on improving the learning algorithm for better or-ganization of prototypes in the LTM to increase recognition accuracy throughout the learning phase. In addition, we aim to extend the model for multimodal concept rep-resentation and recognition, concept classification of spatio-temporal demonstrations with missing data, and concept categorization of stimulating actions based on their functional effects.

