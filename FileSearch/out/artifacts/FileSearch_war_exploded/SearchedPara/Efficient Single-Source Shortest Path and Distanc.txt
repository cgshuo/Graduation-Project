 This paper investigates two types of graph queries: single source distance (SSD) queries and single source shortest path (SSSP) queries. Given a node v in a graph G , an SSD query from v the distance from v to any other node in G , while an SSSP query re-trieves the shortest path from v to any other node. These two types of queries fi nd important applications in graph analysis, especially in the computation of graph measures. Most of the existing solu-tions for SSD and SSSP queries, however, require that the input graph fi ts in the main memory, which renders them inapplicable for the massive disk-resident graphs commonly used in web and social applications. There are several techniques that are designed to be I/O ef fi cient, but they all focus on undirected and/or unweighted graphs, and they only offer sub-optimal query ef fi ciency. To address the de fi ciency of existing work, this paper presents Highways-on-Disk (HoD) , a disk-based index that supports both SSD and SSSP queries on directed and weighted graphs. The key idea of HoD is to augment the i nput graph with a set of auxiliary edges, and exploit them during query processing to reduce I/O and computation costs. We experimentally evaluate HoD on both di-rected and undir ected real-world graphs with up to billions of nodes and edges, and we demonstrate that HoD signi fi cantly outperforms alternative solutions in terms of query ef fi ciency.
 D.2.2 [ Graph theory ]: Graph algorithms Shortest path queries; Distance queries; Graph; Algorithm
Given a graph G ,a single source distance (SSD) query from a node v  X  G asks for the distance from v to any other node in Meanwhile, a single source shortest path (SSSP) query retrieves the shortest path from v to any other node. These two types of queries fi nd important applications in graph analysis [8], especially in the computation of graph measures [5, 7, 11, 24]. For example, the estimation of cl oseness measures [11] on a graph G requires performing SSD queries from a large number of nodes in G , while the approximation of betweenness measures [7] requires executing numerous SSSP queries.

The classic solution for SSD and SSSP queries is Dijkstra X  X  al-gorithm [10]. Given a SSD or SSSP query from a node s , Dijkstra X  X  algorithm traverses the graph starting from s , such that the nodes in
G are visited in ascending order of their distances from s a node v is visited, the algorithm returns the distance from based on the information maintained during the traversal; the short-est path from s to v can also be ef fi ciently derived if required. A plethora of techniques have been proposed to improve over Dijkstra X  X  algorithm for higher query ef fi ciency (see [9,23] for sur-veys). Although those techniques all require pre-processing the given graph (which incurs extra overhead compared with Dijk-stra X  X  algorithm), the pre-computation pays off when the number of queries to be processed is large, as is often the case in graph analysis. Nevertheless, most of the existing techniques assume that the given graph fi ts in the main memory (for pre-computation and/or query processing), which renders them inapplicable for the massive disk-resident graphs commonly used in web and social ap-plications. There are a few methods [15, 17 X 20] that address this issue by incorporating Dijkstra X  X  algorithm with I/O-ef fi cient data structures, but the performance of those methods are shown to be insuf fi cient for practical applications [8]. The main reason is that, when Dijkstra X  X  algorithm traverses the graph, the order in which it visits nodes can be drastically different from the order in which the nodes are arranged on the disk. This leads to a signi fi cant number of random disk accesses, which results in poor query performance.
In contrast to the aforementioned techniques, Cheng et al. [8] propose the fi rst practically ef fi cient index (named VC-Index )for SSD and SSSP queries on disk-resident graphs. The basic idea of VC-Index is to pre-compute a number of reduced versions of the input graph G . Each reduced graph contains some relatively im-portant nodes in G , as well as the distances between some pairs of those nodes. During query processing, VC-Index scans a selected subset of reduced graphs, and then derives query results based on the pre-computed distances. Compared with those methods based on Dijkstra X  X  algorithm [15, 17 X 20], VC-Index is more ef fi cient as it only performs sequential reads on disk-resident data. Motivation and Contribution. All existing disk-based solutions for SSD and SSSP queries [15, 17 X 20] require that the input graph is undirected, which renders them inapplicable for any application built upon directed graphs. This is rather restrictive as numerous important types of graphs (e.g., road networks, web graphs, social graphs) are directed in nature. Furthermore, even when the input graph is undirected, the query ef fi ciency of the existing solutions is less than satisfactory. In particular, our experiments (in Section 7) show that VC-Index, albeit being the state of the art, requires tens of seconds to answer a single SSD query on a graph with less than 100 million edges, and needs more than two days to estimate the closeness measures on the same graph.
 To address the de fi ciency of existing work, this paper proposes Highways-on-Disk (HoD) , a disk-based index that supports both SSD and SSSP queries on directed and weighted graphs. The key idea of HoD is to augment the input graph with a set of auxil-iary edges (referred to as shortcuts [22]), and exploit them during query processing to reduce I/O and computation costs. For exam-ple, Figure 1a illustrates a graph G , and Figure 1e shows an aug-mented graph G  X  constructed from G . G  X  contains three shortcuts: v 8 ,v 9 , v 9 ,v 7 ,and v 9 ,v 10 . Each shortcut has the same length with the shortest path connecting the endpoints of the shortcut. For example, the length of v 8 ,v 9 equals 2 , which is identical to the length of the shortest path from v 8 to v 9 . Intuitively, the shortcuts in
G  X  enable HoD to ef fi ciently traverse from one node to another (in a manner similar to how highways facilitate traversal between distant locations). For instance, if we are to traverse from v 10 in G  X  , we may follow the path v 1 ,v 9 ,v 10 , which consists of only three nodes; in contrast, a traversal from v 1 to v 10 require visiting fi ve nodes: v 1 , v 9 , v 6 , v 7 ,and v
In general, when HoD answers an SSD or SSSP query, it often traverses the augmented graph via shortcuts (instead of the original edges in G ). We show that, with proper shortcut construction and index organization, the query algorithm of HoD always traverses nodes in the same order as they are arranged in the index fi le. Con-sequently, HoD can answer any SSD or SSSP query with a linear scan of the index fi le, and its CPU cost is linear to the number of edges in the augmented graph. We experimentally evaluate HoD on a variety of real-world graphs with up to 100 million nodes and 3 billion edges, and we demonstrate that HoD signi fi cantly out-performs VC-Index in terms of query ef fi ciency. In particular, the query time of HoD is smaller than that of VC-Index by up to two orders of magnitude. Furthermore, HoD requires a smaller space and pre-computation time than VC-Index in most cases.
Let G be a weighted and directed graph with a set V of nodes and a set E of edges. Each edge e in E is associated with a positive weight l ( e ) , which is referred to as the length of e .Apath is a sequence of nodes v 1 ,v 2 ,...,v k , such that v i ,v [1 ,k  X  1] ) is a directed edge in G . The length of P is de fi ned as the sum of the length of each edge on P .Weuse l ( e ) and denote the length of an edge e and a path P , respectively.
For any two nodes s and t in G ,wede fi ne the distance from t , denoted as dist ( s, t ) , as the length of the shortest path from t .Givena source node s in G ,a single-source distance (SSD) query asks for the distance from s to any other node in G . Meanwhile, a single-source shortest path (SSSP) query from s retrieves not only the distance from s to any other node v ,butalsothe predecessor of v , i.e., the node that immediately precedes v in the shortest path from s to v . Note that, given the predecessor of each node, we can easily reconstruct the shortest path from s to any node v tracking from v following the predecessors. One may also consider an alternative formulation of SSD (resp. SSSP) query that, given only a destination node t , asks for the distance (resp. shortest path) f rom any other node to t . For simplicity, we will focus on SSD and SSSP queries from a source node s , but our solution can be easily extended to handle queries under the alternative formulation.
Let M be the size of the main memory available, and B be the size of a disk block, both measured in the number of words. We assume that B  X | V | X  M  X | E | , i.e., the main memory can accommodate all nodes but not all edges in G . This is a realistic as-sumption since modern machines (even the commodity ones) have gigabytes of main memory, which is suf fi cient to store the node set of a graph with up to a few billio n nodes. On the other hand, the number of edges in a real graph is often over an order of magnitude larger than the number of nodes, due to which E can be enormous in size and does not fi t in the main memory.

Our objective is to devise an index structure on G that answers any SSD or SSSP query with small I/O and CPU costs, such that the index requires at most M main memory in pre-computation and query processing. In what follows, we will fi rst focus on SSD queries in Sections 3-5, and will extend our solution for SSSP queries in Section 6. As mentioned in Section 1, the main structure of HoD is a graph G  X  that augments the input graph G with shortcuts. In this section, we present the overall idea of how the shortcuts in G  X  are con-structed and how they can be utilized for query processing, so as to form a basis for the detailed discussions in subsequent sections.
In a nut shell, HoD constructs shortcuts with an iterative proce-dure, which takes as input a copy of the graph G (denoted as In the i -th ( i  X  1 ) iteration of the procedure, HoD fi rst reduces G i  X  1 by removing a selected set of less important nodes in and then, it constructs shortcuts in the reduced graph to ensure that the distance between any two remaining nodes is not affected by the node removal. The resulting graph (with shortcuts added) is denoted as G i , and it is fed as the input of the ( i +1 procedure. This procedure terminates only when the reduced graph G i is suf fi ciently small . All shortcuts created during the procedure are inserted into the original graph G , leading to an augmented graph G  X  that would be used by HoD for query processing. We illustrate the iterative procedure with an example as follows.
E XAMPLE 1. Assume that the input to the iterative procedure is the graph G 0 in Figure 1a. Further assume that the reduced graph is suf fi ciently small if it contains at most two nodes and two edges. In the fi rst iteration of the procedure, HoD inspects G 0 and identi fi es v , v 2 ,and v 3 as less important nodes. To explain, observe that the node v 1 in G 0 does not have any incoming edge, while v 2 have no outgoing edges. As a consequence, v 1 , v 2 ,and v lie on the shortest path between any two other nodes. That is, even if we remove v 1 , v 2 ,and v 3 from G 0 , the distance between any two remaining nodes is not affected. Intuitively, this indicates that v , v 3 are of little importance for SSD queries. Therefore, HoD eliminates v 1 , v 2 ,and v 3 from G 0 , which results in the reduced graph G 1 in Figure 1b.

In the second iteration, HoD selects v 4 , v 5 ,and v 6 as the less important nodes in G 1 , and removes them from G 1 .Theremoval of v 4 changes the distance from v 8 to v 9 to +  X  ,since v 8 is the only path (in G 1 )thatstartsat v 8 and ends at v 9 this change, HoD inserts into G 1 a shortcut v 8 ,v 9 that has the same length with v 8 ,v 4 ,v 9 , as illustrated in Figure 1c. As such, the distance between any two nodes in G 1 remains unchanged after v is removed. Similarly, when HoD eliminates v 6 , it constructs a shortcut v 9 ,v 7 with a length 2 to reconnect the two neighbors of v . Meanwhile, v 5 is removed without creating any shortcut, since deleting v 5 does not change the distance between its two neighbors. Figure 1c illustrates the resulting reduced graph G 2 . To explain why HoD chooses to remove v 4 , v 5 ,and v 6 from observe that each of those nodes has only two neighbors. For any v v v v of such nodes, even if the removal of the node changes the distance between its neighbors, HoD only needs to construct one shortcut to reconnect its neighbors. In other words, the number of shortcuts required is minimum, which helps reduce the space consumption of HoD. In contrast, if HoD chooses to remove v 9 from G 1 has a larger number of neighbors than v 4 , v 5 ,and v 6 ), then much more shortcuts would need to be constructed.
 Finally, in the third iteration, HoD removes v 7 and v 8 from as they are considered unimportant. The removal of v 7 leads to a new shortcut v 9 ,v 10 with a length 3 ,since v 9 ,v 7 ,v only path connecting v 9 to v 10 , and the length of the path equals 3 . On the other hand, v 8 is directly eliminated as it is not on the shortest path between its only two neighbors v 9 and v 10 shows the reduced graph G 3 after the removal of v 7 and v
Assume that the reduced graph G 3 is considered suf fi ciently small by HoD. Then, the iterative procedure of HoD would ter-minate. The three shortcuts created during the procedure (i.e., v 8 ,v 9 , v 9 ,v 7 ,and v 9 ,v 10 ) are added into the original graph G , which leads to the augmented graph G  X  in Figure 1d.

The above discussion leaves several issues open, i.e., (i) the spe-ci fi c criterion for identifying less important nodes in the reduced graph, (ii) the detailed algorithm for generating shortcuts after node removal, and (iii) the exact term ination condition of the reduction procedure. We will clarify these issues in Section 4 by presenting the detailed preprocessing algorithm of HoD. For the discussions in the rest of this section, it suf fi ces to know that when HoD ter-minates the reduction procedure, the reduced graph must fi tinthe main memory. We use G c to denote this memory-resident reduced graph, and we refer to it as the core graph . (Note that G graph of the augmented graph G  X  .) In addition, we de fi ne the rank r ( v ) of each node v in G as follows: 1. If v is removed in the i -th iteration of the iterative procedure, 2. If v is not removed in any iteration (i.e., v is retained in the For instance, in Example 1, the ranks of v 1 , v 2 ,and v since they are removed from G in the fi rst iteration of the reduction procedure. Similarly, r ( v 4 )= r ( v 5 )= r ( v 6 )=2 ,and r ( v r ( v 8 )=3 . The ranks of v 9 and v 10 equal 4 , since they are in the core graph G c . The ranks of the nodes are utilized in the query processing algorithms of HoD, as will be illustrated shortly. Unless otherwise speci fi ed, we use the term edge to refer to both a shortcut and an original edge in G  X  .
Given an SSD query from a node s , HoD answers the query with two traversals of the augmented graph G  X  .The fi rst traver-sal starts from s , and it follows only the outgoing edges of each node, ignoring any edge whose starting point ranks higher than the ending point . For instance, if HoD traverses from the node v in Figure 1e, it would ignore the outgoing edge v 9 ,v 7 ,since r ( v 9 )=4 &gt;r ( v 7 )=3 . As such, the fi rst traversal of HoD never moves from a high-rank node to a low-rank node, and it terminates only when no higher-rank nodes can be reached. For each node visited, HoD maintains the distance from s to v along the paths that have been seen during the traversal, denoted as dist ( s, v ) Let V be the set of nodes that are not in the core graph of The second traversal of HoD is performed as a linear scan of the nodes in V , in descending order of their ranks . For each node v  X  V scanned, HoD inspects each incoming edge e of v ,and then checks the starting point u of the edge. For any such calculates dist ( s, u )+ l ( e ) as an upperbound of the distance from s to v . (Our solution guarantees that u should have been visited by HoD before v .) Once all incoming edges of v are inspected, HoD derives the distance from s to v based on the upperbounds, and then it moves on to the next node in V . This process terminates when all nodes in V are examined.
 We illustrate the above query algorithm of HoD with an example.
E XAMPLE 2. Consider an SSD query from node v 1 in Fig-ure 1a. Given the augmented graph G  X  in Figure 1e, HoD fi rst traverses G  X  starting from v 1 , following the outgoing edges whose ending points rank higher than the starting points. Since only one outgoing edge v 1 ,v 9 , and since v 9 ranks higher than HoD moves from v 1 to v 9 . v 9 has three outgoing edges: v 9 ,v 7 ,and v 9 ,v 10 . Among them, only v 9 ,v 10 has an end-ing point that ranks higher than the starting point. Therefore, HoD moves from v 9 to v 10 . v 10 has outgoing edges to three unvisited nodes, i.e., v 3 , v 5 ,and v 8 . Nevertheless, all of those nodes rank lower than v 10 , and hence, they are ignored. As none of the re-maining nodes can be reached without violating the constraints on node ranks, the fi rst traversal of HoD ends. Based on the edges visited, HoD calculates dist ( v 1 ,v 9 )=1 and dist ( v 1
The second traversal of HoD examines the nodes not in the core graph in descending order of their ranks, i.e., it fi rst exam-ines v 7 and v 8 (whose ranks equal 3 ), followed by v 4 , v 6 (whose ranks equal 2 ), and fi nally v 2 and v 3 (whose ranks equal 1 ), ignoring v 1 (as it is the source node of the query). has two incoming edges, v 6 ,v 7 and v 9 ,v 7 . Among v 6 v , only v 9 has been visited by HoD. Therefore, HoD calculates dist ( v 1 ,v 7 )= dist ( v 1 ,v 9 )+ l ( v 9 ,v 7 )=3 . Similarly, af-ter inspecting v 8  X  X  only incoming edge v 10 ,v 8 , HoD computes dist ( v 1 ,v 8 )= dist ( v 1 ,v 10 )+ l ( v 10 ,v 8 )=5 . The remaining nodes are processed in the same manner, resulting in
Observe that all the above distances computed from G  X  are identi-cal with those from the original graph in Figure 1a.

The query algorithm of HoD has an interesting property: the fi rst traversal of the algorithm always visits nodes in ascending order of their ranks (as it never follows an edge that connects a high-rank node to low-rank node), while the second phase always visits nodes in descending rank order. Intuitively, if we maintain two copies of the augmented graph, such that the fi rst (resp. second) copy stores nodes in ascending (resp. descending) order of their ranks, then HoD can answer any SSD query with a linear scan of the two copies. This leads to high query ef fi ciency as it avoids random disk accesses. In Section 4, we will elaborate how such two copies of the augmented graph can be constructed.
As discussed in Section 3.1, the preprocessing algorithm of HoD takes as input a copy G 0 of the graph G , and it iteratively reduces G 0 into smaller graphs G 1 ,G 2 ,... , during which it creates short-cuts to augment G . More speci fi cally, the ( i +1 )-th ( of the algorithm has four steps: 1. Select a set R i of nodes to be removed from G i . 2. For each node v  X  R i , construct shortcuts in G i to ensure 3. Remove the nodes in R i from G i to obtain a further reduced 4. Pass the G i +1 to the ( i +2 )-th iteration as input. In the following, we fi rst elaborate Steps 2 and 3 , and then clarify Step 1 . After that, we will discuss the termination condition of the preprocessing algorithm, as well as its space and time complexities.
For ease of exposition, we represent each edge e = u, v as a triplet u, v, l ( e ) or v,u,  X  l ( e ) ,where l ( e ) is the length of For example, the edge v 9 ,v 7 in Figure 1a can be represented as either v 9 ,v 7 , 2 or v 7 ,v 9 ,  X  2 . That is, a negative length in the triplet indicates that the second node in the triplet is the starting point of the edge. In addition, we assume that the input graph stored on the disk as adjacency lists, such that (i) for any two nodes v and v j , the adjacency list of v i precedes that of v j if and (ii) each edge v i ,v j with length l is stored twice: once in the adjacency list of v i (as a triplet v i ,v j ,l ), and another in the adjacency list of v j (as a triplet v j ,v i ,  X  l ).
Let v  X  be a node to be removed from G i .Wede fi ne an outgoing neighbor of v  X  as a node u to which v  X  has an outgoing edge. Similarly, an incoming neighbor of v  X  is a node w from which has an incoming edge. We have the following observation:
O BSERVATION 1. For any two nodes v j and v k in G i , the dis-tance from v j to v k changes after v  X  is removed, if and only if the shortest path from v j to v k contains a sub-path u, v  X  ,w u (resp. w ) is an incoming (resp. outgoing) neighbor of v  X 
By Observation 1, we can preserve the distance between any two nodes in G i after removing v  X  , as long as we ensure that the dis-tance between any incoming neighbor and any outgoing neighbor of v  X  remains unchanged. This can be achieved by connecting the incoming and outgoing neighbors of v  X  with shortcuts, as demon-strated in Section 3.1. Towards this end, a straightforward approach is to generate a shortcut u, w for any incoming neighbor u any outgoing neighbor w . The shortcuts thus generated, however, are often redundant . For example, consider the graph G i ure 2a. Suppose that we are to remove v 2 , which has an incoming neighbor v 1 and an outgoing neighbor v 3 . If we construct a short-cut from v 1 to v 3 , it is useless since (i) v 1 already has an outgoing edge to v 3 , and (ii) the edge v 1 ,v 3 is even shorter than the path from v 1 to v 3 via v 2 . As another example, assume that ure2aisalsotoberemoved. v 4 has an incoming neighbor v 1 and an outgoing neighbor v 5 ,butthepath v 1 ,v 4 ,v 5 is no shorter than another path from v 1 to v 5 , i.e., v 1 ,v 3 ,v 5 , which does not go through v 4 . As a consequence, even if we remove v 4 from distance from v 1 to v 5 is still retained, and hence, it is unnecessary to insert a shortcut from v 1 to v 5 .

In general, for any incoming neighbor u and outgoing neighbor w of v  X  , a shortcut from u to w is unnecessary if there is a path P from u to v , such that (i) P does not go through v  X  , and (ii) P is no longer than u, v  X  ,w . To check whether such a path exists, one may apply Dijkstra X  X  algorithm to traverse G i (or w ), ignoring v  X  during the traversal. However, when not fi t in main memory (as is often the case in the pre-computation process of HoD), this approach incurs signi fi cant overhead, due to the inef fi ciency of Dijkstra X  X  algorithm for disk-resident graphs (as discussed in Section 1). To address this issue, we adopt a heuristic approach that is not as effective (in avoiding redundant shortcuts) but much more ef fi cient. Speci fi cally, for each v  X  in the node set to be removed from G i , we generate a candidate edge e c from each incoming neighbor u of v  X  to each outgoing neighbor of v  X  , setting the length of the shortcut to l ( u, v  X  ,w ) such candidate edge e c , we insert it into a temporary fi le triplets: u, w, l ( e c ) and w,u,  X  l ( e c ) .

In addition to the candidate edges, we also insert two additional groups of edges (referred to as baseline edges ) into the temporary fi le T as triplets. The fi rst group consists of any edge necting two nodes not in R i , i.e., the two endpoints of be removed. The second group is generated as follows: for each node v not in R i , we select v  X  X  certain incoming neighbor outgoing neighbor w , and we construct a baseline edge u ,w setting its length to l ( u ,v,w ) .
 The purpose of inserting a baseline edge e into the temporary fi le T is to help eliminate any redundant candidate edge that (i) shares the same endpoints with e but (ii) is not shorter than e . Towards this end, once all baseline edges are added into T , we sort the triplets in
T using a standard algorithm for external sort, such that a triplet t = v a ,v b ,l 1 precedes another triplet t 2 = v  X  ,v  X  ,l of the following conditions hold: 1. a&lt; X  ,or a =  X  but b&lt; X  . 2. a =  X  , b =  X  ,and l 1 &gt; 0 &gt;l 2 . That is, any outgoing edge 3. a =  X  , b =  X  , l 1  X  l 2 &gt; 0 (i.e., t 1 and t 2 are both incoming 4. a =  X  , b =  X  , l 1  X  l 2 &gt; 0 , | l 1 | = | l 2 | ,and Once T is sorted, the outgoing (resp. incoming) edges with the same endpoints are grouped together, and the fi rst edge in each group should have the smallest length within the group. If the fi rst edge e in a group is a candidate edge, then we retain e as it is shorter than any other baseline or candidate edges that we have generated. On the other hand, if e is a baseline edge, then the distance between the endpoints of e must not be affected by the removal of any nodes in R i . In that case, all candidate edges in the group can be omitted. With one linear scan of the sorted T and the adjacency lists of we can remove the information of any node in R i , and merge the retained candidate edges into the adjacency lists of the remaining nodes. We illustrate the above algorithm with an example.
E XAMPLE 3. Suppose that, given the graph G i in Figure 2a, we are to remove a node set R i = { v 2 ,v 4 } from G i . only one incoming neighbor v 1 and one outgoing neighbor v and l ( v 1 ,v 2 ,v 3 )=2 . Accordingly, HoD generates a candidate edge v 1 ,v 3 by inserting into the temporary fi le T two triplets, v 1 ,v 3 , 2 and v 3 ,v 1 ,  X  2 . Similarly, for v 4 , HoD creates a can-didate edge v 1 ,v 5 , which is represented as two triplets in v 1 ,v 5 , 2 and v 5 ,v 1 ,  X  2 .

Meanwhile, the edge v 1 ,v 3 in G i is selected as a baseline edge and is inserted into T , since neither v 1 nor v 3 is in R HoD also generates a baseline edge v 1 ,v 5 from the neighbors of v 3 . This is because that (i) v 1 ,v 3 ,v 5 are not in R an incoming neighbor of v 3 , and (iii) v 5 is an outgoing neighbor of v 3 . Figure 2c illustrates the temporary fi le T after all candi-date and baseline edges are inserted, with some triplets omitted for simplicity. Figure 2d shows the fi le T after it is sorted. The base-line edge v 1 ,v 3 , 1 precedes the candidate edge v 1 ,v indicates that we do not need to add a shortcut from v 1 to ilarly, the baseline edge v 3 ,v 1 ,  X  1 precedes the candidate edge v 3 ,v 1 ,  X  2 , in which case the latter is omitted. Overall, each of the candidate edges in T is preceded by a baseline edge, and hence, no shortcut will be created. Consequently, HoD removes from the adjacency lists of v 2 and v 4 , as well as all edges to and from v and v 4 in any other adjacency lists. This results in the reduced graph illustrated in Figure 2b.

In summary, HoD decides whether a candidate edge e should be retained, by comparing it with all edges in G i as well as some two-hop paths in G i . This heuristic approach may retain unnec-essary candidate edges, but it does not affect the correctness of SSD queries. To understand this, recall that each candidate edge e = u, w has the same length with a certain path u, v  X  ,w exists in G i ,where v  X  is the node whose removal leads to the cre-ation of e . In other words, the length of e is at least larger than or equal to the distance from u to w . Adding such an edge into would not decrease the distance between any two nodes in G hence, retaining e does not change the results of any SSD queries.
The above discussions assume that HoD has selected a set R of nodes to be removed from G i , and has decided which baseline edges are to be generated from the neighbors of the nodes not in R . We will clarify these two issues in Section 4.2 and 4.3.
Consider any node v in G i . Intuitively, if the removal of quires us to insert a large number of shortcuts into G i ,then lie on the shortest paths between many pair of nodes, in which case v should be considered important. Let B in and B out be the set of incoming and outgoing neighbors of v , respectively. The maximum number of shortcuts induced by v  X  X  removal is: We refer to s ( v ) as the score of v in G i , and we consider portant if s ( v ) is no more than the median score in G i tical ef fi ciency, we use an approximated value of the median score computed from a sample set of the nodes.) Ideally, we would like to remove all unimportant nodes from but this is not always feasible. To explain, consider that we are given the reduced graph G 1 in Figure 1b, and we aim to elimi-nate both v 6 and v 7 . v 6 has only one incoming neighbor one outgoing neighbor v 7 , and hence, HoD creates one candidate edge v 9 ,v 7 , setting its length to 2 (i.e., the length of the path v 9 ,v 6 ,v 7 ). Similarly, for v 7 , HoD generates a candidate edge v 6 ,v 10 . These two candidate edges are intended to preserve the distance between any two nodes in G i after v 6 and v 7 are removed. However, none of the two candidate edges is valid if both v are eliminated. In particular, v 9 ,v 7 points from v 9 to it connects v 9 to a node that no longer exists. To avoid the above error, whenever HoD chooses to delete a node v from G i , it will retain all neighbors of v in G i , even if some neighbor might be unimportant. For example, in Figure 1b, if HoD decides to remove v , then it will prevent v 7 from being removed at the same time, and vice versa.
As mentioned in Section 4.1, a baseline edge generated by the preprocessing algorithm of HoD is either (i) an edge in G endpoints are not to be removed, or (ii) an arti fi cial edge corresponds to certain two-hop path u, v, w in G i , such that none of u, v, w is to be removed. The construction of baseline edges from two-hop paths is worth discussing. First, given that there ex-ists an enormous number of two-hop paths in G i , it is prohibitive to convert each two-hop path into a baseline edge. Therefore, we only select a subset of the two-hop paths in G i for baseline edge genera-tion. In particular, the total number of two-hop paths selected is set to c  X  v  X  R i s ( v ) ,where c is a small constant, s ( v ) Equation 1, and v  X  R induced by the removal of nodes in R i . In other words, we require that the number of baseline edges generated from two-hop paths is at most c times the number of candidate edges. In our implementa-tion of HoD, we set c =5 .
 First, we randomly choose an edge in G i , and arbitrarily select an endpoint v of the edge that is not in R i . (Note that such an end-point always exists.) After that, from the incoming (resp. outgoing) neighbors of v , we randomly select a node u (resp. w ), and we gen-erate a baseline edge u, w , setting its length to l ( u, v, w ) such, if a node v is adjacent to a large number of edges, then it has a high chance of being selected to produce baseline edges. This is in-tuitive since such a node v tends to lie on the shortest paths between many pairs of nodes, and hence, the baseline edges generated from v may be more effective in eliminating redundant shortcuts. As mentioned in Section 3, HoD requires that the core graph fi ts in the main memory, where G c is the reduced graph obtained in the last iteration of HoD X  X  preprocessing algorithm. Accordingly, we do not allow the pre-computation procedure of HoD to termi-nate before the reduced graph G i has a size no more than addition, even after G i fi ts in the main memory, we will still con-tinue the preprocessing procedure, until the size of G i is reduced by less than 5% in an iteration of the processing algorithm. This is intended to reduce the size of the core graph G c to improve query ef fi ciency, as will be explained in Section 5. Once the preprocessing procedure completes, the core graph is written to the disk in the form of adjacency lists. Meanwhile, the adjacency list of each node not in G c is separated into two parts that are stored in two different fi les, F f and F b .Thesetwo fi les are created at the beginning of HoD X  X  preprocessing algorithm, and they are initially empty. Whenever a node v is removed from the reduced graph G i , we inspect the adjacency list of v in we append all of v  X  X  outgoing (resp. incoming) edges to F F ). Upon termination of the preprocessing procedure, we reverse the order of nodes in F b , but retain the order of nodes in refer to the graph represented by F f as the forward graph , denoted as
G f . Meanwhile, we refer to the graph represented by F b the backward graph , denoted as G b . When combined, G c , and G b form the augmented graph that is used by HoD for query processing. For example, for the augmented graph in Figure 1a, its core graph is as illustrated in Figure 1e, while its forward and backward graphs are as shown in Figure 3. For ease of exposition, we will abuse notation and use G f (resp. G b ) to refer to both (resp. G b ) and its underlying fi le structure F f (resp. G f and G b have two interesting properties. First, all nodes in G f (resp. G b ) are stored in ascending (resp. descending) order of their ranks. To explain this, recall that any node v removed in the i -th iteration of the preprocessing algorithm has a rank r ( v )= i Consequently, if a node u is stored in G f before another node then r ( u )  X  r ( w ) .Asfor G b , since we reverse the order of all edges in G b upon termination of the preprocessing produce, we have r ( u )  X  r ( w ) for any node u that precedes another node G . Second, for any node v , its edges in G f and G b only connect it to the nodes whose ranks are strictly higher than v . Thisisbe-cause, by the time v is removed from the reduced graph, all nodes that rank lower than v must have been eliminated from the reduced graph, and hence, any edge in v  X  X  adjacency list only links nodes whose rank is at least r ( v ) . Meanwhile, any neighbor in the reduced graph should have a rank higher than r ( v ) wise, we have r ( u )= r ( v ) , which, by the de fi nition of node ranks, indicates that u and v are removed in the same iteration of the pre-processing algorithm. This is impossible as the pre-computation procedure of HoD never eliminates two adjacent nodes in the same iteration, as explained in Section 4.1. In Section 5, we will show how HoD exploits the above two properties of G f and G b to ef fi -ciently process SSD queries.
The preprocessing algorithm of HoD requires O ( n ) main mem-ory, where n is the number of nodes in G . This is because (i) when removing a node v from the reduced graph, HoD needs to record the neighbors of v and exclude them from the node removal process, and (ii) v may have O ( n ) neighbors. Other parts of the preprocess-ing algorithm do not have a signi fi cant memory requirement.
The major I/O and CPU costs of the preprocessing algorithm are incurred by sorting the edge triplets in each iteration. In the worst case when the input graph G is a complete graph, there are triplets generated in each iteration, leading to a prohibitive I/O and v v CPU overhead. Fortunately, real-world graphs are seldom com-plete graphs, and they tend to contain a large number of nodes with small degrees. In that case, each iteration of HoD X  X  preprocess-ing procedure would only generates a moderate number of edge triplets, leading to a relatively small overhead.

Lastly, the space consumption of HoD X  X  index is O ( n 2 ) since, in the worst case, HoD may construct a shortcut from each node v to every node that ranks higher than v . This space complex-ity is unfavorable, but it is comparable to the space complexity of VC-Index [8]. In addition, as shown in our experiments, the space requirement of HoD in practice is signi fi cantly smaller than the worst-case bound. Given an SSD query from a node s that is not in the core graph G , HoD processes the query in three steps: 1. Forward Search: HoD traverses the forward graph G f start-2. Core Search: HoD reads the core graph G c into the main 3. Backward Search: HoD linearly scans the backward graph On the other hand, if s is in G c , then HoD would answer the query with a core search followed by a backward search, skipping the forward search. In what follows, we will present the details of three searches performed by HoD. For convenience, we de fi ne an index value  X  ( v ) for each node not in the core graph G c , such that i only if the i -th adjacency list in G f belongs to v .Bytheway is constructed (see Section 4.5), for any two nodes u and  X  ( u ) &lt; X  ( v ) , the rank of u is no larger than the rank of
The forward search of HoD maintains a hash table H f and a min-heap Q f . In particular, H f maps each node v to a key which equals the length of the shortest path from s to v that is seen so far. Initially,  X  f ( s )=0 ,and  X  f ( v )=+  X  for any node v = s . On the other hand, each entry in Q f corresponds to a node v , and the key of the entry equals  X  ( v ) , i.e., the index of become evident shortly, Q f ensures that the forward search visits nodes in ascending order of their indices, and hence, it scans the fi le structure of G f only once, without the need to backtrack to any disk block that it has visited before.

HoD starts the forward search by inspecting each edge e = s, v adjacent to s in G f , and then inserting v into H f with a key l ( e ) . (Note that G f contains only outgoing edges.) In addition, HoD also inserts v into Q f . After that, HoD iteratively removes the top entry u in Q f , and processes u as follows: for each edge e = u, v adjacent to u ,if  X  f ( v )=+  X  in the hash table HoD sets  X  f ( v )=  X  f ( u )+ l ( e ) and inserts v into Q HoD sets  X  f ( v )=min {  X  f ( v ) , X  f ( u )+ l ( e ) } .When empty, HoD terminates the forward search, and retains the hash table H f for the second step of the algorithm, i.e., the core search.
The core search of HoD is a continuation of the forward search, and it inherits the hash table H f created during the forward search. In addition to H f , HoD creates a min-heap Q c , such that entries of the form v, X  f ( v ) ,where v is a node and  X  f key of v in H f . For any node u with  X  f ( u ) =+  X  (i.e., visited by the forward search), HoD inserts u into Q c . Given H f and Q c , HoD performs the core search in iterations. In each iteration, HoD extracts the top entry v from Q c ,andexam-ines each outgoing edge e of v . For every such edge, HoD inspects its ending point w ,andsets  X  f ( w )=min {  X  f ( w ) , X  f Then, HoD adds w into Q c if w is currently not in Q c . This itera-tive procedure is repeated until Q c becomes empty. After that, the hash table H f is sent to the last step (i.e., the backward search) for further processing.
Given the hash table H f obtained from the core search, the re-versed search of HoD is performed as a sequential scan of the back-ward graph G b , which stores nodes in descending order of their in-dex values. For each node v visited during the sequential scan, HoD checks each edge e = u, v adjacent to v . (Note that G b contains only incoming edges). If  X  f ( u ) =+  X  and  X  f ( u )+ l ( e ) &lt; X  then HoD sets  X  f ( v )=  X  f ( u )+ l ( e ) . Once all nodes in G scanned, HoD terminates the backward search and, for each node v , returns  X  f ( v ) as the distance from s to v .

One interesting fact about the backward search is that it does not require a heap to decide the order in which the nodes are visited. This leads to a much smaller CPU cost compared with Dijkstra X  X  algorithm, as it avoids all expensive heap operations. Compared with Dijkstra X  X  algorithm, the main difference of HoD X  X  query algorithm is that it visits nodes in a pre-de fi ned order based on their ranks. The correctness of this approach is ensured by the shortcuts constructed by the preprocessing algorithm of HoD. In particular, for any two nodes s and t in G , it can be proved that the augmented graph G  X  always contains a path P from s to that (i) P  X  X  length equals the distance from s to t in G can be identi fi ed by HoD with a forward search from s , followed by a core search and a backward search. More formally, we have the following theorem.

T HEOREM 1. Given a source node s , the SSD query algorithm of HoD returns dist ( s, v ) for each node v  X  G .
 Interested readers are referred to our technical report [27] for the proof of Theorem 1.

The query algorithm of HoD requires O ( n + m c ) main memory, where m c is the size of the core graph. This is due to the fact that (i) the forward, core, and back searches of HoD all maintain a hash table that takes O ( n ) space, and (ii) the core search requires reading the core graph G c into the memory. The time complexity of the algorithm is O ( n log n + m ) ,where m is the total number of edges in G c , G f ,and G b . The reason is that, when processing an SSD query, HoD may need to scan G f , G c ,and G b once, and it may need to put O ( n ) nodes into a min-heap. Finally, the I/O costs of the algorithm is O (( n + m ) /B ) , since it requires at most one scan of G f , G c ,and G b .
Given a source node s , an SSSP query differs from an SSD query only in that it asks for not only (i) the distance from s node v , but also (ii) the predecessor of v , i.e., the node that immedi-ately precedes v on the shortest path from s to v . To extend HoD for SSSP queries, we asso ciate each edge u, w in the augment graph G  X  with a node v , such that v immediately precedes w on the short-est path from u to w in G . For example, given the augmented graph in Figure 1e, we would associate the edge v 9 ,v 7 with v (i) the shortest path from v 9 to v 7 in G is v 9 ,v 6 ,v immediately precedes v 7 in the path.

With the above extension, HoD processes any SSSP query from a node s using the algorithm for SSD query with one modi fi cation: Whenever HoD traverses an edge u, w and fi nds that dist ( s, u )+ l ( u, w ) &lt;dist ( s, w ) , HoD would not only update dist ( s, w ) but also record the node associated with u, w . That is, for each node w visited, HoD keeps track of the predecessor of w in the shortest path from s to w that have been seen so far. As such, when the SSD query algorithm terminates, HoD can immediately return dist ( s, w ) as well as the predecessor of w .

Finally, we clarify how the preprocessing algorithm of HoD can be extended to derive the node associated with each edge. First, for each edge e in the original graph, HoD associates e with the starting point of e . After that, whenever HoD generates a candidate edge u, w during the removal of a node v , HoD would associate u, w with the node that is associated with the edge v,w .For example, in Figure 1c, when HoD removes v 7 and creates a can-didate edge v 9 ,v 10 , it associates the edge with v 7 , which is the node associated with v 7 ,v 10 .
This section experimentally compares HoD with three meth-ods: (i) VC-Index [8], the state-of-the-art approach for SSD and SSSP queries on disk-resident graphs; (ii) EM-BFS [6], an I/O ef-fi cient method for breadth fi rst search; and (iii) EM-Dijk [18], an I/O ef fi cient version of Dijkstra X  X  algorithm. We include EM-BFS since, on unweighted graphs, any SSD query can be answered us-ing breadth fi rst search, which is generally more ef fi cient than Dijk-stra X  X  algorithm. We obtain the C++ implementations of VC-Index, EM-BFS, and EM-Dijk from their inventors, and we implement HoD with C++. As the implementation of VC-Index only sup-ports SSD queries, we will focus on SSD queries instead of SSSP queries. All of our experiments are conducted on a machine with a 2 . 4 GHz CPU and 32 GB memory.
We use fi ve real graph datasets as follows: (i) USRN [1], which represents the road network in the US; (ii) FB [14], a subgraph of the Facebook friendship graph; (iii) BTC [2], a semantic graph; (iv) Meme [16] and UKWeb [3], which are two web graphs. Among them, only USRN and FB are undirected. Since VC-Index, EM-BFS, and EM-Dijk are all designed for undirected graphs only, we Table 4: Average running time for SSD queries (in seconds). are indeed of more undirected datasets for experiments. For this purpose, we transform BTC and UKWeb into undirected graphs, using the same approach as in previous work (see [8] for details). After that, for each undirected (resp. directed) graph G ,wecom-pute its largest connected component (resp. weakly connected com-ponent) C , and we use C for experiments. Table 1 illustrates the details of the largest component obtained from each graph. In par-ticular, u-BTC and u-UKWeb are obtained from the undirected ver-sions of BTC and UKWeb, respectively.
 Remark. The previous experimental study on VC-Index [8] uses USRN, u-BTC, and u-UKWeb instead of their largest connected components (CC) for experiments. We do not follow this approach as it leads to less meaningful results. To explain, consider a massive undirected graph G where each CC is small enough to fi tinthe main-memory. On such a graph, even if a disk-based method can ef fi ciently answer SSD queries, it does not necessarily mean that it is more scalable than a main-memory algorithm. In particular, one can easily answer an SSD query from any node s in G ,by fi rst reading into memory the CC that contains s , and then running a main-memory SSD algorithm on the CC. In general, given any graph G , one can use an I/O ef fi cient algorithm [21] to pre-compute the (weakly) connected components in G , and then handle SSD queries on each component separately.
In the fi rst sets of experiments, we evaluate the performance of each method on four undirected graphs: USRN, FB, u-BTC, and u-UKWeb. For HoD, EM-BFS, and EM-Dijk, we limit the amount of memory available to them to 1 GB, which is smaller than the sizes of all datasets. For VC-Index, we test it with 2 GB memory as it cannot handle any of our datasets under a smaller memory size.
Table 2 shows the preprocessing time of HoD and VC-Index on the four graphs. (EM-BFS and EM-Dijk are omitted as they do not require any pre-computation.) In all cases, HoD incurs a sig-ni fi cantly smaller overhead than VC-Index does. In particular, on FB, the preprocessing time of HoD is more than ten times smaller than that of VC-Index. Table 3 compares the space consumptions of HoD and VC-Index. Except for the case of u-BTC, the space required by VC-Index is consistently larger than that by HoD.
To evaluate the query ef fi ciency of each method, we generate 100 SSD queries for each dataset, such that the source node of each query is randomly selected. Table 4 shows the average run-ning time of each approach in answering an SSD query. The query time of HoD is at least an order of magnitude smaller than that of Table 5: Estimated time for closeness computation (in hours). VC-Index. Meanwhile, VC-Index always outperforms EM-BFS, which is consistent with the experimental results reported in previ-ous work [8]. We omit EM-BFS on USRN and u-UKWeb, since those two graphs are weighted, for which EM-BFS cannot be used to answer SSD queries. Finally, EM-Dijk incurs a larger query overhead than all other methods.

In the next experiment, we demonstrate an application of HoD for ef fi cient graph analysis. In particular, we consider the task of approximating the closeness for all nodes in a graph G ,usingthe algorithm by Eppstein and Wang [11]. The algorithm requires ex-ecuting k =ln n/ 2 SSD queries from randomly selected source nodes, where n is the number of nodes in G and is a parameter that controls the approximation error. Following previous work [8], we set =0 . 1 .

Table 5 shows an estimation of the time required by each method to complete the approximation task. Speci fi cally, we estimate the total processing time of each method as (i) its query time in Table 4 multiplied by k , plus (ii) its preprocessing time (if any). Observe that both EM-BFS and EM-Dijk incur prohibitive overheads  X  they require more than a week to fi nish the approximation task. In con-trast, HoD takes at most 2 . 4 hours to complete the task, despite that it pays an initial cost for pre-computation. Meanwhile, VC-Index is signi fi cantly outperformed by HoD, and it needs around two days to accomplish the task on FB and u-UKWeb. Our last experiments focus on the three directed graphs: BTC, Meme, and UKWeb. We run HoD on BTC and Meme with 1GB memory, and on UKWeb with 16GB memory, as the enormous size of UKWeb leads to a higher memory requirement. Table 6 shows the preprocessing and space overheads of HoD, as well as its aver-age query time in answering 100 randomly generated SSD queries on each dataset. (We omit VC-Index, EM-BFS, and EM-Dijk as they do not support directed graphs.) On BTC and Meme, HoD only incurs small pre-computation costs and moderate space con-sumptions. On UKWeb, the preprocessing, space, and query over-heads of HoD are considerably higher, but are still reasonable given that UKWeb contains 30 times more edges than BTC and Meme do. To our knowledge, this is the fi rst result in the literature that demonstrates practi cal support for SSD que ries on a billion-edge graph.
As mentioned in Section 1, the existing techniques for I/O-ef fi cient SSD and SSSP queries include VC-Index [8] and a few methods that adopt Dijkstra X  X  algorithm [15, 17 X 20]. All of those techniques are exclusively designed for undirected graphs, and they incur signi fi cant query overheads, as is shown in our experiments. In contrast, HoD supports both directed and undirected graphs, and it offers high query ef fi ciency along with small costs of pre-computation and space.

Other than the aforementioned work, there exists large body of literature on in-memory algorithms for shortest path and distance queries (see [9, 23, 25, 26] for surveys). The majority of those al-gorithms focus on two types of queries: (i) point-to-point shortest path (PPSP) queries, which ask for the shortest path from one node to another, and (ii) point-to-point distance (PPD) queries, which ask for the length of the shortest path between two given nodes. These two types of queries are closely related to SSD and SSSP queries, in the sense that any SSD (resp. SSSP) query can be an-swered using the results of n PPD (resp. PPSP) queries, where is the number of nodes in the graph. Therefore, it is possible to adopt a solution for PPD (resp. PPSP) queries to handle SSD (resp. SSSP) queries. Such an adoption, however, incurs signi fi cant over-heads, especially when n is large. For example, the state-of-the-art solution [4] for PPD queries requires 266 ns to answer a PPD query on the USRN dataset in Section 7. (Note: the solution is not I/O ef fi cient and it requires 25 . 4 GB memory to handle USRN.) If we use this solution to answer an SSD query on USRN, then we need to execute 24 . 5 million PPD queries, which takes roughly 266 ns  X  24 . 5  X  10 6 =6 . 52 s. In contrast, HoD requires only 1 . 8 s to process an SSD query on USRN, using only 1 GB memory.
Furthermore, almost all existing solutions for PPD and PPSP queries require that the dataset fi ts in the main memory during pre-computation and/or query processing. This renders them inappli-cable for the massive disk-resident graphs considered in this paper. The only exception that we are aware of is a concurrent work by Fu et al. [12], who propose an I/O-ef fi cient method called IS-Label . HoD and IS-Label X  X  preprocessing algorithms are similar in spirit, but their index structures and query algorithms are drastically dif-ferent, as they are designed for different types of queries. In par-ticular, IS-Label focuses on PPD and PPSP queries, and does not ef fi ciently support SSD or SSSP queries.

Finally, we note that previous work [9, 13, 22] has exploited the idea of augmenting graphs with shortcuts to accelerate PPD and PPSP queries. Our adoption of shortcuts is inspired by previous work [9, 13, 22], but it is rather non-trivial due to the facts that (i) we address I/O ef fi ciency under memory-constrained environ-ments, while previous work [9, 13, 22] focuses on main memory algorithms; (ii) we tackle SSD and SSSP queries instead of PPD and PPSP queries; (iii) we focus on general graphs, while pervious work [9, 13, 22] considers only road networks (where each node is degree-bounded).
This paper presents HoD, a practically ef fi cient index structure for distance queries on massive disk-resident graphs. In particu-lar, HoD supports both directed and undirected graphs, and it ef-fi ciently handles single-source shortest path (SSSP) queries and single-source distance (SSD) queries under memory-constrained environments. This contrasts the existing methods, which either (i) require that the dataset fi ts in the main memory during pre-computation and/or query processing, or (ii) support only undi-rected graphs. With extensive experiments on a variety of real-world graphs, we demonstrate that HoD signi fi cantly outperforms the state of the art in terms of query ef fi ciency, space consumption, and pre-computation costs. For future work, we plan to investigate how HoD can be extended to (i) support point-to-point shortest path and distance queries and (ii) handle dynamic graphs that change with time.
 This work was supported by the Nanyang Technological University under SUG Grant M58020016.
