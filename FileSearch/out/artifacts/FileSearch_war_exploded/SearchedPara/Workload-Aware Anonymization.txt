 Protecting data privacy is an important problem in micro-data distribution. Anonymization algorithms typically aim to protect individual privacy, with minimal impact on the quality of the resulting data. While the bulk of previous work has measured quality through one-size-fits-all mea-sures, we argue that quality is best judged with respect to the workload for which the data will ultimately be used.
This paper provides a suite of anonymization algorithms that produce an anonymous view based on a target class of workloads, consisting of one or more data mining tasks, as well as selection predicates. An extensive experimental evaluation indicates that this approach is often more effec-tive than previous anonymization techniques.
 H.2.8 [ Database Management ]: Database Applications Algorithms, Experimentation, Security Privacy, Anonymity, Data Recoding, Predictive Modeling k -Anonymity [22, 23] and l -diversity [18] have been stud-ied widely as mechanisms for preventing re-identification at-tacks in microdata release. Of course, subject to the given anonymity constraints, the data should remain as useful as possible. Unfortunately, there is often a tension between these two goals.

It is our position that the best way of measuring quality is based on the task for which the data will ultimately be used. This paper provides anonymization techniques that incorporate a target workload of selections and mining tasks. Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00.
Suppose that a trusted agency compiles a database of dis-ease information for several million hospital patients. How-ever, the agency is prohibited by law from distributing this data without taking precautions to ensure individual pri-vacy. For example, the agency should take steps to guaran-tee that the released data does not reveal any individual X  X  HIV status.

Alice is an external researcher who is directing two sep-arate studies, each of which could benefit from using the data in the central database. As part of the first study, Alice wants to build a classification model that uses age, smoking history, and HIV status to predict life expectancy. In the second study, she would like to find combinations of variables that are useful for predicting elevated cholesterol and obesity in males over 40.

In this situation, it is desirable to distribute anonymized microdata to individuals like Alice (the data recipients ). One might consider a simpler protocol, in which Alice re-quests a specific model, constructed entirely by the agency. However, there are two downsides to this approach. First, the simple model-distribution protocol assumes that the tasks are fully-specified at the time of the initial request. How-ever, in our example, Alice X  X  second study involves an entire class of models, each constructed using a subset of the data (attributes and records). Indeed, workloads like this arise naturally in certain types of exploratory data analysis [9].
Also, the inference implications of releasing one or more models constructed on the agency X  X  unmodified data are not well-understood. Each such model reveals something about the distributional characteristics of the agency X  X  data, and in certain cases, the revealed information might constitute a breach of privacy. However, in the case of a single released view, there are well-defined notions of anonymity, and the best Alice can do is to approximate the distribution in the (sanitized) data she is given.

The work presented in this paper is motivated by this type of scenario, where the goal is to create a single view of the database that respects all given anonymity constraints, but that remains useful for carrying out the tasks in a target class of workloads.
We begin by reviewing the problems of anonymity, classi-fication, and regression in Section 2. Because previous defin-
We assume that Alice only receives one version of any given data set and that she does not collude with others receiving data distributions from the same source.
 itions of anonymity with respect to a sensitive attribute (i.e., l -diversity [18]) have assumed that the sensitive attribute is nominally-valued, we also propose a novel diversity require-ment for numeric attributes.

Our first main contribution, described in Section 3, is a suite of algorithms for generating an anonymous data snap-shot, while preserving the utility of the data with respect to a target class of workloads. While previous work has con-sidered incorporating a single classifier (constructed over the entire released data set) [13, 15, 24], we incorporate the fol-lowing expressive workload characteristics:  X  Classification &amp; Regression We incorporate models predicting both categorical and numeric attributes.  X  Multiple Target Models Often, the data recipient will want to build separate models to predict multiple different attributes.  X  Selection &amp; Projection Frequently, one or more of the mining tasks will involve only a subset of the data (e.g., males over 40). In this case, it is important to guarantee that this data can be precisely and accurately selected from the released snapshot. Similarly, it is important to guarantee that the data remains useful when only a subset of the released attributes is used for a particular task.
Our second main contribution is an extensive experimen-tal evaluation, described in Section 4. The results show that our anonymization algorithms are often more effective than previous algorithms in producing high-quality data, as judged by a variety of workloads.

Much of the previous work on k -anonymity has measured data quality or optimality using simple measures based on equivalence class size or the total number of generaliza-tions/suppressions [2, 5, 17, 19, 22, 23]. Not surprisingly, our experiments also show that one-size-fits-all measures are not necessarily indicative of quality with respect to a par-ticular workload.

In order to assess the impact of anonymization on sub-sequent analysis techniques, we first had to address some additional problems. Because standard learning algorithms use point data for training, rather than the region data pro-duced by multidimensional recoding, Section 4.2 proposes a pre-processing step for converting regions to points. Fol-lowing pre-processing, standard learning algorithms can be applied without modification .

The paper concludes with discussions of related and future work in Sections 5 and 6.
K -anonymity [22, 23] and l -diversity [18] were proposed to limit re-identification risk in microdata publishing. Consider a single relation T . In defining anonymity, each attribute in T is characterized by at most one of the following types:  X  Unique Identifiers A unique identifier is any attribute that identifies individuals (e.g., SS#). Known identifiers are typically removed entirely from released microdata.  X  Quasi-identifier ( Q 1 , ..., Q d ) A quasi-identifier is a min-imal set of attributes that can be joined with external information to re-identify individual records. We assume that a quasi-identifier is recognized based on knowledge of the domain.  X  Sensitive attributes (S) An attribute is considered sen-sitive if an adversary should not be permitted to uniquely associate its value with a unique identifier. For example, the HIV Status field in released medical data would likely be considered sensitive. Previous work assumed a single, nominally-valued, sensitive attribute [18]; we also propose an extension to a numeric sensitive attribute.

The k -anonymity requirement is quite simple. Intuitively, it stipulates that no individual record should be uniquely identifiable from a group of k on the basis of its quasi-identifier values. We will refer to each group of tuples in T with identical quasi-identifier values as an equivalence class . K-Anonymity [22, 23] A table T is k-anonymous with re-spect to quasi-identifier set Q 1 , ..., Q d if every unique tuple  X  q , ..., q d  X  in the (multiset) projection of T on Q 1 , ..., Q occurs at least k times. l -Diversity [18] provides a natural extension, incorporat-ing a nominal sensitive attribute S . The l -diversity prin-ciple requires that each equivalence class (as defined by k -anonymity) also contain at least l  X  X ell-represented X  distinct values for S . This principle can be instantiated in various ways. The strictest proposal formulates l -diversity in terms of entropy. Because entropy is concave, entropy l -diversity requires that the full database have entropy at least log ( l ). D S denotes the (finite) domain of attribute S .
 Entropy l -Diversity (Nominal S) [18] A table T is en-tropy l -diverse with respect to quasi-identifier set Q 1 and sensitive attribute S if, for every equivalence class E in T , fraction of tuples in E with S = s .
 For numeric sensitive attributes, diversity is more subtle. For example, if S = Salary , an equivalence class containing salaries { 100 K, 101 K, 102 K } is considered 3-diverse, but in-tuitively does not protect privacy as well as an equivalence class containing salaries { 1 K, 50 K, 500 K } . For this reason, we define a new diversity requirement that guarantees a cer-tain level of dispersion within each equivalence class: Squared-Error Diversity (Numeric S) Table T is squared-error diverse with respect to quasi-identifier set Q 1 , ..., Q and sensitive attribute S if, for every equivalence class E in T ,
P of S in E , and error is the diversity parameter.
In classification/regression, attributes are typically char-acterized by at most one of the following types:  X  Target attribute (C or R) The goal of classification is to build a model that accurately predicts the value of a nominal class label ( C ). Regression aims to predict a numeric attribute ( R ).  X  Predictor attributes Some set of (discrete or continu-ous) predictor attributes (also commonly called features ) are used to predict the target attribute.

When a target classification or regression model is consid-ered in conjunction with anonymity, each attribute has two Figure 1: A possible value generalization hierarchy for the Nationality domain characterizations. In the remainder of this paper, we will as-sume that the set of predictor attributes is a quasi-identifier. Under this assumption, it is contradictory to categorize an attribute as both target and sensitive, and we disallow this categorization.
Numerous recoding techniques have been proposed for san-itizing microdata to satisfy an anonymity constraint. In a relational database, each attribute X has a domain of values D
X . A global recoding achieves anonymity by mapping the quasi-identifier domains to ranges or coarsened values.
Global recoding can be broken down into two sub-classes [16, 17]. If the quasi-identifier consists of d attributes ( Q ..., Q d ), a single-dimensional global recoding is defined by a set of functions  X  1 , ...,  X  d such that each  X  i : D Q i anonymous view V of T is obtained by applying each  X  i to the value of Q i in each tuple of T .

On the other hand, a multidimensional global recoding is defined by a single function  X  : D Q 1  X  ...  X  D Q d  X  D 0 is used to recode the domain of unique vectors associated with the quasi-identifier. In this case, V is obtained by applying  X  to the vector of quasi-identifier values in each tuple of T .

For attributes with continuous or ordinal (ordered cat-egorical) domains, it is convenient to think of each vec-tor of quasi-identifier values  X  q 1 , ..., q d  X  as a point in a d -dimensional space. A class of multidimensional recoding models partitions the domain space into non-overlapping d -dimensional rectangular regions [17]. Recoding function  X  is defined by mapping each point to the region in which it is contained. Thus, each region corresponds to an equivalence class in anonymous view V . 2
When the domain of a quasi-identifier attribute is nomi-nal, this partitioning may be further constrained by a user-defined value generalization hierarchy , or partial order, as described by Samarati and Sweeney [22, 23]. For exam-ple, Figure 1 shows a possible hierarchy for the Nationality domain; the domain values are found at the leaves. The notation French  X  European indicates that French is de-scended from European in the hierarchy.

The hierarchy can be used in several ways to constrain the set of possible recodings [16]. In this paper, within a particular d -dimensional region , we require that if  X  maps a leaf value v to some ancestor a , then all leaves that are descended from a must also be mapped to a .

Every single-dimensional recoding can be equivalently ex-pressed as a multidimensional recoding, but the reverse is frequently not true [17]. Depending on the distribution of the data, this can affect data quality. For example, consider a dataset with exactly two predictors/quasi-identifiers (Age and Zip). Suppose the distribution of class labels (+ ,  X  ) is as shown in Figure 2, and that k = 3. In this case, there is
Hyper-rectangular regions are easily expressed in tabular form using range values (e.g., Age = [20-35]). (a) Multidimensional (b) Single-Dimensional Figure 2: Comparing multidimensional and single-dimensional recoding in two dimensions a k -anonymous multidimensional recoding that groups to-gether only records with like labels, but this cannot be ac-complished with single-dimensional recoding, which requires that the values of each attribute be recoded uniformly.
This section proposes several algorithms for creating a single snapshot of a given data set that respects a given anonymity constraint, but remains useful for executing a particular class of workloads. The target class of workloads is specified by the following parameters: 1. A set of predictor attributes ( Q 1 , ..., Q d ) 2. Either a set of one or more nominal target class labels ( C 1 , ..., C m ), or numeric target attributes ( R 1 , ..., R 3. Optionally, a set of selection predicates ( PR 1 , ..., PR
The anonymity constraint is k -anonymity, optionally ex-tended by l -diversity or squared-error diversity. Also, we assume that the predictor attributes are a quasi-identifier.
In the simplest case, when the target workload consists of one classification or regression model, without selection predicates, the heuristics used by our algorithms implement entropy l -diversity and squared-error diversity in reverse.
The Mondrian algorithm was recently proposed for k-anonymization using multidimensional recoding [17]. The algorithm is based on a greedy recursive partitioning of the (multidimensional) quasi-identifier domain space (see Fig-ure 3). In order to obtain approximately uniform parti-tion occupancy, [17] suggests recursively choosing the split attribute with the largest normalized range of values, and (for continuous or ordinal attributes) partitioning the data around the median value of the split attribute. This process is repeated until no allowable split remains, meaning that a particular region cannot be further divided without vio-lating the anonymity constraint, or constraints imposed by value generalization hierarchies. We refer to this algorithm as Median Mondrian .

When the (set of) target mining model(s) is known, we can improve this heuristic. First consider a single target classifi-cation model, with predictor attributes Q 1 , ..., Q d (also the quasi-identifier) and class label C . In this case, we pro-pose a heuristic partitioning scheme based on information gain, which is reminiscent of decision tree construction. In-tuitively, the goal of this greedy criterion is to produce ho-mogeneous partitions of class labels.

At each recursive step, we choose the split that minimizes the weighted entropy over the set of resulting partitions (without violating the anonymity constraint). P denotes the current (recursive) tuple set, and partitions P 0 denotes the set of partitions resulting from the candidate split. p ( c | P is the fraction of tuples in P 0 with class label C = c . We refer to this algorithm as InfoGain Mondrian .

InfoGain Mondrian handles continuous quasi-identifier val-ues as they are typically handled by decision-trees, parti-tioning around the threshold value with smallest entropy (see [12]). The data is first sorted with respect to the split attribute. Then the data is scanned, and each time there is a change in class label, this candidate threshold is checked with respect to anonymity and entropy. In the event that no candidate threshold satisfies the anonymity constraint, the median is also checked as a default.

InfoGain Mondrian scales to large data sets through a straightforward adaptation of an existing scalable decision-tree induction scheme, such as RainForest [14].
Similar greedy heuristics can be used when the target at-tribute is numeric. Specifically, we use the mean squared error (MSE) to measure the impurity of target attribute R within a candidate partition P 0 . A heuristic inspired by the CART algorithm for regression trees [7] recursively chooses the split that minimizes the weighted sum of MSEs over the set of resulting partitions. r ( P 0 ) denotes the mean value of R in P 0 .

Because | P | is constant for all candidate splits, the al-gorithm chooses the split that minimizes the following ex-pression (without violating anonymity). We call this Least Squared Deviance (LSD) Mondrian . This algorithm handles continuous attributes through discretization.
In certain cases, we would like to allow the data recipient to build several models, to accurately predict the marginal distributions of several class labels ( C 1 , ..., C m ) or regres-sion attributes ( R 1 , ..., R m ). InfoGain Mondrian and LSD Mondrian can be extended to handle multiple discrete and numeric target attributes, respectively.

For classification, there are two ways to make this ex-tension. In the first approach, the data recipient would build a single model to predict the vector of class labels,  X  C 1 , ..., C m  X  , which has domain D C 1  X  ...  X  D C m . A greedy split criterion would minimize entropy with respect to this single variable.

However, in this simple approach, the size of the domain grows exponentially with the number of target attributes. To avoid potential problems due to data sparsity, we instead simplify the problem by assuming independence among tar-get attributes. This is a reasonable assumption because we are ultimately only concerned about the marginal dis-tribution of each target attribute. Under the independence assumption, a greedy split criterion minimizes the sum of weighted entropies:
In regression (the squared error split criterion in particu-lar), there is no analogous distinction between treating the set of target attributes as a single variable and assuming in-dependence. For example, if we have two target attributes, R 1 and R 2 , the joint error is the distance between an ob-served point ( r 1 , r 2 ) and the centroid ( r 1 ( P ) , r dimensional space. The squared joint error is just the sum of individual squared errors, ( r 1  X  r 1 ( P )) 2 + ( r 1 For this reason, the greedy split criterion minimizes the sum of squared error:
Sometimes one or more of the tasks in the target workload will use only a subset of the released data, and it is important that this data can be selected precisely, despite recoding. For example, a researcher may want to build a model using only males over 40, but this is difficult if the ages of some men are recoded to the range [30  X  50]. This problem was originally described in [17].

Consider a set of selection predicates ( PR 1 , ..., PR m fined by boolean functions of the quasi-identifier attributes ( Q 1 , ..., Q d ). Conceptually, each PR i defines a query region R i in the domain space such that R i = { p  X  D Q 1  X  ...  X  D PR i ( p ) = true } . For the purposes of this work, we only con-sider selections for which the query region can be expressed as a hyper-rectangle. (Some additional selections can be decomposed into two or more hyper-rectangles, and incor-porated as separate queries.)
A multidimensional recoding function  X  divides the do-main space into non-overlapping regions P 1 , ..., P n . For-mally, the recoding region P i = { p  X  D Q 1  X  ...  X  D Q d  X  ( p ) = p 0 i } , where p 0 i is a particular generalization of the quasi-identifier vector. When evaluating PR i over the re-coded view V , it may be that no subset of the recoding re-gions can be combined to produce query region R i . Instead, it is intuitive to return the tuples from V that are contained in any recoding region overlapping R i . More formally,
Notice that this will often produce a larger result set than evaluating PR i over the original table T ; the imprecision is the difference in size between these two result sets. For example, Figure 4 shows a 2-dimensional domain space. The shaded area represents a query region, and the tuples of T are represented by points. The recoding regions are bounded by dotted lines and numbered. Recoding regions 2, 3, and 4 overlap the query region. If we evaluated this query using the original data, the result set would include 6 tuples. However, evaluating the query using the recoded data yields 10 tuples, an imprecision of 4.

Ideally, the goal of selection-oriented anonymization is to divide the domain space into a set of (anonymous) recod-ing regions that minimize imprecision for the set of target predicates. We incorporate this goal into the Mondrian algo-rithm through a new greedy splitting heuristic. Specifically, at each recursive step, when partitioning a recursive region P , we choose the split that minimizes the total imprecision for the set of resulting regions { P 0 1 , ..., P 0 n } :
The algorithm proceeds until there is no allowable split that reduces the imprecision of the current partition P , and continuous attributes are handled through discretiza-tion. We will call this algorithm Selection Mondrian .
In practice, we expect this technique to be used most often for simple selections, such as breaking down health data by state. After incorporating selections, we continue to anonymize each resulting partition independently, using the appropriate classification-or regression-oriented algorithm.
Our experimental evaluation has several goals, the first of which is to provide some insight about quality evalua-tion methodology. We describe an experimental protocol for evaluating an anonymization algorithm with respect to a target data mining workload, and we compare the results to those obtained using some simpler quality measures. Figure 5: Mapping a d -dimensional rectangular re-gion to 2  X  d attributes
The second goal is to evaluate the algorithms described in Section 3. In particular, we assess the impact of incorpo-rating a set of target classification or regression models into the anonymization, and multidimensional recoding. Also, we evaluate the effectiveness of our algorithms with respect to selections, projections, and multiple target models.
Given a target classification or regression workload, the most direct way to evaluate the quality of an anonymiza-tion is by training each target model using the anonymized data, and evaluating the resulting models using predictive accuracy (classification), mean absolute error (regression), or similar measures. We will call this methodology model evaluation . All of our model evaluation experiments follow a common protocol: 1. The data is first divided into training and testing sets (or 10-fold cross-validation sets), T train and T test . 2. The anonymization algorithm determines recoding func-tion  X  using only the training set T train . Anonymous view
V train is obtained by applying  X  to T train . 3. The same recoding function  X  is then applied to the testing set ( T test ), yielding V test . 4. The classification or regression model is trained using V and tested using V test .

This experimental design is different from the setup used by Fung et al. [13] for an important reason. In [13], the combined training and testing sets were anonymized using a single-dimensional recoding algorithm based on informa-tion gain. Following this step, the data was separated into training and testing sets. In our opinion, this setup is in-appropriate for evaluating the anonymization algorithm be-cause incorporating the test set when choosing a recoding is tantamount to looking at the test set while doing feature selection. Instead, all of our experiments hold out the test set during both the anonymization and training phases.
We used k-anonymity as the anonymity constraint, and we used the implementations of the following learning algo-rithms provided by the Weka software package [25]:  X  Decision Tree (J48) Default settings were used.  X  Naive Bayes Supervised discretization was used for con-tinuous attributes; otherwise all default settings were used.  X  Random Forests Each classifier was comprised of 40 ran-dom trees, and all other default settings were used.  X  Support Vector Machine (SMO) Default settings were used, including a linear kernel function.  X  Linear Regression Default settings were used.  X  Regression Tree (M5) Default settings were used. Figure 6: Synthetic predictor/quasi-identifier at-tributes and class label functions
In addition to model evaluation, we also measured cer-tain characteristics of the anonymized training data to see if there was any correlation between these simpler measures and the results of the model evaluation. Specifically, we measured the average equivalence class size , and for classi-fication tasks, we measured the conditional entropy of the class label given the partitioning:
When single-dimensional recoding is used, standard learn-ing algorithms can be applied directly to the resulting point data, notwithstanding the  X  X oarseness X  of some points [13]. Although multidimensional recoding techniques are more flexible, using the resulting hyper-rectangular data to train standard data mining models poses an additional challenge. To address this problem, we make a simple observation. Because we restrict the recoding regions to include only d -dimensional hyper-rectangles, each region can be uniquely represented as a point in (2  X  d )-dimensional space. For ex-ample, Figure 5 shows a 2-dimensional rectangle, and its unique representation as a 4-tuple. This assumes a total or-der on the values of each attribute, similar to the assumption made by support vector machines.

Following this observation, we adopt a simple pre-processing technique for learning from regions. Specifically, we extend the recoding function  X  to map data points to d -dimensional Census Database Contraceptives Database regions, and in turn, to map these regions to their unique representations as points in (2  X  d )-dimensional space.
Our primary goal in developing this technique is to estab-lish the utility of our anonymization algorithms. There are many possible approaches to the general problem of learning from regions. For example, Zhang and Honavar proposed an algorithm for learning decision trees from attribute values at various levels of a taxonomy tree [26]. However, a full com-parison is beyond the scope of this paper.
Our first set of experiments used synthetic data based on the classification generator introduced by Agrawal et al. [3]. Predictor/quasi-identifier attributes were generated ac-cording to the distributions described in Figure 6, and class labels were generated as a function of the predictor values. We present results for four representative label functions, chosen from the original ten (functions 2,4,6,7). To simplify the evaluation, we applied the labeling functions determin-istically, without injecting noise.

Notice that the basic labeling functions in Figure 6 in-clude a number of constants (e.g., 75 K ). In order to get a more robust understanding of the behavior of the various anonymization algorithms, for functions 2, 4, and 6, we in-stead generated many independent data sets, varying the function constants independently at random over the range of the attribute.

Figure 6 notes, for each predictor/quasi-identifier attribute, whether it was treated as continuous or nominal (with an associated generalization hierarchy) during anonymization.
In addition to the synthetic data, we also used several real-world data sets . The first was derived from a sample of the 2003 Public Use Microdata, distributed by the United States Census American Community Survey 3 , with target attribute Salary. This data was used for both classification and regression, and contained 49,657 records. For classifi-cation, we replaced the numeric Salary with a Salary class ( &lt; 30 K or  X  30 K ); approximately 56% of the data records had Salary &lt; 30 K . For classification, this is similar to the http://www.census.gov/acs/www/index.html Adult database from the UCI Machine Learning Repository [6], which has been used in numerous k-anonymity evalua-tions. However, we chose to compile a new data set that can be used for both classification and regression.

The second real data set is the smaller Contraceptives database from the UCI Repository, which contained 1,473 records after removing those with missing values. This data includes nine socio-economic indicators, which are used to predict the choice of contraceptive method ( long-term , short-term , or none ) among sampled Indonesian women. Sum-maries of both real data sets are provided in Figure 7.
InfoGain Mondrian and LSD Mondrian combine multidi-mensional recoding with classification-and regression-oriented splitting heuristics. In this section, we evaluate the effects of these two components through a comparison with two pre-vious anonymization algorithms. All of the experiments in this section consider a single target model, constructed over the entire anonymized training set.

Several previous algorithms have incorporated a single target classification model while choosing a single-dimensional recoding [13, 15, 24]. To gage the impact of multidimen-sional recoding, we compared InfoGain Mondrian and the greedy Top-Down Specialization (TDS) algorithm [13]. Also, multidimensional recoding was used in Median Mon-drian [17], without regard to workload. We compare this to InfoGain Mondrian and LSD Mondrian to gage the effects of incorporating a target model.

Using the synthetic data, Figure 8 compares the predictive accuracy of classifiers trained on data produced by the dif-ferent anonymization algorithms. In these experiments, we generated 100 independent training and testing sets, each containing 1000 records, and we fixed k = 25. The results are averaged across these 100 trials. For comparison, we also include the accuracies of classifiers trained on the (not anonymized) original data.

InfoGain Mondrian consistently outperforms both TDS and Median Mondrian, a result that is overwhelmingly sig-nificant based on a series of paired t-tests. It is important to note that the pre-processing step used to convert regions to points (Section 4.2) is only used for the multidimensional re-codings; the classification algorithms run unmodified on the single-dimensional recodings produced by TDS [13]. Thus, should a better technique be developed for learning from re-gions, this would improve the results for InfoGain Mondrian, but it would not affect TDS. 4
We performed a similar set of experiments using the real-world data. Figures 9(a,b,c) show results for the Census classification data, for increasing k . The graphs show test set accuracy (averaged across 10 folds) for three learning algorithms. The variance across the folds was quite low, and the differences between InfoGain Mondrian and TDS, and between InfoGain Mondrian and Median Mondrian, were highly significant based on paired t-tests.

It is important to point out that in certain cases, no-tably Random Forests, the learning algorithm overfits the model when trained using the original data. For example, the model for the original data in Figure 9(c) gets 97% ac-curacy on the training set, but only 73% accuracy on the test set. When overfitting occurs, it is not surprising that the models trained on anonymized data obtain higher ac-curacy because anonymization acts as a form of feature selection/construction. Interestingly, we also tried apply-ing a traditional form of feature selection (ranked feature selection based on information gain) to the original data,
Note that by mapping to 2  X  d dimensions, we effectively expand the hypothesis space considered by the linear SVM. Thus, it is not surprising that this improves accuracy for the non-linear class label functions (Figure 8(d)).
 and this did not improve the accuracy of random forests for any number of chosen attributes. We suspect that this discrepancy is due to the flexibility of the recoding tech-niques. Single-dimensional recoding (TDS) is more flexible than traditional feature selection because it can incorporate attributes at varying levels of granularity. Multidimensional recoding is more flexible still because it (conditionally) in-corporates different attributes for different data subsets.
Next, Figures 9(d,e) show conditional entropy and aver-age equivalence class size measurements, averaged across the ten anonymized training folds of the Census classification data. Average equivalence class size, which does not take into account any characteristics of the workload, is not a very good indicator of model accuracy. Conditional entropy, which incorporates the target class label, is a lot better; low conditional entropy generally indicates higher accuracy.
We performed the same set of experiments using the Con-traceptives database, and observed similar behavior. Info-Gain Mondrian yielded higher accuracy than TDS or Me-dian Mondrian. Results for J48 are shown in Figure 9(f). The remaining results are omitted due to space constraints.
For regression, we found that LSD Mondrian generally led to better models than Median Mondrian. Figure 9(i) shows the mean absolute test set error for the M5 regression tree, using the Census regression data. A similar relative com-parison was observed for linear regression, but the overall error was higher because Salary is non-linear.
In Section 3.3 we described a simple adaptation to the basic InfoGain Mondrian algorithm that allowed us to in-corporate more than one target attribute, expanding the set of models for which a particular anonymization is  X  X p-timized. X  To evaluate this technique, we performed a set of experiments using the synthetic classification data, increas-ing the number of class labels.

Figure 10 shows average test set accuracies for J48. We first generated 100 independent training and testing sets, containing 1000 records each. We used synthetic labeling functions 2-6,7, and 9 from the Agrawal generator [3], ran-domly varying the constants in functions 2-6 as described in Section 4.3.

Each column in the figure (models A-G) represents the av-erage of 25 random permutations of the synthetic functions. The anonymizations (rows in the figure) are  X  X ptimized X  for an increasing number of target models. (For example, the anonymization in the bottom row is optimized exclusively for model A.) There are two important things to note from the chart, and similar behavior was observed for the other classification algorithms.  X  Looking at each model (column) individually, when the model is included in the anonymization (above the bold line), test set accuracy is higher than when the model is not included (below the line).
 Figure 10: Average test set accuracy for multiple incorporated target models (J48, k=25)
Figure 11: Imprecision for synthetic Function 2  X  As we increase the number of included models (moving upward above the line within each column), the test set accuracy tends to decrease. This is because the quality of the anonymization with respect to each individual model is  X  X iluted X  by incorporating additional models.
In Section 3.4, we discussed the importance of preserv-ing selections, and described an algorithm for incorporating rectangular selection predicates into an anonymization. We conducted an experiment using the synthetic data (1,000 generated records), but treating synthetic Function 2 as a selection predicate. Figure 11 shows the imprecision of this selection when evaluated using the recoded data. The figure shows results for data recoded using three different anonymization algorithms. The first algorithm is Median Mondrian, with greedy recursive splits chosen from amongst all of the quasi-identifier attributes. It also shows a re-stricted variation of Median Mondrian, where splits are made with respect to only Age and Salary. Finally, it shows the results of Selection Mondrian, incorporating Function 2 as three separate rectangular query regions. It is intuitive that imprecision increases with k , and that imprecision is reduced by incorporating the selection into the anonymization.
Incorporating selections can also affect model quality. In the absence of selections, InfoGain and LSD Mondrian choose recursive splits using a greedy criterion driven by the target model(s). When selections are included, the resulting par-titions may not be the same as those that would be chosen based on the target model(s). In the worst case, there may be a selection on an attribute that is uncorrelated with the target attribute.

To test this intuition, we performed an experiment using the Census classification data. To simulate the effect of se-lections that are uncorrelated with the target model, we first assigned each training tuple to one of n groups, chosen uni-formly at random. (We assume | Data | n  X  k .) This mimics the behavior of Selection Mondrian for a set of equality selec-tions on a new attribute, Group number, which takes values 1 , ..., n . We then anonymized each group independently, us-ing either InfoGain Mondrian or Median Mondrian. Once recodings were determined for each training group, we ran-domly assigned each test tuple to one of the n groups, and recoded the tuple using the recoding function for that group. Finally, we trained a single classification model using the full recoded training set (union of all training groups), and tested using the full recoded test set. This process was re-peated for each of ten folds.

The results of this experiment for J48 are shown in Fig-ure 9(g), for increasing n and k = 50. As expected, ac-curacy decreases slightly as the number of selections ( n ) increases. However, several selections can be incorporated without large negative effects. Similar results were observed for the other classification algorithms.
Sometimes not every model constructed by the data re-cipient will use the full set of predictor attributes; rather, they will use a projected attribute subset. We conducted an experiment to compare anonymization algorithms when only a subset of the released predictor attributes is actu-ally used. First, we ranked the attributes using the original data and a greedy information gain criterion. Then we re-moved the attributes in order, from most to least predictive, and constructed classification models using the remaining attributes. We fixed k = 100.

As expected, test set accuracy decreases as the most pre-dictive attributes are dropped. However, the rate of this decline varies depending on the anonymization algorithm used. Figure 9(h) shows the observed accuracies for J48 us-ing the Census database. Because of the single-dimensional recoding pattern, which is known to preserve fewer attributes over non-uniform quasi-identifier distributions [17], this rate of decay is the most precipitous for TDS.

The results were similar for the other classification algo-rithms and the Contraceptives data.
The most closely-related work includes several algorithms that have incorporated a single classification model (con-structed over the full data set) while choosing a k -anonymous single-dimensional recoding. The proposed algorithms in-clude top-down [13] and bottom-up [24] greedy heuristic searches, and genetic algorithms [15]. Each of these papers used the target classification model to evaluate the recoding. Additionally, other recent work suggested using a workload of aggregate queries as a tool for evaluating the quality of anonymizations [17].

Numerous other k-anonymization algorithms have been proposed [2, 5, 16, 19, 22, 23]. However, much of the pre-vious work has sought to optimize simple general-purpose measures of quality, such as the size of equivalence classes, or the total number of generalizations/suppressions.
Aside from k -anonymity, a variety of other methods have been proposed for protecting individual privacy while allow-ing certain data mining tasks. One widely-studied approach is based on the randomized response paradigm [4, 11, 21]. The main advantage of generalization is that the released data is  X  X ruthful, X  though at a coarsened level of granular-ity. This allows additional workloads to be carried out using the data, including selection. Generalization also has similar advantages as compared to data swapping [20].

Several cluster-based techniques have also been proposed that are similar in spirit to k -anonymity. The condensation approach first divides the data into  X  X ondensation groups X  with required minimal occupancy, and then generates point data based on the aggregate statistical properties of each group [1]. Microaggregation first clusters the data into (ide-ally homogeneous) groups of required minimal occupancy, and then publishes the centroid of each group [10]. How-ever, neither of these approaches requires that the resulting groups be hyper-rectangular, nor do they handle categorical attributes with hierarchical generalization constraints.
Finally, privacy-preserving histogram sanitization was pro-posed with the similar goal of guaranteeing that individuals blend into a crowd, based on some suitable distance measure [8]. However, the probabilistic privacy definition does not capture situations where the identification of even a single individual would be considered a breach, and the proof of privacy is highly dependent on the original data distribution. k -Anonymity and l -diversity are widely-studied techniques for protecting individual privacy in microdata release. Sub-ject to the anonymity requirement, the data should remain as useful as possible with respect to the workload for which it will ultimately be used.

This paper provided algorithms for incorporating a class of target workloads, consisting of classification or regression models, as well as selection predicates, when generating an anonymous data recoding. An extensive experimental study validated the effectiveness of these algorithms with respect to a variety of workloads. Additionally, our results show that simple quality measures are not always indicative of data quality with respect to a particular workload.
This work also brought to light several interesting op-portunities for future work. As described in Section 4.4, anonymization sometimes behaves as a form of feature selec-tion or construction. This has some interesting implications because multidimensional recoding naturally leads to a form of feature selection where different attributes are condition-ally retained (at varying levels of granularity) for different data subsets. In the future, it will be valuable to character-ize the situations under which this approach leads to better predictive accuracy than traditional feature selection.
Additionally, our selection-oriented anonymization algo-rithm (Section 3.4) currently only supports selections that can be expressed as rectangular regions. Although we expect simple queries to be the most common, we are working to extend this algorithm to a more expressive class of queries.
Finally, a full study of the learning from regions problem is the topic of future research.
 Our thanks to Bee-Chung Chen, Hector Corrada Bravo, Ted Wild, and Jude Shavlik for insightful conversations, to Jesse Davis for comments on an earlier draft of this paper, and to Benjamin Fung for providing an implementation of the TDS algorithm.
 This work was supported by an IBM Ph.D. fellowship and National Science Foundation Grant IIS-0524671.
