 The major challenge for Question Retrieval (QR) in Community Question Answering (CQA) is the lexical gap between the queried question and the historical questions. This paper proposes a novel Question-Answer Topic Model (QATM) to learn the latent topics aligned across the question-answer pairs to alleviate the lexical gap problem, with the assumption that a question and its paired answer share the same topic distribution. Experiments conducted on a real world CQA dataset from Yahoo! Answers show that combining both parts properly can get more knowledge than each part or both parts in a simple mixing way and combining our QATM with the state-of -the-art translation-based language model , where the topic and translation information is learned from the question-answer pairs at two different grained semantic levels respectively, can significantly improve the QR performance. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Community Question Answering , Question-Answer Topic Model, Topic Model, Translation Model, Question Retrieval Community Question Answering (CQA) services have accum u-lated large archives of question-answer pairs . To reuse the inval u-able resources, it is essential to develop effective retrieval models to retrieve similar questions, which are semantically equivalent or relevant to the queried questions. 
The major challenge for question retrieval, as for most info r-mation retrieval tasks, is the lexical gap between the queried que s-tion and the historical questions in the CQA archives. 
Most of previous work to bridge the lexical gap is based on the statistical translation approach [7 , 9, 13], which learns the word-to-word translation probabilities from the historical comparable question-answer pairs at the fine-grained lexical semantic level (aka at the word level), while ignoring the latent semantic info r-mation in calculating the semantic similarity between the queried question and the historical questions. 
Recently, some work has been proposed to use the latent s e-mantic information to bridge the lexical gap in question retrieval [1 , 15 ]. However, both of these work learns the semantic repr e-sentation only from the question part (seeing a question as a common document), ignoring the important paired answer part. Furthermore, simply applying the existing methods to both parts can benefit from the answer part but only slightly as we have shown. 
In this paper, we argue that it is beneficial to involve the a n-swer part into learning the latent semantic topics for question retrieval. Thus, our research goal is to investigate how to develop effective topic models to learn the latent semantic topics from the question-answer pairs more precisely and effectively, and apply the models to improve the retrieval performance. Specifically, we first propose a novel Question-Answer Topic Model (QATM) to model the question-answer relationships to learn the latent topics aligned across the historical comparable question-answer pairs at the coarse-grained latent semantic level to alleviate the lexical gap problem, with the assumption that a question and its paired answer share the same topic distribution. Second, realizing that the shared topic vector can be easily dom i-nated by the longer one of the question-answer pair, we further extend QATM with posterior regularization [4 ] (QATM-PR) by constraining the question-answer pair have similar fractions of words assigned to each topic. Third , we introduce the retrieval model using QATM, which ranks historical questions by their probabilities of generating a queried question. Then, we propose a general framework, which combines the translation and topic information learned from the question-answer pairs at two diffe r-ent grained semantic levels, for question retrieval in CQA. Finally, we conduct experiments on a real world CQA dataset from Yahoo! Answers. We proceed to present them in the following sections. In a CQA archive, since the asker and answerer may express sim i-lar meanings with different words, it is natural to use the question-answer pairs as the parallel corpus that is used for estimating the translation probabilities, which can be seen as the information learned at the fine-grained lexical semantic level. Similarly, i n-spired by the work of [ 5, 11 ], the question from the asker and the answer from the answerer can also be assumed to be written in two different languages, while sharing as much as possible the same topic fractions. Based on this assumption, we propose a model called Question-Answer Topic Model (QATM) to model the question-answer relationships at the coarse-grained latent semantic level to learn the latent semantic topics aligned across the question-answer pairs. We assume that a question and its paired answer ent (perhaps overlap ping ) vocabularies to express these topics . Figure 1 shows the graphical representation of QA TM, while Figure 2 summarizes the generative story of generating a que s-tion-answer pair. 
Thus, the log-likelihood of a whole collection of question-answer pairs together with the parameters is where In our work, we learn the parameters using MAP estimation, trea t-ing as hyper-parameters, each corresponding to one Dirichlet prior. According to the standard EM algorithm, we can use the iterative updating formulas given in Figure 3 to estimate all the parameters. A question-answer pair is expected to not only share the same prior distribution over topics, but also contain similar fractions of words assigned to each topic. Since MAP estimation of the shared topic vector (in the M-Step of Figure 3) is concerned with explaining the union of words in the question and its paired a n-swer, and can be easily dominated by the longer one of the two, it does not guarantee that each topic occurs with similar frequency in the question and its paired answer. Thus, following [ 5, 11 ], we also extend QATM with posterior regularization [ 4] (QATM-PR) by constraining the question-answer pair have similar fractions of words assigned to each topic , trained using a modified E-Step in the original EM algorithm . Since the Question-Answer Topic Model a nd the Translation-based Methods cover different grained semantic levels, it is inte r-esting to explore how to combine their strength. In this paper, we choose the Translation-based Language Model (TransLM) as the Translation-based Method since TransLM has gained the state-of -the-art performance for question retrieval [ 3, 13]. Finally, we have the following ranking function for question retrieval: 
Here, denotes the historical question-answer pair. historical question-answer pair and the topic-specific question-word distribution, respectively; and is the parameter to balance between QATM and TransLM. and are the maximum likelihood estimation of word in and the whole collection , respectively; and is the Jelinek-Mercer smoothing factor. is the probability of translating a word in into a word in . is the parameter to balance between the Language Model and the Translation Model. 
Notice that, although the query term in Equation (5 ) is generated from the topic-specific word distributions in question language , the topic distribution in QATM is learned from the parallel question-answer pairs. In addition,  X  ( | ) in Equation (5) can be seen as performing a generative process of a queried question term from the question language . Thus, the question retrieval funciton using our QATM in Equation (4) can be seen as ranking a historical question by its probabilities of generating a queried question . over LM and TransLM, respectively. We collect all the questions-answer pairs from Yahoo! Answers using getByCategory function provided in Yahoo! Answers API Specifically, we utilize the resolved questions under the top-level category, namely "Computers &amp; Internet". The resulting question repository that we use for question retrieval contains 524,195 questions. We use 1,186,853 question-answer pairs from another dataset 2 for training the word translation probabilities and the topic models. With the above two dataset, we use the subject field as the question part and the bestanswer field as the answer part. For preprocessing, all the questions and answers are lowercased and stopwords are removed using a standard list of 418 words. 
To create the test set for question retrieval, we randomly select 200 questions from the question repository, with the remaining 523,995 question-answer pairs as the retrieval corpora. To create the ground-truth for question retrieval, we obtain annotation by pooling the top 20 results from all the models for each query. Baselines: Three types of baselines are used to compare with our proposed retrieval models, which are summarized as follows: (1) Language Model (LM) (2) Translation Model (Trans) and the state-of -the-art Transl a-tion-Based Language Model (TransLM). We use GIZA++ 3 train the IBM model 1 to get the word translation probabilities. (3) Topic Models learned from the question part (PLSA_q) , the answer part (PLSA_a) and the question-answer pairs in a simple "plus" way 4 (PLSA_qa) with the traditional topic model PLSA [ 6]. We use folding-in with 10 EM iterations to map each question in the retrieval corpora to its corresponding topic vector. We use 200 topics for all the topic models including our proposed QATM.
We also combine all the topic models with LM and TransLM to see the interpolation performance. The name of the combined models is denoted using the symbol "+" to plus each name of the models. For example, QATM+TransLM means we will mix QATM and TransLM linearly. http://developer.yahoo.com/answers 
The Yahoo!Webscope dataset ydata-yanswers-all-questions-v1_0 , available at http://research.yahoo.com/Academic_Relations http://www.fjoch.com/GIZA++.html Here, we simply "plus" the question and its paired answer as a whole text. It is different from our proposed QATM, which can be seen as in a "parallel" way. Parameter Setting: The experiments use many parameters. Following the literature, we set the smoothing parameter [3 ] in Equations (6), [ 3, 13 ] in Equation (7) and hyper-parameters [5 , 11] in Equation (1). Parameter in Equation (3 ) is tuned via 5-fold cross-validation: in each trial, we tune the parameters with four of the five subsets and then apply it to the remaining one. All the results reported above are those averaged over the five trials. We evaluate the performance of all the ranking models using MAP and P@10. We also perform a significance test using a paired t -test with a default significant level of 0.05. Table 1 presents the comparison of different models for question retrieval. There are some clear trends in the results of Table 1: (1) Trans significantly outperforms LM (row 1 vs. row 2). TransLM significantly outperforms Trans (row 2 vs. row 3). The results are consistent with the former work [ 13]. (2) QATM outperforms LM significant ly (row 1 vs. row 7). (3) QATM does not outperform Trans (row 2 vs. row 7). W e think that there are mainly two possible reasons: First, Trans is trained at the fine-grained lexical semantic level, which may co n-tribute much to find similar questions than QATM which is trained at the coarse-grained latent semantic level. Second, from Equation (8), we can see that Trans includes LM. Sp eci fically, when we assume , Equation (8) will reduce to LM, but QATM is not the case. What excites us is that when interpolating them with LM, QATM+LM performs as well as TransLM with no significant difference (row 3 vs. row 12). This demonstrates that the topic information extracted from parallel question-answer translation information learned at the lexical semantic level. (4) When further incorporating QATM with TransLM, the r e-trieval performance can be further improved (row 3 vs. row 17). This means that the topic information learned at the coarse-grained semantic level using our QATM can bring more knowledge to enhance the state-of -the-art TransLM, where the translation information is learned at the fine-grained lexical s e-mantic level. (5) When using posterior regularization (PR) to constrain the paired question and answer not only to share the same prior topic distribution, but also to have similar fractions of words assigned to each topic, the difference between QATM and QATM-PR is statistically significant (row 7 vs. row 8; row 12 vs. row 13; row 17 vs. row 18). In this section, we will show how effective to learn the latent s e-mantic topics jointly from both parts properly than each part or a simple "plus" way . There are mainly four ways (five models) to learn the latent topics. Three of the models are the third type of baselines . The other two are the proposed QATM and QATM-PR. 
First, we do experiments only using the five topic models as the document model for question retrieval. The results in Table 1 suggest several observations. (1) Only using PLSA_q, PLSA_a and PLSA_qa as the document model hurts the ranking perfo r-mance and is worse than LM (row 4~6 vs. row 1). (2) The latent topics learned in a simple "plus" way are better than that only from the question part or the answer part (row 4~5 vs. row 6). (3) QATM significantly outperforms LM (row 7 vs. row 1), and of course outperforms PLSA_q, PLSA_a and PLSA_qa (row 4~6 vs. row 7). This shows that QATM can learn the latent topics from the question-answer pairs more effectively and precisely. (4) The performance of QATM can be further improved by introducing constraints in the EM training to force the paired question and answer to share the same proportion of topics (row 7 vs. row 8). 
Then, we do the comparison experiments of the five topic models incorporated with LM. The results in Table 1 show the following observations. (1) After linearly combined with LM, PLSA_q and PLSA_a do not improve LM (row 9~10 vs. row 1), however, PLSA_qa can improve LM significantly (row 11 vs. row 1). This suggests that learning the latent topics from the question-answer pairs is much better than only from the question part or the answer part. Similar observations can be seen in the first group of comparisons. (2) Incorporating QATM with LM can benefit LM significantly (row 12 vs. row 1). (3) QATM-PR benefits LM more than QATM (row 12 vs. row 13). 
Finally, we also compare the five topic models incorporated with TransLM to see whether the topic models can bring more knowledge into the state-of-the-art TransLM. The observations from Table 1 are as follows. (1) PLSA_a does not improve TransLM (row 15 vs. row 3); however, PLSA_q and PLSA_qa can improve TransLM (row 14, row 16 vs. row 3). (2) Incorpora t-ing QATM or QATM-PR with TransLM outperforms TransLM significantly (row 17~18 vs. row 3). These results denote again that our proposed QATM can learn the latent topics from the question-answer pairs more effectively and precisely. 
From the above three groups of comparisons, we may get the following conclusions. (1) To learn the latent topics only from the answer part will not improve the retrieval performance. (2) When incorporating the answer part with the question part, no matter in a simple "plus" way or in a new parallel way, we can learn more knowledge on the latent topics than either from the question part or from the answer part. This indicates that learning the latent topics from both parts together can benefit from the answer part, which is not investigated in previous work [1 , 15]. (3) Our propose d QATM in a parallel way can benefit more from the answer part to learn the latent topics than the simple "plus" way by significant margins. The main reason maybe we only keep the topic-word distributions from the question part for question retrieval in Equation (5), however, PLSA_qa keeps the topic-word distributions in the whole text of question part and answer part, which will involve much noise. Thus, our proposed QATM can learn the latent topics more effectively and precisely. Recently, question retrieval has been widely investigated in CQA data. Most of previous work focuses on the translation-based methods [7 , 9, 13, 14] to alleviate the lexical gap problem. Be-sides , category information has been exploited [ 3, 2, 8, 10] in question retrieval task. Wang et a l. [12 ] propose a syntactic tree matching method to find similar questions. Cai et al. [1 ], Zhou et al. [15 ] propose to learn the latent topics from the questions. Moreover, Cai et al. [1 ] also incorporate the question categories in learning the latent topics for further improvements. In this paper, we propose a novel Question-Answer Topic Model (QATM) to learn the latent semantic topics from the question-answer pairs for question retrieval. Experiments conducted on a real world CQA dataset demonstrate that our proposed QATM significantly outperforms the other topic models learned from the question part, the answer part or both parts in a simple "plus" way with a traditional method. In addition, combining QATM with the state-of-the-art translation-based language model, where the topic and translation information is learned from the question-answer pairs at two different grained semantic levels respectively, can further improve the retrieval performance significantly. 
There are some interesting future works to be continued. First, contexture information should be considered to learn the latent topics, since the phrase-based translation model [ 14 ] has been proposed to show the effectiveness of the contexture information. Second, category information can also be incorporated into our model for discovering latent topics in the context of questions. This work is supported by the National Science Foundation of China under Grant No. 61070111 and the Strategic Priority R e-search Program of the Chinese Academy of Sciences un der Grant No. XDA06030200. 
