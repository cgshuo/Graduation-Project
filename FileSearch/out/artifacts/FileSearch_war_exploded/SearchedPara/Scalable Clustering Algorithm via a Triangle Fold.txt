 Facing up to the incessant growth of complex networks, more and more researchers start turning to a multilevel comput-ing paradigm with high scalability for clustering. By virtue of iterative coarsening level by level, the clustering results which are obtained from the coarsest network and then pro-jected to the original network, is superior to the ones from mining the original complex network explicitly. Empirical works reflect that the local-aggregation characteristic is a key point for multilevel clustering algorithms, thus tech-niques like modularity, label propagation etc. are used to discover the micro-clusters for coarsening. In this paper, we propose a scalable clustering algorithm via a triangle fold-ing processing for complex networks(SCAFT). Based on the strong cluster property of triangle, we fold each traversed tri-angle of the network into a superverex to realize coarsening. And each generated coarsened network by iteration is capa-ble of reserving the cluster structures of last level network, or even the intrinsic cluster structures of original complex net-work, improving the computational accuracy. What X  X  more, a streaming algorithm is embedded in our novel approach to generate a serial input sequence of vertices, reducing the heavy burdens of memory usage of system. Experimental results on real-world complex networks show that, SCAFT outperforms the state-of-the-art multilevel clustering algo-rithms in terms of clustering accuracy, running time, espe-cially in memory usage.
 I.5 [ Pattern Recognition ]: Clustering Algorithms multilevel clustering, triangle folding, streaming algorithm
Clustering is an efficient and foundational technique for analyzing complex networks, which are derived from a wide range of application domains like biological networks, social networks, the World-Wide-Web etc. By means of identifying the dominant structures and grouping the similar instances together [37], clustering converts the perspective of analyz-ing complex networks to a mesoscale (cluster) to simplify the difficulty of studying. In addition, the potential information is easier to discover, and the deep insight on complex net-works becomes possible. However, the unprecedent expan-sion of complex networks has posed lots of new challenges, inducing the traditional clustering algorithms like spectral clustering [2], divisive clustering [21] etc. hard to analyze the networks with millions of vertices or more. Therefore, how to extend the capability of clustering algorithms to large-scale complex networks is paramount.

Except for the improved existing clustering algorithms by heuristic skills, lots of researchers focus on data preprocess-ing, i.e. collecting available meta-data [28], sampling for sparsification [36], reducing the dimensions of feature space [6] etc. As is known to us, it is impractical to have some valuable information about data in hand for the unsuper-vised learning scenarios. Lack of valid sampling probability, the accuracy of clustering results from data sparsification is often out of expectation. Although dimensional reduction stresses the predominant sub-space, the quantity of data in primitive space has not been cut down, which inevitably leads to a high computational task. The deficiencies of the discussed methods above limit their further researches and applications.

To analyze the large-scale complex networks, plenty of approximate methods emerge successively, of which a mul-tilevel clustering paradigm is proved more fast and scalable. This paradigm is stemmed from the typical algorithm Metis [14], subsequently is used for all kinds of learning scenar-ios. With respect to the clustering applications, there are many multilevel algorithms such as the modularity-based method [25], the density-based method [12] and the label-propagation-based method [31] etc. By coarsening the input large-scale complex network level by level into a sequence of coarsened networks, the cluster structures of the initial com-plex network can be approximately projected by the initial clustering results from the coarsest network. Many empirical works demonstrate that the implicit clustering results from the deduction of initial mined clusters after multilevel coars-ening are better than the results from analyzing the original complex network explicitly [1]. In-depth studying in multi-lev el clustering paradigm shows that the local-aggregation characteristic is a key factor. Therefore, based on the lo-cal strong cluster property of triangle [29], we propose a scalable clustering algorithm via a triangle folding process-ing for complex networks(SCAFT). By virtue of folding the traversed triangles which stand for micro-clusters, the mul-tilevel coarsening process is realized and the intrinsic cluster structures of original complex network have been kept, im-proving the clustering accuracy. In addition, a streaming algorithm is employed to reduce the memory usage. Ex-perimental results on real-world complex networks demon-strate the prominent performances of our proposed approach SCAFT.
Clustering analysis in complex networks has been pro-ceeded and developed for decades in manifold fields. To meet the versatile application demands, apart from the traditional clustering algorithms like k-means [23], agglomerative hi-erarchical clustering [11], modularity-based clustering [26] etc., many mixture models equipped with other discipline theories have appeared, such as maximum margin cluster-ing [34] which comes from the supervised learning scenario of support vector machine, probability generation modeling which originates from statistics [18], random walking based clustering [30], genetic algorithm based clustering [5], Potts-model based clustering [24], resistance analog modeling [33] etc. The advantages of these clustering algorithms have been exhibited in many applications, but their ability of mining large-scale complex networks is restricted by the high com-putational complexity.

Within a certain error tolerance, approximating computa-tion is a better choice to settle the clustering problems with large-scale complex networks. According to some probabil-ity, a proportion of sub-network can be sampled to represent the original complex network, lowing the actual size of net-work to be analyzed. Of these approximate methods, the Nystr  X  om method based spectral clustering [10] or kernel k-means [32] are more efficient. To expand the scalability of spectral clustering with high accuracy and global optimal solution, or reduce the computational complexity of kernel k-means caused by dimensional increment, many researches adopt the Nystr  X  om method to generate low-rank approxi-mate matrices to speed up the entire clustering procedure. However, the saved time and space are obtained at the cost of the accuracy of clustering results.

Multilevel clustering is a rising popular technique with superior scalability. It is initially proposed for graph par-titioning (Metis [14]) by Karypis, and then developed for clustering such as Graclus [9] by Dhillon, and MMLSC [25] by Rotta etc. These algorithms have the common  X  X ax-imal matching based edge selection X  coarsening policy. A matching of network is to select a set of edges so that in the set there are no two edges incident on a same vertex, and a maximal matching means that the number of matched edges ready for coarsening is as large as possible. This sort of coarsening policy has several drawbacks as follows: (1) the maximal matching is a hard problem [13]; (2) despite the collapsed two vertices are joined by a same edge, it is uncertain that both of them belong to a same cluster; (3) it is unsuitable for a category of special networks whose degree of nodes follows a power-law distribution [1].

To break the limitation of existing multilevel clustering algorithms listed above, recently lots of researches on multi-level clustering have been promoted. Shiokawa et al. coars-ened the input network by the modularity-based incremental aggregation and pruning process [27]. Although there is no need to traverse all vertices, the computation of modular-ity and additional optimization of vertex-selecting order is costly, and the cluster information for pruning is often insuf-ficient. Huang et al. shrunk the micro-clusters detected by DBSCAN into supervertices [12]. Similar to DBSCAN, even though the discovery of micro-clusters based on local den-sity is relative easier than the global searching, the compu-tational complexity of mining parameter-free micro-clusters is higher. Wang et al. utilized the label propagation algo-rithm to search for the micro-clusters of network for coars-ening [31], which was implemented fast. However, the over shrinkage of vertices is liable to induce confusion between ad-jacent micro-clusters. Thus the refinement step which adds extra operations into the entire system is indispensable. In general, a complex network is depicted as a graph G = ( V; E; W ), where vertex v  X  V represents one data instance (or entity) of complex network, edge e  X  E rep-resents some kind of relationships between vertices, edge weight w  X  W represents the degree of connection and the value of w could be unit or numerical. The computing pro-cess of multilevel clustering consists of three phases which is displayed in Figure 1. And the definition of multilevel clustering is depicted as follows [14]: Definition 1 (Multilevel Clustering) Input: Large-scale graph G, iterator i=0 and initialize a transitional graph G i = G , threshold T .
 Output: k clusters of G .
 Process: 1. Coarsening phase : search for vertex subsets of G i based on some coarsening policy and fold each vertex subset into a supervertex; generate the coarsened graph G i +1 and save it; if ( | V G i +1 |  X  T ?) continue next step, else i = i + 1 and return to 1; 2. Initial clustering phase : mine k initial clusters of the coarsest graph G m by some high-performance clustering al-gorithm; 3. Uncoarsening and re nement phase : unfold each coarsened graph from the coarsest G m level by level in an in-verse order, project the initial clusters to graph G and refine the cluster affiliation of unfolded vertices from supervertices to obtain the eventually clustering results.

There are three key points which concern the computa-tional complexity of multilevel clustering algorithms in Defi-nition 1. One is to select a high-quality clustering algorithm for initial clustering, meanwhile focus on the accumulated edge weights. Another is to refine the cluster affiliation of random free vertices which are generated by unfolding su-pervertices during uncoarsening, improving the eventual ac-curacy of clustering results. The last one is how to detect an appropriate subset of vertices to be folded into a super-vertex, which is the most important. If all vertices folded into a supervertex actually belong to the same cluster, the uncertainty of whether the vertices unfolded from a super-Fi gure 1: The composed three phases of multilevel clustering vertex pertaining to a same cluster or not will be eliminated. Moreover, it X  X  obvious that the cluster structures of original graph (or network) would not be destroyed by the iterative coarsening, so the initial clustering results from the coarsest graph G m can project the basic clusters of original graph almost identically, and the refining operations can be omit-ted nearly or simplified enormously during the uncoarsening procedure. Shrinking two vertices incident on one edge tends to lose this promise, and the maximal matching is hard to match completely, especially when the distribution of node degree is out of balance. Micro-cluster computed by means of modularity or density has the better local-aggregation property which can keep up this promise, but in essence, the computation of these methods is a kind of local cluster mining process which is time-consuming.

Differing from all the multilevel clustering algorithms dis-cussed above, in this paper we select triangles as the ver-tex subsets, and fold each traversed triangle of network for coarsening to realize the multilevel clustering. In theory, because of the complete connection among all the inner ver-tices, clique is a local definition of cluster [22], thus clique with any order (n-clique) ought to be considered as a micro-cluster. However, the computational difficulty of higher-order clique (n-clique, n  X  4) will rise exponentially with the increasing of value of order and size of network, even for 4-clique. To the contrary, triangle (3-clique) owns the most simple structure, while its traversing procedure is the eas-iest. And relative to other local-aggregation micro-cluster detected by some clustering algorithm, the complexity of multilevel clustering based on searching for triangles of net-works will be reduced greatly. Meanwhile, triangle is able to comply with the promise of the vertices which one su-pervertex contains affiliating to the same cluster, thus the initial clustering and eventual clustering results are much better. In addition, to lower the space complexity of multi-level clustering, we input the vertices of network serially by a streaming algorithm. And with respect to all the triangles incident on each streaming-input vertex, we only traverse the triangle with the largest modularity gain [8], reducing the randomness of triangle selection for folding and coars-ening results.
Triangle is the ubiquitous topological structures in vast majority of complex networks [7], thus lots of research works adopt triangle as an entry point for deep learning on com-plex networks. According to Latapy X  X  analysis [17], count-ing all triangles of a network graph needs  X ( m 3 = 2 ) time and  X (3 m + 3 n ) memory, where m is the number of edges and n is the number of vertices. But fortunately, there is no need to search for all triangles in the coarsening procedure for our proposed multilevel clustering algorithm SCAFT. Let X  X  consider an example in Figure 2. Obviously, there are three clusters of the simple network graph in Figure 2(a), while Figure 2(b) shows the coarsened graph by triangle folding (TF), and edges  X  b; e  X  ,  X  f; i  X  and  X  m; o  X  are newly gener-ated. Obviously, the coarsened graph in Figure 2(b) keeps the basic cluster structures. Moreover, Figure 2(a) contains 9 triangles, but only 4 triangles are used to be folded, the remaining triangles disappear with the adjacent folded trian-gles, which can reduce the entire computational complexity of multilevel clustering enormously.
The structures of real-world networks are much more com-plicated so that the iterative coarsening is going on level by level. When the coarsening levels are built up, the high-order polygons of network graph will become lower-order p olygons or even triangles of next level coarsened graph. This transformation is produced by the adjacent relation be-tween polygons and folded triangles as well. It is significant for SCAFT that, when the original network graph is coars-ened deeper and deeper, the process of high-order polygons gradually evolving into triangles can make the sustainability of iterative coarsening.
Due to the  X (3 m + 3 n ) memory usage for counting trian-gles, the space complexity of multilevel clustering by folding the traversed triangles for large-scale complex networks is higher. Therefore, in order to reduce the memory usage in each level coarsening, we adopt a streaming algorithm to input each vertex of graph serially, and search for one of its adjacent triangles to be folded into a supervertex. The streaming detection is not executed in the beginning, owing to lack of sufficient vertices which are affiliated to the same triangle with the input vertex. Here two policies are pro-posed to tackle this problem. One is to input the subsequent vertex as close to the last vertex as possible. The other is to save the header sequence of streaming input vertices into memory, and start searching for a triangle incident on the next input vertex when 30 percent of memory is occupied. these two policies are the premise of streaming-based trian-gle folding process. In essence, the initial overlook of tri-angles incident on a certain number of vertices input firstly will not affect the eventual clustering results, because they can be saved for next level coarsening. The whole process is described as follows:
Definition 2 (Streaming-based Triangle Folding Pro-cess (STF)) Input: Streaming input vertex v t of G i at time t . Output: Generated supervertex v s .
 Process: Detect all triangles incident on v t ; if existing, then select an optimal triangle to be folded into a supervertex v else place v t in memory explicitly; t = t + 1 .

Until now, someone may doubt what does  X  X n optimal triangle X  mean? As is known to us, vertices with high de-gree often have more adjacent triangles than vertices with low degree. This imbalance will lead to the randomness of coarsening results, similarly signifies that different choice of triangles incident on the input vertex will generate differ-ent coarsened graphs. One efficient settlement to this prob-lem is to order the vertex selection, but it is not applicable to the streaming algorithm. Therefore, we make use of the modularity gain as a metric to measure the quality of micro-clusters (adjacent triangles), and select the triangle with an optimal modularity gain to be folded. Based on a weighted network graph, the modularity Q is defined in Equation 1 [20]: where w ij denotes the weight of edges between cluster i 0. And the definition of modularity gain  X  Q is depicted in Equation 2. wh ere W T is the sum of edge weights in triangle T , W v t ;in is the sum of weights of edges incident on v t in T , W tot the sum of weights of edges incident on T , W v t is the sum of weights of edges incident on v t , m is the sum of edge weights in graph.

Let X  X  view back the streaming-based triangle folding pro-cess briefly. Initially, each streaming input vertex of graph is assigned to an independent cluster. Starting at some time t, detect all triangles incident on a streaming input vertex v , compute the modularity gain  X  Q by Equation 2 for each triangle which is assumed as a micro-cluster, and select the triangle with maximum gain to be folded. By virtue of the modularity gain  X  Q , two kinds of randomness are elimi-nated with furthest but not completely. One is the selection of triangles incident on the streaming input vertex v t , the other is the orders of the streaming input vertices. Because of the optimal triangle selected by  X  Q to be folded, no mat-ter what the streaming input order of vertices is, the overall coarsening process is proceeded by the continuous optimized modularity gain  X  Q , which can make the final results in line with the optimal value of modularity Q .
The implementation of the proposed scalable clustering algorithm via a triangle folding processing for complex net-works (SCAFT) is depicted in Algorithm 1. And the con-crete description of Detectalltriangle() in Algorithm 1 is shown in Algorithm 2, where D ( v ) denotes the degree of vertex v , F ( v ) denotes a flag bit, and N ( v ) denotes the set of vertices adjacent to v .

The core of SCAFT is the streaming-based triangle folding process (STF) for coarsening. During the iterative coarsen-ing procedure, a sequence of coarsened graphs G 1 , G 2 ,..., G are generated, satisfying | V G |  X  | V G 1 |  X  | V G 2 |  X  Each level coarsening based on the traversed triangles fold-ing of graph G i is an independent procedure, by loop itera-tion of which the whole coarsening procedure of SCAFT is built up. Note that the information of each level interme-diate coarsened graph has to be stored, in support of the subsequent uncoarsening operations.

SCAFT appreciates the initial clustering phase much more than the uncoarsening phase, which is different from most of current multilevel clustering algorithms. As is discussed be-fore, due to the same cluster affiliation of the vertices of one triangle, the triangle folding based coarsening process can maintain the intrinsic consistency of cluster structures be-tween the coarsened graph G i and the original graph G , thus the initial clustering results determine the entire computa-tional accuracy of SCAFT immensely. Therefore, we select a high-quality spectral clustering algorithm [2] for the ini-tial analysis of cluster structures, which is superior to other traditional clustering algorithms and the computing results are globally optimal.

Under the premise of the first two phases of SCAFT, one of which is guaranteeing the basic cluster structures, and the other is making use of the high-quality clustering algo-rithm, the cluster structures of the input large-scale network have been mined and restored mostly by initial clustering. In consequence to some extent, there is no need to refine the cluster affiliation results from the intermediate uncoarsened graphs, because the random free vertices which are gener-ated by unfolding supervertices do not exist.

In another way, by means of the streaming algorithm pro-ducing a vertex input sequence, lots of memory usage during coarsening is saved, lowing the space complexity of SCAFT. And the randomness of adjacent-triangle searching can be eliminated maximally but not completely by acquired op-timal modularity gain value ( X  Q ). After all, all of the multilevel clustering algorithms are approximate computing methods.

Here we need to pay attention to a special phenomenon  X  X ver coarsening X , which is shown in Figure 3. The over coarsening phenomenon is a random event with low proba-bility, but happens when the folded triangles locate in the same high-order maximal complete subgraph. If without any constraints, the number of edges within clusters will decrease dramatically, so that it is almost equivalent to the ones be-tween clusters, obscuring the boundary and losing the mean-ingful cluster structures with local-aggregation property. As is exhibited in Figure 3, clusters A, B and C eventually de-generated into three vertices. Whereas in Detectalltrian-gle() , we make use of the flag bit F ( v ) set to prevent over coarsening efficiently, and experiences reflect that the best situation is that the number of coarsened triangles incident on a same vertex is no more than 2.

In summary, compared with the state-of-the-art multilevel clustering algorithms like Metis, Mmc and Shrink etc., the proposed algorithm SCAFT skips the heavy computation of maximal matching, and leaves out searching for the local micro-clusters and the refining operations, accelerating the entire analyzing process of multilevel clustering. And the initial clustering adopts a high-quality spectral clustering algorithm to enhance the accuracy. Furthermore, the com-puting procedure of SCAFT based on a streaming algorithm saves much memory usage of system.
In the sequel, let X  X  analyze the computational complexity of SCAFT.

Lemma 1 (Complexity) The time complexity of SCAFT is  X ( Lm 3 = 2 ) and the space complexity is smaller than or identical to the main memory, where m is the number of edges of graph G , L is the number of coarsening iteration. Al gorithm 1 SCAFT
Inp ut: Large-scale network graph G = ( V; E; W ), itera-tor i = 0, threshold T
Output: k clusters of G 1: Initialize a transitional graph G i = G 2: Coarsening: 3: repeat: 4: Scan vertex v t of G i at time t 5: while occupation of memory  X  30% do 6: Save v t in memory, t = t + 1 and return step 2 7: endwhile 8: Detectalltriangles( v t ) 9: if there is no triangle 10: Save v t in G i +1 explicitly 11: else 12: Compute  X  Q for each triangle 13: Select the triangle with the optimal value of  X  Q to be folded into supervertex v s 14: Save v s in G i +1 15: until No available vertex remained in G i 16: if | G i +1 |  X  T 17: i=i+1 and go on 18: else 19: i=i+1 and return step 2 20: Initial Clustering: 21: Clustering the coarsest graph G i by a high-quality spectral clustering algorithm 22: Uncoarsening without Refinement: 23: Project the initial clustering results to G by unfold-ing supervertices of each coarsened graph level by level inversely, eventually obtaining k clusters of G
Pro of. Relative to the original large-scale network graph, the size of the generated coarsest graph could be nearly ig-nored, and owing to the refinement omitted, the time con-sumption of initial clustering and uncoarsening is far little. Thus the time complexity of SCAFT mainly depends on coarsening. Review Algorithm 1, there are two nested loops during the coarsening procedure, the aim of which is to tra-verse all the edges of graph in  X ( m ) time; while the inner-most loop concealed by Detectalltriangle() is the intersecting computation, which can be completed in  X ( the whole procedure of counting all triangles of graph takes  X ( m 3 = 2 ) time in the worst case. But SCAFT has not to traverse all the triangles on account of the adjacent relation with the folded triangles(refer to aforementioned section). The other hand is the coarsening iteration, and the number of iteration levels L differs far from m in several orders of magnitude. Therefore to sum up, the The time complexity of SCAFT is little than  X ( Lm 3 = 2 ). In addition, due to the effi-cient streaming algorithm which is high-spatial-compression, the memory usage of SCAFT for clustering large-scale graph has been saved enormously.
In this section, we will evaluate the performances of our proposed algorithm SCAFT on several real-world complex networks. Two sub-experiments will be executed respec-tively. Firstly in comparison with the  X  X aximal matching based edge selection coarsening policy X  which is embedded in Metis [14], we demonstrate that SCAFT which assumes the A lgorithm 2 Detectalltriangle() In put: one vertex v of network graph G
Output: one set of detected triangles which are all inci-dent on vertex v 1: Begin 2: Initialize a triangle set  X  v = N U LL ; 3: If ( F ( v ) 6 1) Then 4: Break; 5: Else 6: For (each vertex u in N ( v )) Do 7: If ( D ( u ) &gt; D ( v )&amp;&amp; F ( u ) 6 1) Then 8: Continue; 9: End If 10: For (each vertex w in N ( v )  X  N ( u )) Do 11: If ( D ( w ) &gt; D ( v )&amp;&amp; D ( w ) &gt;
D ( u )&amp;&amp; F ( w ) 6 1) Then 12: Continue; 13: Else 14: Put triangle(u,v,w) in  X  v ; 15: F ( v ) = F ( v )+1; F ( u ) = F ( u )+1; F ( w ) =
F ( w ) + 1; 16: Break; 17: End If 18: End For 19: End For 20: Output  X  v ; 21: End If 22 End tri angle folding based coarsening policy is fit for the power-law complex networks. Secondly by contrast to SCAFT, we choose four multilevel clustering algorithms such as Metis, Mmc [27], Shrink [12] and Mlp [31] as baseline for exper-iments. Both Metis and Mlp are the graph partitioning algorithms, which need to be varied a little for clustering before experimental operations. All of the experiments are executed on a Linux machine with a 2.6GHz 4Core CPU and 8G main memory, and all algorithms are implemented in Java.
Our experimental datasets are listed in two tables respec-tively for two different sub-experiments. The datasets in Ta-ble 1 come from the Stanford University X  X  SNAP networks [35], and the two networks Actor and Google are the typical instances whose degree of nodes follows the power-law dis-tribution. With regard to the first sub-experiment, we only focus on the coarsening phase of both algorithms (Metis and SCAFT) on Actor and Google. And along with the coars-ening process goes on level by level, the ratio of the size (number of nodes or number of edges) of each level coars-ened graph to the one of the original network graph varies, which are plotted as the charts in Figure 4.

The datasets in Table 2 are collected from a wide range of repository. Wiki-Talk, Parents, LiveJournal and Twitter are online networks from the Stanford University X  X  SNAP Database [35]. R-MAT is a random-generated scale 24 net-work [4]. Wiki-Links is an article-link-represented network [15]. Sk-2005 is a crawl of Slovakian domain using Ubi-Crawler [3]. Structured RDF network DBpedia is generated from Wikipedian data [19].
 All the real-world complex networks in Table 2 own their Table 1: Complex networks with power-law distri-bution.
 N etwork V ertex Number Edg e Number Go ogle 87 5,713 5 ,105,039 1. 41 -2 .23 T able 2: Description of real-world complex net-works.
 Wik i-Talk 2 .1M 4. 6M 9 Liv eJournal 4 M 34 .7M 16
Wi ki-Links 2 5.5M 49 8M 17 0
DB pedia 6 2M 19 0M 8 real clusters, which can be referred as the ground-truth clus-tering results. Thus we can compare the analyzing accuracy of each algorithm by the following two criteria, and no mat-ter which one is selected, the greater calculated value means the better clustering results. 1. Normalized Mutual Information (NMI) . NMI [16] is such a metric that it is able to maintain the bal-ance between clustering quality and number of clusters, the definition of which is: wh ere N denotes the confusion matrix, N ij is the number of vertices in C i the sum on row i and column j of N respectively. 2. Rand Index (RI) . RI [16] is a measure of similarity, and its definition is: where T P , F P , F N , T N respectively denote true posi-tives, true negatives, false positives, false negatives. Their concrete meanings are omitted here.

We partition the second sub-experiment into two parts to evaluate SCAFT. The first part is used to test the elimina-tion of random searching for the objective folded triangles by the modularity gain. Based on NMI , we compute the clustering results of eight real-world networks by SCAFT on two different conditions. One is selecting the folded triangle randomly, the other is selecting an optimal triangle base on the maximal modularity gain  X  Q . The comparative results are drawn in Figure 4. The second part is to compare the performances of SCAFT with other multilevel clustering al-gorithms in terms of accuracy, time complexity and space o ccupation. The results of RI , running time and memory usage on eight networks are collected in Table 3, Table 4, Table 5 respectively.
The trend of folding lines in Figure 4 (no matter Figure 4(a) or Figure 4(b)) exhibits that, the capability of SCAFT to coarsen networks complied with the power-law distribu-tion is superior to Metis. Obviously, the folding line of Metis has an asymptotic ratio value more than zero, which implies that the coarsening process of Metis is terminated much ear-lier. The main reason of this phenomenon is that the imbal-ance of node-degree distribution limits the maximal match-ing extremely. To the contrary, the coarsening process of SCAFT goes on. Therefore, SCAFT is suitable to analyze the power-law networks. In addition, under the same hori-zontal axis, the coarsening reduction ratio of Metis is lower than SCAFT after the identical number of coarsening levels; under the same vertical axis, Metis needs more coarsening levels than SCAFT to obtain the equivalent coarsening re-duction ratio. Therefore, we can also conclude from Figure 4 that, SCAFT is able and suitable to analyze the power-law complex networks, which can also be an explanation for further measuring results of SCAFT in running time and memory usage. Figure 4: The comparison of coarsening capability on Table 3: RI comparison of different algorithms on datasets.
 Wik i-Talk 0. 835 0 .879 0 .901 0 .812 0 .905 Liv eJournal 0. 772 0 .811 0 .836 0 .817 0 .829
Wi ki-Links 0. 713 0 .725 0 .724 0 .716 0 .728
S ubsequently, let X  X  analyze the clustering results in Figure 5. With regard to the graph of each network, there are two broken lines expressing the different clustering accuracy of NMI on two conditions. One is the clustering results from searching for one folded triangle incident on the streaming-input vertex randomly, the other is the results from selecting the triangle with the largest value of modularity gain  X  Q as a micro-cluster. Each broken line of each graph is composed of eight independent executing results under the same exper-imental condition (by random or  X  Q ). Obviously, the value of NMI with random searching is volatile, that is because, if there are many triangles incident on one streaming-input vertex, different selections of adjacent triangle to be folded result in different coarsened graphs. Moreover, the gener-ated coarsened graphs and clustering results are different from each other. By contrast, the value of NMI based on the modularity gain is plain, demonstrating that the clus-tering results from SCAFT by folding triangles with the op-timal modularity gains  X  Q for coarsening are much more stable.

The scalability of multilevel graph clustering can be con-cluded from all the experimental results in Table 3, Table 4 and Table 5. Any one of the five algorithms in comparison can analyze the large-scale network graphs efficiently. In the sequel, let X  X  compare the different performance indices of five algorithms in detail separately.

The RI comparison of different algorithms is shown in Ta-ble 3, which is used to measure and compare the clustering accuracy. From Table 3, we can observe that the RI of Metis is the lowest, that is because the coarsened graphs generated by shrinking two vertices incident on one edge, is not capa-ble of guaranteeing the consistence of cluster structures of the coarsened graphs with the ones of the original graph. To the contrary, the other algorithms promise this point. But due to the over shrinkage of vertices which is prone to induce boundary confusion among adjacent micro-clusters, the RI of Mlp is relative lower than Mmc, Shrink and SCAFT. The reason of the RI of Shrink being higher than Mmc is that, Shrink is realized by two metrics of modularity and den-sity. By contrast with Shrink, the RI of SCAFT is higher except for LiveJournal and R-MAT which are caused by ran-dom errors in accident, displaying the better performances of SCAFT in computational accuracy.

The different running time results of five algorithms on eight network graphs are listed in Table 4. There is on doubt that the time consuming of Metis is the largest, which is mainly caused by the computational procedure of maxi-mal matching and the low coarsening reduction ratio. The Table 4: Running time(s) comparison of different algorithms on datasets.
 Wik i-Talk 37 6 1 39 15 8 1 02 9 1 Liv eJournal 59 1 1 92 21 6 1 79 1 22
Wi ki-Links 31 10 1 400 14 90 1 260 7 46 d etection of local micro-clusters, which is based on the mod-ularity or density clustering algorithms, needs to take much time to complete, thus the running time of Mmc and Shrink is more than Mlp and SCAFT. Because of the boundary confusion resulted from the over shrinkage, there demands plenty of extra time to refine the initial clustering results, thus the time complexity of Mlp is higher than SCAFT. Moreover, the omitted computational processes of the micro-cluster searching and refining operations have saved lots of CPU time for SCAFT.

By virtue of embedding a streaming algorithm into our proposed multilevel clustering approach, the space complex-ity of SCAFT can be reduced vastly, which is proved by the comparison results of memory usage on eight complex networks, with the smallest space occupation of SCAFT in Table 5. Corresponding to the highest time complexity of Metis, its memory usage is the largest of five algorithms. Different from the analytical accuracy on RI and running time, the size of coarsened graphs which are generated from the over shrinkage of vertices is much smaller, thus the space occupation of Mlp is smaller than Metis, Mmc and Shrink. The larger memory usage of Shrink than Mmc is caused by the much more computation on double micro-cluster discov-ery metrics.
 Table 5: Memory usage(GB) comparison of different algorithms on datasets.
 Li veJournal 9 .79 1 .80 2. 05 1. 01 0. 06
Wiki -Links 6 7.1 1 1.6 13 .0 6. 4 0. 49
Inspired by the performance preponderance of multilevel clustering paradigm and the local-aggregation characteris-tic, we propose a scalable clustering algorithm via a triangle folding processing for complex networks (SCAFT). Different from the existing multilevel algorithms, SCAFT assumes a novel traversed-triangle folding based coarsening policy to put the performance of multilevel clustering forward. On account of the strong cluster effect of triangle, the cluster structures of coarsened graphs generated by SCAFT are in line with the basic ones of the original network. Thus the initial clustering results from the coarsest network af-ter iterative coarsening level by level, suffice for the entire projection of the clusters in the initial large-scale complex network nearly, promoting the analytical accuracy of mul-tilevel clustering paradigm. Moreover, by means of an em-bedded streaming algorithm, the memory usage of SCAFT is reduced greatly, and the randomness of searching for the folded triangle incident on each serially streaming-input ver-tex is eliminated mostly by the optimal modularity gain. Lots of experimental results on large-scale real-world com-plex networks demonstrate that, the computational com-plexity of SCAFT is far lower than the state-of-the-art mul-tilevel clustering algorithms, especially in memory usage, a nd the RI comparison of five algorithms on eight datasets displays the prominent performance of SCAFT in cluster-ing accuracy. Besides, there is only one limitation of that SCAFT is applicable to the learning scenarios where the objective complex networks are rich in triangles. This work is supported by the National Science Founda-tion of China under grant number 61402473, KeJiZhiCheng Project under grant number 2012BAH46B03, National HeGaoJi Key Project under grant number 2013ZX01039-002-001-001, and  X  X trategic Priority Research Program X  of the Chinese Academy of Sciences under grant number XDA06030200. [1] A. Abou-Rjeili and G. Karypis. Multilevel algorithms [2] M. Belkin and P. Niyogi. Laplacian eigenmaps and [3] P. Boldi, B. Codenotti, M. Santini, and S. Vigna. [4] D. Chakrabarti, Y. Zhan, and C. Faloutsos. R-mat: A [5] C. Chira, A. Gog, and D. Iclanzan. Evolutionary [6] R. Chitta, R. Jin, and A. K. Jain. Efficient kernel [7] S. Chu and J. Cheng. Triangle listing in massive [8] L. Danon, A. D  X  X az-Guilera, and A. Arenas. The effect [9] I. S. Dhillon, G. Y, and B. Kulis. Weighted graph cuts [10] C. Fowlkes, S. Belongie, F. Chung, and J. Malik. [11] R. Gil-Garcia, J. M. Badia-Contelles, and [12] J. Huang, H. Sun, J. Han, H. Deng, Y. Sun, and [13] G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar. [14] G. Karypis and V. Kumar. A fast and high quality [15] J. Kunrgis. Konect X  X he koblenz network collection. [16] V. Labatut. Generalized measures for the evaluation [17] M. Latapy. Main-memory triangle computations for [18] C. Li and G. Biswas. Improving clustering with hidden [19] M. Morsey, J. Lehmann, S. Auer, and A. N. Ngomo. [20] M. Newman. Fast algorithm for detecting community [21] M. E. J. Newman and M. Girvan. Finding and [22] G. Palla, I. Der  X  l , enyi, I. Farkas, and T. Vicsek. [23] W. L. Ping and A. T. L. Phuan. Centroid stability [24] J. Reichardt and S. Bornholdt. Detecting fuzzy [25] R. Rotta and A. Noack. Multilevel local search [26] P. Schuetz and A. Caflisch. Efficient modularity [27] H. Shiokawa, Y. Fujiwara, and M. Onizuka. Fast [28] G. M. Slota, K. Madduri, and S. Rajamanickam. Pulp: [29] P. Sun and L. Gao. Fast algorithms for detecting [30] S. A. Tabrizi, A. Shakery, and M. A. et al.
 [31] L. Wang, H. W. Y. Xiao, and B. Shao. How to [32] C. K. I. Williams and M. Seeger. Using the nystr  X  om [33] F. Wu and B. A. Huberman. Finding communities in [34] L. Xu, J. Neufeld, B. Larson, and D. Schuurmans. [35] J. Yang and J. Leskovec. Defining and evaluating [36] L. Yue, A. Joshi, P. Aashish, L. John, and J. Ghosh. [37] K. Zhang, I. W. Tsang, and J. T. Kwok. Maximum
