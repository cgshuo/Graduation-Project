 1. Introduction mous increase in user-generated multimedia content like movieclips and pictures. On-line databases are actively used to egorize the content, this has resulted in huge collections of unstructured data.

For future retrieval, many network users actively annotate the content using tags. Although most people use tagging to organize their own content collection, it has been shown that social tagging results in semantically descriptive annotations that can be used for content retrieval by the entire network (Golder &amp; Huberman, 2006; Marlow, Naaman, in which the more popular tags are typeset in a larger font or more prominent color. Although there exist many dif-ferent methods to draw these clouds (Kaser &amp; Lemire, 2007 ), the relevance of a tag is often based on the global pop-ularity of the tags in the entire network (e.g. popular tags in Last.fm engines, people often use multiple word queries in order to disambiguate their information need. To enable effective con-work we show that a personalized system that takes latent semantic relations into account can aid the user in his search for the desired content.

We focus on social content systems that enable collaborative tagging to annotate the available content. In collaborative retrieval.
 Besides tagging, the social aspects of networks stimulate people to share their opinion about the provided content.
In many interfaces people can assess the quality of the content by giving a rating. With the introduction of ratings and tags in on-line databases, content annotation has shifted to subjective categorization. The combination of these two information sources creates a non-hierarchical database categorization based on both content quality and topic. Using ratings and tags, we create a graph of the network, resembling the actual relations in social content systems. We use a personalized random walk over this graph to evaluate the retrieval performance of queries with increasing number of terms. 2. Personalization model
For the relevance ranking of the content based on the selected query tags we propose to use a random walk over the graph, created by all rating and tagging actions. The random walk has proven to be an effective ranking method for net-clarity we now briefly discuss the model.
 ability distribution. This distribution can be represented by the transition matrix A , where a from node i (at time n )to j (at time n  X  1): The initial state can now be represented as a vector v 0 (with
Multi step probabilities can be found by repeating the multiplication all nodes in the network. 2.1. Transition matrix  X  A  X  matrix D  X  u k ; i l ; t m  X  , where each position indicates if user u (with m  X f 1 ; ... ; M g ).
 but sum over the 3 dimensions of D to obtain:
UT matrix: UT  X  u k ; t m  X  X  P l  X  L l  X  1 D  X  u k ; i l ; t
IT matrix: IT  X  i l ; t m  X  X  P k  X  K k  X  1 D  X  u k ; i l ; t
UI matrix: UI  X  u k ; i l  X  X  P m  X  M m  X  1 D  X  u k ; i l ; t tent. Therefore, we replace the tag-based UI matrix by the matrix based on the users X  ratings. The rating matrix  X  R  X  u contains the explicit users X  preference for the available content, often expressed on a five or ten point scale. the initial state. The self-transitions are represented by an identity matrix S is equal for all nodes.
 ley, 1988 ). For example, the weighted User-Tag matrix is computed by: to one.
 of the submatrices, the rows of A now sum to 1, so they can be used as transition probabilities. random walk, we can therefore fix a and optimize only the walk length. Earlier work has shown that the optimal retrieval sition probability  X  a  X  to a relatively high value of 0.8.
 matrix A . After n steps, the content ranking is obtained by ordering the part of  X  ready rated by the target user). We assume that a different user interface is used to browse previously seen content (the user X  X  library), therefore we remove the training examples from the final ranking. 2.2. Query weight  X  h  X  vector, both the query tag and the target user are assigned a value according to h  X  h 2 X  0 ; 1  X  : (where u k is the target user and t m indicates the set of selected query tags: m  X f m the selected query tags, so the result will not be personalized for u collaborative filtering ( Resnick &amp; Varian, 1997 ).
 3. Data 3.1. LibraryThing network where both collaborative tagging ( 40 million) and rating ( 5 million) are actively used by the community.
We have collected a trace from the LibraryThing network, containing 25,295 actively tagging users. data set we retain 7279 users that have all supplied both ratings and tags to at least 20 books. We remove books and tags 2,056,487 UIT relations, resulting in a density of 7 : 2 10 matrices have a density of respectively: 2 : 8 10 3 ; 5 : 2 10 in full documents indeed follow a power-law (Newman, 2005 ), the distribution of tag assignments seems to deviate from a and a power-law fit for q &gt; 5: We find the optimal fit with parameters k  X  2 : 3 for the Poisson distribution and C  X  83 ; s  X  4 : 4 for the Power-law.
Arampatzis and Kamps compared various TREC and AOL data sets and found that the average exponent is close to 5 for web query length (Arampatzis &amp; Kamps, 2008 ). In full textual documents the exponent of word frequencies is generally known to be lower, for example Newman found a value of 2.2 for English text in the book Moby Dick (Newman, 2005 ).
The slope of the Power-law fit on the LibraryThing tagging data (Exponent: 4.4) lies between the distributions observed in web-queries and in full English documents. This shows that the annotations that people make in social tagging systems are more exhaustive than queries but more focused than full documents.

In our experiments we will assume that people would use a subset of the terms they have used to annotate their content if they needed to retrieve this content. Here we make the common assumption that the query and document are derived the query with an extra randomly selected tag. As in any text based retrieval system, we assume that we can only answer queries with terms that occur in the corpus.
 methods on the collected data, we expect that this distribution lacks a power-law tail because our data crawl was biased towards users with many annotations (Mislove, Marcon, Gummadi, Druschel, &amp; Bhattacharjee, 2007 ). 4. Experimental setup 4.1. Data preparation ing out 1/5 of the items of 1/5 of the training users (the validation set).
 has been evaluated at least once.

We compute the mean score over all validation users in the training set and to obtain stable results we repeat the opti-mization for all 5 independent user splits. We compare the obtained mean performance for different settings of n and h to set, but will be present in the graph.

The optimal model parameters derived from the training set are used to compute the performance on the test set, by of our optimal model to the results achieved with conventional methods ( Step 5 , Fig. 7 ). 4.2. NDCG evaluation
To evaluate the predicted content ranking, we use the Normalized Discounted Cumulative Gain (NDCG) proposed by J X rv-elin and Kek X l X inen (2002) .
 ion r 2f 3 ; 3 : 5 ; 4 ; 4 : 5 ; 5 g are assigned a value of respectively G 2f 1 ; 2 ; 3 ; 4 ; 5 g , called the gain . log lative Gain (DCG) now accumulates the values of the discounted gain vector:
The DCG vector is normalized to the optimal DCG vector. This optimal DCG is computed using a gain vector where all test ratings are placed in the top of the ranking in descending order. Component by component division now gives us the NDCG use the area below the NDCG curve as score to evaluate our rank prediction. 5. Experiments
We will use the proposed random walk model to discuss the retrieval performance for increasing query length. For each
This frequency ranking is obtained by taking one step through the graph with h  X  0. In this case the ranking will only be based on the number of people who have assigned the query tag(s) to the content. Due to the TF X  X DF weighting on the IT T matrix this ranking corresponds to using a simple vector space model with TF X  X DF weighting. 5.1. Smoothing and personalization
To find the optimal model parameters and evaluate the sensitivity of the model we use the random walk to predict the which means that personalized retrieval gives a more accurate prediction than both completely personal and completely tag-based queries (Fig. 5 , point B).

We also find that the optimal number of steps is larger than one  X  n  X  13  X  , which means that the random walk improves a
When the number of steps further increases  X  n !1 X  the state vector will converge to the stable distribution based on the global network popularity of the content. As expected the mean NDCG drops to a lower value if the content ranking forgets the information about the initial query.
 dent on the initial query (and h ). We therefore use the popularity ranking based on the finite state vector as frequency ranking with ^ q  X  0(Fig. 5 , point C). The difference in NDCG between n  X  99 and n  X  101 is 5 : 1 10 the reported significance, therefore we use the result at n  X  101 as finite state vector.

We repeat the optimization for increasing number of query tags and show the optimal model parameters in Fig. 6 .Ifwe add more tags to the query we see that the optimal parameter settings converge to the frequency based ranking ( h  X  0 and personalization and smoothing diminishes. 5.2. The influence of personalization and smoothing
For each number of query terms we will compare the NDCG with optimal model parameters to the NDCG obtained with fre-quency ranking. The mean NDCG and standard deviation  X  r  X  are shown in Table 1 and visually depicted in Fig. 7 .
These results show that the optimal model indeed converges to the frequency based model when the user issues longer queries. When the query consists of 4 tags there is an insignificant performance difference between both models. When the query consists of 4 tags only the user itself can make his information need more specific by selecting more tags.
We map the result of the optimal model to the interpolated NDCG obtained with frequency ranking. In this way we can recommendations is closer to a ranking based on a user selected query term than to the popularity ranking. ing more terms or typing a longer query the gain of the personalized model disappears. 6. Discussion 6.1. Related work
Research on query length in web search has shown that users generally do not like to type exhaustive queries. The re-advocates that personalization provides another way to disambiguate the multiple meanings encoded by (too) short queries. too short to allow re-ranking or filtering. The graph ranking method we have used exploits the network structure which is terms.
 and often enjoy giving their opinion by supplying a rating.
 personalization based on query expansion with a users previous annotations can on average improve short queries by half a query term.
 have used the random walk model to evaluate various retrieval tasks in differently designed tagging systems. We have shown that the positive effect of the random walk on the reduction of the vocabulary problem becomes larger in sparser on the length of the query. Especially the commonly short queries can benefit from the integration of latent relations. 6.2. Synonym and homograph robustness
Well known problems in tagging systems are synonyms and homographs. Synonyms are different words that share the as a query, the content might not be found. The same problems arise when people use abbreviations, singular or plural words, word combinations and different languages. If a tag-cloud is used to query a database, only a single word is used his initial query.

Clustering methods have been proposed to group tags with strong lexical relations ( Begelman et al., 2006 ). Clustering
A random walk has shown to have a soft clustering effect that smoothly relates similar concepts before converging to the these strongly connected entities which makes the random walk robust against synonymity problems.
Homographs are words that do not necessarily have the same pronunciation, but are written in exactly the same way. If a ambiguate the terms a user is looking for, our personalized random walk model integrates the information about the past behavior of that user. By starting the random walk at both the query tag and the target user, the content that matches the number of clicks a user has to do to reach the desired content. 7. Conclusions
The number of tags per annotation in social media closely resembles the number of terms people use in web-queries. We expect that the same generative process forms the basis of both events. We have therefore used the tags assigned by the users as their hypothetical queries to retrieve this content.

Retrieval models in social content systems can greatly benefit from personalization and smoothing. Due to the vocabulary that arises in these systems can effectively be used to give recommendations or rank the content according to the users X  queries.

We have shown that there is a clear relation between the length of the query and the quality of the predicted content ranking. For queries shorter than 4 terms the proposed model can significantly improve the content ranking. When a user decides to put more effort in his query the positive effect of personalization and smoothing diminishes. Acknowledgement
The research leading to these results has received funding from the European Community X  X  Seventh Framework Pro-gramme [FP7/2007-2011] under Grant Agreement No. 216444 (see Article II.30. of the Grant Agreement). References
