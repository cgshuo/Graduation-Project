 1. Introduction
Recently, user generated data is growing rapidly and becoming one of the most important source of information in the web. This data has a lot of information to be processed like opinion, experience, etc. which can be useful in many applica-tions. Forums, mailing lists, on-line discussions, community question answering sites and social networks like facebook are some of these data resources that have attracted researchers lately.

Blogosphere (the collection of blogs on the web) is one of the main source of information in this category. Millions of people write about their experience and opinion in their blogs everyday, and this provides a huge amount of information Rijke, Macdonald, Mishne, &amp; Soboroff, 2006 ).
 query topic. In other words, we want to find the most important blogs for a specific topic which by reading them, user will have as much information as possible.

There are some properties of blogs that make blog analysis different from usual text analysis. One of these properties is blog relevance to the query. For example a blog which has more relevant posts lately would be more relevant to the query than a blog with the same number of relevant posts that are older. Also each post in a blog can have viewer generated comments that can change the relevance of the blog to the query if these are considered as part of the content of the blog. in the blogosphere show content relation between the source and the destination that can be similarity or agreement or dis-agreement about a topic, while links between websites are more about trust and can be used as a measure of authority of the  X  erty and try to use aggregation methods like Ordered Weighted Averaging (OWA) operators to combine post relevance and compute blog relevance as a whole.

The rest of the paper is organized as follows: in Section 2 we review related work, specially voting models as the state of the art fusion methods applied to blog distillation. Section 3 includes description of the Ordered Weighted Averaging oper-ators as the aggregation methods implemented in our experiments. Section 4 explains a graph-based method for calculating the importance of posts in a query-based cluster, which we involve it later in the aggregation. Section 5 shows our exper-imental results and Section 6 gives conclusions and future work. 2. Related work The main research in blog distillation started after 2007, when TREC organizers proposed this task in the blog track.
Researchers have applied different methods from similar problems to blog distillation like ad-hoc search methods, expert search algorithms or methods from resource selection in distributed information retrieval.
 where they treat each blog as one long document created by the concatenation of all its posts. Given a query q they derive a score for each blog b in the corpus using the negative KL -divergence between the query language model and the language beside content of the blogs. They use temporal span and temporal dispersion as two measures of relevance over time and show that these features can help in blog retrieval.

Expert Search is a task in TREC Enterprise Track where systems are asked to rank candidate experts with respect to their their experiments show that these features do not improve performance of the system.

Resource selection in distributed information retrieval is another similar problem and some of its methods are applied to recourse selection problem. They model each blog as a collection of posts and use a language modelling approach to select ate topic-based clusters of posts in each blog and select blogs which have the most similar clusters to the query.
Our work in this paper is similar to resource selection algorithms for distributed information retrieval, where we want to use aggregation methods to combine available evidence and find the most relevant blogs. The intuition in this paper is art methods.

As the baseline, we use voting models ( Hannah et al., 2007; Macdonald &amp; Ounis, 2006b, 2008) to aggregate relevance methods to find related blogs. These methods rank blogs by aggregating the relevance scores of the posts associated with each blog. We use their best two aggregation methods, called expCombSum and expCombMNZ, as the baselines. ExpComb-
Sum ranks blogs by considering the sum of the exponential of the posts relevance score as follows: ilarity between the post and the query that is computed using a search engine. ExpCombMNZ includes a component which takes into account the number of posts in each blog that are in the ranked list of the query, R(Q) : where kk shows the size of the set. For more details about voting models in blog retrieval refer to ( Hannah et al., 2007;
Macdonald &amp; Ounis, 2006b, 2008 ). 3. Ordered Weighted Averaging operators
The Ordered Weighted Averaging operators, commonly called OWA operators, were introduced by Yager (1988) . OWA operators provide a parametrized class of mean type aggregation operators, that can generate OR operator ( Max ), AND oper-ator ( Min ) and any other aggregation operator between them.
 An OWA operator of dimension n is a mapping F : R n ! R that has an associated weighting vector W such that and where where a ind ( i ) is the i th largest element in the operand collection a
As can be seen, when w 1 = 1, the operator returns the largest element (like an OR operator) and when w the smallest element (like an AND operator). By changing the weighting vector, we can have any operator between these two extremes. For example, when " i ; w i =1/ n , it will be a mean operator.

OWA operators have different behaviours based on the weighting vector associated with them. Yager introduced two measures for characterizing OWA operator ( Yager, 1988 ). The first one is called orness and is defined as: which characterizes the degree to which the operator behaves like an or operator. This measure was previously introduced in different forms by others ( Marichal, 1998; Torra &amp; Narukawa, 2007 ).

The second measure is dispersion and is defined as and it measures the degree to which OWA operator takes into account all the available information in the aggregation.
As mentioned before, one of the issues in blog retrieval is aggregating posts relevance score and calculate a score for the the blog being relevant to the query and fuzzy aggregation methods like OWA operators seem applicable in blog retrieval. 3.1. Linguistic-functional specification for weighting vector
One important issue in applying OWA operators to a problem is determining the weighting vector. Yager introduced a method based on linguistic quantifiers for obtaining these weights: where n is the number of operands to be combined, and Q is the fuzzy linguistic quantifier. We use the following definition for the Q function as suggested by Zadeh (1983) : and  X  X  As many as possible  X  X . We use these quantifiers for computing the weighting vector in our experiments. 3.2. Importance weighted OWA aggregation
In this way we can take into account other available information in the final aggregated score. In our problem, the impor-tance could be calculated based on the hyperlink information, user comments, temporal information or content relations between posts.
 gated score for a blog, Score ( B ), will be: where ( a i , v i ) tuple is the given information for each blog post with a tance. Again we assume a ind ( j ) as the j th largest element of a
R  X  P n j  X  1 v ind  X  j  X  as the sum of the importance weights, the OWA weights are calculated by: tion Q . After calculating the weighting vector, the aggregated score for each blog is obtained by:
As we can see in Eq. (6) , when the importance is zero, the weight for that operand will be zero and it will be ignored:
Similarly when the importance is very small, the difference between R consequently. However when R i &gt; R j , there is no guarantee that u we use importance values v i for both ranking and weight calculation, the operator will be same as the Importance Induced antees higher weights by increasing importance, however because special setting in our application we want to give more priority to the relevance scores than importance values and we simply want to smooth the relevance score based on the importance of the document. 4. Posts importance in a query-based cluster
In order to integrate importance in the OWA operators based on the Formula (7) , we need to define a measure of impor-tance for each blog post. We use the content-based relation between the documents to calculate their importance. We con-sider a set of retrieved documents for each query as a cluster of relevant documents for that query. The more a document is similar to the other retrieved documents, more important it is in the cluster.

So we can use the similarity between retrieved documents as an importance measure. To capture these similarities in a general way, we define a graph-based representation of the cluster which includes the retrieved documents for a topic and the terms occurring in those documents. Fig. 1 shows part of such a graph, where an edge between a post and a term indi-cates that the term occurred in that specific post. The more common terms there are between two documents, the more sim-ilar those documents should be. By performing a long enough random walk in this matrix and reaching the stationary distribution, we will have the importance of each individual document in the graph.

We represent the graph by its adjacency matrix A , where each row is equivalent to a node in the graph and elements of is a directed graph where the weighted edges show the strength of the relation between nodes and will be described later in more detail.
 other words, the transition probabilities have different meanings based on the type of the nods and can be defined as follows: where i 2 T means node i is a term and i 2 P means node i is a post. The outgoing probabilities from a node and hence the of rows (columns) is equal to the total number of posts and terms.

We compute the transition probabilities between nodes in more than one step by multiplying the matrix A by itself. Ele-ment C ij , where C = A n , is thus the probability of reaching j from i after n steps in a random walk.
To make the computation less expensive and calculate the importance around the query, we just compute the stationary will use the notation P n ( t j j p i )=( A n ) ij to denote the probability of moving from post p this random walk can be seen as a type of smoothing where we compute probability estimates even for terms not present in the document. This graph-based smoothing takes into account the frequency of each term in similar documents, where sim-ilar documents are determined by their common terms. For example, even if a particular blog post discussing some aspect of machine learning did not contain the word  X  X  X egularization X  X , the term would be assigned a non-zero value within a smoothed high frequency.
 swell &amp; Szummer, 2007 ), by iterating forward from each query term node t query term. The transition probabilities between terms and documents are calculated using Maximum Likelihood estimate: where tf ( t j , p i ) is the frequency of the term t j in the post p it. Similarly, the probability of transitioning from a term node t
This formula can be concluded directly from Eq. (11) by assigning proper prior probabilities for posts and terms. We set the prior probability of a post to be proportional to its size: and probability of a term is set to be proportional to its frequency in the collection: Using these prior probabilities in Bayesian theorem Eqs. (11) and (12) can be derived from each other.
A random walk of length one is equivalent to a Maximum Likelihood estimate for P would generate a stationary probability distribution independent of the starting points.

By adding a self-loop transition to all term nodes, we turn a length n random walk into the weighted (exponentially decaying) average of walks of length 1 to n . We do this by a = P ( t a smoothing parameter which regulates the importance of shorter versus longer walks in the post-term graph. Thus the parameter a regulates how much smoothing we do on the initial Maximum Likelihood estimate. The smaller the self-loop probability a , the more the estimate will be smoothed with longer walks and vice versa.
 have a value. By adding the self-loop on the terms, we keep a history of all walks to that term.
At the end, to make the matrix stochastic (sum up to one in each row) by having term self-loops, we decrease the prob-abilities from terms to posts. The generated matrix looks like: object type X to the object type Y. Once we have computed P as the post importance in the cluster around the query:
We use this importance value, as an another information available for the posts, in the formula (7) and aggregate blog post relevance scores and calculate blog relevance score as a whole. 5. Experimental results
For evaluating our methods we use three years worth of TREC blog track data that is the set of available data sets for the has 50 new queries. We use only the title of the queries in our experiments.

The Blogs06 collection is a crawl of about one hundred thousand blogs over an 11-weeks period ( Macdonald &amp; Ounis, 2006a ), and includes blog posts (permalinks), feeds and homepages for each blog. Blog08 is a collection of about 1 million blogs crawled over a year with the same structure as Blog06 collection. In our experiments we use only the permalinks com-ponent of the collections, which consist of approximately 3.2 million blog posts in the Blog06 and about 28.4 million blog posts in the Blog08 collection.
 the top 15,000 posts by using the Terrier version of BM25 applying default stemming and stop words removal. Then we use the aggregation methods presented previously, to combine the relevance scores of posts for each blog. Since we have three years for each year using the other two years as training data and tuned the parameters to optimize MAP.
Before generating the transition matrix for the random walk-based smoothing, we discarded terms with very high doc-ument frequency (more than 80% of the documents) or very low document frequency (less than 5 documents) in order to our experiment showed that length of 20 is long enough for all the generated graphs.
 1 shows the properties of implemented OWA operators for different values of n . The a and b values for each quantifier are used in the formula (4) to calculate the weighting vector with the desired properties.
 Tables 2 X 4 show the evaluation results for TREC07, TREC08 and TREC09 respectively. Tables 2a, 3a and 4 a show the Mean Average Precision (MAP) and Precision at 10 (precision of the system in the top 10 retrieved documents) for the baseline, ExpCombSum and ExpCombMNZ, respectively for each year.

MAP values of the three different OWA operators with four different values of n on TREC07, TREC08 and TREC09 are test on scores for each query at the 0.05 level. Statistically significant improvements over ExpCombSum and ExpCombMNZ, as the two baseline methods, are shown by and  X  respectively. It is shown that in most of the cases, OWA operators have has the best MAP across the three different data sets. In the best run for each year, the OWA aggregation operators improve the ExpCombSum in MAP by 35%, 33% and 31% for TREC07, TREC08 and TREC09 respectively.

It is worth to note that by increasing the number of aggregated posts, the operators with higher orness value perform
MAP value. It is mainly because of the low number of retrieved posts for each blog. In our experiments, average number of retrieved posts for each blog to be aggregated is 12.7, 13.73 and 7.66 for TREC07, TREC08 and TREC09 respectively. So when we aggregate higher number of posts with low orness operators, we give more importance to the smaller elements which are zero. Because of that, we miss some information that decreases the performance of the system.
 evaluation metric as MAP. Same as noticed before, aggregating higher number of posts performs better when is done by low-er orness operators and vice-versa. Statistically significant improvements over the baselines are detectable in most of the cases. In the best result for each year, OWA operators improve the ExpCombSum by 24%, 14% and 38% for TREC07, TREC08 and TREC09 respectively.

Importance weighted OWA operators are implemented as described in Section 3.2 by importance calculated in a graph
Q . Tables 2c, 3c and 4 c show MAP values of the OWA operators with cluster-based importance integrated in the weighting vector. It is shown that importance weighting improves previous OWA operators in most of the cases, specially for higher values of n . For the small values of n , since we have limited amount of information, small change in one of them can have a huge effect on the aggregated results and we can see that with n = 5, we do not get any improvement. On the other hand, with the higher values of n , we have more information and if the number of retrieved posts for a blog is less than n , the importance values for extra elements will be zero and they do not affect the result of the aggregation. Tables 2e, 3e and 4 e show the precision at 10 after involving importance in the OWA operators. 6. Conclusion paper we used Ordered Weighted Averaging (OWA) operators with linguistic quantifiers for this task. We see each post as that, by using OWA with fixed number of highly relevant posts in each blog we can get statistically significant improvement over the baselines.

We carried out our experiments on TREC X 07, TREC X 08 and TREC X 09 data sets. In the best runs by OWA operators, we got 35%, 33% and 31% improvements in MAP over ExpCombSum method for three consequent data sets respectively. These improvements over ExpCombSum in precision at 10 were 24%, 14% and 38% in the best results for each year.
We also investigate the extended version of OWA operators to integrate the importance of the elements in the aggrega-documents. It was shown that this extension improves the performance of the retrieval, when the number of aggregated posts from each blog is high.

We have not modelled temporal properties of the posts and link structure of blogosphere here. In the future we intend to use this information to obtain a better relevance score or importance value for each post, before combining them. Acknowledgment
We thank Mark Carman for his helps and constructive discussions. We also want to thank Amirhossein Malekpour for his great review and comments. This work was supported by Swiss National Science Foundation (SNSF) as XMI project (Project No. 200021-117994/1).
 References
