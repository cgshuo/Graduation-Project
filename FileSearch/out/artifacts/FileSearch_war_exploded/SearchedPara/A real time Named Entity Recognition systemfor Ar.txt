 Harith Al-Jumaily  X  Paloma Mart X nez  X  Jos X  L. Mart X nez-Fern X ndez  X  Erik Van der Goot Abstract Arabic is the most widely spoken language in the Arab World. Most people of the Islamic World understand the Classic Arabic language because it is the language of the Qur X  X n. Despite the fact that in the last decade the number of Arabic Internet users (Middle East and North and East of Africa) has increased considerably, systems to analyze Arabic digital resources automatically are not as easily available as they are for English. Therefore, in this work, an attempt is made to build a real time Named Entity Recognition system that can be used in web applications to detect the appearance of specific named entities and events in news written in Arabic. Arabic is a highly inflectional language, thus we will try to minimize the impact of Arabic affixes on the quality of the pattern recognition model applied to identify named entities. These patterns are built up by processing and integrating different gazetteers, from DBPedia ( http://dbpedia.org/About , 2009 ) to GATE (A general architecture for text engineering, 2009 ) and ANERGazet ( http://users.dsic.upv.es/grupos/nle/?file=kop4.php ).
 Keywords Arabic language  X  Text mining  X  Named Entity Recognition  X  Event detection  X  Morphological analysis  X  Root extraction 1 Introduction We currently have many opportunities to obtain a wide variety of information from the Internet. This information is growing at an exponential rate. Most of it is written in natural language because the Web was designed for human reading and understanding, not for machine recognition and interpretation. The huge volumes of information and the widely extended use of Internet have attracted researchers to face up to these new challenges and to improve Internet services. Information Retrieval (IR) is one of the most important services that provides tools to achieve relevant and complicated searches on Internet. Therefore, there is fierce competition between the gigantic search engines such as Google, Yahoo, etc., to provide the best application with more performance and accurate information.

Text mining technology is becoming one of the major issues in IR. It highlights the relevant information in the text that can be used for different applications providing the users with powerful search functionality that goes far beyond text search (Steinberger et al. 2008 ). So, text mining applying techniques can help to confront the challenge of searching through huge volumes of information (Martin and Van der Goot 2009 ). For example, the web applications which are used to detect news about people, organizations and places, as well as those which may give earlier warnings about medical and health-related topics or natural disasters, all require more work and efforts to be made in text mining and pattern recognition (Best et al. 2007 ). The framework in which the research work described in this paper has been developed includes a real time monitoring system for news channels in order to detect the appearance of specific words or expressions, which have been collected as a result of previous works. A large quantity of news must be processed in a short period of time so efficient methods to look for these words in the news are needed. Names of people, places and organizations must also be tagged so a Named Entity Recognition (NER) process is required. Thus, our system has been designed to recognize two types of elements in the Arabic language: named entities and a set of common words (nouns and verbs). As regards NER, in this paper we will consider only a basic categorization scheme for named entities made up of three main classes: Person, Location and Organization. As regards the common words, we apply the recognition task to detect nouns and verbs. Khoja X  X  Stemmer (Khoja and Garside 1999 ) has also been integrated to extract the linguistic roots of the detected nouns and verbs. Our approach tries to minimize the impact of Arabic prefixes and suffixes on the quality of the recognition patterns, which is considered one of the major problems found in Arabic (Afify et al. 2006 ). A part-of-speech process has not been considered because it would take too much time to process each piece of news so on-the-fly monitoring would not be feasible.

The rest of this work is organized as follows: In Sect. 2 , we provide a brief introduction on the Arabic language to make it easier for a non-native Arabic reader to understand the difficulties of the Arabic language. In Sect. 3 , some related works are presented and discussed. Section 4 describes the architecture of the system. Section 5 , shows defined experiments and discusses the results. In Sect. 6 , some conclusions and future works are presented. 2 Why the Arabic language? Despite the number of Arabic Internet users having increased considerably in the last decade (Fig. 1 ) (Internet World Stats, Usage and Population Statistics, http://www.internetworldstats.com/ ), the content of Arabic digital resources on the Internet is still lower than its actual weight as a language. These resources are less than 1% of all Internet content, while people who speak Arabic natively represent 5% of the world X  X  population (El potencial de la Red en a  X  rabe, 2010 ), so a significant increase in Arabic content is expected and tools, like those proposed in this work, are needed to process this content automatically.

The Arabic language is one of the Semitic languages that is used by people living in the Middle East, and North and East of Africa. It is the official language throughout the Arab World, which consists of 25 countries although each one of them has its own regional variants. In addition, many people of the Islamic World (non-Arab countries such as Turkey, Iran, Pakistan, etc.) understand Classic Arabic (CA) because it is the Language of the Qur X  X n. Nevertheless, most writing in the Arabic World such as books, newspapers, magazines, official documents, etc., is in Modern Standard Arabic (MSA), which is one of the official languages of the United Nations.  X  X he major difference between the MSA of today and the CA of yesteryear is that the former is truly a living language subject to the many influences of the Arabic spoken dialects, whereas the latter is a frozen, static entity X  (Kaye 1991 ). For this reason, we have only considered MSA in this work.
 The Arabic alphabet consists of 28 letters; three of them are used as long vowels. Most of these letters have different shapes depending on whether it will be connected at the beginning, middle or end of the word. The Arabic alphabet also contains three short vowels that are normally placed above or below the corresponding letter. On the other hand, the reader should know the difference between the basic concepts of Arabic; root, stem, and vowel patterns. Arabic text is written and read from right to left. Most of the words are built from roots, except the common names and particles. At the same time, these words can be analyzed to obtain the base roots. Around 64% of the Arabic roots are made up of three letters (Khoja et al. 2001 ). A root can also be formed from two or four letters. In limited cases, a root can have more than four letters.

The Arabic language has highly inflectional and derivational difficulties because there are many irregular words (Al-Zoghby et al. 2007 ), and there are many vowel patterns, each defining a grammatical state of the stems. For example, let us consider Table 1 . So far, it seems easy: all that we need to do is apply the vowel patterns to the roots to obtain almost 70% of the Arabic stems. Nevertheless, the problem here is that there are more than 5,000 Arabic roots and more than 1,500 vowel patterns (Alqatta Alsaqly 1999 ). In addition, many of these forms consist of the same set of letters differing only in the way the short vowels are used. For example, in Table 1 , the stem (  X   X   X   X  because the short vowels are typically not written in normal texts such as (books, newspapers, magazines, of fi cial documents, etc.). Sometimes, they are written when word ambiguity cannot be solved from the text. So the reader must be familiar with the language to understand the missing vowels.

Another problem is al -hamzah (  X   X  ) which is an additional letter in the Arabic alphabet, representing the sound of a glottal stop. It can be written in different forms; people do not usually write the al -hamzah in the right place or it can be totally (  X   X   X   X   X   X   X   X sbAnyA ) in Google which are different ways of writing  X  Spain  X  in Arabic using different types of the al -hamzah, we will get approximately the same number of pages (4.7 million). Although the second spelling of the previous example is not a variety but a wrong spelling of Spain in Arabic, Google considers the three letters ( to the al -hamzah , there are other letters that can be written in different shapes in Arabic, such as using tatweel (  X  ) to elongate the Arabic letter, and using the modi fi ed letters such as (  X  p,  X  v,  X   X   X  g, etc.) to write foreign words (Habash 2010 ).
Finally, as we said, one of the major problems of the Arabic language is the prefixes and suffixes because there is a large number of them, approximately more than 80 prefixes and 200 suffixes. A prefix length can range from 1 to 4 letters, while a suffix length can range from 1 to 6. For example, if we use the suffix (  X   X  An ) with books  X  . In addition to the large number of them, the compatibility problem must also be resolved between them and with stems (Buckwalter 2004 ). In this work, the impact of using the Arabic af fi xes in our system will be studied and a veri fi cation algorithm will be implemented to improve its performance. 3 Related work In this section we study and analyze some of the important efforts on Morphological Analysis (MA) and NER for Arabic. We start by presenting the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter 2004 ) which is considered a pioneering work for the Arabic language. It consists of a dictionary of lexicons of Arabic stems, prefixes, and suffixes, with truth tables to indicate a correct combination of these affixes. It provides morphological categories such as Function word, Nouns, and Verbs. It uses Buckwalter transliteration, which can be converted directly to Unicode Arabic with a minimal amount of automatic processing. Many important Arabic researches are based on BAMA such as; MADA + TOKAN (Habash et al. 2009 ) which is a freely available toolkit for Arabic NLP applications. MADA handles the Morphological Analysis and Disambiguation for each word, and TOKAN presents the results in a wide variety of customizable formats. SAMA 3.1 (Maamouri et al. 2009 ) is another Arabic morphological analyzer which is based on BAMA. SAMA is considered the continuity of the previous BAMA releases.

It is worth highlighting other efforts such as, AMIRA (Diab 2009 ) which is an online toolkit for Arabic tokenization, lemmatization, POS-tagging and Base Phrase chunking. It has been widely used for different NLP applications due to its speed and high performance. Serf (The Arab League Educational, Cultural and Scientific Organization (Alecso) 2007 ) is an Arabic Morphology analyzer that uses the trilateral and quadrilateral roots as input, the output is a set of all the grammatical states of these roots. The main limitation of Serf is that the inputs are only roots. NOOJ (Silberztein 2002 ) is a developed NLP environment in many languages. It offers a free plug-into provide morpho-syntactic tools for Arabic processing. Khoja X  X  Stemmer (Khoja and Garside 1999 ) is also a valuable system for the Arabic language. It uses an algorithm to remove the prefixes and suffixes from the input words and then it extracts roots from these words. In an earlier phase, it removes stop words and strange words from the original text. A stop word is a commonly used Arabic word. A strange word is a foreign word written using Arabic script. Although removing the affixes is not sufficient for many NLP applications (Al-Sughaiyer and Al-Kharashi 2004 ), we believe that root extraction can help in the ED task because most of the Arabic words can change their orthographic forms when their grammatical states are changed.

On the other hand, NER is considered to be an important task since it helps to improve the performance of many NLP applications (Benajiba et al. 2008 ). It is a valuable source to capture the semantic content of a written text. However, very little research into NER for Arabic has been published (Benajiba 2009 ) due to the lack of the related resources and the limited progress made in Arabic NLP in general (Shaalan and Raza 2008 ). Many techniques are used to build NER systems for Arabic. For example, Abuleil ( 2004 ) used a set of rules to predict where the Arabic proper names are located in the text. It states that entity names seem to appear close to trigger words (keywords or special verbs). So it assumes that these names are found in a space of 10 words to the left and 10 words to the right of the trigger word. ANERsys which is a NER system built exclusively for Arabic texts based-on n-grams and maximum entropy approach is presented in Benajiba et al. ( 2007 ). They developed their own corpora and gazetteers to train, evaluate and boost the system. They obtained an improvement with respect to a baseline results without using any POS-tag information or text segmentation. In Benajiba et al. ( 2010 ) the authors achieve a significant, high-performance Arabic NER system by using lexical, syntactic and morphological features. In Shaalan and Raza ( 2008 ) a system for Arabic NER is presented which consists of two main processing resources: a dictionary of names (whitelist or gazetteer), and a grammar, in the form of regular rules to recognize the Named entities. A filtration mechanism is used as a blacklist to reject matches returned by rules but which are invalid entities. The system is evaluated using its own corpora which have been tagged in a semi-automated way. GATE ( 2009 ) is a Java suite of tools, which is widely used in NLP tasks, including information extraction in many languages. It has an Arabic module as one of the plug-ins in the CREOLE directories. GATE can be used to extract basic entities, such as date, name, location, organization, etc. The main problem of the tools such as GATE is that they were developed mainly to analyze non-Arabic language, however, plugs-in have been added in them to make sense of the Arabic (Farghaly and Shaalan 2009 ).

From the aforementioned overall trends the NLP for Arabic is directed towards the Morphological Analysis (including root extraction), and NER. We agree with (Benajiba et al. 2009 ) that from the NER system X  X  point of view, the recognition task in Arabic is relatively different from performing the task in English due to the aforementioned problems and because the Arabic script lacks capital letters. Thus we believe that performing text mining on the Arabic language requires more effort and poses special challenges (Halpern 2007 ). Although our system is directly related to NER, we are conscious that the morphological categories (nouns and verbs) are vital to detect events and provide earlier warnings about them. So, we believe that a system is necessary that provides information such as nouns and verbs in addition to the common Named entities. The root extraction is also included in our system to make the identification of these words easier.
Finally, in this work we are interested in studying the impact of the Arabic affixes on the performance of our system. In other words, we will try to reduce the impact of these affixes and to improve the recognition results. If an Arabic token (prefix-stem-suffix) is recognized then a verification process is used to ensure that the three combination prefix-stem, stem-suffix, and prefix-suffix are compatible. A stem may be one of the Named entities or the morphological categories considered in this work. Finally, our system has been designed to detect the Named entities which can be represented by more than one word. It can be easily integrated with the rest of the system, providing output results in XML format and UTF-8 codepage to simplify subsequent exploitation. 4 System architecture In this section, we will explain our proposed system architecture for Arabic text mining and analysis (Fig. 2 ) in more detail. When we started to design our system architecture, we realized that this architecture must meet the following requirements:  X  Use the UTF-8 codepage for the I/O.  X  Use existing systems of NLP with some adaptation to reduce the level of effort  X  Allow the user to append information into the system dictionary  X  PMG; this  X  The system provides automatic mechanisms to manage the prefixes and the  X  The system has been implemented using Java, to facilitate the integration of the  X  The output is in XML format to make the information exchange with other  X  The architecture could be adopted for analyzing other languages that are currently
The architecture built to meet these requirements contains two types of processes: offline and online. In the following, a brief description is shown for each these processes: 4.1 System dictionary  X  PMG creation The main objective of these processes is the creation of  X  PMG. This dictionary is used to save all patterns that were retrieved from various information resources. The objective of creating  X  PMG offline is to accelerate the system performance.
Currently  X  PMG contains about 94,000 patterns, each one of which is associated to of these attributes can have one or more values. A pattern specifies a reference word in the Arabic language while the attributes specify the information and the categories of the corresponding pattern. Almost all of these patterns are associated with the morphological categories while 13% of them are associated with the Named entities. The formal definition of a pattern and its attributes are shown below: We can distinguish three parts in  X  PMG; Prefixes  X  P, Morphological Resources  X 
M, and Gazetteer  X  G. In the following a brief description of each of the dictionaries is shown: (a) Prefixes  X  P: The Arabic prefixes are stored in the Prefix part, where each prefix (b) BAMA Dictionary  X  M: The second part of  X  PMG is the morphological
This example de fi nes a pattern that shows the normalized pattern of the word (  X   X   X   X   X bHr ). The symbol (%) that is associated with the pattern indicates that this pattern allows the aggregation of suf fi xes, for example, the letter (  X  t )in (  X   X   X   X   X  AbHrt ) which means  X  She/It travels  X  . In the following, we explain each one of the pattern  X  s attributes:  X (a 1 ) has one value (  X   X (a 2 ) has two values (a 2,1 = set sail and a 2,2 = travel by sea ) to indicate the  X (a 3 ) has one value (PV) to show the morphological category of the pattern. Our (c) Gazetteer  X  G: The third part of  X  PMG is the gazetteer  X  G that aims to define
Although  X  G forms only 13% of  X  PMG, i.e. it is smaller than the morphological dictionary; the offline processes that were used to generate  X  G have been more complicated and more expensive because various digital resources have been used in different ways. In order to generate about 12,000 non-repeated patterns for  X  G, the estimation of the total time spent in this process was approximately one person for 420 h of work. This time has been averaged between providing a number of programs for automatic processing, using various tools and databases to save and manage the generated data, and finally manual work to adapt these data to the  X  PMG requirements.

In the following the main resources of data used in this work are explained:  X  DBpedia/Wikipedia: DBpedia is a project aimed at extracting structured  X  Other Gazetteers and Resources: From the Internet and other tools for entity  X  Feedback: It is an offline process which is used to maintain the lexicons of the 4.2 Implementation issues for the classification algorithm The main objective of these processes is to apply the classification algorithm according to the proposed architecture. The algorithm starts when one or more UTF-8 Arabic documents is entered. The online processes are run according to the following sequence. (a) Normalization (T): This process is run in the first place to convert the entered (b) UnicodeTokenizar (T X ): This process receives the normalized text (T X ) and (c) Recognizer (t i ): For any token (t i  X  T X ), the Recognizer process looks in the (d) NoMatch (t i ): This process is run when {P} = { X  X  X , i.e., the set of the matched (e) isStopWord(t i ): If the set of the matched patterns {P} is not empty this
To reduce the set of matched patterns we have defined suffList that contains more than 200 suffixes normally used in the Arabic language. If suff j  X  suffList then the corresponding p j is removed from the matched set. Therefore, for the pre-vious example, the matched patterns p 1 ,p 2 , and p 6 are removed from the set because calculated suf fi xes belong to suffList then the corresponding t i is written as NoMatch (t ) in TokensNotTagged fi le. The new matched patterns set will be {P  X  }andm  X  =3. (g) EditDistance (t i , {P X  X ): This process calculates the edit distance d j  X  D (h) P  X  S Veri fi cation: Although in the previous processes (f and g) we carry out two (i) Stemming (p j ): The main aim of this process is to reduce p j to its root. The root
When the word (  X   X   X   X   X  zlzAl )  X  earthquake  X  is used in the plural, the orthographical plural where the singular form of the word is different from the plural form of the same word (Goweder et al. 2004 ). In addition, the different grammatical states such as: Prepositional, Nominative, Irregular, Non-standard, Accusative, etc. can add one or more letters to the original word. The root extraction process can help in the ED task because all the previous words have only one Arabic quadrilateral root for some applications will help to detect all the possible words referencing those events. (j) XMLConveter (t i ,d j ,p j ,a j , r): This process is used to convert the output 4.3 Prefix X  X uffix verification In this section, we will explain our approach to managing the Arabic prefixes and suffixes to solve the compatibility problem of using them with each of our categories, and to minimize the impact of these affixes on the performance of our system. As we said, the Arabic prefixes and suffixes are particles added to the stems to obtain new grammatical states. To calculate the usage frequency of each of the Arabic prefixes and suffixes in a modern text, we have used an Arabic collection of documents with more than 12 million words. With regard to the prefixes, the results showed that almost 57.3% of the words in the collection did not take prefixes, while 12.9, 27.3, 2.4, and 0.03% of them did take prefixes of one, two, three, four letters respectively. With regard to the suffixes, the results showed that almost 70.7% of the words did not take suffixes, while 21.3, 7.3, 0.5, and 0.01% of them contained suffixes of one, two, three, four letters respectively. Table 2 shows some of the Arabic prefixes and suffixes with the highest frequency of use in the collection.
In the following, we will explain our approach to managing the compatibility of the Arabic prefixes and suffixes with each of our categories.  X  Person Category {Per}: It contains more than 9,000 patterns of the Arabic fi rst  X  (t  X  pref  X  Location Category {Loc}: It contains more than 2,000 patterns such as  X  (t  X  pref  X  k }  X  Organization Category {Org}: It contains more that 1,000 patterns such as  X  (t  X  pref  X  Noun Category {Nou}: It contains almost 50,000 nouns that have been defined  X  (t  X  pref At ,  X   X   X  wll ,  X   X   X   X  wbAl ,  X   X   X  wll ,  X   X   X  kAl ,  X   X   X   X  wkAl } Anh ,  X   X   X  wnh ,  X   X   X  thn ,  X   X   X  nhA ,  X   X  tm ,  X   X   X  Akm }  X  Verb Category {Vrb}: It contains almost 32,000 verbs that have been defined  X  (t  X  pref 5 System evaluation The Arabic language has become a popular area of research in IR, but it presents serious challenges due to its richness, complex morphology, and syntactic flexibility (Attia 2008 ). Although in the last decade a lot of work been carried out to make the task of NLP of Arabic easy, the systems to analyze Arabic automatically are not as easily available as they are for other languages such as English (Sawalha and Atwell 2008 ). In addition, available digital resources such as, for example, the corpora for Arabic NER are still limited although efforts are being made to remedy this (Farghaly and Shaalan 2009 ). One of the pioneering efforts is provided by the Linguistic Data Consortium (LDC) ( 2011 ), where more than one Arabic corpus annotated with regard to information extraction is provided in XML format. 2 Nevertheless, we have preferred to use ANERcorp (Natural Language Engineering Lab, http://users.dsic.upv.es/grupos/nle/?file=kop4.php ) in our experiments because the Named entities of this corpus have been annotated on the text with a simple us to modify the corpus manually to include the two morphological categories considered in our work in addition to the Named entities (Person, Location, and Organization) provided in the original corpus. ANERcorp contains almost 150,000 terms which have been prepared from a collection of 316 articles that were manually obtained from various sources on the web.
 In order to evaluate our approach, we applied widely used measurements such as Precision, Recall, Fmeasure, and Accuracy (Yang 1999 ). Precision is the ratio of the retrieved tokens which are relevant in the corpus, i.e., it evaluates the exactness of the system. A token is considered relevant when our tool labels it correctly with respect to the manually labeled corpus. Recall is the ratio of the retrieved relevant tokens. It measures the ability of the system to retrieve a complete set of the relevant tokens from a corpus, i.e., it evaluates the system coverage. Fmeasure evaluates the effectiveness of the system. Accuracy shows the ability of the system to retrieve relevant tokens and discard irrelevant ones. The terms TruePositives (TP counts the tokens correctly assigned to this category), FalsePositives (FP counts the tokens incorrectly tagged to this category), FalseNegatives (FN counts the tokens incorrectly rejected from this category), and TrueNegatives (TN counts the tokens correctly rejected from this category) were gathered to calculate the previous measures, according to the following formulas:
To highlight the importance, and to clarify the effect of the Arabic prefixes and suffixes in the recognition results, we carried out two experiments to calculate the previous measures. The first experiment was carried out without Prefix X  X uffix Verification (Sect. 4.3 ), while in the second one the verification process was used for all categories. Tables 3 and 4 show the results of the two experiments.

From these tables, we can distinguish the role of the Arabic pre fi xes and suf fi xes in each category. In general, the veri fi cation process improved the recognition results for all the categories although this improvement was not symmetrical. The biggest improvement was produced in the Verb category where the result of the precision has been improved from 51.19 to 85.79. This is because in the Arabic language adding some pre fi xes to the verbs produces other grammatical states. For example, the past (  X 
 X  ,  X  y ,  X  t ,  X   X  Al ) respectively. We discuss the reason for this improvement by looking at the FP results of the Verb category in Tables 3 and 4 , where the number of patterns was reduced from 17,150 to 2,762. It means that using the system without veri fi cation process returns many patterns as verbs, although these patterns are not labeled in the corpus. However, when the veri fi cation process was used, the number of these patterns was signi fi cantly reduced, so the precision result was increased.
Now, looking at Table 4 , differences in precision and recall measures can be observed between categories. While Location precision is more than 81%, for the Organization category, precision reaches 65%. In our opinion, there are several reasons to explain these differences. The fi rst one relates to the normalization process that our system carries out to remove the orthographical confusion problem (see Sect. 2 ). We think that this problem is dif fi cult to resolve because it is part of the orthographic habits of the people. The second reason relates to the wide variations in usage and meaning of some of the Arabic words. In order to not overburden the reader, we will detail an example of it. The precision result of the Person category is (77.63%) which means that the system correctly tagged (5,425) tokens as persons, but at the same time, there are (1,563) tokens that are incorrectly tagged. This is because there are several Arabic words that have several meanings and uses, for  X 
Tahseen  X  , etc., are used as people  X  s fi rst name, but these words are used also as nouns meaning  X  peace  X  ,  X  live  X  and  X  improvement  X  respectively. So, all these words have been returned as relevant to the Person category, although they were not labeled in the corpus. The third reason relates to the Latin words, where most of these words are written in Arabic in different ways. For example, the name of the Prime Minister of Spain  X  Zapatero  X  could be written in Arabic in the following ways: words in Google, it returns the following number of documents (70,300, 31,200, 19,900) respectively. Our work does not currently provide the solution to this problem, so most of the tokens that were incorrectly rejected of this category were Latin words. The fourth reason can be observed in the case of the Organization category, where our corpus is about Arabic news, and normally the Arabic  X 
Almustaqbal Newspaper  X  , etc. Whenever such names are found in the corpus, they are correctly tagged as organization category, but often in the text of news only the most signi fi cant parts of these names are written. Therefore, this leads to more confusion because the system will tag these parts as nouns. The system does that because these parts of the names have other meanings such as; Alanbaa  X  the news  X  , Aljazeera  X  the island  X  , Almustaqbal  X  the future  X  , etc.

The Recall/coverage results show the ability of the system to retrieve the complete set of the relevant tokens. In general, looking at Table 4 , the Organization category has the lowest coverage because the system retrieved only (50.91%) of the relevant tokens in the corpus. The rest of the tokens have been lost because they were not defined in the system dictionary. The results for the rest of categories are almost the same.
 6 Conclusion In the last decade, the Arabic Language has become a popular area of research in IR in general and in text mining in particular. Unfortunately, working with Arabic adds more difficulties than the languages that derive from Latin, because it implies the solving of different types of problems such as the short vowels, al -hamzah , prefixes, suffixes, etc. In this work, we have tried to minimize the impact of the Arabic affixes on the performance of the system. A verification process has been designed to do that.

As we had expected, the veri fi cation process has improved the recognition results although this improvement was not symmetrical. The improvements in the results of Precision in all the categories Person, Location, Organization, Noun, and Verb are 7.32, 5.55, 5.14, 3.93, and 34.6, respectively. We do not think that these results are bad but they could be improved on. This depends on improving the following aspects in our system. (1) Improve the system dictionary by including new patterns in each category. (2) Another problem that must be solved in future works is how Latin words are written in Arabic because including all the possible ways of writing these words in the dictionary would be an impossible solution, so we need to improve our algorithms to detect all the possible ways used to write Latin words in Arabic. (3) Incorporate expert feedback to our system by using intelligent learning techniques such as active learning (Freund et al. 1997 ) or learning by demonstration techniques (Lieberman 2001 ) and (4) apply and adapt context analysis techniques already available to solve ambiguity issues for other languages, for example, this solution sentence.
 References
