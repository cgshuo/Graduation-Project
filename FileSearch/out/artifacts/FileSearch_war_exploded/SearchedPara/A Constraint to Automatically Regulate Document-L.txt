 Retrieval functions in information retrieval (IR) are funda-mental to the effectiveness of search systems. However, con-siderable parameter tuning is often needed to increase the effectiveness of the retrieval. Document length normalisa-tion is one such aspect that requires tuning on a per-query and per-collection basis for many retrieval functions.
In this paper, we develop an approach that regularises the level of normalisation to apply on a per-query basis. We formally describe the interaction between query-terms and document length normalisation using a constraint. We then develop a general pre-retrieval approach to adapt a number of state-of-the-art ranking functions so that they adhere to the constraint.

Finally, we empirically demonstrate that the adapted re-trieval functions outperform default versions of the origi-nal retrieval functions, and perform at least comparably to tuned versions of the original functions, on a number of datasets. Essentially this regulates the normalisation pa-rameter in a number of retrieval functions on a per-query basis in a principled manner.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval: Models General Terms: Experimentation, Measurement, Perfor-mance Keywords: Retrieval Functions, Constraints
Document length normalisation is known to be of crucial importance to the effectiveness of retrieval functions. How-ever, the level of normalisation to apply is known to be both query and collection specific [2, 11]. As a result, considerable parameter tuning needs to be conducted before a retrieval function is close to optimal on a given collection and set of queries. Retrieval functions derived from several models of retrieval [13, 15, 1] use the ratio of the document length to the average document length to normalise a document. This paper deals with these types of retrieval functions. The contribution of this paper is three-fold:
In the next section we discuss background and related-work.
Typically, a user submits a query Q to an information re-trieval (IR) system M . The system, which has an index of N documents, scores each document D according to some scor-ing, or retrieval, function S ( Q, D ). The system then returns all documents that contain at least one query-term (the re-turned set RET ) in decreasing order of S ( Q, D ). Each doc-ument and query consists of a set of terms t in the collection C (i.e. t  X  C ). Although all documents are ranked accord-ing to a static query, the query has important characteristics that affect retrieval effectiveness. Recent research [14] has outlined that most modern retrieval functions can still be thought of as a inner-product of term-weights from a query and document vector as follows: where G ( t, Q, D ) is a query-side term-weighting function and F ( t, Q, D ) is a document-side term-weighting function. The axiomatic approach to information retrieval [9, 10] models the document in an inductive manner and describes a re-trieval function by modelling the manner in which the score of a document (via F ( t, Q, D )) changes as on-topic or off-topic terms are added to the document. This approach has provided an interesting and novel way of defining a basic underlying mathematics of retrieval that has been adopted by others [6, 7, 4, 5, 14]. Currently most ranking functions apply a simple weighting function to the terms in the query-vector ( G ( t, Q, D )) and concentrate on deriving high per-forming term-weights for the document vector ( F ( t, Q, D )). The query-side weighting function (i.e. G ( t, Q, D )) may have several interesting constraints that have not yet been correctly captured. Recent research [14] has begun to look at the change in the ranking of documents when terms are added to the query.

Research into the automatic tuning of document length normalisation has previously been conducted [11, 12, 3]. Some approaches [11] measure what they call the  X  X ormali-s ation effect X  and hypothesise that this is similar across all collections. The approach described [11] is computation-ally expensive as all the documents that contain query-terms need to be analysed in order to tune the document length normalisation parameter. Others [3] have incorporated the query-length into the vector space model and conducted ex-periments on Chinese and English corpora suggesting that the query-length should be incorporated in other existing ranking functions. In this work, we focus on adapting three modern ranking functions, namely, pivoted document length normalisation (Piv) [15], a probabilistically-derived ranking function (BM25) [13], and a retrieval function based on the divergence-from-randomness model (PL2) [1]. The retrieval functions used in this paper are generalised by equation 1. Specifically, we use the versions of the retrieval functions that adhere to many of the original constraints and are de-scribed in recent research (Table 1 in [14]).
In the original axiomatic work, the retrieval functions were described by the change in document score as on-topic, or off-topic, terms were added to the document. However, we will see that the relative ranking of documents can also change as terms are added to the query (i.e. a reformulated query). In this section we will introduce a new constraint and motivate it accordingly. Let Q be a query and q be a query-term such that q  X  Q . Assume D 1 and D 2 are two documents such that q  X  { D 1  X  D } . Furthermore, let us assume that S ( Q, D 1 ) = S ( Q, D and | D 2 | &gt; | D 1 | . If we reformulate the query by adding a term t where t /  X  { Q  X  D 1  X  D 2 } , then S ( Q  X  t, D S ( Q  X  t, D 2 ).
 This normalisation constraint ensures that longer documents get penalised more when terms mismatch. This constraint controls the interaction of document length normalisation with the query length and can be considered a query length normalisation constraint QLNC . It ensures that there is greater length normalisation applied to documents for longer queries. The reformulated query contains an extra term that appears in neither D 1 nor D 2 . For the reformulated query, the score of both documents should be lower than with the original query Q . However, the score of D 2 should now be lower than D 1 because it is more off-topic. In most retrieval functions the score of a document does not decrease when a query-term does not match a document.

From a probabilistic perspective, D 2 has a greater prior probability of matching any new query-term (i.e. t ) because it is a longer document. Therefore, it should also be pe-nalised more if t does not occur. This constraint will help to regulate document length normalisation so that it is query-dependent (which previous research would tend to suggest). Longer queries require greater normalisation (i.e. higher b in BM25, higher s in Piv, lower c in PL2). Table 1 out-lines the retrieval functions that adhere to QLNC . We can see that the only modern retrieval function that adheres to the new constraint is the Dirichlet-Priors Language model Table 1: Adherence of Retrieval Functions to QLNC (Dir) 1 . Therefore, we only focus on the three aforementioned retrieval functions for the experiments in this paper.
We will now outline a general method that can be em-ployed to adapt the necessary retrieval functions so that they adhere to QLNC . The only retrieval function that adheres to QLNC is Dir. Therefore, we will include some feature of the query (one that increases with length) into the doc-ument length normalisation components of Piv, BM25, and PL2. The general approach taken is to adapt the normalisa-tion aspect of the retrieval functions so that each document appears shorter (than its true length) when presented with a short query, while making the document appear closer to its true length for a long query.
The document length normalisation used in Piv, BM25, and PL2 consists of the ratio of the document length to the average document length (i.e. | D | avg dl ) . Document length normalisation penalises longer documents as they have a higher prior probability of containing different query-terms. However, for short queries, the probability that a document chosen at random will contain a query-term, is quite low. We hypothesise that for this type of query, the level of nor-malisation to apply, should be low. Conversely, long queries (that also may contain terms that appear in many docu-ments i.e. high df t terms), the level of document length normalisation (penalisation) should be higher, as there is a higher prior probability that a randomly selected document will contain a query-term. The probability that a document D chosen at random from the collection contains at least one query-term is given by: where q is any query-term. We can see that this probability increases as new query-terms are added to the query. The values of 0 . 5 and 1 ensure that the probability strictly in-creases as the query-length increases and can be interpreted as hyper-parameters used for smoothing. We incorporate this probability into the normalisation aspect of Piv, BM25, and PL2 by multiplying it by the document length ( | D | ) as follows: The right hand side of the equation is re-written by substi-tuting avg dl = | C | / N , and shows that the normalisation this constraint is the Dirichlet-Priors language model which incorporates a term penalisation factor ( log ( u/ ( u + | D | )) where u is a tuning parameter) into every query-term. Fur-thermore, it has been shown that Dir is one of the most effective modern retrieval functions [9]. We only mention this retrieval function (Dir) for completeness. component can be interpreted as using both the probability of seeing a specific q in this D (i.e. | D | / | C | ) and the prior probability of seeing any query term q  X  Q in any document D . It is worth remarking that P ( q  X  any D )  X  N i s an accu-rate estimate of the size of the returned set ( | RET | ) of the query (under the assumption of term-independence). Previ-ous research [8] has suggested that the size of the returned set is correlated to the optimal level of document length nor-malisation to apply (although in that research a solution to automatically tuning normalisation was not proposed).
Figures 1 and 2 shows the effectiveness of the adapted re-trieval functions compared to the original retrieval functions in terms of MAP (mean average precision) over safe normali-sation parameter ranges. In Figures 1 and 2, we can see that the black curves (indicating the performance of the adapted retrieval functions) peak at, or close to, the same parameter values for each specific retrieval function and each specific collection. This is not true for the original versions. For example, for the original BM25 function on the WT2G col-lection, the best setting for short keyword queries is b = 0 . 2, while for long verbose queries is b = 0 . 6. However, for the adapted BM25 function, the best setting for both long and short queries is b = 0 . 6. The approach adopted has been successful in regulating the level of normalisation so that the same parameter setting is suitable for different queries on the same collection. Furthermore, for the adapted Piv function, we can see that its X  effectiveness is less sensitive to the normalisation parameter s over its safe range of values (0 to 0 . 4 [10]). For all of the adapted retrieval functions, we can see that the optimal level of normalisation to apply for queries of different length is quite similar on the same collection.
In this section, we compare the adapted versions of the re-trieval functions against the original functions using a more standard evaluation.
The test collections used in this work are subsets of TREC d isks 1-5 and two Web collections. We used many collec-tions with varying document length characteristics (Table 2). This aids in drawing more general conclusions. We cre-ated three query types. We used short keyword queries (ti-tle field only), long keyword queries (description field only), and verbose queries (title, description, and narrative field s). Porter X  X  stemming and stop-word removal was performed on all collections and queries.

As baseline retrieval functions, we used the suggested de-fault settings for Piv ( s = 0 . 2), BM25 ( k 1 = 1 . 2, b = 0 . 75, k 3 = 1000), and PL2 ( c = 2 . 0). We also used tuned ver-sions of the baselines. We tuned s in Piv from 0 to 0 . 4 2 in increments of 0 . 04 for each set of queries on each collec-tion (denoted Piv t ). We tuned b in BM25 from 0 to 1 in increments of 0 . 1 on each collection for each set of queries (denoted BM25 t ). We tuned c in PL2 from 1 to 23 in in-crements of 2 . 0 on each collection for each set of queries (denoted PL2 t ). As the tuning was conducted on each col-lection and query set, we are confident that the effectiveness of the tuned version of the function is at the upper bound of each respective function. Furthermore, considerable ef-fort is spent tuning these values, which is not afforded to the adapted versions of the retrieval functions that adhere to QLNC . The adapted versions of the retrieval functions are denoted Piv qn , BM25 qn , and PL2 qn respectively, and their normalisation parameters are set to the default values of s = 0 . 2, b = 0 . 75, and c = 2 . 0. Table 3: Effectiveness (MAP) for Keyword Queries
Table 3 shows the effectiveness of the retrieval approaches ( Piv, BM25, and PL2) with and without the per-query tun-ing. We can see that in most cases the adapted versions of functions. when s &gt; 0 . 4 [10]. one-tailed t-test compared to the default retrieval function.
We have introduced a new constraint that formalises the interaction between query-length and document-length nor-malisation. We have adapted a number of modern retrieval functions so that they automatically adhere to this con-straint. Furthermore, we have shown that the adapted re-trieval functions perform comparably to tuned versions of the original functions. Although we have introduced a method to automatically tune normalisation on a per-query basis, it may be possible to further improve performance by tuning on a per-collection basis also. This is left for future work. The first author is funded by the Irish Research Council for Science, Engineering and Technology (IRCSET), co-funded by Marie Curie Actions under FP7. The authors would like to thank ChengXiang Zhai and Yuanhua Lv for some infor-mal discussion on query constraints.
