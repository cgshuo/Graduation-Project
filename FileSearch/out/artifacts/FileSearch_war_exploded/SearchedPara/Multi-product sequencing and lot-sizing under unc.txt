 1. Introduction
In this paper, a multi-product lot-sizing and sequencing problem under uncertainties is studied. The source of the problem is derived from an automated semiconductor manufacturing plant where there are non-negligible percentages of rejects and breakdowns. However, this situation can concern any automatic production line working under uncertainties and the proposed approach could be easily extended to different types of produc-tion lines.

The example given here is from our experience of designing a paced line to produce several types of conductor patterns. These parts are used to obtain electronic modules (printed circuits).
Since the considered semi-conductor factory is greatly auto-mated, there is no staff other than maintenance for almost the whole day. The facility functions with three shifts. Specifically, the main task for the day shift is to define the production plan for the next 24 h and start the manufacturing process. The evening and night shifts, which consist of maintenance personnel only, insure the production line continue to function, but cannot change the production plan. As a consequence, the production plan is set for 24 h and will not be adjusted to take into account rejects or breakdowns that may occur in the later shifts.

After processing, parts (conductor patterns) are placed in an automatic storage system, and they are used for the assembly of electronic modules. The automatic storage system is expensive and restricted in volume. Consequently, it should work with one day stock limit, if possible. So, this line and storage system should be able supply the next assembly line just-in-time. In other words, the following policy is applied: all the items used for assembly in period r  X  1 must be in the storage system by the end of planning period r . At the beginning of the period r , the demand for all items types for assembly in the planning period r  X  1is known (taking into account the current stocks in the automatic storage system, if they exist, and the production plans of the assembly line for period r and r  X  1). Thus, for each period r , the following question has to be answered: how many items of each type must be released to production in the beginning of the period r to obtain the necessary quantity for all components in the next production run r  X  1 of the assembly line? With this sort of production, there is a non-negligible percentage of rejects, because some finished components are produced with unaccep-table quality. Quality control is made at the end of the line with no intermediate quality control. In addition, the machines of the line are often stopped briefly because of breakdowns.
This leads to a new and very interesting production control problem dealing with optimal lot-sizing and scheduling under uncertainties. There are two types of possible policies which are in conflict. To diminish the influence of random breakdowns, the safety time (the difference between the duration of the planning horizon and the time necessary to produce all lots) can be increased, but in this case, it is necessary to reduce the sizes of lots, so the production plan can be more easily perturbed by rejects. On the other hand, the size of lots can be increased to diminish the impact of random rejects, but the line will be more sensitive to random breakdowns, because of insufficient safety time. There would be not enough time to repair of all these breakdowns and the line cannot produce the necessary quantity of items. Moreover, a set-up time is necessary between processing of two different products for reconfiguration of manufacturing facility. The set-up time depends on type of already manufactured product and new items to process. Thus, for the both policies mentioned above, there is an additional level of action affecting the safety time.

In this paper, we will reexamine the probabilistic formulation of this lot-sizing and scheduling problem, initially evoked in
Dolgui (2002) . For this problem, a first approach was suggested in Dolgui et al. (2005) : authors have shown that this problem can be reduced to a single machine problem with sequence-depen-dent set-up times and that its optimal solution can be obtained using a decomposition into several optimization sub-problems: enumerating, sequencing and lot-sizing. Note that the latter two problems are NP-hard but the sequencing sub-problem can be transformed in a well-known Traveling Salesman Problem, for which there exist a large number of effective algorithms. For lot-sizing sub-problem, in Dolgui et al. (2005) , the authors presented an idea how dynamic programming (DP) approach could be used to solve it. Nevertheless, only the decomposition framework and a recursive DP expression for lot-sizing were provided. No evaluat-ing tests were performed. Thus, the question on the effectiveness of this approach for small, medium and large size cases is still open. This needed to be explored further which is the motivation of the current paper.

We present a global approach intended to treat actual pro-blems of industrial sizes. This study will employ the earlier proposed overall decomposition approach. DP will be tested on several numerical examples and a memetic algorithm (MA) based on a local search (LS) and a genetic algorithm (GA) will be suggested for large scale cases.

The rest of the paper is organized as follows. Overall assump-tions and problem statement are presented in Section 2 . A review of related literature is given in Section 3 . Section 4 introduces the solution framework: how the uncertainties are modeled and decomposition is accomplished. In Section 5 , a Memetic Algo-rithm (MA) with its elements is presented. In Section 6 , several experimental results comparing the algorithms (DP, LS, MA) are reported. Section 7 contains some concluding remarks and further perspectives. 2. Problem formulation
In this paper, a paced flow line that produces items of several types in lots is considered. This consists of several machines located sequentially according to a manuf acturing process. One lot is a set of items of the same type that pass through the line sequentially without any other types inserted . A machine can produce no more than one item at the same time. There are no buffers between machines. The processing time s are known and transfer times between machines can be integrated in processing times. There is a setup time between adjacent lots and before the first lot (these values are known for each pair of products). It is considered that in the beginning of the day (or planning horizon) production line is idle. To start any manufacturin g process, the line needs a set-up procedure that depends on the type of product. As all products pass through all machines of the line, thus it is necessary to reconfigure each machine when changing the type of product.

The machines are considered as imperfect in sense that they: (1) can produce defective items; (2) are liable to breakdowns.
There is no intermediate quality control, thus defects are only detected after the last machine. These items cannot be reworked, and are rejected. The probabilities of defective items for each item type and each machine are known. When a machine breakdowns, the line is stopped for a certain time for repair, during which no new items can be manufactured.

Machine breakdown rates are known. It is supposed that breakdowns occur only during ongoing manufacturing (when the line is stopped for maintenance or setup, breakdowns are not possible).
 The decision variables are the sequence of lots and their size. The difficulty of this problem comes from the interdependence of the two types of decision variables: the optimal sequence depends on the sizes of lots and, vice versa, the optimal sizes of lots depend on the sequence selected. We need to find both the optimal sequence and sizes of lots maximizing the probability of obtaining the required quantities of items for each type by the end of the current planning period. The benefit of this optimiza-tion is evident. Without any additional resources, we will reduce the production cost and planning nervousness, because the next assembly line will produce with less of stoppages.

This problem has to be solved at the beginning of each production run. Thus, a one period model can be used. It must take into account two kinds of uncertainties: random lead time induced by machine breakdowns and random yield to take into account defective parts. An additional difficulty is a sequence-dependent set-up time between items of different types.
There are n types of items and m machines. The planning period duration (run) is equal to T . For items of type i , i  X  1, the following parameters are given: d i  X  demand level (defined by the assembly line); t iq , q  X  1, y , m  X  processing time required for manufacturing item i on machine q . Let T tr be the transfer time of an item between two successive machines. We consider that transfer of all items on the line is simultaneous between all machines.
So the takt time t i for the production of item of type i is t i  X  T tr  X  max notion to represent the item X  X  i unitary processing time. As this is a paced line, this assumption is not restrictive for the model proposed, and is used only to facilitate its presentation.
The following notations will be used to present sequence-dependent set-up times: s i , j , q  X  set-up time required in order to switch the production from items of type i to items of type j on machine q , i , j  X  1, y , n ; q  X  1, y , m . Set-up time begins only when the pro-duction line is empty, i.e. the last item of precedent lot has left the last machine of the line. As production of the product j begins once the set-up of all machines is finished, we can integrate the notion of the  X  X  X ine set-up time X  X  and use the notation of s i , j to represent it. Line set-up time s i , j obtained as the maximum of the times for machine set-ups, i.e. s 0, i  X  line set-up time required to start processing of items i , if the lot of items i is the first on the line, s 0, i 4 0, i
Hereafter, it is assumed that the set-up times satisfy the triangle inequality s i , j  X  s j , k Z s i , k for i  X  0,
The decision variables are x  X  ( x 1 , x 2 , y , x n ) and p  X  ( p where x i is the size of lot for item i , i  X  1, y , n , and p is the sequence of all lots. Each p i A [1, n ], p i a p j when i The solution of the problem is a specific production plan that determines the quantity of items for all product types to manu-facture and the order of lots on the production line. In Fig. 1 , we present an example.

For this example, the first lot to manufacture is a lot of product three that contains 26 items, i.e. x 3  X  26, p 1  X  3. The second lot is a lot of product five of 1187 items ( x 5  X  1187, p and so on.

The total time for each lot i , i  X  1, y , n includes the following terms. Without losing generality, let this be the first lot on the production line, see Fig. 2 : Set-up time s 0,i to prepare the line to produce items of type i .
Loading time (m 1)t i :attime s 0, i the first item of the lot i enters the first machine M 1 ,at s 0, i  X  t i this item is transferred without any delay to the second machine M 2 and, simultaneously, the second item of the lot is inserted in turn into the machine M etc. So, the first item of the lot will be finished in s 0, i time is the period between the start of a lot and the moment when the first item enters the last machine. Assume that setups are impossible during this loading time. Note that after these production line can be considered as a single machine.
Cycle time t i x i for processing x i components of lot i in  X  X  X teady state X  X .
 When the production line is empty, the next line set-up can start.
This set-up is necessary to produce the second lot (product j ). Once again, the line set up time s i , j is equal to the maximum among the set-up times of the machines. After the set-up, a lot of items j is released and we have a line loading that takes ( m 1) t j time, followed by cycle time t j x j forthislot,andsoon.
Fig. 3 demonstrates an example where rejects and breakdowns are taken into account.

As is the case often in semiconductor industry, we consider that defective items cannot be repaired and so they are disposed of. Let x act i be actual quantity of acceptable items (i.e. items of required quality) produced by the end of planning horizon from x items initially released, where x act i r x i , i  X  1, y , n . Let T planned safety time (i.e. the time reserved for all repairs of any breakdown machines). Thus, the goal is to find a sequence p and lot sizes x to maximize service level. In other words, maximize the probability of obtaining the required quantities of items amongst all types at the end of period: Max P  X  x act i Z d i , i  X  1 , ... , n  X  p , x  X  X   X  1  X 
Hence, the maximum possible planned safety time for a given solution ( p , x ) can be calculated as follows:
T p , x total loading time.

When increasing the lot size of any type of item, the prob-ability of satisfying the demand level for said item will also increase. Conversely, the planned safety time will decrease. If the planned safety time appears insufficient for the completion of all repairs, then the last lot cannot be completed or even not produced at all (see Fig. 3 ). Non-optimized set-up (lot sequence) can considerably reduce the time that can be allowed for planned
Data : n = 5, T = 24 hours.
 Solution Demand d i Processing time t i
Lots 1 2 3 4 5 Sequence Sizes of lots x
Lots 1 2 3 4 5 
Set-up time s s s s
Set-up + Loading time Time 0 Stock of finished items safety time, and so can lead to the same consequences as insufficient planned safety time.

Note that, for the problem considered, if the actual quantity for a component is greater than required, the surplus items will be used in the next period. Thus, this quantity will be deducted from the demand for the next period. The corresponding inventory cost is not considered, because it can be neglected when compared with the cost of shortages. 3. Survey of literature
This is a recently stated problem, examined only in two previous publications ( Dolgui, 2002 ) and ( Dolgui et al., 2005 ).
Nevertheless, there is an extensive literature on related problems of operations management (see for example, Dolgui and Proth, 2010 ). Thus, the objective of this section is to try to position this new problem on corresponding research domains and show problems containing certain similar elements. This can be useful to better understand the problem considered.

Our problem intersects two classes of optimization problems: (1) deterministic scheduling with batching and lot-sizing; and (2) lot-sizing for imperfect production systems.

Most often in literature, problems of lot-sizing and scheduling are considered in a deterministic environment. Emmons and Mathur (1995) studied the lot-sizing problem in a no-wait flow shop in which the jobs to process can be divided into groups according to their types. The goal was to find the optimal batch sizes and sequence of said batches to minimize the total completion time (makespan).
A local search algorithm with dual re-optimization for the same sort of problem can be found in Meyr (2000) . Cheng and Wang (2010) described a dynamic programming approach to resolve two problems for a single machine and a heuristic algorithm for parallel machines.
Comprehensive surveys for integrated scheduling and lot-sizing can be found in Potts and Van Wassenhove (1992) , Zhu and Wilhelm (2006) and Allahverdi et al. (2008) . Usually, the above problems are treated as mixed integer programs.

Lot-sizing problems with random production or procurement yields were investigated by many authors. Yano and Lee (1995) presented a survey of this literature. Another review for MRP environments was given in Dolgui and Prodhon (2007) . Arda and
Hennet (2006) consider an inventory control problem where the arrivals of customers X  orders are random and delivery times from suppliers are also random. Gerchak et al. (1994) introduced and analyzed the models for assembly systems with random component manufacturing and assembly yields. See also Inderfurth (2009) , Jaber and Khan (2010) , to name a few. In general, the problems of this type can be classified into three categories by their uncertainty modeling methods:
Bernoulli process : the probability p that a item is of a good quality is given (see Singh et al., 1988 ; Teunter and Flapper, 2003 ).

Stochastically proportional yield : the fraction of good quality components in a batch is known and does not depend on the size of batch (see Agnihothri et al., 2000 ; Wang and Gerchak, 2000 ; Li et al., 2008 ; Haji et al., 2008 ).

Interrupted geometric : the probability p that the process will become  X  X  X ut-of-control X  X  at a certain moment of time (and all components produced after this moment will be defective) is known (see Guu and Liou, 1999 ; Guu and Zhang, 2003 ; Maddah et al., 2010 ).

There are many methods for modeling breakdowns. For example, Lin and Gong (2006) studied the effects of machine breakdowns on an Economic Production Quantity (EPQ) model. There, repair times are constant for all breakdowns, but the time between failures is a random variable with an exponential distribution. For more examples, see Giri and Dohi (2004) , Giri and Yun (2005) , Chakraborty et al. (2009) , and Chiu (2010) . Sometimes models proposed in literature contain both types of uncertainties: breakdowns and rejects, as in the paper of Radhoui et al. (2009) on maintenance planning, where a machine can produce defective units as well as can breakdown.

A problem of lot-sizing and sequencing on a single imperfect machine with breakdowns and rejects was studied in Dolgui et al. (2011) . The objective was to minimize the total cost of client dissatisfaction. In that article, th e authors replaced random variables with deterministic functions and presented a fully polynomial time approximation scheme (FPTAS) to minimize makespan or total cost of demand dissatisfaction for this deterministic model.
The problem studied in this paper, was uncovered in our earlier research. The two following papers have been published. These two publications form the framework of our current study.
In Dolgui (2002) , the author considers models of renewal process and proves several mathematical properties of these models. He demonstrates how the probability of a given total cumulative time can be calculated for such a model. Then, an extension called a renewal process with random yield is proposed. Finally, the utility of these models is illustrated with an example where lot-sizing and scheduling decisions for a line should be evaluated taking into account machines breakdowns and part rejects. In fact, this was first time where the considered problem was evoked. Nevertheless, in Dolgui (2002) this was not an optimization but an evaluation problem. The message of the last section of that previous paper is that mathematical model of renewal process completed with a Bernoulli process model can be used to calculate service level for a given sequence and sizes of lots for the production lines where there are breakdowns and part rejects. This model based on renewal and Bernoulli processes are used in this current paper for the service level (fitness) calculation.

Dolgui et al. (2005) describe for the first time the optimization problem that we consider currently. The authors presented an iterative decomposition schema to solve to optimality this pro-blem by considering separately sequencing and lot-sizing sub-problems. This was possible using a complete enumeration to decide which lot will be the last one in the sequence and solving subsequent lot-sizing and sequencing problems for the remaining lots. So, the authors concluded that, taking into account the fact that, in this decomposition, the sequencing sub-problem can be easily reduced to well-known asymmetric traveling salesman problem, to solve the initial problem it is only necessary to develop a method for the lot-sizing sub-problem. The authors suggested a dynamic programming (DP) algorithm. Note that only one numerical example with four lots to illustrate calculation steps was provided. There are no experimental results showing the performance of this exact approach. This explains some of the motivation of our present work.

In this paper, we will provide the results of our experimental study of the DP algorithm and show that it should be used only for small size cases up to 13 lots maximum. Then, to tackle larger industrial problems, we will develop a memetic algorithm which can finally give good quality approximate solutions for large scale cases. 4. Resolution framework 4.1. Calculation of the overall service level for a feasible solution
For the problem considered, the criterion is the overall service level, i.e. the probability of obtaining the required quantities of items for each type at the end of period. This criterion takes into account both rejects and breakdowns, i.e. random number of good quality items and random total working time of the line. Note that the line considered is a paced line where if a machine breakdowns then the entire production line is halted. Also, the setups are made for all machines simultaneously. Thus, this multi-machine line can be mathematically treated for the final probability calculation as a single machine under the condition the loading time, line breakdown and repair rates and set-up times can be calculated. The loading and setup times have been considered in
Section 2 . How to calculate breakdown and repair rates of this  X  X  X ingle X  X -machine line by using the characteristics of individual machines will be shown hereafter.

In this paper, we postulate that t he number of failures and repairs for a given period follow Poisson processes. This means that number of events (failures or repairs) for a time interval depends on the length of this interval and the ra te parameter of the corresponding
Poisson process. The length of periods between two successive events follows an exponential probability density. We suppose that Mean time to Failure (MTTF) 1/ u q and Mean time to Repair (MTTR) 1/ r each machine are known, q , q  X  1, y , m . MTTF 1/ U and is MTTR 1/ R of the whole line can be calculated as follows: U  X 
Cumulative working time (the sum of all periods of work between breakdowns) is a random variable. The model of renewal processes proposed in Dolgui (2002) can be used to calculate the probability that the cumulative working time for a given horizon
T is greater than or equal to the time necessary to process all considered items T p which is known for a given solution ( p , x ) and is equal to P n
Note that in our model neither cumulative working time nor time to process all considered items contain set-up and loading time, because we assume that breakdowns are possible only during working time (breakdowns are not possible during set-up time and those that occur during loading time are taken into account in Eq. (3) where failure and repair rates of the line are calculated). Set-up and loading times are deduced from available time and then only working and repair times are considered.
Remember, the objective of the problem is to maximize the probability (1), that is equivalent to the following expression (see Dolgui et al., 2005 ): Max and P  X  x act i Z d i x i  X  is the probability to obtain at least d good quality when x i items of lot i were produced, which can be calculated as follows (using Bernoulli X  X  formula):
P  X  x Z d i 9 x i  X  X  where p i  X  Q m q  X  1 p iq , and p iq is the probability of obtaining an item of good quality of type i , i  X  1, y , n at machine q , q  X  1,
Note that the expression (4) contains the probabilities to obtain at least d i items of adequate quality for each lot i , i  X  1,2, y , n . For the first n 1 lots, this probability depends only on rejects, while for lot n it depends on both rejects for lot n and all breakdowns for the planning horizon (cumulative repair time). Remark that the formula to calculate Pr( s ) contains an infinite sum.
Nevertheless, we can find upper and lower bounds to obtain its approximate value as follows ( Dolgui, 2002 ): Pr  X  s  X  X  1 exp f UT x n  X  s p RT x n  X  s s g
The value L of the number of elements for the sum is chosen using: Pr  X  s  X  Pr  X  s  X  r 2 e , where e is a positive value of admitted error as close to zero as possible. Finally, value Pr( s ) can be found as follows:  X  Pr  X  s  X  X  Pr  X  s  X  X  = 2.

Equations of this section will be used in the following sections to calculate the solution X  X  fitness value for proposed approaches. 4.2. Optimization via decomposition
In Dolgui et al. (2005) , a decomposition schema to obtain an exact solution was presented. As aforementioned, this was based on the complete enumeration for last lot, and solving separately subsequent sequencing problems and lot-sizing for the remaining lots. The sequencing sub-problem can be easily reduced to the well-known asymmetric traveling salesman problem. The lot-sizing problem is an extension of the knapsack problem which needs specific solutions. Here, we present just a brief description of this decomposition idea.
 There are n lots to process, so the decision space is P X ,where
P is the set of all possible permutations p  X  ( p 1 , p 2 (sequences of lots) on the set {1, y , n }and X  X  X 1 X 2 is the set of possible values for the size of lot i . Let the initial problem (1) be called P and ( p n , x n ) A P X be the optimal solution of this problem.

By transforming Eqs. (1) X (4), the following three-level decom-position is possible which guarantees the optimality of the solutions. The first level of decomposition splits the problem P into n equivalent sub-problems P 1 as follows:
P 1: maximizing the probability to satisfy the overall demand under the condition that the last lot p n is fixed. Assign in order  X  1,2, y , n , and for each value i of p n , solve the following problem:
Max P  X  x act i Z d i , i  X  1 , ... , n 9  X  p , x  X  X   X  7  X  ( p , x ) A P X and P ( i )  X  { p A P 9 p n  X  i }
Resolving the sub-problem P 1( i ) gives an optimal solution of the initial problem for the case p n  X  i . When all sub-problems i  X  1,2, y , n are resolved, the best solution is the optimal solution of the problem P .

In turn, each problem P 1( i ) can be decomposed in two sub-problems: P 2( i ) and P 3( i ).

P2 : once the last lot p n is set, the sequence of other lots has an influence on the time remaining for the line repairs. Increasing the total set-up time decreases planned safety time T s . So, the optimizing the sequence of lots is equivalent to the following problem: Min S  X  p  X  X  s 0 , p 1  X  This problem is equivalent to the well-known Asymmetric Traveling Salesman Problem and can be solved using the appropriate methods, see for example Choi et al. (2003) , Xing et al. (2008) , and O  X  ncan et al. (2009) . Hereafter, it is assumed that the optimal sequence p n ( i ) was found and lots are renumbered correspondingly.

P 3: This problem consists in determining the optimal sizes of all lots to maximize the service level (4) subject to a given sequence of lots.

Dolgui et al. (2005) suggested a Dynamic Program (DP) to find the optimal solution of the problem P 3. The three-level decom-position and DP define a resolution method that can theoretically solve this complex problem to optimality. However, there is no performance evaluation of the method done as of yet. 5. Lot-sizing subproblem The sub-problem P 1 is a simple enumeration, and sub-problem P 2 can be solved efficiently using known methods from literature.
Therefore, hereafter, we deal with only the sub-problem P 3. It is supposed that the sequence of lots p n was set, all lots were renumbered accordingly and total set-up time S ( p n ) was calculated.
While DP from Dolgui et al. (2005) provides an optimal solution, it might be inefficient for large scale instances because of the rapidly growing computing time and computer memory required. As mentioned earlier in this paper, a Memetic Algorithm (MA), i.e. a
Genetic Algorithm (GA) with a Local Search (LS), will be proposed instead of DP to solve this lot-sizing sub-problem P 3 for large scale instances. First of all, in Section 5.1 , why this type of approach was chosen to resolve our problem will be explained. In the same section, a general schema of the algorithm will be outlined. Then, solution coding method and fitness function are presented in
Section 5.2 . The second part of Section 5.2 deals with the calculation of upper and lower bounds for sizes of lots. In Section 5.3 ,the process of initial population generation and distance metric are described. Section 5.4 explains the genetic operations used in the MA (crossover, mutation, and replacement selection). Finally, in
Section 5.5 , the local search procedure is presented. 5.1. Choice of a memetic algorithm and its structure
The objective is to find the lot sizes which maximize the probability (4) to produce required quantity of adequate quality items of all types. First of all, a genetic algorithm for this problem will be developed.
 Genetic algorithms were first proposed by Holland (1975) and
Goldberg (1989) . For general description of GAs see also Cox (2005) and Said (2005) . Genetic algorithms are widely used to resolve different design and planning problems. Examples can be found in Chen et al. (2002) , Pierreval et al. (2003) , and Hnaien et al. (2009) . There are some papers presenting GAs for different lot-sizing models, for example, Lee et al. (1997) propose a genetic algorithm for solving both scheduling and lot-sizing problems to minimize the makespan. In Hernandez and Suer (1999) ,an algorithm was presented for an incapacitated, single-item, sin-gle-level lot-sizing problem. Dellaert et al. (2000) suggested a binary encoding GA to resolve a multi-level lot-sizing problem.
Gaafar (2006) applied a GA to a deterministic time-varying lot-sizing problem with batch ordering. Some other interesting applications of GA are presented in Yao and Huang (2005) ,
Supithak et al. (2010) , and Rezaei and Davoodi (2011) . As one can see, there are a number of examples in literature, where GA X  X  were successfully used for different lot-sizing problems. Their authors report that good results were obtained. In our opinion, they are so popular because of reasonable CPU time, high quality solutions, and simplicity in lot-sizing solution coding.
Thus, we will use this type of algorithm with a standard overall scheme (see Fig. 4 ): (i) create a set of solutions presenting an initial population, and (ii) apply the operations of crossover and mutation.

In addition, to speed-up convergence, a LS procedure will be applied at the end of each iteration. It is important to point out that hybrid genetic algorithms like we are using (with integrated local search procedure) are also called Memetic Algorithms ( Moscato, 1989 ). 5.2. Coding of solutions and fitness
Decision variables are the sizes of lots. Each solution can be presented as an array of integer numbers, where each element represents the size of an appropriate lot. The size of the last lot is calculated separately, so if we have n types of products, then the length of each solution is equal to n 1. Represent a chromosome as a vector (for example, vector g ) that contains n 1 elements: items of product i that we will manufacture.

Fig. 5 presents an example for a problem with n  X  7. Here, the size of the first lot is equal to 12, for the second, it is equal to seven, and for the third, it is equal to three, etc.

Each chromosome g is characterized with its fitness f ( g ), which is calculated using Eqs. (4) X (6) from Section 4.1 .

To calculate the Upper and Lower Bounds on quantities, let us suppose we know a solution with overall service level b . SP chromosomes
Then, solutions with a service level for any item type smaller than b should be excluded, because they cannot provide better overall service level than the known solution ( Dolgui et al., 2005 ). The same reasoning applies when there is an a priori required minimal service level greater than or equal to this minimal service level. Note : minimal service level is fixed in adv ance and applied to all products.
Thus, using Eq. (5), a minimum quantity x min i of items of each lot i  X  1,2, y , n which have to be processed, can be calculated as follows: x  X  min f zP  X  x act i Z d i z  X  Z b , z  X  d i , d i  X  1 , ... g  X  9  X 
In other words, x min i is the minimal size of lot i , i  X  1,2, which the probability to satisfy the demand d i is no less than b .
Similarly, the maximum size x max i for each lot can be calculated as follows: x  X  min f zP  X  x act i Z d i z  X  Z 1 e , z  X  d i , d i  X  1 , ... g  X  10  X  where e is a relative small positive value close to zero, x max the minimal size of the lot i such that the probability of obtaining at least d i good quality items from x max i processed is sufficiently close to 1. Value of e is fixed and the same for all products. It influences the upper bound of lot size values: decreasing of e implies increasing of x max i , i  X  1,2, y , n and vice versa.
In certain cases, this upper bound value x max i can be amelio-rated using the value x upp i : x  X  min f x max i , x min i  X  T s  X  p n , x min i  X  = t i g X  11  X 
This additional condition is very useful because value x max very significant. Term x min i  X  X  T s  X  p n , x min  X  = t quantity of items of type i that can actually be produced under the (ii) there is not any machine breakdown.

For each chromosome representing a sequence of n 1 first lots with their sizes, the probability to satisfy the demands is calculated under assumption that x n  X  x upp n .

To decrease calculation time, after the first generation of the MA, determine the matrix M / X , p S , each line i , i  X  1,2, intended to store the probabilities P  X  x act i Z d i x i matrix of all possible lot sizes, i.e. X  X  i  X  b  X  x min b
A  X  1 , x upp i x min i  X  1 . Remark that the quantity of elements in each line can differ. This matrix avoids computing the probabilities
P  X  x act
Z d i x i  X  with Eq. (5) for the evaluation of each solution during subsequent iterations (see Section 5.4.6). Indeed, P  X  x act equal to MX , p 5.3. Creation of initial population
Let SP be the size of the population. To have several solutions of a good quality, we apply three heuristic algorithms.
The main idea of the first algorithm G1 is to take a solution y where all sizes of lots y 0 i for i  X  1,2, y , n 1, are set to their corresponding minimal values x min i . Then, by increasing the lot size with a minimal value of probability P  X  x act i Z d i 9 y 0 the total probability of demand satisfaction for the current solution.
If this is the case, continue to in crease corresponding values (one value at each iteration), otherwise the algorithm stops.
Algorithm G1. 1.

Set j  X  0. Create a solution y 0  X  X  y 0 1 , y 0 2 , ... , y 0 i  X  1, y , n 1. Calculate the cumulative processing time for the solution y 0 : T p  X  y 0  X  X  P n 1 2. Let I 0 min :  X  arg min n 9 y 0  X  . 3. Create solution 4.

While T p  X  y j  X  o T S  X  p n  X  X  m 1  X  P n i  X  1 , ... , n 9 y j  X  4 p j 1
I. p j :  X  P  X  x act i Z d i , i  X  1 , ... , n 9 y j  X  ; II.

I min :  X  arg min i III.
 IV. j :  X  j  X  1.
 End while.

Algorithm G2 consists in the following: create a solution g where all genes g 0 i are set to corresponding maximal values of lot sizes x upp i . Then, by decreasing the size of lot with a maximal value demand for the current solution increases. If this is the case, continue to decrease corresponding values (one for each itera-tion), otherwise the algorithm stops.

Algorithm G2. 1. Create a solution g 0  X  X  g 0 1 , g 0 2 , ... , g 0 n 1 1,2, y , n 1; set j  X  0. Calculate the cumulative processing time for this solution: T p  X  g 0  X  X  P n 1 2.

Let I 0 max :  X  arg max i  X  1 , 2 , ... , n 9 g 0  X  . 3. While T p  X  g 0  X  X  t n d n o T S  X  p n  X  X  m 1  X  P n I. g 0 II.

I max :  X  arg max i 4. Create solution 5. While  X  P  X  x act i Z d i , i  X  1 , ... , n 9 g j  X  4 p
I. p j :  X  P  X  x act i Z d i , i  X  1 , ... , n 9 g j  X  ; II.

I max :  X  arg max i III.
 IV. j :  X  j  X  1.
 End while.

Algorithm G3. Finds the  X  X  X verage X  X  solution g av  X  X  g av  X  where g av i  X  X  x min i  X  x upp i  X  = 2 .

The other SP-3 chromosomes of the initial population are generated randomly. Each gene g i of a solution is generated in following condition must hold:
Eq. (12) verifies that the time needed to process g i items for n 1 first product and d n items of the last product is less than the actual manufacturing time available, which can be found by subtracting the total set-up time S ( p * ) and total loading time  X  m 1  X  wise, several items of the last product will not be produced; service level is equal to zero also. If such a solution is generated, it is rejected and one other solution is created.

When a new solution g is obtained, it is compared with all solutions generated earlier to avoid: (1) clones; (2) solutions which are too close to each other (see Section 5.4.5 ). To decide if any two solutions are close to each other and by how much, we introduce the distance metric. Let y 1 and y 2 be two solutions. Then, the distance d ( y 1 , y 2 ) between these solutions is equal to: d  X  y 1 , y 2  X  X 
In other words, the distance between two solutions is deter-mined using the L 1 norm. In our experiments the minimum authorized distance between two chromosomes is equal to three except for the mutation operator when this distance is two.
The process of solution X  X  generation is repeated until the necessary quantity of solutions is obtained. 5.4. Genetic operators: crossover, mutation, and replacement selection 5.4.1. Selection and crossover
A crossover operator is used to generate new solutions with features similar to the best solutions in the population. To determine the pairs of parents for the crossover, a tournament selection is used. For that, choose randomly two chromosomes from the current population, the one with the greater fitness value will become the first parent and the second is then rejected. Again, the second parent-solution is chosen in the same manner.
This procedure should be repeated as many times as necessary. TP is a parameter of the algorithm which is the percentage of population solutions to be selected for the crossover.
There is also another parameter: a crossover probability CP (equal for each pair of potential parents). This means that it is not sure that each couple of chromosomes chosen in the previous step will produce two new offspring. To accomplish this, for each couple, we generate a number in the range [0,1], if this number is less or equals to CP, the crossover operation will be applied for a selected pair of chromosomes. A hybrid crossover operation is employed, where for each offspring X  X  gene there are two possibi-lities: (1) takes a value of corresponding gene of one of its parents; (2) its value is generated randomly in the range delim-ited by corresponding parent X  X  genes. The second issue is possible with probability equal to CP. The procedure of crossover for a given pair of parents g p 1 and g p 2 is as follows: 5.4.2. Crossover operation 1. For each gene i , i  X  1,2, y , n 1 generate randomly a number in 2. If this number is less than CP then. 4. Add offspring g o 1 i and g o 2 i to the population.
Repeat the same procedure for all selected pairs of parents. 5.4.3. Mutation
A mutation operator is used to increase the population X  X  diversity. The mutation operation is applied to all offspring from the last generation. The mutation probability is equal to MP for mutate. To determine which genes of a given offspring will mutate, we use the same mutation probability MP, i.e. each gene i , i  X  1,2, y , n 1 of the chromosome g has a probability MP to mutate. The mutation operator used acts as a noising method which randomly shifts the value of some genes of a chromosome. The mutation of an offspring g to g mut is as follows. 5.4.4. Mutation operation 1. For each i , i  X  1,2, y , n 1, generate a value mv i in the range [0,1]. 2. If ( mv i o MP) Do:
I. Construct the set of values for the gene i as follows: II. Choose randomly one element m i from this ensemble and set g mut i :  X  g i  X  m i . 3. Else g mut i :  X  g i .

At this step, we evaluate all the offspring created and sort the newly obtained population. Note that for this mutation operator, the minimal distance between initial and obtained chromosomes is equal to two. 5.4.5. Replacement selection
This chooses the solutions from the population to keep for the next generation. Our selection is based on three steps: Update of the bounds (on quantiti es) and solutions accordingly. Deletion of redundant solutions.

Actual selection among remaining solutions or completion of the population when needed. 5.4.6. Updating process
If the fitness value f best of the best solution for current generation is greater than the current service level probability b , then set b  X  f best and recalculate the values x min i formula (9) for each i , i  X  1,2, y , n 1. Considering new values of i , verify that each gene g i of all the solutions in the population is in the range  X  x min i , x upp i . If this is not the case, i.e. g i , then set g i  X  x min i . This process is recursive if these changes generate a new best solution in the population. Update the fitness matrix M / X , p S by deleting useless probabilities. 5.4.7. Deleting clones
This includes the elimination of both repetitive and too close solutions. To delete these nearby solutions, calculate the distance d ( g population, using the formula (13). If the distance d ( g is strictly less than 3, the solution with the lower fitness value is eliminated.

If the residual number of solutions in the population is less than SP, which is a given parameter of the algorithm, regenerate randomly a required quantity of additional solutions, respecting the minimum authorized distance between solutions (this insures a diversified population). Otherwise, use an elitism strategy to choose the SP best solutions for the next generation. 5.5. Local search algorithm
Local search is often used to tackle hard computational problems. The procedure starts from any feasible solution  X  created randomly or found with help of a heuristic. Then, considering neighborhoods, depending the problem studied, a set of neighbor solutions is defined. If there exist in this set a better solution, the current solution is replaced. The local search stops if either: (i) the limit of the calculation time is reached; or (ii) the current best solution cannot be improved, because a local optimum was found. In the case of genetic algorithms, local search is usually applied on the best solution at the end of each generation in order to ameliorate it.

In our Memetic algorithm we use the procedure Local Search (LS) explained below. Let y be a solution that we are trying to ameliorate. Then, to execute one iteration of the local search, the following steps should be performed. 5.5.1. Local search 1. Create set N ( y ) of solution-neighbors for a chosen solution i r y 0 i r x upp i ; i  X  1 , 2 , ... , n 1 g . 2. Evaluate (see Section 5.2  X  X  X oding of solutions and fitness X  X ) all solutions belonging to the set N ( y ). 3. If there is one (or several) solution(s) y 0 A N ( y ) such that the maximal fitness. 4. End of algorithm.

Note that the use of the condition d ( y , y 0 )  X  1 implies there exists a single index i , i  X  1,2, y , n 1 such that or y 0  X  y i 1.

If the current best solution has not changed since the last generation and cannot be improved with the local search proce-dure (local maximum was reached), then LS operation will be applied to the solution with the best fitness among the remaining solutions which could be ameliorated.

The Memetic Algorithm (MA) stops after a certain number of generations or when a given time limit is reached. 6. Computer experiments
This section is divided into five parts. Section 6.1 presents how the problem instances were generated and the main parameters of the MA proposed. Section 6.2 announces the methods that will be tested and compared. Section 6.3 demonstrates the limitations of DP method. Section 6.4 provides an analysis of quality for MA solutions for the instances of small size. Finally, in Section 6.5 , the
MA is compared with the LS for large scale problems. 6.1. Problem instance generation All the tests were run on a SUN UltraSPARC IIIi with 1593 MHz CPU and 16 Gb of RAM.

The planning horizon T is equal to 24 h. Considering numerical characteristics of industrial instances, for each problem, the following values were randomly generated: Demands d i , i  X  1,2, y , n in the range [10, 50] or [20, 30].
Mean time to failure 1/ u l in the range [50, 500] or [200, 300] h for each machine l  X  1,2, y , m .

Mean time to repair 1/ r l in the range [0.3, 1] or [0.5, 0.6] h for each machine l  X  1,2, y , m .

Total line processing time (including all loading time) in the range [0.5 T , 0.6 T ] or [0.7 T , 0.8 T ].

All possible combinations of intervals for these four para-meters were considered to create 16 families of instances. Ten instances for each family were generated, giving 160 instances in total for each studied size n of the problem.

Total set-up time was set at 2 h. Minimal service level prob-ability is the same for each type of products and is equal to b  X  0.7.
The probabilities p i that a given item of product i , i  X  1,2, is an item of adequate quality are generated in the range [0.8, 0.95].

Total line processing time belongs to the interval [ a 1 T , a the pair [ a 1 , a 2 ] corresponds to {0.5, 0.6} or to {0.7, 0.8}. To 1. Generate value a in range [ a 1 , a 2 ]. 2. Calculate an approximate total processing time T proc  X  current instance. 3. Calculate the following value:
N
This represents the total number of items of all types which should have been produced by the end of the planning horizon plus an additional number of items to represent the loading time.
Divide T proc by the number of items N pc to have an approximate value for the processing time of one item for any product type t
Generate values t i , i  X  1,2, y , n in the range [0.5 t item representing the unitary processing time of the corresponding product type. 6.1.1. MA parameters For each generated instance, five independent runs of the
Memetic Algorithm were carried out. The time for each run was limited to 0.2 n s, where n is the size of a problem. For example, for and so on. The MA parameters were chosen empirically according to the results obtained with preliminary numerous tests. They are as follows: 1. Size of the population depends on the problem size: SP  X  4 2. Percent of solutions selected for crossover TP  X  50%. 3. Crossover probability CP  X  0.8. 4. Mutation probability MP  X  0.1. 6.2. Methods used for comparison In order to evaluate our MA, we compared it with the
Dynamic Program (DP) described in Dolgui et al. (2005) and with a Steepest Descent (SD) algorithm based on the neighborhood defined in Section 5.5 : SD algorithm begins with an initial solution, obtained using the greedy algorithm G1 ; then, we apply the LS procedure.

The difference with the procedure described in Section 5.5 is in the fact that the process is continued as long as the solution can be improved. Thus, the SD algorithm stops when a local max-imum is reached. 6.3. Limits of DP procedure In Table 1 , the experimental results for the DP are presented.
More precisely, the number of instances solved to optimality by the DP for n A [4,13] and CPU time values are reported. Calculation time of DP was limited to 1 h. One can easily see that the DP successfully solved only small size problems. For the instances with n  X  7 lots, 15 examples were not solved within the time limit.
For n  X  8 lots and more, DP usually failed to find a solution because of a lack of computer memory. In the fifth, sixth and seventh columns of this table, the minimum, average and max-imum running times of the DP algorithm are reported. All resulting CPU times were rounded to two significant decimals.
CPU time is very different for problems of an equivalent size, and depends on the instance data.

Generally speaking, the DP algorithm provides exact solutions, but it is not capable to treat problems with more than 13 lots. This represents a serious drawback when using the DP to resolve industrial problems. Actually, even for problems with as few as only eight lots, less than 40% of the instances could be solved. In addition, the average CPU time consumed for instances solved could be a problem for a practical use within the decomposition procedure which implies solving n different lot-sizing sub-problems. 6.4. MA and LS results versus optimal solutions
For problems with a small number of lots, it is possible to compare solutions obtained by the MA and LS with the exact solutions using the DP from Dolgui et al. (2005) . Experimental results, for instances with number of lots from 4 to 13, are presented in Table 2 .

Column two shows the quantity of instances for which this comparison were possible (i.e. quantity of instances resolved by the DP). In the third and fourth columns of this table, the running time in seconds of MA and LS are reported. As the running time of MA was limited by 0.2 n , so the time given in the corresponding column is the average time of five runs of each problem instance until the moment when the best solution was found. Both methods take little time to find their best solutions.
Columns 5 X 8 present the quality of the solutions with the MA and LS. Values reported in these columns are the relative errors (in percentage), obtained as follows: exact_sol  X  DP  X  approximative_sol  X  MA = LS  X  for instances where the DP was capable to obtain an exact solution. The  X  X  X verage relative error X  X  is the average of errors for all solutions obtained using a given optimization approach for instances of given size resolved by the DP. The  X  X  X aximum relative error X  X  represents the maximal relative error obtained with a corresponding approach. The average quality of solutions (column five for MA and column seven for LS) is very high, especially for the MA. As shown, in the worst case, the average value of relative error is only 0.328% from optimum that is a very good result. The same values for the LS are ostensibly worse. If we look at the maximum errors, for the MA, in the worst case, we have the relative error of 3.8%, but for the LS, it can be as much as 35.28%, i.e. about ten times as bad. 6.5. Comparison of MA with LS for large scale problems
Table 3 demonstrates average running time of MA and LS for instances with the number of lots from 10 to 150. Remember, for the MA, five independent runs for each of 160 instances for each problem size were effectuated. For the MA, two values are reported: (i) average calculation time under condition of a fixed time limit, in column two; and (ii) average time needed to find the best solution, in column three. For the LS, only the average calculation time is reported. One can see that while the LS found its local optima quicker than the MA, nevertheless CPU time remain fully compatible with a practical use on instances up to 150 lots for both methods.

It is also interesting to see that, for the MA, the variation of calculation time among different instances (see Fig. 6 ) was quite small. This figure demonstrates how the minimal, average and maximal CPU time of MA augments when the size of problem increases. We can observe that the maximal curve, which char-acterizes the relation between the CPU time and the number of lots, is quite linear.

Table 4 compares the effectiveness of approaches in terms of the solution X  X  quality. In columns two and three we report the average fitness values obtained respectively by LS and MA.
Results for LS correspond to the average result among the 160 instances whereas for MA, due to the stochastic character of the algorithm, we report the average result among the 160 instances and the five independent runs completed for each instance.
Remember that each solution of the problem is a probability, i.e. a value between zero and one. Note that the average values with
MA are always greater than the average values of LS. Column four indicates the percentage of instances in which the MA provides a better solution than the LS. It is interesting to note that this percentage tends to increase with the number of lots.
Overall, from 2400 instances tested, the average results obtained on five runs of the MA are greater than the correspond-ing results of the LS for 1267 instances and smaller for six instances only.
 Columns 5 X 8 report the results of the heuristic algoritms
G1 X  X 3 (in the MA these algorithms are used to generate the initial population). First of all, note that G1 and G2 have created solutions with non-zero fitness for all problem instances, while algorithm G3 was only able to create such a solution for 25% to 48% of tests on average (see the last column of the table), which can be explained because heuristic G3 does not ensure to generate solutions that respect the condition of Eq. (12). In such cases, zero was used to compute the average value of fitness. This is why, the average results for algorithm G3 (column seven) appear lower than average results in columns two and three.
However, when G3 provides a solution with a non-zero prob-ability, its fitness is usually on line with those of G1 or G2 .Ifwe compare G1 X  X 3 , the average results for the first heuristic is better for all sizes of lots, and these values are relatively not very far from the averages results of the MA and LS.
 Based on the tests provided for three solution approaches  X  DP,
MA and LS  X  it can be concluded that the first can only be used for small size problems because of high CPU time and memory deficiency, whereas both MA and LS can resolve industrial size problems in a reasonable time. Solution quality comparaison accomplished for instances up to 13 lots shows that solutions 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 CPU time of MA (s) provided by MA are of a better quality that those of LS; which is also true for the problems with a higher number of lots. The MA is a relatively stable method providing high quality solutions; coupled with an existing method to solve the TSP problem, they will form a general approach capable to effectively resolve initial lot-sizing and sequencing problems. 7. Conclusions
A real-life problem of optimal lot-sizing and sequencing for a production line with random breakdowns and rejects was stu-died. The line considered manufactures intermediate components of different types for subsequent assembly into modules. The problem is to choose sequences and lot sizes. The objective is to maximize the probability to have a sufficient number of compo-nents by the end of a given planning horizon, i.e. maximize the overall service level. The benefit of this optimization is evident, because without any additional resources, production cost can be reduced by limiting the stoppages for the assembly line that follows.

With an optimal decomposition procedure which uses a complete enumeration to search for the optimal last lot, sequen-cing and lot-sizing decisions can be considered separately. The sequencing sub-problem can be reduced to the well studied
Asymmetric Traveling Salesman Problem and thus be solved with known methods.

For lot-sizing, a local search and a memetic algorithm were proposed. Some experimental results were shown and discussed.
The algorithms developed were compared with a dynamic pro-gramming procedure for small size instances and between them for large size problems. The MA and LS developed can find good solutions for large problems and thus this approach can be applied to large scale industrial problems.

Future work may entail using simulation methods to replace the evaluation function (fitness) in order to consider problems with various probability distributions or integrating other uncertainty phenomena (e.g. uncertain manufacturing time). For example, by using simulation we could study problems in which the quantity and/or seriousness of breakdowns increases with the age of machines, etc. It will be interesting also to develop a metaheuristics approach to resolve the entire problem without decomposition and compare the results with and without decomposition.
 Acknowledgments The authors thank Chris Yukna for his help with English. References
