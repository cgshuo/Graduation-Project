 In this paper we give methods for time-aware music rec-ommendation in a social media service with the potential of exploiting immediate temporal influences between users. We consider events when a user listens to an artist the first time and this event follows some friend listening to the same artist short time before. We train a blend of matrix factor-ization methods that model the relation of the influencer, the influenced and the artist, both the individual factor decom-positions and their weight learned by variants of stochastic gradient descent (SGD). Special care is taken since events of influence form a subset of the positive implicit feedback data and hence we have to cope with two different defini-tions of the positive and negative implicit training data. In addition, in the time-aware setting we have to use online learning and evaluation methods. While SGD can easily be trained online, evaluation is cumbersome by traditional measures since we will have potentially different top recom-mendations at different times. Our experiments are carried over the two-year  X  X crobble X  history of 70,000 Last.fm users and show a 5% increase in recommendation quality by pre-dicting temporal influences.
 H.3.3 [ Information Storage and Retrieval ]: Information filtering; I.2.6 [ Artificial Intelligence ]: Learning temporal recommendation and evaluation; social influence; online matrix factorization; Last.fm; music recommendation
Part of the appeal of Web 2.0 is to find other people who share similar interests. Last.fm organizes its social network around music recommendation: users may automatically share their listening habits and at the same time grow their friendship. Based on the profiles shared, users may see what artists friends really listen to the most.

In a recent paper [22], we proved the existence of the in-fluence of friends on musical taste by carefully decoupling trends and homophily, the fact that friends are a priori more likely to have similar taste. In this paper we exploit the timely information gathered by the Last.fm service on users with public profile to exploit the potential influence between friends for recommendation. Last.fm X  X  service is unique in that we may obtain a detailed timeline and catch immedi-ate effects by comparing the history of friends in time and comparing to pairs of random users instead of friends.
As our main contribution, we give a matrix factorization mixture model for influence between friends that yield im-proved collaborative filtering methods. In the simplest set-ting, we may recommend a new artist a to a user u closely after a friend v listened to the same artist. When we turn to modeling the tensor data &lt; u,v,a &gt; that may even involve the time elapsed since v listening to a , we face a very sparse problem. Hence instead of modeling the tensor, we flatten out along the variables and define three matrices in addition to single-variable effects similar to the ones defined by the centralization procedures of [4].

Since influence from friends has a very strong time de-pendence in that only the events of the last few hours or days may have an effect on the user behavior, in this paper we consider online learning with very strong time sensitiv-ity. Compared to standard collaborative filtering methods, we process events only once and in the order they have ap-peared. As baseline we use online stochastic gradient de-scent (SGD) with high learning rate so that recent events have high contribution to the factor weights. The online fac-tor model already incorporates not just popularity by using a high learning rate and involving an online updated item bias, but also part of friends X  influence. Immediately after a user listens to an artist, the corresponding factor weights are relative strongly adjusted due to the high learning rate. If a friend has similar factor weights e.g. by homophily, the same artist will have high recommendation score after the learning step. The online factor model hence involves an im-plicit variant of an influence recommender by itself that we will further improve by a direct modeling of the influences.
To obtain the weighted combination of the baseline and the influence recommenders, we propose a new method for online learning user-dependent blending weights. If the deriva-tives of the individual models are available, a single SGD could optimize both the internal parameters and the blend-ing weights. However as it turns out, the influence recom-mender requires a different set of implicit positive items and a procedure for generating a negative sample than the tra-ditional online matrix factor model.

In our blend, we obtain a 5% of increase in quality, a strong result in view of the three-year Netflix Prize com-petition [6] to improve recommender quality by 10%. The fact that influences blend well with collaborative filtering and temporal effects prove that close events in the network bring in new information: friends X  close events in the past can be exploited in a recommender system.

Finally, as part of our results, we introduce quality mea-sures for time-aware recommender evaluation. As influence from friends has only a short, typically few hours effect, we retrain part of our models after each event and hence po-tentially give completely new top list of items for each event in the testing period. We highlight that discounted cumula-tive gain (DCG) computed individually for each event and averaged over time is an appropriate measure for real time recommender evaluation.

The rest of this paper is organized as follows. After de-scribing our Last.fm data in Section 2, we explore for mea-surable signs of influence by friends in Section 3. Our main influence recommender is defined in Section 4, our online evaluation metric in Section 5, the online blending method in Section 6 and the baseline algorithms in Section 7. Finally we show our measurements for improved recommendation quality in Section 8.
The Netflix Prize competition [6] has recently generated increased interest in recommender algorithms in the research community and put recommender algorithms under a sys-tematic thorough evaluation on standard data [5]. The final best results blended a very large number of methods whose reproduction is out of the scope of this paper.

Bonchi [7] summarizes the data mining aspects of research on social influence. He concludes that  X  X nother extremely important factor is the temporal dimension: nevertheless the role of time in viral marketing is still largely (and sur-prisingly) unexplored X , an aspect that is key in our result. Notion of influence similar to ours is derived in [3, 8] for Flickr and Twitter cascades, respectively.

Closest to our results are the applications of network influ-ence in collaborative filtering under the term of  X  X ocial reg-ularization X  [18, 21, 25, 26]. These results add smoothing to make friends X  model similar. We use social regularization as one baseline model in our experiments. In other results, only ratings and no social contacts are given [11], or in [13], both friendship and view information was present over Flickr, but the main goal was to measure the strength of the influence and no measurements were designed to separate influence from other effects.

Since our goal is to recommend different artists at different times, our evaluation must be based on the quality of the top list produced by the recommender. This so-called top-K recommender task is known to be hard [10]. A recent result on evaluating top-K recommenders is found in [9].

Music recommendation is considered in several results or-thogonal to our methods that will likely combine well. Mood data set is created in [14]. Similarity search based on au-dio is given in [16]. Tag based music recommenders [12, 23] and many more, a few of them based on Last.fm tags, use annotation and fall into the class of content based methods percent of 2012 Figure 1: The number of the users and friendship edges in time as the fraction of the values at the time of the data set creation (2012). as opposed to collaborative filtering considered in our paper [15, 19, 20].
Last.fm became a relevant online service in music based social networking. For registered users, it collects,  X  X crob-bles X  1 what they have listened. Each user has its own statis-tics on listened music that is shown in her profile. Most user profiles are public, and each user of Last.fm may have friends inside the Last.fm social network. Therefore one rel-evant information for the users is that they see their own and their friends X  listening statistics.

We investigate a data set that consists of the contacts and the implicit feedback timeline, the  X  X crobble history X  of the users. Our goal is to exploit the influence of social contacts for recommendation. For privacy considerations, throughout our research, we selected an anonymous sample of users. Anonymity is provided by selecting random users while maintaining a connected friendship network. We set the following constraints for random selection:  X  User location is stated in UK;  X  Age between 14 and 50, inclusive;  X  Profile displays scrobbles publicly (privacy constraint);  X  Daily average activity between 5 and 500.  X  At least 10 friends that meet the first four conditions. The above selection criteria were set to select a representa-tive part of Last.fm users and as much as possible avoid users who artificially generate inflated scrobble figures. In this anonymized data set of two years of artist scrobble timeline, edges of the social network are undirected and timestamped by creation date (Fig. 1). The number of users both in the time series and in the network is 71,000 with 285,241 edges; no edges are ever deleted from the network.

The time series contain 979,391,001 scrobbles from 2,073,395 artists and were collected between 01 January 2010 and 31 December 2011. The same user can scrobble an artist sev-eral times. The number of unique user-artist scrobbles is 57,274,158.
The name  X  X crobbling X  is a word by Last.fm, meaning the collection of information about user listening. Figure 2: Potential influence on u by other users to scrobble ( u,a,t u ).
The key concept in this paper is a user v influencing an-other u to scrobble a . The sign of an influence is if u scrob-bles artist a the first time at time t u , after v last scrobbling the same artist at some time t v &lt; t u before. The time dif-ference  X  t = t u  X  t v is the delay , as seen in Fig. 2. Our key assumption is that we observe such a subsequent first time scrobbling between non-friends only by coincidence while some of these events between friends are the result of cer-tain interaction. Our goal is to prove that friends indeed influence each other and this effect can be exploited for rec-ommendations.

Similar influence definitions are given in [3, 8, 13]. As detailed in [3], one main difference between these definitions is that in some papers t v is defined as the first and not the last time when user v scrobbles a . The smaller the delay  X  t between the scrobbles of v and u , the more certain we are that u is affected by the previous scrobble of v . The distribution of delay with respect to friends and non-friends will help us in determining the frequency and strength of influence over the Last.fm social network.

Out of the 57,274,158 first-time scrobbles of a certain artist a by some user, we find a friend who scrobbled a be-fore 10,993,042 times (19%) in the whole time series and 4,203,109 times in the second year. Note that one user can be influenced by more friends, therefore the total number of influences is 24,204,977. If we only consider influences with delay less than one week, this number reduces to 4,625,141. Note that there is no influencing user for the very first scrob-bler of a in the data set. For other scrobbles there is always an earlier scrobble by some other user, however, that user may not be a friend of u . Some of the observed subsequent scrobbles may result by pure coincidence, especially when a new album is released or the popularity of the artist in-creases for some other reason.

In order to quantify real influence within the set of sub-sequent first time scrobbles, our goal is to determine the probability that the subsequent scrobbles are result of in-fluence. If we condition this probability for friends and by a limit t on the delay, we should obtain a monotonically decreasing function Infl( t ).

To formalize, let us consider the probability space of sub-sequent first time scrobbles among all users. Let I denote the event that an subsequent first time scrobble is the result of an influence. I c is the opposite, no influence occurs. Coin-cidence or other, external reason such as the overall increase in popularity causes the subsequent first time scrobble in
P (
 X  t  X  t )
P (
 X  t  X  t ) Figure 3: Fraction of subsequent first time scrobbles with delay  X  t  X  t as the function of t , in case of friends ( P ( X  t  X  t | f )) and non-friends ( P ( X  t  X  t | f c )) over the entire timeline ( top ) and the first 24 hours ( bottom ). the time series. Let f denote events between friends and f between non-friends. Finally let  X  t  X  t denote the set of events with delay at most t . With these notations, = P ( I,  X  t  X  t,f ) As non-friends f c should not have any real influence on each other, we assume that
P ( X  t  X  t, I c | f )  X  P ( X  t  X  t,I c | f c ) = P ( X  t  X  t | f Using this approximation, we can compute the probability of influences between friends as in (1) by expanding (3), By the above equation, the influence probability can be ap-proximated by observing the cumulative density curves in Fig. 3. The estimate of this function as in (5) is shown in Fig. 4. As expected, Infl( t ) is a monotonically decreasing function of t . However, the decrease is slow unlike in some recent influence models that propose exponential decay in time [13]. Therefore, we approximate the influence proba-bility with a slowly decreasing logarithmic function instead of an exponential decay, where c is a constant.
Based on the measurements in the previous section, we model the observed influences and give a method to apply for Figure 4: The influence probability approximated by equa-tion (5), the ratio of increase among friends compared to non-friends very closely follows a logarithmic function of de-lay  X  t  X  t . Figure 5: Scheme of the influence based recommender algo-rithm. recommendation. Influence depends on time and no matter how relative slow, the influential power of a friend scrobbling an artist decays as time passes by. For this reason, the influence based recommender must learn online.

To formalize, let v a ; X  t  X  X   X  X  X  X  X  X  X  X  X  u denote the event that user u scrobbles artist a the first time in her time series, and  X  t time after her friend v also scrobbled a . The time difference  X  t is restricted to be in a time interval T . As illustrated in Fig. 5, we would like to decompose the probability that v  X  X  X  X  X  X  X  X  X  u happens and the reason for this event is influ-ence ( I ) between the users into a factor that only depends on  X  t and another one that is independent of  X  t . First we decompose the full event into a conditional probability as When a scrobble event happens at time exactly t after the scrobble of v , the interval becomes a point and hence we are looking for the derivative We model the right hand side of (7), the  X  X trength X  of the influence between users u and v , independent of time as hence by equation (7) we may divide the derivative (8) by f ( v a  X  X  X  u ) to get We model influence conditional probabilities by a global function for all users that depend only on the time  X  t elapsed, By using our function in (5) and (6), equation (10) becomes lim Now we give our matrix factorization model for f ( v a  X  X  X  u ). We decompose the model into seven terms that give a global model for one or more of the three variables u,v,a in ( v u ). By replacing variables considered globally by ing that the last term with all three variables global is a constant, we get f ( v a  X  X  X  u )  X  w 0 + w ( We have four global effects, a constant, an influencer, an influenced, and an artist, and three bivariate terms that can be modeled by matrix factorization as f ( v a  X  X  X  u )  X   X  0 +  X  1 b v +  X  2 b u +  X  3 b a The three bias terms b v ,b u and b a correspond to the frequen-cies of user v influencing, user u being influenced and influ-ences occurred with artist a .  X  1 ,..., X  3 are learned weights of the biases, and  X  0 is the global learned bias. The six vectors correspond to six different latent vectors.
The final prediction score  X  r is based on (8), by using (15) and (13) we can write it in a form where we sum up for all neighbors of u and t v is when v last scrobbled a before t u . For training, we only update f ( v a  X  X  X  u ) by the actual positive events and a generated sam-ple of negative events. In our algorithm we use SGD with respect to MSE to train the latent factors and the weights  X  ,..., X  3 . Notice that the weight of the factor models is included within the factors, since the entire formula (15) is trained by a single SGD procedure. As we learn online, the weight of the effects are also trained by SGD and not by the least squares optimization procedure proposed in [4].
In an efficient implementation, since the expression (13) quickly decays with t , we only need to retrieve the past scrobbles of all friends of u . This step is computationally inexpensive unless u has too many friends, when the rec-ommendation is noisy anyway. To speed up computations, we only consider influences with delay not more than a pre-defined time frame T and hence we set c = 1 / (1 + log T ). With a sufficiently small parameter of the time frame in the range of a few days, our algorithm can hence be imple-mented even to provide recommendations based on real time updated models. Figure 6: Number of new ( u,a ) scrobbles as the function of time.
Recommender systems in practice need to rank the best K items for the user. In this top-K recommendation task [10, 9] the goal is not to rate some of the individual items but to provide the best candidates. Despite the fact that only pre-diction for the top list matters in top-K evaluation, several authors propose models trained for RMSE with good top-K performance [17, 24] and hence we follow their approach.
In a time sensitive or online recommender that poten-tially retrains its model after each and every scrobble, we have to generate new top-K recommendation list for every single scrobble in the test period. The online top-K task is hence different from the standard recommender evalua-tion settings, since there is always a single item only in the ground truth and the goal is to aggregate the rank of these single items over the entire testing period. For our task, we need carefully selected quality metrics that we describe next.

Out of the two year scrobbling data, we use the full first year as training period. The second year becomes the testing period where we consider scrobbles one by one. We allow a recommender algorithm to use part or full of the data before the scrobble in question for training and require a ranked top list of artists as output. We evaluate the given single actual scrobble a in question against the recommended top list of length K . As seen in Fig. 6, by the second year, the number of first-time scrobbles stabilize around 50,000 a day after the artificial peak in the beginning caused by the lack of earlier data. For the reason of stability, we measure our recommender methods in Year 2 of the timeline.

One possible measure for the quality of a recommended top list of length K could be precision and recall [25, 26]. Note that we evaluate against a single scrobble. Both the number of relevant (1) and the number of retrieved ( K ) items are fixed. Precision is 1 /K if we retrieve the single item scrobbled and 0 otherwise. Recall is 0 if we do not retrieve the single relevant item and 1 otherwise. The value of K that maximizes precision is the rank of the item scrob-bled and hence  X  X aximal precision X  follows the function of 1/rank.

Recently, measures other than precision and recall are pre-ferred for measuring the quality of top-K recommendation [2]. The most common measure is NDCG that is a normal-ized version of the discounted cumulative gain (DCG) with threshold K
DCG@K( a ) =
P (pop( a )  X  x ) F igure 7: Top: Distribution of scrobble count to a given artist and the cumulative distribution. Bottom: Fraction of scrobbles for artists with popularity at least a given value x , as the function of x . F igure 8: The number of different artists scrobbled before a given time in the two year period of the data set.
 Since DCG is a slower decreasing function of the rank than what we observed for maximal precision, DCG is more ad-vantageous since we have a large number of artists of poten-tial interest to each user. Our choice is in accordance with the observations in [2] as well.

Note that in our unusual setting of DCG evaluation, there is a single relevant item and hence for example no normaliza-tion is needed as in case of the DCG measure. Also note that the DCG values will be small since the NDCG of a relative short sequence of actual scrobbles will roughly be equal to the sum of the individual DCG values. The DCG measured over 100 subsequent scrobbles of different artists cannot be more than the ideal DCG, which is P 100 i =1 1 / log 20 . 64 in this case (the ideal value is 6.58 for K = 20). Hence the DCG of an individual scrobble will on average be less than 0.21 for K = 100 and 0.33 for K = 20.

In our evaluation we discard infrequent artists from the data set both for efficiency considerations and due to the fact that our item based recommenders will have too little information on them. As seen in Fig. 7, top, the number of Figure 9: Scheme of the 1-layer( top ) and 2-layer( bottom ) online combination models. artists with a given scrobble count follow a power-law dis-tribution with near 60% of the artists appearing only once. While 90% of the artists gathered less than 20 scrobbles in two years, as seen in Fig. 7, bottom, they attribute to only less than 10% of the data set. In other words, by discard-ing a large number of artists, we only lose a small fraction of the scrobbles. For efficiency we only consider artists of frequency more than 14.

As time elapses, we observe near linear increase in the number of artists that appear in the data set in Fig. 8. This figure shows artists with at least 14 scrobbles separately. Their count grows slower but still we observe a large number of new artist that appear in time and exceed the minimum count of 14. Very fast growth for infrequent artists may be a result of noise and unidentified artists from e.g. YouTube videos and similar Web sources.
We give two methods based on SGD that learn the online blending weight of recommender algorithms. Note that the algorithms may or may not themselves be based on SGD, i.e. the derivative of the individual models may or may not be available for the blending optimization procedure. Further-more, we may blend methods with different definitions of the implicit feedback data sequence: the positive instances for the influence based recommender form a small subset of all the events and hence the influence recommender also needs different methods for generating negative training samples.
If the derivatives of the individual models are available for the top level optimizer, we may optimize in a single layer (top of Fig. 9) by minimizing where we sum over all models m , and F is the error measure, MSE in our case. Notice that we learn a user dependent blending weight vector  X  u m , hence for example the blending of a k and a k 0 factorization will in theory have at most as high F as a single k + k 0 one, and in our experience performed only slightly better.

We may take the derivatives for both the constants  X  and  X  and the individual model parameters ~  X  m : If the derivatives are not available, the individual models are considered as black box for blending and we have to train in two layers (bottom of Fig. 9) and we may only use the last two derivatives (20) and (21).

If different models need different training samples, we can-not use the derivative (19) either. This is the case if we com-bine the baseline matrix factorization with the algorithm of Section 4. If the current positive event is not the result of an influence (i.e. not a first time scrobble or no friend scrob-bling the same artist before), then we only update the base-line models. And if there is at least one possible influencer v  X  X  X  u for the current event ( u,a ), then we generate separate negative training instances for the baseline and the influence models. Notice that even a negative influence training data v  X  X  X  u must satisfy that v 0 is a friend of u who scrobbled a and hence we usually have to choose from a restricted small set. Blending is meaningful only over this restricted set too, since for other events, the influence recommender has no t value in equation (16) to compute its prediction. Hence for blending, we have to use the same negative samples as for training the influence model.
We describe three baseline methods. The first one is based on dynamic popularity in Section 7.1. The second one in Section 7.2 is an online matrix factorization and the third one in Section 7.3 adds regularization over friendship as in [18].

All the methods discussed here are online algorithms, as opposed to the batch methods used in challenges such as Netflix. In some preliminary experiments the batch algo-rithms performed significantly worse in the online task com-pared to their online versions. We plan to compare the per-formance of batch and online versions of the algorithms in an online task more extensively in the future.
Given a predefined time frame T as in Section 4, at time t we recommend an artist based on the popularity in time not earlier than t u  X  T but before t u . In our algorithm we update the counts and store artists sorted by the current popularity. In one time step, we may either add a new scrobble event or remove the earliest one, corresponding to a count increment Figure 10: Online performance of the three different recom-menders. or decrement. For globally popular items, the sorted order can be maintained by a few changes in the order only.
Stochastic gradient descent methods in batch setting may iterate several times over the training set until convergence. In an online setting [1], the model needs to be retrained af-ter each new event and hence reiterations over the earlier parts of the data is ruled out. We may implement an online recommender algorithm by allowing a single iteration over the training data only, and this single iteration processes the events in the order of time. We used the first time scrobbles as positive training instances and generated negative train-ing instances by selecting three random artists uniformly at the time when a user first scrobbled an artist.

Online recommenders seem more restricted than those that may iterate over the data set several times and one would expect inferior quality by the online methods. On-line methods however have the advantage of giving much more emphasis on recent events. In some sense, the online methods may incorporate the notion of influence from Sec-tion 3: if friends have similar taste and hence similar factor weights, a friend scrobbling some artist a will in the near future strengthen the weight for this artist for all users who have similar taste.
Ma et al. [18] propose a method to implement constraints in a factor model based recommender algorithm for keep-ing the profile of friends similar. We implemented both the average-based and the individual-based regularization of [18] and found the latter superior, hence we use individual-based regularization in our experiments. Note that these algorithms have no knowledge of time and hence cannot in-corporate our notion of subsequent first time scrobbles as in Section 3, even though they may work very well for other, non-first-time scrobbles that we do not consider in this pa-per.
In this section we describe the quality of our results for the second year testing period. Under various settings, we give daily average DCG@K defined by equation (17). Figure 11: Combination of the influence and factor models. Our experiments were carried out over the single core of an AMD based virtual server with 128GB RAM. On average, it took 28 minutes to process one day of scrobble history, up-date the online models and provide top-K recommendation corresponding to each user event.

Parameter K in equation (17) controls the length of the top list considered for evaluation. In other words, K can be interpreted as the size of the list presented to the user. Practically K must be small in order not to flood the user with information. We show results for K = 10 and 100. In Fig. 10, DCG@100 is shown for two baseline methods, matrix factorization and temporal popularity, as well as our influence model.

When combining variants of baseline and influence recom-mendation predictions, we observed that that social regular-ization did not improve matrix factorization and temporal popularity did not blend with online factorization. Indeed in Fig. 10 we may observe that peaks in temporal popu-larity performance immediately appear as peaks in matrix factorization performance, since online factorization learns temporal trends very well.

In Fig. 11, one can see that the online combination with influence recommendation improves over online matrix fac-torization both for DCG@10 and DCG@100. The aver-age improvement is roughly 7% for DCG@10, and 3% for DCG@100. Over the same figure, we plot the performance of the constant term alone in equation (15). This simple rec-ommender corresponds to adding up all the (1  X  c (1 + log t )) values for possible influencers without model building be-yond learning the blending weight involved. At first this simple model blends best with the baseline, however, as the factor models get more training data, they become superior and the importance of the constant term  X  0 in the model diminishes.
 Based on a 70,000-entry sample of Last.fm users, we were able to exploit the effect of users influencing the taste of friends for improving the quality of music recommendation. Over static baseline recommenders, we achieved a 5% im-provement in recommendation accuracy when presenting artists from friends X  past scrobbles that the given user had never seen before.

Our system has very strong time-awareness: when we rec-ommend, we look back in the near past and combine friends X  scrobbles with the baseline methods. The influence from a friend at a given time is certain function of the observed influence in the past and the time elapsed since the friend scrobbled the given artist.

All of our methods learn online and provide top-K recom-mendation lists recomputed for every user query. Because of the inherent time dependence, we defined average DCG as our evaluation metric and gave a new online blending procedure that learns online user-dependent weights.
