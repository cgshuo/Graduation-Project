 Privacy preserving data mining is a relatively new research area in data mining and knowledge discovery. The main goal of privacy preserving data mining is to preserve the privacy during data mining operations and this can be done by modifying the traditional data mining algorithms, which were not considered, so that the private raw data like identifiers, names, addresses, etc. remain private for the data owner even after the mining processes. The algorithms for privacy preserving data mining depend on the data mining tasks(association rule, clas-sification, clustering) and how the data are distributed among parties( centralize where all attributes and transactions locate in one party, horizontally where transactions are distributed to involving parties but each party has only a sub-set of transactions attributes, vertically where transaction attributes are distrib-uted to involving parties but each party has only a subset of attributes). In this paper, we particularly focus on applying privacy-preserving method on the decision tree-based classification on ver tically partitioned data. There are con-siderable amount of applications that use decision tree in classification, whereas the attributes are distributed across several parties, e.g. a collection of depart-mental databases on number of products sold. Each product is a column in the table, different departments offer different products. Some department requires that individual data should not be revealed to other parties.
 sion tree and to classify a query transaction. The privacy is preserved through both building and classification stages. 2. Our algorithms could extend the num-ber of involving parties while the communication cost is reduced when compared to existing methods.
 data mining. The inference problem in decision tree classification is discussed in Section 3. Section 4 presents our work private decision tree both in tree building and classification stages to protect the inf erence problem. Conclusion is given at the last section. In recent work of privacy preserving data mining. The secure multi party com-putation (SMC) techniques [4] such as secure sum, secure scalar product, secure intersection, are utilized in the algorithms. Two privacy preserving algorithms proposed by Clifton [1] and [2] are based on an SMC technique. They were de-signed to find association rules on horizo ntally and vertically partitioned data, respectively. Both use secure scalar product of the vectors as a primary tool. Secure scalar product allows two parties to collaboratively compute the scalar product without revealing their own vector to the other party.
 partitioned data in [3]. They introduced an SMC-based protocol which improves performance of secure scalar product but their algorithm requires the use of a third party. However, their decision tree may still reveal some sensitive data due to the inference problem . Moreover, it is difficult to extend the number of involving parties when secure scalar product is used. In [7], Vaidya proposed another algorithm to build the decision tree. However, the tree on each party does not contain information that belongs to other parties. The drawback of this method is that the resulting class can be altered by a malicious party. Moreover, the communication cost is rather high due to the heavy use of SMC operations. In decision tree-based classification with v ertically partitioned data scheme, the inference problem can be derived from the use of public decision trees . Pub-lic decision tree is a traditional decisi on tree which does not have any feature to protect privacy. After the training stage, all parties can access full infor-mation of the public decision tree. Such information can be used to infer the private data of other parties both in tree building and classification stages. Let us consider the following example where two parties, Alice and Bob are involved. Suppose that Alice and Bob have collaboratively built a public decision tree shown in Fig. 1 without explicitly exchanging any sensitive data. After the tree is built, both parties have complete knowledge of the structure of the tree. Now they want to classify a new transaction T i =(Outlook = Sunny; Temperature = Cold; Humidity = High; Wind = Strong) which Alice holds only attributes  X  X utlook = Sunny; Temperature = Cold X  and Bob holds the other attributes. After T i is classified, both parties know that  X  X lay X  is the outcome and thus they can use the structure of the tree to trace all possible paths that lead to  X  X lay X . There might be many paths that result in  X  X lay X  but since each party knows some attribute values of Transaction T i , it can narrow down the possibilities. In the example below, both parties can trace to the path  X  X utlook = Sunny; Humidity = High; Temperature = Cold X . Hence Alice can use this path to iden-tify the value of  X  X umidity X , which is Bob X  X  private attribute. However, Alice cannot obtain Bob X  X   X  X ind X , because it is not a part of the outcome path. Bob can perform the same analysis and discover the values of both of Alice X  X  private attributes. The inference of the outcome path can also be applied to the training data set that was used during the tree building stage too. In this section, we describe our algorithms that build and classify decision tree and at the same time preserve the privacy of the data of each party. Our tree building algorithm is based on ID3 algorithm [6], but it can easily be modified to accommodate other decision tree construction algorithms. 4.1 Tree Building Let P = P 1 ,...,P k be a set of k parties involved in the operations. Any trans-action, t ,containsasetof m + 1 attributes A S = A 1 ,...,A m ,C where C is the class attribute. The set of training transactions, T , is vertically partitioned into k partitions, T 1 ,...,T k , such that T i is accessible from P i only. Each T i has attribute set AS P i ,where AS P i  X  A S and AS P i  X  AS P j =  X  when i = j . from T withoutrevealingtheirowndatatootherparties.Inordertodoso,we introduce private decision tree, DT i ,foreachparty P i . DT i is known to P i only. Full DT could be built from all DT i  X  X  combined. 1. Every party P 1 ,...,P k has the same number of transactions. 2. AS P i is not empty for all i  X  X . 3. Domain of the class attribute C is known to all parties. 4. Attributes of query transactions are distributed in the same manner as train-tion gain similar to the original ID3 algorithm [6] and compares with the best information gain received from other parties. If its best local information gain is the best among all parties, the node is labeled with the attribute A which belongs to its best local information gain. The party P i then notifies other par-ties that the node belongs to P i but it does not give any information related to the attribute A such as the attribute name and its values. Then the party P i partitions T into m partitions T a 1 ,...,T a m such that attribute associated with the maximum information gain A of every transaction in T a i has value a i .Then the party P i broadcasts each partition associated with each of new m nodes and also broadcasts sets of transaction IDs ID ( T a i ) associated with each partition T a i . Finally, each party updates its unselected attributes AS P i along the new nodes.
 rate using these trees to classify new coming query transactions. Let us con-sider the example in Fig. 2 Alice X  X  private decision tree (left side in Fig. 2) contains only the information for Alice. Similarly, Bob X  X  private decision tree (right side in Fig. 2) contains only the information for Bob. To classify a new coming transaction (Outlook = Sunny; Temperature = Hot; Humidity = High; Wind = Strong) which Alice holds only attributes  X  X utlook = Sunny; Tem-perature = Hot X  and Bob holds the rest attributes. Alice creates its candi-date paths set A = Path 1 ,Path 3 ,Path 4. Bob creates its candidate paths set B = Path 2 ,Path 3 then both parties use the normal intersection protocol such as in [5] to find the result of A  X  B = Path 3 which is the predicted outcome (class).
 4.2 Privacy Analysis During the tree building, the following information have been disclosed  X  Sets of transaction IDs associated wi th each tree path. This can be used to  X  The information gain associated with each node.  X  The owner and cardinality of each node which can be derived from the tree combined together to derive private data of other parties. This is mainly because the attribute associated with each node is undisclosed. However, if a malicious party is aware of the distribution of an attribute or each party has very few attributes, it might be possible to guess the value of private data. Moreover, the malicious party cannot guess the data values in the same transaction by using the knowledge in public decision tree as described earlier. Therefore, the inference problem cannot occur during tree building stage.
 party is encrypted in the intersection protocol [5]. Candidate path IDs will be guarded. Only the number of candidate paths is disclosed. After classification, all parties know the outcome path ID. This combined information cannot be used to reconstruct the public decision tree. Therefore, the inference problem cannot occur during classification. More over, in order to get the correct result in classification, each party cannot alter its own set of candidate paths. This removes the drawback of the algorithm in [7], which allows a malicious party to notify other parties with the wrong classification results.
 terms of protecting the data privacy but it reduces the computation and com-munication costs and improves the efficiency. 4.3 Computation and Communication Analysis The computation and communication costs depend on the following parameters: the number of parties k , the number of nodes on the tree N .Twomajorsteps contribute to the communication cost. The first one occurs while it finds the best information gain at each node. k parties broadcast their bestGain to compare to other parties, thus the communication needed is k  X  sizeof bestGain  X  N bits. The second communication requires broad casting a set of transaction IDs ID ( T a i )to every node. The communication cost for this is sizeof ID ( T a i )  X  N bits. Actually, sizeof ID ( T a i ) linearly decreases with the depth of the node in the tree. There-fore, the total communication cost for tree building is O ( k  X  sizeof bestGain  X  sizeof ID ( T a i )  X  N 2 ) bits. For computation cost it needs no extra SMC algorithm like [3,7] since each party computes its private decision tree locally. Therefore, the computation cost is comparable to the original ID3 algorithm [6]. S path then uses the intersection protocol from [5] to find the solution path. The intersection protocol requires that the set of each party needs to be encrypted by all other parties. Assume that the average number of elements in set of candidate paths is n and average size of each element is sizeof n bits. The computation and communication costs are O ( nk 2 )and O ( nk 2  X  sizeof n ) respectively. Compared to the computation and communication costs in [7], we need to involve the intersection protocol only once in the classification stage to find the predicted class while the algorithm in [7] needs to involve the intersection protocol in tree building stage every time the information gain of each attribute is computed. In this paper, we have investigated the problem of privacy preserving classifi-cation based on decision tree on vertically partitioned environment. We have shown that information in the public decision tree can be used to infer private data of other parties both in the tree building and classification stages. There-fore, we propose a new set of classification algorithms using private decision tree to avoid the inference problem. Another advantage of our approach is that the number of involving parties can be easily extended while the communication cost is reduced.

