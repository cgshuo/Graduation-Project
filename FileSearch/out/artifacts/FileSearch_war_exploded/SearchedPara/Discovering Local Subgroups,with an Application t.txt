 Rob M. Konijn, Wouter Duivesteijn, Wojtek Kowalczyk, and Arno Knobbe In this paper, we present a method for dis covering local patterns in data. Our method, called Local Subgroup Discovery (LSD) , is inspired by Subgroup Dis-covery (SD) techniques [4,8], which to some degree have a local focus, but the notion of locality plays a more important role here than in standard SD. When a dataset contains natural variations that are explainable , traditional SD meth-ods will focus on these. By contrast, when relatively rare events such as fraud or terrorism are concerned, we aim to find local deviations within these natural fluctuations. Hence, the LSD method intends to provide interesting and action-able phenomena in the data, within the natural variations in the data that are not interesting to report. As we are interested in local deviations, we will use a neighborhood concept, in terms of a ba sicdistancemeasureoverthedata.
In order to define the notion of locality, we work with a reference group that represents a subpopulation or neighborhood, in the context of which we want to evaluate subgroups. A local subgroup is a subgroup within this reference group. Such local subgroups will be judged in terms of their unusual distribution of the target attribute, compared with that of the reference group (rather than com-paring with the entire population). Both the reference group and the subgroup will be defined in terms of distances from a common subgroup center. Standard quality measures from the SD literature are used to quantify how interesting a subgroup is with respect to its referen ce group. Figure 1 shows an example of two local subgroups within an artificial dataset. In SD, we are interested in find-ing groups that contain relatively many positive examples. The local subgroup consists of points within the smallest circle, the corresponding reference group are points within the larger circle. Both the reference group and the subgroup are defined in terms of distances from their subgroup center. Both subgroups contain relatively many red crosses, co mpared to their local neighborhood.
In this paper we are interested in finding the most interesting subgroups within reference groups in a dataset. The main contributions of this paper are: defining the Local Subgroup Discovery task, presenting a new algorithm that searches for local subgroups efficiently, and showing the usefulness of the local subgroup concept in a real-life fraud detection application. 1.1 Motivation: Health Insurance Fraud Detection The motivation for LSD comes from the field of fraud detection in health insur-ance data, where we are interested in identifying suspicious claim behavior of medical practitioners. The problem is essentially an unsupervised one, since we are not presented with any examples of known fraud cases. The goal is to identify groups of claims that warrant further inspection by fraud investigators. We do this by comparing the claim distribution of one medical practitioner (typically, a high-cost claimer) with that of the remaining practitioners. The health insur-ance data we consider in our experiments contains information about patients and practitioners. A single record in this dataset summarizes the care (treatment, medication, costs, etc.) an individual has received over a selected period of time. Although the data is described in terms of patients, we are actually more con-cerned with an analysis of this data on the level of medical practitioners. After all, consistent  X  X nefficient X  claim behav ior (in the extreme case: fraud) committed by specific practitioners has a far more substantial commercial impact than such behavior committed by specific patients.

We will explain the setting with the help of Figure 1. Suppose that each point represents a patient. The dataset clearly consists of three clusters, which we can interpret as groups of patients with the same type of disease. Within these clus-ters the differences between patients are c aused by treatment costs, variations in medication types, and so on. The approach we take in this paper is to single out an individual medical practitioner, and define a temporary binary column that identifies the patients of this practitioner. This column will then serve as the target in a Subgroup Discovery run, in order to find patterns in the claim be-havior that distinguish this practitioner from the others. In Figure 1, patients of the marked practitioner are represented by red crosses. Patients of other prac-titioners appear as blue plusses. The two subgroups (smaller circles) indicate a difference in claim behavior within a re ference group of patients having the same disease type (larger circles); the proportion of red plusses in the subgroup is much higher than the proportion of plusses in the reference group. If substan-tial local subgroups can be found for an individual practitioner, this is a strong indication of inefficient or fraudulent practice. By repeating this process, each time focusing on a different practitioner, we can produce a list of all suspicious practitioners, along with the necessary details about the unusual behavior. Describing distributional differences between the target and non-target set is usually referred to as Subgroup Discovery [8], but also as Contrast Set Mining [1], and Emerging Pattern Mining [2]. These methods find subgroups that are interesting compared to the whole dataset, whereas the method we propose finds locally interesting subgroups. Also, in Subgroup Discovery the subgroups are usually described by conditions on the non-target attributes, whereas in our application we use a distance measure to define subgroups. This is similar to epidemiology where a spatia l scan statistic [6] is often used to identify regions where a certain type of disease (the targe t attribute) is more frequently present than in the rest of the country. Here a likelihood ratio statistic is often used to identify interesting regions. In our approach we also look for interesting regions in our data. Unlike with the spatial scan, our approach allows for any quality measure (instead of the likelihood ratio statistic) and finds reference groups together with subgroups. Calculating the quality measure on a subset of the data has been done before [7]. The subset of the data is obtained by using a distance measure. Luong et al. fix a nearest neighbor parameter k , calculate a quality measure on a part of the data based on this k , and then describe interesting regions in the dataset for which this quality measure is high. The difference with our approach is that we are interested in searching for interesting subgroups, while automatically finding relevant values of k .

To the best of our knowledge, this is the first approach to unsupervised fraud detection by using Subgroup Discovery to compare between entities (in this article these entities are medical practi tioners, but they could be shops, cashiers, etc.). Other approaches to fraud detection are supervised methods (where fraud is labeled beforehand), and outlier detection methods. Since we do not have a labeled fraud set, and we are interested in differences on the aggregated level of claims of medical practitioners rather than finding single outliers, these methods are beyond the scope of the paper. Throughout this paper we assume a dataset D with N elements ( examples )that are ( h + 1)-dimensional vectors of the form x = { a 1 ,..,a h ,t } . Hence, we can view our dataset as an N  X  ( h + 1) matrix, where each data point is stored as arow x i  X  D .Wecall a i = { a i 1 ,..,a i h } the attributes of x i ,and t i its target .We assume that each target is binary, and ea ch vector of attributes comes from an undefined space A on which we have a distance measure  X  : A X A X  R .

A subgroup can be any subset of the dataset S  X  D .A quality measure q :2 D  X  R is a function assigning a numeric value to any subgroup. Quality measures describe how interesting subgroups are, and usually take into account the size of a subgroup (larger is better) as well as its difference in target distri-bution (higher proportion of the target is better).

To deal with locality we propose a distance-based approach to find subgroups and reference groups, based on prototypes. A prototype can be any point in attribute space x  X  X  .The distance-based subgroup S  X  based on x for parameter  X   X  N , consists of the  X  nearest (according to  X  ) neighbors of x in D .The reference group R  X  basedonthesame x for parameter  X   X  N s.t.  X   X   X  , consists of the  X  nearest neighbors of x in D . The idea is that R  X  forms a region in input space where the target distribution is different from that distribution over the whole dataset, and we strive to find subgroups S  X   X  R  X  in which the target distribution is different from the distribution within R  X  .

We write S ( x,  X ,  X  ) for the subgroup S  X  in a reference group R  X  ,whichwe call a reference-based subgroup . The prototype can be seen as the center of this subgroup, and as the center of the reference group encompassing the subgroup. A quality measure calculated for a reference-based subgroup considers only ex-amples inside the reference group: the quality of the subgroup is calculated on a contingency table of the data, as if the reference group were the entire dataset.
Given a prototype x , a distance measure  X  , and the target vector t ,wecan obtain a ranking of the target variable (see Figure 2). This ranking is a sorted list of targets, where the leftmost point is closest to x and the rightmost point is the point furthest from x . To find the optimal reference and subgroup for agiven x ,wehavetoset  X  and  X  in such a way that the quality measure is maximized. For example, let us calcu late the Weighted Relative Accuracy (WRAcc) quality measure for the subgro up and reference group in Figure 2, for the parameters  X  =8and  X  = 14. The WRAcc of a subgroup S with respect to target t is defined as P ( St )  X  P ( S ) P ( t ), where P ( St ) is the probability of the target and subgroup occurring together, P ( S ) is the probability of a record being in the subgroup, and P ( t ) is the probability of the target being true. These probabilities are all calculated given that a point belongs to the reference group. In this example the WRAcc is thus given by: 6 / 14  X  8 / 14  X  7 / 14 = 1 / 7  X  0 . 143. If we would set  X  to 11 instead of 14 this would lead to a somewhat higher quality: / In this section we explain how the optimal subgroups and their reference groups are found. First we explain how we search for the most interesting subgroups with the highest quality. We also explore our approach to two problems encoun-tered when searching for local subgroups. The first problem is how to compare qualities found on different reference groups, with different reference group sizes and different numbers of positives. The second problem is concerned with the potential redundancy in the collection of reported subgroups. 4.1 Searching for the Optimal Values In LSD, subgroups are described by optimal combinations of the prototype x and the parameters  X  and  X  . Assume we are considering a candidate prototype x .We then loop over possible values of  X  , and for each value, try all possible values for  X  and calculate the quality. Per value of  X  , the highest quality obtained in this way is called the optimal quality , and the value  X  ( x,  X  ) at which this maximum is obtained is called the optimal value for  X  ,given x and  X  .
If we were to search for optimal values of the quality measures in this way, we would find that for the ranking in Figure 2, the optimal value for WRAcc would be obtained at  X  =3,and  X  = 2, with a WRAcc value of 2 / 9  X  0 . 222. Unfortunately, this subgroup is not that interesting because it is quite small. Nor is it very significant; in any dataset and for any prototype, we can typically construct such a tiny subgroup and a reference group that perfectly separates positive from negative examples. This behavior of favoring very small reference groups in which we can perfectly separate positive from negative cases does not only occur for the WRAcc measure; any quality measure will suffer from this problem. Hence, guiding the search solely by high quality will not lead to interesting results. The size of the ref erence group should also be big enough to ensure that a subgroup with a high quality is really interesting. Hence, we need to deal with the significance of the found quality. 4.2 Significance and Interestingness To compute the significance of a candidate x ,  X  , and associated  X  ( x,  X  ), we use a swap randomization techni que, creating a baseline distribution of false discov-eries (DFD). This method [3] was originally designed for SD where subgroups are defined by attribute-value descriptions. We modify the method for use with distance-based subgroups, as follows. Fir st, the target variable in the reference group is permuted, while keeping the rest of the dataset intact. Within Figure 2 this corresponds to permuting all plusses and minusses up to  X  . Since we leave the attribute space intact, all distances between examples remain the same. Next we search for the optimal quality in this permuted reference group. The optimal quality found can be considered a false discovery, because it is a discovery made on data in which the attribute space is left intact, but its connections with the targets are randomized. We can repeat this procedure to obtain more false dis-coveries. Together, these qualities constitute a sample of the DFD. The DFD for a quality measure thus differs for each combination of reference group size, and the number of times the target is positive in the reference group. Using this DFD we can assign p-values to subgroups having a certain quality. As [3] describes, a normal distribution can be used to estimate p-values, corresponding to the null hypothesis that a subgroup with the given quality is a false discovery.
The p-value obtained gives us a fair measure to compare qualities found for different reference groups. A low p-value indicates a low probability of finding the quality by chance. Within our approach, we compare subgroups found on different reference groups by comparing their p-value. In Section 5 we show how to search for subgroups with the lowest p-values efficiently. 4.3 Choosing Prototypes and Removing Redundancy In the previous section, we explained how to find optimal values for  X  and  X  ,for a given prototype x . Since we will find optimal values for each prototype, which can be each point in the dataset, this will lead to discovering many (redundant) subgroups. In this section, we describe how to find optimal (non-redundant) val-ues for x , with the goal of presenting a concise list of subgroups to the user. To achieve this, we use a top-k approach: only the k most interesting subgroups are mined. Additionally we will use two techniques to remove redundancy from this top-k list. The first technique, based on the quality neighborhood of exam-ples, will prevent redundant subgroups to enter the top-k . The second technique postprocesses the top-k to select a small group (generally 3 to 6 subgroups) as the least redundant subgroups from the top-k list.
 Consider Only Local Maxima. Points that are close to each other in the dataset will generally have the same neighbors. When these examples are con-sidered as prototypes, they will have similar optimal qualities, since their optimal subgroups and reference groups will strongly overlap. Given a subgroup size  X  and a reference size  X  , we can compute the quality of the subgroup S ( x,  X ,  X  ) for each prototype x . In this way we can determine a quality landscape for our data. Within this quality landscape, we then look for local optima. To this end, we define the quality neighborhood q neighborhood ( x,  X ,  X  ), of a point x .Wedo this by considering the set X x  X  D of the  X  nearest neighbors of x .Foreach neighbor we determine the quality of its reference-based subgroup. These values form the quality neighborhood: q neighborhood ( x,  X ,  X  )= { q ( S ( x , X , X  )) | x  X  X x } , where q () is the quality measure on the subgroup. A prototype x is a local max-imum if its quality is maximal among its quality neighborhood: q ( S ( x,  X ,  X  )  X  max q neighborhood ( x,  X ,  X  ). Prototypes that are no local maximum are considered not interesting, and their subgroups will therefore not be reported. Post-processing the Top-k. There still may be some largely overlapping sub-groups and reference groups of prototypes in each others neighborhood that have only a slightly different value for  X  and  X  . Hence we employ redundancy removal techniques such as joint entropy and the exclusive coverage heuristic [5]. We select the combination of subgroups with the highest value for the heuristic. Distance-based methods can be computationally intensive. We use different prun-ing strategies to reduce the number of times the DFD has to be computed.
From all possible reference group sizes  X  for a prototype, we would like to report the optimal quality with the lowest p-value. To obtain p-values, we have to estimate the DFD. The estimation of all DFDs is computationally intensive (it requires O ( s X  ) calculations, where s is the sample size). In total there are n possible values of  X  so (if the DFD is not stored) it has to be recomputed n times for each prototype, where n is the number of examples. Computing the DFD is unnecessary for a subgroup that will not enter the top-k anyway. We present a user-set parameter and two pruning techniques to reduce the number of DFD calculations, and show the pseudocode.
Algorithm 1. Lowest p-Value for Prototype( db , x , q optimal ,  X  optimal ) Maximum Value for  X  . To decrease computation tim e, and ensure locality of Consider Only Local Maxima. We can check whether a point is a local max-Pruning the  X  -Search Space Based on Sample Size. To search efficiently We explain how this pruning strategy works step by step, by using the pseu-docode in algorithm 1. For each prototype we keep in memory a threshold on the quality, denoted by q threshold . We also keep in memory the optimal p-value that is found so far for this prototype, pval best . We are interested in finding the lowest p-value for this prototype. We start by calculating the p-value for a prototype for the maximal value for  X  in the first iteration.

Next, we observe the qualities found for the same prototype, for smaller values of  X  , in decreasing order. If the optimal qua lity found for such a smaller reference group, q optimal (  X  ), is lower than the threshold, we skip the estimation of the DFD and the calculation of the p-value, because we know the p-value will be lower. For smaller values of  X  that have a higher optimal quality, we compute the DFD. We also obtain the cumulative distribution function of the DFD,  X  DFD ,and the inverse cumulative distribution function,  X   X  1 DFD . From the DFD we obtain the p-value of the quality found. If the newly obtained p-value is lower than pval best , this subgroup is the best subgroup found so far. For this prototype x , the corresponding values for  X  optimal and  X  optimal as well as its quality q optimal , and the p-value are stored. The quality threshold is updated and is set to the quality corresponding to the new optimum. If the newly obtained p-value is higher than the one previously found on a bigger sample, these variables are not updated. The quality threshold is updated by inserting 1  X  pval best into the inverse cumulative distribution function of the DFD.
 Pruning the  X  Search Space Using a Top-k Approach. A subgroup only enters the top-k if its p-value is lower than the current maximum p-value in the top-k . The key idea (again) is to update the threshold each time the DFD is estimated. The only difference with pruning-per-prototype is that we can update the quality threshold by inserting the current maximum p-value of the top-k list into  X   X  1 DFD instead of inserting the minimum p-value found so far for this prototype, to obtain the new threshold. Artificial Data. We start by testing our method on the artificially generated data that already featured in the introduction (Figure 1). This two-dimensional data consists of 252 examples, with a roughly equal spread between positive and negative examples. 20 subgroups were obtained by considering each individual example in the data as a prototype, using Euclidean distance and WRAcc as quality measure. From these 20 subgroups, we select 3 non-redundant subgroups by using the exclusive coverage measure [5]. We compare the results with those of a  X  X raditional X  SD algorithm which features in the generic SD tool Cortana 1 . The traditional SD algorithm describes subgroups in terms of attribute-value descriptions.

The first subgroup discovered by LSD is also found by Cortana. In Figure 1 this corresponds to the big cluster at the top. The second subgroup, found in the lower left cluster in Figure 1, is not found using traditional SD methods, because there are many subgroups from the big cluster with the same size that also have a high proportion of positive examples. The third subgroup is situated in the lower right corner. This subgroup is not d etected with Cortana. This is because the density of the target variable in the subgroup is the same as the density of the target in the entire dataset, so the density of the target differs only locally.
In order to gauge the efficiency of our method and the different pruning op-tions, we generated datasets of various sizes, while keeping the original distribu-tion intact (all artificial datasets will be made available online). Figure 3 shows the influence of the different pruning strategies on the computation time. In gen-eral, a combination of pruning and local maxima offers the best performance, over an order of magnitude faster than either method alone. For comparison, the brute force approach at n = 200 takes 4,548 seconds, over two orders of magnitude slower (157.9 times) than the fastest result.
 We also observed the effect the local maxima pruning strategy has on the Subgroup Discovery results. If the local maxima strategy is not used, this will lead to the presentation of many redundant subgroups from the big cluster in the top. Each point in this cluster is then presented as an interesting prototype. Fraud Detection. Our health care application concerns fraud amongst den-tists. Each patient is represented by a bin ary vector of treatmen ts received during a year. The dataset contains 980,350 patients and 542 treatment codes. We use Hamming distance, and quality measure WRAcc. Note that because of the dis-crete nature of the data, there are many duplicate examples (many patients with identical treatments). Additionally, the distance of a point to different neighbors may be identical, which limits the number of values of  X  and  X  that need to be tested. We restrict  X  to a maximum of 10% of the data. We select a dentist with a markedly high claiming profile, and define the target accordingly. 5,567 patients (0.57% of the population) visit this dentist.

Table 1 shows the local subgroups found by our proposed method, LSD. These results were obtained after mining the top 50 subgroups first, and then selecting for diversity using the exclusive coverage heuristic. The interpretation for sub-group S1 is that for patients receiving a regular consult (C11, C12) and dental cleaning (M50), the dentist often charges extra costs for a plaque score (M31) and an orthopantomogram x-ray picture (X21). Also an anamnese (investigating the patients history, C22) is charged much more often for this group of patients. In subgroup S2, patients receiving a reg ular consult and a plaque score are oc-curring relatively more frequently than patients having only a regular consult without the plaque score (which are in the reference group outside the subgroup). In subgroup S3, codes X10 and X21 are x-ray pictures , and C13 means an in-cidental consult . Note that treatment C11 is not in the prototype, but still has a support of 77% in the subgroup and a support of 98% in the reference group outside the subgroup. We can conclude that this dentist charges relatively many x-ray pictures of type X10 with a regular or incidental consult. The qualities for the subgroups S1, S2 and S3 are 32, 15 and 14 standard deviations from the mean of the DFD, respectively, which results in p-values near zero.
 As a baseline, we compare the results using traditional SD in Cortana, using WRAcc, a search depth of 3 and beam search with beam width 100. We obtain the top 50 subgroups first, and then select for diversity using the exclusive cov-erage heuristic [5]. There are two subgroups that cover the other subgroups in the top 50: X21 = 1, and C11 =1  X  V21 = 1. Code X21 represents an orthopan-tomogram (x-ray photo), code C11 represents a consult , and code V21 is used for polishing a sealing . The subgroup sizes are 100,643 and 369,748, with 2,438 and 3,228 positive examples, respectively, which leads to a WRAcc of 0.0020, and 0.0014 respectively. The main difference between LSD and traditional SD is that the local approach presents locally deviating patient groups and provides information about the patient group X  X  neighborhood. The resulting subgroups are easier to evaluate by domain experts, and detailed enough to be investi-gated further by fraud investigators. The traditional SD approach returns global patterns that are not interesting or specific enough to trigger an action.
With our LSD algorithm, we were able to mine interesting subgroups in 5.5 hours in this dataset containing almost a million examples and over 500 at-tributes. The Cortana traditional SD algorithm took 24 minutes. Both were run on the same machine with 32 GB of main memory, and 8 cores. Although the runtime of the LSD approach depends on the dataset, and the parameter for the maximum value of  X  , this shows that the LSD approach is scalable to fairly big datasets.

We applied our method to compare pha rmacies as well as different type of dentists, also using other distance measu res like standardized Euclidean distance (in this case, the emphasis is on costs per treatment rather than combinations of treatments only). The results were presented to the fraud investigation depart-ment of an insurance company, and were considered very interesting for further inspection. The absence of  X  X heap X  patients in the reference group as well as the presence of relatively many similar, but more expensive, patients in the subgroup is very useful for indicating inefficient claim behavior. In this paper, we present a new approach to find local subgroups in a database. These local subgroups are very relevan t within a fraud detection application because systematically committed fraud leads to local distribution changes. In-spired by the fraud detection application, there are numerous directions to inves-tigate further. One promising direction will be cost-based Subgroup Discovery to find even more interesting subgroups. Instead of the distance-based approach, we can also investigate a more traditional, descriptive approach to find local subgroups.
 Acknowledgments. This research is financially supported by the Netherlands Organisation for Scientific Researc h (NWO) under project number 612.065.822 (Exceptional Model Mining).

