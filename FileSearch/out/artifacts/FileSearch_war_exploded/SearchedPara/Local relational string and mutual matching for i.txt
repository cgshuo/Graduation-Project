 1. Introduction
Digital acquisition of images occurred increasingly these recent years in widely different domains. Today databases contain a huge amount of visual information. Effectively indexing and searching images in a data-base remains a challenge. Text based indexing may have been useful in early days but shows today a limited performance mainly due to subjective interpretation and tedious human work. Conversely automatic tech-niques, computer vision based, offer promising perspectives in content interpretation except that interpretation requires programs to capture some semantics. Indeed, the latter programs piece usually two steps together: (1) extracting meaningful features to describe and summarize images (2) comparing the set of abstracting features, so called signature , to match images. Despite considerable research efforts actual realisations keep offering poor content based image retrieval (CBIR). Although many systems have been proposed so far, there is still a need of new methods and techniques to improve performances. The research reported in this paper addresses both steps of segmentation and matching, so let us begin in introducing main trends in the two problems to frame better our own work described in the sequel of the article. 1.1. Feature extraction
Most features deal with colour, texture and shape as visual attributes ( Carson, Thomas, Belongie, Heller-has been widely used in CBIR, for instance through the colour histogram considered as a joint probability of colour channels. Other colour descriptors in CBIR systems include the colour moments, the colour covariance matrix and the colour coherence ( Flickner et al., 1995; Pass, Zabih, &amp; Miller, 1997; Ravishankar, Prasad, Gupta, &amp; Biswas, 1999; Stricker &amp; Swain, 1994 ). Most colour spaces have been utilised such as RGB,
HSV, LUV, LAB ( Stricker &amp; Orengo, 1995; Worring &amp; Gevers, 2001 ). Even though colour attributes show averagely good discriminative ability, they fail in many cases describing objects or image regions. For instance a green table may share a common colour histogram with a green carpet or wall. Colour alone does not erty despite some lack of definition compared with colour. Texture provides key features for surface and object identification from natural photographs, indoor and outdoor scenes, satellite images, and many other types of which can be organised into four categories: statistical methods, structural methods, model based methods and transform-based methods. There is no obvious common definition of the texture phenomenon, it is gen-frequency distribution X  X  depending on the granularity (image resolution). This implies no common features can be defined for textures in general. For example the popular Grey Level Co-occurrence Matrix (GLCM) ( Hara-zig, 1990 ) define the joint probability that grey levels occur at a specific distance in given directions.
Geometrical methods study the spatial distribution of texture primitives and are often used for (pseudo) peri-odic structures Blostein and Ahuja (1989), Vilnrotter and Nevatia (1982), Voorhees and Poggio (1987), and
Zucker (1976) . Texture can also be modelled by Markov random fields (MRF) where it is defined as a stochas-assume that our human visual system projects a retinal image onto a spatial frequency representation ( Camp-
A signature can involve varied features at different abstraction levels. We can distinguish between two main approaches for features extraction, global and local approaches. In the first one features are computed over the whole image. The second decomposes images into several parts, then extracting visual features from each part. The latter approach is better adapted semantic-wise because scenes generally comprise several different entities. Local approaches need additional process to decompose the images into different parts. Segmentation is a natural way to deliver coherent regions, but it is often complex and results depend on both predetermined uniformity and scan-based decision criteria. Simpler processes merely divide pictures into regular blocks in order to capture some local information ( Chua, Tan, &amp; Ooi, 1997; Faloutsos et al., 1994 ). This technique is less precise for object detection than segmentation, but easier to implement.

We advocate for a texture description based on the distribution of intrinsic primitives. First elementary structures are extracted from a limited region around every pixel. Local properties will be enhanced by using spatial operators to compute a new image representation. Then the spatial arrangement of these structures is measured. 1.2. Image matching
As already mentioned, CBIR proceeds by two main phases: extracting a signature from every image thanks to low level operators and applying defined rules to compare images. The common ground for comparing images is to estimate their closeness in the feature space merely by computing conventional distances between feature vectors. A significant number of distances has been proposed and can be classified into four categories ( Rubner, Puzicha, Tomasi, &amp; Buhmann, 2001 ): heuristic histogram distances, non-parametric statistic tests, information-theory divergence and ground distance measures. Measuring a distance between global colour or textures statistics expresses similarity between features and may differ from visual similarity. Human sim-ilarity judgements remain hard to comprehend and, among other questions, do not obey the metric require-ment of symmetry ( Tversky, 1977 ). Typically, user X  X  image-understanding takes place at a higher semantic level than some primitive feature distribution assuming that an object is composed of segments with varying colour and texture patterns. Several works show more effectiveness when considering the image as a multi-component entity ( Carson et al., 1999; Ma &amp; Manjunath, 1999; Petrakis, 2002; Wang, Li, &amp; Wiederhold, 2001 ). As previously mentioned the concept covers the so called local approach. In case of query by single region, the similarity measure comes to that of the global approach since one distance between feature vectors is computed. The more interesting case of searching with multiple reference regions is more complex and does not depend only on feature vectors. The aim is to detect and match significant components of objects leading query and data base images as an assignment problem and solve it with the Hungarian Algorithm. An exten-sion is proposed in Weber and Mlivoncic (2003) where authors define a low cost and efficient method. It matches each region of a first image set with only one region of a second set in a (1:1) solution. The technique is thus very sensitive to segmentation errors and may fail even with a very good segmentation algorithm as in
Weber and Mlivoncic (2003) . The simplicity system ( Wang et al., 2001 ) uses the integrated region matching (IRM) algorithm to overcome such difficulties. It states that segmentation is an imperfect process in nature: any object can be over or under segmented, then yielding region variations between query and target images.
IRM allows one component of a given set of segments to match with multiple components of the other seg-ment set. Designing a satisfactory similarity measure, even in a restricted application field as CBIR, is still open problem. The human judgement of similarity is not well understood yet and appears subjective causing the semantic gap.

We advocate for a two-way comparison between subsets of bands, respectively extracted from images. The one to many tentative matches are generated and then ruled by a pairing process inspired from the  X  X  X table marriages X  X  paradigm and its preference lists.

To summarize, in this paper we propose a full methodology for image retrieval. Our feature extraction scheme is based here on spatial relationship between sets of pixels. A spatial operator applies at each pixel location, yielding a symbolic representation called motif or pattern. Then a global description via a multi-dimensional histogram is used to characterise the distribution of motifs. Images are decomposed into regular bands which the features are extracted from. Measuring the similarity between images involves graph match-ing. The proposed matching strategy is based on mutual preferences and comparison between elements of each part.

The rest of the paper is organised as follows. Section 2 details our method to extract features. Section 3 describes the retrieval scheme. Performances evaluation scheme is developed in Section 4 . Experiments and results are presented in Section 5 and the paper concludes in Section 6 . 2. Features extraction
Helpful features must indicate both similarity and dissimilarity between visual indexes. We focus here on texture attributes since texture is omnipresent in natural scenes and has excellent discriminative properties. to enhance local properties by having spatial operators transform the image into a new representation. The second step consists in measuring the spatial arrangement of such structures. Generally the features represent statistical as well as structural characteristics of the texture using some mathematical rule.
Several spatial operators exploit the relationship between pixels to encode the local texture ( Ojala, Val-kind of techniques operates generally on higher statistical order where the original data space is modified. Some evaluate quantitatively the relationship within a neighbourhood, e.g. grey level difference ( Unser, 1986 ). Others use more symbolic representations, through space filling curves for instance ( Jhanwar, Chaudh-explores the relationship in a local neighbourhood. 2.1. Local relational string 2.1.1. Relative relations
We can describe local dependencies in intensity thanks to comparison operators. Let g set S where I is a set of pixels and R represents a set of linguistic variables (equal to, less than, greater than).
We define the relationship between a central pixel and its neighbours as an ordered symbolic string called local relational string (LRS).

The example Fig. 1 yields the following chain:
This string is considered as a specific motif coding the relationship within a given neighbourhood. There are three relations for four points resulting into 3 4 possible motifs. We view LRS simply as a local operator suit-does not quantify the dependence between pixels. The comparative operator makes patterns more consistent under intensity changes. Consider for instance the central pixel as a black one with value 0, the string is the one description whatever the neighbour intensities. Actually we do not extract here usual patterns like corners or edges, LRS models the neighbourhood by discarding contrast as it depends on the grey scale. A multi-scale recognition of the texture is correlated to the scale at which we extract primitives. In order to ensure a good description and feature extraction we analyse local relations at the different scales. The multiresolution anal-ysis can be completed by combining local relations at different distances from a central pixel. The local binary pattern (LBP) method ( Ojala et al., 2002 ) defines a circular neighbourhood where the radius determines a spe-cific scale; the number of neighbours is proportional to the values of the radius. We adopt the same concept to include several resolutions in the process. In contrast with LBP the number of neighbours is constant indepen-dently of the radius, this reduces the combinatorial complexity. Fig. 2 describes an example which includes neighbours at the third-order scale. The radius d has respectively values 1, 2 and 3 pixels. By varying d we can obtain LRS at any scale and multiresolution analysis can be performed by combining information pro-vided by the LRS operator. Let be X d  X f g d 1 ; g d 2 ; g mula of the local relations is given by: for one point depends on the desired resolution. The distribution of motifs is computed separately at each scale.

Some works show that an histogram over primitives representing local properties as grey level differences or the image the LRS operator is applied to extract an appropriate motif. In our case we compute histogram to measure the distribution of local relations. As described previously three symbols are used to represent four
To incorporate the multiresolution information the LRS histogram is computed at each scale resulting into a d dimensional histogram. The complexity increases with the number of spatial resolutions involved. However adding more information about resolution does not necessarily lead to better performances. There exists an optimal value of d . Experiments show that d = 3 realizes a trade off for our application. Given X the marginal distribution (histogram) with respect to the chosen radius d as
By using a multi-dimensional histogram over local relational strings we define a discrete density function where each value of the random variable represents a joint probability of specific neighbourhood interactions.
Two textures are considered similar if their joint distributions are close enough. Here, an histogram concat-enation assumes the different spatial scales to be independent. Under this assumption the distance is simplified to the sum of distances between the corresponding histograms at each scale as shown in Eq. (5) . 2.1.2. Illumination invariance
The problem of the lighting variations has been addressed for the last decade, but there is not a solid model for textures that provides illumination-invariant features. At each location a monochromatic image intensity g can be expressed by: ous that the change in illumination does not change the texture content and hence should not change texture features. Let us consider two textured images under different illuminations. The images are respectively acquired under illuminations with spectral distribution I ( k ) and I scribed by Healey and Slater (1997) : where M is a coefficient depending on the illumination change, not on the illumination itself. The relations Q 2 R between two locations i and j are then As M is independent from g 0 we obtain: In result: Let H LRS ( g ) denote the LRS histogram with illumination I and H
As the relation is not affected by the illumination model, the motif does not change and therefore the histo-grams stay invariant in both cases:
Comparing with the histogram of the grey level differences (GLD) the latter is not consistent under illumina-tion changes because g i g j  X  M  X  g 0 i g 0 j  X  , the pixel attribute depends on the illumination itself. 3. Image retrieval
Visual features alone are not enough to distinguish between images. Using colour, texture or other attri-butes they might be deemed similar although semantically be completely different. On the other hand no semantics could be derived if not building on visual features. The problem of achieving acceptable semantics is to describe higher level abstractions. One of the most important vector of semantic retrieval then resorts to scene entities. Partitioning an image into several parts could help understanding its content, thus contributing to meaningful analysis. 3.1. Regions selection
Images are divided into horizontal and vertical blocks. That makes a simple way to capture essential parts of objects without any real segmentation. Bands offer the advantage of maintaining some partial context from the picture. They isolate significant elements of the scene thus making it easier to match between images. For instance the image of Fig. 3 is equally divided into four horizontal and vertical blocks. The bands are well adapted in that case as the main part of the bus is included in the second and the third horizontal blocks ( h 2 , h 3 ), and h 1 contains the top of buildings while h 4 ful information too, for example the second vertical block ( v profit by the implicit semantic all blocks must be compared and results combined into a global similarity mea-sure. In the next section we describe the matching strategy to using the partition-structure. From here, let us refer to bands or blocks as regions in the image. 3.2. Similarity measure
Multi-region matching involves all image segments for the maximum number of query segments to match with the maximum number of target segments. When matching a single element the similarity measure depends only on a distance in the feature space. A multi-region approach requires similarity estimation through some global criterion, possibly a distance again, over all components. This criterion achieves a trade off between the number of matched regions and the similarity degree within each couple (region query, region database). Similarity increases with the number of close enough couples in terms of distance. For instance searching a scene that contains sky, beach and forest together, priority should be given to those images with the three types of region then to those including only two and so on. 3.2.1. Mutual matching
A bipartite graph G =( V , E ) is an undirected graph whose vertices are divided into two disjoint sets Q and B ( V = Q [ B and Q \ B = / ). Edges link the sets in such a way that no edge connects vertices in the same partition E  X  A  X  B . Let be Q : f Q  X f R i g M 1
R [ R 0 2 [[ R 0 N g respective sets of regions or blocks in the query and database images (see Fig. 4 ). Let be s ij a weight assigned to an edge between Q and B , where s M and N, respectively can be represented by its weight matrix with size M  X  N .

S is called the similarity matrix. This array makes an adequate representation of the coincidence between Q and B . Each row ( i ) informs about the similarity between one element R case the minimum distance coincides with the best match in the target image. Conversely, each column ( j ) indi-cates the similarity between one segment R 0 j of B and all components of Q . Also the minimum distance in one column indicates the most similar query region ( R k ) independent of any R B and B to Q , a preference list can be extracted for each segment: it contains elements of the other set ranked actions between different elements of the query and database images. They provide more abstract information for similarity evaluation. Table 1 shows an example of the preference list structure.

This representation leads naturally to an optimisation problem according to the model of stable marriages mates would mutually prefer each other to their current spouse. In general this kind of algorithm does not allow multiple matching. Moreover, segmentation artifacts may hamper the global satisfaction of stable matching. Indeed, according to the algorithm by Gale and Shapely, if one element is not preferred by its part-weighting the intra-distance of couples. One segment may show a minimum distance in one sense (rows or columns) but not in the opposite one. It does not mean that this segment is any best match. To enforce the ment by the other segment, again a stable matching fashion. Here couples get not married right away, they are given more importance when they prefer mutually.
 of the matrix S . Let be p i the rank of R i in the preference list of R the preference index, a decreasing function of the preference. It is constant for elements with the same pref-erence degree.
Let be min i and min j the minima in terms of distance along the row i and column j , respectively. We use a weighted Chamfer distance to compute the global cost function.
 where weights c j and c j depend on the preference rank. empirically the value 0.1 proves to be a good trade off.

The distance U expresses the global similarity between two images from both the most similar components and the mutual preference. 4. Performance evaluation
Performance evaluation is an essential task in content based image retrieval ( Muller, Muller, Squire, Marc-hand-Maillet, &amp; Pun, 2001; Smith, 1998 ). However evaluation of CBIR systems is peculiarly difficult. Images are very complex carriers of information. Thus benchmarks are likely user and application dependent not to forget the semantic gap between user X  X  image-understanding and the low level image representation by the machine. In CBIR there is not yet a common judgement of the relevance bound to queries. Because evaluating
A very common technique is to use predefined subsets according to different topics such as in the Corel col-lection. Images in this database are organised into groups, about 100 images each, dealing with an alleged  X  X  X ame X  X  topic in a common sense: Africa villages, elephants, beaches, old trains, race cars, ... are examples.
However the relevance between images is not restricted to the predefined subset, two images from different subsets can be very similar even though they do not belong to the same topical group. For instance the
Bus subset contains exclusively buses, but they can be found in other context (e.g. downtown) as well. There-fore it is more reasonable to consider the similarity over several subsets. The performance evaluation proposed by Liu, Su, Li, and Zhang (2001) provides an acceptable ground truth. They divide 10,000 images into 79 semantic classes, for relevance of which nine annotators have participated in the labelling. This method pre-sents the advantage that the ground truth is labelled by a similarity degree varying between 0 and 1. This per-mits to use several similarity degrees when evaluating our method. Further more we trust the TrecEval method to compute the recall and precision indexes, mean average precision (MAP) and other statistics.
For our experiment we have used the MAP since the ground truth does not provide all relevant images, there-fore the recall measure is not significant.

The ground truth file is transformed into the TrecEval format thereby choosing a threshold in [0.1, 1] for the similarity degree. The binary annotation being assigned to the ground truth (relevant (1)/not relevant (0)) as it is required for TrecEval. 5. Experiments and results Experiments are conducted over 60,000 Corel images in the JPEG format with size 384  X  256 or 256  X  384.
In order to have a good evaluation of our method we have used several colour spaces. Two additional colour spaces HSV and Lab are extracted from the original one RGB. To obtain a significant evaluation we select randomly 33 ground truth pictures. The results reported in these experiments are the average over all the 33 images. All tests have been done in the same conditions to guarantee result coherence.

Each image from the collection is split into N horizontal and N vertical bands (blocks), four values of N have been tested: N = 1, 2, 3, 4. Features are extracted for each block then stored in the database which is used for comparison between query and target images. The size of the similarity matrix (Eq. (12) )is 2 N  X  2 N , the parameter K of (Eq. (15) ) is set to 0.1. We compare LRS method with colour histogram (HIST), colour co-occurrence matrix (CCM) and colour moments (CM). To evaluate the better distance for these tech-niques we use two types of distances appropriate to such kind of feature. It consists in the Euclidean distance and the histograms intersection. CCM and CM are based on statistics measures, histogram intersection is not appropriate for their features vectors. We use only the euclidean distance in that case. For LRS and histogram we can use both distances, but histograms intersection is more interesting. The comparison strategy between images is described in Section 3.2 .

Parameters of the algorithms are set as follows:  X  HIST is the standard histogram.  X  LRS is computed with radius d = 3 except in Section 5.1 .  X  CM, three moments are used l 1 , l 2 and l 3 . Their weights are set to 1.  X  CCM, for the orientation between two pixels involved in the grey level occurrence h =0 ,45 ,90 , 135 .
The spatial distance a of the occurred pixel is a = 1. Seven features have been extracted from the joint histogram.

Table 2 illustrates an example of some measures of TrecEval. Here, ground truth images are considered relevant to the query topics if annotated greater than 0.7. The efficiency is proportional to the MAP value.
This value depends essentially on the rank of retrieved documents. In the next experiences the similarity anno-tation threshold is set to 0.9 which allows to obtain a dependable judgement for relevant images. A compar-ison for different values of this threshold is reported in Section 5.4 . 5.1. Influence of the neighbourhood size
In this section we test the influence of the parameter d of our LRS method. As described in Section 2.1.1 it defines a set of neighbours involved in the LRS computation. The number of neighbours is proportional to the value of d . Fig. 5 shows results obtained in the HSV space for different values of d and where LRS is computed can see that d = 5 is the optimal value. Increasing the neighbourhood size does not necessarily improve the retrieval precision. The MAP of d =3, d = 5 and d = 7 are very close it is more advantageous to use d =3 since computation and storage costs are lower. For the next experiments the value of d is then fixed to d =3. 5.2. Influence of the colour space
To study the influence of the colour space, we test two approaches: (1) considering the three original planes where features are computed for each plane, then concatenated into one vector (2) quantising the colour space where the features are computed for one plane (greyscale). The following scheme for colour quantisation is shown in the Table 3 express the percentage of MAP (mean average precision) for the different methods. Images are divided into three horizontal and vertical bands. The Euclidean distance was employed for CM and CCM, the histogram intersection for LRS and HIST techniques. For three image planes LRS shows better perfor-mances unlike for the quantified space, here colour histograms do better. Comparing the whole results, we can notice that LRS gives the best scores with HSV and Lab spaces. The quantified RGB is the appropriate space fort the colour histogram. CM and CCM show least scores. Their advantage should be the distance com-puting time since the size of the feature vector is small, but they need overall longer processing time. 5.3. Influence of the number of bands
The goal of the present test is to study the impact of the splitting method. Dividing the image into N parts purpose images are split into N horizontal and N vertical stripes ( N  X  N ): N =1,2,3,4. N = 1 represent the whole image. Fig. 6 shows results with the MAP percentage. Analysing RGB, HSV and Lab spaces we can see that LRS provides the best scores. For three plans the performances of LRS and CM features increase with the number of the horizontal and vertical blocks. CM technique is less sensitive to this number. However HIST method shows better performances in quantified space. Here the number of bands improves the score of HIST peculiarly on RGB. We can notice from these tests that slicing images into bands improves the retrieval per-formance with regards to the global approach. However one expects performances degradation after a certain number of blocks. 5.4. Influence of the human similarity appreciation
In order to study the impact of the human similarity judgement, we compute the MAP values of the thresh-old sim . Thirty-three query images are used for each sim value. Fig. 7 shows the performance of HIST, LRS, CM and CCM function of sim . We have chosen the HSV space with a 3  X  3 splitting process. We notice the similarity annotation. Obviously a high value of the similarity degree reduces the number of relevant images, yielding very close images in the perceptual space. 6. Conclusion
In this paper we have presented a technique for image retrieval using LRS for a cue and mutual region matching for the similarity measure. LRS was shown to combine local information with global description to both colour and texture characterisation. Despite high discriminative properties LRS alone does not com-plete efficient image retrieval. We have developed a method for measuring an overall similarity between images. The mutual matching scheme is based on a region comparison that incorporates the way regions pre-fer each other. The application of our technique to a database of about 60,000 general-purpose images shows good performance of CBIR. We have studied the influence of the pertinence judgement by examining the ground truth with different similarity annotations. As a general future research trend we test different prop-erties of the proposed approach to be added aiming at better accuracy.
 References
