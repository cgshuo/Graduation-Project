 Aspect-oriented opinion mining detects the reviewers X  senti-ment orientation (e.g. positive, negative or neutral) towards different product-features. Domain customization is a big challenge for opinion mining due to the accuracy loss across domains. In this paper, we show our experiences and lessons learned in the domain customization for the aspect-oriented opinion analysis system OpinionIt .Wepresentacustomiza-tion method for sentiment classification with multi-level la-tent sentiment clues. We first construct Latent Seman-tic Association model to capture latent association among product-features from the unlabeled corpus. Meanwhile, we present an unsupervised method to effectively extract vari-ous domain-specific sentiment clues from the unlabeled cor-pus. In the customization, we tune the sentiment classi-fier on the labeled source domain data by incorporating the multi-level latent sentiment clues (e.g. latent association among product-features, domain-specific and generic senti-ment clues). Experimental results show that the proposed method significantly reduces the accuracy loss of sentiment classification without any labeled target domain data. I.2.7 [ Artificial Intelligence ]: Natural language process-ing X  text analysis Algorithms Experimentation Opinion mining, Sentiment classification, Supervised learn-ing, Domain customization Opinion mining is a critical task in business intelligence. In many applications, simply judging the overall sentiment orientation of a review is not sufficient. Reviewers usually praise some aspects of the product and complain about other aspects. Hence, we built an aspect-oriented opinion min-ing system OpinionIt [5], which detects the reviewers X  sen-timent orientation towards different product aspects using the sentence-level sentiment classifier. The sentiment clas-sifier often losses accuracy if the single sentiment clue en-countered in the sentence was not learned by the system. It usually requires amounts of labeled target domain data to tune sentiment classifiers in the domain customization. However, annotating a large-scale corpora for each domain is impractical. Some domain customization methods have been proposed for document-level sentiment classification[2, 6, 7]. Blitzer et al. [2] employ structural corresponding learning to infer generalized feature representation across domains. Li et al. [6] transfer common lexical knowledge across domains via matrix factorization technique.
In the domain customization for OpinionIt ,wepresenta customization method for sent ence-level sentiment classifi-cation with multi-level latent sentiment clues (MLSC). It is a more challenging task since review sentences usually are short text with sparse sentiment clues. We overcome the data gap across domains using multi-level latent sentiment association among product-features and opinions. We con-struct a latent semantic association (LaSA) model to cap-ture latent association among product-features from the un-labeled corpus at first. LaSA model groups words into a set of semantic concepts according to their syntactic and seman-tic context in the reviews. Meanwhile, we present an unsu-pervised method to effectively capture the domain-specific sentiment clues from the unlabeled corpus. In the domain customization, we tune the sentence-level sentiment classi-fier by integrating multi-level latent sentiment association among product-features, domain-specific and generic senti-ment clues. Experimental results show that the proposed MLSC-based customization method significantly enhances the performance without any labeled target domain data.
The reminder of this paper is organized as follows. Section 2 presents domain customization method with multi-level latent sentiment clues. Section 3 discusses the experimental results. The conclusion is given in Section 4.
In order to reduce the accuracy loss in the domain trans-fer for aspect-oriented sentiment classification, we present a customization method with multi-level latent sentiment clues. It effectively overcomes the data gap across domains.
It is hard for supervised approaches to obtain enough labeled data to illustrate all the features of the domain. Product-features and various sentiment clues significantly impact the performance of the aspect-oriented sentiment classification. Hence, we integrate the multi-level latent sen-timent association among product-features, domain-specific and generic sentiment clues in the model customization.
People often use various terms to refer to the same product-feature in the reviews. In aspect-oriented sentiment analysis, we present LaSA model to capture latent association among product-features from the unlabeled corpus. LaSA model effectively augments training data in the learning.
We construct LaSA model  X  for words using the algorithm presented by Guo et al. [4]. We first construct the virtual context document vd x i for each word x i from the unlabeled corpus. The weight of each context word in vd x i is calcu-lated using Mutual Information (MI) [3], and is normalized to non-negative. Then, LaSA model  X  with Dirichlet dis-tribution is generated on the virtual context document set VDSet using LDA [1]. In LaSA model learning, vd x i is composed of all the context units around the word x i in the corpus. For example, given x i =  X  X oom X  , s k =  X  X his new hotel is very good because its room is very large and clean X  .In the context window { -3, 3 } (i.e. previous 3 words and next 3 words around x i in s k ), the context feature set F ( x around  X  X oom X  in s k includes: 1) the current word: x i ( room ); 2) left/right opinion sets (i.e., two left/right adjacent adjec-tive units): O L ( good ), O L ( new ), O R ( large ), O R the nearest left/right adjacent units: A L ( its ), A R ( is ); 4) the other two left/right adjacent context unit sets: C L ( because ), C L ( good ), C R ( very ), C R ( large ).
 Table 1: Latent topics of some words in hotel domain
LaSA model learns the posterior distribution to decom-pose words and their virtual context documents into top-ics. It better captures the semantic category distribution of words without any labeled data. Table 1 shows some la-tent topics generated by LaSA model  X  . As shown, words in the same topic actually are grouped into broad aspects. For example, topic 4, 12 and 16 are related to the aspects environment , location and shopping , respectively.
In the sentiment classification, we generate latent topics for the words in product-features using LaSA model  X  .In  X  , the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all the virtual context docu-ments. Given a word w i in the product-feature in the review, we may perform posterior inference to determine the condi-tional distribution of the hidden topic variables associated with w i . Algorithm 1 describes w i  X  X  latent topic generation, where, Mult(  X  ( vd i )) refers to sample from the posterior dis-tribution over topics given a virtual document vd i .
Algorithm 1 : Generate latent topic for w i using K -topic LaSA model
Sentiment classifiers often loss accuracy in the domain cus-tomization due to unknown target domain sentiment words. In order to reduce the human efforts, we iteratively build domain-specific sentiment lexicon from the raw corpus. Table 2: Domain-specific sentiment clue samples
We first group all the sentences into positive , negative and neutral subsets according to their sentiment polarity. Each sentence X  X  polarity is detected according to the ratio of its positive and negative opinion words. The sentiment lexi-con is initialized with the public generic sentiment lexicon. Given a n-gram (1  X  n  X  3) word sequence x i .Let F pos ( x and F neg ( x i ) be the frequency of x i in the positive and neg-ative sets, respectively. The difference between F pos ( x F neg ( x i ) is calculated by Equation 1. If diff &gt; 1, then the frequencies are not similar. We consider x i as a validate sentiment clue with enough sentiment distinguishing power. In counting occurrences, if an item is preceded by a negation, its count in the oppositive corpus is increased by one. We iteratively build the domain-specific sentiment lexicon using the clues with higher sentiment scores ( | score | X  0.5 in the experiments). The sentiment score is calculated according to its distribution difference in both sets using PMI [9]. Table 2 shows some sentiment clues extracted from hotel reviews.
In order to minimize the efforts for customizing aspect-oriented sentiment classification, we present a MLSC-based customization framework to bridge the data gap across do-mains. Figure 1 shows MLSC-based domain customization framework in OpinionIt . In the domain customization, we first construct LaSA model  X  to capture the latent associa-tion among product-features from the unlabeled source and target domain data. Latent topics of product-features are inferred using  X  . Meanwhile, we extract domain-specific sen-timent lexicon from the unlabeled source and target data. Then, the multi-level sentiment clues are extracted from the source training data by leveraging the domain customiza-tion resources. Finally the original sentiment classifier is tuned on the source training data by incorporating multi-level latent sentiment clues. The proposed customization framework may reduce the number of parameters required to model the target domain data. It can also improve the quality of the estimated parameters in the domain transfer. Figure 1: MLSC-based domain customization framework in OpinionIt
In the domain customization, each sentence s i is char-acterized by the following multi-level latent sentiment clue (MLSC) set.  X  Bag of non-stop words ( BOW );  X  Generic sentiment clue set ( GSC ): 1)Generic sentiment words; 2)The numbers of the positive/negative words; 3) Negation words ( NW ) and negation tag ( NT );  X  Domain-specific latent association clue set ( DLAC ): 1) Latent topic set ( TP ) of the headwords in product-features; The headword is defined as the last word in the term. 2) Candidate opinion word set ( OW ) which composed of all the adjectives in s i ; 3) Co-occurrence relation set CR ( TP,OW ): all co-occurrence pairs of TP k and OW j in s i ;Intheaspect-oriented sentiment classification, DLAC is employed to char-acterize latent association among product-features and opin-ion words in s i . CR ( TP,OW ) provides useful hints for de-tecting the dynamically sentiment polarity of opinion words (e.g.  X  high  X ,  X  low  X ,  X  small  X ,  X  large  X ). For example, according to the modified product-features,  X  high quality  X  is positive while  X  high consumption  X  is negative.  X  Domain-specific sentiment clue set ( DSC ): 1) Domain-specific sentiment word set; 2) The number of domain-specific positive/negative words; 3) Overall sentiment distribution orientation of the sentiment words.

We employ Robust Risk Minimization classification method [10] to learn sentence-level sentiment classifier. In the mod-elling, the feature vector for each sentence is constructed with its MLSC set. The weight of each feature is calculated by MI [3]. Since negation clues NW , NT and the sentiment orientation have higher influence on the sentiment polarity of the sentence, we further multiply them by a predefined parameter  X  (  X  =5 in the experiments). This allows us to bias the learning algorithm so that the more relevant feature components have higher influence on the system decision.
In this section, we measure the efficiency of the proposed techniques on large-scale English and Chinese review corpus in Autocar (Aut), Hotel (Hot) and Movie (Mov) domains. We quantify the benefits of MLSC-based model in the cross-domain and in-domain sentiment classification. Training data is always an important concern in supervised learning methods in the real applications. Hence, we also investigate the effects of MLSC-based model on the size of training data. English and Chinese reviews (totally 680,361 words) for Hotel and Autocar domains are extracted from several popu-lar web sites. The sentiment polarity (i.e. positive, negative, neutral) of each review sentence is tagged manually. We also employ the public annotated English movie review corpus made by Bo Pang [8], which consists of only positive and negative sentences. In the experiments, we randomly held out around 20% data for test, and trained the classifiers on the remaining parts. In MLSC-based domain customization, we tune the sentiment classifier on the source domain train-ing data with MLSC sets. Since most of product-features are noun terms, we extract 1  X  3 continuous nouns from the corpus as product-feature candidates. All the LaSA models are built from the unlabeled source and target domain data. The number of topics is 100, and the context window size is { -3,3 } . The hyper-parameters  X  is 0.1 and the number of iterations is 1,000.

Table 3 shows the experimental results for all the pairs of domain customization on English and Chinese corpus. Here, {
Aut , Hot , Mov } are English domain-specific data sets while {
ZAut , ZHot } are Chinese data sets. In the experiment, the basic source domain sentiment classifier SA s is learned from the specific domain training data set D dom . SA s employs only the bag of non-stop words. Here, dom  X  X  Aut , Hot , Mov , ZAut , ZHot } . M-Base directly employs SA s in a new target domain, its F-measure in this basic transfer is con-sidered as baseline (denoted by F base ). F in dom denotes the F-measure of the in-domain basic sentiment classifier, which is considered as top-line. In the domain customization, M-MLSC integrates all the multi-level sentiment clues while M-GSC integrates only the bag of non-stop words and the generic sentiment clues.  X ( F )and X ( loss )denotetheper-centage change in F-measure and accuracy loss of M-MLSC or M-GSC over M-Base . The accuracy loss loss =1  X  F F in Table 3: Performance enhancement of M-MLSC and M-GSC over M-Base in the domain transfer.
Experimental results show that M-MLSC effectively en-hances F-measure and reduces the accuracy loss in all the domain transfers (see Table 3). Compared with M-Base , M-MLSC significantly enhances F-measure by 9.25% and reduces the accuracy loss by 83.00% in average. M-GSC en-hances F-measure by 5.84% and reduces the accuracy loss by 52.31% in average. Compared with M-GSC , M-MLSC fur-ther improves F-measure by 3.23% and reduces the accuracy loss by 37.17% in average. In MLSC -based customization method, latent topics and domain-specific sentiment clues provide very important hints for overcoming the domain difference. Even though word instances do not appear in a training corpus (or appear rarely) but are in similar con-text, they still might have relatively high probability in the same concept set and similar sentiment distribution. Figure 2: Effects of multi-level latent sentiment clues on in-domain sentiment classification
We also investigate effects of multi-level sentiment clues on in-domain sentiment classification (see Figure 2). In the experiments, the sentiment classifiers are trained on the in-domain training data. In the MLSC set construc-tion, LaSA models and domain-specific sentiment lexicons are pre-constructed from the unlabeled in-domain data. Ex-perimental results show that M-MLSC reduces much more errors than M-Base and M-GSC in the in-domain sentiment classification. Compared with M-Base , M-MLSC reduces more than 7% errors on English reviews, and more than 16% errors on Chinese reviews. All the multi-level sentiment clues make a good impact on the performance enhancement.
Training cost is a bottleneck for supervised learning meth-ods since lots of manual efforts are required in tagging the instances. Hence, we compare the training efforts used in in-domain sentiment classification. Experimental results show that M-MLSC obtains much better performance with much less training data. Compared with M-Base , M-MLSC signif-icantly reduces the labeled data size by 67.96% in average. Compared with M-GSC , M-MLSC also significantly reduces the training data size by 15.87% in average.

All the above experimental results show that M-MLSC better approximates the underlying data distribution by in-corporating latent topics, domain-specific and generic sen-timent clues. Especially, with latent topics, the model is no longer restricted to whether or not it knows a word; it now can know something about the concept group to which a word belongs, even if it does not know the word in the application. Hence, M-MLSC can customize the sentiment classification model more quickly with less efforts.
Domain customization is a big challenge for aspect-oriented sentiment classification. Supervised classifiers usually re-quire large-scale labeled training data due to the limited sentiment clues in the review sentences. Hence, efficient and robust customization method is very important in the real applications. In the domain customization for the aspect-oriented opinion analysis system OpinionIt ,wepresenta MLSC-based customization met hod. It effectively overcomes the domain difference without any labeled target domain data. Experimental results on English and Chinese corpus show that the proposed method significantly reduces the ac-curacy loss in the domain t ransfer. Compared with M-Base and M-GSC methods, MLSC-based customization method significantly reduces the accuracy loss by 83.00% and 37.17% in average, respectively. Moreover, MLSC-based model also significantly enhances the performance of in-domain senti-ment classification with less training data. Compared with M-Base and M-GSC , MLSC-based method respectively sig-nificantly reduces the labeled data size by 67.96% and 15.87% in average. All the experimental results indicate that the proposed MLSC-based customization method better approx-imates the underlying data distribution by incorporating latent topics, domain-specific and generic sentiment clues. Given the encouraging results, we believe that the proposed approach is effective for practical aspect-oriented sentiment classification customization problems. [1] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [2] J. Blitzer, M. Dredze, and F. Pereira. Biographies, [3] K. W. Church and P. Hanks. Word association norms, [4] H. Guo, H. Zhu, Z. Guo, X. Zhang, and Z. Su. Product [5] H. Guo, H. Zhu, Z. Guo, X. Zhang, and Z. Su.
 [6] T. Li, V. Sindhwani, C. Ding, and Y. Zhang.
 [7] S. J. Pan, X. Ni, J. Sun, Q. Yang, and Z. Chen. [8] P. Pang and L. Lee. A sentiment education: Sentiment [9] P. Turney. Thumbs up or thumbs down? semantic [10] T. Zhang, F. Damerau, and D. E. Johnson. Text
