 JUNE-JEI KUO and HSIN-HSI CHEN National Taiwan University 1. INTRODUCTION Owing to the widespread use of the Internet, large-scale multicultural and multilingual information can be obtained simultaneously by computer users despite geographic differences. In this information exploration era, how to filter out useless information, and how to absorb and employ information ef-fectively, becomes an important issue for users. Document summarization, which aims to create a short version of the original documents, is indispens-able yet presents a challenge. Summarization systems can be divided into two categories: (1) single document summarizers [Kupiec et al. 1995; Lin and Hovy 1997; Hovy and Marcu 1998; Brunn et al. 2001], and (2) multidocument sum-marizers [Barzilay et al. 1999; Chen and Huang 1999; Radev et al. 2001; Chen et al. 2003a; Lin and Hovy 2002; Lapata 2003; Filatova and Hatzivassiloglou 2004b; Okazaki et al. 2004; Sakurai and Utsumi 2004; Lee et al. 2005].
Multidocument summarization systems can be viewed as augmented single-document summarization systems, but they must further cope with the issues of redundancy, collocation, sentence ordering, etc. Recently, most researchers for automatic summarization have transferred their efforts from single docu-ments to multiple documents. Furthermore, some researchers have refocused their efforts from monolingual multidocument summarization to multilingual multidocument summarization [Chen and Lin 2000; Chen et al. 2003a; Evans and McKeown 2005].

A typical multidocument summarization system may be composed of two kernel components, that is, event clustering and sentence clustering. The for-mer touches on document-level similarity, and the latter determines sentence similarity as well as dissimilarity. Consider a multinews summarizer [Chen et al. 2003b] as an example. A news clusterer receives news streams from multiple online news sites, and directs them into several output news streams according to the reported events. An event is denoted by five basic entities such as people, affairs, time, places, and things. After clustering, the news articles for the respective event are summarized by a news summarizer (including sen-tence clustering and selection). Figure 1 demonstrates an example of three consecutive sentences in a summary generated by this system.

The example in Figure 1 highlights several challenging issues to be considered. (1) Semantics issue. To deal with synonyms, we must identify polysemy and term dependency to avoid redundancy and select salient sentences for sum-mary generation. (2) Alias of named entities. The expression of an entity in a document may be different from the expression of the same entity in another document. For example,  X  * / c  X  l  X  (Asia Pacific Harbor Engineering Company Lim-ited) has an alias  X  * S  X  l  X  . Similarly,  X  a  X  S  X  l  X  (Global Industry, Singapore) also has different expressions such as h l  X  and  X  l  X  . Unification of named entities is necessary to avoid decreasing the performance of sentence clustering. (3) Coreference resolution. Two pronouns may or may not denote the same entity. Both pronouns  X  (they) in sentence 2 refer to the same entity
 X   X  (Aviation Safety Council). Without coreference resolution, the weight of  X   X  (Aviation Safety Council) is underestimated, and the performance of sentence clustering may be affected accordingly. (4) Temporal resolution. The extracted sentences in a multidocument sum-mary usually come from different documents. The same temporal expressions may denote a different time or date in two documents, for example, ( ) (yesterday) in sentences 1 and 3. That difference may confuse readers. (5) Sentence order. As the extracted sentences were ordered chronologically, the problems of cohesion and coherence were not addressed. The readability may be affected. (6) Information coverage. When an extracted sentence contains superflu-ous information, more sentences may not be included due to length limitation. That may affect information coverage.

In this article, we introduce latent semantic analysis to address the seman-tics issue in sentence selection. Different features such as informative words and event words are employed to construct a word-by-sentence matrix. As our summarization objective is print Chinese news, we propose a Chinese temporal resolution algorithm using focus time and coreference chains. In addition, we use informative words, event words, and temporal words, to keep important phrases in a summary and to remove extraneous clauses. Instead of publi-cation date, we use a sentence time (date) to order the extracted sentences for multidocument summarization. To address the fine-grained sentence time issue, we also propose a temporal resolution algorithm using focus time and coreference chains.

This article is organized as follows. Section 2 presents the architecture of our proposed summary generation system. In Section 3, the Chinese tempo-ral resolution algorithm using focus time and coreference chains is specified. Event extraction and noun phrase (NP)-chunking using a web corpus are spec-ified in Section 4. Then, we describe latent semantic analysis for sentence se-lection in Section 5. Section 6 presents sentence reduction using event words, informative words, and temporal words; sentence ordering using sentence time (date) is also described. Section 7 reports and discusses our experimental re-sults. Section 8 concludes the discussion. 2. SYSTEM ARCHITECTURE OF A NEWS SUMMARIZER Figure 2 shows the system architecture of our proposed news summarizer (summary generation system). First, we use the output of event clustering we previously proposed as the input of the news summarizer [Kuo and Chen 2007]. We also proposed a metric of normalized chain edit distance to mine, in-[Kuo and Chen 2007]. Take  X   X   X   X  (Peng Hu) as an example. Its synonyms such as  X   X   X  (the abbreviation of Peng Hu),  X  V # (Peng Hu Prefecture), and  X   X  (Island of Chrysanthemum) can be mined automatically. The head word  X  V (Peng Hu) is treated as an authorized term to unify the synonyms among documents. Through the controlled vocabulary mined with the nor-malized chain edit distance algorithm, the named entities in the documents are unified. In the Chinese-temporal-processing module, the temporal expres-sions in each sentence are resolved using a temporal tagger, specified later in Section 3. Moreover, the final focus time of each sentence is considered as the sentence time (date), which will be used in sentence ordering.

In the informative-words-and-event-extraction module, the informative words of each document are identified using an algorithm specified later in Section 5.2. Moreover, we propose an NP-Chunker using the Web corpus in that module and use NP-V-NP patterns to extract the related atomic events, which are represented as 3-tuples, that is, (entity 1 , verb, entity 2 ). The atomic events are useful to extract the related event words in a document. Besides the event words, we use informative words along with their corresponding frequen-cies to construct a word-by-sentence matrix and conduct the latent semantic analysis. Next, in the sentence-reduction-and-summary-generation module, sentences are sorted according to their importance. The length of each sen-tence is reduced using informative words, event words, and temporal words. The reduced sentences are extracted sequentially until the length limit is met. Finally, we use the sentence time (date) to order the extracted sentences. 3. RESOLVING CHINESE TEMPORAL EXPRESSIONS Because the same temporal expressions  X  for example yesterday  X  in differ-ent documents may denote different times, temporal expressions in documents should be converted into calendrical forms. In multidocument summarization, information retrieval, or question answering, providing fine-grained chronolo-gies of events over time is very useful. Mani and Wilson [2000] developed a temporal annotation algorithm to resolve a class of temporal expressions in print or broadcast English news, such as  X  X ow, X   X  X oday, X   X  X omorrow, X   X  X ext Tuesday, X   X  X wo days ago, X   X 20 minutes after the next hour, X  etc. The desig-nated time depends on the speaker and some  X  X eference time. X  Li et al. [2004] proposed a model to mine and organize temporal relations embedded in Chi-nese sentences. Three kinds of event expressions are accounted for: (1) single events, (2) multiple events, and (3) declare events. To investigate the time fac-tor on Chinese streaming news, our focus here deals with indexical expressions [Linguistic Data Consortium 2005] in print Chinese news.
 3.1 Temporal Resolution Using Focus Time and Coreference Chains Figure 3 shows the system architecture of the temporal tagger, used in our proposed system X  X  Chinese-temporal-processing module. The tagger takes a document as input, which has been tokenized into Chinese words and sen-tences, and tagged by parts of speech. Our proposed system passes each sen-tence first to the module that identifies temporal expressions. The next module checks whether each temporal expression belongs to any coreference chains is already a calendrical expression in the coreference chain. The calendrical expression substitutes the temporal expression in the chain, and sets up a ref-erence time for the later usage.

If a calendrical expression does not exist for reference, the system passes the temporal expression into a preprocessing module. This module transforms the temporal expression in Chinese print news into the western temporal ex-pression. For example, both the calendrical expressions X  X ay, the western style (e.g.,  X 2004 t 5 5  X   X ) and Taiwan local style (e.g.,  X  93 t 5 5  X   X ) X  X ill be mapped into a uniform representation such as 5/5/2004. In addition, it also converts the Chinese character numbers in a temporal expression, such as  X  i C  X   X  t  X   X   X  , X  into an Arabic number expression, such as 5/5/2004. Next, the focus time decision module tries to get the reference time set up. reference time by default.

Two sets of Chinese lexical markers were collected manually in our tem-poral tagger. The first set contained temporal markers like t (year), (month),  X  (day), and so on, which recognize temporal expressions. The sec-ond set contained range markers like  X  (over), (minutes duration),  X  g (within),  X   X  (after), and so on, which interpret and disambiguate temporal expressions. Consider an example. The Chinese temporal expression ] A t is converted into  X 1990. X  From the range marker, ] A t  X  is interpreted as a time duration  X  X ver 90 years X  instead of  X  X ver 1990. X  Chinese has another specific feature: that is, there is no tense in Chinese sentences. Instead of using verb tense, Chinese speakers employ time adverbs and as-pect markers, such as  X   X  (already) and  X   X   X  (aspect marker of completion) to make a correct interpretation. We postulate that the nearest temporal ex-pression of the previous paragraph or sentence is the focus time . The focus time decides the calendrical form of the recognized temporal string. Moreover, the corresponding temporal element in the coreference chain is replaced by its calendrical form as well. 3.2 Experiments To evaluate the proposed Chinese temporal tagger, we randomly selected 20 documents from the test data, specified later in Section 4.1. The 20 documents were manually annotated by calendrical temporal expressions. The system performance is shown in Table I.
 The types of errors generated by our Chinese temporal tagger are as follows. The numbers in parentheses are total errors of the corresponding types.  X  Chinese segmentation error (11). Because a Chinese sentence is composed of words without any boundary, Chinese segmentation may introduce errors.
For example, 1 m (last Saturday) was segmented as (up) and 1 m (Saturday). Similarly, , m ) (the sixth day) was segmented as , m (the sixth) and , m (day).  X  Wrong focus time (3). The tagging algorithm employs a heuristic rule to determine the focus time, that is, the nearest time representation of the previous sentence or paragraph. Focus time tracking may introduce errors.  X  Lack of reference time (4). There is no information, not even a document publication date, which can be used to derive the focus time. For example, as the accurate time of a specific event  X  X isuniting X  is not known in a related document, the temporal expression of  X   X  M A (11 minutes before disuniting) cannot be resolved.  X  Others (1). There is an omission character in the original sentence. For example, HA  X  (ten o X  X lock in the morning) was mistyped as HA  X  .

Without the omission word, the absolute time cannot be determined properly. 3.3 Discussion Summary Example 2 in Figure 4 shows the constrasting results of Summary Example 1 in Figure 1, after the controlled vocabulary and Chinese tempo-ral processing are introduced. In comparison with Summary Example 1, the readability of Summary Example 2 is obviously improved after the coreference and temporal expressions in documents have been resolved.
 4. NP-CHUNKING AND EVENT EXTRACTION Events link major constituents of the actions specified in a text or a collection of texts through a relation and connector pair Filatova and Hatzivassiloglou [2004a]. The constituents in an atomic event can represent the salient cues of a topic. Filatova and Hatzivassiloglou [2004b] computed both the normal-ized frequency of relation and the normalized frequency of connector for each atomic event candidate. Then they used the product of these two frequencies and threshold to filter the atomic event candidates. Due to the strict criteria, many good candidates of atomic events may be lost. In this article, we collect all the triples (noun entity 1 , verb, noun entity 2 ) as events, and consider the terms in the triples as event words.
 4.1 NP-Chunking Using a Significance Estimation Function and the Web Corpus Consider the example shown in Figure 5. Each Chinese word is tagged with its part of speech, that is, Nb (proper noun) and Neu (numeric noun). The words in border with the corresponding verbs form atomic events, that is, ( - X  * z l  X  m  X  _ ,  X  1 ,  X  V w ) (the flight 611 of China Airlines, disappeared, in the sea area of Peng Hu). To extract the atomic events in a sentence, a Chinese NP-Chunker is indispensable. We propose an NP-Chunker based on both a rule-based approach and a machine learning approach as follows. It employs a significance estimation function and the Web corpus.

We used the corpus provided by the United Daily News (http:// udndata.com/), which has collected more than 6,270,000 Chinese news articles from Six Taiwan local newspaper companies since 1/1/1975. To prepare a test corpus, we first set the topic to be an event  X   X  * z  X   X  (air accident of China Airlines), and the range of searching dates from 5/26/2002 to 9/4/2002 when all rescue activities were stopped. A total of 964 related news articles  X  each having a published date, news source, headline, and content  X  were returned from a search engine. All were in SGML format. After reading, we deleted five news articles which had headlines but no content. The average length of news articles was 15.6 sentences.

We used this data set to create a suffix tree, which deals with the out-of-vocabulary (OOV) problem that is, the inadequate coverage of the dictionary, in Chinese. For the readability, we used four separate lists to show our suffix tree in Figure 6. For example, because a new term,  X   X   X   X   X  (Mudou Isle), does not exist in the suffix tree, it is segmented into three single characters:  X   X   X  (Mu),  X   X   X  (Dou), and  X   X   X  (Isle). Because the frequency of  X   X   X   X   X  (Mudou Isle) is larger than a predefined threshold (e.g.,  X  = 40), the three characters are merged into an NP.

In addition to term extraction, most NPs have a strong association between their composite words. NP extraction can be done by measuring the mutual information of two adjacent words using the following significance estimation (SE) function.
 where c is an NP candidate to be measured, a and b are the substrings of c , A  X  (Chen Suei-Bian), b =  X  = q  X  (president), and c =  X  s 4 A = q  X  (President Chen Suei-Bian), then SE ( s 4 A = q ) ( SE [President Chen Suei-Bian]) will be 34 / (60 + 242  X  34) = 0 . 164 after consulting the suffix tree in Figure 6. Similarly, let a =  X  = q  X  (president), b =  X  :  X  (instruct), and c =  X  = q :  X  (President instructed). Accordingly, SE( = q : ) ( SE [President instructed]) = 3 / (242 + 118  X  3) = 0 . 008. Thus, if the significance estimation of an NP candidate is larger than the threshold (e.g.,  X  = 0 . 15), the candidate string can be deemed an NP and the two substrings are merged.

In term extraction, three issues must be considered. (1) If the new terms appear only once in the collected documents  X  for exam-(2) The NV or VN pattern is much easier to be incorrectly merged than the (3) Highly frequent words in an event cannot be merged properly. For ex-
To address issues 1 and 3, we introduced the Web corpus. When the fre-quency of either term is 0, or the frequency difference between an NP candi-date and its composite terms is larger than a predefined threshold (e.g., 150), we use the term frequencies from the Web corpus instead. At first, we con-sider two substrings as query terms, submit them to a search engine (e.g., in the snippets. For example, the frequency of f (  X  B  X   X  ) ( f (medical work-ers)), f (  X  B ) ( f (medical)), and f (  X   X  ) ( f (workers)) from the Web corpus is 11, 14, and 16, respectively. Because SE (  X  B  X   X  ) ( SE (medical workers)) is equal to 11/(14 + 16-11) = 0.58, these two terms can be correctly merged into an NP. For issue 2, we employ two different thresholds, that is, a smaller threshold for the NN pattern, and a larger threshold for the NV or VN pattern. 4.2 NP-Chunker Using the Web Corpus and Syntactic Rules Figure 7 shows the flow of the proposed NP-Chunker. There are four knowl-edge bases: (1) controlled vocabulary, (2) dynamic suffix tree, (3) static suffix tree, and (4) syntactic rules for NP. We have adopted an approach [Kuo and Chen 2007] to set up a controlled vocabulary. In this approach, we use the static suffix trees and the dynamic suffix trees obtained from the news data set and the Web corpus, respectively, to compute the significance estimation. Sinica Treebank [Chen et al. 2003] is a syntactic structure-tagged corpus for Chinese language processing. We used a total of 60 simple syntactic rules selected from this corpus and judged by humans to merge the adjacent NPs or nouns into a larger NP.

The input of the proposed NP-Chunker is a tagged sentence and the out-put is a sentence with newly added NP tags. In the unknown-word-processing module, the input tagged sentence is scanned word by word. If a single-character word is detected, the word is merged with the next word to be a candidate for NP chunking. First, the candidate is checked as to whether it is contained in the controlled vocabulary. If it is, the candidate is deemed an NP. Otherwise, if its frequency in the static suffix tree is larger than a threshold  X  , this candidate is also deemed an NP. For example, the input sentence is  X . . .  X  (to, P)  X  (Mu, Na)  X  (Dou, Na)  X  (Isle, Nb) . . .  X  and the related threshold  X  2, the candidate  X   X   X   X  (to Mu) is not an NP. On the other hand, because f (  X   X  ) ( f (Mudou)) and f (  X   X   X  ) ( f (Mudou Isle)) are 138 and 138, respectively, the candidate  X   X   X   X   X  (Mudou Isle) is an NP.

In the boundary-detection-using-static-suffix-tree module, the input tagged sentence is scanned word by word as well. The current word is merged with the next word to be a candidate. If either of two words is a single character, we use the related frequency in the static suffix tree and a threshold  X  to determine if it is an NP. On the other hand, if neither of the two words is a single-character SE thresholds for the NN and NV (VN) patterns, respectively. The algorithm in the boundary-detection-using-dynamic-tree module is the same as the one using the static suffix tree. The related threshold for term frequency judgment is  X  . Finally, the postprocessing module, which refers to the syntactic rules, merges the consecutive nouns or NPs into a larger NP, that is, a compound NP. For example, (John, N) and (Mary, N) is merged to (John and Mary, NP) by consulting the rule X (N) + and + Y (N)  X  X and Y (NP). Values  X  1 and  X  2 are SE thresholds for NN and NV (VN) patterns, respectively. 4.3 Experiments Sinica Treebank 3.0 [Chen et al. 2003] has six files (ev.check, ko.check, news.check, oral.check, sini.check, and travel.check), and contains more than 54,000 sentences. We used the file ev.check (5,492 sentences) to develop our summary generation system and the file ko.check (8,040 sentences) to test our system. These two files contain Chinese textbooks used by primary schools in Taiwan. After development, the best thresholds for  X  , (  X  ,  X  1,  X  2), and above SE thresholds, the average precision, average recall, and average F score in the development stage are 0.9285, 0.9243, and 0.9254, respectively. The SE thresholds are further used in the testing stage. Average precision, average recall, and average F score are 0.8880, 0.8865, and 0.8864, respectively.
In addition, we also evaluated our system in a noisy environment with both segmentation errors and tagging errors. We used a Chinese tagger [Chen et al. 1998], whose accuracy is around 74%, to tag all the documents in the test cor-pus of the topic  X  X ir accident X  specified in Section 4.1. We randomly selected 31 sentences and tagged the NPs manually as the gold-standard answer. The experimental results are shown in Table II. Modules 1, 2, 3, and 4 denote the unknown-word-processing module, boundary-detection-using-static-tree mod-ule, boundary-detection-using-dynamic-tree module, and postprocessing mod-ule, respectively. Model type ( n + m ) denotes the use of modules n and m . For example, model type (1 + 2 + 4) means that the model uses modules 1, 2, and 4. Comparing with the performance of the baseline model type (1 + 4), the av-erage F score is increased 10% after introducing SE and the static suffix tree, that is, model type (1 + 2 + 4). Furthermore, after introducing the dynamic suffix tree, that is, model type (1 + 2 + 3 + 4), the performance is increased 18% further. The results show that the proposed NP-Chunker is promising even under a noisy environment. 4.4 Event Extraction To extract atomic events in each sentence, we employed the NP-V-NP pattern. Figure 8 shows the steps involved in our proposed event extraction: After applying the event extraction algorithm to the sample text shown in Figure 5, we found the following atomic events: ( - X  * z l  X  m  X  _ ,  X  1 ,  X  V w ) ([flight 611 of China Airlines, disappeared, in the sea area of Peng Hu]), ( L ? b  X   X   X  ( * z @ ,  X  , }  X   X   X   X  - X  ) (Executive Yuan and Civil Aeronautics Administration Ministry of Transportation and Com-munications, formed, Emergency Command Center), and ( L ? b w 8 + , : ,  X   X   X  W  X   X  X  ) ([Prime Minister Shyi-Kun Yu, instructed, the prosecutors of Yunlin and southern courts]). The words in an atomic event are called event words hereafter. 5. SENTENCE SELECTION 5.1 Latent Semantic Analysis Latent semantic analysis (LSA) is a mathematical technique for extracting and inferring relations of expected contextual usage of words in passages of dis-course. Sentences that are closely related, but contain no common words, will be recognized as similar under LSA analysis. During summary generation, the redundancy can be further addressed by removal to enhance summary quality.
Extraction using LSA is based on singular value decomposition (SVD) [Gong and Liu 2001; Yeh et al. 2005]. SVD semantically clusters content words, and derives a latent semantic structure for sentences among documents. The result of applying SVD to each sentence is shown in Figure 9. In word-by-sentence matrix A, column vector A i represents the term frequency vector of sentence i in a document under consideration, and the element a ji of A is frequency of feature word j in sentence i . U is j -by-i matrix of left-singular vectors, 6 is an i -by-i matrix of singular values, and V T is an i -by-i matrix of right-singular vectors. Besides event words, we also introduce the informative words of each document (refer to Section 5.2) and their corresponding frequencies in each sentence to construct the word-by-sentence matrix. We also used a, Matlab library to conduct SVD. 5.2 Informative Words 5.2.1 Paragraph Dispersion. Paragraph dispersion PD i , d denotes the de-gree of a word i appearing across paragraphs in a document d [Fukumoto and Suzuki 2000]. In other words, if the frequency of a term is more or less the same across different paragraphs, its PD value is smaller. In contrast, if the term frequency is highly unstable, or skewed across different paragraphs,its PD value is larger. Thus, the terms with small PD values are informative terms. To introduce the paragraph dispersion factor into our selection of in-formative words, we revised the dispersion formula of [Fukumoto and Suzuki 2000] by adding a negation sign. That is, we let the informative terms have a larger PD value. Furthermore, to normalize the paragraph dispersion value to be small and around 0, we employed its logarithm value and added 0.01 to avoid the appearance of log(0). Normalized paragraph dispersion (NPD) is defined in Equation (2) where tf i , j , d denotes the term frequency of word i in paragraph j of document d , utf i , d denotes the average term frequency of word i in document d , and M denotes the total number of paragraphs in document d . Equation (2) indicates that the larger the NPD value is, the more paragraphs the word crosses. 5.2.2 Selection of Informative Words. Choosing words that can precisely represent a document X  X  main concepts can also help in selecting the most im-portant sentence for summarization. Topic words are also considered to be rep-resentative if they appear frequently across documents or appear frequently in each document [Fukumoto and Suzuki 2000]. Thus, besides the NPD factor, we consider two more factors. The score, denoted as IW i , d of word i in docu-ment d , is defined in Equation (4). Equation (5) defines the second factor, that is, the normalized term frequency ( Ntf i , d ) of a word i in a document d , where tf i , d is the term frequency of a word i in a document d , and utf i is the mean term frequency of a word i in an event cluster which is defined in Equation (6). Equation (7) defines the third factor, that is, the average document frequency of a word i . Here, df i is the document frequency of word i and N is the total documents in an event cluster which is defined in Equation (6). The three fac-tors are mixed together by weights  X  ,  X  , and  X  shown in Equation (4). In the latter experiments,  X  ,  X  , and  X  are set to equal weight.
 Those words having higher IW values are selected as the informative words for each document. The informative words are used as the features of each document. Consequently, both the event words and the informative words ap-pearing in each sentence are used to construct the word-by-sentence matrix.
Each singular vector represents a salient topic. The singular vector with the largest singular value represents the topic that is the most salient. According to the length constraint, a fixed number of singular values are selected from left to right. For each singular vector, a sentence having the largest index is ex-tracted as an important sentence. Thus, the extracted sentences can describe the important topics represented by the singular vectors. 6. SENTENCE REDUCTION AND SUMMARY GENERATION 6.1 Sentence Reduction Using Both Informative Words and Event Words The punctuation in a sentence, that is, comma and a semicolon, can be used to separate a sentence into several clauses . We postulate that the more in-formative words and event words a clause contains, the more informative the clause is. In other words, if a clause does not contain any informative or event words, the clause can be eliminated with no loss of information. Moreover, if event words in an atomic event can be preserved in a summary, a subject-verb-object word order can assure readability. On the other hand, the temporal expressions in a sentence can indicate the order of occurring events and play an important role in understanding a sentence. In order not to decrease the readability, we assign a higher weight to the temporal words factor than to the other two factors. Thus, Equation (8) defines the score for each clause. deleted and not put into a summary. We set parameters  X  ,  X  , and  X  in Equation (8) to 2, 1, and 5, and let threshold  X  be 5. An example follows in Figure 10. Underlined words indicate either the informative words, for ex-ample,  X  L ? b w 8 +  X  (Prime Minister Yu Shyi-kun), or temporal words, for example,  X  , B  X   X  (at the first time). On the other hand, those border words indicate the elements of event word pairs, for example,  X  L ? b w 8 +  X  (Prime Minister Yu Shyi-kun) and  X  2  X   X  (the minister of defense). If the scores of the candidate clauses are larger than the threshold  X  , they are re-tained during the sentence reduction processing. For example, the score for the clause  X  L ? b w 8 +  X  \ D 0  X  -c _ 4  X   X  ( * z  X  (Prime Min-ister Yu Shyi-kun went to CKS airport and Civil Aeronautic Administration Minister of Transportation and Communication immediately), which contains one event pair and two informative words, is 5. Thus, the clause is kept in the summary. From this example, we find that sentence reduction keeps the important clauses, and effectively deletes uninformative clauses. 6.2 Summary Generation Using Sentence Date In single-document summarization, we can use the position of an extracted sentence in its original document to effectively decide its position in the generated summary. However, for multidocument summarization, we cannot straight forwardly use the sentence positions in each document [Barzilay et al. 2000]. How to determine the most probable permutation of sentences, or how to reconstruct the discourse structure of sentences gathered from multiple sources, becomes an important consideration. A newspaper usually deals with new events occuring since the last publication. Hence, the publication date (time) of each article turns out to be a good estimator of resemblance relation, contingency in time, and cause-effect relation [Okazaki et al. 2004]. As re-solving temporal expressions in sentences is not an easy task, Okazaki et al. [2004] arranged the extracted sentences by chronological order, assigning a time stamp to each sentence by its publication date. Moreover, Barzilay et al. [2000] also combined constraints from the chronological order of events and topical relatedness to propose a sentence ordering algorithm.

Because the algorithm we have proposed uses focus time and coreference chains to deal with the temporal expressions in sentences, as we described in Section 3, we can obtain a more precise estimation of sentence temporal rela-tion. In our approach, we use the sentence time (date) rather than publication date to be the time stamp for each sentence. For those sentences having the same time stamp, we elaborate the order on the basis of their sentence posi-tions in the original document. 7. EXPERIMENTS 7.1 Data Set and Evaluation Metrics We conducted experiments to test the effectiveness of our proposed multidoc-ument summary generation system. First, two annotators were asked to read all 959 news articles described in Section 4.1, and to classify these articles into 13 events or mark them as  X  X ther. X  A news article that reported more than one event could be placed in more than one event cluster. We then compared the classification results of the annotators and considered only the consistent an-notations as our answer set. Among them, the rescue event which contained 68 documents (a total of 1.64 MB) was chosen as the test corpus. The other 12 events were used as the training corpus. We adopted, the subjective eval-uation method used in NTCIR-TSC2 [Okumura et al. 2004]. Human judges evaluated and ranked all n summaries on a 1 to n scale, where 1 was best, 2 was second, and n was worst. The scale rates two points of views, that is, the content (how extensively the system covers the important contents of the origi-nal articles) and the readability (how readable the system summary is). In our experiments, we asked 14 graduate students to evaluate the generated system summaries. Moreover, the NTCIR-TSC2 claimed that in multidocument sum-marization, longer summaries had worse scores, especially in the readability evaluation. Therefore, a short summary (20% compression, 5,120 characters) for the rescue event was generated for each multidocument summarization system.
 7.2 Results and Discussion Our baseline system used Equation (4) specified in Section 5.2.2 to compute the informative word score (IW) for each word in a document, and selected the top 10 words to be the informative words. On the other hand, to introduce the importance of the leading sentences, especially for newswire documents, the score of each sentence was computed using Equation (9). The related weights were the best results obtained from the training data. After sorting the scores in descending order, we iteratively extracted sentences until we reached the limitation of summary length. Furthermore, the extracted sentences were or-dered by the publication date of their respective documents. where | W | denotes the number of informative words and event words in sentence s , IW ( t ) denotes the normalized score of informative word t , and Position ( s ) is the sentence position in a document.

Because we wanted to evaluate the performance of our baseline system with and without temporal processing and named entity unification, we generated the following type B summary. Furthermore, to compare the related performance between the baseline system and the SVD system, we generated another three types of summaries (C-E) using different numbers of informative words and event words as features in each document as shown: type A : the baseline system type B : uses type A system with named entity unification and temporal processing type C : uses SVD system with 10 informative words in each document type D : uses SVD system with 20 informative words in each document type E : uses SVD system with 30 informative words in each document
Each judge was given all 68 documents and evaluation guidelines (similar to those in NTCIR-TSC2), and asked to read them in advance. The just-listed five types of generated summaries were then given to the judges, who ranked the summaries in two ways: (1) by content metric (Cont), and (2) readability metric (Read). Judges did not know what types of summaries they read.
Table III shows the related experimental results. Both the readability and content performances of type B are better than those of type A. Thus, we can conclude that the proposed controlled vocabulary and temporal processing can effectively deal with issues 2-4 specified in Section 1. Because both the content and readability performances of type D are better than those of type B, the SVD system can select more important sentences than the baseline system. The t-test (  X  = 0.025) further shows that the content score of type D outperforms that of type B significantly. Moreover, the best number of informative words in each document is 20.
 Next, to evaluate the proposed sentence reduction algorithm specified in Section 6.1 and to study the effect of information words and event words on sentence reduction, we evaluated three more types of summaries (F-H). We used 20 informative words in each document. The related parameters specified in Section 6.1 are shown here: type F : uses type D system with parameters (  X  ,  X  ,  X  ,  X  ) = (2, 1, 5, 5) type G : uses type D system with parameters (  X  ,  X  ,  X  ,  X  ) = (1, 1, 5, 5) type H : uses type D system with parameters (  X  ,  X  ,  X  ,  X  ) = (1, 2, 5, 5)
In the second experiment, we prepared five types of summaries. Besides types F, G, and H, types B and D are also included for comparison. Each of the same 14 judges was given five types of system summaries and asked to rank the summaries using the content metric and the readability metric. The experimental results are shown in Table IV.

Table IV shows that the performance of either type G or type H is worse than that of type F. This is because the informative words appear in each clause fre-quently, but the event words can only appear in a few clauses. To reflect the importance of each clause effectively, a larger weight should be assigned to the informative words. Moreover, as the sentence reduction deletes some content in a sentence, the information loss is inevitable. However, the difference of average content is not significant when we compare the content scores of types D and F. In contrast, the t-test (  X  = 0.05) shows that the average readability of type F outperforms the readability of type D significantly. Because we re-tain all the clauses that contain the event words, the summary can keep the NP-V-NP structure. In addition, the introduced sentences can bring more con-text information to enhance readability.

It is clear, in comparison with the baseline multidocument summary gen-eration system, the SVD system can improve the performance of information coverage (content). Furthermore, the proposed sentence reduction can improve readability. Both information coverage and readability are improved signifi-cantly using our proposed news summarizer. 8. CONCLUSION This paper presents a novel summary generation system for multidocument summarization using both informative and event words. The proposed infor-mative words, event words and latent semantic analysis are used to tackle the sentence selection issue. On the other hand, the Chinese temporal resolution using focus time is used to deal with the sentence ordering and readability issues. In addition, both the event words extracted from atomic events and informative words are used in a sentence reduction algorithm. That can en-hance the quality of summary content. The experimental results show that the proposed sentence extraction module can improve the information coverage significantly. Meanwhile, the proposed sentence reduction can also improve the readability significantly.

Ordering the sentences is only the first step towards creating a readable summary. We have to perform amendments to sentences and smooth the tran-sition from a sentence to next. To investigate the performance of our proposed summary generation system further, we plan to compare it with the other sys-tems, e.g., MEAD system. Moreover, to include more sentences within the length limit, we also plan to make some researches on filtering out irrelevant content from long sentences, e.g., transition words, adverbs or adjective, ti-tles, etc. To generate good quality summary, we will introduce the co-reference chains between entities and controlled vocabulary to recover pronouns back to the original nominal expressions.

