 We present a knowledge-intensive and model-based case-based reasoning framework that supports the truster for situation-aware trust management. The suggested method augments the typically sparse trust information by inferring the missing information from other situational conditions, and can better support situation-aware trust management. Our framework can be coupled with existing trust manage-ment models to make them situation-aware. It uses the un-derlying model of trust management to transfer trust infor-mation between situations. We validate the proposed frame-work for Subjective Logic trust management model and eval-uate it by conducting experiments on a large real dataset. K.6.5 [ Management of Computing and Information Systems ]: Security and Protection Security Analogical Reasoning, Case-based Reasoning, Conditional Reasoning, Context, Ontology, Recommender Systems, Se-mantic Similarity, Trust
A network of people having established trust relations and a model for propagation of related trust scores are funda-mental building blocks in many of today X  X  most successful e-commerce and recommendation systems. Trust is situation-specific and the trust judgment problem with which the  X   X  X enter for Quantifiable Quality of Service in Communi-cation Systems, Center of Excellence X  appointed by The Re-search Council of Norway, funded by the Research Council, NTNU and UNINETT. at http://www.q2s.ntnu.no truster is confronted might be, in some ways, similar but not identical to some problems the truster has previously encountered. The truster then may draw information from these past experiences while may be useful for the current situation. For example, a person trusting Bob as a good car mechanic will not automatically trust him also in undertak-ing heart surgeries. On the other hand he probably could be quite capable in repairing motorcycles. Since, there is a large similarity between the domains of repairing cars and motorcycles but a very low one between both of these and medical surgery. We think to use trust relations in one do-main to infer trust relations in similar domains and consider ontologies describing the degrees of similarity between the domains as a useful means for the purpose.

The rest of this paper is organized as follows: Section 2 provides an overview of the related research. In section 3, we briefly explain the thesis proposal. Our achievements are described in section 4. Next in section 5, we present our plan for future work.
Researcher have had different motivations to incorporate the notion of context into the trust management accounts. For example, [12] aims at reducing the complexity in man-agement of trust relationships. [13, 5] focuses on the im-provement of the trust recommendation process. [7] in-vestigates how to infer trust information in context hier-archies. [14] improves the performance of trust manage-ment systems. [14, 15] provide protection against changes of identity and first time offenders in trust management sys-tems. [2, 1, 5] provide methods that correlate trust in-formation among various contexts. In addition to differ-ences in the main focuses and motivations, there has been differences also in the representation of the context infor-mation: Context-aware domains [12, 13], Intensional Pro-gramming [24], Multi-dimensional goals [6], Clustering [14], Graph [7, 2], Bayesian network [1], Ontologies [4, 8, 23], Trust attributes [3, 5].

In next section, we present our solution for context repre-sentation which is based on case-based reasoning [11].
We propose a Context Management Framework (CMF) which can be combined with existing trust management mod-els (TMM) to extend their capabilities towards efficient mod-eling of the situation-aware trust by Figure 1: Scope and interconnection of context man-agement framework (CMF) and trust management model (TMM). a) Estimation of the trust value in unknown situations. b) Adjustment of the output of TMM (trust value) based on the underlying situ-ation.
We consider two approaches for the inference task among situations: similarity-based reasoning and rule-based infer-ence, depicted respectively as case-based reasoner (CBR) and rule-based reasoner (RBR) modules. The former pro-vides the first role (Figure 1(a)), estimation of the trust value in unanticipated situations and the latter is responsi-ble for the second role (Figure 1(b)) of CMF, adjustment of the trust values based on underlying situation.

The CBR module is discussed thoroughly in [18] and is implemented and evaluated for the Subjective Logic [9] as TMM. Subjective Logic uses a specific belief calculus. There trust is expressed by a belief metric called opinion and sev-eral operators can be used to analyze the trust network. As a result of [18], the Subjective Logic is extended with a sit-uation dimension.

Although CBR techniques are extensively used for recom-mender systems and there are some works which use CBR to build more trust through providing explanations, to the best of our knowledge this proposal is quite new. The RBR mod-ule is the focus of future work. The next section presents the progress of the thesis up to date.
We highlight the focuses of attention within the trust management literature, and reviewed various accounts of situation-aware trust judgment in [22].

In [19] we propose a hierarchical Bayesian reputation al-gorithm for trust management and a method based on max-imum likelihood estimation to bootstrap trust with unfamil-iar agents based on stereotypes and context information.
We give a more comprehensive solution for the problem of context-awareness in [18]. This paper presents a context Figure 2: Knowledge containers in case-based rea-soner (CBR). TMM: trust management model, MBR: Model-based reasoner, RBR: rule-based rea-soner, CMF: context management framework. management framework (CMF) that employs case-based rea-soning [11] to analyze the correlation between trust informa-tion in various situations and help to bootstrap the trust in unanticipated situations using trust information avail-able from similar situations. The case-based reasoning tech-nique is particularly useful for tasks which are experience-intensive, involve plausible (i.e. not sound) reasoning and have incomplete rules to apply.

The fundamental principle of the case-based reasoning technique is similar to that of the human analogical rea-soning process which employs solutions of past problems to solve current ones. The reasoning process is generally com-posed of three stages: remembering, reusing, and learning. Remembering is the case-retrieval process, which retrieves relevant and useful past cases. In the reusing step, the case-based reasoning system applies the cases that have been re-trieved to find an effective solution to the current problem. Learning is the process of casebase enhancement. At the end of each problem-solving session the new case and problem-solving experiences are incorporated into the casebase [10] (see the case base and solution transformation boxes in fig-ure 2).

In the case-based reasoning approach, knowledge is dis-tributed among the four knowledge containers: ontology, casebase, similarity measures, and solution transformation.
CMF is generally composed of three processes: Remem-bering, Reusing, and Learning.
We validate the proposed framework for Subjective Logic trust management model and evaluate it by conducting ex-periments on the MovieLens dataset 1 . The results are com-pared to the Pearson correlation coefficient as the baseline
The data consists of 100,000 ratings from 943 users on 1682 movies with every user having at least 20 ratings. Demo-graphic information for the users and film genres are in-cluded.
 Figure 4: Achievements to date. P 1 : [19], P 2 : [21], P : [20], P 4 : [17], P 5 : [18], B 1 : [22], B 2 : [16] algorithm according to four metrics: coverage (percentage of predictions), FCP (fraction of correct predictions), MAE (Mean Absolute Error), and RMSE (root mean square er-ror). All-in-all, the results of the evaluation lead to the ex-pectation that our approach provides an improvement over the Pearson algorithm and this implies that situational in-formation is useful in making predictions.

In [17] we propose a novel approach to trust inference called  X  X ILLIT X  (Trust Inference Links based on Like-minded Interaction Transitions). TILLIT is based on combination of trust inferences and user similarity. The similarity is de-rived from the structure of the trust graph and users X  trust behavior as opposed to other collaborative-filtering based approaches which use ratings of items or user X  X  profile. This approach is validated for Subjective Logic trust management model and evaluated using Advogato dataset 2 . TILLIT can also be considered as a kind of similarity measurement algo-rithm for our framework, according the similarity measures box in figure 2.
The RBR module is the focus of our future work and we will explain how trust values are adjusted based on the underlying situation in the Subjective Logic. We evaluate
Advogato is an online community site dedicated to free software development. On Advogato a user can certify an-other user as  X  X aster X ,  X  X ourneyer X ,  X  X pprentice X  or  X  X b-server X , based on the perceived level of involvement in the free software community. The Advogato social network is an example of a real-world, directed, weighted, large social network. our proposal using a real large-scale dataset. We consider situation-based trust reasoning as a special kind of inductive reasoning where situations form predecessor for the trust inference task.

We also aim to add a Risk Management Module to this framework. Risk evaluation becomes important in inferring trust values among situations, especially when the trust-worthiness of some principal is completely unknown and no recommendation information is available. The intuitive idea behind such a risk assessment can be to look up the in the casebase to see if there are any similar previous interactions, i.e., if we have previously encountered an entity with simi-lar trust attributes and similar risk attributes in the same situation. The ontology part should be able to describe the level of situational risk. Normally, one would assume that the higher the risk of negative outcome, the higher the level of precision that must be captured. [1] E. Bagheri, M. Barouni-Ebrahimi, R. Zafarani, and [2] E. Bagheri and A. Ghorbani. Behavior analysis [3] A. Caballero, J. Botia, and A. Gomez-Skarmeta. On [4] J. Golbeck, B. Parsia, and J. Hendler. Trust Networks [5] E. Gray, Y. Chen, and C. Jensen. Initial Investigation [6] N. Gujral, D. DeAngelis, K. Fullam, and K. Barber. [7] S. Holtmanns and Z. Yan. Context-Aware Adaptive [8] J. Huang and M. S. Fox. An ontology of trust: formal [9] A. J X sang. A Logic for Uncertain Probabilities. [10] C. Jung, I. Han, and B. Suh. Risk Analysis for [11] B. Morris. SCAN: a case-based reasoning model for [12] R. Neisse, M. Wegdam, and M. van Sinderen.
 [13] R. Neisse, M. Wegdam, M. van Sinderen, and [14] M. Rehak, M. Gregor, M. Pechoucek, and [15] M. Rehak and M. Pechoucek. Trust modeling with [16] M. Tavakolifard. Web Intelligence and Intelligent [17] M. Tavakolifard, P. Herrmann, and S. Knapskog. [18] M. Tavakolifard, P. Herrmann, and P.  X  Ozt  X  urk. [19] M. Tavakolifard and S. Knapskog. Probabilistic [20] M. Tavakolifard, S. Knapskog, and P. Herrmann. [21] M. Tavakolifard, S. Knapskog, and P. Herrmann. Trust [22] M. Tavakolifard and P.  X  Ozt  X  urk. Security Engineering [23] S. Toivonen and G. Denker. The impact of context on [24] K. Wan and V. Alagar. An Intensional Functional
