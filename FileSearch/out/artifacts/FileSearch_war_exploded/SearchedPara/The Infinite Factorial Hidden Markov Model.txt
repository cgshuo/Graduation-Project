 When modeling discrete time series data, the hidden Markov model [1] (HMM) is one of the most widely used and successful tools. The HMM defines a probability distribution over observations y s ,s 2 ,  X  X  X  ,s T with s t  X  { 1  X  X  X  K } whose dynamics is governed by a K by K stochastic transition model F parametrized by a state dependent parameter  X  s t . We can write the probability distribution induced by the HMM as follows 1 Figure 1 shows the graphical model for the HMM.
 One shortcoming of the hidden Markov model is the limited representational power of the latent variables. One way to look at the distribution defined by the HMM is to write down the marginal distribution of y t given the previous latent state s t  X  1 Equation (2) illustrates that the observations are generated from a dynamic mixture model. The factorial hidden Markov model (FHMM), developed in [2], addresses the limited representational power of the hidden Markov model. The FHMM extends the HMM by representing the hidden state in a factored form. This way, information from the past is propagated in a distributed manner through a set of parallel Markov chains. The parallel chains can be viewed as latent features which evolve over time according to Markov dynamics. Formally, the FHMM defines a probability distribution to Markov dynamics and at each timestep t , the Markov chains generate an output y t using some likelihood model F parameterized by a joint state-dependent parameter  X  s (1: m ) in figure 2 shows how the FHMM is a special case of a dynamic Bayesian network. The FHMM has been successfully applied in vision [3], audio processing [4] and natural language processing [5]. Unfortunately, the dimensionality M of our factorial representation or equivalently, the number of parallel Markov chains, is a new free parameter for the FHMM which we would prefer learning from data rather than specifying it beforehand.
 Recently, [6] introduced the basic building block for nonparametric Bayesian factor models called the Indian Buffet Process (IBP). The IBP defines a distribution over infinite binary matrices Z where element z nk denotes whether datapoint n has feature k or not. The IBP can be combined with distributions over real numbers or integers to make the features useful for practical problems. In this work, we derive the basic building block for nonparametric Bayesian factor models for time series which we call the Markov Indian Buffet Process (mIBP). Using this distribution we build a nonparametric extension of the FHMM which we call the Infinite Factorial Hidden Markov Model (iFHMM). This construction allows us to learn a factorial representation for time series. In the next section, we develop the novel and generic nonparametric mIBP distribution. Section 3 describes how to use the mIBP do build the iFHMM. Which in turn can be used to perform inde-pendent component analysis on time series data. Section 4 shows results of our application of the iFHMM to a blind source separation problem. Finally, we conclude with a discussion in section 5. Similar to the IBP, we define a distribution over binary matrices to model whether a feature at time t is on or off. In this representation rows correspond to timesteps and the columns to features or Markov chains. We want the distribution over matrices to satisfy the following two properties: (1) the potential number of columns (representing latent features) should be able to be arbitrary large; (2) the rows (representing timesteps) should evolve according to a Markov process.
 Below, we will formally derive the mIBP distribution in two steps: first, we describe a distribution over binary matrices with a finite number of columns. We choose the hyperparameters carefully so we can easily integrate out the parameters of the model. In a second phase, we take the limit as the number of features goes to infinity in a manner analogous to [7] X  X  derivation of infinite mixtures. 2.1 A finite model Let S represent a binary matrix with T rows (datapoints) and M columns (features). s tm represents the hidden state at time t for Markov chain m . Each Markov chain evolves according to the transition matrix Beta (  X /M, 1) and b m  X  Beta (  X , X  ) . Each chain starts with a dummy zero state s 0 m = 0 . The hidden state sequence for chain m is generated by sampling T steps from a Markov chain with transition matrix W ( m ) . Summarizing, the generative specification for this process is Next, we evaluate the probability of the state matrix S with the transition matrix parameters W ( m ) 0 , 0  X  1 , 1  X  0 and 1  X  1 transitions respectively, in binary chain m (including the transition from the dummy state to the first state). We can then write We integrate out a and b with respect to the conjugate priors defined in equation (4) and find where  X ( x ) is the Gamma function. 2.2 Taking the infinite limit Analogous to the IBP, we compute the limit for M  X   X  of the finite model in equation (6). The probability of a single matrix in the limit as M  X   X  is zero. This is not a problem since we are only interested in the probability of a whole class of matrices, namely those matrices that can be transformed into each other through column permutations. In other words, our factorial model is exchangeable in the columns as we don X  X  care about the ordering of the features. Hence, we compute the infinite limit for left-ordered form (lof)-equivalence classes [6].
 The left-ordered form of a binary S matrix can be defined as follows: we interpret one column of length T as encoding a binary number: column m encodes the number 2 T  X  1 s 1 m + 2 T  X  2 s 2 m +  X  X  X  + s Tm . We call the number which a feature encodes the history of the column. Then, we denote with M h the number of columns in the matrix S that have the same history. We say a matrix is a lof-matrix if its columns are sorted in decreasing history values. Let S be a lof-matrix, then we denote with [ S ] the set of all matrices that can be transformed into S using only column permutations; we call [ S ] the lof-equivalence class. One can check that the number of elements in the lof-equivalence class of S is equal to M ! This form allows us to compute a meaningful limit as M  X   X  . A writeup on the technical details of this computation can be found on the author X  X  website. The end result has the following form where H t denotes the t  X  X h Harmonic number and M + denotes the number of Markov chains that switch on at least once between 0 and T , i.e. M + is the effective dimension of our model. 2.3 Properties of the distribution First of all, it is interesting to note from equation (9) that our model is exchangeable in the columns and Markov exchangeable 2 in the rows.
 Next, we derive the distribution in equation (9) through a stochastic process that is analogous to the Indian Buffet Process but slightly more complicated for the actors involved. In this stochastic process, T customers enter an Indian restaurant with an infinitely long buffet of dishes organized in of the buffet and stopping after a Poisson (  X  ) number of dishes as his plate becomes overburdened. A waiter stands near the buffet and takes notes as to how many people have eaten which dishes. The t  X  X h customer enters the restaurant and starts at the left of the buffet. At dish m , he looks at the customer in front of him to see whether he has served himself that dish. The customer then moves on to the next dish and does exactly the same. After the customer has passed all dishes people have previously served themselves from, he tries Poisson (  X /t ) new dishes. If we denote with M ( t ) 1 the number of new dishes tried by the t  X  X h customer, the probability of any particular matrix being produced by this process is p ([ S ]) = We can recover equation (9) by summing over all possible matrices that can be generated using the Markov Indian Buffet process that are in the same lof-equivalence class. It is straightforward equation (9). This construction shows that the effective dimension of the model ( M + ) follows a Poisson (  X H T ) distribution. 2.4 A stick breaking representation Although the representation above is convenient for theoretical analysis, it is not very practical for inference. Interestingly, we can adapt the stick breaking construction for the IBP [8] to the mIBP. This will be very important for the iFHMM as it will allow us to use a combination of slice sampling and dynamic programming to do inference.
 the order statistics of the parameters a . Since the distribution on the variables a m in our model are identical to the distribution of the feature parameters in the IBP model, we can use the result in [8] that these variables have the following distribution The variables b m are all independent draws from a Beta (  X , X  ) distribution which is independent of M . Hence if we denote with b ( m ) the b variable corresponding to the m  X  X h largest a value (in other words: the b value corresponding to a ( m ) ) then it follows that b ( m )  X  Beta (  X , X  ) . In this section, we explain how to use the mIBP as a building block in a full blown probabilistic model. The mIBP provides us with a matrix S which we interpret as an arbitrarily large set of par-allel Markov chains. First we augment our binary representation with a more expressive component which can describe feature specific properties. We do this by introducing a base distribution H from which we sample a parameter  X  m  X  H for each Markov chain. This is a rather flexible setup as the base distribution can introduce a parameter for every chain and every timestep, which we will illustrate in section 3.1.
 Now that we have a model with a more expressive latent structure, we want to add a likelihood model F which describes the distribution over the observations conditional on the latent structure. the likelihood must satisfy in order for the limit M  X   X  to be valid: (1) the likelihood must be shows the graphical model for our construction which we call the Infinite Factorial Hidden Markov Model (iFHMM). In the following section, we describe one particular choice of base distribution and likelihood model which performs Independent Component Analysis on time series. 3.1 The Independent Component Analysis iFHMM Independent Component Analysis [9] (ICA) means different things to different people. Originally invented as an algorithm to unmix a signal into a set of independent signals, it will be more insightful for our purpose to think of ICA in terms of the probabilistic model which we describe below. As we explain in detail in section 4, we are interested in ICA to solve the blind source separation problem. Assume that M signals are represented through the vectors x m ; grouping them we can represent the signals using the matrix X = [ x 1 x 2  X  X  X  x M ] . Next, we linearly combine the signals using a mixing matrix W to generate the observed signal Y = XW . Additionally, we will assume IID Normal (0 , X  2 Y ) noise added: Y = XW + .
 A variety of fast algorithms exist which unmix the observations Y and recover the signal X . How-ever, crucial to these algorithms is that the number of signals is known in advance. [10] used the IBP to design the Infinite Independent Component Analysis (iICA) model which learns an appropri-ate number of signals from exchangeable data. Our ICA iFHMM model extends the iICA for time series.
 The ICA iFHMM generative model can be described as follows: we sample S  X  mIBP and point-wise multiply (denoted by ) it with a signal matrix X . Each entry in X is an IID sample from a Laplace (0 , 1) distribution. One could choose many other distributions for X , but since in section 4 we will model speech data, which is known to be heavy tailed, the Laplace distribution is a conve-nient choice. Speakers will be speaking infrequently so pointwise multiplying a heavy tailed distri-bution with a sparse binary matrix achieves our goal of producing a sparse heavy tailed distribution. Next, we introduce a mixing matrix W which has a row for each signal in S X and a column for each observed dimension in Y . The entries for W are sampled IID from a Normal (0 , X  2 W ) distribution. Finally, we combine the signal and mixing matrices as in the finite case to form the observation matrix Y : Y = ( S X ) W + where is Normal (0 , X  2 Y ) IID noise for each element. In terms of the general iFHMM model defined in the previous section, the base distribution H is a joint distribution over columns of X and rows of W . The likelihood F performs the pointwise multiplication, mixes the signals and adds the noise. It can be checked that our likelihood satisfies the two technical conditions for proper iFHMM likelihoods described in section 3. 3.2 Inference Inference for nonparametric models requires special treatment as the potentially unbounded dimen-sionality of the model makes it hard to use exact inference schemes. Traditionally, in nonparametric factor models inference is done using Gibbs sampling, sometimes augmented with Metropolis Hast-ings steps to improve performance. However, it is commonly known that naive Gibbs sampling in a time series model is notoriously slow due to potentially strong couplings between successive time steps [11]. In the context of the infinite hidden Markov model, a solution was recently proposed in [12], where a slice sampler adaptively truncates the infinite dimensional model after which a dy-namic programming performs exact inference. Since a stick breaking construction for the iFHMM is readily available, we can use a very similar approach for the iFHMM. The central idea is the following: we introduce an auxiliary slice variable  X  with the following distribution It is not essential that we sample from the uniform distribution, in fact for some of our experiments we use the more flexible Beta distribution. The resulting joint distribution is It is clear from the equation above that one recovers the original mIBP distribution when we integrate out  X  . However, when we condition the joint distribution on  X  we find which forces all columns of S for which a m &lt;  X  to be in the all zero state. Since there can only be a finite number of a m &gt;  X  , this effectively implies that we need only resample a finite number of columns of S .
 We now describe our algorithm in the context of the ICA iFHMM: we start with an initial S matrix and sample a , b . Next, conditional on our initial S and the data Y , we sample the ICA parameters X and W . We then start an iterative sampling scheme which involves the following steps: We experimented with 3 different algorithms for step 2. The first, a naive Gibbs sampler, did not perform well as we expected. The second algorithm, which we used for our experiments, is a blocked Gibbs sampler which fixes all but one column of S and runs a forward-filtering backward-sampling sweep on the remaining column. This allows us to analytically integrate out one column of X in the dynamic program and resample it from the posterior afterwards. W can be sampled exactly conditional on X , S and Y . A third algorithm runs dynamic programming on multiple chains at once. We originally designed this algorithm as it has the potential to merge two features in one sweep. However, we found that because we cannot integrate out X and W in this setting, the inference was not faster than our second algorithm. Note that because the bulck of the computation is used for estimating X and W , the dynamic programming based algorithms are effectively as fast as the naive Gibbs sampler. A prototype implementation of the iFHMM sampler in Matlab or .NET can be obtained from the first author. Figure 4: Blind speech separation experiment; figures represent which speaker is speaking at a cer-tain point in time: columns are speakers, rows are white if the speaker is talking and black otherwise. The left figure is ground truth, the next two figures in are for the 10 microphone experiment, the right two figures are for the 3 microphone experiment. To test our model and inference algorithms, we address a blind speech separation task, also known as the cocktail party problem. More specifically, we record multiple people who are simultane-ously speaking, using a set of microphones. Given the mixed speech signals, the goal is to separate out the individual speech signals. Key to our presentation is that we want to illustrate that using nonparametric methods, we can learn the number of speakers from a small amount of data. Our first experiment learns to recover the signals in a setting with more microphones then speakers, our second experiment uses less microphones then speakers.
 The experimental setup was the following: we downloaded data from 5 speakers from the Speech Separation Challenge website 3 . The data for each speaker consists of 4 sentences which we ap-pended with random pauses in between each sentence. Figure 4(a) illustrates which person is talking at what point in time. Next, we artificially mix the data 10 times. Each mixture is a linear combi-nation of each of the 5 speakers using Uniform (0 , 1) mixing weights. We centered the data to have zero mean and unit variance and added IID Normal (0 , X  2 Y ) noise with  X  Y = 0 . 3 . In our first experiment we compared the ICA iFHMM with the iICA model using all 10 microphones. We subsample the data so we learn from 245 datapoints. We initialized the samplers for both models with an initial S matrix with 10 features, 5% random entries on. We use a Gamma (1 . 0 , 4 . 0) prior on people speak for larger stretches of time, say the time to pronounce a sentence. We ran the samplers for 5000 iterations and then gathered 20 samples every 20 iterations.
 For both the ICA iFHMM and iICA models, we average the 20 samples and rearrange the features to have maximal overlap with the ground truth features. Figure 4(b) shows that the ICA iFHMM model recognizes that the data was generated from 5 speakers. Visual inspection of the recovered S matrix also shows that the model discovers who is speaking at what time. 4(c) illustrated the results of the iICA model on the same data. Although the model discovers some structure in the data, it fails to find the right number of speakers (it finds 9) and does a poor job in discovering which speaker is active at which time. We computed the average mutual information between the 5 columns of the true S matrix and the first 5 columns of the recovered S matrices. We find that the iFHMM has an average mutual information of 0 . 296 compared to 0 . 068 for the iICA model. The difference between the two models is strictly limited to the difference between using the IBP versus mIBP. We want to emphasize that although one could come up with ad-hoc heuristics to smooth the iICA results, the ICA iFHMM is a principled probabilistic model that does a good job at comparable computational cost.
 In a second experiment, we chose to perform blind speech separation using only the first 3 micro-phones. We subsampled a noiseless version of the data to get 489 datapoints. We ran both the ICA iFHMM and iICA inference algorithms using exactly the same settings as in the previous experi-ment. Figure 4(d) and 4(e) show the average of 20 samples, rearranged to match the ground truth. In this setting both methods fail to identify the number of speakers although the ICA iFHMM clearly performs better. The ICA iFHMM finds one too many signal: the spurious signal is very similar to the third signal which suggests that the error is a problem of the inference algorithm and not so much of the model itself. The iICA on the other hand performs poorly: it is very hard to find any structure in the recovered Z matrix. We compared the mutual information as described above and find that the iFHMM has a mutual information of 0 . 091 compared to 0 . 028 for the iICA model. The success of the Hidden Markov Model set off a wealth of extensions to adapt it to particular situations. [2] introduced a factorial hidden Markov model which explicitly models dynamic latent features while in [13] a nonparametric version of the the Hidden Markov Model was presented. In this paper we  X  X omplete the square X  by presenting a nonparametric Factorial Hidden Markov called the Markov Indian Buffet Process. We showed how this stochastic process can be used to build a nonparametric extension of the FHMM which we call the iFHMM. Another issue which deserves further exploration is inference: in [2] it was found that a structured variational method provides a good balance between accuracy and computational effort. An interesting open problem is whether we can adapt the structured variational method to the iFHMM. Finally, analogous to the two-parameter IBP [14] we would like to add one more degree of flexibility to control the 0  X  1 transition probability more finely. Although the derivation of the mIBP with this extra parameter is straightforward, we as yet lack a stick breaking construction for this model which is crucial for our inference scheme.
 Acknowledgments We kindly acknowledge David Knowles for discussing the generalized Amari error and A. Taylan Cemgil for his suggestions on blind source separation. Jurgen Van Gael is supported by a Microsoft Research PhD scholarship; Zoubin Ghahramani is also in the Machine Learning department, CMU. References
