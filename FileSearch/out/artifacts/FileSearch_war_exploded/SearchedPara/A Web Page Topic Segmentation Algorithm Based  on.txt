 This paper presents experiments using an algorithm of web page topic segmentation that show significant precision improvement in the retrieval of documents issued from the Web track corpus of TREC 2001. Instead of processing the whole document, a web page is segmented into different semantic blocks according to visual criteria (such as horizontal lines, colors) and structural tags (such as headings &lt;H1&gt;~&lt;H6&gt;, paragraph &lt;P&gt;). We conclude that combining visual and conten t layout criteria gives the best results for increasing the precision: the ranking of the page is calculated for relevant segmen ts of pages resulting from the segmentation algorithm. H.3.1 [ Content Analysis and Indexing ]: Abstracting methods-Indexing methods; H.3.3 [ Information Storage and Retrieval ] Algorithms, Measurement, Perfo rmance, Experimentation. Segmentation, topic analysis, ev aluation, block X  X  coherence. Most information retrieval syst ems on the Web process web pages as the smallest and undividable un its of information, whereas a web page as a whole may not be appropriate to represent a single topic. A web page usually contains various contents which are not all related to the same topic. Mo reover, a web page often contains multiple topics that are not necessarily semantically linked to each other. Therefore, detecting the semantic content structure of a web page could potentially improve the performance of web information retrieval. Many web applications can use the semantic content structure of we b pages to improve information retrieval. Previous work uses ad hoc methods to deal with different types of web pages. If we can get the semantic content structure of the web page, wrappers could be built more easily and information could be extracted more easily. A straightforward approach for segmenting web pages is to use tag information. Usually, a small set of tags serves as segment types of segments: paragraph, table, list and headings, respectively. [4] treats segments of web pages in a learning based web query processing system and d eals with these major types of tags. In [6], only &lt;TABLE&gt; tag is used to partition a page into several blocks, its offspring as a content block and it uses entropy based approach to discover inform ative ones. Similarly, in [1], several simple tags, such as &lt;P&gt;, &lt;TABLE&gt; and &lt;UL&gt; are chosen to divide the web page for subsequent conversion and summarization. A Function-base d Object Model (FOM) is proposed in [3]. FOM attempts to understand author X  X  intention by identifying object functions. VIPS (VIsion-based Page Segmentation) algorithm [2] extracts the semantic structure for a web page. In VIPS, a tree structur e is used to model the page. Each node corresponds to a block in a page, and has a value to indicate the Degree of Coherence. The DOM tree is analyzed from root to leaves and the DOM nodes are divided, based on their spatial layout and visual cues. [5] describes an HTML web page segmentation algorithm for dividing online medical journal articles. In [5], the web page content is modelled by a zone tree structure based on the geometric layout of the web page. A single web page often contai ns multiple semantics and the different parts of the web page ha ve different importance in that page. We suppose that there are two types of Web pages: single topic Web page and multi-topics Web pages. The contents of single topic Web page are homogeneous, while multi-topics Web pages are divided into several blocks of homogeneous contents. The textual contents of a page follow sequential organization of the topic. Topic analysis is based on boundary delimitation. In the case of flat texts, we distinguish two types of basic units: the sentence with is made up of a fixed number of words and paragraphs. However, in the case of World Wide Web, a document is composed of textual contents and HTML structure. The authors use both visual criteria like the horizontal lines, vertical lines, colors, and content layout of the page like headings to separate possible segments into different topics. The separation mode differs from an author to a nother, and the visual criteria and content layout tags are not used in different cases as segment delimiters, from where a major pr oblem to segment Web pages. Consequently, the criteria of de limitation of segments are random and do not depend on specific rules to respect. We propose a solution for Web page segmen tation based on evaluation of several segmentations by usi ng a topic analysis method. Furthermore, the topic segmen tation algorithm based on visual criteria and content layout is described as follows: different segments are extracted from each web page of the TREC collection, by using various segm ent delimiters appearing in the page and that have been chosen from a predefined criteria list. One solution per criterion is generated. So, the result is a set of segmentation solutions. After that, the evaluation function is applied for each solution of segmentation. The best segmentation solution is checked and the block index is created. The goal of our idea is to find a solution of segmentation based on visual criteria (lines, color) and content presen tation (paragraph, subtitles) in order to extract blocks that are coherent inside their contents and for which the distance between them is great. Our contribution compared to the various segmentation algorithms that we studied before consists in dividing web pages into topic segment units. Really, our topic segmentation algorithm is a method for partitioning Web pages into coherent segment units that correspond to a sequence of sub topical passages. The algorithm assumes that a set of words are used during the course of a given subtopic discussion, and when that subtopic changes, a significant proportion of the vocabulary changes as well. With our evaluation function of segmentation solutions , we maintain only candidate delimiters for segmenting a Web page by eliminating noisy HTML tags. The segmentation evaluation func tion is calculated with two measures: a block X  X  content coherence and a distance between these blocks. The block X  X  conten t coherence measure is applied inside the segment, and depe nds on the co-occurrence between terms belonging to the same segm ent. This measure reflects the density of the information linked to one topic and the degree of correlation between terms of the block. The second measure is based on a similarity measure be tween two segment vectors. The distance between adjacent blocks allows us to locate boundaries between the dissimilar neighbouring blocks. The evaluation function is described as follow: Where S j is a segmentation solution of the page P based on the visual criterion j . nb(P,S j ) represents the number of blocks extracted from P according to the solution of segmentation S best segmentation solution is the one which has the greatest value of the function. Coh(b) is the coherence inside the block b which is calculated as follow: Where Nbdoc(t1,..,tn) represen ts the number of documents containing all the terms t1,..,tn and nt(b) is the number of terms of the b block. Dist(b k ,b k+1 ) represents a distance measure between adjacent blocks. This measure is defined as follows: Where V bk and V bk+1 are block vectors of b k and b k+1 The weight of each term is calculated by using Okapi25 measure . Our experiments are based on Web Tracks of TREC 2001. We used OKAPI BM25 measure in our ranking function. We compare two categories of algorithms (DocRank and BlockRank). DocRank (P) represents the BM25 score of the page P and BlocRank(P) represents the higher BM25 score of blocks of the page P . From table 1, we can s ee that BlockRank performed better results than DocRank, either on MAP or P@5 or P@10 on TREC collection. For example, the result achieved 58%, 75% and 57% improvements over the DocRank algorithm on MAP, P@5 and P10 on WT10g. In this paper, we proposed a topic segmentation method which allows us to extract semantic bl ocks from Web pages using visual criteria and content presentation HTML tags. The topic segmentation algorithm is a method for partitioning Web pages into coherent segment units that correspond to a sequence of sub topical passages. We performed e xperimental evaluations of our algorithm using information retrieva l test collection of TREC 9. We found that our web page topic segmentation algorithm improve information retrieval by indexing documents more precisely and by subdividing text s into thematically coherent segments. Our topic segmenta tion method allows to better estimate the relevance compared to the request [1] Buyukkokten, O., Garcia-Molina, H., and Paepche, A., [2] Cai, D., Yu, S., Wen, J.-R., and Ma, W.-Y., Extracting Content [3] Chen, J., Zhou, B., Shi, J., Zh ang, H., and Wu, Q., Function-[4] Diao, Y., Lu, H., Chen, S., and Tian, Z., Toward Learning Based [5] Jie, Z.D.L., and George, R. T., Combining DOM Tree and [6] Lin, S.-H., and Ho, J.-M., Di scovering Informative Content 
