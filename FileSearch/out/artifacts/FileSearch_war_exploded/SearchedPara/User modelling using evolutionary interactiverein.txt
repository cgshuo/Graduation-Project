 H. O. Nyongesa  X  S. Maleki-dizaji
Abstract As the volume and variety of information sources continues to grow, there is increasing difficulty with respect to obtaining information that accurately matches user in-formation needs. A number of factors affect information retrieval effectiveness (the accuracy of matching user information needs against the retrieved information). First, users often do not present search queries in the form that optimally represents their information need.
Second, the measure of a document X  X  relevance is often highly subjective between different users. Third, information sources might contain heterogeneous documents, in multiple for-mats and the representation of documents is not unified. This paper discusses an approach for improvement of information retrieval effectiveness from document databases. It is pro-posed that retrieval effectiveness can be improved by applying computational intelligence techniques for modelling information needs, through interactive reinforcement learning. The method combines qualitative (subjective) user relevance feedback with quantitative (algorith-mic) measures of the relevance of retrieved documents. An information retrieval is developed whose retrieval effectiveness is evaluated using traditional precision and recall.
Keywords User information needs modelling . Interactive evolutionary learning
Information relevance . Adaptive information retrieval 1. Introduction
The emergence of the World Wide Web (WWW) has resulted in access to a vast and expo-nentially growing, unstructured and dynamic network of information sources. There is also increasing focus on digital libraries as a means of making educational and scholarly informa-tion readily and easily available on-line. However, it can now be argued that the volume of information available on-line is becoming a hindrance to effective information retrieval. It is timely and necessary, therefore, to build new tools aimed at helping users retrieve documents that satisfy their information needs accurately and efficiently. Current methods for searching information sources, such as the WWW, retrieve documents from a collection in response to a user X  X  query, which is compared (typically at keyword level) against documents in a collection to find those most likely to be related to the query. Users then have to scan through hundreds of retrieved documents to identify information that is relevant to their needs. This is a time-consuming exercise. Furthermore, the same process of identifying relevant documents is repeated each time the user searches the same or similar information sources. An optimal information retrieval (IR) system is one which would be able to obtain from an information source only those documents that are relevant to a user X  X  information needs, while at the same time excluding documents that are non-relevant. The concept of relevance, however, is one that is a major topic of discussion in Information Sciences on which there is not universal con-vergence. Early studies on the concept of relevance and relevance assessment include Cuadra and Katter (1967) and Saracevic (1975). More recently Harter (1992), Saracevic (1996) and
Mizzaro (1998) have propounded more divergent views on the concept of relevance. Borlund (2003) presents a comprehensive overview of the different interpretations and opinions on the concept of relevance.

The effectiveness of an IR system is determined primarily by the relevance assessment of retrieved information (Saracevic, 1996; Ingwersen, 1996). These authors among others, categorise relevance into two main classes: Objective relevance and subjective relevance.
Objective relevance is an algorithmic measure of the degree of similarity between the query representation and the document representation. It is also referred to as a topicality measure, referring to the degree to which the topic of the retrieved information matches the topic of the request (Harter, 1992). Subjective relevance, on the other hand, is user-centric and deals with fitness for use of the retrieved information (Vakkari and Hakala, 2000). Subjective rele-vance, therefore, involves intellectual interpretation by human assessors or users (Borlund and
Ingwersen, 1998) . Subjective relevance, hence, should be seen as a cognitive, dynamic pro-cess involving interaction between the information user and the information source. Schamber et al. (1990) suggest that relevance criteria derived from users X  perspective are the most ap-propriate approach to obtain a complete and useful understanding of the dimensionality of relevance. Schamber (1994) published a list of 80 relevance criteria compiled from literature, which the author furthermore points out is not exhaustive. Among the factors that influence the subjective relevance of a retrieved document are: user knowledge, user perception, in-formation currency and clarity of the retrieved information. In spite of great improvements in the effectiveness of search engines (Voorhees and Harman, 2000; Buckley et al., 1998), a large proportion of documents retrieved are often assessed as not relevant to user information needs. This is because subjective relevance per se is fundamentally multidimensional (indi-vidual); any one assessor X  X  judgement is as valid an assessment as another X  X  (Borlund and
Ingwersen, 1998; Borlund, 2003), if the retrieved information meets, or does not, his or her information needs. Borlund and Ingwersen (1998) introduced relative relevance as a measure to bridge the gap between objective and subjective relevance assessments by computing the degree of agreement between the different types of relevance used in evaluation of IR sys-tems. The authors also introduced another measure, the ranked half-life, which indicates the ability of the IR system to present the retrieved information as high up a ranked list according to the user X  X  assessment of the retrieved documents.

In an attempt to deal with the multidimensionality of relevance assessment, this paper presents an approach for applying subjective relevance assessments of documents returned by an IR system, as a means to derive and adapt user information needs models that can be used to improve information retrieval effectiveness. The paper describes a machine learning approach for acquisition of the user information needs models from relevance feedback provided by users. In this approach, an evolutionary algorithm is used for interactive reinforcement learning in combination algorithmic relevance (similarity) measures. The novel feature of the approach, compared to other studies (Petry et al., 1993; Vrajitoru, 1998) is to combine interactive user feedback and traditional similarity measures with exploratory search for identification and adaptation of user information preferences. Exploratory search is proposed because it is assumed that user information needs cannot be precisely specified and can gradually change over several sessions of interaction with the IR system. On one hand, this may occur dynamically as the information need becomes more focused on or diverges from the initial information request. On the other hand, the currency (relevance) of the retrieved information will diminish over several sessions of interaction or period of time.
When the information needs change, the system must be able to modify its representation of the user information needs. The proposed IR system applies evolving user models, using genetic algorithms (Goldberg, 1989), for exploration of newer information domains and to suggest new items of potential interest to the user. Exploration, thus, improves the adaptation process in the face of changing user interests and can help to match a hitherto unknown user interest. At this juncture, we note that Campbell and van Rijsbergen (1996) developed an
IR system which applies ostensive evidence provided by a user to suggest other sources of information for the user to explore. The approach addresses the exploratory capability of IR systems proposed by Doyle (1963), which attempts to deal with the issue of users X  inability to express their information needs precisely. Campbell and van Rijsbergen X  X  (1996) approach, however, differs from the evolutionary algorithm proposed in this paper in the sense that the evolutionary algorithm evaluates and adapts several probabilistically generated information needs models using neo-Darwinian survival of the fittest techniques. This concept is discussed in section 4 of the paper.

The rest of the paper is organized as follows. Section 2 presents an overview of adaptive and learning approaches in IR, while Section 3 introduces user information needs modelling.
Section 4 discusses the proposed evolutionary learning approach for user information needs modeling and its implementation in an IR system. Section 5 presents the evaluation of the IR system and, in particular, comparison with conventional relevance feedback techniques.
Conclusions from the paper are given in Section 6. 2. Information retrieval: an overvew
Keyword based IR systems are popular mainly due to their simplicity. However, the per-formance of such systems ultimately suffers the so-called keyword barrier (Mauldin et al., 1987): keyword based systems cannot convey the semantic context of documents. But, the semantic context alone may not satisfactorily express the relevance of a document in re-lation to its eventual usefulness. User information needs modelling has been proposed to address this question, and two different approaches are commonly used: knowledge based approaches (Chen and Dhar, 1995) and machine learning approaches (Chen et al., 1998).
Knowledge-based approaches involve endowing the IR system with a great deal of domain specific background knowledge about different users, usually, gleaned from human experts.
This enables the creation of clusters or stereotypes of such users. Such knowledge can then used to customise the interaction with different users. The main deficiencies of the knowl-edge based approach are, firstly, the effectiveness of the system is only to the extent it is programmed, and secondly, a significant effort and a priori knowledge are required from the domain experts in order to build the IR system. In machine learning approaches the IR sys-tem is designed to autonomously acquire knowledge through interactions with the user. The advantages of this approach are that it requires less effort from users, or domain experts, and the system is able to adapt to changes in user information needs over time. Machine learning techniques for this reason offer an approach for generating and adapting user models in IR applications.

Three basic functions are carried out in IR systems: representation of the content of docu-ments, representation of users X  information needs, and comparison of the two representations (Croft, 1993). Representation of a document is usually called indexing, and the most com-mon representation is a set of features derived from the document collection, such as, a set of keywords from the document collection. A number of pre-processing steps are, usually, carried out before words become features. Typically, words will have their letter cases nor-malised; stop words such as prepositions, determiners and pronouns are removed, and words are stemmed to replace them with their root forms. An additional subtlety that is common in
IR systems is the assignment of numerical weights to feature terms, to quantify the terms X  significance to the subject matter of the document.

Representing an information need is often referred to as query formulation (Baeza-Yates and Ribeiro-Neto, 1999). In a general sense, query formulation involves the interaction between the system and user, leading not only to a suitable query but possibly also to a better understanding by the user of his or her information needs. For example, relevance feedback is a general technique that allows a user to interactively express an information requirement by modifying successive query formulations using extraneous information, and is very useful in text and image retrieval. The additional information is often inferred from the list of relevant documents among the documents retrieved by the system. The comparison of the query against document representations is called matching and results in a (hyper-linked) list of potentially relevant documents.

The main objective of IR is the retrieval of relevant documents. Ranked retrieval puts the most relevant documents at the top of a ranked list, minimizing the time the user has to invest in reading the list of documents. Many types of models are used for the matching query and document representation including binary models, vector space models and probabilistic models (Zhang and Korfhage, 1999). These models are called approximate matching models, because they use the frequency distribution of terms over documents to compute the ranking of the retrieved sets. 3. User information X  X eeds modelling
User information needs modelling can be defined as the effort to define a relevance framework from the users X  perspective and employ this to improve the retrieval effectiveness of the system by predicting user information needs. User profiles can be represented using a wide range of techniques, from simple keyword-based files to more intelligent representations involving contextual and semantic attributes. A common approach for constructing user profiles is to require the user to provide the necessary keywords that define their information needs.
This approach, however, is unsatisfactory because it requires much effort from the user, and an understanding of the vocabulary of the information source. An alternative approach is to collect and analyse user information preferences and use these to build user profiles dynamically. This can be accomplished as follows. At the very start the user provides a set of keywords which describe an initial, primitive model of information preferences. The system uses this profile to select documents which are potentially of interest and presents them to the user. The user then provides feedback on the relevance of the documents, which the system uses to adjust the user profile. In the objective definition of relevance, the measure of relevance is a static algorithmic relationship between the query representation and the retrieved documents and hence, is independent of any knowledge by the information seeker. In the subjective definition, however, relevance assessment is a cognitive user-centred exercise, which means two users presenting the same query to an IR system may give different relevance judgments on the retrieved documents. To complicate matters, it is useful to note that a typical user may have multiple and overlapping interests.

IR systems that learn from user feedback modify either the query representation or the document representation (Sebastiani, 2002). Document feature-vector modification improves document indexes based on user assessment of the relevance of retrieved documents. Using such a technique, the vectors of documents previously retrieved in response to a given query are modified by moving the vectors closer to the query vectors, and at the same time moving irrelevant documents away from the query. When a document feature is present in the query its weight is increased, while, conversely, when feature is not in the query, its weight is decreased (unless it was not present in the document representation). In query modification, the user is provided with interactive query refinement mechanisms, which allow the system to automatically refine the query and resubmit it to retrieve a new set of documents (Sebastiani, 2002). The process continues until the system cannot provide any new documents that satisfy the latest version of the query. This approach is adopted in this paper, to enable the derivation of user models with no a priori knowledge of the user X  X  information needs. Specifically, the user information needs model is evolved starting from randomly chosen feature vectors. The approach is discussed in the next section. 4. Evolutionary modelling of user information needs
User information needs modeling proposed in this paper, applies an evolutionary, genetic algorithm (GA) (Goldberg, 1989) to evolve and adapt query vectors that are representative models of user information needs. The user information needs models represent hypothetical knowledge about user information needs, which are encoded in the GA as search features.
In other words, a user information needs model is a fixed number of keywords which can change through GA operations. Furthermore, the exact significance and relationship between features in determining the relevance of retrieved documents is not explicit, but evolves under the GA. In this paper, the vectors are expressed as keyword terms and associated weights.
Search vector are used to retrieve documents whose relevance is assessed according to user information needs, and compete against other search vectors to match the user information needs. In order to effect adaptation of the user model within a reasonably short time, it is assumed that user information needs are stochastic but non-transient. In other words, the information needs vary in a subjective non-deterministic manner between users, but they do not change rapidly over time. In this way, a GA can evolve a model for one user information need. However, it is recognized that a user may indeed have several, different information needs. There are two possibilities for dealing with such a situation. Either, the length of the model vectors could be made sufficiently long to accommodate feature vectors for the different information needs. Alternatively, the different information needs models can be evolved within the same population, using a so-called multi-objective GA. Both cases have not been addressed in this paper.

GAs are blind, probabilistic search mechanisms, which for online learning applications it is always advantageous to initialize with any a priori knowledge in order to avoid undesirable degradation in performance in the early stages of learning. In constructing the information needs models a vocabulary of keywords terms was predetermined to be inclusive for a group of users with diverse information needs. Search vectors, which represent the information needs models of individual users, are comprised of pairs, ( t , w ) where t is a keyword term and w is the term X  X  weight. The keyword terms are randomly selected from the vocabulary pool, and the weights are initially set to small random values between 0.0 and 1.0. The query vectors are initially assigned an (equal) value called fitness , which is proportional to the mean similarity between all vectors. In the present case, the query vectors are comprised of 30 ( t , w ) pairs, and a typical population of vectors was 20. The representation of the query vectors is illustrated below:
In order to adapt and improve the information needs models, a GA operation called crossover is carried out on pairs of model vectors to generate new (offspring) vectors (Gold-berg, 1989). This is carried out as follows. First, two (parent) vectors are probabilistically selected from the population of vectors. Next, two random positions along the vector are chosen as crossover points. Then, all keywords and weights between the crossover points are copied into respective positions in offspring (parent1 to offspring1, parent 2 to offspring 2). For positions outside the crossover points, keywords are copied from the opposite parent, in order, if they don X  X  already exist in the offspring. This is illustrated as follows, where the crossover points are marked as | . Consider two parent vectors, where keyword pairs are shown as letters for clarity as: The new (offspring) vectors, according to the operation described above are,
Another GA operation called mutation is carried out by replacing randomly selected vectors positions by other random choices of keywords from the vocabulary pool. In this manner, information needs models are evolved and adapted from the population of possible models.
The key role for GA in user-needs modeling is to continuously modify the representation of user needs. In this paper, this is based on quantitative and qualitative relevance metrics.
On one hand, a quantitative (algorithmic) metric is given by the similarity between the user-model chromosome and the documents retrieved using the chromosome. On the other hand, each of the retrieved documents is given a qualitative assessment, interactively by the user.
These two measures are then combined through a fuzzy inference system to derive an overall parameter that is used to adjust the  X  X itness for use X  of competing information needs models.
This is a novel learning approach we have termed evolutionary interactive reinforcement learning (EIRL).

The fuzzy inference system used to adjust the fitness of competing information need models is a rule-based system that uses the similarity between a search vector and a retrieved document, and the user feedback to derive the required fitness modification for the search vector. These rules are, in general, heuristic but were fine-tuned by experimenting with the system. The underlying philosophy of the rules is to reward those vectors, which retrieve documents that the user judges to be relevant to his or her needs, and penalize those the user judges to be irrelevant. Thus, if the user judges a document to be relevant then the fitness of the search vector used for retrieval of the document should be increased, and especially more so if the algorithmic similarity measure is low. Conversely, if the user feedback is poor (not relevant) but, the algorithmic similarity between query and documents is high then the fitness of the chromosome should be reduced significantly. Users provide an assessment of the documents over a scale of [0 . . . 10], and the similarity is calculated over a scale of [0.0 . . . 1.0].

Fuzzy inference systems function using so called linguistic variables, which are variables whose values are words. It is therefore necessary to convert the numeric inputs, described above, into linguistic values. This is done through the fuzzy membership functions, which are shown in Fig. 1 for both similarity and user feedback. The inference rules are shown in Table 1. In both cases the linguistic values are abbreviated as follows: Similarity and feedback values: -Very Poor ( VP ), Poor ( P ), Moderate ( M ), Good ( G ), Very Good ( VG ); Fitness adjustment values: -Increase High ( IH ), Increase Moderate ( IM ), Increase Low ( IL ), Decrease Low ( DL ), Decrease Moderate ( DM ), Decrease High ( IH ).

Consider, as shown in Fig. 1, that for a given retrieved document the similarity to the search vector is 0.3 and the user relevance feedback is 6.0. It is seen that the similarity measure has membership,  X  s of 0.2 to the linguistic value M and 0.8 to the linguistic value P . Similarly, user feedback of 6.0 has membership,  X  f of 0.6 to linguistic value M and 0.4 to linguistic value G . Referring to Table 1, the conjunction of the input parameters, similarity and feedback results in four possibilities for fitness adjustment: IM, IL, IM and IL, as highlighted in the Table. Using the rules of fuzzy inference, the degree to which each rules is activated (also called weight, w )isgivenby min of the degrees of the individual parameters. Thus, the output of the first rule is IM with weight, w 1 equal to min(0.4, 0.8) i.e. 0.4, the second IL with weight w equal to min(0.6, 0.8) i.e. 0.6, the third IM with weight w and the fourth IL with weight w 4 equal to min(0.6, 0.2), i.e. 0.2. The rule outputs, were defined equally spaced discrete, rather than fuzzy, values; IH equal to 0.8, IM equal to 0.5 and IL equal to 0.2. The same assignment is used for negative equivalents. Using the rule of weighted averages the overall fitness adjustment,  X  for all rules, j is given by:
The fitness adjustment can be carried out after each user feedback assessment, or as a mean value of adjustments after the all ranked documents have been assessed. Another point to note is that, whereas there are many user information needs models competing to evolve as the optimal user information needs model, in fact, only one plausible model is used to retrieve documents for which user relevance feedback is provided. Consequently, the fitness of the rest of the population of models is adjusted in proportion to their similarity to the model that was used to retrieve documents. Furthermore, a reward-penalty (Narendra, 1974) algorithm is applied whereby a proportion,  X  (  X  0.1) of the current fitness is deducted at the same time. This prevents the fitness of any model representation increasing without bounds.
The overall fitness adjustment thus, is given by, where, Q 0 is the evaluated user model, q j are the other competing models and Sim is their similarity function given by, where t i are the keywords terms in the user model and w i
It is also necessary to adjust the weights of the terms that make up the user information needs models. This is due to the fact that the initial term-weights are randomly assigned and might not accurately represent the relevance of the documents to the user. Term-weight adjustment is also carried out using the output of the fuzzy inference system and is given by, where d 0 is a retrieved document vector, q j are the query vectors, i are terms in the query vectors and k are index terms of the retrieved document. In other words, a term weight is only adjusted by  X  , if contained in both the query and the retrieved documents. Term weighs are furthermore bound within [0.0 ... 1.0]. 5. Evaluation of the IR system
Evaluation of any IR system calls upon examination of many issues including human com-puter interaction, usability and applicability of the system. In this paper, however, the only aspect of evaluation that is of concern is the number of relevant documents retrieved with respect to a query. This aspect of evaluation is known as retrieval effectiveness. The effec-tiveness of an IR system expresses how well the produced output satisfies a user X  X  infor-mation need. The common performance indicators of retrieval effectiveness of IR system are recall and precision. Both indicators can be based on the user X  X  subjective relevance as-sessments following the retrieval process. Recall measures the completeness of the output, which is the ability of the system to retrieve all relevant information. Precision measures the relevance of the output, in other words, the ability of the system to reject irrelevant ma-terial. A good IR system should exhibit both high recall and high precision. In the present study, a fixed ranked list of retrieved documents was produced by the IR system, which implies that recall measures are not meaningful. Thus, for the fixed number (10) of retrieved documents: where w  X  (0.0 ... 10.0) is the scaled relevance judgement value, n is the total number of retrieved documents and r is the number of relevant items in the collection.

The first stage was to evaluate the performance of the proposed evolutionary learning technique. This involves carrying out several experiments with the IR system, in order to fix the optimal GA parameters for the most efficient learning. 1. The IR system creates an initial random population of 20 query vectors as described in
Section 4. Each query vector represents a plausible user information needs model. 1.1. A GA parameter value was set, in this case the probability of crossover Pc. One of the 1.2. Each retrieval produced a fixed list of 10 documents, for which user relevance feedback 1.3. The relevance evaluation was used to assign fitness to the population of search vectors. 1.4. GA operators were used to create a new population of search vectors. 1.5. The process is iterated from step 1.1, 10 times. The mean (or best) precision over the 2. The experiments are repeated from step 1, 4 times. The mean of the values recorded at step 1.5 is recorded for each GA parameter setting.

As shown in Fig. 2, low values for the crossover parameter do not show significant learn-ing improvement. This is because at low crossover values, fewer new search vectors are introduced to the population, which results in a longer time for the system to improve its per-formance. Conversely, too high a value for the crossover parameter results in introducing new vectors too quickly, which causes the system to change the population of user models more quickly and more randomly, regardless of user relevance feedback. The best performance of the system is given by medium values between 0.6 and 0.7 for crossover probability. The second stage was to carry out interactive retrieval sessions with the different users. The experiments were carried using five PhD students in the area of Computer Science and Information Systems in the School of Computing and Management Sciences at Sheffield Hallam University, United Kingdom. The evaluated documents were obtained from the Bath
Information and Data Services (BIDS) (www.bids.ac.uk). From the areas of the information needs of the assessors, 300 documents were selected and another 100 noisy documents, which had some common keywords but the contents were not relevant to the users X  information needs, were added. The retrieval effectiveness experiments were carried out as follows. 1. The IR system creates an initial random population information needs models (search vectors), and sets optimal GA parameters. 1.1 In each iteration a search vector is selected and used to retrieve documents. 1.2 The 10 documents retrieved are assessed for relevance and, the recall and precision 1.3 The IR system applies evolutionary learning as has been described in Section 4 to 1.4 The process is repeated from step 1.1, 20 times.

The results shown in Figs. 3 and 4 are the mean value in each iteration for the five different information needs.

A comparison was made of information retrieval effectiveness of the proposed evolu-tionary learning IR system against a conventional relevance feedback (RF) technique. RF is a technique that allows interactive reformulation of search query using information gained from retrieved documents known to be relevant (Salton and Buckley, 1998). RF applies query reformulation where terms from relevant documents are added, and terms from non-relevant documents are removed from the query vector. Figures 3 and 4 show the average precision and recall for both techniques. It is shown that overall the performance of the evolutionary approach, EIRL is higher than conventional RF, although it can be observed that in the case of EIRL there are large fluctuations in performance over the period of user interaction with the
IR system, which are attributable to the probabilistic nature of evolutionary learning. How-ever, a statistical analysis was carried out to determine the significance of any differences between the two methods. Thus, a significance test was adopted to reject the null hypothesis,
H 0 that there is no difference between method EIRL and RF. The hypothesis was tested by comparing average precision values, across all queries. The paired t -test was used because it is particularly useful for small samples, in this case the mean retrieval performance with 5 different users. The result of the test was t equal to + the probability, assuming the null hypothesis to be true, of obtaining a test statistic that is contradictory to the null hypothesis. The null hypothesis is rejected if the P -value is less than or equal to a prescribed confidence level. In other words, from the statistical analysis we can claim that EIRL performs better than RF, with a confidence level of 96.8%. 6. Conclusion
An adaptive IR system must be able to specialize to user interests, adapt as they change and explore new domains for potentially relevant information. In this paper, we have described a novel approach for improving document retrieval effectiveness by combining fuzzy rele-vance feedback and evolutionary reinforcement learning. This approach has been evaluated especially for applications where user information needs are subjective but relatively static, and hence can be accurately modelled over a short period of time.

Results obtained in this study suggest that the proposed approach, in general, performs better than conventional relevance feedback. Previous studies (Vrajitoru, 1998; Chen et al., 1998), did not show any improvement over conventional relevance feedback when using an evolutionary approach for user modelling. This, however, can be attributed to the fact that they used binary coded genetic algorithms to represent the presence or absence of keywords.
The proposed approach encodes chromosomes as keywords and their weights to imply their significance to user information needs profiles. The improvement in retrieval effectiveness, it is argued, is achieved by on-line reinforcement learning through interaction with users.
Human interactive reinforcement provides a direct evaluation of the relevance of documents, namely, user preference that cannot be expressed by any analytical fitness function. This results in a user model that is, in fact, optimised by the user. The result also indicated that, in most cases, the maximum value for retrieval precision was reached in about 10 generations, which suggests that learning can achieved in a relatively short period of interaction. This is desirable in order that specialization to user information needs is not a time-consuming exercise. However, if the user information needs model was to change evolutionary operators enable the IR system to learn the new model. It is pointed out, however, these result was obtained in simulated tests using a selected, fixed size document collection.
 References
