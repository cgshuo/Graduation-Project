 ORIGINAL PAPER Richard Zanibbi  X  Dorothea Blostein Abstract Document recognition and retrieval technologies complement one another, providing improved access to increasingly large document collections. While recognition and retrieval of textual information is fairly mature, with wide-spread availability of optical character recognition and text-based search engines, recognition and retrieval of graph-ics such as images, figures, tables, diagrams, and mathemati-cal expressions are in comparatively early stages of research. This paper surveys the state of the art in recognition and retrieval of mathematical expressions, organized around four key problems in math retrieval (query construction, normali-zation, indexing, and relevance feedback), and four key prob-lems in math recognition (detecting expressions, detecting and classifying symbols, analyzing symbol layout, and con-structing a representation of meaning). Of special interest is the machine learning problem of jointly optimizing the component algorithms in a math recognition system, and developing effective indexing, retrieval and relevance feed-back algorithms for math retrieval. Another important open problem is developing user interfaces that seamlessly inte-grate recognition and retrieval. Activity in these important research areas is increasing, in part because math notation provides an excellent domain for studying problems common to many document and graphics recognition and retrieval applications, and also because mature applications will likely provide substantial benefits for education, research, and mathematical literacy.
 Keywords Math recognition  X  Graphics recognition  X  Mathematical information retrieval  X  Content-based image retrieval  X  Human-computer interaction 1 Introduction In practice, the problem of retrieving math notation is closely tied to the problem of recognizing math notation. For exam-ple, a college student may want to search textbooks and course notes to find math notation that has similar structure or semantics to a given expression, or a researcher may wish to find technical papers that use or define a given function. In both of these examples, recognition of math notation is needed in order to support the retrieval of math notation: the system must be able to recognize math expressions that the user provides as a query, and the system must be able to recognize math expressions in the target documents that are the subject of search. Retrieval of math notation has received increasing research attention in the past decade (see Sect. 3 ), while math recognition has been a subject of research for over forty years (see Sect. 4 ). To our knowledge, we pro-vide the first survey of mathematical information retrieval; in surveying math recognition, we focus on research that has appeared in the decade since the survey of Chan and Yeung [ 28 ].

The math domain provides an excellent vehicle for studying pattern recognition and retrieval problems, and for studying methods of integrating pattern recognition algo-rithms to improve performance. The four central pattern recognition problems X  X egmentation, classification, pars-ing, and machine learning (i.e., optimizing recognition model ( a ) (b) (c) parameters) X  X ll come into play when recognizing math-ematics. The math domain offers sufficient complexity to challenge researchers, yet has characteristics that make the domain tractable: the semantics of math notation are fairly constrained, and a typical math expression consists of rela-tively few symbols.

The input to a math recognition system can take three forms: vector graphics (such as PDF), strokes (such as pen strokesonadatatablet),ora document image .Theprocessing that is needed to extract expressions and recognize charac-ters depends greatly on the form of input. For example, a PDF document directly provides encoded symbols, so there is little need for character recognition [ 13 , 14 ]. Figures 1 and 2 illustrate systems that accept various forms of input: vector graphics is shown in Fig. 1 b; strokes are shown in Figs. 1 a and 2 a, b, c, d; and a document image is shown in Fig. 1 c.
In the next sections, we discuss key recognition and retrieval problems as they apply to all three forms of input. As the need arises, we point out situations in which differ-ences in input format cause large differences in processing methods. 1.1 Overview of math notation recognition Math recognition is used for various purposes. For exam-ple, a user may write an expression by hand and insert the recognition result (e.g., a L A T E X string or image) into a docu-ment.Alternatively,arecognizedexpressioncanbeevaluated using a computer algebra system such as Maple or Math-ematica. Another option is to use the recognized expression as a query, to retrieve documents containing similar math notation. Recent work in human-computer interaction fur-ther motivates the development and use of pen-based math entry systems. Bunt et al. study mathematicians in a research setting, and find that in order to be useful, CAS systems need to support annotation, provide multiple levels of formality, and provide more transparency for the operations that they apply [ 23 ]; they suggest that pen-based systems for math might be used to address these needs.

Math recognition also finds application in tutoring sys-tems. For example, when middle school and high school students tested a math tutoring prototype (based on FFES/ DRACULAE), students using pen entry completed their math tutoring sessions in half the time of those that typed, with no significant difference between their pre-to-post test score gains [ 7 ].

The following four key problems arise in the recognition of math notation, as illustrated in Fig. 3 . 1. Expression Detection (Sect. 4.1 ). Expressions must be 2. Symbol Extraction or Symbol Recognition (Sect. 4.2 ). In 3. Layout Analysis (Sect. 4.3 ). Analysis of the spatial rela-4. Mathematical Content Interpretation (Sect. 4.4 ).Symbol Figure 3 illustrates a series of stages commonly used in rec-ognition of mathematical notation. The order of stages can vary [ 18 ]. Intermediate results produced by one stage may provide contextual information to constrain analysis in other stages, or to constrain the analysis of other parts of the input. This is discussed further in Sect. 4.6 .

The first publicly available math recognition systems appeared about a decade ago, building on math recognition research dating back to the late 1960s [ 5 , 6 , 17 , 31 ]. The 1999 applet 1 created by Matsakis et al. recognizes simple hand-writtenexpressions[ 100 ].In2001,ChenandYeung[ 30 ]pub-lished a paper on the first pen-based calculator. In 2002, the FFES/DRACULAE pen-based equation editor 2 [ 135 , 165 ] was distributed as an open-source prototype. Several more recent systems recognize handwritten [ 81 , 133 , 144 ] and typeset [ 46 ] expressions. Commercial applications began to appear, including MathJournal, 3 and pen-based entry in the Windows operating system [ 114 ]. The Infty math OCR sys-tem of Suzuki et al. has also been influential [ 71 , 140 ]. Infty is sophisticated and supports speech and Braille output for the visually impaired [ 140 ]. Infty supports both document image and pen-based input.

At present, most commercial systems for OCR do not rec-ognize mathematical expressions. To address this, OCR out-put can be annotated with the results produced by a math recognition system. For example, the InftyReader 4 applica-tion (see Fig. 1 c) uses the Infty system to recognize expres-sions and insert corresponding L A T E X strings into the PDF file produced by a commercial OCR system [ 71 ].

User interfaces for expression entry and recognition result visualization are important research topics that we will dis-cuss only briefly here for reasons of space. In addition to the papers cited in Figs. 1 and 2 and mentioned already, the inter-ested reader should consult the following: [ 84 , 119 , 133 , 169 ]. Key issues are ease of input, and visualization of feedback. One repeated observation of interest is that for pen-based systems, presenting recognition results separately from the user X  X  input as a rendered image leads to situations where: (1) in experiments, participants find themselves unable to detect errors reported in the structure of their expression, not because they are not shown, but because they have difficulty perceiving them [ 165 , 169 ], and (2) users try to edit the rec-ognized expression image, rather than the pen-based input [ 82 , 169 ]. 1.2 Overview of mathematical information retrieval Figure 6 illustrates the information retrieval process. The user formulates queries through the Query Interface, and views results through the Result Interface. Indexing, Normaliza-tion, and Matching are three system processes used to pro-cess the document collection and query, and find matches for the query in the collection.

Math recognition can be applied both to the query (e.g., to recognize a stylus-drawn expression, as in Figs. 1 and 2 ) and to the searchable documents (e.g., to recognize math expres-sions in document images or PDF files). Prior to indexing, document images can be annotated with region types (e.g., text, table, figure, image, math), character information, and recognized structure and semantics for detected math expres-sions. Existing math retrieval systems lack the ability to rec-ognize stylus-drawn queries. Instead, template editors are provided to assist in generating query strings; an example is the Math WebSearch prototype (Fig. 5 a).

The following four key problems arise in the retrieval of math notation, as illustrated in Fig. 6 . 1. Query Languages and Query Formulation (Sect. 3.1 ). 2. Normalization (Sect. 3.2 ). In order to reduce variation, 3. Indexing and Matching (Sect. 3.3 ). Retrieval perfor-4. Relevance Feedback (Sect. 3.4 ). During examination of In addition to these four key problems, the evaluation of a math retrieval system is also difficult. Evaluation is discussed in Sect. 3.5 .

Mathematical Information Retrieval (MIR) is a relatively new research area, lying at the intersection of text-based information retrieval [ 62 , 125 ], content-based image retrieval [ 35 , 38 , 132 ], and Mathematical Knowledge Management (MKM [ 25 ]). Mathematical knowledge management is con-cerned with the representation, archiving, extraction, and use of mathematical information. Systems for mathemati-cal information retrieval have been developed for a variety of applications:  X  Finding equations in a database of technical documents  X  Semantic search for expressions on the internet (e.g.,  X  Finding functions in mathematical function libraries such  X  Supporting equation search in online learning tools (e.g.,  X  Searching integral tables [ 41 ]  X  Supporting proof assistants such as Coq [ 9 ].
It is interesting to compare question-answering systems to information retrieval systems. For textual data, Salton dis-tinguishes these two types of systems based on the types of data stored and the form queries take [ 125 ]. Informa-tion retrieval systems use stored data consisting of docu-ments; in contrast, question-answering systems use stored data consisting of facts and general knowledge. Queries in information retrieval systems take the form of keywords and excerpts; queries in question-answering systems use natural language. Recently, question-answering systems for mathe-matical information have been devised [ 171 ]. An example is the well-known Wolfram Alpha web site. 9 The Wolfram Alphaknowledgebaseincludesfactsonmathematicsandsta-tistics, along with many other topics including the sciences, technology, finance, culture, and geography. Wolfram Alpha provides some processing for natural language (though key-words may be used), and responses are returned using a table of relevant facts, figures, and computations. For example, users may request that the system factor a polynomial.
Investigation of image-based math retrieval has recently begun. Retrieval is based on the similarity of math notation images,withoutrecognizingtheirmathcontent.Forexample, Marinai et al. propose a method based on shape contexts for retrieving mathematical symbols [ 96 ], while Yu and Zanibbi propose a retrieval method in which handwritten queries are matched to document images using a combination of X  X  Y cutting and word shape matching [ 161 , 167 ].

According to the framework of Smeulders et al. [ 132 ], math images are a  X  X arrow X  image retrieval domain, with constrained semantics and very controlled scene and sensor properties. For example, math images tend to have stable illumination. However, the math domain does present chal-lenges: images of math are polysemic , meaning that a sin-gle expression may be interpreted in multiple related ways. For example, the meaning or value of an expression varies depending on the variable binding, the type of a variable (e.g., natural, integral, real, or complex), and the interpretation of operators and functions (e.g., the function  X  f  X  is heavily over-loaded). It can be difficult to deduce which interpretation was intended by the author of a math expression. Some clues may be found elsewhere in the document (e.g., definitions of symbols and functions), but often it is necessary to draw on knowledge of the notational conventions used in a certain branch of mathematics.

Having provided an overview of math recognition and retrieval, in the next section we summarize mathematical notation and issues related to the representation and interpre-tation of mathematical expressions. In the remaining sections we continue our discussion of math recognition and retrieval in more detail. 2 Mathematical notation In this section we provide a brief overview of mathematical notationandfileformatsusedtorepresentmathematics.Math notation may be understood as a semi-formal visual language [ 97 ]. As with other two-dimensional notations such as chem-ical diagrams, music notation, and flowcharts, math notation is a graphical language for representing complex interactions between primitive objects [ 21 ]. Defining math notation is dif-ficult, but some resources for study are available, including books on typesetting for mathematics [ 33 , 63 , 74 , 157 ], and a history of the origins and evolution of the notation [ 24 ]. For both people and machines, interpreting the notation provides many challenges: the set of symbols used is very large, and ambiguities and context-dependencies arise in interpreting symbol identity, layout, and semantics (see Fig. 7 ).
In math notation, symbols are used to represent constants (e.g.,  X , e , 0), variables (e.g., a , X  ), operators, functions, and relations (e.g., , fraction lines, f , cos, &lt; ), and the scope of subexpressions (e.g., grouping using (), [ ], {}). Unlike prim-itive arguments or objects in an expression, operations, func-tions, relations and subexpression scopes are also represented implicitly , using the spatial arrangement of symbols (e.g., the implicit multiplication in xy ). Table 1 summarizes the six spatial relationships commonly used in isolated expressions. Both subscripts and superscripts can be placed to the left of the symbol or subexpression they modify, as in the Table 1 example for  X  n choose k  X . Most math recognition systems do not currently accommodate these  X  X refix X  super/subscripts, because they are rare.
Subexpression scopes are often represented using grid (or  X  X abular X ) layouts, where subexpressions are arranged in rows and columns. An example is shown at the bottom of Table 1 . Grid layouts are also used frequently in derivations. A num-ber of well-known symbol shorthands are used to represent patterns and repeated matrix elements; these include ellipses (e.g., x 1 ... x n ), lines, and large symbols such as a large 0 to represent zeros in the upper-triangular region of a matrix.
Mathematical expressions represent an application of functions, operators, and relations to arguments. As can be seen in Table 1 , multiple mathematical statements may be represented by a single expression; in other words, mathe-matical expressions are polysemic . For example, if x is a list the expression x 1 can represent the first or second element in the list. The definition and even role of symbols frequently change; for example, in an arbitrary expression,  X  can rep-resent a variable, a constant, or a binding function as in the Lambda Calculus. Even when the domain is clear, symbol definitions are often ambiguous. Consider P in the context of Bayesian probability: is P used to represent a probability mass function or a probability density function?
Without knowing the precedence and associativity of operations, the order in which operations are to be applied and relations tested may be unclear. For example, in Table 1 , x 1 is indicated as representing the square of x 1 ; in another context, this might be representing a restriction on sequence x , where the precedence of operations is reversed. The pre-cedence of operators is determined using the following [ 19 ]:  X  Operator range defines legal spatial locations for argu- X  Operator dominance (Chang [ 31 ]), defines a partial  X  Operator associativity orders application when two or  X  Operator precedence orders the application of different An unambiguous definition for operator range, dominance, associativity, and precedence imposes a unique evaluation order on an expression. The result may be represented as an operator tree, with operators and relations at internal nodes, and constants and variables at the leaves (see Fig. 4 b).
However, some expressions are not intended for evalua-tion. For example, consider the integral shown in Table 1 . The vector space is continuous, and thus this integral cannot be computed directly. Doing so would also not be of interest, as this expression is commonly used in a constraint that the expression needs to evaluate to 1 . 0.

We now briefly describe file formats used for symbol lay-out trees and operator trees. Symbol layout trees represent the placement of symbols on baselines (writing lines), and the spatial arrangement of the baselines. File formats for repre-senting symbol layout trees include Presentation MathML and L A T E X, as shown in Fig. 8 b, c. Compared to L A T Presentation MathML contains additional tags to identify symbols types; these are primarily for formatting. Grid lay-outs are represented by rows and columns of subexpres-sions (e.g., using the array construct in L A T E X), with each subexpression represented by a symbol layout tree or grid. Grids may occur as subexpressions in symbol layout trees, as in the factorial function definition in Table 1 :themain baseline of the expression consists of x !={[ sub ] , where [ sub ] represents a grid containing four subexpressions (two value X  X ondition pairs) used to define the function.
An operator tree, as shown in Fig. 4 b, represents the oper-ator and relation syntax for an expression. Operator trees may be encoded in a number of ways, including Content Math-ML and OpenMath [ 36 , 37 ]. To evaluate an expression, it is necessary to know the definitions for all symbols and oper-ations. As shown in Fig. 8 d, tags in Content MathML rep-resent defined primitives (e.g., &lt;cn&gt;2&lt;/cn&gt; ), operations (e.g., &lt;plus/&gt; ), and relations. The OpenMath standard pro-vides an encoding for formalizing the semantics of symbols and operations using content dictionaries . Given this infor-mation, an expression may be evaluated mechanically, using a Computer Algebra System. 3 Mathematical information retrieval Figure 6 summarizes the process of information retrieval. In general, users have an information need that they attempt to satisfy using the retrieval system. Information needs take many forms (Table 2 ) and are seldom concrete: often, they change as a user interacts with a retrieval system. Consider image retrieval: Smeulders et al. [ 132 ] point out that often users X  impression of the images they want are only par-tially defined, such as when looking for an image belong-ing to a class of objects (e.g., chairs), or not defined at all, as when browsing through an image collection. A discus-sion of research on information needs, including difficulties associated with their observation and common misconcep-tions, is provided by Case [ 26 ] Chaps. 1 and 4. Research on image search needs and behaviors is summarized by West-man [ 156 ].

A better understanding of users X  information needs will further the development of MIR systems. At present, MIR research has been motivated primarily by developing new search techniques based on query-by-expression [ 75 , 171 ]. Better response to information needs will allow MIR to mir-ror the advances in internet search interfaces over the last two decades [ 61 ]. In a study of MIR usage, Zhao et al. [ 171 ] report that participant queries may be motivated by a specific information need, such as the need for a definition or deriva-tion. In addition to information needs, participants expressed resource needs , requesting resources with a certain style and depth of presentation (e.g., tutorials versus research papers), or requesting resources with a particular function (e.g., writ-ten documents, including slides and web pages, versus code and data sets).

General-purpose search engines such as Google can be used to locate mathematical content, but the results may be weak in relation to the user X  X  goals, as these systems use term-based indexing with no model for mathematical con-tent. For example, one can try matching MathML tags, or matching the L A T E X strings that occur in some web pages as annotations for the expression images they were used to create. It seems likely that as MIR research advances, users will continue to use a combination of general-purpose search engines along with specialized MIR systems for their math-ematical information needs, as was observed in Zhao et al. X  X  [ 171 ] study.

In the remainder of this section we address four key prob-lems inMIR: queryformulationandlanguages for expression queries, normalization of queries and documents, document indexing and matching, and query refinement and relevance feedback. The final section discusses evaluation of MIR systems. 3.1 Query languages and query construction Systems for MIR using standard keyword-based query lan-guages (see [ 125 ], Chap. 2) have existed for quite some time. Examples include the web pages for searching Mathemati-cal Reviews 10 and Zentralblatt f X r Mathematik. 11 Both ser-vices have been compiling bibliographies and disseminating reviews of published work on mathematics since the first half of the twentieth century. Their materials have been man-ually indexed, using the Mathematical Subject Classification (MSC) [ 99 ]. 12 In the web interfaces provided by these ser-vices, MSC categories can be used to constrain searches.
To make existing text-based query languages better suited to MIR, researchers are extending them with syntax express-ing the appearance and content for mathematical expressions (e.g., using L A T E X and MathML). Also, content-based image retrieval (CBIR) methods [ 35 , 132 ] can be adapted to allow expression images to be used directly as queries.
Expressions have been represented in MIR query lan-guages using Lisp [ 41 ], L A T E X and L A T E X-like string lan-guages [ 3 , 9 , 103 ], Mathematica (for Wolfram web sites), MathML [ 78 ], and operator tree shorthands [ 77 ]. Example queries are shown in Fig. 5 . Recently, images of symbols [ 96 ] and complete expressions (handwritten [ 161 , 167 ] and typeset [ 168 ]) have been used for query-by-expression.
To make expression queries more precise, boolean con-straints (AND, OR, NOT) may be used [ 78 , 91 ], and cardi-nality and matching constraints added. Figure 5 c shows an example of a simple boolean constraint in a query language supporting both expression and keyword matching. Wild-cards to permit matching any symbol or subtree at a specified point in an expression have also been used [ 9 , 77 , 106 ]. An example is shown in Fig. 5 c, where the wildcard character $ matches any subscript on the integral. Altamimi and Youssef use an AWK-like syntax [ 2 ] and regular expression patterns to identify matching subexpressions, and allow equivalence and type constraints to be imposed on matched entities [ 3 ]. Constraints can also be applied to indicate which document regions to match; an example is indicating a preference for theorems, proofs, and section headings demarcated within the document collection [ 103 , 171 ].

A variety of query interfaces for MIR have been pro-posed, a small number of which we summarize here. The simplest interfaces provide a box in which to type a query string, such as used in the Springer L A T E X search interface and the NIST Digital Library of Mathematical Functions (see Fig. 5 a, c). The MathWebSearch interface shown in Figure 5 a[ 78 ] provides templates for structures such as frac-tions and summations; text representing these operations is inserted into the query using a mouse click. In the Mathdex system, users can enter expressions using a graphical equa-tion editor similar to the editors provided in word-processing programs [ 105 ].
Query expressions constructed using string languages and template editors tend to contain a small number of symbols (see Fig. 5 ). Single-symbol query expressions are imprecise, while query expressions containing a large number of sym-bols are uncommon, because of the effort required to express and interpret them [ 59 , 67 ]. The rarity of large query expres-sions is an example of the principle of least effort [ 173 ] com-monly observed for natural language (see p. 60 of Salton and McGill [ 125 ]). In contrast, large queries are easy to construct when queries are expression images: a user can easily select large image regions, so a large number of symbols does not affect the effort involved in query construction.
Despite the efforts to add expressions into query lan-guages, their addition may not always add value for users [ 75 ]. Zhao et al. [ 171 ] studied a small group of professors, graduate students, and librarians affiliated with the Math Department at the National University of Singapore and found that most of their participants could not identify a sit-uation where they would want to search using an expression. Expressionsareoftennamed(e.g.,thePythagoreantheorem), may be overly specific for some information needs, and may be inconvenient to enter using the methods known to the participants, which included graphical template editors and string-based interfaces (image-based querying was not con-sidered). When asked what their preferred expression entry method would be, participants responded that they would like to use L A T E X, due to its familiarity.

Kohlhase and Kohlhase [ 75 ] suggest pen-based entry may be a more natural expression input modality. We propose that pen-based entry will be most effective when paired with keyboard and mouse input. There should also be support for query-by-example, in which queries are constructed using expression images from the document collection. It remains to be seen whether such an interface would make query-by-expression more appealing to math experts such as those in Zhao et al. X  X  study.

As MIR matures, we expect the ability to browse expres-sions and their surrounding text within a single document or document collection will be useful, particularly for non-expert users in elementary school and high school, and in technical disciplines. 3.2 Query and document normalization For information retrieval, normalization is the process of reducing variation within queries and documents, to facilitate matches between related or identical entities with different representations. In textual IR, common normalization oper-ations include replacing words by their stems (e.g.,  X  X nfor-mation X   X   X  X nform X  and  X  X etrieval X   X   X  X etriev X  [ 125 ]), and the removal of high-frequency, low-discrimination stop words such as but , to , and the . Often a thesaurus is used to add synonyms for low-frequency terms to the query.

The normalizations that are performed for math retrieval depend on the representation (symbol layout tree vs. oper-ator tree), and on the matching algorithm used for search. For example, the order in which spatial relationships are pre-sented is critical in systems that match symbol layout trees that have been linearized. Identical expressions will fail to be matched if relationships appear in different orders, as in x  X  2_1 and x_1  X  2 . Standardized ordering is also needed in operator trees, as ultimately the tree structure is used in matching.

Analogous to synonyms in text, mathematical concepts often have multiple notational representations. Consider  X  n choose k  X , which may be written as n k , n C k , C n k , In terms of expression semantics, the variability is even more severe: consider the number of expressions that evaluate to 0. It is not clear when or to what extent transformation and simplification should be used to recover such equivalences.
Below is a short list of query and document normalizations that have been applied in MIR systems.  X  Thesaurus: adding synonyms for symbols to a query  X  Canonical orderings: fixing the order for spatial rela- X  Enumerating variables: variables may be enumerated  X  Replacing symbols with their types: allows matching  X  Simplification: producesmallerrepresentationswithless 3.3 Indexing and retrieval Most MIR research assumes that mathematical expressions are represented explicitly in the document collection, using markup languages such as L A T E X, MathML [ 10 ], or Open-Math [ 37 , 139 ]. These encodings allow expression appear-ance or mathematical content to be extracted directly and then embedded in documents or evaluated using CAS sys-tems. New languages, formats, and tools for creating mathe-matical documents have also been developed.

The OMDoc format developed by Kohlhase [ 76 ]isXML-based, allowing expressions to be embedded using MathML and OpenMath. OMDoc was used to represent documents for Math WebSearch (see Fig. 5 a), and ActiveMath, an on-line math tutoring system that supports query-by-expression [ 91 ]. Miller created L A T E XML, a tool for translating L A T XHTML and MathML [ 103 ]. This is analogous to the well-known latex2html converterusedtotranslateL A T E X doc-uments to HTML, embedding mathematical expressions as images (e.g., .png files). L A T E XML was used in creating the NIST Digital Library of Mathematical Functions (DLMF) (see Fig. 5 c). In contrast, Springer X  X  L A T E X search (Fig. 5 b) represents documents using the L A T E X sources provided directly by the authors of academic papers and books. These encodings allow expression data to be represented explicitly, in a suitable form for indexing and retrieval prior to archiving a document collection.

Unfortunately, many documents do not represent mathe-matical information explicitly. Examples include document images such as .tiff or .png files, and vector-based represen-tations such as .pdf files [ 13 , 14 ]. This makes it necessary to recover mathematical information using pattern recogni-tion techniques, and then annotate documents with recog-nition results prior to indexing. Pattern recognition has been used to identify math symbols and structure in raw document images [ 8 , 102 ] and .pdf files [ 14 , 71 ]. Another use of pattern recognition is to segment documents into region types such as theorem, proof, and section heading [ 171 ]; these region types can then be used in queries.

A German and Japanese project led by Michler devel-oped a prototype for annotating documents in digital math-ematics libraries in the early 2000s [ 101 , 102 ]. Document images were recognized using commercial OCR software (ABBYY FineReader), mathematical expressions were seg-mentedandconvertedintoL A T E Xusingtechniquesdeveloped by Ashida et al. [ 8 ], and paper references were linked to online reviews from Zentralblatt f X r Mathematik and Math-ematical Reviews. References were detected using regular expression matching in OCR results. Archived documents were stored using the DjVu format, which represents docu-ment pages in three layers: (1) image, (2) OCR and math rec-ognition results, including associated page coordinates, and (3) links to reviews for cited papers, with the associated page coordinates for the citations [ 102 ]. DjVu viewers allowed OCR/math recognition results to be seen in-place while view-ing a document image, and for reviews of references to be consulted simply by selecting a reference (e.g., using a mouse click).

During indexing, documents are converted to the repre-sentation used in the document index . In the early stages of indexing, documents are filtered (e.g., to select expressions and/or index terms) and normalized in the same fashion as queries. 3.3.1 Vector-space models In vector-space models, documents are represented by vec-tors in R n , where each dimension corresponds to an index term [ 62 , 95 , 125 ]. Index terms normally exclude stop words (very high-frequency terms such as  X  X he X  that carry little information) as well as highly infrequent terms, whose inclu-sion would have little effect on retrieval performance, while increasing the dimensionality of the vector space. Salton and McGill discuss index term selection, the use of synonyms for low-frequency terms, and the construction of term phrases for high-frequency terms (Chap. 3 of [ 125 ]). Documents are represented by the weighted number of occurrences of each index term (the term frequencies ). Commonly, term frequen-cies are weighted using some variation of inverse document frequency , to emphasize terms that appear in fewer docu-ments in the collection, and thereby likely to be more infor-mative [ 62 , 125 ]: u = freq ( i , u )  X  log N where freq ( i , u ) is the frequency (occurrence count) for term i in document u , docfreq ( i ) is the number of documents con-taining term i , and N is the number of documents in the collection.

The most common similarity measure used is the cosine of the angle between two document vectors u i and v i : sim ( u ,v) = cos ( u ,v) = This is simply the inner product of the document vectors divided by the product of their magnitudes. If term vectors are first normalized (length 1.0), then the denominator need not be computed. sim ( u ,v) has a value of 1 when the vectors coincide (0  X  ), and 0 when the vectors are orthogonal (  X 
For large document collections, the document index must be pre-structured to reduce the number of comparisons made for a query. A common approach uses clustering, and then compares a query vector with the centroid of each child clus-ter at a node (Chap. 6.4 of [ 125 ]). The cluster tree is traversed top-down until individual documents are reached, pruning paths in which similarity is less than a threshold value. This greatly reduces retrieval time, but carries the risk that the document(s) most similar to the query will not be located (see [ 40 ] pp. 185 X 186). Smeulders et al. [ 132 ] identify three methods for hierarchically decomposing a document index in image retrieval : partitioning the feature space, partition-ing the data, or distance-based indexing relative to exam-ples. Spatial data structures used by these three decomposi-tion approaches, respectively, include k -d trees, R -trees, and M -trees [ 126 ].

A number of MIR systems implement vector-space mod-els using the popular Lucene 13 [ 60 ] indexing and retrieval library, both for indexing entire documents that include expressions [ 91 , 103 ], and for indexing individual expres-sions in L A T E X documents [ 168 ]. In these approaches, math-ematical symbols are treated as terms, and the expressions are linearized ( X  X lattened X ) before conventional text-based index-ingisperformed.Forexample,considertheL A T E Xexpression for x t  X  2 = 1, which is x  X  {t-2} = 1 . Below we show the symbol layout tree for the L A T E X expression, along with the linearization produced by Miller and Youssef [ 103 ]:
This string is a depth-first linearization of the symbol lay-out tree for the expression. Note that the exponent scope is represented by folding the L A T E X superscript operator into the fence tokens BeginExpt and EndExpt .Forthe ActiveMath system, OMDoc is used to encode the docu-ment collection, and OpenMath representations for expres-sion operator trees are extracted and linearized depth-first in a manner similar to the example above [ 91 ]. Once mathemat-ical expressions have been converted, documents are indexed using traditional term-based indexing methods. Lucene may be used to automatically determine the set of index terms for use in indexing and retrieval. 3.3.2 Tree-based indexing and retrieval Other methods for indexing and retrieving math expressions use the hierarchical structure in layout and operator trees. The hierarchical structure can be used in its entirety, or as a set of trees representing subtrees of the expression. Retrieval is performed using subexpressions extracted from the query expression.

Matching operator trees may be viewed as a variation of the unification problem addressed in automated reasoning systems: given a query expression, identify indexed expres-sions whose variables and/or subexpressions may be matched consistently with those of the query. Graf developed a term indexing method for first-order logic known as substitution tree indexing [ 57 ]. A substitution tree represents the struc-ture of all indexed first-order logic terms, with paths from the root to the leaf defining a sequence of variable substitutions. Substitution trees can be adapted for indexing operator trees in a straightforward manner, as illustrated in Fig. 9 .
Retrieval in a substitution tree is performed through a backtracking search over variable bindings (similar to Prolog [ 57 ]). Using different matching functions, we may search for exact matches, instances, generalizations, and variant substi-tutions. An example of instance-based matching using Fig. 9 is that the query sqrt ( X ) returns the three expressions at the leavesofthetreethatcontainanoutermostsqrt () .Anexample of matching with generalizations is to ignore specific symbol identities. In matching with variant substitutions, we match expressions that are equivalent up to variable renaming.
Substitution tree retrieval was applied to MIR by Kohlhase and Sucan [ 78 ]. To simplify matching sub-expressions, Kohlhase and Sucan add all sub-expressions in the docu-ment collection to the substitution tree along with their par-ent expression. They claim that this leads to a manageable increase in the index size, because many sub-expressions are shared by the larger expressions, and each sub-expres-sion appears only once in the substitution tree. To facilitate rapid retrieval, all substitution tree nodes contain references to matched expressions in the document collection.
Earlier, a related method was used by Einwohner and Fat-eman for searching through integral tables, given an inte-grand expressed as an operator tree in Lisp (e.g., (expt (log (cos x)) 1/2) )[ 41 ]. Expressions from the inte-gral tables were indexed using hash tables: after normaliza-tion of the Lisp expressions, the head (first atom) of each list in the lisp expression is used as the key for storing the associated sub-expression (sub-tree) in the table. Retrieval was performed by recursively looking up each lead atom (key); if the first key returns a non-empty set of expres-sions, the current key is expanded to include the next key, and the intersection of the previous returned and current lists of matches is taken. This differs from the substitution trees in that operator trees are matched using a depth-first traversal of the query operator tree rather than based on common sub-stitutions that may not be strictly depth-first, and symbols are matched exactly.

Hashimoto et al. [ 59 ] generate an index using paths from the root of the tree for Presentation MathML expressions. Expressions are indexed in an inverted file using two paths: the first (leftmost) and the deepest paths from the root of the tree to a leaf. Retrieval is performed based on the longest partial match along the two paths. The authors also consider producing inverted files using the nodes at the first depth with more than three nodes.

Kamali and Tompa [ 67 ] propose rewriting trees and com-puting relevance using a set-based measure, in the context of Content MathML (an operator tree encoding). Intersections between nodes in two operator trees are defined using syn-tactic equivalences (possibly involving transformations, e.g., to detect a + b = b + a ) with a noise/mismatch tolerance. A weighting function  X  is used to weight trees by the nodes they contain, most simply counting nodes in the tree: This is closely related to the Tanimoto metric for set similar-ity ([ 40 ], p. 188). This approach resembles the graph probing methodology for comparing table structure recognition algo-rithms [ 64 , 92 ].

Miner and Munavalli [ 105 ] take a different approach, in which symbol layout trees expressed in Presentation MathML are decomposed into a set of n -grams (linearized sub-expressions). In their formulation 1-grams are single symbols; higher n -grams are defined by the number of chil-dren of a node in the MathML tree (i.e., there may be more than 5 symbols in a  X 5-gram X ). In the symbol layout tree, weights are assigned to  X  n -grams X  associated with nodes based on their depth in the tree, structural complexity, and length (the  X  n  X  for the associated n -gram). A threshold is then used to select nodes for use in querying: roughly speak-ing, this prefers larger and more complex sub-expressions. Expressions are indexed based on the linearized  X  n -grams X , and retrieval is performed by combining queries issued to a Lucene implementation.

In image-based MIR, representations for symbol layout trees have been constructed using X  X  Y cutting to decompose document pages and expression regions [ 161 ]. Recursive binary X  X  Y cuts decompose each page image, and sub-trees of the X  X  Y tree up to a maximum depth and number of components are stored in a single expression index. Indexed regions are then re-segmented using a simplified X  X  Y cutting, to approximate symbol layout trees for expres-sions present in the candidate set. Previously, pixel projection profile methods with post-processing were used successfully to recover symbol layout trees from expression images by Okamoto et al. [ 112 , 153 ]. Retrieval is performed using (stan-dard) XY-tree structure, and dynamic time warping of query and candidate image columns similar to the word-spotting technique of Rath and Manmatha [ 120 , 121 ]. A related approach was developed for visual matching of L A T E X-generated expression images [ 168 ]. Connected com-ponents in the query image are matched with connected components in archived images using visual similarity of connected components, again based on features similar to Rath and Manmatha X  X . The matching process also measures similarity in layout between pairs of connected components. 3.4 Query reformulation and relevance feedback After query submission the retrieved documents are pre-sented to the user through an interface. In order to support reformulation of queries, one interface is normally used both for constructing queries and evaluating results, as seen in Fig. 5 . If a user X  X  information need is satisfied by a retrieval result oriftheuserbecomesfrustrated,heorshewillstopsearching. Otherwise the user may craft a new query or may refine the existing query, for example by filtering retrieved documents by source or publication year (Fig. 5 b). New queries may also be created automatically, in response to relevance feedback.
Users provide relevance feedback by indicating whether returned documents are relevant or irrelevant to their infor-mation need. These positive and negative examples can be used to automatically produce a new query. Relevance feed-back is provide through the result interface, using a selection mechanism such as check boxes, or clicking on relevant/irrel-evant objects. For interesting examples from image retrieval, see [ 123 ].

For vector-space models, a new query may be produced by averaging and re-weighting the vector elements that define the feature space: increase the weights for features present in positive examples, and decrease the weights for features in negative examples. A concise explanation of relevance feed-back operations using re-weighting is given by Salton and McGill [ 125 ] Chaps. 4.2.B, 4.3.B, and 6.5. Machine learning methodshavealsobeeninvestigated.Discriminativemethods estimate classification boundaries for relevant and irrelevant documents, whereas generative methods estimate probability distributions [ 35 , 172 ].

Ideally, relevance feedback algorithms learn optimal transformations of the feature space using user-provided relevance indications [ 172 ]. Optimality is defined by the user X  X  information need, which may change as the user inter-acts with the system [ 35 ]. Modifications produced through relevance feedback may occur in multiple ways: the set of searched documents may be modified, the feature representa-tion changed, or the similarity metric modified. For annotated images, the relationships between text annotations and image features are often exploited, e.g., producing  X  X oncept classes X  for sets of images that have similar annotations [ 132 ].
At the time of this writing, the authors are unaware of any work on relevance feedback for MIR. In text-based retrieval, Hearst has noted that despite significant improve-mentsfortext-basedretrievalinlaboratoryexperimentswhen relevance feedback is used, modern search interfaces tend not to provide a relevance mechanism (see [ 61 ], Chap. 6). Instead, they make metadata visible for query refinement (e.g., Fig. 5 b), or suggest alternate queries. In contrast, for image-based retrieval systems using query-by-example, rel-evance feedback is essential for a usable system, and is an active area of research. Zhou and Huang have suggested two reasons for this [ 172 ]: (1) images are more ambiguous than words, and (2) evaluating the relevance of text documents may require more effort than evaluating the relevance of images.

For MIR, it may often be faster to discern the relevance of a document based on the appearance of expressions than based on the document text, particularly in the case where a user is browsing rather than searching for a specific item as in done in Zhao et al. X  [ 171 ] experiment. This distinction betweenretrievaltasksinvolvingaspecificitemversusaclass of items or browsing is important in information retrieval [ 35 , 132 ]. In addition to using expressions within queries, returned expressions may be used for relevance feedback. A revised query can be generated based on the relevant and non-relevant expressions X  visual appearance, symbol layout, mathematical content, and associated text. We feel that this is an important future research direction. 3.5 Evaluation of math retrieval systems Evaluation of information retrieval systems is difficult due to variation in the information needs of individual users, and the impracticality of having participants in human experiments identify all relevant documents in large collections (see [ 125 ] Chap. 5, [ 22 ] and [ 132 ]). This leads to the definition of rel-evance being inherently subjective.

In practice, it is necessary to either define test sets for a pre-defined collection, query set, and relevance assess-ments as done for many of the NIST TREC retrieval com-petitions, 14 or to perform user-centered evaluations where searching behavior within real workflows (e.g., [ 75 , 171 ]) or constructed task scenarios are observed, with assessments provided by participants regarding the satisfaction of their information needs [ 22 ]. For off-line experiments such as those done for TREC, relevance assessments are usually binary (relevant/non-relevant) and produced before an exper-iment is run. In contrast, user-centered experiments permit relevance evaluations to be made using a scale, and allow rel-evance evaluations to change during iterations of relevance feedback. Constructed task scenarios paired with pre-defined relevance assessments allow off-line as well as user-centered metrics to be collected [ 22 ]. Hearst provides guidelines for evaluating retrieval interfaces [ 61 ].
The standard metrics for off-line retrieval are recall (% of relevant documents retrieved) and precision (% of retrieved documents that are relevant). There is a well-understood trade-off between the metrics: as more relevant items are located (higher recall), the number of irrelevant items returned generally increases (lower precision), and vice versa. Relevance assessments by human participants nor-mally consider just the first k elements returned. This is sometimes called precision-at-k (e.g., with observations at k = 1 , k = 5 , and k = 10 [ 61 , 132 ]). For off-line experi-ments, precision-at-k may be used to measure relevance for results users might actually examine. A variation frequently used in image retrieval is mean average precision [ 35 ]. Here, the precision from the first to each of returned results up to top k -th result is computed (for { ( 1 ), ( 1 , 2 ),...,( 1 , and then averaged, producing a bias for relevant results that have high rank. This set of precision values is averaged for the query, and the mean of these average precisions is computed over the query test set.

Systems are often compared visually by plotting precision against recall ( X  X recision-recall X  curves). More quantitative comparisons have been made using statistical hypothe-sis tests, or using AUC (area-under-the-curve) metrics for precision-recall plots. AUC metrics require interpolation for missing points [ 125 ]. Salton and McGill demonstrate using the Wilcoxon signed rank test to compare average preci-sion for different recall value ranges (  X  0.1,...,  X  1.0, see [ 125 ] Chap. 5.2.C), and determine whether the distribu-tions are significantly different. The Wilcoxon test is non-parametric, making no assumption regarding the distribution of recall/precision values (e.g., they need not be normally distributed, as for a t -test).

To date, published evaluations for MIR systems have been largelyillustrative,andbyexample.Oneinterestingapproach compared retrieval using the ActiveMath system [ 91 ] with retrieval from the ActiveMath web pages using the Google search engine, as well as a human-centered evaluation using a  X  X alk aloud X  protocol, where participants are asked to speak their thoughts as they completed search tasks involving key-words and/or small expressions. Marinai et al. [ 96 ] provide precision-recall plots for their method for image-based math symbol retrieval using a bag-of-visual-words produced from clustered shape contexts [ 15 ]. Precision at 0% recall is pre-sented,withprecisionvaluesashighas87%reported.Exami-nationoftheprecision-recallcurvesshowsarapiddecreasein precisionbeforerecallreachesapproximately20%(precision falls to roughly 20% in all conditions presented), but this likely includes many more elements than would be consid-ered by a user. Their metrics were produced for almost 400 queries on a very large dataset of binary symbol images from document scans (from the Infty dataset [ 142 ]). Note that in this case determining relevance reduces to matching symbol labels in ground truth.

Yu and Zanibbi [ 161 , 167 ] use a combination of off-line and user-centered evaluation for an image-based handwritten expression retrieval system. Participants were shown type-set expressions, which they drew using pen and paper. The pages were scanned to produce expression images for use in retrieval. For simplicity, only the region containing each test expression was identified in the ground truth. The sys-tem returned a ranked list of ten regions, each correspond-ing to the best match on an individual page. The observed measurements were (1) maximum ratio of overlap for the tar-get region, and (2) whether the associated page appeared in the top k elements for k ={ 1 , 5 , 10 } . These are essentially recall -at-k measures, but where a speci f ic expression is soughtafter.Thesemetricsareconservative:nocreditisgiven for anything other than one region on a single page. Search was run offline, and participants were brought back to evalu-ate the top-10 regions using a Likert scale (see Fig. 10 ); par-ticipants were asked to evaluate the proportion of the query expression contained in each returned region. For compari-son, the original query images were also used for retrieval, and performance evaluated on-line by each participant, and off-line. Retrieval of original images was much more effec-tive than for handwritten queries; the average maximum ground truth region overlap was 43% for handwritten que-ries, but 90% for the original images. The corresponding human similarity evaluations were an average of 3.15/5 for the handwritten queries, and 4.83/5 for the original images.
Going forward, perhaps the most important direction in evaluating MIR systems is determining experimental proto-cols that can be easily replicated, and that reduce the need for manual identification of relevant documents or document regions,andperhapscreatingalabeledtestsetsimilartothose developed for TREC. For MIR in general, relevance pertains to both text and expressions, making this a very time-inten-sive task, one that is sensitive to the expertise of the intended users. Once a reasonable method for defining or approximat-ing relevance is determined, existing information retrieval metrics are likely sufficient. 4 Recognition of mathematical notation Pattern recognition methods for mathematical notation may be used in a variety of contexts. Firstly, in Mathematical Information Retrieval, math recognition can be used to interpret user queries and to annotate document collections. An important open problem is to develop robust MIR meth-ods that make effective use of recognition results even when recognition errors are present. Secondly, math recognition is used to support the insertion of expressions into documents; for example, entry of L A T E X expressions using images, pen, keyboard, and mouse is illustrated in Fig. 1 . Thirdly, math recognition is used to recover layout and operator trees from images, handwritten strokes, or vector-based encodings (e.g., .pdf files). Finally, math recognition is used to integrate pen-based math entry into CAS systems (see Fig. 2 ); in the future, expression images might also be used as input. This requires recognition of mathematical content, with the resulting oper-ator tree used to support evaluation and manipulation of the expression.

Research on the recognition of math notation began in the 1960s [ 5 , 6 , 31 , 98 ], and a number of surveys are available [ 19 , 28 , 52 , 146 ]. In this paper we do not attempt to summa-rize the entire history as provided in these surveys, but rather provide an updated account of the state of the art, with an emphasis on advances since the well-known survey by Chan and Yeung [ 28 ] written a decade ago.

Many factors make the recognition of mathematical nota-tion difficult. There may be noisy input in the case of images and strokes, and ambiguities arise even for noise-free input (see Fig. 7 ). Math notation contains many small symbols (dots and diacritical marks) which can be difficult to dis-tinguish from noise. Symbol segmentation can be difficult, particularly in handwritten mathematical notation. Symbol recognition is challenging due to the large character set (Roman letters, Greek letters, operator symbols) with a vari-ety of typefaces (normal, bold, italic), and a range of font sizes (subscripts, superscripts, limit expressions). Several common symbols have ambiguity in their role; for exam-ple, a dot can represent a decimal point, a multiplication operator, a diacritical mark, or noise. Also, spatial relation-ships are difficult to identify; for example, it is difficult to distinguish between configurations that represent horizontal adjacency and those that represent superscripts or subscripts. The lack of redundancy in mathematical notation means that relatively little information is available for resolving ambiguities.

As shown in Fig. 3 , we identify four key problems that every math recognition system must address. 1. Expression detection 2. Symbol extraction or symbol recognition 3. Layout analysis 4. Mathematical content interpretation These key problems are discussed in Sects. 4.1  X  4.4 .Most systems address these problems in sequence, but alternative control flow can be used to allow analysis at later stages to constrainorrepairdecisionsmadeinearlierstages(Sect. 4.5 ), or to integrate and jointly optimize solutions to two or more of these problems simultaneously (Sect. 4.6 ). 4.1 Expression detection The input to a math recognition system can consist of vector graphics (such as PDF), pen strokes, or a document image. As discussed below, different challenges arise in detecting expressions in each of these input types, and there is an interaction between detecting symbols and expressions. For document images, some methods apply OCR or perform a coarse classification of connected components before seg-menting expressions in documents, while others attempt to locate expressions using geometry or other methods. For pen-based entry systems, symbol segmentation and recognition are normally performed as the user writes, in part because it simplifies the system design, but also because it avoids requiring the user to check recognition results over a large set of objects and relationships. 4.1.1 Expression detection in vector graphics For vector graphics, work has begun on methods for extracting symbols and recognizing manually segmented expressions, but not on methods for automatic detection. Currently, vector file formats such as PDF do not demar-cate math regions. This is an important direction for future work, particularly for Mathematical Information Retrieval applications. 4.1.2 Expression detection in pen-based input For pen-based applications, expressions are often segmented using gestures [ 85 , 144 ]. For example, the  X   X  gesture is used in the E-chalk system to indicate the end of an expression, and request its evaluation (see Fig. 2 b). Typically, a gesture gives a partial or approximate indication of the extent of an expression. Additional clustering or region growing methods can be applied, based on the properties of recognized sym-bols. Matrix elements can be detected using similar methods [ 89 , 147 ]. 4.1.3 Expression detection in document images In images, expressions are normally found using properties of connected components. Before discussing these methods, we distinguish between displayed expressions that are off-set from text paragraphs and expressions that are embedded in text lines (Fig. 11 ). Displayed expressions are easier to detect than embedded expressions, because text lines and displayed expressions tend to differ significantly in attributes such as height, separation, character sizes, and symbol layout [ 52 , 66 ].

Kacem et al. detect displayed expressions in images based on simple visual and layout features of adjacent con-nected components [ 66 ]. Embedded expressions are found by coarsely classifying connected components. Regions are grown around components that are identified as operators. The region growing is based on the expected locations for operands (i.e., operator range and dominance).

An alternative approach for detecting embedded expres-sions first locates text lines, then computes symbol n -grams [ 52 ]. Training data provides frequencies for adjacent sym-bols, in textlines that are pure text, versus textlines that contain embedded expressions. A 97% recognition rate is reported for this technique. In subsequent work, Garain extends this approach by averaging over more general fea-ture values for embedded and displayed expressions [ 49 ]. He obtained recall rates as high as 95% for embedded expres-sions, and 97% for displayed expressions.

Offset expressions can be detected without symbol classi-fication.DrakeandBairdusepropertiesoftheneighborgraph for connected components (a pruned Delaunay triangulation) to distinguish text lines from displayed expressions [ 39 ]. The reported accuracy for this method is high (over 99%), but it has not yet been used for embedded expressions. 4.2 Symbol extraction or symbol recognition OCR for math is a difficult problem, due to the large num-ber of classes (see [ 94 ]), and problems caused by touch-ingandover-segmentedcharacters[ 27 , 52 , 100 , 135 ].Berman and Fateman observed that commercial optical character rec-ognition systems with recognition rates of 99% or higher fell to 10% or less once tried on perfectly formed characters in mathematical equations: heuristics that work well on straight text, multi-column printing, and tables fail with math nota-tion because of variations in font size, multiple baselines, special characters, and differing n -gram frequencies [ 16 ].
Techniques have improved since, and recognition rates as high as 97.7% have been reported for typeset symbols in the work of Malon et al. [ 94 ], where Support Vector Machines [ 154 ] are used to reduce common class confusions in the Infty OCR system [ 141 ] for 608 symbol classes.

Accuracies for online recognition of handwritten mathe-matical symbols have also been reported at rates of over 95%. In recent years there have been a number of methods based on Hidden Markov Models (HMMs [ 118 ]) that extend early work by Winkler [ 158 ] and Kosmala and Rigoll [ 80 ]. There is a general trend here, where HMMs were first used to perform simultaneous segmentation and recognition for a time series of pen strokes, but now later stages in processing, particu-larly layout and content information, are being incorporated into training and recognition stages. An open challenge is to adapt these methods to better handle  X  X ate additions X  to sym-bols, e.g., when a dot is added to the top of an  X  i  X  after a large expression has been entered. Developments in HMM-based recognition methods are discussed further in Sect. 4.6 .
Another group of successful methods employ features that approximate handwritten strokes via linear combinations of basisvectorsorparametriccurves.Varioustechniquesforthis have been used, including Principal Components Analysis [ 100 ] and polynomial basis functions [ 32 , 54 , 55 ]. These fea-tures allow recognition to be performed effectively within a small feature space (e.g., using the first fifteen principal com-ponents [ 100 ]), while allowing regeneration of the original data up to a chosen level of fidelity, making the interpretation of the features simple.

Voting-based methods for classifier combination have been employed to good effect. The method of Golubitsky and Watt [ 56 ] utilizes runoff elections in order to com-bine 1-against-1 SVM classifiers for a set of 280 symbols (280*279/2 = 39,060 classifiers in total). Majority voting is used first, followed by a runoff election where only votes for the top N classes are considered to break ties. La Viola and Zelenik applied AdaBoost [ 45 ] to another all-pairs classifier ensemble, with a binary classifier for every pair of classes. Each base classifier uses only a single feature; most are mea-sured on strokes, but output from the Microsoft handwrit-ing recognizer is included as a feature [ 86 ]. This work was concerned with adapting a writer-independent classifier (the Microsoft classifier) to the handwriting of specific individu-als through stroke-based features. 4.3 Symbol layout analysis Visual syntax refers to the layout and topology of symbols. A variety of formats can be used to represent visual syntax, the essence of which may be represented by a symbol layout tree (see Fig. 4 ).

A number of techniques have been used to recover symbol layout. The first three approaches discussed below use recur-sive decomposition, based on operator dominance, on cutting pixel projection profiles, and on identification of symbols on thedominantbaseline.Followingthat,wediscussapproaches based on penalty graph minimization.

Operator-driven decomposition recursively decomposes a math expression by using operator dominance to recursively identify an operator which has most or all of the remaining symbols as its operands [ 31 ]. These symbols are partitioned into the expected operand locations [ 29 , 31 ]. Unlike the other approaches described in this section, operator-driven decom-position constructs an operator tree (Fig. 4 b) directly from the symbol layout, rather than first producing a symbol layout tree. The earliest example of a simple pen-based math calcu-lator made use of this method [ 30 ]. Lee and Wang [ 88 ]use a similar approach to recover symbol layout, using operator dominance to group symbols vertically, followed by deter-mining horizontal adjacencies between symbols.

Projection profile cutting recursively decomposes a type-set math expression using a method similar to X  X  Y cutting [ 109 ]. Pixel intensity histograms in the vertical and horizon-tal directions are computed, followed by splitting at gaps identified in the histograms [ 112 , 113 , 153 ]. The first cut is made in the vertical direction (roughly speaking, to separate horizontally adjacent subexpressions), after which the direc-tion for cutting alternates. An improvement was suggested by Raja et al. [ 119 ] in which connected components are first extracted, and then regions containing more than one con-nected component that cannot be decomposed during cutting (e.g., for square roots or kerned characters) have the largest connected component removed, continuing cutting with the remaining connected components. In related X  X  Y cutting methods, thresholds for cutting have been chosen using the estimated dominant character height and width for a page (using the mode of run lengths in horizontal and vertical pro-jections at the page level), and then scaling these thresholds linearly based on the size of the area to be cut relative to the entire page [ 128 ].

Baseline extraction decomposes a math expression by recursively identifying adjacent symbols from left to right on the main baseline of an expression, and then partition-ing remaining symbols into regions relative to the baseline symbols [ 162 , 163 ]. Operator dominance information is used so that symbols need not be precisely aligned in some cases (e.g., for a symbol following a binary operators such as + Baseline extraction has been used in a number of pen-based math entry systems [ 7 , 117 , 133 , 145 , 147 ], though the tech-nique may be used for symbols taken from document images as well. Some work has been carried out into using more sophisticated symbol layout models (e.g., using multiple points on the bounding box in determining spatial relation-ships [ 145 ]), as well as using a minimum spanning tree for the symbol partitioning step [ 145 ], as shown in Fig. 11 .To handle ambiguous spatial relationships, fuzzy methods have been used to produce multiple interpretations [ 170 ].
Penalty graph minimization is a more global approach to layout recognition, in which candidate relationships between symbols are defined before minimizing a penalty crite-rion. Eto, Suzuki et al. make use of Virtual Link Networks to represent penalties for candidate symbol identities and spatial relationships (see Fig. 11 ), and then compute the minimum spanning tree of the graph to produce a final interpretation [ 42 ]. Spatial relationships in the networks are binary (between symbol pairs) and of five types: above, below, inline, superscript, and subscript. Candidate spa-tial relationships and penalties are defined based on sym-bol bounding boxes (normalized relative to the estimated font height and writing line location), and box center points [ 4 , 42 ]. Discrimination of spatial relationships may be improved through document-specific adaptation for deter-miningascender/descender/centerregionsonwritinglines.A recognition rate of 99.57% is reported for a test on valid adja-cent symbol-pair relationships for the Infty dataset (158,308 adjacent symbol pairs, taken from the ground truth).
Matrix layout requires special processing. The follow-ing approaches have been reported. The virtual link net-work method was extended to use projections of symbols inside a matrix, and then solve a resulting linear system of equations to estimate row and column positions [ 69 , 70 ]. Other authors have performed segmentation of matrix ele-ments using simpler projections of symbol bounding boxes [ 145 ]orregiongrowing[ 88 , 147 ] before analyzing elements using a single expression technique. Recently, there has been work to allow matrices containing ellipses to be used within pen-based systems integrated with computer algebra systems [ 89 , 127 , 147 ]. In handwritten expressions, matrices can be processed by detecting left fence symbols, followed by clus-tering and projection analyses [ 150 , 151 ].

At this point, no one technique for layout analysis com-pletely dominates another, and improving these methods is an active area of research. It may be worth exploring meth-ods for combining layout analyzers, in a manner similar to combination methods used for classification. 4.4 Mathematical content interpretation Many math recognition systems do not perform analysis beyond symbol layout, and such systems do not construct a representation of the mathematical meaning of the expres-sion. For systems designed to evaluate expressions and/or integrate with Computer Algebra Systems, however, a rep-resentation of the logical relationships between symbols and a representation of domain semantics are necessary. Various encodings can be used to represent the hierarchy of opera-tors, relations, and operands, which are generally equivalent to some form of operator tree (Fig. 4 b). Generally the defini-tions for operators and relations are assumed for a given math dialect in recognition systems, although content dictionaries such as those provided by OpenMath [ 37 ] might be used to encode and lookup the operations associated with symbols.
Recovering an operator tree from symbol locations may be understood as accepting sentences from a formal visual language [ 97 ], using a parser to analyze symbol layout in order to produce an operator tree. The earliest approach to recognizing symbol layout, by Anderson, is of this type: an operator tree is constructed top-down, and then a string rep-resenting the tree structure is synthesized bottom-up [ 5 ]. A numberofdifferentattributedgrammartypeshavebeenused, including context-free string grammars [ 43 ] and graph gram-mars [ 58 , 87 , 137 ].

Grammar-based methods commonly represent symbol locations by geometric objects such as bounding boxes or convex hulls. The placement of symbol centroids reflects the presence of ascenders ( h ) and descenders ( y ). Predicates and actions associated with grammar productions make use of the bounding boxes and centroids to determine spatial relationships. It should be noted that grammars are a very general formalism, and variations of layout analysis tech-niques seen in the previous section have been employed within the production rules of grammars designed to recover the operator tree of an expression. Examples included syn-tactic recognition using operator-driven decomposition [ 5 ], and baseline extraction [ 14 ]. A key issue is the geometric model used to partition the input and define primitives. For example, using unrestricted subsets of image pixels as prim-itives is far too computationally intensive. Instead, primitive regions are represented using geometric objects such as axis-alignedrectangles,alongwithconstraintsonallowableorder-ings and adjacencies between regions. Liang et al. provide a helpful overview, including examples from math recognition [ 90 ]. Different parsing algorithms explore the space of legal expressions in different orders, some more efficiently than others.

Stochastic context-free grammars allow uncertainty in symbol recognition, layout, and/or content to be accommo-dated, by returning the maximum likelihood derivation for theinputimage[ 34 ]orsymbols[ 104 ].Thesemethodsaredis-cussed further in Sect. 4.6 . Some more recent parsing meth-ods that model uncertainty include fuzzy-logic-based parsing [ 44 , 53 ], and A*-penalty-based search [ 122 ].
As discussed previously, usage of notation differs signif-icantly in different dialects of mathematical notation, and so the space of operator trees and corresponding grammar productions need to be adapted for different mathematical domains of discourse. The notion of devising one grammar to cover all of mathematical notation seems quite impracti-cal, though defining grammars with some utility for a specific domain (e.g., matrix algebra) is possible.

Methods that permit recognition to be defined at the level of a grammar are very appealing, in that with suit-able implementations for pattern recognition methods being available, a language definition may be sufficient for recog-nizing a dialect of mathematical notation, including layout andmathematical content.However,ithasbeenobservedthat the tight coupling between the assumed recognition model and grammar formalism can make it difficult to adapt syn-tactic pattern recognition methods. One compromise is to use a modular organization similar to a compiler, where rec-ognized symbols are combined into tokens and have their layout analyzed, after which an operator tree is constructed through restructuring and annotating the symbol layout tree [ 18 , 163 ]. More advanced techniques might interleave and/or iterate these stages. 4.5 Post-processing: constraining outputs Pattern recognition systems commonly use post-process-ing to correct preliminary recognition results. Many post-processing operations apply contextual constraints to results for individual objects and relationships identified largely in isolation of one another [ 149 ]. In document recognition, per-haps the most well-known example of post-processing is the use of dictionaries and n -grams to refine preliminary OCR results obtained for individual characters [ 108 , 116 ].
Ten years ago, the last IJDAR survey on math recogni-tion [ 28 ] identified post-processing as an important direc-tion for future research. Indeed, significant advances for post-processing of math recognition have been made in the last ten years. Several methods are similar to dictionary and n -gram methods used for OCR. Others incorporate syntactic constraints on two-dimensional symbol layout or expression syntax; these methods work with symbol layout trees and operator trees, respectively. 4.5.1 Statistical analysis of math notation Statistical information about math notation is useful in post-processing. The frequency estimates described below have been used to re-rank and constrain preliminary symbol rec-ognitionresultsforhandwrittenmathentry[ 134 ].Inaddition, they have been used to categorize mathematical documents by Math Subject Classification categories [ 155 ]; so far, this appears to be the only paper published on this interest-ing problem. Also, recognition systems can use information aboutsymbolfrequenciesandexpressionfrequenciesasprior probability estimates.

So and Watt [ 138 ] conducted an empirical study of over 19,000 papers stored in the ArXiv e-Print Archive. This archive at http://arxiv.org provides electronic versions and L A T E X source of papers from scientific, mathematical, and computing disciplines. So and Watt X  X  study determined the frequencies for expression usage in different mathematical domains, as identified by the Mathematical Subject Classi-fication described in Sect. 3.1 . Documents were categorized using the top-level Mathematical Subject Classification pro-vided by the ArXiv. Analyses were made at the symbol layout level after converting the available L A T E X to Presentation MathML.

The statistics produced by So and Watt make a distinc-tion between identifier symbols and operator symbols. In both cases, but especially for operator symbols, plotting sym-bols by decreasing frequency shows an exponential decrease in frequency with rank; this is similar to the Zipf distribu-tion [ 173 ] seen for word frequencies. Similarly, expressions become significantly less frequent as they become larger and more structurally complex. Interestingly, the number of dis-tinct expressions increases with expression size and com-plexity.

In a later study, Watt focused on engineering mathematics, analyzing the L A T E X sources for three engineering mathemat-ics textbooks [ 155 ]. In this study, all symbols were analyzed together, producing another Zipf distribution. N -grams (for n  X  X  2 , 3 , 4 , 5 } ) were produced by traversing the symbol layout tree in writing order. The leaves of the tree, which store the symbols, provide the starting point. The traversal collects layout information to provide context: there is infor-mation about the spatial relationship between the n -gram symbols and symbols on neighboring baselines (e.g., frac-tions, super/subscript, containment by square root). 4.5.2 Heuristic rules and contextual constraints Heuristic rules and manually constructed language models are receiving use in post-processing. Chan and Yeung [ 29 ] describe an error-correcting parsing technique for convert-ing handwritten symbols into operator trees, adding heuristic rules to re-segment characters recognized with low confi-dence, to insert epsilon (empty) symbols to recover from parse errors (e.g., after detecting unbalanced parentheses), and to replace symbol identities to make them consistent with the expression grammar (e.g., replacing  X 1 X  by  X / X  in  X  y 1 x  X , and  X  +  X  X y X  t  X  X n X  + an X ). Garain and Chaudhuri make use of a simple L A T E X grammar to constrain handwritten symbol recognition alternatives [ 50 ], while Kanahori et al. present work in analyzing the mathematical content (operator tree) for matrices in order to revise symbol layout analysis [ 68 ]. A more recent technique by Fujiyoshi et al. [ 47 , 48 ], similar to that of Chan and Yeung, defines a grammar for valid sym-bol layout trees and then parses initial recognition results in order to identify invalid structures. During parsing, syntax errors are visualized so that users may identify the specific symbols associated with parse errors (e.g., unbalanced fence symbols).

Contextual constraints can also be incorporated into the recognition process itself. For example, Kim et al. [ 73 ] mod-ify the penalty metric used in an A* search for constructing symbol layout trees for handwritten expressions [ 122 ]. The penalty metric considers measures of consistency of symbol size, style, and repetition, along with symbol n -grams and repeated subscripting. 4.6 Integration of recognition modules Integration of recognition modules has been an impor-tant new area of development in the last ten years. Most approaches involve some form of dynamic programming. The earliest work in this area is Chou X  X  influential paper describing the use of stochastic context-free string grammars for analysis of typeset images of mathematical notation [ 34 ]. This approach combines segmentation, recognition, and lay-out analysis and is highly tolerant of bit-flip noise. Subse-quent work includes extensions by Hull [ 65 ], and extension to a more general HMM-based model for document image decoding [ 79 ].

Stochastic context-free grammars associate a probability with each derivation rule; the derivation rules associated with each non-terminal have probabilities that sum to one. The probability of a derivation is computed as the product of the probabilities of all rule applications used to derive the input string. Rule probabilities can be estimated by the author of the grammar, or they can be derived from a training cor-pus using the Inside-Outside algorithm [ 34 ]. To facilitate the use of parsing through dynamic programming, stochas-tic context-free grammars are often represented in Chomsky-Normal Form: all rules are of the form A  X  BC or A  X  t .A modified form of the Cocke-Younger-Kasami (CYK) parsing algorithm uses dynamic programming to produce the maxi-mum likelihood parse in O ( n 3 ) time, where n is the number of input tokens.

In Chou X  X  [ 34 ] paper, the expression grammar is aug-mented to include symbols representing horizontal and ver-tical concatenation of adjacent regions in the input image. In a  X  X exical X  stage that precedes parsing, a template-based character recognizer is applied to the entire input region, identifying a set of candidate symbols based on the Hamming distance between input regions and a set of templates. This produces a set of candidate symbols with associated proba-bilities. More recently Yamamoto et al. [ 159 ] used a stochas-tic context-free grammar for online handwritten expressions, which introduces rules to model the likelihood of written strokes along with rules incorporating probabilities for the expected relative positions of symbols (the authors term these hidden writing areas ).

There are many unexplored possibilities for using stochas-tic context-free grammars for math recognition. For exam-ple, a variety of segmentation and classification methods might be employed within a framework of stochastic con-text-free grammars. Also, various heuristics could be used to prune or modify rules that are inferred from training data. It is true that sequential implementations of stochastic con-text-free grammars are computationally intensive, but both probability-estimation algorithms and parsers may be parall-elized [ 34 ]. Many opportunities for parallelization exist in modern CPUs with multiple cores and graphical processing units.

The related technique of Hidden Markov Models (auto-matathatrecognizeprobabilistic regular languages)hasbeen used to integrate segmentation and classification of hand-written symbols [ 80 , 158 ] (analogous to speech recognition [ 118 ]). For stochastic regular languages, the CYK algorithm reduces to the Viterbi algorithm, which may be used to deter-mine the maximum likelihood path (parse) through a Hidden Markov Model [ 34 ]. Hidden Markov Models form the core of a general model of document image decoding, in which the document-generation process is explicitly modeled as part of the recognition system [ 79 ].

More recently, dynamic programming methods have been used to let later stages of processing constrain earlier ones in an optimization framework. For example, Toyozumi et al. address segmentation of handwritten symbols drawn online [ 152 ]. They produce improvements on the order of 5 X 7% over a feature-based elastic matching method by using sim-ple, local grammatical rules to consider neighboring strokes and possible under-segmentation of vertical operators such as fractions, square roots, and summations. Shi et al. [ 130 ] go further, using a dynamic programming framework to optimize symbol segmentation and recognition. Their sys-tem considers a sequence of strokes from online handwrit-ten input. The space of all possible partitions of the stroke sequenceintosymbols(containingatmost L strokespersym-bol) is searched to find an optimal partition through dynamic programming. The criterion function that is used to eval-uate a given stroke partition uses two components: (1) a bigram model for symbol adjacencies along particular spa-tial relationships, and (2) the probability of the sequence of spatial relationships observed between symbols. As a post-processing step, a trigram symbol sequence model is evalu-ated for re-ranking alternatives. On a test set of over 2,500 expressions, a symbol accuracy of 96.6% is reported. An extension employing graph-based discriminative training is reported by Shi and Soong [ 131 ], with similar results. A method integrating complete symbol layout trees into the dynamic programming is described in Awal et al. [ 11 ]. 4.7 Evaluation of math recognition systems At present, meaningfully comparing evaluations of math rec-ognition systems is challenging [ 12 , 83 ]. This is in large part because different systems tend to focus on different mathematical domains, layout conventions, and stages of the recognition process illustrated in Fig. 3 (detection, sym-bol recognition/extraction, layout analysis, and interpreting mathematical content). To properly interpret results, perfor-mance metrics need to be supplemented by a characterization of the scope of the systems, to support informed comparison of high-accuracy narrow-scope systems versus systems that process a broad range of inputs with lower accuracy.
We discuss the use of benchmark data below, which are commonly used to address these issues, albeit in a way that inevitably leads to debates about representativeness of the data, and/or the relevance of the data for particular applica-tions. Even in the presence of benchmark data, quantitative means for characterizing the scope of mathematical notation handled by systems is an important area for future research. It is particularly difficult to quantify the amount of noise and distortion that a system can handle; perhaps benchmark data can be modified using document degradation models for this purpose [ 72 ], analyzing results over a space of degrada-tion parameter settings (e.g., increasing skew in handwritten expressions, or blurring in images).

The most common class of performance metrics for eval-uation of math recognition systems are recognition rates, for complete expressions [ 29 , 111 , 163 ] and individual symbols [ 8 , 29 , 111 , 143 ]. Characterizations of layout structure accu-racy have been measured using a variety of metrics; most simply, the number of symbols with the appropriate par-ent symbol, relationship, and depth in a symbol layout tree ( X  X oken placement X ), and the number of baselines that con-tain the correct symbols [ 163 ]. Other metrics provide recall measures for layout structures in a symbol layout tree (e.g., scripting, fractions, limits, roots, and matrices [ 29 , 111 ]).
One can devise metrics that combine symbol and layout-level error metrics, which may serve as criterion functions for machine learning algorithms (to optimize a complete sys-tem). Chan and Yeung [ 29 ] propose a  X  X lobal X  recall metric, the number of correctly recognized symbols and structures (subtrees) in an operator tree , divided by the number of sym-bols and structures. Garain and Chaudhuri [ 51 ] proposed a related recall measure for symbol layout trees, where recall for symbol classes and placement (i.e., symbols with the correct parent symbol and relationship in the symbol lay-out tree) is computed, but weighting misplacement errors by the depth of nesting for a symbol in ground truth. String edit distances are used to compare symbol layout trees for recognition results and ground truth, after the trees are linear-ized into Euler strings [ 124 ]. This was proposed to overcome the NP-completeness of computing a full tree edit distance between layout trees.

Recently it was proposed that a bipartite graph could be usedtocapturesegmentation,classification,andlayouterrors simultaneously [ 166 ]. The graph represents all N primitives in one node set, and the classification labels assigned to each primitive in the second node set (each primitive receives the label of its associatedsymbol). N ( N  X  1 ) spatial relationships aredefinedbetweentheunlabeled(parent)andlabeled(child) primitives. Given a symbol layout tree, spatial relationships are inherited and represented explicitly in the bipartite graph; for example, in x 2 a , the symbol a is in a subscript relationship with2,butalsoasuperscriptrelationshipwith x .Onecanthen compute recall for primitive labels and spatial relationships in the graph. Correcting these labels induces the correct clas-sification, segmentation, and layout for all input primitives (e.g., connected sub-components, or strokes). This represen-tation provides a meaningful, intuitive representation for an expressions X  elements and their interpretation at the layout level. The bipartite representation can be generalized in a straight-forward manner to operator trees as well. 4.7.1 Data sets for math recognition evaluation Just as in the TREC competitions for information retrieval (see Sect. 3.5 ), in pattern recognition and machine learn-ing research, benchmarking data are used to make meaning-ful system comparisons, in a fixed domain whose scope of interpretation is defined by examples in the data set. The ambiguities that arise from human decisions about the rele-vance of retrieval results are replaced by ambiguities arising from human decisions about how to interpret the location, symbols, layout, and mathematical content of expressions. In both cases, algorithms are evaluated by their ability to imitate those persons defining ground truth [ 164 ]. Ground truth data are expensive to create, because it requires laborious human effort; a semi-automated ground truth creation technique for handwritten expressions is described in MacLean et al. [ 93 ]. Similar to the normalizations used in retrieval, care needs to be taken to normalize ground truth and recognizer out-puts, so that equivalent expressions match properly during evaluation.

Currentlythereissomelimiteduseofavailablebenchmark datasets, but we expect their use to increase significantly as research in this area intensifies. The following is a list of benchmark data sets that have been reported in the literature, some of which are publicly available.

Infty I-III 15 [ 142 ]: Infty-1 provides around 500 pages from English technical articles on pure mathematics con-taining over 20,000 typeset expressions. Ground truth was created manually and provides symbol bounding boxes, identities, and edges of the symbol layout tree in .csv,
XML, and MathML. Infty-II adds documents from Eng-lish, French, and German publications. Infty-III provides over 250,000 single alphanumeric characters and mathe-matical symbols.

UW-III 16 [ 115 ]: mathematical content consists of 25 pages, with approximately 100 typeset equations. Ground truth creation involved double entry and triple verifica-tion. Math expressions are represented in ground truth as
L A T E X and labeled bounding boxes for expressions and symbols (in Xfig format).

Waterloo/MathBrush 17 [ 93 ]: handwritten expressions by 20 writers (4,655 expressions total). Ground truth provides operator trees, L A T E X, .gif (for typeset target), and Micro-soft and SCG ink formats.

MNIST 18 : 70,000 segmented, size-normalized (28  X  28) grayscale handwritten digit images (60 k train, 10 k test). Ground truth provides symbol identities.

Brown Dataset 19 [ 86 ]: 48 handwritten symbols from 11 writers (10 train, 12 test instances per class) Ground truth: Stroke data in Unipen format
Chan and Yeung [ 29 ] 600 handwritten expressions (11,190 symbols), written by 10 different writers, and drawn from CRC Standard Mathematical Tables and For-mulae [ 174 ].

Ashida et al. [ 8 ]: 1,400 pages for symbol recognition data (43,495 typeset expressions), 700 pages for structure analysis (21,472 typeset expressions), taken from Archiv der Mathematik and Commentarii Mathematici Helvetici .
Ground truth was created using automatic recognition fol-lowed by manual correction. Ground truth encodes bound-ing boxes and labels for expressions and symbols, and expression structure in an extended MathML format.
Garain and Chaudhuri [ 51 ]: 400 pages (297 real data and 103 synthetic data) containing 5,560 typeset expressions.
Ground truth creation used automatic recognition followed by manual correction. Ground truth consists of L A T E X and symbol bounding boxes for isolated expressions, as well as extended MathML for document pages.

ICDAR 2011 20 : data provided for the online handwrit-ten math recognition contest at the International Confer-ence on Document Recognition and Retrieval in 2011 (over 1,000 handwritten expressions from multiple writers). 5 Conclusion Recognition and retrieval of mathematical notation are chal-lenging, interrelated research areas of great practical impor-tance. In math retrieval, the key problems are defining query languages, normalizing the query and searchable documents, defining methods of indexing and matching, and providing relevance feedback. In math recognition, the key problems are detecting expressions, detecting and classifying symbols, analyzing symbol layout, and constructing a representation of meaning. Math notation provides an excellent domain for studying issues that also arise in recognition and retrieval of other types of graphical notations.

We conclude our paper by outlining expected develop-ments and numerous opportunities for future research in this area. In general terms, we predict that future research will enhance the ability of recognition and retrieval sys-tems to process a broad scope of notations and dialects, to exhibit robustness to noise, and to provide flexible, effec-tive user interfaces. We summarize open problems and future directions in five categories: query interfaces, indexing and retrieval, relevance feedback, performance evaluation, and math recognition.

Future directions in query interfaces include image-based math retrieval (allowing expression images to be used as queries) and sketch-based math retrieval (allow-ing online handwritten expressions to be used as queries). We predict that sketch-based retrieval will make promi-nent use of finger-based rather than stylus-based drawing, due to the convenience and widespread use of tablets and touch interfaces. Flexible query interfaces will combine text, images, sketching, keyboard, and mouse. Improved interfaces will be developed to allow a user to specify matching constraints; for example, hard constraints could be indicated by a box surrounding strokes and/or connected components.

Future directions in indexing and retrieval include impro-ved methods for normalization of queries and documents; flexible normalization approaches will be able to adapt to the nature of the query and document data, whether it be hand-written, vector graphics, or images. Indexing and retrieval will include pattern recognition methods to locate, recognize, and annotate mathematical expressions in typeset and hand-written document corpora. The strengths and weaknesses of document representations will be explored, determining when vector-based, tree-based, or combined models are most appropriate.

Relevance feedback is an important but as yet unaddressed research opportunity for math retrieval. We expect that there will be improvement in the interfaces and mechanisms used, and in algorithms for defining refined queries from user inter-actions. Machine learning methods may play an important role in improving relevance feedback.

Future directions in performance evaluation will include advances in the technology for creating databases with ground truth, and increased availability of datasets for math recognition and retrieval. There will be advances in perfor-mance metrics for computing errors in layout, segmentation, parsing, classification, and representation of meaning. Per-formance evaluation needs to be carried out in reference to tasks a user is trying to accomplish. Research is needed to obtain a better understanding of different models of relevance for mathematical information retrieval. Relevance depends on a number of factors, including the expertise of the user, the task underlying the user X  X  information need, and the type of resource(s) sought.

In math recognition, future directions and open problems include the detection of inline expressions, the automatic detection of mathematics in vector graphics documents, and the processing of matrix and tabular structures. We predict refinements of layout analysis, including development of new techniques and combination of existing methods via parser combination. More sophisticated language models will be developed to incorporate statistical information about mathematical notation; this information can be used during recognition or post-processing. Stochastic language models will be become increasingly sophisticated; stochastic gram-mars, as initially proposed by Chou [ 34 ], can be extended using different segmentation and/or parsing approaches. A challenge is to identify usable notation sets with invariants that can be easily adapted to dialects; the goal is to scale this up to the index set used by the Mathematical Subject Classification (MSC) [ 99 ].

In conclusion, the combination of math retrieval and math recognition technologies provides rich possibilities for math-aware computer interfaces, and for intelligent search and retrieval tools for math in documents.
 References
