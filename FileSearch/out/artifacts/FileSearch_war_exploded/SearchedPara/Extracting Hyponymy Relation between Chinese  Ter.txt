 Detecting terms and hyponymy relation among them in text data has many applica-tions. The previous work on identifying hyponymy relation commonly used pattern-based methods and had several problems. We can classify terms that have hyponymy relation into two types: hyponym and hypernym. This paper develops a novel ap-proach for acquiring hyponymy relation by modeling commonality of hyponyms and that of hypernyms separately. This method is different from traditional approaches in that terms having hyponymy relation don X  X  need to occur syntactically near one an-order to solve the second problem, we introduce the Sequential Patterns (SP), which is another pattern representation method and is well-known in Data Mining field. Section 3 defines the problem. Section 4 records our preliminary experiments we ran. Finally, section 5 makes a conclusion of our work. category uses statistical techniques, such as (Miller et al., 2000), (Zhao and Grisman, 2005), and (Zhou et al., 2006). Statistical approaches perform well on large corpora, many training examples must be labeled, which is expensive and time-consuming for some domain. The second category makes use of hand-cra fted or automatically extracted rules. sketched an algorithm to learn patterns that indicate the relation of interest, and then sentences containing both terms of seed instances, which limit the number of relation instances we can get because that not all relation instances would occur syntactically near one another. 
Another related work is about Sequential Patterns (SP). SPs have been used in Liu, 2006). The work in (Sun et al. 2007) focuses on the problem of detecting errone-ous/correct sentences. This section first defines the problem in a formal way and then presents our solution. 3.1 Problem Statement Let T be a set of terms in a domain D. Given a corpus, we could treat all terms in it as T. We say term t1 in T is a hyponym of term t2 if people accept sentences constructed from the frame A/An t1 is a (kind of) t2. Here, t2 is said to be a hypernym of t1. Let T hypo be the set of all hyponyms in T and T hyper the set of all hypernyms in T. A hy-ponymy relation, r, is in the form of &lt;t1, t2&gt;, where term t1 is a hyponym of term t2. Let R T be a set of relations among terms in T and T hypo term pairs composed of terms in T hypo and T hyper , and, obviously, R T
We treat the task of identifying hyponymy relation as two separate problems. The first problem is defined as follows. Note that terms are already labeled in corpora and given to us as input. Problem 1(Term Type Recognition). Suppose T is the set of terms in corpora D; recognize the set of hyponyms T hypo and the set of hypernyms T hyper in D. Problem 1 is that of determining whether a term pair has the hyponymy relation. T 3.2 Term Type Recognition To solve this problem, we first present the following assumption. Hypothesis 1. If two terms in T hold the same term type (either hyponym or hy-pernym), their occurrences in text data tend to have similar context. For many domains, this assumption is intuitively true. Based on the assumption, for a given corpus T, ideally, we could recognize all terms that are hyponyms and all those adopt for this recognition problem is similar in spirit to the pattern-based techniques composed of distant words in sentences and that we want to extract patterns indicating term types (i.e. hyponym and hypernym) rather than hyponymy relation. 
In order to extract patterns from sentences, we introduce the idea of Sequential Pat-terns (SP) from Dining Mining. The definitions of sequence and sequential pattern and the algorithms for extracting such patterns are introduced in (Sun et al. 2007). 3.3 Relation Identification Terms in a specified domain are usually associated with meaningful phrases which example, the noun phrase  X  X  X  ( volume ) describes a property of the term  X  X  X  X   X  X  X  ( RAM ) in sentence  X   X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  ( RAM volume is a critical parameter for the majority of tasks  X  . X  In sentence,  X   X  X  X  X  X  X  X  X  SCSI  X   X   X  X  X  X  USB  X   X  X  X  ( This driver uses the SCSI subsystem to access to the USB stor-term USB  X   X  X  X  ( USB storage device ), a property of the term USB  X   X  X  X  ( USB stor-age device ). 
In terms of Part of Speech (POS), we clas sify phrases that could show terms X  prop-one example of property noun. As other examples, phrase  X  X  X  ( speed ) describing term  X  X  X  X  ( CPU ), phrase  X  X  X  ( size ) describing term  X   X  X  X  X  X  X  ( notebook ). with  X  X  X  X  ( computer ) is another example. 
Note that two terms having hyponymy relation are often described by similar prop-erty nouns and domain verbs. Take relation r = &lt;  X   X  X  X  X  X  X  (notebook),  X  X  X  X  (computer) &gt; as an example. Term  X  X  X  X  ( computer ) can be described with property noun  X  X  X  ( size ) , so can term  X   X  X  X  X  X  X  (notebook) , and they both can be described problem, by just selecting all those term pairs described by similar property nouns and domain verbs. 
Property nouns and domain verbs in a specific domain D1 could be specified manually. In this paper, we get all the verbs and nouns relatively specific to corpus T1 phrases. After dividing terms into hyponym and hypernym and extracting phrases consists of all the phrases we extracted. If a term includes a phrase, the corresponding constraints. For example, term t1 and t2 ca nnot be the same; the similarity between t1 stances according to the similarities of their terms at last. The following subsections describe the experiments we ran in computer domain and the experimental results. 4.1 Experimental Setup In order to evaluate our algorithm, we first collected sentences from the book  X  X  X  X   X  X  X  X  X  X  X  X  X  X  (Encyclopedia of Computer Science and Technology), which are mostly technical essays in computer domain, and tagged all terms in these sentences. Among the collected sentences, 3623 sentences contain terms and 740 terms are la-beled. There are about 1282 hyponymy relation instances. In order to extract property nouns and domain verbs in target domain, we collected 1000 sentences from the Chi-nese broadcast news training data for ACE 2004, which are mainly daily news and definitely a different domain. 4.2 Experimental Results Term Type Recognition. The experiment needs some relation instances as seeds to bootstrap. The seeds we selected are: &lt;  X   X  X  X  X  X  X  X  (notebook),  X  X  X  X  (computer)&gt; , &lt;  X   X  X  X  X  X  X  (tape),  X   X  X  X  (storage)&gt;, &lt;  X  X  (keyboard),  X  X  X  X  X  (input device)&gt;, &lt;  X  X  (ring network),  X  X  X  X  (LAN)&gt;. We adopted the frequent sequence mining algorithm in (Pei et al., 2001) for learning patterns. In order to ensure that our discov-ment, min_sup, denoting the minimum number of terms whose context contains the hyponym and hypernym. In addition, there are also terms that are not contained in any corpus and few sentences contain these terms. The performance of the step is showed in Table 1. Property Nouns and Domain Verbs. This step is relatively simple. For the parame- X   X  (type),  X  X  X  (price),  X  X  (performance),  X   X  (size),  X  X  (speed),  X   X  X  (complexity),  X  X  X  (efficiency). Some examples of the discovered domain verbs:  X   X  (calculate),  X  X  X  (operate),  X  (add),  X  X  (transform),  X  X  X  (hit),  X   X  (execute),  X   X  (search),  X   X  (store),  X   X  (store),  X  X  X  (save),  X  X  X  (put),  X   X  (input),  X   X  (output),  X   X  (send),  X  X  X  (transfer),  X  X  X  (share), ,  X  X  X  (distribute),  X  X  (communicate). Due to space limitation, we do not show all the phrases we extracted. We calculated the precision, recall, and F-scor e. There are two different ways to affect amount of relations our algorithm outputs, or setting another parameter min_sim, which determines when two terms should be identified as a hyponymy relation. Table 2 reports the performance of the first method. And the performance of the second method is presented in Table 3. As can be seen from Table 3, the highest precision is achieved when min_sim is set at 0.9 and with large threshold, the performance dete-rioration is significant. At the same time, this proves our assumption that terms having hyponymy relation are usually described by similar property nouns and domain verbs. As shown in Table 2, our technique got the best performance, e.g. 56.18%, when we set k at 1000. When k is relatively small, we can achieve high precision. This is be-then the k-top instances have the largest similarities. 
Comparing with Other Methods In this paper, we compare our technique with (Hearst, 1992). As discussed in Section 2, Hearst (1992) pioneered the pattern-based relation extraction method, and proposed a relation extraction framework which is proach is: precision: 42.24% recall: 39.78%, f-measure: 40.97%. It is obvious that our method outperforms Hearst(1992) in terms of precision, recall and f-measure. After our method don X  X  necessarily contain terms that occur in the same sentence. That is to say, even though two terms appear far enough in the corpus, our technique could still instances far away in the corpus as well. This paper proposed a new method to identify hyponymy relation. Empirical evaluat-ing in Computer domain demonstrated the effectiveness of our techniques. This described by similar property nouns and domain verbs in the corpus. Our method pattern-based methods. 
