 This poster is concerned with the problem of exploring the use of social annotations for improving language models for information retrieval (denoted as LMIR).Two properties of social annotations, namely keyword property and structure property are studied for this aim. The keyword property improves LMIR by concatenating all the annotations of a document to generate a summary of the document. The structure property can boost LMIR further when similarity among annotations and similarity among documents are taken into consideration simultaneously. The two properties of social annotations are leveraged for the use of language modeling with a mixture model named as  X  X anguage Annotation Model X  (denoted as LAM). Evaluations us ing del.icio.us data show that LAM outperforms the traditional LM IR approaches significantly. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Search process Algorithms, Performance, Experimentation Language Model, Social Annota tion, Information Retrieval The language modeling approach for information retrieval has been approved to be an efficient and effective way for modeling relevance between queries and doc uments [7, 9]. However, LMIR usually suffer from two critical pr oblems, namely, data sparseness and term independence assumption. In recent years, there emerged many web sites that provide folksonomy services, e.g. del.icio.us 1 . The user generated  X  X ags X  that we call social annotations are something like keywords [1]. Since generated by the mass, th e social annotations are very cheap to achieve a great deal. In this poster, we are to explore the use of social annotations in addressing the two problems that LMIR suffers from. The newly emerging social annotations have the following characteristics. 1) The keyword property. Social annotations can be seen as good keywords for describing the respective documents from various aspects [1, 2]. 2) The structure property. An annotation may be associated with multiple documents and in return a document may be associated with multiple annotations. The structure of social annotations can be used to explore two types of similarity, document-doc ument similarity and annotation-annotation similarity [2]. In this poster, we propose a mixture model called  X  X anguage Annotation Model X  (LAM) to incorporate social annotations within the language modeling framework. LAM benefits from social annotations in two folds. 1) Based on the keyword property, the concatenation of all the annota tions of a document is likely to be a good summary of the owner doc ument. The term distribution from a summary of such can complement that from the document content. 2) With the structure property, the similarity between documents and that between annota tions can be obtained. As will be elaborated later, the similarity between documents can be used to construct topic clusters of doc uments. The clusters are assumed to better approximate the term di stribution of latent topics of documents. The similar ity between annotations can be used to relax the term independence assumption of LMIR. We crawled a dataset from del.icio.us to evaluate LAM, which consists of 1,736,268 documents with 269,566 different tags. 80 queries were collected and labe led by a group of CS students. Preliminary experimental results show that both the keyword property and the structure property benefit LMIR significantly. The keyword feature of social annotations has been discussed in many prior efforts [1, 2]. Based on this feature, the concatenation document from users X  perspective. A summary of such usually can be used as a complement of its owner documents. For http://del.icio.us/ (http://www.google.com/) there is almost no explicit text description of the search engine function of Google. In contrast, the two tags  X  X earch X  and  X  X ngine X  are used as the annotations of the Google homepage 142 and 28 times respectively in the del.icio.us data we crawled. The structure property of social annotations discussed in this poster denotes the bipartite ta gging linkage structure between annotations and documents [2]. Give n the bipartite graph structure, we are to explore two types of similarity within it. On the one hand, two documents sharing the sa me annotations may be similar to each other. On the other hand, the annotations that are assigned to the same documents may also be semantically related to each other. Furthermore, the two types of similarity can propagate and iteratively boost each other. On the basis of social annotations, three sets of data can be derived. From the keyword property, we obtain a summary dataset denoted as sum ann . sum ann = { d s1 , d s2 ... d summary of the i th document. From the structure property, we derive a dataset of document similarity denoted as sim dataset of annotation similarity denoted as sim ann sim ann are both sets of triples defined as follows: where doc i and doc j denote the i th document and the j simscore_doc ij is the similarity score between doc in sim doc . We define an operator to simplify operating the triples. Let t be a triple, t [i] means the i th dimension of t . In this subsection, we are to describe the Language Annotation Model (LAM) that we propose for incorporating the two properties of social annotations within the language modeling framework. Figure 1. Bayesian network for generating a term in LAM The popular collection smoothing methods utilize term distribution over the whole collection to give unseen words non-zero probabilities. This method can be explained, from mixture language model of a document d is a mixture of the term distribution of d  X  X  content and the term distribution over the whole collection. Inspired by this, the Language Annotation Model is implemented as a mixt ure of 4 term distributions generated from various sub m odels. A preview of Language Annotation Model is illustrated in Figure 1 which is a Bayesian network. content, or it may relate to d  X  X  annotations. Thus, we assume two sub-models: Content Model (CM) and Annotation Model (AM). The term distribution of d  X  X  language model is a mixture of the term distribution from CM and AM, i.e. generating q i from AM and  X  d is the mixture parameter. As for Content Model, we assume two retrieval processes. 1) Match the query against the literal content of a document; 2) match the query against the latent topic of a document. The simple unigram language model fits the first part well. We give it the name  X  X ontent Unigram Model X  (CUM). The second part is very similar to cluster-based la nguage model [6]. We assume the similar documents of document d may more or less share the same latent topic of d . We call d  X  X  similar documents including d better embodiment of d  X  X  latent topic than d itself. In other words, the term distribution of d  X  X  topic cluster may better approximate term distribution over d  X  X  topic cluster can be used to smooth d  X  X  language model. We call this T opic Cluster Model (TCM). As a result, Content Model is a mixt ure model containing two parts: generating q i from CUM and TCM, respectively and  X  mixture parameter. As to Annotation Model, a na X v e intuition is to implement a unigram language model on sum ann . However, the sim brings us another choice. In mo st of current tagging systems, annotations are restricted to only one word. Thus, the similarities between annotations in fact reflect the similarities between words. Thus, we can bring word relationships into AM. Inspired by Cao et al. X  X  work [3], we assume AM contains two sub models: an independency model and a depende ncy model. The independency model simply matches query terms in summaries without considering word relationships. It is the right feature of unigram language model, thus we can model it by a unigram language model which we call Annotation Unigram Model (AUM). For the dependency model, we consider a Markov process to generate a query term. First, an annotation a is selected randomly from the annotation summary d s . Second, the probability of q i based on the observed annotati on. The dependency model is named to Annotation De pendency Model (ADM): Equation 4 shows Annotation Model, as follows: where  X  a is the mixture parameter. At last, combing all the sub parts into one equation, we obtain the entire Language Annotation Model equation: The whole model equation seems very complicated. To simplify it let  X  cum = ( 1 - X  d )( 1 - X  c ),  X  tcm = ( 1 - X  d )  X  equation can be rewritten as: The above equation shows that th e Language Annotation Model is indeed a mixture model of four sub-models: Content Unigram Model, Topic Cluster Model, Annotation Unigram Model and Annotation Depende ncy Model. In Language Annotation Model, 5 model probabilities { P cum P aum ( q i | d s ), P tcm ( q i |d ), P ( q i | a ), P ( a | d (  X  c,  X  a,  X  d ) have to be estimated. The unigram model P cum ( q i | d ) and P aum ( q i several classic smoothing methods . According to Zhai X  X  work, Dirichlet prior method performs very well on concise keyword queries [9]. In our experiment data corpus, the queries are all very short. So we accept Dirichlet prior as the smoothing method to  X  X eave-one-out X  [9] likelihood on the terms all over the content collection and annotation collecti on, respectively. The detailed explanation about this estimate model can be found in [9]. In Topic Cluster Model, the topic cluster of a document d can be seen as an extended document enriched by d  X  X  similar documents. Thus, P tcm ( q i | d ) can be estimated using a unigram language model on the topic clusters. Similar to P cum ( q i | d ) and P smooth the unigram model by Dirichlet prior. document d  X  X  summary d s . Since Annotation Dependency Model is very similar to Cao et al. X  X  dependency model [3], we accept their idea of maximum likelihood estimation to approximate P ( a | d As for P ( q i | a ), we assume a dictionary-like structure, i.e. a list of approximate the probability of generating q i from the annotation a shown in the following: where t, t qa sim ann and t qa is the triple that satisfies t t [2]= q i or t qa [1]= q i and t qa [2]= a . The key problem now is the es timation of the three mixture parameters. In [9], the author s proposed an EM algorithm to estimate the Jelinek-Mercer smoothing parameter. In this poster, parameters. The extended algorithm is similar to its prototype in [9], we don X  X  list them here. Since there are no suitable standard test dataset available, we build a new test bed by the del. icio.us data crawled during May 2006. The raw data set consists of 1,736,268 web pages with 269,566 different annotations. Although the annotations in del. icio.us are easy to read and understand for human, they are not designed for computers. One main issue is originated from the one-word-tag limitation of del.icio.us service. The users ma y use concatenation of several words to form an annotation, e.g. search.engine, searchengine, etc. These annotations may decline th e retrieval performance of some model. We split this kind of tags with the help of WordNet before the experiments are conducted. We asked for a group of CS student s to help us collect 80 queries with 497 relevant documents in all, such as image search engine, Beijing Olympic 2008, hydrogen fuel cell, Beatles music, and so on. Most of the 80 queries are a bout computer science since most of the del.icio.us web pages we crawled are about computer science. We also selected some queries about other domains to make the queries diverse enough. Although the scale of the experiment is not large, it is th e best we can do. The experiments are carried out based on Lucene 2.0. To make the experiments fair as well as to focus on the ability of our method, we merge each document X  X  annotations into its content and implement a Dirichlet prior smoothed unigram language model on the merged source as our baseline. We call this model Merged Source M odel or MSM for short. The evaluation metric we accept in this work is Mean Average Precision (MAP). Many approaches can be applied to explore the similarities of annotations and documents from social annotations X  bipartite structure. In this poster we accept SocialSimRank (SSR) and Separable Mixture Model (SMM) [4]. SSR is an iterative annotation structure exploration algorithm proposed in [2]. SMM Jensen-Shannon Divergence [5] on the output of SMM to measure the similarity between documen ts and between annotations. Before the main experiments ar e carried out, we run SSR and SMM to exploit the similarities. In Table 1, top 3 most similar annotations for 5 sample annotations are listed. program ml assemble gc code develop dev The experimental results of the main experiments are presented in Table 2. The MAP for CUM, AUM , ADM, TCM, CM and AM is measured when the 6 sub-models are applied as a retrieval model alone. The overall relative improvement of LAM compared to the baseline is presented in row  X  X mprovement X . AM (AUM+ADM) 0.5326 0.4890 As we can see from Table 2, Fi gure 2 and Figure 3, LAM with SSR and SMM similarities both outperform baseline significantly. The experiments with SSR similarity scores and SMM similarity scores both produce exciting resu lts from which two conclusions can be derived. 1) Language A nnotation Model is promising and consistent in utilizing social annotations to improve language model estimation. 2) The two algorithms both work well in exploiting social annotation and document similarities from social annotation structure. Another interesting observation is that AUM outperforms CUM in both experiments. That means a nnotations can generally better represent their owner documents than contents. This observation strongly proves the keyword property of annotations. In this poster we have studied th e problem of integrating social annotations into LMIR. Two prope rties of social annotations, namely the keyword property and the structure property, are studied and effectively utilized to lighten the data sparseness problem and relax the term inde pendence assumption. A formal mixture model called Language A nnotation Model is proposed to incorporate the two properties into LMIR framework. The evaluation of LAM using the del. icio.us data shows that LAM consistently outperforms the traditional LMIR approaches significantly. In future, we are to explore more features of social annotations and more sophisticated ways of using the social annotations. The authors would like to thank the three anonymous reviewers for their elaborate and helpful comments. [1] Al-Khalifa, H. S., and Davis, H. C. Measuring the Semantic [2] Bao, S., Wu, X., Fei, B., Xue, G. R., Su, Z., Yu, Y. [3] Cao, G., Nie, J.Y., Bai, J. Integrating word relationships [4] Hofmann, T. and Puzicha, J. Statistical models for co-[5] Lin, J. Divergence measures based on the shannon entropy. [6] Liu, X. and Croft, W. Cluste r-based retrieval using language [7] Ponte, J.M., Croft, W.B. 1998. A language modeling [8] Wu, X., Zhang, L., and Yu, Y. Exploring social annotations [9] Zhai, C. and Lafferty, J. A study of smoothing methods for 
