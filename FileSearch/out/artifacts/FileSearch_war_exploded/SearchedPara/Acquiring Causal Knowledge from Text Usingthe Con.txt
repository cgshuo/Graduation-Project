 TAKASHI INUI
Research Fellow of the Japan Society for the Promotion of Science and KENTARO INUI and YUJI MATSUMOTO School of Information Science, Nara Institute of Science and Technology 1. INTRODUCTION
The general notion of causality has been a topic of inquiry since the days of the ancient Greeks. From the early stages of research into artificial intelligence (AI), many researchers have been concerned with common-sense knowledge, particularly cause X  X ffect knowledge, as a source of intelligence. Relating to this interest, ways of designing and using a knowledge base of causality informa-tion to realize natural language understanding have also been actively studied [Schank and Abelson 1977; Heckerman et al. 1993]. For example, knowledge about the preconditions and effects of actions is commonly used for discourse understanding based on plan recognition. Figure 1 gives a typical example of this sort of knowledge about actions. An action consists of precondition and ef-fect slots (in this case  X  X eather X  and  X  X et-dry, X  respectively) and is labeled with a header ( X  X ry-laundry-in-the-sun X ).

This knowledge-intensive approach to language understanding results in comprehensive knowledge base. Despite the considerable effort put into the
Cyc [Lenat 1995] and OpenMind [Stork 1999] projects, it is still unclear how feasible it is to try to build such a knowledge base manually. Very recently, on the other hand, several research groups have reported on attempts to automatically extract causal knowledge from a huge body of electronic documents [Garcia 1997; Khoo et al. 2000; Girju and Moldovan 2002; Satou et al. 1999]. While these corpus-based approaches to the acquisition of causal knowledge have considerable potential, they are still at a very preliminary stage in the sense that it is not yet clear what kinds and how much causal knowledge they will be able to acquire, how accurate the acquisition process can be made, and how useful acquired knowledge will be for language understanding.

Motivated by this background, in this paper, we describe our approach to automatic acquisition of causal knowledge from a document collection. We aim to acquire causal knowledge, such as those in Figure 2, which are binominal relations whose headings indicate the types of causal relation and whose ar-guments indicate the events involved in a causal relation. The causal relation instances in Figure 2 can be seen as constituent elements of the plan operator in Figure 1. The relations in Figure 2, therefore, represent a decomposition of the plan operator in Figure 1.

We use resultative connective markers as linguistic cues to acquire causal knowledge. For example, given the following sentences (1), we may be able to acquire the causal relation instances given in Figure 2, (1) a. Because it was a sunny day today, the laundry dried well.
The idea of using these sorts of cue phrases to acquire causal knowledge is not novel in itself. In this paper, however, we address the following subset of the unexplored issues, focusing on knowledge acquisition from Japanese texts:
What kinds and how much causal knowledge is present in the document collection? How accurately can relation instances be identified?
How many relation instances can be acquired from currently available doc-ument collections?
In Section 2 and Section 3, we describe causal knowledge that we aim to acquire. In Section 2, we describe a typology of causal relations we deal with.
In Section 3, we describe the importance of characterizing causal relation in-stances as knowledge rather than as rhetorical expressions. We then draw to-gether issues in defining the problem to be tackled in this paper. In Section 4, we outline several previous research efforts on knowledge acquisition. In Section 5, we introduce the data on which we base our investigation and acquisition of causal knowledge. We describe an investigation into the distribution of causal relations in Japanese newspaper articles. The main part of the investigation is conducted based on human judgments using linguistic tests. Section 6 and
Section 7 describe methods for automatically acquiring causal knowledge from text using machine-learning approaches. In Section 6, we deal with volitionality estimation. Volitionality information is a useful feature for classifying samples method of automatic causal relation identification and experimental results using it. Section 8 concludes this paper and outlines future work. 2. A TYPOLOGY OF CAUSAL RELATIONS
There have been various attempts to classify relations between textual seg-ments, such as sentences and clauses. These range from rhetorical relations to higher-order abstract relations by linguistics [e.g. Mann and Thompson 1987; Nagano 1986; Ichikawa 1978] and AI researchers [e.g. Litman and Allen 1987;
Allen 1995; Schank and Riesbeck 1981; Schank and Abelson 1977] and [Hobbs 1979, 1985].

In this work, we focus mainly on a set of causal relations related to the Allen X  X  plan operator [Litman and Allen 1987; Allen 1995] which was proposed in the research field of discourse understanding. Figure 1 is a simple example of the plan operator. The reasons for the adoption of this scheme are: 1. While some relations proposed by previous researchers are unclear as 2. Some previous works [e.g. Hobbs 1985] tend to involve various kinds of re-lations in addition to causal relations in order to explain all of the relations held in a text. On the other hand, Allen deals with causal relations in detail. 3. It has been reported that Allen X  X  relations are very useful in the research field of discourse recognition [Allen 1983].

The original plan operator consists of a frame-organized relationship be-tween a central (core) event and its surrounding (marginal) situation. A core event, which is shown at the top of Figure 1, often represents an agent X  X  voli-tional action. The marginal event surrounding the core event represents actions and states of affairs that occurred around the core event.

The idea of organizing a core event and its marginal events as an instance of a plan operator is an appealing one. One of the reasons for this is that it is assumed that a causal relation is held between a core event and each marginal event. Furthermore, it is assumed that different kinds of causal relations can be held between events, since the plan operator defines a number of different semantic roles, precondition , effect , and decomposition .

Based on the distinction between these relations, we have created a typol-ogy of causal relations as summarized in Table I. In our typology, we classify causal relations with respect to the volitionality of their arguments. The vo-litionality of an event distinguishes it as being an action or a state of affairs.
In this paper, we call the set of elements which constitute the arguments of causal relations an event . An agent X  X  volitional action, such as  X  X rying laun-dry X  is indicated as an action (abbreviated as Act) and all other kinds of non-volitional states of affairs such as  X  X aundry drying X  termed a state of affairs (abbreviated as SOA).

The volitionality combinations shown in the first column of Table I are a necessary condition for each causal relation class. In the table, Act volitional action and SOA i denotes a nonvolitional state of affairs. For example, effect (Act 1 , SOA 2 ) denotes that, if the effect relation holds between two argu-ments, the first argument must be a volitional action and the second must be a nonvolitional state of affairs. One of the main goals of discourse understand-ing is the recognition of the intention behind each volitional action appearing in a given discourse. The importance of distinguishing volitional actions from nonvolitional SOA has been discussed already [e.g. Carberry 1990].
The effect relation in Table I represents the relationship between a core ac-tion and its effect on a state of affairs. The precond relation represents the rela-tionship between a core action and its precondition state of affairs. The means relation represents the relationship between a core action and its marginal subaction, which is called decomposition in the plan operator. We impose the additional necessary condition on the means relation that the agents of the two argument actions must be identical. Because the two different cases obviously have a different intentional structure: the case where one agent executes two actions and the other case where two agents execute two different actions with independent intentions. The cause relation represents the relationship between two states of affairs. We decided to include this relation in this work, because although the cause relation is less related to the plan operator than the other three relations, it often indicates typical causal relations, such as  X  X eavy rain causes flooding. X  It is not easy to provide rigorously sufficient conditions for each relation class.
To avoid addressing unnecessary philosophical issues, we provide a set of lin-guistic tests for each relation class that loosely specify the sufficient condition.
Some examples of the templates that we used in the linguistic tests are shown in Table I. Note that while the examples are expressed in English, our study is carried out on Japanese. The details of the linguistic tests are described in
Section 5.2. 3. APPROACH AND PROBLEM 3.1 Using Cue Phrases
Let us consider the following examples in English, from which one can obtain several observations about the potential sources of causal knowledge. (2) a. The laundry dried well today because it was sunny.  X  e. cause ( it is sunny , laundry dries well ) (3) a. Mary used a tumble dryer because she had to dry the laundry quickly.  X  e. means ( using a tumble dryer , drying laundry quickly )
First, causal relation instances can be acquired from sentences with var-ious connective markers. (2e) Is a cause relation instance that is acquired from subordinate constructions with various connective markers as in (2a X 2d).
Likewise, the other classes of relations are also acquired from sentences with various connective markers, as in (3) . The use of several markers is advanta-geous for improving the recall of the acquired knowledge.

Second, it is also interesting to see that the source of knowledge could be extended to sentences with an adverbial clause or even a prepositional phrase as exemplified by (2d), (3c), and (3d). Note, however, that the acquisition of causal relation instances from such incomplete clues may require additional effort in order to infer elided constituents. To acquire a means relation instance (3e) from (3d), for example, one might need the capability to paraphrase the prepositional phrase  X  X ith a tumble dryer X  into a subordinate clause, say,  X  X f she had used a tumble dryer. X 
Third, different kinds of instances can be acquired with the same connective marker. For example, the type of knowledge acquired from sentence (2a) is a cause relation, but that from (3a) is a means relation.

Here example (4) corresponds to (2) and example (5) corresponds to (3). For example, while (2a) is expressed in English and (4a) is expressed in Japanese, these sentences express the same meaning.

One could acquire the same causal relation instances from sentences with connective markers such as  X  tame (because, in order to), X ,  X  ga (but), X , and  X  reba (if), X . For example, a cause relation instance (4e) is acquired from subordinate constructions with various connective markers as in (4a X 4d). A means relation instance (5e) is acquired from sentences, such as (5a X 5d). Similarly, different kinds of instances can be acquired with the same connective marker. The type of knowledge acquired from sentence (4a) is a cause relation, but that acquired from (5a) is a means relation. (4) a. hareteiruta tame sentakumono ga yoku kawaita.  X  e. cause ( hareru , sentakumono ga yoku kawaku ) (5) a. sentakumono wo hayaku kawakasu tame kansouki wo tsukatta.  X  e. means ( kansouki wo tsukau , sentakumono wo hayaku kawakasu )
Thus, although the connective marker is useful for knowledge acquisition, as described above, there is a problem. There are no one-to-one correspondences between markers and causal relations. Therefore, we need to create a compu-tational model that is able to classify and identify which type of causal relation can be acquired from a given sentence. This is the central issue addressed in this paper. 3.2 Rhetorical and Causal Relations
The sentences exemplified in (6) represent a relationship between the volitional actions  X  mikan no kawa wo muku (peeling an orange), X  and  X  mikan wo taberu (eat-ing an orange), X  expressed using various types of rhetorical expressions. Look-ing at these sentences, we are able to recognize different rhetorical relations among (6a j  X 6c j ) and (6a e  X 6c e ). In general, the sentences (6a be interpreted as a P URPOSE rhetorical relation, (6b j ) and (6b rhetorical relation, and (6c j ) and (6c e )asaC ONTRAST rhetorical relation. (6) a j . mikan wo taberu tameni kawa wo muita. (P URPOSE
Here, we assume that the reason that we are able to recognize all of these sentences as coherent is that the sentences conform to the causal knowledge presented in (7). (7) [knowledge]
This suggestion is supported by the following observation: we are able to recog-nize the sentences in (8) as incoherent because we do not possess any knowledge to which they can coherently conform. [We attached the symbol  X  ning of each example sentence in (8) to indicate that the sentence is incoherent .
This is a convention in the linguistics community.] (8) a j .  X  mikan no kawa wo muita tameni mikan wo taberu koto ga dekinakatta.
We aim to acquire causal knowledge like (7), which can work as the basis for recognition of rhetorical expressions, such as in (8) as being coherent.
Figure 3 illustrates the relationship between the rhetorical level and the causal knowledge level. We assume that the relationships between event in-stances indicated in a text are located at the rhetorical level. We also assume that when the event instances are abstracted from the rhetorical level to a higher abstract level, the relationships between abstracted classes are located at the causal knowledge level.

For example, while the two events expressed in the sentence  X  X hough I peeled the orange, I could not eat it X  constitute the elements at the rhetorical level, the relationship between the abstracted classes  X  X eeling an orange X  and  X  X at-ing an orange X  is assumed at the causal knowledge level. Our proposed col-lection of causal relations should constitute a higher level of abstraction than mere rhetorical relations. At the very least, we must, therefore, abstract away modality information such as:
Tense and aspect: 1 whether the event represented has already occurred or not.
Elements relating to the information structure: which element is focused on in a sentence and which element is new information. 3.3 Representation of Arguments
Knowledge representation is one of the central issues in the field of AI. We rep-resent arguments of causal relation instances by natural language expressions such as Figure 2, (2e), and (3e), instead of by any formal semantic representa-tion language for the following reasons.

It is still unclear whether abstraction is a necessary process in representing knowledge. Having decided to do abstraction, it is very hard to decide the most suitable level for the abstraction.

It has proved difficult to design a formal language that can fully represent the diverse meanings of natural language expressions.
As discussed in Iwanska and Shapiro [2000], there has been a shift toward viewing natural language as the best means for knowledge representation.
As discussed in detail in Section 7.4, we anticipate using acquired causal knowledge within the framework of case-based reasoning, which has been ap-plied successfully in the machine translation community, for example Satou X  X  work [Satou and Nagao 1990]. We believe that acquired knowledge is suffi-cient for practical use without any abstraction process.

In fact, for example, Harabagiu and Moldovan [1997] proposed a text-based knowledge representation system, which applied a knowledge expression scheme based on natural language. All the knowledge in the Open-Mind Com-mon Sense knowledge base organized by Singh et al. [2002] is also represented by English sentences and Liu et al. [2003] reported that Singh X  X  database could be successfully used for textual affect sensing. 3.4 Target Problem
On the basis of the above, to acquire causal knowledge from text, we use a simple procedure consisting of two main phases, shown in Figure 4.
Given text segments, the process of acquiring causal knowledge forms two independent phases: proposition extraction and causal relation identification. 1. Proposition extraction: Removing the modality expressions and extracting 2. Causal relation identification: Identifying causal relations held between  X  sentakumono ga yoku kawaku . X 
In this paper, we aim to develop an implementation of the latter phase, causal relation identification, because the former phase, proposition extraction, can be simply resolved using current natural language processing techniques.
Simply speaking, the proposition extraction phase is run as follows. First, the morphological analysis is executed to get part-of-speech information for each word in the input sentence. Next the dependency structure analysis is executed to extract chunks that express events. For each chunk extracted, some modal-ity elements, which are identified by part-of-speech information, are removed.
Finally, the remaining elements in the chunk are extracted as a proposition. 4. RELATED WORK
In recent years, there have been several attempts at automatically acquiring causal knowledge from document collections [Garcia 1997; Satou et al. 1999; knowledge acquisition, three of which make use of cue phrases as we do and one of which makes use of a statistical technique. Next, we describe the study causal relations, such as Pearl [1988, 2000] and Heckerman et al. [1997] forms one subfield of the causality research activity. However, since in this paper, we focus on automatic knowledge acquisition from text rather than modeling, we do not describe the studies of probabilistic modeling. 4.1 Cue Phrase-Based Approaches
Girju and Moldovan [2002] proposed a method for acquiring causal knowledge from text in English based on the triplet patterns as follows: where clue is a causative verb, and NP 1 and NP 2 are noun phrases. Causative verbs express a causal relation between the subject and object (or prepositional phrase of the verb), such as  X  X ause X  and  X  X orce. X 
In their method, first all triplets matching the pattern above are collected from the gloss of WordNet 1.7 [Fellbaum 1998]. The following is one such example: (9) extreme leanness NP
Next, for each pair of nouns determined as above, they search for sentences containing the noun pairs in a document collection. From these sentences, they automatically determine all patterns NP 1 verb / verbal expression NP
NP 1 -NP 2 is the pair under consideration. For example,  X  extreme leanness associated with starvation or disease NP to the noun pairs in the previous example. In addition,  X  associated with  X  X sanew extracted expression that suggests causality. Third, to eliminate the patterns, which do not represent causal relation, they apply semantic constraints, which are mainly based on the semantic categories defined in WordNet. Finally, they ranked the remaining patterns according to the ambiguity of the sense for the verb, and its frequency. From the evaluation using the TREC-9 [Voorhees and Harman 2001] collection of texts which contains 3GB of news articles from Wall
Street Journal, Financial Times, Financial Report, etc., they extracted about 1300 patterns (causal expressions. Using 300 of the 1300 patterns, the accuracy of their method, as evaluated by human subjects, was about 65%.

Terada [2003] proposed a method for acquiring causal knowledge similar to that of Girju et al. He used only a small set of cue phrases as follows: causative verb cause causing caused by result in resulting in result from lead to prepositional phrase because of due to
While Girju et al. used only noun phrases as contextual information around the cue phrases, Terada used three types of contextual information.

NP Noun phrase (equivalent to Girju et al.) ex. aircraft loss NP
NP + PP In addition to NP , a prepositional modifier of the NP is considered. ex. aircraft loss NP of oil pressure PP
N / A In addition to NP + PP , full clauses are considered. ex. aircraft oil pressure lose clause
He applied a constraint based on the frequency of the patterns using a se-quential pattern-mining algorithm, PrefixSpan [Pei et al. 2001] instead of the semantic constraints applied by Girju et al. In an evaluation using aviation safety reports handled by the Aviation Safety Reporting System in National
Aeronautics and Space Administration, a collection containing 24,600 docu-ments (15.4 words/document), he extracted very few causal expressions. In the case of using N / A contextual information, he extracted 23 expressions, which was the largest number of causal expressions extracted for any of the contextual information classes.

Khoo et al. [2000] acquired causal knowledge with manually created syntac-tic patterns especifically for the MEDLINE text database [MEDLINE 2001].
Figure 5 shows an example of syntactic patterns where square brackets refer to character strings and round brackets refer to syntactic or semantic role. In their method, an input sentence is first parsed and a syntactic structure is built.
Next, if the syntactic structure matches any of the syntactic patterns, the ele-ment in the  X  X ause X  slot is extracted as the cause element of the causal relation and the element in the  X  X ffect X  slot is extracted as the effect element of the same causal relation. In all, 68 syntactic patterns were constructed. Their method was evaluated using 100 MEDLINE abstracts and had precision of about 60%.
In three studies described above, explicit cue phrases were used; this ap-proach is adopted in our method. Girju et al. and Terada focused on causative verbs, and Khoo et al. on syntactic patterns. However their approach is different from ours. While they focused mainly on discovering and creating new patterns for acquiring causal expressions to cover more instances of causal relations, we focus on classifying and identifying the types of causal relations using a particular cue phrase (described in the remaining sections in this paper). 4.2 A Statistics-Based Approach
Torisawa [2003] proposed a statistical method for extracting common-sense in-ference rules, which are identical with our causal knowledge from Japanese newspaper articles. While the above-mentioned previous studies focused on ex-plicit cue phrases to acquire knowledge of causal relation, in Torisawa X  X  method, in addition to the expressions with cue phrases, the expressions without cue phrases are also dealt with as knowledge source such as: (10) biiru wo nomi VP
The key idea of Torisawa X  X  method for knowledge acquisition is to construct a statistical model for causal relations using several kinds of expressions, in-cluding those with/without cue phrases based on an assumption that is related to the sharing of nouns by two expressions.
Torisawa extracted approximately 200 inference rules using 33 years of newspaper articles. The extracted rules were all of high quality. His approach, based on statistics, may have wider coverage than cue phrase-based approaches, since it can use as its source parallel verb phrase pairs without cue phrases.
However, current reported coverage on extraction is not high enough to make it usable in applications, such as inference systems. 4.3 Rhetorical Parsing Several linguistic theories of textual coherence have been proposed. Rhetorical
Structure Theory (RST) [Mann and Thompson 1987] is one such theory. In RST, every text segment, or more precisely clause, has a relationship to another text segment. This relationship is known as a rhetorical relation.

The aim of rhetorical parsing [Marcu 1997, 2002] is to correctly determine the type of rhetorical relation in a given document. However, note that our typology of causal relations is not just a simple subset of common rhetorical relations as proposed in RST. That is, identifying causal relations is fundamentally different from rhetorical parsing. As described in Section 3.2, our proposed collection of causal relations constitute a higher level of abstraction than mere rhetorical relations. While rhetorical parsing can make clear which types of coherence relations are presented in linguistic expressions, causal knowledge provides the basis for explaining how a rhetorical relation can be recognized as coherent. 5. DATA COLLECTION AND ANALYSIS
Linguists suggest that there are some expressions that act as cue phrases for causal relations. However, it is not clear what proportion of linguistic expres-sions containing cue phrases actually implicitly include causal relations and what kinds of causal relations these are. To resolve these issues, we investi-gated the distribution of causal relations in Japanese text documents.
Currently, there are several kinds of electronic text resources available, such as newspapers, dictionaries [e.g. RWC 1998], encyclopedias [e.g. Britannica 1998], novels, e-mails, and web documents. We selected newspaper articles as text resources in this study. One of the reasons for this decision is that both the morphological analyzer and dependency structure analyzer we used in prepro-cessing are optimized for the types of sentences found in newspaper articles.
To acquire correct knowledge, the sentences included in the source text should be amenable to correct analysis at the preprocessing stage. 5.1 Causal Expressions in Japanese Text
Causal relations can be expressed in various ways. For example, Altenberg [1984] attempted to make an inventory of various causal expressions in spoken and written British English. In Altenberg X  X  work, four major types of causal expression are taken into consideration, which are defined on the basis of the link between the events: Adverbial linkage (e.g., so , hence , therefore ) Prepositional linkage (e.g., because of , on account of ) Subordination linkage (e.g., because , as , since ) Clause-integrated linkage (e.g., that X  X  why , the result was )
It can be assumed that a similar causal expression classification can be per-formed on Japanese text [Masuoka and Takubo 1992; Masuoka 1997] as has been performed on English. The following examples show Japanese causal ex-pressions categorized according to part of speech of the cue phrases. (11)  X  X onjunction
The categories of explicit cue phrases described above have a relaxed corre-spondence with their arguments, which are marked by the follow categories of cue phrase.
Of the three types of cue phrases, we focus here on the conjunctive particle by which clauses are most likely to be indicated since:
In general, an event is described in text concisely using a predicate and some case elements connected by particles
Clauses are usually constructed using the same constituents as events, say, a predicate and case elements connected by particles
We consider that if a cue phrase expression occurs with high frequency and no ambiguous uses, it is a suitable expression for use in knowledge acquisition.
Here, we examined the frequency distribution of conjunctive particles. Table II shows the ten most frequent conjunctive particles in the collection of Nihon
Keizai Shimbun newspaper articles from 1990 [Nikkei 1990]. This table was generated by counting all conjunctive particles after morphological analysis of the articles using ChaSen 2 [Matsumoto et al. 1999].

In this table, the word  X  tame (because), X  and  X  reba (if), X  have a pragmatic con-straint on the inevitability implicit in the relationship between two arbitrary events. The relations signaled by these words usually involve a high degree ally confirmed this pragmatic constraint on the inevitability implicitly in tame , based on the approximately 2000 examples. Based on the above discussion, we selected the word tame as our main target for further exploration.
Next, Table III shows the frequency distribution of the intra-sentential con-texts in which tame appears in the same newspaper article corpus used above.
The sentences classified into the  X  X dverbial verb phrase X  type are extracted as follows: adverbial verb phrase. First, for each sentence including tame , the depen-dency structure between bunsetsu -phrases is automatically constructed with
CaboCha 3 [Kudo and Matsumoto 2003]. The bunsetsu -phrase is one of the fun-damental units in Japanese, which consists of a content word (noun, verb, ad-jective, etc.) accompanied by some function words (particles, auxiliaries, etc.).
Next, each modifier bunsetsu -phrase of tame indicated as  X  X  X  in Figure 6 and modified bunsetsu -phrase of tame indicated as  X  X  X  in Figure 6 is identified. A sentence is classified as being of the  X  X dverbial verb phrase X  type if both mod-ifier bunsetsu -phrase and modified bunsetsu -phrase fulfill one of the following morphological conditions: c1. Includes a morpheme, whose part of speech is c2. Includes a morpheme whose part of speech is c3. Includes a morpheme, whose part of speech is c4. Includes a morpheme, whose part of speech is any noun category except
In Table III, we see that more than half of sentences are classified into type (a). In these sentences, the word tame is used as an adverbial connective marker accompanying a verb phrase that constitutes an adverbial subordinate clause.
We are pleased to observe this tendency, because the knowledge acquisition from this type of sentence is expected to be easier than from the other types of sentences shown in Table IIIb. As described in Section 3.1, one may need to infer elided constituents in order to acquire causal relation instances from the sentences classified into type b. Based on this preliminary survey, we restrict our attention to the sentences classified into type a in Table III. Hereafter, this type of sentence will be indicated as tame -complex sentences . 5.2 Data Collection Procedure
We assembled a collection of data for examining the distribution of causal re-lation in tame -complex sentences as follows (see also Figure 7):
Step 1 : Collection. First we randomly took 1000 samples that were auto-matically categorized into tame -complex sentences from the same newspaper article corpus mentioned in Section 5.1. We used ChaSen and CaboCha again for preprocessing. Next, from the 1000 samples, we removed sentences which are inappropriate as knowledge resource. We removed interrogative sentences and sentences from which a subordinate-matrix clause pair was not properly extracted due to preprocessing (morphological analysis and dependency struc-lation instances have not been acquired from interrogative sentences. As a result we were left with 994 sentences. These 994 sentences fulfill the con-dition of c1 for the adverbial verb phrase. We indicate this set of sentences as
S
Step 2 : Division. We extracted the proposition from each subordinate and extraction process. For each sentence in S 1 , we first removed the modality ele-ments attached to the end of the head verb, which is the verb in bunsetsu -phrase  X  X  X  or  X  X  X  from the sentence. The remaining elements in the sentence were then regarded as the proposition. By this operation, some modality information, such as tense or passive voice information, was erased. Hereafter, we indicate the extracted proposition as the clause . Next, we manually divided the 994 samples into four classes depending on the combination of volitionality (volitional ac-tion or nonvolitional SOA) in the subordinate and matrix clauses. Volitionality was judged using the linguistic tests described in Section 5.2.1. The frequency distribution of the four classes (A X  X ) is shown in the left-hand side of Table IV. for the cause relation, the clause pairs classified into the classes B and C fulfill the necessary conditions for the effect relation and the precond relation, and the clause pairs classified into the class D fulfill the necessary condition for the means relation. (It should be noted that it is not always possible to confirm that the same agents X  condition for class D is fulfilled.)
Step 3 : Classification. We then examined the distribution of the causal re-lations we could acquire from the samples of each class using the linguistic tests. The details of the linguistic tests for judging the causal relations are also described in Section 5.2.1. 5.2.1 Linguistic Tests. A linguistic test is a method for judging whether a linguistic expression, normally a sentence, conforms to a given set of rules. We call the sentence to be judged a target expression. The rules are realized as a linguistic template, which is linguistic expression including several slots. An example of linguistic templates is shown in Figure 9.

In practice, a linguistic test is usually applied using the following steps: 1. Preparing the templates. 2. Embedding the target expression in the slots of the template to form a can-didate sentence. 3. If the candidate sentence is judged to be correct syntactically and semanti-cally, the target expression is judged to conform to the rules. If the candidate sentence is determined to be incorrect, the target is judged nonconforming. 5.2.2 Linguistic Tests for Judging Volitionality. We prepared four tem-plates for volitionality judgments as follows: vol t1 jibun de [ ... ] to iu koto wo shitai. vol t2 jibun de [ ... ] to iu koto wo suru tsumori desu. vol t3 jibun de [ ... ] to iu koto wo suru kotoni suru. vol t4 jibun deha [ ... ] to iu koto wo shitaku ha nai.
The square brackets indicate the slots in which the target expression is em-bedded. If a candidate sentence is determined to be correct by a human subject, the embedded target is judged to be a volitional action. On the other hand, if the candidate sentence is incorrect, this template is rejected, and another is tried. If all templates are tried without success, the target expression is judged to be a nonvolitional SOA. The following are examples of this process. In each case, the first item shows a target expression, the middle item or items show candidate sentences, and the last item shows the final judgment. (12) a. mise wo shimeru. (13) a. kabushiki shijou ga teimeisuru.
 5.2.3 Linguistic Tests for Judging Causal Relations. We prepared three to seven templates for each causal relation. The following are some examples. All templates are shown in the appendix.  X  cause  X  effect  X  precond  X  means
We embed the subordinate and matrix clauses in the slots of the templates to form candidate sentences. If a candidate sentence is determined to be correct, the causal relation corresponding to the particular template used is assumed to hold between the clauses. If the candidate sentence is incorrect, this template is rejected, and another is tried. If all templates are tried without success, the candidate sentence contains a relation unclassifiable within our typology and is assigned to the class others .

The expressions  X  shibashiba (often) X  or  X  futsuu (usually) X  in templates indi-cate a pragmatic constraint on the inevitability of the relationship between any two events: that is, the relations indicated by these words usually have a high degree of inevitability. For example, a causal relation can be said to ex-ist between two events shown in (14a). However, we are able to recognize the sentence in (14b) which contains the expression futsuu as incorrect, since the relation possesses a very low degree of inevitability.
 (14) a. takara kuji wo kattara ittou ga atatta.

This constraint affects the judgments, which are made based on inevitabil-ity. Therefore, causal relations with a very low degree of inevitability can be rejected.

The following are examples of judgment process. In each case, the first item shows a sentence including target expressions, the middle item or items show candidate sentences, and the last item shows the final judgment. (15) a. shijou ga teimeishita tame mise wo shimeru. (16) a. kaigansen wo kaihatsusuru tameni chousa wo oeteiru.
 5.2.4 Reliability of Judgments. Volitionality and causal relations were judged using the linguistic tests. To estimate the reliability of judgments, two human subjects majoring in computational linguistics annotated the texts with both volitionality and causal relation information. For a measure of reliability of judgments, we used the  X  statistic, which is one of the well-known statis-tics for a measure of reliability of judgments X  agreement between two subjects originally proposed by Cohen [1960]. It is claimed by Krippendorf [1980] that if  X &gt; 0 . 8, it is highly reliable.

We calculated the  X  statistic using 200 annotated samples. The 0.93 for volitionality are 0.88 for causal relations. This means that the reliabil-ity of judgments of both volitionality and causal relations are sufficiently high. 5.3 Analysis 5.3.1 The Marker tame . The right-hand side of Table IV shows the most abundant relation and its ratio for each class A X  X . For example, given a tame -complex sentence, if the volitionality of the subordinate clause is a volitional action and the volitionality of the matrix clause is a nonvolitional SOA (namely, class B), they are likely to conform to the relation effect (Act probability of 0.93 (149/161). The following are examples of the most abundant relation in a given class.
 (17) Tai de manguroubu wo hakaishita tame dai suigai ga hasseishita.  X  effect ( Tai de manguroubu wo hakaisuru , dai suigai ga hasseisuru ) (18) Pekin eno kippu wo kau tame kippu uriba ni itta.  X  means ( kippu uriba ni iku , Pekin eno kippu wo kau )
The following are examples of cases where the most abundant relation in a given class did not hold. (19) a. kigyou no seichou ga mikomeru youni natta tame kiun ga takamatteiru. Table IV shows the quite suggestive result for causal knowledge acquisition.
As far as tame -complex sentences are concerned, if one can determine the value samples, that is, subordinate and matrix clauses pairs indicating each different event extracted from tame -complex sentences into the four relations X  cause , effect , precond , and means  X  X ith precision of 85% or more. Motivated by this observation, in the next section we first address the issue of automatic estima-tion of volitionality before moving onto the issue of automatic classification of causal relations. As shown in Table IV, we cannot completely classify the sam-ples into correct causal relation classes using only the value of the volitionality and syntactic information. Therefore, we need to use further rich information and 7. 5.3.2 Other Markers. We attempted the same procedure outlined in
Section 5.2 using the other five cue phrases. The cue phrases and data sizes used in this investigation are shown in Table V.

In order to apply the linguistic tests to the cue phrases ga and noni ,wede-veloped a minor variation of candidate sentence generation as described below.
The Japanese connectives ga and noni are usually used to connect expressions, which do not hold any causal relations. This means that if given a modified version of an expression pair by means of adding/removing a negation word to/from one of two expression connected ga or noni , we acquire a causal relation instance from them.

If a target expression located in the matrix clause includes a negative expres-sion, we remove the negative expression from the target expression. We then embed the resulting target expression in the slots of the templates to form the candidate sentences. (20) chichioya ga nakunatta noni kokubetsu shiki ni kaketsuke nai.
If a target expression located in the matrix clause does not include a negative expression, we add a negative expression onto it. We then embed the resulting target expression in the slots of the templates to form the candidate sentences. (21) hi ga sasu noni ame ga furu.

The results for each cue phrase are shown in Table VI to Table X. Looking at the tables, it is clear that these five cue phrases are of less use than tame , because of the fact that almost one-half of the samples were not classifiable within our typology of causal relations. The word node has a relatively similar distribution to tame as compared to the other four cue phrases. However, no samples were classified as the means relations. Based on the above results, we do not use these five cue phrases in the experiments on knowledge acquisition described in Sections 6 and 7.

The following (22) are sample sentences from which extracted subordi-nate and matrix clause pairs were identified as either (a) causal relations or (b) noncausal relations within our typology. The samples are grouped according to cue phrase. (22)  X  node  X  reba  X  tara  X  ga  X  noni
Based on these results, we attempt to automatically acquire causal knowl-edge from tame -complex sentences, as described in Section 7. Note that the difficulty of acquiring causal knowledge depends on the characteristics of the relations without worrying about the degree of inevitability implicit in rela-tions between events thanks to the pragmatic constraint on inevitability in tame -complex sentences. However, when focusing on cue phrases with a lower degree of inevitability than tame , such as tara , in addition to classifying causal relations, it is necessary to take account of the framework that determines the degree of inevitability.
 6. ESTIMATION OF VOLITIONALITY
In the previous section, to acquire causal knowledge, it is important to esti-mate the volitionality (volitional action or nonvolitional SOA) of the clauses.
Hereafter, we call volitionality of the clause clausal volitionality . In the field of linguistics, work has been done on volitionality of verbs as one of the mood attributes (we call volitionality of the verb verbal volitionality ). However, no work has been done on volitionality over larger linguistic segments, such as phrases and clauses. In this section, we investigated experimentally how ac-curately clausal volitionality of clauses can be estimated using Support Vector
Machines X  X n accurate binary classification algorithm. 6.1 Preliminary Analyses
Clausal volitionality depends mostly on the verb in a clause, more precisely, it depends on verbal volitionality. That is, if certain clauses contain the same verb, volitionality of these clauses also tends to be the same. For example, in the set S 1 which includes 1988 clauses, there are 720 different verbs, 299 of which occur 2 times or more. Of these 299 verbs, 227 occurred exclusively in clauses sharing the same clausal volitionality.

Nevertheless, there are some counterexamples. Some samples were found to depend on other contextual factors. For example, both the subordinate clause (expand). X  However although the clausal volitionality of the former case is a vo-(23) a. seisan nouryoku wo kakudaisuru tame setsubi toushisuru.
In order to estimate clausal volitionality with high accuracy, we need to incor-porate additional factors. As a result of analyzing the tame -complex sentences in
S volitionality.

A clause tends to be nonvolitional SOA when the agent is not a person or an organization.

The volitionality value of a clause tends to change depending on whether it appears as a subordinate clause or a matrix clause.

The volitionality value of a clause tends to change based on modality, such as tense. 6.2 Experimental Conditions 6.2.1 Learning Algorithm. We applied Support Vector Machines (SVMs) as learning algorithm. SVMs are binary classifiers, originally proposed by Vapnik [Vapnik 1995]. SVMs have performed with high accuracy in various tasks, such identification [Jonsson 2000].

SVMs are one of the large-margin classifiers. Based on the large-margin criterion, the training procedure finds a hyperplane, that not only separates the samples in one class from those in the other, but also for which the separation is as large as possible.

Although we omit details of the algorithm here, we describe some advan-tages of SVMs. In most cases, the generalization performance of SVMs does not depend on the dimensionality of the feature space. Furthermore, SVMs can use kernel functions, which can deal with nonlinear classification by means of an implicit mapping of the original feature space into a high-dimensional space. We used the quadratic polynomial kernel as the kernel function. The polynomial kernel function makes it possible to deal with any combination of features.

In this experiment, using only intraclause information, we created a separate classifier for each clause type, since we found little evidence of a correlation between the clausal volitionality of a matrix clauses and a subordinate clause.
In this work, we used the TinySVM software package. 5 6.2.2 Features. Based on the results of our preliminary analyses men-to represent the clauses in the sentences. Table XI shows all the features we used. Fortunately, the verbal features, which provide the most important in-formation, can be easily extracted from the currently obtainable dictionaries: the EDR concept dictionary, the dictionary incorporated in the ALT-J/E transla-tion system, and NTT Goi-Taikei. The case and modality information can also be extracted using simple pattern-matching rules. While almost all features can be extracted automatically, it is not so easy to extract agent information.
Phrases to represent agents usually do not appear overtly in Japanese complex sentences. In the field of natural language processing, ellipsis resolution is well-known as a very difficult task. In this experiment, we implemented a simple agent feature extractor with a precision of about 60%, instead of attempting to implement an ellipsis resolution component. This means agent information described later. 6.2.3 Data. We used all the sentences in S 1 as training samples and a new set of tame -complex sentences, S 2 , as test samples. The set 985 tame -complex sentences. This set was created using the same procedure as
S . We first sampled 1000 random sentences from a newspaper article corpus issued in a different year than S 1 . We then removed interrogative sentences and sentences from which a subordinate-matrix clause pair was not properly extracted due to preprocessing errors, leaving us with 985 test samples. The frequency distributions of clausal volitionality for both
Table XII. 6.3 Results
Table XIII shows the results. The values in Table XIII denote accuracy, which is calculated by dividing the number of correct samples by the total number of samples. The row  X  X c &amp; Mc X  is the accuracy when estimating both subordinate and matrix, clauses in the same sentence. The column  X  X VM2 X  denotes accuracy in the case where a classifier is trained using all the features shown in Table XI.
The column  X  X VM1 X  denotes accuracy in the case where a classifier is trained using all the features shown in Table XI, except agent information. The columns  X  X L1 X  and  X  X L2 X  denote accuracy for the baseline.  X  X L1 X  is very simple but the most commonly used model which outputs volitional action all the time because the frequency of appearance of a clause with volitional action is greater than the frequency with nonvolitional SOA (see Table XII).  X  X L2 X  denotes the accuracy achieved by applying a simple classification strategy as follows:
BL2: voting strategy. (a) if a verb of an input clause appeared in the training set, the clause is classified by a majority vote, and (b) if the voting is even or the verb is not present in the training set, the clause is classified as a volitional action by default.

From the preliminary analyses mentioned in Section 6.1, it is found that clausal volitionality is mostly dependent on verb information. Therefore, the approach based on verb information is used as the second baseline model.
Table XIII offers several insights. First, the accuracy of  X  X L2 X  is an improve-ment on the accuracy of  X  X L1. X  This result suggests that verb information is useful in performing clausal volitionality estimation. Second, the results ob-tained using SVMs are an improvement on the baseline accuracy. The case feature and the modality feature are responsible for this improvement be-cause the accuracy of both  X  X VM1 X  and  X  X VM2 X  is greater than that of  X  X L2. X 
Comparison of the accuracy of  X  X VM1 X  and  X  X VM2 X  shows that agent infor-mation also contributes to improved accuracy, although the agent information extraction is not perfect in this work.

Next, we introduced a reliability metric to further improve accuracy. When the reliability of estimated volitionality is known, the accuracy of automatic classification of causal relations can be improved by removing samples where the reliability value is low.

To estimate the reliability, we used the absolute values of the discriminant function (the distances from the hyperplane) output by the SVMs. We set a output for a given sample when the reliability was greater than
We applied this metric to the results of  X  X VM2. X  By varying the coverage-accuracy curves of Figure 10 where:
Figure 10 indicates that when the threshold value is increased, the number of samples output decreases, and coverage is low. The accuracy, in the case of low coverage, is higher than that in the case of high coverage. These results confirm that it is possible to produce clausal volitionality estimates with a very high confidence level. 7. AUTOMATIC ACQUISITION OF CAUSAL KNOWLEDGE
In this section, we describe an experiment designed to assess how accurately causal relation instances can be acquired automatically. As shown in Figure 4 in Section 3.4, the process consists of two main phases. We implemented a high precision rule based proposition extractor for the first phase using existing nat-ural language processing techniques. In this section we describe our approach to automatic identification (classification) of causal relations.

In Section 5, we described the distribution of causal relations in Japanese newspaper articles. It was demonstrated that the pairs of subordinate and ma-trix clauses in the tame -complex sentences can be classified by hand into the causal relation classes within our typology with a precision of 85% or more. In
Section 6, we showed that it is possible to achieve clausal volitionality estima-tion with good accuracy using a machine-learning approach.

Based on these findings, we attempted to identify causal relation instances contained in tame -complex sentences. Clausal volitionality was used as a fea-ture in performing classification. We used five classes X  cause , effect , precond , means , and others relations. The others class contains relation instances, which were categorized into the others class during the investigation of distribution of causal relations described in Section 5. We again used SVMs as the classifier. 7.1 Identification Procedure
Clausal volitionality is a major factor used in classifying the sample. A sample therefore could be incorrectly identified if the degree of confidence in clausal volitionality estimation is low. Based on this assumption, we use the following procedure for the identification of causal relations.

Step A: Clausal Volitionality Estimation. A subordinate clause/matrix clause pair is extracted from an input tame -complex sentence. The clausal vo-litionality for each clause is also estimated with a given degree of confidence.
Hereafter, the degree of confidence of a subordinate clause is denoted by conf and that of a matrix clause is denoted by conf m .

Step B: Filtering. Suppose that a threshold for the degree of confidence of subordinate clauses is  X  s and a threshold for the degree of confidence of matrix clauses is  X  m .If conf s  X   X  s and conf m  X   X  m then go on to Step C, otherwise classify into the others relation class deterministically and the procedure is fin-ished. Although this step reduces recall, our hope is that it increases precision. Step C: Classification. Classify the sample into a causal relation class using
SVMs. The standard SVMs can apply only to binary classification. Therefore, the one-versus-rest method was used so that we could apply SVMs to multiple classifications. The one-versus-rest method is one of common extensions to the multiple class case. See, for example, Rifkin and Klautau [2004] for details. For the N-ary classification problem, N different binary classifiers are constructed, the class i or not-i . In the classification phase the classifier with the maximal output defines the estimated class. 7.2 Experimental Conditions 7.2.1 Features. The features we used are as follows: f1 . The clausal volitionality estimated by the technique described in the previ-ous section; f2 . All the features except  X  X  word X  shown in Table XI; f3 . Whether the agents of the two clauses in the sentence are the same.
The third, agent correspondence feature can be automatically extracted with a high level of precision by using the technique described in Nakaiwa and Ike-hara [1995]. However, in this experiment, we were unable to implement this method because of the unavailability of the detailed linguistic rules. Instead, a simple rule-based extractor was used. For example, we decided that a sample has the same agent when the agent is represented by the case marker ga in the matrix clause and by ellipses in the subordinate clause. 7.2.2 Data. The data are the same as those in Section 6. We used the sen-tences in S 1 as training samples and S 2 as test samples. We first estimated the clausal volitionality and its reliability using all the training data in We then removed about 20% of the samples by applying the reliability metric.
The remaining samples were then used to train the classifiers for the causal relations.
 The distribution of the causal relations in tame -complex sentences in shown in Table XIV. The notations in this table follow those in Table IV. 7.2.3 Evaluation Measure. Classification performance is evaluated using recall and precision, where, for each causal relation R:
The three-point averaged precision is also used as a summary of the 0 . 25, 0 . 50, and 0 . 75. The recall-precision curves are calculated using the same procedure as described for reliability in Section 6.3, where the reliability was defined as: where s 1 is the maximum discriminant function value obtained through the one-versus-rest method, and s 2 is the second highest value. 7.3 Results
The results are shown in Tables XV, and XVI, and Figure 11. the three-point averaged precision of the causal relation classification where
Step B (filtering) is skipped. On the other hand, Table XVI shows the results where Step B is included. Figure 11 shows the recall-precision curves corre-sponding to R3 in Table XVI.

We discuss the results from the viewpoint of the effect of clausal volitionality on the classification. First, we consider the results of Table XV. In Table XV, R1 denotes the results in the case where the classifiers were trained using only f1, clausal volitionality as features. In this case, no information except clausal voli-tionality was used. Therefore, we applied a minor variation of the classification process,  X  X tep C-forR1, X  instead of the one presented in Section 7.1.
Step C-forR1:
R2 denotes the results in the case where the classifiers were trained using f2 and f3. R3 denotes the results in the case where the classifiers were trained using all the features described in Section 7.2.

The three-point averaged precision of R1 for each causal relation class is lower than that of R3. In R1, the error in clausal volitionality estimation is di-rectly responsible for the error in causal relation classification. The three-point averaged precision of R2 is also lower than that of R3. Comparing R2 and R3, it is clear that clausal volitionality plays an important role in classifying causal relations. The results for R1 and R2 demonstrate that clausal volitionality is one important factor for causal relation classification, however, the samples cannot be classified with high precision by considering clausal volitionality alone. This remark is supported by the observation that the three-point averaged precision of R3 is higher than that of both R1 and R2.
 R3 represents the current upper bound of causal relation classification.
These are the results in the case where the classifiers were trained with the feature information for the two primitive features, the agent feature and the agent correspondence feature, using a human judge instead of our simple fea-ture extractor in an effort to avoid machine-induced errors in input data. In comparison between R3 and R3 our results (R3) do not reach the current up-per bound R3 . However, the difference between R3 and R3 is small. This means that even if the feature extractor is improved, significant improvements in the causal relation classification will not be achieved.

Next, we discuss the effect of step B, the sample filtering process. Table XVI shows the results when Step B is included. The up arrow in Table XVI indicates that the performance improves as a result of the sample filtering process. The thresholds for the degree of confidence  X  s and  X  m are set by focusing on the ratio of the input samples that have the confidence score lower than the threshold. threshold such that 20% of input samples are classified into the others relation class, bacause we achieved the best accuracy when using this ratio. For the most part the results suggest that the sample filtering process contributes to improving classification. The effect of filtering is especially strong in R1. In this work, Step B was implemented using a very simple algorithm. It can be assumed that classification precision can be further increased by using a more refined measure of the degree of confidence.

Finally, to statistically confirm the difference between methods ( X  X tep B skipped X  vs.  X  X tep B included X ), we applied the Wilcoxon matched-pairs signed-ranks test. The null hypothesis is that the difference between results of two methods has median value zero. As a result, the null hypothesis was rejected at 0.05 significance level ( p -value  X  0.03906). 7.4 Discussion
Let us estimate the amount of knowledge one can acquire from tame -complex sentences in a collection of one year of newspaper articles with a total of ap-proximately 1,500,000 sentences.

Suppose that we want to acquire causal relation instances with a precision of, say, 99% for the cause relations, 95% for the precond relations and the means relations, and 90% for the effect relations. First, it can be seen from Figure 11 that we achieved 79% recall (REC) for the cause relations, 30% for the effect relations, 82% for the precond relations, and 83% for the means relations. Sec-tame -complex sentences are as given in Table XIV. In this case, the frequency ratio of the cause relations class for example was 193 / 1000 it can be seen that we achieved 64% recall:
Finally, since we collected about 42,500 tame -complex sentences from 1 year of newspaper articles (see Table III), we expect to acquire over 27,000 instances of causal relations ( 42, 500  X  0 . 64). This number accounts for 1.8% of all sen-tences (1,500,000 sentences), and is not small in comparison to the number of causal instances included in the Open Mind Common Sense knowledge base [Singh et al. 2002] and Marcu X  X  results [Marcu 2002]. acquired causal knowledge within the framework of case-based reasoning. The reason for this decision is as below. Our causal relation instances, as discussed in Section 3.3, are not abstracted as propositional information. A reasonable concern is that when one applies causal relation instances as inference rules, there will be few input samples matched to the inference rules. However, even if there are no input samples that strictly match any of the inference rules, case-based reasoning can estimate a similarity value between an input sample and a sample in the memory-base, i.e., a causal relation instance, by initiating a dynamic abstraction process in order to discover an appropriate inference rule. For example, suppose the input samples are:
Hanako ga sentakumono wo kawakasu (Hanako dries the laundry) sentakumono ga kawaku (the laundry dries)
In this case, it could be inferred that the effect relation holds between the input samples when a causal relation instance such as (24), whose arguments are similar to the input samples, is included in the memory-base. (24) effect ( Taro ga sentakumono wo kawakasu , sentakumono ga kawaku ) kawakasu  X  and the causal relation instance (24) is in the memory-base, an event  X  sentakumono ga kawaku  X  could be inferred to happen as a result of  X  Hanako ga sentakumono wo kawakasu . X  7.4.3 Feasibility of the Extension to Another Resource. We describe the fea-sibility of the extension of our proposed method to another resources. To do this, we focus on two points: topic and style.

TOPIC. We used only newspaper articles on economics in this study. Indeed, while one-half of sentences in the articles are about economics, the other half of sentences are about noneconomics, such as sentences (17) and (18) in Section 5. We can expect that given document articles with some another topics as knowledge resources, the similar results to ours described in this paper, is obtained.

STYLE. On the other hand, we have to pay attention to extend the resources into texts which have different styles. Since we need to execute the morpho-logical analysis and the dependency structure analysis for preprocessing, the quality of acquired knowledge is dependent on the performance of linguistic analyzers. For newspaper articles, we can use the highly accurate linguistic analyzers ( ChaSen for morphological analysis and CaboCha for dependency structure analysis). However, for another text documents such the web data, we require additional effort in order to handle preprocessing errors. Fortu-nately, recently, the natural language processing techniques for the web data have been studied extensively and levels of performance have substantially increased [Suyama 2005]. 7.5 Problems
There are some problems still to be resolved in order to refine the acquired knowledge. Indeed, there are some constituents in the instances, such as el-lipses and pronouns, which render the instances incomplete. For example, the second arguments of the instance (25) would include the constituents  X  Ta i d e (in
Thailand), X  because the location where the mangrove is destroyed and where flooding occurred should be the same. (25) effect ( Ta i d e manguroubu wo hakaisuru ,
Therefore we need to insert these various missing constituents in order to refine the acquired causal relation instances.
 Furthermore, acquired instances currently contain unnecessary modifiers.
These constituents should be removed in order to refine the acquired knowl-edge. Unfortunately, however, it is hard to determine which constituents are required to construct a causal relation instance and which constituents are op-tional. For example, the constituent  X  tsumetai (cool), X  in (26a) may be required to construct the cause relation instance (26a). On the other hand,  X  akiguchi ni (in early autumn), X  in (26b) may be optional. (26) a. cause ( tsumetai kuuki ga nagarekomu ,
To utilize acquired knowledge in applications such as inference systems, we, therefore, need to be careful to remove unnecessary modifiers only. 8. CONCLUSION
We described our approach to automatic knowledge acquisition of causal rela-tions from a document collection. We considered four types of causal relations based on agents X  volitionality, as proposed in the research field of discourse understanding. The idea behind knowledge acquisition is to use resultative connective markers as linguistic cues.

Our investigation of Japanese complex sentences led to the following find-ings:
The pairs of subordinate and matrix clauses indicating each different event extracted from tame -complex sentences can be classified into the four relation types X  cause , effect , precond and means  X  X ith a precision of 85% or more.
Using SVMs, automatic causal knowledge acquisition can be achieved with high accuracy: 80% recall with over 95% precision for the cause , precond , and means relations, and 30% recall with 90% precision for the effect relation.
The experimental results suggest that over 27,000 instances of causal re-lations could potentially be acquired from 1 year of Japanese newspaper articles.

In this work, we have dealt with only a small subset of all the textually encoded knowledge potentially available in the world. In order to increase the volume and refine the quality of the causal knowledge acquired, the following issues will need to be addressed.

Linguistic forms expressing events: Events are expressed using a variety of linguistic forms: words, phrases, clauses, sentences, and intersentential units. In this work, we focused on clauses in trying to capture events. Other linguistic units should be exploited in order to increase coverage. Other languages: The framework discussed in this paper is not specific to Japanese. We want to investigate applications to other languages such as
English. As described in Section 3.3, the arguments of causal relation in-stances are represented in natural language (in this case, Japanese) rather than in any formal semantic representation language. It will be interesting to investigate the compatibility of causal relation instances acquired from different source languages.

Other resources: There is always a trade-off between quantity and quality of text documents. We used newspaper articles as a source of knowledge in this work. As preprocessing modules (morphological analysis and depen-dency structure analysis) are improved, we anticipate the incorporation of additional types of source texts such as e-mail and web pages in order to increase coverage.

Coreference and unnecessary modifiers: As described in Section 7.5, there are some constituents in causal relation instances, such as ellipses and pronouns, which render the instances incomplete. Techniques for coreference (ellipses and anaphora) resolution will need to be incorporated in our framework in the form of a preprocessing module. Similarly, unnecessary modifiers should be removed to refine acquired knowledge.
 APPENDIX
The following are all linguisitic templates for judging causal relations to sup-plement to those shown in Section 5.2.3.  X  cause cau t1 . [SOA] ( to iu ) koto ga okoru sono kekka to shite cau t2 . [SOA] ( to-iu ) joutai deha cau t3 . [SOA] ( to iu ) joutai ni nareba sore ni tomonai  X  effect eff 1. [Act] ( to iu ) koto wo suru to eff 2. [Act] ( to iu ) koto wo suru to sono kekka eff 3. [Act] ( to iu ) koto wo suru koto ha  X  precond pre 1. [SOA] ( to iu ) joukyou de ha pre 2. [SOA] ( to iu ) joutai de ha pre 3. [SOA] ( to iu ) joutai ni naru baai  X  means mea 1. X ga [Act] ( to iu ) koto wo jitsugensuru sono shudan toshite mea 2. X ga [Act] ( to iu ) koto wo jitsugensuru sono shudan toshite mea 3. X ga [Act] ( to iu ) koto wo jitsugensuru sono shudan toshite mea 4. X ga [Act] ( to iu ) koto wo suru koto niyotte mea 5. X ga [Act] ( to iu ) koto wo suru koto niyotte mea 6. X ga [Act] ( to iu ) koto wo suru koto niyotte mea 7. X ga [Act] ( to iu ) koto no ikkan toshite We would like to express our special thanks to the creators of Nihongo-
Goi-Taikei and several of the dictionaries used in the ALT-J/E translation system at NTT Communication Science Laboratories, and the EDR electronic dictionaries produced by Japan Electronic Dictionary Research Institute. We would also like to thank Nihon Keizai Shimbun, Inc. for allowing us to use their newspaper articles. We are grateful to the reviewers for their suggestive comments, Taku Kudo for providing us with his dependency analyzer and SVM tools, and Eric Nichols and Campbell Hore for proofreading.

