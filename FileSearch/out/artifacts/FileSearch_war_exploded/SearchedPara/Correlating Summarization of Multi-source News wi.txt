 With the emergence of enormous amount of online news, it is desirable to construct text mining methods that can ex-tract, compare and highlight similarities of them. In this paper, we explore the research issue and methodology of correlated summarization for a pair of news articles. The algorithm aligns the (sub)topics of the two news articles and summarizes their correlation by sentence extraction. A pair of news articles are modelled with a weighted bipar-tite graph. A mutual reinforcement principle is applied to identify a dense subgraph of the weighted bipartite graph. Sentences corresponding to the subgraph are correlated well in textual content and convey the dominant shared topic of the pair of news articles. As a further enhancement for lengthy articles, a k -way bi-clustering algorithm can first be used to partition the bipartite graph into several clusters, each containing sentences from the two news reports. These clusters correspond to shared subtopics, and the above mu-tual reinforcement principle can then be applied to extract topic sentences within each subtopic group.
 bipartite graph, biclustering, news summarization, corre-lated summarization The fast growth of the World Wide Web has been accompa-nied by the explosion of online information. Recent studies [14] have showed that there are more than hundreds of mil-lions of web pages and the number is still increasing. How to make the overwhelming amount of information accessi-ble to users is an important task. A lot of research efforts have recently been made on web mining [2], text mining [6], information extraction [3], and information retrieval [8]. Online news represents an important part of online infor-mation. Considering the scenario of browsing news online, hundreds or even thousands of news articles may be found on almost any topic/event. They may report the same event or the development of events over time. There is, with no doubt, a high degree of redundancy in information provided by the set of news articles. Some of them may convey a view of the corresponding reporters. This raises an inevitable problem: how can we provide users an quick overview of the complete story? This problem becomes even more cru-cial with the increase of popularity in accessing the online news with mobile handheld devices such as cell phones and PDAs. Because of the small screen size of a typical hand-held devices, presenting the whole lists of news in the user-friendly manner is a nontrivial task. In addition, the low bandwidth wireless channels used for data transfers make another hurdle in data transport layer during user exam-ines the retrieved sets. How to present useful information to handheld users, while keeping the length down to fit into the small screen of handhold devices, is a challenge task. In these cases, it is desirable to design an automatically-generated comprehensive summarization of the contents in a non-redundant way.
 In this paper, we tackle the problem of automatic summa-rization of multi-resource news from multiple sources in a correlated manner. High degree of content redundancy is resulted from correlated contents across news articles. Dis-covering and utilizing the correlation among them represents an important research issue. However, identifying where the redundancies occur is by no means a trivial task as the rela-tion between sentences in arbitrary documents is difficult to characterize [22]. The correlation between a pair of news ar-ticles takes various forms. They may present the same event, or they may describe the same or related events from dif-ferent points of view. For example, news reports about the same events provided by different web sites, which may in-clude different comments of the reporters on the issue. The proposed algorithm intends to automatically correlate the textual contents of these news reports and highlight their similarities and shared features by extracting sentences that convey shared (sub)topics. This provides readers first step towards advanced summarization as well as helps them un-derstand the multi-source news and reduce the redundancy in information. It also meets the application demand of find-ing related news articles based on users X  query [5; 11] with even finer granularity.
 The essential idea of our approach is to apply a mutual re-inforcement principle on a pair of news articles to simulta-neously extract two sets of sentences. Each set is from one article, and the two sets of sentences together convey non-trivial shared topics. These extracted sentences are ranked based on their importance in embodying the shared domi-nant topics, and produce a shallow correlating summariza-tion of the pair of news articles. By selecting different num-bers of sentences based on their ranking, we can vary the size of summarization text. In the case that the pair of ar-ticles are long and with several shared subtopics, a k -way bi-clustering algorithm is first employed to co-cluster sen-tences into k clusters each containing sentences from the pair of articles. Each of these sentence clusters corresponds to a shared subtopic, and within each cluster, the mutual reinforcement algorithm can then be used to extract topic sentences.
 The rest of the paper is organized as follows. Section 2 re-views some related work. Section 3 introduces the bipartite graph model for a pair of news articles. In Section 4, we present the mutual reinforcement principle to extract sen-tences that embody the dominant shared topics from the pair of news articles simultaneously. The criteria for ver-ifying the existence of the dominant shared topics is pre-sented as well. Section 5 discusses k -way bi-clustering algo-rithm that co-clusters sentences in a pair of articles based on shared subtopics. This algorithm is applied to a pair of long articles with more than one shared subtopics. In Section 6, we present detailed experimental results on a set of news articles, and demonstrate that our bi-clustering algorithm and mutual reinforcement algorithm are effective in corre-lating summarization. We conclude the paper in Section 7 and discuss possible future work. With the huge amount of information available online, the Web mining research becomes a converging area from sev-eral research communities, such as database, information retrieval (IR), machine learning, and natural language pro-cessing (NLP). Basically, Web mining can be classified into three types: Web content mining, Web structure mining, and Web usage mining [13]. But because the Web is huge, diverse, dynamic, unstructured, and redundant, the tradi-tional IR and NLP approaches may not be sufficiently to perform the tasks.
 Automated text summarization is an important field of study that covers both content and usability of the Web. Given any text document, automatic text summarization attempts to identify and abstract important information in text and present it to users in a condensed form and in a manner sensitive to the users X  or applications X  needs [17]. Applications range from snippet generation by search engine to tailoring of the content to suit specific displays such as PDA. A comprehensive survey on text summarization has been provided by Marcu in [18]. There are generally two types of tasks in text summarization: single-document sum-marization [20] and multiple-document summarization [15], according to the number of documents for summarization. In many instances, summarizing a collection of documents is a more difficult task than summarizing an individual doc-ument because the former needs to address additional chal-lenges such as the inconsistence in contents [18], difference in subtopics, and the form of the abstraction.
 Many efforts have been performed on clustering and sum-marizing multiple documents [7; 22; 24]. These approaches exploit meaningful relations among documents based on the analysis of text cohesion and the context in which the com-parison is desired. Providing summarization for web pages is a nature application of multi-document summarization techniques. Systems [19; 23] were developed to perform web pages clustering and generic summarization based on rele-vant results from a search engine. Centroid words are used to find the most salient themes in a cluster of documents. Techniques particularly targeted on news articles have also been proposed in [4].
 Multi-document summarization techniques partially address the challenges in summarizing multi-source news. The sum-mary generated by these approaches, however, is usually consist of the most salient information gleaned from all the documents. They may leave out some important informa-tion which is enclosed in some but not all the documents. Techniques to generate non-redundant summarization [1; 9] alleviate the problem, but they fail to differentiate the shared (sub)topics from the un-shared ones. To provide a comprehensive summarization of the shared and un-shared (sub)topics, we proposed to generate a correlated summa-rization of the documents. Our method is different from the above approaches by presenting similarities and differ-ences in content of news articles, rather than a generic salient theme for the collection of news. The correlated summariza-tion provides more explicit contextual information to users than most existing text summarization approaches and di-rectly help users navigate through text and quickly obtain desired information. There have been very limited research in correlated summarization. Mani et al. [16] address the problem of summarizing the similarities and differences of documents by analyzing the relations of meaningful text units. An algorithm developed for summarizing customer reviews [12] takes a correlated approach. The comments are extracted from a set of reviews on a same product and classified as positive or negative opinions. The final summa-rization is generated from these comments. For our purpose of correlated summarization, each news ar-ticle is viewed a consecutive sequence of sentences. First, as the preprocessing, text is tokenized, generic stop words are eliminated, and words are stemmed [21]. The text in each news article is split into sentences and each sentence is represented with a vector. Each entry in a vector is the occurrence of the corresponding word in the correspond-ing sentence. An article can further be represented with a sentence-word count matrix, whose rows corresponding to sentences in the text, and whose columns corresponding to words in the text after stop word deletion and stemming. The correlation between two news articles may be repre-sented with a bipartite graph (see Figure 1), which includes two components: two types of nodes and edges connect-ing nodes of different types. The weights on the edges are nonnegative. In the context of summarizing a pair of news articles, the sentences are modelled as the nodes in the bi-partite graph. Nodes corresponding to an article are of the same type, and they are of different types if they are from different articles. The edges connect two nodes correspond-ing to sentences from different articles. The similarity be-tween the two sentences is expressed as the edge weights of the bipartite graph. Suppose there are m sentences in ar-ticle A and n sentences in article B . We denote the two Figure 1: A bipartite graph representation of a correlated documents. The width of the edges correspond to the edge weights. types of nodes A = { a 1 , a 2 , ..., a m } and B = { b 1 representation of sentences. The edge weights W = [ w ij ( i = 1 , 2 , ..., m , j = 1 , 2 , ..., n ) between node a computed as the pairwise similarities between the sentence a in A and the sentence b j in B . The weighted bipartite graph of the news articles is then denoted as G ( A, B, W ), where W is a m -by-n matrix. Suppose the two news articles in question is presented in a bipartite graph G ( A, B, W ). The dominant shared topic of the article A and the article B is embodied by two subsets of sentences, X and Y , while X  X  A and Y  X  B . Suppose news articles A and B are related in topic. Sentences in X then tend to correlate well with sentences in Y , and they together embody the dominant shared topic of the pair of news articles. In the bipartite graph model, the nodes cor-responding to X and Y form a dense subgraph. We use the mutual reinforcement principle to extract this dense sub-graph from the bipartite graph.
 We associate each sentence a i in A a saliency score u ( a indicate its importance in the delivery of the topic. High saliency score implies the sentences is the key to the topic. Similarly, the saliency score is assigned to each sentence b in B , denoted as v ( b i ). Those sentences that embody the dominant shared topic of the two articles should have high saliency scores. It is easy to see that the following observa-tion are valid.
 In another words, Mathematically, the above statement is rendered as where a i  X  b j represents that there is an edge between ver-tices a i and b j , the symbol  X  stands for  X  X roportional to X . Now we collect the saliency scores for sentences into two vectors u and v , respectively, the above equation can then be written in the following matrix format where W is the weight matrix of the bipartite graph of the article in question, W T stands for the matrix transpose of W , and 1 / X  is a proportionality constant. u and v are the left and right singular vectors of W corresponding to the singular value  X  . If we choose  X  to be the largest singular value of W , then both u and v have nonnegative compo-nents. The corresponding component values of u and v are then the sentences saliency scores of articles A and B , re-spectively. Sentences with high saliency scores are selected from the sentence set A and B . These sentences and cross edges among them construct a dense subgraph of the orig-inal weighted bipartite graph, which are well correlated in textual content.
 A direct question raised is to determine the number of sen-tences included in the dense subgraph. We first reorder the sentences in A and B according to their correspond-ing saliency scores to obtain a permuted weight matrix  X  W . For  X  W = [  X  W s,t ] 2 s,t =1 , we compute the quantity of matrix at the upper left of  X  W ,  X  W 22 is the ( m  X  i )-by-( n  X  j ) submatrix at lower right, and h (  X  ) is the sum of all the ele-ments of a matrix and n (  X  ) is the square root of the product of the row and column dimensions of a matrix. We then choose first i  X  sentences in A and first j  X  sentences in B such that The i  X  sentences from A and the j  X  sentences from B are considered as sentences in articles A and B that most closely correlate with each other. A post-evaluation step is per-formed to verify the existence of shared topics in the pair of articles in question. Only when the average cross-similarity density of the sub-matrix  X  W 11 is greater than a certain threshold, we say that there is shared topic between the pair of articles and the extracted i  X  sentences and j  X  sentences efficiently embody the dominant shared topic. If article A and B present unrelated event or object, then the average cross-similarity density of extracted sub-graph is below the threshold. This sentence selection criteria avoids local max-imum solution and extremely unbalanced bipartition of the graph.
 The implementation of the mutual reinforcement principle contains left and right singular vectors computing. The sin-gular vectors can be obtained by Lanczos bidiagonalization process [25], which is an iterative process each involving the two matrix-vector multiplications. The computation cost is proportional to the number of nonzero elements of the object matrix W , nnz ( W ). The major computational cost in the implementation of the mutual reinforcement principle comes from computing the largest pair of singular vectors and max-imizing J ij . The cost of selecting the maximum value of J is proportional to the number of entries in the matrix, which is greater than or equal to the nnz ( W ). Therefore, the total cost of mutual reinforcement principle for topic sentences selection is proportional to the number of entries in the ma-trix. The above approach usually extracts a dominant topic that is shared by the pair of news articles. However, the two arti-cles may be very long and contain several shared subtopics besides the dominant shared topic. Each shared subtopic may be presented at various positions in a long article as well. To extract these less dominant shared topics, a k -way bi-clustering algorithm is applied to the weighted bipar-tite graph introduced above before the mutual reinforcement principle is used for shared topic extraction. The k -way bi-clustering algorithm will divide the bipartite graph into k subgraphs. Each subgraph contains sentences from both of the two articles and corresponds to one of shared subtopics if available. Within each subgraph, we then apply the mutual reinforcement principle to extract topic sentences. Given the bipartite graph G ( A, B, W ) representing the cor-related news articles A and B , the k -way bi-clustering algo-rithm partition the graph into and where A i and B i form a dense sub-graph. We define vectors Ia i of length m and Ib i of length n as the component indi-cators of A i in A and B i in B , respectively. The elements of Ia i and Ib i are 1 for those corresponding to the sentences in A i and B i , respectively. And the rest elements of Ia Ib i are 0. That is, and A pair of sentences a and b is considered matched with re-spect to the partition P ( A, B ) if a  X  A i and b  X  B i for some 1  X  i  X  k . Hence, sentences in the same bicluster are about the same sub-topic. Intuitively, the desired partition should have the following property: the similarities between sen-tences in A i and sentences in B i are as high as possible, and the similarities between sentences in A i and sentences in B ( i 6 = j ) are as less as possible. This would give rise to par-titions with closely similar sentences concentrated between all A i and B i pairs. In our context of extracting shared subtopics, this strategy leads to the desired tendency of dis-covering subtopic bi-clusters A 1  X  B 1 , A 2  X  B 2 , ..., A Now we introduce the Normalized Cut algorithm we used for the graph bi-partition[10].
 The k -way Normalized Cut to find a partition P ( A, B ) aims at minimizing the objective function N cut ( G ( A, B, W )) = w ( V 1 , V where V i = A i  X  B i ( i = 1 , 2 , ..., k ), V = A  X  B , and w ( V is the summation of weights between vertices in subgraph V and vertices in subgraph V j . Let Z is column orthogonal. The bipartite Normalized Cut problem can then be simplified to The relax problem of the minimizing problem can be solved by setting columns of Z to be any orthonormal basis for the subspace spanned by the columns of the matrix where U = ( u 1 , u 2 , . . . , u k ) and V = ( v 1 , v 2 left and right singular vectors corresponding to the k largest singular value of  X  W , respectively.
 Given the weight matrix of the edges, the Ncut algorithm partitions the graph according to the following steps: 1. Compute D A and D B with W e = D A e and W T e = 2. Compute the left and right singular vectors, U and V , 3. Calculate U = D  X  1 / 2 A  X  U and V = D  X  1 / 2 B  X  V respectively, 4. Partition the rows of U and V into k submatrices by We downloaded 20 pairs of news articles from Google News 1 Each pair of the news articles are about the same topic ac-cording to Google News. These news are generally fall into the categories of IT news, business new and world news. We label them it as IT news, buz as business news, and wld as world news. The overflow of our experiments is summarized as follows: http://news.google.com 1. Text pre-processing: we take a pair of concatenated 2. Calculate sentence-sentence similarities across the pair 3. Use k -way biclustering to partition sentences in 4. For each subtopic group, use mutual reinforcement To our best knowledge, there is no standard measures defined for evaluating correlated summarization methods. Some researchers use human-generated summarization or extraction to evaluate their algorithms. But most manual sentence extraction and correlation results tend to differ sig-nificantly, especially for long articles with several subtopics. Hence, the performance evaluation for correlating summa-rization of a pair of news articles becomes a very challenging task. We try to provide some quantitative and qualitative evaluation on our algorithms based on our experimental re-sults with the news articles, each generated through com-bining two news articles of different subjects. We report the experimental results in two sections. The first section demonstrates the mutual reinforcement principle for extract-ing the dominant shared topic of a pair of news articles, and the second section demonstrates the bi-clustering algorithm for sentences co-clustering based on subtopics sharing. We extract the shared topic of each pair of news articles with mutual reinforcement principle. Sentences that em-body the dominant shared topic were also manually chosen for evaluation purposed. We then use two standard mea-sure metrics of Information retrieval, precision and recall to evaluate our method. The automatically extracted sen-tences for each news article is seen as the retrieved sentences, and the manually extracted sentences for each news article is seen as the relevant sentences. The precision measure is defined as the fraction of the retrieved sentences that are relevant, and the recall measure is the fraction of the rele-vant sentences that are retrieved. Higher values of precision and recall usually indicate more accurate algorithms for key sentence extraction. Table 1 lists our experimental results for key sentence extraction. For the purpose of comparison, we also tried to find the dominant shared topic between two un-correlated news articles. The average cross-similarities between extracted sentences are computed to determine an empirical cutoff for correlated topics. The threshold was de-termined to be 0.7. The score for the pairs of news articles where there is no shared topic, are listed in the last three row of Table 1.
 As demonstration for mutual reinforcement principle to ex-tract dominant shared topic of a pair of news articles, we present the experimental results of two pairs of news articles: it 1 and it 2, and wld 1 and wld 2. The mutual reinforcement principle is applied to each pair of news articles, and sen-tences with high saliency scores are extracted from each pair of news articles. Two sentences with top two saliency scores are marked in bold font in Table 2 for each pair of articles. In the first example, both news articles are about Apple introducing iPod U2 special edition. The mutual reinforce-ment principle has successfully extracted the key sentences from each articles. The average cross-similarity among the extracted sentences is 2.845, which is greater than our em-pirical threshold 0.7. This indicates mathematically that there is a shared topic between the pair of articles and the extracted sentences are efficient in embodying the shared topic. Similar case happens in the second example. We now present the results of our experiments on bi-clustering algorithm for sentences co-clustering to reveal shared subtopics. Due to the lack of labelled data, we gen-erated our own news collection where each article is a con-catenation of two news articles. We use the concatenated news articles to simulate news articles of multiple shared subtopics. We then apply the k -way bi-cluster algorithm to the long news articles to group sentences with shared topics. Sentences from the same pair of news articles should be put into a bicluster.
 1 Apple Computer has unveiled two new ver-sions of its hugely successful iPod: the iPod
Photo and the U2 iPod . 2 Apple also has expanded its iTunes Music Store to nine more European markets, evidence that the com-pany intends to maintain its global hegemony in the portable-music-player and digital-download markets. 3 The announcements came Oct. 26 at a media event that featured a keynote by Apple CEO Steve Jobs and a live performance by U2 X  X  Bono and the Edge, who played songs from the band X  X  forthcoming Island album,  X  X ow to Dismantle an Atomic Bomb. X  4 The high-end 60GB iPod Photo ($599) offers some innovations. 5 In addition to its music capacity, it has another 20GB of memory  X  making it the largest-capacity iPod  X  and a high-resolution color screen to display album art and other digital images. 6 It also comes in a 40GB version ($499). 7 The limited-edition, 20GB black U2 iPod ($149), features custom engraving of the band members X  sig-natures, plus coupon discounts on a  X  X igital boxed set X  of the band X  X  catalog and rare tracks available exclusively through iTunes. 8 Apple X  X  European Union iTunes Music Store rolled out in Austria, Belgium, Finland, Greece, Italy, Lux-embourg, the Netherlands, Portugal and Spain. 9 It features more than 700,000 songs from all four major labels and more than 100 independents. 10 The latest territories join iTunes stores in the United Kingdom, France, Germany and the United
States. 11 The computer giant will launch iTunes in Canada next month. 12 Apple claims that iPods represent 65% of portable-music-player sales and that iTunes represents 72% of all digital downloads. 1 OSAMA bin Laden appears to have boosted
George Bush X  X  US election campaign. 2 Dubya last night held a six-point lead over chal-lenger John Kerry in the first polls since the al-Qaeda chief X  X  video threat. 3 Fifty per cent of likely voters said they backed the Republican president as the Democrat X  X  support slipped to 44 per cent. 4 They were tied in the same poll a week ago and
Kerry held a one per cent lead in a survey on Friday. 5 If bin Laden planned to humiliate Bush before to-morrow X  X  election, it backfired. 6 Whenever the subject of the campaign has turned to terrorism, it has benefitted Bush, X  said Newsweek. 7 In every poll, voters have said they trust Bush more than Kerry to handle terrorism and homeland secu-rity. 8 Bin Laden X  X  tape was so well-timed for Bush some suggested the Republicans were behind it. 9 Former TV news anchorman Walter Cronkite joked he was inclined to think the political manager at the
White House probably set up bin Laden to this thing. 10 Bush ally Senator John McCain said:  X  X t X  X  very helpful to the president. 11 I X  X  not sure if it was intentional or not, but I think it does have an effect. 12 Bush did not mention the tape specifically during campaign appearances over the weekend.
 An example of biclustering the concatenated news articles news 1 ( wld 11 and wld 21) and news 2 ( wld 12 and wld 22) is presented in Table 3. The sentences in the wrong bicluster are in italic, and the key sentences extracted with mutual reinforcement principle are labelled in bold font. Quantitative results of some experiments are listed in Ta-ble 4. Each row of the table corresponds to one experi-ment. Some news articles are produced by concatenating news articles from the same fields, others are produced by concatenating news articles from different fields. The num-ber of subtopics within a long news article are related to the number of news articles being concatenated together. Higher accuracy represents that higher percentage of sen-tences in a article are correctly clustered. The results in Table 4 demonstrate that the bi-clustering algorithm is ef-fective in co-clustering sentences based on shared subtopics. When varying the number of shared subtopics of a pair of news articles, the performance of the algorithm is stable. However, when the ratio of the number of shared subtopics to the number of subtopics in a article decreases, the accu-racy tends to deteriorate. In experiments listed in the last two rows of Table 3, there are three subtopics in each long news article. Only two of them are shared between the pair of news articles. The accuracies in the experiments are lower than those in other groups of experiments. The text in a web page usually addresses a coherent topic. However, a web page with long text could address several subtopics and each subtopic is usually made of consecutive sentences. Thus, it is necessary to segment sentences into topical groups before studying the topical correlation of mul-tiple web pages. There has been many text segmentation algorithms available.
 In this paper, we propose a new procedure and algorithm to automatically summarize correlated information from online news articles. Our algorithm contains the mutual reinforce-ment principle and the bi-clustering method. The mutual reinforcement principle extracts sentences, which convey the dominant shared topic, from a pair of news articles simulta-neously. The bi-clustering algorithm, which co-clusters the sentences in a pair of articles, is employed to find the shared subtopics of them. We test our algorithm with news articles in different fields. The experimental results suggest that our algorithms are effective in extracting dominant shared topic and/or subtopics of a pair of news articles.
 This study has two major contributions: (1) we bring up the research issue of correlated summarization for news articles, and (2) we present a new algorithm to align the (sub)topics of a pair of news articles and summarize their correlation in content. The proposed method can automatically extract, correlate, and summarize information to prevent users from information overload. It also allows user to use small-screen mobile handheld devices to read news.
 The proposed algorithms could be improved to handle more than two news articles simultaneously. Another research direction boosted by NIST, known as Topic Detection and Tracking 2 , is to discover and thread together topically re-lated material in streams of data [26]. Our algorithm may also be applied to generating a completed story line from a set of news articles about the same event over time. The method is applicable to correlated summarize multilingual articles, considering the growing volume of multilingual doc-uments online. The authors want to thank the editors and the anonymous referees for many constructive comments and suggestions. [1] J. G. Carbonell and J. Goldstein. The use of mmr, [2] R. Cooley, J. Srivastava, and B. Mobasher. Web mining: [3] J. Cowie and W. Lehnert. Information extraction. Com-[4] S. B.-G. D. Radev, Z. Zhang, and R. S. Raghavan. In-http://www.nist.gov/speech/tests/tdt/ [5] J. Dean and M. Henzinger. Finding related pages in the [6] M. Dixon. An overview of document mining technology. [7] L. Ertoz, M. Steinbach, and V. Kumar. Finding topics [8] P. Gawrysiak. Using data mining methodology for text [9] J. Goldstein, V. Mittal, J. Carbonell, and K. M. Multi-[10] M. Gu, H. Zha, C. Ding, X. He, and H. Simon. Spec-[11] T. H. Haveliwala, A. Gionis, D. Klein, and P. In-[12] M. Hu and B. Liu. Mining and summarizing customer [13] R. Kosala and H. Blockeel. Web mining research: A [14] S. Lawrence and C. Giles. Accessibility of information [15] I. Mani and E. Bloedorn. Multi-document summariza-[16] I. Mani and E. Bloedorn. Summarizing similarities and [17] I. Mani and M. Maybury. Advances in automatic text [18] D. Marcu. Automatic abstracting. Encyclopedia of Li-[19] J. L. Neto, A. D. Santos, C. A. A. Kaestner, and A. A. [20] C. D. Paice. Constructing literature abstracts by com-[21] M. Porter. An algorithm for suffix stripping. Program , [22] D. Radev. A common theory of information fusion from [23] D. R. Radev and W. Fan. Automatic summarization [24] D. R. Radev and K. R. McKeown. Generating natu-[25] H. D. Simon and H. Zha. Low rank matrix approxima-[26] C. Wayne. Multilingual topic detection and tracking:
