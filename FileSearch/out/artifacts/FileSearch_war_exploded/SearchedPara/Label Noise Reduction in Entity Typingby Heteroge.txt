 Current systems of fine-grained entity typing use distant su-pervision in conjunction with existing knowledge bases to assign categories (type labels) to entity mentions. However, the type labels so obtained from knowledge bases are often noisy ( i.e. , incorrect for the entity mention X  X  local context). We define a new task, Label Noise Reduction in Entity Typ-ing (LNR), to be the automatic identification of correct type labels (type-paths) for training examples , given the set of candidate type labels obtained by distant supervision with a given type hierarchy. The unknown type labels for indi-vidual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task. We propose a general framework, called PLE , to jointly em-bed entity mentions, text features and entity types into the same low-dimensional space where, in that space, objects whose types are semantically close have similar representa-tions . Then we estimate the type-path for each training ex-ample in a top-down manner using the learned embeddings. We formulate a global objective for learning the embeddings from text corpora and knowledge bases, which adopts a novel margin-based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases. Our experiments on three public typing datasets demonstrate the effectiveness and robustness of PLE, with an average of 25% improvement in accuracy compared to next best method.
Entity typing is an important task in text analysis. As-signing types ( e.g. , person , location , organization ) to men-tions of entities in documents enables effective structured analysis of unstructured text corpora. The extracted type information can be used in a wide range of ways ( e.g. , serving as primitives for information extraction [23] and knowledge base (KB) completion [4], and assisting question answer-ing [6]). Traditional entity typing systems [22, 18] focus on a small set of coarse types (typically fewer than 10). Recent studies [34, 14, 35] work on a much larger set of fine-grained Equal contribution.
 types which form a tree-structured hierarchy ( e.g. , actor a subtype of artist , and artist is a subtype of person , as in blue region of Fig. 1). While types are usually defined to be mutually exclusive within a coarse type set ( e.g. , by assum-ing a mention cannot be both person and location ) , fine-grained typing allows one mention to have multiple types, which together constitute one type-path (not necessarily end-ing in a leaf node) in the given type hierarchy, depending on the local context ( e.g. , sentence). Consider the example in Fig. 1,  X  Trump  X  could be labeled as { person , artist , actor } in S3 (TV show). But he could also be labeled as { person , politician } in S1 or { person , businessman } in S2.
A major challenge in fine-grained typing is the absence of human-annotated data. The process of manually label-ing a training set with large numbers of fine-grained types (usually over 100) is too expensive and error-prone (hard for annotators to distinguish over 100 types consistently). Cur-rent systems annotate training corpora automatically using knowledge bases ( i.e. , distant supervision ) [22, 34, 14, 35]. A typical workflow of distant supervision is as follows (see Fig. 1): (1) identify entity mentions in the documents; (2) link mentions to entities in KB; and (3) assign, to the candi-date type set of each mention, all KB types of its KB-linked entity. However, this approach introduces label noise to the mentions since it fails to take the semantics of the mentions X  local contexts into account when assigning type labels. For example, in Fig. 1, the types assigned to entity Trump in-clude person , artist , actor , politician , businessman , while only { person , politician } are correct types for Trump in S1.
Many previous studies ignore the label noise in automati-cally labeled training corpora X  all candidate types obtained by distant supervision are treated as  X  X rue X  types in train-ing multi-label (hierarchical) classifiers [34, 14, 35]. This has become an impediment to improving the performance of cur-rent fine-grained typing systems as a majority of mentions in training sets have noisy types (see Table. 1, row (1)). A few systems try to denoise automatically labeled training cor-pora by simple pruning heuristics such as deleting mentions with conflicting types [7]. However, such strategies signifi-cantly reduce the size of training set (Table 1, rows (2a-c)) and lead to performance degradation (later shown in our ex-periments). The larger the target type set, the more severe the loss. So far there is no effective way to automatically create high-quality training data for fine-grained typing.
This motivated us to define a new task: Label Noise Re-duction in Entity Typing (LNR), that is, identifying the cor-rect type labels for each training example from its noisy candidate type set (generated by distant supervision with a given type hierarchy). While the typical entity typing sys-tems assume that type labels in training data are all valid and focus on designing models to predict types for unlabeled mentions , LNR focuses on identifying the correct types for automatically labeled mentions , which is related to partial label learning [20, 2]. LNR is a fundamental task in build-ing entity typing systems with distant supervision because it reduces the level of type label noise in the training data that, in turn, yields a better entity type classifier.
The presence of incorrect type labels in a mention X  X  can-didate type set poses a unique challenge to estimating the re-latedness between entity mentions and types using fully/semi-supervised learning methods [34, 3, 33] X  X o-occurrence pat-terns alone between mentions and their candidate types in the corpus may be unreliable , as shown in our example above.
We approach the LNR task as follows: (1) Model the true type labels in a candidate type set as latent variables and require only the  X  best  X  type (measured under the proposed metric) to be relevant to the mention X  X his requirement is less limiting compared with other multi-label learning meth-ods that assume every candidate type is relevant to the mention. (2) Extract a variety of text features from en-tity mentions and their local contexts, and leverage corpus-level co-occurrences between mentions and features to model mentions X  types. (3) Model type correlation (semantic simi-larity) jointly with mention-candidate type associations and mention-feature co-occurrences, to assist type-path infer-ence, by exploiting two signals: (i) the given type hierarchy, and (ii) the shared entities between two types in KB.
To integrate these elements of our approach, a principled framework, Heterogeneous Partial-Label Embedding ( PLE ), is proposed. First, PLE constructs a heterogeneous graph to represent three kinds of objects: entity mentions, text fea-tures and entity types, and their relationships in a unified form (see Fig. 2). Associations between mentions and their true types are kept as latent structures in the graph to be es-timated (Sec. 3.1). We formulate a global objective to jointly embed the graph into a low-dimensional space where, in that space, objects whose types are semantically close also have similar representations (see Sec. 3.2). Specifically, we design a novel margin-based rank loss to model mention-type as-sociations , which enforces only the best candidate type to be embedded close to the mention (thus is robust to the false candidate types). We further integrate the margin-based rank loss with the skip-gram model [17] to jointly cap-ture the corpus-level mention-feature co-occurrences and the KB-based type correlation in the embedding process. With the learned embeddings, we can efficiently estimate the cor-rect type-path for each entity mention in the training set in a top-down manner. An efficient alternative minimization algorithm is developed to solve the optimization problem based on block-wise coordinate descent [30] (see Sec. 3.3). The major contributions of this paper are as follows: 1. This is the first systematic study of noisy type labels in distant supervision. It defines a new task, Label Noise
Reduction in Entity Typing , to identify the correct type-path for each mention from its noisy candidate type set. 2. An embedding-based framework, PLE, is proposed. It models and measures semantic similarity between entity mentions and type labels, and is robust to label noise. 3. A joint optimization problem is formulated that inte-grates mention-type association, corpus-level mention-fea-ture co-occurrence, and KB-based type correlation. 4. Experiments with three public fine-grained typing datasets demonstrate that PLE reduces their label noise substan-tially and, when PLE-denoised corpora are used as train-ing sets, they also improve the performance of state-of-the-art fine-grained typing systems significantly. The input to LNR is a knowledge base  X  with type schema , a target type hierarchy Y which covers a subset of types in  X  , i.e. , Y  X  Y  X  , and an automatically labeled training corpus D (obtained by distant supervision with Y ). Knowledge Base and Target Type Hierarchy. A KB with a set of entities E  X  contains human-curated facts on both entity-entity facts of various relationship types and entity-type facts. We denote entity-type facts in a KB  X  (with type schema Y  X  ) as T  X  = ( e,y )  X  X   X   X Y  X  . A target type hierar-chy is a tree where nodes represent types of interests from Y (or types which can be uniquely mapped to those in Y  X  ). In existing entity typing studies, several fine-grained type hier-archies are manually/semi-automatically constructed using WordNet [35] or Freebase [7, 14].
 Automatically Labeled Training Corpora. Formally, a la-beled corpus for entity typing consists of a set of extracted entity mentions M = { m i } N i =1 ( i.e. , token spans representing entities in text), the context ( e.g. , sentence, paragraph) of each mention { c i } N i =1 , and the candidate type sets {Y automatically generated for each mention. We represent the training corpus using a set of mention-based triples D = ( m i ,c i , Y i ) N i =1 . There exist publicly available automatically-labeled corpora such as the Wikilinks dataset [26] where en-tity mentions have already been extracted and mapped to KB entities using anchor links in the corpus. In specific domains ( e.g. , customer reviews, tweets) where such pub-lic datasets are unavailable, one can utilize distant supervi-sion [22, 3, 14] to automatically label the corpus, where an entity linking system [25] will detect mentions m i (in set M ) and map them to one or more entity e i in E  X  . Types of e in KB  X  are then associated with m i to form its candidate type set Y i , i.e. , Y i = y | ( e i ,y )  X  X   X  , y  X  X  . Problem Description. Since Y i is annotated for entity e i includes all possible types of e i and thus may contain types that are irrelevant to m i  X  X  specific context c i . Ideally, the type labels for m i  X  X  should form a type-path (not required to end at a leaf) in Y i [34, 7, 35], which serves as a context-dependent type annotation for m i . However, as discussed in [7] and shown in Fig. 1, Y i may contain type-paths that are irrelevant to m i in c i . Even though in some cases Y already a type-path, it may be overly specific for c i and so insufficient to infer the whole type-path using c i . We denote the true type-path for mention m i as Y  X  i . This work focuses on estimating Y  X  i from Y i based on mention m i as well as its context c i , where the candidate type set Y i may contain (1) types that are irrelevant to c i , and (2) types that are overly specific to c i . Formally, we define the LNR task as follows.
Definition 1 (Problem Definition). Given a KB  X  with type schema Y  X  and entity-type facts T  X  = ( e,y ) , a target type hierarchy Y  X  Y  X  , and an automatically labeled training corpus D = ( m i ,c i , Y i ) N i =1 , the LNR task aims to estimate a single type-path Y  X  i  X  X  i for each entity mention i  X  X  , based on m i itself as well as its context c i . Non-goals. Label noise may also come from incorrect men-tion boundaries and wrong mapping of mentions to KB enti-ties. This work relies on existing entity linking tools [25] to provide decent entity mention detection and resolution re-sults ( e.g. , leftmost column of Fig. 2), but we do not address their limits here. We also assume human-curated target type hierarchies are given for the task (It is out of the scope of this study to generate the type hierarchy Y ).
This section lays out the framework. As the candidate type sets in the training corpus contain  X  X alse X  types, su-pervised learning techniques ( e.g. , multi-label learning [14], hierarchical classification [35]) may generate predictions bi-ased to the incorrect type labels [7]. Our solution casts the problem as a weakly-supervised learning task, which aims to derive the relatedness between mentions and their candidate types using both corpus-level statistics and KB facts.
Specifically, each entity type is treated as an individual object to be modeled. As type assignment on each mention is noisy , we adopt ideas from partial label learning [2] to carefully model mention-type associations, and extract a set of text features for each mention to assist in modeling its true types. In order to capture the semantic similarity between types, we further derive type correlation from two different sources, i.e. , KB and the given type hierarchy.
 Framework Overview. We propose a graph-based partial-label embedding framework (see also Fig. 2) as follows: 1. Generate text features for each entity mention m i  X  M , 2. Perform joint embedding of the constructed graph G into 3. For each mention m i (in set M ), search its candidate
To capture the shallow syntax and distributional seman-tics of a mention m i  X  M , we extract various features from both m i itself ( e.g. , head token) and its context c i ( e.g. , bi-gram). Table 2 lists the set of text features used in this work, which is similar to those used in [34, 14]. We denote the set of M unique features of M extracted from D as F = { f j } M Details of feature generation are introduced in Sec. 4.1. With entity mentions M , text features F and target types Y , we build a heterogeneous graph G to unify three kinds of links: mention-type link represents each mention X  X  candi-date type assignment; mention-feature link captures corpus-level co-occurrences between mentions and text features; and type-type link encodes the type correlation derived from KB or target type hierarchy. This leads to three subgraphs MY , G MF , and G Y Y , respectively.
 Mention-Type Association Subgraph. In the automatically labeled training corpus D = ( m i ,c i , Y i ) , each mention m is assigned a set of candidate types Y i from the target type set Y . This naturally forms a bipartite graph between entity mentions M and target types Y , where each mention m i  X  X  is linked to its candidate types Y i with binary weight, i.e. ,
Existing embedding methods rely on either the local con-sistency assumption [9] ( i.e. , objects strongly connected tend to be similar), or the distributional assumption [17] ( i.e. , ob-jects sharing similar neighbors tend to be similar) to model graph structures. However, some links are  X  X alse X  links in the constructed mention-type subgraph X  X dopting the above as-sumptions may incorrectly yield mentions of different types having similar embeddings. For example, in Fig. 2,  X  Hillary Clinton  X  in S1 and  X  Trump  X  in S3 have several candidate types in common (thus high distributional similarity), but their true types are different ( i.e. , politician versus busi-nessman ). Instead of defining a binary variable to indicate whether a mention-type link is true or not, we specify the likelihood of a mention-type link being true as the relevance between the corresponding mention and type, and progres-sively estimate the relevance by incorporating other side sig-nals ( e.g. , text features, type correlation). We propose to model mention-type links based on the following hypothesis.
Hypothesis 1 (Partial Label Association). A men-tion should be embedded closer to its most relevant candidate type than to any other non-candidate type, yielding higher similarity between the corresponding embedding vectors.
During model learning, relevance between an entity men-tion and its candidate type is measured by the similarity between their current estimated embeddings. Text features, as complements to mention-candidate type links, also partic-ipate in modeling the mention embeddings, and help identify a mention X  X  most relevant type. In sentence S1 of Fig. 2, context words democratic and presidential infer that type politician is more relevant than type actor for mention  X  Hillary Clinton  X . This hypothesis assumes that the embed-dings of two mentions will be close if and only if their most relevant candidate types are similar.
 Mention-Feature Co-occurrence Subgraph. Intuitively, en-tity mentions sharing many text features ( i.e. , with similar distributions over F ) tend to have close type semantics; and text features which co-occur with many entity mentions in the corpus ( i.e. , with similar distributions over M ) likely rep-resent similar entity types. The following hypothesis guides our modeling of mention-text feature co-occurrences. Hypothesis 2 (Mention-Feature Co-occurrences).
 If two entity mentions share similar features, they should be close to each other in the embedding space ( i.e. , high simi-larity score). If two features co-occur with a similar set of mentions, their embedding vectors tend to be similar. In Fig. 2, for example, mentions  X  Donald Trump  X  in S2 and  X  Trump  X  in S4 share multiple features ( e.g. , Trump , presi-dential and campaign ), and thus are likely of the same type politician . Conversely, features campaign and presiden-tial likely represent the same type politician since they co-occur with similar sets of mentions in the corpus.
Formally, we form binary links between mentions and their text features to construct a mention-feature co-occurrence subgraph, i.e. , w ij = 1 if feature f j  X  F is extracted for mention m i  X  M ; and w ij = 0 otherwise. We use G MF = Type Correlation Subgraphs. In target type hierarchy Y , types closer to each other ( i.e. , shorter path) tend to be more related ( e.g. , actor is more related to artist than to person in the left column of Fig. 3). In KB  X  , types assigned to similar sets of entities should be more related to each other than those assigned to quite different entities [12] ( e.g. , actor is more related to director than to author in the right column of Fig. 3). We propose to model type correlation based on the following hypothesis.

Hypothesis 3 (Type Correlation). If high correla-tion exists between two target types based on either type hi-erarchy or KB, they should be embedded close to each other.
We build a homogeneous graph G Y Y to represent the cor-relation between types. A simple way to measure correla-tion between two types is to use their distance in the target type hierarchy (tree). Specifically, a link ( y k ,y k 0 if there exists a path between types y k and y k 0 in Y (paths passing root node are excluded). We define the weight of link denotes the length of the shortest path between types y k 0 in Y . Although using shortest path to compute type cor-relation is efficient, its accuracy is limited X  X t is not always true that a type ( e.g. , athlete ) is more related to its parent type ( i.e. , person ) than to its sibling types ( e.g. , coach ), or that all sibling types are equally related to each other ( e.g. , actor is more related to director than to author ).
An alternative approach to avoid this accuracy issue is to exploit entity-type facts T  X  in KB to measure type corre-lation. Given two target types y k ,y k 0  X  Y , the correlation between them is proportional to the number of entities they share in the KB. Let E k denote the set of entities assigned with type y k in KB, i.e. , E k = e | ( e,y k )  X  X   X  . The weight where |E k | denotes the size of set E k . We compare these two methods for measuring type correlation in our experiments. Entity-entity facts of various relationships in the KB can also be utilized to model type correlation, as discussed in KB embedding [10, 1]. We leave this as future work.
This section follows notations in Table 3 to formulate a joint optimization problem for embedding the constructed heterogeneous graph G into a d -dimensional vector space.
A straightforward solution is to model the whole graph with the local consistency objective [9]. Such a solution en-counters several problems: False candidate types negatively impact the ability of the model to determine mention X  X  true types, and the mention-feature links are too sparse to model mention X  X  types. As such, the learned embeddings may not accurately capture relatedness between mentions and types.
In our solution, we formulate a novel optimization objec-tive, by extending a margin-based rank loss to model noisy mention-type links ( i.e. , G MY ) and leveraging the distribu-tional assumption [17] to model subgraphs G MF and G Y Y . Modeling Mention-Type Association. To effectively model the noisy mention-type links in subgraph G MY , we extend the margin-based loss in [20] (used to learn linear classifiers) to enforce Hypothesis 1. The intuition of the loss is simple: for mention m i , the maximum score associated with its can-didate types Y i is greater than the maximum score associ-ated with any other non-candidate types Y i = Y \Y i , where the scores are measured using current embedding vectors.
Specifically, we use vectors u i , v k  X  R d to represent men-tion m i  X  M and type y k  X  Y in the d -dimensional embed-ding space, respectively. The score of ( m i ,y k ) is defined as the dot product of their embeddings, i.e. , s( m i ,y k ) = v We define the partial-label loss ` i for m i  X  X  as follows. ` i = max n 0 , 1  X  h max
Minimizing ` i encourages a large margin between the max-forces m i to be embedded closer to the most  X  X elevant X  type than to any other non-candidate types ( i.e. , Hypothesis 1). This constrasts sharply with multi-label learning [35], where a large margin is enforced between all candidate types and non-candidate types without considering noisy types. Modeling Mention-Feature Co-occurrences. Hypothesis 2 models mention-feature links based on the idea that nodes with similar distributions over neighbors are similar to each other . This idea is similar to those in the second-order proximity model [29] and skip-gram models [17] X  X t mod-els text corpora following the distributional hypothesis [8] which says that you should know a word by the company it keeps.
 ture f j  X  X  in the embedding space. Following second-order proximity [29], we define the probability of feature f j gener-ated by mention m i for each link ( m i ,f j )  X  G MF as follows.
High conditional probability p ( f j | m i ) indicates that em-beddings of m i and f j are similar. Following Hypothesis 2, we enforce the conditional distribution specified by embed-dings, i.e. , p (  X | m i ) to be close to the empirical distribution ( i.e. , link distribution of m i to F in subgraph G MF ), which can be achieved by minimizing the following objective [29].
Optimizing O MF with p ( f j | m i ) defined by Eq. (3) is com-putationally expensive since it involves summation over all the features. We adopt the negative sampling method [17] to sample multiple negative features for each link ( m i ,f according to some noise distribution . The method replaces log p ( f j | m i ) in Eq. (4) with the following function. where  X  ( x ) = 1 / 1 + exp(  X  x ) is the sigmoid function. The first term in Eq. (5) models the observed links in G MF , and the second term models the Z negative features sampled from the noise distribution P n ( f )  X  D 3 / 4 f over all features F [17]. Here D f denotes the degree of feature f in G MF Modeling Type Correlation. Type correlation links can be modeled with a method similar to that used in modeling the mention-feature subgraph X  X wo types are similar to each other if they are correlated to the same set of types ( i.e. , Hypothesis 3). As link ( m i ,f j ) in bipartite graph G directed , we treat each undirected link ( y k ,y k 0 ) in the homo-geneous graph G Y Y as two directed links [28]. Hypothesis 3 can be modeled by minimizing the following objective. O This enforces the conditional distributions specified by em-beddings to be close to its empirical distributions in terms of both directions of the link ( y k ,y k 0 ) . We use two vectors ding space, where v 0 k serves as the  X  X ontext X  view of y Following a similar negative sampling procedure as that in Eq. (5), we define log p ( y k 0 | y k ) as follows. Similar to the derivation of log p ( y k 0 | y k ) in Eq. (6), we can The Joint Optimization Problem. Our goal is to embed the heterogeneous graph G into a d -dimensional vector space, following the three proposed hypotheses in Sec. 3.1. Intu-itively, one can collectively minimize the objectives of the three subgraphs G MY , G MF and G Y Y , as mentions M and types Y are shared across them. To achieve the goal, we formulate a joint optimization problem as follows. where objective O MY of the subgraph G MY is specified by aggregating the partial-label loss defined in Eq. (2) across all the mentions M , along with ` 2 -regularizations on { u and { v k } K k =1 to control the scale of the embeddings [20]. Tuning parameter  X  &gt; 0 is used to control the amount of regularization on the embeddings. In Eq. (7), one can also minimize the weighted combination of the three sub-graph objectives to model the importance of different sig-nals, where weights could be manually determined or auto-matically learned from data. We leave this as future work. By solving the optimization problem in Eq. (7), we are able to represent every node in G with a d -dimensional vector. Algorithm 1: Model Learning of PLE
We propose an alternative minimization algorithm based on the block-wise coordinate descent method [30] to jointly optimize the objective O in Eq. (7). In each iteration, the algorithm goes through links in G to sample negative links, and update each embedding based on the derivatives.
We first take the derivative of O with respect to { u i } while fixing other variables. A similar procedure to that in [20] is followed to calculate the derivative for partial-label loss. where 1 (  X  ) denotes the indicator function, and F i = { f | ( m  X  G MF } denotes features linked to m i in G MY . We use note the embeddings of the most relevant types in m i  X  X  can-didate type set Y i and non-candidate set Y i , respectively.
The first two terms in Eq. (9) adjust u i to ensure sufficient difference (margin) exists between its similarity to the most relevant candidate type and that to any non-candidate type. The last part requires u i to be close to (different from) its linked (unlinked) features in G MF , respectively.

Second, we fix { u i } and { v k } to compute the derivative of O with respect to { c j } . Let M j = { m | ( m,f j )  X  G denote the mentions linked to feature f j in graph G MF .
The first part in Eq. (10) models the observed links be-tween feature f j and other mentions in graph G MF . The second part models negative samples drawn from links in
MF ( i.e. , with size Z | G MF | ) which involve feature f
Finally, we compute the derivatives for { v k , v 0 k } by fixing other variables. We use N k = { y | ( y,y k )  X  G Y Y } to denote the set of types linked to type y k in graph G Y Y . Algorithm 2: Type Inference where for each k the vector u k i is defined as follow. u a way similar to Eq. (10), which models both the observed links in G Y Y and the negative samples of the observed links.
Algorithm 1 summarizes our algorithm. Eq. (7) can also be solved by a mini-batch extension of the Pegasos algo-rithm [24], which is a stochastic sub-gradient descent method and thus can efficiently handle massive text corpora. Due to lack of space, we do not include derivation details here. Type Inference. With the learned mention embeddings { u i and type embeddings { v k } , we perform top-down search in the candidate type sub-tree Y i to estimate the correct type-path Y  X  i . Starting from the tree X  X  root (denoted as r ), we recursively find the best type among the children types (de-noted as C i ( r ) ) by measuring the dot product of the corre-sponding mention and type embeddings, i.e. , s ( u i , v k search process stops when we reach to leaf type, or the sim-ilarity score is below a pre-defined threshold  X  &gt; 0. Algo-rithm 2 summarizes the proposed type inference process. Computational Complexity Analysis. In graph construction, the cost of building subgraph G Y Y is O ( K 2 I ) , where I is the average number of entities associated with a type in the KB. Building G MY and G MF takes O ( N ) time.

Let E be the total number of links in G . By alias table method [29], sampling a negative link takes constant time and setting up alias tables takes O ( N + M + K ) time for all the nodes in G . In each iteration of Algorithm 1, optimization with negative sampling and partial labels takes O d ( Z + K ) E time. Supposing the algorithm stops after T iterations ( T &lt; 50 in our experiments), the overall time complexity of PLE is O dT ( Z + K ) E , which is linear to the number of links E and does not depend on the number of nodes in G . Our experiments use three public datasets 1 . (1) Wiki [14]: The training corpus consists of 1.5M sentences sampled from  X  780k Wikipedia articles. 434 news report sentences are manually annotated using 113 types (2-level hierarchy) to form the test data; (2) OntoNotes [32]: It has 13,109 news documents where 77 test documents are manually annotated using 89 types (3-level hierarchy) [7]; (3) BBN [31]: It con-sists of 2,311 Wall Street Journal articles (  X  48k sentences) which are manually annotated using 93 types (2-level hier-archy). Statistics of the datasets are shown in Table 5. Automatically Labeled Training Corpora. We followed the process introduced in [14] to generate training data for Wiki dataset. For BBN and OntoNotes datasets, we utilized DB-pedia Spotlight 2 , a state-of-the-art entity linking tool, to identify entity mentions from text and map them to Freebase entries. We then applied the types induced from Freebase to each entity mention and map them to the target types. For experiment purpose, we discarded types which cannot be mapped to Freebase types in BBN dataset (46 out of 93). Feature Generation. Table 2 lists the set of features used in our experiments, which are similar to those used in [34, 14] except for topics and ReVerb patterns. We used a 6-word window to extract context unigrams and bigrams for each mention (3 words on the left and the right). We applied the Stanford CoreNLP tool [16] to get POS tags and dependency structures. The word clusters were derived for each corpus using the Brown clustering algorithm 3 . We discarded fea-tures which occur only once in the corpus. The same kinds of features were used in both label noise reduction (Sec. 4.2) and fine-grained entity typing (Sec. 4.3) experiments. Type Correlation Graphs. We used 2015-06-30 Freebase dump 4 (1.9B triples, 115M entities, 16,701 types) and col-lected 266M entity-type facts (triples with  X  type.instance  X  as predicate). Given two target types, we mapped them to Freebase types and followed the procedure introduced in Sec. 3.1 to compute their KB-based correlation score. Evaluation Sets. For Wiki and OntoNotes datasets, we used the provided training/test set partitions of the cor-pora. Since the BBN corpus is fully annotated, we followed a 80/20 ratio to partition it into training/test sets. Test sets for label noise reduction (Sec. 4.2) consist of mentions in the original test set which can also be linked to KB en-tities (241, 1,190 and 32,353 mentions for Wiki, OntoNotes and BBN datasets, resp.). We further created a validation set by randomly sampling 10% mentions from the test set and used the remaining mentions to form the evaluation set. Compared Methods. We compared the proposed method (PLE) with its variants which model parts of the hypothe-ses, and three pruning heuristics [7]. Several state-of-the-art embedding methods and partial-label learning methods were also implemented (or tested using their published codes): (1) Sib [7]: removes siblings types associated with a mention. A mention is discarded if all its types are pruned; (2) Min [7]: removes types that appear only once in the document; (3) All [7]: first performs Sib pruning then Min pruning; (4) DeepWalk [21]: DeepWalk is an approach for embedding a homogeneous graph with binary edges. We applied it to the heterogeneous graph G by treating all nodes as if they had the same type; (4) LINE [29]: We used second-order LINE model and edge sampling algorithm on feature-type bipar-tite graph (edge weight w jk is the number of mentions having feature f j and type y k ); (5) WSABIE [34]: adopts WARP loss with kernel extension to learn embeddings of features and types; (6) PTE [28]: We applied PTE joint training algorithm on subgraphs G MF and G MY . (7) PL-SVM [20]: Partial-label SVM uses a margin-based loss to handle la-bel noise. (8) CLPL [2]: uses a linear model to encourage large average scores for candidate types. We adopted the suggested setting (SVM with square hinge loss).
 For PLE, besides the proposed model, PLE , which adopts KB-based type correlation subgraph, we compare (1) PLE-NoCo : This variant does not consider type correlation sub-graph G Y Y in the objective in Eq. (7); and (2) PLE-CoH : It adopts the type hierarchy-based correlation subgraph. Parameter Settings. In our testing of PLE and its variants, default, based on the analysis on validation sets. For con-vergence criterion, we stopped the loop in Algorithm 1 if the comparison, the dimensionality of embeddings d was set to 50 and the number of negative samples ( Z in PLE) was set to 5 for PLE, PTE and LINE, as used in [29]. For Deep-Walk, we set window size as 10, walk length as 40, walks per vertex as 40, as used in [21]. Learning rates of LINE and PTE were set to  X  t =  X  0 (1  X  t/T ) with  X  0 = 0 . 025 where T is total number of edge samples (set to 10 times of the number of edges), as used in [28] and [29]. After tuning on validation sets, we set learning rate as 0 . 001 for WSABIE, and set the regularization parameters in PL-SVM and CLPL as 0 . 1. Evaluation Metrics. We use F1 score computed from Pre-cision and Recall scores in 3 different granualities [14, 34]. Let P denote evaluation set. For mention m  X  X  , we denote its ground-truth types as t m and the predicted types as b  X  Strict : The prediction is considered correct if and only if  X  Loose Macro : The Macro-Precision ( Ma-P ) and Macro-
Recall ( Ma-R ) are computed for each mention: Ma-P =  X  Loose Micro : The Micro-Precision ( Mi-P ) and Micro-Recall ( Mi-R ) scores are averages over all mentions, i.e. , We first conduct intrinsic evaluation on how accurately PLE and the other methods can estimate the true types of mentions ( i.e. , {Y  X  i } ) from its noisy candidate type set ( i.e. , i } ). Let P L denote the test mentions which can be linked to KB. We evaluate the quality of the candidate type set ( i.e. , Raw), and three pruning methods on P L . For PLE and other embedding methods, we learn models on D X  X  L using the candidate types, and evaluate the estimation results on the ground-truth types of P L . To test pruning methods, we further apply them on D X  X  L (the pruned corpus is denoted as D P ), and learn the compared embedding models on D P . 1. Comparing PLE with the other methods. Tables 6 and 7 summarize the comparison results on the three datasets. For embedding models learned on different pruned corpora, we only show the combination that yields the best result. Overall, PLE and its variants outperform others on Accu-racy, Precision and F1 scores, and achieve Recall close to that of Raw X  X aw X  X  Recall is the upper bound since type inference is conducted within the candidate type set. In par-ticular, PLE obtains a 40.57% improvement in Accuracy and 23.89% improvement in Macro-Precision compared to the best baseline PTE-Raw on Wiki dataset, and improves Ac-curacy by 16.39% compared to the best baseline LINE-Raw, on the OntoNotes dataset. All three pruning methods suffer from low Recall because they filter conflicting subtypes ( e.g. , Sib) and/or infrequent types ( e.g. , Min) aggressively. Supe-rior performance of PLE demonstrates the needs of LNR to identify true types from the candidate type sets (versus ag-gressive type deletion). PTE utilizes heterogeneous graph structure but suffers from low Precision and Recall, since it does not handle the noisy mention-candidate type links and does not model type correlation. PLE X  X  performance improvement validates Hypotheses 1 and 3. Both WSABIE and LINE aggregate feature-mention-type associations into feature-type associations to reduce the effect of noisy types, but statistics of infrequent features may be biased due to noisy mention-type links. PLE obtains superior performance because it effectively models the noisy type labels. 2. Comparing PLE with its variants. Comparing with PLE-NoCo, PLE gains performance from capturing type semantic similarity with the type correlation subgraph G Y Y , which assists in embedding rare types in the corpus. PLE always outperforms PLE-CoH on all metrics on the three datasets. The enhancement mainly comes from modeling type corre-lation with entity-type facts in KB, which yields more ac-curate and complete type correlation statistics compared to the type hierarchy-based approach (see Sec. 3.1).
 3. Example output on news articles. Table 8 shows the types estimated by PLE, PTE and WSABIE on three news sentences from OntoNotes dataset: PLE predicts fine-grained types with better accuracy ( e.g. , person_title ) and avoids from overly-specific predictions ( e.g. , news_company ). 4. Testing the effect of training set size. Experimenting with the same settings for graph construction and model learning, Fig. 4(a) shows the performance trend on Wiki dataset when varying the sampling ratio (subset of mentions randomly sampled from the training set D ). Performance of all methods improves as the ratio increases, and becomes insensitive as the ratio &gt; 70% . PLE always outperforms its variant and the best baseline PTE. In particular, PLE model trained at 10% sampling rate outperforms the best PTE model (obtained at 70% sampling rate). 5. Testing sensitivity of the tuning parameter. Fig. 4(b) analyzes the performance sensitivity of PLE with respect to  X   X  X he only tuning parameter in the proposed model X  on BBN dataset. Performance of PLE becomes insensitive as  X  becomes small enough ( i.e. , 0.01). We set  X  = 10 throughout our experiments for PLE and its variants.
We further conduct extrinsic evaluation on fine-grained typing to study the performance gain from denoising the au-tomatically generated training corpus D . Two state-of-the-art fine-grained type classifiers, HYENA [35] and FIGER [14], are trained using the same set of features on the denoised corpus (denoted as D d ), which is generated using PLE or the other compared methods. Trained classifiers are then tested on the evaluation set P . Similar to the process in Sec. 4.2, embedding models trained on pruned corpora are compared as well (only the best performing ones). We also compare with partial-label learning methods PL-SVM [20] and CLPL [2], which are trained on D and evaluated on P . 1. Comparing with the other noise reduction methods. Ta-ble 9 reports the comparison results of the two best perform-ing pruning methods and embedding methods on the three datasets. Both typing systems achieve superior performance on all metrics when using PLE and its variant to denoise the training corpus. In particular, PLE improves FIGER X  X  Ac-curacy ( i.e. , Raw) by 33.53% and HYENA X  X  Accuracy by 26.97% on the BBN dataset. Compared to the best baseline PTE-Min, PLE obtains over 28% improvement in HYENA X  X  F1 scores and over 13% enhancement in FIGER X  X  F1 scores on the Wiki dataset. Superior performance of PLE demon-strates the effectiveness of the proposed margin-based loss in modeling noisy candidate types. PLE always outper-forms PLE-NoCo on all metrics on both typing systems. It gains performance from capturing type correlation, by jointly modeling the type-type links in the embedding pro-cess. In particular, we observe that pruning methods do not always improve the performance ( e.g. ,  X  X ll X  pruning results in a 11.15% drop in Macro-F1 score on FIGER on the Wiki dataset), since they aggressively filter out subtypes and/or rare types in the corpus, which may lead to low Recall. 2. Comparing with partial-label learning methods. Compar-ing with PL-SVM and CLPL, both typing systems obtain superior performance when PLE is applied to denoise the training corpora. PL-SVM adopts a modified margin-based objective to fit linear models on features using the noisy can-didate types, but it assume that only one candidate type is correct and does not consider semantic similarity between the types. CLPL simply averages the model output for all candidate types, and thus may generate results biased to frequent false types. Superior performance of PLE mainly comes from jointly modeling of type correlation derived from KB and feature-mention co-occurrences in the corpus. 3. Testing on unseen mentions. Fig. 5 compares PLE with the other methods for predicting types of unseen mentions in the three datasets. We used the learned feature embed-dings and type embeddings to estimate the type-path for each mention in P . PLE outperforms both FIGER and HYENA systems ( e.g. , over 21% improvement in Micro-F1 on the OntoNotes dataset) X  X emonstrating the predictive power of the learned embeddings, and the effectiveness of modeling noisy candidate types. Although FIGER trained on PLE-denoised corpus obtains superior F1 scores, PLE can achieve competitive performance without training an additional classifier ( i.e. , more efficiently). 1. Testing at different type levels. Fig. 6(a) reports the Accuracy of PLE, PTE and WSABIE on recovering ground-truth types at different levels of the target type hierarchy Y . The results shows that it is more difficult to distinguish among deeper (more fine-grained) types. PLE always out-performs the other two method, and achieves a 153% im-provement in Accuracy, compared to the best baseline PTE on level-3 types. The gain mainly comes from explicitly modeling the noisy candidate types, since most mention-type links on fine-grained types are false positives. 2. Iterative re-training of PLE. We re-train PLE model and its variants using the corpus D d which has been de-noised by PLE, to analyze the effect of boostrapping PLE. To avoid overly-low Recall, in each iteration we conduct type inference in the original candidate type set {Y i } . Fig. 6(b) shows that the performance gain becomes marginal after 3 iterations of re-training. This may be because the learned embeddings in the first round of training already capture all the signals encoded in the heterogeneous graph X  X he up-dated mention-type subgraph from the denoised corpus does not cause significant changes to the embeddings. Fine-Grained Entity Typing. There have been extensive studies on entity recognition and typing. In terms of the de-pendence on context information, existing work can be cate-gorized into context-dependent [18, 14] and context-independent approaches [19, 13]. Work along both lines can be further categorized in terms of the type granularity that is consid-ered. Traditional named entity recognition systems [16] fo-cus on coarse types ( e.g. , person , location ) and cast the problem as multi-class classification following the type mu-tual exclusion assumption ( i.e. , one type per mention) [18]. Recent work has focused on a much larger set of fine-grained types [35, 14]. As type mutual exclusion assumption no longer holds, they cast the problem as multi-label multi-class (hierarchical) classification problems [7, 35, 14], or make use of various supervised embedding techniques [34, 3] to jointly derive feature representations in classification tasks.
Most existing fine-grained typing systems use distant su-pervision to generate training examples and assume that all candidate types so generated are correct. By contrast, our framework instead seeks to remove false positives, denoising the data and leaving only the correct ones for each mention based on its local context. Output of our task, i.e. , denoised training data, helps train more effective classifiers for entity typing. Gillick et al. [7] discuss the label noise issue in fine-grained typing and propose three type pruning heuristics. However, these pruning methods aggressively filter training examples and may suffer from low recall (see Table. 9).
In the context of distant supervision, the label noise issue has been studied for other information extraction tasks such as relation extraction [27] and slot filling [11]. However, the form of supervision is different from that in entity typing. Partial Label Learning. Partial label learning (PLL) [36, 20, 2] deals with the problem where each training example is associated with a set of candidate labels, where only one is correct . Unlike this PLL formulation, our problem can be seen as hierarchical classification with partial labels . Existing PLL methods model a single true label for each training example and do not consider label correlation information. We compare with simple extensions of PL-SVM [20] and CLPL [2] by applying the learned partial-label classifiers to predicted type-paths in a top-down manner (see Table. 9). Text and Network Embedding. The proposed PLE frame-work incorporate embedding techniques used in modeling text data [34, 3, 17], and networks/graphs [28, 21, 9]. How-ever, existing methods assume links are all correct (unsuper-vised) or labels are all true (supervised) X  X ur approach seeks to delete noisy links and lables in the embedding process. We compare with several embedding methods like PTE [29] to validate Hypothesis 1 on noisy labels (see Sec. 4.2).
We study a new task on reducing label noise in distant supervision for fine-grained entity typing, and propose a heterogeneous partial-label embedding framework (PLE) to denoise candidate types in automatically labeled training corpora. Experiment results demonstrate that the proposed method can recover true type labels effectively and robustly, and the denoised training data can significantly enhance per-formance of state-of-the-art typing systems. Interesting fu-ture work includes extending PLE X  X  similarity function to model hierarchical type dependency [10], deploying multi-sense embedding to model topics of contexts [34], and ex-ploiting relation facts in KB jointly [1]. Embeddings learned by PLE can be directly used to predict types for unseen men-tions, which saves time otherwise needed to build additional classifiers. PLE is general and can be used to denoise train-ing data in other domains ( e.g. , image annotation [33]).
Research was sponsored in part by the U.S. Army Re-search Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.
