 Given a collection of document groups, a quick question is what are the differences in these groups. In this paper, we study a novel problem of summarizing the differences between document groups. A discriminative sentence se-lection method is proposed to extract the most discrimina-tive sentences which represent the specific characteristics of each document group. Experiments on real world data sets demonstrate the effectiveness of our proposed method. H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; I.2.6 [ Arti cial Intelligence ]: Learning Algorithms, Experimentation, Performance Comparative Document Summarization, Discriminative Sen-tence Selection
In many applications, when facing a set of document groups sharing similar topics, people are interested to know the dif-ferences in these document groups. Thus a summary de-scribing major differences among the given documents is necessary to facilitate the comparison of these document groups, e.g., summarizing different points of view in news articles, comparing different blog communities, and summa-rizing the changes in the community evolution. To the best of our knowledge, the problem of summarizing the distinct-ness of documents has not been well defined and studied. Thus in this paper, we study the novel problem referred to as Comparative Extractive Document Summarization (CDS) to summarize the differences between comparable document groups. Specifically, given a collection of document groups, the CDS problem is to generate a short summary deliver-ing the differences of these documents by extracting the most discriminative sentences in each document group. This problem is related to the traditional document summariza-tion problem since both of them try to extract sentences from documents to form a summary. However, traditional document summarization aims to cover the majority of in-formation among document collections, while our goal is to find differences.

In this paper, we propose a discriminative sentence se-lection approach based on a multivariate normal genera-tive model to extract sentences best describing the unique characteristics of each document group. Given a collection of document groups (clusters), we decompose these docu-ments into sentences, and calculate sentence-document and sentence-sentence similarities using cosine similarity. Since each document is labeled to indicate which cluster it belongs to, we select sentences one by one to minimize the average variance of all the cluster targets under the distribution es-timation based on a multivariate normal generative model. Experiments on real world data sets demonstrate the ef-fectiveness and the discriminative ability of the summaries generated by our method.
Traditional document summarization aims to generate a summary delivering the major information expressed in a collection of documents. Current methods usually ranks the sentences in the documents according to the scores calcu-lated by a set of predefined features, such as term frequency-inverse sentence frequency (TF-ISF) [5], sentence or term position [8], and number of keywords [8]. Other techniques such as latent semantic analysis (LSA) [3], matrix factoriza-tion [6], hidden Markov model [1], and graph ranking [2] are also used in document summarization.
 There are few works focusing on comparing documents. Some work on comparing product reviews has been pro-posed in [4]. Although the work summarizes and com-pares the positive/negative aspects of products, the essence of the work is still based on word-level opinion mining. An-other work referred to as comparative text mining (CTM) [9] tries to discover common and specific themes in multiple documents using a generative probabilistic mixture model. However, the word-level representation used in the work has limited interpretation ability. There is also very recent work on evolutionary summarization which compares the different event evolutionary phases [7].
Suppose we have f sentences of the document collection, denoted by f X i j i 2 F g , where F is the full sentence index set, having j F j = f . We have the group variable, Y , repre-sented by multiple group indicator variables. The problem of sentence selection is selecting a subset of sentences, S F , to accurately discriminate the documents in different groups, i.e. to predict the group identity variable Y , given that the cardinality of S is m ( m &lt; f ). Let us denote f X i j by X S , for any set S . The prediction capability of Y given X
S can be measured by the entropy of Y given X S , which is defined as where E p ( ) is the expectation given the distribution p , and p stands for the underlying document distribution, i.e. the joint distribution p ( Y; X s ). The sentence selection problem using the mutual information criterion is
Selecting an optimal subset of sentences is a combinatorial optimization problem, which is an NP-hard problem. The effective practice is to take a greedy approach, i.e., sequen-tially selecting features to achieve a sub-optimal solution.
We assume that the joint distribution of f X i g and Y is a multivariate normal distribution, where is the mean vector, and is the covariance matrix. Let F be the index set of X in z , and T be the index set of Y in z .

We denote the sentence-document similarity matrix by e X , where each row represents a sentence, and each column rep-resents a document. For example, the sentence-document similarity matrix can be constructed using the dot product of the sentence-term and term-document matrices which are computed using cosine similarity. We consider multiple tar-get variables. For grouped documents, we denote the group identity matrix as e Y , where each column represents group identity variables of a document, and each row represents a group identity variable.

Given the data, we estimate the parameters of Eq. (3) by where n is the number of rows of matrix e X , 1 is a column vector of size n , whose elements are all ones, and Next, we consider the sentence-sentence similarity matrix W . For example, the sentence-sentence similarity matrix can be obtained by the product of the standardized sentence-term matrix and its transpose. We use sentence-sentence similarity matrix to augment the covariance matrix. Also we consider to add a regularization term to prevent the ill-posed problem of the estimation. Then, we define our covariance matrix by where I is the identity matrix of size of the number of groups, is a mixture parameter to weigh the importance of the sentence-sentence matrix, is the regularization parameter to increase the robustness. The reason for the lower-right corner of the second term is that we consider that the doc-ument group are exclusive.
In the multivariate normal model, the sentence selection problem in Eq. (2) becomes plement. As the determinant of the covariance matrix is known as generalized variance . This criterion is to minimize the generalized variance of the joint distribution of targets. We use the greedy approach to solve Eq. (7). Let K =
D | S , where D is the full index set.Based on the property of multivariate normal distribution, we have Therefore We can compute D | S  X  X  i } from K = D | S by
Algorithm 1 shows the computational procedure. The procedure is similar to the sequential algorithm in [10]. Algorithm 1 Discriminative Sentence Selection (DSS) 1: K = ; 2: S =  X  ; 3: repeat 4: i = arg max 6: S  X  S  X  X  i } ; 7: until | S | = m .
A case study is conducted to examine the summarization results by different methods on real Blog data. Each method forms a one-sentence summary for each blog community.
The real blog data was collected by an in-house blog crawler during 2005 and 2006. In this data set, we have 407 English blogs with 274,679 entries in 441 days (63 weeks) between July 10th in 2005 and September 23rd in 2006. The data set contains 7 communities as follows: 1. War and Terrorist : discusses the war and conflicts with Iraq; 2. Race Issues : consists of entries on the topic of race and ethnic policy and facts; 3. Duke Lacrosse Case : describes the scandal that started in March 2006 when a black stripper falsely accused three white members of Duke University X  X  men X  X  lacrosse team of raping her; 4. Religion : mainly focuses on sto-ries about the Christian religion; 5. 911 Commission : discusses the national commission on terrorist attacks upon the United States on September 11, 2001; 6. China Issues : contains entries about China X  X  democracy, politics, and eco-nomics; 7. Hurricane Katrina : describes the destroy of the hurricane Katrina in New Orleans in 2005, and discusses the government X  X  behavior in this disaster.
We implement the following systems in the case study. NMF-1 : performs non-negative matrix factorization on the sentence-term matrix. K-Means : conducts K-Means clustering on sentences and includes the centroid sentences into the sum-mary. LSA : conducts latent semantic analysis on terms by sentences matrix as proposed in [3]. LeadBase : re-turns the leading sentences of all the documents for each topic. Center : selects the sentence most similar to all of the rest sentences in each community. NMF-2 : performs non-negative matrix factorization on the sentence-document matrix. DSS : our proposed discriminative sentence selec-tion method. Table 1: Sentences selected by our proposed DSS approach The rst column represents the commu-nity ID to which the selected sentences belong.

Table 1 and 2 show the sentences selected by different implemented systems. From the results, we observe that the widely used existing document summarization methods such as NMF-1, K-Means and LSA can not extract sen-tences covering all the seven communities contained in these blog entries. For example, NMF-1 method extracts two sen-tences from 911 commission and hurricane Katrina commu-nities respectively, however, the duke lacrosse case and war and terrorist communities are missing. Another problem of these methods is that many of the selected sentences can not discriminate the communities because 1) they come from the same community (for example, there are three sentences from hurricane Katrina in the results of K-Means method, and three sentences from war and terrorist in the results of LSA method); 2) some of the selected sentences are too gen-eral, such as  X  X he system is designed to keep you running in circles so you won X  X  see the real issues X  X n the results of NMF-1 method. This sentence is supposed to describe the specific content in the race issue community, however, the sentence is not distinctive at all and may appear in any community. The LeadBase and Community Center approaches explore each community one by one, so the sentences they select def-initely come from different communities. And it is nice that NMF-2 can automatically extract one sentence from each of the seven communities. However, there are still some sen-tences selected by these methods are non-discriminative. In Table 2, we label the non-discriminative sentences using a crossing below the community ID.

While looking at the results by our proposed discrimina-tive sentence selection method, each of the sentences repre-sents one community respectively, and the specific charac-teristics of the community are well summarized. In Table 1, we highlight some keywords representing the unique features of each topic.
In this paper, a discriminative sentence selection method is proposed to summarize the differences of document groups based on the multivariate normal model. Experiments on real world data show the effectiveness of the proposed method. Appendix: The work is partially supported by NSF grants IIS-0546280 and DMS-0844513. discriminative.
