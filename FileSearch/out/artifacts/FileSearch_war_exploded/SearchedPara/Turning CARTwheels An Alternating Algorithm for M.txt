 We present an unusual algorithm involving classification trees X  CARTwheels X  X here two trees are grown in opposite direc-tions so that they are joined at their leaves. This approach finds application in a new data mining task we formulate, called redescription mining. A redescription is a shift-of-vocabulary ,or a different way of communicating information about a given subset of data; the goal of redescription mining is to find subsets of data that afford multiple descriptions. We highlight the importance of this problem in domains such as bioinformatics ,which exhibit an underlying richness and diversity of data descriptors (e.g. ,genes can be stud-ied in a variety of ways). CARTwheels exploits the duality between class partitions and path partitions in an induced classification tree to model and mine redescriptions. It helps integrate multiple forms of characterizing datasets ,situates the knowledge gained from one dataset in the context of others ,and harnesses high-level abstractions for uncovering cryptic and subtle features of data. Algorithm design deci-sions ,implementation details ,and experimental results are presented.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining; I.2.6 [Artificial Intelligence]: Learning General Terms: Algorithms.
 Keywords: Classification trees ,redescriptions ,data min-ing in biological domains.
Classification and regression trees (CART) were among the earliest proposed approaches for pattern classification and data mining [3]. While being powerful in terms of accu-racy and efficiency of induction ,their results are also sim-ple to understand as they mimic the decision-making logic of human experts. The renewed emphasis on data mining propagated by the KDD community in the 1990s has fueled a resurgence of interest in tree-based methods [7 ,9].
In this paper we introduce a new data mining task X  redescription mining  X  X nd also propose a novel tree-based algorithm (CARTwheels) for mining redescriptions. A re-description is a shift-of-vocabulary ,or a different way of communicating information about a given subset of data; the goal of redescription mining is to find subsets of data that afford multiple descriptions.

Consider the set of all countries in the world. The ele-ments of this set can be described in various ways ,e.g. ,ge-ographical location ,political status ,scientific capabilities , and economic prosperity. Such features allow us to define various subsets of the given (universal) set ,called descrip-tors . Examples of these are shown in Fig. 1.

Redescriptions are equivalences describing a subset in two ways ,for instance: Both sides of this redescription refer to the singleton set {
US } . Such relationships can be mined using techniques from the association rules literature [1] ,but our view of re-descriptions is broader in scope and also includes set-theoretic expressions involving descriptors: Here ,we have constructed a set intersection on the left and a set difference on the right ,from the given descriptors ,and obtained a redescription for the 3-element set: { US ,UK , Fran ce } . A typical approach to mining such patterns would be to first fix the form of the set-theoretic expressions and then search within the space of possible instantiations. The goal of this paper is to present an algorithmic framework that simultaneously constructs set-theoretic expressions and searches in the space of possible redescriptions.

Formally ,the inputs to redescription mining are the uni-versal set of objects O (e.g. ,countries) and two sets ( X and Y ) of subsets of O . The elements of X are the descriptors X ,and are assumed to form a covering of O ( Similarly is that it be a proper subset of O and denote some logical grouping of the underlying objects (for ease of interpreta-tion). The goal of redescription mining is to find equiva-lence relationships of the form E  X  F that hold at or above F are set-theoretic expressions involving X i  X  X  and Y i  X  X  ,re-spectively. For tractability purposes ,some restrictions on the length of the allowable set-theoretic expressions (not their form) is assumed to be provided. Redescription mining hence involves constructive induction (the task of inventing new features) and exhibits traits of both unsupervised and supervised learning. It is unsupervised because it finds con-ceptual clusters underlying data ,and it can be viewed as su-pervised because clusters defined using descriptors are given meaningful characterizations (in terms of other descriptors).
Why is this problem relevant? We posit that today X  X  high-throughput data-driven sciences are drowning in not just the dimensionality of data ,but also in the multitude of descrip-tors available for characterizing data. Consider gene expres-sion studies using bioinformatics approaches. The univer-sal set of genes in a given organism ( O ) can be studied in many ways ,such as functional categorizations ,expression level quantification using microarrays ,protein interactions , and biological pathway involvement. Each of these method-ologies provides a different vocabulary to define subsets of O (e.g. , X  X enes localized in cellular compartment nucleus , X   X  X enes up-expressed two-fold or more in heat stress, X   X  X enes encoding for proteins that form the Immunoglobin complex, X  and  X  X enes involved in glucose biosynthesis X ). While tradi-tionally we would custom-build data mining algorithms to work with each of these vocabularies ,redescription mining provides a uniform way to characterize and analyze the re-sults from any of them. In addition ,it helps bridge diverse experimental methodologies by uniformly relating subsets across the corresponding vocabularies.

We further argue that redescription mining serves as a fundamental building block of many important steps in the iterative ,often unarticulated ,knowledge discovery process. A shift of vocabulary allows a given subset of data to be interpretable in a different context ,and allows us to harness existing knowledge from this other context. For instance, if we are able to redescribe results from a new stress ex-periment onto ,say ,a heat shock experiment studied ear-lier ,we will be able to study the new results in terms of known biological knowledge about heat shock. Chains of re-descriptions allow us to relate diverse vocabularies ,through important intermediaries.

Even redescriptions that hold with Jaccard X  X  coefficient &lt; 1 find application in many domains. An approximate re-description implies a common meeting ground for two con-certed communities of objects. A chain of such approximate redescriptions can effectively relate two subsets that have nothing in common! This is especially useful in story telling and link analysis applications. A query such as  X  X hat is the relationship between people traveling on Flight 847 and the top10wantedlistbytheFBI? X  X anbeposedintermsof redescription finding.

While related problems have been studied in the data min-ing community (most notably ,conceptual clustering [5 ,12] , niche finding ,and profiling classes [19]) ,we believe that the above formulation of redescription mining has not been at-tempted before. Our contributions here are both the intro-duction of this new data mining problem ,as well as a novel tree-based algorithm for mining redescriptions.
We now introduce an approach (CARTwheels) to mining redescriptions that involves growing two trees in opposite directions ,so that they are matched at their leaves. The de-cision conditions in the first tree (say ,top) are based on set membership checks in entries from X and the bottom tree is basedonmembershipchecksinentriesfrom Y ;thusmatch-ing of leaves corresponds to a potential redescription. This idea hence uses paths in the classification trees as represen-tations of boolean expressions involving the descriptors.
The CARTwheels algorithm is an alternating algorithm, in that the top tree is initially fixed and the bottom tree is grown to match it. Next ,the bottom tree is fixed ,and the top tree is re-grown. This process continues ,spouting redescriptions along the way ,until designated stopping cri-teria are met. For ease of illustration ,consider the artificial example in Fig. 2 that shows two sets of descriptors for the universal set O = { o 1 ,o 2 ,o 3 ,o 4 ,o 5 } . Here ,the set X corresponds to the set of descriptors { X 1 ,X 2 ,X 3 ,X 4 } and Y corresponds to { Y 1 ,Y 2 ,Y 3 ,Y 4 } . The cardinalities of X and Y may not be the same in the general case. Further ,in a realistic applica-tion ,the number of descriptors would far exceed the number of objects.

To initialize the CARTwheels alternation ,we prepare a traditional dataset for classification tree induction ,where the entries correspond to the objects ,the boolean features are derived from one of X or Y ,and the classes are derived from the other. In the dataset shown in Fig. 3 (left) ,the features correspond to set membership in entries of Y and each object is assigned a unique class ,chosen from the X it participates in. We employed a greedy set covering of the objects using the entries of X in order to establish the class labels in Fig. 3 (left). For instance, o 2 belongs to both X and X 3 ,but the tie is broken in favor of X 1 .Noticethatin this process, X 3 does not receive any representation in the prepared dataset.

A classification tree can now be grown using any of the impurity measures studied in the literature (e.g. ,entropy , Gini index ,misclassification rate). Fig. 3 (right) depicts a possible tree. The leaves of the tree deterministically predict a class label from X ,typically the majority class. At this point ,the specific details of how the tree was induced are not important ,only that any such tree will induce a partition of the underlying objects. In this case ,the tree induces a 3-partition which mirrors the 3-class partition present in the original dataset ,but is not exactly the same. The left most path corresponds to the region Y 3  X  Y 2 ,the right most path corresponds to O  X  Y 3  X  Y 1 ,and the union of the two middle Y Y Y Y obj. Y 1 Y 2 Y 3 Y 4 class o o o o o 5  X   X  to evaluation by Jaccard X  X  coefficient. paths gives ( Y 3  X  Y 2 )  X  ( Y 1  X  Y 3 ). The reader can verify that these regions do not have a one-to-one correspondence with the regions X 1 , X 2 ,and X 4 in the original partition. For instance ,only X 2 enjoys such a correspondence ,with O  X  Y 3  X  Y 1 . In  X  X eading off  X  a partition from a tree in this manner ,a conjunction thus results from a path of length &gt; 1 ,a disjunction results from multiple paths predicting the same class ,with negations corresponding to following the  X  X o X  branch from a given node. This partition is used as the starting point for the alternation (Fig. 5 ,first frame).
We now prepare a dataset with entries from X as the features and the regions thus formed (involving Y i  X  X ) as the classes ,as shown in Fig. 4 (left). Inducing a classification tree from this dataset really corresponds to growing a second tree to match the first tree at the leaves ,as depicted in Fig. 5 (second frame). In this case ,the second tree also learns a 3-partition and we can evaluate each of these matchings using the Jaccard X  X  measure. This produces three redescriptions: all of which hold at Jaccard X  X  coefficient 1. This need not be the case in general. The bottom tree might be able to match only some paths in the top tree ,or the matches might not pass our Jaccard X  X  cutoff. This process is then continued, now with Y i  X  X  as features and the partitions derived from the bottom tree as classes (see right of Fig. 4). The new matchings yield the redescriptions: which ,fortuitously ,also have a Jaccard X  X  coefficient of 1. Notice that ,this time ,the root decision node that has been picked is Y 4 (see third frame of Fig. 5) and the tree actu-ally resembles a decision list (a tree where every internal node has a leaf on its  X  X es X  branch). The alternation can be continued (see Sec. 2.4 for ways to configure the search).
If we limit the size of the trees at every iteration ,it is easy to see that the set-expressions constructed cannot get arbitrarily long. In our running example ,we use a depth limit of 2 so that all expressions on either side of a mined redescription can involve at most three descriptors. The longest expressions result from unions of two paths involving different subtrees.
The use of trees to mine one-directional implications (rules) is well understood and is the idea behind algorithms such as C4.5 [15]. In CARTwheels ,we exploit the duality between class partitions and path partitions to posit the stronger no-tion of equivalence. In fact ,if a tree reduces the entropy to zero ,it is clear that there must be a one-to-one corre-spondence between its path partitions and class partitions, which are really path partitions from the other tree. Keep in mind that different paths are union-ed when they predict the same class ,and this property is crucial to establishing the duality.

The search for redescriptions in CARTwheels can be viewed as a problem of identifying (and creating) correlated random Figure 6: Contour plot depicting best attainable Jaccard X  X  coefficient, for different set sizes. variables. We present a simple analysis in the case of one-level tree (the extension to more levels is beyond the scope of this paper). A descriptor ,e.g. , D ,canbeconsideredto be a discrete random variable that takes on values from O . Every object in D occurs with probability 1 | D | and other ob-jects occur with probability zero ,to yield total probability mass of 1. Notice that this makes the self entropy of such a random variable to be the logarithm of the size of the de-scriptor. Now consider running a CARTwheels alternation with a depth limit of 1 for the classification trees. Mining a redescription with Jaccard X  X  coefficient of 1 is equivalent to identifying a random variable D whose entropy distance from D is zero. The entropy distance is given by: where H ( D,D ) is the joint entropy function of { D , D } I qualifies the mutual information ,in turn given by: where H ( D ) is the self-entropy of D and H ( D | D )isthe conditional entropy of D given D . In other words ,the av-erage reduction in uncertainty about D due to knowing D is exactly the self entropy of D ,causing an entropy distance of 0. Entropy distance is a true distance measure ,unlike mea-sures such as the Kullback-Leibler (KL) divergence. Smaller values of entropy distance hence imply higher values of Jac-card X  X  coefficient.
CARTwheels provides a general framework to explore a space of redescriptions; to configure its alternation ,there are several issues to be considered.

We will begin by observing that the continuation of CART-wheels alternation ,after mining a redescription ,is really an attempt to explore and stay within a relatively small region of high Jaccard X  X  coefficient. Fig. 6 shows an idealized sce-nario where descriptors (or expressions derived from them) occur in all possible sizes ,with the best possible overlaps. In a realistic dataset ,the regions of high Jaccard X  X  coefficient might be disjoint ,and a good exploration policy must try to visit all potential regions.

In contrast to traditional classification tree induction which is motivated at reducing entropy ,CARTwheels must actually maintain entropy in some form ,since impurity drives explo-ration. However ,if the impurity in the underlying datasets remains constant ,some redescriptions are bound to be found over and over again. The tradeoff here is clearly between ex-ploration and redundancy: to support sufficient exploration, we must accept redundancy ,and conversely if we desire to reduce redundancy ,we must settle for insufficient coverage of the redescription space. This tradeoff suggests that a tunable parameter for CARTwheels alternation is the num-ber of times that a descriptor is allowed to participate in redescriptions.
Table 1 describes the CARTwheels algorithmic framework in detail. The outline follows the example shown previously: construct dataset prepares a dataset suitable for CART in-duction as in Fig. 3; construct tree creates the decision tree of depth d ;and paths to classes reads expressions off an in-duced tree ,to be used as classes in the next step for each object in O . Notice the use of an impurify function in both the initialization and the alternation steps ,which typically assigns the second-best class label to the chosen leaf l . Addi-tional impurification steps ,to aid exploration ,are included in our implementations of construct tree (e.g. ,we do not al-ways branch on the attribute with the best entropy gain and sometimes perform randomized moves at the root level).
The eval function returns redescriptions satisfying the Jac-card X  X  threshold  X  . Our implementation of eval requires re-descriptions to hold in both the mined and complementary forms ,e.g. ,for the equivalence E 1  X  E 2  X  F to be considered as a redescription ,it must hold with Jaccard X  X  coefficient at least  X  ,as must its complement:  X  E 1  X  X  E 2  X  X  F .This ensures that every redescription truly induces a partition of O  X  O space. descriptors is a function that analyzes a set-theoretic expression and returns the set of descriptors participating in it.

The important tunable parameter in Table 1 is  X  ,control-ling the tradeoff between redundancy and exploration. A participation count is incremented each time a given descrip-tor appears in a redescription in its role as part of a class, and when this reaches  X  ,the descriptor is removed from con-sideration. The parameter  X  specifies the maximum number of alternations that CARTwheels can go through without mining any redescriptions.
There are many ways to assess significance of redescrip-tions mined by CARTwheels. They vary in their formulation of the null hypothesis. For instance ,given a redescription X  X  Y with Jaccard X  X  coefficient  X  we can ask  X  X ow likely is it that two descriptor expressions of size | X | and | Y | as their Jaccard X  X  coefficient? X  or  X  X ow significant is it that expressions having the same syntactic bias as X and Y have  X  as their Jaccard X  X  coefficient? X  The first approach focuses on the sizes of the descriptor expressions whereas the second is concerned with the way expressions are constructed ,and must inherently utilize the distribution of descriptor sizes (and maybe second order information ,such as commonality or differences). We adopt the first approach in this paper.
Specifically ,we assess if the Jaccard X  X  coefficient (  X  )can happen by chance if we had chosen sets X and Y randomly from the available universal set O ,keeping | X | and | Y This yields a simple statistical test giving a p-value based on the distribution of set overlaps for the given set sizes (details omitted for space considerations). Keep in mind that one waytogetastrongp-valuewouldbetohaveverysmall sizes for X and Y (which in turn ,make the achievement of arespectable  X  difficult). On the other hand ,if X and Y are large ,the ease with which they could overlap increases ,and hence even high Jaccard coefficients might not correspond to a strong p-value. Therefore ,for interpretation purposes ,it is important to not think of intersection size as a surrogate for significance of redescriptions. In the experiments reported here ,we have found statistically significant redescriptions involving as few as 1 object to as large as 80 objects.
CARTwheels is implemented in C++ atop a Postgres data-base providing access to the descriptors. We use an AD-tree data structure [13] for fast counting purposes and estima-tion of entropy (this is distinct from the classification tree Table 2: Summary o funiversal sets and descriptors. # stresses 5 7 7 #expts 7 9 9 #ORFs 74 332 171 GO (biological process) descriptors 210 479 382 GO (cellular component) descriptors 42 112 97 GO (molecular function) descriptors 126 298 204
Expression level range descriptors 224 373 344 k-means clusters 70 270 0
Histone expression range descriptors 152 168 162 #descriptors 824 1700 1189 that combines the descriptors). The AD-tree provides access to the distributions of  X  X lass labels X  for every combination of  X  X eatures X  and ,since the definition of features and class labels change at every iteration ,is rebuilt continually. No-tice that the data structure is expected to provide both the sizes of descriptors as well as their negations (when we fol-low the  X  X o X  branch) and hence ,the depth of the AD-tree is set to just greater than the allowable depth of the classifica-tion trees. The CARTwheels algorithm consults the AD-tree whenever it must make a choice of a decision node (except when its move is exploratory). After evaluating matchings, set-expressions read off the trees are subjected to tabular minimization ,in order to arrive at a canonical form.
The implementation allows for configuring the space of redescriptions that are explored. The depth limit for the top and bottom trees can be individually specified ,and we can also preferentially include or exclude certain types of expressions in mined redescriptions. For instance ,syntactic constraints on redescriptions (e.g. ,only conjunctions are al-lowed) can be incorporated as biases in the tree construction phase of CARTwheels.
We now present an application of CARTwheels to study-ing gene expression datasets from microarray experiments conducted on the budding yeast Saccharomyces cerevisiae . Bioinformatics is fertile ground for application of CART-wheels and S. cerevisiae is arguably the most well studied (and documented) model organism through bioinformatics techniques. Practically every experimental methodology ap-pliedtowardyeastcanbeviewedasawaytodefinede-scriptors. Even the results of other data analysis/mining algorithms can be used as a source of descriptors! The un-derlying universal set of objects could be initialized to the set of genes ,proteins ,or processes ,in S. cerevisiae .CART-wheels hence brings many computational and experimental technologies to bear upon redescription mining. It supports the capture of both similarities and distinctions among de-scriptors derived from these diverse sources.
The redescription process begins by defining the univer-sal set of genes (or open reading frames ,ORFs) G ,which is dependent on our biological goals. Here ,we are inter-ested in characterizing similarities and differences in yeast gene expression behavior across related families of stresses. Gasch et al. ([8]) is an important source for such a study since it provides results from more than 170 comparisons, across a variety of environmental stresses. We use three dif-ferent universal sets ,to illustrate diverse ways of using the CARTwheels framework: G : the set of ORFs that show significant change in expres-sion (more than 1-fold up-or down-regulation) in some time point in each of the five stresses from (heat shock from 25 to 37  X  C ,hyper-osmotic shock ,hypo-osmotic shock , H exposure ,and mild heat shock at variable osmolarity). G : the set of ORFs that show more than 4-fold up-or down-regulation change in expression in some time point in each of the seven stresses from (heat shock from 25 to 37  X  C ,hyper-osmotic shock ,hypo-osmotic shock , H exposure ,mild heat shock at variable osmolarity ,heat shock from 37  X  Cto25  X  C ,and heat shock from 29  X  Cto33 Notice that two additional stresses are included ,from how G 1 was constructed.
 G : the set of ORFs more than 4-fold up-or down-regulation change in expression in some time point in each of the seven stresses in G 2 and that do not belong to the set of ESR (Environmental Sress Response) genes as characterized by Gasch et al. ([8]). The ESR dataset (comprising 868 ORFs) constitute a characterization of yeast ORFs that show a marked uniformity of expression across diverse stresses ,and hence have been excluded by many researchers in their anal-yses  X  see for instance ,([17]).

The choice of the universal set can be viewed as a condi-tioning context and must be kept in mind when interpreting any mined redescriptions. It can be viewed as an implicit descriptor occurring on both sides of every mined redescrip-tion ,e.g. , E  X  F in G 1 canbeviewedas E  X  G 1  X  F  X  G 1
We defined descriptors for the genes in the chosen univer-sal sets in a variety of ways. One class of descriptors was derived from categories in the GO (Gene Ontology) biologi-cal process ,GO cellular component ,and GO molecular func-tion taxonomies ,that have representation among the chosen genes. The microarray results from the stresses of Gasch et al. (relevant to each universal set) were bucketed to yield range descriptors of the form  X  X xpression level  X  [%x ,0] in time point %y of stress experiment %z X  (for negative %x) and  X  X xpression level  X  [0 ,%x] in time point %y of stress experiment %z X  (for positive %x). Notice that we are not constrained to pick descriptors from only the stresses used to define the universal set ,although we have made that choice here. Further ,k-means clustering was performed using the Genesis software suite ([18]) on each of the stresses individ-ually ,with a setting of 10 clusters for G 1 and 10 and 20 clusters for G 2 . No descriptors based on k-means clustering were defined for G 3 . Since heat shock and mild heat shock at variable osmolarity are actually pairs of experiments ,this step yields (5+2)  X  10 = 70 (for G 1 )and(7+2)  X  (10 + 20) = 270 (for G 2 ) descriptors ,depicting clusters of genes with similar temporal profiles. It must be kept in mind that each of these experiments in turn comprise of multiple time points ,different for each stress. Finally ,we included microarray results from a histone depletion experiment con-ducted by Wyrick et al. ([20]) and created range descriptors similar to the Gasch stresses; this is to allow us to relate the effect of histone depletion to that of environmental stresses. Table 2 summarizes the number of descriptors of each type defined for each of the universal sets ,and provides count statistics. Fig. 8 presents frequency plots for the sizes of the descriptors in each of the universal sets. As expected ,a majority of descriptors in each case have very few number of ORFs.
To invoke CARTwheels for a particular universal set ,we initialized X to be all descriptors derived from the Gasch et al. dataset (which includes the range descriptors as well as the k-means clusters). This ensures that all redescriptions will involve some aspect of the Gasch et al. experiment and prevents the possibility of ,say ,mining a redescription between two GO taxonomies. Y was initialized to the set of all descriptors; thus ,there is some overlap between X and Y . In order to prevent obvious redescriptions arising from this overlap ,the algorithm was precluded from utilizing descriptors in one tree if they are already present in the other tree.

We employed a Jaccard X  X  threshold  X  of 0.5 and a depth-limit d  X  2 in both the top and bottom tree induction alter-nations. The limit on the number of allowable alternations  X  is set to 10 ,and  X  was varied from 1 to 6. Redescriptions mined by CARTwheels are subjected to a  X  X ightening X  step, akin to rule pruning in packages like C4.5 ([15]). This might involve attempting to drop terms from both sides of the re-description ,or restricting range descriptors (if they occur in the redescription) ,and determining whether this causes significant degradation of Jaccard X  X  coefficient. If no degra-dation is observed ,then the redescription can be tightened. A p-value cutoff of 0.001 for significance of redescriptions was utilized in this paper. We first describe the qualitative nature of biological results obtained through redescription and then assess the exploratory behavior of CARTwheels. Seven key mined redescriptions (R1 X  X 7) are depicted in Fig. 7. R1-R3 are defined over universal set G 1 ,R4-R6 over G ,and R7 over G 3 . These redescriptions were selected for both their biological interest as well as for their feature construction novelties. The proteins encoded by genes in a redescription may interact with one another or ,with other proteins not included in the redescription. Such analyses make it possible to uncover cryptic and subtle features of gene expression and regulation.

R1 is a redescription where both sides involve descriptors from gene expression bucketing. It relates negatively ex-pressed ORFs in the histone depletion experiment with sim-ilarly expressed ORFs in a Gasch comparison (heat shock). R1 can be read as  X  X f the 74 ORFs in the first universal set ,the ORFs negatively expressed in the histone deple-tion experiment (6 hours) are also those that are negatively expressed two-fold or more in the heat shock (10 minutes) experiment. X  This redescription holds with a Jaccard X  X  coef-ficient of 0.78. Since each side contains a single descriptor, this redescription does not present any set construction. R1 involves 7 ORFs ,three of which are reported to be regulated by similar mechanisms ,according to the work of Segal et al. ([17]). These ORFs comprise functions related to meta-bolism ,catalytic activity ,and are located in the cytoplasm. The Pearson coefficients for these ORFs in the histone de-pletion experiments match very strongly ,showcasing the use of redescription in identifying a concerted set of ORFs.
R2 relates a k-means cluster to a set difference of two re-lated GO cellular component categories. While the 8 ORFs in R2 appear to be part of different response pathways ,5 of these 8 ORFs are similarly regulated according to the work of Segal et al.; these genes relate to the cellular hy-perorganization and membrane dynamics in the regulation network.

R3 is actually a triangle of redescription relationships that illustrates the power of CARTwheels. Three different exper-imental comparisons are involved in this circular chain of redescriptions ,with 10 ORFs being implicated in all three descriptors. From a biological standpoint ,this is a very in-teresting result  X  the common genes indicate concerted par-ticipation across stress conditions; whereas the genes par-ticipating in ,say ,two of the descriptors ,but not the third , suggest a careful diversification of functionality. 6 of the 10 ORFs are related to cell growth and maintenance. 5 of the 10 ORFs have binding motifs related to the DNA binding protein REB1. The importance of phosphate and ribosomes appears to be salient in this redescription. It is important to note that the circularity of R3 is not directly mined by CARTwheels ,but inferred post-hoc from a linear chain. The theme in R4 is ribosome assembly/biogenesis and RNA processing. R4 is a linear chain comprising two re-descriptions ,and uses a GO descriptor as an intermediary between two expression-based descriptors. It is also inter-esting that this redescription involves a set of 45 ORFs!
R5 is an even longer chain involving 41 ORFs that are common to all descriptors. Notice the rather complicated set construct involving a disjunction of a conjunction and a difference ,involving three different GO biological categories. Incidentally ,this is the most complicated set expression rep-resentable in a 2-level tree.

R6 is a relationship between two k-means clusters ,be-tween heat shock stresses. The ORFs participating in R6 demonstrate a clear focus on sugar or sugar phosphate meta-bolism.

R7 is a redescription relating a disjunction of descriptors to a GO cellular component category. It is also our first ex-ample of a redescription where a rectangular region is mined in a 2D space involving two different experimental compar-isons. Usually such a region would require a 4-level tree ,but since it is bounded by the extremal values specific to each experiment ,it can be captured by a conjunction of merely two descriptors.
If we view the alternation process as one of information retrieval ,we can adapt traditional precision and recall met-rics for algorithm assessment. Precision here refers to the number of unique redescriptions as a fraction of the total number of redescriptions mined. Recall refers to the num-ber of unique redescriptions as a fraction of the total number of redescriptions possible. Unfortunately ,the latter metric is nearly impossible to attain ,even for our depth limit of 2. For even the smallest universal set considered here ,the size of the space of possible redescriptions is O (10 14 )! Our approach hence is to track precision and the total number of redescriptions ,across various values of  X  .Fig.9shows the monotonic decrease of precision as  X  is increased ,and Fig. 10 depicts the steady increase in the total number of redescriptions mined. These graphs indicate that the trade-off between redundancy and exploration holds across all the to the redescription. R1-R3 are defined over universal set G ORFs, whereas others such as R5 involve larger numbers. datasets considered here. A formal characterization is un-derway.

The effect of  X  parameter ,that controls the number of unsuccessful consecutive alternations ,is as expected: in-creasing  X  results in a greater number of (total and unique) redescriptions mined (not shwon for space considerations).
This paper is a first exploration into the formulation of the redescription mining problem and has presented an ap-proach for mining redescriptions automatically. Redescrip-tions can be thought of as generalizations of one-directional implications (e.g. ,association rules [1] ,rules in ILP [14]) , where one descriptor is required to be a proper subset of the other. This generalization coupled with the automatic iden-tification of set-theoretic constructions makes CARTwheels a very powerful approach to mining (approximate) equiva-lence relations. We have demonstrated the effectiveness of CARTwheels in a domain that exhibits a richness of descrip-tors ,and shown how it captures patterns involving small as well as large sets of objects.

The work presented here has close connections with ideas pursued in the schema matching [16] ,clustering categorical data [6] ,and model management [2] literature. The relation-ships considered in schema matching research are primarily of the foreign key nature or otherwise operate at the instance level ,whereas we consider more complex set-theoretic rela-tionships. Clustering categorical data focuses on defining similarity measures in non-metric spaces and this research can be fruitfully integrated with our work. However ,notice that we are not merely clustering data but also imposing de-scribability constraints. Model management is a framework that recognizes the complex inter-relationships that would exist in multi-database enterprises and provides union ,in-tersection ,and difference operators for reconciliation ,inte-gration ,and migration purposes. The relationships here are assumed to be user provided ,and the emphasis is on actually  X  X xecuting a redescription. X  CARTwheels can thus be use-fully employed here as a driver for determining what these relationships should be.

We now outline some directions for future research. The connection between Jaccard X  X  coefficient and algorithmic dri-ver parameters (such as entropy) deserves further study. Other ways of evaluating redescriptions [10 ,11] are also per-tinent here (e.g. ,Dice coefficient) and some of these could support more efficient tree-based algorithms than the Jac-card X  X  coefficient. Ideally ,an evaluation metric would obey some closure properties in the space of redescriptions ,which can be used to configure an exploration strategy. In addi-tion ,it is preferable that an evaluation metric lend itself to the design of a statistical test of significance for redescrip-tions.

Thus far ,we have assumed a  X  X lat X  organization of the given descriptors and do not recognize any structural rela-tionships between them. However ,some descriptor vocabu-laries (e.g. ,derived from GO) enjoy a hierarchical structure , which can be exploited by the mining algorithm. Specialized redescription algorithms can thus be designed for targeted descriptor families.

There are various other formulations of the redescription mining problem ,in particular the question of identifying a generating set of redescriptions is open. This will avoid hav-ing to find all redescriptions and instead allow us to exploit the algebraic structure of descriptors ,akin to the strategy pursued by Zaki for mining a non-redundant set of associa-tion rules [21].

There is an intrinsic limit to a dataset X  X  potential to re-veal redescriptions ,which can be studied through statistical analysis of set size distributions and estimates of overlap potential. Of particular interest here is qualifying the  X  X x-pected X  results from a CARTwheels alternation before ac-tually performing the alternation ,using notions such as the entropy rate of the stochastic process underlying the alter-nation [4].

Our current focus is on using redescriptions to automati-cally span multiple levels of abstraction (e.g. ,gene subsets pathways  X  biological processes). This would firmly estab-lish the importance of redescription in bridging the diverse levels at which information is created and characterized. NR and DK are supported by NSF grants EIA-9984317 and EIA-0103660. The work of MP and RH is supported through the Multidisciplinary University Research Initiative (MURI) program of the Department of Defense (Biomimetic Cell and Tissue Stasis; N00014-01-1-0852) and the Metabolic Engi-neering for Cellular Stasis program of DARPA (N00173-98-1-G005-P00004 and N00173-02-1-G016). BM is supported by grants from NSF X  X  ITR ,QuBIC ,and SGER programs , DARPA ,the US Air Force (AFRL) ,National Institutes of Health (NIH) ,and New York State Office of Science ,Tech-nology &amp; Academic Research (NYSTAR). We thank Chris Bailey-Kellogg and T.M. Murali for useful comments. [1] R. Agrawal and R. Srikant. Fast Algorithms for [2] P.A. Bernstein ,R. Pottinger ,and A.Y. Halevy. A [3] L. Breiman ,J.H. Friedman ,R.A. Olshen ,and C.J. [4] T.M. Cover and J.A. Thomas. Elements of [5] D.H. Fisher. Knowledge Acquisition via Incremental [6] V. Ganti ,J. Gehrke ,and R. Ramakrishnan. CACTUS: [7] V. Ganti ,J. Gehrke ,and R. Ramakrishnan. Mining [8] A.P. Gasch ,P.T. Spellman ,C.M. Kao , [9] J. Gehrke ,R. Ramakrishnan ,and V. Ganti.
 [10] J.C. Gower and P. Legendre. Metric and Euclidean [11] W.P. Jones and G.W. Furnas. Pictures of Relevance: [12] R.S. Michalski. Knowledge Acquisition through [13] A.W. Moore and M.S. Lee. Cached Sufficient [14] S. Muggleton. Scientific Knowledge Discovery using [15] J.R. Quinlan. C4.5: Programs for Machine Learning . [16] E. Rahm and P.A. Bernstein. A Survey of Approaches [17] E. Segal ,M. Shapira ,A. Regev ,D. Pe X  X r ,D. Botstein , [18] A. Sturn ,J. Quackenbush ,and Z. Trajanoski. Genesis: [19] R.E. Valdes-Perez ,V. Pericliev ,and F. Pereira. [20] J.J. Wyrick ,F.C. Holstege ,E.G. Jennings ,H.C. [21] M. Zaki. Generating Non-Redundant Association
