 The goal of information extraction (IE) is to ex-tract structured information from unstructured natu-ral language documents. Pattern induction to gener-ate extraction patterns from a number of training in-stances is one of the most widely applied approaches for IE.

A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training in-stances are parsed by dependency analyzer and con-verted into dependency trees. Each subtree of a de-pendency tree is considered as a candidate of ex-traction patterns. An extraction pattern is gener-ated by selecting the subtree which indicates the de-pendency relationships of each labeled slot value in the training instance and agrees on the selec-tion criteria defined by each pattern representation model. A number of dependency tree-based pat-tern representation models have been proposed. The predicate-argument (SVO) model allows subtrees containing only a verb and its direct subject and object as extraction pattern candidates (Yangarber, 2003). The chain model represents extraction pat-terns as a chain-shaped path from each target slot value to the root node of the dependency tree (Sudo et al., 2001). A couple of chain model patterns shar-ing the same verb are linked to each other and con-struct a linked-chain model pattern (Greenwood and Stevenson, 2006). The subtree model considers all subtrees as pattern candidates (Sudo et al., 2003).
Regardless of the applied pattern representation model, the methods have concentrated on extracting only exactly equivalent subtrees of test instances to the extraction patterns, which we call hard pattern matching. While the hard pattern matching policy is helpful to improve the precision of the extracted results, it can cause the low recall problem. In or-der to tackle this problem, a number of soft pattern matching approaches which aim to improve recall with minimized precision loss have been applied to the linear vector pattern models by introducing a probabilistic model (Xiao et al., 2004) or a sequence alignment algorithm (Kim et al., 2008).

In this paper, we propose an alternative soft pattern matching method for IE based on a local tree alignment algorithm. While other soft pattern matching approaches have been able to handle the matching among linear vector instances with fea-tures from tree structures only, our method aims to directly solve the low recall problem of tree-to-tree pattern matching by introducing the local tree align-ment algorithm which is widely used in bioinformat-ics to analyze RNA secondary structures. Moreover, we present an effective policy for controlling degree of flexibility in the pattern matching by setting the optimal threshold values for each extracted pattern. The low recall problem of information extraction based on hard pattern matching is caused by lack of flexibility in pattern matching. For example, the tree pattern in Figure 1(a) cannot be matched with the tree in Figure 1(b) by considering only exactly equivalent subtrees, because the first tree has an ad-ditional root node  X  X aid X  which is not in the second one. However, the matching between two trees can be performed by omitting just a node as shown in Figure 1(c).

In order to improve and control the degree of flex-ibility in tree pattern matching, we have adopted a local tree alignment approach as the pattern match-ing method instead of hard pattern matching strat-egy. The local tree alignment problem is to find the most similar subtree between two trees.

We have adopted the Hochsmann algorithm (Hochsmann et al., 2003) which is a local tree align-ment algorithm used in bioinformatics to analyze RNA secondary structures. The goal of the Hochs-mann algorithm is to find the local closed forest alignment which maximizes the similarity score for ordered trees. The algorithm can be implemented by a dynamic programming approach which solves a problem based on the previous results of its subprob-lems. The main problem of Hochsmann algorithm is to compute the similarity score between two sub-forests according to the defined order from the sin-gle node level to the entire tree level. The similarity score is defined based on three tree edit operations which are insertion, deletion, and replacement (Tai, 1979). For each pair of subforests, the maximum similarity score among three edit operations is com-puted, and the kind and the position of performed edit operations are recorded.

The adaptation of Hochsmann algorithm to the IE problem is performed by redefining the  X  -function, the similarity score function between two nodes, as follows:  X  ( v,w ) = where v and w are nodes to be compared, lnk( v ) is the link label of v , lbl( v ) is the node label of v , and p ( v ) denotes a parent node of v . While general local tree alignment problems consider only node labels to compute the node-level similarities, our method considers not only node labels, but also link labels to the head node, because the class of link to the head node is important as the node label itself for depen-dency trees. Moreover, the method should consider the alignment of slot value nodes in the tree patterns for adopting information extraction tasks. If the pat-tern node v is a kind of slot value nodes, the similar-ity score between v and w is inherited from parents of both nodes.

After computing for all pairs of subforests, the optimal alignment is obtained by trace-back based on the recorded information of edit operation which maximizes the similarity score for each subforest pair. On the optimal alignment, the target node aligned to a slot value node on the pattern is regarded as an argument candidate of the extraction. Each ex-traction candidate has its confidence score which is computed from the alignment score, defined as: where | T | denotes the total number of nodes in tree T and S ( T computed by Hochsmann algorithm.

Only the extraction candidates with alignment score larger than the given threshold value,  X  , are accepted and regarded as extraction results. For the simplest approach, the same threshold value,  X  , can be applied to all the patterns. However, we assumed that each pattern has its own optimal threshold value as its own confidence score, which is different from other patterns X  threshold values. The optimal thresh-old value  X  pattern P where eval fscore ( D,P, X  ) is the evaluation result in F-score of the extraction for the data set D using the pattern P with the threshold value  X  . For each pat-tern, the threshold value which maximizes the eval-uation result in F-score for the training data set and the maximum evaluation result in F-score are as-signed as the optimal threshold value and the con-fidence score for the pattern respectively. In order to evaluate the effectiveness of our method, we performed an experiment for the scenario tem-plate extraction task on the management succession domain in MUC-6. The task aims to extract sce-nario template instances which consist of person-in, person-out, position, organization slot values from news articles about management succession events. We used a modified version of the MUC-6 corpus including 599 training documents and 100 test doc-uments described by Soderland (1999). While the scenario templates on the original MUC-6 corpus are labeled on each document, this version has sce-nario templates for each sentence.

All the sentences in both training and test documents were converted into dependency trees dency trees and scenario templates on the training data, we constructed pattern candidate sets for four types of pattern representation models which are SVO, chain, linked-chain, and subtree models. For each pattern candidate, corresponding confidence score and optimal threshold value were computed.
The pattern candidates for each pattern represen-tation model were arranged in descending order of confidence score. According to the arranged order, each pattern was matched with test documents and the extracted results were accumulated. Extracted templates for test documents are evaluated by com-paring with the answer templates on the test corpus.
The curves in Figure 2 show the relative perfor-mance of the pattern matching strategies for each pattern representation model. The results suggest that soft pattern matching strategy with optimal threshold values requires less number of patterns for the performance saturation than the hard pat-tern matching strategy for all pattern models except the SVO model. For the SVO model, the result of soft pattern matching strategy is equivalent to that of hard pattern matching strategy. It is because most of patterns represented in SVO model are relatively shorter than those represented in other models.
In order to evaluate the flexibility controlling strategy, we compared the result of optimally de-termined threshold values with the cases of using various fixed threshold values. Table 1 represents the final results for all pattern representation mod-els and threshold values. For the SVO model, all the results are equivalent regardless of the thresh-old strategy because of extremely short length of the patterns. For the other pattern models, precisions are increased and recalls are decreased by increasing the threshold. The maximum performances in F-score are achieved by our optimal threshold determining strategy for all pattern representation models. The experimental results of our method show the better recall than the cases of hard pattern matching and controlled precision than the cases of extremely soft pattern matching. We presented a local tree alignment based soft pat-tern matching approach for information extraction. The softness of the pattern matching method is con-trolled by the threshold value of the alignment score. The optimal threshold values are determined by self-evaluation on the training data. Experimental results indicate that our soft pattern matching approach is helpful to improve the pattern coverage and our threshold learning strategy is effective to reduce the precision loss followed by the soft pattern matching method.

The goal of local tree alignment algorithm is to measure the structural similarity between two trees. It is similar to the kernel functions in the tree kernel method which is another widely applied approach to solve the IE problems. In the future, we plan to in-corporate our alignment-based soft pattern matching method into the tree kernel method for IE.
 This work was supported by the Korea Science and Engineering Foundation(KOSEF) grant funded by the Korea government(MEST) (No. R01-2008-000-20651-0)
