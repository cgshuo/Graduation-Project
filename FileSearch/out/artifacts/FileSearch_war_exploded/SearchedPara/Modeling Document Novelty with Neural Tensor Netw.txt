 Search result diversification has attracted considerable at-tention as a means to tackle the ambiguous or multi-faceted information needs of users. One of the key problems in search result diversification is novelty , that is, how to mea-sure the novelty of a candidate document with respect to other documents. In the heuristic approaches, the prede-fined document similarity functions are directly utilized for defining the novelty. In the learning approaches, the nov-elty is characterized based on a set of handcrafted features. Both the similarity functions and the features are difficult to manually design in real world due to the complexity of modeling the document novelty. In this paper, we propose to model the novelty of a document with a neural tensor net-work. Instead of manually defining the similarity functions or features, the new method automatically learns a nonlin-ear novelty function based on the preliminary representation of the candidate document and other documents. New di-verse learning to rank models can be derived under the rela-tional learning to rank framework. To determine the model parameters, loss functions are constructed and optimized with stochastic gradient descent. Extensive experiments on three public TREC datasets show that the new derived algo-rithms can significantly outperform the baselines, including the state-of-the-art relational learning to rank models. search result diversification; neural tensor network; rela-tional learning to rank
In web search, it has been widely observed that a large fraction of queries are ambiguous or multi-faceted. Search result diversification has been proposed as a way to tackle this problem and diverse ranking is one of the central prob-lems. The goal of diverse ranking is to develop a ranking Corresponding author: Jun Xu.
 model that can sort documents based on their relevance to the given query as well as the novelty of the information in the documents. Thus, how to measure the novelty of a can-didate document with respect to other documents becomes a key problem in the designing of the diverse ranking models.
Methods for search result diversification can be catego-rized into heuristic approaches and learning approaches. The heuristic approaches construct diverse rankings with heuris-tic rules [3, 8, 14, 24, 25, 26]. As a representative model, the maximal marginal relevance (MMR) [3] formulates the construction of a diverse ranking as a process of sequential document selection. At each iteration the document with the highest marginal relevance is selected. The marginal relevance consists of the relevance score and novelty score. The novelty score is calculated based on a predefined doc-ument similarity function. Thus, the selection of the docu-ment similarity function becomes a critical issue for MMR. Different choices of the similarity functions result in different ranking lists. Usually it is difficult to define an appropriate similarity function in a real application.

Recently, machine learning models have been proposed and applied to the task of search result diversification [17, 20, 23, 28, 32]. The basic idea is to automatically learn a diverse ranking model from the labeled training data. Rela-tional learning to rank is one of the representative framework in this field. In relational learning to rank, the novelty of a document with respect to the previously selected documents is encoded as a set of handcrafted novelty features. Several algorithms have been developed under the framework and state-of-the-art performances have been achieved [28, 32]. However, it is still an unsolved problem to define a set of novelty features which can effectively capture the complex document relationship. Unlike the designing of relevance features in conventional learning to rank, it is much more difficult to extract novelty features for search result diver-sification. Currently, a very limited number of novelty fea-tures can be utilized when constructing a diverse ranking model. For example, in R-LTR [32] and PAMM [28], the novelty of a document is characterized with only seven nov-elty features. Most of the features are based on the cosine similarities of two documents represented with tf-idf vectors or topic vectors. Thus, it is very difficult, if not impossible, for users to handcraft an optimal set of novelty features for search result diversification.

To address above problems and inspired by the neural models for relation classification [27], we propose to model the document novelty for search result diversification using a neural tensor network (NTN). Unlike existing methods which manually define the document similarity functions or novelty features, the method automatically learns a non-linear document novelty function from the training data. It first generates the novelty signals with a nonlinear ten-sor layer, through interacting the candidate document with other documents. Then, a max-pooling operation is applied to select the most effective novelty signals. Finally, the se-lected signals are combined linearly to form the final docu-ment novelty score.

New diverse ranking models, then, can be proposed under the relational learning to rank framework. The marginal relevance in relational learning to rank, which is used for selecting the best document at each step, is calculated as a sum of the query-document relevance score and document novelty score. Modeling the document novelty score with the proposed neural tensor network, we can achieve new diverse ranking models. On the basis of existing relational learning to rank algorithms of R-LTR and PAMM, two new loss func-tions are constructed and optimized, achieving two novel di-verse ranking algorithms of R-LTR-NTN and PAMM-NTN.
To evaluate the effectiveness of the proposed algorithms, we conducted extensive experiments on three public TREC benchmark datasets. The experimental results showed that our proposed algorithms, including R-LTR-NTN and PAMM-NTN, can significantly outperform the state-of-the-art base-lines including heuristic approaches of MMR, and learning approaches of SVM-DIV [29], R-LTR, and PAMM. Analysis showed that the proposed approaches achieved better results through learning better document dissimilarities in terms of distinguishing the documents with different subtopics. Thus, the proposed algorithms have the ability to improve the queries with high ambiguity.

Contributions of the paper include: 1) We proposed to model the document novelty with a neural tensor network, which enables us to get rid of the manually defined similar-ity functions or handcrafted novelty features in search re-sult diversification; 2) Based on the new document novelty model, two diverse ranking algorithms were derived under the framework of relational learning to rank; 3) The effec-tiveness of the proposed algorithms were verified based on public benchmark datasets.

The rest of the paper is organized as follows. After a summary of related work in Section 2, we present the neural tensor network model for measuring document novelty in Section 3. Section 4 presents the two derived diverse ranking algorithms under the relational learning to rank framework. Experimental results and discussions are given in Section 5. Section 6 concludes the paper and gives future directions.
This paper concerns about the ranking models for search result diversification. Existing methods can be categorized into heuristic approaches and learning approaches. One of the central problems in both of these two approaches is nov-elty, that is, how to model the novelty information of a doc-ument with respect to other documents.
It is a common practice to use heuristic rules to construct a diverse ranking list in search. Usually, the rules are cre-ated based on the observation that in diverse ranking a doc-ument X  X  novelty depends on not only the document itself but also the documents ranked in previous positions. Carbonell and Goldstein [3] proposed the maximal marginal relevance criterion to guide the design of diverse ranking models. The criterion is implemented with a process of iteratively select-ing the documents from the candidate document set. At each iteration, the document with the highest marginal rel-evance score is selected, where the score is a linear combi-nation of the query-document relevance and the maximum distance of the document to the documents in current re-sult set, in another word, novelty. The marginal relevance score is then updated in the next iteration as the number of documents in the result set increases by one. A number of methods have been developed under the criterion. PM-2 [8] treats the problem of finding a diverse search result as find-ing a proportional representation for the document ranking. xQuAD [26] directly models different aspects underlying the original query in the form of sub-queries, and estimates the relevance of the retrieved documents to each identified sub-query. Hu et al. [14] proposed a diversification framework that explicitly leverages the hierarchical intents of queries and selects the documents that maximize diversity in the hierarchical structure. See also [2, 4, 10, 11, 12, 22]
All of these heuristic approaches rely on a predefined doc-ument similarity (or distance) function to measure the nov-elty of a document. Thus, the selection of the similarity function is critical for the ranking performances. Usually it is hard to design an optimal similarity function for a specific task. In this paper, we focus on the learning approaches to estimate the novelty scores of documents.
Machine learning techniques have been applied to con-struct ranking models for search result diversification. In these approaches, the relevance features and novelty features are extracted for characterizing the relevance and novelty in-formation of a document, respectively. The ranking score is usually a linear combination of these features and the pa-rameters can be automatically estimated from the training data. Some promising results have been obtained. For ex-ample, Zhu et al. [32] proposed the relational learning to rank framework in which the diverse ranking is constructed with a process of sequential document selection. The train-ing of a relational learning to rank model thus amounts to optimizing the object function based on the ground-truth rankings. With different definitions of the object functions and optimization techniques, different diverse ranking al-gorithms have been derived [28, 32]. Radlinski et al. [23] proposed online learning algorithms that directly learn a di-verse ranking of documents based on users X  clicking behav-iors. More works please refer to [17, 20, 30].

Most learning approaches depend on a set of handcrafted novelty features to represent the novelty of a document. Construction of such features is usually difficult and time consuming in real applications. In real world, we have a very limited number of novelty features, which greatly lim-its the usability of these diverse ranking models. In this paper, we propose to automatically learn the novelty with a neural tensor network and enhance the usability of the diverse ranking algorithms.
Inspired by the neural models for relation classification, in Figure 1: Visualization of the neural tensor network for this paper we propose to use neural tensor network to model the novelty of a document w.r.t. a set of other documents.
In deep learning literature, neural tensor networks (NTN) is originally proposed to reason the relationship between two entities in knowledge graph [27]. Given two entities ( e represented with l e dimensional features, the goal of NTN is to predict whether they have a certain relationship R . Specifically, NTN computes a score of how likely it is that these two entities are in certain relationship R by the fol-lowing function: product e T 1 W [1: z ] R e 2 results in a vector h  X  R z entry of h is computed by one slice i ( i = 1 ,  X  X  X  ,z ) of the tensor: h i = e T 1 W [ i ] R e 2 . The other parameters for relation R are the standard form of a neural network: V R  X  R z  X  2 l  X 
R  X  R z , and b R  X  R z . Figure 1 illustrates the neural tensor network with two slices for entity relationship reasoning.
Intuitively, the neural tensor networks model the relation-ships between two entities with a bilinear tensor product. The idea can be naturally extended to model the novelty relation of a document with respect to other documents for search result diversification. That is, we can represent the novelty information of a candidate document as a bilinear tensor product of the document and other documents, as shown in Figure 2.

More specifically, suppose that we are given a set of M documents X = { d j } M j =1 , where each document d j can be characterized with its preliminary representation v j  X  R l e.g., the topic distribution [9, 13] of d j or the document vector generated with a doc2vec [15] model. Given a candi-date document d  X  X with its preliminary presentation v , and a set of documents S  X  X \{ d } with their preliminary respect to the documents in S can be defined as a neural tensor network with z hidden slices: where each column in matrix v 1 ,..., v | S |  X  R l v  X | S | Figure 2: Visualization of the neural tensor network for for the preliminary representation vector of the correspond-ing document in S , W [1: z ]  X  R l v  X  l v  X  z is a tensor, and  X   X  R z the weights correspond to the slices of the tensor. As shown in Figure 2, the neural tensor network consists of a tensor layer, a max-pooling layer, and a linear layer.
Tensor Layer : The tensor layer takes the preliminary representations of the documents as inputs. The interactions between the document d and documents in S are represented as a bilinear product followed by a nonlinear operation: where h i  X  R | S | is computed by one slice of the tensor.
Compared with the original neural tensor network in Sec-tion 3.1, the tensor in Equation (1) models the relationship between one document and multiple documents simultane-ously. Thus, the output of Equation (1) is a z  X | S | matrix rather than a z -dimensional vector. Also, since the number of documents in S varies in different document selection it-erations, the term V R e 1 e network is ignored. Moreover, in ranking we cares about the order of the documents rather than the ranking scores. Thus, the bias term b R is also ignored.

Max-pooling Layer : In the max-pooling layer, the ma-trix outputted by the tensor layer is mapped to a z -dimensional vector with the max operation: Intuitively, the pooling layer aggregates individual novelty signal learned at each tensor layer h T i . Max-pooling extracts the most significant signals among them. Thus, vector t can be considered as a the z -dimensional novelty features and each dimension is defined by one slice of the tensor.
Linear Layer : Finally, the novelty score of the document is calculated as a linear combination of the novelty signals outputted by the max-pooling layer:  X  T t , where  X  is an z -dimensional parameter vector.
New diverse ranking algorithms can be derived based on the proposed neural tensor network for modeling document novelty. In this paper, we propose two algorithms under the framework of relational learning to rank. Algorithm 1 Ranking via maximizing marginal relevance 2: for r = 1 ,  X  X  X  ,M do 5: end for 6: return Y
The relational learning to rank framework [32] formalizes the ranking of documents as a process of sequential docu-ment selection and defines the marginal relevance as linear combination of the relevance score and the novelty score. Formally, let X = { d 1 ,  X  X  X  ,d M } denotes the set of docu-ments retrieved by a query q . For each query-document pair ( q,d i ), relevance feature vector x i  X  R l x is extracted. Let R  X  R M  X  M  X  K denotes a 3-way tensor representing relation-ships between the documents, where R ijk stands for the k -th feature of relationship between documents d i and d j suming that a set of documents S have been selected in the previous iterations, the marginal relevance of the i -th candi-date document with respect to S , denoted as f ( x i ,R i then defined as the combination of the relevance score and the novelty score: where  X  T r x i stands for the relevance score and  X  r is the rel-evance weight vector,  X  T n h S ( R i ) stands for the novelty score of the document with respect to S and  X  n is the diversity weight vector, R i stands for the matrix of relationships be-tween document x i and other documents, and h S ( R i ) stands for the aggregation function on R i which aggregates the ma-trix R i into a novelty feature vector. Usually, h S can be one of the operations of max, min, or average.

According to the maximal marginal relevance criterion, sequential document selection process can be used to cre-ate a diverse ranking, as shown in Algorithm 1. The algo-rithm initializes S 0 as an empty set, and then iteratively selects the documents from the candidate set. At iteration r ( r = 1 , 2 ,  X  X  X  ,M ), the document with the maximal marginal relevance score f ( x j ,R j ,S r  X  1 ) is selected and ranked at po-sition r . At the same time, the selected document is inserted
Given a set of training instances which consist of queries, documents, and their relevance labels, the model parame-ters can be learned from the training data. The process amounts to optimizing an objective function based on the training data. Different definitions of the objective func-tions and optimization techniques lead to different relational learning to rank algorithms. For example, in algorithm R-LTR [32], the likelihood of the training queries is maximized using stochastic gradient descent. In algorithm PAMM [28], the loss function upper bounding the diversity evaluation measure is constructed and optimized with structured Per-ceptron.

Relational learning to rank models depend on a set of handcrafted features for characterizing the novelty of a doc-ument. However, how to design the features that can ef-fectively capture the complex document relationship is still an unsolved problem. Unlike the conventional learning to rank in which a large number effective relevance features have been developed [21], it is much harder to find novelty features for search result diversification. As a result, the re-lational learning to rank algorithms of R-LTR and PAMM utilized only seven features in their experiments, as have listed in Table 1. We can see that most of these features are calculated based on the predefined similarities of two documents (represented as tf-idf vectors or topic distribu-tions), and respectively applied to the document fields of title, body, and anchor.

In real world applications, the performances of the rank-ing algorithms heavily depend on the effectiveness of these handcrafted features and different ranking tasks need differ-ent features. It is necessary to develop a method that can learn the document novelty automatically and release people from the handcrafted novelty features.
In this subsection, based on the technique of modeling the document novelty with neural tensor network, we develop two new relational learning to rank algorithms that can learn the document novelty function automatically.
Following the notations used in Section 3.2 and Section 4.1, let X = { d 1 ,  X  X  X  ,d M } denotes the set of documents retrieved by a query q . Each query-document pair ( q,d ) is represented with the relevance feature vector x  X  R l x . Each document d  X  X is characterized with its preliminary representation quential document selection, a set of documents S have been selected. We define the marginal relevance score of a candi-date document d as: f ( d,S ) = g r ( x ) + g n ( v ,S ) (4) where g r ( x ) is the relevance of d w.r.t. query q , which is further defined as a linear combination of the relevance fea-tures; g n ( v ,S ) is the novelty of d w.r.t. the documents in S , which is further defined as a neural tensor network, as have been shown in Section 3.2. The model parameters  X  ,  X  , and W [1: z ] can be learned with the training data.

In the online ranking, a diverse ranking can created with the sequential document selection process, similar to the pro-cedure shown in Algorithm 1. http://www.dmoz.org
The main advantage of using neural tensor network to model document novelty is that the tensor can relate the candidate document and the selected documents multiplica-tively, instead of only through a predefined similarity func-tion (as that of in heuristic approaches) or through a linear combination of novelty features (as that of in learning ap-proaches and shown in Equation (3)). Intuitively, the model can be explained that each slice of the tensor is responsi-ble for one aspect or subtopic of a query. Each tensor slice settles the diversity relationship between the candidate doc-ument and the selected documents set differently. Thus, with multiple tensor slices, the model calculates the novelty scores based on multiple diversity aspects.
The parameters of the ranking model can be determined with supervised learning methods, which amounts to opti-mizing the objective function built upon the labeled training data.

In training procedure, given the labeled data with N queries { d related with the n -th query. Let x ( n ) j  X  R l x denote the rele-vance feature vector for the n -th query and document d ( n ) v and J ( n ) the human labels on documents which is in the form of a binary matrix. J ( n ) js = 1 if document d tains the s -th subtopic of the query and 0 otherwise 2 . The learning process amounts to minimizing the total loss with respect to the given training data: where  X  X ( n ) ,f denotes the ranking generated by the ranking model f in Equation (4), for the documents in X ( n ) The generated ranking  X  is then compared with the human labels J ( n ) by the loss function ` . Intuitively, the learn-ing process can be interpreted as finding an optimal ranking model f from some functional space F so that for each train-ing query the difference between the generated permutation  X  and the human labels J is minimal.

Different objective functions and optimization techniques lead to different algorithms. In this section, based on the relational learning to rank algorithms of R-LTR [32] and PAMM [28], we construct two novel algorithms in which the document novelty is modeled with a neural tensor network, referred to as R-LTR-NTN and PAMM-NTN, respectively.
Based on the loss function defined for R-LTR [32], we derive the loss function of R-LTR-NTN, which is a negative logarithm likelihood of the training queries: where Y ( n ) is the ground-truth ranking generated from the human label J ( n ) . For any query, the probability Pr( Y | X ) In this paper we assume that all labels are binary. Algorithm 2 The R-LTR-NTN Algorithm 2: repeat 3: Shuffle the training data 4: for n = 1 ,  X  X  X  ,N do 9: end for 10: until convergence can be further defined as where Y ( r ) denotes the index of the document ranked at ranked at the top r  X  1 positions in Y , f ( d Y ( r ) the marginal relevance score of document d Y ( r ) w.r.t. the selected documents in S r  X  1 , as defined in Equation (4), and S 0 is an empty set.

Stochastic gradient descent is adopted to conduct the op-timization. Given a query q , the retrieved documents X = { d j } M j =1 , and the ranking Y generated by the ground-truth labels, the gradient of the model parameters can be written as  X   X  = where t is defined in Equation (2), and where  X   X  R l v  X  l v and  X  i (1  X   X  i  X | S | ) stands for the output of the max-pooling position for the i -th (1  X  i  X  z ) tensor slice.

Algorithm 2 shows the pseudo code of the R-LTR-NTN.
Based on the loss function defined for PAMM [28], we derive the loss function of PAMM-NTN, which is directly defined over a diversity evaluation measure: where E (  X  ,  X  )  X  [0 , 1] is a diversity evaluation measure such as  X  -NDCG or ERR-IA etc. It can be proved that the Equation (10) is upper bounded by L . where Y ( n )+ and Y ( n )  X  are the sets of positive and neg-ative rankings generated from human labels J ( n ) , respec-tively. J  X  K is one if the condition is satisfied otherwise zero. Pr(  X | X  ) stands for the probability of the ranking, as defined in Equation (5).

Also, stochastic gradient descent is adopted to conduct the optimization. At each iteration, we are given a query q , the retrieved documents X = { d j } M j =1 , a positive ranking Y and a negative ranking Y  X  . For convenience of calculation, we resort to the optimization problem of max log Pr( Y + | X ) Thus, the gradients of the parameters can be written as where t is defined in Equation (2), and  X  is defined in Equa-tion (9). Algorithm 3 shows the pseudo code of the PAMM-NTN algorithm. We analyzed time complexities of R-LTR-NTN and PAMM-NTN. The learning process of R-LTR-NTN (Algorithm 2) is Algorithm 3 The PAMM-NTN algorithm 1: for n = 1 to N do 4: end for 6: repeat 7: for n = 1 to N do 12:  X   X   X  +  X   X  X   X  13:  X   X   X  +  X   X  X   X  15: end if 16: end for 17: end for 18: until convergence of order O ( T  X  N  X  M 2  X  ( l x + l v  X  Z )), where T denotes the num-ber of iterations, N the number of queries in training data, M the maximum number of documents per training query, l the number of relevance features, l v the dimensions of the preliminary document representation, and Z the number of tensor slices. The learning process of PAMM-NTN (Algo-rithm 3) is of order O ( T  X  N  X   X  +  X   X   X   X  M 2  X  ( l x + l where  X  + denotes the number of positive rankings per query and  X   X  the number of negative rankings per query.The time complexity of online ranking prediction (Algorithm 1) is of order O ( M  X  K  X  ( l x + l v  X  Z )), where M is the number of can-didate documents for the query and K denotes the number documents need to be ranked. We conducted experiments to test the performances of R-LTR-NTN and PAMM-NTN using three TREC bench-mark datasets for diversity task: TREC 2009 Web Track (WT2009), TREC 2010 Web Track (WT2010), and TREC 2011 Web Track (WT2011). Each dataset consists of queries, corresponding retrieved documents, and human judged la-bels. Each query includes several subtopics identified by the TREC assessors. The document relevance labels were made at the subtopic level and the labels are binary 3 . Statistics on the datasets are given in Table 2.
 All the experiments were carried out on the ClueWeb09 Category B data collection 4 , which comprises of 50 million English web documents. Porter stemming, tokenization, and stop-words removal (using the INQUERY list) were applied to the documents as preprocessing. We conducted 5-fold cross-validation experiments on the three datasets. For each dataset, we randomly split the queries into five even subsets.
The graded judgements in WT2011 was treated as binary. http://boston.lti.cs.cmu.edu/data/clueweb09 Table 2: Statistics on WT2009, WT2010 and WT2011.
 At each fold three subsets were used for training, one was used for validation, and one was used for testing. The results reported were the average over the five trials.

The TREC official evaluation metrics for the diversity task were used in the experiments, including the ERR-IA [5],  X  -NDCG [6], and NRBP [7]. They measure the diversity of a result list by explicitly rewarding novelty and penalizing redundancy observed at every rank. Following the default settings in official TREC evaluation program, the parame-ters  X  and  X  in these evaluation measures are set to 0.5. We also used traditional diversity measures of Precision-IA (de-noted as  X  X re-IA X ) [1], and Subtopic Recall (denoted as  X  X -recall X ) [31]. All of the measures are computed over the top-k search results ( k = 20).

We compared R-LTR-NTN and PAMM-NTN with sev-eral types of baselines. The baselines include three heuristic approaches to search result diversification.
 MMR [3] : a heuristic approach in which the document xQuAD [26] : a representative heuristic approach to search PM-2 [8] : a method of optimizing proportionality for search Note that these baselines require a prior relevance function to implement their diversification steps. In our experiments, ListMLE [16, 18] was chosen as the relevance function.
The baselines also include state-of-the-art learning ap-proaches to search result diversification.
 SVM-DIV [29] : a learning approach in which structural R-LTR [32] : a state-of-the-art learning approach devel-PAMM [28] : another state-of-the-art learning algorithm Following the practice in [32], for the baseline of R-LTR, we used the results of R-LTR min in which the relation function h ( R ) was defined as the minimal distance of the candidate document to the selected documents.

For the baseline PAMM (and our approach PAMM-NTN), we configure them to directly optimize  X  -NDCG@20 be-cause it is one of the most widely used performance mea-sures. Thus, the baseline of PAMM is denoted as PAMM(  X  -NDCG). Following the practice in [28], we set the number of sampled positive rankings per query  X  + = 5 and the number of sampled negative rankings per query  X   X  = 20.
As for the relevance features, we adopted the features used in R-LTR experiments [21], including the typical weighting Table 3: Relevance features used in the experiments. models (e.g., TF-IDF, BM25, LM) and term dependency model [19]. Table 3 summarized the relevance features. For all the query-document matching features, they were applied in five fields: body, anchor, title, URL, and the whole doc-ument, resulting in 5 features in total. Note that the MRF feature has two variations: ordered phrase and unordered phrase [19]. Thus the total number of MRF features be-comes 10.

The neural tensor network need preliminary representa-tions of the documents as its inputs. In the experiments, we used the document vector generated by the topic model of probabilistic latent semantic analysis (PLSA) [13] or the deep learning model of doc2vec [15], both are trained on all of the documents in ClueWeb09 Category B data col-lection and the number of latent dimensions are set to 100. For training the doc2vec model, we used the distributed bag of words (DBOW) model 5 . In all of the experiments, the learning rate is set to 0 . 025 and the window size is set to 8.
Our approaches (R-LTR-NTN and PAMM-NTN) with the settings of using the PLSA or doc2vec as document repre-sentations are denoted with the corresponding subscripts. For example, the R-LTR-NTN that using PLSA as docu-ment representations is denoted as R-LTR-NTN plsa . Thus, in all of the experiments, our approaches include R-LTR-NTN plsa , R-LTR-NTN doc2vec , PAMM-NTN(  X  -NDCG) plsa , and PAMM-NTN(  X  -NDCG) doc2vec . Please note in all of the experiments, PAMM-NTN was configured to direct optimize the evaluation measure of  X  -NDCG@20.
Table 4, Table 5, and Table 6 report the performances of the proposed methods and baselines in terms of 5 diver-sity metrics (ERR-IA@20,  X  -NDCG@20, NRBP@20, Pre-IA@20, and S-recall@20) on the datasets of WT2009 6 , WT2010, and WT2011, respectively. Boldface indicates the highest score among all runs. For all of our approaches, the number of tensor slices z is set to 7.

From the results we can see that, on all of the three datasets and in terms of the five diversity evaluation met-rics, our approaches (R-LTR-NTN plsa , R-LTR-NTN doc2vec , PAMM-NTN(  X  -NDCG) plsa , and PAMM-NTN(  X  -NDCG) doc2vec ) can outperform all of the baselines. We conducted signifi-cant testing (t-test) on the improvements of our approaches over the baselines. The results indicate that the improve-ments of R-LTR-NTN plsa and R-LTR-NTN doc2vec over R-LTR are significant (p-value &lt; 0 . 05), in terms of all of the http://radimrehurek.com/gensim/models/doc2vec.html
The performances of XQuAD reported in Table 4 are differ-ent to that of reported in [26]. It may caused by the different splitting of the dataset in cross validation. performance measures. The results also indicate that the improvements of PAMM-NTN(  X  -NDCG) plsa and PAMM-NTN(  X  -NDCG) doc2vec over all of the baselines are signifi-cant, in terms of all of the performance measures. The re-sults indicate that the neural tensor network is effective for modeling the document novelty information, and thus can improve the performances.
We conducted experiments to show the reasons that our approaches outperformed the baselines and impacts of differ-ent parameter settings, using the results of R-LTR-NTN plsa and R-LTR-NTN doc2vec on WT2009 dataset as examples.
We found that the learned neural tensor network can help to distinguish the relevant documents in terms of different subtopics, by learning a better dissimilarity (novelty) func-tion for documents. That is one of the reasons why our approaches can outperform the baselines.

Specifically, the dissimilarities between two documents can be calculated based on the preliminary document represen-tations, either using the Euclidean distance or using the learned neural tensor network (the novelty score of a doc-ument w.r.t. another document). That is, given two doc-uments represented with the preliminary presentations v and v j , the dissimilarity score can calculated either based on the Euclidean distance: or based on the learned neural tensor network: where  X  and W [1: z ] are learned with the R-LTR-NTN algo-rithms. Here we can ignore the max operation because there is only one document v j at the righthand of W [1: z ] .
Suppose we are given a set of queries and the associated relevant documents. For each query, the relevant documents can be grouped into several clusters, each corresponds a subtopic of the query. Thus, all of the associated docu-ments from all queries are grouped into different clusters, each corresponds to a subtopic. We calculated the ratio of average inter-cluster documents dissimilarities to average intra-cluster document dissimilarities. It is obvious that in search result diversification, a good document dissimilarity function would get large inter-cluster document dissimilar-ities and small intra-cluster document dissimilarities (large ratio value). This is because such a dissimilarity function could discriminate the subtopics well.

Table 7 shows the ratios calculated based on different dissimilarity definitions and different preliminary document representations. From the results, we can see that the ra-tio of  X  d n with PLSA X  (documents represented with PLSA topics and dissimilarities are calculated with neural tensor Table 7: Ratio of average inter-cluster documents dis-network) is larger than the ratio of  X  d e with PLSA X  (docu-ments represented with PLSA topics and dissimilarities are calculated as Euclidean distance), and the ratio of  X  d n doc2vec X  is larger than the ratio of  X  d e with doc2vec X . The results indicates that the dissimilarity functions learned by the tensor neural network are better than the Euclidean dis-tances, in terms of discriminating the query subtopics.
The conclusion is quite intuitive and nature because the parameters of neural tensor network are determined based on the labeled data and thus can be adapted to the spe-cific dataset and task, while the Euclidean distance is a pre-defined function for all datasets and tasks. Therefore, we can conclude that R-LTR-NTN (and also PAMM-NTN) can improve the performances through learning a better doc-ument dissimilarity function which distinguishes the docu-ments with different subtopics effectively.
We also conducted experiments to show on which kinds of queries our approaches can perform well. Specifically, in each fold of the experiments on WT2009, we trained an R-LTR-NTN doc2vec model, an R-LTR, and a PAMM(  X  -NDCG) model on the training data and tested them on the test data. We then grouped the queries in the test datasets according to the number of subtopics they associated. We compared the performances of these three models in terms of  X  -NDCG@20 on each of the query groups and the re-sults are shown in Figure 3. Boldface indicates the number of associated subtopics by the candidate documents, and the numbers in the parentheses indicate the proportion of queries in that group to the number of all queries. Please note that in Figure 3 some queries associated with only one or two subtopics while in Table 2 all queries have at least 3 subtopics associated. This is because we used the Indri toolkit to retrieve the top 1000 documents as the candidates. Some labeled documents may not be ranked at top 1000 and thus be eliminated from the candidate set.

From the results reported in Figure 3, we can see that for those queries that associated with only one or two subtopics, R-LTR-NTN performed worse than the baselines of R-LTR and PAMM(  X  -NDCG). However, for those queries that as-sociated with three or more subtopics (queries with high ambiguity), R-LTR-NTN outperformed the baselines. We also observed the trends that larger improvements R-LTR-NTN can achieve on the queries with more subtopics. The results is also intuitive because the document relations are more complex for ambiguous queries and neural tensor net-work can model the complex document relationship better. Thus, we can conclude that R-LTR-NTN can improve the baselines through improving the high ambiguity queries. http://lemurproject.org/indri F igure 3: Performances with respect to query groups F igure 4: Ranking accuracies and training time with
Finally, we conducted experiments to test if the proposed algorithms are sensitive to the model parameters. One of the most important parameters in the proposed method is the number of tensor slices z . Thus, in the experiments we tested if R-LTR-NTN doc2vec is sensitive to different settings of z values. Specifically, we tuned z by varying the values of parameter z from 1 to 19, with step 2 and fixing other model parameters to the default or optimal values. Figure 4 shows the performances of R-LTR-NTN doc2vec with respect to number of slices z , in terms of  X  -NDCG@20. The training time (in hours) with respect to z are also shown in the figure.
From the results, we can see that the performances did not change much with different z values, which indicates R-LTR-NTN doc2vec (and other proposed algorithms) are ro-bust and not sensitive to the parameter settings. In all of the experiments the number of tensor slices was set to the optimal value 7.

One of the negative effects of increasing z values is that the training time increased dramatically with the creased z values, as shown in Figure 4. This is because much more operations are needed for training the model if z is increased. Please refer to Section 4.2.5 for the time complexities of the proposed algorithms.
How to model the novelty of a candidate document with respect to other documents is one of the key problems in search result diversification. Existing approaches have been hurt from the necessaries of predefining a document simi-larity function or a set of novelty features, which are usu-ally hard in real applications. In this paper we proposed to model the novelty of a document with a neural tensor net-work, which enables us to automatically learns a nonlinear novelty function based on the preliminary representations of the candidate document and other documents. Under the framework of relational learning to rank, new diverse learning to rank models have been derived, by replacing the novelty term in the original objective function with the neu-ral tensor network. Experimental results based on three benchmark datasets showed that the proposed models sig-nificantly outperformed the baseline methods, including the state-of-the-art relational learning to rank models. Experi-mental results also showed that the proposed algorithms can improve the baselines via learning a document dissimilarity function that matches well with the query subtopics. The results also showed that more improvements can be achieved on the queries with high ambiguity.

As future work, we would like to verify the effectiveness of the proposed algorithms on applications other than search result diversification such as multi-document summarization etc. We also want to study the approaches to learning the relevance features and novelty features simultaneously.
The work was funded by the 973 Program of China un-der Grants No. 2014CB340401 and 2012CB316303, the 863 Program of China under Grants No. 2014AA015204, the National Natural Science Foundation of China (NSFC) un-der Grants No. 61232010, 61472401, 61433014, 61425016, and 61203298, the Key Research Program of the Chinese Academy of Sciences under Grant No. KGZD-EW-T03-2, and the Youth Innovation Promotion Association CAS un-der Grants No. 20144310 and 2016102.
