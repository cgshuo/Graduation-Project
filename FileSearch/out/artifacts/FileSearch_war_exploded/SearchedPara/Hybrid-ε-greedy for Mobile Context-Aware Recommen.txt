 Mobile technologies have made access to a huge collec tion of information, anywhere and anytime. Thereby, information is cust omized according to users X  needs and prefe-than the traditional navigation task. 
A considerable amount of research has been done in recommending relevant informa-information to the user in order to follow the evolution of his interest. 
In order to give Mobile Context-aware Recommender Systems (MCRS) the capa-(BA) and case-based reasoning (CBR) methods in order to tackle these two issues:  X 
Finding situations that are similar to the current one (CBR);  X 
Making the deal between exploring the user interests and recommending the most relevant content according to the current situation (BA). works. Section 3 presents the proposed recommendation algorithm. The experimental out possible directions for future work. We reference in the following recent relevant recommendation techniques that tackle the both issues namely: following the evolution of user X  X  interests and managing the user X  X  situation. 2.1 Following the Evolutio n of User X  X  Interests The trend today on recommender systems is to suggest relevant information to users, using supervised machine learning techniques. In these approaches, the recommender system has to execute two steps: (1) The learning step, where the system learns from samples are presented to the system to perform a generalization [14]. 
These approaches suffer from difficulty in following the evolution of the user X  X  in-quently. Besides, these seemingly optimal documents may in fact be suboptimal, due balance exploration and exploitation in the field of recommender systems. However, none of them consider the user X  X  situation during the recommendation. 2.2 Managing the User X  X  Situation Few research works are dedicated to manage the user X  X  situation on recommendation. ommend relevant content. 
Another work [2] describes a MCRS operating on three dimensions of context that complement each other to get highly targeted. First, the MCRS analyzes information history in order to improve the quality of the recommendations. 
Each work cited above tries to recommend interesting information to users on con- X 
Inspired by models of human reasoning developed by [7] in robotic, we propose to ing technique, which is not considered in [3, 4, 14].  X  tion/exploitation strategy, however they do not take into account the content in the strategy. Our intuition is that, considering the content when managing the explora-based filtering techniques together with  X  -greedy algorithm. tion, and then we detail our methods for inferring the recommendation. 3.1 Terminology and Notations ractions with the system. rences on the visited documents. We assume that a visited document is relevant, and through 2 types of preference:  X  rate, like for example putting stars ( X * X ) at the top of the document.  X 
The indirect preference: it is the informatio n that we extract from the user system interaction, for example the number of clicks or the time spent on the visited doc-uments. the number of times d was recommended, and the direct preference rate on d. the corresponding situations in order to exploit this data to improve the recommenda-tion process. meetings. Time and location information is automatically inferred by the system. the location (resp. time and social) dimension. phone X  X  GPS; the time "Mon Oct 3 12:10:00 2011" from his phone X  X  watch; and the abstracted concepts using on tologies reasoning means.  X  the situation.  X 
Time: To allow a good representation of the temporal information and its manipu-representing and reasoning about time. We propose to base our work on this ontol-ogy and extend it if necessary. Taking the example above, for the time value "Mon day X .  X  interlocutors (e.g. a friend, an important customer, a colleague or his manager). We use the FOAF Ontology [9] to describe the social network by a set of concepts and properties. For example, the information about  X  X he meeting with Paul Gerard X  can yield the value  X  X ine client X  for the social dimension. 3.2 The Bandit Algorithm In our MCRS, documents X  recommendation is modeled as a multi-armed bandit prob-t, the algorithm performs the following tasks:  X  and arm a, and is referred to as the context.  X  receives reward  X 
Task 3. It improves its arm-selection strategy with the new observation, ( ward r t,a ) is observed for unchosen arms a  X  a t . In tasks 1 to 3, the total T-trial reward of A is defined as  X  expected T-trial reward is defined as expected total reward is maximized. 
In the field of document recommendation, we may view documents as arms. When ward of a document is precisely its Click Through Rate (CTR). The CTR is the aver-age number of clicks on a recommended document, computed diving the total number of clicks on it by the number of times it was recommended. Consequently, choosing a the total expected rewards. 3.3 The Proposed Hybrid- X  -greedy Algorithm arms (probability =  X  ) or a random arms otherwise (probability = 1  X   X  ). rithm: integrating case base reasoning (CBR) and content based filtering (CBF). This tion/exploitation strategy. situation S of a mobile user when he navigates on his mobile device, while the value case from the case base is denoted as C= (S, UP). algorithm involves the following four methods. RetrieveCase() (Alg. 3 ) 
S s is selected from PS by computing the following expression as it done in [4]: scope of this paper, taking a value of 1 for all dimensions. or social). We use the same similarity measure as [12] defined by equation 2: of nodes in the path from the node to the ontology root. RecommendDocuments() (Alg. 3 ) In order to insure a better precision of the recommender results, the recommendation where B is a threshold value and () may improve the user X  X  satisfaction. 
The CBF algorithm (Alg. 2) computes the similarity between each document Algorithm 1. The RecommendDocuments() method Input:  X  , UP c , N Output: D D =  X 
For i=1 to N do q = Random({0, 1}) j = Random({0, 1}) argmax d (UP-D) (getCTR(d)) if j&lt;q&lt;  X  Random(UP c ) otherwise D = D  X  {d i } Endfor
Return D Algorithm 2. The CBF() m ethod Input: UP, d b
Output: d s d s = argmax Return d s UpdateCase() &amp; InsertCase().
 After recommending documents with the RecommendDocuments method (Alg. 3), the This is done by the UpdatePreferences function (Alg. 3). context, two scenarios are possible: Sc and the updated UP. thod updates the case having premise situation S c with the updated UP. Algorithm 3. hybrid- X  -greedy algorithm Input: B,  X  , N, PS, S s , UP s , S c , UP c Output: D 
D =  X  (S s , UP s ) = RetrieveCase(S c , PS) if sim(S c ,S s )  X  B then D = RecommendDocuments(  X  , UP s , N) UP c = UpdatePreferences(UP s , D) PS = InsertCase(S c , UP c ) PS = UpdateCase(S p , UP c ) else PS = InsertCase(S c , UP c ); end if
Return D of a standard evaluation framework, we propose an evaluation framework based on a present and discuss the obtained results. 4.1 Experimental datasets during their meetings (social information is extracted from the users X  calendar). 
The diary study took 8 months and generated 16 286 diary situation entries. Table ation 1 becomes as shown in Table 2. 
From the diary study, we obtained a total of 342 725 entries concerning user navi-expressed by stars (Interest), where the maximum stars is five. 4.2 Finding the Optimal B Threshold Value values. 
Figure 1 shows the effect of varying the threshold situation similarity parameter B larity measure for testing effectiveness of our MCRS presented below. 4.3 Experimental Datasets without executing the CBF. 
We evaluated these algorithms over a set of similar user situations using the optim-al threshold value identified above (B = 2.4). documents using CTR estimates obtained from the learning subset. 4.4 Results for  X  Variation results are obtained by a single run. had a smaller number of clicks. Moreover, when the parameter is too large, the algo-rithms seemed to over-explore and thus wasted some of the opportunities to increase each algorithm and run them once on the evaluation data. 
We can conclude from the plots that CBR information is indeed helpful for finding a greedy in the learning subset by selecting more attractive documents to recommend. 4.5 Valuate Sparse Data sizes of 30%, 20%, 10%, 5%, and 1%, respectively. 
To better visualize the comparison results, figures 4 and 5 show algorithms X  preci-ment subset (0.363) over the  X  -greedy X  X  one (0.174). This paper describes our approach for implementing a MCRS. Our contribution is to make a deal between exploration and exploitation for learning and maintaining user X  X  interests based on his/her navigation history. strategy significantly increases the performance of the recommender system following the user interests. tradeo ff.

