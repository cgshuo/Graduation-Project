 Online social services such as Twitter, Quora have been heavily used in recent years, the data produced by which is ever growing and has inspired many re-searchers to invest their efforts into text mining related tasks. Sentiment analysis of online texts has recently become a hot rese arch topic. Detecting the emotional tendencies could help ones better understand the public opinions and social be-haviors, thus to conduct corresponding financial and political decision making for enterprise and government [1].

The classification of semantic orientati on has shown its effectiveness for sen-timent analysis. In the literature, previous works mainly focus on two-class clas-sification (positive and negative emotion). However, the sentiments of human beings are complex in a variety of forms. In this paper, we propose a lexicon-based multi-class semantic orientation analysis for Sina Weibo posts. Sina Weibo is a popular Twitter-like micro-blogging serv ice in China with more than 600 million users. Firstly, based on the conventional classes( Joy, Blue, Anger, Fear )inpsy-chology study [2], we build up a sentiment lexicon with five categories( Concern, Joy, Blue, Anger, Fear ) for online texts sentiment detection. We argue that the adoption of new class Concern helps better capture the social behaviors and pub-lic concerns for the public events. The le xicon is based on the words extracted from the amount of randomly grabbed Sina Weibo posts and the semantic sim-ilarity presented in HowNet [3] -a WordNet-like lexical resource in Chinese. Accordingly, each post is represented a s a multi-dimensional numerical vector in feature space. Then we adopt a Semi-Supervised Gaussian Mixture Model (Semi-GMM) and a K-nearst neighbor (KNN) by using symmetric Kullback-Leibler divergence (KL-divergence) as the similarity measurement to classify the posts. We compare our proposed methodologies with the competitive baseline methods e.g., majority vote, KNN by using Cosine similarity and Support Vector Machine (SVM). The experimental evalua tion validates the effectiveness of our proposed methods. Semi-GMM is rather robust to noises and the small data set as compared with other approaches.

The remainder of the paper is organized as follows. Section 2 discusses the related work of semantic orientation analysis. Section 3 presents the details of the sentiment lexicon construction. Section 4 introduces why we divide the posts into 5 categories and the adaptive classification methods. The experimental results and performance evaluation are reported in Section 5. The conclusion and future work are presented in Section 6. Semantic orientation analysis of online texts has been attracting increasing at-tentions from researchers and widely adopted in many applications. Recent ad-vances in research often fall into two categories, lexicon-based approach and text classification-based approach. In general, lexicon-based approach achieves bet-ter performance than the text classification-based one [4] due to the leverage of typical sentiment words in lexicon. In this paper, other than developing a multi-class lexicon for Chinese Weibo posts, we adapt different learning approaches to classify the lexicon-based semantic vect ors so that the accuracy of the semantic orientation detection c an be further enhanced.

Lexicon is a pre-built and classified list of labeled words and emoticons. The sentiment lexicons are usually derived from thesaurus or knowledge base. Re-cently, the learning techniques are introduced to enrich the lexicon due to the emerging of out-of-vacabulary words from online social media. And most of the existing sentiment lexicons are built for the polarity classification (positive and negative sentiment) e.g., NRC hashtag sentiment lexicon and Sentiment140 lex-icon [5]. The NRC hashtag sentiment lexicon is created according to the positive and negative hashtags in the tweets such as # good ,# bad . While Sentiment140 lexicon is built according to the positive and negative emoticons. In addition to manually labeling the lexicon, researchers exploit various ways of automati-cally collecting the training data to build the lexicon with larger size and more accurate category assignment. In this paper, we develop a sophisticated Chi-nese sentiment lexicon by manually labeling the seed words. Then we adopt the semantic similarity between words d efined in HowNet to detect more words  X  X imilar X  to the seed words from the amount of corpus to extend the dictionary.
Intheliterature,thereexistlotsofrelatedworksfor thesentimentorientationde-tection. In [6], the authors demonstrate that a learning approach performs better than simply counting the positive and negative sentimental terms using a hand-crafted dictionary. P. Melville et al. [4] propose to combine background lexical in-formation with supervised learning to a chieve higher classification accuracy.
In [7], the authors adopt semi-Naive Bayes learning to classify the emotional intensity such as, very negative, negative, neutral, positive, very positive opinions towards a specific subject on the long texts. However, Naive Bayes is sensitive to the problem with sparse data and not suitable for the short texts classification such as Tweets, Microblogs and Weibo posts etc. In [8], the authors study a bayesian modeling approach to classify the sentiments with incorporation of a document-level multi-dimensional sentiment distributions prediction. However, the prediction of sentiment distribution over documents is time consuming and the document-level approach can not be applied directly for the short texts min-ing. Moreover, most of the existing works focus on the polarities classification. Intuitively, recognizing the texts as fine-grained emotions such as happiness, anger, sadness, fear, etc. could offer much delicate financial or political insights. In [9], the authors group the Weibo posts into 4-category sentiments ( Joy, Blue, Anger, Disgusting ) according to 95 emoticons among the texts instead of using the semantics of words and sentences. And the new set of categories in [9] is a variation of the conventional psychological category( Joy,Blue,Anger,Fear ). We argue that the aforementioned categories are unable to perceive the public concern and support to special events which will be further discussed in Sec. 4.1. From the above observations, we propose to adopt semi-GMM supervised learning and supervised learning to a Multi-class emotion classification to further improve the performance of semantic orientation classification for microblogs. In this section, we propose to generate a comprehensive Chinese sentiment lex-icon by using the Chinese affective words and phases from Sina Weibo posts. And we evaluate the lexicon coverage by adopting the approach in [10]. 3.1 Sentiment Lexicon Generation First, we conduct a serial of statistical analysis methods over a large amount of online posts. We take the highly frequent terms of the existing corpus dictionary (HowNet and NTU Sentiment Dictionary (NTUSD) [11]) and the manually an-notated words as the seed words. Based on the set of seed words and the semantic similarity defined in HowNet [3], a set of new sentiment words are obtained ac-cordingly to further enrich the lex icon. In HowNet, each vocabulary v k has many items expressing different concepts, and each item S k composes several primi-tives p k 1 ,  X  X  X  ,p kn to describe its characteristics. The semantic similarity between different items v k is defined as follows: where t 1 , t 2 is the number of primitive for S 1 and S 2 . 1 2 t 1  X  i +1 is the weight of the primitive p 1 i for item S 1 . And the similarity between words is denoted HowNet X  X  well-constr ucted semantic tree,  X  is an empirical constant to guar-antee the denominator is non-zero [12]. We also extract the catchwords from Sina Weibo posts which are popularly used by Chinese young generation and have gradually become the mainstream languages and the items of modern Chi-nese vocabularies. In this paper, we obtain 8204 sentiment words including 613 catchwords and 101 commonly used emoticons. 3.2 Lexicon Coverage Evaluation To verify the effectiveness of our constructed lexicon, we adopt the approach proposed in [10] to observe whether the average emotional values E avg follow a consistent trend for the daily posts and social events. E avg is defined as: where d stands for the Weibo post, f i is the frequency of the ith word v i , Key p and Key n refer to the predefined positive and negative seed lexicons. M and N are the number of positive and negative s eed lexicons respectively. And for those catchwords which do not exist in HowNet, we conduct the majority vote on the manually scores to determine their emotional value.
 Fig. 1 shows the average emotional value of daily Sina Weibo posts from March. 23 th , 2013 to April. 26 th , 2013 based on our newly created lexicon. It is obvious that the value is correlated with the catastrophic events and holidays. The consistency of the emotion tendency with the real world events illustrates the effectiveness and the coverage of the lexicon.
 In this section, we presen t the motivation of our newly designed category of the sentiments and the details of the adaptive learning approach for semantic orientation classification. 4.1 Sentiment Categories The conventional psychology study [13] suggests a four-class identification for hu-man sentiments, namely, Joy, Blue, Anger ,and Fear . Our observation from daily online posts is that people resort to the online services e.g., Twitter, Sina Weibo as the portal to convey their concern and support to some special groups and events. Fig. 2 shows a post published on Sina Weibo after the Malaysia Airlines (MAS) flight MH370 was confirmed lost. The post mainly expresses the social concern and support for the victims and their next of kin. And this kind of emotion often breaks out shortly after some public events happen e.g., the disaster like earthquake and the crimes of causing death. With investigation of vocabulary frequency in numer-ous emotional posts, we find that numbers of words and emoticons such as Pray , Peace ,[ candle ] (shown in Fig. 2)... tend to express such feelings. While in the con-ventional four-class orientation detection, it X  X  highly likely the post will be iden-tified as a Joy post. For words like  X  X ondolence X  also express the concern while it will be identified as a blue word in four-class sentiment scale.

To further highlight the need of Concern category, Fig. 3 presents the propor-tion of the Concern posts in the daily posts from March. 23 th , 2013 to April. 26 th , 2013 according to the sentiment lexicon we built in Sec. 3 and the lexicon vector introduced in Sec. 4.2. We could observe that the number of concern postsisin-creasing sharply when some vital social event happens which illustrates the impor-tance of the Concern category. Thus, we introduce the 5 th emotional identification Concern into the conventional four-class senti ment classifications. Accordingly,the sentiment categories in this paper are Concern , Joy , Blue , Anger and Fear . 4.2 Lexical Vectors Basedontheconstructedsentimentlexi coninSec.3,webuildaseedsetcomposedof themanuallylabeledrepresentativewordsforfivecategories.Theseedsetisdenoted as seedset = { PC,PJ,PB,PA,PF } ,where PC , PJ , PB , PA , PF stands for the subset of ( Concern, Joy, Blue, Anger, Fear ) respectively. For each non-seedset vocabulary v , we propose to detect its tendency based on Eq.(5) defined as follow: where K 1 , K 2 , K 3 , K 4 , K 5 is the number of vocabularies in the set of PC , PJ , PB , PA , PF respectively.  X  ( v ) is the category for which the above argument attains its maximum value. And for those catchwords which do not exist in HowNet, we conduct the majority vote on the manually marked labels to deter-mine its sentiment category. So far the sentiment lexicon is a list of vocabularies with sentiment labels indicating their a ssigned category and there is no overlap between categories. Eventually, in our derived lexicon, there are 816, 2618, 2189, 1382 and 1199 words for the five categories respectively.
 To address the issue of sentence segmentation, we adopt NLPIR [14]-a popular Chinese words segmentation system (also known as ICTCLAS2013) to segment the Weibo posts into the vocabularies, as it X  X  well-known that unlike English there is no spaces between Chinese chara cters. To further clean the data, we remove the obviously useless vocabularies and interpunctions e.g.,  X  X e X , X , X .
Then we determine the sentiment category of each segmented vocabulary in the Weibo post and convert the post into a vector-based numerical expression by using the generated five-class sentiment lexicon. Let D = { d 1 ,d 2 ,  X  X  X  ,d N } be a set of posts, where d i is the i-th post. d i =[ w iC ,w iJ ,w iB ,w iA ,w iF ] T where w iC , w iJ , w iB , w iA , w iF is the number of vocabularies belonging to the category of Concern , Joy , Blue , Anger and Fear respectively. Then all the posts can be represented as 5-dimensi onal vectors accordingly.

For those non-lexicon-based sentiment analysis [15], the researchers usually set up a relatively large training set and use TF-IDF (term frequency-inverse document frequency) to select a number of sentiment words to form a high-dimensional vector. It will lead to the incomplete expression, high-dimensionality suffering and over-fitting for the sentimen t learning. With the generated lexicon and defined lexical vectors, we reduced the information loss and made the data more suitable for further classification. 4.3 Adaptive Classification Approaches In this section we present the details of the adaptive Semi-GMM and KNN algorithm to classify the lexical vectors.
 Semi-GMM Sentiment Classifier. Gaussian mixture model (GMM) adapted with the optimization method -Expectation Maximization algorithm (EM) is a classy unsupervised learning combo for the data classification. GMM leverages the latent variables to estimate each Gaussian density and the weight (  X  i )of each Gaussian, with the assumption that the data is produced according to a set of multivariate Gaussian component. Semi-supervised learning has shown its effectiveness for the problem with a s mall set of labeled training data. To further improve the classification performance, we propose to adopt a semi-supervised GMM for the sentiment clustering by leveraging the prior knowledge of the labeled data, the hidden structure among the unlabeled data and the effectiveness of GMM as a probability clustering method.

We incorporate the labeled data into the standard GMM to influence the clus-tering preferences. Then the Semi-supervised GMM performs as a self-training method. In each iteration of the training process, the positive result from the classification is added to the set of labeled sample set L . The newly updated L in turn helps to maximize the distribution likelihood. With the results of E-step, M-step will be the intermediate classifier on the training set under the new train-ing. And the unlabeled sample set U continues shrinking during each iteration. The pseudo codes for the Semi-GMM is illustrated as follow: 1 i  X  0 2  X  (0)  X  arg max 4 E-step: 6 ( j,k )  X  arg max 7 L  X  L  X  u j 8 U  X  U  X  u j 9 M-step: 11 i  X  i +1 where L is the labeled sample set, U is the unlabeled sample set, K indicates the KNN by Symmetric KL-Divergence. k-nearest neighbors algorithm (KNN) [16] classifies the objects based on the majority vote of its k  X  X losest X  training examples in the feature space. The  X  X los eness X  is measured by the similarity be-tween the clustering center and the other nodes. KNN usually adopts the cosine of the angle between two vectors of an inner product space as the similarity. However cosine similarity is not a proper metric for measuring the  X  X loseness X  between the probabilities.

In this paper we adopt Kullback-Leibler divergence (KL-divergence) as the similarity measurement between the nor malized lexical vectors for the semantic orientation analysis. KL-divergence is a rigorous non-symmetric measure of the difference between two probability distributions P and Q , denoted as D KL ( P || Q ). Recall that the lexical vector d i is defined in Section 4.2, here we convert the vector space into a set of probability distributions via normalization. And the normalized vector T i is denoted as follows: The KL-divergence between T i and T j is defined as follow: As KL-divergence is a non-symmetric measurement which represents the infor-mation loss of using Q to approximate P , where P usually represents the precise distribution. In sentiment analysis, we use the labeled lexical vectors as T i ,the unlabeled vectors as T j to indicate the  X  X istance X  from the unknown data to the determined data. In order to alleviate the asymmetry of the conventional KL-divergence, a symmetric formula [17] is given as follows In this section, we compare the experime ntal results of the adaptive classifi-cation algorithms (Semi-GMM and KNN by Symmetric KL-divergence) with the conventional baseline approaches (Majority Vote, KNN by Cosine similarity, SVM). We randomly selected 7170 Sina Weibo posts to evaluate our proposed methodology. We invited 25 students working on Natural Language Process-ing to manually classify the posts into 5 groups. Thus each post gets 25 votes. And then the majority vote was conducted to determine its sentiment category. Among these posts, there are 1300 posts for Concern , 2100 posts for Joy , 1340 posts for Blue , 1310 posts for Anger and 1120 posts for Fear .

Firstly, we adopt two different measurements Eq. (7) and Eq. (8) as similar-ities for KNN-based sentiment classification. Table 1 shows that the accuracy achieved by using the symmetric KL-divergence is higher than that of using non-symmetric conventional KL-divergence. Hereinafter, we only put KNN by using symmetric KL-divergence (KNN-KL) into the comparison. The size of training sets ranges from 1000 to 4000. And we randomly selected 3170 posts as the test set. There are 500 posts for Concern , 1300 posts for Joy , 540 posts for Blue , 510 posts for Anger and 320 posts for Fear .

Fig. 4 shows the detailed performance of the adopted classification algorithms over different training sets. When the size of training set is 4000, KNN by sym-metric KL-divergence outperforms other algorithms and the accuracy reaches 85 . 1%. It is obvious that KNN-KL outperforms KNN-Cosine for all the training sets, which illustrates the effectiveness of using symmetric KL-divergence as the measurement to define its k neighbors. KNN now captur es the lexical vectors X  relations better than that of using cosine similarity.
When the size of training set is smaller than 3000, Semi-GMM outperforms all the algorithms. We can observe that the performance of Semi-GMM is more stable than that of KNN-Cosine and KNN-KL when the size of training set fluctuates. After removing 3000 samples from the training set of 4000 labeled data, the accuracy of KNN-KL based classification has declined by 8.9%, while Semi-GMM has merely declined by 2.9%, whi ch demonstrates the effectiveness of the semi-supervised learning on the small training set. While the performance of the supervised learning methods such as KNN is sensitive to the size of training set and the number of neighbors k .

With respect to SVM, it is usually adopted for two-class classification. Al-though there are a lot of variations of SVM for multi-classification, the compet-itive advantage over other multi-classification algorithms is far less than that of the conventional SVM. And its classification performance also depends on the high quality of the training data. Besides, SVM is also not favored for large-scale data mining tasks due to its high complexity. Thus we argue that Semi-GMM is more suitable for the sentiment classification with smaller training set. And in practice, obtaining training labels is expensive in sentiment analysis and many other text classification problems, while large quantities of unlabeled texts are ready-made [18].

Training Set Size Methods Concern Joy Blue Anger Fear
Table 2 shows the accuracy achieved by KNN-KL for 5 sentiment classes under the same test set with different size of training set. We observe that the accuracy of classification of Concern and Blue drops sharply with the decreasing of the number of training data. For the class of Concern , there are 79 posts falsely labeled, among the falsely labeled posts there are 64 posts identified as Joy , 11 posts identified as Blue and 4 posts identified as Anger . For the class of Blue , there are 60 posts falsely classified, among them 8 posts are identified as Concern , 28 posts are identified as Joy , 13 posts are identified as Anger ,11 posts are identified as Fear .As Concern and Blue are not intense emotional feelings as Fear and Joy , the clustering for the Concern and Blue is quite sensitive to the training set. While Table 2 also shows the accuracy achieved by Semi-GMM for 5 sentiment classes and Table 3 shows the F1-score by Semi-GMM and KNN-KL on different size of training set, which further illustrates the advantages of Semi-GMM on the small training set. We also conducted the experiments with unsupervised l earning approach GMM and k-means to determine the sentiment orientation by classifying the Sina Weibo posts. The accuracy of the GMM algorithm is ranging from 58 . 6% to 64 . 4%. For another popular unsupervised learning algorithm k-means, the accuracy is around 54 . 6% which is slightly worse than GMM. The unsupervised learning achieves relatively poor performance comparing with our proposed adaptive approaches as it is lack of the utilization of the prior knowledge from the labels. In this paper, we propose to generate a five-class sentiment lexicon by using Sina Weibo posts, HowNet and NTUSD. The Concern class is introduced into the lexicon to better capture the public attention, concern and support for the public event. Based on the lexicon , the posts are then represented as the lexical vectors. The adaptive Semi-GMM and KNN by symmetric KL-divergence are proposed to classify the lexical vectors to further enhance the performance of semantic orientation classification. Extensive experiments have been conducted and the results show that our classification methods outperform the conventional approaches in terms of the learning accu racy and F1 score. Especially, the pro-posed Semi-GMM shows its advantages over other approaches when the training set is relatively small.

In the future work, we will further modify the proposed methodologies. One potential modification is to build the sentiment lexicon via the soft clustering and assign the proper weights for each sentiment vocabulary. A more sophisticated sentiment lexicon and lexical vector w ill be further investigated to enhance the classification performance for the semantic orientation analysis.

