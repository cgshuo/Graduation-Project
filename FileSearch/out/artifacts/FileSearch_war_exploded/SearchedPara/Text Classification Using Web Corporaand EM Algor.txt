 In practical use, the Web has become the largest source of training data [1, 4]; however, it is cost-ineffective to handlabel each extracted documents from the Web. Thus many algorithms using few labeled data and large unlabeled data to train a text classifier were presented [3]; and [2] proposed a method without requiring labeled training data. The purpose of the paper is extended from the previous work and focuses much on using EM techniques to extract more reliable training data.
 via sending the class name itself to Web search engines. But while using the Web as the training data source, the extended problem is how to check the relevancy of the extracted documents to the class of concern. If the training data contains too many noisy documents, no doubt the classifiers trained by the data might not be reliable enough. In view of this problem, our idea is to retrieve only a small set of documents as the initial data for each class, and generate proper keywords from it as the relevant concepts of the class to retrieve augmented but reliable training data. The approach we proposed in this paper is based on the concept of the Naive Based modeling and EM algorithms. It assumes that the training data of a class is distributed and mixed with some relevant concepts; thus, we could model the distribution of each mixture based on a small set of data retrieved from Web search engines.
 the initial data; second is the keywords extracted from the initial data to describe relevant concepts of the class of concern; third is to refine the initial modeling of each concept (keywords). As for extracting initial documents from the Web, depending on the ranking ability of search engines, like Google, it can be retrieved from the top-ranked documents, since their relevance to the target class might be high. With the initial data, we apply a greedy EM algorithm to determine the proper number of relevant concepts of each class. Then, for each mixture, refine its corresponding distribution depending on more  X  X ugmented X  training data extracted via sending several queries into the search engine. The queries are those with the highest mutual information in distributions, i.e. keywords. In this step, an augmented EM algorithm is applied to iteratively update parameters in each distribution with the increasing of likelihood. Experimental results have shown the great potential of the proposed approach in creating text classifiers without the pre-request of labeled training data.
 the background assumption, i.e. Naive Bayes, and the modeling based on Naive Bayes. Section 3 describes the main idea of using the Web-based approach to acquiring training data from the Web, and its extended problems will need to be resolved, including document clustering, keyword generation, extracted data verification, and etc. Section 4 presents the augmented EM algorithm for text classification. Section 5 shows the experiments and their result. The summary and our future work are described in Section 6. Before introducing our proposed approach, here introduce a well known way of text representation, i.e. Naive Bayes assumption. Naive Bayes assumption is a particular probabilistic generative model for text. First, introduce some notation about text representation. A document, d , is considered to be an ordered list of words, { w 1 ,w 2 , ..., w | d | } ,where w j means the j th word in document d and | d | means the length of d . Second, every document is generated by a mixture of components { C k } , for k=1 to K. Thus, we can characterize the likelihood of document d with a sum of total probabilities conditioned on all mixture compo-nents: where  X  is a set of parameters including the probabilities of all words in class C k and the prior probability of C k . document as: where Based on standard Naive Bayes assumption, the words of a document are gener-ated independently of context, that is, independently of the other words in the same document given the class model. We further assume that the probability of a word is independent of its position within the document; thus (3) is derived. Thus, the parameters of an individual class are the collection of word proba-In this section we will introduce the framework of the proposed approach to acquiring training data from the Web and creating text classifiers, and in the next section address the detailed descriptions of the proposed text classification algorithm that utilizes EM techniques. Since it is normally lack of sufficient and relevant training data in many practical text classification applications, unlike conventional supervised learning approaches, we pursue to create a text classifier that requires no labeled training data. We use the Web as the unlabeled corpus source and real search engines the agents to retrieve relevant documents as the training data for each subject class of concern. To assure the accuracy of the auto-retrieved training data, the proposed approach is composed of an EM-based document clustering and keyword generation method to acquire more training data without increasing many noses. In addition, an EM-based classification algorithm is presented to make the created classifiers more reliable. 3.1 The Approach for Corpus Acquisition As shown in Figure.1, suppose now we want to train a classifier for K classes C ,C 2 , ..., C K ; then as our previous approach proposed in [2] we treat each class name of C k for k=1 to K as a query sent to search engines to retrieve a number of relevant documents from the Web. Considering the information capacity and convenience, only the short descriptions of the retrieved documents (the snippets of search result pages) are used, which include page titles, short descriptions and URLs. Since most of the search engines, like Google and Yahoo, provide ranking service for the retrieved documents, we could believe that the documents with the higher ranking scores have higher association with the corresponding class, C k , and these highly-ranked documents are then taken the initial training data of C k , i.e., D l k . It is not hard to imagine that the training data might contain some texts describing the relevant concepts of C k . To acquire more relevant training data, the keywords, T k,m , describing the relevant concepts of C k will be generated, from D l k where m=1 to of generated keywords in C k .Asfor T k,m  X  X  generation, the documents in D l k will be clustered with their similarity into a set of clusters and keywords with the highest weighted log likelihood ratio in each cluster will be extracted as the for C k via sending the keywords to search engines. Each T k,m is then taken as a sub-concept class of C k and the retrieved documents as the corresponding training corpus in the process of training the text classifier, which will be further described in next section. However, here comes with the difficulties such as how to determine a proper number of clusters when clustering D l k , and how to extract keywords to represent each auto-created cluster. The complete process of the corpus acquisition approach is thus designed as follows: Step1. Given a set of C 1 ,C 2 , ..., C K that require training data from the Web.
Step2. Send C 1 ,C 2 , ..., C K as the queries into search engines to retrieve the
Step3. Apply an unsupervised clustering method to determine the number of
Step4. Choose those words in D l k,m with the highest weighted log likelihood
Step5. Put T k,m as the new queries into search engines and retrieve new  X  X ug-
Step6. Perform a verification process to filter out the unreliable augmented
Step7. Refine parameter  X  T k,m with D l k and D u k,m ,form=1to | C k | and k = Below are the detailed processes from Step 3 to Step 7. 3.2 Document Clustering and Keywords Generation This part describes step 3 and step 4; further detailed description about step 3( the greedy EM algorithm ) will be in next subsection. In the process, the documents in the initial training data D l k will be clustered with their similarity into a set of clusters and keywords that can represent the concept of each cluster will be extracted. After clustering the initial training data into several clusters, the distribution of each cluster in a probabilistic form can be calculated with the data in the cluster by applying a greedy EM algorithm to be described in 3.3. ter, i.e class naming problem. With the representative keywords of the cluster, the  X  X ugmented X  data could be collected directly by sending the names of the keywords to search engines. However, class naming problem is a big issue. For convenience, we simply represent the cluster name as the word with the highest weighted log likelihood ratio among the contained words in this cluster. With this assumption, the  X  X ain X  word could be chosen directly by comparing the weighted log likelihood ratio 1 defined as: means the sum of the probabilities of word w j in those clusters except T k,m . Those chosen keywords by 5 are used to extract new  X  X ugmented X  training data, D k,m from the Web, where D 3.3 The Greedy EM Algorithm Because we have no idea about how many concepts strongly associated with each class, thus for each class, C k , it is straightforward to apply the Greedy EM algorithm to clustering the  X  X nitial X  data from the Web into a certain number of clusters automatically. The algorithm is based on the assumptions of the theoretical evidence developed in [5, 6], and the basic idea is to suppose that all the training data belong to one component at the initial stage, then successively adding one more component (concept) and redistributing the training data step by step until the maximal likelihood is approached.
 in any class, which are mixed with M components. In particular, assume that a new component with parameter set  X  M +1 is added to this M-component class; thenthemixtureofthisM-componentclasswillbe: with  X  in (0,1), where f M ( D ) means the probability of document set D in this M-component class and  X  ( D,  X  M +1 ) means the probability of D in the newly added component. Thereafter, as long as the weight  X  and the parameter set  X 
M +1 of M + 1 component are optimally chosen, then for each M-component class, the new log-likelihood derived as will be maximized, where { d n } N n =1  X  D . In addition, a notable property of the above maximization problem is that the parameters of old M-component class,  X  M , remain fixed during maximization of L M +1 .
 rithm as our use,  X  ,  X  M +1 , f M ( d n )and  X  ( d n , X  M +1 ) should be replaced as: for each class C k ,where T k, | C k | +1 means the newly added component (keyword) in class, C k ,and | V | means the total number of words shown in D l ,the initial training data. partial EM: where the numerator and denominator in (13) and (13) are augmented with  X  X seudo-counts X  (one for each word) to assure non-zero frequency of each word in the newly added component, T | C k | +1 ;where | V | and | D | respectively means the number of vocabularies and the number of documents shown in the initial training data.
 steps constitute a simple and fast method for locally searching for the maxima of L
M +1 , without needing to resort to other computationally demanding nonlinear optimization methods. 3.4 The Verification Process This subsection is for step 6 in subsection 3.1. The purpose of the verification process is to further filter out the retrieved documents that are not reliable enough to be included in the set of the augmented training data. For each key- X  X nitial X  training documents of C k clustered into T k,m ; thus the probability of any document d i assigned to class C k , is defined as: document d i respectively.
 C k , if the responsibility of C k to d i is lower than the responsibility of C j = k to d ,then d i is dropped out of the collected  X  X ugmented X  data. This is reasonable, because if d i is extracted from the keywords belonging to C k , but C k doesn X  X  get the highest responsibility to d i ; then in some sense d i should be viewed as noises and should be dropped out.
 In this section, we will introduce the text classifier based on EM techniques. Suppose there are K classes and each class has its corresponding model, i.e. word probabilities and mixture weight, as described in Section 2. Given a new document d s to be classified, its tendency to be assigned into class C k will be judged from its responsibility in class C k and the responsibility is defined as: p ( C k | T k,m ,d s )  X  1and p ( C k | T k,m ,d s )  X  0if j = k are provided. 4.1 Training It is well known that the result of EM-based algorithm is sensitively depending on the initial models (parameters). A bad initial given modeling will trap the EM algorithm into local extreme value. In section 3, we have provided the initial document. Using simple Bayes theorem, and Naive Bayes assumption, (4), training the classifier is equivalent to training shown that if we want to utilize (8) and (9) as the initial modeling of p ( T k,m ) and p ( w d s | T k,m ), then C k in (8) and (9) has to be dropped out. Thus, if set p p ( w t | T k,m )and p 0 ( T k,m ) could be derivated easily as: With the initial parameters, the responsibility of T k,m to document d s could be calculated as then update p ( T k,m )and p ( w t | T k,m )as where | T | and | V | represents the number of total components (concepts) and the number of total vocabularies respectively, shown in training data which is combined with the initial training set and the  X  X ugmented X  training set. a) Those initial training data in D l k  X  k =1 to K will always be given respon-b) All the newly retrieved  X  X ugmented X  documents D u have to pass the verifi-c) d s in (19), (20) and (21) belongs to the set of { D u ,D l } . 4.2 Classification As describing in the start of this section, classifying a new document is by judging its responsibility calculated as (15). The further extension of (15) is: According to (22), the testing document will be assigned to the class with the highest responsibility. After describing the theoretical part, in this section, we will show the experiment results of embedding keywords generation and Web-based corpora into a text classifier system. 5.1 Data Description Our experiments took the  X  X omputer Science X  hierarchy in Yahoo! as the bench-mark. There were totally 36 classes in second level in the  X  X omputer Science X  hierarchy, 177 classes in the third level and 278 classes in fourth level, all rooted at the class  X  X omputer Science X . We used the second-level classes, e.g.,  X  X rti-ficial Intelligence X  and  X  X inguistics X  as the target classes and tried to classify text objects into them.
 the Web pages linked from Yahoo! X  X  Website list under the Computer Science hierarchy, short documents, which were the site description offered by Yahoo!, and text segments, which were the directory names. 5.2 Keyword Generation In section 3.3, the Greedy EM algorithm is treated as the unsupervised learning method to cluster  X  X nitial X  training data to generate keywords for each class. Here comes a problem, too many retrieved documents will cause noises, but too few won X  X  contain enough information about this class. Finally, for each class, we queried 200 short descriptions by sending its own name to Google (http://www.google.com). Table.1 shows the generated bi-gram keywords. The number of keywords in each class was determined automatically by the Greedy EM algorithm.
 gram keywords do. It is encouraging that the algorithm extracted he main idea for some classes. Taking  X  X odeling X  for example,  X  X odeling X  is a rough acronym to describe many fields. In the unigram keywords, only  X  X tructural X  and  X  X gen-cies X  were extracted to represent  X  X odeling X ; however, in the bi-gram keywords, the specific area in  X  X odeling X  were extracted, like  X  X rotein modeling X ,  X  X olid modeling X ,  X  X athematical modeling X  etc. Again,  X  X andheld X  and  X  X hallenges X  were extracted to represent  X  X obile computing X  in the unigram keywords; but in the bi-gram keywords  X  X omputing program X  and  X  X ress releases X  were ex-tracted. There was a little difference between this two representation ways on  X  X obile computing X . We can not decide which way is better, thus the following experiments will be tested with the unigram keywords and bi-gram-keywords. of concern. However, some noises were still extracted like  X  X isenstadt/Burnett 1000 X  in  X  X nd user programming X . That was arisen from a retrieved document tackling about a $1000 bet during 1985-1995 to predict the scarcity of end user programming. It X  X  interesting but shouldn X  X  be taken to describe the concept of  X  X nd user programming X . The same situation is shown while  X  X AQ revision X  is extracted in  X  X ecurity and encryption X  in bi-gram keywords. 5.3 Classification Accuracy In order to check the classification effect of the proposed approach, the fourth level (450 classes) were used to be the test text objects. For each object it got ten retrieved documents from Google, then transforming the ten documents as a bag of words to represent the class. Thus, if an object got the highest responsibility in its own upper second level, then it was taken as  X  X orrectly classified X . Table.2 shows the achieved top-1, top-2, top-3, top-4 and top-5 accuracy. The achieved result is encouraging which demonstrates its great potential that a text classifier can be created via using Web corpora and no labeled training data is required. This, however, will increase the availability of text classification in many real applications., in which to prepare sufficient labeled training data are always be a big problem.
 a) Temporal factors. The documents retrieved via Web search engines that b) Word string matching. Searching with word string matching instead of se-c) Probability framework. Usually, using probability framework to do text clas-ment, using N-gram model to represent a document is also what we are on going. In past research, Ngram modeling does provide higher performance than only a bag of words. In addition, combining vector-based modeling and Support Vector Machine will be the next work.

