 TOMOKO IZUMI, KENJI IMAMURA, TAICHI ASAMI, and KUNIKO SAITO The need for text mining systems, such as opinion mining and sentiment analysis, is growing rapidly due to the increasing amount of textual information, especially consumer-generated media and call center data. These systems must offer deep semantic analysis of the target language. Nasukawa [2009] claims that in the domain of voice-of-customer (VOC) analysis, a practical system must be able to distinguish among complaints, compliments, and questions. Inui et al. [2008] emphasize the im-portance of determining whether what is written is factual or not in the domain of experience mining (i.e., factuality analysis). These studies often claim that the sim-ple bag-of-word technique is insufficient for deep semantic analysis [Inui et al. 2008, p. 318; Nasukawa 2009, p. 1].

For example, in the domain of VOC analysis, expressions such as would like to as in  X  would like to buy X  and can X  X  as in  X  X an X  X  install X  are key expressions in detecting the customer X  X  needs and complaints, and extracting only a single content word ( X  X uy X  and  X  X nstall X  in the preceding example) would fail to capture this information. Similarly, recognizing tense marking and the existence of a modal auxiliary could be crucial to detecting whether what is described by the predicate actually happened or is simply supposed (e.g., purchas ed vs. might purchase). In order to extract subtle but semanti-cally essential information from the input text, it is crucial to consider both the content word and the functional expressions [Nasukawa 2001].

Few studies have dealt extensively with functional expressions for use in Japanese natural language processing (NLP) systems (e.g., [Matsuyoshi and Sato 2006, 2008; Tanabe et al. 2001]). This is due to the fact that functional expressions such as would like to and might have been are syntactically complicated and semantically abstract and so are poorly handled by NLP systems. For example, the expression would like to has meaning similar to want to and wanna , but the system cannot recognize their similarities from just the surface forms. This is especially the case in Japanese.
In Japanese, functional expressions appear in the form of suffixes or auxiliary verbs that follow the content word. This sequence of a content word ( c for short) plus several functional expressions ( f for short) forms a predicate in Japanese (COMP for comple-tive aspect marker, NOM for nominalizer, COP for copular verb). The meaning of  X  X ant to X  is expressed by -takat (f 2 ) , and the past tense is expressed by -ta (f 3 ) . The other functional expressions, -tyai (f alter the formality of expressing  X  X anted to buy, X  as there is no direct English transla-tion. Rather, these expressions are used for discourse purposes, such as emphasizing the action itself and wrapping (or softening) the speaker X  X  comment [Maynard 1997; Tsujimura 2007]. Therefore, (1) expresses the same fact as (2).
As just shown, in Japanese, sentential predicates are multimorpheme expressions that consist of two different types of functional expressions: one influences the fac-tual meaning of the predicate (f 2 and f 3 ) , while the other is merely used for discourse purposes and does not alter the factual status of the predicate (f one extracts a predicate phrase with functional expressions, however, the number of differences in surface forms increases drastically regardless of their similarities in meaning, as shown in (1) and (2). This increase in surface forms complicates NLP sys-tems, especially information extraction systems including text mining, because they are unable to recognize that these seemingly different predicates actually express the same fact.

In this article, we introduce a novel normalization technique that paraphrases com-plex functional expressions in Japanese into simplified natural language forms. The term normalize is used here to refer to the procedure of unifying the surface variations of predicates that express similar meanings. By focusing on the extraction of predi-cates that express the same event, we define functional expressions that influence the factuality of predicative meaning. The normalization system reduces the differences in surface forms of predicates while retaining the factual status of the information. This is made possible by our linguistically-directed paraphrasing rules.

The remaining of this article is organized as follows. In Section 2, we provide re-lated work on Japanese functional expressions in NLP systems as well as problems that need to be solved. Section 3 introduces the linguistic theories on which our para-phrasing rules are constructed. Section 4 describes the experiments conducted on our normalization system. Section 5 discusses the results and applicability of our normal-ization system to text mining systems. The last section is the conclusion. Throughout this article, we use the term functional expression to indicate not only a single function word but also compounds (e.g., would like to ). Shudo et al. [2004] construct semantic rules for functional expressions and use them in order to find whether two different predicates have the same meaning. Matsuyoshi et al. [2006, 2007; Matsuyoshi and Sato 2008] construct an exhaustive dictionary of functional expressions, which are hierarchically organized, and use it to generate para-phrases of functional expressions.

Although these studies provide useful insights and resources for NLP systems, if the intention is to extract and group predicates expressing the same event, we find there are still problems that need to be solved. We focus here on the following two key problems.

The first problem is that many functional expressions are unnecessary for deciding the factuality of a predicate. (3) can be simply paraphrased as follows in (4). In actual NLP applications, such as text mining, it is essential that the system rec-ognizes that (3) and (4) express the same event of something  X  ripped . X  In order to achieve this, the system needs to recognize -tesimat, -no, and -dearu as unnecessary ( f , f 3 , f 4  X   X  ). Previous studies that focus on the paraphrasing of one functional ex-pression to another ( f  X  f ) cannot solve this problem.

The second problem is that we sometimes need to add certain functional expressions in order to retain the meaning of a predicate (  X   X  f ) . Example (5) is in a coordinate structure, and two verbal predicates, iki (P1)  X  X o X  and nonbirisi-takat-ta (P2)  X  X anted to relax, X  are coordinated.

As the English translation indicates, the first predicate has the factual meaning of iki-takat-ta  X  X anted to go, X  which implies that the speaker was not able to go to Hawaii. If the first predicate was extracted and analyzed as iku, the base (present) form of  X  X o, X  then this would result in faulty predicate extraction, indicating the erroneous fact of going to Hawaii in the future (present tense in Japanese expresses a future event). In this case, we need to add the functional expressions takat  X  X ant X  and ta (the past tense marker) to the first verbal predicate.

As previously shown, there are two problems that need to be solved.  X  Several functional expressions are necessary for sustaining the meaning of the event expressed by a predicate, while others barely alter the meaning ( f  X  Several predicates in coordinate structures lack necessary functional expressions at the surface level (  X   X  f ) . This results in an incorrect interpretation of the predicate meaning if only the surface form of the predicate is extracted.

These problems, caused by variations in functional expressions, have also been re-ported in the field of machine translation. Shirai et al. [1993] constructed rewriting rules to convert Japanese functional expressions that express tense and modality into pseudo-linguistic forms that are translated into English. However, the expressions that they covered are very limited (only expressions such as yotei-da  X  X e planning to X  and tokoro-da  X  X e going to X  were included in the rules.). Oku [1990] also constructed a rule to rewrite Japanese predicate phrases into simplified forms. However, he only treats light verb constructions, such as sihai-o-ukeru  X  X o be under control (literally, re-ceive control), X  and provides no rule for simplifying functional expressions in predicate phrases. As shown, neither Oku [1990] nor Shirai et al. [1993] constructed rewriting rules that broadly cover different types of functional expressions, including those that are merely used for discourse purposes. This is because the two studies target newspa-per articles, which tend to have fewer variations in functional expressions than blogs and conversational style texts.

On the other hand, the study by Lee et al. [2006] translated Korean conversational-style texts into English. They constructed a rule that deleted Korean function words that were untranslatable into English before translation and achieved an improve-ment in overall translation quality. However, they simply used POS tags in deciding which expressions to delete, so it is not clear whether crucial information was prop-erly sustained. Furthermore, they failed to offer any rules that could add necessary functional expressions to intermediate predicates, although Korean shows a similar tendency of lacking necessary functional expressions in a coordinate structure [Yoon 1994]. This would result in a serious loss in the information needed for correct English translation.

As just shown, although there are studies that focus on paraphrasing functional expressions, they still leave many issues unanswered. In this study, based on syntactic and semantic theories in linguistics, we construct paraphrasing rules that broadly cover various functional expressions in Japanese predicates and solve the problems by normalizing complex functional expressions into syntactically simple but semantically rich forms. The overall flow of our normalizing system is depicted in Figure 1. The system works as follows. (i) Given a parsed sentence as an input, it extracts a predicate(s) and assigns a se-(ii) As for an intermediate predicate, necessary functional expressions are added if (iii) From each predicate, delete unnecessary functional expressions that do not alter (iv) Conjugate each element and generate a simplified predicate.
 There are two fundamental questions that we need to answer to accomplish this system. (a) What are unneccesary functional expressions (at least for NLP applications), that (b) How do we know which functional expressions are missing and so should be added? We answer these questions by combining what is needed in our NLP applications and what is discussed in linguistic theories. We first answer question (a). As discussed in Section 1 and in Inui et al. [2008], actual NLP applications must be able to recognize whether two seemingly different predicates express the same fact. This emphasis on factuality is similar to the truth-value approach of an event de-noted by predicates, as discussed in the field of formal semantics (e.g., [Chierchia and Mcconnel-Ginet 2000; Portner 2005]). Although an extensive investigation of these theories is beyond the scope of this article, one can see that expressions such as tense (aspect) , negation, as well as, modality , are often discussed in relation to the meaning of an event [Narrog 2005; Partee et al. 1990; Portner 2005].  X  Tense (Aspect) . Expresses the time in (at/for) which an event occurred.  X  Negation . Reverses the truth value of an event.  X  Modality . Provides information such as possibility, obligation, and the speaker X  X  These three categories are indeed useful in explaining the preceding examples discussed. The predicate kat-tyai-takat-ta-n-da in (6) and kai-takat-ta in (7) express the same event, because they share the same tense (past), negation (none), and modality (want). Although (6) has the completive aspect marker -tyai while (7) does not, they still ex-press the same fact, because the Japanese past tense marker -ta also expresses the completive aspect. The information expressed by -tyai in (6) is redundant and so un-necessary.

On the other hand, the predicate iku in (5) and iki-takat-ta , which conveys the actual meaning of the predicate, express a different fact because they establish a different tense (present vs. past) and different modality (none vs. want).

As shown, once we examine the semantic functions of functional expressions, we can see that the factual information in a predicate is influenced by tense (aspect), negation, and modality. Therefore, the answer to question (a) is that the necessary functional expressions are those that belong to tense (aspect), negation, and modality. Furthermore, if there are several functional expressions that have the same semantic function, retaining one of them is sufficient. The other question that we need to answer is how we can find which functional ex-pressions are missing when normalizing predicates in a coordinate structure (e.g., (5)). This shortfall occurs when a predicate appears in the middle of a sentence (henceforth, intermediate predicates ). We solve this based on a detailed analysis of the syntactic structure of predicates.

In coordinate structures, several equivalent phrases are coordinated by conjunctions such as and, but, and or . If a predicate is coordinated with another predicate, these two predicates must share the same syntactic level. Therefore, the structure in (5) is depicted as follows. (What TP and ModP stand for will be discussed later). This is the reason why the first predicate iki should be paraphrased as iki-takat-ta  X  X anted to go. X  It needs to be tagged with the modality expression -takat  X  X ant to X  and the past tense marker -ta , which seem to be attached only to the last predicate.
This procedure of adding necessary functional expressions to the intermediate pred-icate is not as simple as it seems, however. In (8), the first predicate nemutai-mitai-de  X  X eem to be sleepy X  should be paraphrased as nemutai-mitai-dat-ta ,  X  X eem ed to be sleepy, X  in which only the functional expression indicating past is required. The other functional expressions such as tagat  X  X ant, X  and the aspect marker te-i (CONTinuation) should not be added ( nemutai-mitai-de-tagat (want) -te-i (CONT) -ta (PAST) is completely ungrammatical).

Furthermore, the intermediate predicate in the following example does not allow for any functional expressions to be added. In (9), the first predicate yasui  X  X nexpensive X  should not be paraphrased as yasukat-ta  X  X as inexpensive X  since this would result in the ungrammatical predicate of  X * (they) were inexpensive (today). X 
As shown in (8) and (9), in order to add necessary functional expressions to an inter-mediate predicate, one needs to solve the following problem.  X  Which functional expressions should be added to which intermediate predicate? We address this problem by turning to the incompleteness of the syntactic structure of a predicate.

Studies such as Rizzi [1999] and Cinque [2006] proposed detailed functional phrases, suchasaTopP, Topic Phrase , in order to fully describe the syntactic structures of a lan-guage. We adopt this idea and construct a phrase structure of Japanese predicates that borrows from the functional phrases of Tense Phrase (TP), Modality Phrase (ModP), and Focus Phrase (FocP) (Figure 2).

ModP, Modality Phrase , is where modality expressions can appear. Phrase , is the phrase where the copula da appears. This phrase is needed because sev-eral modality expressions syntactically need the copula da in either the following or preceding position [Kato 2007]. The existence of FocP also indicates that the modality expressions within the phrase are complete (i.e., no more modality phrase is attached). TP, Tense Phrase , is where the tense marker appears. 3
As discussed, we assume that predicates are coordinated at one of the functional phrase levels in Figure 2. Functional expressions that need to be added are, therefore, those of the outer phrases of the target phrase.

For example, if the target phrase has da , the head of FocP, then it only needs the past tense marker to be added, which is located above the FocP (i.e., TP). This explains the paraphrasing pattern of (8). Therefore, by looking at which functional expressions are held by the target predicate, one can see that the functional expressions to be added are those that belong to phrases above the target phrase.

Furthermore, as is shown in Figure 2, the predicate can be said to be complete if there is a TP, because, as often described in syntactic theories (e.g., [Adger 2003]), a sentence can be said to be a phrase with tense (i.e., TP). In other words, if a predicate has tense, it can stand alone as a sentence.

By adopting this idea, we judge the completeness of a predicate by the existence of tense. If there is tense, then no functional expression has to be added because the predicate is syntactically complete. Because Japanese marks past tense by the past tense marker -ta ,weuse -ta to detect the existence of tense. However, Japanese has no explicit present tense marker; the base form of a verb is also its present form.
We solve this based on the coordinate conjunction that follows a predicate. As dis-cussed in Minami [1993], the finite state and the type of conjunction are related; some conjunctions follow tensed phrases while others follow infinitival phrases. By inves-tigating various coordinate conjunctions in Japanese, we find that predicates in the gerundive form (also called renyoukei ) and those coordinated by -te/de, as in (5) and (8), cannot directly cooccur with the tense marker -ta , meaning they are tenseless. These are the predicates that are syntactically incomplete, so we add functional ex-pressions that belong to the outer phrases of the target predicate, as in (5) and (8).
As shown, the answer to question (b) is that we only add functional expressions to incomplete predicates, where judgment is based on the existence/absence of tense. The appropriate functional expressions to be added are those of outer phrases of the target phrase. In this final section, we describe how we actually implemented our theoretical obser-vations in our normalization system.  X  Categorize functional expressions . First, we divided functional expressions listed in  X  Add necessary functional expressions .  X  Delete unnecessary functional expressions .  X  Generate simple predicates . Last, conjugate all elements and generate simplified These procedures of categorize, add, and delete are our linguistically directed paraphrasing. In order to evaluate the accuracy of our paraphrasing rules as well as the impact of our normalization on text mining system performance, we conducted three experiments. Experiment 1 measures the paraphrasing accuracies against human-annotated data. Experiment 2 measures the rate of reduction in surface differences obtained by our normalization system. Experiment 3 examines the impact of our normalization system on a text mining application.
 4.1.1. Constructing Paraphrase Data. We selected 2,000 sentences from newspaper and blog articles in which two or more predicates were coordinated. had three or more functional expressions (n  X  3).

We then asked one annotator with a linguistic background to paraphrase each pred-icate into the simplest form possible while retaining the meaning of the event. asked another annotator, who also has a background in linguistics, to check whether the paraphrased predicates made by the first annotator followed our criterion, and if not, to resolve this discrepancy with the first annotator by settling on one cor-rect paraphrase. Four hundred and twenty-four out of 4,939 predicates (8.5%) were judged by the second annotator as not following the criterion and were re-paraphrased. This means that the accuracy of 91.5% is the gold standard of our task. Out of 2,000 sentences in the data, 400 were used for constructing the rules as development sets (Closed) while 1,600 were used as test sets (Open). 4.1.2. Procedure. We evaluated the accuracy of our paraphrasing system as follows. First, we excluded instances that had tokenization errors and those that were judged as inappropriate as a predicate. 7 We also manually assigned correct semantic labels to these predicates. A total of 1,501 intermediate predicates (287 for development and 1,214 for test) and 1,958 last predicates (391 for development and 1,567 for test) were used in the evaluation of our paraphrasing rules.

The accuracy was measured based on the exact match in surface forms with the manually constructed paraphrases. For comparison, we used the following baseline methods. The last baseline method (Delete on POS) was used for comparing Lee et al. X  X  [2006] method of preprocessing Korean-English translation to our proposed method.  X  (BL 1) No Add/Delete . Do not add/delete any functional expression.  X  (BL 2) Simp-Add . Simply add all functional expressions that the intermediate  X  (BL 3) Delete on POS . Delete functional expressions based on their POS tags. 4.1.3. Results of Experiment 1. Table II indicates the results. Our paraphrasing rules achieved the high accuracy of 77.5% (Intermediate (predicates)) and 81.4% (Last (pred-icates)) in Open (against the test set) and 82.6% (Intermediate) and 87.5% (Last) in Closed (against the development set). These values are quite high compared to the baseline methods (No Add/Delete (open), 57.8%; Simp-Add (open), 32.8%; Delete on POS (open), 32.0%). The differences between the proposed method and the baseline methods are all statistically significant (**p &lt; 0.01).
We also measured the overall accuracy of our normalization system, which means all the procedures in Section 3.1 were automatically implemented. We used MeCab as the tokenizer and POS tagger and CaboCha 11 as the dependency parser. For predi-cate extraction and semantic label tagging, we used Imamura et al. X  X  [2011] automatic predicate extractor and semantic label tagger, which extracts a predicate phrase and assigns one of the semantic labels of Matsuyoshi et al. [2006, 2007] to each functional expression of the predicate. The overall accuracy of Imamura et al. [2011] is 95.8%. The accuracy of extracting predicates and assigning correct semantic labels is 86.3%. In or-der to extract intermediate predicates in coordinate structures, we created heuristic rules based on dependency information.

The overall accuracy is listed in Table III. Only the results against the test set (1,600 sentences) are shown. We divided the results into three categories; PRED Extraction Error, Correct, and Wrong . PRED Extraction Error indicates that the system failed to extract a target predicate, which is caused by Imamura et al. X  X  [2011] predicate extrac-tor and our heuristic rules to extract intermediate predicates. Correct indicates that the automatically normalized functional expression matched the human annotation. Wrong indicates that the normalized forms output by the system and by the human annotators do not match at the surface level. The Wrong instances were caused by two factors: errors in our normalizing rules and errors in Imamura et al. X  X  [2011] semantic label tagger.

The overall accuracies were 78.6% for Last and 46.9% for Intermediate. The accu-racy for Intermediate seems low, because we set a rather strict criterion for extracting intermediate predicates in coordinate structures, resulting in the decrease in recall. The accuracy for Intermediate is lower in Blogs (42.9%) than in News (51.2%), indi-cating the difficulties of extracting correct predicates from texts with informal style. For 774 instances out of the 791 PRED Extraction Errors, the system simply failed to recognize and extract them as a target predicate. 4.2.1. Datasets. Next, we examined the reduction rate of differences in surface forms of predicates before and after normalization. We used two datasets.  X  News . One-year collection of newspaper articles ( The Mainichi Shimbun Newspa- X  Blogs . Two-week collection of blog articles ( April 1 X 14, 2007; 427,474 sentences) Our normalizer paraphrased both intermediate and last predicates in these datasets. A total of 478,922 predicates were normalized in News and 479,695 in Blogs.
We counted the number of differences in type in predicates (i.e., the sequence of c .. c m  X  f 1 .. f n is counted as one) and the number of differences in type in functional ex-pressions (i.e., a sequence of f 1..  X  f n is counted as one) before and after normalization. We use the term ORG (ORiGinal) to indicate  X  X redicates/functional expressions be-fore normalization X  and NORMED to indicate  X  X redicates/functional expressions after normalization. X  4.2.2. Results of Experiment 2. Table IV indicates the number of types in predicates as well as functional expressions in News and Blogs before and after normalization and the reduction rates. The reduction rates were calculated by the following equation.
As shown, our normalizer succeeded in reducing the differences in surface forms of predicates by up to 21.5% in News and 30.7% in Blogs. This indicates that as many as 21.5% of the predicates in News and 30.7% in Blogs would have been wrongly recog-nized as  X  X xpressing different meanings X  without our normalization. The differences in functional expressions were drastically reduced, by up to 57.5% in News and 66.7% in Blogs.
 Lastly, we examined the impact of our normalization system on a text mining applica-tion. As has been discussed, using only the head word of a predicate for text mining systems, such as VOC analysis and factuality analysis, is insufficient because it might lead to an erroneous conclusion. For example, the predicates  X  X an X  X  open, X   X  X ant to open X , and  X  X pened  X  X  X ll of which express different facts X  X ould be incorrectly ana-lyzed as  X  X pen. X  On the other hand, if the system simply uses the surface forms of Japanese predicates, it would also fail to correctly count up the frequencies of the predicates. This also leads to an incorrect analysis. By normalizing predicates based on their meaning, we can expect to avoid these problems. 4.3.1. Task Description. In order to evaluate the effect of our normalization system on an NLP application, we set up the simple text mining task of extracting predicate phrases from two different groups of datasets and finding the bias in predicate distri-bution towards a particular group (henceforth, biased predicate extraction task). The goal of this task is to find phrases that are characteristic to certain datasets.
We conducted the biased predicate extraction task based on head words of predi-cates (HEAD), original surface forms of predicates (ORG), and normalized predicates (NORMED). We expect that the use of HEAD overmerges different predicates, while the use of ORG miscalculates the frequencies of predicates. The use of NORMED will correctly count the frequencies of predicates based on their factual meanings. 4.3.2. Datasets. We used data from Yahoo! Chiebukuro , Yahoo! Answers . The data consists of questions and answers posted to Yahoo! Chiebukuro , a user-oriented Q&amp;A site. In this experiment, we compared two differ-ent pairs of datasets. One is the data in questions from the Internet category, and we compare this data to questions from the Relationships category (i.e., we did not use the answers). We selected these two groups because the questions posted to these two categories will differ in content, and so we can clearly observe the effect of our normal-ization system on the biased predicate extraction task. 13  X  X  can X  X  open a zip file  X  X nd X  X  want to use wireless Internet connection at home X  would occur in Internet , while expressions such as  X  X  can X  X  get along with my new boss X  would occur in Relationships . The other pair is the data in questions from the Diet category, and we compare this data to questions from the Relationships category. We selected Diet because questions posted to this category often ask what to do and/or report what is happening/happened, which makes it easier to see the effect of our predicate nor-malization. We expect expressions such as  X  X  want to lose 10 pounds in a month X  and  X  X  gained 10 pounds X  would occur in Diet . We used the questions posted in June of 2004. (1) Pair 1 . (2) Pair 2 . 4.3.3. Procedure. The procedure of the biased predicate extraction task is listed next. In order to calculate bias in a predicate distribution, we used a chi-square (  X  because a  X  2 test gives a score for distributional differences, making it easy to observe the results.  X  For each group, count the number of question posts in which each predicate oc- X  For each predicate, conduct a  X  2 test to compare the distribution of the predicate  X  Select predicates whose  X  2 score is above 6.635. 4.3.4. Results of Experiment 3. Tables V and VI show several extracted predicates whose  X  2 scores were above the threshold in Pair 1 (i.e., predicates whose distributions were biased towards Internet ), and Tables VII and VIII show those in Pair 2 (i.e., predicates whose distributions were biased towards Diet ). The head word of the predicates in each table is the same ( X  X se X  in Table V,  X  X pen X  in Table VI,  X  X ose X  in Table VII, and  X  X top X  in Table VIII). HEAD represents the result of biased predicate extraction task in which only the head of a predicate is used. ORG represents the result in which we used the original forms of predicates, and NORMED shows the result of normalized predicates.
Table V indicates that in HEAD, the different predicates tukat-te-iru  X  X sing X  and tukai-tai  X  X ant to use X  were all merged into tukau  X  X se. X  Similarly, Table VI reveals that hiraka-nai  X  X an X  X  open X  and hiraku  X  X pen, X  which express opposite meaning, were also merged into hiraku  X  X pen X  in HEAD. This oversimplifies the characteristics of the Internet group, and so fails to obtain the important fact of  X  X anting to use something X  or  X  X ot being able to open something. X  Table VII also shows that hera-nai  X  X an X  X  lose, X  het-te-iru  X  X osing (progressive), X  he-ru  X  X ose X , and het-ta  X  X ost X  were all merged into heru  X  X ose. X  This loses an important distinction between  X  X an X  X  lose X  and  X  X ost X  expressed in Diet .

The use of original surface forms also proved a problem. As shown in Table V, the predicates tukat-te-i-masu  X  X sing (polite), X  tukat-te-iru-no-desu-ga  X  X sing-NOM-COP (polite)-but, X  and tukat-te-i-masu-ga  X  X sing (polite)-but, X  all of which express the same event of  X  X sing, X  were counted separately. This obscures the characteristic of Internet (i.e., the  X  2 scores of these predicates became lower). Not only did the use of ORG obscure the result, but it also failed to obtain important predicates. As shown in Ta-ble VI, no predicate with the head word  X  X pen X  was extracted in the ORG, because the predicates with the head  X  X pen X  appeared in various surface forms and their fre-quencies were miscalculated. This results in failing to extract the predicate phrases hiraku  X  X pen X  and hiraka-nai  X  X an X  X  open X  from the ORG data. A similar tendency is also observed in Tables VII and VIII. The use of ORG fails to extract predicates such as hera-nai  X  X an X  X  lose X  and yamerare-nai  X  X an X  X  stop. X 
When normalized predicates (NORMED) were used, however, these problems of oversimplification and miscalculation seemed to disappear. As shown in Table V, the predicates with the head  X  X se X  were extracted in two different forms of tukat-te-iru  X  X sing X  and tukai-tai  X  X ant to use X  from NORMED with the relatively high  X  indicating the effect of normalization. Furthermore, Table VI shows that only from the NORMED data was the predicate hiraka-nai  X  X an X  X  open X  extracted, because the predicates in HEAD were all oversimplified, losing the meaning of  X  X an X  X  X , while the predicates in ORG were not calculated correctly and so were not extracted. The pred-icate with the head  X  X top X  in Table VIII was only extracted from NORMED. Indeed, a total of 22 different types of predicates in Pair 1 and 36 different types of predicates in Pair 2 were only extracted in NORMED (see Appendix for 22 predicates in Pair 1). In addition, no incomplete predicates which lack appropriate functional expressions were extracted from NORMED, while the ORG data had some (e.g., tukat-te  X  X se (gerundive form) X  in Table V).
 As shown, our normalization system can successfully generate simple predicates that contain only the functional expressions essential for retaining the factual meaning of the predicate. The predicates produced by our system had fewer variations in their sur-face forms, while 81.4% (Last) and 77.5% (Intermediate) of them exactly matched the simplified predicates produced by human annotators, that is, much better performance than the baseline systems.

Accuracies as a Predicate Paraphrase Generator. As the results of Experiment 1 show, the proposed system achieves high accuracy as a paraphrase generator, because the paraphrasing rules are based on a solid analysis of linguistic theories in seman-tics and syntax. The quite low accuracy of the baseline methods, especially SimpAdd and Delete on POS, further supports our claim that implementing linguistic theories in actual NLP applications can greatly improve system performance. Note that these theories on semantics and syntax are not language dependent; they can be applied to other languages.

Error analysis of Experiment 1 reveals that most of the errors were caused either be-cause there were more simplified predicates available or because the generated pred-icates were ungrammatical. We tried to avoid the second problem by using trigram scores as a measure of normalized predicate grammaticality. However, the results in-dicate that we need a more sophisticated system to judge the grammaticality (or nat-uralness) of the output predicates.

Critical errors of our task are those that force normalization to output incorrect pred-icate meaning. We counted the number of these predicates in Last (Open) data. It was found that only 91 instances out of 1,567 (5.8%) could be considered as critical errors. Most of the critical errors happened when there were more than one negation phrase in the predicate. Recall that we simply delete all the negation phrases if the total num-ber of negations is even, and we leave only one if it is odd. Considering the semantic complexity of negations, this deletion rule is too simple, and we need to construct a more sophisticated algorithm to deal with negations. Regardless of these errors, we can say that our normalization system achieves high accuracy as a simple paraphrase generator.

Impact as a Predicate Normalizer on an NLP Application. Experiment 2 revealed that our normalizing system reduced the differences in surface forms of functional ex-pressions by up to 66.7%. This was achieved because we constructed deletion rules ( f  X   X  ), unlike previous studies [Matsuyoshi and Sato 2008; Shirai et al. 1993; Shudo et al. 2004]. Regardless of the domain of the texts, our paraphrasing system can com-press the differences in functional expressions to a limited amount. This is especially important for systems, such as VOC analysis and opinion mining from consumer gen-erated media. In these domains, the surface forms of predicates vary greatly compared to a typical written text, such as news articles, making it hard for the system to deal with these texts. Our normalization system can simplify them by reducing unneces-sary elements.

Experiment 3 revealed that our normalization system has an important effect on the biased predicate extraction task, which we set as a simple text mining operation. By normalizing predicates, the system correctly counted the frequencies of predicates while retaining the crucial meaning of functional expressions. We also analyzed the results of Experiment 3 and found that 22 different types of predicate phrases in Pair 1 and 36 in Pair 2 were extracted from just the NORMED data. These include todoka-nai  X  X aven X  X  received, X  kaisetu-si-tai  X  X ant to set up X , and kie-ta  X  X anished, X  all of which could be important expressions for detecting customers X  needs and wants. By reducing the surface differences of predicates while retaining the crucial meaning, we succeeded in extracting crucial predicate phrases which would not be found if only the surface forms or the head words were used. This effect was observed regardless of the differences in categories (i.e., Internet and Diet) .

By comparing the extracted predicates between the Internet and Diet categories, we also found that predicate phrases on their own gave valuable information for analyz-ing the user experience. For example, the expression  X  can X  X  lose X  in Diet is informative enough to analyze the failure of the user X  X  diet. However, if one needs to extract users X  specific needs and wants, not only is the predicate information necessary, but also its argument information. For example, in Internet , one might need to extract the expres-sion  X  X an X  X  install X  as well as its argument  X  X X printer X  (i.e.,  X  can X  X  install -XX printer  X ). Our future work will be to combine information conveyed by a normalized predicate and by its arguments and observe the effect of correctly capturing users X  needs and wants.

Usability of Paraphrase-Based Normalization. Unlike the study of Brun and Hag ` ege [2003], which produces a symbolic representation for normalizing textual information, we generate simplified natural language paraphrases as normalized forms. One ad-vantage of paraphrasing as a means of normalization is that it is application indepen-dent. Symbolic representations are often constructed in restricted form for use in a particular application, as in Brun and Hag ` ege [2003]. On the other hand, paraphrased forms can be manipulated by various systems, including text mining, as in Experiment 3, as long as the systems process natural language. For example, we could apply our normalization to Japanese-English translation as a preprocessing step to reduce null alignments between Japanese words and English words. Our normalization focuses on the preservation of factual meaning as well as the grammatical correctness of simpli-fied paraphrases. We can expect a lower risk of information loss than is possible with the previous method which simply deletes function words based on their POSs (Lee et al. [2006]), as was criticized by Hong et al. [2009]. An investigation of our normal-ization as applied to machine translation is, however, future work.

Unlike the study by Inui et al. [2008], we did not include the meaning of content words in the normalization system. Therefore, our system is not capable of distin-guishing information in which the semantic analysis of content words plays a crucial role (e.g., distinguishing a complaint such as  X  can X  X  install X  from a compliment such as  X  X an X  X  wait for (getting the iPhone app soon) X  ). However, this does not mean that our normalization is incapable of conducting deeper semantics analysis. Rather, combining the analysis of content words with functional expressions is important. As mentioned in Inui et al. [2008] as well as in Section 1, bag-of-word-based feature extraction, espe-cially if only content words are used, is insufficient for conducting statistically-based deep semantic analysis. If normalized predicates were used instead of a single content word, we could expect an improvement in those statistically-based methods, because each predicate holds important information about fact. In conclusion, we presented a novel normalization technique that paraphrases com-plex functional expressions in Japanese predicates into simplified natural language forms. Paraphrasing rules were constructed based on linguistic theories, and these rules generate paraphrases that, while retaining the crucial information of pred-icative meaning, are syntactically simple but semantically rich. By normalizing functional expressions in predicates, we succeeded in increasing the recall rates of predicate extraction tasks, which is crucial for text mining systems. The results of our study prove the usefulness of paraphrasing as a means of normalizing various linguistic expressions and providing an encouraging indication of its applicability to actual applications.
 In this appendix, we provide a list of predicate phrases that were extracted only when normalized predicates were used in Pair 1 of Experiment 3.

