 Coreference resolution is the task of clustering refer-ring expressions in a text so that each resulting clus-ter represents an entity. It is a very challenging task in natural language processing and it is still far from being solved, i.e. the best reported overall CoNLL score on the CoNLL 2012 English test set is 63.39 (Wiseman et al., 2015).

Text spans referring to an entity are called men-tions. Mentions are the primary objects in a corefer-ence resolution system. As with most previous work on coreference resolution, we only consider men-tions that are noun phrases. However, not all of the noun phrases are mentions. A noun phrase may not refer to any entity at all. The pronoun it in the sen-tence it is raining is an example of a non-referential noun phrase. Noun phrases which do refer to an en-tity (mentions) can be further divided into two cat-egories: mentions referring to entities which only appear once in the discourse (i.e. singletons), and mentions realizing entities that have been referred to more than once in the text (i.e. coreferent men-tions). Henceforth, we refer to both singletons and non-referential phrases as non-coreferent mentions. A large number of mentions that appear in a text are non-coreferent. For instance, more than 80% of mentions are singletons in the OntoNotes English development set (Marneffe et al., 2015).

The latent ranking model is the best perform-ing model for coreference resolution to date (Wise-man et al., 2015; Martschat and Strube, 2015). If we use gold mentions, the latent ranking model of Martschat and Strube (2015) achieves an overall score of 80% on the CoNLL 2012 English test set. This result shows that once we have the ideal pruned search space, the ranking model with the current set of features is reasonably capable of finding corre-sponding entities of mentions. The substantial gap (17%) between the results of the gold mentions and system mentions implies that search space pruning is a promising direction for further improvements in coreference resolution.

Marneffe et al. (2015) examine different search space pruning methods that exist for coreference res-olution. Among those, anaphoricity detection is the most popular method (e.g. Ng and Cardie (2002), Denis and Baldridge (2007), Ng (2009), Zhou and Kong (2009), Durrett and Klein (2013), Martschat and Strube (2015), Wiseman et al. (2015), Peng et al. (2015), and Lassalle and Denis (2015)), while sin-gleton detection is a more recent method (Recasens et al., 2013; Ma et al., 2014; Marneffe et al., 2015).
Anaphoricity detection examines whether a phrase is anaphoric. Singleton detection examines whether a phrase belongs to a coreference chain re-gardless of being anaphor or antecedent. There-fore, anaphoricity detection only prunes the search space of anaphors while singleton detection prunes the search space of both anaphors and antecedents.
Except for Clark and Manning (2015), all of the state-of-the-art coreference resolvers explicitly model anaphoricity detection (Martschat and Strube, 2015; Wiseman et al., 2015; Peng et al., 2015). Therefore, modeling search space pruning as single-ton detection can provide additional information for the state-of-the-art coreference resolution systems.
In this paper we propose a simple but efficient sin-gleton detection model. We first perform intrinsic evaluations and show that our simple model signifi-cantly improves the state-of-the-art results in single-ton detection by a large margin. We then evaluate our singleton model extrinsically on coreference res-olution showing that search space pruning improves different coreference resolution models. In this section we show that pruning the coreference resolution search space is not a very difficult task. By using a simple set of features and a standard classifier, we achieve new state-of-the-art results for classifying coreferent and non-coreferent mentions.
Unlike Marneffe et al. (2015) who use both sur-face (i.e. part-of-speech and n-gram based) features and a large number (123) of carefully designed lin-guistic features, we select a simple and small set of shallow features: 1. lemmas of all words included in the mention; 2. lemmas of the two previous/next words be-3. part-of-speech tags of all words of the mention; 4. part-of-speech tags of the two previous/next 5. complete mention string; 6. length of the mention in words; 7. mention type (proper, nominal, pronominal); 8. whether the whole string of the mention ap-9. whether the head of the mention appears again We use an anchored SVM (Goldberg and Elhadad, 2007) with a polynomial kernel of degree two for classification. When only few features are available, anchored SVMs generalize much better than soft-margin-SVMs (Goldberg and Elhadad, 2009). In our experiments, we use a count threshold for discard-ing vary rare lexical features that occur fewer than 10 times.

Similar to Marneffe et al. (2015), we use three different configurations for evaluation. The Surface configuration only uses the shallow features. The Combined configuration uses the surface features plus the linguistic features introduced by Marneffe et al. (2015). The linguistic features of Marneffe et al. (2015) also include some pairwise combinations of the single features. Since our SVM with a poly-nomial kernel of degree two implicitly models fea-ture pairs, we only include the single features in our Combined configuration. When removing mentions that are classified as non-coreferent during prepro-cessing, precision matters more than recall in order not to over prune coreferent mentions. To achieve higher precision, the Confident configuration uses high confidence predictions of SVM (i.e. classify-ing a mention as non-coreferent if the SVM output is less or equal to -1, and as coreferent if the output is greater or equal to +1). We use the same set of shallow features as Surface for Confident . However, Marneffe et al. (2015) use their combined feature set for Confident . 2.1 Results Table 2 shows the results of our singleton detec-tion model in comparison to that of Marneffe et al. (2015). We train our model on the CoNLL 2012 English training set and evaluate it on the develop-ment set using recall, precision, F1 measure and ac-curacy for both coreferent and non-coreferent men-tions. Unlike Marneffe et al. (2015) that also use some gold annotations for their features, we extract all of our surface features from  X  X uto_conll X  files. Therefore, only predicted annotations are used.
The incorporation of linguistic features in Marn-effe et al. (2015) improves the classification of both coreferent and non-coreferent mentions by about 1 percent in comparison to the Surface results. How-ever, in our case, the linguistic features only improve the results by about 0.1 percent.

As the results show, by only using shallow fea-tures, we achieve a new state-of-the-art performance for singleton detection that improves the results of Marneffe et al. (2015) by a large margin for classi-fying both coreferent and non-coreferent mentions. 2.2 Error Analysis For a singleton detector, precision errors (classify-ing a coreferent mention as non-coreferent) are more harmful than recall errors. If a coreferent mention is classified as non-coreferent, the recall of the coref-erence resolver that uses the singleton detector will decrease. On the other hand, recall errors only af-fect the singleton detector itself and not coreference resolvers.

The precision error ratios of our Surface and Con-fident systems for proper name (NAM), nominal (NOM) and pronominal (PRO) mentions are listed in Table 2. For each mention type, Table 2 also shows the precision error ratio by mention type re-lated to the mentions that are first mentions of their corresponding entities. For example, in the Confi-dent system 73.45% of the nominal mentions that are incorrectly classified as non-coreferent are first mentions of their corresponding entities. As can be seen, many of the precision errors in both Surface and Confident systems are errors in which the first mention of an entity is detected as non-coreferent. Detecting whether a mention will be referred to later, is indeed very hard and requires more context infor-mation. Features (8) and (9) from our feature set are designed to address the correct detection of the first mentions of entities to a limited degree. These fea-tures only address first mentions of entities that are Surface Confident referred to by later mentions with head or complete string match. More features considering properties of other mentions, rather than the examined mention itself, are required in order to improve the correct detection of the first mentions of entities.
Table 3 shows the ratio of recall errors for each mention type. For our Surface system, this ratio is more or less the same for different mention types. However, Confident  X  X  main source of recall errors is the detection of non-coreferent nominal mentions. 2.3 Discussion Our results significantly outperform the results of Marneffe et al. (2015) who use both surface features and a set of hand-engineered features targeting dif-ferent linguistic phenomena related to the task. Our findings are mirrored by Durrett and Klein (2013) X  X  work on the coreference resolution task. Durrett and Klein (2013) show that a coreference resolution sys-tem that uses surface features can outperform those using hand-engineered linguistic features.

Linguistic features like syntactic nearness (on which Hobbs X  algorithm (Hobbs, 1978) is based), morpho-syntactic and semantic agreement (e.g. number, gender and semantic class agreements), re-cency, focus (Grosz and Sidner, 1986), and center-ing (Brennan et al., 1987) are examples of useful linguistic features for coreference resolution which have the additional benefit of being applicable to dif-ferent languages. For example, Hobbs X  algorithm and agreement features are being used successfully in the Stanford system (Lee et al., 2013). How-ever, apart from features like these, a large number of linguistically motivated features have been pro-posed which either do not have a significant impact or are only applicable to a specific language or do-main. Therefore, designing general linguistic fea-tures which provide information that is not captured by surface features deserve more attention in order to gain higher recall and better generalization.
We combine a simple set of surface features with a standard machine learning model that can handle a large number of surface features. This leads to a new state-of-the-art singleton detection with high preci-sion that can easily be incorporated in a coreference resolution system for pruning non-coreferent men-tions. In this section, we investigate the effect of search space pruning on coreference resolution. We choose the Stanford rule-based system (Lee et al., 2013) and our baselines for coreference resolution. Wiseman et al. (2015) is the best performing coreference res-olution system to date. However, we choose Cort as our learning-based baseline because Cort is a frame-work that allows evaluations on various coreference resolution models, i.e. ranking, antecedent trees, and pairwise. The pairwise model is the most commonly used model in coreference resolution, and latent ranking is the best performing model for coreference resolution to date (Wiseman et al., 2015; Martschat and Strube, 2015). 3.1 Results Table 4 shows the results of integrating singleton detection into different coreference resolution ap-proaches. We evaluate the systems on the CoNLL 2012 English test set using the M U C (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), and CEAF e (Luo, 2005) measures as provided by the CoNLL coreference scorer version 8.01 (Pradhan et al., 2014). According to the approximate random-ization test (Noreen, 1989), all of the improvements made by our singleton detection module are statisti-cally significant ( p &lt; 0 . 05 ).

Baseline shows the result of the Stanford system without using singleton detection. +Stanford Single-ton is the result of the Stanford system including its singleton detection module (Recasens et al., 2013). +Preprocess Pruning is the result when our Confi-dent model from Section 2 is used.

The singleton detection modules of Recasens et al. (2013) and Marneffe et al. (2015) are incorpo-rated in the Stanford system in a heuristic way: if both anaphor and antecedent are classified as single-ton, and none of them is a named entity, then those mentions will be disregarded. However, since our Confident model does have a high precision, we use it for removing all non-coreferent mentions in a pre-processing step. As shown in Table 4, our singleton detection improves the overall score of the Baseline system by about 2 percent on the test set.

Cort uses a perceptron for learning. Therefore, we use a perceptron in Cort while an anchored SVM would have performed slightly better. We also in-clude all the additional features that are used in Cort for our Cort singleton detection model. SVM accu-racy with surface features on the development set is about 0.1 percent better than that of the perceptron with Cort X  X  additional features.

For the pairwise model, singleton detection is per-formed in a preprocessing step. The singleton detec-tion module improves the overall performance of the pairwise model by about 1 percent on the test set.
The Cort latent model already performs search space pruning in the form of anaphoricity detection. Additional pruning of potential anaphors in the pre-processing step by the singleton model hurts the re-call of the latent model. Therefore, we add the out-put of the singleton model as a new feature for both anaphor and antecedent. For obtaining these fea-tures for training, we split the training data into two halves and train a singleton perceptron separately on each half. The values of the singleton feature for the first half are computed based on the model that is trained on the second half, and vice versa. This way, the accuracy of singleton features on both training and testing is similar. If we would train the singleton model on the whole training data, we would over-fit the model seriously. The values of the singleton feature would be very accurate on the training data, and the learner would overestimate the importance of this feature.

The new feature improves the overall perfor-mance of the latent ranking model by about 0.5 percent on the test set. This result is the best re-ported overall score for coreference resolution on the CoNLL 2012 English test set to date.

The singleton feature support is added to the Cort source code. It is available at http://github.com/smartschat/cort. 3.2 Discussion Recent improvements in coreference resolution have been made by exploring more complex learning and inference strategies, a larger number of features, and joint processing. There are also technically vi-able solutions for improving the performance of a coreference resolver which do not work in prac-tice. For instance, since coreference resolution is a set partitioning problem, entity-based models seem to be more suitable for coreference resolution than mention-pair models. However, entity-based mod-els do not necessarily perform better than mention-pair models (e.g. Ng (2010) and Moosavi and Strube (2014)). The same is true for incorporating more semantic-level information in a coreference resolu-tion system (e.g. Durrett and Klein (2013)).
In this paper, we show that coreference resolution can also simply be improved by performing search space pruning. The significant gap between the per-formance of the latent ranking model on gold men-tions and on system mentions indicates that there is still room for further improvements in search space pruning. We achieve new state-of-the-art results for singleton detection by only using shallow features and simple classifiers. We also show that search space pruning significantly improves different coreference resolu-tion models. The substantial gap between the per-formance on gold mentions and on system mentions indicates that there is still plenty of room for further improvements in singleton detection. Therefore, search space pruning is a promising direction for fur-ther improvements in coreference resolution. The proposed singleton detector as a feature for coref-erence resolvers is implemented for the Cort coref-erence resolver. It is available with the Cort source code.
 The authors would like to thank Sebastian Martschat for his help to use the proposed singleton detec-tor in the Cort coreference resolver. We would also like to thank Mark-Christoph M  X  uller, Benjamin Heinzerling, Mohsen Mesgar, Daraksha Parveen and Alex Judea for their helpful comments. This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. The first author has been supported by a Heidelberg Institute for Theoretical Studies PhD. scholarship.
