 Rishabh Iyer rkiyer@u.washington.edu University of Washington, Seattle, WA 98195, USA Stefanie Jegelka stefje@eecs.berkeley.edu University of California, Berkeley, CA 94720, USA Jeff Bilmes bilmes@u.washington.edu University of Washington, Seattle, WA 98195, USA In this paper, we address minimization and maximiza-tion problems of the following form: Problem 1: min where f : 2 V  X  R is a discrete set function on subsets of a ground set V = { 1 , 2 ,  X  X  X  ,n } , and C  X  2 V is a family of feasible solution sets. The set C could express, for example, that solutions must be an independent set in a matroid, a limited budget knapsack, or a cut (or spanning tree, path, or matching) in a graph. Without making any further assumptions about f , the above problems are trivially worst-case exponential time and moreover inapproximable.
 If we assume that f is submodular, however, then in many cases the above problems can be approximated and in some cases solved exactly in polynomial time. A function f : 2 V  X  R is said to be submodular (Fujishige, 2005) if for all subsets S,T  X  V , it holds that f ( S ) + j )  X  f ( S ) as the gain of j  X  V with respect to S  X  V , then f is submodular if and only if f ( j | S )  X  f ( j | T ) for all S  X  T and j /  X  T . Traditionally, submodularity has been a key structural property for problems in combinatorial optimization, and for applications in econometrics, circuit and game theory, and operations research. More recently, submodularity X  X  popularity in machine learning has been on the rise.
 On the other hand, a potential stumbling block is that machine learning problems are often large (e.g.,  X  X ig data X ) and are getting larger. For general uncon-strained submodular minimization, the computational complexity often scales as a high-order polynomial. These algorithms are designed to solve the most general case and the worst-case instances are often contrived and unrealistic. Typical-case instances are much more benign, so simpler algorithms (e.g., graph-cut) might suffice. In the constrained case, however, the problems often become NP-complete. Algorithms for submod-ular maximization are very different in nature from their submodular minimization cohorts, and their com-plexity too varies depending on the problem. In any case, there is an urgent need for efficient, practical, and scalable algorithms for the aforementioned problems if submodularity is to have a lasting impact on the field of machine learning.
 In this paper, we address the issue of scalability and simultaneously draw connections across the apparent gap between minimization and maximization problems. We demonstrate that many algorithms for submodu-lar maximization may be viewed as special cases of a generic minorize-maximize framework that relies on discrete semidifferentials. This framework encompasses state-of-the-art greedy and local search techniques, and provides a rich class of very practical algorithms. In addition, we show that any approximate submodular maximization algorithm can be seen as an instance of our framework.
 We also present a complementary majorize-minimize framework for submodular minimization that makes two contributions. For unconstrained minimization, we obtain new nontrivial bounds on the lattice of minimiz-ers, thereby reducing the possible space of candidate minimizers. This method easily integrates into any other exact minimization algorithm as a preprocessing step to reduce running time. In the constrained case, we obtain practical algorithms with bounded approx-imation factors. We observe these algorithms to be empirically competitive to more complicated ones. As a whole, the semidifferential framework offers a new unifying perspective and basis for treating submodu-lar minimization and maximization problems in both the constrained and unconstrained case. While it has long been known (Fujishige, 2005) that submodular functions have tight subdifferentials, our results rely on a recently discovered property (Iyer &amp; Bilmes, 2012a; Jegelka &amp; Bilmes, 2011b) showing that submodular functions also have superdifferentials. Furthermore, our approach is entirely combinatorial, thus complementing (and sometimes obviating) related relaxation methods. Submodularity X  X  escalating popularity in machine learn-ing is due to its natural applicability. Indeed, instances of Problems 1 and 2 are seen in many forms, to wit: MAP inference/Image segmentation: Markov Random Fields with pairwise attractive potentials are important in computer vision, where MAP inference is identical to unconstrained submodular minimization solved via minimum cut (Boykov &amp; Jolly, 2001). A richer higher-order model can be induced for which MAP inference corresponds to Problem 1 where V is a set of edges in a graph, and C is a set of cuts in this graph  X  this was shown to significantly improve many image segmentation results (Jegelka &amp; Bilmes, 2011b). Moreover, Delong et al. (2012) efficiently solve MAP inference in a sparse higher-order graphical model by restating the problem as a submodular vertex cover, i.e., Problem 1 where C is the set of all vertex covers in a graph.
 Clustering: Variants of submodular minimization have been successfully applied to clustering problems (Narasimhan et al., 2006; Nagano et al., 2010). Limited Vocabulary Speech Corpora: The prob-lem of finding a maximum size speech corpus with bounded vocabulary (Lin &amp; Bilmes, 2011a) can be posed as submodular function minimization subject to a size constraint. Alternatively, cardinality can be treated as a penalty, reducing the problem to un-constrained submodular minimization (Jegelka et al., 2011).
 Size constraints: The densest k -subgraph and size-constrained graph cut problems correspond to submod-ular minimization with cardinality constraints, prob-lems that are very hard (Svitkina &amp; Fleischer, 2008). Specialized algorithms for cardinality and related con-straints were proposed e.g. in (Svitkina &amp; Fleischer, 2008; Nagano et al., 2011).
 Minimum Power Assignment: In wireless net-works, one seeks a connectivity structure that maintains connectivity at a minimum energy consumption. This problem is equivalent to finding a suitable structure (e.g., a spanning tree) minimizing a submodular cost function (Wan et al., 2002).
 Transportation: Costs in real-world transportation problems are often non-additive. For example, it may be cheaper to take a longer route owned by one carrier rather than a shorter route that switches carriers. Such economies of scale, or  X  X ight of usage X  properties are captured in the  X  X ategorized Bottleneck Path Prob-lem X   X  a shortest path problem with submodular costs (Averbakh &amp; Berman, 1994). Similar costs have been considered for spanning tree and matching problems. Summarization/Sensor placement: Submodular maximization also arises in many subset extraction problems. Sensor placement (Krause et al., 2008), docu-ment summarization (Lin &amp; Bilmes, 2011b) and speech data subset selection (Lin &amp; Bilmes, 2009), for example, are instances of submodular maximization.
 Determinantal Point Processes: The Determi-nantal Point Processes (DPPs) which have found nu-merous applications in machine learning (Kulesza &amp; Taskar, 2012) are known to be log-submodular distri-butions. In particular, the MAP inference problem is a form of non-monotone submodular maximization. Indeed, there is strong motivation for solving Problems 1 and 2 but, as mentioned above, these problems come not without computational difficulties. Much work has therefore been devoted to developing optimal or near optimal algorithms. Among the several algorithms (McCormick, 2005) for the unconstrained variant of Problem 1, where C = 2 V , the best complexity to date is O ( n 5  X  + n 6 ) (Orlin, 2009) (  X  is the cost of evaluating f ). This has motivated studies on faster, possibly special case or approximate, methods (Stobbe &amp; Krause, 2010; Jegelka et al., 2011). Constrained minimization problems, even for simple constraints such as a cardinality lower bound, are mostly NP-hard, and not approximable to within better than a polynomial factor. Approximation algorithms for these problems with various techniques have been studied in (Svitkina &amp; Fleischer, 2008; Iwata &amp; Nagano, 2009; Goel et al., 2009; Jegelka &amp; Bilmes, 2011a). Unlike submodular minimization, all forms of submodular maximization are NP-hard. Most such problems, however, admit constant-factor approximations, which are attained via very simple combinatorial algorithms (Nemhauser et al., 1978; Buchbinder et al., 2012). Majorization-minimization (MM) 1 algorithms are known to be useful in machine learning (Hunter &amp; Lange, 2004). Notable examples include the EM algorithm (McLachlan &amp; Krishnan, 1997) and the convex-concave procedure (Yuille &amp; Rangarajan, 2002). Discrete instances have been used to minimize the difference between submodular functions (Narasimhan &amp; Bilmes, 2005; Iyer &amp; Bilmes, 2012b), but these algorithms generally lack theoretical guarantees. This paper shows, by contrast, that for submodular optimization, MM algorithms have strong theoretical properties and empirically work very well. We first briefly introduce submodular semidifferentials. Throughout this paper, we assume normalized sub-modular functions (i.e., f (  X  ) = 0). The subdifferential  X  ( Y ) of a submodular set function f : 2 V  X  R for a set Y  X  V is defined (Fujishige, 2005) analogously to the subdifferential of a continuous convex function:  X  f ( Y ) = { y  X  R n : (1) For a vector x  X  R V and X  X  V , we write x ( X ) = P j  X  X x ( j )  X  in such case, we say that x is a normal-ized modular function. We shall denote a subgradient at Y by h Y  X   X  f ( Y ). The extreme points of  X  f ( Y ) may be computed via a greedy algorithm: Let  X  be a permutation of V that assigns the elements in Y to the first | Y | positions (  X  ( i )  X  Y if and only if i  X | Y | ). Each such permutation defines a chain with elements S 0 =  X  , S This chain defines an extreme point h  X  Y of  X  f ( Y ) with entries Surprisingly, we can also define superdifferentials  X  f ( Y ) of a submodular function (Jegelka &amp; Bilmes, 2011b; Iyer &amp; Bilmes, 2012a) at Y :  X  f ( Y ) = { y  X  R n : (3) We denote a generic supergradient at Y by g Y . It is easy to show that the polyhedron  X  f is non-empty. We define three special supergradients  X  g Y ( X  X row X ),  X  g ( X  X hrink X ) and  X  g Y as follows (Iyer &amp; Bilmes, 2012a): For a monotone submodular function, i.e., a function satisfying f ( A )  X  f ( B ) for all A  X  B  X  V , the sub-and supergradients defined here are nonnegative. With the above semigradients, we can define a generic MM algorithm. In each iteration, the algorithm opti-mizes a modular approximation formed via the current solution Y . For minimization, we use an upper bound and for maximization a lower bound Both these bounds are tight at the current solution, satisfying m g Y ( Y ) = m h Y ( Y ) = f ( Y ). In almost all cases, optimizing the modular approximation is much faster than optimizing the original cost function f . Algorithm 1 Subgradient ascent [descent] algorithm for submodular maximization [minimization] 1: Start with an arbitrary X 0 . 2: repeat 3: Pick a semigradient h X t [ g X t ] at X t 5: t  X  t + 1 6: until we have converged ( X i  X  1 = X i ) Algorithm 1 shows our discrete MM scheme for maxi-mization (MMax) [and minimization (MMin)] , and for both constrained and unconstrained settings. Since we are minimizing a tight upper bound, or maximizing a tight lower bound, the algorithm must make progress. Lemma 4.1. Algorithm 1 monotonically improves the objective function value for Problems 1 and 2 at every iteration, as long as a linear function can be exactly optimized over C .
 Proof. By definition, it holds that f ( X t +1 )  X  m that The observation that Algorithm 1 monotonically in-creases the objective of maximization problems follows analogously.
 Contrary to standard continuous subgradient descent schemes, Algorithm 1 produces a feasible solution at each iteration, thereby circumventing any rounding or projection steps that might be challenging under certain types of constraints. In addition, it is known that for relaxed instances of our problems, subgradient descent methods can suffer from slow convergence (Bach, 2011). Nevertheless, Algorithm 1 still relies on the choice of the semigradients defining the bounds. Therefore, we next analyze the effect of certain choices of semigradients. For minimization problems, we use MMin with the su-pergradients  X  g X ,  X  g X and  X  g X . In both the unconstrained and constrained settings, this yields a number of new approaches to submodular minimization. 5.1. Unconstrained Submodular Minimization We begin with unconstrained minimization, where C = 2
V in Problem 1. Each of the three supergradients yields a different variant of Algorithm 1, and we will call the resulting algorithms MMin-I, II and III, respectively. We make one more assumption: of the minimizing arguments in Step 4 of Algorithm 1, we always choose a set of minimum cardinality.
 MMin-I is very similar to the algorithms proposed in (Jegelka et al., 2011). Those authors, however, de-compose f and explicitly represent graph-representable parts of the function f . We do not require or consider such a restriction here.
 Let us define the sets A = { j : f ( j | X  ) &lt; 0 } and B = { j : f ( j | V \{ j } )  X  0 } . Submodularity implies that A  X  B , and this allows us to define a lattice 2 L = [ A,B ] whose least element is the set A and whose greatest element is the set is B . This sublattice L of [  X  ,V ] retains all minimizers X  X  (i.e., A  X  X  X   X  B for all X  X  ): Lemma 5.1. (Fujishige, 2005) Let L  X  be the lattice of the global minimizers of a submodular function f . Then L  X   X  X  , where we use  X  to denote a sublattice. Lemma 5.1 has been used to prune down the search space of the minimum norm point algorithm from the power set of V to a smaller lattice (Bach, 2011; Fujishige &amp; Isotani, 2011). Indeed, A and B may be obtained by using MMin-III: Lemma 5.2. With X 0 =  X  and X 0 = V , MMin-III returns the sets A and B , respectively. Initialized by an arbitrary X 0 , MMin-III converges to ( X 0  X  B )  X  A . Proof. When using X 0 =  X  , we obtain X 1 = argmin X f (  X  ) + P j  X  X f ( j ) = A . Since A  X  B , the algorithm will converge to X 1 = A . At this point, no more elements will be added, since for all i /  X  A we have  X  g X 1 ( i ) = f ( i |  X  ) &gt; 0. Moreover, the algorithm will not remove any elements: for all i  X  A , it holds that  X  g X 1 ( i ) = f ( i | V \ i )  X  f ( i )  X  0. By a similar argumentation, the initialization X 0 = V will lead to X 1 = B , where the algorithm terminates. If we start with any arbitrary X 0 , MMin-III will remove the ele-ments j with f ( j | V \ j ) &gt; 0 and add the element j with f ( j | X  ) &lt; 0. Hence it will add the elements in A that are not in X 0 and remove those element from X 0 that are not in B . Let the resulting set be X 1 . As before, for so these elements will not be removed in any possible subsequent iteration. The elements i  X  X 1 \ A were not removed, so f ( i | V \ i )  X  0. Hence, no more elements will be removed after the first iteration. Similarly, no elements will be added since for all i /  X  X 1 , it holds that f ( i | X  )  X  f ( i | V \ i ) &gt; 0.
 Lemma 5.2 implies that MMin-III effectively provides a contraction of the initial lattice to L , and, if X is not in L , it returns a set in L . Henceforth, we therefore assume that we start with a set X 0  X  X  . While the known lattice L has proven useful for warm-starts, MMin-I and II enable us to prune L even further. Let A + be the set obtained by starting MMin-I at X 0 =  X  , and B + be the set obtained by starting MMin-II at X 0 = V . This yields a new, smaller sublattice L + = [ A + ,B + ] that retains all minimizers: Theorem 5.3. For any minimizer X  X   X  L , it holds that A  X  A +  X  X  X   X  B +  X  B . Hence L  X   X  L +  X  L . Furthermore, when initialized with X 0 =  X  and X 0 = V , respectively, both MMin-I and II converge in O ( n ) iterations to a local minimum of f .
 By a local minimum, we mean a set X that satisfies f ( X )  X  f ( Y ) for any set Y that differs from X by a single element. We point out that Theorem 5.3 generalizes part of Lemma 3 in (Jegelka et al., 2011). For the proof, we build on the following Lemma: Lemma 5.4. Every iteration of MMin-I can be writ-ten as X t +1 = X t  X  { j : f ( j | X t ) &lt; 0 } . Simi-larly, every iteration of MMin-II can be expressed as X t +1 = X t \{ j : f ( j | X t \ j ) &gt; 0 } . Proof. (Lemma 5.4) Throughout this paper, we as-sume that we select only the minimal minimizer of the modular function at every step. In other words, we do not choose the elements that have zero marginal cost. We observe that in iteration t + 1 of MMin-I, we add the elements i with  X  g X t ( i ) &lt; 0, i.e., X t +1 = X f ( j | X t ) &lt; 0 } . No element will ever be removed, since  X  g
X t ( i ) = f ( i | V \ i )  X  f ( i | X t  X  1 )  X  0. If we start with X 0 =  X  , then after the first iteration, it holds that X 1 = argmin X f (  X  ) + P j  X  X f ( j ). Hence X 1 MMin-I terminates when reaching a set A + , where f ( j | A + )  X  0, for all j /  X  A + .
 The analysis of MMin-II is analogous. In iteration t + 1, we remove the elements i with  X  g X t ( i ) &gt; 0, i.e., X t +1 = X t \{ j : f ( j | X t  X  j ) &gt; 0 } . Similarly to the argumentation above, MMin-II never adds any elements. If we begin with X 0 = V , then X 1 = arg min X f ( V ) + P j  X  V \ X f ( j | V  X  X  j } ), and therefore X 1 = B . MMin-II terminates with a set B + .
 Now we can prove Theorem 5.3.
 Proof. (Thm. 5.3) Since, by Lemma 5.4, MMin-I only adds elements and MMin-II only removes elements, at least one in each iteration, both algorithms terminate after O ( n ) iterations.
 Let us now turn to the relation of X  X  to A and B . Since f ( i ) &lt; 0 for all i  X  A , the set X 1 = A found in the first iteration of MMin-I must be a subset of X  X  . Consider any subset X t  X  X  X  . Any element j for which f ( j | X t ) &lt; 0 must be in X  X  as well, because by submodularity, f ( j | X  X  )  X  f ( j | X t ) &lt; 0. This means f ( X  X   X  j ) &lt; f ( X  X  ), which would otherwise contradict the optimality of X  X  . The set of such j is exactly X t +1 and therefore X t +1  X  X  X  . This induction shows that MMin-I, whose first solution is A  X  X  X  , always returns a subset of X  X  . Analogously, B  X  X  X  , and MMin-II only removes elements j /  X  X  X  .
 Finally, we argue that A + is a local minimum; the proof for B + is analogous. Algorithm MMin-I generates a chain  X  = X 0  X  X 1  X  X 2  X  X  X   X  A + = X T . For any t  X  T , consider j  X  X t \ X t  X  1 . Submodularity implies follows from the fact that j was added in iteration t . Therefore, removing any j  X  A + will increase the cost. Regarding the elements i /  X  A + , we observe that MMin-I has terminated, which implies that f ( i | A + )  X  0. Hence, adding i to A + will not improve the solution, and A + is a local minimum.
 Theorem 5.3 has a number of nice implications. First, it provides a tighter bound on the lattice of minimizers of the submodular function f that, to the best of our knowledge, has not been used or mentioned before. The sets A + and B + obtained above are guaranteed to be supersets and subsets of A and B , respectively, as illustrated in Figure 2. This means we can start any algorithm for submodular minimization from the lattice L + instead of the initial lattice 2 V or L . When using an algorithm whose running time is a high-order polynomial of | V | , any reduction of the ground set V is beneficial. Second, each iteration of MMin takes linear time. Therefore, its total running time is O ( n 2 ). Third, Theorem 5.3 states that both MMin-I and II converge to a local minimum. This may be counter-intuitive if one considers that each algorithm either only adds or only removes elements. In consequence, a local minimum of a submodular function can be obtained in O ( n 2 ), a fact that is of independent interest and that does not hold for local maximizers (Feige et al., 2007). The following example illustrates that L + can be a strict subset of L and therefore provides non-trivial pruning. Let w 1 ,w 2  X  R V , w 1  X  0 be two vectors, each defining a linear (modular) function. Then the func-tion f ( X ) = p w 1 ( X ) + w 2 ( X ) is submodular. Specifi-The tightened sublattice contains exactly the mini-mizer: A + = B + = X  X  = [1 , 6 , 7 , 8 , 10]. As a refinement to Theorem 5.3, we can show that MMin-I and MMin-II converge to the local minima of lowest and highest cardinality, respectively.
 Lemma 5.5. The set A + is the smallest local mini-mum of f (by cardinality), and B + is the largest. More-over, every local minimum Z is in L + : Z  X  L + for every local minimum Z .
 Proof. The proof proceeds analogously to the proof of Theorem 5.3. Let Y s be the local minimum of smallest-cardinality, and Y ` the largest one. First, we note that X 0 =  X   X  Y s . For induction, assume that X t  X  Y . For contradiction, assume there is an element j  X  X t +1 that is not in Y s . Since j  X  X t +1 \ X t , it holds by construction that f ( j | Y s )  X  f ( j | X t ) &lt; 0, implying that f ( Y s  X  j ) &lt; f ( Y s ). This contradicts the local optimality of Y s , and therefore it must hold that X t +1  X  Y s . Consequently, A +  X  Y s . But A + is itself a local minimum, and hence equality holds. The result for B + follows analogously.
 By the same argumentation as above for Y s and Y ` , we conclude that each local minimum Z satisfies A +  X  Z  X  B + , and therefore Z  X  X  +  X  X  .
 As a corollary, Lemma 5.5 implies that if a submodular function has a unique local minimum, MMin-I and II must find this minimum, which is a global one. In the following we consider two extensions of MMin-I and II. First, we analyze an algorithm that alternates between MMin-I and MMin-II. While such an algorithm does not provide much benefit when started at X 0 =  X  or X 0 = V , we see that with a random initialization X 0 = R , the alternation ensures convergence to a local minimum. Second, we address the question of which supergradients to select in general. In particular, we show that the supergradients  X  g and  X  g subsume alternativee supergradients and provide the tightest results with MMin. Hence, our results are the tight. Alternating MMin-I and II and arbitrary ini-tializations. Instead of running only one of MMin-I and II, we can run one until it stops and then switch to the other. Assume we initialize both algorithms with a random set X 0 = R  X  X  + . By Theorem 5.3, we know that MMin-I will return a subset R 1  X  R (no element will be removed because all removable elements are not in B , and R  X  B by assumption). When MMin-I j /  X  R 1 , and therefore R 1 cannot be increased using  X  g 1 . We will call such a set an I-minimum . Similarly, MMin-II returns a set R 1  X  R from which, considering that  X  g R 1 ( j ) = f ( j | R 1 \ j )  X  0 for all j  X  R 1 ments can be removed. We call such a non-decreasable set a D-minimum . Every local minimum is both an I-minimum and a D-minimum.
 We can apply MMin-II to the I-minimum R 1 returned by MMin-I. Let us call the resulting set R 2 . Analo-gously, applying MMin-I to R 1 yields R 2  X  R 1 . Lemma 5.6. The sets R 2 and R 2 are local optima. Furthermore, R 1  X  R 2  X  R 2  X  R 1 .
 Proof. It is easy to see that A  X  R 1  X  B , and A  X  R 1  X  B . By Lemma 5.4, MMin-I applied to R 1 will only add elements, and MMin-II on R 1 will only remove elements. Since R 1 is an I-minimum, adding an element j  X  V \ R 1 to any set X  X  R 1 never helps, and therefore R 1 contains all of R 1 , R 2 and R 2 . Similarly, R 1 is contained in R 2 , R 2 and R 1 . In consequence, it suffices to look at the contracted lattice [ R 1 ,R 1 ], and any local minimum in this sublattice is a local minimum on [  X  ,V ]. Theorem 5.3 applied to the sublattice [ R 1 ,R 1 ] (and the submodular function restricted to the sublattice) yields the inclusion R 2  X  R 2 , so R 1  X  R 2  X  R 2  X  R 1 , and both R 2 and R 2 are local minima.
 The following lemma provides a more general view. Lemma 5.7. Let S 1  X  S 1 be such that S 1 is an I-minimum and S 1 is a D-minimum. Then there exist local minima S 2  X  S 2 in [ S 1 ,S 1 ] such that initializing with any X 0  X  [ S 1 ,S 1 ] , an alternation of MMin-I and II converges to a local minimum in [ S 2 ,S 2 ] , and Proof. Let S 2 ,S 2 be the smallest and largest local min-ima within [ S 1 ,S 1 ]. By the same argumentation as for Lemma 5.6, using X 0  X  [ S 1 ,S 1 ] leads to a local minimum within [ S 2 ,S 2 ]. Since by definition all lo-cal optima in [ S 1 ,S 1 ] are within [ S 2 ,S 2 ], the global minimum within [ S 1 ,S 1 ] will also be in [ S 2 ,S 2 ]. The above lemmas have a number of implications for minimization algorithms. First, many of the properties for initializing with V or the empty set can be trans-ferred to arbitrary initializations. In particular, the succession of MMin-I and II will terminate in O ( n 2 ) it-erations, regardless of what X 0 is. Second, Lemmas 5.6 and 5.7 provide useful pruning opportunities: we can prune down the initial lattice to [ R 2 ,R 2 ] or [ S 2 ,S respectively. In particular, if any global optimizer of f is contained in [ S 1 ,S 1 ], it will also be contained in [ S Choice of supergradients. We close this section with a remark about the choice of supergradients. The following Lemma states how  X  g X and  X  g X subsume al-ternative choices of supergradients and MMin-I and II lead to the tightest results possible.
 Lemma 5.8. Initialized with X 0 =  X  , Algorithm 1 will converge to a subset of A + with any choice of supergradients. Initialized with X 0 = V , the algorithm will converge to a superset of B + with any choice of supergradients. If X 0 is a local minimum, then the algorithm will not move with any supergradient. The proof of Lemma 5.8 is very similar to the proof of Theorem 5.3. 5.2. Constrained submodular minimization MMin straightforwardly generalizes to constraints more complex than C = 2 V , and Theorem 5.3 still holds for more general lattices or ring family constraints. Beyond lattices, MMin applies to any set of constraints C as long as we have an efficient algorithm at hand that minimizes a nonnegative modular cost function over C . This subroutine can even be approximate. Such algorithms are available for cardinality bounds, inde-pendent sets of a matroid and many other combinatorial constraints such as trees, paths or cuts.
 As opposed to unconstrained submodular minimization, almost all cases of constrained submodular minimiza-tion are very hard (Svitkina &amp; Fleischer, 2008; Jegelka &amp; Bilmes, 2011a; Goel et al., 2009), and admit at most approximate solutions in polynomial time. The next theorem states an upper bound on the approximation factor achieved by MMin-I for nonnegative, nonde-creasing cost functions. An important ingredient in the bound is the curvature (Conforti &amp; Cornuejols, 1984) of a monotone submodular function f , defined as Theorem 5.9. Let X  X   X  argmin X  X  X  f ( X ) . The solu-tion b X returned by MMin-I satisfies f ( b
X )  X  If the minimization in Step 4 is done with approxima-tion factor  X  , then f ( b X )  X   X / (1  X   X  f ) f ( X  X  ) . Before proving this result, we remark that a similar, slightly looser bound was shown for cuts in (Jegelka &amp; Bilmes, 2011b), by using a weaker notion of curvature. Note that the bound in Theorem 5.9 is at most problem.
 Proof. We will use the shorthand g ,  X  g  X  . To prove The-orem 5.9, we use the following result shown in (Jegelka, 2012): for any i  X  V . We now transfer this result to curvature. To do so, we use i 0  X  arg max i  X  V f ( i ), so that g ( X P For problems where  X  f &lt; 1, Theorem 5.9 yields a constant approximation factor and refines bounds for constrained minimization that are given in (Goel et al., 2009; Svitkina &amp; Fleischer, 2008). To our knowledge, this is the first curvature dependent bound for this general class of minimization problems.
 A class of functions with  X  f = 1 are matroid rank functions, implying that these functions are difficult instances the MMin algorithms. But several classes of functions occurring in applications have more be-nign curvature. For example, concave over modular functions were used in (Lin &amp; Bilmes, 2011b; Jegelka &amp; Bilmes, 2011b). These comprise, for instance, func-tions of the form f ( X ) = ( w ( X )) a , for some a  X  [0 , 1] and a nonnegative weight vector w , whose curvature f ( X ) = | X | a , with curvature  X  f = 1  X  an a  X  1 f ( X ) = log(1 + w ( X )) satisfying  X  f  X  1  X  min j w ( j ) The bounds of Theorem 5.9 hold after the first iter-ation. Nevertheless, empirically we often found that for problem instances that are not worst-case, subse-quent iterations can improve the solution substantially. Using Theorem 5.9, we can bound the number of iter-ations the algorithm will take. To do so, we assume an  X  -approximate version, where we proceed only if f ( X t +1 )  X  (1  X   X  ) f ( X t ) for some  X  &gt; 0. In practice, the algorithm usually terminates after 5 to 10 iterations for an arbitrarily small  X  .
 Lemma 5.10. MMin-I runs in time for minimizing a modular function subject to X  X  X  .
 Proof. At the end of the first iteration, we obtain a approximate assumption implies that f ( X t +1 )  X  (1  X   X  ) f ( X t )  X  (1  X   X  ) t f ( X 1 ). Using that log (1  X   X  )  X   X  and Theorem 5.9, we see that the algorithm terminates 5.3. Experiments We will next see that, apart from its theoretical proper-ties, MMin is in practice competitive to more complex algorithms. We implement and compare algorithms using Matlab and the SFO toolbox (Krause, 2010). Unconstrained minimization We first study the results in Section 5.1 for contracting the lattice of possible minimizers. We measure the size of the new lattices relative to the ground set. Applying MMin-I and II (lattice L + ) to Iwata X  X  test function (Fujishige &amp; Isotani, 2011), we observe an average reduction of 99 . 5% in the lattice. MMin-III (lattice L ) obtains only about 60% reduction. Averages are taken for n between 20 and 120.
 In addition, we use concave over modular functions p w 1 ( X ) +  X w 2 ( V \ X ) with randomly chosen vectors w ,w 2 in [0 , 1] n and n = 50. We also consider the application of selecting limited vocabulary speech cor-pora. Lin &amp; Bilmes (2011a); Jegelka et al. (2011) use functions of the form p w 1 ( X ( X )) + w 2 ( V \ X ), where  X ( X ) is the neighborhood function of a bipartite graph. Here, we choose n = 100 and random vectors w 1 and w . For both function classes, we vary  X  such that the optimal solution X  X  moves from X  X  =  X  to X  X  = V . The results are shown in Figure 3. In both cases, we ob-serve a significant reduction of the search space. When used as a preprocessing step for the minimum norm point algorithm (MN) (Fujishige &amp; Isotani, 2011), this pruned lattice speeds up the MN algorithm accord-ingly, in particular for the speech data. The dotted lines represent the relative time of MN including the respective preprocessing, taken with respect to MN without preprocessing. Figure 3 also shows the average results over 10 random choices of weights in both cases. In order to obtain accurate estimates of the timings, we run each experiment 5 times and take the minimum of these timing valuess.
 Constrained minimization. For constrained mini-mization, we compare MMin-I to two methods: a sim-ple algorithm (MU) that minimizes the upper bound g ( X ) = P i  X  X f ( i ) (Goel et al., 2009) (this is identical to the first iteration of MMin-I), and a more complex algorithm (EA) that computes an approximation to the submodular polyhedron (Goemans et al., 2009) and in many cases yields a theoretically optimal approxima-tion. MU has the theoretical bounds of Theorem 5.9, while EA achieves a worst-case approximation factor of O ( retical worst-case and average-case instances. Figure 4 illustrates the results.
 Worst case. We use a very hard cost function (Goe-mans et al., 2009) where  X  = n 1 / 2+ and  X  = n 2 , and R is a random set such that | R | =  X  . This function is the theoretical worst case. Figure 4 shows results for cardinality lower bound constraints; the results for other, more complex constraints are similar. As shrinks, the problem becomes harder. In this case, EA and MMin-I achieve about the same empirical approximation factors, which matches the theoretical guarantee of n 1 / 2  X  . Average case. We next compare the algorithms on more realistic functions that occur in applications. Fig-ure 4 shows the empirical approximation factors for minimum submodular-cost spanning tree, bipartite matching, and shortest path. We use four classes of randomized test functions: (1) concave (square root or log) over modular (CM), (2) clustered CM (CCM) of the form f ( X ) = P k i =1 p w ( X  X  C k ) for clusters C ,  X  X  X  ,C k , (3) Best Set (BS) functions where the optimal feasible set R is chosen randomly ( f ( X ) = I ( | X  X  R | X  1) + P j  X  R \ X w j ) and (4) worst case-like functions (WC) similar to equation (11) . Functions of type (1) and (2) have been used in speech and com-puter vision (Lin &amp; Bilmes, 2011b; Jegelka &amp; Bilmes, 2011b; Iyer &amp; Bilmes, 2012b) and have reduced cur-vature (  X  f &lt; 1). Functions of type (3) and (4) have  X  f = 1. In all four cases, we consider both sparse and dense graphs, with random weight vectors w . The plots show averages over 20 instances of these graphs. For sparse graphs, we consider grid like graphs in the form of square grids, grids with diagonals and cubic grids. For dense graphs, we sparsely connect a few dense cluster subgraphs. For matchings, we restrict ourselves to bipartite graphs, and consider both sparse and dense variants of these.
 First, we observe that in many cases, MMin clearly outperforms MU. This suggests the practical utility of more than one iteration. Second, despite its simplicity, MMin performs comparably to EA, and sometimes even better. In summary, the experiments suggest that the complex EA only gains on a few worst-case instances, whereas in many (average) cases, MMin yields near-optimal results (factor 1 X 2). In terms of running time, MMin is definitely preferable: on small instances (for example n = 40), our Matlab implementation of MMin takes 0.2 seconds, while EA needs about 58 seconds. On larger instances ( n = 500), the running times differ on the order of seconds versus hours. Just like for minimization, for submodular maximiza-tion too we obtain a family of algorithms where each member is specified by a distinct schedule of subgradi-ents. We will only select subgradients that are vertices of the subdifferential, i.e., each subgradient corresponds to a permutation of V . For any of those choices, MMax converges quickly. To bound the running time, we assume that we proceed only if we make sufficient progress, i.e., if f ( X t +1 )  X  (1 +  X  ) f ( X t ). Lemma 6.1. MMax with X 0 = argmax j f ( j ) runs in time O ( T log 1+  X  n ) , where T is the time for maximizing a modular function subject to X  X  X  .
 Proof. Let X  X  be the optimal solution, then Furthermore, we know that f ( X t )  X  (1 +  X  ) t f ( X 0 Therefore, we have reached the maximum function value after at most (log n ) / log(1 +  X  ) iterations. In practice, we observe that MMax terminates within 3-10 iterations. We next consider specific subgradients and their theoretical implications. For unconstrained problems, we assume the submodular function to be non-monotone (the results trivially hold for monotone functions too); for constrained problems, we assume the function f to be monotone nondecreasing. Our results rely on the observation that many maximization algorithms actually compute a specific subgradient and run MMax with this subgradient. To our knowledge, this observation is new. 6.1. Unconstrained Maximization Random Permutation (RA/RP). In iteration t , we randomly pick a permutation  X  that defines a sub-gradient at X t  X  1 , i.e., X t  X  1 is assigned to the first | X t  X  1 | positions. At X 0 =  X  , this can be any permuta-tion. Stopping after the first iteration (RP) achieves an approximation factor of 1 / 4 in expectation, and 1 / 2 for symmetric functions. Making further iterations (RA) only improves the solution.
 Lemma 6.2. When running Algorithm RP with X 0 =  X  , it holds after one iteration that E ( f ( X 1 ))  X  1 if f is a general non-negative submodular function, and E ( f ( X 1 ))  X  1 2 f ( X  X  ) if f is symmetric. Proof. Each permutation has the same probability 1 /n ! of being chosen. Therefore, it holds that Let  X  X  X  S  X  1  X  S  X  2  X  X  X  S  X  n = V be the chain correspond-ing to a given permutation  X  . We can bound because max X  X  V h  X   X  ( X )  X  f ( S  X  k ) ,  X  k and P n 1. Together, Equations (14) and (15) imply that By E S ( f ( S )), we denote the expected function value when the set S is sampled uniformly at random, i.e., each element is included with probability 1 / 2. Feige et al. (2007) shows that E S ( f ( S ))  X  1 4 f ( X  X  symmetric submodular functions, the factor is 1 2 . Randomized local search (RLS). Instead of using a completely random subgradient as in RA, we fix the positions of two elements: the permutation must satisfy that  X  t ( | X t | + 1)  X  argmax j f ( j | X t ) and  X  t 1)  X  argmin j f ( j | X t \ j ). The remaining positions are assigned randomly. An  X  -approximate version of MMax with such subgradients returns an  X  -approximate local maximum that achieves an improved approximation factor of 1 / 3  X   X  in O ( n 2 log n  X  ) iterations. Lemma 6.3. Algorithm RLS returns a local maximum X that satisfies max { f ( X ) ,f ( V \ X ) } X  ( 1 3  X   X  ) f ( X Proof. At termination ( t = T ), it holds that max j f ( j | X T )  X  0 and min j f ( j | X T \ j )  X  0; this implies that the set X t is local optimum.
 To show local optimality, recall that the subgradi-h the set X T is a local maximum.
 We now use a result by Feige et al. (2007) showing that if a set X is a local optimum, then f ( X )  X  1 3 f ( X  X  f is a general non-negative submodular set function and f ( X )  X  1 2 f ( X  X  ) if f is a symmetric submodular function. If the set is an  X  -approximate local optimum, we obtain a 1 3  X   X  approximation (Feige et al., 2007). A complexity analysis similar to Theorem 6.1 reveals that the worst case complexity of this algorithm is Note that even finding an exact local maximum is hard for submodular functions (Feige et al., 2007), and therefore it is necessary to resort to an  X  -approximate version, which converges to an  X  -approximate local maximum.
 Deterministic local search (DLS). A completely deterministic variant of RLS defines the permutation by an entirely greedy ordering. We define permutation  X  t used in iteration t via the chain  X  = S  X  t ...  X  S  X  t n it will generate. The initial permutation is  X  subsequent iterations t , the permutation  X  t is  X  ( j ) = This schedule is equivalent to the deterministic local search (DLS) algorithm by Feige et al. (2007), and therefore achieves an approximation factor of 1 / 3  X   X  . Bi-directional greedy (BG). The procedures above indicate that greedy and local search algorithms implicitly define specific chains and thereby subgradi-ents. Likewise, the deterministic bi-directional greedy algorithm by Buchbinder et al. (2012) induces a dis-tinct permutation of the ground set. It is therefore equivalent to MMax with the corresponding subgradi-ents and achieves an approximation factor of 1 / 3. This factor improves that of the local search techniques by removing  X  . Moreover, unlike for local search, the 1 / 3 approximation holds already after the first iteration. Lemma 6.4. The set X 1 obtained by Algorithm 1 with the subgradient equivalent to BG satisfies that f ( X )  X  1 3 f ( X  X  ) .
 Proof. Given an initial ordering  X  , the bi-directional greedy algorithm by Buchbinder et al. (2012) generates a chain of sets. Let  X   X  denote the permutation defined by this chain, obtainable by mimicking the algorithm. We run MMax with the corresponding subgradient. By construction, the set S  X  returned by the bi-directional greedy algorithm is contained in the chain. Therefore, it holds that The first inequality follows since the subgradient is tight for all sets in the chain. For the second inequality, we used that S  X  belongs to the chain, and hence S  X  = S j for some j . The last inequality follows from the approximation factor satisfied by S  X  (Buchbinder et al., 2012). We can continue the algorithm, using any one of the adaptive schedules above to get a locally optimal solution. This can only improve the solution. Randomized bi-directional greedy (RG). Like its deterministic variant, the randomized bi-directional greedy algorithm by Buchbinder et al. (2012) can be shown to run MMax with a specific subgradient. Start-ing from  X  and V , it implicitly defines a random chain of subsets and thereby (random) subgradients. A simple analysis shows that this subgradient leads to the best possible approximation factor of 1 / 2 in expectation. Like its deterministic counterpart, the Randomized bi-directional Greedy algorithm (RG) by Buchbinder et al. (2012) induces a (random) permutation  X   X  based on an initial ordering  X  .
 Lemma 6.5. If the subgradient in MMax is determined by  X   X  , then the set X 1 after the first iteration satisfies over the randomness in  X   X  .
 Proof. The permutation  X   X  is obtained by a random-ized algorithm, but once  X   X  is fixed, the remainder of MMax is deterministic. By an argumentation similar to that in the proof of Lemma 6.4, it holds that The last inequality follows from a result in (Buchbinder et al., 2012). 6.2. Constrained Maximization In this final section, we analyze subgradients for max-imization subject to the constraint X  X  C . Here we assume that f is monotone. An important subgradient results from the greedy permutation  X  g , defined as This definition might be partial; we arrange any remain-ing elements arbitrarily. When using the corresponding subgradient h  X  g , we recover a number of approximation results already after one iteration: Lemma 6.6. Using h  X  g in iteration 1 of MMax yields the following approximation bounds for X 1 : p +  X  f , for the intersection C =  X 
C , where K and k are the maximum and minimum cardinality of the maximal feasible sets in C . Proof. We prove the first result for cardinality con-straints. The proofs for the matroid and general down-monotone constraints are analogous. By the construc-tion of  X  g , the set S  X  g k is exactly the set returned by the greedy algorithm. This implies that The last inequality follows from (Nemhauser et al., 1978; Conforti &amp; Cornuejols, 1984).
 A very similar construction of a greedy permutation provides bounds for budget constraints, i.e., c ( S ) , P i  X  S c ( i )  X  B for some given nonnegative costs c . In particular, define a permutation as: The following result then follows from (Lin &amp; Bilmes, 2010; Sviridenko, 2004).
 Lemma 6.7. Using  X  g in MMax under the budget constraints yields: max { max Let  X  ijk be a permutation with i,j,k in the first three positions, and the remaining arrangement greedy. Run-ning O ( n 3 ) restarts of MM yields sets X ijk (after one iteration) with The proof is analogous to that of Lemma 6.6. Table 1 lists results for monotone submodular maximization under different constraints.
 It would be interesting if some of the constrained vari-ants of non-monotone submodular maximization could be naturally subsumed in our framework too. In partic-ular, some recent algorithms (Lee et al., 2009a;b) pro-pose local search based techniques to obtain constant factor approximations for non-monotone submodular maximization under knapsack and matroid constraints. Unfortunately, these algorithms require swap opera-tions along with inserting and deleting elements. We do not currently know how to phrase these swap oper-ations via our framework and leave this relation as an open problem.
 While a number of algorithms cannot be naturally seen as an instance of our framework, we show in the follow-ing section that any polynomial time approximation algorithm for unconstrained or constrained variants of submodular optimization can be ultimately seen as an instance of our algorithm, via a polynomial-time computable subgradient. 6.3. Generality The correspondences between MMax and maximization algorithms hold even more generally: Theorem 6.8. For any polynomial-time unconstrained submodular maximization algorithm that achieves an approximation factor  X  , there exists a schedule of sub-gradients (obtainable in polynomial time) that, if used within MMax, leads to a solution with the same approx-imation factor  X  .
 The proof relies on the following observation. Lemma 6.9. Any submodular function f satisfies max Lemma 6.9 implies that there exists a permutation (and equivalent subgradient) with which MMax finds the optimal solution in the first iteration. Known hardness results (Feige, 1998) imply that this permutation may not be obtainable in polynomial time.
 Proof. (Lemma 6.9) The first equality in Lemma 6.9 follows from the fact that any submodular function f can be written as For the second equality, we use the fact that a linear program over a polytope has a solution at one of the extreme points of the corresponding polytope.
 We can now prove Theorem 6.8 Proof. (Thm. 6.8) Let Y be the set returned by the approximation algorithm; this set is polynomial-time computable by definition. Let  X  be an arbitrary per-mutation that places the elements in Y in the first | Y | positions. The subgradient h  X  defined by  X  is a subgradient both for  X  and for Y . Therefore, using X 0 =  X  and h  X  in the first iteration, we obtain a set X 1 with f ( X 1 )  X  h  X   X  ( X 1 )  X  h  X   X  ( Y ) = f ( Y )  X   X f ( X The equality follows from the fact that Y belongs to the chain of  X  .
 While the above theorem shows the optimality of MMax in the unconstrained setting, a similar result holds for the constrained case: Corollary 6.10. Let C be any constraint such that a linear function can be exactly maximized over C . For any polynomial-time algorithm for submodular maxi-mization over C that achieves an approximation factor  X  , there exists a schedule of subgradients (obtainable in polynomial time) that, if used within MMax, leads to a solution with the same approximation factor  X  . The proof of Corollary 6.10 follows directly from the Theorem 6.8. Lastly, we pose the question of se-lecting the optimal subgradient in each iteration. An optimal subgradient h would lead to a function m h whose maximization yields the largest improvement. Unfortunately, obtaining such an  X  X ptimal X  subgradi-ent is impossible: Theorem 6.11. The problem of finding the optimal subgradient  X  OPT = argmax  X ,X  X  V h  X  X t ( X ) in Step 4 of Algorithm 1 is NP-hard even when C = 2 V . Given such an oracle, however, MMax using subgradient  X  OPT returns a global optimizer.
 Proof. Lemma 6.9 implies that an optimal subgradient at X 0 =  X  or X 0 = V is a subgradient at an optimal solution. An argumentation as in Equation (40) shows that using this subgradient in MM leads to an optimal solution. Since this would solve submodular maximiza-tion (which is NP-hard), it must be NP-hard to find such a subgradient.
 To show that this holds for arbitrary X t (and corre-spondingly at every iteration), we use that the sub-modular subdifferential can be expressed as a direct product between a submodular polyhedron and an anti-submodular polyhedron (Fujishige, 2005). Any problem involving an optimization over the sub-differential, can then be expressed as an optimization over a submodu-lar polyhedron (which is a subdifferential at the empty set) and an anti-submodular polyhedron (which is a subdifferential at V ) (Fujishige, 2005). Correspond-ingly, Equation (38) can be expressed as the sum of two submodular maximization problems. 6.4. Experiments We now empirically compare variants of MMax with different subgradients. As a test function, we use the objective of Lin &amp; Bilmes (2009), redundancy parameter. This non-monotone function was used to find the most diverse yet relevant subset of objects in a large corpus. We use the objective with both synthetic and real data. We generate 10 instances of random similarity matrices { s ij } ij and vary  X  from 0 . 5 to 1. Our real-world data is the Speech Training data subset selection problem (Lin &amp; Bilmes, 2009) on the TIMIT corpus (Garofolo et al., 1993), using the string kernel metric (Rousu &amp; Shawe-Taylor, 2006) for similarity. We use 20  X  n  X  30 so that the exact solution can still be computed with the algorithm of Goldengorin et al. (1999).
 We compare the algorithms DLS, BG, RG, RLS, RA and RP, and a baseline RS that picks a set uniformly at random. RS achieves a 1 / 4 approximation in expec-tation (Feige et al., 2007). For random algorithms, we select the best solution out of 5 repetitions. Figure 5 shows that DLS, BG, RG and RLS dominate. Even though RG has the best theoretical worst-case bounds, it performs slightly poorer than the local search ones and BG. Moreover, MMax with random subgradients (RP) is much better than choosing a set uniformly at random (RS). In general, the empirical approximation factors are much better than the theoretical worst-case bounds. Importantly, the MMax variants are extremely fast, about 200-500 times faster than the exact branch and bound technique of (Goldengorin et al., 1999). In this paper, we introduced a general MM framework for submodular optimization algorithms. This framework is akin to the class of algorithms for minimizing the difference between submodular func-tions (Narasimhan &amp; Bilmes, 2005; Iyer &amp; Bilmes, 2012b). In addition, it may be viewed as a special case of a proximal minimization algorithm that uses Bregman divergences derived from submodular functions (Iyer et al., 2012). To our knowledge this is the first generic and unifying framework of combinatorial algorithms for submodular optimization. An alternative framework relies on relaxing the discrete optimization problem by using a continuous extension (the Lov  X asz extension for minimization and multilinear extension for maximization). Relaxations have been applied to some constrained (Iwata &amp; Nagano, 2009) and unconstrained (Bach, 2011) minimization problems as well as maximization problems (Buchbinder et al., 2012). Such relaxations, however, rely on a final round-ing step that can be challenging  X  the combinatorial framework obviates this step. Moreover, our results show that in many cases, it yields good results very efficiently.
 Acknowledgments: We thank Karthik Mohan, John Halloran and Kai Wei for discussions. This material is based upon work supported by the National Science Foundation under Grant No. IIS-1162606, and by a Google, a Microsoft, and an Intel research award. Averbakh, I. and Berman, O. Categorized bottleneck-minisum path problems on networks. Operations Research Letters , 16:291 X 297, 1994.
 Bach, F. Learning with Submodular functions: A convex Optimization Perspective. Arxiv , 2011. Boykov, Y. and Jolly, M.P. Interactive graph cuts for optimal boundary and region segmentation of objects in n-d images. In ICCV , 2001.
 Buchbinder, N., Feldman, M., Naor, J., and Schwartz,
R. A tight (1/2) linear-time approximation to un-constrained submodular maximization. In FOCS , 2012.
 Conforti, M. and Cornuejols, G. Submodular set func-tions, matroids and the greedy algorithm: tight worst-case bounds and some generalizations of the
Rado-Edmonds theorem. Discrete Applied Mathe-matics , 7(3):251 X 274, 1984.
 Delong, A., Veksler, O., Osokin, A., and Boykov, Y.
Minimizing sparse high-order energies by submodular vertex-cover. In In NIPS , 2012.
 Feige, U. A threshold of ln n for approximating set cover. Journal of the ACM (JACM) , 45(4):634 X 652, 1998.
 Feige, U., Mirrokni, V., and Vondr  X ak, J. Maximiz-ing non-monotone submodular functions. SIAM J. COMPUT. , 40(4):1133 X 1155, 2007.
 Fujishige, S. Submodular functions and optimization , volume 58. Elsevier Science, 2005.
 Fujishige, S. and Isotani, S. A submodular function minimization algorithm based on the minimum-norm base. Pacific Journal of Optimization , 7:3 X 17, 2011. Garofolo, J., Lamel, L., Fisher, W., Fiscus, J., Pal-let, D., and Dahlgren, N. Timit, acoustic-phonetic continuous speech corpus. In DARPA , 1993.
 Goel, G., Karande, C., Tripathi, P., and Wang, L. Ap-proximability of combinatorial problems with multi-agent submodular cost functions. In FOCS , 2009. Goemans, M.X., Harvey, N.J.A., Iwata, S., and Mir-rokni, V. Approximating submodular functions ev-erywhere. In SODA , pp. 535 X 544, 2009.
 Goldengorin, B., Tijssen, G.A., and Tso, M. The maximization of submodular functions: Old and new proofs for the correctness of the dichotomy algorithm . University of Groningen, 1999.
 Hunter, D.R. and Lange, K. A tutorial on MM algo-rithms. The American Statistician , 2004.
 Iwata, S. and Nagano, K. Submodular function min-imization under covering constraints. In In FOCS , pp. 671 X 680. IEEE, 2009.
 Iyer, R. and Bilmes, J. The submodular Bregman and Lov  X asz-Bregman divergences with applications. In NIPS , 2012a.
 Iyer, R. and Bilmes, J. Algorithms for approximate minimization of the difference between submodular functions, with applications. In UAI , 2012b.
 Iyer, R., Jegelka, S., and Bilmes, J. Mirror de-scent like algorithms for submodular optimization.
NIPS Workshop on Discrete Optimization in Ma-chine Learning (DISCML) , 2012.
 Jegelka, S. Combinatorial Problems with submodular coupling in machine learning and computer vision . PhD thesis, ETH Zurich, 2012.
 Jegelka, S. and Bilmes, J. A. Approximation bounds for inference using cooperative cuts. In ICML , 2011a. Jegelka, S. and Bilmes, J. A. Submodularity beyond submodular energies: coupling edges in graph cuts. In CVPR , 2011b.
 Jegelka, S., Lin, H., and Bilmes, J. On fast approximate submodular minimization. In NIPS , 2011.
 Krause, A. SFO: A toolbox for submodular function optimization. JMLR , 11:1141 X 1144, 2010.
 Krause, A., Singh, A., and Guestrin, C. Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies. JMLR , 9: 235 X 284, 2008.
 Kulesza, A. and Taskar, B. Determinantal point processes for machine learning. arXiv preprint arXiv:1207.6083 , 2012.
 Lee, J., Mirrokni, V.S., Nagarajan, V., and Sviridenko,
M. Non-monotone submodular maximization under matroid and knapsack constraints. In STOC , pp. 323 X 332. ACM, 2009a.
 Lee, Jon, Sviridenko, Maxim, and Vondr  X ak, Jan.
Submodular maximization over multiple matroids via generalized exchange properties. In APPROX , 2009b.
 Lin, H. and Bilmes, J. How to select a good training-data subset for transcription: Submodular active selection for sequences. In Interspeech , 2009. Lin, H. and Bilmes, J. Multi-document summarization via budgeted maximization of submodular functions. In NAACL , 2010.
 Lin, H. and Bilmes, J. Optimal selection of limited vocabulary speech corpora. In Interspeech , 2011a. Lin, H. and Bilmes, J. A class of submodular functions for document summarization. In ACL , 2011b.
 McCormick, S Thomas. Submodular function mini-mization. Discrete Optimization , 12:321 X 391, 2005. McLachlan, G.J. and Krishnan, T. The EM algorithm and extensions . New York, 1997.
 Nagano, K., Kawahara, Y., and Iwata, S. Minimum average cost clustering. In NIPS , 2010.
 Nagano, K., Kawahara, Y., and Aihara, K. Size-constrained submodular minimization through mini-mum norm base. In ICML , 2011.
 Narasimhan, M. and Bilmes, J. A submodular-supermodular procedure with applications to dis-criminative structure learning. In UAI , 2005. Narasimhan, M., Jojic, N., and Bilmes, J. Q-clustering. NIPS , 18:979, 2006.
 Nemhauser, G.L., Wolsey, L.A., and Fisher, M.L. An analysis of approximations for maximizing submodu-lar set functions X  X . Mathematical Programming , 14 (1):265 X 294, 1978.
 Orlin, J.B. A faster strongly polynomial time algorithm for submodular function minimization. Mathematical Programming , 118(2):237 X 251, 2009.
 Rousu, J. and Shawe-Taylor, J. Efficient computation of gapped substring kernels on large alphabets. Journal of Machine Learning Research , 6(2):1323, 2006. Stobbe, P. and Krause, A. Efficient minimization of decomposable submodular functions. In NIPS , 2010. Sviridenko, M. A note on maximizing a submodular set function subject to a knapsack constraint. Operations Research Letters , 32(1):41 X 43, 2004.
 Svitkina, Z. and Fleischer, L. Submodular approxima-tion: Sampling-based algorithms and lower bounds. In FOCS , pp. 697 X 706, 2008.
 Wan, P.-J., Calinescu, G., Li, X.-Y., and Frieder, O.
Minimum-energy broadcasting in static ad hoc wire-less networks. Wireless Networks , 8:607 X 617, 2002. Yuille, A.L. and Rangarajan, A. The concave-convex
 Rishabh Iyer rkiyer@u.washington.edu University of Washington, Seattle, WA 98195, USA Stefanie Jegelka stefje@eecs.berkeley.edu University of California, Berkeley, CA 94720, USA Jeff Bilmes bilmes@u.washington.edu University of Washington, Seattle, WA 98195, USA In this paper, we address minimization and maximiza-tion problems of the following form: Problem 1: min where f : 2 V  X  R is a discrete set function on subsets of a ground set V = { 1 , 2 ,  X  X  X  ,n } , and C  X  2 V is a family of feasible solution sets. The set C could express, for example, that solutions must be an independent set in a matroid, a limited budget knapsack, or a cut (or spanning tree, path, or matching) in a graph. Without making any further assumptions about f , the above problems are trivially worst-case exponential time and moreover inapproximable.
 If we assume that f is submodular, however, then in many cases the above problems can be approximated and in some cases solved exactly in polynomial time. A function f : 2 V  X  R is said to be submodular (Fujishige, 2005) if for all subsets S,T  X  V , it holds that f ( S ) + j )  X  f ( S ) as the gain of j  X  V with respect to S  X  V , then f is submodular if and only if f ( j | S )  X  f ( j | T ) for all S  X  T and j /  X  T . Traditionally, submodularity has been a key structural property for problems in combinatorial optimization, and for applications in econometrics, circuit and game theory, and operations research. More recently, submodularity X  X  popularity in machine learning has been on the rise.
 On the other hand, a potential stumbling block is that machine learning problems are often large (e.g.,  X  X ig data X ) and are getting larger. For general uncon-strained submodular minimization, the computational complexity often scales as a high-order polynomial. These algorithms are designed to solve the most general case and the worst-case instances are often contrived and unrealistic. Typical-case instances are much more benign, so simpler algorithms (e.g., graph-cut) might suffice. In the constrained case, however, the problems often become NP-complete. Algorithms for submod-ular maximization are very different in nature from their submodular minimization cohorts, and their com-plexity too varies depending on the problem. In any case, there is an urgent need for efficient, practical, and scalable algorithms for the aforementioned problems if submodularity is to have a lasting impact on the field of machine learning.
 In this paper, we address the issue of scalability and simultaneously draw connections across the apparent gap between minimization and maximization problems. We demonstrate that many algorithms for submodu-lar maximization may be viewed as special cases of a generic minorize-maximize framework that relies on discrete semidifferentials. This framework encompasses state-of-the-art greedy and local search techniques, and provides a rich class of very practical algorithms. In addition, we show that any approximate submodular maximization algorithm can be seen as an instance of our framework.
 We also present a complementary majorize-minimize framework for submodular minimization that makes two contributions. For unconstrained minimization, we obtain new nontrivial bounds on the lattice of minimiz-ers, thereby reducing the possible space of candidate minimizers. This method easily integrates into any other exact minimization algorithm as a preprocessing step to reduce running time. In the constrained case, we obtain practical algorithms with bounded approx-imation factors. We observe these algorithms to be empirically competitive to more complicated ones. As a whole, the semidifferential framework offers a new unifying perspective and basis for treating submodu-lar minimization and maximization problems in both the constrained and unconstrained case. While it has long been known (Fujishige, 2005) that submodular functions have tight subdifferentials, our results rely on a recently discovered property (Iyer &amp; Bilmes, 2012a; Jegelka &amp; Bilmes, 2011b) showing that submodular functions also have superdifferentials. Furthermore, our approach is entirely combinatorial, thus complementing (and sometimes obviating) related relaxation methods. Submodularity X  X  escalating popularity in machine learn-ing is due to its natural applicability. Indeed, instances of Problems 1 and 2 are seen in many forms, to wit: MAP inference/Image segmentation: Markov Random Fields with pairwise attractive potentials are important in computer vision, where MAP inference is identical to unconstrained submodular minimization solved via minimum cut (Boykov &amp; Jolly, 2001). A richer higher-order model can be induced for which MAP inference corresponds to Problem 1 where V is a set of edges in a graph, and C is a set of cuts in this graph  X  this was shown to significantly improve many image segmentation results (Jegelka &amp; Bilmes, 2011b). Moreover, Delong et al. (2012) efficiently solve MAP inference in a sparse higher-order graphical model by restating the problem as a submodular vertex cover, i.e., Problem 1 where C is the set of all vertex covers in a graph.
 Clustering: Variants of submodular minimization have been successfully applied to clustering problems (Narasimhan et al., 2006; Nagano et al., 2010). Limited Vocabulary Speech Corpora: The prob-lem of finding a maximum size speech corpus with bounded vocabulary (Lin &amp; Bilmes, 2011a) can be posed as submodular function minimization subject to a size constraint. Alternatively, cardinality can be treated as a penalty, reducing the problem to un-constrained submodular minimization (Jegelka et al., 2011).
 Minimum Power Assignment: In wireless net-works, one seeks a connectivity structure that maintains connectivity at a minimum energy consumption. This problem is equivalent to finding a suitable structure (e.g., a spanning tree) minimizing a submodular cost function (Wan et al., 2002).
 Transportation: Costs in real-world transportation problems are often non-additive. For example, it may be cheaper to take a longer route owned by one carrier rather than a shorter route that switches carriers. Such economies of scale, or  X  X ight of usage X  properties are captured in the  X  X ategorized Bottleneck Path Prob-lem X   X  a shortest path problem with submodular costs (Averbakh &amp; Berman, 1994). Similar costs have been considered for spanning tree and matching problems. Summarization/Sensor placement: Submodular maximization also arises in many subset extraction problems. Sensor placement (Krause et al., 2008), docu-ment summarization (Lin &amp; Bilmes, 2011b) and speech data subset selection (Lin &amp; Bilmes, 2009), for example, are instances of submodular maximization.
 Determinantal Point Processes: The Determi-nantal Point Processes (DPPs) which have found nu-merous applications in machine learning (Kulesza &amp; Taskar, 2012) are known to be log-submodular distri-butions. In particular, the MAP inference problem is a form of non-monotone submodular maximization. Indeed, there is strong motivation for solving Problems 1 and 2 but, as mentioned above, these problems come not without computational difficulties. Much work has therefore been devoted to developing optimal or near optimal algorithms. Among the several algorithms (McCormick, 2005) for the unconstrained variant of Problem 1, where C = 2 V , the best complexity to date is O ( n 5  X  + n 6 ) (Orlin, 2009) (  X  is the cost of evaluating f ). This has motivated studies on faster, possibly special case or approximate, methods (Stobbe &amp; Krause, 2010; Jegelka et al., 2011). Constrained minimization problems, even for simple constraints such as a cardinality lower bound, are mostly NP-hard, and not approximable to within better than a polynomial factor. Approximation algorithms for these problems with various techniques have been studied in (Svitkina &amp; Fleischer, 2008; Iwata &amp; Nagano, 2009; Goel et al., 2009; Jegelka &amp; Bilmes, 2011a). Unlike submodular minimization, all forms of submodular maximization are NP-hard. Most such problems, however, admit constant-factor approximations, which are attained via very simple combinatorial algorithms (Nemhauser et al., 1978; Buchbinder et al., 2012). Majorization-minimization (MM) 1 algorithms are known to be useful in machine learning (Hunter &amp; Lange, 2004). Notable examples include the EM algorithm (McLachlan &amp; Krishnan, 1997) and the convex-concave procedure (Yuille &amp; Rangarajan, 2002). Discrete instances have been used to minimize the difference between submodular functions (Narasimhan &amp; Bilmes, 2005; Iyer &amp; Bilmes, 2012b), but these algorithms generally lack theoretical guarantees. This paper shows, by contrast, that for submodular optimization, MM algorithms have strong theoretical properties and empirically work very well. We first briefly introduce submodular semidifferentials. Throughout this paper, we assume normalized sub-modular functions (i.e., f (  X  ) = 0). The subdifferential  X  ( Y ) of a submodular set function f : 2 V  X  R for a set Y  X  V is defined (Fujishige, 2005) analogously to the subdifferential of a continuous convex function:  X  f ( Y ) = { y  X  R n : (1) For a vector x  X  R V and X  X  V , we write x ( X ) = P j  X  X x ( j )  X  in such case, we say that x is a normal-ized modular function. We shall denote a subgradient at Y by h Y  X   X  f ( Y ). The extreme points of  X  f ( Y ) may be computed via a greedy algorithm: Let  X  be a permutation of V that assigns the elements in Y to the first | Y | positions (  X  ( i )  X  Y if and only if i  X | Y | ). Each such permutation defines a chain with elements S 0 =  X  , S This chain defines an extreme point h  X  Y of  X  f ( Y ) with entries Surprisingly, we can also define superdifferentials  X  f ( Y ) of a submodular function (Jegelka &amp; Bilmes, 2011b; Iyer &amp; Bilmes, 2012a) at Y :  X  f ( Y ) = { y  X  R n : (3) We denote a generic supergradient at Y by g Y . It is easy to show that the polyhedron  X  f is non-empty. We define three special supergradients  X  g Y ( X  X row X ),  X  g ( X  X hrink X ) and  X  g Y as follows (Iyer &amp; Bilmes, 2012a): With the above semigradients, we can define a generic MM algorithm. In each iteration, the algorithm opti-mizes a modular approximation formed via the current solution Y . For minimization, we use an upper bound and for maximization a lower bound Both these bounds are tight at the current solution, satisfying m g Y ( Y ) = m h Y ( Y ) = f ( Y ). In almost all cases, optimizing the modular approximation is much faster than optimizing the original cost function f . Algorithm 1 Subgradient ascent [descent] algorithm for submodular maximization [minimization] 1: Start with an arbitrary X 0 . 2: repeat 3: Pick a semigradient h X t [ g X t ] at X t 5: t  X  t + 1 6: until we have converged ( X i  X  1 = X i ) Algorithm 1 shows our discrete MM scheme for maxi-mization (MMax) [and minimization (MMin)] , and for both constrained and unconstrained settings. Since we are minimizing a tight upper bound, or maximizing a tight lower bound, the algorithm must make progress. Lemma 4.1. Algorithm 1 monotonically improves the objective function value for Problems 1 and 2 at every iteration, as long as a linear function can be exactly optimized over C .
 Contrary to standard continuous subgradient descent schemes, Algorithm 1 produces a feasible solution at each iteration, thereby circumventing any rounding or projection steps that might be challenging under certain types of constraints. In addition, it is known that for relaxed instances of our problems, subgradient descent methods can suffer from slow convergence (Bach, 2011). Nevertheless, Algorithm 1 still relies on the choice of the semigradients defining the bounds. Therefore, we next analyze the effect of certain choices of semigradients. For minimization problems, we use MMin with the su-pergradients  X  g X ,  X  g X and  X  g X . In both the unconstrained and constrained settings, this yields a number of new approaches to submodular minimization. 5.1. Unconstrained Submodular Minimization We begin with unconstrained minimization, where C = 2
V in Problem 1. Each of the three supergradients yields a different variant of Algorithm 1, and we will call the resulting algorithms MMin-I, II and III, respectively. We make one more assumption: of the minimizing arguments in Step 4 of Algorithm 1, we always choose a set of minimum cardinality.
 MMin-I is very similar to the algorithms proposed in (Jegelka et al., 2011). Those authors, however, de-compose f and explicitly represent graph-representable parts of the function f . We do not require or consider such a restriction here.
 Let us define the sets A = { j : f ( j | X  ) &lt; 0 } and B = { j : f ( j | V \{ j } )  X  0 } . Submodularity implies that A  X  B , and this allows us to define a lattice L = [ A,B ] whose least element is the set A and whose greatest element is the set is B . This sublattice L of [  X  ,V ] retains all minimizers X  X  (i.e., A  X  X  X   X  B for all X  X  ): Lemma 5.1. (Fujishige, 2005) Let L  X  be the lattice of the global minimizers of a submodular function f . Then L  X   X  X  , where we use  X  to denote a sublattice. Lemma 5.1 has been used to prune down the search space of the minimum norm point algorithm (Bach, 2011; Fujishige &amp; Isotani, 2011). Indeed, A and B may be obtained by using MMin-III: Lemma 5.2. With X 0 =  X  and X 0 = V , MMin-III returns the sets A and B , respectively. Initialized by an arbitrary X 0 , MMin-III converges to ( X 0  X  B )  X  A . Lemma 5.2 implies that MMin-III effectively provides a contraction of the initial lattice to L , and, if X is not in L , it returns a set in L . Henceforth, we therefore assume that we start with a set X 0  X  X  . While the known lattice L has proven useful for warm-starts, MMin-I and II enable us to prune L even further. Let A + be the set obtained by starting MMin-I at X 0 =  X  , and B + be the set obtained by starting MMin-II at X 0 = V . This yields a new, smaller sublattice L + = [ A + ,B + ] that retains all minimizers: Theorem 5.3. For any minimizer X  X   X  L , it holds that A  X  A +  X  X  X   X  B +  X  B . Hence L  X   X  L +  X  L . Furthermore, when initialized with X 0 =  X  and X 0 = V , respectively, both MMin-I and II converge in O ( n ) iterations to a local minimum of f .
 By a local minimum, we mean a set X that satisfies f ( X )  X  f ( Y ) for any set Y that differs from X by a single element. We point out that Theorem 5.3 generalizes part of Lemma 3 in (Jegelka et al., 2011). Theorem 5.3 has a number of nice implications. First, it provides a tighter bound on the lattice of minimiz-ers of the submodular function f that, to the best of our knowledge, has not been used or mentioned before. This means we can start any algorithm for submod-ular minimization from the lattice L + instead of the initial lattice 2 V or L . When using an algorithm whose running time is a high-order polynomial of | V | , any reduction of the ground set V is beneficial. Second, each iteration of MMin takes linear time. Therefore, its total running time is O ( n 2 ). Third, Theorem 5.3 states that both MMin-I and II converge to a local minimum. In consequence, a local minimum of a sub-modular function can be obtained in O ( n 2 ), a fact that is of independent interest and that does not hold for local maximizers (Feige et al., 2007).
 The following example illustrates that L + can be a strict subset of L and therefore provides non-trivial pruning. Let w 1 ,w 2  X  R V , w 1  X  0 be two vectors, each defining a linear (modular) function. Then the func-tion f ( X ) = p w 1 ( X ) + w 2 ( X ) is submodular. Specifi-The tightened sublattice contains exactly the mini-mizer: A + = B + = X  X  = [1 , 6 , 7 , 8 , 10]. The MMin algorithms can be extended to arbitrary ini-tializations and other supergradients (Iyer et al., 2013). 5.2. Constrained submodular minimization MMin straightforwardly generalizes to constraints more complex than C = 2 V , and Theorem 5.3 still holds for more general lattices or ring family constraints. Beyond lattices, MMin applies to any set of constraints C as long as we have an efficient algorithm at hand that minimizes a nonnegative modular cost function over C . This subroutine can even be approximate. Such algorithms are available for cardinality bounds, inde-pendent sets of a matroid and many other combinatorial constraints such as trees, paths or cuts.
 As opposed to unconstrained submodular minimization, almost all cases of constrained submodular minimiza-tion are very hard (Svitkina &amp; Fleischer, 2008; Jegelka &amp; Bilmes, 2011a; Goel et al., 2009), and admit at most approximate solutions in polynomial time. The next theorem states an upper bound on the approximation factor achieved by MMin-I for nonnegative, nonde-creasing cost functions. An important ingredient in the bound is the curvature (Conforti &amp; Cornuejols, 1984) of a monotone submodular function f , defined as Theorem 5.4. Let X  X   X  argmin X  X  X  f ( X ) . The solu-tion b X returned by MMin-I satisfies f ( b
X )  X  If the minimization in Step 4 is done with approxima-tion factor  X  , then f ( b X )  X   X / (1  X   X  f ) f ( X  X  ) . A similar, slightly looser bound was shown for cuts in (Jegelka &amp; Bilmes, 2011b), by using a weaker notion of curvature. Note that the bound in Theorem 5.4 is of the problem. We prove Theorem 5.4 in (Iyer et al., 2013).
 In the worst case, when  X  f = 1, our approximation bounds are identical to prior work (Goel et al., 2009; Svitkina &amp; Fleischer, 2008). Matroid rank functions have  X  f = 1, implying that they are difficult instances for MMin. But several practically relevant submodular functions do satisfy  X  f &gt; 0. In such case, Theorem 5.4 replaces known polynomial bounds by an improved factor depending on  X  f . An example for such functions are concave over modular functions used in (Stobbe &amp; Krause, 2010; Lin &amp; Bilmes, 2011b; Jegelka &amp; Bilmes, 2011b). These comprise, for instance, functions of the form f ( X ) = ( w ( X )) a , for some a  X  [0 , 1] and a nonnegative weight vector w , whose curvature is  X  f  X  1  X  a ( applications use a sum of such functions, each with bounded support (Jegelka &amp; Bilmes, 2011b; Iyer &amp; Bilmes, 2012b). This further reduces the curvature. The bounds of Theorem 5.4 hold after the first iter-ation. Nevertheless, empirically we often found that for problem instances that are not worst-case, subse-quent iterations can improve the solution substantially. Using Theorem 5.4, we can bound the number of iter-ations the algorithm will take. To do so, we assume an  X  -approximate version, where we proceed only if f ( X t +1 )  X  (1  X   X  ) f ( X t ) for some  X  &gt; 0. In practice, the algorithm usually terminates after 5 to 10 iterations for an arbitrarily small  X  . time, where T is the time for minimizing a modular function subject to X  X  X  . 5.3. Experiments We will next see that, apart from its theoretical proper-ties, MMin is in practice competitive to more complex algorithms. We implement and compare algorithms using Matlab and the SFO toolbox (Krause, 2010). Unconstrained minimization We first study the results in Section 5.1 for contracting the lattice of possible minimizers. We measure the size of the new lattices relative to the ground set. Applying MMin-I and II (lattice L + ) to Iwata X  X  test function (Fujishige &amp; Isotani, 2011), we observe an average reduction of 99 . 5% in the lattice. MMin-III (lattice L ) obtains only about 60% reduction. Averages are taken for n between 20 and 120.
 In addition, we use concave over modular functions p w 1 ( X ) +  X w 2 ( V \ X ) with randomly chosen vectors w ,w 2 in [0 , 1] n and n = 50. We also consider the application of selecting limited vocabulary speech cor-pora. Lin &amp; Bilmes (2011a); Jegelka et al. (2011) use functions of the form p w 1 ( X ( X )) + w 2 ( V \ X ), where  X ( X ) is the neighborhood function of a bipartite graph. Here, we choose n = 100 and random vectors w 1 and w . For both function classes, we vary  X  such that the optimal solution X  X  moves from X  X  =  X  to X  X  = V . The results are shown in Figure 1. In both cases, we ob-serve a significant reduction of the search space. When used as a preprocessing step for the minimum norm point algorithm (MN) (Fujishige &amp; Isotani, 2011), this pruned lattice speeds up the MN algorithm accord-ingly, in particular for the speech data. The dotted lines represent the relative time of MN including the respective preprocessing, taken with respect to MN without preprocessing.
 Constrained minimization. For constrained mini-mization, we compare MMin-I to two methods: a sim-ple algorithm (MU) that minimizes the upper bound g ( X ) = P i  X  X f ( i ) (Goel et al., 2009) (this is identical to the first iteration of MMin-I), and a more complex algorithm (EA) that computes an approximation to the submodular polyhedron (Goemans et al., 2009) and in many cases yields a theoretically optimal approxima-tion. MU has the theoretical bounds of Theorem 5.4, while EA achieves a worst-case approximation factor of O ( retical worst-case and average-case instances. Figure 2 illustrates the results.
 Worst case. We use a very hard cost function (Goe-mans et al., 2009) where  X  = n 1 / 2+ and  X  = n 2 , and R is a random set such that | R | =  X  . This function is the theoretical worst case. Figure 2 shows results for cardinality lower bound constraints; the results for other, more complex constraints are similar. As shrinks, the problem becomes harder. In this case, EA and MMin-I achieve about the same empirical approximation factors, which matches the theoretical guarantee of n 1 / 2  X  . Average case. We next compare the algorithms on more realistic functions that occur in applications. Fig-ure 2 shows the empirical approximation factors for minimum submodular-cost spanning tree, bipartite matching, and shortest path. We use four classes of randomized test functions: (1) concave (square root or log) over modular (CM), (2) clustered CM (CCM) of the form f ( X ) = P k i =1 p w ( X  X  C k ) for clusters C ,  X  X  X  ,C k , (3) Best Set (BS) functions where the optimal feasible set R is chosen randomly ( f ( X ) = I ( | X  X  R | X  1) + P j  X  R \ X w j ) and (4) worst case-like functions (WC) similar to equation (7) . Functions of type (1) and (2) have been used in speech and com-puter vision (Lin &amp; Bilmes, 2011b; Jegelka &amp; Bilmes, 2011b; Iyer &amp; Bilmes, 2012b) and have reduced cur-vature (  X  f &lt; 1). Functions of type (3) and (4) have  X  f = 1. In all four cases, we consider both sparse and dense graphs, with random weight vectors w . The plots show averages over 20 instances of these graphs. For more details, please refer to (Iyer et al., 2013). First, we observe that in many cases, MMin clearly outperforms MU. This suggests the practical utility of more than one iteration. Second, despite its simplicity, MMin performs comparably to EA, and sometimes even better. In summary, the experiments suggest that the complex EA only gains on a few worst-case instances, whereas in many (average) cases, MMin yields near-optimal results (factor 1 X 2). In terms of running time, MMin is definitely preferable: on small instances (for example n = 40), our Matlab implementation of MMin takes 0.2 seconds, while EA needs about 58 seconds. On larger instances ( n = 500), the running times differ on the order of seconds versus hours. Just like for minimization, for submodular maximiza-tion too we obtain a family of algorithms where each member is specified by a distinct schedule of subgradi-ents. We will only select subgradients that are vertices of the subdifferential, i.e., each subgradient corresponds to a permutation of V . For any of those choices, MMax converges quickly. To bound the running time, we assume that we proceed only if we make sufficient progress, i.e., if f ( X t +1 )  X  (1 +  X  ) f ( X t ). Lemma 6.1. MMax with X 0 = argmax j f ( j ) runs in time O ( T log 1+  X  n ) , where T is the time for maximizing a modular function subject to X  X  X  .
 In practice, we observe that MMax terminates within 3-10 iterations. We next consider specific subgradients and their theoretical implications. For unconstrained problems, we assume the submodular function to be non-monotone (the results trivially hold for monotone functions too); for constrained problems, we assume the function f to be monotone nondecreasing. Our results rely on the observation that many maximization algorithms actually compute a specific subgradient and run MMax with this subgradient. To our knowledge, this observation is new. The proofs for the statements in Section 6.1 may be found in (Iyer et al., 2013). 6.1. Unconstrained Maximization Random Permutation (RA/RP). In iteration t , we randomly pick a permutation  X  that defines a sub-gradient at X t  X  1 , i.e., X t  X  1 is assigned to the first | X t  X  1 | positions. At X 0 =  X  , this can be any permuta-tion. Stopping after the first iteration (RP) achieves an approximation factor of 1 / 4 in expectation, and 1 / 2 for symmetric functions. Making further iterations (RA) only improves the solution.
 Randomized local search (RLS). Instead of using a completely random subgradient as in RA, we fix the positions of two elements: the permutation must satisfy that  X  t ( | X t | + 1)  X  argmax j f ( j | X t ) and  X  t 1)  X  argmin j f ( j | X t \ j ). The remaining positions are assigned randomly. An  X  -approximate version of MMax with such subgradients returns an  X  -approximate local maximum that achieves an improved approximation factor of 1 / 3  X   X  in O ( n 2 log n  X  ) iterations. Deterministic local search (DLS). A completely deterministic variant of RLS defines the permutation by an entirely greedy ordering. We define permutation  X  t used in iteration t via the chain  X  = S  X  t ...  X  S  X  t n it will generate. The initial permutation is  X  subsequent iterations t , the permutation  X  t is  X  ( j ) = This schedule is equivalent to the deterministic local search (DLS) algorithm by Feige et al. (2007), and therefore achieves an approximation factor of 1 / 3  X   X  . Bi-directional greedy (BG). The procedures above indicate that greedy and local search algorithms implicitly define specific chains and thereby subgradi-ents. Likewise, the deterministic bi-directional greedy algorithm by Buchbinder et al. (2012) induces a dis-tinct permutation of the ground set. It is therefore equivalent to MMax with the corresponding subgradi-ents and achieves an approximation factor of 1 / 3. This factor improves that of the local search techniques by removing  X  . Moreover, unlike for local search, the 1 / 3 approximation holds already after the first iteration. Randomized bi-directional greedy (RG). Like its deterministic variant, the randomized bi-directional greedy algorithm by Buchbinder et al. (2012) can be shown to run MMax with a specific subgradient. Start-ing from  X  and V , it implicitly defines a random chain of subsets and thereby (random) subgradients. A simple analysis shows that this subgradient leads to the best possible approximation factor of 1 / 2 in expectation. 6.2. Constrained Maximization In this final section, we analyze subgradients for max-imization subject to the constraint X  X  C . Here we assume that f is monotone. An important subgradient results from the greedy permutation  X  g , defined as This definition might be partial; we arrange any remain-ing elements arbitrarily. When using the corresponding subgradient h  X  g , we recover a number of approximation results already after one iteration: Lemma 6.2. Using h  X  g in iteration 1 of MMax yields the following approximation bounds for X 1 : p +  X  f , for the intersection C =  X 
C , where K and k are the maximum and minimum cardinality of the maximal feasible sets in C . A similar result holds for Knapsack constraints. The proof of Lemma 6.2 (Iyer et al., 2013) relies on the ob-servation that the maximizer of the function m h for the subgradient h = h  X  g is never worse than the result of a greedy algorithm. The bounds follow from (Conforti &amp; Cornuejols, 1984). 6.3. Generality The correspondences between MMax and maximization algorithms hold even more generally: Theorem 6.3. For any polynomial-time unconstrained submodular maximization algorithm that achieves an approximation factor  X  , there exists a schedule of sub-gradients (obtainable in polynomial time) that, if used within MMax, leads to a solution with the same approx-imation factor  X  .
 Under mild assumptions, Theorem 6.3 holds even for constrained maximization. Lastly, we pose the question of selecting the optimal subgradient in each iteration. An optimal subgradient h would lead to a function m h whose maximization yields the largest improvement. Unfortunately, obtaining such an  X  X ptimal X  subgradi-ent is impossible: Theorem 6.4. The problem of finding the optimal subgradient  X  OPT = argmax  X ,X  X  V h  X  X t ( X ) in Step 4 of Algorithm 1 is NP-hard even when C = 2 V . Given such an oracle, however, MMax using subgradient  X  OPT returns a global optimizer. 6.4. Experiments We now empirically compare variants of MMax with different subgradients. As a test function, we use the objective of Lin &amp; Bilmes (2009), f ( X ) = P dancy parameter. This non-monotone function was used to find the most diverse yet relevant subset of objects. We use the objective with both synthetic and real data. We generate 10 instances of random simi-larity matrices { s ij } ij and vary  X  from 0 . 5 to 1. Our real-world data is the Speech Training data subset selec-tion problem (Lin &amp; Bilmes, 2009) on the TIMIT cor-pus (Garofolo et al., 1993), using the string kernel met-ric (Rousu &amp; Shawe-Taylor, 2006) for similarity. We use 20  X  n  X  30 so that the exact solution can still be com-puted with the algorithm of Goldengorin et al. (1999). We compare the algorithms DLS, BG, RG, RLS, RA and RP, and a baseline RS that picks a set uniformly at random. RS achieves a 1 / 4 approximation in expec-tation (Feige et al., 2007). For random algorithms, we select the best solution out of 5 repetitions. Figure 3 shows that DLS, BG, RG and RLS dominate. Even though RG has the best theoretical worst-case bounds, it performs slightly poorer than the local search ones and BG. Moreover, MMax with random subgradients (RP) is much better than choosing a set uniformly at random (RS). In general, the empirical approximation factors are much better than the theoretical worst-case bounds. Importantly, the MMax variants are extremely fast, about 200-500 times faster than the exact branch and bound technique of (Goldengorin et al., 1999). In this paper, we introduced a general MM framework for submodular optimization algorithms. This framework is akin to the class of algorithms for minimizing the difference between submodular func-tions (Narasimhan &amp; Bilmes, 2005; Iyer &amp; Bilmes, 2012b). In addition, it may be viewed as a special case of a proximal minimization algorithm that uses Bregman divergences derived from submodular functions (Iyer et al., 2012). To our knowledge this is the first generic and unifying framework of combinatorial algorithms for submodular optimization. An alternative framework relies on relaxing the discrete optimization problem by using a continuous extension (the Lov  X asz extension for minimization and multilinear extension for maximization). Relaxations have been applied to some constrained (Iwata &amp; Nagano, 2009) and unconstrained (Bach, 2011) minimization problems as well as maximization problems (Buchbinder et al., 2012). Such relaxations, however, rely on a final round-ing step that can be challenging  X  the combinatorial framework obviates this step. Moreover, our results show that in many cases, it yields good results very efficiently.
 Acknowledgments: We thank Karthik Mohan, John Halloran and Kai Wei for discussions. This material is based upon work supported by the National Science Foundation under Grant No. IIS-1162606, and by a Google, a Microsoft, and an Intel research award. Averbakh, I. and Berman, O. Categorized bottleneck-minisum path problems on networks. Operations Research Letters , 16:291 X 297, 1994.
 Bach, F. Learning with Submodular functions: A convex Optimization Perspective. Arxiv , 2011. Boykov, Y. and Jolly, M.P. Interactive graph cuts for optimal boundary and region segmentation of objects in n-d images. In ICCV , 2001.
 Buchbinder, N., Feldman, M., Naor, J., and Schwartz,
R. A tight (1/2) linear-time approximation to un-constrained submodular maximization. In FOCS , 2012.
 Conforti, M. and Cornuejols, G. Submodular set func-tions, matroids and the greedy algorithm: tight worst-case bounds and some generalizations of the
Rado-Edmonds theorem. Discrete Applied Mathe-matics , 7(3):251 X 274, 1984.
 Delong, A., Veksler, O., Osokin, A., and Boykov, Y.
Minimizing sparse high-order energies by submodular vertex-cover. In In NIPS , 2012.
 Feige, U., Mirrokni, V., and Vondr  X ak, J. Maximiz-ing non-monotone submodular functions. SIAM J. COMPUT. , 40(4):1133 X 1155, 2007.
 Fujishige, S. Submodular functions and optimization , volume 58. Elsevier Science, 2005.
 Fujishige, S. and Isotani, S. A submodular function minimization algorithm based on the minimum-norm base. Pacific Journal of Optimization , 7:3 X 17, 2011. Garofolo, J., Lamel, L., Fisher, W., Fiscus, J., Pal-let, D., and Dahlgren, N. Timit, acoustic-phonetic continuous speech corpus. In DARPA , 1993.
 Goel, G., Karande, C., Tripathi, P., and Wang, L. Ap-proximability of combinatorial problems with multi-agent submodular cost functions. In FOCS , 2009. Goemans, M.X., Harvey, N.J.A., Iwata, S., and Mir-rokni, V. Approximating submodular functions ev-erywhere. In SODA , pp. 535 X 544, 2009.
 Goldengorin, B., Tijssen, G.A., and Tso, M. The maximization of submodular functions: Old and new proofs for the correctness of the dichotomy algorithm . University of Groningen, 1999.
 Hunter, D.R. and Lange, K. A tutorial on MM algo-rithms. The American Statistician , 2004.
 Iwata, S. and Nagano, K. Submodular function min-imization under covering constraints. In In FOCS , pp. 671 X 680. IEEE, 2009.
 Iyer, R. and Bilmes, J. The submodular Bregman and Lov  X asz-Bregman divergences with applications. In NIPS , 2012a.
 Iyer, R. and Bilmes, J. Algorithms for approximate minimization of the difference between submodular functions, with applications. In UAI , 2012b. Iyer, R., Jegelka, S., and Bilmes, J. Mirror de-scent like algorithms for submodular optimization.
NIPS Workshop on Discrete Optimization in Ma-chine Learning (DISCML) , 2012.
 Iyer, R., Jegelka, S., and Bilmes, J. Fast
Semidifferential-based Submodular Function Opti-mization : Extended Version, 2013.
 Jegelka, S. and Bilmes, J. A. Approximation bounds for inference using cooperative cuts. In ICML , 2011a. Jegelka, S. and Bilmes, J. A. Submodularity beyond submodular energies: coupling edges in graph cuts. In CVPR , 2011b.
 Jegelka, S., Lin, H., and Bilmes, J. On fast approximate submodular minimization. In NIPS , 2011.
 Krause, A. SFO: A toolbox for submodular function optimization. JMLR , 11:1141 X 1144, 2010.
 Krause, A., Singh, A., and Guestrin, C. Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies. JMLR , 9: 235 X 284, 2008.
 Kulesza, A. and Taskar, B. Determinantal point processes for machine learning. arXiv preprint arXiv:1207.6083 , 2012.
 Lin, H. and Bilmes, J. How to select a good training-data subset for transcription: Submodular active selection for sequences. In Interspeech , 2009. Lin, H. and Bilmes, J. Optimal selection of limited vocabulary speech corpora. In Interspeech , 2011a. Lin, H. and Bilmes, J. A class of submodular functions for document summarization. In ACL , 2011b.
 McCormick, S Thomas. Submodular function mini-mization. Discrete Optimization , 12:321 X 391, 2005. McLachlan, G.J. and Krishnan, T. The EM algorithm and extensions . New York, 1997.
 Nagano, K., Kawahara, Y., and Iwata, S. Minimum average cost clustering. In NIPS , 2010.
 Narasimhan, M. and Bilmes, J. A submodular-supermodular procedure with applications to dis-criminative structure learning. In UAI , 2005. Narasimhan, M., Jojic, N., and Bilmes, J. Q-clustering. NIPS , 18:979, 2006.
 Nemhauser, G.L., Wolsey, L.A., and Fisher, M.L. An analysis of approximations for maximizing submodu-lar set functions X  X . Mathematical Programming , 14 (1):265 X 294, 1978.
 Orlin, J.B. A faster strongly polynomial time algorithm for submodular function minimization. Mathematical Programming , 118(2):237 X 251, 2009.
 Rousu, J. and Shawe-Taylor, J. Efficient computation of gapped substring kernels on large alphabets. Journal of Machine Learning Research , 6(2):1323, 2006. Stobbe, P. and Krause, A. Efficient minimization of decomposable submodular functions. In NIPS , 2010. Svitkina, Z. and Fleischer, L. Submodular approxima-tion: Sampling-based algorithms and lower bounds. In FOCS , pp. 697 X 706, 2008.
 Wan, P.-J., Calinescu, G., Li, X.-Y., and Frieder, O.
Minimum-energy broadcasting in static ad hoc wire-less networks. Wireless Networks , 8:607 X 617, 2002. Yuille, A.L. and Rangarajan, A. The concave-convex
