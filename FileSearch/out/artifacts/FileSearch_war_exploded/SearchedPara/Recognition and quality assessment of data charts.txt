 ORIGINAL PAPER Sudhindra Shukla  X  Ashok Samal Abstract Data charts can be used to effectively compress large amounts of complex information and can convey infor-mation in an efficient and succinct manner. It is now easier to create data charts by using a variety of automated soft-ware systems. These data charts are routinely inserted in text documents and are widely disseminated over many different media. This study addresses the problem of finding good-ness of data charts in mixed-mode documents. The quality of the graphics can be used to assist the document develop-ment process as well as to serve as an additional criterion for search engines like Google and Yahoo. The quality measures are motivated by principles of visual learning and are based on research in educational psychology and cognitive theories and use attributes of both the graphic and its textual context. We have implemented the approach and evaluated its effec-tiveness using a set of documents compiled from the Web. Results of a human study shows that the proposed quality measures have a high correlation with the quality ratings of the users for each of the five classes of data charts studied in this research. 1 Introduction Pictures or graphics help to stimulate human interest, since they are often easier to understand and are more interesting to the reader than text. Graphics and images also provide a more compact medium to convey information, as the saying  X  X  picture is worth thousand words. X  A special class of graphics called data charts (e.g., pie charts, bar charts, line charts, etc.) are widely used now in academic, business, and scientific settings to support description and analysis of quantitative data. They help to locate and compare groups of quantitative data more easily, and to make generalizations about the data quickly. The use of graphics makes more vivid impact than a set of numbers or their description alone. According to Mayer [ 21 ], visual learning techniques that use images combined with written words is a powerful tool for enhancing cognition skills. Petre also notes that good graphics link perceptual cues to important information [ 26 ].

While data charts have been used over many centuries, their use has exploded with the introduction of computer-aidedtools(e.g.,Excel,SAS,SPSS,STATA,andGnuplot)for creating them. This has many latent benefits and challenges. While it is now easier to develop data charts than ever before, it is now more difficult to maintain their quality. In the past, trained professionals who had a variety of skills in graphics design, art, statistics, and mathematics created data charts. This enforced a certain degree of quality control.
A good data chart conveys information in an efficient and, succinct manner, while a bad chart is confusing and places additional burden on the user for comprehension [ 35  X  37 ]. Figure 1 a has a caption; its segments are labeled and the percentages are shown for each pie segment. Figure 1 b, on the other hand, has no caption, and does not clearly show the percentage for each slice. Clearly, Fig. 1 b does not convey the intended information as efficiently as Fig. 1 a. 1.1 Motivation and applications The goal of this research is to advance the state-of-the-art in visual learning by developing an automated system that will assess the goodness of data charts in mixed-mode documents. The goodness of a data chart is measured by its effectiveness in conveying the information to assist visual learning. This can be used to help users assess the quality of the graphics they create and/or suggest deficiencies in data charts that already exist in mixed-mode documents.

This work can be used in many applications. It can be used in search engines to rank the retrieved documents that have graphics; a document with a higher quality of graphics is given a higher rank. A graphic evaluation tool can be used to develop better data charts in semiautomated authoring sys-tems (e.g., Microsoft Office) that are used for generating reports and other types of mixed-mode documents. Statis-tical, mathematical, and drawing software that generate gra-phics can use the concept of graphic quality to create more effective data charts. While the techniques described in this study apply directly to data charts, the ideas can be exten-ded to other types of graphics including pictograms, icons, animations, control charts, and flow charts. 1.2 Data charts The main reasons for focusing on data charts are (1) data charts are widely used; (2) they are often generated by auto-mated tools; (3) they are structured and have well-defined properties. After an extensive survey of data charts, we chose the five classes, which we found most common: line charts, column charts, bar charts, pie charts, and bubble charts. We estimated that these classes constitute over 75% of the charts used for displaying quantitative information today. Figure 2 shows an example of each class of charts. It should be noted that while charts can be an effective vehicle to communicate relational information, they are not as effective for simple information lookup [ 7 ]. 1.3 Problem formulation Our goal is to determine the quality of a graphic in a mixed-mode document. The problem can be formally stated as fol-lows: Given a mixed-mode document, D =[ T , G ] , where T represents the textual component of the document D and G represents the graphics component and is represented as G ={ g where g i is a single isolated graphic in the document and m is the number of graphic components. Our goal here is to define a function QoG that is defined as QoG : g i  X  T  X  X  0 , 1 ] (2)
Thus, the QoG function maps each graphics component in the image (in the context of the associated text) to a good-ness value. This function can be integrated to get a quality measure of the overall document, but is not addressed here. Since each graphic is evaluated independently, without loss of generality, we assume that each document contains only onegraphic.Inaddition,weassumethatdocumenthasnotext wrapping, that its text lines are horizontal, and that the data charts have explicit or implicit rectangular frames (boundary lines). 1.4 Overview of the approach Figure 3 describes the schematic of our approach. First, the document is split into (1) text and (2) graphic parts. The infor-mation extracted from each part is then combined to compute the quality metrics. The textual processing involves finding the chart references with their locations, text stemming, fin-ding keywords in the adjacent paragraphs of the chart(s), and finding caption keywords [if caption(s) is/are outside the chart]. In graphics-processing , we derive the underlying components of the graphic component to both classify the graphic and derive its quality measure. The text-matching stage involves keyword-matching between the reference text keywords, label keywords, and caption keywords. Using this information, we compute a set of quality measures (QMs), which are integrated to yield an overall quality of graphic (QoG) function. This approach is applicable for any docu-ment in the digital form that is amenable to text-and graphics-processing.Anyhtmlpage,pdfdocument,andascanned(and OCR X  X d) document can be processed using this approach. 1.5 Previous work Webrieflyreviewtheexistingliteratureongraphics-andtext-processing, two important intermediate stages in our QoG computation. Literature related to quality of graphics is dis-cussed in Sect. 2 , since it is quite vast and merits a more detailed analysis.

Graphics-processing . We use many low and intermediate level processing steps to extract the structure of the gra-phic. A full review of all the operations is beyond the scope of this paper. Interested reader may review some standard references in computer vision [ 13 , 29 , 32 , 38 ]. We focus on the more significant problem of line structure segmentation here, since it is more important in extraction of structure in data charts. A common approach to extract line struc-ture is through vectorization, i.e., converting the image to raw fragment vectors. These smaller vectors are then grou-ped into longer lines and polylines. Three approaches in vectorization are common: thinning [ 23 , 31 , 34 ], border following [ 20 , 30 ], and direction distance propagation [ 20 , 30 ]. The problem with the first two methods in our appli-cation is that thinning can cause shape distortion at line junctions and figure intersections, while border following methods will mix line vectors and text vectors at figure inter-sections. Directional distance propagation is proposed to overcome these drawbacks, but this method requires many phases of postprocessing [ 14 ]. Myers et al. [ 22 ] proposed a verification-based data extraction approach in which linear features are extracted by (1) identifying linear-segment pix-els, (2) linking detected line pixels to form a list of linear segments, and (3) applying semantic criteria to verify linear features. We follow this approach to detect and verify the features in data charts. All these methods are based on the same idea: extract line-feature and recover missing part with sufficient line information. Zhou and Tan [ 41 ] have propo-sed a Hough-based approach to recognize bar charts. They also proposed a HMM-based approach to recognize scienti-fic charts [ 42 ]. Use of constraint grammars for syntactic and semantic analysis of diagrams have also been proposed in literature [ 6 , 10  X  12 ].

Text-Processing: There are many steps in text-processing and the review of all of them is beyond the scope of this study. Here, we focus on text-searching algorithms, since they are the most important step in our work. These algorithms try to find a place where one or several strings (also called patterns) are found within a larger string or text. Over the years many algorithms for text-matching have been proposed including the brute force algorithm [ 3 ], and Knuth X  X orris X  X ratt algo-rithm [ 16 ]. Boyer X  X oore algorithm [ 4 ] examines the target string that is being searched for, but not the string that is being searched. Empirical results show that the variations of Boyer and Moore X  X  algorithm designed by Crochemore and Rytter are the most efficient in practice [ 8 ]. 2 Visual learning with data charts Visual learning techniques are graphical ways of working with ideas and presenting information. The effectiveness of information transmission from the graphic to the human is crucial in deciding the quality of the graphic. The quality of data charts is motivated by cognitive theories (Sect. 2.1 ), concepts of structural elements (Sect. 2.2 ), and the principles of graphics integrity. They are briefly described in this sec-tion. While the section is focused on data charts, most of the discussion is also applicable for graphics in general. 2.1 Cognitive theories Human understanding of pictures is a vast research area without a universally accepted theory. The process is divi-ded into multiple levels and encompasses actions from the first glance at a picture to detailed ideas about it. Arnheim [ 1 ] contends that picture perception is the viewer X  X  response to the basic forms present in the picture and the Gestalt laws of organization are the primary conveyors of meaning. Cog-nitivism, one of most dominant paradigms still researched today, defines cognition with symbolic representations [ 33 ]. In the case of data charts, they correspond to keywords and structural elements. Mayer [ 21 ] carried out a comprehensive study to determine the characteristics of effective multime-dia presentations. The verbal form (words) typically denotes speech and printed text. The pictorial form (pictures) can be static graphics (illustrations and photos) or dynamic graphics (animation and video). The focus of the study was on coordi-nating words and pictures to maximize learning. After rigo-rous testing and experimental results, Mayer [ 21 ] proposed a set of principles for an effective multimedia presentation. We summarize below the principles that apply directly to data charts:  X  Spatial contiguity : Learning is more effective when a  X  Coherence : Learning is more effective when extraneous  X  Redundancy : It is best to present information in multiple  X  Individual differences : The design of the document has a Other significant research results are reported in [ 17 , 28 ]. Lewandowsky and Spense review several empirical studies that examined the suitability of graphs and the role of psycho-physics in their perception [ 17 ]. Bertin proposed taxonomy of graphics elements and their perceptual properties and a grammar do describe them [ 2 ]. 2.2 Structural elements of data charts A chart can be regarded as an alternative representation of data already stored in a text format. Thus, it is important to reinforce the connection between text and pictures for enhan-ced cognitive processing. Data charts help in this regard, as they reveal patterns, relationships, and interdependencies.
The close interaction between the picture elements and their descriptions derived by human learners has been esta-blished by many researchers. Strothotte and Strothotte [ 33 ] state that, learning from pictures is achieved by first forming a mental model of the picture and then carrying out a mental dialogue with it. Furthermore, more engaged a user is in the process of interpretation, the deeper is the understanding. Steps involved in the cognitive processing of a data chart include the following (1) naming and categorizing the pic-ture (2) identification of basic graphic elements (e.g., circles, rectangles, or lines), (3) naming the basic graphic elements, (4) recognizing and naming the structured elements, and (5) deriving the semantic information. We have used criteria similar to this approach to break down a data chart into struc-tural components and then recognize it by examining their organization. 2.3 Graphical integrity of data charts Graphical integrity refers to effective transmission of information via graphics. Pioneering work in this area was carried out by Tufte, whose focus was on printed text and cor-responding figures (graphics) in data analysis [ 35  X  37 ]; it is especially important in the context of learning, since false or inaccurate learning of the concept may be difficult to reverse. Tufte [ 35  X  37 ] listed many criteria of excellence in the graphi-cal display of quantitative information. The relevant criteria for data charts are listed below:  X  The graphic should induce the reader to focus on the  X  The graphic should encourage the comparison of data,  X  The graphic should show data at different levels of  X  Thegraphicshouldshowthedataandpresentmanypieces  X  The graphic should avoid distortion of data and overload 3 Quality measures for graphics Inthissection,wedefineasetofmeasurestoevaluatethequa-lity of data charts. We first summarize the framework used to design the quality measures (QMs). The measures are moti-vated by research in educational psychology and cognition (Sect. 2 ) and use structural components of the data charts as the basic units of analysis. 3.1 Framework for quality measures In Sect. 2 , we described important principles from psycho-logy that are critical in the cognition of data charts. Here, we describe the principles, based on which we define the quality of data charts. Before we list them, we briefly define some central terms used in our research and referred to in the rest of this article: 1. Caption : A title, short explanation, or description accom-2. Labels : Text that is used to identify something within a 3. Reference text : Text in paragraphs adjacent to the graphic 4. Caption keywords : A significant or descriptive word 5. Label keywords :Asignificantordescriptivewordpresent 6. Reference text keywords : A significant or descriptive 7. Structural elements : These are elements of a graphic that 8. Necessary elements : These are the structural elements 9. Optional elements : These are structural elements that
Many observations and principles in the literature (Sect. 2 ) are qualitative or imprecise and hence cannot be directly quantified. Examples include  X  X ncourage the comparison of data X  or  X  X erve the purpose and are coherent. X  We have designed quantitative measures to approximate the qualita-tive principles proposed in the literature. Identification of structural elements allows for comparison between them and improves coherency. For example, identifying the bars in a bar chart, segments in a pie chart, and circles in a bubble chart fosters a comparative analysis between them. Using these principles, we list the key principles to compute the quality of a graphic: 1. Ability to divide the graphic into known structural com-2. Graphics modality in terms of structural components and 3. Distance between the graphic and its references :Thisis 4. Text modality in the whole document :Thisisthe 5. Contrast of the graphic : This refers to the clarity of the 3.2 Structural elements of data charts In this section, we describe the graphic (structural) elements present in data charts. The goal is to systematically ana-lyze their structure. This analysis is analogous to the implicit recognition and classification process employed by humans described in Sect. 2.1 . The recognition is achieved by recognizing the structural elements in the data charts, clas-sifying them, and finally forming a mental model of them. The subsequent cognition process then relies on the mental model to integrate and assimilate facts about the data charts.
We divide the elements of a data chart into two classes: necessary elements and optional elements (Sect. 3.1 ). The necessary elements correspond to the core structural ele-ments used by humans to understand and classify a data chart. The optional elements may or may not further reinforce this process depending on the complexity of the context. The necessary and optional elements for the five classes of data charts used in this research (Sect. 1.1 ) are summarized in Table 1 . 3.3 Quality measures Inthissection,wedefinethequalitymeasuresthatcanbeused to evaluate the quality of a data chart. It is important to define the measures such that their values are on a uniform scale and are normalized. This facilitates the comparison between different data charts. In the following, all the QMs are defined so that their values are normalized (between 0 and 1).  X  Spatial location quality: This is a measure of the distance  X  Label completeness: Ideally, all structural elements of a  X  Graphic contrast : This is motivated by Tufte X  X  principles  X  Modality measures: We define three different types of
Reference text and caption consistency :Referencetextand caption consistency (RCC) measures the degree of match bet-ween the reference text keywords and caption text keywords. It is motivated by Mayer X  X  individual differences principle, Strothotte X  X  guidelines, and Tufte X  X  principles for graphical integrity(Sect. 2 ).Itcanbecomputedasthepercentagematch between the number of reference text keywords and caption keywords. Ideally, it should be 1. The value is normalized between 0 and 1. Given a graphic G in a document D ,itis defined as RCC ( G , D ) = where n c ( G , D ) is the number of caption keywords and n ( G , D ) is the number of reference text keywords for gra-phic G in document D .

Reference text and label consistency : Reference text and label consistency (RLC) is the degree of match between the reference text keywords and caption text keywords and is defined as follows: RLC ( G , D ) = where n l ( G , D ) is the number of label keywords and n ( G , D ) is the number of reference text keywords for gra-phic G in document D . The value is normalized between 0 and 1.

Caption and label consistency : Caption and label consis-tency (CLC) is the degree of match between the caption key-words and label keywords. Given a graphic G in a document D , it is defined as CLC ( G , D ) = where n c ( G , D ) is the number of caption keywords and n ( G , D ) is the number of label keywords for graphic G in document D . The value is normalized between 0 and 1. 4 Text-processing In this section, we describe the processing of the main-text body of the document. The main-text body consists of the document without the data chart(s), i.e., a complete docu-ment page with blank space inserted at the location of the data chart. If the figure caption is outside the data chart (e.g., below the figure), it is considered to be a part of the main-text body. The main purpose of the text-processing is to locate the text that is related to the graphic and extract the impor-tant information from it. The end result is a list of reference text keywords. We assume that each graphic has a reference. However, the absence of any reference to the graphic is easily detected in our approach. In such a scenario, we assign a pre-defined score to the document and short circuit the quality computation. 4.1 Text-parsing The objective of this step is to understand the structure of the main-text body. We segment the text into words, text lines, and structural blocks (paragraphs, which consist of a group of text lines) using a structural layout analysis. This is carried out in a top X  X own fashion, where the page is split into blocks of text (paragraphs) and each paragraph is split into lines. The steps involved in text-parsing are as follows: 1. Compute the total number of lines in a page : The number 2. Form a character matrix : All characters are assumed to 3. Compute the distance between words : A word is a conti-4. Detect and mark figure references : The locations in the 4.2 Reference text-stemming Text stemming is the process of reducing a word to its stem or root form, so that variations of particular words such as past tense, plural, and singular usage are recognized with the same stem form. The objective of this step is to determine the stem-med forms of the words in the reference text. The stemmed words are used for keyword-matching later on. This is carried out with the caption keywords. We used the Porter stemming algorithm for our research. This is a popular algorithm that is widely used and has been adapted over many years [ 27 ]. It is defined as  X  X  process for removing the commoner morpho-logical and inflexional endings from words in English. X  We used an ANSI C version of the porter stemming algorithm ( http://www.tartarus.org/~martin/PorterStemmer ). 4.3 Reference text keywords compilation The objective in this step is to accumulate the keywords in the reference text. This can be done by parsing the entire stem-med paragraph (Sect. 4.2 ) and recursively removing high frequency words like  X  X nd, X   X  X he, X  and  X  X s. X  The remaining words are then marked as keywords. This is done in accor-dance with Zipf X  X  law [ 39 ]. The words exceeding a predefi-ned frequency are considered to be common and are removed from consideration. This process is also applied to the figure caption. As with stemming, any standard software can be used to find stop words. 5 Graphics-processing In this section, we describe the process of extracting high level information from the graphics image (data chart). First, we perform several image-processing operations to prepare the image for extraction of structural elements. Since lines form an important class of structuring or substructuring ele-ments, we describe how they can be extracted efficiently. After identifying relevant structural elements, we verify their presence, and use them for classification. 5.1 Initial processing Initial processing is commonly performed in image analysis tasks to simplify the complexity and effectiveness of downs-tream analysis. In the case of data charts, the goal of initial processing steps is to go from pixels to linear structures. The initial processing steps includes binarization, noise reduc-tion, thinning, and edge detection.

Image binarization : Data charts typically have significant amount of white space (background). Using a threshold ope-rator, we can derive a quick and simple segmentation of the image into background (white space) and foreground (text and linear structures). An adaptive thresholding scheme pro-ved effective for this task [ 25 ].

Noise reduction : Image noise occurs mainly from image transmission across different media such as the conversion from physical samples to scanned images. Salt and pepper noise is the most common form of noise, which we encoun-tered in data chart images. Standard filtering operations were effective in removing this type of noise.

Thinning : It is an image-processing operation in which the regions of a binary image are reduced to lines that approxima-tely fit center lines or skeletons. This is especially effective in images where main structures are elongated. In the case of data charts where many central elements are linear, this is an important step in information compaction. Thinning significantly improved the subsequent recognition process.
Edge detection : Edges characterize boundaries that are areas with strong intensity contrasts X  X  jump in intensity from one pixel to the next. Many different edge detection methods are reported in literature. In our experimentation with different operators using our images, the Canny edge detector [ 5 ] was found to be the most effective and hence is used in our work. 5.2 Line-processing Since lines form an important class of structures in our images, we extract the linear structures. Our line detection algorithm starts with edge images and is a generalization of vectorization [ 9 , 15 ], which yields straight lines and arcs. It broadly consists of two phases: (1) primitive line detection is carried out to obtain line fragments from the edge image pixels and (2) a postprocessing step in which the line frag-ments are joined, manipulated, and fitted to refine the output. Overall, we formulated the line detection algorithm to yield fine lines that are as accurate as possible. The different opera-tional steps in our line detection process are based on [ 18 , 19 ] and are described next: 1. Edge-linking : In this first step, we form lists of connected 2. Fitting line segments : We use an array to store the edge 3. Merging colinear segments : In this step, we merge 5.3 Text extraction To extract the text labels in the data charts, we used optical character recognition (OCR). In addition to the labels, some-times the figure caption is also embedded in the data chart and has to be extracted as well. There is a large body of literature on OCR [ 24 , 40 ] and a number commercial OCR software exists. For our purpose, we used standard OCR software to derive a text output (labels and/or captions) of the scanned data chart to a file along with the respective locations of the text. Then label-stemming is carried in the same way as the reference text-stemming described in Sect. 4.2 . The label keywords are then compiled in the same manner as reference text keywords (Sect. 4.3 ). 5.4 Extraction of structural elements Using the lower level features obtained so far, we derive the structural elements of the data charts. The set includes cir-cular segments, horizontal and vertical bars, axes, legends. These correspond to the structural elements identified in Sect. 3.2 . The process is complicated by the fact that these features touch and overlap and by inherent inaccuracy of the lower level operations. We use a two-step approach for this purpose: (1) we group linear structures to form structural ele-ments and (2) use the semantic properties of the structural elements to verify their presence. 5.4.1 Formation of structural elements The operational steps involved in forming an initial list of structural elements are as follows: 1. Remove outer bounding boxes in the figure: Sometimes 2. Extract the x -axis and y -axis if present: The x -axis is 3. Remove elements below the x -axis and to the left of the 4. Remove elements outside the rectangular region formed These results of using the four steps are shown in Fig. 4 . Figure 4 a shows the original binary image and Fig. 4 bisthe image obtained after the four operations. 5.4.2 Verification of structural elements Weusesemanticrules toverifythepresenceof shapes formed by the structural elements found in data charts. The semantic rules used in our work are described below.

Circle : A number of methods have been proposed in the literature to compute the roundness of a shape. A simple roundness metric is given by Roundness = where P and A denote the perimeter and area of the shape, respectively. This metric is equal to one only for a circle and it is less than one for any other shape. Given a shape S ,we verify it to be a circle if its roundness is greater than 0.90. Thus, Roundness ( S )  X  0 . 9  X  Circle ( S )
Horizontal bar : Horizontal bars are characterized by pairs of horizontal lines that are of equal length, equidistant from each other, and emanating from the y -axis. They are termina-ted at both ends by a vertical line that is parallel to the y -axis (see Fig. 5 a). A set of three line segments h 1 , h 2 , and a horizontal bar if and only if h = y -axis  X  h = v. bottom  X  v || y -axis
Vertical bar : Vertical bars are characterized by pairs of vertical lines that are of equal length, equidistant from each other, and emanating from the x -axis. They are terminated at both ends by a horizontal line h that is parallel to the x -axis (see Fig. 5 b). A set of three line segments v 1 ,v 2 , and h form a vertical bar if and only if v = x -axis  X  v = h . left  X  v
Skewed line : Lines in the grid area that are not parts of horizontal bars, vertical bars, circles or any closed polygon are considered to be skewed lines. Skewed lines are charac-terized by the absence of symmetry in the relevant grid area formed by x -and y -axis, i.e., they are not equidistant from each other; they do enclose any known shape and may or may not touch the axes. 5.5 Classification of data charts Classification of the graphic is an important step in the understanding of the data chart. Different classes of the chart will induce different mental models and analyses (Sect. 2.2 ). Our classification scheme is motivated by the literature in cognitive theories (Sect. 2 ) that strongly suggest that structuring elements play a crucial role in the understanding of data charts. To enact this classification scheme, we use a decisiontreebasedonthesestructural elements toclassifythe graphic being examined into one of the five classes of charts described in Sect. 1.2 .An unknown category is included to allow for data charts that cannot be classified. Structural ele-ments that have been identified in Sect. 3.2 , and extracted using techniques described in Sect. 5.4 , play a central role in the classification process.

A set of simple rules to identify each class of data chart based on its necessary features is given below. The rules are graphically shown in the form of a decision tree in Fig. 6 .  X  X -axis  X  Y -axis  X  Origin  X  Horizontal bars  X  Bar chart  X  X -axis  X  Y -axis  X  Origin  X  Vertical bars  X  Column  X  X -axis  X  Y -axis  X  Origin  X  Skewed Lines  X  Line chart  X  X -axis  X  Y -axis  X  Origin  X  Circles  X  Bubble chart  X  Circle + Line Segments (inside circle that intersect at
Figure 6 shows that the high-level features are used for classification, and it is thus critical that they be identified accurately. The process of extracting these features (e.g., axes, bars, columns, etc.) is complex, because we need not only to extract them from complex images, but also to verify them using contextual information. 6 Quality of graphic computation In this section, we discuss how text and graphics-base des-criptors for the graphic are integrated to evaluate its quality. First, the text-matching of the keywords (Sect. 3.1 )isdis-cussed. We then describe how the different quality measures are computed. Finally, we present how these measures are combined to compute an overall quality of the graphic. 6.1 Text-matching We described how the keywords are extracted from the text in Sect. 4.2 . With the keywords established, we need to detect and check for matches within the three text modes described in Sect. 3.1 : (1) label keywords and caption keywords, (2) label keywords and reference text keywords, and (3) label caption keywords and reference text keywords. We use a version of the Knuth X  X orris X  X ratt algorithm [ 16 ], which searchesforoccurrencesofapattern(keyword)byemploying the simple observation that when a mismatch occurs, we have enough knowledge simply by possessing the pattern to determine where the next match could begin, thus bypassing re-examination of previously matched characters. 6.2 Quality measures computation From the text-processing (Sect. 4 ), graphics-processing (Sect. 5 ), and text-matching stages, we obtain all the descrip-tors needed for computation of the quality measures defined in Sect. 3.3 . The text-matching stage checks the modality of keywords obtained from the text-and graphic-processing stages, respectively. The text-based descriptors include the following:  X  Location of data chart on document page  X  Location of figure references on document page  X  Character count of document page  X  Number of characters in a line, i.e., line character count  X  Reference text keywords  X  Caption keywords
The image-based descriptors include the following:  X  Location and coordinates of lines  X  Location and coordinates of structural elements  X  Location of labels  X  Label keywords  X  Contrast block distance of equalized histogram 6.3 Quality of graphic computation The quality of a graphic (QoG) is an integrated quantitative measure of the overall quality of a data chart in a mixed-mode document. The formulation here is designed for data charts, but it can be suitably extended to other types of graphics as well. In general, QoG is a function of all the quality measures (QMs) defined in Sect. 3.3 , i.e., QoG = f ( SLQ , LC , GC , RLC , CLC , RCC ) (10)
In general, the function f can take any form. Arithmetic mean and weighted mean are two common functions that can be used for this. If normalized quality measures are used (i.e., the range of values for QMs is between 0 and 1), a QoG value of 1 would indicate a perfect data chart and vice versa.
If a weighted mean approach is used, the weights can be derived according to the graphic type being evaluated or the features being checked for. For example, if the emphasis is on checking the labels in a graphic, the weight for LC can be set to be relatively high. If the emphasis is on checking the modality, we can increase the weight for the text moda-lity measures. This flexibility is an important feature, which allows for applying the QoG measurement to a variety of graphic types and emphases on quality aspects.

In our research, we have considered all the quality mea-sures to be of equal importance and have thus used a simple mean to compute the QoG. While this formulation is by no means binding, we use this formulation as a base model. This can be expressed as QoG = 7 Implementation and results In this section, we discuss the implementation details and the results of using the approach on a test set. The system was implemented on MATLAB ( http://www.mathworks.com ). In the training stage, we tuned our algorithms on a set of data charts. The system was then tested with an independent set of data charts that formed our test set. 7.1 Implementation details The MATLAB package was chosen as the base platform. It integrates mathematical computing, visualization, and is a powerful technical language. Customized algorithms were writtenin X  X  X  X ndwereintegratedwiththeMATLABengine.
 The MATLAB image-processing tool box provides support for color space conversion, image analysis, image files I/O, image registration, image transforms, filter design, and image enhancement. The API support provided in the MATLAB package enables user to link the application with other platforms also. All the text-processing algorithms were implemented in the C++ programming language with the assumption that the alphabet is the set of ASCII codes or any subset of it. 7.2 Training phase Our training data set consisted of 30 mixed-mode documents with six documents representing each of the five classes of data charts. In this step, the goal was to debug the system and tune the parameters involved. Two issues were consi-dered in choosing the documents. We chose documents that had English text in only horizontal and vertical orientations. This was done primarily to accommodate the requirements of the OCR systems that recognize only letters of the English alphabet and whose orientations are either vertical or hori-zontal. This merely simplifies the text search and matching processes and does not affect the generality of our approach. It also simplifies the process of specifying the location of figure labels within a figure. Second, since our emphasis is on the evaluation of the quality of a data chart in a mixed-mode document, we chose documents that did not contain special icons or special decorative fonts embedded within a body of text. This again does not affect the generality of our approach, but simplifies the text-processing stages, which would otherwise be very computationally intensive.
Anumberofparametershadtobetunedduringthetraining stage. The document character count, line character count, distancemeasurebetweenwords,andtext-matchinghadtobe adjusted to account for blank spaces and different font types. In all cases, we manually checked the results to ascertain the accuracy of the results obtained.

In training, we found several problems and we briefly list them below:  X  OCR errors : Some characters are wrongly recognized by  X  Vectorization limitations : In some data charts, no good  X  Complex charts : Sometimes, the structure of the charts  X  Interfering labels : The verification and classification pro-7.3 Performance evaluation 7.3.1 Test set Our test set consisted of 75 mixed-mode documents with 15 documents for each one of the five classes of data charts. These documents were compiled from a variety of sources all available on the World Wide Web (WWW). 7.3.2 Classification Table 2 summarizes the results of our classification process in a confusion matrix format. The results show that all charts were classified as their true class type or as unknown. All 15 bubble charts were classified correctly. Overall, the system classified the charts with 93.3% accuracy. It did not misclas-sify any chart into another class but could not classify about 7% of the charts. Figure 8 shows some sample charts that were misclassified. 7.3.3 QoG computation We obtained QoG measures for all the figures we tested. The values of the QoG measures intuitively matched the quality of the graphic being examined. In general, data charts with poor labels got lower QoG values compared to data charts with good labels, with all other aspects being approximately the same. The QoG measures varied from 0.25 to 0.82. The measures range from 0.44 to 0.68, 0.52 to 0.64, 0.37 to 0.70, 0.49 to 0.82, and 0.25 to 0.62, for pie charts, bubble charts, column charts, line charts, and bar charts, respectively. The figures below show some sample data charts and their QoG values. In Fig. 9 , the QoG value is relatively high (0.68) for the column chart, since both the axes are labeled. In addition, all the structural elements are also labeled. The score is not very high, because the keyword-matching is not complete ( X  X hildbirth X  was not mentioned in the description of the graphic).

The sample line chart shown in Fig. 10 has the struc-tural elements (lines) labeled, but the axes are not labeled. Figure 10 was also mentioned relatively far away from the figure.

The bar chart shown in Fig. 11 has a low QoG value (0.35), since it does not have a caption, the axes are not labeled, it has a large character distance greater than 850 (i.e., it is located far away from where the figure is first mentioned), and has low keyword-matching.
 7.3.4 Evaluation using a human study To further evaluate the approach, we undertook a human study. We used the same set of documents (15 documents from each of the five classes) that is used for automated ana-lysis. We used a partially balanced incomplete block design for our study. A set of 25 adults were randomly chosen for the study. Each subject was given a set of three documents from each class to evaluate. The subjects were asked to eva-luate the goodness of the graphic in the document using a seven-point Likert scale (7=high quality and 1=low qua-lity). Thus, each document was examined by five subjects. We computed the Pearson correlation between the computed QoG scores using our approach and the average ratings for each document from the human study. The correlation values are summarized in Table 3 .

The table shows that the computed QoG scores are highly correlated to scores given by human subjects. The bar charts and column charts were the most highly correlated and the pie and line charts were the least. The results thus validate the QoG computation proposed in this research. 8 Summary and future work This paper is one of the first attempts to determine the quality of graphics in a mixed-mode document. We have integrated research from several fields including image analysis, edu-cational psychology, and human cognition. In this study, we formulated the problem of recognition and quality assess-ment of data charts in documents. We described five major classes of data charts that are widely used today. We also developed automated approaches to classify data charts into these five classes of charts based on their structural elements and also to compute their quality. The approach is based on cognition related theories, guidelines, and principles.
The steps in our automated processing include text-processing, graphics-processing, and text-matching. The algorithms for line extraction, methods for text-processing, and methods for graphics-processing are described in this article. We extract text-based and image-based descriptors for the embedded graphic, which are used to compute the overall quality of graphic (QoG). Experimental results show that our approach is efficient for recognition of data charts and effective for assessing their quality. A formal quantita-tive validation of the QoG measures by humans is beyond the scope of this work. This may be based on surveys of popula-tion samples, which can also be used to establish a scale for QoG measures. The quality measures and consequently the QoG measures can be tuned according to the data obtained. Experimental results show that a large number of documents do not have very high QoG implying that they are not desi-gned for graphics quality.

Future work : The recognition and quality assessment of graphics is a complex problem and this is an early work in this direction. The scope of evaluating the quality of gra-phics is immense and much more work can be done in this area. The problem of graphics goodness or quality is going to get worse. Automated software to generate graphics is now ubiquitous and is used by novices and experts alike to create graphics and to embed them in multimedia documents. However, the users do not know what is important in crea-ting an effective graphic. Our work can be extended in many different directions, some of which are listed below.
Our focus is on single page documents and the approach can be extended to multipage documents (scanned docu-ments, pdf documents, etc.), since the distances are based on number of characters. Our work can be extended to other types of data charts, graphics, and multimedia. This includes developing graphic-specific quality measures. Including sup-port for 3-D figures such as bar charts made with cones or pyramids would also be useful. Mixed data charts, pie charts within bubble charts, and pie charts within line charts are get-ting popular today and our work can be extended to include them as well. Color is an integral part of data charts today and formulation of additional color-related perceptual measures, e.g., tone, color density, would also be useful. Color percep-tion and retention are vast independent areas of research by themselves and can be used to develop more color-related quality measures. The text recognition from graphics can be broadened to include a variety of font types and document layouts. Developing a Graphics Quality Advisor along the same lines as the spell checker tool available in MS Word can be used to advise people on the quality of graphics that they create.
 References
