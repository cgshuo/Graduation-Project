 Methods for creating accurate classifiers fro m data are of central interest to the data mining community [2,15,16]. The focus of this talk is on binary classification, i.e. clas-sification tasks in which there are only two possible classes, which we will call positive and negative . In binary classification, there are just two types of error a classifier can make: a false positive is a negative example that is incorrectly classified as positive, and a false negative is a positive example that is incorrectly classified as negative. In gen-eral, the cost of making one type of misclassification will be different X  X ossibly very different X  X han the cost of making the other type. 1
Methods for evaluating the performance of classifiers fall into two broad categories: numerical and graphical. Numerical evaluations produce a single number summarizing a classifier X  X  performance, whereas graphical methods depict performance in a plot that typically has just two or three dimensions so that it can be easily inspected by humans. Examples of numerical performance measur es are accuracy, expected cost, precision, recall, and area under a performance curve (AUC). Examples of graphical performance evaluations are ROC curves [18,19], precision-recall curves [6], DET curves [17], re-gret graphs [13], loss difference plots [1], skill plots [4], prevalence-value-accuracy plots [21], and the method presented in this talk, cost curves [7,11].

Graphical methods are especially useful when there is uncertainty about the misclas-sification costs or the class distribution that will occur when the classifier is deployed. In this setting, graphical measures can present a classifier X  X  actual performance for a wide variety of different operating points (combinations of costs and class distributions), whereas the best a numerical measure can do is to represent the average performance across a set of operating points.

Cost curves are perhaps the ideal graphical method in this setting because they di-rectly show performance as a function of the misclassification costs and class distribu-tion. In particular, the x-axis and y-axis of a cost curve plot are defined as follows.
The x-axis of a cost curve plot is defined by combining the two misclassification costs and the class distribution X  X epresented by p (+) , the probability that a given in-stance is positive X  X nto a single value, PC (+) , using the following formula: where C(-|+) is the cost of a false negative and C(+|-) is the cost of a false positive. PC (+) ranges from 0 to 1 .

Classifier performance, the y-axis of a cost curve plot, is  X  X ormalized expected cost X  ( NEC ), defined as follows: where FN is a classifier X  X  false negative rate, and FP is its false positive rate. NEC ranges between 0 and 1. To draw the cost curve for a classifier we draw two points, y = FP at x =0 and y = FN at x =1 , and join them by a straight line. The cost curve represents the normalized expected cost of the classifier over the full range of possible class distributions and misclassification costs. For example, the dashed line in Figure 1 is the cost curve for the decision stump produced by 1R [14] for the Japanese credit dataset from the UCI repository and the solid line is the cost curve for the decision tree C4.5 [20] learns from the same training data. In this plot we can instantly see the relation between 1R and C4.5 X  X  performance across the full range of deployment situations. The vertical difference between the two lines is the diffe rence between their normalized expected costs at a specific operating point. The intersection point of the two lines is the operating point where 1R X  X  stump and C4.5 X  X  tre e perform identically. This occurs at PC (+) = 0 . 445 . For larger values of PC (+) 1R X  X  performance is better than C4.5 X  X , for smaller values of PC (+) the opposite is true.

Mathematically, cost curves are intimatel y related to ROC curves: they are  X  X oint-line duals X  of one another. However, cost curves have the following advantages over ROC curves (see [11] for details):  X  Cost curves directly show performance on their y-axis, whereas ROC curves do  X  When applied to a set of cost curves the natural way of averaging two-dimensional  X  Cost curves allow confidence intervals to be estimated for a classifier X  X  perfor-For these reasons, we have gained insights into classifier performance using cost curves that would likely not have been possible using other methods [8,9,10] and other data mining researchers are using cost curves in their analyses [3,5,22,23].
 We thank the Natural Sciences and Engineering Research Council of Canada and the Alberta Ingenuity Centre for Machine Learning for their support of this research.
