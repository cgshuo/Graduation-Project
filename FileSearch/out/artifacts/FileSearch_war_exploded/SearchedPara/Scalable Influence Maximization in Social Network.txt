 Email: weic@microsoft.com
Influence maximization is the problem of finding a small set of most influential nodes in a social network so that their aggregated influence in the network is maximized. The seminal work by Kempe, Kleinberg and Tardos [1] provides the first systematic study of influence maximization as a discrete optimization problem. Influence maximization has the obvious application in viral marketing through social networks, where companies try to promote their products and services through the word-of-mouth propagations among friends in the social networks. With online social networking sites such as Facebook, LinkedIn, Myspace, etc. attracting hundreds of millions of people, online social networks are also viewed as important platforms for effective viral marketing practice. This further motivates the research com-munity to conduct extensive studies on various aspects of the influence maximization problem (e.g. [1], [2], [3], [4], [5], [6], [7]).

In [1] Kempe et al. proposed two basic stochastic influ-ence cascade models, the independent cascade (IC) model and the linear threshold (LT) model , which are extracted from earlier work on social network analysis, interactive particle systems, and marketing. In both models, a social network is modeled as a directed graph G = ( V,E ) , where the vertices of V represents individuals and edges in E rep-resent relationships and the orientations of the edges indicate the direction of influence. Roughly speaking, in the IC model each edge has an activation probability and influence is propagated by activated nodes independently activating their inactive neighbors based on the edge activation probabilities. In the LT model, each edge has a weight, each vertex has a threshold chosen uniformly at random, and a vertex becomes activated if the weighted sum of its active neighbors exceeds its threshold (see Section II for model details).

The two models characterize two different aspects of social interaction. The IC model focuses on individual (and independent) interaction and influence among friends in a social network. The LT model focuses on the threshold behavior in influence propagation, which we can frequently relate to  X  when enough of our friends bought a MP3, played a new computer game, or used a new online social networks, we may be converted to follow the same action. The random threshold  X  v is to model the uncertainty of individuals X  conversion thresholds. In [1], Kempe et al. show that both models can be generalized and their generalized versions become equivalent. However, the basic IC and LT models stay as two distinct models.

The influence spread in the LT or IC model given a seed set is the expected number of activated vertices after the activation process ends. The influence maximization problem with parameter k is to find a seed set S of size k such that the influence spread of S is the largest. Kempe et al. show that the maximization problem in both models are NP-hard, and then they provide a greedy approximation algorithm for both models that achieves an approximation ratio of 63% . However, the greedy algorithm relies on the computation of influence spread given a seed set, the exact solution of which is left as an open problem in [1] for both models. Instead, they use Monte-Carlo simulations on influence cascade to estimate the influence spread, which makes the algorithm rather slow and not scalable  X  the algorithm takes days to select 50 seeds in a moderate sized graph of 30 K nodes.
To overcome the inefficiency of the original greedy algo-rithm, a series of studies have been done to either improve the original greedy algorithm or propose new heuristic algorithms ([3], [4], [6], [7]). The improvements on the greedy algorithm reported in [4], [6], although significant, is still not scalable  X  it reduces the computation in the above examples from days to hours, but cannot scale up to larger networks, as reported in [7]. The new heuristic algorithms proposed in [3], [6], [7] are orders of magnitude faster than the fastest implementation of the greedy algorithm while maintaining a competitive level influence spread, making it a very promising direction. However, all of these heuristic algorithms are designed using specific properties of the IC model. In constrast, for the equally important LT model, the above heuristics do not apply and there is no scalable heuristic designed by utilizing special features of the LT model. In this paper, we fill this gap in the research of scalable influence maximization algorithms.

First, we study the influence computation in the LT model (Section III). We show that computing the exact influence spread in the LT model is #P-hard, even if there is only one seed in the network. Our reduction uses the interpolation technique, and is more involved than the simple reduction used in [7] to show the #P-hardness in the IC model. This hardness result closes the open problem left in [1] and further indicates that the greedy algorithm may have intrinsic difficulty to be made more efficient. To constrast with this hardness result, we show that computing influence spread in directed acyclic graphs (DAGs) can be done in linear time, which relies on an important linear relationship in activation probabilities between a node and its in-neighbors in DAGs.
Next, based on the fast influence computation for DAGs we propose the first scalable heuristic algorithm tailored for influence maximization in the LT model, which we refer to as the LDAG algorithm (Section IV). Our idea is to construct a local DAG surrpounding every node v in the network, and restrict the influence to v to be within the local DAG structure. This makes influence computation tractable and fast on a small DAG. To select local DAGs that could cover a significant portion of influence porpagation, we propose a fast greedy algorithm of adding nodes into the local DAG of a node v one by one such that the individual influence of these nodes to v is larger than a threshold parameter  X  . After constructing the local DAGs, we combine the greedy approach of selecting seeds that provide the maximum incremental influence spread with a fast scheme of updating incremental influence spread of every node. Our combined fast local DAG construction and fast incremental influence update make the LDAG algorithm very efficient.
We conduct extensive simulations on both real-world networks and synthetic networks to demonstrate the scala-bility and effectiveness of our algorithm (Section V). Our simulation results show that our LDAG algorithm scales to networks with millions of nodes and edges, while the optimized greedy algorithm already take days for networks in the size of 64 K . In term of influence spread, our LDAG algorithm is always very close to that of the greedy algorithm in all test cases, showing that the LDAG algorithm is able to achieve the same level of influence spread while running in orders of magnitude faster than the greedy algorithm. We also compare the LDAG algorithm with some other heuristic algorithms such as PageRank [8] and the degree discount heuristic [6]. The results show that the LDAG algorithm always performs among the best algorithms in term of the influence spread in all test cases, while other heuristics performs poorly in some test cases. We believe this is because our LDAG algorithm is designed specifically for the LT model while other heuristics do not take advantages of the special features of the LT model or are designed for a different model.
 A. Related work
Domingos and Richardson [9], [10] are the first to study influence maximization as an algorithmic problem. Their methods are probabilistic, however. Kempe, Kleinberg, and Tardos [1] are the first to formulate the problem as a discrete optimization problem, but one of the issues of their work is the scalability of their greedy algorithm.

In [4], Leskovec et al. present a  X  X azy-forward X  opti-mization in selecting new seeds to significantly reduce the number of influence spread evaluations, but it is still slow and not scalable to large graphs with hundreds of thousands of nodes and edges, as demonstrated in our experiments.
Several recent work proposes different heuristic algo-rithms specifically designed for the IC model. In [3], Kimura and Saito propose shortest-path based influence cascade models and provide efficient algorithms to compute influ-ence spread under these models. In [6], Chen et al. propose degree discount heuristics for the uniform IC model in which all edge probabilities are the same. In [7], Chen et al. propose maximum influence arborescence (MIA) heuristic for the general IC model. since all of them are designed using specific features of the IC model, they do not apply directly to the LT model. In term of design principle, our LDAG algorithm is similar to the MIA algorithm. Both uses local structures to make the influence computation tractable and reduce computation cost. However, the local structure and the influence computation are different: MIA uses local tree structures because that is the only structure making the influence computation tractable in the IC model, while LDAG uses local DAG structures, and thus could include more influence paths in the local structure.

Narayanam and Narahari [5] propose a Shapley value based heuristic SPIN for the LT model. However, SPIN only relies on the evaluation of influence spreads of seed sets, and thus does not use specific features of the LT model. Moreover, SPIN is not scalable, with running time comparable (as shown in [5]) or slower (as shown in our tests) than the optimized greedy algorithm.

Several studies design machine learning algorithms to extract influence cascade model parameters from real datasets [11], [12], [13], [14], which can be used to generate influence graphs studied in this paper.

Following the definition in [1], we define the linear threshold (LT) model as follows. An (LT) influence graph is a weighted graph G = ( V,E,w ) , where V is a set of n vertices (nodes) and E  X  V  X  V is a set of m directed edges, and w : V  X  V  X  [0 , 1] is a weight function such that w ( u,v ) = 0 if and only if ( u,v ) 6 X  E , P u  X  V w ( u,v )  X  1 . In the LT model, when given a seed set S  X  V , influence cascades in graph G as follows. First, every vertex v independently selects a threshold  X  uniformly at random in range [0 , 1] , which reflects our lack of knowledge of users X  true thresholds as pointed out in [1]. Next, influence cascades in discrete steps i = 0 , 1 , 2 ,..., , and let S i denote the set of vertices activated at step i , with S 0 = S . In each step i  X  1 , a vertex v  X  V \ X  0  X  j  X  i  X  1 is activated (and thus is in S i ) if the weighted number of its activated in neighbors reaches its threshold, i.e.
 The process stops at a step t when S t =  X  . For convenience, we consider S i =  X  for all i &gt; t . Let  X  L ( S ) denote the expected number of activated nodes given the seed set S (i.e. the expected value of | S i  X  0 S i | ) , where the expectation is taken among all  X  v values from their uniform distributions. We call  X  L ( S ) the influence spread of seed set S in influence graph G under the linear threshold model.

As shown in [1], the linear threshold model defined above is equivalent to the reachability in the following random graphs, called live-edge graphs : Given an influence graph G = ( V,E,w ) , for every v  X  V , select at most one of its incoming edges at random, such that edge ( u,v ) is selected with probability w ( u,v ) , and no edge is selected with probability 1  X  P u w ( u,v ) . The selected edges are called live and all other edges are called blocked . Let R denote the random graph generated from G , which includes all vertices in V and all live edges selected. Thus, we have
Proposition 1 (Claim 2.6 of [1]): Given an influence graph G and a seed set S , the distribution of the set of active nodes in G with seed set S under the linear threshold model is the same as the distribution of the set of nodes reachable from S in the random graph R G . Algorithm 1 Greedy ( k,f ) 1: initialize S =  X  2: for i = 1 to k do 3: select u = arg max w  X  V \ S ( f ( S  X  X  w } )  X  f ( S )) 4: S = S  X  X  u } 5: end for 6: output S
The above equivalence is central in analyzing the linear threshold model, including that showing its influence spread is submodular ([1]), proving that computing its influence spread is #P-hard, and designing scalable algorithm for influence maximization, as shown later in the paper. We say that a set function f on subsets of V is submodular if for any S  X  T  X  V and any u  X  V \ T , f ( S  X  X  u } )  X  f ( S )  X  f ( T  X  X  u } )  X  f ( T ) . Intuitively, submodularity indicates that f has diminishing margin returns when adding more nodes into a set. We say that f is monotone if f ( S )  X  f ( T ) for all S  X  T  X  V . The following proposition states an important property of  X  L .

Proposition 2 (Theorem 2.5 of [1]): The influence spread  X  L under the linear threshold model is monotone and submodular.

The influence maximization problem under the linear threshold model is, when given the influence graph G and an integer k , finding a seed set S of size k such that its influence spread  X  L ( S ) is the maximum. It is shown in [1] that finding the exact optimal solution is NP-hard, but because  X 
L is monotone and submodular, a greedy algorithm has a constant approximation ratio. Algorithm 1 shows a generic greedy algorithm for any set function f . It simply execute in k rounds, and in each round it selects a new entry that gives the largest marginal increase in f . It is shown in [15] that for any monotone and submodular set function f with f (  X  ) = 0 , the greedy algorithm has an approximation ratio f ( S ) /f ( S  X  )  X  1  X  1 /e , where S is the output of the greedy algorithm and S  X  is the optimal solution.

However, the generic greedy algorithm requires the evalu-ation of f ( S ) . In the context of influence maximization, the exact computation of  X  L ( S ) was left as an open problem in [1]. In the next section, we close this open problem by showing that the exact computation of  X  L ( S ) is #P-hard. This hardness result further indicates the intrinsic limitation of the greedy algorithm approach and motivates us to pursue scalable heuristic algorithms for the influence maximization problem in the LT model.

In this section, we first show that computing exact influ-ence spread for general graphs is #P-hard, and then provide a linear-time algorithm computing exact influence spread in directed acyclic graphs (DAGs). The DAG computation al-gorithm is the basis for our influence maximization solution presented in the next section.
 A. #P-hardness for general graphs
We show that the exact computation of  X  L ( S ) is #P-hard by applying Proposition 1 and using a reduction from the simple path counting problem.

Theorem 1: Given an influence graph G and a seed set S as the input, it is #P-hard to compute  X  L ( S ) in G . Proof. We reduce this problem from the problem of counting simple paths in a directed graph. Given a directed graph G = ( V,E ) , counting the total number of simple paths in G is #P-hard [16]. Let n = | V | . From G , we construct a graph G 0 by adding a new node s 6 X  V and adding edges from s to all nodes in V . Let d be the maximum in-degree of any node in G 0 . For every edge e in G 0 , we assign its weight w ( e ) = w  X  1 /d , where w is a constant to be determined later. By the selection of d , we know that the summation of weights among all incoming edges of a node is at most 1 , satisfying the weight requirement of the LT model. Now we have an instance of the influence computation problem: G 0 with edge weights w and seed set S = { s } . We show that if for any eligible w computing  X  L ( S ) in G 0 is solvable, we can count the number of simple paths in G , and thus show that influence computation is #P-hard.

Let P denote the set of all simple paths starting from s in G 0 . By the equivalence given in Proposition 1, we have Let B i be the set of simple paths of length i in P , for i = 0 , 1 ,...,n , and let  X  i = | B i | . Then we have  X  L ( S ) = With the above equation, we can set w to n + 1 different values w 0 ,w 1 ,...,w n . For each w i , by assumption we can obtain  X  L ( S ) corresponding to w i . Then we obtain a set of n + 1 linear equations with  X  0 ,..., X  n as variables. The coefficient matrix M of these equations is a Vandermonde matrix ( M ij = w j i ,i,j = 0 ,...,n ). Thus the equations have a unique solution for  X  0 ,..., X  n and is easy to compute.
Finally, we notice that for each i = 1 ,...,n , there is a one-to-one correspondence between paths in B i and simple paths of length i  X  1 in graph G . Therefore, P n i =1 the answer to the total number of simple paths in graph G . Thus we complete the reduction and the theorem holds.
From the proof we see that #P-hardness holds even if seed set S contains only one vertex. It is also #P-hard if we want to compute the influence to one vertex, since the influence spread to a graph is the sum of influence to all vertices in the graph. Algorithm 2 compute ap ( u ) for all u in DAG D , with seed set S 1:  X  u in D , ap ( u ) = 0 ;  X  u  X  S, ap ( u ) = 1 ; 2: topologically sort all nodes reachable from S in D into 3: for each node u  X   X  \ S according to order  X  do 5: end for B. Linear-time algorithm for DAGs
Theorem 1 shows that computing influence spread in general graphs is #P-hard. We now show that in directed acyclic graphs (DAGs), the computation instead can be done in time linear to the size of the graph.

Let D = ( V,E,w ) be a DAG, and let S  X  V be a seed set in D . For any u  X  V , let ap ( u ) be the activation probability of u , that is, the probability that u is activated in D under the LT model given the seed set S . By definition, ap ( u ) = 1 if u  X  S . The following lemma shows the important linear relationship of activation probability in a DAG, the proof of which uses Proposition 1.

Lemma 3: For any v  X  V \ S , we have Proof. by Proposition 1, we consider the random graph R D generated by live edges. Let E u denote the event that edge ( u,v ) is selected as a live edge in R D . By the live-edge graph generation method, we have Pr( E u ) = w ( u,v ) . Let R u denote the event that u is reachable from seed set S . By Proposition 1, Pr( R u ) = ap ( u ) . Then for all v  X  V \ S , we have When the graph is a DAG, for any ( u,v )  X  E , whether u is reachable from S is independent of ( u,v ) being selected as a live edge, because there is no path from S to u that passes through v . Therefore, Pr( R u | E u ) = Pr( R u ) = ap ( u ) , and the lemma holds.

Based on the above lemma, we can design a linear-time algorithm to compute ap ( v ) for all v  X  V , as shown in Algorithm 2. We use N in ( u ) and N out ( u ) to denote the in-neighbors and outneighbors of node u , respectively. Topological sort in line 2 is to total order nodes and respect the partial order given by the DAG D . Then in lines 3 X  5 we compute ap ( u )  X  X  using Equation (III.1) for all u  X  X  following the topological order, which guarantees that when we compute ap ( u ) , all ap ( x )  X  X  of u  X  X  in-neighbors x have been computed. The operation  X   X   X   X  in line 4 is mainly for convenience of reusing this code in Algorithm 5, and could be omitted here without affecting the computation. It is clear that the algorithm computes all ap ( v )  X  X  in time linear to the size of the DAG D . Finally, we can add all ap ( v )  X  X  together to obtain the influence spread of the seed set S in graph D .
In the previous section, we show that computing influence in a DAG is easy. However, real social networks are not DAGs typically, so we cannot apply the algorithm for DAG directly. In [1] the authors use Monte-Carlo simulations to estimate the influence spread, making their greedy al-gorithm very inefficient. To allow efficient computation of influence in general social networks, we compute a local DAG for every node v in the graph and use influence to v propagated through its local DAG to approximate the influence in the original network. We refer to this as the LDAG influence model . The intuition is that (a) influence computation in DAGs are fast, and (b) influence cascade in the LT model is typically local because of the exponential dropoff in the probability of influence propagation. However, the local DAGs need to be carefully select in order to cover a significant portion of influence while allowing fast computations. In this section, we first introduce the general framework of the LDAG influence model, and then study local DAG constructions and influence maximization in the LDAG model.
 A. LDAG influence model In the LDAG influence model, each node v in the graph G = ( V,E,w ) is associated with a local DAG LDAG ( v ) , a subgraph of G containing v . We also refer to LDAG ( v ) as the LDAG rooted at v . Given a seed set S , we assume that the influence from S to v is only propagated within LDAG ( v ) according to the LT model. Let ap ( v,S ) be the activation probability of v when influence is propagated within LDAG ( v ) . Then the influence spread of S in the LDAG influence model, denoted as  X  D ( S ) , 3 is given by
Given G and LDAGs rooted at all nodes, maximizing  X  D ( S ) is still NP-hard.
 Theorem 2: The influence maximization problem in the LDAG influence model is NP-hard.
 Proof. (Sketch). We reduce the problem from the Vertex Cover problem. For every node v , we use v together with v  X  X  in-neighbors and the edges between these in-neighbors and v to construct the LDAG rooted at v . The rest of the proof is similar to the one in [1].

Although finding the optimal seed set in the LDAG influence model is NP-hard, computing  X  D ( S ) given S is in polynomial-time because all computations are on DAGs. It is also easy to see that  X  D ( S ) is still monotone and submodular Algorithm 3 FIND-LDAG( G,v, X  ), compute LDAG ( v, X  ) 1: X =  X  ; Y =  X  ;  X  u  X  V, Inf ( u,v ) = 0 ; Inf ( v,v ) = 1 2: while max u  X  V \ X Inf ( u,v )  X   X  do 4: Y = Y  X  X  ( x,u ) | u  X  X } /* adding edges */ 5: X = X  X  X  x } /* adding the node */ 6: for each node u  X  N in ( x ) do 7: Inf ( u,v ) += w ( u,x )  X  Inf ( x,v ) 8: end for 9: end while 10: return D = ( X,Y,w ) as the LDAG ( v, X  ) (because every ap ( v,S ) is monotone and submodular on S ). Therefore, we can use the greedy Algorithm 1 on  X  find S with an approximation ratio of 1  X  1 /e .
 In the following, we address two tasks to make our LDAG algorithm effective and efficient. First, for each node v , we need to compute its local DAG LDAG ( v ) that covers a significant portion of influence from other nodes to v . Second, we make the algorithm more efficient when combining the greedy Algorithm 1 and the DAG influence computation of Algorithm 2.
 B. Local DAG construction
We first need to compute the local DAG surrounding v such that it covers a significant portion of influence from other nodes to v while ignoring nodes that has only very small influence to v . This is formally defined as the following maximization problem. Let Inf G ( u,v ) be the influence probability from u to v in graph G , that is, the probability that v is activated when u is the only seed.
Definition 1 (MAX-LDAG Problem): Given an influence graph G = ( V,E,w ) , a node v  X  V , and a threshold  X   X  [0 , 1] as the input, the MAX-LDAG problem is to compute a DAG D = ( X,Y,w ) , such that (a) D is a subgraph of G , i.e. X  X  V , Y  X  E ; (b) v  X  X ; (c) Inf D ( u,v )  X   X  for all u  X  X ; and (d) P u  X  X Inf D ( u,v ) is the maximum among all DAGs satisfying (a), (b), and (c).
 Condition (c) above is for controlling the size of the LDAG using parameter  X  , which represents a tradeoff be-tween efficiency (smaller DAGs and thus faster computa-tions) and accuracy (larger DAGs and more accurate influ-ence result). Condition (d) aims at maximizing the sum of individual influence from any node u in the DAG to its root v . This is a heuristic for covering as much as possible the influence propagation in the selected DAG. Unfortunately the problem MAX-LDAG is NP-hard, as shown by the following theorem.
 Theorem 3: Problem MAX-LDAG is NP-hard.
 Proof. (Sketch). The reduction is from the Regular Graph Vertex Cover problem. See [17] for a complete proof.
To circumvent the NP-hardness result, we use an efficient greedy heuristic algorithm shown in Algorithm 3 to compute a local DAG LDAG ( v, X  ) for each node v given a threshold  X  . Initially the DAG D to be computed is empty, and only the influence probability from v to itself is 1 and all others are 0 . The algorithm add nodes into D one by one. Each time, the algorithm selects the node x that has the largest influence to v among all nodes not in D , and add x together with all its outgoing edges to nodes already in D into DAG D . After x is added into D , we need to update the influence probability for those in-neighbors u of x not yet in D , since they may have new paths through x to influence v (line 7). The process ends when the x selected has influence to v less than  X  . It is easy to note that the algorithm has the similar structure as the classic Dijkstra shortest-path algorithm. Let n v be the number of nodes in LDAG ( v, X  ) , and ` v be the volume of LDAG ( v, X  ) , which is the sum of in-degrees of nodes in LDAG ( v, X  ) . Then we know that our LDAG construction algorithm (Algorithm 3) has an efficient implementation in O ( ` v + n v log ` v ) time (using a Fibonacci heap).
While our LDAG algorithm does not provide an ap-proximation guarantee, it is very efficient and produces very good results in practice. In our experiment section, we will show that our FIND-LDAG algorithm leads to much better result in influence maximization than randomly selected local DAGs, and its performance is already very close to the gready Algorithm 1 for influence maximization, suggesting that the room for further improving the local DAG construction is small.
 C. LDAG algorithm
After selecting the LDAGs rooted at all nodes, we may simply follow the greedy Algorithm 1 to select the k seeds, and use Algorithm 2 to compute influence spread. This is not very efficient, however, as we now explain. Let InfSet ( u ) = { v  X  V | u  X  LDAG ( v, X  ) } , which represents the set of nodes that could be influenced by u in the LDAG influence model. After a new seed s is selected, for every v  X  InfSet ( s ) , we need to recompute the incremental influence spread of every node u in LDAG ( v ) because it may have changed. The naive computation would be for every such u , using Algorithm 2 to compute the influence to v in LDAG ( v ) when u is added to the seed set. Let n and m v denote the number of nodes and edges of LDAG ( v ) , respectively. Since computing influence in LDAG ( v ) given a seed set takes O ( m v ) time using Algorithm 2, and we need to try all possible nodes in LDAG ( v ) as the next seed, it takes O ( n v m v ) time to compute the incremental influence spread of any node in LDAG ( v ) . In the following, we utilize the linear relationship shown in Lemma 3 to reduce the above time from O ( n v m v ) to O ( m v ) .

Informally, in a DAG D , the activation probabilities of nodes u and v have a linear relationship, so if we know the linear coefficient  X  and the activation probability ap ( u ) of u , we can immediately know that when u is selected as a seed, the additional influence u imposes on v is (1  X  ap ( u ))  X  . Algorithm 4 compute  X  v ( u ) for all u in DAG D 1:  X  u in D ,  X  v ( u ) = 0 ;  X  v ( v ) = 1 ; 2: topologically sort all nodes that can reach v in D into 3: for each node u  X   X  \ ( S  X  X  v } ) according to order  X  5: end for More specifically, consider a DAG D = ( V,E,w ) and a seed set S  X  V , and for all u  X  V , let ap ( u ) denote the activation probability of u as computed by Algorithm 2. For two nodes u,v  X  V \ S , let the incremental influence of u to v in D be the amount of increase in ap ( v ) when u is selected as an additional seed. We have
Lemma 4: For two nodes u,v  X  V \ S , the incremental influence of u to v in D is (1  X  ap ( u ))  X   X  v ( u ) , where  X  is calculated in Algorithm 4.
 Proof. (Sketch). The proof is done by repeatedly expanding ap ( v ) using Equation (III.1).

Algorithm 4 shows that we can compute all  X  v ( u )  X  X  for all u  X  D in time linear to the size of the DAG. Then by the above lemma we can immediately obtain the incremental influence of all nodes u to v . Therefore, by using the linear relationship, we reduce the incremental influence computation from O ( n v m v ) to O ( m v ) .
 Algorithm 5 shows our full algorithm of selecting k seeds. For ease of reading, we add subscript v on variables such as ap v ( u ) to denote that the variables are for LDAG ( v, X  ) rooted at node v . Lines 1 X 12 are for the preparation phase, in which LDAG ( v, X  )  X  X  are computed (and InfSet ( v )  X  X  are derived from them), ap v ( u )  X  X  are initialized to 0 since there is no seed, and  X  v ( u )  X  X  are computed. We use a max-heap to maintain IncInf ( u ) for every u  X  V , which is the incre-mental influence of u to all nodes if u is selected as the seed. By Lemma 4, initially IncInf ( u ) = P v  X  InfSet ( u )  X 
The main loop in lines 14 X 31 uses the greedy approach to select k seeds one by one. After selecting a seed s with the highest incremental influence (line 15), we need to update related ap ( u )  X  X  and  X  ( u )  X  X  in order to calculate the new incremental influence of nodes. The nodes needed to be updated are those sharing at least one LDAG ( v, X  ) with s , i.e. those u  X  X  in LDAG ( v, X  ) for all v  X  InfSet ( s ) \ S . In each of such LDAG ( v, X  )  X  X , when s is selected as the next seed, by Algorithm 4 we can see that only those nodes u that can reach s in LDAG ( v, X  ) need to update their  X  ( u )  X  X . Due to the linear relationship, the update of those  X  ( u )  X  X  can be done by simply computing their changes  X   X  v ( u )  X  X  through reusing the code in Algorithm 4, with the initial condition  X   X  v ( s ) =  X   X  v ( s ) because  X  changed to zero when s is selected as a seed (lines 18 X  21). These nodes with updated  X  v ( u )  X  X  do not change their ap ( u )  X  X  because they are not reachable from s . Thus their Algorithm 5 LDAG algorithm for seed selection 1: /* preparation phase */ 2: set S =  X  3:  X  v  X  V, IncInf ( v ) = 0 4: for each node v  X  V do 5: generate LDAG ( v, X  ) using Algorithm 3 6: /* InfSet ( v )  X  X  are derived from LDAG ( v, X  )  X  X  */ 7:  X  u  X  LDAG ( v, X  ) , set ap v ( u ) = 0 8:  X  u  X  LDAG ( v, X  ) , compute  X  v ( u ) using Algorithm 4 9: for each u in LDAG ( v, X  ) do 10: IncInf ( u ) +=  X  v ( u ) 11: end for 12: end for 13: /* main loop for selecting k seeds */ 14: for i = 1 to k do 15: s = arg max v  X  V \ S { IncInf ( v ) } 16: for each v  X  InfSet ( s ) \ S do 17: /* update  X  v ( u ) for all u  X  X  that can reach s in 18:  X   X  v ( s ) =  X   X  v ( s ) ;  X  u  X  S,  X   X  v ( u ) = 0 19: topologically sort all nodes that can reach s in 20: compute  X   X  v ( u ) for all u  X   X  , using lines 3 X 5 of 21:  X  v ( u ) +=  X   X  v ( u ) , for all u  X   X  22: IncInf ( u ) +=  X   X  v ( u )  X  (1  X  ap v ( u )) for all u  X   X  23: /* update ap v ( u ) for all u  X  X  reachable from s in 24:  X  ap v ( s ) = 1  X  ap v ( s ) ;  X  u  X  S,  X  ap v ( u ) = 0 25: topologically sort all nodes reachable from s in 26: compute  X  ap v ( x ) for all u  X   X  , using lines 3 X 5 of 27: ap v ( u ) +=  X  ap v ( u ) , for all u  X   X  28: IncInf ( u )  X  =  X  v ( u )  X   X  ap v ( u ) for all u  X   X  29: end for 30: S = S  X  X  s } 31: end for 32: return S incremental influence IncInf ( u ) needs to be updated by adding  X   X  v ( u )(1  X  ap ( u )) (line 22). Similarly, for all nodes u reachable from s in LDAG ( v, X  ) , they need to update ap v ( u ) but not  X  v ( u ) , and the update of ap v ( u ) follows Algorithm 2 by computing the changes  X  ap v ( u ) , with the initial condition  X  ap v ( s ) = 1  X  ap v ( s ) and for all seeds u  X  S  X  ap v ( u ) = 0 (lines 24 X 27). Finally the incremental influence IncInf ( u ) of each u reachable from s decreases by  X  v ( u ) X  ap v ( u ) (line 28).
 Time and space complexity of LDAG algorithm. Let n be the total number of nodes in G . Let m  X  and  X  m  X  be the maximum size and average size (in terms of the number of edges) of LDAG ( v, X  ) among all v  X  V , respectively. Let n be the maximum size of InfSet ( v ) among all v  X  V . The LDAG ( v, X  ) is computed by a Dijkstra-like algorithm in Algorithm 3, and let  X  t  X  be the average time to compute one LDAG ( v, X  ) among all v  X  V . Note that  X  m  X  = O (  X  t for sparse graphs (such as typical social networks)  X  t  X  For every node v  X  V , the LDAG algorithm maintains LDAG ( v, X  ) and InfSet ( v ) , and for every u in LDAG ( v, X  ) , the algorithm maintains ap v ( u ) and  X  v ( u ) . The algorithm also maintains a max-heap for IncInf ( v ) for all v  X  V . Thus, it is easy to see that space needed is proportional to the total size of all LDAGs, which is O ( n  X  m  X  ) .
The preparation phase of our LDAG algorithm (lines 1 X  12) generates all LDAG ( v, X  )  X  X , and for each of them compute  X  v ( u )  X  X . The LDAG construction takes O ( n time, and  X  v ( u ) computations take O ( n  X  m  X  ) time totally. The initialization of the max-heap for IncInf () takes O ( n ) time. Thus the entire preparation phase takes O ( n  X  t  X 
In each iteration of the main loop (lines 14 X 31), selecting a new seed from the max-heap takes constant time, and for each v  X  InfSet ( v ) \ S , updating  X  v ( u )  X  X  and ap v all u  X  LDAG ( v, X  ) takes O ( m v ) time, where m v is the size of LDAG ( v, X  ) . Then updating each IncInf ( u ) takes O (log n ) time on the max-heap. Therefore, one iteration O ( n  X  m  X  log n ) . Therefore, to select k seeds, the total time linear relationship speedup, the time complexity would be O ( n  X  t  X  + kn  X  m  X  ( m  X  + log n )) .

We use experiments on real-world networks as well as synthetic networks to demonstrate the effectiveness and the efficiency of our LDAG algorithm.
 A. Setting up the experiments
The four real-world networks we use and their basic statistics are summarized in Table I, which include: (a) NetHEPT, an academic collaboration network extracted from  X  X igh Energy Physics -Theory X  section of the e-print arXiv (http://www.arXiv.org), with nodes representing authors and edges representing coauthorship relations; (b) DBLP, the Computer Science Bibliography Database maintained by Michael Ley (http://www.informatik.uni-trier.de/  X  ley/db/), again with nodes representing authors and edges repre-senting coauthorship relations; (c) Epinions, the Who-trust-whom network of Epinions.com [18], where nodes are members of the site and a directed edge from u to v means v trust u (and thus u has influence to v ); and (d) Amazon, the Amazon product co-purchasing network [19] dated on March 2, 2003, where nodes are products and a directed edge from u to v means product v is often purchased with product u (and thus u has influence to v ). These datasets vary in size and features and thus can test the performance of the algorithms in different cases. We also use synthetic power-law degree graphs generated by the DIGG package [20] to test the scalability of our algorithm with different sized graphs of the same feature.

For the graphs we tested, we use the following two methods to generate the influence weights on all edges: (a) the uniform method, in which for every node v in a graph with in-degree d v , we set the weight of every incoming edge of v to be 1 /d v ; and (b) the random method, in which the weight of every edge is generated uniformly at random in the range [0 , 1] , and then we normalize the weights of all incoming edges of a node v so that they sums to 1 .

In the experiments, we compare our LDAG algorithm with several other algorithms for influence maximization. As explained in the Introduction, to the best of our knowledge we do not find any other algorithm that is designed using specific features of the LT model. Thus we compare our algorithm with a few other more or less generic algorithms and heuristics, as we list below.  X  LDAG (  X  ): Our LDAG Algorithm 5 with threshold pa- X  Greedy : The greedy Algorithm 1 on the LT model  X  SPIN : A heuristic algorithm based on the Shapley  X  DegreeDiscountIC : The degree discount heuristic  X  PageRank : The popular algorithm used for ranking
We run 20000 simulations to accurately estimate  X  L ( S ) for every seed set S obtained from any heuristic algorithms, which matches the accuracy of the greedy algorithm. All experiments are run on a server with 2.33GHz Quad-Core Intel Xeon E5410, 32G memory, and Microsoft Windows Server 2003.
 B. Results of the experiments Scalability on the synthetic dataset. We first test the scalability of the algorithms, using a family of synthetic power-law graphs generated by the DIGG package [20]. We generate graphs with doubling number of nodes, from 2 K , 4 K , up to 256 K , using power-law exponent of 2 . 16 . Each size has 10 different random graphs and our running time result is the average among the runs on these 10 graphs. Every undirected edge is treated as two directed edges, and we use uniform method to generate edge weights for the directed edges. We run different algorithms to select 50 seeds in each graph. Figure 1 shows our scalability test result, with normal scale in (a) and log-log scale in (b) for better viewing of different curves. The results clearly show that Greedy is not scalable  X  it almost runs 16 hours for the graphs with about 80 K edges. LDAG scales quite well, only taking 1 . 5 minutes for graphs with 350 K edges.

The scalability of our LDAG algorithm is further demon-strated in our tests on real networks, as shown in Figure 2. The figure shows the running time of different algorithms on the four real-world networks of different sizes, and weights are generated using the uniform method (the results on the random method are similar and thus omitted). We can see that even for the largest DBLP graph with 655 K nodes and 2 M edges, LDAG only takes 5 minutes to finish, while Greedy takes 190 hours. Therefore, our LDAG algorithm has much better scalability and is more than three orders of magnitude faster than the greedy algorithm. One of the key reasons for the efficiency of LDAG is the small LDAG size computed by the algorithm, as reported in Table II.

Among other heuristics algorithms, SPIN turns out to have very poor scalability, running very slow even for the smallest NetHEPT graph of 15 K nodes. For this reason we do not include SPIN in our scalability test or in other larger datasets. PageRank and DegreeDiscountIC have a better scalability than LDAG , but we will show next that their influence spread is not as good as LDAG .
 Influence spread in the real-world datasets To compare influence spread generated by different algorithms, we run all algorithms on four real-world networks using both uni-form weights and random weights, and we select from 1 seed to 50 seeds. Figure 3 reports the results using random weights on four networks. The results using uniform weights are similar and are reported in [17]. For ease of reading, the legend of each figure lists the algorithms in the same order as their corresponding influence spread with 50 seeds. Several conclusions can be made from these test results. First, comparing with Greedy , LDAG consistently matches the performance of Greedy . The largest difference is in the DBLP dataset where LDAG is 6 . 7% and 5 . 5% lower than Greedy (for uniform and random weights respectively), while in other datasets LDAG is very close to Greedy or essentially the same as Greedy . Second, comparing with other heuristics PageRank and DegreeDiscountIC , LDAG perofrms consistently well, while DegreeDiscountIC per-forms poorly in Amazon dataset (more than 90% lower than LDAG ) and Epinions dataset (more than 34% lower than LDAG ), and PageRank performs significantly worse than LDAG in Amazon dataset ( 9 . 4% and 19 . 9% lower in uni-form weights and random weights, respectively). PageRank and DegreeDiscountIC do performs a few percentage better than LDAG in the DBLP dataset. However, the unstable performance of PageRank and DegreeDiscountIC makes them not suitable as a general heuristic for the LT model to be applied for different type of networks.

We believe that our test results provide a balanced view among these different algorithms. The main advantage of our LDAG algorithm is that it performs consistently among the best algorithms in all tests, and we attribute it to the design of LDAG tailored specifically to the LT influence model. Greedy algorithm with smaller number of simulations. We run Greedy with a smaller number of simulations to es-timate influence spread (20, 200 and 2000, instead of 20000) to see if we can significantly reduce Greedy  X  X  running time while obtaining similar influence spread. Our results in Figure 4(a) clearly shows that it is not the case: Greedy with 20, 200 and 2000 simulations are 56% , 13% and 4 . 3% worse than Greedy with 20000 simulations, and all are worse than our LDAG algorithm. In particular, Greedy (20) has running time comparable to LDAG , but has much worse influence spread. Therefore, the greedy algorithm cannot maintain high influence spread when reducing its number of simulations in estimating incremental influence spread. Importance of finding a good LDAG. Finally, we verify the effectiveness of our LDAG construction Algorithm 3. To do so, we compare it against an algorithm that randomly generates LDAGs: at each step, the algorithm randomly selects one node from the in-neighbors of all nodes already in the LDAG and adds the node as well as its outgoing edges into the LDAG. We denote this algorithm as RandDAG . Since threshold  X  does not apply to RandDAG , we directly control the size of LDAGs, and in our test RandDAG always select 30 nodes in each LDAG. To make a fair comparison, we also modify Algorithm 3 so that it also selects 30 nodes for each LDAG instead of using parameter  X  . We run both algorithms in the NetHEPT network using uniform weights. Our results in Figure 4(b) show that our greedy approach of generating LDAGs perform much better than randomly generated LDAGs, indicating that indeed LDAGs should be carefully selected. On the other hand, our greedy LDAG construction already results in influence spread very close to that of the greedy seed selection algorithm, so the benefit of further improvement in LDAG construction is small.
To summarize, the experimental results demonstrate that our LDAG algorithm performs consistently among the best algorithms in term of the influence spread and can scale to graphs with millions of nodes and edges, while other algo-rithms either do not scale or do not have stable performance in influence spread. Therefore, we believe that our LDAG algorithm is suitable as the scalable solution to the influence maximization problem in the LT model.
 There are many future directions related to this work. First, we need to go beyond the basic IC and LT models in the framework of [1], and study influence maximization problems in other models, especially those that may not satisfy the submodularity property. Second, we need to analyze real social networks using real-world social inter-action data to learn that what type of influence models are suitable for these networks, in order to effectively apply influence maximization algorithms. Third, influence maximization may be combined with other network analysis techiques such as clustering and community detection to further enhance the efficiency and effectiveness of influence maximization. Finally, one may further pursue the theoretical problems related to influence maximization, for example, finding efficient approximation algorithms for computing influence in the IC or LT model, constructing LDAGs with approximation ratio guarantees, etc.

