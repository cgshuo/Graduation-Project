 In digital advertising, advertisers want to reach the right audience over media channels such as display, mobile, video, or social at the appropriate cost. The right audience for an advertiser consists of existing customers as well as valuable prospects, those that can potentially be turned into future customers. Identifying valuable prospects is called the au-dience extension problem because advertisers find new cus-tomers by extending the desirable criteria for their start-ing point, which is their existing audience or customers. The complexity of the audience extension problem stems from the difficulty of defining desirable criteria objectively, the number of desirable criteria (such as similarity, diver-sity, performance) to simultaneously satisfy, and the ex-pected runtime (a few minutes) to find a solution over bil-lions of cookie-based users. In this paper, we formally de-fine the audience extension problem, propose an algorithm that extends a given audience set efficiently under multi-ple desirable criteria, and experimentally validate its perfor-mance. Instead of iterating over individual users, the algo-rithm takes in Boolean rules that define the seed audience and returns a new set of Boolean rules that corresponds to the extended audience that satisfy the multiple criteria. H.3.5 [ Information Storage and Retrieval ]: Online In-formation Services; I.2.1 [ Artificial Intelligence ]: Appli-cations and Expert Systems Algorithms, Application Online advertising; Targeting; Audience Extension * The authors contributed to this work equally.
 c  X 
Advertising budgets are increasingly moving towards pro-grammatic or digital advertising. In digital advertising, the ecosystem is roughly divided into four main entities: De-mand side platforms (DSPs), ad exchanges, supply side plat-forms (SSPs), and data management platforms (DMPs). Advertisers are on the demand side, i.e. they want to reach the right audience at the right place, cost, and time. Adver-tisers use DMPs to understand and define their audiences and DSPs to define and execute advertising campaigns to reach those audiences.

Access to an audience occurs through a number of ad for-mats (such as banner ads, video ads, etc.) on a number of devices (such as desktops, TVs, mobile phones, etc.). The audience is of course on the supply side, paying their at-tention to publishers through browsing web pages, playing games on mobile phones, shopping on e-commerce sites, etc. SSPs help publishers to monetize what keeps bringing audi-ence to publishers.

Ad exchanges are the bridges between demand and sup-ply sides. Given a user in an online context, ad exchanges perform a match between advertisers (i.e. bids and ads) and publishers (i.e. ad-space) in real-time. It is usually the case that the highest bid wins the match [18].

DMPs have been emerging as a central hub to seamlessly (and rapidly) collect, integrate, manage and activate large volumes of user data [10]. Such user data could be first-party data (i.e., historical user data collected by advertis-ers in their private customer relationship management sys-tems), or third-party data (i.e., data provided by third-party data partners, typically each specializing in a specific type of data, e.g., demographics, credit scores, buying intentions, etc.). After advertisers utilize DMPs to tie their existing customers to their digital identities (fully anonymous with-out any personally identifiable information), they could run two kinds of advertising campaigns: retargeting campaigns or prospecting campaigns. The former are run to target ex-isting customers with ads that may help them make more purchases. The latter are run to reach new audiences and convert some portion of them to customers.

In prospecting campaigns, the first and probably the most important question is to define the right audience to reach. By leveraging the data on DMPs, an advertiser can set up a specific segment (groupings of users according to some rules, e.g.  X  X ale users in California of ages 25-35 X ) towards which to target their advertisements. For example, to focus on performance, advertisers can target audiences that have previously visited their websites to maximize the likelihood of conversion (e.g. product purchase, subscription, filling out a form, etc.); to promote their brand, advertisers can target audiences that are marked with a given demographic profile by some third-party data provider (e.g.  X  X arents of Infants X  marked by an independent data provider).

Such audience segments are usually manually created for multiple reasons. Most of the time, manual generation of targeted user segments is due to advertiser policy, e.g. a sports company may only target certain age ranges, or a certain income group. Such a choice can be easily justified even if the online performance (clicks or conversions) of such segments is not that good, since the advertiser may want to reach these audiences to improve company recognition (this recognition will help offline purchases etc.). Another rea-son is to achieve additional filtering on top of automatically generated user audiences to improve performance and obey company policy. The final reason can be listed as simply the intuition of the advertiser, i.e. carrying of advertiser experience/know-how from different domains into the online advertising domain.

In many cases, the manually created segment only covers a small percentage of population and needs to be expanded. Here are two use cases:  X  Predictive targeting : The advertiser identified a group of  X  Data sparsity : It is very difficult to collect reliable de-
In this paper we focus on the topic of what we call au-dience extension . This problem deals with how to best ex-tend the advertiser-provided set of targeted segments so that the new set of users in the extended segment is similar to the original segments X  set of users, and performance metrics (such as click-through rate, conversion rate, or return-on-investment which is the ratio of the amount of monetary value received from clicks and conversions to the amount of money spent by the advertiser on showing impressions) are preserved or improved in the extended segments. Fur-thermore, by extending the initially provided audience, we increase the advertiser X  X  reach of users, as well as the amount of money that can be spent on impressions (spending capac-ity [13]) by the advertiser. The contributions of this paper are as follows:  X  Formal definition of audience extension problem in the  X  Multiple algorithms to extend audiences initially pro- X  Parallel implementation details of our audience exten- X  Evaluation of different methodologies proposed in terms To the best of our knowledge, this is the first paper that focuses on the topic of audience extension, and fills up a sig-nificant void in the literature on the methodical examination of this crucial industry problem.

The rest of the paper is organized as follows. We give a more detailed description as well as some explanatory ex-amples of audience extension problem in  X  2. Previous work in the literature for similar problems is discussed in  X  3. Later, we give multiple methodologies for solving audience extension problem in  X  4, and the parallel implementation details needed to scale to our domain X  X  large data sizes in  X  5. Finally, we conclude the paper with the evaluation of the proposed audience extension methodologies in  X  6, fol-lowed by the paper X  X  summary as well as our future work suggestions in  X  7. Background and Motivation . In digital advertising, users are usually referred to as the audience (for advertisements). From the business perspective, advertisers wish to learn ev-erything about their audience: their demographics, psycho-graphics, online and offline behavior, and how they respond to different types of advertisements. In Turn X  X  DMP sys-tem, each user is essentially a cookie ID with an associated profile data. Examples of data are visits to specific pages or purchases, user demographics (age, gender, income), or user intent (searching for a used car on an auction site). User data can come from an online context (pixels placed on pages) or could be collected offline, through a matching process joined to online users. Data can be owned by the advertiser (first-party) or can be purchased (third-party).
First-party and third-party data usually originate from the data source X  X  own cookie space and identifying the users across all these platforms remains a constant challenge. In-side Turn, we achieve this by syncing cookie IDs, which al-lows us to incorporate different types of data from a variety of partners and make the data actionable. For example, now advertiser  X  X nfantMilk X  might observe that users purchasing their product usually have label  X  X oungCouple X  from a third party. They can then utilize such information so that the impressions are delivered towards this specific population. Advertisers have to pay an impression-based fee for using third-party data, which is called data cost ; and in reality, it is another reason for audience extension. An advertiser may prefer to utilize the extended audience rules, especially if the third-party data in the extended rules have a lower data cost.

Such a holistic view of the audience data is a key factor to design of highly targeted ad campaigns that would maximize the return-on-investment (ROI). First and third-party data essentially tag users into all kinds of label categories. An ad-vertiser can then decide the audience population for adver-tisement delivery by designing some rules to check whether a user has some specific labels. In this paper, we focus on how to extend such a manually-selected audience population to improve audience size and preserve the performance met-rics. Each user is represented as a bag of data categories u = &lt; c i 1 , c i 2 , ..., c in &gt; , where c ij is category j assigned to user u i from some data source.

Definition 1. A category variable I j ( u i ) is a boolean in-dicator which is 1 if user u i has category label c wise. Sometimes we simplify I j ( u i ) as c j for brevity. An audience rule is a propositional logic formula where each variable is a category variable. Figure 1: Explainative examples for advertiser-defined segments and audience extension problem.

Definition 2. A segment is a portion of the online users that qualify for the advertiser-defined audience rule. Such rules are propositional logic formulas operating over user properties that can be first-party or third-party.
 Two examples of advertiser-defined segments are given in Figure 1(a). In the figure, segment  X  Age Range 26-30  X  is defined as the propositional logic formula which checks whether a user has one of the given age labels. Segment  X  Parents of Infants  X  is defined as which checks whether a user has label  X  X arentOfInfant X . Both segments are subsets of the total set of users. The intersection of these two segments can further be defined as a new segment which essentially covers young parents of in-fants. If an advertiser originally targets those young parents of infants and needs to expand its audience pool, Parents of Infants or Age Range 26-30 will be a natural choice. Research Problem . Given the fact that there are billions of users labeled with all kinds of data categories, advertis-ers usually conclude that their manually created segment is small and needs to be expanded. This audience extension problem can be formally defined as follows: Definition 3. Given an advertiser-defined segment rule S , Audience Extension recommends a new user population with a segment rule S 0 such that, Above, sim is a similarity score which looks at how similar the two audiences (defined by S and S 0 ) are, perf is the per-formance metric (conversion/click rate, ROI etc.) calculated for the two audiences, and finally, | aud ( S ) | denotes the size (number of users that fall into the rule, or reach ) of segment S (please note that | aud ( S  X  S 0 ) | &lt; | aud ( S ) | + | aud ( S in most cases due to intersection of users between two seg-ments). Note that there could be multiple definitions to calculate sim and perf , as we will show later.
 An example for the above problem definition is given in Figure 1(b). In the figure, we want the intersection be-tween two segments to be large, and the extended segment to bring additional reach (novel set of users) and have good performance (only ROI has been given in the figure for con-ciseness). We will be exploring multiple methodologies that we developed for our system in  X  4.

There are multiple factors that make audience extension challenging. First, it is usually infeasible to optimize towards each requirement at the same time. Users which are highly similar to the seed audience are usually rare, let alone the set of events (clicks, conversions) that they are involved in, which are necessary to compute their performance. We have to keep a balance among different criteria. Second, computa-tional efficiency is extremely desirable in audience extension. There are tens of thousands of categories in our system and any propositional logic formula of them could be a segment. Given the huge number of possible category combinations, pre-computing the recommendation offline for each possible segment would be expensive. A fast audience extension al-gorithm is critical for user experience. Finally, advertisers want the extension results to be easily understood, evalu-ated and modified. This excludes most of black-box machine learning methods for our purpose. In this paper, the search space of S 0 we focus on is the logical disjunction forms of categories, i.e. S 0 = ( c 1  X  c 2  X  ..  X  c m ). Like other overwhelm-ingly common  X  Find Good Items  X  tasks in the recommender systems literature [15], we would suggest a list of the recom-mended categories, along with predictions (scores) for how much the advertisers would like them.
Our problem is significantly different from another au-dience extension definition used in online advertising [1, 2], which allows publishers to earn extra money by tagging users who visit their websites, so that this information can later be used by themselves or other advertisers to target those users even when they are outside of the publisher X  X  domain. As explained in the introduction section, we focus on me-thodically increasing the audience population based on an advertiser X  X  manually created rule. Research work in some other domains is related to ours and could potentially be applied.
 Understanding User Interests . In order to perform ef-fective advertisement targeting, it is critical to understand user interests. As users interact with content and advertis-ing, their passive behavior can reveal their interests towards advertising [20]. Since there are usually plenty of clicks while other information is not available at a large scale, most ex-isting work in behavioral targeting uses clicks on advertise-ments as a proxy of interest [8, 22, 27]. Maximizing clicks does not necessarily imply maximizing purchase activities or transactions which directly translate to advertiser X  X  rev-enue [20]. Recently, advertisers have been willing to share individual responses to advertisements, making it feasible to use machine learning methods to develop models that are specifically optimized for conversions [5, 4]. There have also been some efforts in the literature that approximate user interest with demographics. For example, Joshi et al. [16] aim to generate textual data for each user based on demo-graphic information, by which the authors aim at efficiently matching advertisements to potentially interested users. User Clustering . User segmentation, which aims at group-ing users into user segments with similar behaviors, is crucial to behavioral targeting. If users with similar purchase inten-tions can be automatically clustered into the same segment, advertisers may gain more profit from advertisement deliv-ery. [24, 3] utilize Latent Dirichlet Allocation (LDA), and [26] utilizes probabilistic latent semantic analysis (pLSA) to group users for advertising, hence generating relevant au-dience subsets over the available users. In this way, it is possible to evaluate the benefit of each group for each ad-vertiser. While these works are useful in matching appro-priate advertisers with appropriate audiences, they do not take into account either advertiser-provided initial segments (our method is basically how to build on top of such prior information), or provide an option for advertisers to choose their audiences. As we will explain later, we provide such an option via weighting of different audience metrics. Extending Social Networks . Research shows that users connect to both friends they already know offline and new friends they discover on social networking sites [9]. Given the size of social networking sites, finding known contacts and interesting new friends to connect with on the site can both be a challenge. It has been shown that algorithms based on text content or friendship connections are effective in providing people recommendations and can significantly increase the number of friends of a user on the site [6]. An interesting work given in [19] actually may intuitively be utilized as a very feasible way to extend audiences. The au-thors look at friendship information between users (collected via an online social networking platform) for targeting. It would be intuitive to have the friendship network as a graph (where nodes are online users, and edges represent friend-ship). Given an initial set of nodes (users) in this graph by the advertiser as the original audiences (i.e. an advertiser-provided subgraph/audience), we can generate an extended audience as the users that have a direct edge (or we can look at n -hop neighborhood depending on advertiser prefer-ence or performance metrics etc.) to the original subgraph. [19] does not follow this kind of route, and unfortunately such friendship information is often proprietary (not even available as third-party data).
 Recommender Systems . Audience Extension is a spe-cial case of making recommendations. There is a wealth of research on recommender systems [15]. One of the most successful technologies for recommender systems, called col-laborative filtering, has been developed and improved over the past decade to the point where a wide variety of al-gorithms exist for generating recommendations. It utilizes similarities of preferences among users to recommend items such as movies for a user to consume. It does not really analyze the actual content of the items, but instead require users to indicate preferences on them, usually in the form of ratings.

Since advertisers typically do not share their created seg-ments, applying many of the existing recommender tech-niques could potentially be very challenging. To address Audience Extension, we can approach Collaborative Filter-ing from two perspectives. First, we can treat each segment as an item and find rules used by similar advertisers. This however may raise advertiser privacy concerns. Instead, we could treat each individual audience as an item and find patterns. This is what we adopted in this paper -look into similarity to recommend audiences.
 Industry Patents . In terms of patents, there is a single one which is remotely relevant to our work. The authors of [11] describe their approach of Audience Extension, which is quite different from what we propose in this paper. They suggest assigning a score (Audience Extension Score) that reflects the likelihood of each particular user to exhibit a desired behavior, such as desired TV viewing behavior or purchasing behavior. The patent is not specific on how to assign such scores, or how to optimize based on an adver-tiser X  X  different preferences. Finally, two patents [12, 23] do mention the problem of audience extension, however they do not provide any details on how to recommend extended audiences.
Based on the problem formulation, we will present the methodologies we applied to extend advertiser-defined seg-ments. As it will be seen, these are either trying to maximize one single function given in the problem definition, or try to find a balance between them.
As we explained before, the segment(s) provided to us by the advertiser is a propositional rule S , involving n cate-gories c 1 ,..,c n . This of course does not suggest that the audiences (set of targeted users) belonging to this segment only have these categories. Rather, the users within the segment may have many different properties, but they have been included in this segment due to the fact that they are tagged with the provided set of categories in the segment definition. Therefore, our first method, which we call purely greedy , aims to recommend the most frequently occurring set of categories in the segment X  X  audiences, which are not in the segment definition. This is a variation of the greedy set cover algorithm, where we want to either completely cover the original segment X  X  audience, or until our newly recom-mended segment X  X  audience reaches a certain size. Details are given in Algorithm 1.

There are multiple disadvantages of the purely greedy ap-proach. First is the way we generate the extension. Since the algorithm is basically the application of the set cover algorithm, the original segment is a subset of the extended audience. Other than this, the algorithm neither looks at the additional reach of the extended segment (covering the original segment does not mean the extended segment added new users to the original segment, since it can be very close in size to the original audience), nor the performance. Ex-tension is based directly on the set cover algorithm, and at no point of this scheme do we check the return-on-investment (ROI) or any other metric of the newly recommended users. This effect can be seen with a sample we picked from our system which is given in Table 1. The original advertiser-defined segment in this example is a single rule to pick up users in the age range 20-30 (we receive this tag info from the third-party data provider  X  X P 1 X ). As it can be seen, the extended audience is not really a gain since it basically either divides the age range to partitions, or presents some obvious facts (the user is a child in the family, i.e. is not the head of household, or makes under 15K dollars a year), Algorithm 1: Greedy approach to extend an audience
Input : S : original segment, m : desired audience size
 X   X  aud ( S );
Collect C  X  c n +1  X  n + m , all categories from the users in aud ( S ) that are not in definition of S , such that  X  c j  X  C , count the # of users in  X  that have c j ;
Order C into C sorted according to the number of users belonging to each category c j  X  C , descending ;
S 0  X  X  X  //extended audience is empty at the beginning; while | aud ( S  X  S 0 ) | &lt; m and C 6 =  X  do 7 Get c j  X  C sorted which is the most frequent ; 9 C  X  C  X  c j ; 10  X   X   X   X  aud ( c j ) ; 11  X  c j  X  C , recalculate the number of users ; 12 Recalculate C sorted from the new C ; Recommend S  X  S 0 as the new segment Table 1: Extended audiences generated in our sys-tem for the age range 20-30 according to the purely greedy approach.
 which comes up with an audience too big, and naturally does not follow the characteristics of the original segment. Sec-ond disadvantage with this method is on the running time. Our data have the strict mapping of users to segment rules (not vice versa), hence the set cover logic takes a long pro-cessing time, since at every point we need to recalculate the set of users that belong to a segment (this is costly in both sequential and parallel implementation, since we have to go through the audience once for each step, and our user space is in the order of hundreds of millions). Please note that we need the extension to be fast since the advertiser wants to constantly generate new segments and extend them in an interactive application (which we provide in our adver-tising platform). The rest of the section will be our expla-nation of a faster algorithm we applied with a much more feasible (better similarity, reach, and performance) recom-mended audience extension.
As we have shown, the greedy approach presented before does not necessarily recommend extended audiences with high reach or performance. In this section, we will present our proposed approach in balancing the necessary metrics as given in the problem definition (Eq. 1). To be exact, we start with an original advertiser-defined segment (set of categories/rules), and come up with an extended audience in a fast manner, while optimizing over the following metrics:  X  Interest: This metric measures the similarity of the  X  Novelty: This metric measures the additional audi- X  Quality: This metric measures the performance (ROI, Next, we will explain the calculation methods for all three of the above criteria.
We have explored two methodologies for the computation of the interest criteria: ( i ) Category correlation, and ( ii ) A simple probabilistic solution (that we decided to apply in the end) which is computationally cheaper, and works well in practice.
 Let X  X  first talk about the correlation between categories. This means that if our newly recommended category (to be included in the extended segment) correlates well with the original categories then it has a high interest score. Corre-lation ( Pearson correlation coefficient) of the recommended new category with an original category can be calculated as: Above, I c k ( u i ) is the indicator function that returns 1 if c is a category that u i belongs to or 0 otherwise (please also see Definition 1 in  X  2). Basically, the above formulation goes over all users and calculates a metric on the overlap of two categories. Please note that in the above formulation, any category can be replaced with a segment (i.e. set of categories) and the formulas can be applied as is.

Correlation is actually a pretty valid similarity criteria, but we have decided not to use it in our proposed method due to the following reasons. The first reason is data spar-sity, since most users belong to a few categories, we have observed that the computed correlation values are very close to each other (and very small) for most category pairs. Fur-thermore, we observed that correlation values are either too small (this is the prominent case), or too high (match per-fectly), in which case the extended audience would match perfectly to the original audience, hence would be redun-dant.

As listed above, the second possibility we explored (and the method of computation we chose) for the interest criteria is based on a simple probabilistic formula. This formulation gives the overlap between the original segment and a newly recommended category, and is as follows: This formula basically answers the following question:  X  X f a user belongs to segment S , what is the probability that Figure 2: Examples of similarity vs. novelty in orig-inal and extended audiences. the same user also belongs to category c new ? X . This value measures how well the extended audience covers the original audience. Please note that the purely greedy solution we describe in  X  4.1 maximizes this, but as we will show in the rest of the section, we look at novelty and quality as well.
Novelty is directly related to the size of new audience (novel audience, i.e. that does not belong to the original audience) in the newly recommended extension. Since we may have different sizes of original or extended audiences, we need a normalized value (rather than just the absolute value of the novel audience) for the novelty of a new cate-gory, which is given as the following probability: The above formulation can easily be applied to a segment, and answers the following question:  X  X f a user belongs to our newly recommended extended category, what is the prob-ability that it will not belong to the original advertiser-provided segment/audience, hence is novel ? X . We show an interpretation of the balance between similarity and novelty in Figure 2. It can be easily seen that we need both values to be balanced, since the goodness of the extended audience does not depend on a single one of the metrics. Furthermore, we give some demonstration of how the metrics of similarity (probabilistic formula), novelty , and correlation (this is what we explored, but ended up not using, for similarity metric) look like for different segments X  extensions in Tables 2, 3, and 4. Please note that the tables are created using a set of cate-gories generated by different first/third-party providers and do not necessarily represent ground-truth (since all providers only have access to, and can reliably tag a certain subset of all users).
Quality criteria can be calculated in multiple ways, de-pending on an advertiser X  X  preferences. We can calculate Table 2: Extended category similarity, novelty, and correlation metrics for the original advertiser-provided segment of  X  X nterest: Gossip X  (ordered by similarity).
 Table 3: Extended category similarity, novelty, and correlation metrics for the original advertiser-provided segment of  X  X tate: California X  (ordered by similarity).  X  Ethnicity: CA  X  represents users who were tagged by a third-party as born in California. click-through rate (CTR), conversion rate (CVR), or return-on-investment (ROI) for an extended category c new gener-ated for an advertiser adv as follows: Above, we have  X  click ( u,adv ) is the number of clicks that user u (having  X  imp ( u,adv ) is the number of impressions shown to user  X  conv ( u,adv ) is the number of conversions that user u  X  cost ( u,adv ) is the amount of money spent by advertiser Table 4: Extended category similarity, novelty, and correlation metrics for the original advertiser-provided segment of  X  X inancial: Makes Stock Trades X  (ordered by similarity).
  X  value ( u,adv ) is the amount of value (by the clicks and Obviously, we want our new segment/audience/category to have a quality value (chosen to be any of above three) as high as possible, while having both good similarity and nov-elty compared to the original advertiser-provided audience /segment. The need for such balancing implies a weighted audience extension scheme, which is given next.
Given the original segment S , our audience extension method combines the previously defined metrics similarity ( sim ), novelty ( nov ), and quality ( q ) and defines the score for a newly recommended category c new as: The intuition for the above formula is to capture the extra return (via nov ( c new | S )  X  q ( c new )) from the right audience (via sim ( c new ,S )). To avoid numerical instability, we take log of both sides, To make the recommending more flexible and allow adver-tisers to balance between criteria, we can assign weights to the log metrics, and when we replace the metrics with the formulations from the previous section, we have: logScore ( c new | S ) =  X  1 log ( p ( c new | S )) + The  X  values are application specific, but we can furthermore entitle different extension choices to the advertiser (accord-ing to different  X  s), giving them the option to choose as they please. Also, the reason we did not elaborate on the for-mulation of quality metric above is because there might be different choices, and Equations 3, 4, or 5 can all be inserted in place of q ( c new ).

Based on the formulation, we can sort different categories, and recommend the top-k ones to the user. Furthermore, it is always possible to pre-compute a segment-to-category matrix of goodness metrics, and immediately calculate the score online for an advertiser X  X  application-use experience.
In this section, we give implementation details on how we achieved large-scale audience extension at Turn; in specific, the weighted scheme presented in  X  4.2. In the online adver-tising domain, we typically have to deal with virtual users (cookie spaces) in the orders of hundreds of millions. To be able to check the segment or category information, as well as calculate quality metrics such as ROI or CTR, we need to apply parallel algorithms.
 System Architecture . Our audience extension system leverages our in-house data warehouse system, called Chee-tah [7] built on top of the Hadoop framework [25]. It is designed specifically for our online advertising application to allow various simplifications and custom optimizations. User facts are stored within nested relational data tables.
We present the first step of the audience extension imple-mentation in Figure 3. This figure gives the basic parallel process on generating the data to calculate segment to cat-egory similarity, novelty, and quality values. We distribute the whole segment and category data, as well as quality in-formation (e.g. number of impressions as well as number of clicks for one or multiple advertisers) for each user to differ-ent mappers. Within each mapper, we generate three types of key-value pairs:  X  Key  X  { segmentId } , Value  X  { qualityInfo,1 } :  X  Key  X  { categoryId } , Value  X  { qualityInfo,1 } :  X  Key  X  { segmentId,categoryId } , Value  X  { qual-After these keys are generated, in the reducer phase we can count the number of users as well as quality information for Figure 4: We count how many users have the spec-ified number of unique categories. The plot shows a power-law degree distribution for the number of categories. each segment, category, or segment-category intersections. These values are then used to calculate similarity, novelty, and quality information as in  X  4.2. For this purpose, we need to join segment and category values on the different types of outputs of reducers, again in a parallelized man-ner. This way we can generate segment-to-category matrices of similarity, novelty, and quality values. At the extension time, it is trivial for each (segment,category) pair to calcu-late the scores according to given different  X  values. We can then sort categories for each segment to be extended and recommend as possible audience extension candidates. The advertiser can then select the extension categories accord-ing to their internal metrics or data cost to utilize the new categories at run-time for targeting.
 Handling Data Skew . Pair-wise computation is expen-sive in big data systems, since this potentially can involve O ( n 2 ) complexity. Skewed data could create imbalanced load on both mappers and reducers, which makes such an operation much more costly. Varying execution times re-sult in low resource utilization and high overall execution time, since the next MapReduce cycle can only start after all mappers/reducers are done [14, 17]. Our user data is highly skewed. Without any mitigation, counting co-occurrences can lead to significantly longer job execution times and sig-nificantly lower cluster throughput.

More specifically, our data skew comes from two dimen-sions  X  users and categories. The user skew is caused by some long-tail users, which have significantly more category labels than others. They could be bots or spam users. We count the number of each user X  X  unique categories and plot the histogram in Figure 4. Like many other scientific data, a user X  X  count of categories roughly fits the power-law func-tion and a small percentage of users have unusually many categories. Sometimes data providers could introduce cate-gory skew into the data  X  advertisers pay a data cost if they use the data provider X  X  data for deciding to deliver an im-pression. Data providers are motivated to tag more users. In some cases, a category could tag so many users that it loses its discriminative power. For example, the most fre-quent category,  X  X raveler X  in our data covers more than 55% of our users.

We take two approaches to mitigate data skew. First, we ignore those long-tail users and categories, since they intro-duce little value to advertisers. In our implementation, the top 5% most frequent categories and 15% most tagged users are removed from the computation. Second, we take the load balance into account when we partition the data: before we do the actual computation, we sample the input records and compute a histogram of the underlying key space. We then partition the data so that each mapper has roughly the same load. With those two approaches implemented, the recom-mendation speed is improved by more than 450%  X  .
In this section, we will give some preliminary results on the extended audiences that our proposed algorithms return. As given in Eq. 6, we can assign different weights to similarity , novelty , and quality . This is advertiser/application-specific, i.e. there is no single correct assignment of parameters, but rather we leave it to the advertisers to choose according to their needs.

For our experiments, we have utilized 15 days of user profile data collected at Turn X  X  online advertising platform within 2014. From this data we can calculate how many users fall into any advertiser-defined segment, or how many users will fall into our recommended extended audience. We present our results for mainly four original segments (whose exact names and properties are not shown here due to pri-vacy reasons):  X  Segment 1 picks up users that have bought a certain  X  Segment 2 picks up users that have interest in a certain  X  Segment 3 picks up users that have stayed at a specific  X  Segment 4 picks up users that have bought a new cer-We have performed two experiments which optimize fully, either similarity score , or quality score , and we present the results below. We compare Weighted which is our proposed system from  X  4.2 to two other methods: Manual gives the human-generated extension (which picks up the top k most frequent categories from the advertiser X  X  original segment population), and P. Greedy is the purely greedy approach given in  X  4.1 (set-cover algorithm).
In this experiment, we are examining whether given a sub-set of an original advertiser-provided segment, we can extend this subset to recover the original segment. The exact steps of this experiment is as follows: 1. Pick up the users that belong to an advertiser-provided 2. Sample n (we took this to be 50K for this instance) 3. Pick up the top k/ 2 categories from this user sample, * Exact computation time is not shown here for confiden-tiality reasons. (a) Sizes of audiences for the original segment and differ-ent recommended extensions. Figure 5: Results of Population Recovery Experi-ment 4. Using different algorithms, generate k/ 2 recommended Results of population recovery experiment is given in Fig-ure 5. In Figure 5(a), we present the audience sizes for the original segments (Segments 1-4 which consist of k 1  X  4 cat-egories), and then we present the audience sizes for different extension algorithms (extension is made on top of the sub-set, and our aim is to recover the original segment). For the weighted case, we have chosen to fully optimize similarity ((  X  1 , X  2 , X  3 )=(1,0,0) in Eq. 6) since this is the most intuitive, and gave the best result in our experience for population re-covery. It can be seen from the figure that although Manual and P. Greedy each employ a different logic to choose the extension categories, audience size results are pretty close. Weighted extension returns the largest audience, which also is significantly larger than the original (further boost to nov-elty, although we were not optimizing towards it).

Figure 5(b) gives the percentage of users (of the original audience) that were covered by the extension algorithms. Our aim for the experiment was to cover as much of the original segment as possible by extending the subset. It (a) Sizes of audiences for the original segment and differ-ent recommended extensions. (b) CTR values for the original segment and different recommended extensions.
 Figure 6: Results of Performance Optimization Ex-periment can be seen that our weighted scheme provides significantly higher coverage in all cases ( p &lt; . 001).
In this experiment, we try to recommend an extended population with high quality scores. We chose click-through rates (CTRs, as described in Eq. 3) as our quality metric. For this purpose, we set the parameters (  X  1 , X  2 , X  3 )=(0,0,1) according to Eq. 6, which fully optimizes according to quality score, which we take to be CTR.
 The results of the optimize CTR experiment is given in Figure 6. We extend the four segments according to differ-ent approaches with one recommended category. We can see that our weighted approach comes up with reasonably larger audiences (Figure 6(a)), and the CTR of the extended audi-ence is the largest in most cases (Figure 6(b)). Please note that we have modified the actual CTR values with a con-stant multiplier for all cases, for privacy purposes. In 3 out of 4 cases, our weighted scheme provides significantly higher CTR values than other methods ( p &lt; . 001). Since the purely greedy approach does not look into the quality of extended audience, it usually produces audiences with a smaller click-through rate compared to the original segments.
In this paper, we presented the problem of audience exten-sion in online advertising. We provided two solutions, one purely greedy that applies a set-cover algorithm on the orig-inal audience, while the other one with different weights on similarity, novelty, and quality of the extended audience. We compared these different approaches on our real-world data set, and explained their implementation in our advertising platform at Turn. Our proposed method is computationally efficient, can flexibly adjust to different needs and shows good performance. To the best of our knowledge, this is the first paper to methodically examine the audience extension problem and possible solutions to it.

There are multiple paths of interesting future work. First, we would like to explore different formulations of the metrics that are optimized for extension, as well as different parame-ter settings on the weights of similarity, novelty, and quality metrics. Second, our current search space of extension is the logical disjunction forms of categories. It is possible to ex-tend the recommendation to other simple logical formulas, if we can design some heuristics to limit the search space. Lastly, in the future we would like to mine the common rules that advertisers utilize to define a segment and leverage such rules to help recommendations by adapting transfer learning techniques [21].
 We thank many talented scientists and engineers at Turn for their help and feedback in this work, and the anonymous reviewers for their valuable comments and suggestions. [1] http://digitalmarketing-glossary.com/what-is-[2] http://www.knowonlineadvertising.com/sharing-[3] A. Ahmed, Y. Low, M. Aly, V. Josifovski, and A. J. [4] M. Aly, A. Hatch, V. Josifovski, and V. K. Narayanan. [5] N. Archak, V. S. Mirrokni, and S. Muthukrishnan. [6] J. Chen, W. Geyer, C. Dugan, M. Muller, and I. Guy. [7] S. Chen. Cheetah: a high performance, custom data [8] Y. Chen, D. Pavlov, and J. F. Canny. Large-scale [9] N. B. Ellison et al. Social network sites: Definition, [10] H. Elmeleegy, Y. Li, Y. Qi, P. Wilmot, M. Wu, [11] J. Evans and T. Liebowitz. System and method for [12] F. Falcon. Audience measurement system, Aug. 3 [13] S. C. Geyik, A. Saxena, and A. Dasdan. Multi-touch [14] B. Gufler, N. Augsten, A. Reiser, and A. Kemper. [15] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [16] A. Joshi, A. Bagherjeiran, and A. Ratnaparkhi. User [17] Y. Kwon, M. Balazinska, B. Howe, and J. Rolia. [18] K.-C. Lee, B. Orten, A. Dasdan, and W. Li.
 [19] K. Liu and L. Tang. Large-scale behavioral targeting [20] S. Pandey, M. Aly, A. Bagherjeiran, A. Hatch, [21] C. Perlich, B. Dalessandro, T. Raeder, O. Stitelman, [22] F. Provost, B. Dalessandro, R. Hook, X. Zhang, and [23] C. Sugnet, J. Shoop, P. Sutter, and K. Feldman. [24] S. Tu and C. Lu. Topic-based user segmentation for [25] T. White. Hadoop: The Definitive Guide . O X  X eilly [26] X. Wu, J. Yan, N. Liu, S. Yan, Y. Chen, and Z. Chen. [27] J. Yan, N. Liu, G. Wang, W. Zhang, Y. Jiang, and
