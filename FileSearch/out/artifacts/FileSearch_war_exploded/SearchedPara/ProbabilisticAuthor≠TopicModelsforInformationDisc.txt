 g We prop ose a new unsup ervised learning technique for ex-tracting information from large text collections. We mo del documen ts as if they were generated by a two-stage stochas-tic pro cess. Eac h author is represen ted by a probabilit y distribution over topics, and eac h topic is represen ted as a probabilit y distribution over words for that topic. The words in a multi-author pap er are assumed to be the result of a mixture of eac h authors' topic mixture. The topic-w ord and author-topic distributions are learned from data in an unsup ervised manner using a Mark ov chain Mon te Carlo al-gorithm. We apply the metho dology to a large corpus of 160,000 abstracts and 85,000 authors from the well-kno wn CiteSeer digital library , and learn a mo del with 300 topics. We discuss in detail the interpretation of the results dis-covered by the system including speci c topic and author mo dels, ranking of authors by topic and topics by author, signi can t trends in the computer science literature between 1990 and 2002, parsing of abstracts by topics and authors and detection of unusual pap ers by speci c authors. An on-line query interface to the mo del is also discussed that allo ws interactiv e exploration of author-topic mo dels for corp ora suc h as CiteSeer.
 Categories and Sub ject Descriptors: I.2.6 [Arti cial Intelligence]: Learning General Terms: algorithms, exp erimen tation Keyw ords: unsup ervised learning, Gibbs sampling, text mo deling
With the adv ent of the Web and various specialized digi-tal libraries, the automatic extraction of useful information from text has become an increasingly imp ortan t researc h area in data mining. In this pap er we discuss a new algo-Cop yright 2004 ACM 1 X 58113 X 888 X 1/04/0008 ... $ 5.00. rithm that extracts both the topics expressed in large text documen t collections and mo dels how the authors of docu-men ts use those topics. The metho dology is illustrated using a sample of 160,000 abstracts and 80,000 authors from the well-kno wn CiteSeer digital library of computer science re-searc h pap ers (La wrence, Giles, and Bollac ker, 1999). The algorithm uses a probabilistic mo del that represen ts top-ics as probabilit y distributions over words and documen ts as being comp osed of multiple topics. A novel feature of our mo del is the inclusion of author mo dels, in whic h au-thors are mo deled as probabilit y distributions over topics. The author-topic mo dels can be used to supp ort a variet y of interactiv e and exploratory queries on the set of docu-men ts and authors, including analysis of topic trends over time, nding the authors who are most likely to write on a given topic, and nding the most unusual pap er written by a given author. Bayesian unsup ervised learning is used to t the mo del to a documen t collection.

Sup ervised learning techniques for automated categoriza-tion of documen ts into kno wn classes or topics has receiv ed considerable atten tion in recen t years (e.g., Yang, 1998). For man y documen t collections, however, neither prede ned topics nor lab eled documen ts may be available. Further-more, there is considerable motiv ation to unco ver hidden topic structure in large corp ora, particularly in rapidly chang-ing elds suc h as computer science and biology , where pre-de ned topic categories may not accurately re ect rapidly evolving con ten t.

Automatic extraction of topics from text, via unsup er-vised learning, has been addressed in prior work using a num ber of di eren t approac hes. One general approac h is to represen t the high-dimensional term vectors in a lower-dimensional space. Local regions in the lower-dimensional space can then be asso ciated with speci c topics. For ex-ample, the WEBSOM system (Lagus et al. 1999) uses non-linear dimensionalit y reduction via self-organizing maps to represen t term vectors in a two-dimensional layout. Lin-ear pro jection techniques, suc h as laten t seman tic indexing (LSI), are also widely used (Berry , Dumais, and O' Brien, 1995). For example, Deerw ester et al. (1990), while not using the term \topics" per se, state:
A somewhat di eren t approac h is to cluster the docu-men ts into groups con taining similar seman tic con ten t, using any of a variet y of well-kno wn documen t clustering tech-niques (e.g., Cutting et al., 1992; McCallum, Nigam, and Ungar, 2000; Popescul et al., 2000). Eac h cluster of docu-men ts can then be asso ciated with a laten t topic (e.g., as represen ted by the mean term vector for documen ts in the cluster). While clustering can pro vide useful broad informa-tion about topics, clusters are inheren tly limited by the fact that eac h documen t is (typically) only asso ciated with one cluster. This is often at odds with the multi-topic nature of text documen ts in man y con texts. In particular, com bina-tions of div erse topics within a single documen t are dicult to represen t. For example, this presen t pap er con tains at least two signi can tly di eren t topics: documen t mo deling and Bayesian estimation. For this reason, other represen ta-tions (suc h as those discussed below) that allo w documen ts to be comp osed of multiple topics generally pro vide better mo dels for sets of documen ts (e.g., better out of sample pre-dictions, Blei, Ng, and Jordan (2003)).

Hofmann (1999) introduced the asp ect mo del (also re-ferred to as probabilistic LSI, or pLSI) as a probabilistic alternativ e to pro jection and clustering metho ds. In pLSI, topics are mo deled as multinomial probabilit y distributions over words, and documen ts are assumed to be generated by the activ ation of multiple topics. While the pLSI mo del pro duced impressiv e results on a num ber of text documen t problems suc h as information retriev al, the parameterization of the mo del was susceptible to over tting and did not pro-vide a straigh tforw ard way to mak e inferences about new documen ts not seen in the training data. Blei, Ng, and Jordan (2003) addressed these limitations by prop osing a more general Bayesian probabilistic topic mo del called la-ten t Diric hlet allo cation (LD A). The parameters of the LD A mo del (the topic-w ord and documen t-topic distributions) are estimated using an appro ximation technique kno wn as variational EM, since standard estimation metho ds are in-tractable. Griths and Steyv ers (2004) sho wed how Gibbs sampling, a Mark ov chain Mon te Carlo technique, could be applied in this mo del, and illustrated this approac h using 11 years of abstract data from the Proceedings of the National Academy of Scienc es .

Our focus here is to extend the probabilistic topic mo d-els to include authorship information. Join t author-topic mo deling has receiv ed little or no atten tion as far as we are aware. The areas of stylometry , authorship attribution, and forensic linguistics focus on the problem of iden tify-ing what author wrote a given piece of text. For example, Mosteller and Wallace (1964) used Bayesian techniques to infer whether Hamilton or Madison was the more likely au-thor of disputed Federalist pap ers. More recen t work of a similar nature includes authorship analysis of a purp orted poem by Shak esp eare (Thisted and Efron, 1987), iden tifying authors of soft ware programs (Gra y, Sallis, and MacDonell, 1997), and the use of techniques suc h as supp ort vector ma-chines (Diederic h et al., 2003) for author iden ti cation.
These author iden ti cation metho ds emphasize the use of distinctiv e stylistic features (suc h as sen tence length) that characterize a speci c author. In con trast, the mo dels we presen t here focus on extracting the general seman tic con-ten t of a documen t, rather than the stylistic details of how it was written. For example, in our mo del we omit common \stop" words since they are generally irrelev ant to the topic of the documen t|ho wever, the distributions of stop words can be quite useful in stylometry . While \topic" information could be usefully com bined with stylistic features for author classi cation we do not pursue this idea in this particular pap er.

Graph-based and net work-based mo dels are also frequen tly used as a basis for represen tation and analysis of relations among scien ti c authors. For example, Newman (2001), Mutsc hke (2003) and Erten et al. (2003) use metho ds from bibliometrics, social net works, and graph theory to ana-lyze and visualize co-author and citation relations in the scien ti c literature. Kautz, Selman, and Shah (1997) de-velop ed the interactiv e ReferralW eb system for exploring net works of computer scien tists working in arti cial intel-ligence and information retriev al, and White and Sm yth (2003) used PageRank-st yle ranking algorithms to analyze co-author graphs. In all of this work only the net work con-nectivit y information is used|the text information from the underlying documen ts is not used in mo deling. Thus, while the grouping of authors via these net work mo dels can implic-itly pro vide indications of laten t topics, there is no explicit represen tation of the topics in terms of the text con ten t (the words) of the documen ts.

The novelty of the work describ ed in this pap er lies in the prop osal of a probabilistic mo del that represen ts both authors and topics, and the application of this mo del to a large well-kno wn documen t corpus in computer science. As we will sho w later in the pap er, the mo del pro vides a general framew ork for exploration, disco very, and query-answ ering in the con text of the relationships of author and topics for large documen t collections.

The outline of the pap er is as follo ws: in Section 2 we de-scrib e the author-topic mo del and outline how the parame-ters of the mo del (the topic-w ord distributions and author-topic distributions) can be learned from training data con-sisting of documen ts with kno wn authors. Section 3 illus-trates the application of the mo del to a large collection of abstracts from the CiteSeer system, with examples of spe-ci c topics and speci c author mo dels that are learned by the algorithm. In Section 4 we illustrate a num ber of appli-cations of the mo del, including the characterization of topic trends over time (whic h pro vides some interesting insigh ts on the direction of researc h in computer science), and the characterization of whic h pap ers are most typical and least typical for a given author. An online query interface to the system is describ ed in Section 5, allo wing users to query the mo del over the Web|an interesting feature of the mo del is the coupling of Bayesian sampling and relational database technology to answ er queries in real-time. Section 6 con-tains a brief discussion of future directions and concluding commen ts.
The author-topic mo del reduces the pro cess of writing a scien ti c documen t to a simple series of probabilistic steps. The mo del not only disco vers what topics are expressed in a documen t, but also whic h authors are asso ciated with eac h topic. To simplify the represen tation of documen ts, we use a bag of words assumption that reduces eac h documen t to a Figure 1: The graphical mo del for the author-topic mo del using plate notation. vector of coun ts, where eac h vector elemen t corresp onds to the num ber of times a term app ears in the documen t.
Eac h author is asso ciated with a multinomial distribution over topics. A documen t with multiple authors has a dis-tribution over topics that is a mixture of the distributions asso ciated with the authors. When generating a documen t, an author is chosen at random for eac h individual word in the documen t. This author picks a topic from his or her multinomial distribution over topics, and then samples a word from the multinomial distribution over words asso ci-ated with that topic. This pro cess is rep eated for all words in the documen t.
 In the mo del, the authors pro duce words from a set of T topics. When T is kept relativ ely small relativ e to the num ber of authors and vocabulary size, the author-topic mo del applies a form of dimensionalit y reduction to docu-men ts; topics are learned whic h capture the variabilit y in word choice across a large set of documen ts and authors. In our sim ulations, we use 300 topics (see Rosen-Zvi et al. (2004) for an exploration of di eren t num bers of topics).
Figure 1 illustrates the generativ e pro cess with a graph-ical mo del using plate notation. For readers not familiar with plate notation, shaded and unshaded variables indi-cate observ ed and laten t variables resp ectiv ely. An arro w indicates a conditional dep endency between variables and plates (the boxes in the gure) indicate rep eated sampling with the num ber of rep etitions given by the variable in the bottom (see Bun tine (1994) for an introduction). In the author-topic mo del, observ ed variables not only include the words w in a documen t but also the set of coauthors A d on eac h documen t d . Curren tly, the mo del does not specify the generativ e pro cess of how authors choose to collab orate. In-stead, we assume the mo del is pro vided with the authorship information on every documen t in the collection.

Eac h author (from a set of K authors) is asso ciated with a multinomial distribution over topics, represen ted by . Eac h topic is asso ciated with a multinomial distribution over words, represen ted by . The multinomial distributions and have a symmetric Diric hlet prior with hyperparame-ters and (see Rosen-Zvi et al. (2004) for details). For eac h word in the documen t, we sample an author x uni-formly from A d , then sample a topic z from the multinomial distribution asso ciated with author x and sample a word w from a multinomial topic distribution asso ciated with topic z . This sampling pro cess is rep eated N times to form documen t d .
The author-topic mo del includes two sets of unkno wn parameters|the K author-topic distributions , and the T topic distributions |as well as the laten t variables corre-sponding to the assignmen ts of individual words to topics z and authors x . The Exp ectation-Maximization (EM) algo-rithm is a standard technique for estimating parameters in mo dels with laten t variables, nding a mo de of the poste-rior distribution over parameters. However, when applied to probabilistic topic mo dels (Hofmann, 1999), this approac h is susceptible to local maxima and computationally ine-cien t (see Blei, Ng, and Jordan, 2003). We pursue an alter-nativ e parameter estimation strategy , outlined by Griths and Steyv ers (2004), using Gibbs sampling, a Mark ov chain Mon te Carlo algorithm to sample from the posterior distri-bution over parameters. Instead of estimating the mo del parameters directly , we evaluate the posterior distribution on just x and z and then use the results to infer and .
For eac h word, the topic and author assignmen t are sam-pled from: where z i = j and x i = k represen t the assignmen ts of the i th word in a documen t to topic j and author k resp ec-tively, w i = m represen ts the observ ation that the i th word is the m th word in the lexicon, and z i ; x i represen t all topic and author assignmen ts not including the i th word. Furthermore, C W T mj is the num ber of times word m is as-signed to topic j , not including the curren t instance, and C kj is the num ber of times author k is assigned to topic j , not including the curren t instance, and V is the size of the lexicon.

During parameter estimation, the algorithm only needs to keep trac k of a V T (word by topic) coun t matrix, and a K T (author by topic) coun t matrix, both of whic h can be represen ted ecien tly in sparse format. From these coun t matrices, we can easily estimate the topic-w ord distributions and author-topic distributions by: where mj is the probabilit y of using word m in topic j , and kj is the probabilit y of using topic j by author k . These values corresp ond to the predictiv e distributions over new words w and new topics z conditioned on w and z .

We start the algorithm by assigning words to random top-ics and authors (from the set of authors on the documen t). Eac h Gibbs sample then constitutes applying Equation (1) to every word tok en in the documen t collection. This sam-pling pro cess is rep eated for I iterations. In this pap er we primarily focus on results based on a single sample so that speci c topics can be iden ti ed and interpreted|in tasks in-volving prediction of words and authors one can average over topics and use multiple samples when doing so (Rosen-Zvi et al., 2004).
 Figure 2: Eigh t example topics extracted from the CiteSeer database. Eac h is illustrated with the 10 most likely words and authors with corresp onding probabilities.
 Figure 3: The four most similar topics to the top-ics in the bottom row of Figure 2, obtained from a di eren t Mark ov chain run.
Our collection of CiteSeer abstracts con tains D = 162 ; 489 abstracts with K = 85 ; 465 authors. We prepro cessed the text by remo ving all punctuation and common stop words. This led to a vocabulary size of V = 30 ; 799, and a total of 11 ; 685 ; 514 word tok ens.

There is inevitably some noise in data of this form given that man y of the elds (pap er title, author names, year, ab-stract) were extracted automatically by CiteSeer from PDF or postscript or other documen t formats. We chose the sim-ple con vention of iden tifying authors by their rst initial and second name, e.g., A Einstein, given that multiple rst ini-tials or fully spelled rst names were only available for a rela-tively small fraction of pap ers. This means of course that for some very common names (e.g., J Wang or J Smith) there will be multiple actual individuals represen ted by a single name in the mo del. This is a kno wn limitation of working with this type of data (e.g., see Newman (2001) for further discussion). There are algorithmic techniques that could be used to automatically resolv e these iden tity problems| however, in this pap er, we don't pursue these options and instead for simplicit y work with the rst-initial/last-name represen tation of individual authors.

In our sim ulations, the num ber of topics T was xed at 300 and the smo othing parameters and (Figure 1) were set at 0 : 16 and 0 : 01 resp ectiv ely. We ran 5 indep enden t Gibbs sampling chains for 2000 iterations eac h. On a 2GHz PC workstation, eac h iteration took 400 seconds, leading to a total run time on the order of sev eral days per chain.
We now discuss the author-topic and topic-w ord distribu-tions learned from the CiteSeer data. Figure 2 illustrates eigh t di eren t topics (out of 300), obtained at the 2000th iteration of a particular Gibbs sampler run.

Eac h table in Figure 2 sho ws the 10 words that are most likely to be pro duced if that topic is activ ated, and the 10 authors who are most likely to have pro duced a word if it is kno wn to have come from that topic. The words asso ciated with eac h topic are quite intuitiv e and, indeed, quite precise in the sense of con veying a seman tic summary of a particular eld of researc h. The authors asso ciated with eac h topic are also quite represen tativ e|note that the top 10 authors asso ciated with a topic by the mo del are not necessarily the most well-kno wn authors in that area, but rather are the authors who tend to pro duce the most words for that topic (in the CiteSeer abstracts).

The rst 3 topics at the top of Figure 2, topics #163, #87 and #20 sho w examples of 3 quite speci c and precise topics on string matc hing, human-computer interaction, and as-tronom y resp ectiv ely. The bottom four topics (#205, #209, #289, and #10) are examples of topics with direct relev ance to data mining|namely data mining itself, probabilistic learning, information retriev al, and database querying and indexing. The mo del includes sev eral other topics related to data mining, suc h as predictiv e mo deling and neural net-works, as well as topics that span the full range of researc h areas encompassed by documen ts in CiteSeer. The full list is available at http://www.datalab.uci.edu/author-topic . Topic #273 (top righ t Figure 2) pro vides an example of a topic that is not directly related to a speci c researc h area. A fraction of topics, perhaps 10 to 20%, are dev oted to \non-researc h-sp eci c" topics, the \glue" that mak es up our re-searc h pap ers, including general terminology for describing metho ds and exp erimen ts, funding ackno wledgmen ts and parts of addresses(whic h inadv erten tly crept in to the ab-stracts), and so forth.

We found that the topics obtained from di eren t Gibbs sampling runs were quite stable. For example, Figure 3 sho ws the 4 most similar topics to the topics in the bot-tom row of Figure 2, but from a di eren t run. There is some variabilit y in terms of ranking of speci c words and authors for eac h topic, and in the exact values of the asso ci-ated probabilities, but overall the topics matc h very closely .
Of the original 162,489 abstracts in our data set, estimated years of publication were pro vided by CiteSeer for 130 ; 545 of these abstracts. There is a steady (and well-kno wn) increase year by year in the num ber of online documen ts through the 1990's. From 1999 through 2002, however, the num ber of documen ts for whic h the year is kno wn drops o sharply| the years 2001 and 2002 in particular are under-represen ted in this set. This is due to fact that it is easier for CiteSeer to determine the date of publication of older documen ts, e.g., by using citations to these documen ts.

We used the yearly data to analyze trends in topics over time. Using the same 300 topic mo del describ ed earlier, the documen ts were partitioned by year, and for eac h year all of the words were assigned to their most likely topic using the mo del. The fraction of words assigned to eac h topic for a given year was then calculated for eac h of the 300 topics and for eac h year from 1990 to 2002.

These fractions pro vide interesting and useful indicators of relativ e topic popularit y in the researc h literature in recen t years. Figure 4 sho ws the results of plotting sev eral di eren t topics. Eac h topic is indicated in the legend by the ve most probable words in the topic. The top left plot sho ws a steady increase (roughly three-fold) in mac hine learning and data mining topics. The top righ t plot sho ws a \tale of two topics": an increase in information-retriev al coupled to an apparen t decrease in natural language pro cessing.
On the second row, on the left we see a steady decrease in two \classical" computer science topics, operating systems and programming languages. On the righ t, however, we see the rev erse beha vior, namely a corresp onding substan tial gro wth in Web-related topics.

In the third row, the left plot illustrates trends within database researc h: a decrease in the transaction and concurrency-related topic, query-related researc h holding steady over time, and a slow but steady increase in integration-related database researc h. The plot on the righ t in the third row illustrates the changing fortunes of securit y-related researc h|a decline in the early 90's but then a seemingly dramatic upward trend starting around 1995.

The lower left plot on the bottom row illustrates the some-what noisy trends of three topics that were \hot" in the 1990's: neural net works exhibits a steady decline since the early 1990's (as mac hine learning has moved on to areas suc h as supp ort vector mac hines), genetic algorithms app ears to be relativ ely stable, and wavelets may have peak ed in the 1994{98 time perio d.

Finally , as with any large data set there are alw ays some surprises in store. The nal gure on the bottom righ t sho ws two somewhat unexp ected \topics". The rst topic consists entirely of Frenc h words (in fact the mo del disco vered 3 suc h Frenc h language topics ). The apparen t peaking of Frenc h words in the mid-1990s is likely to be an artifact of how Cite-Seer prepro cesses data rather than any indication of Frenc h researc h pro ductivit y. The lower curv e corresp onds to a topic consisting of largely Greek letters, presumably from more theoretically orien ted pap ers|fans of theory may be somewhat disma yed to see that there is an apparen t steady decline in the relativ e frequency of Greek letters in abstracts since the mid-1990s!
The time-trend results above should be interpreted with some caution. As men tioned earlier, the data for 2001 and 2002 are relativ ely sparse compared to earlier years. In addi-tion, the num bers are based on a rather skewed sample (on-line documen ts obtained by the CiteSeer system for whic h years are kno wn). Furthermore, the fractions per year only indicate the relativ e num ber of words assigned to a topic by the mo del and mak e no direct assessmen t of the qualit y or imp ortance of a particular sub-area of computer science. Nonetheless, despite these caveats, the results are quite in-formativ e and indicate substan tial shifts in researc h topics within the eld of computer science.

In terms of related work, Popescul et al. (2000) investi-gated time trends in CiteSeer documen ts using a documen t clustering approac h. 31K documen ts were clustered into 15 clusters based on co-citation information while the text in-formation in the documen ts was not used. Our author-topic mo del uses the opp osite approac h. In e ect we use the text information directly to disco ver topics and do not explic-itly mo del the \author net work" (although implicitly the co-author connections are used by the mo del). A direct quan titativ e comparison is dicult, but we can say that our mo del with 300 topics app ears to pro duce much more no-ticeable and precise time-trends than the 15-cluster mo del.
In man y applications, we would like to quic kly assess the topic and author assignmen ts for new documen ts not con-tained in our subset of the CiteSeer collection. Because our Mon te Carlo algorithm requires signi can t pro cessing time for 160K documen ts, it would be computationally inecien t to rerun the algorithm for every new documen t added to the collection (ev en though from a Bayesian inference viewp oint this is the optimal approac h). Our strategy instead is to apply an ecien t Mon te Carlo algorithm that runs only on the word tok ens in the new documen t, leading quic kly to likely assignmen ts of words to authors and topics. We start by assigning words randomly to co-authors and topics. We then sample new assignmen ts of words to topics and authors by applying Equation 1 only to the word tok ens in the new documen t eac h time temp orarily updating the coun t matri-ces C W T and C AT . The resulting assignmen ts of words to authors and topics can be saved after a few iterations (10 iterations in our sim ulations).

Figure 5 sho ws an example of this type of inference. Ab-stracts from two authors, B Scholk opf and A Darwic he were com bined together into 1 \pseudo-abstract" and the docu-men t treated as if they had both written it. These two au-thors work in relativ ely di eren t but not entirely unrelated sub-areas of computer science: Scholk opf in mac hine learn-ing and Darwic he in probabilistic reasoning. The documen t is then parsed by the mo del. i.e., words are assigned to these authors. We would hop e that the author-topic mo del, condi-tioned now on these two authors, can separate the com bined abstract into its comp onen t parts.

Figure 5 sho ws the results after the mo del has classi ed eac h word according to the most likely author. Note that the mo del only sees a bag of words and is not aware of the word order that we see in the gure. For readers viewing this in color, the more red a word is the more likely it is to have been generated (according to the mo del) by Scholk opf (and blue for Darwic he). For readers viewing the gure in blac k and white, the sup erscript 1 indicates words classi ed by the mo del for Scholk opf, and sup erscript 2 for Darwic he. The results sho w that all of the signi can t con ten t words (suc h as kernel, supp ort, vector, diagnoses, directed, graph) are classi ed correctly . As we migh t exp ect most of the \er-rors" are words (suc h as \based" or \criterion") that are not speci c to either authors' area of researc h. Were we to use word order in the classi cation, and classify (for example) whole sen tences, the accuracy would increase further. As it is, the mo del correctly classi es 69% of Scholk opf 's words and 72% of Darwic he's.
In Tables 1 through 3 we used the mo del to score pap ers attributed to three well-kno wn researc hers in computer sci-ence (Christos Faloutsos, Mic hael Jordan, and Tom Mitc hell). For eac h documen t for eac h of these authors we calculate a perplexit y score. Perplexit y is widely used in language mo deling to assess the predictiv e power of a mo del. It is a measure of how surprising the words are from the mo del's persp ectiv e, loosely equiv alen t to the e ectiv e branc hing fac-tor. Formally , the perplexit y score of a new unobserv ed doc-umen t d that con tains a set of words W d and conditioned on a topic mo del for a speci c author a is: where p ( W d j a ) is the probabilit y assigned by the author topic mo del to the words W d conditioned on the single au-thor a , and jW d j is the num ber of words in the documen t. Even if the documen t was written by multiple authors we evaluate the perplexit y score relativ e to a single author in order to judge perplexit y relativ e to that individual.
Our goal here is not to evaluate the out-of-sample predic-tive power of the mo del, but to explore the range of per-plexit y scores that the mo del assigns to pap ers from speci c authors. Lower scores imply that the words w are less sur-prising to the mo del (lower bounded by zero).In particular we are interested in the abstracts that the mo del consid-ers most surprising (highest perplexit y) and least surprising (lowest perplexit y)|in eac h table we list the 2 abstracts with the highest perplexit y scores, the median perplexit y, and the 2 abstracts with the lowest perplexit y scores.
Table 1 for Christos Faloutsos sho ws that the two pap ers with the highest perplexities have signi can tly higher per-plexit y scores than the median and the two lowest perplexit y pap ers. The high perplexit y pap ers are related to \query by example" and the QBIC image database system, while the low perplexit y pap ers are on high-dimensional indexing. As far as the topic mo del for Faloutsos is concerned, the index-ing pap ers are much more typical of his work than the query by example pap ers.

Tables 2 and 3 pro vide interesting examples in that the most perplexing pap ers (from the mo del's viewp oint) for eac h author are pap ers that the author did not write at all. As men tioned earlier, by com bining all T Mitc hell's and M Jordan's together, the data set may con tain authors who are di eren t from Tom Mitc hell at CMU and Mic hael Jor-dan at Berk eley . Thus, the highest perplexit y pap er for T Mitc hell is in fact authored by a Toby Mitc hell and is on the topic of estimating radiation doses (quite di eren t from the mac hine learning work of Tom Mitc hell). Similarly , for Mic hael Jordan, the most perplexing pap er is on soft ware con guration managemen t and was written by Mic k Jordan of Sun Microsystems. In fact, of the 7 most perplexing pa-pers for M Jordan, 6 are on soft ware managemen t and the JAVA programming language, all written by Mic k Jordan. However, the 2nd most perplexing pap er was in fact co-authored by Mic hael Jordan, but in the area of mo deling of motor planning, whic h is a far less common topic compared to the mac hine learning pap ers that Jordan typically writes.
We have built a JAVA-based query interface tool that sup-ports interactiv e querying of the mo del 1 . The tool allo ws a user to query about authors, topics, documen ts, or words. For example, given a query on a particular author the tool retriev es and displa ys the most likely topics and their prob-abilities for that author, the 5 most probable words for eac h topic, and the documen t titles in the database for that au-thor. Figure 6(a) (top panel) sho ws the result of querying on Pazzani M and the resulting topic distribution (highly-rank ed topics include mac hine learning, classi cation, rule-based systems, data mining, and information retriev al).
Mouse-clic king on one of the topics (e.g., the data mining topic as sho wn in the gure) pro duces the screen displa y to the left (Figure 6(b)). The most likely words for this topic and the most likely authors given a word from this topic are then displa yed. We have found this to be a useful technique for interactiv ely exploring topics and authors, e.g., whic h authors are activ e in a particular researc h area.
Similarly , one can clic k on a particular pap er (e.g., the pap er A Learning Agent for Wir eless News Access as sho wn in the lower screenshot (Figure 6(c)) and the displa y in the panel to the righ t is then pro duced. This displa y sho ws the words in the documen ts and their coun ts, the probabilit y distribution over topics for the pap er given the word coun ts 1 A protot ype online version of the tool can be accessed at http://www.datalab.uci.edu/author-topic . (rank ed by highest probabilit y rst), and a probabilit y dis-tribution over authors, based on the prop ortion of words assigned by the mo del to eac h topic and author resp ectiv ely.
The system is implemen ted using a com bination of a re-lational database and real-time Bayesian estimation (a rela-tively rare com bination of these technologies for a real-time query-answ ering system as far as we are aware). We use a database to store and index both (a) the sparse author-topic and topic-w ord coun t matrices that are learned by our algorithm from the training data, and (b) various tables de-scribing the data suc h as documen t-w ord, documen t-author, and documen t-title tables. For a large documen t set suc h as CiteSeer (and with 300 topics) these tables can run into the hundred's of megab ytes of memory|th us, we do not load them into main memory automatically but instead issue SQL commands to retriev e the relev ant records in real-time.
For most of the queries we have implemen ted to date the queries can be answ ered by simple table lookup follo wed by appropriate normalization (if needed) of the stored coun ts to generate conditional probabilities. For example, displa y-ing the topic distribution for a speci c author is simply a matter of retrieving the appropriate record. However, when a documen t is the basis of a query (e.g., as in the lower screenshot, Figure 6(c)) we must compute in real-time the conditional distribution of the fraction of words assigned to eac h topic and author, a calculation that cannot be com-puted in closed form. This requires retrieving all the rele-vant word-topic coun ts for the words in the documen t via SQL, then executing the estimation algorithm outlined in Section 4.2 in real-time using Gibbs sampling, and displa y-ing the results to the user. The user can change adjust the burn-in time, the num ber of samples and the lag time in the sampling algorithm|t ypically we have found that as few as 10 Gibbs samples gives quite reasonable results (and tak es on the order of 1 or 2 seconds dep ending on the mac hine being used other factors).
 on a particular documen t written by the author.

We have introduced a probabilistic algorithm that can that can automatically extract information about authors, topics, and documen ts from large text corp ora. The metho d uses a generativ e probabilistic mo del that links authors to observ ed words in documen ts via laten t topics. We demon-strated that Bayesian estimation can be used to learn suc h author-topic mo dels from very large text corp ora, using Cite-Seer abstracts as a working example. The resulting CiteSeer author-topic mo del was sho wn to extract substan tial novel \hidden" information from the set of abstracts, including topic time-trends, author-topic relations, unusual pap ers for speci c authors and so forth. Other poten tial applications not discussed here include recommending poten tial review-ers for a pap er based on both the words in the pap er and the names of the authors. Even though the underlying proba-bilistic mo del is quite simple, and ignores sev eral asp ects of real-w orld documen t generation (suc h as topic correlation, author interaction, and so forth), it nonetheless pro vides a useful rst step in understanding author-topic structure in large text corp ora.
 We would like to thank Stev e Lawrence, C. Lee Giles, and Isaac Council for pro viding the CiteSeer data used in this pap er. We also thank Momo Alhazzazi, Amnon Mey ers, and Josh ua O'Madadhain for assistance in soft ware dev el-opmen t and data prepro cessing. The researc h in this pap er was supp orted in part by the National Science Foundation under Gran t IRI-9703120 via the Kno wledge Disco very and Dissemination (KD-D) program.
 Blei, D. M., Ng, A. Y., and Jordan, M. I., (2003) Laten t
Bun tine, W.L. (1994) Op erations for learning with graphi-Cutting, D., Karger, D. R., Pederson, J., and Tukey, J. Deerw ester, S. C., Dumais, S. T., Landauer, T. K., Furnas,
Diederic h, J., Kindermann, J., Leop old, E., and Paass, G.
Erten, C., Harding, P. J., Kob ouro v, S. G., Wampler, K.,
Gra y, A., Sallis, P., MacDonell, S. (1997) Soft ware foren-
Griths, T. L., and Steyv ers , M. (2004) Finding scien-
Hofmann, T. (1999) Probabilistic laten t seman tic index-Kautz, H., Selman, B., and Shah, M. (1997) Referral Web: Lagus, K, Honk ela, T., Kaski, S., and Kohonen, T. (1999)
Lawrence, S., Giles, C. L., and Bollac ker, K. (1999) Digi-
McCallum, A., Nigam, K., and Ungar, L. (2000) Ecien t Mosteller, F., and Wallace, D. (1964) Applie d Bayesian and
Mutsc hke, P. (2003) Mining net works and cen tral entities Newman, M. E. J. (2001) Scien ti c collab oration net works: Popescul, A., Flak e, G. W., Lawrence, S., Ungar, L. H., and Rosen-Zvi, M., Griths, T., Steyv ers, M., Sm yth, P. (2004)
Thisted, B., and Efron, R. (1987) Did Shak esp eare write a
White, S. and Sm yth, P. (2003) Algorithms for estimating
Yang, Y. (1999) An evaluation of statistical approac hes to
