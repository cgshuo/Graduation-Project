 Spam is highly pervasive in P2P file-sharing systems and is diffi-cult to detect automatically before actually downloading a file due to the insufficient and biased description of a file returned to a client as a query result. To alleviate this problem, we first charac-terize spam and spammers in th e P2P file-sharing environment and then describe feature-based techniques for automatically de-tecting spam in P2P query result se ts. Experimental results show that the proposed techniques successfully decrease the amount of spam by 9% in the top-200 results and by 92% in the top-20 re-sults. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Search Process Measurement, Experimentation, Security, Human Factors P2P search, spam, characterization, detection Spam is a well-known problem in P2P file-sharing systems, due to their anonymous, decentralized and dynamic nature [1][2][3][8]. A 2005 study observed that more than 50% of the matching results of popular recent songs were spam [3]. To im-prove the usability of P2P file-sharing systems, it is important to develop effective spam detection techniques. We define as spam any file that is deliberately misrepresented or represented in such a way as to circumvent established retrieval and ranking techniques. One reason spam is so prevalent in P2P file-sharing systems is most shared files are not self-describing . Shared files are often binary media files that are identified by users by their filenames. A spammer can easily rename a file to manipulate how it is retrieved and ranked. For example, the mu-sic/movie industry has been injec ting large amounts of spam into the network by naming them after real songs/movies in the battle against the illegal distribution of copyrighted materials [2][3]. Spam is harmful to P2P file-sharing systems in several ways. First, it degrades user experien ce. Second, spam may contain malware that, when executed, could destroy a computing system. Third, its transfer and discovery waste a significant amount of network and computing resources. The na X ve approach for identifying spam is to download the file and then examine its contents. If the file turns out to be spam, it can be reported on centralized databases (e.g., Bitzi [17]). The obvious problems with this appro ach are that it consumes time and computing resources and can release malware onto the client. We propose a way of identifying spam that does not require the download of candidate files. To this end, we:  X  Characterize spam  X  Characterize spammers  X  Propose techniques that use our characterizations to rank Our proposed spam detection also requires little new functionality in existing P2P file-sharing systems. Rather, it relies on captured statistics to detect spam. Our results on Gnutella trace data show that we can decrease the amount of spam by 9% in the top-200 results and by 92% in the top-20 results compared with the base case. We discuss preliminaries first. In Section 2, we present related work and contrast it to ours. In Section 3, we specify how queries are processed in P2P file-sharing systems. We describe the four types of spam we have identified in P2P file-sharing systems in Section 4. To identify the spam , we propose in Section 5 the use of query result  X  X eatures X , such as the combinations of terms found in a descriptor and demons trate how feature values are correlated with spam. In Section 6, we outline a framework for automatic spam detection and pres ent experimental results. We make concluding rema rks in Section 7. The most widely recognized form of spam is email spam, also known as junk emails, which are unsolicited, nearly identical messages sent in large quantities to numerous recipients with the purpose of commercial advertising or spreading viruses or other malware. Many popular automate d email spam detection meth-ods filter and block email spam by analyzing their content and/or syntax, storing DNS-based blacklists of known spammers X  IP addresses or constructing social networks for email addresses. For instance, [4] presents an a pproach that identifies semantic patterns in emails and then classifies them by applying a back-propagation neural network. [5 ] proposes MailRank, a social network-based approach, to rank and classify emails according to addresses from different sources and then creates a graph for the social network via email interac tions. However, global informa-tion is needed to compute a ranking score for each email address. It is not resilient to attacks from cooperating spammers who build their own social networks. In general, these techniques are not applicable to P2P spam detection because P2P query results are often hard to distinguish (their filenames are relatively short and contain all query terms) and they require global information and the tight integration of users, which is assumed to be infeasible in general P2P environments. Another well-known type of spam is Web spam  X  Web pages that are unrelated to the query that appear in search engine results. Many studies have been conduc ted on detecting Web spam. A variety of methods identify spam pages by analyzing either the content or link structure of Web pa ges [6][7][25][27]. Again, due to the dynamic and distributed na ture of P2P file-sharing systems and the fact that shared files are only represented by small, user-defined file descript ors, Web spam detec tion techniques are not applicable in the P2P scenario. The P2P spam detection technique proposed in [3] identifies shared music files as spam if the files are either non-decodable (unplayable) or their lengths are not within +10% or -10% of the official CD version. These techniques require downloading the file and only works for commercial music files whose official CD length is known. Judgments of shared music files encoded in other formats cannot be made. The general idea of using a file size, however, is similar to our feature-based spam detection. Because the file size feature has already been considered, we do not consider it in this work. [9] takes a different view of the spamming problem in P2P net-works. Instead of measuring and detecting spam files, it focuses on the relationship between spa mming degree and P2P user be-havior (e.g., awareness of spam , elapsed time between download completion and quality checking). Through a controlled study of spam crafted by various conten t and description manipulation strategies, [9] claims that user awareness is a key factor in pollu-tion dynamics  X  low awareness of most types of spam and delay on checking the quality of downloaded files result in the uninten-tional spread of spam. While this may be true, it is orthogonal to the automatic detection of spam. A spam filter was introduced to LimeWire X  X  Gnutella [10] at the end of 2005. A user can mark a search result that is not relevant to his query or appears to be a virus as junk. Over time, the filter learns from peers that mark search results as junk, and updates the more likely to be considered spam [24]. Compared with this user-controlled approach, our work does not rely on previous user judgments and takes a different a pproach on automatically detect-ing spam results. Several works rely on the experience of other peers with shared [11][12][16] build reputation systems to allow peers to rank each other, so that peers identified as malicious are less able to share files. However, the success of this mechanism is determined by the honesty level of peers. Instead of judging peers, [13] proposes that individual files be judged by users. The authenticity of a file is evaluated by having the client collect its judgments and evalu-ate them based on a credibility judgment of the client from which the judgments come. This system requires each peer maintain a vote database for the purpose of vote matching, which may not be scalable in a large system, is resource X  X ntensive, and may be un-reliable in environments where peers anonymously join the net-work for only short periods of time. In typical P2P file-sharing syst ems (e.g., Limewire X  X  Gnutella) peers collectively share a set of (binary) files by maintaining local replicas of them. Each replica is represented by a user-tuned descriptor, which includes a file name, some embedded descriptive information (e.g., ID3 data embedde d in mp3 files [19]) as well as an identifying key (e.g., a SHA-1 hash on the file X  X  bits). All replicas of the same file naturally share the same key. The query processing includes the following major steps: 1. A client issues a query and routes it to all reachable servers 2. A server compares the query to its local replicas X  descrip-3. On a match, the server returns its system identifier and the 4. The client groups individual results by key. Each group is 5. The client ranks each group in the result set by a specific 6. The client becomes a server for the file that is downloaded. We classify P2P spam to organize our approaches for their detec-tion. Each class of spam is distinct in how their creators attempt to disseminate them. These differe nces allow us to tailor the vari-ous techniques used to detect them. To classify P2P spam and design and evaluate our spam detection algorithms, we use a collection of  X  X etadata X  from 25,137,217 P2P audio files, of which 9,575,113 are unique, shared by 226,786 peers in Gnutella network. The shared data were col-lected by browsing peers X  shared folders using our IR-Wire crawl-ing tool [14] in the Spring of 2007. The information (i.e., meta-data) we recorded for each file includes the filenames, unique identifications (i.e., IP addresses) and file types. As stated in Section 1, we consider as spam any file that is altered to manipulate the P2P file-shari ng system X  X  retrieval or ranking functions. By this definition, a virus file named  X  X piderman-movie.dvi X  is spam, whereas the same file named  X  X irus.exe X  is not. Regardless, spammers find ways to place these results at the top of a user X  X  search results. Spamming is generally performed by manipulating Steps 1, 3 and 5 of the query processing specification stated in Section 3. These steps control who processes the queries, what results are returned to the client and how they are ranked in the result set. They ma-nipulate Step 1 by placing highly active peers in the network that actively participate in file sharing (e.g., see Overpeer [22]). Reputation systems discussed in S ection 2 address this problem so it is not in the scope of our work. Rather, we focus on the spam that manipulates query processi ng Steps 3 and 5, which focus on identifying spam that are in the query result sets sent to clients. Many of the classes of the P2P spam have analogs in Web spam. These analogs are similar in gene ral approach and we point them out where appropriate. In our data analyses and our experience using P2P file-sharing systems, we have identified four types of spam. 1. Files whose replicas have seman tically different descriptors. In this case, a spammer tries to disseminate widely a file by repli-cating it and creating different descriptions for each. A spammer might name a file after a currently popular song. An example of with key 26NZUBS655CC66COLKMWHUVJGUXRPVUF. This file X  X  replicas have desc riptors that contain various song christmas.mp3 X ,  X  X iche-Oops Oh My.mp3 X ,  X  X  want you tha-lia.mp3 X  and  X  X omon be my girl.mp3 X . Notice that each of these descriptors looks normal in term s of size and combination of terms. It is only when we comp are the descriptors of different replicas does it become clear that the shared file is likely spam. Type 1 spam has many analogs to Web spam, including Web  X  X ontent spam X  techniques, such as keyword stuffing [25] or Web site scraping [26]. These tec hniques add popular terms to Web sites to increase their visibility in search results. Type 1 spam is also similar to the Web link spam practice of  X  X age hijacking, X  where a well-known Web site is copied, but then redirects a user to spam content [27]. 2. Files with long descriptors th at contain semantically non-Here, a spammer creates a single file that matches a large class of queries by putting popular terms in th eir descriptors. This type of spam is different from the first ty pe, as terms in the descriptor together do not attempt to represent an existing file. 1200473A4BB17724194C5B9C271F3DC4 is  X  X erosmith,Van Halen,Quiet Riot,Kiss, Poison, Acdc, Accept, Def Leappard, Boney M, Megadeth, Metallica, Offspring, Beastie Boys, Run Dmc, Buckcherry, Salty Dog Remix.mp3. X  Type 2 spam is similar to Type 1 spam with the difference that the additional keywords used to boost the file X  X  ranking are added to a single descriptor instead of being spread out over the descrip-tors of several replicas. 3. Files with descriptors that contains no query terms. A server wishing to share a particular file may return the file re-gardless of whether it matches the user X  X  query. For instance, the result could be advertisements or a warning on the illegality of downloading of copyrighted material s, such as files with the de-scriptor,  X  X an you afford 0.09 www.BuyLegalMP3.com.mp3 X . Type 3 spam falls under the cate gory of query-independent spam because it manipulates query results independent of the query. On the Web, link spam does the sa me thing. For example, link farms X  goal is to increase the strength of association that of a Web site has with a particular term set [23]. 4. Files that are highly replicated on a single peer. We assume that normal users do not create multiple replicas of the same file on a single server and that the only reason this is done is to manipulate the  X  X roup size X  ranking technique used on most P2P file-sharing clients or to retard the query routing tech-niques used to route queries for hard-to-find content [28]. Al-though the file may be correctly described, because its replication manipulates the ranking function, it is by definition spam. For instance, in our dataset, all of the 177 replicas of the file with key 6DY2QXX3MYW75SRCWSSUG6GY3FS7N7YC are shared on a single peer. Type 4 spam is analogous to  X  X uplicate content X  Web spam, which aims to increase a site X  X  association with some content also similar to the link-farming technique used by Web spammers to increase a Web site X  X  PageRank. Among the 4 types of spam, Types 2 and 3 should be easy for any query-dependent similarity-based ranking function (e.g., Cosine similarity ranking) [20] to identify directly and rank low. Hence, they may not be widely spread in the network and would be less harmful. However, their inclus ion in query result sets does de-grade the user X  X  search experience and wastes network and com-puting resources. Types 1 and 4 spam are more difficult to detect because they ap-pear to match the query and be described with a sensible combi-nation of terms. We propose automa tic ways of detecting them in this work so as to avoid downloading files from spammers. Our approach in the automatic identification of spam files is based on identifying the features that characterize them, such as replication degree, distribution of files over hosts, descriptor lengths, size of the vocabulary used to describe a file and so forth. Ideally, once these features are identified, spam identification becomes a task of feature computation. To make this task more manageab le, we isolate our initial investi-gations to the files shared by the 50 peers in our data set who share the most files. We pick these peers because their high de-gree of sharing makes them suspicious. No casual user would share so many files  X  8,000 files on average for these peers. In total, the top 50 peers share 401,855 replicas of 149,923 unique files. The top and bottom peer s share 15,844 and 5,452 files re-spectively. To the best of our knowledge, no benchmark P2P data set cur-rently exists, esp. the lack of spam judgment, hence, for the pur-pose of spam evaluation, we manually inspected every unique file and labeled it as spam or non-sp am based on the collected file information (e.g., terms in file de scriptors) from Gnutella network as well as information retrieved by looking up the file (identified by its key) on Bitzi [17]. For instance, one file in the top 50 peer dataset with different descript ors  X  X amie kennedy -matress mack.mp3 X   X  X all busters prank calls.mp3 X  and key KVGBBGVZYJ7BFPJBFYIVPAWKNE HMPDKX is labeled as a 27-second audio advertisement of 'efreeclub.com' on Bitzi. An-other example of spam in our dataset is file with key QFX3NMHJMOGG7VF7IK5AOFST2L 3EWKCA and different filenames such as  X  X rothers boots when she made me prom-ise.wma X ,  X  X arth its easy for u to say.wma X  is rated on Bitzi as  X  X angerous/Misleading X  and one us er comment for this file is  X  X ownloaded accidentally -clearly a virus X . Among all the 149,923 unique files, 17,129 (11.4%) are labeled as spam. We investigate the correlations between several features of shared files and the peers that share them and prevalence of spam. The features include: z Replication degree of a file (numRep): We expect that ex-z Number of hosts on which a file is shared (numHost): We z Average descriptor length of a file (avgDLen): A long average z Vocabulary size of a file X  X  group descriptor (numU-z Variance of terms in replica de scriptors of a file: High vari-z Per-host replication degree of a file (repPerHost): This repre-z Average file replication degree on a peer (avgRepDegree): Table 1 shows statistics of the vari ous features in the top-50 peer dataset. (More statistics can be found in [29].) 
Table 1. Statistics of various P2P features in the top-50 peer 
P2P feature Min Max Mean Median Std dev numUniqueTerms 1 113 5.77 5 3.18 An indication of the ability of the features to identify spam is how well each can isolate spam when ranking the files shared by the top-50 peers. In Table 2, we show how many of the top 20 files with highest value of each feature are spam. At least 95% of the top 20 files ranked by numUniqueTerms, Jaccard, Cosine or rep-PerHost are spam, which suggests that they are more strongly correlated with spam files when compared with numRep, num-Host and avgDLen. 
Table 2. Percentage of spam in 20 files with highest feature We examine the effectiveness of each feature in identifying spam in more detail in the following sections. In this first experiment, we inve stigate the effectiveness of repli-cation degree (numRep) in identifying spam. In Figure 1, we compare replication degree and likelihood of being spam. Figure 1 also indicates the percentage of files that have particular replica-tion degrees. Most files have a low replication degree, with 36% having only a single replica, 20% having two replicas, and so forth. The spam-possibility line goes up and down repeatedly and seems to have no clear trend, though ther e is a decrease when file repli-cation degree increases from 5 to 25. This is evidence for the hypothesis that extremely highly replicated files are spam. However, the graph does not seem to be a very reliable indicator of spam, given its sudden spikes and valleys. This may be caused by the fact that some popular authentic files are reasonably shared among many peers. Both spam and non-spam can have high nu-mRep values. 
Figure 1. Distribution of spam relative to file replication de-In this experiment, we explore the correlation between the num-ber of hosts who share a file (numHost) and its possibility of be-ing spam. The results in Figure 2 show that 97% (145,567) of files are each found on no more than one peer. Among these files, 90,998 have more than one replica shared on the peer (i.e., num-Rep&gt;1 and numHost=1). In other words, 95% of the files with multiple replicas in the dataset each have all of their replicas shared on a single peer. This distribution may indicate that there exist potential spammers who shar e multiple instances of a same as for almost the entire numHost range, the incidence of spam is lower than 50%. While it is true that the graph monotonically files (fewer than 5 in our data set) replicated on 10 or more hosts. 
Figure 2. Distribution of spam relative to number of hosts An examination of the relations hip between average length of a replica descriptor (avgDLen) and incidence of spam is shown in Figure 3. Overall, there is no clear upward or downward pattern shown in the spam incidence gr aph with increasing avgDLen. Furthermore, for almost the entire avgDLen range, the incidence of spam is lower than 50%. Hence we conclude that the correla-tion between avgDLen and the in cidence of spam is low. The relationship between the numbe r of unique terms in a file X  X  group descriptor (numUniqueTerms) and the incidence of spam is shown in Figure 4. The incidence of spam increases with numU-niqueTerms. The graph gets noisi er towards the right due to the variance caused by the small numbe r of files whose descriptors contain many unique terms. Figure 4. Distribution of spam relative to number of unique We are also interested in how different replicas of a spam file are described. A low Jaccard distance score represents low variance in how different replicas of a f ile are described. As shown in Figure 5, the incidence of spam increases consistently with Jac-card distance. Hence, files with high Jaccard distance scores (high descriptor variance) are more likely to be spam. Notice that only files that have multiple replicas (numRep&gt;1) are considered in Figure 5 as well as Figure 6, as Jaccard and Cosine distance are not available for file with only one replica. 
Figure 5. Distribution of spam relative to average Jaccard The ability of cosine distance to identify spam is similar to that of Jaccard, as shown in Figure 6. The graph depicting the incidence of spam rises steadily as Cosine distance increases. This suggests that Cosine distance within descriptors of a file may be a good indicator of spam as well.
 Because of the similarity of approach between Jaccard and Co-sine, we compare the top-20 lists generated by these two features to check for overlap. It turns out that 12 files appear in both lists, indicating that each of the techniques identify different spam. In the dataset, we observed that, for quite a few spam files, multi-ple replicas of the spam shared on a same peer are named by ap-pending different number and/or le tter combinations to a same filename. For instance, replicas of a spam file with key 6DY2QXX3MYW75SRCWSSUG6GY3 FS7N7YC have file-names  X  X BB_3F.WAV X ,  X  X BB _41.WAV X ,  X  X BB_1E_0.WAV X  and etc. This file has the lowest Jaccard score (0.054) in the data-the dataset. So although Jaccard a nd Cosine distance are similar, they are not equal. Figure 6. Distribution of spam relative to Cosine distance We can use the average replica tion degree of a file among peers who share it as a heuristic to evaluate the spamming behavior of a peer. Similar to other features, such as numRep, per-host replica-tion degree is designed to identify attempts to manipulate group size ranking. The difference in this case is that the replication degree is normalized by the number of peers that share it, so we avoid the  X  X opular file X  problem of numRep (See Section 5.2.1). As shown in Figure 7 and Table 1, the distribution of files on various per-host file replication degrees is skewed, with a maxi-mum of 177, a mean of 2.56 and a median of 2. Keep in mind that this data is for the top-50 peers, which may not be representa-tive of normal peers in the network. Because their sharing behav-ior is so different than the average (discussed in more detail be-low), likely they are spammers. 54,713 files (36%) each have one replica per peer. 17,556 file (11%) have at least 5 replicas per peer. We treat files which per-host replication degree is equal to or greater than 5 as spam in our analysis as a conservative esti-mate of the impact of P2P spam. We therefore do not indicate in Rep=5 are considered spam.
Figure 7. Distribution of files relative to per-host file replica-Another way to measure peer  X  quality X  is average replication degree of all the files shared on a peer. In this experiment, we compute the average replication degree of the collections of each of the top-50 peers and examine the correlation between this peer feature and percentage of spam shared by the peer. In Figure 8, as expected, peers with high file replication degrees share more spam. This indicates that such peers are very likely spammers. To understand better how differen tly spammers and normal peers behave in terms of sharing multiple replicas of a same file, we created another 50-peer dataset by random selection of peers. In this random-50 peer dataset, the to tal number of files is 30,444, of which 24,932 are unique. As shown in Figure 9, by comparison, the file replication degree on the random 50 peers is much lower than that of the top 50 peers. Most of the 50 random peers share only a single copy of each file, which reinforces the stat ement that a normal peer shares only one copy of a file in general. To be exact, only 2 peers share two or more copies per file on average among the 50 random peers, whereas this number is 39 in the top 50 peer dataset. Hence, average file replication degree on a peer is a good indica-tor of a spammer. More evidence of the suspicious behavior of the spammers can be observed by analyzing the degree of commonality amongst their collections and the degree of commonality between their collec-tions and that of a random peer. We visualized this evidence via a graph of the top-50 peers and the 50 random peers shown in Fig-ure 10. Each node represents a peer and the size of a node corre-sponds to the number of files shared on the peer. Peers with file replication degree equal to 1 and greater than 1 are colored in black and white, respectively. An edge is drawn between two nodes if the two peers share at least 30 files in common. We observe that most of the white nodes cluster to form a single connected graph with a radius less than 10. Most of the black nodes, on the other hand, are isolated with no connections to oth-ers. (We excluded these nodes from the figure to simplify it.) This is strong evidence that suspected spammers cooperate with each other. However, average peers share files based on their unique interest and therefore have little linkages to randomly selected peers. Finally, the lack of edges between the black and white nodes  X  despite the white nodes X  linkages to each other  X  indicates the segregation. This is natural if the white nodes shared spam and the black nodes were normal users; a normal user may download spam, but would delete it as soon as it is iden-tified as spam. 
Figure 8. File replication degree and percentage of spam on 
Figure 9. Comparison of file replication degree on peer be-
Figure 10. Node graph for peers with various file replication To summarize, features such as number of replicas, number of hosts and average descriptor length of a file are not strongly cor-related with the possibility of spam. However, vocabulary size, variance of replica descriptors, and per-host replication degree of a file are good indicators of spam; replication degree of a peer X  X  shared content is a good indicator of spammer. In the next sec-tion, we explain how to use these features to detect spam. Our goal is to improve P2P search accuracy by automatically identifying spam in P2P query result sets without requiring a user to download any files. We take the basic query processing steps outlined in Section 3 and make modifications to them to accom-modate spam detection. Current P2P clients rank search re sults typically based on server or file quality such as available bandwidth or relative popularity of the file (i.e., group size). R ecent work demonstrates that ran-domly ranking search results is s ubstantially more reliable than these ranking functions [15]. Group size ranking is not effective on identifying spam results, as the number of copies of a spam file may exceed the number of an authentic file in result set. Our experiments on the numRep fea-ture (see Table 2 and Figure 1), which show the unreliability of replication degree in identifying spam, is more evidence of the failures of group size ranking in this regard. To identify Types 2 and 3 spam, we propose a straight-forward application of query-dependent IR-ranking techniques. Types 2 and 3 spam are characterized by several terms that are irrelevant to the user X  X  query. Group size ranking, by being query inde-pendent, does not identify such sp am. However, query-dependent ranking functions [20], such as Cosine similarity or Okapi BM25 naturally identify Types 2 and 3 spam. The modification we make to th e steps of query processing to detect Types 2 and 3 spam is replacing step 5 with the following: 5a. Groups are ranked by cosine similarity (or some other query-dependent ranking function). Types 1 and 4 spam are not detect able with query-dependent be-cause they naturally resemble the query. In this case, we make use of the features identif ied above to identify spam. Recall that Type 1 spam is ch aracterized by variance among the descriptors of its replicas. This ty pe of spam is identifiable by the following two features:  X  Vocabulary size of a group (numUniqueTerms).  X  Variance of replica descriptors of a group (Jaccard or Type 4 spam is characterized by its high replication degree per peer. This type of spam is id entified by the following feature:  X  Per-host file replication degree (repPerHost). To integrate these features into the query processing steps, we propose the following steps after Step 5a and before Step 6: 5b. Identify the top-M results as candidate results. 5c. Re-rank the top-M results by either NumUniqueTerms or Jaccard/Cosine distance. The results that are low in the order are more likely to be Type 1 spam than those higher up. 5d. Identify the top-N results, where N &lt; M as the new candi-date results. 5e. Re-rank the top-N results by their per-host file replication degree. The results that are low in the order are more likely to be Type 4 spam than those higher up. These steps isolate candidate resu lts from the first ranking and re-rank them to identify Type 1 spam in within the candidates (Steps 5b and 5c). We repeat this pro cess for Type 4 spam (Steps 5d and 5e). One of the challenges in detecting spam is that the query results will tend to look alike due to the conjunctive matching condition. For example, one of our proposed methods for detecting Type 1 spam is to identify variance among th e replicas X  descriptors. Yet, conjunctive matching only retrieves the replicas of a file with descriptors that resemble the query (and therefore resemble each other), while not retrieving replicas of the same file with very different descriptors. To solve this problem created by conjunctive matching, we pro-pose the use of  X  X robe queries, X  [30] which, given a file X  X  key, searches for its feature information relevant to spam detection from other peers in the network. A probe query contains only the key of a result file and is sent to peers who share this file in the network. A peer responding to a probe query sends back local descriptor(s) of the probed file, the total number of replicas, the numbe r of unique files shared on this peer and the identifier of the peer. By issuing a probe query for a file, we create a more complete view of how a file is shared. This information (e.g., descriptors that do not match the original query, servers who act like spam-mers) is used to identify it as spam. To integrate probing into the query processing steps described above, we insert the following step after Step 5b: 5b X . Issue probe queries for the top-M results. The information collected from the probe query issued for the candidate results will help in determining whether they are Types 1 or 4 spam. To evaluate the effectiveness of the proposed techniques, we simulate a P2P search on a client X  X  perspective using the data we crawled from Gnutella network. On these data, we issue the top 50 most popular queries for audio files that we identified from our crawled data. We use these queries as they are representative of the most users and likely targets for spam. The client issues the basic 6 steps outlined above for query proc-essing, with variations based on th e experiment. To simulate P2P query routing, without loss of ge nerality, a query is randomly sent to a given number of peers (i.e., 50 peers) who return matching results. This process repeats until the number of results returned to the client reaches a given threshold (i.e., 200 results) or a threshold number of peers have received the query (i.e., 50,000 peers). Threshold values were chosen based on the specifications of a real-world P2P file-sharing system (e.g., LimeWire X  X  Gnutel-la [10]). We manually judge the retrieved results for each of the 50 queries as spam or non-spam based on the description of spam Type 1 to 4 as introduced in Section 4.1. Performance is measured using a standard metric  X  the number of the top N ranked results that is spam, especially when N is small, as a user tends to look at only a few top-ranked results. To test the proposed probing and ranking techniques, we compare them with the two no probing (noprobe) base cases where group size (numRep) ranking and Cosine similarity (CosineQD) ranking are performed. As discussed earlier, spam Types 2 and 3 (i.e., a file containing many random noisy words in a replica descriptor) are identified by any query-dependent, content-ba sed similarity ranking such as Cosine similarity even with no probing, as terms in this type of spam X  X  descriptors are irrelevant to query. Spam Type 4 (i.e., a file highly replicated on a single peer) is detected by the proposed ranking  X  per-host file replicati on degree (repPerHost), which can be easily computed based on the st atistics (i.e., number of replicas Hence, in our experiments, we focus on examining how the pro-posed content-based file  X  X uality X  ranking functions with the assist of probing perform on the detection of Type 1 spam. Figure 11 presents the average amount of spam in the top N result sets of 35 of the 50 queries. (Fif teen queries returned no spam, so they are excluded from the performance analysis.) Compared with the two no-probing base cas es, the proposed probing-based ranking functions (Cosine, Jaccard and numUniqueTerms) are better at ranking spam low in result set, especially when the value of top N is small. For instance, compared with the base case, noprobe+numRep, probe+Cosine improves the performance by 9% over all results and by 92.5% for the top-20 results. Com-pared with the base case noprobe +CosineQD, the two numbers are 21.6% and 97.8% respectively. We also examine how numRep perfo rms in the case of probing. The results show that probe+num Rep performs the worst, which suggests that group size has trouble detecting spam results, espe-cially when such a spam file is widely spread in the network. As shown in Figure 11, the ranking function numUniqueTerms seems to perform better than Cosine and Jaccard when the value tance can only be computed for files with multiple replicas; how-ever, the number of unique terms of a file can be computed even if there is only a single replica of a file. In order to compare Cosine, Jaccard with numUniqueTerms in a fair way, we consider only multi -replica result files in ranking, and recomputed the average number of spam in top-N results. As shown in Figure 12, Cosine and Jaccard performs consistently better than numUniqueTerms in the case of multi-replica files. Probing on query results may introduce extra network cost. How-ever, we argue that, compared w ith the cost on downloading large media spam due to user X  X  unaware ness, it is worth to apply prob-ing to filter spam out in advance. Furthermore, because probe queries are only issued to the top-ranked results, the cost should not be increased dramatically. 
Figure 11. Number of spam in top-N results with various 
Figure 12. Number of spam in top-N results with various ranking functions (only multi-replica files are considered) Insufficient and biased description of a file returned to a client as a query result makes it difficult to detect spam automatically be-fore actually downloading a file. By characterizing spam in the P2P file-sharing environment, we reveal that P2P features such as vocabulary size, variance of repli ca descriptors, and per-host rep-lication degree of a file are strongly correlated with the possibility of spam; replication degree of a peer X  X  content is a good indicator of spammer. Then we propose probing technique that aggregate more descriptive information of re sult files and statistics of peers and ranking functions that use our characterizations to rank query results. The experimental results demonstrate that the proposed techniques improve the ability to detect spam by 92.5% over the top 20 results. Because our work requires little new functionality in existing P2P file-sharing systems, it can be co mbined easily with other existing techniques discussed in Section 2 (e.g., using file size, social feedback) to detect more types of P2P spam. To boost accuracy, we are currently working on ways of combin-ing features into single  X  X pam probability X  scores. We are also working on characterizing peers based on an analysis of their collections to determine if they are spammers and identifying other possible types of P2P spam. To reduce cost, we are now exploring ways of limiting the scope of the probing process. We thank Evan Estola and Jas on Soo in Information Retrieval Lab at IIT for their help on spam evaluation. [1] S. Shin, J. Jung, H. Balakris hnan. Malware Prevalence in the [2] N. Christin, A. S. Weigend and J. Chuang. Content Avail-[3] J. Liang, R. Kumar, Y. Xi a nd K. Ross. Pollution in P2P File [4] R. Hashemi, M. Bahar, K. D. Tift, and H. Nguyen. Spam [5] P. A. Chirita, J. Diederich, and W. Nejdl. MailRank: Using [6] Qingqing Gan and Torsten Suel. Improving Web Spam Clas-[7] A. Ntoulas, M. Najork, M. Manasse, D. Fetterly. Detecting [8] J. Liang, N. Naoumov, K. Ro ss. The Index Poisoning Attack [9] Uichin Lee, Min Choi, Junghoo Cho, Medy. Y. Sanadidi, [10] Limewire. www.limewire.org [11] D. Dutta, A. Goel, R. Govindan, H. Zhang, The Design of A [12] Sepandar D. Kamvar, Mario T. Schlosser, and Hector Gar-[13] Kevin Walsh, Emin Gun Sirer. Experience with an Object [14] L. T. Nguyen, W. G. Yee, D. Jia, and O. Frieder, A Tool for [15] D. Dumitriu, E. Knightly, A. Kuzmanovic, I. Stoica and W. [16] Runfang Zhou and Kai Hwang. Gossip-based Reputation [17] Bitzi website. www.Bitzi.com [18] Google Duplicate Content Web Site. [19] M. Nilsson. Id3v2 we b site. www.id3.org. [20] D. Grossman and O. Frieder. Information Retrieval: Algo-[21] Steve Webb, J. Caverlee, and C. Pu. Characterizing Web [22] J. Macguire. Hitting P2P Users Where It Hurts, In Wired, [23] Googlebombing  X  X ailure. X  Official Google Blog. Sept. 16, [24] http://wiki.limewire.or g/index.php?title=Junk_Filter [25] K. Svore, Q. Wu, C.J.C. Bu rges and A. Raman. Improving [26] http://en.wikipedia.org/wik i/Web_scraping#References [27] J. Caverlee and L. Liu. Countering Web Spam with Credibil-[28] The Gnutella protocol specification v0.6. http://rfc-[29] W. G. Yee, L. T. Nguyen, O. Frieder. A View of the Data on [30] D. Jia, W. G. Yee, L. T. Nguyen, O. Frieder. Distributed, 
