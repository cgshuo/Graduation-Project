 Online Ad Servers attempt to find best ads to serve for a given triggering user event. The performance of ads may be measured in several ways. We suggest a formulation in which the ad network tries to maximize revenue subject to relevance constraints. We describe several algorithms for ad selection and review their complexity. We tested these algorithms using Microsoft ad network from October 1 2006 to February 8 2007. Over 3 billion impressions, 8 million combinations of triggers with ads, and a number of algorithms were tested over this period. We discover curious differences between ad-servers aimed at revenue versus clickthrough rate. I.2.1 [ Artificial Intelligence ]: Applications a nd Expert Systems Algorithms, Experimentation. Ad serving, Online advertising. Online Advertising networks such as MSN [1] and Doubleclick [2] serve ads to users visiting we b pages. Ad inve ntory typically comprises millions of different ad creatives, each of which has its own unique constraints and agreements for payment. Constrained ad delivery has been discussed in details by [5]. In this paper we describe an ad serving application with fewer constraints, but focus on the core problem of serving high revenue ads, and estimating ad performance statistically. We also diverge from the literature in modifying the objective function. Typically ad serving is conceptualized as a problem of serving the ad which will generate the highest revenue [4][6]. We argue that this kind of approach has led to a proliferation of irrelevant and financia lly-orientated ads online  X  for instance, ads about  X  X ortgage X ,  X  X oans X , and  X  X  efinancing X . We show examples of this in the final section. We instead formulate the objective function as one of maximizing revenue subject to well-defined relevance constraints. This approach allows the ad server to maintain minimal standards of user experience in serving its ads. We tested these algorithms live from October 1 2006 to February 8 2007. Over 3 billion impressions, 744,642 unique ad-trigger pairs, and 6 algorithms were test ed over this period. We discover that approximate methods of es timating ad clickthrough rate are effective in production, smoothed predictions raise optimization performance although modeling perform ance is lower, and that explicit optimization methods ar e also effective but more expensive. In paper is organized in six sections. Section 2 gives an introduction to online advertising. Section 3 defines the ad serving problem in a mathmatical way. Section 4 talks about relevance prediction (CTR). Section 5 propos es a solution to the ad serving optimizer. Section 6 gives our expe rimental results, and Section 7 concludes the paper. A trigger t is any user-initiated event such as a webpage impression, typed search query, length-of-time-on-page, a user with a particular profile visiting a page, or any other behavior that may be valuable to marketers. Online advertising is powerful because triggering events are used to provide context for the display of the advertisement. Co nversion rates as high as 80% are possible for well-targeted advertisements, particularly those in query search marketing [9]. In response to a trigger, online a dvertisements are served to the user. If the user takes some action after their exposure to the ad such as clicking on the ad, or converting with the advertiser, then a payment event is generated and the publisher is paid by the advertiser. Revenue events commonly Pay per click , Pay per impression and Pay per acquisition . The trigger, advertisement, re venue event relationship can be generalized as a variable r k,t where t is the triggering event, k is the advertisement that is displayed to the user, and r is the amount the advertiser agrees to pay if a s ubsequent behavior is observed from the user. Example 1 . Say that Joe is advert ising shoes on publisher everythingathletic.com. The trigge ring event is a user viewing a page everythingathletic.com/ athleticfootwear.html. The advertisement Joe might want to show is about Nike Airmax shoes. The revenue event is a click of the user on Joe X  X  advertisement  X  if this occurs, Joe will pay a pre-arranged amount $0.10.
 The ad server has a large amount of flexibility to server ads in response to a triggering event. The ad server has to respect the advertiser X  X  pre-arranged requirements r k,t , which indicates that k may be displayed in response to t . However, the ad server will want to rank different ads in a variety of ways so as to achieve ad-network revenue and relevance goals. An ad-server function I k,t indicates whether ad k is displayed in response to trigger t . It is important that an advertisement be served back to the user that is optimal in terms of maximizing revenue for the advertiser, subj ect to reaching a threashold for clickthrough rate (CTR), for user relevance, or some other well defined metric. Definition 1: Revenue maximization subject to relevance Given a set of revenue agreements r k,t , find an ad selection for each trigger, I k,t such that when I k,t =1, ad k is displayed in response to trigger t , and no other ads are displayed. Such ad selections I k,t should be chosen so as to maximize ad-server revenue subject to rele vance constraints. where (1) is a revenue function. In this function we see three variables: c k,t is the probability of the payment event and r agreed upon revenue to be paid from the advertiser if a payment determines which of the advertis ements are shown in response to a trigger t . (2) is an ad-delivery constraint. We were able to deliver P or fewer ads per trigger, and we were able to refuse to deliver ads for certain triggers if this would have a poor result on revenue or relevance. In other applications all P ads may need to be delivered equality for these applications. We have noted that in other ad-serving contexts, constraints are considerably richer and may include constraints on size of ad, time of day, and so on. (3) is a maximum number of trigger-ad pairs that will be stored by the ad-serving system. This is a practical constraint, and can be set to infinity if the ad-server is able to service an unlimited number of trigger,ad pairs. (4) is a relevance constraint indicating that the ads delivered are meeting a minimum level of user experience. Many metrics may be used to measure relevance of advertising including revisit probability and clickthrough rate, the latter of which is reflected in the formula above. k,t is the only variable which is unknown. A method for predicting trigger-ad-paymentevent probabilities from historical data is therefore needed to so that the objective function can be maximized. The next section will describe robust and computationally efficient methods for estimating the trigger-ad probabilities. In order to maximize revenue, th e probability of the payment event c k,t must be estimated statistically. The problem with this task is the cross-product of T  X  K is extremely large and sparse. In our empirical data, out of 5 million trigger-ad possibilities, less than 2% have any data about click in response to a trigger-ad pair  X  this includes single impr essions with zero clicks. For pairs without any impressions  X  or with low and potentially statistically unreliable numbers of impressions, it is necessary to estimate probability of click using some additional information. We investigated a variety of approaches for predicting payment probability. These ar e described below. This algorithm (labeled as  X  X lobalctr X  in the figures) works by setting the probability of click given a trigger-ad pair equal to the click rate given the ad summed over all triggers. For instance, if customers tend to click after seeing an advertisement for Britney Spears music CD, the ad server would tend to assume that Britney Spears music CD advertisements will generate a click, even if the triggering page is something unrelated, eg. SCUBA diving. This algorithm does not take into account the particular context of the user. Although this may seem poor, it has certain advantages. This method (labeled  X  X istory X  in the figures) involves using empirical counts of clicks and im pressions to estimate conditional CTR for each pair. A count of clicks given ( t , k ) pair, and impressions of ( t , k ) pairs is taken, and then the two are divided to generate conditional clickthrough ra te, as shown in Equation (6). Accumulators can be used to r ecord clicks and impressions for each observed ( t , k ) pair. However, space complexity is now O( T * K ), and this may be impractical in some ad serving domains. A further disadvantage is that the sparsity leads to over-generalization when very low samples are available. For example, CTR is thus estimated at 100%. In another case, if 1 impression and 0 clicks are observed, then a CTR of 0% is estimated. The vast majority of tri gger-ad pairs likely have neither received an impression, nor generated a click. In our data, just 2% of all trigger-ad pairs had impressions data. This method (labeled  X  X moothed X  in the figures) utilizes the observed conditional clickthrough rates, but weights in an a priori estimate of the clickthrough rate of the group of ads, as formulated in (7) below. The similar approach has been described elsewhere in the literature [3][7]. t,k = In our application trigger-ads are grouped into algorithm buckets a , and each of them has a certain clickthrough rate Pr( a ). As a result, we could use the observe d conditional clickthrough rate, and weigh in the algorithm clickthrough rate. The weighting of the observed clickthrough rate increases with the number of impressions. With more impressions observed, more weighting is put onto the observed pair X  X  clickthrough rate than on the algorithm X  X  expectation for clickthrough rate. We tested both linear regression ( X  X inear X  in the figures) and decision tree ( X  X tree X  in the fi gures) for predicting clickthrough rate. The decision tree was similar to C4.5 and has been described in [8]. We used 3 months of data on trigger-ad displays and clickthroughs from October to December 2006, to predict the following month of trigger-ad clickthrough results in January 2007. All algorithms were scored on the same trigger-ad pairs. Table 1 shows Spearman X  X  correlation metric for each of the methods. This correlation statisti c ranges from about 0.2 for the globalCTR, historicalCTR, smoot hed methods, to a maximum of about 0.5 for the decision tree approach. Response Operator Curves were also created by discretizing the target clickthrough prediction into  X  X igh X  clickthrough rate cases which had clickthrough rates greater than 9% (Figure 1). ROC curve shows that the historical -conditional-ctr method generates very good performance initially, however, ultimately the method falls victim to a missing value problem. This is because many trigger-ad pairs that are not encountered in the training period, but generate clickthroughs in the futu re period. Thus, the approach shows good performance in itially as pairs which have been observed are selected, but then shows random performance as cases which were 0 in the historical period essentially predict 0 in the future period. Figure 2 shows a comparison of the algorithms across different deciles of actual clickthrough rate values. The decision tree approach out-performs the other methods. We next turn to the task of solving the objective function so as to find ad selections I k,t . In order to cope with the scale, we adopt the greedy algorithm of selecting ads with the highest value of impressions ratio that satisfies the serving constraints. This algorithm is well known for knapsack problems [10]. Because the optimization objective is clickthrough rate, this means in practice ads are ranked in a desceding way in terms of th e click-to-impression ratio and selected based on the number of s earches and predicted CTR so as to reach a global CTR threshold. The Maximum difference between optimal solution and generated solution under greedy CTR allocation is O(max IMP * CTR ) where max IMP*CTR is the maximum number of clicks per day from any trigger-advertisement. The sketch of this proof is that selecting the item with highest click-to-impression ratio necessarily is the best item to add for a given level of cost (impressions), will hold recursively until we reach a final item that is suboptimal. The final item will have the property that when we add it, there is another item wh ich could have been added, and would have perfectly filled our knapsack up to the desired number of impressions. Thus we need only find the item with largest benefit as the upper bound on the distance from optimality. Figures 4 (right) shows distance to optimal solution for different scales of solution. As more trigger-ads are added, Empirically the maximal benefi t item was 138,370 clicks. As a result, if we add the top 1,000 ads, the worst-case distance to optimality is 75 times the number of clicks generated under the greedy solution. At 50,000 pairs, number of clicks being lost due to greedy drops to just 39% of the quantity obtained under the greedy solution. Figure 3 and 4 show cumulative cl icks versus cl ickthrough rate, versus distance to optimal soluti on as more and more trigger-ads are loaded into the system. In order to examine the difference between ad-serving for revenue maximization versus ad-serving to achieve the highest clickthrough-rate, we chose to te st both optimization extremes, and report on the result here. In order to achieve clicks optimization, we set r k,t =1  X  k , t ; otherwise we used the objective function in section 3 unchanged. We tested these algorithms live from October 1 2006 to February 8 2007. Over 3 billion impressions, 744,642 unique ad-trigger pairs, and 6 algorithms were test ed over this period. We deployed the following ad-serving algorithms : We noted in Section 4 that the best clickthrough rate predicto rs (aside from decision tree and linear regression methods) were roughly history CTR, followed by global CTR, followed by smoothed CTR. The comparison of ad-serving performance using each of these predictors to inform the clickthrough rate is shown in Figure 5 (left). Historical conditional clickthrough rate ge nerated the highest global clickthrough rate, followed by smoothe d. This is consistent with the higher accuracy of the historical method. We now turn to the relationship between clickt hrough rate and revenue. Figure 5 (right) shows the rela tionship between the clickthrough rate of an ad and revenue produced by the ad. Higher clickthrough ads produce more revenue up until the 80 th percentile of the clickthrough rates. After that, revenue produced by higher-clickthrough ads actually declines. This means that there may be  X  X yper-relevant X  ads which genera te less revenue. The inverted  X  X  X  function has not to our knowledge been noted before. Table 2 shows the top trigger-ads selected for clickthrough rate maximization versus revenue ma ximization. Revenue maximizer selects a disproportionate number of financially-related terms including  X  X efinance X ,  X  X oan X ,  X  X ortgage X , and so on. This bias is not apparent in the case of c lickthrough rate maximization. We conjecture that this is why banner advertisements are often contextually unrelated to the page they are on, and are dominated by mortgate, loan, and refinancing creatives. We have presented a general framework for ad serving and have tested clickthrough-rate predicti on algorithms experimentally in the Microsoft ad network. Thes e clickthrough rate prediction algorithms were tested experimentally within an ad-serving context, and we were able to show that higher accuracy algorithms do generate more clicks when exposed to human traffic. We also experimentally tested extreme optimization solutions  X  one maximizing reve nue, and the other clickthrough rate  X  and have noted interestin g differences between the results produced. Our results suggest that the bias towards revenue-generating advertisements needs to be tempered with well-defined relevance constraints. case optimal solution / greedy solutin. rates generate only half the revenue available creatives. Rank Objective=Revenue Objective=Clickthrough rate 1 renu renu eye infection Flyingflowers flying flowers 2 whole life insurance no medical 6 mortgages bad credit mortgage bad credit Barnesandnobel barnes nobel com 7 online roulette roulette on line west elm www westelm com 8 charity cars charity car maplins electronics maplin electronics 9 wheelchair lift vans handicap lift free online ganes free online games 11 instant life insurance quotes instant life insurance quote Matlins marlins 12 2nd mortgages 2nd mortgage rate alligient airlines allegiant airlines 15 auto insurnace auto insurance premier travel inns premier travel lodge 16 www insurance companies insurance company ll bean kids llbean com 19 hp printer tech support hp printer crates barrel crate barrell 20 credit card consolodation credit card consolidation 101cds 101cd 21 buy notes buying note loeh mans plaza loehman plaza 22 equity line credits equity line credit www famousfootwear 23 nn125 home equity loans home equity http www ebay com ebay home 24 paydayadvances payday advance jcpenney cat alog j c penney catalog 25 family planing family planni ng reverse look reverse look up 26 best buy let mortgages buy let mortgage advice gr eatlakes com great lakes 27 bad credit rate bad credit rating 28 auto insurance com car insurance 29 stocks investments stock investing 30 stock trading companies stock trading company Thanks to Microsoft for making this research possible [1] What is Microsoft adCenter?(2007), Microsoft Corporate [2] Dart Motif: Ad Serving Features (2007), Doubleclick [3] Buhlmann, H. (1967), Experience rating and credibility , [4] Ad serving. (2007, February 22). In Wikipedia, The Free [5] Amiri, A. and Menon, S. (2003), Efficient scheduling of [6] Dwight, Allen, Merriman, et al. (1999), Method of delivery, [7] Hardy, M. (2007), Topics in Actuaria l Analysis: Bayes, [8] Kitts, B. (1997), Regression Trees , Technical Report, [9] Kitts, B. Laxminarayan, P., LeBlanc, B. and Meech, R. [10] Magazine, M.E., Nemh auser, N.L., and Trotter, L.E. 1975. 
