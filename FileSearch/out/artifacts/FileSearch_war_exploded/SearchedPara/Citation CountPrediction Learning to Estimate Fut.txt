 In most of the cases, scientists depend on previous literature which is relevant to their research fields for developing new ideas. How-ever, it is not wise, nor possible, to track all existed publications because the volume of literature collection grows extremely fast. Therefore, researchers generally follow, or cite merely a small pro-portion of publications which they are interested in. For such a large collection, it is rather interesting to forecast which kind of lit-erature is more likely to attract scientists X  response. In this paper, we use the citations as a measurement for the popularity among researchers and study the interesting problem of Citation Count Prediction (CCP) to examine the characteristics for popularity. Es-timation of possible popularity is of great significance and is quite challenging. We have utilized several features of fundamental char-acteristics for those papers that are highly cited and have predicted the popularity degree of each literature in the future. We have im-plemented a system which takes a series of features of a particular publication as input and produces as output the estimated citation counts of that article after a given time period. We consider several regression models to formulate the learning process and evaluate their performance based on the coefficient of determination ( R 2 ). Experimental results on a real-large data set show that the best pre-dictive model achieves a mean average predictive performance of 0.740 measured in R 2 , which significantly outperforms several al-ternative algorithms.
 H.3 [ Information Storage and Retrieval ]: Content Analysis and Indexing; I.2 [ Artificial Intelligence ]: Natural Language Process-ing X  Text analysis
It is natural to find that not all publications attract equal atten-tion to academia. We show the citation distribution (the number of papers vs. citation counts) in the log-log plot of Figure 1.(b): the interests toward literature measured by citation counts is highly skewed. Not surprisingly, the plot follows a power law distribu-tion. A power law relationship between two quantities x and y can be written as y = ax b where a and b are constants. We see that a huge number of research papers attract only a few citations, and a few research papers accumulate a large number of citations.
For the ever-growing literature collection, it is rather interesting to forecast which kind of literature is more likely to attract scien-tists X  response. In this paper, we use the citation counts as a simple measurement for the popularity among researchers and the citation count is calculated by how many times a particular publication is cited by other articles. We study the interesting problem of Citation Count Prediction (CCP) to examine the correlative characteristics for popularity.

As a pilot study on learning to forecast future citations for liter-ature, Citation Count Prediction faces with several challenges:  X  The first challenge for CCP is to explore the truly effective fea-tures important to future citation counts from several aspects such as paper content, author expertise and venue impact. We introduce a series of features which are correlative with the number of future citations of literature;  X  The second challenge for CCP is to combine all relevant fea-tures to identify the potentially interesting papers in a unified pre-dictive model, linearly or non-linearly. Given multiple features rel-evant to popularity, i.e., citation counts in this study, we utilize sev-eral regression models to estimate future citations.
 Our contributions are manifold by solving these challenges. In Section 2 we first define a series of features which correlate with citation counts. We then formulate citation count prediction as a learning problem and introduce several regression models to unify all possible features for prediction. We describe experiments and evaluations in Section 3, including performance comparisons and feature analysis. We briefly review previous works in Section 4 and draw conclusions in Section 5.
In this section, we first present several necessary definitions and a formal representation of the citation count prediction problem.
Citations. Given the literature corpus D , the citation counts ( C
T ( . ) ) of a literature article d  X  D is defined as:
Learning task: Given a set of article features,  X  X = x 1 , x 2 , . . . , x n , our goal is to learn a predictive function f to predict the citation counts of an article d after a give time period  X  t . Formally, we have
To learn the predictive model, we have investigated multiple rel-evant factors such as paper content, author expertise and venue im-pact. It is also important to find unified models which are able to consider all the features simultaneously. We introduce both aspects in the following subsections.
The h-index is useful which attempts to measure both the pro-ductivity and impact of the published work of a scientist [8]. The index is based on the set of the scientist X  X  most cited papers and the number of citations received in others X  publications. Besides, h-index has been proved to have measuring power of scientific out-put and impact of a researcher [8]. Therefore, we consider h-index as a candidate feature to predict citation counts.
We try to identify the correlation between author rank and av-erage citation count. Sometimes, the  X  X ame" of an author X  X  name ensures the amount of citations. Each author has his/her own ex-pectation of citation counts. We calculate all authors according to their average citation counts and assign each of them a unique rank position number.
According to [1], authors have inclination to cite papers they have written themselves. Intuitively, the more productive an author is, the larger chances for his/her papers to be cited. We hence as-sume the productivity of an author is relevant to the citation counts, due to the self-citation behavior analysis from previous studies.
From the author social factor studies in [1], researchers tend to cite papers from whom the author(s) have co-authored. Thus, it is natural to assume that the paper from a widely connected author has a larger probability to be cited by his/her wide variety of co-authors. A straightforward and simple measurement is to count the Number of Co-Authors (NOCA) and we assume the correlation between the number of co-authors and average citation counts.
A unique social network for academia is established from the  X  X iting -cited" relationships among literature articles. Publications carry with author authorities: a widely cited paper indicates peer acknowledgements, and hence indicates authority. We transmit pa-per authority to all its authors. We first build a graph of G a ( V, E ) , where V is the set of vertices and each vertex v i in V represents a literature paper and E denotes the citing-cited linkage. The citing-cited graph has directions. The out-degrees measure how many times a paper is cited while in-degrees indicate the references of a particular paper. When there is a citing-cited relationship be-tween two papers, we add a link into the graph. We use standard cosine similarity between two papers to weigh the linkage in the ity between v i and v j is defined by normalizing the corresponding affinity weight as follows: We use the row-normalized matrix M = M i;j j V jj V j to describe G a with entry corresponding to the transition probability, i.e., M i;j = p ( v i , v j ) . In order to make M be a stochastic matrix, the rows with all zero elements are replaced by a smoothing vector with all ele-ments set to 1 | V | . Based on the matrix M , the authority score of a paper d (denoted as Authority ( d ) ) can be deduced from those of all other papers linked with it, which can be formulated in a recur-the combination of a loss function with a regularization term (the norm of the weights). There are two main categories for support vector machines: support vector classification (SVC) and support vector regression (SVR). SVM is a learning system using a high dimensional feature space. It yields prediction functions that are expanded on a subset of support vectors.

The model produced by SVR only depends on a subset of the training data, because the cost function for building the model ig-nores any training data that is close to the model prediction. Sup-port Vector Regression is the most common application form of SVMs. An overview of the basic ideas underlying support vector machines for regression and function estimation has been given in details in [14].
We then fit a Classification and Regression Tree (CART) model [3], in which a greedy optimization process recursively partitions the feature space, resulting in a piecewise-constant function where the value in each partition is fit to the mean of the corresponding training data. Folded cross-validation [12] is used to terminate par-titioning to prevent over-fitting. Our model included 10 features summarized in the last section as predictors.
 Figure 2: An example of regression tree for citation prediction.
Figure 2 shows the regression tree for one of the folds. Con-ditions at the nodes indicate partitions of the features, where the left (right) child is followed if the condition is satisfied (violated). Leaf nodes give the function value for the corresponding partition. Thus, for example, one of the leaves indicates that papers with h-index  X  [1.756, 2.903) and Sociality (NOCA) &lt; 2.247 are predicted to have approximately 180 citation counts.

Thorough comparisons among all predictive methods and all fea-tures are examined in the experiments and evaluations.
We perform citation prediction on the real-world data set 3 , which is extracted from academic search and mining platform ArnetMiner [18]. It covers 1,558,499 papers from major Computer Science publication venues and has gathered 916,946 researchers for more than 50 years (from 1960 to 2011). The full graph of citation net-work contained in this data has 1,558,499 vertices (literature pa-pers) and 20,083,947 edges (citations).

To predict the citation counts after one year, we randomly take 10,000 papers from the literature collection from Year 2009 as the Downloaded from http://arnetminer.org/citation
The best predictive performance of 10-Year citation count pre-diction is shown in Figure 3, and the detailed results are summa-rized in Table 2 and 3. The size of the circles in Figure 3 indicates the number of points in each predicted citation counts. Most circles are gathered within in the range of [0, 50], indicating most of the papers have relatively low citations. The predicted citation counts will be overestimated for a short period of years. A possible expla-nation is that for papers with certain features (such as high author rank , high venue rank , etc.) are predicted to have high citations. To sum up, the system is not well performed in predicting short term impact but it is still of great significance because it is likely to esti-mate the long term citation counts for a paper more accurately, but the ultimate citations determine the achievements of literature.
Different predictive models have different performances on these three individual tasks in our experiments. In general, non-linear regression achieves better performance. From Table 2, we notice that kNN has the worst performance. The result is as expected be-cause kNN merely seeks the most similar neighbors and takes the neighbors X  citation counts as the predictive citations while utilizes little information from the enormous training data. LR, by linear combination of all features, and CART by non-linear regressions have comparable performances and proves the generality of our extracted features. CART performs best among these regression models in practice.

We then examine the different aspects of feature groups: paper content (feature 1-2), author expertise (feature 4-8) and venue im-pact (feature 9-10) in Table 2. Author expertise is proved to be the most influential feature group in citation count prediction, with the highest performance of R 2 =0.611 in isolation and the lowest per-formance when left out from full feature combination. It is under-standable that authors are likely to cite papers written by reputable and influential authors. Venue impact is also significant. Papers from prestigious venues are likely to be highly cited. Unexpect-edly, paper content is proved to have the least significance, with the average performance of R 2 =0.12 in isolation for CART. We assume (1) authors have biases to choose their bibliography: they sometimes merely consider author/venue reputation; (2) it seems that paper quality is represented by author/venue which create the paper. Influential authors or venues seem to overwhelm the impact of paper content itself; (3) it might also be due to the insufficient feature distilling for contents, e.g. using abstracts as approximation may not be enough for topic/diversity discovery.

We also conduct to a detailed experiment on all separate features in Table 3. We mark the most prominent performance of single features with asterisks in Table 3. The absence of Author Rank , Venue Rank and H-Index lead to unfavorable decrease.
 gated different impacts of author, venue and content features for clustering in these heterogeneous networks [16]. Through citation linkage, authors are found to affect to authors and paper contents [19, 17], and as well contents (such as topics) are influential to each other [11, 4]. We conduct to an extended examination of all these factors correlated with citation counts, with many more new features added. There do exist several prediction works for the lit-erature world based on citation features, such as co-author predic-tion [10] and citation linkage prediction by collaborative filtering [9]. Other applications include literature search/recommendation system based on features and citation behaviors [1, 7].

Unlike previous studies, we formally research into a new predic-tive task of citation count prediction and what is more, we add more relevant features into consideration.
In this paper we present a novel task of Citation Count Prediction (CCP), which predicts the future citations for publications. Given a particular paper and its corresponding features relevant with ci-tation patterns (such as paper content, author expertise and venue impact), CCP predicts its possible citation counts. We formally for-mulate CCP task as a learning problem utilizing several regression models, and evaluate the prediction performance by coefficient of determination ( R 2 ).

From our experiments, we find that authors have biases in citing references. Author expertise and venue impact are the distinguish-ing factors for the consideration of bibliography, among which, Au-thor Rank , Venue Rank make paper attractive. Content features in isolation are not predictive. In general, the prediction after a longer period can achieve the best accuracy ( R 2 =0.786 when  X  t = 10 ). Currently, we consider a particular paper itself without consider-ing any of its audience (citing papers). However, the impact of audience can also be modeled because once a paper is cited by an attractive audience, it is likely to be attractive as well. As consid-ering the audience will result in a multi-step diffusion problem and increase the complexity in measurement. In this study, we do not consider the audience X  X  characteristics when measuring the popu-larity of the cited literature, while it can be further studied in the future. The work was supported by the Natural Science Foundation of China (Grant No. 60933004 and No. 61073073), HGJ Grant No. 2011ZX01042-001-001, Chinese National Key Foundation Research (No. 60933013 and No. 61035004). Particularly, Rui Yan was sup-ported by the MediaTek fellowship. [1] S. Bethard and D. Jurafsky. Who should I cite: learning [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [3] L. Breiman. Classification and regression trees . Chapman &amp; [4] L. Dietz, S. Bickel, and T. Scheffer. Unsupervised prediction
