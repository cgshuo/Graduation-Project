 User browsing information, particularly their non-search re-lated activity, reveals important contextual information on the preferences and the intent of web users. In this paper, we expand the use of browsing information for web search rank-ing and other applications, with an emphasis on analyzing individual user sessions for creating aggregate models. In this context, we introduce ClickRank , an efficient, scalable algorithm for estimating web page and web site importance from browsing information. We lay out the theoretical foun-dation of ClickRank based on an intentional surfer model and analyze its properties. We evaluate its effectiveness for the problem of web search ranking, showing that it con-tributes significantly to retrieval performance as a novel web search feature. We demonstrate that the results produced by ClickRank for web search ranking are highly competi-tive with those produced by other approaches, yet achieved at better scalability and substantially lower computational costs. Finally, we discuss novel applications of ClickRank in providing enriched user web search experience, highlighting the usefulness of our approach for non-ranking tasks. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Theory ClickRank, aggregate user behavior, intentional surfer model, learning to rank, web search
Knowledge discovery and mining of user behavior data on the web promises major improvements in several key as-pects of web search. Usage information associated with web search, such as aggregated user activities on search engine result pages, has been a valuable source of information for learning and recognizing query intents. Studies of search  X  This work was conducted at Yahoo! Inc.
 engine query logs [36, 35, 2, 37, 1, 25] and web search click-through data [9, 20, 21, 3, 33] have demonstrated significant improvements in retrieval quality, even when the activities examined are limited to actions on search result pages only  X  a relatively small fraction of a user X  X  activity online.
By effectively incorporating information on all web user activities, search engines gain insights into user preferences and intents, and improve both retrieval performance and user experience. First, analysis of all user actions provides a more robust estimate of user perceived importance associ-ated with web pages and sites [26]. We discuss this aspect in more details later on. Second, search engines face the chal-lenge of prioritizing and adapting their computing resources under practical constraints in crawling, indexing, and query processing [4]. In this context, the relative attention a web page receives from all users provides an intuitive and user-centric optimization criterion, and is responsive to evolving user behaviors. As a large amount of web content emerges and refreshes within a shorter time interval than a typical crawling and indexing cycle of a search engine [31], discover-ing popular content and adapting crawling schedules based on the degree of usage may prove to be an effective and agile policy. Finally, another challenging area for search en-gines is access to the deep (or invisible) web  X  the fraction of the web that is dynamically generated and not directly accessible to automated crawlers [17]. Their coverage can substantially improve by leveraging large-scale user brows-ing history, which collectively reveals some of the hidden URLs, providing gateways to their content.

In this paper, we focus on using the large amount of knowl-edge gained from computational analysis of user browsing behavior by: (1) leveraging all browsing actions; and (2) de-veloping models that incorporates rich context within logical units of user activity X  X ser sessions. Our main contribution is ClickRank, a novel algorithm we propose for estimating web page and web site importance, which is based on these two key notions. ClickRank first estimates a local impor-tance value for every page or site in each user browsing ses-sion, based on the implicit preference judgments of the user in the session context. It then aggregates these local values over all sessions of interest to create a global ranking.
We evaluate this approach in three important areas of web search. Our first experiment is on the traditional task of website ranking, where we show that results from ClickRank are competitive against state-of-the-art approaches, includ-ing PageRank [32] and the recently proposed BrowseRank [26], and yet obtained at significantly lower computational costs. In the second experiment, we demonstrate the novelty and effectiveness of ClickRank in web page ranking together with several hundred state-of-the-art web search features, includ-ing those computed from page visit counts and the link struc-ture of the web graph. In this large-scale test, we formulate the task of learning the optimal ranking model as an ad-ditive regression problem using gradient boosted decision trees, and quantify the variable importance of ClickRank in direct comparison with other features. Finally, we demon-strate ClickRank in a system that mines and presents recent, popular pages to web search users as dynamic quicklinks in search result summaries.

The structure of this paper is as follows. Section 2 reviews related work. In Section 3, we present important character-istics of general web sessions, and describe in details our approach to session mining by incorporating contextual in-formation in session representation. In Section 4, we intro-duce the ClickRank algorithm, and describe how we com-bine it with existing approaches for the task of web search by learning an optimal web search ranking model. We com-prehensively evaluate ClickRank in three core web search applications in Section 5 and conclude in Section 6.
PageRank [32], HITS [23], and TrustRank [16] are rep-resentative link analysis algorithms for computing author-itative sources using the link structure of the web graph, and have been widely used in web search as measures of relative importance of web pages. The well-known PageR-ank algorithm, for instance, considers a link from a source page to another as an explicit endorsement of the destination page in perceived page quality, and uses only the static link structure of the web as input. Based on the assumption of a random surfer model and the first-order Markov process, PageRank computes the stationary probability distribution for the web link graph iteratively, resulting in the World X  X  largest matrix computation [29].

A number of problems are commonly associated with link analysis algorithms. First, user browsing behaviors are driven by intents, and they significantly deviate from the random surfer model that PageRank is based on. A recent study on real network traffic [28] demonstrated that user visita-tion patterns differs considerably from that approximated by the uniform surfing behavior model used in PageRank. Sec-ond, static modeling of the link structure favors old pages, because a new page is less likely to be linked to within a short period of time, even if it has very good quality. Third, link structures are prone to manipulation as adversarial links can be generated to artificially inflate ranking more quickly than quality links that typically originate in manual editing. Last, as the web grows at an explosive speed 1 , computing page importance at the web scale by link analysis becomes very computationally expensive [24], even through various optimization schemes [8, 27].

As a logical unit of general user web experience, a web session contains rich information on the preferences and the intent of the users within a short-to-medium time frame. It is a particularly important subject for the search and data mining communities because of its generality across all cat-egories of web activities. However, there exists very little study on general non-search browsing data. Prior literature related to sessions [39, 38, 5, 6, 12] focuses almost exclu-sively on search trails within query sessions. However, as we will present in Section 3, search-related activities account for less than 5% of overall user activity online. Analysis of web sessions in a general setting broadens the user behavior models with richer contextual information from the entire spectrum of actions, and is key to new web search appli-cations that aim to provide enriched user search experience centered around users X  interests.

A new page importance ranking algorithm called BrowseR-ank [26] has recently been proposed. BrowseRank makes two significant contributions. First, it uses the more reli-able input of user behavior data, computing a user browsing graph, rather than a web link graph. Second, BrowseRank models the random walk on the user browsing graph by a continuous-time Markov process. BrowseRank has shown better ranking performance compared with link analysis al-gorithms at the expense of higher computational costs.
Study on search trails in query sessions is the subject in a few recent works. Dramatic differences in user interaction behaviors with a search engine are reported in [39]. The idea of identifying popular end points of search trails as query-dependent feature is discussed in [38] for improving web search interaction. A recent study [5] shows improved retrieval quality using post-search browsing activities over alternative data sources that contain only the end points of search trails or clickthrough logs. Also, the study suggests that post-search browsing behavior logs provide strong sig-nal for inferring document relevance for future queries.
We define a web session as a logical unit of time-ordered user browsing activities, representing a single span of user interactions with a web browser. The concept of session in our study is generalized to all categories of web activities, while studies related to search log or search clickthrough data consider a session simply as a set of search queries and largely ignore all other activities.
A user X  X  browsing history is commonly accessible from sev-eral sources, for instance, the ISP or other gateway to the web [28] or clients installed on the user X  X  environment [39]. In this study, we use information logged by the Yahoo! Tool-bar, a browser add-on that assists users with quick access to various web tasks. The toolbar logs user activities for a subset of users who opted in for this data collection during installation. Each log entry is a tuple of { cookie , times-tamp , URL , referral URL , event attribute list } . The cookie is a unique, anonymous client identifier that expires and re-freshes after a pre-defined time period. The URL is the identifier of the page being accessed and the referral URL is the URL from which the user access the current URL. The event attribute list is composed of various metadata associ-ated with the activity. For the experiments in this paper, the browsing data consisted of over 30 billion anonymous events, across millions of unique Yahoo! users, collected over 6 months in 2008.

To segment web activities into sessions, we first use the referral URL  X  current URL structure to reconstruct the entire chain of browsing activities per user. This scheme en-sures that, for users who are multitasking (e.g., those having multiple browser windows or tabs open), we group activ-ities associated with different tasks into separate sessions rather than interleaving them together. Next, we partition the time-ordered user events using two boundary conditions. First, we start a new session from the current event if there Table 1: Key characteristics of general web sessions. is more than 30 minutes of inactivity between the current event and its immediately preceding event. Second, a new session starts if the current event entry does not have a re-ferral URL. This typically happens when the user launches a new web browser, or clicks on a link in a non-browser source ( e.g . in a text file).

Our session segmentation approach requires only one-pass scanning over the data. While this is a simple mechanism, a recent study on finding logical sessions from query logs [6] has shown that in vast majority (92%) of the cases, a session segmentation method based on timeout threshold gives iden-tical scores to an advanced and computationally expensive algorithm [6], when both are compared with human judged sessions using the objective Rand index [34]. For the small fraction of remaining sessions that are difficult for the ad-vanced algorithm, the timeout-based method gives merely marginally degraded performance of 1 . 4%.
Table 1 summarizes the key characteristics of general web session. Figure 1 shows the probability distributions of the number of events in a session and session duration, respec-tively. The number of events in a web session approximately follows a power law distribution. Its mean and standard derivation are 9 . 1 and 24 . 5, respectively, demonstrating that a web session contains significantly richer activity context and diversity than a search session, which reportedly con-sists of an average of 5 events [5]. In addition, search sessions (those containing at least one query sent to one of the ma-jor web search engines) constituted 4 . 85% of overall sessions, signaling again that focusing on them may lead to a biased view in downstream analysis [30].

The session duration graph shows two different power law behaviors across the timeout threshold of 1 , 800 seconds. On average, a web session lasts 420 . 3 seconds, with the stan-Figure 2: Probability distribution of web page oc-currence in analyzed user browsing logs. dard deviation of 1068 . 0 seconds, demonstrating its short-to-medium time range coverage of user activities.
It is important to study the sparseness of content among the 30 billion events used in our study. We discover a total of 3 . 1 billion unique URLs. To remove individual bias, we consider web pages that are clicked by more than 5 users, which include a total of 48 . 5 million web pages. Figure 2 shows the distribution of web page occurrence in analyzed user browsing logs.
Mining user sessions at the web scale is particularly im-portant for learning and recognizing user behavior patterns associated with structured intents. We employ several clus-tering approaches to discover web sessions driven by differ-ent intents and learn their statistical characteristics. Due to space constraint, we focus our discussion on one representa-tive clustering effort in this section.

In this experiment, we mapped each URL to an event cat-egory based on five high-level intents X  X earch, email, infor-mation/reference, rich content ( e.g . social networking and multimedia), and shopping. We computed the histogram representation of a session by the distribution of number of events over the intent categories. While certain temporal in-formation is discarded, we will see in next section that this histogram representation preserves adequate discriminating power for the clustering purpose, and still being compact for the large amount of data. cant features associated with each cluster are highlighted in bold.
To reliably associate a visit to each URL with an inter-pretable type, we used human categorizations of the top 1 , 200 most popular web sites to map events to intents. While coverage achieved this way was reasonable at 41% for all events, we augmented these categorizations using heuristics that map from URLs to likely intents; for exam-ple, URLs of the format shopping.*.com/* were mapped to shopping intent, and so on.

Within each session, a browsing event was labeled either as unknown, or assigned to one of these five intent cate-gories described above. We then computed the distribution of events over the six intent labels ( i.e ., including the un-known class), and discarded those sessions that contain more than 80% of unknown events, as they cannot be reliably clustered. Finally, we smoothed each normalized intent his-togram of the remaining sessions by evenly distributing the weight associated with the unknown class to all the other five bins in the histogram.

The final session histogram is a 7 dimensional feature vec-tor. The first 5 dimensions correspond to the normalized intent histogram, with their sum equal to 100. The last 2 dimensions correspond to the number of events in the session and the session duration in seconds, respectively.
To gain further insights on the spread in session histograms, we used principle component analysis (PCA) to reduce the dimensionality. PCA seeks projections onto a low-dimensional linear subspace that best preserves the data scatter in a least-squares sense [13]. The 3D view of session histogram shown in Figure 3 demonstrates the heterogeneity as the histogram data covers a broad continuum of activity space. Among the first 6 eigenvalues that are all significant, the first eigenvalue is dominant.
A meaningful interpretation to sessions is key to under-standing the context of activities on general, unconstrained user behavior data. Table 2 summarizes the unsupervised session histogram clustering results using k -means algorithm with k = 10. These clusters are ordered based on the cluster size. Significant features that give clear indication of cluster attributes in Table 2 are highlighted in bold.

Various intent-driven web browsing patterns clearly emerge from statistical properties of the clusters. The top 5 clus-ters correspond to coherent sessions of rich content browsing, search, email, shopping, and information, respectively. For instance, the center of cluster 1, with 29 . 8% of entire data, Figure 3: Visualization of session histograms in 3D by dimensionality reduction using PCA. contains 99 . 42% rich content browsing. Typically, these are interactions of users with social networking sites, such as Facebook and MySpace. Its cluster-wise standard deviation of 2 . 82% along this feature dimension is significantly smaller than the standard deviation of 45 . 69% for the entire data.
Clusters revealing more sophisticated user behaviors are also evident in Table 2. These interesting patterns include browsing web search results without a click (cluster 2), col-lecting information during shopping (cluster 6), visits to rich content web site through navigational queries (cluster 8), and prolonged activities in social networking sites (cluster 10, note the average session duration).

These observations demonstrate that even a simple ap-proach to session representation X  X s distributions over high-level classes X  X an provide the search engine with valuable in-formation, such as the distribution over the types of content that users are likely to access (useful for crawling schedul-ing as well as for ranking purposes). If we apply filter to the entire set of sessions and preserve only those containing search queries, we can further observe what queries often lead to a particular session type (e.g., a shopping session) and optimize the user experience for that.
In this section, we present a novel web search ranking al-gorithm, ClickRank, that combines different notions of user preferences mined from browsing sessions. The ClickRank algorithm provides a robust estimate of the importance of web pages and websites without explicitly constructing a web graph; its relatively low computational cost make it particularly useful for web search ranking purposes. We also describe how ClickRank can be incorporated with a large set of other ranking features for learning a ranking model.
A web session contains several contextual indicators of user preferences among the visited web pages. Intuitively, users tend to browse content that they perceive as important in the context of their informational need. This makes the dwell time on a web page an important endorsement of the user X  X  interest level in it. The click order within a general trail of user activities is also important: accessing one web page before another in the session may be interpreted as a preference signal coming from the user. ClickRank aims to combine these signals to determine a local importance value for each page within a session, and then aggregate the importance values over all sessions of interest.

We start by computing local importance values within each session. The ClickRank of a web page p i in a given web session s j is a function of several indicators within the session context X  X he dwell time on the page, the page load time, the rank of p i in the ordered set of all visited URLs, and the frequency of occurrence in the session. We define the local ClickRank function as
ClickRank ( p i , s j ) = X where w r ( i, s j ) is a weight function induced on the rank of the event i in session s j , and w t ( p, s j ) is a weight func-tion computed from the set of temporal attributes associ-ated with the browsing of page p i . I () denotes the indicator function.

We define the weight function w r () for an event i in rank r ( i ) of a session s j with a total of n j events as decreasing function w.r.t. the rank of the event within a session i . The function choice for w r () is motivated by mea-surements of implicit user preference judgements through eye tracking experiments [21], which show decreasing rela-tive attention devoted to ordered clicks in navigational and informational tasks. Note that the sum of w r ( i, s j ) over a given session s j is always equal to 1, i.e ., P n j i =1
For a set of web sessions S = ( s 1 , . . . , s k ) across users and over a period of time, we aggregate the ClickRank values as where ClickRank ( p, s ) is the local ClickRank function de-fined in (1) given an instance of observed sessions, and AGGR denotes an aggregation function, such as summation or av-eraging, over all sessions of interest. In the following exper-iments, we use summation as the aggregation function.
Finally, the ClickRank of a website w for a set of ses-sions S is simply the sum of the ClickRank values of all pages in S that are part of the site: ClickRank ( w, S ) = P p  X  w ClickRank ( p, S ). Note that using a sum implicitly models both the importance (as evidenced by ClickRank values of individual pages) and the size of the website  X  the amount of pages that it consists of.
Our formulation of ClickRank has a theoretical interpre-tation based on an intentional surfer model. A web session can be viewed as a logical sequence of hops through the hy-perlink structure of the web. At each step, a user selects what she judges as most relevant as the next click, based on a variety of features such as the attractiveness of content in the context of the use X  X  activity, her prior knowledge, and so on. The user further indicates her interest through various temporal attributes, such as the time devoted to the page or whether it was visited multiple times. This process con-tinues throughout the duration of the session, until the user starts another journey on the web.

More concretely, the local ClickRank function defines a random variable X i j :  X   X  R + 0 associated with the web page p , given an observed session s i . X i j is bounded for all prac-tical purposes, so E ( X i j ) &lt;  X  and var ( X i j ) &lt;  X  . Denote the set of random variables associated with the web page p over the entire set of observed sessions S = ( s 1 , . . . , s { X 1 j , X 2 j , . . . , X k j } , and assume they are independent and identically distributed. As k  X  X  X  , 1 k P k i =1 X i j converges to E ( X i j ) a.s. by the strong law of large numbers.
We can establish bounds on a ClickRank-induced function in a probabilistic setting by the following theorems.
Theorem 1. Let f : R  X  [0 , +  X  ) be a non-negative func-tion, then
Theorem 2. If f : R  X  [0 , +  X  ) is a non-negative func-tion taking values bounded by some number M , then
Simply put, as the volume of these web browsing sessions analyzed by ClickRank reaches a sizable sample of the entire web traffic, the rank computed by ClickRank for each page converges to its true rank according to a usage criterion.
As a query-independent feature, ClickRank can be incor-porated into a document ranking process in several ways [10]. One particular framework that has recently become promi-nent, is the learning to rank approach to information re-trieval, which aims to apply machine-learning algorithms to derive a ranking function from data. In a machine-learned ranking framework, a large variety of features are used to model a query and a document. Query features can be its length or frequency in a search log, and document features can be term statistics or, in the case of web documents, the number of incoming HTML links. Machine learned ranking provides a convenient approach for quantitatively evaluating the effectiveness of ClickRank as a novel feature on top of a large collection of existing ranking features.

We learn the ranking model using the functional regression framework of gradient boosting [14], which expresses the solution to the ranking function as additive expansion of M parameterized functions where f 0 ( x ) is an initial guess, and [ f m ( x )] M 1 functions (or  X  X oosts X ). In Equation(4), each incremental function f m ( x ) can be further factored as the product of a base learner h ( x ; a m ) and corresponding coefficient  X 
The idea of gradient boosting is to sequentially fit a pa-rameterized function to current residuals by least-squares criterion at each iteration and where N is the number of training samples. The optimal coefficient  X  m is computed by line search
We use decision tree as the base learner h ( x ; a m ) in (4), where it is parameterized by the splitting variables and cor-responding split points. At each iteration m , a decision tree partitions the entire feature space into disjoint regions [ R lm ] L l =1 and predicts based on the region that contains the observed feature vector x as
Gradient boosted decision trees (GDBT) produce compet-itive, highly robust, interpretable procedures in regression and classification [14], and are particularly useful for set-tings with large amounts of data and a dense feature space.
ClickRank has a number of advantages over approaches that estimate the web page authority from explicit graph formulations, such as PageRank and BrowseRank. First, ClickRank is data driven, and does not embed assumptions on the traversing scheme over the web. Second, it is signifi-cantly more computationally efficient: local ClickRank val-ues are inexpensive to calculate and can be derived indepen-dently for each session. This makes ClickRank well-suited to distributed computation (e.g., the MapReduce computation paradigm [11] that was used for the experiments in this pa-per), as well as memory friendly. Furthermore, addition of new data requires only incremental computation of new lo-cal ClickRank values on the newly logged web sessions, and combining with those from existing sessions, rather than re-computation of the entire model (such as would be needed by PageRank and BrowseRank). This is particularly important for the processing of web-scale user browsing information, which is constantly changing.
We demonstrate the effectiveness of ClickRank algorithm in three core aspects of web search X  X ite ranking, page rank-Table 3: Top-ranked sites with different algorithms ing, and mining new, popular web pages. In our experi-ments, we assume that the dwell time on a page and the page load time are two independent random processes and define the temporal weight function in (1) as where t d and t l are the normalized dwell time on the page and page load time w.r.t. the entire session. t ( p ) is the timestamp of the event, and T denotes the time range.
In the following experiments, we used the same 6 months of aggregate user browsing logs collected from the Yahoo! toolbar. In total, the data contains more than 3 . 3 billion web sessions. These sessions contain 16 . 3 million unique websites, and 3 . 1 billion unique web pages.
We computed the ClickRank for each website and ordered them by this value. We list the top-ranking 20 sites com-puted with ClickRank, and compare them to those com-puted by PageRank 2 and BrowseRank 3 . Results are listed in Table 3, following the same convention used in [26].
On the task of site ranking, our results confirm the same finding reported in [26] that link analysis algorithms like PageRank have a strong bias towards sites with higher de-gree of inlinks and do not necessarily reflect the degree of actual usage. This is a fundamental limitation of the web link graph, from which PageRank and other link-based au-thority estimation algorithms are derived.
 The computed site ranked lists by both ClickRank and BrowseRank algorithms are surprisingly similar, with a to-tal of 18 overlapping entries among the top 20 sites. Both ranked lists correlates better with web users X  informational need compared to PageRank, as they are both computed over user behavior data. Some ranking differences between BrowseRank and ClickRank in this table can be attributed to their data source. BrowseRank is computed over a set Figure 4: Distribution of discretized ClickRank score over a large collection of judged documents. of users who installed the Live toolbar, and are presumably users of live.com and msn.com services; similarly, ClickRank is computed over a set of Yahoo! users.
 One key difference between the results produced by Click-Rank and BrowseRank is that ClickRank consistently ranks the starting point of user X  X  web experience higher. One of the major search engines, ask.com , does not even appear among top 20 sites produced by BrowseRank.

ClickRank has a significantly lower computational cost than PageRank or BrowseRank. ClickRank requires only one pass through the data, and does not require building in-termediate graphs and solving stationary probability distri-butions. This also allows for rapid adaptation of ClickRank values to new content: as noted earlier, new browsing infor-mation that is collected does not require recomputation over entire data. The overall running time of our implementation of ClickRank algorithm in ranking of the 16 . 3 million web-sites in this section and 3 . 1 billion web pages for the page ranking test in the next section are 56 minutes and 1 hour 32 minutes, respectively, using the map-reduce framework on 300 Hadoop nodes. To our best knowledge, these are the best published run times for page importance ranking on a web scale.

In a realistic, production-grade search engine environment, it is important to minimize the footprint of every relevance feature used by the ranking model so that latency and mem-ory requirements are met. Often, float numeric values are compressed or discretized into a small dynamic range that can be represented with as few bits as possible. To this end, and to evaluate the ranking performance of ClickRank as deployed in a production system, we quantize the computed ClickRank score for each web page into an unsigned byte within the range of [0 , . . . , 255]. The distribution of these values are shown in Figure 4.
We comprehensively evaluated the page ranking perfor-mance of ClickRank in conjunction with several hundred additional features used in commercial search engines. To gain further insights, we quantified the search improvement from ClickRank with a state-of-the-art baseline system, and measured its relative variable significance against this large pool of ranking features. This evaluation scheme gives more realistic, quantitative results in contrast to common pub-lished evaluations using limited feature set as baselines. For instance, [26] employs the single feature of BM25 [22] as the relevance baseline in their evaluation.

We used discounted cumulative gain (DCG) and normal-ized discounted cumulative gain (NDCG), two widely used search engine relevance measures [18, 19], to quantitatively evaluate ranking performances. Given a query and a ranked list of returned documents in response to the query, the DCG ( K ) score for the query is computed as where g k is the weight for the document at rank k . A five-grade score is assigned to each document based on its degree of relevance.

We trained ranking models using gradient boosted deci-sion trees on the baseline system with all existing features, and on the alternative system that includes one additional ClickRank feature. Training and test data is partitioned through cross-validation. We used identical parameter set-tings in all the following comparison experiments.
To quantify the relative importance S i of each individual input ranking feature x i , we used the following measure of variable importance for decision trees [7] where v t is the splitting variable at the non-terminal node n , y l , y r are the means of the regression responses in the left and right subtrees respectively, and w l , w r are the cor-responding sums of the weights.
In this experiment, we used a set of randomly sampled 9 , 041 queries from a search log. For each query, 5 X 20 web pages have been independently judged by a panel of editors and assigned with one of the five relevance scores.
The usage of ClickRank as an additional relevance feature brings 1 . 02%, 0 . 97%, 1 . 11%, and 1 . 331% web search im-provements in DCG (1), DCG (5), DCG (10), and N DCG , respectively, on top of a state-of-the-art ranking model X  a model already incorporating hundreds of features derived from content ( e.g ., anchor, title, body, and section), from the link structure of the web, from search engine query logs, and from other sources. The reported gains are strongly statistically significant.

The gains in retrieval performance from ClickRank on top of a competitive search engine are summarized in Table 4. These improvements are very substantial in the context of commercial web search: our strong baseline incorporates a feature set of several hundred signals tuned over a long pe-riod of time. In addition, 81 . 2% out of over 9 , 000 queries are affected in the alternative experiment, demonstrating the generality of ClickRank. Furthermore, we observe higher improvements on long queries in Table 4, which are typically much more challenging for search engines. We show search improvements across different query lengths in Figure 5.
We experimented with several variants of ClickRank, and observed that it consistently ranks among the top features in variable significance as calculated by (11). For exam-ple, in the experiment shown in Figure 5 and Table 4, the ClickRank feature is ranked 25th in variable importance among several hundred other features, significantly higher than the highest-ranking feature derived from page visit counts (ranked 56th) and a feature based on a propaga-tion of authority through the link graph (ranked 108th). Figure 5: Search improvements from ClickRank for different query lengths.
 These results demonstrate the significance of session-based web importance estimation and show that ClickRank cap-tures novel user preference knowledge not identified through other modeling techniques.
Many web search engines supply a set of  X  X uicklinks X   X  direct access links to certain pages within the site, in addi-tion to the search result itself. For example, while the top result for the navigational query  X  X bay X  is www.ebay.com, it also contains quick access links to popular destination within ebay.com, such as X  X otors X (links to motors.ebay.com), X  X alf Books X  (links to half.ebay.com), and so on. Typically, these quicklinks are pointers to frequently visited destinations within the host mined from query or clickthrough logs. This method, however, has two major limitations. First, query logs do not contain user activities beyond the scope of interactions with search engines, which account for the vast majority (more than 95%, as we showed earlier) of real web traffic. Second, results computed from query logs have a strong bias towards old, navigational links within the site since they receive more clicks within the visibility range of search engines.
We demonstrate a novel application of ClickRank for dis-covering and displaying dynamic quicklinks in web search results through recency ranking. The idea is to adapt the time range for the indictor function in Equation (9) w.r.t. the content refresh rate found by web crawlers. In addition to normal search results, the system displays highly ranked web pages computed by ClickRank as quicklinks to the user.
Figure 6 shows search results with discovered quicklinks by the system in response to the query of  X  X eijing olympic 2008 X  on two days during summer Olympic Games 2008, us-ing the time range of 24 hours. Quicklinks mined by Click-Rank are displayed side by side with the most frequently Figure 6: Dynamic quicklinks discovered using ClickRank by recency ranking. clicked navigational links. The quicklinks effectively capture the event highlights, while the most frequently clicked nav-igational links remain unchanged. The quicklink results by ClickRank are more meaningful in suggesting content that are of potential interest to web users, than those that reflect the structural property of the website.
In this paper, we explored the direction of mining gen-eral user browsing information for discovering session models driven by structured user intents, and proposed user pref-erence models that incorporate rich session context for web search ranking. We presented characteristics of general web browsing sessions and revealed interesting user behavior pat-terns mined from sessions. We introduced ClickRank , an ef-ficient, scalable algorithm for estimating web page and web-site importance based on user preference judgments mined from session context. ClickRank is based on a data-driven intentional surfer model, and is empirically shown to be an effective and novel ranking feature even on top of a highly competitive baseline system employing hundreds of ranking features. We also discussed the advantages of ClickRank over existing importance ranking approaches. ClickRank is effective and efficient to compute, delivering highly corre-lated ranking results compared to the state-of-the-art ap-proach that utilize browsing data. We also demonstrated a promising application that mines dynamic quicklinks for enhancing web user experience.

These promising results, together with earlier findings from user browsing data in web search trails, highlight the great potential of data-driven user behavior modeling at the web scale. As the amount of web traffic continues to grow ex-ponentially, we expect that explicit information about user behavior online will play an increasingly prominent role in web search and in the modeling of user intents. We thank Benoit Dumoulin and other members of the Query Intent Modeling Team in Yahoo! Search and Ya-hoo! Research Barcelona for useful discussions. The authors would also like to thank Emre Velipasaoglu, Scott Farrar, Jerry Ye, and the Yahoo! grid team for their support.
