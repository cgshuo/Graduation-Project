 Recently there has been a lot of interest in graph-based analysis. One of the most important aspects of graph-based analysis is to measure similarity between nodes in a graph. SimRank is a sim-ple and influential measure of this kind, based on a solid graph theoretical model. However, existing methods on SimRank com-putation suffer from two limitations: 1) the computing cost can be very high in practice; and 2) they can only be applied on static graphs. In this paper, we exploit the inherent parallelism and high memory bandwidth of graphics processing units (GPU) to accel-erate the computation of SimRank on large graphs. Furthermore, based on the observation that SimRank is essentially a first-order Markov Chain, we propose to utilize the iterative aggregation tech-niques for uncoupling Markov chains to compute SimRank scores in parallel for large graphs. The iterative aggregation method can be applied on dynamic graphs. Moreover, it can handle not only the link-updating problem but also the node-updating problem. Ex-tensive experiments on synthetic and real data sets verify that the proposed methods are efficient and effective.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms GPU, Parallel, SimRank, Graph, Iterative Aggregation  X 
The work was supported by China National 863 grant 2008AA01Z120, MOE New Century Talent Support Plan, MingDe Young Scholar Support Plan of Renmin University of China, and Research Brand Plan of Renmin University of China.  X  Corresponding Author: licuiping@ruc.edu.cn
Recently there has been a lot of interest in graph-based analysis, with examples including social network analysis, recommendation systems, document classification and clustering, and so on. A graph is an abstraction that naturally captures data objects as well as re-lationships among those objects. Objects are represented as nodes and relationships are represented as edges in the graph.
One of the most important aspects of graph-based analysis is to measure similarity between nodes in a graph. There are many sit-uations in which it would be useful to answer questions such as  X  X hich other nodes in the graph are most similar to this one? X . For this purpose, a great number of similarity measures[11], [17], [19], [7] and [22] have been proposed.
 Among them, SimRank is an influential and simple one [17]. It is based on a clear human intuition ( X  X wo objects are similar if they are referenced by similar objects X  [17]) and a solid theoreti-cal  X  X andom surfer-pairs X  model. In contrast with other link-based similarity measures, SimRank does not suffer from any field re-strictions and can be applied to any domain with object-to-object relationships. Furthermore, SimRank takes into account not only direct connections among nodes but also indirect connections.
Unfortunately, existing work on SimRank computation suffers from the following two limitations: 1. The computing cost can be very high in practice. In [26], 2. Existing iterative methods can only be applied on static graphs.
In this paper, we exploit the inherent parallelism and high mem-ory bandwidth of graphics processing units (GPU) to accelerate the computation of SimRank on large graphs. GPU is an integral com-ponent in commodity machine, which was firstly designed to be a co-processor to the CPU for graphic applications such as visualiza-tion and so forth. Recently, the GPU has been used as a hardware accelerator for various non-graphics applications, called generous purpose computation, such as scientific computation, matrix multi-plication, databases and so on.

To address the second limitation, we propose to utilize the itera-tive aggregation techniques for uncoupling Markov chains [21] to compute SimRank scores in parallel for large graphs. Our key ob-servation is that the iterative computation formula of SimRank can be transformed into a homogeneous first-order Markov chain by doing some mathematical operations. Based on this, we develop a family of novel iterative aggregation based SimRank computation algorithms for static and dynamic graphs, and give formal proofs, complexity analysis, and experimental results, showing our meth-ods are provably efficient and effective. Specifically, this paper has made the following contributions.
The rest of this paper is organized as follows. Section 2 gives the background information of our study. Section 3 introduces our parallel SimRank computation framework, and the iterative ag-gregation based SimRank computation techniques for static graph. Section 4 gives the iterative aggregation based incremental update algorithm for dynamic graph. Section 5 presents the implement details of our GPU-based SimRank computation. A performance analysis of our methods is presented in Section 6. We discuss re-lated work in Section 7 and conclude the study in Section 8.
In this section, we provide the necessary background for the sub-sequent discussions. We first present some notations and assump-tions that are adopted in this paper in Section 2.1, and then give a brief review of SimRank in Section 2.2. Table 1 lists the main symbols we use throughout the paper.
Without loss of generality, given a graph G = ( V , E ) where nodes in V represent objects of the domain and edges in E rep-resent relationships between objects. For a node v in a graph, I ( v ) and O ( v ) denote the set of in-neighbors and out-neighbors of v , respectively. In this section, we will give a brief review of SimRank. Let S ( a, b )  X  [0 , 1] denote the similarity between two objects a and b , the iterative similarity computation equation of SimRank is as follows:
S ( a, b ) = where c is the decay factor for SimRank (a constant between 0 Individual member of I ( a ) or I ( b ) is referred to as I object is considered maximally similar to itself, i.e., S ( a, a ) = 1. For preventing division by zero in the general formula (1) in case of I ( a ) or I ( b ) being an empty set, S ( a, b ) is specially defined as zero for I ( a ) =  X  or I ( b ) =  X  .

Let S denote the whole similarity matrix of G , and W denote the column-normalized adjacency matrix of G , Equation (1) can be written as the following matrix form: where I is an identity matrix, and S 0 = I .
Equation (2) shows that SimRank scores are propagated through the graph in multiple iterations until convergence. As discussed earlier, this computation framework is very expensive in most real applications. In this section, we introduce a new SimRank compu-tation framework which utilizes the intensive parallel computation power of GPU to speed up SimRank computation on large graphs.
In contrast with the main memory, GPU memory is relatively small; it is hard to hold the whole adjacency matrix W . A natural way to compute SimRank in parallel based on GPU is to partition W into blocks and compute the SimRank scores block by block.
Let V 1 , V 2 , . . . , V m be groups of nodes in G , where V are mutually disjoint and group V i has g nodes (zeros are filled for the case that the last group does not have g nodes). W is partitioned into: where W ij denotes the ( i, j ) -th block of W . Moreover, the i -th row of blocks in W is denoted by W i  X  , while the j -th column of blocks is denoted by W  X  j .

Correspondingly, the similarity matrix S are partitioned in the same way. According to Equation (2), the similarity block S be computed by in which, I ij is an identity matrix if i = j , otherwise, it is a zero matrix. Since SimRank scores are symmetric, we have S ij = S
Algorithm 1 outlines the pseudo-code of the Naive SimRank computation algorithm based on GPU for the ( i, j ) -th block in the k -th iterative step.
 Algorithm 1 GPU SimRank Block Computation (GPUSRB)
The procedure GPUsmm() in Line 04 is a sparse matrix manipu-lation algorithm in which GPU performs as a co-processor of CPU to accelerate the processing of matrix computing. GPUsmm() plays an essential role in algorithm 1. It can finish the computation of the following kind of equation efficiently by exploiting the high parallel computation power of GPU. We will discuss the implement details of GPUsmm() in Sec-tion 5.
Algorithm 1 provides a natural parallel way for SimRank compu-tation. One drawback of Algorithm 1 is, it will iterate many times and at each iterative step, the SimRank scores for each block S need to be computed. The computation will take very long time to complete especially when the size of graph is large. This de-lay is unacceptable in most real environments, as it severely limits productivity. The usual requirement for the computation time is a few seconds or a few minutes at the most. There are many ways to achieve such performance goals. A commonly used technique is to do some approximation to improve the efficiency while almost preserve the accuracy. Our key observation is that by doing some mathematical operations, the SimRank formula can be transformed into a homogeneous first-order Markov chain. This opens the door for us to utilize the iterative aggregation techniques for uncoupling Markov chains [21] to compute SimRank scores in parallel for large graphs.
In [25], by utilizing the Kronecker product (  X  ) and the vector-ization operator ( vec ), we re-write the SimRank formula into the following form: vec ( S k ) T = c ( vec ( S k  X  1 ) T )( W  X  W ) + (1  X  c ) vec ( I )
Let  X  = vec ( S ) , P = c ( W  X  W ) ,  X  = (1  X  c ) vec ( I ) , Equation (6) thus takes the form:  X  T =  X  T P +  X  T , which fits the first-order Markov Chain Equation.  X  is the stationary distribution and P is the transition probability matrix. If G has n nodes, the size of  X  is n , and that of P is n 2  X  n 2 .
Iterative aggregation (IA) is an algorithm for solving nearly un-coupled Markov chains. First proposed in [35], the iterative ag-gregation has been widely used on applications based on Markov chains. Assume  X  T = (  X  1 ,  X  2 , . . . ,  X  q ) is the stationary distribu-tion vector for an q -state homogeneous irreducible Markov chain with transition probability matrix Q q  X  q , and  X  T = (  X  is the stationary distribution vector for the updated transition prob-ability matrix P p  X  p . The basic idea of the iterative aggregation updating is to use the previously known distribution  X  T and the updated transition probabilities matrix P to build an aggregated ma-trix A that is smaller in size than P . The stationary distribution  X  of A is used to generate an estimate of the true updated distribution  X 
In our setting, at each iterative step, the previously computed similarity vector vec ( S k  X  1 ) can be looked as the original station-ary distribution vector  X  , the new similarity vector vec ( S looked as the new stationary distribution vector  X  . Each time when vec ( S k ij ) is computed for the ( i, j ) -th block, nodes in S considered as the changed states, and all other nodes can be looked as not changed. For the static graph case, P = Q = c ( W  X  W ) . Under this case, the updating problem is to compute vec ( S by using the components in vec ( S k  X  1 ) . We will outline the whole process below.

Step 1: partition the states of the updated chain into G  X  where G contains the states that are affected by the updates, and contains all other states. In our setting, G corresponds to the states for vec ( S k ij ) , and it has g 2 states. Reorder and partition vec ( S according to G  X   X  G .

Step 2: Reorder and partition the updated transition matrix P = c ( W  X  W ) into  X  P according to G and G : where  X  P 12 is the row of blocks W j  X   X  W i  X  with W jj moved,  X  P 21 is the column of blocks W  X  j  X  W  X  i with W removed, and  X  P 22 is the sub-matrix of  X  P with the row W and the column W  X  j  X  W  X  i removed.

Step 3: lump the states in  X  G into one superstate to create a smaller approximate aggregated matrix given by in which s are components from vec ( S k  X  1 ) that correspond to the states in  X  G , i.e., s is vec ( S k  X  1 ) with vec ( S k  X  1 this step,  X  P is compressed into a ( g 2 + 1)  X  ( g 2 + 1) aggregated matrix A .

Step 4: the stationary distribution  X  T = (  X  1 ,  X  2 , . . . ,  X  for A can be computed by using the iterative Equation (6). That is: where (  X  0 ) T = ( vec ( I ij ) T , 1) . Please notice that to execute Equa-tion (9), we need start a new nested iterative process (local itera-tion), thus l is used here, not k .

Let vec ( S k )  X  vec (  X  S ) =  X  , Equation (9) can be further ex-panded as:
Then, by Equation (8), we have, vec (  X  S l ij ) T = c ( vec (  X  S l  X  1 ij ) T ( W jj  X  W
Recall that  X  P 21 is the column of blocks W  X  j  X  W  X  i W ii removed, and s is vec ( S k  X  1 ) with vec ( S k  X  1 ij have:
When l is sufficiently large, vec (  X  S l ij ) T should approach its ex-act vector vec ( S k ij ) T , which can be obtained by applying the vec operation to Equation (4):
Compared Equation (11) with Equation (10), we can find the only difference between them is the factor  X  l g 2 +1 . Thus, we can reasonably draw the conclusion that lim simply set  X  g 2 +1 = 1 to avoid computing it during the iteration.
Now, Equation (10) is reduced to:
By reducing the vec opeartor, we have,
To distinguish the results from iterative aggregation based method and naive iterative method, we use  X  S k in iterative aggregation method instead of S k . Furthermore, we let
Finally, we have Notice that, the first part of Equation (13) can be computed by GPUsmm() iteratively, while the second part H ij needs to be com-puted only once. Equation (12) is similar with Equation (4). So it can be computed by GPUSRB (Algorithm 1) with few modifica-tions.
 Algorithm 2 IA based GPU SimRank(IADSimRank)
The complete iterative aggregation algorithm for a SimRank block computation is outlined in Algorithm 2. As mentioned, the GPUSRB can be used in Line 03, and the GPUsmm() can be used in Line 05. And in Line 06, err ( A , B ) is the average differences between two matrices calculated by
In Algorithm 2, to compute the whole SimRank matrix, we al-ways use the newest computed SimRank block  X  S ij to calculate the subsequent SimRank blocks even in the same iterative step.
As discussed above, to compute the SimRank scores for a block in a certain iterative step, the naive iterative SimRank method (Al-gorithm 1) uses Equation (4) while the iteration aggregation method (Algorithm 2) uses Equation (13). From the comparison of the two Equations, we can find that the iteration aggregation method is not efficient. A whole iteration process is embedded in it in order to part conclusion. Although iteration aggregation method takes more time at each iterative step than the naive iterative SimRank method does, it produces better result. That means, it needs fewer iterations to reach the final convergence. So the overall performance of the iteration aggregation is better. We will give a detailed theoretical justification on this in the following.

Though some convergence properties of iteration aggregation method are analyzed by existing works ([41], [29] and so on), the Random Suffer-Pairs Model of SimRank is more complex than Markov chains. we will only discuss the global convergence of our method, and leave the local convergence analysis to the future study.

In order to justify the iteration aggregation method to some ex-tent in this paper, we will prove that the iteration aggregation method goes further in one step than a naive method does. In another word, the iteration aggregation method converges faster.
T HEOREM 1. S x and S y ij are the results of the x -th and the y -th naive iterative SimRank step respectively. If x  X  y , then S S ij  X  S .

Theorem 1 indicates that the iterative results are nondecreasing as the iterative number increases. This theorem is presented by [17]. Similarly, the local iteration of iterative aggregation SimRank has Theorem 2.

T HEOREM 2.  X  S x ij and  X  S y ij are the results of the x -th and the y -th local iterative step of the same iterative aggregation SimRank step respectively. If x  X  y , then  X  S x ij  X   X  S y ij  X 
Theorem 2 can be proved by induction. We omit it here due to the limit of space.

L EMMA 1. Let S  X  k  X  1 be the result of the (  X  k  X  1) -th naive it-erative SimRank step, and  X  S  X  k  X  1 be the result of the ( iterative aggregation SimRank step, S k be the result of the k -th naive iterative SimRank step, and  X  S l ij be the result of the l -th lo-cal iterative step in the  X  k -th iterative aggregation SimRank step. If S k  X  1  X   X  S  X  k  X  1  X  S , and l = k  X   X  k , there is S k The proof of Lemma 1 is omitted here due to the limit of space. T HEOREM 3. Let S k be the result of the k -th naive iterative SimRank step, and  X  S k be the result of the k -th iterative aggregation SimRank step, then S k  X   X  S k  X  S , and lim iterative aggregation SimRank step. From Theorem 1 and Lemma 1, there is S k ij  X  S l ij  X   X  S l ij  X  S ij , when k  X  l . Because  X  S
And since lim Theorem 3 shows the global convergence of iterative aggregation SimRank method, as well as the property that iterative aggregation SimRank step can produce greater results than a naive iterative one. In another word, iterative aggregation converges faster than naive iterative method.
In many real setting, the graphs are evolving and growing over time, e.g., new nodes(links) arrive or link weights change. The study of such evolution of the graph would require computing the SimRank scores for the graph at different time instances. A straight-forward approach would be to compute these scores for the whole graph at each time instance. However, given the large size of many real graphs, it is becoming increasingly infeasible. Furthermore, if the percent of nodes that change during a typical time interval is not high, a large portion of the computation cost may be wasted on re-computing the scores for the unchanged portion. Hence, to save the computation cost, there is a requirement for computing SimRank scores incrementally.
 As discussed earlier, the only research work on incremental Sim-Rank computation [25] suffers from the limitation that it can only handle the link-updating problem. Consequently, in this section, we will introduce how the iterative aggregation method can handle the link-updating problem as well as the node-updating problem and is computationally cheap. The basic idea is to reorder and par-tition the updated column-normalized adjacent matrix  X  W into two parts: affected region and original region . Newly added nodes are automatically located in affected region, and deleted nodes are ac-counted for by changing affected transition probabilities to zero. The stationary distribution is updated only for those blocks located in affected region by using the iterative aggregation method. The intuition is that the change is primarily local, and most stationary probabilities are not significantly affected.

Assume the number of graph nodes changed from n to  X  n , and each node group still has g nodes. The updated column-normalized adjacency matrix  X  W is partitioned into the following blocks: in which r = p t  X  g q ,  X  m = p  X  n  X  g q , and t is the number of most affected nodes in  X  W .

Then, reorder and partition the similarity matrix  X  S correspond-ingly. For each block  X  S ij ( 1  X  i  X  r or 1  X  i  X  r ), Algorithm 2 is called to update the SimRank scores. Algorithm 3 outlines the whole process for SimRank updating. Please note that Line 07 is a single global iteration step, which adjusts the SimRank values of original region, and also contributes to the convergence process. Algorithm 3 IA based SimRank Update(IADSimRankUpdate)
GPU has shown its power beyond graphic and recently, signifi-cant developments make the new generation GPU capable of gen-eral purpose programming, there are increasing attention to exploit the parallel computational power of GPU. In this section, we will introduce how to implement the key procedure GPUsmm() of Al-gorithm 1 based on GPU. It is used to finish the expensive matrix manipulation efficiently.
In order to utilize the inherent parallelism and vector processing capabilities of the GPUs for matrix computing, a suitable underly-ing data storage model should be carefully designed. Since the real application graphs are sparse, we take the spare matrix as the rep-resentation of our data. Considering the characteristics of GPUs we adopt the Double Compressed Sparse Row (DCSR) [3] to rep-resent sparse matrices in GPU memory. DCSR format is a popular, general-purpose sparse matrix representation, which allows fast ac-cess to rows of the matrix.

The DCSR format facilitates fast queries of matrix elements in row-wise order. In addition, it allows other quantities of interest to be computed, such as the number of nonzero elements in a par-ticular row ( rowPtr(i+1)-rowPtr(i) ). The storage space of sparse matrix A in DCSR format is strictly O ( nnz ( A )) , where nnz ( A ) denotes the number of nonzero values in A .
The pseudo-codes of GPUsmm to solve Equation (5) are shown in Algorithm 4 and Algorithm 5. Algorithm 4 is running on the CPU side, which is in response of transferring data and invoking GPU kernels. Algorithm 5 is pseudo-code of a kernel running on a single GPU thread, which produces a row of result matrix. Algorithm 4 GPUsmm (  X  , A , B , C ,  X  , D ) Algorithm 5 GPUsmmKernel  X  n  X  ( a , A , B , C , b , D )
In Algorithm 5, parameter n is the total number of threads in the launched kernel grid, which is specified by Algorithm 4 according to the number of non-empty rows in A . To localize elements of the i -th row in Algorithm 5 (Line 3, 5, 7 and 10) is straightly via DCSR format, because rowPtr(i) shows the position of the first element of this row in columnIdx and value , while the following ( rowPtr(i+1)-rowPtr(i) ) elements belong to this row.
The GPU memory is not large enough for a whole sparse matrix even in a compressed format, the cost of communication between main memory and GPU memory is relatively high.
To evaluate the effectiveness and efficiency of our algorithms, we conducted extensive experiments. We implemented all experiments on a PC with Intel Pentium 4 3.0GHz CPU, 1G main memory and a 256M NVIDIA GeForce 9600GT GPU, running Fedora 8 Linux operating system 2 .

We first present a comprehensive study using the synthetic datasets, which shows high effectiveness and efficiency of our algorithms. We then evaluate the efficiencies of our algorithms on two real data sets, the DBLP and the English Wikipedia data. The runtime re-ported in all experiments includes the I/O time. We compare the performance of the following three algorithms:
Table 2 shows the detail of our generated synthetic graphs G G , . . . , G 5 . Each node of G i ( 1  X  i  X  5 ) can choose a constant number of neighbors randomly.

In this set of experiment, we use the following default parame-ters: decay factor c = 0 . 8 , tolerance of iterations  X  = 10 observe that there will be 3 to 8 steps in each local iteration in av-erage.
In this experiment, we conducted experiments to evaluate the ef-ficiency of our three parallel algorithms. We set group node number g to be 1000. For the iterative aggregation update algorithm IADU , SimRank scores of G i is computed based on the scores of G we have made our codes available through the web: http://bi.ruc.edu.cn/file/GPUSimRank.rar.
Figure 1 shows the efficiency performance of our three algo-rithms. Figure 1(a) shows the average time spent on each itera-tive step, and Figure 1(b) shows the total computation time used to obtain the final convergent result. We can find that although the iterative aggregation methods ( IADC and IADU ) spend more aver-age time in one iterative step due to the embeded local iteration, they have better overall performance than the naive method ( Ite ) does. That is, to reach a given tolerance, IADC and IADU meth-ods need fewer steps. This coincides with our theoretical analysis very well. Comparing to the naive method, the iterative aggrega-tion methods can generally have 1.5-2x reduction on total computa-tion time. From Figure 1, we can also find that IADU outperforms IADC . This is because only most affected blocks of IADU needs a local iteration for each iterative step. The SimRank scores of the unaffected blocks are retained for the the new graph, which enables IADU to achieve a faster convergence speed.

In Table 3, rows labeled by  X  k = 1  X ,  X  k = 10  X  and  X  k = 20  X  show the values of err ( S k , S k  X  1 ) (Equation (14)). Rows la-beled by  X  X um of steps X  show the number of iterative steps to con-vergence. These results indicate that IADC and IADU converge about 2x faster than Ite does. IADU is a little faster than IADC . Rows labeled by  X  X rr X  are computed by err ( S Ite , S err ( S Ite , S IADU ) , which show the average difference between the  X  X onverged X  results of the iterative aggregation methods and the naive method. These  X  X rr X  values are relatively small; it prove that the iterative aggregation methods have high accuracy.

This set of experiments are used to evaluated the performance of the three algorithms on different hardware platforms. To compare the GPU algorithms with CPU algorithms, we also implemented similar CPU-based algorithms on the same PC with single-core CPU ( CPUS ) and another expensive PC with quad-core Intel Core 2 Quad 2.66GHz CPU ( CPUQ ), 4G main memory running Win-dows XP Professional Edition.

Figure 2 shows the average step time of Ite and IADC running on three different hardware platforms. From both Figures, we can find that our GPU algorithms achieves about 3x speed up than CPUS and is comparable with CPUQ .
Figure 2: Performance on Different Hardware Platforms
This experiment is to used to check the impact of group size on algorithm performance. Graph G 1 are partitioned into 2, 4, 5, 8, 10, and 20 groups respectively by setting g to be 5000, 2500, 2000, 1250, 1000, and 500. Figure 3(a) shows the convergence speeds by spotted the values of err ( S k +1 , S k ) . IAD@i means running IADC on a graph with i groups. Please note that when the graph has only one group, algorithms IADC and Ite are same. So IAD@1 is exactly Ite . From Figure 3(a), we can find that to reach a given tolerance, Ite needs 45 steps, IAD@2 needs 24 steps, IAD@4 needs 25 steps, IAD@5 needs 25 steps, IAD@8 needs 25 steps, IAD@10 needs 25 steps, and IAD@20 needs 24 steps. Figure 3(b) shows the average time IADC used for one iterative step, and Figure 3(c) shows the total time that IADC used for the whole computation process on different graph partitions. From the results, we can find that running IADC on different graph partitions has nearly the same convergence speeds. IADC converges about 2x faster than Ite does. But different group size causes the average step time to be different, and thus affects the total time.
This experiment is used to verify the efficiency and effective-ness of three algorithms for computation and update on practical datasets.

We extract the 10-year (from 1998 to 2007) author-paper infor-mation from the whole DBLP dataset 3 . Here, we pick up papers published on 6 major conferences ( X  X CDE X ,  X  X LDB X ,  X  X IGMOD X ,  X  X WW X ,  X  X IGIR X  and  X  X DD X ). Every year forms a time step. For each time step, we construct a co-authorship graph incrementally from the one of previous time step. In these graphs, the authors are reordered first by their first year to show up in this dataset, and then by the conference they first participated in this year. Conse-quently, we can have a natural partition on the nodes by years and conferences. The details of DBLP dataset is presented in Table 4.
Table 5 and Figure 4 show the experimental results. Table 5 gives the number of iterative steps needed of three algorithms to reach the final convergence, Figure 4(a) shows the average step time, and Figure 4(b) shows the total time. As expected, IADU performs bet-ter than the other two algorithms. The performance trends revealed by Figure 4 is remarkably similar to those revealed by Figure 1. http://dblp.uni-trier.de/xml/, more details are presented in [24]
In contrast to the synthetic datasets in which nodes have a fix number of neighbors, the co-authorship graphs follows a power law to some degree. The characters such as power law distribu-tion and natural partition help all three algorithms (especially IADC and IADU ) gain a better performance on DBLP dataset than on syn-thetic datasets.

From the results of DBLP dataset, we also notice that some blocks of the SimRank matrix remain zero after several iterative steps. One of our future work is to detect these empty blocks in advance, which could reduce the computation cost dramatically.
At last, we attempt to employ our algorithms on large data graphs, such as Wikipedia.

Wikipedia 4 is  X  X  multilingual, Web-based, free-content encyclo-pedia project which is written collaboratively by volunteers from all around the world X . As a most popular online encyclopedia, http://www.wikipedia.org/ Wikipedia has recently obtained a big interest from academic com-munities, such as [4] and [27].
 In this experiment, we want to compute the SimRank scores of Wikipedia by using the three algorithms. First, we organized data from Wikipedia into the SimRank graph model by the method pre-sented in [27]. An article in Wikipedia, which describes a single encyclopedia concept, becomes an node in the graph. The rela-tionships  X  X n article belongs to a category which is also an article itself X  is chosen to be links in the graph. Note that, category links constitute a subset of links in Wikipedia, so the category graph cov-ers only a subset of the whole Wikipedia.

We generate 3 category graphs from 3 English Wikipedia dumps achieved respectively on August 16, 2009 (wiki0816), August 27, 2009 (wiki0827) and September 9, 2009 (wiki0909). Category graph wiki0816 has 3,027,633 nodes and 1,104,571 edges, wiki0827 has 3,042,063 nodes and 1,112,619 edges, and wiki0909 has 3,055,136 nodes and 1,116,820 edges.

To keep the matrices sparse during the computation, we set a threshold  X  = 0 . 01 [27] to remove the small values. Since the SimRank computation on large graphs is time consuming, we only finish 5 iterations for each algorithms with decay factor c = 0 . 8 . We report the value of err ( S 5 , S 4 ) and the average step time in Table 6. Though IADC and IADU have no superiority in average step time, we can find that they converges faster than Ite does.
A great many analytical techniques have been proposed toward a better understanding of information networks and their properties. Below we briefly describe the work that is most relevant to the cur-rent work.

Static Graph Analysis. There is a lot of research work on static graph analysis, including power laws discovery [30], frequent pat-tern mining [40, 39], clustering and community identification [32, 13], and node ranking [33, 18].

In terms of node similarity, generally, two categories can be sum-marized: 1) content-or text-based similarity measures that treat each object as a bag of items or as a vector of word weights [11], and 2) link-or structure-based ones that consider object-to-object relations expressed in terms of links [17], [19], [7], [22]. In the research of [28], the above two kinds of measures are evaluated, and link-based measure produced systematically better correlation with human judgements than the former one. SimRank [17] is a influential measure of the second category, which based on both a clear human intuition and a solid theoretical background. Xi et al. proposed another node similarity computing algorithm called Sim-Fusion [38] that utilizes the similar idea of recursively computing node similarity scores based on the scores of neighboring nodes.
However, the time complexity of the straightforward SimRank or SimFision computation algorithms are very high. This leads to a variety of optimization techniques to reduce the computation cost of SimRank. Fingerprint-SimRank [10] pre-computes several steps of random walk path from each object. Although it improves computational performance of SimRank, Fingerprint-SimRank has highly cost of high space complexity. Lizorkin et al. [27] estimates the accuracy of computing SimRank and presents three optimiza-tion strategies to speed up the computation of SimRank. Overall, these methods are all based on regular CPU, none of which has con-sidered to utilize the parallel function of hardwares such as GPU or multi-core CPU. To the best of our knowledge, this is the first pa-per that considers to optimize the SimRank computation based on GPU.

Dynamic Graph Analysis. Recently, there is an increasing in-terest in mining dynamic graphs, such as group or community evo-lution [36, 1], power laws of dynamic graphs [23], dynamic tensor analysis [34], and dynamic clustering [5]. In terms of similarity up-dating, to the best of our knowledge, the only two existing papers are [37] and [25]. [37] proposed two algorithms to update the simi-larity matrix incrementally based on the Random Walk with Restart (RWR) model for a bipartite graph. [37] is the only paper concern-ing the incremental SimRank update problem on evolving graphs. Unfortunately, these two methods all have one inherent limitation: they all assumes that the number of graph nodes are fixed. That means, they can only handle the link-updating problem. In contrast, the iterative aggregation method proposed in this paper can handle both the link-updating problem and the node-updating problem.
Iterative Aggregation. Since [31] brought forward the con-cept of nearly completely reducible (NCR) Markov chain, the iter-ative aggregation method has been widely exploited to applications based on NCR Markov chains, e.g. distributed PageRank comput-ing [41], PageRank updating [20], [21], etc.

GPU Applications. Recently, the GPUs have been used as a hardware accelerator for various non-graphics applications, called general purpose computation, such as scientific computation, ma-trix multiplication, sort, databases operations and so on. Meth-ods have been proposed to enhance k nearest neighbor query [12], stream mining [15], information retrieval [6], relational joins on database [16] and sort [14]. Besides, [8] gives a general framework of GPU-CPU based data mining, which takes k-means clustering and Apriori frequent pattern mining as case studies. The compu-tation of SimRank can be split to Matrix-Matrix multiplications, which is indeed suitable to take advantage of parallel programming. [3] discussed the challenge and advances to implement sparse ma-trix multiplication under parallel architecture, and [2] used graphic processers to further improve the performance.
This paper addresses the issues of optimization as well as incre-mental update of SimRank for static and dynamic graphs. We have proposed a GPU-based parallel framework for SimRank computa-tion. Based on the observation that SimRank is essentially a first-order Markov Chain, we have developed two efficient algorithms to compute SimRank scores for static and dynamic graphs. We provide theoretical guarantee for our methods and demonstrate its efficiency and effectiveness on synthetic and real data sets. Overall, we believe that we have provided a new paradigm for exploration of and knowledge discovery in large graphs. This work is just the first step, and there are many challenging issues. We are currently investigating into detailed issues as a further study. [1] L. Backstrom, D. Huttenlocher, and J. Kleinberg. Group [2] N. Bell and M. Garland. Efficient sparse matrix-vector [3] A. Bulu X  and J. R. Gilbert. Challenges and advances in [4] L. S. Buriol, C. Castillo, D. Donato, S. Leonardi, and [5] Y. Chi, X. Song, D. Zhou, K. Hino, and B. L. Tseng.
 [6] S. Ding, J. He, H. Yan, and T. Suel. Using graphics [7] C. Faloutsos, K. S. McCurley, and A. Tomkins. Fast [8] W. Fang, K. K. Lau, M. Lu, X. Xiao, C. K. Lam, P. Y. Yang, [9] D. Fogaras and B. Racz. Scaling link-based similarity search. [10] D. Fogaras and B. R X cz. Scaling link-based similarity search. [11] P. Ganesan, H. Garcia-Molina, and J. Widom. Exploiting [12] V. Garcia, E. Debreuve, and M. Barlaud. Fast k nearest [13] M. Girvan and M. Newman. Community structure in social [14] N. K. Govindaraju, J. Gray, R. Kumar, and D. Manocha. [15] N. K. Govindaraju, N. Raghuvanshi, and D. Manocha. Fast [16] B. He, K. Yang, R. Fang, M. Lu, N. K. Govindaraju, Q. Luo, [17] G. Jeh and J. Widom. Simrank: a measure of [18] J. Kleinberg. Authoritative sources in a hyperlinked [19] Y. Koren, S. C. North, and C. Volinsky. Measuring and [20] A. N. Langville and C. D. Meyer. Updating pagerank with [21] A. N. Langville and C. D. Meyer. Updating markov chains [22] E. A. Leicht, P. Holme, and M. E. J. Newman. Vertex [23] J. Leskovec, J. M. Kleinberg, and C. Faloutsos. Graphs over [24] M. Ley. Dblp: some lessons learned. Proc. VLDB Endow. , [25] C. Li, J. Han, G. He, X. Jin, Y. Sun, Y. Yu, and T. Wu. Fast [26] D. Lizorkin, P. Velikhov, M. Grinev, and D. Turdakov. [27] D. Lizorkin, P. Velikhov, M. N. Grinev, and D. Turdakov. [28] A. G. Maguitman, F. Menczer, F. Erdinc, H. Roinestad, and [29] I. Marek, P. Mayer, and I. Pultarova. Convergence issues in [30] M.E.J.Newman. The structure and function of complex [31] C. D. Meyer. Stochastic complementation, uncoupling [32] A. Ng, M. Jordan, and Y. Weiss. On spectral clustering: [33] L. Page, S. Brin, R. Motwani, and T. Winograd. The [34] J. Sun, D. Tao, and C. Faloutsos. Beyond streams and graphs: [35] Y. Takahashi. A lumping method for numerical calculations [36] C. Tantipathananandh, T. Y. Berger-Wolf, and D. Kempe. A [37] H. Tong, S. Papadimitriou, P. S. Yu, and C. Faloutsos. [38] W. Xi, E. A. Fox, W. Fan, B. Zhang, Z. Chen, J. Yan, and [39] X. Yan and J. Han. Closegraph: Mining closed frequent [40] X. Yan, P. S. Yu, and J. Han. Substructure similarity search [41] Y. Zhu, S. Ye, and X. Li. Distributed pagerank computation
