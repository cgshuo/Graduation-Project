 1. Introduction unstructured text. Some examples include [3  X  6].
 identifying speci fi c kinds of semantic associations.
 propose a generic framework for using co-occurrence patterns to extract different kinds of semantic associations.
In the proposed framework, each document in a corpus is treated as an upon the semantic associations proposed and are constant across all the algorithms.
While the techniques used in the speci fi c algorithms (like random walks, clustering, K basis for explaining the rationale behind a semantic association that is mined from the corpus.
The rest of the paper is organized as follows. Section 2 brie this model are then demonstrated in Section 4 and the concluding remarks are noted in Section 5 . 2. Related literature rather than a comprehensive survey. For the latter, the interested reader may like to refer to [7 2.1. Co-occurrence graph mining plied to semantics mining. The way co-occurrence graphs are constructed, are usually algorithm speci occurrences are thought to capture different aspects of meaning.
 struct a co-occurrence graph [12,13] . They then use a graph clustering algorithm to identify signi terms (nouns and adjectives) inside a document and compute a random-walk centrality of the nodes to identify the terms the sentence summarizing the document best.
 tures (nouns) in a given productcorpus. Similarly, a noun in speech disambiguation [16] .
 corpus. 2.2. Dimensionality reduction sionality reduction asin LatentSemantic Analysis (LSA) [17] . LSAuses singularvaluedecompositionona term yond what was originally captured.

Dimension reduction techniques have also been applied to co-occurrence graph mining in Hyperspace Analogue to Language (HAL) [18] and Correlated Occurrence Analogue to Lexical Semantics (COALS) [3] . Both the algorithms work on a term composed of co-occurrence vectors instead of document vectors for mining semantic associations. ations. In addition, LSA computations are global in nature involving the entire corpus, making it dif models for capturing latent semantics. 2.3. Generative models t o be generated by a mixture of one or more random processes.
 of topics, where each topic generates terms with a given probability distribution. ( fi topics which generated the corpus [21] .
 over the base LDA model.
 than model a document as a mixture of probability distributions, we look at the intensional de 3. The 3-layer cognitive model
Our approach for mining latent semantics is based on building a Philosophy and of semantic memory from Cognitive Science.
 a relationship between term usage and semantics, thereby implicitly reaf number of episodes and is necessary for our use of language. 3.1. 3-layer model ing in humans by dividing it into three clear compartments ( Fig. 1 ): can be described as a set of concepts and a set of associations between the concepts.
Concepts are mental abstractions of real world entities like Federer , space shuttle or of abstract notions like son to person but overlap signi fi cantly and thus enable communication.
 describing the relationship between the concepts Federer and Wimbledon .
 lated to the concepts Tennis and Sport than an arbitrary concept like space shuttle .Wede scribe the in fl ue n ce between concepts.
 the real unit interval [0, 1].

A ( P ). idea is the glue which binds the concepts and associations expressed in an episode. Hence an episode like, the semantic signature of the concept in the analytic layer. ations change in accordance to usage.
 terms along with associated structure (language). Note that the three layers are simpli 3.2. 3-layer model for co-occurrence semantics
The linguistic layer processes input documents based on their language and identi the base for several powerful semantics extraction algorithms.
 erations called primitives ( Fig. 2 ). 3.2.1. Co-occurrence layer Formally, the co-occurrence graph G is a weighted, undirected graph of the form: corpus. The function w indicates the corresponding co-occurrence count between two terms t
De fi nition 2. Closure and focus : Given a set of terms X , their closure X the terms in X .Theirfocus X  X  , is the set of all terms which co-occur with all the terms in X .
De fi nition 3. Coherence :Asetofterms X is said to be coherent if X
Incoherent terms  X  terms which do not share co-occurring terms
De with their co-occurrence counts. In other words, it is the where T N ( t ) ={ t }  X  { u | u  X  T ,{ t , u }  X  C }, C N ( t ) of a set of terms X can be de fi ned in its two canonical forms: N ( X Formally:
When computing the neighborhood of a set of terms X representing a compound concept, the primitives X hypothetical terms representing the compound concept, so that the neighborhoods N ( X co-occurrence weights of terms in the neighborhood of X  X 
The above equations are essentially multiset (bag) intersection and multiset sum (
De fi nition 5. Semantic context : Given a co-occurrence graph G , the semantic context form { v 1 , v 2 } from G such that v 1 , v 2  X  V ( H ).

Formally the semantic context is de fi ned as:
As before, for a set of terms X we de fi ne the semantic contexts of their closure and focus. latent semantics pertinent to terms in X will be found within the semantic context of either X X are coherent in the fi rst place.
 ture this asymmetry, we de fi ne the notion of generatability .

De happens to be u is called the generatability of u in the context of t . Formally: Every edge ({ u , v }  X  C ) can have two generatability probabilities associated with it ( originating from a term u form a probability distribution which is called the generatability distribution i fi ed in Eqs. (7) and (8) . 3.3. Methodology for mining semantics ogy involves three steps. For a given semantic association S , do the following: 1. Provide an intensional de fi nition of S , indicating what S is supposed to mean in terms of the analytic layer for S primitives
These three steps are fundamental to the way we mine semantics, as re in the following section. 4. Semantic associations over a co-occurrence graph generated from named entities extracted from Wikipedia articles. pedic nature like Wikipedia. 4.1. Document corpus used for measuring co-occurrences. The dataset was cleaned by removing all the non-article pages the text, as the primary objective was to extract semantics based solely on co-occurrences. we picked all the terms with their own Wikipedia page as the set of keywords. was used sometimes. Such instances are explicitly mentioned in the relevant sections. 4.1.1. Topical anchors the document. Here, Tennis acts as the topical anchor for these set of words. to why the algorithm results in topical anchors.

To extract topical anchors, we ad opt the 3-layer methodology by aboutness distribution of Q : A(Q) .
 about.
The next step is to reduce this de fi nition into an extensional de
Q , how will it be evidenced across different episodes? of generation increases with the length of the episode.
 In such a context, we are bound to encounter the term Tennis , the longer the conversation, document or article gets.
Note the difference between the intensional and extensional de human language usage that represent the intensional structure of the semantic association. (say) Tennis, without mentioning the term  X  Tennis.  X  the topic in order to reinforce the relevance of what is said, to the topic. The topic is what the document is lative generatability score in an in fi nitely long random walk executed on in accordance with its generatability to other nodes. As this process is repeated, the cash-this algorithm is shown in Table 1 . As in OPIC, each iteration of the random walk has a complexity of O ( N of nodes in the semantic context  X  ( Q ).
 two values would be exactly the same for cash distributed by a node u if, N ( u )  X  ( Q  X  ) then the two metrics differ.

For example, in the graph shown in Fig. 3 , let the sub-graph in the dotted circle indicate edges indicate N(u) . As earlier, let u have a cash of x to distribute. If we just take uting cash using generatability where  X  u  X  r =0.05and  X  u  X  s
This effectively reduces u 's say in determining the topical anchor of  X  ( Q  X  ).
 cash is leaked out of the system and is not distributed any further.

The results for some polysemic query terms are presented in Table 2 . 4.1.1.4. Validating the hypothesis. The experiment was conducted in two phases. In the episodes (sets of terms) for which topical anchors as per the analytic de given by the volunteers were recorded and compared with the topical anchors generated by the algorithm.
For the experiment, we partitioned the topical anchors given by the volunteers into con computer for the query,  X  CPU, hard disk, monitor, mouse  X  intervals are in steps of 10starting from 40to 50and goingup to 90 of the con fi dence intervals above 40 are ignored because of the lack of adequate support.
With a con fi dence cut-off at 40, there are a total of 156 topical anchors, which are in con the 100 chosen queries. Some queries like,  X  summer, winter, spring, autumn Watt, Ohm, Tesla  X  have several evaluator given anchors like unit, electricity ,and physics .
We evaluated three different algorithms for computing the most central nodes. First we used a variant of TF of TF  X  IDF whichissimilarin spirit.Term Frequency (TF) of a nodefor a context edges tonodes in thecontext. Inverse of Document Frequency (IDF) of a node wasde of TF and IDF was used as the score of a node as shown in Eq. (13) .
 weights in the sub-graph. The former is called cl where cl stands for cash leakage and the latter opic. the number of correctly identi fi ed topical anchors of t cl 3 and cl 10.
 chosen by the volunteers.
 that t fi df 10 and opic 10 could correctly pick only 40 and 56 topical anchors respectively of the 156, i.e., t 70% and cl 10 had a recall of 95.5%.
 fi gure in any precision computation.
 text which contains the query terms.
 rithm [26] . Refer to the same for further experiments and results involving topical anchors. 4.2. Semantic siblings form semantic siblings, as they are all different types of gems.
 tic query expansion, recommender systems, semantic matching of documents, etc. 4.2.1. Speci fi c related work page are likely to be siblings [31] .

Sometimes  X  xisay  X  patterns in text can be used to determine the parent and can perform well even on unstructured corpora like free text or transcripts. (cardinality: 3) of semantic siblings is taken as input and a larger set (20) of siblings is returned as the result.
As before, we follow the 3-layer methodology of de fi ning semantic siblings with intensional and extensional de ducing it to a co-occurrence algorithm. 4.2.2. Intensional de fi nition
Asemanticsibling s of a set of concepts Q ={ q 1 , q 2 , ... distribution of each of the concepts in Q .i.e.,( A ( q 1 concepts. 4.2.3. Episodic hypothesis ticsiblings of oneanother, if givenanepisode e that features one of the concepts q some other concept q  X   X  Q , with the rest of the concepts and associations in e able in most of the associations. replaceability.
 hoods of each term in Q , N ( q i ).
 forth referred to as direct, the generatability distribution of a candidate sibling used to determine the semantic siblings. In this algorithm, henceforth referred to as interleaved, the joint generatability distribution timated by assuming them to be independent. Similarly, a new set Q replaced by the candidate s . The candidate s can replace q is followed as in direct.

Both the algorithms compare one probability distribution with another and for this purpose we used Kullback (K  X  L divergence) [33]. The K  X  L divergence of a distribution B with respect to a distribution A is given as,
K  X  L divergence between two distributions is a positive number in the range [0, Given a query Q ={ q 1 , q 2 , q 3 }, and a candidate sibling s , the direct algorithm computes the vector For the same example, the resultant vector in the interleaved algorithm would be, plexity of O ( N 3 ) and direct algorithm has a time complexity of O ( N Algorithm 1. Semantic siblings using interleaved method.

Some sample queries along with the top 10 siblings given by the interleaved algorithm are shown in Table 3 . Algorithm 2. Semantic siblings using direct method.
 of results between the algorithms.
 had four or more evaluators.
 by at least two evaluators were considered.

Nadal, Roddick }  X  Tennis player or sportsperson ; or co-meronyms of a shared holonym like, { Germany, France, Spain } everyday usage, given that the query terms were semantic siblings themselves. semantic siblings, on an average the interleaved yielded 63.4% precision and the direct yielded 59.2% precision. space of each algorithm had a minimal overlap with the other.
  X  ( Q  X  ) where Q ={ Federer, Nadal, Roddick }, the number of nodes was 2334. Only 4% of these nodes ( players.
 the number of semantic siblings obtained and reducing the load on evaluators. the overall precision could be improved to 71%.
 represent people had a speci fi c signature of their own. In our dataset, the algorithms performed signi terms in Q represented people.

We also compared these algorithms with other queries on structured datasets like, WordNet,
WordNet is a hand-tagged lexical database for English language, which de which is similar to the semantic sibling relationship.
 were de fi ned in WordNet, of which 201 terms had the association sister terms de an average of 22 results per query.
 An important point of note here is that the semantic sibling queries submitted by the volunteers were predominantly (
Kurosawa , Mickey Mouse , Golden Retriever , Poseidon and Victoria falls have sister terms de cannot as be exhaustive as free text.
 ciations. Like WordNet, YAGO2 describes several relationships between terms and one among them is is tures hyponym  X  hypernym relationships which are inherent in semantic siblings. Hence, to was nosimple way by which we could eliminate the highly generic is the queries still could not be answered.
 ber of queries being answered. However, as in the case of YAGO2 each of the queries had millions of semantic siblings. structured techniques. 4.3. Topical markers can determine the topic of the episode as Tennis with high con high con fi dence, even though the term machine learning itself need not to appear in the tweet. 4.3.1. Speci fi c related work
TF or Tennis need not be con fi ned to the boundaries of a small set of documents.
The 3-layer methodology for identifying topical markers follows. 4.3.2. Intensional de fi nition high aboutness value but not necessarily vice versa.
 relevant to, but not vice versa. 4.3.3. Episodic hypothesis length of the episode or with the number of such episodes. m , which can unilaterally determine the topic with high probability. 4.3.4. Co-occurrence algorithm terms only in  X  ( t ).

A topical marker m is a term whose generatability distribution lies almost completely within the vertices of unique to  X  ( t ). To compute these terms which are central to of a context simultaneously.

First a bipartitegraph is created bydividingeach vertex in all the hubs are initialized to be 1/ n where n is the number of vertices in puted recursively as in Eq. (15) . k terms are chosen as the topical markers of t . As in HITS, the time complexity of the algorithm is O ( N number of nodes in the semantic context  X  ( Q ).
 cates how well the term can be generated by good hubs in the semantic context. hubs and also good authorities, represented by having high hub and authority scores.
Some example results are given in Table 5 . 4.3.5. Validating the hypothesis them, for the given topic.
 which was chosen by at least two evaluators was considered a topical marker. racy is plotted in Fig. 7 .

API. 7 In general, this API only searches on certain websites but it wasadequately modi there were 100 web pages for each topic (10 results for each of the 10 topical markers of the topic). our algorithm for the given topic and not the topics themselves. Hence, the high number of web pages being classi determinethetopic. Fig. 8 shows thenumber of searchresults forall 10 topical markers of eachtopic whichwere classi belonging to the topic. The 10 topics are shown on the x-axis.

We also compared the topical markers with the top 30 terms having the highest TF metric used for this purpose is same as that in Eq. (13) , used in topical anchors evaluation. The TF to the topic. For example, for the topic capitalism , the terms with the highest TF United Kingdom etc. Even though these terms are important to capitalism, they are not topical markers.
In addition, we also performed a qualitative comparison of our results with Google AdWords
AdWords with topical markers may be attractive. 4.4. Topic expansion unfolding t into a set of concepts that are collectively  X  term represents a different concept in the analytic layer 4.4.1. Speci fi c related work vectors so as to use existing clustering techniques. Along with co-occurrences they also use other features or from algorithms like LSA  X  to fi nd clusters representing different senses of a given word. graph [38  X  41] . Among these, HyperLex [39] mines a minimal spanning tree in a context de occurrence graph created out of special contexts like verb focus here is on the generic framework and methodology, that can achieve similar results. suitably applying LDA so as to use it as a benchmark for comparison.
 4.4.2. Intensional de fi nition
For a topic representedbya concept t , a topic expansion TE ( t )={ c aboutness for t .
 t ,making TE(t) as a tuple of terms: b c 1 , c 2 , c 3 , ...
We know that a concept has the maximum aboutness score of 1 for itself. Hence it will always be the 4.4.3. Episodic hypothesis 4.4.4. Co-occurrence algorithm set by a series of cluster merge and fi ltration steps. t and the i th most generatable term in N(t) .
 Algorithm 3. Cluster generation with the i th most generatable term.

The term u i , which is the i th most generatable term from t is used as the cluster. The index i associated with a cluster represents the importance rank of the generated cluster. progressively merge clusters based on their similarity. Cluster similarity between clusters C any major sense of the topic t .

Algorithm 4. Cluster merging. 4.4.4.3. Filtration. In the third step, such extraneous clusters which do not depict any major sense of t are cluster index represents the  X  importance  X  of a cluster or the dominance of the sense that the cluster represents clusters that are left out tend to have a higher index, and hence lower importance. imum overlap between any two clusters drops below another moderate threshold representing a different dominant sense for the topic. where the exclusivity of two terms t m and t n is de fi ned as: tance of the topic itself, to the given term. Overall, the topic expansion algorithm has a time complexity of O ( N ber of nodes in the semantic context  X  ( t ).

Table 7 shows some examples of topic terms and the dominant senses expanded using the above algorithm. 4.4.5. Validating the hypothesis tion aspectof the algorithm. For each of these25 terms,topic expansionalgorithm wasrunwith algorithm were compared with topic modeling and word sense disambiguation algorithms. by this algorithm.
 specifying the relevance of a cluster to one of the senses of the topic term t . jumbled such that an evaluator looking at the clusters would not be able to identify the algorithm that generated it. each volunteer evaluated 15 input terms.
 expansion, whereas it was 1.7 for LDA.

We also computed the overall relatedness score  X  in a similar fashion was found to be 2.16 for topic expansion, whereas it was 1.48 for LDA.
 picked the 10 most important nodes in the cluster for our evaluation.

This algorithm for word sense disambiguation was proposed on a speci ture (like lists and syntactical patterns) in the data and are not suited well for unstructured data. found to be 2.16 for topic expansion, whereas it was 1.003 for word sense disambiguation. 5. Conclusions
The research presented in this paper approaches the problem of mining latent semantics with two speci the extracted results.
 5.1. Future directions exist in the form of recommender systems.

References
