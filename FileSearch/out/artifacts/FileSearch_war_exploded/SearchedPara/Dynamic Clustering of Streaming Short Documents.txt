 Clustering technology has found numerous applications in min-ing textual data. It was shown to enhance the performance of re-trieval systems in various different ways, such as identifying differ-ent query aspects in search result diversification, improving smooth-ing in the context of language modeling, matching queries with documents in a latent topic space in ad-hoc retrieval, summariz-ing documents etc. The vast majority of clustering methods have been developed under the assumption of a static corpus of long (and hence textually rich) documents. Little attention has been given to streaming corpora of short text, which is the predominant type of data in Web 2.0 applications, such as social media, forums, and blogs. In this paper, we consider the problem of dynamically clus-tering a streaming corpus of short documents. The short length of documents makes the inference of the latent topic distribution challenging, while the temporal dynamics of streams allow topic distributions to change over time. To tackle these two challenges we propose a new dynamic clustering topic model -DCT -that enables tracking the time-varying distributions of topics over doc-uments and words over topics. DCT models temporal dynamics by a short-term or long-term dependency model over sequential data, and overcomes the difficulty of handling short text by assigning a single topic to each short document and using the distributions in-allowing the aggregation of information. At the same time, taking a Bayesian approach allows evidence obtained from new stream-ing documents to change the topic distribution. Our experimental results demonstrate that the proposed clustering algorithm outper-forms state-of-the-art dynamic and non-dynamic clustering topic models in terms of perplexity and when integrated in a cluster-based query likelihood model it also outperforms state-of-the-art models in terms of retrieval quality.
  X  Information systems  X  Clustering; Clustering; Topic Models; Streaming Text; Cluster-based Retrieval
New media applications and the increasing prevalence of mo-bile devices have facilitated the collection and rapid dissemina-tion of news and information by anyone connected to the Internet. Massive amounts of user generated content, often in the form of short text (e.g. microblog posts), typically clustered around real-life events [6, 20], are streaming in, and being consumed by inter-connected users. Organizing large text collections around concise topics (or clusters) allows effective summarization and retrieval of information [5, 7, 13]. In the case of a rapidly streaming short text, however, traditional clustering algorithms are either not ap-plicable, or do not tackle the temporal and sparse nature of the text corpus [7, 25]. In this paper we propose a dynamic cluster-ing topic model method  X  DCT  X  for short-length streaming text and we demonstrate that it can effectively model both the temporal nature of topics in streaming text and the sparsity problem of short text, improving the performance of clustering and ad-hoc search.
One of the key challenges in clustering streaming data is the dy-namic nature of topics (or clusters): topic distributions change with time, with previously salient topics  X  X ading-off X  and vice versa [1, 6, 7, 10, 22]. Therefore, techniques developed ought to allow for changes in the topic distribution along time. For example, Twitter posts about Apple Inc. on September 9, 2015, when Apple in-troduced iPhone 6s plus , are expected to be clustered around Ap-ple iPhone 6s plus , while this may not be the case on December 3, 2015, when Apple swift was announced. The problem of clus-tering documents in streams has been widely investigated in the past [1, 6, 10, 22]. However, most of the previous work makes the assumption that the content of documents is rich enough to infer a per-document multinomial distribution of topics. The second key challenge in clustering streaming data is that this assumption does not hold for short text, as the number of words in each document is limited, which prohibits the accurate inference of a topic distribu-tion over the document. Our method tackles the two challenges by introducing a collapsed Gibbs sampling algorithm that (a) assigns a single topic to all the words of a short document, and (b) uses the inferred topic distribution of past documents as a prior of the topic distribution of the current documents, while at the same time allowing new evidence (newly streamed documents) to change the posterior distribution of topics. Based on the exact definition of the prior the proposed model enables both short-term and long-term dependencies between the previously and currently inferred distri-butions.

In this paper, we take a special interest in the application of topic models in the area of information retrieval. Our goal is to infer the relevance of each cluster to a user query by calculating the dynamic topic distribution over short documents and incorporating that in a query likelihood model for ad-hoc retrieval. We evaluate our pro-posed clustering model on a publicly available Twitter dataset by comparing the retrieval performance achieved with state-of-the-art methods and demonstrate the superiority of our algorithm.
The contribution of this work is threefold: (1) We propose a Dynamic Dirichlet Multinomial Mixture Model (2) We propose a collapsed Gibbs sampling algorithm for our (3) We analyze the effectiveness of the proposed clustering mod-
The remainder of the paper is organized as follows:  X 2 discusses related work;  X 3 details the problem;  X 4 describes the proposed clustering model;  X 5 describes our experimental setup;  X 6 is de-voted to our experimental results and we conclude the paper in  X 7.
There are two lines of work related to our work, topic modeling and clustering, with a rich literature available on both topics. In the following sections we only discuss the most related models and algorithms.
Topic modeling provides a suite of algorithms to discover hid-den thematic structure in a collection of documents. A topic model takes a collection of documents as input, and discovers a set of  X  X a-tent topics X  X  X ecurring themes that are discussed in the collection X  and the degree to which each document exhibits those topics [3]. Latent Dirichlet Allocation (LDA) [3] is one of the simplest topic models, and it decomposes a collection of documents into topics X  biased probability distributions over terms X  X nd represents each document with a subset of these topics.

Many models that extend LDA have been proposed, such as topic over time model [20], dynamic mixture model [22], topic track-ing model [10], online multi-scale dynamic topic model [11] and more recently, (static) Dirichlet multinomial mixture model [25], Dirichlet-hawkes topic model [6] and user-aware sentiment topic model [24]. These models can either infer topics in static collec-tions of short text, e.g. the (static) Dirichlet multinomial mixture model [25], or infer dynamic topics in long documents, e.g. the dy-namic mixture model [22], the topic tracking model [10], and the online multi-scale dynamic topic model [11]. Instead, we propose two dynamic Dirichlet multinomial mixture topic models for short text streams: one for short term dependency of the current infer-ence of the topics and another for long term dependency. Based on these topic models we can infer the dynamic changes of the multi-nomial distribution of the documents in a stream, and the document probabilities to the topics, and we use the inferred topics to cluster the documents. Hence, our model can both infer topics in short text streams and track the dynamic changes in clusters.
Clustering is one of the main technologies that has been applied to tackle many challenges in data mining, text mining, and infor-mation retrieval [5]. For instance, [21] proposed a cluster-based document retrieval model where the clusters are generated by LDA. Table 1: Main notation used in dynamic clustering topic model. [13] presented a burst-aware approach to fusing document lists re-trieved in response to a query via integrating information used by fusion methods with that induced from time-sensitive clusters of documents. Efron et al [7] found that relevant documents tend to cluster together in time and utilizing some existing clustering algo-rithms can boost the performance of tweet search. In terms of data mining, Botezatu et al. [4] proposed a multi-view incident ticket clustering algorithm for optimal ticket dispatching.

To this date, a large number of clustering algorithms have been proposed with KNN (K-Nearest Neighbours) and K-Means as some of the most famous ones. Among those, given that we want to tackle the problem of clustering short documents in streams, we focus on Dirichlet multinomial mixture clustering model [25], that performs well on short text, and which is based on topic modeling. This model acknowledges that as the number of words in short doc-uments is limited, and thus each word in the same document can be assigned to one topic. Then documents assigned to the same topic are in the same cluster. Their experimental results validated the ef-fectiveness of this assumption. However, this model and more re-cent short document clustering model based on convolutional neu-ral networks [23] can only cluster a static collection of short docu-ments. Other clustering technologies based on topic modeling in-clude dynamic mixture model [22], topic over time model [20] and topic tracking model [10]. However, until now all of the dynamic topic models make a strong assumption that documents arriving in a data stream are long and provide rich context for the inference. To the best of our knowledge, our proposed clustering algorithm is the first attempt to cluster streams of short text documents.
The task we address in this work is the clustering of short text streaming documents, with clusters changing dynamically, as new documents stream in. The dynamic clustering algorithm is essen-tially a function f that satisfies: where d  X  t represents the stream of documents with d 0 t most recent set of short documents, arrived at time t , and c resulting set of clusters of documents up to time t , with c the z -th cluster in c t and Z the total number of clusters. d prises a set of short text documents, with each document d being represented by a sequence of words appearing in d , coming from a vocabulary V = { v 1 ,v 2 ,...,v V } . We assume that the length of d is no more than a predefined small length (for instance, 140 characters in the case of Twitter). For brievity, in the remainder of the paper, we denote d  X  t and c  X  t with d t and c t , respectively.
Table 1 summarizes the main notation used in our dynamic clus-tering topic model.
In this section, we describe our proposed dynamic clustering topic model, DCT , aiming at the effective clustering of short doc-ument streams.
The goal of the dynamic clustering topic model is to infer the dynamically changing topic distribution and document distribution over topics at any given time t . That is, we want to infer the tempo-ral word probability for a topic, P ( v | t,z ) , and the temporal topic probability over a document, P ( z | t,d ) . Previous work [25] has demonstrated that algorithms that assign a single topic to all the words in a short document outperform those that assign different topics to different words in terms of clustering quality. The intu-ition behind this observation is that the number of words in short documents is limited and a short document is likely to be associ-ated with one topic. Following [25], our proposed Gibbs sampling  X  as it will be described in the following sections  X  assigns a single topic to all the words in each short document.

Following the notation of past topic modeling work [2, 3, 10, 20], we let  X  t = {  X  t,z } Z z =1 be the topic distribution at time t with  X  t,z = P ( z | t ) &gt; 0 , and P Z z =1  X  t,z = 1 . We also let  X  {  X  t,z } Z z =1 be the word distribution over topics at time t .  X  {  X  t,z,v } V v =1 is the (multinomial) distribution of words for topic z at time t , while the probability of a word v belonging to z at t ,  X  t,z,v = P ( v | t,z ) &gt; 0 , and P V v =1  X  t,z,v = 1 ; V is the size of the vocabulary V . In fully bayesian non-dynamic topic mod-els (such as LDA [3]), there is an underlying assumption that the per-document topic distribution is independent of the past distri-butions, and have a Dirichlet prior with a static set of parameters  X  = {  X  z } Z z =1 , with  X  z &gt; 0 ,
Similarly, the per-topic word distribution  X  t,z also has a Dirich-let prior with a static set of parameters  X  = {  X  v } V v =1
The assumptions made in (1) and (2) are not realistic when it comes to a data stream setting, where the distributions at time t are dependent on past distributions. In the following subsections, we infer  X  t and  X  t by modeling short-term dependency (Section 4.2) and long-term dependency (Section 4.3). Modeling short-term dependency. To model the temporal de-pendencies of the topics in a document stream, and by following the work of past dynamic topic models [10, 11, 22], we propose a short-term-dependency DCT model. According to this model, the topic distribution at time t remains the same as the one at time t  X  1 if no new documents are observed, while it is updated on the basis of new evidence when a new set of documents is observed at time t . To achieve that we factorize the parameter  X  in (1) into the mean of the distribution at the previous time-step,  X  t  X  1 ,z , and a set of preci-sion values  X  t = {  X  t,z } Z z =1 . Hence,  X  =  X  t  X  t  X  1 the mean of the current distribution  X  t to depend on the mean of the previous distribution  X  t  X  1 , where the precision value  X  t,z represents the topic persistency, that is how salience is topic z at time t compared to that at time t  X  1 . The distribution is a conjugate prior of the Multinomial distribu-tion, hence the inference can be performed by Gibbs sampling [17].
In a similar way, to model the dynamic changes of the multino-mial distribution of words specific to topic z , we assume a Dirichlet prior, in which the mean of the current distribution  X  t evolves from the mean of the previous distribution  X  t  X  1 with the precision being  X  , where as before, the Dirichlet prior parameter  X  in (2) is factorized into the mean and precision,  X  =  X  t,z  X  t  X  1 ,z , with  X  being the set of precision values at time t for the topics. Here  X  t,z = {  X  t,z,v } V v =1 , with  X  t,z,v representing the persistency of word v in topic z at time t , a measure of how consistently word v belongs to topic z at time t compared to that at the previous time t  X  1 . We describe the inference for  X  t ,  X  t ,  X  t and  X  of this section.
 Assuming that we know the topic distribution at time t  X  1 ,  X  t  X  1 , and the word distribution over topics at time t  X  1 ,  X  the proposed Dynamic Dirichlet Multinomial Mixture Model is a generative topic model that depends on  X  t  X  1 and  X  t  X  1 initialize (at time t = 0 ) the means of the two distributions to  X  0 ,z = 1 /Z and  X  0 ,z,v = 1 /V . The generative process (used by the Gibbs sampler for parameter estimation) of our model for documents in stream d t at time t , is as follows, ii. Draw Z , one for each topic z , multinomial distributions  X  iii. For each document d  X  d t , draw a topic z d from the multi-Fig. 1 illustrates the graphical representation of our Dynamic Dirichlet Multinomial Mixture Model; given that documents are short, and following [25], all words in the same document d are drawn from the Multinomial distribution associated with the same topic z d . The parameterization of the proposed dynamic topic model is as follows: Note that in the generative process described above, there is a fixed number of latent topics Z . A non-parametric Bayes version of our dynamic topic model that automatically integrates over the number of topics is possible, but we leave this as future work. Inference for the short-term dependency DCT. The inference of the distribution parameters of the model is intractable. Follow-ing [14, 15, 19, 20] we employ a collapsed Gibbs sampler [9] for an approximate inference. We adopt a conjugate prior (Dirichlet) for the multinomial distributions, and thus we can easily integrate out the uncertainty associated with  X  t,z and  X  t . In this way we enable sampling since we do not need to sample  X  t,z or  X  t .

In the Gibbs sampling procedure we need to calculate the condi-tional distribution P ( z d | z t,  X  d , d t ,  X  t  X  1 ,  X  Figure 1: Graphical representation of our dynamic Dirich-let multinomial mixture clustering topic model, DCT. Note that short term dependence DCT model excludes the two blue curved lines; while long term dependence DCT model does in-clude these two lines. The figure is best viewed in color. where z t,  X  d represents the topic assignments for all documents in d except document d . We begin with the joint probability of the current document set d t , P ( d t , z t |  X  t  X  1 ,  X  t  X  1 pendix A for the detail of the join probability), and using the chain rule, we can obtain the following conditional probability, where m t,z is the total number of documents in d t assigned to topic z , N d,v is the number of word v in the document d , n t,z,v,  X  d total number of the word v assigned to topic z except that in d , and n t,z,  X  d is the total number of documents assigned to z except d . Detailed derivation of Gibbs sampling for our proposed DCT model is provided in Appendix A. During sampling, at each iteration, the precision parameters  X  t and  X  t can be estimated by maximizing the joint distribution P ( d t , z t |  X  t  X  1 ,  X  t  X  1 , X  t point iteration to get the optimal  X  t and  X  t at time t . The following update rule of  X  t for maximizing the joint distribution in our fixed-point iteration is derived by applying two bounds in [18],  X  where  X (  X  ) defined by  X ( x ) =  X  log  X ( x )  X  X  is the digamma function; whereas the following update rule of  X  t is, B and n t,z,v is the number of word v assigned to topic z in stream d Algorithm 1: Inference for the Dynamic Dirichlet Multinomial Mixture Model at time t .
 Input : Previous topic distribution  X  t  X  1 Output: Current topic distribution  X  t
Initialize topic assignments randomly for all documents in d for iteration = 1 to N iter do 3 for d = 1 to | d t | do 6 update  X  t and  X  t
Compute the posterior estimates  X  t and  X  t Compute P ( z | t,d ) Our derivation of the update rules for  X  t and  X  t , and the two bounds used in deviating the update rules are detailed in Appendix B. An overview of our proposed collapsed Gibbs sampling algorithm, in-cluding the input and output, is shown in Algorithm 1. Modeling long-term dependency. So far the distributions  X   X  t depend on the previous time-step distributions. Research has shown that topic distributions -or the interests of a user on a topic when searching for information -may depend on a longer time-step history. We model such a long-term ( L -steps) dependency DCT model on the basis of the distribution priors as follows:
The mean in this case is proportional to the weighted sum of the past L  X  X opic trends X  in the documents, and  X  t,l = {  X  t,z,l represents how the topics at time t are related to the l -previous top-ics. For a comparison with the short-term dependency model refer to Eq. (3) and Eq. (6). Further, long-term dependency reduces the information loss and the bias of the inference due to the multiple estimates.

Similarly, the Dirichlet prior of the topic trends  X  t,z at t can be modified such that  X  t,z depends on the past L topic trends {  X  as well. By doing so, we can make the inference more robust. Thus, we have: where  X  t,z,l = {  X  t,z,v,l } V v =1 represents how the word distribution over topics at time t are related to the l -previous one. Inference for the long-term dependency DCT. The parameters  X  t and  X  t,z in Eq. (6) and Eq. (7) can be integrated in the ex-act same way as before (since priors are still Dirichlet distributed) and  X  t and  X  t,z at time t are inferred using the proposed Gibbs sampling in Algorithm 1. The only difference lies in the way we sample the latent topic for each document (step 4 in Algorithm 1) and the update rules for the priors (step 6 in Algorithm 1). Similar to Eq.(5), we sample a latent topic for a document d by: The derivation of Eq. (8) is similar to that of Eq. (5) (see Ap-pendix A). Again, we update  X  t,z,l in Eq. (8) using the two bounds in [18] with fixed-point iteration such that: with fixed-point iteration by:  X  do not show the derivations of the update rules for  X  t,z,l as they are similar to those for  X  t,z and  X  t,z,v in our short term de-pendency DCT model (see Appendix B).
Now, we can infer the dynamic topic distribution at time t ,  X  in our short-term dependency DCT model as, where m t is the total number of documents in d t , and infer a multi-nomial distribution over words for topic z at time t as, where n t,z is the number of words assigned to topic z at time t . Similarly, we can infer the dynamic topic distribution at time t in our long-term dependency DCT model as, and the multinomial distribution over words for topic z at time t , As one can observe in all equations for the two models, the short-term model is just a special case of the long-term one for L = 1 .
Having computed  X  t,z and  X  t,z,v , we can compute the probabil-ity that a document d is relevant to topic z d at time t in the stream d , P ( z d | t,d ) as: P ( z d | t,d ) = by Eq. (5) and Eq. (8) for the short-and long-term dependency DCT model, respectively. Finally, the document d in stream d is clustered to cluster c 0 z , i.e., the topic z = arg max
Ideally, we would like to evaluate the performance of our dy-namic clustering model by directly comparing the clustering result with ground truth labels in a streaming short text corpus. However, to the best of our knowledge, there is no such collection available to this date; obtaining cluster labels for all documents in a stream and all points in time is rather expensive. Instead, we perform an extrinsic evaluation of the proposed model: (a) we incorporate the clustering algorithm derived by the DCT model into a cluster-based query likelihood model for ad-hoc retrieval [5, 21], and test the clustering quality on the basis of retrieval performance, and (b) we test the ability of the DCT generative model to predict the observed data on the basis of perplexity [2, 3]. We compare the performance of our model with other state-of-the-art clustering models.
The cluster-based ad-hoc retrieval model [21] used in our exper-imental setup is the following: where n ( v,q ) is the term frequency of term v in query q , and P ( v | t,d ) is the probability of document d  X  d t being relevant to the query term v , which is computed by using a Dirichlet smooth-ing language model [5] as,
P ( v | t,d ) =  X P Cluster ( v | t,d )+ (1  X   X  ) N d where  X  is a free parameter,  X  is a Dirichlet prior in language model [5], and P ML ( v | t,d ) , P ML ( v | d t ) and P Cluster maximum likelihood estimates of word v in the document d , in the current short document stream d t and in the document d in terms of clusters at time t , respectively. According to the cluster-based retrieval model proposed in [21], P Cluster ( w | t,d ) is computed by, where P ( v | t,d,z ) is the probability of word v being relevant to topic z at time t , and P ( z | t,d ) the probability of document d being assigned to topic z . When applying the proposed DCT clustering model, for instance, we set P ( v | t,d,z ) =  X  t,z,v is defined in Eq. (9) and Eq. (10) for the short and long term de-pendence DCT models, respectively, while P ( z | t,d ) is defined in Eq. (11), for the two models, respectively.
The research questions we investigate in experimental section of the paper are: On the basis of ranking performance: On the basis of the generative model:
One of the key criteria for a suitable test collection for our ad-hoc retrieval task is the dynamic nature of the intent of a users X  query. That is we make the assumption that for the same query, e.g. Egypt , the intent may change over time (something that we hope to be re-flected in the identified dynamic topic distribution). Publicly avail-able labeled corpora, such as Tweets2011 and Tweets2013 used for ad hoc retrieval in TREC 2011 X 2015 Microblog track [16], have been constructed however by judging documents against a static query intent; furthermore the time-span of the collection is rela-tively small (16 and 59 days, respectively).

To allow for a dynamic query intent we construct a new test col-lection based on a publicly available corpus of Twitter posts (an 1% sample of all tweets). 1 The corpus has been collected between February 1, 2015 and April 30, 2015, covering a period of 90 days. Most of the tweets are written in English; we remove non-English tweets and retweets to end up with 369 million tweets. We fol-low Fisher et al. [8] and generated queries and relevance labels as follows: (a) Manual selected hashtags on topics of general inter-est, such as  X #Apple X  and  X #Egypt X  are transformed into keyword queries. (b) Given a query at time t , we label the top-k documents retrieved by a time-sensitive language model (see Section 5), result-ing in the query-document ground truth used in our experiments. Assessors are university students employed remotely, while no spe-cific intent for a query was provided to them. Therefore, it was up to their own judgment to decide what constitutes relevant and what not. To enable the possibility of query intent drifting relevance judgments were not obtained retrospectively (i.e. at the end of the 90 days period) but we simulated a streaming scenario and obtained labels at 20-day intervals 2 . This resulted in 5 sets of ground truth data: on February 9th, March 1st, March 21st, April 10th, and April 30th of 2015. Our test collection includes 107 queries, and 5 sets of (disjoint) ground truth labels for each one of them.
We compare the DCT 3 model with a number of baselines and state-of-the-art algorithms: Language Model (LM) [5]: Directly ranks documents by their rel-Time-aware Microblog Search (TMS) [7]: Based on the tempo-beling and we found that it yielded not significantly different results in many cases. bitbucket.org/sliang1/dct/get/DCT.zip Laten Dirichlet Allocation (LDA) [21]: Clusters documents based Dirichlet Multinomial Mixture Model (DMM) [25]: Clusters doc-Topic Tracking Model (TTM) [10]: Clusters documents based on
LDA, DMM, TTM and our proposed DCT use the same retrieval model, i.e., Eq.(13), to compute the relevant scores for the docu-ments; they only differ in the way they perform clustering. For all methods including the vanilla LM, we define the probability of a term given a document and a point in time as P ML ( v | t,d ) = P rate of the recency decay and t d is the creation time of document d . In the remainder of this paper we refer to the cluster-based retrieval models with the name of the clustering method they employ, that is, LDA, DMM, TTM and DCT.

The evaluation metrics used to assess the performance of the ranking algorithms are the ones widely used in TREC 2011 X 2015 Microblog tracks [16]: NDCG [12], MAP [5], Recall, R-prec, and P@k (Precision at k ) [5]. R-Prec is the precision after R documents have been retrieved, where R is the total number of relevant doc-ument for the query. We set k to 30 to align with the cut-off used in the TREC Microblog tracks [16]. The statistical significance of the observed differences between the performance of two ranking algorithms across the 107 queries is tested using a two-tailed paired t-test and is denoted using N (or H ) for  X  = . 01 , and M  X  = . 05 .

Experiments are run as follows: First, we obtain the top-k docu-ments, d t , in response to a user X  X  query using a vanilla query likeli-hood model at time t . In our experiments we used k = 500 , but we experimented with other values for k ; for any k &gt; 100 the results of our experiments remained stable. For cluster-based retrieval, topics are then inferred over the documents in d t , and (a) documents are re-ranked based on the cluster-based query likelihood model, and rankings are evaluated on the basis of different information retrieval metrics, and (b) we calculate the likelihood of observing these doc-uments in the collection on the basis of the underlying generative model. We use a 60/30/10 split of our collection for training, val-idation and testing, respectively. We train the vanilla LM, LDA, DMM, TTM, and DCT for different values of the parameters  X  , and  X  in Eq. (13);  X  varies from 0 to 1.0 and  X  from 0 to 1000. The optimal  X  and  X  values are decided based on the validation set, and evaluated on the test set. The training/validation/test splits are permuted until all 107 queries have been chosen once for the test set. We repeat the experiments 10 times and report the average evaluation measures.
We start by comparing the retrieval performance of DCT with the rest of the methods in Section 5.3 (RQ1) , and the persistence of the performance across queries (RQ2) . We then analyse the effect of Table 2: Mean performance over the five test cutoff days. The best performance per metric is in boldface. Statistically signifi-cant differences between DCT and the best baseline, TTM, are marked in the upper right-hand corner of DCT X  X  performance scores.
 various parameters in our model: the dependency length (RQ3) , the mixture parameter  X  (RQ4) , and the predefined number of topics (RQ5) . Last, we test the generalisability of the proposed generative model in terms of perplexity (RQ6) . RQ1 : We compare the ranking performance of the short term DCT cluster-based retrieval model with the rest of the methods in Section 5.3.

Table 2 reports the performance averaged across all five testing time cutoffs. The ranking of models with respect to the retrieval performance is consistent across the different evaluation measures, and in particular the following order is observed: DCT &gt; TTM &gt; DMM &gt; TMS  X  LDA &gt; LM. Here &gt; denotes statistically sig-nificantly better performance at a significance level of 99%, and  X  denotes statistically significantly better performance at a signif-icance level of 95%. To get a better insight on the persistence of the results across the five testing time cutoffs, we compare the per-formance of the six algorithms on a per cutoff basis. We visualise the results in Fig. 2 in terms of five heat maps, one per metric, so that the relative performance per model and per time cutoff can be observed, by examining the intense of the color (dark blue trans-lates to high measure values, and light blue to low measure val-ues). The five heat maps lead to the exact same findings per time cutoff to those when the average values were considered: in most cases, DCT statistically significantly outperforms TTM, which is followed by DMM, TMS, LDA, and LM.

The finding DCT &gt; TTM in both Table 2 and Fig. 2 illustrates that the way we track the changes of topics specific to a query in DCT works better than the way it is done by TTM which focuses on long documents. The finding DCT &gt; DMM illustrates that DCT integrates time information better in the inference of topics distri-bution at time t compared to DMM, which ignores time informa-tion. An interesting observation in Fig. 2 is that as time progresses, the performance of both DCT and all other baselines slightly de-creases due to the fact that more and new intents underlying a given query appear and make the retrieval task more challenging. Instead the performance of DCT remains stable across all the test time cut-offs.
RQ2: We take an in-depth view of the improvements of DCT performance over the best baseline (TTM) on a per query basis.
Fig. 3 shows the per query performance differences in terms of all the metrics, averaged across all the test days. The number of queries on which DCT outperforms TTM is larger than the number of queries on which TTM outperforms DCT, for every metric. Fur-ther, the positive differences of DCT against TTM are larger than the negative differences in most case. Both of these findings fur-ther support the conclusion that DCT can effectively capture the topic distribution at a given time and query for clustering short documents in streams compared to state-of-the-art dynamic or non-dynamic clustering topic models for long or short text documents. There are only very few cases in which DCT performs worse than TTM.
RQ3: We compare the short-term DCT with the long-term DCT (DCT-L with L being the length of dependency under considera-tion). We vary the length of dependency from 1 to 8 time-steps.
Fig. 4 shows the performance on the metrics, averaged across the five test cutoff days. It is clear from the figure that the longer the de-pendences captured by the model the better the performance of the ranking algorithm. This is especially true for L = 1 ,..., 4 , while after that the performance reaches a plato. This illustrates that our DCT model can enhance the performance of clustering when past distribution information is integrated in the model.
 In the remaining of the analysis we will focus on the short term DCT model so that we can study the performance of our dynamic topic model independently of the length of the dependency. The performance of DCT-L is at least as good as the performance of the short-term DCT.
RQ4: We vary  X  in Eq. (13) and measure the average perfor-mance of our model to analyze the contribution of clustering ingre-dient in the cluster-based retrieval model.

Fig. 5 depicts the performance on all metrics. For  X  = 0 , the performance of DCT and the rest of the methods is identical with the time-sensitive language model (LM) performance, as expected. As  X  increases from 0 to 0 . 6 , giving more weight to the cluster terms, the performance of all cluster-based methods improves, with the DCT clusters providing more relevant to the query terms. This leads to a faster improvement of DCT compared to the rest of the methods (TTM, DMM, and LDA), which demonstrates the homo-geneity of clusters on the query topic. The performance of all al-gorithms drops as expected when larger weights are given to the cluster terms. However, even when the query is completely ig-nored (  X  = 1 ) the DCT clusters continue to provide good on-topic terms outperforming the language model method in the task of re-ranking. Again, these findings strengthen our conclusion that in-tegrating high quality clustering information, as provided by our dynamic clustering model, can enhance the performance of ad-hoc retrieval in short document streams.
RQ5: We examine the effect of the number of latent topics passed as an input parameter to DCT and the rest of the clustering models on the overall retrieval performance. We vary the number of latent topics from 2 to 16 for each query, and compare the per-formance in terms of all the metrics, averaged across all five test cutoff days.

As illustrated by Fig. 6 when only two latent topics are mod-eled, the four clustering models yields almost the same perfor-mance; if the number of available topics to be inferred is small DCT does not offer any improvements compared to other methods. With the number of latent topics increasing to 4 and 8, the posi-tive performance differences between DCT and baseline methods also increases. When the number of latent topics further increases (e.g. between 8 to 16), the performance of all the clustering models reaches a plato. This also demonstrates the merit of the proposed DCT model: it is robust and insensitive to the number of latent top-ics and once enough latent topics are used it is able to improve the performance of the cluster-based retrieval model and work better than the state-of-the-art dynamic and non-dynamic clustering mod-els in short document streams.
RQ6: Last, we evaluate the performance of DCT and the base-line models in terms of perplexity, which is widely used as an eval-uation metric in previous topic modeling work [2, 3]. The perplex-ity used in language modeling, is monotonically decreasing with the likelihood of the documents, and is algebraically equivalent to the inverse of the geometric mean per-word likelihood. The per-plexity [3] that is widely used to evaluate the generalization per-formance of many topic models is computed as Perplexity ( d exp  X  lower perplexity score indicates better generalization performance. Fig. 7 shows the mean perplexity performance of DCT and the baseline models, over the five test cutoff days with the number of latent topics ranging between 2 and 16 for each query. As it can be observed, DCT consistently performs better than the rest of the models, with the performance flattening out when the number of topics is equal or more than 8.
Clustering technologies have been widely used in a number of text related applications including information retrieval, and sum-marization. In this work we studied the problem of clustering short document streams, and proposed a new dynamic Dirichlet multi-nomial mixture clustering topic model, DCT, to effectively handle both the textual sparsity of short documents, and the dynamic na-ture of topics across time. The proposed clustering model can cap-ture short-term and long-term trends in topics. We evaluated the performance of the proposed model in terms of retrieval effective-ness. We conducted experiments over a Twitter streaming dataset, which was manually labeled. To allow possible drifts in the query intent across time we did not provide any static query intent de-scription to the assessors. We compared the performance of the proposed model with a state-of-the-art dynamic topic model that in-fers clusters in the context of long documents, a static topic model that infers clusters in static short document sets, a state-of-the-art time-aware microblog search model, an LDA topic model, and a time-sensitive language model. Our experimental results demon-strate the effectiveness of the proposed dynamic clustering model.
As future work we intent to automatically estimate the (dynamic) number of topics in our clustering model in the context of short document streams, and use the proposed model to improve the per-formance of other text-related applications such as tweet summa-rization, sentiment analysis, and query suggestion in the context of short document streams.
 Acknowledgments. We thank Prof. W. Bruce Croft and Stephen M. Harding at the University of Massachusetts, Amherst for help-ful discussion and preprocessing the dataset, respectively. This re-search was partially supported by the UCL Big Data Institute and Elsevier. Figur e 7: Mean perplexity of DCT and state-of-the-art topic models
