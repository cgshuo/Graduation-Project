 The concern of privacy has become an important issue for online social networks. In services such as Foursquare.com, whether a person likes an article is considered private and therefore not disclosed; only the aggregative statistics of articles (i.e., how many people like this article) is revealed. This paper tries to answer a question: can we predict the opinion holder in a heterogeneous social network without any labeled data? This question can be generalized to a link prediction with aggregative statistics problem. This paper devises a novel unsupervised framework to solve this problem, including two main components: (1) a three-layer factor graph model and three types of potential functions; (2) a ranked-margin learning and inference algorithm. Finally, we evaluate our method on four diverse prediction scenarios using four datasets : preference (Foursquare), repost (Twitter), response (Plurk), and citation (DBLP). We further exploit nine unsupervised models to solve this problem as baselines. Our approach not only wins out in all scenarios, but on the average achieves 9. 90 % AUC and 12 .59 % NDCG improvement over the best competitors. The resources are available at http://www.csie.ntu.edu.tw/~d97944007/aggregative/ H.2.8 [ Database Management ]: Database applications  X  Data mining ; E.2 [ Data ]: Data Storage Representations  X  Linked representations ; J.4 [ Computer Applications ]: Social and Behavioral Sciences  X  Sociology . Link prediction; Social network mining; Heterogeneous social network; Probabilistic graphical model Most of the social network services allow users to express their opinions (e.g.,  X  like  X  or  X  +1  X  ) to messages posted by other people. Such individual opinions are usually valuable: companies can identify a specific customer  X  s preference, and government can recognize the will or desire of target influential person. However, due to privacy concern, opinion holders are sometimes concealed. An example is Foursquare.com, a popular location-based social network websites. In Foursquare, users can post tips to certain venues of their interest, and other people may  X  like  X  the tips. Nevertheless, the information about which user likes which tip is generally not available to public due to the privacy concern. Another example is Pinterest.com, which is a pinboard-style photo sharing website. In Pinterest, users can  X  like  X  or  X  repin  X  other s X  images, but only a little portion of such information is available due to internal limitation of Pinterest (only first 24 difficult to gather a full spectrum of information about each individual  X  s opinion under such circumstances. Fortunately, aggregative statistics of opinions are usually available. For example, the total count of  X  like  X  of each tip in Foursquare is accessible, and the total count of  X  like  X  and  X  repin  X  of an image in Pinterest is also obtainable. Such aggregative statistics are important because it is usually the only available clue to understand the quality of certain item without violating the policy rule . Hence, this paper tries to address a problem: can we predict a link between a user and an item (e.g., whether a user likes a tip) using the aggregative statistics together with other information in a heterogeneous social network? We generalize the question to an unseen-type link prediction with aggregative statistics problem. The term unseen is used because we assume it is not possible to obtain which person likes which tip from data (therefore, such  X  like  X  link can be regarded as a kind of relationship that is previously unseen). From link prediction point of view, one can assume there is no labeled training data available of such type of links. An example we use through this paper is a network gathered from Foursquare (Figure 1). There are 7 nodes and 7 links wit h 3 node types (users, items, and categories) and 3 lin k types (be -friend-of, own, and belong -to). W e want to predict the existence of  X  like  X  links (e.g., whether user u 2 likes item r 2 or not) using the aggregative statistics (e.g., total like count of the item r 1). Note that the links of  X  like  X  type is unseen, which means we do not see such link at all in the data. Most of the link prediction literatures aim at predicting links of seen types (i.e., some labeled historical links are observable as the training data) [ 18 , 20 , 33 ], thus cannot be applied to our problem. Some researchers predict links of unseen types using external node group information [ 15 ], but those information are not always available. As in the Foursquare example, the only available information in our problem is the aggregative statistics. Nevertheless, our problem is non-trivial due to the following three challenges: 
Figure 1 . The unseen-type link prediction with aggregative  X  Lack of labeled data . The absence of labeled training data  X  Diverse information . In a heterogeneous social network, the  X  Sparsity of links . Since the type is unseen, presumably the In this paper, we try to address these challenges by proposing a novel unsupervised probabilistic graphical model. First, we devise a factor graph model with three layers of random variables (candidate, attribute, and count) to infer the existence of unseen-type links. Second, we define three types of potential functions (attribute-to -candidate, candidate-to -candidate, and candidate -to -count) to integrate diverse information into the factor graph model. Third, we design a ranked-margin learning algorithm to automatically tune the parameters using aggregative statistics. Finally, we design a two-stage inference algorithm to update the candidate-to -count potential functions, and optimize the outputs. The main contributions of this study are as below:  X  We propose and formulate a novel yet practical problem to  X  We devise an unsupervised learning framework to solve the  X  We evaluate our method on four diverse scenarios using We start by formulating the proble m.
 Definition 1. Heterogeneous social network N = ( V, E,  X  is a directed graph, where V is a set of nodes,  X  V is a set of node labels,  X  E is a set of link labels, and E  X  V X   X  links.
 The function type(v)  X  l V maps node v onto its node label l the function type(e)  X  l E maps link e onto its link label l For the example shown in Figure 1, there are 7 nodes and 7 links, with  X  V = {  X  user  X ,  X  item  X ,  X  category  X  } and  X  of  X ,  X  own  X ,  X  belong-to  X  } . For brevity, we denote U  X  V as the set of node for type =  X  user  X , R  X  V for type =  X  item  X , and C  X  V for type =  X  category  X  . The relationship between node labels and link labels can be enumerated. For instance, a user u may  X  be-friend-of  X  another (i.e., &lt; r ,  X  belong-to  X  , c &gt;). It should be noted that the number of items, | R |, is equivalent to the total number of  X  own  X  links, and is also equivalent to the total number of  X  belong-to  X  links (i.e., each item can only be owned by one user, and can only belong to one category). Definition 2. Unseen-type links is a set of links with a special typ e  X  ?  X  ; links of such type do not appear in a given heterogeneous social network. That is, unseen-type links  X  = {  X  |  X  = &lt; source,  X  ?  X  , target &gt;, type(source)  X   X   X  ?  X   X   X  E } .
 For the example in Figure 1 , the unseen-type links denote the plausible candidate pairs in Figure 1. Definition 3. Aggregative statistic is the total unseen-type link count of a target node . In other words, the aggregative statistic of target = v } |, which is a non-negative integer. In our example, the aggregative statistic of an item r 2  X  ) = | {  X  |  X  = &lt; u ,  X  like  X  , r &gt;  X   X  , r = r Definition 4. Aggregative statistics of a heterogeneous social aggregative statistic s of the unseen links for a heterogeneous social network N. In Figure 1, the aggregative statistics of heterogeneous social network N is T ( N ,  X  ) = { &lt; r 1 , 2 &gt;, &lt; r Based on above definitions, we formulate the unseen-type link prediction with aggregative statistics problem as follows: given a heterogeneous social network N and corresponding aggregative statistics T(N ,  X  ), predict the existence of unseen-type links  X  . The relational schema for our example is shown in Figure 2: given the heterogeneous social network (3 types of nodes and 3 types of edges) and aggregative statistics of  X  like  X  , predict whether each &lt; u ,  X  like  X  , r &gt; exists or not, where u  X  U and r  X  R . Figure 2. Relational schema of the unseen-type link prediction We first propose to solve this problem using a probabilistic model . Then, we use an illustrative example to demonstrate our model. Finally, we describe a novel learning algorithm utilizing the aggregative statistics to learn the model parameters, as well as a two-stage inference algorithm to predict unseen-type links. To handle this problem, we propose a novel probabilistic graphical model: factor graph model with aggregative statistics (FGM-AS), as shown in Figure 3. There are three layers of variables in FGM-AS:  X  Candidate: the binary random variables Y in the candidate  X  Attribute: the random variables A in the attribute layer carry  X  Count : the random variables T in the count layer encode the Together with the random variables, we also propose three types of potential functions:  X  Attribute-to -candidate functions : w e define this type of  X  Candidate-to -candidate functions: this type of potential  X  Candidate-to -count functions: this type of potential function According to the FGM-AS model, when the candidates, attributes and counts are known, we can define the joint distribution as Therefore, the marginal probability of candidate random variable y being positive (e.g., like ) is The marginal probability P ( A , T , Y , y i = 1) is the desired output in We believe that FGM-AS is a general graphical model for solving the unseen-type links prediction problem. The three layers of random variables and the three types of potential functions can be flexibly defined for different application context. Here we use FGM-AS to predict whether a user likes an item or not. Figure 4 illustrates an example of FGM-AS, which is built from the heterogeneous social network shown in Figure 1. The three layers of random variables are defined as: Figure 4 . An example of FGM-AS based on Figure 1's network.  X  Candidate: candidate random variables Y = { y i | i = 1, 2, ... ,  X  Attribute: attribute random variables A = U  X  R  X  C contain  X  Count: count random variables T = { t 1 , t 2 , ... , t The design of the three potential functions is described in the following three subsections. According to Equation (1), we define f  X  ( A , y i f ( u ( y i ), r ( y i )), f CP ( c ( y i )) &gt;. The functions f on user friendship, item ownership, and category popularity , which are defined below:  X  User friendship (UF) function: f UF ( u ( y i )) = the number of  X  Item ownership (IO) function: f IO ( u ( y i ), r ( y  X  Category popularity (CP) function: f CP ( c ( y i )) = the number According to Equation (2), we define g X  ( Y , y i ) = &lt;  X  g g , g FI , g OF and g CC are based on owner, friend, owner-friend, and co-category relationships, which are defined as follows:  X  Owner-identification (OI ) function : g OI ( y i , y  X  Friend-identification (FI) function : g FI ( y i , y  X  Owner-friend (OF) function: g OF ( y i , y j ) = 1 if &lt; u ( y  X  Co -category (CC) function : g CC ( y i , y j ) = 1 if &lt; u ( y According to Equation (3), we define h  X  ( T , y i ) = &lt; h The functi on h CT is defined as: The summation term in Equation (6) sums up all the probabilities of a certain item r ( y i ) being liked by each user, which we hope to Thus, the difference of this term and t ( y i ) represents how close the prediction to the known aggregative statistics is. We divide this difference by | U | for normalization purpose. Ideally, the difference is 0, and thus h CT ( y i , t ( y i )) = 1. Also, 0  X  h It should be noted that P(A, T, Y, y j = 1) are not random variables anymore but the posterior probability of them . Therefore, the conventional exact or approximated inference methods cannot be applied directly. To update accordingly, we design a two-stage inference algorithm, which is described at the end of section 3.3. The key factor that contributes to the success of FGM-AS lies in the algorithm X  X  capability of learning the parameters without labeled data. Here we discuss the main idea. Given a parameter joint probability P ( A , T , Y ) can be written as where all potential functions for a y i is written as s ( y g X  ( Y , y i ), h X  ( T, y i ) &gt;, Z = Z  X  Z  X  Z  X  , and S =  X  Now, we will discuss how to learn the parameters of the model. Traditionally the idea of maximum-likelihood estimation (MLE) can be exploited and algorithms such as EM can be applied to achieve this goal. Alternatively for a factor graph, algorithms such as gradient decent can be exploited to greedily search in the parameter space. However, in our scenario, the absence of labels eliminates the possibility of exploiting MLE strategy for learning. Moreover, even if one can somehow come up with certain approximated objective to be maximized in the M-step of EM, the which can lead to very high computational cost for parameter learning. To effectively and efficiently perform the learning task, we propose a novel idea to maximize the ranked-margin of the instances, incorporating the aggregative statistics into the objective function. The intuition is to assume the count for an only t ( y i ) of them like this object. Therefore, during learning we want to adjust the parameter so that while the rest have very low probabilities of liking it. To realize this idea, we propose to do the following. For each item r , first rank each user u i based on the marginal probability of y = &lt; u Then, let P(Y r upper ) be the average positive margin al probabilities for the top t ( y i ) th candidate pairs, and P(Y margin al probabilities for the rest of the candidate pairs, for all y parameters to maximize An extreme example is that the marginal probability of the top t ( y candidate pairs are all 1, while the rest are all 0. In this case Diff (Y r margin ) = 1  X  0 = 1. Another extreme example is the opposite, which results in Diff (Y r margin ) = -1. Thus, -1  X  Diff (Y Based on the above idea and Equation (8), we define the log-likelihood objective function to be maximized as Besides the intuitiveness of Equation (8) with respect to the count as mentioned, there are two other advantages of using Equation (9) as our objective function. First, it should be noted that computing the normalization factor Z in Equation (7) is very time-consuming . However, for Equation (9), we can essentially eliminate Z to avoid the high computa tional cost during learning. Second, the gradient of Equation (9) can be obtained through sampling using any inference algorithm (as shown below). To maximize the objective function, we exploit an idea similar to the Stochastic Gradient Descent (SGD) method, as shown in Algorithm 1. We calculate the gradient and update the parameters for each item iteratively until convergence, then move on to the next item (  X  is the learning rate of our algorithm). The gradient for each parameter  X  and item r is where The value of S can be obtained naturally using approximated inference algorithms, such as Gibbs Sampling or Contrastive Divergence. It should be noted that the proposed ranked-margin algorithm can be exploited not just for graphical model, but also for other learning models as long as the gradient of the expected difference can be calculated. In Algorithm 1, we need to perform an inference algorithm on the factor graph, to obtain the marginal probability of each candidate pair y . Also, after the parameters are learned, we need to apply the inference algorithm again to compute the marginal probability, representing how likely the person likes the item. Unfortunately, such inference cannot directly be done as P(A , T , Y , y Equation (6) requires the posterior probabilities of y . Input: FGM -AS, learning rate  X  Thus, we design a two-stage inference algorithm (Algorithm 2). In the first stage, we perform general inference method using f ( A , y Y , y i = 1). In the second stage, we compute h ( T , y y = 1), and then perform inference one more time. This way, we integrate the posterior information into the inference process. Here we want to verify the generalization of our model by testing whether it can be applied to datasets in four different scenarios. We also want to verify the usefulness of the potential function s. We study the following four types of scenarios of the unseen-type link prediction problem, each with a real-world dataset. The statistics of the datasets are shown in Table 1.  X  Preference prediction . In location-based social network  X  Repost prediction . In social network websites, we are  X  Response prediction . In micro-blog services, we are Table 2 . Mapping of the random variables for the datasets  X  Citation prediction . In academic indexing and searching The mapping of the information in the four abovementioned datasets to the random variables in FGM-AS is shown in Table 2. Note that in the above four datasets (Foursquare, Twitter, Plurk, and DBLP), we hide all unseen-link information as ground truth to evaluate our proposed framework. Also note that we obfuscate personal information in all of the datasets. It should be noted that the unseen-type link s used as ground truth are actually sparse comparing to all nodes and relations. For example, in Twitter dataset, the unseen-to -candidate ratio, unseen-type links for these datasets is a very challenging task. We use nine unsupervised model for comparison. The first three methods are single attribute-to -candidate functions: UF , IO, a nd CP. Another six methods are as follows (note that all methods are executed on the whole heterogeneous social network):  X  Betweenness Centrality (BC) . This method is used to  X  Jaccard Coefficient (JC) . This method is used to directly  X  Preferential Attachment (PA ) . This method bases on an  X  Attractiveness (AT) . This method is designed to compute  X  PageRank with Priors (PRP) . This method executes  X  AT -PRP . We combine the Attractiveness and PageRank with Because of the sparsity of unseen-links in ground-truth, we use Area Under ROC Curve (AUC) [ 5] [ 19 ] and Normalized Discounted Cumulative Gain (NDCG) [ 10 ] to evaluate our proposed method. For each item, we rank all the candidate pairs based on their predicted positive marginal probabilities, and then compare the rankings with the ground-truths to obtain AUC and NDCG scores. Finally, we average the scores over all items. We select Loopy Belief Propagation (LBP) as our base inference method [ 23 ], utilize MALLET [ 21 ] for LBP inference, and apply LingPipe [ 1] for stemming. We use JUNG [ 22 ] to compute betweenness centrality and PageRank with Priors algorithms. 
Table 3 . Experiment results of our framework (FGM-AS) and In FGM-AS, we set all zero potential function values to a small constant (0.000001), and use learning rate  X  = 0.0001. We run all experiments on a Linux server with AMD Opteron 2350 2.0GHz Quad-core CPU and 32GB memory. The results of different methods using AUC and NDCG are shown in Table 3. The LEARN method is to exploit Algorithm 1 to perform learning and Algorithm 2 for inference, while INFER is to exploit Algorithm 2 for inference without learning. In all cases, LEARN performs best. Note that INFER outperforms all baselines, and LEARN provides further improvement than INFER. Averaging over the four datasets, our framework (LEARN) are 9. 90 % AUC and 12 .59 % NDCG better than the best comparing methods . LEARN achieves best result for Foursquare dataset, with improvement of 16 .04 % in AUC and 28 .84 % in NDCG. From Table 3, we see that the performance distinction between the three attribute-to -candidate functions, UF, IO, and CP, varies depending on the dataset used. We believe that these three functions are complementary to each other, and can be ensembled to contribute to our integrated framework. BC does not work well in all experiments, JC performs well for Twitter in terms of NDCG, and PA performs well for DBLP in terms of AUC. On the other hand, AT is in general the strongest comparing method (performs best among comparing methods in both metrics for all four datasets ); PRP in general does not perform well; AT-PRP ranks just between AT and PRP. Our framework consistently outperforms these comparing methods significantly. Based on the above experiment results, we believe our framework can be a general method to solve the unseen-type link prediction problem. In the previous subsection, we evaluate the attribute-to -candidate functions and compare them to our proposed framework. However, the candidate-to -candidate functions cannot be evaluated independently (i.e., without attribute-to -candidate functions). Therefore, we verify the feasibility of the four functions, namely OI, FI, OF, and CC, by performing a simple analysis in our datasets. First, we set all  X  own  X  links as  X  like  X  links. As shown in Figure 1, we set &lt; u 1 ,  X  like  X  , r 1 &gt;, &lt; u r &gt;, as positive prediction. Then, we apply the above four candidate-to -candidate functions to extend the predicted links. For example, considering OF function, there will be a link between &lt; u 1 ,  X  like  X  , r 2 &gt; and &lt; u predict &lt; u 2 ,  X  like  X  , r 2 &gt; as positive based on OF. We compare the result of candidate-to -candidate functions using precision and recall with the unseen-type links in ground-truth, as shown in Table 4. We also ensemble the four functions and examine the effectiveness of the combination (the All row). All of the candidate-to -candidate functions has low precision (less than 4%), but have some extend of recall (especially All ). For Foursquare and DBLP datasets, the recall of All reaches as high as 95.00% and 94.66%, respectively. It should be noted that O I performs bad for Twitter, Plurk and DBLP datasets, but provides some improvement for Foursquare dataset. On the other hand, FI seems to be of little use for Twitter dataset, but it does provide information for other three datasets. Therefore, we regard these four candidate-to -candidate functions as complementary to each other, and can be ensembled to contribute to our framework. In this section, we discuss some of works related to unsupervised unseen-link prediction framework using aggregative statistics. Our problem is effectively link prediction in heterogeneous social network. Link prediction is a well-studied task in social network analysis, and is characterized by graph topology, testing how proximal nodes are to each other [ 18 ]. Many features have been tested and developed for homogeneous network, using different graph topological properties [ 20 ]. However, such approaches do not consider the sparsity and diversity of heterogeneous social network. Feature design for heterogeneous social network was recently explored [ 33 ], casting as a supervised learning task [ 14 ]. One area of research interest is to predict actual popularity of a microblog (e.g., tweet) in a social media. In this case, the task is formulated as a supervised learning problem, where it can be binary (e.g., whether a tweet will be retweeted or not) or multi-class (e.g., assign the prediction of how a tweet will be retweeted by popularity category) classification problem [ 8] [ 24 ]. Another approach applies probabilistic model on social media response prediction [ 35]. This work essentially incorporates collaborative filtering accounting user and item (i.e., tweets) features, but still require training data . Another related area is to predict the link from user to venue (i.e., point of interest recommendation) using geographic information [ 34 ]. However, such method fails to utilize effects of information propagation in social network. Regarding unsupervised link prediction, there have been works such as cold-start link prediction [ 15 ], transfer learning [ 6], and triad census [ 4]. They are fundamentally different from this work. Cold-start link prediction requires category information, and works only on homogeneous network. Transfer learning assumes another domain of labeled data is available. Triad census do es not consider the aggregative statistics information in the networks. Pure unsupervised heterogeneous social network link prediction explores different context of the data by examining probabilistically the topological features of the reweighed path [ 3] [33 ]. However, these works usually predict links between two entities of the same type, holding the underlying assumption that birds of a feather flock together. Our work tries to predict links between two different types (usually users and items) where such assumption is not likely to hold. Factor graph [ 11 ] is a unified framework for general probabilistic graphical models. Recently, factor graphs have been widely adopted to resolve various problems [ 9] [ 25 ] [ 29 ] [ 30 ]. Among these applications, factor graphs are suitable for social relationship prediction tasks. [ 29 ] proposed a time-constrained unsupervised probabilistic factor graph (TPFG) to model the advisor-advisee relationship using time information. Triad Factor Graph (TriFG) model [ 9] incorporates the factor graph representations and social theories over triads into a semi-supervised model. [ 25 ] investigates the relationship prediction problem on heterogeneous social networks. Previous attempts are extended and integrated into a transfer-based factor graph (TranFG) model. However, these methods either need additional external information or do not consider the aggregation of statistics during computation. Several margin-based learning methods on probabilistic graphical models ha ve been proposed. Previous methods require the ground-truth labels to figure out the proper direction of parameter update. For example, [ 27 ] formulates the parameter fitting problem as a quadratic program and performs Sequential Minimal Optimization (SMO) learning to solve the problem. For max-margin methods solving similar problems such as structural support vector machines [ 28 ], the ground-truth is also needed to fit these models. However, in our problem, it is the aggregative statistics instead of the ground-truth labels that are given. Therefore, our framework maximizes the ranked -margin instead of traditional margin. Mining on social networks using incomplete information has gained its own value due to its applicability, as in the real world we cannot always expect all the information to be observable. In this paper, we demonstrate that the unseen-type link prediction can be solved using an unsupervised framework through exploiting the aggregative statistics. We show ed how various information sources in the heterogeneous social network can be modeled all together in a factor graph, propose a novel learning algorithm to learn the parameters using aggregated counts, and devise an inference algorithm to predict unseen-type links using learnt parameters. Wi th such framework, one can now derive hypotheses on the individual behavior using the group statistics . Especially, under the growing concern of personal privacy preservation, we believe our framework provides a means for applications that tries to distill personal preference informati on from the statistics. On the other hand, in the area of biomedicine, our framework can be applied to identify novel protein-disease relationships, given clinical aggregat ed observations. Future work includes extending the current ranked-margin learning framework to other types of models such as discriminant classification and clustering. Also, for some networks (e.g., Foursquare), the very small amount of observable links may be utilized to extend our framework to a semi-supervised setting to further improve the prediction accuracy. Our framework can also be applied to more application scenarios and networks. Next , temporal information may be considered, which further empowers our framework to deal with dynamic networks. Finally, our work may also be extended to predict positive / negative links (e.g., applying methods described in [ 16 ]) using aggregative statistics. We thank Dr. Mi-Yen Yeh for fruitful discussions. This work is supported by National Science Council, National Taiwan University and Intel Corporation under Grants NSC 101-2911-I-002 -001, NSC 101-2628-E-002-028-MY2 and NTU 102R7501. 
