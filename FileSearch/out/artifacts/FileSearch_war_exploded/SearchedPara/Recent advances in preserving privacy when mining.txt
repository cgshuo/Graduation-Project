 1. Introduction
Modern information and communication technologies enable service providers to observe and record an individual X  X  daily actions with relative ease. Given the ability to construct detailed collections of person-spe-cific information, service providers hope to mine for patterns, models, and trends that will assist in the provision of knowledge-dependent services in various environments, including e-business, e-commerce, e-gov-ernment, and e-health. The potential societal benefits of data mining are substantial; however, the collected data often contains sensitive personal information. As a consequence, the application of data mining to person-specific records often raises significant concerns regarding citizens X  privacy, confidentiality, and freedom.

The integration of privacy-awareness into data mining endeavors is crucial to foster wide-spread adoption and social acceptance of emerging knowledge-based applications. Privacy protections must be supported by policy and legal frameworks, as well as technical assistance. The previous provides a precedent for privacy, whereas the latter provides an ability to enforce privacy-specific requirements. The study of data mining with respect to privacy constraints, has rapidly become a lively area of research in computer science [6,3,1,8] .In addition, major information technology corporations have allocated significant resources to study and devel-op products that address privacy concerns. As a result, the importance of privacy protection in data mining has captured the attention of many researchers and administrators across a large number of data-rich envi-ronments, such as biomedicine (e.g., electronic health records), the Internet (e.g., web usage logs), and wireless networks (e.g., mobility data from sensors).

Despite such recognition and efforts, there remain many open issues that deserve further investigation. One of today X  X  critical challenges is that there remains a lack of technology transfer in privacy preserving data min-ing technologies. This problem is due, in part, to the fact that privacy concerns and data mining endeavors vary across application domains. Nonetheless, privacy preserving data mining is a research area that is moving towards maturity, and forums, such as this special issue, provide an opportunity for the exchange of new ideas, developments, and discussion of privacy issues for data mining researchers. Through the presentation of specific achievements in privacy applications, we hope principles can be extracted and applied to real world environments on a broader scale. 2. Articles in the special issue This special issue features five articles that are extensions of papers presented at the Privacy Aspects of
Data Mining Workshop 1 held in Hong Kong in December 2006 in conjunction with the 6th IEEE Interna-tional Conference on Data Mining. The aim of the workshop was to gather researchers and practitioners interested in privacy aspects of data mining and have them present recent research developments. The work-shop received 29 high-quality paper submissions, and 11 of these papers were selected for presentation at the workshop, the proceedings of which were published by the IEEE Computer Society Press. After the presen-tations, and considering reviewers suggestions, we invited five of these papers for extension in this issue of
Data and Knowledge Engineering . As a summary of the issue, we provide a brief discussion about each paper.
 One mechanism for privacy protection is to disclose a  X  X  X erturbed X  X  version of a data holder X  X  records.
Before the data is released for data mining, noise from a known distribution is added. Given the distribu-tion of the noise and the perturbed data, a data miner can reconstruct an approximation of the original data distribution. This approach was sketched in one of the first papers on privacy preserving data mining by Agrawal and Srikant [1] , where data perturbation techniques were developed for decision tree classifi-cation. To date, data perturbation research has assumed every data subject has the same privacy require-ment; however, various investigations (e.g., [5] ) suggest that people have different concerns regarding their privacy. The first paper of this special issue,  X  X  The Applicability of the Perturbation Based Privacy Preserving
Data Mining for Real-world Data  X  X , by Liu, Kantarcioglu and Thuraisingham, proposes an individually adaptable perturbation model, which enables each data subject to specify a different level privacy. The authors demonstrate with experiments on both synthetic and real data sets that the new approach is effec-tive at satisfying personal privacy preferences while remaining efficient to build data mining models from perturbed data.

At times, data must be publicly published in its raw form, such that it is not encrypted and perturbed. In this case, a simple precaution is to  X  X  X nonymize X  X  it before the release. In previous work, it was shown that the removal the personally identifying information from data is insufficient for protecting anonymity Samarati and Sweeney [7] . To reconcile this problem, a basic privacy standard called k -anonymity was proposed for publishing data, such that each record X  X  person-specific identifiers (the combination of which is known as a  X  X  X uasi-identifier X  X ) were made equivalent to at least k 1 other records X  identifiers [7] . A common way to achieve k -anonymity is to  X  X  X eneralize X  X  identifiers (e.g., date of birth can be generalized to month of birth).
The second paper in this special issue,  X  X  Towards Optimal k-anonymization  X  X , by Li and Li, proposes several novel generalization schemes that are claimed to be more flexible than the existing approaches. Their exper-imental findings with data from the US Census Bureau indicate that their approaches produce k -anonymiza-tions with less generalization compared to prior models. They conclude that a  X  X  X ottom-up X  X  approach (i.e., proceeding from most-specific to least-specific values) for k -anonymization is preferable for small values of k and small number of quasi-identifying attributes.

The prior approaches are applicable when data can be disclosed beyond the control of the collecting institution. However, a different scenario manifests when the data is distributed across multiple sites that are legally prohibited from sharing their collections with each other, but hope to construct a data mining model that accounts for the complete set of records. In this special issue, there are two papers that address this scenario. The first of these two, and the third paper in this issue,  X  X  Privacy-Preserving Impu-tation of Missing Data  X  X , by Jagannathan and Wright, addresses the problem of handling, or reconstruct-ing, missing values, which is important for building accurate data mining models. The authors propose a cryptographic protocol based on decision tree imputation on horizontally partitioned databases (i.e., each data holder X  X  collection has the same attributes, but different records). The protocols assumes there are two data holders, and allows each data holder to compute missing values without sharing any information about their data. Neither the decision tree, nor the traversed path to either party are revealed. Two variants on the protocol are proposed that allow users to trade-off between privacy and efficiency requirements.

Secure multi-party computation (SMC) techniques, such as those leveraged in the previous paper, have been proposed as solutions to maintain privacy in various distributed data mining environments (e.g. [4] ).
The majority of SMC-based protocols are limited; however, in that they assume the data holders reside in a  X  X  X emi-honest X  X  environment. In such a world, the involved parties follow the protocol, but may leverage information exchanged during the protocol to learn more than is revealed at the completion of the protocol.
The semi-honest model is not always a proper characterization of data holder X  X  behavior in the real world, where the involved parties may deviate from the protocol. The second paper in this special issue that addresses distributed data, and the fourth paper in this special issue,  X  X  Transforming Semi-Honest Protocols to Ensure
Accountability  X  X , by Jiang, Clifton and Kantarc X og  X  lu, claims that SMC protocols with a malicious adversary model may have very high complexities, therefore they are, in their current form, not suitable for data mining applications. Instead, the authors propose what they call an  X  X  X ccountable computing (AC) framework X  X  that provably assigns liability for privacy to the responsible party. The authors devise a simple, efficient way of transforming a semi-honest two-party protocol into a protocol satisfying the AC-framework. Malicious behavior is detected via a verification phase of the transformed protocol discouraging the parties from cheat-ing. Though the proposed protocol does not prevent malicious behavior, it does discourage illicit behavior by guaranteeing its detection.

The first four papers consider privacy concerns at the record level; however, sensitive and confidential information may be mined from aggregate results (e.g., an implication that HIV-positive individuals tend to reside in a particular geographic region). In this case, the data mining models themselves pose a privacy breach. To account for this problem, information hiding approaches (e.g., [2] ) have been proposed. In this special issue, the final paper,  X  X  A MaxMin Approach for Hiding Frequent Itemsets  X  X , by Moustakides and Verykios, proposes a novel algorithmic approach to sanitize a disclosed collection of sensitive knowl-edge. In this study, the authors focus on association rules as the target data mining model. The proposed approach is based on a decision theoretic criterion for maximizing the minimum information gain and utilizes the border theory of frequent itemsets. Experimental results in the paper indicate that the pro-posed methodology is effective at hiding sensitive rules and is efficient in complexity compared to state of the art.

References
