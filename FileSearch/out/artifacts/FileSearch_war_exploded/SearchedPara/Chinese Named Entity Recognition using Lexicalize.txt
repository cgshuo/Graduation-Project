 Department of Linguistics, The University of Hong K ong This paper presents a lexicalized HMM-based approac h to Chinese named entity recognition (NER). To tackle t he problem of unknown words, we unify unknown word identificat ion and NER as a single tagging task on a sequence of known words. To do this, we first employ a known-word bigram-based model to segment a sentence into a sequence of known words, and then apply the uniformly lexicalized HMMs to assign each known word a proper hybrid tag that indicates its pattern in forming an entity and the category of the formed entity. Our s ystem is able to integrate both the internal formation patterns and the surrounding contextual clues for NER under the fram ework of HMMs. As a result, the performance of the system ca n be improved without losing its efficiency in training and tagging. We have tested our system using different public co rpora. The results show that lexicalized HMMs can substantiall y improve NER performance over standard HMMs. The results als o indicate that character-based tagging (viz. the tag ging based on pure single-character words) is comparable to and c an even outperform the relevant known-word based tagging wh en a lexicalization technique is applied. Chinese named entity recognition, lexicalized hidde n Markov models, known word tagging, character tagging. The goal of named entity recognition (NER) is to re cognize phrases in a document that indicate the names of pe rsons, organizations, locations, times or quantities. As a n important subtask of information extraction and text mining, NER has been attracting more and more attention in the NLP commu nity. It has now become a shared task of a number of conferences or projects, such as the Multilingual Entity Task (MET) at the M essage Understanding Conferences (MUCs), the language-inde pendent NER task at CoNLL-2002 and CoNLL-2003, and the 1999 DARPA-TIDES Information Extraction-Entity Recogniti on (IEER-99) technology evaluation project. Current research on NER has focused on machine lear ning approaches, including hidden Markov models (HMMs) [ 1][2][3], maximum entropy (ME) [4], transformation-based erro r-driven learning (TBL) [5], and support vector machines (SV Ms) [6]. In comparison with rule-based methods, machine-learnin g approaches are more adaptive and robust. However, i t is still a challenge for most of them to keep a balance betwee n capacity and computational cost [7]. While a HMM-based tagge r has proven to be very speedy in training and tagging [8 ], it usually achieves relatively lower tagging accuracy for it o nly takes into account the context of the category tags, and no co ntextual word information, which sometimes gives strong evidence for NER. On the contrary, some learning methods such as ME a nd SVMs are capable of combining much richer lexical inform ation in a straightforward way. However, they usually need muc h more time in training and tagging, which will become a s erious problem in processing a large amount of data or som e on-line applications like text mining. In order to address these problems, some recent work suggested the use of lexicalizatio n techniques to enhance the standard HMMs [8][9][10]. Their expe riments demonstrated that their systems could be improved w ithout increasing much computational cost in training and processing. Recently, a number of methods have been reported fo r Chinese NER. Sun et al. proposed a class-based language model approach to Chinese NER [11]. In their work, they used diffe rent models to identify different types of NEs in Chinese text, in cluding a character-based trigram for person , a word-based model for location and a more complicated model for organization . Further, in [12], Wu et al. modified the class-based language model approach by incorporating human knowledge, particul arly semantic information. Zhang et al. put forward a stochastic role model to recognize Chinese NEs [13]. In this work, they defined a set of roles about component tokens within a Chin ese NE and the relevant contexts. Their experiments showed tha t the role-based model was effective for different NEs. More r ecently, Chen et al. proposed a smoothing maximum entropy model for Chinese nominal entity tagging [14]. They suggested that simple semantic features extracted from a dictionary help improve the performance of the model in NER, especially when th e training data is not sufficient. Guo et al. presented a robust risk minimization (RRM) classification method to Chinese NER, which was able to incorporate the advantages of cha racter-based and word-based models [15]. Their experiments have also demonstrated that local Chinese characters, Chinese word segmentation information, the surrounding context a nd part-of-speech (POS) are the most informative features that have significant impacts on the performance of NER. Although much progress has been made in the literat ure, it is still a big challenge to develop a high-performance NER system for Chinese due to the language-specific issues in Chinese. Unlike other languages such as English and Spanish, there are no explicit delimiters to indicate word boundaries in a plain Chinese text. Word segmentation is therefore an essential s tep to many Chinese processing tasks. The second issue concerns unknown words in open-ended documents. Most current systems need a dictionary to guide their analysis. However, no dic tionary could be complete. While a predefined dictionary may cove r most words in use, there are many other words in open-en ded documents, such as proper nouns and domain-specific terms that cannot be exhaustively listed. On the other hand, u nknown word identification (UWI) is still a difficult problem f or unknown words are constructed freely and dynamically in Chi nese. Furthermore, it is not easy to explore word-interna l cues and contextual information for NER from an open set of unknown words. Finally, there is less exterior information in plain Chinese texts, such as capitalization in English to help id entify entity names and unknown words. In this paper, we propose a lexicalized HMM approac h to Chinese NER. In order to address the problem of unk nown words, we unify Chinese UWI and NER, and reformulate them as a single tagging process on a sequence of known words (viz. lexicon words that are listed in the system lexicon ). To do this, we develop a two-stage NER system for Chinese. Give n a sentence, a known word bigram model is first applie d to segment it into a meaningful sequence of known words. Then, a lexicalized HMM tagger is used to assign each known word a proper hybrid tag that indicates its pattern in for ming an entity and the category of the formed entity. In compariso n with previous methods, our system is able to explore thr ee types of features, i.e. entity-internal formation patterns, contextual word evidence and contextual category information, and c ombine them for NER under the framework of HMMs. As a consequen ce, the system X  X  performance can be improved without losing its efficiency in training and processing. The rest of this paper is organized as follows: In section 2, we discuss how to reformulate Chinese NER as a tagging problem on a sequence of known words. In section 3, we pres ent a bigram model for known word segmentation. In section 4, we describe in detail a lexicalized HMM-based tagger for Chinese N ER. We report in section 5 our experimental results and gi ve our conclusions on this work in section 6. In our work, we use the same named entity tag set a s defined in this task specifies twelve different types of NEs f or Chinese. These entity categories are further encoded using t welve different at http://www.nist.gov/speech/tests/ie-er/er_99/er_ 99.htm. abbreviated SGML tags. To show the different format ion rules between Chinese personal names and transliterated p ersonal names, we subdivide the class personal name (PER) into two groups, namely Chinese personal name (CPN) and transliterated personal name (TPN). In addition to NEs, our system will also assign each common word in the input sentence a pro per POS tag. For convenience, we adopt the Peking University POS tag-set, which contains 48 different POS tags [16]. In general, a named entity can be composed of one k nown word or several known words. In other words, a known wor d may present itself as an independent entity or a compon ent of an entity after NER. Similar to UWI [17], a known word w may take one of the following four patterns to present itself during NER: (1) w is an independent named entity; (2) w is the beginning component of a named entity; (3) w is at the middle of a named entity; (4) w is at the end of a named entity. In our work, we use four tags ISE , BOE , MOE and EOE to denote the above four patterns respectively. Other than common segmented words in a sentence, we consider known words to be the basic units or components wit hin a named entity, because: Firstly, any Chinese unknown word or entity name is actually a combination of known words if th e system dictionary covers all Chinese characters. It is the refore very convenient to handle word-internal clues for NER ba sed on known words. Secondly, tagging based on known words is more general and actually contains two major notions for NER: the character-level model and the common known-word mod el. In fact, the character-level model discussed in [18][1 9][20] is a special form of the known word model, in which the system dictionary only consists of single-character words. For this reason, we also refer to this model as pure single-characte r word model. Thirdly, UWI and NER can be unified as a single tag ging task on a sequence of known words. Moreover, a Chinese sent ence can be segmented into a sequence of known words with ac curacy using the known-word n-grams [17]. Obviously, a segmented named entity in a sentence c an be represented as a sequence of known words together w ith their pattern tags. For example, the segmented string  X   X  X  X  X  /  X  X  X  / X  ( wen1jia1bao3 zong3li3 , Premier Wen Jiabao ) is equivalent to  X  X  X  &lt;/ISE&gt; X . In other words, the boundary of an entity name wil l be determined if all its components are assigned a pro per pattern tag. At this point, the identification of NEs can be vie wed as a process of assigning each known word in the input a n appropriate pattern tag that indicates its position in an entit y. For example, a known word will be tagged with ISE if it is an independent entity name. Similarly, a known word will be labeled with BOE , MOE or EOE respectively if it is a beginning, middle or end component of a named entity. However, a full named entity task involves identify ing and classifying NEs in documents. To do this, we define a hybrid tag set by merging the category tags defined in section 2.1 and the pattern tags defined in section 2.2. In our work, a hybrid tag has a format as follows: P C t t  X  . Where, C t denotes the category tag of a named entity, and P t denotes the pattern tag of a known word within the named entity. Thus, a NE-tagged sentence can be fully reformulate d as a sequence of known words together with their hybrid tags. Given an entity name n w w w E L 2 1 = , it is normally tagged as standard format is represented as follows: Where, ) 1( n i w i  X   X  stands for a known word within the named this formulation, each known word in an entity shou ld have the same category tag as the entity. Figure 1 Representing a NE-tagged sentence as a seq uence of Figure 1 gives an example of different representati ons of NEs in the Chinese sentence  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X   X   X . Where, (a) is the original sentence, and the next three sequences, i.e. (b), (c) and (d), are re spectively the English translation, the transcription in Chinese P honetic Alphabet and the segmentation of known words for th is sentence. As can be seen from this figure, the standard NE ta gged string (f) can be equivalently converted to a sequence of know n words and their hybrid tags, as shown in (e). The goal of known word segmentation is to segment a sequence of characters into a meaningful sequence of known w ords. In a sense, known word segmentation is actually a proces s of disambiguation. In our system, we apply known word bigram language models to resolve word boundary ambiguitie s in known word segmentation. Given a Chinese character string multiple candidate known word sequences } { according to a given system lexicon. Known word big ram segmentation aims to find the most appropriate segm entation  X  = that maximizes the conditional probability which can be estimated from a segmented corpus usin g maximum likelihood estimation (MLE). It should be n oted that all unknown words in the training corpus must be de composed to a sequence of known words before counting known wor d bigrams. For simplicity, we employ the maximum match techniq ue [21] to perform this conversion. To resolve the issue of da ta sparseness in MLE, we apply the linear interpolation technique to smooth the estimated word bigram probabilities. At present, two types of lexicalization techniques are used to improve HMM-based taggers, i.e. the uniformly lexic alized HMMs [9] and the selectively lexicalized HMMs [8][1 0]. In view of the convenience in implementation, we employ the uniformly lexicalized models to perform the tagging of known words for Chinese NER. Given a sequence of known words n w w w W L 2 1 = , the task of the tagger for Chinese NER is to find an appropriat e sequence of hybrid tags n t tt T L 2 1  X  = that maximizes the conditional probability ) | ( W T P , namely Since the probability ) ( W P remains fixed for all candidate tag sequences, we can disregard it. Thus, we have a gen eral statistical model for Chinese NER as follows =  X  In theory, the general model in Equation (4) can pr ovide the tagging system with a powerful capacity of disambig uation. However, this general model is not computable in pr actice for it involves too many parameters. Generally, two types of approximations are employed to simplify the general model. The first approximation is based on the independent hypothesis used in standard HMMs: The appearance of current wo rd depends only on current tag i t during tagging, and the (a)  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X  (b) Chinese President Hu Jintao held talks with North 
Korean leader Kim Jong-Il (c) zhong1guo2 guo2jia1 zhu3xi2 hu2jin3tao1 tong2 bei3chao2xian3 ling3dao3ren2 jin1zheng4ri4 ju3xing2 hui4tan2. (d)  X  X  /  X  X  /  X  X  X  /  X  /  X  /  X  /  X  /  X  X  X  X  /  X  X  X  X  /  X  /  X  /  X  /  X  X  /  X  X  X  /  X  / ISE&gt;  X  X  X  &lt;/n-ISE&gt; &lt;CPN-BOE&gt;  X  &lt;/CPN-BOE&gt; &lt;CPN-MOE&gt;  X  &lt;/CPN-MOE&gt; &lt;CPN-EOE&gt;  X  &lt;/CPN-EOE&gt; &lt;p- X  X  X  &lt;/n-ISE&gt; &lt;CPN-BOE&gt;  X  &lt;/CPN-BOE&gt; &lt;CPN-MOE&gt;  X  &lt;/CPN X  X OE&gt; &lt;CPN-EOE&gt;  X  &lt;/CPN-EOE &lt;v-ISE&gt;  X  X  &lt;/vn&gt; &lt;w&gt;  X  &lt;/w&gt; assignment of current tag i t depends only on its previous K general model in Equation (4) can be rewritten as Where, ) | ( i i t w P denotes the so-called lexical probability; and of the problem of data sparseness, we use the first -order HMMs The second approximation follows the notion of the lexicalization technique, where two main hypotheses are made: The appearance of current word i w is assumed to depend not only on the current tag i t and the previous )1 1(  X   X   X  i I I tags depend both on its previous )1 1(  X   X   X  i K K words and )1 1(  X   X   X  i L L tags Equation (6) gives a general form of the uniformly lexicalized HMMs for Chinese NER. With a view to the issue of d ata sparseness, we set 0 = I and 1 = = = L K J . By comparison, the uniform lexicalization technique is able to handle richer contextual information for the assign ment of tags to known words, including both contextual words and co ntextual tags under the framework of HMMs. Consequently, the accuracy of the named entity recognizer can be improved with out losing its efficiency in training and tagging. If a large NE-tagged corpus is available, the param eters in Equation (5) and (6) can be easily estimated using the MLE technique. However, MLE will yield zero probabiliti es for any cases that are not observed in the training data. T o solve this problem, we employ the linear interpolation smoothi ng technique to smooth higher-order models with their relevant l ower-order models, or to smooth the lexicalized parameters usi ng the related non-lexicalized probabilities, namely  X   X   X  where  X  and  X  denote the interpolation coefficients. Based on the above models, the tagging algorithm ai ms at finding the most probable sequence of hybrid tags for a giv en sequence of known words. In our implementation, we employ th e classical Viterbi algorithm to perform this task, which works in three major steps as follows: (1) The generation of candidate tags: This step aim s to generate a lattice of candidate hybrid tags for a sequence of known words produced by the known word segmenter. As discussed above, a hybrid tag of a known word involves a category tag and a pattern tag. Given a known word, it may take one of the fou r patterns defined in Section 2.2 to present itself in a segme nted word or candidates. As for its category tag candidates, the y can be constructed by looking up the system dictionary and the lexical probability library. The candidate hybrid tags of a known word are a combination of its candidate category tags an d its candidate pattern tags. All these candidates are stored in a lattice structure. (2) The decoding of the best tag sequence: In this step, the well-known Viterbi algorithm is employed to score all ca ndidate tags with the proposed language models, and then search the best path through the lattice that has the maximal score . This path contains the best sequence of tags for the known wo rd string. (3) The conversion of the results: The direct outpu t of our tagger has the same format as shown in formula (1). For ev aluation purposes, we further convert it to the standard rep resentation by merging the consecutive known words into entities i n terms of their patterns. Our system may yield two types of inconsistent tagg ing, namely pattern inconsistency and class inconsistency. Pattern inconsistency arises when two adjacent know n words are assigned inconsistent pattern tags such as  X  X SE:MOE  X  or  X  X SE:EOE X . It has been shown that the inconsistent pattern tagging hardly exerts any influence on the results in word segmentation [20]. In practice, entity boundary det ection is very similar to word segmentation. This suggests by anal ogy that the inconsistency in pattern tagging has no effects on the identification of entity boundaries. For this reaso n, we do nothing to the inconsistent patterns during the result conv ersion. Category inconsistency means that two adjacent know n words are labeled with different category-tags while at the s ame time, they are assigned the pattern tags that indicate they sh ould appear in the same word or named entity. For example, the Chi nese personal name  X  X  X  X  (Zhang Xiaohua) might be inconsistently tagged as &lt;CPN-BOE&gt;  X  &lt;/CPN-BOE&gt;&lt;Vg-MOW&gt;  X  &lt;/Vg-MOW&gt;&lt;CPN-EOE&gt;  X  &lt;/CPN-EOE&gt;. In this case, the system cannot make its decision in choosing a category tag for the personal name  X  X  X  X  (Zhang Xiaohua). According to our intuition, the end component may be more informativ e in classifying Chinese NEs. Furthermore, few inconsist ent category-tags can occur in the results because they usually have lower probabilities, and will be accordingly blocked by t he decoder. Therefore, we resolve these inconsistent categories just by assuming the categories of ending components to be that of the relevant NEs or unknown words. To evaluate our approach, we conducted a number of experiments on our system using the public PFR corp us, the IEER-99 newswire data and the MET2 data. This secti on reports the results of these experiments. We evaluate our system in terms of recall (R), precision (P) and F-measure (F). Here, recall (R) is defined as the number of correctly recognized NEs divided by the total numbe r of NEs in the manually annotated corpus, and precision (P) is defined as the number of correctly recognized NEs divided by t he total number of NEs recognized by the system. In our eval uation, a recognized entity is correct if and only if both it s boundary and its category are the same as the manual annotations in the data for testing. As shown in Equation (8), F-measure is a weighted harmonic mean of precision and recall. Where  X  is the weighing coefficient. In our experiments, we use the balanced F-score (viz. 1 = performance of our system because it is not clear w hether recall or precision is more important in evaluating a NE r ecognizer. As shown in Table 2, we use three types of corpora in our experiments: The PKU corpus is a manually tagged co rpus containing one month of news texts from the People X  X  Daily (January 1998) [16]. In this work, we further annot ate this corpus with the entity tags defined in Table 1 mainly unde r the guidance of the IEER-99 Mandarin NE Task Definition (version 1.2). Moreover, we divide it into two parts: 90% for trai ning and 10% for testing. The IEER-99 newswire test data is orig inally used for the IEER evaluation sponsored by the National Insti tute of Standard and Technology. The third corpus is the ME T2 test data, which is originally used for Chinese NER evaluation at the Second Multilingual Entity Task (MET2). In our expe riments, we use the later two corpora as the data for an ope n comparison evaluation. Category Training Testing In order to examine the effectiveness of our system , we conducted a number of experiments using the corpora in Table 2. In particular, we intended to examine the following three issues through these experiments: (1) In principle, lexicalized HMMs should be more p owerful than standard HMMs in the tagging for Chinese NER b ecause lexicalized HMMs can handle richer contextual infor mation for tagging, in particular the contextual lexical infor mation. Consequently, our first aim is to examine how the u se of the lexicalization technique affects the performance of our system. (2) In practice, the formulation of NER as a taggin g task on a sequence of known words involves two different mode ls: the word-level model (viz. the common known word model) and the character-level model (viz. the pure single-charact er known word model). There are some arguments in the community o f NER about whether a word model or a character model is better. For this reason, our second intention is to investigate whether the word-level mode or the character-level model is mor e effective for Chinese NER. (3) The third motivation of our experiments is to c ompare our system with other public systems for Chinese NER. For comparison purpose, we concentrate our evaluati on on the three major groups of NEs, i.e. personal names (PER , including Chinese personal names (CPN) and transliterated per sonal names (TPN), organization names (ORG) and location names (LOC). The experimental results are presented below . 
Character based 
Character based with lexicalized Table 3 shows the results of the experiments on the NE-tagged PKU test corpus. lexicalized HMMs ORG 76.07 74.63 75.34 
Known-word based lexicalized HMMs ORG 71.15 70.40 70.78 Table 4 Results for the evaluation using the IEER-9 9 data Table 4 gives the results of the evaluation using t he IEER-99 test data. In this evaluation, two other public systems, i.e. the system developed by Sun et al. [11] and the system by Wu et al. [12] are shown for comparison. 
The KRDL system 
The NTU system lexicalized HMMs ORG 74.01 67.72 70.72 based tagging with lexicalized HMMs ORG 73.47 66.27 69.69 Table 5 Results for the evaluation using the MET-2 data Table 5 lists the results of the evaluation using t he MET2 data. For comparison purpose, we also list the correspond ing results of two public systems, i.e. the NTU (National Taiwan U niversity) System and the KRDL (Kent Ridge Digital Labs) syste m. From these results, we can draw the following concl usions: (1) As can be seen in Table 3, the lexicalized HMMs significantly outperform the standard HMMs for all types of NEs under investigation. This indicates that the use of lexicalization technique leads to the improvement of accuracy in N ER. (2) The character model can yield results that are comparable to or better than the word-level model with the lexica lization technique, for all test data. However, the characte r model performs worse than the word-level model without th e lexicalization technique. (3) It can be observed that the proposed lexicaliz ed HMM approaches are effective for most Chinese NEs. Howe ver, it achieves the relatively lower performance for entit ies like ORG. The reason may be that organization names usually h ave more complicated structures that are possibly beyond the current models. Moreover, some types of organization names are not clearly specified in the IEER-99 named entity task, it is therefore difficult to perform consistent annotation on them. (4) As shown in Table 4, our methods, whether the word level model or the character-level model, perform better than the system in [11] as a whole. However, they perform wo rse than the system of Wu et al. [12] except for personal names. The reason may be that Wu et al. [12] have integrated some additional human knowledge, in particular semantic features in their system. (5) By comparing Table 3, 4 and 5, we can see that our system yields worse results for MET2 data than for IEER-99 data or the NE-tagged PFR corpus. An intensive error analysis s hows that wrongly recognized entities mainly result from thre e causes: the problem of data sparseness, the inconsistent taggin g between the training data and the MET2 data, and some complicat ed NEs such as nested organization names that are beyond t he sequence models. In this paper, we have presented a lexicalized HMM-based approach to Chinese NER. In particular, we formaliz e Chinese NER as a tagging task on a sequence of known words. We have also developed a two-stage NER system for Chinese, which consists of two major modules: a segmenter using kn own-word bigrams and a tagger using lexicalized HMMs. In thi s way, both the internal entity formation clues and the surroun ding contextual information, in particular the contextual lexical i nformation, are explored and combined to recognize different types of NEs in Chinese documents. The experimental results on diff erent public corpora show that the NER performance can be signif icantly enhanced using lexicalization techniques. The resul ts also indicate that character-level tagging (viz. the pur e single-character word models) are comparable to and may even outperform known-word based tagging when a lexicali zed method is applied. While our system has achieved a promising performan ce, there is still much to be done to improve it. First, our cur rent tagger is a problem of data sparseness, particularly in open-do main applications. Secondly, our system usually fails to yield correct results for some complicated NEs such as nested org anization names. For future work, we intend to explore some d omain-adaptive techniques and heuristic information to en hance our system. We would like to thank the Institute of Computation al Linguistics, Peking University, for their lexicon a nd corpus, and the U.S. National Institute of Standard and Technology for their Mandarin named entity tag set and corpus. We also w ould like to thank the reviewers for their helpful and valuable comments. [1] Bikel, D. M. Bikel, Schwartz, R., and Weischedel, R .M. An [2] Zhou, G.D., and Su J. Named entity recognition usin g an [3] Cohen, W.W., and Sarawagi, S. Exploiting dictionari es in [4] Borthwick, A. A maximum entropy approach to named [5] Brill, E. Transformation-based error-driven learnin g and [6] Isozaki, H., and Kazawa, H. Efficient support vecto r [7] Nakagawa, T. Kudo, T., and Matsumoto, Y. Revision [8] Pla, F., and Molina, A: Improving part-of-speech ta gging [9] Lee, S.-Z., Tsujii, J., and Rim, H.-C. Lexicalized hidden [10] Molina, A., and Pla, P. Shallow parsing using speci alized [11] Sun, J., Gao, J., Zhang, L., Zhou, M., and Huang, C . [12] Wu, Y., Zhao, J., and Xu, B. Chinese named entity [13] Zhang, H.-P., Liu, Q., Yu, H.-K., Cheng, Y.-Q., and Bai, S. [14] Chen, J., Xue, N., and Palmer, M. Using smoothing [15] Guo, H., Jiang, J., Hu, G., and Zhang, T. Chinese n amed [16] Yu, S., Duan, H., Zhu, S., Swen, B., and Chang, B. [17] Fu, G., and Luke, K.-K. Chinese unknown word [18] Klein, D., Smarr, J., Nguyen, H., and Manning, C.D. [19] Jing, H., Florian, R., Luo, X., Zhang, T., Ittycher iah, A. [20] Xue, N. Chinese word segmentation as character tagg ing. [21] Liang, N. CDWS ---A written Chinese automatic word [22] Yu, S., Bai, S., and Wu, P. Description of the Kent Ridge [23] Chen, H.-H., Ding, Y.-W., Tsai, S.-C., and Bian, G. -W. Guohong Fu is now a post-doctoral fellow in the Dep artment of Linguistics, the University of Hong Kong. He recei ved his Ph.D. degree in computer science from Harbin Institute of Technology. His research interests mainly include Chinese infor mation processing, natural language processing, and machin e learning. Kang-Kwong Luke is now a senior lecturer and serves as the head of the Department of Linguistics at the Univer sity of Hong Kong. He received his Ph.D. degree from the York Un iversity in 1988. His current research interests include Chines e grammar, Chinese dialects, discourse and conversation, compu tational linguistics, corpus linguistics, etc. 
