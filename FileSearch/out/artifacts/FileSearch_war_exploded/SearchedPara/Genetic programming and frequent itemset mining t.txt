 1. Introduction
Epilepsy is a neurological disorder that impairs millions world-wide with recurrent often uncontrollable seizures ( World Health
Organization, 2012 ). Physicians at epilepsy centers acquire combina-tions of various noninvasive or/and invasive brain signal modalities to diagnose the seizure onsets in patients, plan neurosurgical treatment, or fathom ictogenesis mechanisms and epilepsy symptom ( Bragin et al., 2010; Donaire et al., 2009a, 2009b; Engel, 1993; Engel et al., 2010; Fried, 1995; Rosenow and Luders, 2001; Sierra-Marcos et al., 2013; Staba and Bragin, 2011 ). These modalities include scalp electroencephalography (EEG), intracranial electroencephalography (iEEG), magnetoelectroencephalography (MEG), functional magnetic resonance imaging (fMRI), and other neuroimaging data. Traditionally, clinicians resort to subjective manual procedures when screening iEEG or fMRI for epilepsy patient diagnoses. But signal processing techniques in pattern classi fi cation and recognition for fMRI and iEEG have become useful tools in epilepsy research to help clinicians more objectively discern differences between functional and dysfunctional brain regions, identifying diseased brain tissue for therapy ( Ayoubian et al., 2012; Donaire et al., 2009a, 2009b; Fernandez-Blanco et al., 2012; Gaspard et al., 2014; Gotman et al., 1995; Grewal and Gotman, 2005; Halford, 2009; Han et al., 2011; Keogh and Cordes, 2007; Lee et al., 2009; Navakatikyan et al., 2006; Osorio et al., 1995, 1998; Qu and Gotman, 1997; Saab and Gotman, 2005; Tzallas et al., 2009, 2012; Wilson and Emerson, 2002; Worrell et al., 2012 ). With further development, validation, and acceptance across several research groups, such algorithms may translate to practical clinical use as decision-support tools for physicians.

One approach to developing sem i-automated pattern classi and decision-support tools for epilepsy data has been in implementing evolutionary computation techniques to select, combine, or create measures (extracted features) that quantify the difference between interictal biomarkers (e.g., pathological gamma oscillations in iEEG, resting-state blood oxygenation changes in fMRI) and interictal back-ground or basal activity ( Burrell et al., 2007a; Smart et al., 2007, 2011 ). Scant research has been published o n the application of evolutionary computation to interictal resting-state fMRI signals from epilepsy patients ( Burrell et al., 2007b ). Instead, pattern detection applications for ictal ( seizure ) activity dominate prior research involving evolutionary computation techniques applied to iEEG and EEG, including mostly genetic algorithms ( Haydari et al., 2011;
Hsu and Yu, 2010; Ocak, 2008; Patnaik and Manyam, 2008; Rivero et al., 2013; Shen et al., 2013 ), genetic programming (Sotelo et al., 2013a, 2013b ), and harmony search optimization ( Gandhi et al., 2012;
Zainuddin et al., 2013 ), although some projects have focused on spike detection applications ( Haydari et al., 2011; Kinnear et al., 1999;
Marchesi et al., 1997a; Shen et al., 2013 ). Additional studies have used evolutionary computation in other manners for epilepsy data ( Bandarabadi et al., 2011; Firpi et al., 2005a; Harikumar et al., 2004;
Rivero et al., 2013; Wei et al., 2010 ). Only a few groups apply evolut-ionary computation techniques to ga mma oscillation pattern detection for encephalography ( Firpi et al., 2007; Smart et al., 2007, 2011 ). We have focused on pattern classi fi cation research for interictal rather than ictal events of interest for the following philosophical positions: (1) certain analyses of interictal brain signals can lead to diagnostic and prognostic information for identifying seizure onset zones equ-ivalent to or complementary to certain analysis of ictal brain signals ( Bettus et al., 2011; Crepon et al., 2010; Heers et al., 2014; Korzeniewska et al., 2014; Lu et al., 2014; Matsumoto et al., 2013; Spencer et al., 2008; Thornton et al., 2011; Valentin et al., 2014;
WorrellandGotman,2011;Zhangetal.,2014 ); and (2) some patients do not have seizures during epilepsy monitoring, so using brain signals not dependent on seizures provides a means to offer some clinical analysis for patients rather than send them home without any diag-nosis. Because it is not a trivial problem to detect interictal biomarkers within iEEG or fMRI signals, especi ally depending on the signal-to-noise ratio for each brain signal mo dality,wehaveusedevolutionary computation techniques to search for robust optimal albeit relatively complex and somewhat human-intractable solutions. Commonly referenced alternative approaches for interictal biomarker detectors using iEEG signals still involve a human veri fi cation stage to discard numerous false positive detections ( Crepon et al., 2010; Gardner et al., 2007; Worrell et al., 2008 ) despite some algorithm developments ( Zelmann et al., 2012 ). Such human involvement counteracts the main purpose of the semi-automated appr oach and depending on the false-positive rate of the detection method might be as laborious as marking the actual true-positive events without running the pattern classi tion. On the other hand, we demonstrated via our prior work on interictal biomarker detection algorithms that  X  for at least our epilepsy brain signal data  X  one may gain higher pattern classi performance for features selected using an evolutionary computation method than for features selected by conventional or popular-in-literature methods for iEEG ( Firpietal.,2007;Smartetal.,2007,2011 ) and for fMRI ( Burrell et al., 2007a ).

Evolutionary computation is a discipline comprising the study and development of evolution-based ( Darwin, 1978 ) search optimization algorithms: for instance, an initial search space contains a population of organisms (possible optimal solut ions) that stochastically undergoes mutation and recombination before su rvival selection (i.e., choosing the most fi t organisms) and generational (iterative) production of a new population of organisms from the prior population (re possible optimal solutions) until no more evolution (optimization convergence). Since its pioneering inception in the 1950s through 1960s ( Baeck et al.,1997; Barricelli,1957, 1962, 1963; Fogel,1998; Fogel et al., 1968; Fraser, 1960; Turing, 1950 ), evolutionary computation has spawned numerous computer science techniques that today has classes or dialects of research areas: (1) evolutionary programming ( Fogel and Fogel, 1986; Fogel et al., 1968; Sebald and Fogel, 1994 ), (2) genetic algorithms ( Booker et al., 1989; Holland, 1992a, 1992b, 1995 ), (3) evolution strategy ( Schwefel, 1981, 1995 ), (4) genetic progr-amming ( Koza, 1989, 1992, 1994, 1996, 1997, 1999; Koza et al., 2006 ), and (5) swarm intelligence ( Beni, 2005; Beni and Wang, 1989; Blum and Merkle, 2008; Bonabeau et al., 1999; Dorigo and Gambardella, 1997; Kennedy et al., 2001 ). In particular, the genetic programming (GP) methodology is a global search optimization procedure that heuristically develops possible solutions (programs) to a prede problem statement using biological evolution concepts (i.e., mutation, crossover, and selection) ( Koza, 1989, 1992, 1994 ). The GP algorithm (see Algorithm 1 ) initializes a set (population) of solutions (indivi-duals) of size P with each element representing a mathematical operation on the input of the GP in the form of a tree structure, uses an objective function to compute an index ( fi tness) for each individual, and executes the evolutionary processes to create new populations that optimize the fi tness to compute best individual. The evolutionary processes have many variations in i mplementation but the same basic concepts: the selection stage chooses a current population subset (intermediate population) based upon individual fi tness; the crossover stage creates new individuals using combinations of paired individuals from the intermediate population, forming a new population; the mutation stage introduces diversity into the new population by rand-omly altering the makeup of a subset of individuals in the new population; and the survival stage simply selects the fi ttest individuals from the new population, creating a new initial population of size P for subsequent GP iterations (generations). The algorithm ends upon attaining a prede fi ned number of generations or prede fi value. From this fi nal population of solutions, one may select the best (optimal) solution according to the chosen fi tness function.
Algorithm 1. Pseudocode for GP Algorithm. non-biomarker (e.g., basal or baseline activity) and biomarker (e.g., spikes, seizures, PGOs, abnormal CBF activations) brain signals from epilepsy patients, GP has been used for both noninvasive and invasive electroencephalography ( Fern X ndez-Blanco et al., 2013; Firpi et al., 2005b, 2005c, 2006; Guo et al., 2011; Lopes, 2007; Marchesi et al., 1997b; Smart et al., 2007; Sotelo et al., 2013a, 2013b ), MEG ( Georgopoulos et al., 2009; Theo fi latos et al., 2009 ), and fMRI ( Burrell et al., 2007b ). However, GP is not a feature selection algorithm. Technically, its use in this way is a mischaracterized appli-cation,wherealgorithmicissuessuchasbloat, fi tness function de fi nition, and choices for the terminals (features) and functions can substantially affect  X  feature selection  X  results. Also, GP the algo-rithm can output practically inelegant solutions since theoretical parsimony is not a guaranteed effect ( Kelly, 1995 ). These limitations accentuate the importance of examining whether GP-based feature-selection solutions demonstrat e reproducible results and useful patterns for pattern classi fi cation of epilepsy data. Consequently, we investigated GP-based feature selection (i.e., implicit feature selection with GP algorithm) for interictal resting-state brain recordings with focus on two main questions regarding the computed feature subsets.
Across patients, do selected subsets exhibit the same feature subsets, indicating universal measures, or di fferent subsets, indicating uncon-ventional case-by-case measures? Per patient, are the selected subsets similar if not the same in content, indicating consistency in solutions?
Since the con fi dence interval concept em bodies the computation of consistency or reliability in an estimated value or parameter set ( Neyman, 1937 ), we investigated these two questions under the same aim: construct and evaluate con fi dence intervals for GP-based feature selection. Since a feature subse t list is qualitative rather than quantitative data, we considered frequent itemset mining (FIM) as an approach for con fi dence interval construction.

Frequent itemset mining is the fi rst stage in association rule learning, an established data-mining method to discover highly replic-able information within a multitude of data ( Agrawal et al., 1993, 1996;
Agrawal and Srikant, 1994, 1995; Rakesh and Ramakrishnan, 1994, 1995, 1998; Rakesh et al., 1993; Zaki, 2000 ). As its name implies, an FIM algorithm discovers (i.e., mines) fr equently occurring itemsets (i.e., collections of data variables) for pa ttern observation. An event (item) represents some variable of interest in the data-mining framework. A set of items (itemset), sometimes called a transaction, is an observed combination occurring events. A collection of multiple itemsets (data-base) is the input for FIM analysis to identify patterns. An itemset percentage (support), s , indicates its regularity or frequency within the database, where an itemset with n events that exceeds a support threshold (or likelihood level),  X  ,istermeda  X  -frequent n -itemset. A maximal (max)  X  -frequent n -itemset is an itemset such that any ( n  X  1)-itemset of which it is a subset has s o  X  . Alternatively stated, a max  X  -frequent itemset is an itemset that has infrequent ( s supersets. It is important to note that for a given support threshold FIM may output multiple itemsets as max frequent n -itemsets and these max itemsets may range in cardinality (e.g., 2-itemsets and 4-itemsets without 3-itemsets) ( Fig. 3 ). As illustrated ( Fig. 3 ), given a database (upper left), the FIM algo rithm computes frequent itemsets (gray rectangles) and max-frequen t itemsets (black rectangles) with the support threshold  X  , while the FIM avoids sub-threshold trials withinthedatabase(whiterectangles)for fi nal output results. The max-frequent itemset with the highest occurrence and largest size in the database represents the fi nal solution (e.g., Fig. 1 D). Because numerous potentially coincident event combinations must be evalu-ated to identify at least one pattern in a database, data-mining algorithms such as FIM provide ef fi cient computational execution in terms of memory usage, disk acce ss, and computational burden to search for putative patterns, aiming to avoid spurious results. Among many different FIM implementations ( Agrawal et al., 1996; Borgelt, 2005; Zaki, 2000 ), the APRIORI algorithm (see Algorithm 2 )islikelythe best known and most often used approach over decades ( Bodon, 2003 ). Yet, there exists few applications of FIM to epilepsy data ( Bourien et al., 2005, 2004; Exarchos et al., 2006; Smart et al., 2012 ) andnoneapplyFIMinthesamemannerthatwepresentwiththis work.

Algorithm 2. Pseudocode for APRIORI FIM Algorithm. /* C_k is current list of candidate frequent itemsets */ /* F_k is current list of lambda frequent itemsets */ /* S_k is current list of support values for each candidate /* F_k_previous is previous list lambda frequent itemsets */ /* num_frequent_itemsets is the cardinality of F_k */ /* database is the input to the FIM algorithm */ /* compute the lambda-frequent 1-itemsets 01. F_1  X  Compute_Frequent_Items(database, lambda); /* start loop for computing frequent n-itemesets */ 02. k  X  2; 03. WHILE NOT (num_frequent_itemsets  X  X  0) /* lambda is the minimum support threshold */ /* F_k_previous  X  F_1 when k  X  2*/ 04. C_k  X  Generate_Candidate_Frequent_Itemsets 05. S_k  X  Compute_Support_for_Candidate_Frequent_Itemsets 06. F_k  X  Compute_Frequent_Itemsets(C_k, S_k, lambda); 07. F_k_previous  X  F_k; 08. k  X  k  X  1; 09. num_frequent_itemsets  X  Compute_Size(F_k); 10. END /* end loop for computing frequent n-itemesets */
We present a framework to essentially compute con fi dence intervals for GP-based feature selection that categorize epileptic biomarkers (not seizures but interictal resting-state activity) and brain activity not considered as epileptic biomarkers by imple-menting the APRIORI FIM algorithm after several GP feature-selection trials. This approach ( Fig. 1 ) transforms stochastic results of the GP analysis into more deterministic results via FIM. In
Section 2, we explain the approach details: Section 2.1 for the acquisition of each the iEEG and fMRI signals ( Fig. 1 A); Section 2.2 for computation of signal measures via feature extraction process (e.g., Fig. 1 B); Section 2.3 for selection of a subset of these measures using GP, a process that we repeated in multiple trials for application of FIM ( Figs. 1 C and 2 ); Section 2.4 for recognition of patterns in repeatedly selected measures (features) via FIM ( Fig. 1 D); and Section 2.5 for our three main computational experiments to apply and validate the framework. 2. Materials and methods 2.1. Signal acquisition collected from another patient group. For each de-identi fi dataset, the Internal Review Boards at the Georgia Institute of
Technology, Emory University, and the University of Pennsylvania approved data analysis. For each dataset, a board-certi fi annotated  X  gold standard  X  epileptic biomarkers, which provided classi fi cation labels (i.e., biomarker, non-biomarker) for the in silico experiments.
 recordings ( Fig. 1 A, left) from seven patients (1 child). Each person had a standard clinical presurgical evaluation for brain resection to treat their seizures: surgical implantation of platinum-iridium brain electrodes (Ad-Tech Medical Instrument Corporation, Racine,
WI) before hospitalization in an epilepsy monitoring unit (EMU) to pinpoint a focal seizure-onset zone (SOZ) for neurosurgical resec-tion ( Engel, 1987; Luders and Comair, 2000; Rosenow and Luders, 2001 ). A clinical EMU iEEG system continuously recorded electro-physiology for each patient. For the child, a 128-channel system (Grass-Telefactor, Warwick, RI) with analog anti-aliasing band-pass fi ltration ( 3 dB cutoffs at 0.5 and 100 Hz) digitized data at 12 bits per sample and 800 samples per second before digital low-pass fi ltering ( 3 dB cutoff at 70 Hz) and down-sampling to 200 samples per second for fi nal storage. For the adults a 64-channel system (Nicolet Biomedical, Madison, WI) with an analog Butter-worth band-pass anti-aliasing fi lter (cutoffs 3 dB at 0.5 and 150 Hz) digitized data at 12 bits per sample and 400 samples per second before digital low-pass fi ltering ( 3 dB cutoff at 100 Hz) and down-sampling to 200 samples per second for fi storage. From the above data for each patient we randomly picked multielectrode iEEG clips with interictal pathological gamma (i.e., 30  X  100 Hz adults, 30  X  70 Hz child) oscillations (PGOs) and without any epileptic biomarker activity in clinically marked SOZ electro-des as manually annotated a priori by epileptologists. We used interictal PGO data since various types of gamma brain activity offered utility as a potential SOZ biomarker ( Bragin et al., 1999;
Medvedev et al., 2011; Pan et al., 2009; Smart et al., 2012; Worrell et al., 2004 ). Our main focus was not to discern SOZ electrodes from non-SOZ electrodes (or seizures from non-seizures) but instead indirectly was to discern PGOs from non-PGOs and directly was to fi nd consistently selected measures to discern PGOs and non-PGOs. But the subsequent analyses did include PGOs and non-
PGOs across heterogeneous electrodes (i.e., signals inside and outside the SOZ). We normalized signals from each electrode to a 1-to-1 scale before creating two single concatenated time-series signals from all interictal iEEG signals: one with the biomarker activity (i.e., PGOs) and one with the non-biomarker activity (non-PGOs). No chosen signals contained artifacts (e.g., electrical, movement). We applied a zero-phase digital bandpass-fi lter (i.e., 30  X  100 Hz) to the scaled artifact-free signals.
We analyzed resting-state ASL (arterial spin labeling) perfusion fMRI scans from fi ve MTLE (mesial temporal lobe epilepsy) patients.
Each scan occurred at 3 T with a 3-s repetition time and lasted 40 min for four patients and 30 min for one patient (P05). We realigned the fMRI images to account for patient motion during scanning and reduce artifacts, smoothed images with a Gaussian kernel to increase signal-to-noise ratio, performed pairwise subtrac-tion to obtain CBF (cerebral blood fl ow), and normalized images to the standard MNI (Montreal Neurological Institute) brain template for conformity using SPM (Statistical Parametric Mapping) software (i.e., SPM2) ( Frackowiak et al., 2004; Friston et al., 2007 ). The resulting CBF dataset consisted of 300 or 400 images depending upon scan duration, where each 16-slice (i.e., 64 64 voxels cross-section) image had a 3.44 3.44 7.50 mm 3 voxel resolution. We limited voxel analysis for each patient to left and right hippocampi since prior clinical tests (e.g., positron emission tomography, video-EEG) during their presurgical evaluation in addition to the fMRI revealed a unilateral temporal lobe seizure focus. We computed the time course (i.e. voxel intensity as a function of time) from the voxels in each hippocampus ( Fig. 1 A, right). 2.2. Feature extraction
For each time-series, whether iEEG concatenation or fMRI voxel, feature extraction involved calculating multiple measures ( n iEEG signals and n  X  13 for fMRI signals) from each signal within a moving W -second window using a mathematical expression, or feature, for each measure. We used measures ( Table 1 ) common to both our prior iEEG ( Smart et al., 2007 )andfMRI( Burrell et al., 2007a ) computational epilepsy research for consistency in this work. For the iEEG signals, we computed W by bootstrapping the median PGO duration using the manually annotated timestamps ( Smart et al., 2012 ). We performed feature extraction with an arbitrarily chosen 75% overlap between consecutive sliding windows to generate 300  X  points for each of the two signals (i.e., concatenated PGO events, concatenated non-PGO events). For the fMRI signals, we made W the entire voxel time-course duration to produce a single value per voxel, generating 100  X  total observation points from both hippo-campi. Ultimately, for each the iEEG and fMRI dataset we computed (1) a measurement matrix, X , with a corresponding measure (repre-sentative feature) per column (i.e., x i for i th measure) and observation points per row; and (2) a ground-truth vector, c ,withthesame number of rows as X and numeric class labels for non-biomarker column. We extracted features such as curve-length ( Table 1 )and created a statistical sample of measurement values for non-biomarker ( Fig. 1 B, black) and biomarker ( Fig. 1 B, gray) epileptic activity in the iEEG ( Fig. 1 B, left) and fMRI ( Fig. 1 B, right) signals. Both X and c became input variables for the feature selection stage ( Fig. 1 C). 2.3. Feature selection
We used a GP algorithm ( Silva and Almeida, 2003a ) to indir-ectly select features and combine measures that optimally classi-fi ed biomarker and non-biomarker activity according to a fi based fi tness function via Eqs. (1)  X  (3) and prede fi ned parameters ( Table 2 ). For each patient and each brain signal modality, we repeated feature selection 500 times using our prior GP-based procedures ( Burrell et al., 2007a; Smart et al., 2007 ): 100 selection trials 5 distinct GP generation parameters. We set 0.50 as the initial probabilities for crossover and mutation before the GP adaptively updated both probabilities to improve average popula-tion fi tness and assist population diversity ( Davis, 1989 ). We utilized total elitism survival to compute the best solution: all the individuals from both parent and children populations are ordered by fi tness alone, regardless of being parents or children.
We used lexicographic parsimony pressure to control bloat in GP individuals ( Luke and Panait, 2002 ): a random number of indivi-duals is chosen from the population, choosing individuals with the best fi tness, where if two individuals have equal fi tness then the individual with less nodes becomes the fi nal solution. We limited the depth of individuals using the dynamic maximum depth parameters to control bloat ( Silva and Almeida, 2003b ; Silva and
Costa, 2004 ): a minimum depth of 6 for both data modalities and a maximum depth of 10 for the fMRI and 11 for the iEEG.

For each patient, each GP generation value, and each trial, we inputted the measurement matrix X and ground-truth vector c (see Section 2.2 )totheGPandoutputtedtworesultsfromtheGP: (1) a multiple-input-single-output transformation, f ,oralternativelya multivariate function composition using preset expressions ( Table 3 ) and variables ( Tables 1 and 2 )columnindices( Fig. 1 C) for the selected measures from X . Illustrating these two outputs ( Fig. 2 ), the gray nodes (rectangles) are GP functions or expressions ( Table 3 )andthe white nodes (rectangles) are GP ter minals or variables, which corre-spond to features ( Table 1 ), for the GP solution. These mock examples correspond to the 99th ( Fig. 2 A and B) and 100th ( Fig. 2 C and D) trials of computing the best GP solution ( Fig. 1 C) for iEEG ( Fig. 2 AandC)and fMRI ( Fig. 2 C and D) signals. We ignored the composite functional mappings (e.g., f 99 and f 100 ) and only compiled the terminals as a database ( Fig. 1 C) for FIM ( Fig. 1 D). We used the same X , c ,andGP parameters for the 100 trials. We de fi ned fi tness function using the following equations. fitness  X  X  1 overlap  X  X  kfactor  X  X  1  X  kfactor  X  overlap  X 
In Eq. (3) , the column vector y  X  f ( X ) had the same number of rows as X and p ( y | c  X  c ) equaled the prior distribution y in class c with mean  X  c and standard deviation  X  c . We used the k -factor in
Eq. (2) , which paralleled the Fisher discriminant ratio (FDR) and the Cohen  X  s d effect size statistics, to quantify the separation between histograms of measures for the epileptic and non-epileptic classes. The k -factor ranged inclusively between 0 for no separation and in fi nity for maximum separation. The overlap ranged inclusively between 0 for no overlap and 1 for total overlap. High k -factor values and low overlap values indicated greatly separated histograms. We introduce this overlap parameter since sometimes seemingly good FDR values result from a statistical sample of measures (extracted feature values) with large overlaps in the corresponding histograms for two disjoint classes. The fi tness function in (1) penalized GP indivi-duals with large class overlaps by increasing the fi score in proportion to the amount overlap. More speci fi cally, we multiplied Eqs. (2) and (3) to obtain Eq. (1) and to account for possible misleading cases of class separation (e.g., probability distributions with distant means but heavy tail skewness proximal means and low variance). Thus, the GP individual with the highest fi tness score was ultimately selected as the best GP solution.
Additionally, because we used a fi lter-based rather than a wrapper-based (e.g., machine learning algorithm) approach for the objective function (Eq. (1) ), we did not need a cross-validation procedure for the GP. Instead, we developed a framework that not only avoided the consequent high computational complexity and execution duration of a wrapper-based approach but also the dependency on a speci fi c model-fi tting method for future pattern classi fi cation.

We prede fi ned sixteen GP parameters ( Table 2 ). We arbitrarily chose 100 for the total number of featu re selection repetitions (trials), which equaled the total number of FIM database transactions ( Fig. 1 C), for each the iEEG and fMRI data. We used different GP generation values for the iEEG signals (i.e., 5,10, 20, 30, and 35) versus the fMRI signals (i.e., 10, 20, 30, 40, and 50) after noticing the different
GP convergences for the different brain signal modalities. In this work, we did not focus on exploring wheth er the number of GP trials for the experiments or whether the GP parameters besides number of generations might considerably affect the FIM results for the follow-ing reasons: (a) we purposely limited the number of overall frame-work parameters (e.g., GP, FIM, feature extraction) under investigation for focusing on establishing the overall foundational approach; (b) we considered the GP generations the most important parameter regulating variability in the best GP solution upon conclusion of all iterations; (c) we only considered the best GP solutions (individuals), which when exploiting the procedural robustness of FIM suf determined the most relevant feature subsets for a given GP con uration(evenaconstrainedoneasinthiswork)andservedasa methodological archetype for other GP con fi gurations; and (d) we reserved rigorously studying the effects of other GP parameters, especially exhaustively exploring the entire con fi guration space, for future research. 2.4. Feature subset con fi dence interval computation
We considered FIM a very suitable technique to study the consistency (i.e., con fi dence interval) of GP selected features for quantitatively discerning non-biomarker and biomarker interictal events. We de fi ned a feature subset con fi dence interval as a list of most frequently co-occurring features (i.e., elements in the subset) after repeating the GP analysis ( Fig. 1 C), where theoretically different
GP repeats resulted in differe nt feature subsets and the most frequently selected features represented a type of  X  expected value.  X 
We compiled the indices ( Table 1 , 3rd or 4th column) of the selected features (see Section 2.4) to form a database ( Fig. 1 C), Q ,fortheFIM analysis ( Fig. 1 D). For Q , each row corresponded to a feature subset. The FIM searched Q for frequently co-occurring (co-selected) features.
For each patient and generations parameter, we formed a feature-subset database using the 100 GP feature-selection trials (see Section 2.3 ). We used FIM support thresholds of  X   X  occurrence in ten trials) for the iEEG feature-subsets and (two occurrence in ten trials) for the fMRI feature-subsets. For both modalities we used a proven high-performance APRIORI FIM implementation ( Bodon, 2005 ) to analyze each database. For instance, if the features entropy and kurtosis comprised a max -frequent 2-itemset that occurred 35/100 times in a particular database, then the GP simultaneously selected these two features more than once every three executions, demonstrating some heuristic consistency and pattern in the ability to discern epileptic and non-epileptic activity with these measures. The FIM avoids an exhaustive search of the total  X  14 k  X  1 sible combinations of creating feature subsets from 14 features (items) by basically fi rst examining the database for 1-itemsets (subsets with only 1 feature) with occurrence greater than or equal to the prede fi ned support threshold  X  ; second making 2-itemsets (subsets with only 2 features) using combinations of the 1-itemsets and excluding 2-itemsets that do not suf fi ce the same threshold third making 3-itemsets (subsets with only 3 features) using combinations of the 2-itemsets and excluding 3-itemsets that do not suf fi ce the threshold  X  , and then repeating the same process such that it makes n -itemsets (subsets with n features) using combinations of the ( n 1)-itemsets and excluding n -itemsets that do not suf fi ce the threshold  X  ( Fig. 1 D). The results of the FIM analysis formed the basis for our main experiments ( Fig. 1 E). 2.5. Main experiments and statistical analyses three key complementary aspects regarding the stochastic GP algorithm for selecting the best features that discriminate epileptic biomarkers and disparate events in each the iEEG and fMRI data sets ( Fig. 1 E).
 resulted from mining the GP-selected features across patients and generations to evaluate the reproducibility and subset size of the GP feature-selection for each the iEEG ( Table 4 ) and fMRI ( Table 5 ) data. We revisited these results in the third experiment, which focused on fi nding possible correlations between measures not frequently identi fi ed by the FIM analysis.

GP-selected features had better pattern classi fi cation performance than the GP-selected feature-subset with the highest fi tness over the 100 trials to evaluate the ultimate utility of using FIM to compute the most appropriate features versus solely using in principle the best
GP-selected features. We used sensitivity and selectivity, as de
Eqs. (4) and (5) , respectively, for the pattern classi fi metrics and dependent variables in a three-factor analysis of variance (ANOVA) to test the null hypothesis of no statically signi difference ( p o 0.05) in performance between mined and not-mined featuresubsets.ForeachtheseparatefMRIandiEEGdata,each patient, each GP generations parameter, and each method (e.g., not mined, mined), we performed leave-M-out cross-validation with a 5-NN (5-nearest-neighbor) classi fi erand100bootstrapsamplesof disjoint training and testing data with the following percentages of testing points: 92.49 7 0.54 for iEEG and 49.97 7 7.44 fMRI. In the
ANOVA, we de fi ned as factors (independent variables) the patient, number of GP generations, and method. We presumed a random effects model for the ANOVA for all factors except the method factor.
More speci fi cally, the method factor had three levels: (M1) not mined or GP only, (M2) mined, using the max  X  -frequent n -itemset with the lowest support (i.e., s  X   X  ), and (M3) mined, using the max n -itemset with the highest support (i.e., s 4  X  ). Comparing the performance of the lowest-suppo rt and highest-support FIM max -frequent n -itemset permitted us to initially test the hypothesis that more frequent and less frequent feature subsets demonstrated equiva-lent ability to classify biomarker and non-biomarker events and that any max  X  -frequent n -itemset rather than a speci fi c feature subset suf fi ced pattern classi fi cation. We performed a separate ANOVA for each the iEEG ( Table 6 )andfMRI( Table 7 ) datasets and each classi fi cation metric. To illustrate the ANOVA results, including descrip-tive statistics such as measures of central tendency and measures of dispersion, we used notched boxplots ( Figs. 3 and 4 )whereforeach boxplot the width of the notch represented the 95% con fi interval in the median performance metr ic (e.g., sensitivity, selectivity) with the MATLAB function boxplot ( McGill et al., 1978; Nelson, 1989;
Velleman and Hoaglin, 1981 ). Thus, boxplots with non-overlapping notches indicated statistical signi fi cance at the 0.05 level ( Chambers, 1983 ).
 Sensitivity  X  TP  X  TP  X  FN  X   X  4  X  Selectivity  X  TP  X  TP  X  FP  X   X  5  X 
In the third experiment, we performed a correlational analysis for each subject and number of GP generations to examine the interchangeability of  X  unshared  X  FIM features. We de fi  X  unshared  X  FIM feature as a feature not within the intersection of all max  X  -frequent itemsets of the same cardinality but within a max  X  -frequent itemset. For example ( Fig. 3 ), we considered features 3, 4, and 5 but not feature 2 as unshared features. Since was a threshold, the FIM algorithm returned multiple non-identical feature subsets all of the same cardinality ( Fig. 3 ). We hypothesized that unshared FIM features correlated with each other and that different FIM feature subsets exhibited practical similarity in composition as well as classi fi er performance. For the correlational analysis, we used the Spearman correlation coef -cient test statistic with a null hypothesis of no statistically signi fi cant correlation ( r  X  0, p o 0.05) between two particular unshared measures. For each subject, we compiled the coef of all pairs of unshared measures across generations and com-puted 95% con fi dence intervals in the median correlation coef -cient for each the iEEG ( Fig. 6 A) and fMRI ( Fig. 6 B) FIM measures.
The number of pairs varied across patients even with the same number of GP generations given the cardinality of the patient-speci fi c FIM results ( Tables 4 and 5 ). For each patient, we further visualized the correlation between paired unshared FIM measures as scatterplots for the iEEG data ( Fig. 7 ) and the fMRI data ( Fig. 8 ).
Again, the purpose of these analyses and plots was to quantita-tively inspect the practical similarity of different FIM feature subsets. 3. Results 3.1. Observed patterns with FIM features resulted from mining the GP-selected features across patients and generations to evaluate the reproducibility and subset size of the
GP-based feature-selection. We computed the max frequent item-sets, or the most frequently occurring feature subsets among the 100 trials, for each patient, biological data modality, and number of GP iterations ( Tables 4 and 5 ). For each max frequent itemset, the item occurred most and the last item occurred least. We noticed that
GP often picked the same feature subsets within a subject across generations, but that feature subsets differed across all patients with only 1  X  2 overlapping features for any given patient pair, and that GP consistently returned subsets with more than one feature for all patients.

GP often selected CL (curve length) and ZC (zero-crossings) for 5 generations, CL and MRV (mean recti fi ed value) for 10, 20, 30, and 35 generations, and RMS (root mean square) along with CL and MRV at 35 generations. For C07, as with four other patients, the number of
GP generations marginally affected the FIM feature subset. However, for patients E02 and E11, FIM always clustered the same subsets: PF (peak frequency), MP (mean power spectral density), K (kurtosis), and CL for E02; and PF, MP, and CL for E11. Furthermore, at least one feature (e.g., CL for all, PF for E02, E09, and E11) always recurred in the max frequent itemsets across all generations, implying consis-tency and patterns in the GP feature-selection.
 ( Table 4 ). The GP generations only slightly affected the FIM feature subsets. For each subject, at least two of the same features appe-ared in the max frequent itemset for each number of generations.
For example with patient P02, features RE (Renyi entropy) and CL (curve length) occurred in all FIM subsets for all GP generations; also, features NE (nonlinear energy) and RE appeared in all FIM subsets for all GP generations except 30. For instance with patient P05, RE and S appeared in all FIM subsets for all GP generations.
But the max itemsets for each patient varied across the number of generations: for P01, sometimes a subset included a fourth feature that was either MF1 (mean frequency) or NE; for P05, sometimes a subset included a third feature that was M, E, or SE1. Additionally, the same subset did not arise for all patients for any given number of generations: for instance with 40 generations, P01 resulted in a con fi dence interval of features (i.e., RE, V, SE1, and NE) that showed different subset size and contents than the resultant con fi dence interval of features (i.e., RE, S, and M) for P05. 3.2. Classi fi cation performance with FIM features
In our second experiment, we studied whether the mined feature subsets had better pattern classi fi cation performance than the feature subset with the highest GP fi tness of the 100 trials. We were not concerned with achieving high classi fi cation performance values but instead we focused on investigating whether (1) changing the number of GP iterations considerably altered performance, which would necessitate parametric care in com bining GP with FIM; and (2) using
GP alone or in conjunction with FIM yielded similar classi performance. In other words, we conducted another observational study and not an optimization study (deferred as later work).
For the iEEG data, after evaluating both the sensitivity and selectivity metrics, we found (a) statistically signi fi cant differences in mean classi fi cation performance between patients; (b) statistically signi fi cant interactions between patients, methods, and GP genera-supported the hypothesis that neither the number of GP generations nor the approach to choose the fi nal feature subsets signi affected classi fi cation performance. Thes e results supported the hypothesis that different patients may exhibit different classi performance even when selecting patient-speci fi cfeatures.We hypothesized statistically signi fi cant interactions between the patient and methods, but did not ob serve this outcome (cf., Fig. 4 , Table 6 )after
Fig. 4 B),forallpatientsandmethods(i.e.,M1:GPaloneversusM2: leastfrequentFIMfeaturesubsetversusM3:mostfrequentFIMfeature subset) using the 30 GP generations ( Fig. 4 ) and other GP generations (Supplementary Figures). We supposed that we might have seen such an effect with a larger patient sample size, translating to more variability across patient in the ability to quantitatively separate PGO and non-PGO events, or perhaps even with a larger FIM database (e.g., 1000 trials rather than 100 trials). We concluded a need for also patient-speci fi c classi fi er design and selection (e.g., k-NN for patients like C07, E03, E05, and E11 but architecture such as mixture models for
E02, E07, E09) as well as patient-speci fi c feature selection ( Table 4 )to discern PGO and non-PGO activity given the ANOVA for the patient variable (cf., Fig. 4 , Table 6 ). With 30 GP generations the approach attained over 65% median sensitivity ( Fig. 4 A) and over 65% median selectivity except for E07 ( Fig. 4 B). We found comparable results for other generations (Supplementary Figures).

For the fMRI data, after evaluating both the sensitivity and selectivity metrics, we found (a) statistically signi fi cant differences in mean classi fi cation performance between patients; (b) statistically signi fi cant interactions between patients and methods; (c) statistically signi fi cant interactions between patients, methods, and GP genera-results supported the research hypothesis that the number of GP iterations did not signi fi cantly affect classi fi cation performance. These results also supported the hypothesis that the approach to choose the fi nal feature subsets (e.g., GP alone, GP and FIM) signi fi classi fi cation performance and depended on each patient. We expected statistically signi fi cant interactions between the patient and methods, indeed observing this outcome in some instances (cf., Fig. 5 ,
Table 7 ), implying that different patients may likely need different approaches to quantitatively assess CBF for biomarker and non-bio-marker voxels. We concluded a need for patient-speci fi c approaches to classify fMRI CBF epileptic activity at all three major pattern classi tion modules: feature extraction; feature selection, which unlike the iEEG fi ndings necessitate a con fi dence interval analysis such as FIM to identify the best feature subset ; and perhaps even the machine learning architecture (like the iEEG conjectures) to computationally decide biomarker and non-biomarker voxels. With 30 GP generations the approach attained over 60% median sensitivity ( Fig. 5 A) and over 60% median selectivity ( Fig. 5 B). We found comparable results for other generations (Supplementary Figures). For one patient ( Fig. 5 B: P05 and M3) we obtained median selectivity of 1.00 (occluded by axes). 3.3. Relationship between features
The correlational analysis per dataset for each patient to inves-tigate unshared features, or measures computed form features within the to all FIM subsets, or less frequently selected features, revealed ( Fig. 6 ) weak to strong nonlinear relationships between certain iEEG measures (median: 0.10 o r o 0.70, p o 0.001) and strong to very strong nonlinear relationships between many fMRI measures (median: 0.50 o r o 0.99, p o 0.001). Likewise, the correla-tional analysis for each GP generations after compiling all patients per dataset revealed weak to strong nonlinear relationships between certain iEEG measures and strong to very strong nonlinear relation-ships between many fMRI measures (results not shown). Thus, while the selected and mined measures exactly differed in some instances, further scrutiny determined that sometimes the algorithms picked somewhat similar (correlated) measures during these discrepancies ( Figs. 7 and 8 ), especially for the fMRI signals ( Fig. 8 ). For instance, E05 and P02 demonstrated the highest overall correlation coef cients (E05: Fig. 6 A, P02: Fig. 6 B) for their corresponding signal modalities. We respectively identi fi ed nine and seven distinct unshared FIM measures (i.e., each panel along the row/column of the y-axis/x-axis in fi gures) with E05 using 35 GP generations ( Fig. 7 ) and with P02 using 50 GP generations ( Fig. 8 ), where some pairings of measures exhibited nonlinear correlations while others no correlation. We noticed a similar pattern with patients corre-sponding to relatively lower overall correlation coef fi cients (e.g., E09: Fig. 6 A, P01: Fig. 6 B) (e.g., Supplementary Figs. S1 and S2). 4. Discussion
Applying FIM to repeated GP-based feature selection, we found patterns in the cardinality of the selected feature subsets, repro-ducibility of the subsets, and correlations between infrequently selected measures as well as a validation of patient-speci subsets. 4.1. Observed patterns with FIM features
Firstly, no analysis resulted in a feature subset with only one feature. More speci fi cally, for each patient and each the fMRI and iEEG signals, the feature selection to discriminate biomarker and non-biomarker interictal b rain activity outputted at least two fea-tures. These results suggest that careful consideration must be taken in the approaches for feature extraction and feature selection, especially if the aim is to reduce false detections. Moreover, these fi ndings partially con fi rm why the current techniques to detect iEEG gamma oscillations, which typically rely on a single feature (e.g., a measure tantamount to time-seri es energy or line-length) rather than multiple features, experience relative disadvantages in both classi fi cation performance and overall human-free semi-automa-ted implementation ( Crepon et al., 2010; Gardner et al., 2007;
Worrell et al., 2008 ). Conversely, the hybrid GP and FIM method used semi-automatic heuristics and an objective class separation statistic via the GP stage to eliminate subjectivity, assumption, and doubt in the proper feature space dimension reduction for pattern classi -cation.

Second, the FIM approach veri fi ed the reproducibility of the stochastic GP feature selection results. We observed within-patient similarity and across-patient variability for FIM feature subsets per number of GP iterations and each brain signal modality. Thus, we objectively disproved the notion of universal features, or feature subset fi ts all  X  for different patients since a single speci
FIM subset did not frequently reproduce across all patients. 4.2. Classi fi cation performance with FIM features
We determined for each the iEEG and fMRI data that (a) the FIM features typically showed the same or higher classi fi cation perfor-mance as the pre-FIM features and (b) the frequent FIM feature subsets demonstrated classi fi cation performance equivalent to or higher than the less-frequent FIM feature subsets ( Figs. 4 and 5 AandB).We conjecturedthatGP-basedfeatureselectioncomputedafeaturesuper-set to suf fi ciently discriminate non-biomarker and biomarker events and that the FIM features represented the most indispensable subset, or kernel, of this superset. We recognized the need for patient-speci feature-selection methods, as well as patient-speci fi c feature subsets (see
Section 4.1), certainly for the fMRI signals and possibly for the iEEG signals. We conjectured that perhaps inherent physical differences between the biological and acquisitio n properties (e.g., spatiotemporal resolution) of the two signal modalities in fl uenced differences in iEEG and fMRI results. But this experiment should be repeated with a larger patient sample, where ideally acquisition of both iEEG and fMRI should occur for each patient, to more clea rly study modality distinctions. 4.3. Relationship between less frequently selected FIM features We investigated similarities in the different FIM feature subsets.
We found correlations between FIM measures unshared to all groups in many cases. This result indicated that although the FIM subsets were technically different combinations of features implicitly selected by the GP, the subsets may have been practically the same as disjoint measures often showed similar quantitative properties per their nonlinear correlation with other measures. Thus, the stochastic nature of the GP may still have a tendency to similarly select features with complementary in a subset despite not replicat-ing exactly the same subset. This tendency needs further study to determine whether it may change depending on the user-chosen fi tness function. For instance, an alternative GP objective function to our choice (i.e., Eq. (1) ) might result in more or less correlated unshared measures and in turn less or more similar subsets. 4.4. Limitations and future research
First, we emphasize that our application of the GP algorithm implicitly performed the feature selection. That was, while the GP formed a subset of features during its global optimization process to return the best solution, it was not a necessary outcome that the selected features had any statistica lly or intrinsically relevant infor-mation. One main factor in this limi tation was the challenge of bloat (i.e., unreasonably large complex solutions with many introns) in constructing GP individuals. Two additional main factors in this limitation were ostensible bias in the fi tness function or the functions (e.g., Table 3 ): in either case, the mathematics that de and functions may favor particular features but not others, perhaps erroneously rendering the un-fa vored measures irrelevant to the problem when in fact they might help achieve a fi tsolutionin combination with the right complem entary measures. Furthermore, some features might get selected just to produce a constant. We partially alleviated these concerns by using GP parameters that adaptively controlled bloat and diversity in the search space ( Davis, 1989; Silva and Almeida, 2003b; Silva and Costa, 2004; Luke and
Panait, 2002 ), but we may not have adequately addressed the needed breadth of the function set ( Table 3 ). Moreover, our GP-based feature selection still actually performed feature transformation since it not only selected the measurement vectors but also produced a mapping function to obtain an optimized fi tness value over the stochastic population of solutions in the search space. By discarding the composite functional mapping information ( Section 2.3 ), which in theory learned a nonlinear boundary that quantitatively separated non-biomarker and biomarker brain activity, we basically reintro-duced the burden of computing an equivalent multi-dimensional boundary to the subsequent classi fi er.
 the approach. We aimed to observe whether the FIM analysis identi fi ed patterns in features selected via GP, establishing a frame-work for constructing a type of con fi dence interval for a selected feature subset, and not yet to design the most optimal framework for the same purpose. Thus, we did not exhaustively examine all framework parameters, especially given the large size of the para-meter space and the ensuing computational complexity of traversing such a space for each main module (i.e., feature extraction, GP, FIM) let alone the entire approach of combined modules. Future work should explore the effects of changing method parameters (e.g., sliding window duration of feature extraction, the set of GP func-tions, the set of GP terminals, population size, fi tness functions, natural selection operators, crossover and mutation probabilities,
FIM support threshold, machine-learning method and its con tions) and even on  X  con fi dence interval construction  X  classi fi cation performance. 5. Conclusions biomarker epileptic activity in iEEG and fMRI signals from epilepsy patients by combining GP and FIM techniques. We used FIM to compute qualitative con fi dence intervals for features selected via a
GP algorithm. We observed within -subject consistency and across-subject variability for GP-based feature selection for both fMRI and iEEG signals. We concluded that the problem of detecting interictal biomarkers for each iEEG and fMRI signal modalities necessitates patient-speci fi c feature extraction, feature selection, and likely also machine learning modules in an overall canonical pattern classi framework ( Duda et al., 2000 ). We demonstrated classi fi mance comparable to prior state-of-the-art research ( Figs. 4 and 5 ). Acknowledgments grams Corporation NASA Harriett G. Jenkins Pre-doctoral Fellowship Program to Dr. Smart and the National Institute of Neurological
Disorders and Stroke (1R01NS048598-01A2) to both Drs. Burrell and Smart provided partial research support for this work. The authors thank the physicians from the Center for Functional Neuroimaging and Department of Neurology at the University of Pennsylvania, the Children  X  s Hospital of Philadelphia, and the Mayo
Clinic in Rochester, Minnesota for providing the separate raw iEEG signals and raw fMRI signals for the signal processing analysis in this work by Drs. Smart and Burrell.
 Appendix A. Supporting information
Supplementary data associated with this article can be found in the online version at http://dx.doi.org/10.1016/j.engappai.2014.12.008 . References
