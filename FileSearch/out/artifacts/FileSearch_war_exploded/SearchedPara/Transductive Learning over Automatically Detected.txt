 We propose a new method for query-biased multi-document summarization, based on sentence extraction. The summary of multiple documents is created in two steps. Sentences are first clustered; where each cluster corresponds to one of the main themes present in the collection. Inside each theme, sentences are then ranked using a transductive learning-to-rank algorithm based on RankNet [2], in order to better iden-tify those which are relevant to the query. The final sum-mary contains the top-ranked sentences of each theme. Our approach is validated on DUC 2006 and DUC 2007 datasets. I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  text analysis Algorithms, Experimentation, Performance Mutli-document summarization, Learning to Rank
Multi-document summarization ( MDS ) aims at reducing the information overload caused by the ever increasing num-ber of documents on the same or similar topics, and hence has attracted significant research attention since the past decade. With the current web growth, there are increas-ingly more web-oriented summarization applications. MDS can be used with conventional search engines, for example to provide informative snippets to help users navigate through different parts of the result page [8]. It can also provide short summaries of documents initially clustered by e.g. a news aggregator to assist users in better understanding the different views presented in the news [5]. Another appli-cation is a Question &amp; Answering system which, for each asked question, provides information about the answer in the form of a short extractive summary [3]. In this study, we consider query-biased MDS where we dispose of a set of queries and a set of relevant documents for each of these queries. For each query, an ideal multi-document summa-rizer consists in producing relevant information around key facets dealing with the query and which is present in the set of its relevant documents. A major issue for a MDS system is, therefore, to automatically detect these themes, and in each of these themes, to rank sentences relevant to the query. This paper introduces a two-step method for query-biased MDS . Our approach first detects the main themes of the docu-ments by clustering the sentences of all of the documents as-sociated to a given query, where sentences are represented in a low-dimensional space obtained with LSI. For each cluster (or theme), the sentences are then ordered using a transduc-tive learning-to-rank algorithm based on RankNet [2]. Ex-periments carried out on DUC 2006 and 2007 corpora show that we consistently improve over competing techniques.
We consider a setting similar to the TAC competitions 1 , where each query consists of a title and a question, and, for each query, we dispose of a set of relevant documents. Our algorithm operates in two steps.

Step 1 -Theme detection: For each query and its set of relevant documents, we suppose that each theme in-side this set, provides a partial answer to the query. Our theme detection scheme indirectly takes into account the query through this assumption. To find these themes, we first group syntagmatic similar words by applying a word-clustering algorithm, proposed in one of the top perform-ing systems at DUC 2007 for query expansion [1]. Sentences are then parsed and, adjectives and verbs are extended us-ing word clusters found before. The augmented sentences are coded in the bag-of-words space with TF features, and the word-sentence matrix is reduced using SVD , a reduction technique similar to LSI. Under this reduced representation, sentence clustering is finally performed using X-means [7]. This clustering algorithm is an extension of the well-known K-means algorithm in which the optimal number of clusters is found at the same time than centroid locations. This clus-tering allows us to treat each theme independently, with the goal of finding the most relevant sentences to the query in each of them. At the end of this step, sentences are then ranked using their bag-of-words similarity with the query. Step 2 -A transductive R ankNet algorithm for MDS : As we shall see in the experiments, the ranking obtained at the end of the first step is rather crude. We propose to improve it with learning-to-rank techniques inspired by web search, adapted to the transductive setting. For each cluster, we first automatically define relevant (resp. irrele-vant) sentences to the query by taking the top (resp. bot-tom) ranked sentences of the first step. This gives us a (artificially) labeled training set to initiate the learning pro-cess. By extracting a generic query for each theme defined as the most frequent terms of that theme, we then charac-terize sentences in the latter by taking 12 features used in the Letor datasets [6] as well as a feature produced by a bigram language model proposed in the top performing sys-tem at DUC 2006 [4]. Thus, for each theme, sentences have a representation that depends on the theme while the associ-ated relevance judgment depends on the topic in hand. For each theme, we then iteratively train the RankNet algorithm [2] and assign pseudo-relevance judgments to sentences us-ing the output of the learned ranking algorithm. With this new training set, we learn another ranking function using RankNet . This transductive learning scheme allows us to gradually improve the quality of the rankings.

For each topic, a summary is finally generated by taking the top ranked sentence given by different RankNet algo-rithms in each of the themes. The first top ranked sentence, of one of the themes, included in the summary is the one which appears in the most recent document of the set of documents associated to the topic. After including all the first ranked sentences, if the overall legnth of the summary does not exceed 250 words (as in DUC 2006 and DUC 2007 main task), we repeat the operation using the second ranked sen-tences until this summary length is reached.
We carried out experiments on DUC 2006 and DUC 2007 datasets 2 . DUC 2006 and DUC 2007 contain respectively 50 and 45 topics, each composed of a set of keywords (the title) and a question. Each topic is associated to 25 relevant docu-ments from the AQUAINT corpus. For each topic, the dataset also has three reference summaries produced by human as-sessors. Since we do not need any prior labeled training data to run our algorithm, these reference summaries are only used for evaluation. In our experiments, we considered title keywords and non-stop words in the question as the query and employed the ROUGE toolkit applied by NIST for per-formance evaluation in DUC competitions. We compared our approach with two base-level summarizers, namely lead and random , and the top two performing systems in both com-petitions. The latter are those which achieved the highest ROUGE scores in that competition. In Table 1, these systems are denoted by system and their attributed numbers given in these competitions. The lead baseline returns all the lead-ing sentences (up to 250 words) in the most recent document for each topic and the random baseline selects sentences in random. In order to show the contribution of each of the two steps; for each topic, we also generate summaries by extract-ing the most similar sentence to the topic question and title in each of the sentence clusters. The most similar sentences which appear in the most recent documents are added first. This strategy corresponds to our first step (before training) Table 1: Comparison results on DUC 2006 and DUC 2007 . DUC 2006 DUC 2007 and is noted by s tep 1 in Table 1. We observe that on DUC 2006 and DUC 2007 , the combination of step 1 and step 2 , achieves the best results over other systems. These results indicate that the transductive approach is able to leverage from both the query dependent pseudo-relevance judgments and the theme dependent sentence representations to find an efficient combination of sentence features for the summary.
We proposed a learning to rank approach for extractive summarization based on a transductive setting. Our ap-proach allows to extract sentences from different themes of a document collection, which are relevant to the query. Our experiments on DUC 2006 and DUC 2007 show that our algo-rithm achieves the best results in terms of the ROUGE mea-sures compared to state-of-the-art.
 This work was supported in part by the IST Program of the EC, under the PASCAL2 Network of Excellence.
