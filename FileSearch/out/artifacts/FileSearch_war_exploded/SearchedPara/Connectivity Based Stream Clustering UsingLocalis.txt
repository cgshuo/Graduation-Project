 Stream mining is an increasingly important area of research that aims to discover interesting information from continually evolving data sets whose size, combined with limitations in available memory and computational resources, typically con-strains our ability to perform timely batch processing of the data. Instead, we desire means by which to incrementally ma intain current and historical models of the data with which to perform queries. Stream data mining has been heavily investigated in the past five years with most efforts concentrated on the cluster-ing aspect of the problem. Of the algorit hms developed, however, only a small number can handle difficult clustering tasks without expert help, typically pro-vided in the form of the number of parti tions expected or the expected density of clusters. Moreover, none of these attempt to build a selective history to track the underlying changes in the clusters observed.

We present a sparse-graph based stream mining approach that employs repre-sentative cluster points to incrementally process incoming data. The graph based description is used because it allows us to model the spatio-temporal relation-ships in a data stream more accurately th an is possible via summary statistics. A critical aspect of our research has been to avoid rediscovery of previously learned patterns by reusing useful cluster information. For this reason, a repository of knowledge is used to capture the history of the relevant changes occurring in the clusters over time. The use of the repository offers two major benefits.
First, the algorithm can handle recurre nt changes in the clusters more effec-tively by storing a concise representatio n of persistent and consistent cluster features. These features assist in the classification of new data points belonging to historical cluster distributions within an evolving data stream. The retention of such features is important as they permit the algorithm to discard older data points in order to adhere to constraints in available memory and computational resources while continuing to st ore useful cluster features.

Second, the repository provides a conc ise knowledge collection that can be used to rebuild a cluster X  X  overall shape and data distribution history. It is there-fore possible to archive core cluster features for future off-line analysis when a recall of historical changes is desired. Several important stream mining algor ithms have been introduced in recent years. One of the first data stream mining methods to consider the archival of cluster information was CluStream [1]. The algorithm uses microclusters to capture and record statistical summary information suitable for off-line analysis. CluStream is, however, best suited to situations in which clusters are spherical, reducing the algorithm X  X  suitability to many real world data sets.

HPStream, a modification of CluStream to enable clustering of high dimen-sional data, was proposed in [2]. The algorithm employs a data projection method to reduce the dimensionality of the data stream to a subset of dimensions that minimise the radius of cluster groupings. However, the underlying assumption remains that clusters in the project ed space remain spherical in nature. Most recently, a multi-density cluste ring technique that extends the DB-SCAN [3] density-based clustering approach to stream mining was proposed in [4]. The algorithm, DenStream, extends DBSCAN by adapting the original density based connectivity search to a microcluster approach.
 An incremental version of the DBSCAN w as earlier proposed in [5]. As with DBSCAN, the algorithm obtains groupings based on the nearest neighbour-hood connectivity of points within an a priori defined radius known as the -neighbourhood. Incremental DBSCAN is limited to keeping only the most recent data points in memory and is therefore likely to discard possibly reusable cluster information without consideration towards its value.

A well known algorithm, Chameleon [6] uses the h Me T iS [7]multilevelgraph partitioning algorithm to recursively divide a sparse graph into micro-clusters. These clusters are then iter atively merged based on user specified thresholds for measures of relative interconnectivity and closeness.

None of the algorithms mentioned provide a means to selectively archive historical information. Those algorithms that facilitate archiving instead tend to store summary statistics with which general changes in clusters can be revisited. Our cluster representation involves the use of dynamically updated sparse graphs that, when used in conjunction with a repository of representative vertices, allows us to rebuild a cluster X  X  history and to rapidly adapt to significant changes previ-ously observed. The RepStream algorithm that we propose aims to capture such change in order to recall it at some future time should the change reoccur. Rep-Stream is a single phase incremental algorithm that updates two sparse graphs of k -nearest neighbour connected verti ces in order to identify clusters among data points. The first graph captures the connectivity relationship amongst the most recently seen data points and to select a set of representative vertices. The second graph is used to track the connect ivity between the chosen representa-tive vertices. The connectivity of the repr esentative vertices on both graphs then forms the basis for the algorithm X  X  clustering decision making.

The representatives we use offer two major advantages. First, since represen-tative vertices typify a set of nearby data points, decisions made at this level improves performance by requiring only a subset of the data to be considered. Second, representative vertices are associ ated with a measure of usefulness which allows the algorithm to selectively retain highly valued representatives as his-torical descriptors of the c luster structures. This ret ention allows the algorithm to accurately classify new data points arriving within a region of the clustering space where the non-representativ e vertices have since been retired. 3.1 Preliminaries Given a data stream P of time ordered points P = { p 1 ,...p | P | } ,wewishto find groupings of points sharing similar properties. We define a cluster c to be asetofpoints c = { p 1 ...p | c | } where each point p i is a multidimensional vector p
Let the set G = { g 1 ...g | P | } be the ideal cluster assignments for points P such that the j th element g j correctly labels point p j . We aim to assign labels to data points such that each point is correct ly classified or any misclassification is minimised. The distance between point p i and point p j is given as D ( p i ,p j ). Points are inserted into a directed k -nearest neighbour (K-NN) sparse graph i th vertex v i corresponds to point p i  X  P . Each edge is an ordered pair u, v of vertices such that u, v  X  V . The sparse graph representation is used as it provides a rich representation of relationships that is otherwise not available by only labelling data points.

Updates to the sparse graph requires knowledge of each vertex X  X  nearest neigh-bours. Let NN ( v i ) be a function that provides an ascending distance ordered array of the nearest neighbours of a vertex v i and let NN ( v i ,j ) be a function that gives the j th nearest neighbour of v i .LetRC( v i ) be a function that provides a set of vertices reciproc ally connected to a vertex v i .WealsoletIE( v i )bea function for determining the incoming edges directed at vertex v i .
Let R = { r 1 ,...r | R | } be a set of representative vertices on SG such that  X  x, r x  X  V and let RSG ( W, F ) be a directed k -nearest neighbour repre-sentative sparse graph which links the vertices W = { w 1 ,...w | W | } via edges F = { f 1 ,...f | F | } .Anedgein F is an ordered pair u, v of vertices such that v, u  X  R .LetNN R ( r i ), NN R ( r i ,j )andRC R ( r i ) be functions that provide the nearest neighbours, the nearest j th neighbour and the set of vertices that are reciprocally linked to a representative vertex r i on RSG.
 Definition (predictor) . Let a representative r i be a predictor if r i satisfies the condition that | IE( r i ) | &lt; k 2 .
 Definition (exemplar) . Let a representative r i be an exemplar if r i satisfies the condition that | IE( r i ) | X  k 2 .
 Definition (representative vertex). Represe ntative vertices represent at most k non-representative vertices on the sparse graph SG. A vertex v i is made repre-sentative if at any time j, v j  X  RC( v i ) ,v j  X  R , that is, if it is not reciprocally connected to an existing repr esentative. Representativ es are further categorised sentatives R P = { r P 1 ,...r P | R P | } such that R P  X  R E = R and R P  X  R E =  X  . Clustering decisions in RepStream are made via vertices representative of regions within the cluster space. At each time step a new point p i is observed in the data stream and added to the sparse graph SG( V, E )asvertex v i . A new vertex joins an existing cluster if it is reciproc ally connected to a representative v j  X  R . Should no such representative vertex exist then v i is itself made representative. The creation of the new cluster may trigger an immediate merge with an existing cluster if the conditions for merging are met. 3.2 Merging and Splitting Clusters Cluster splits and merges are made by monitoring both the reciprocal connectiv-ity of vertices on the representative sparse graph as well as their relative density based on the proximity of their nearest neighbours on SG. The trigger condition for either of these events is the creation or removal of density-related links. Definition (relative density) . The density of representative vertex r i  X  R is determined by the function RD ( r i )= 1 | NN( r Definition (density-related) . Given a density scaler  X  , two representatives r i and r j  X  RC R ( r i ).
 Merges are therefore triggered when a n update to the connectivity of vertices on RSG sees the creation of a new reciproc al connection that is also density-relate or when the addition or removal of a vertex affects the density of two existing representatives t hat are reciprocally connect ed such that their density-related status is altered. Monitoring the connectivity and relative density of representatives enables the algorithm to evolve with changes in the data.
Split checks are executed when the loss of a density-related link between two vertices on RSG is d etected. A standard O ( n 2 ) region growing algorithm that follows the density-related links of the r epresentative vertices was employed to perform split checks. 3.3 Knowledge Repository A significant aim of RepStream is to retain those representative vertices that prove, over time, to be useful in representing the shapes and distributions of clusters. Such vertices are retained for as long as possible (subject to available re-sources) via a repository defined a s an ordered vector of vertices S = s 1 ,...s | S | sorted in ascending usefulness.
 Definition (representative usefulness) . The usefulness of a representative ver-tex r i is defined by the decay function: usefulness( r i ,count ) = log(  X  )  X  (current time  X  creationTime( r i ) + 1) + log( count +1). Here  X  is a user specified decay rate and count is the representative vertex X  X  reinforcement count. This count is incremented when an incoming vertex i s found to be a nearest neighbour of r i . The decay function ensures a monotonic o rdering of vertices in the repository with respect to the passing of time. In our implementation of RepStream we chose to index the repository using a AVL binary search tree [8]. Updating the reinforcement count of a representative vertex that has already been added to the repository requires only two tree operations: the removal of the vertex and then its subsequent reinsertion following an increment to its reinforcement count. The least useful representative vertex can be rapidly found by traversing to the AVL tree node with the lowest usefulness score.

New additions to the repository are made whenever a new representative vertex is created until reso urce constraints have been reached. At this point only the most useful repository members are retained. This is achieved by comparing the least useful repository member with other non-repository representatives whenever their reinforcement count is in cremented. Vertices retired from the repository are immediately unlinked from both graphs and archived to disk. 3.4 Singularities The occurrence of many identical points within a data stream is captured via singularities , a special case of representative vertices intended to succinctly and efficiently represent such occurrences.
 Definition (singularity) . A representative vertex r i  X  R is termed a singularity when k j =1 D( r i , NN ( r i ,j )) = 0 and | NN ( r i ) | = k .
 Singularities represent a collection of identical points that offer no new informa-tion to the clustering process, yet whose inclusion in the sparse graphs would require the retirement of otherwise useful vertices. New points that are identical to a singularity are therefore immediatel y deleted in order to avoid the overhead of unnecessary sparse graph updates and to maintain the information value of the repository. The occurrence of identical points is not lost, however, as they are represented by a singulari ty X  X  reinforcement count.

Singularities are unable to be assigned non-zero density measures and as such do not lose their singularity status once it is acquired. This ensures that the presence of a singularity is permanently captured by the algorithm even though its nearest neighbours may be retired ov er time. Representative vertices are unable to form density-related links to singularity vertices. 3.5 Data Retirement Processing and memory constraints require the algorithm to discard information over time. This is accomplished by prioritising the disposal of data such that the least useful information for clustering is removed first. Non-representative ver-tices are queued on a first in, first out basis and removed whenever resource limitations are reached. Representative vertices that are not stored in the repos-itory are considered to have little reten tivevalueandarealsoremovedviathe deletion queue. All other representative vertices remain in memory; their deletion is instead managed via the repository update procedure.

The removal of a vertex requires updates to the sparse graph and the repre-sentative sparse graph. Graph updates are made to ensure that any vertices with edges directed at the removed vertex are u pdated with a new nearest neighbour. Representative vertices are also updat ed to ensure that their local density is adequately maintained. The performance of RepStream was evaluated using synthetic and real world data sets. Our real world data sets consisted of the KDD-99 Cup network intru-sion data and the forest canopy type data described in [9]. The synthetic data was designed to test the algorithm X  X  capacity to cluster a difficult set contain-ing a variety of arbitrarily shaped clusters of different densities. The real world data sets, in contrast, were selected to investigate the practical application of the approach on large evolving data streams.

Cluster purity [10] was used to measure how well data is classified over a horizon of the previous h data points. The purity of a cluster c i is defined as: The total clustering purity is then found by averaging over all clusters via:
The algorithm was constrained to using only 10 MiB of memory and the decay factor used in all experiments was set to  X  =0 . 99. The chosen purity horizons were selected to correspond w ith previous work in clustering data streams [1,2]. The KD-Tree [11] was used to perform nearest neighbour searches. 4.1 Synthetic Data The clustering quality of RepStream was first compared against an incremental version of DBSCAN [5] using the hand crafted synthetic data set. DBSCAN was selected for comparison as this algorithm employs a density based method of clustering known to perform well with arbitrarily shaped clusters. However, DBSCAN is limited to operating at a single density and is therefore expected to exhibit difficulties when dealing with this data set. As DBSCAN relies on a priori knowledge of the optimal cluster density, we repeated each of the DBSCAN experiments using a variety of values for . The minimum number of points required to form a cluster was set to 5. The data was presented to the algorithms using a randomised point ordering and the Manhattan distance was used to compute the similarity between points.

Figure 1 depicts the RepStream clustering of the data using the optimal pa-rameter set k =4and  X  =4 . 0. These results show that the algorithm was able to cluster the arbitrarily shaped clusters well. The discovered clusters are sub-optimal, however, with some minor fragmentation evident. The separate clustering of these points is not consider ed an error, however, as their location and density suggests that these points may, indeed, belong to separate clusters when compared to the remaining points.

Increasing the density scaler from  X  =4 . 0 to a higher value of  X  =6 . 0didnot correct this clustering. Decr easing the scaler did, however, result in increased fragmentation. An increase of the neighb ourhood connectivity successfully over-came the fragmentation issue as shown in Figure 1(b).

In contrast, DBSCAN was found to produce well formed higher density clus-ters with an -neighbourhood parameter of = 15. The lower density clusters, however, were found to be highly fragmented with the presence of a significant number of unclustered points as shown i n Figure 2(a). Decr easing the density with = 16 marginally decreased the clus ter fragmentation, as seen in Fig-ure 2(b), though at the expense of the incorrect merging of the two top left triangular clusters. 4.2 Network Intrusion Data The KDD Cup-99 data set features 494,020 network connection records derived from seven weeks of raw TCP logs consisting of both regular network traffic as well as 24 types of simulated attacks within a military local area network. Of the dimensions available, 34 continuous va lued features were used for clustering and a single outlier point was removed.

RepStream was tested using a purity horizon of h =1 , 000. The Manhattan distance function was used to compute the similarity of data points from features that were normalised on-the-fly. A point p i = { p i, 1 ...p i,D } of D dimensions was normalised in each dimension d using the formula p i,d = p i,d | P | |
P | refers to the number of points in memory at any given time. The nearest neighbourhood connectivity was set to k =9with  X  =1 . 5.

The purity results in Figure 3 show that RepStream is able to accurately dif-ferentiate between different types of a ttack connections. T he accuracy of Rep-Stream was also evaluated against publis hed results reported on the same data set for the HPStream, DenStream and CluStream algorithms. The results of the comparisons, depicted in Figure 4 and in Figure 5, shows that in most cases RepStream was able to classify network connections as well as or with higher accuracy than HPStream, DenStream and CluStream. The data stream sample times were chosen to match those reported in [1,2]. 4.3 Forest Cover Data The forest cover data set contained 581,012 records consisting of a total of 54 geological and geographical features t hat describe the environment in which trees were observed. Records also included the ground truth as to which of seven different types of canopy were present on the trees. Attri butes consisted of a mixture of continuous and Boolean valued data, the latter taking values from the set { 0 , 1 } . Dimensions were normalised as described in Section 4.2 and the Manhattan distance function was used to measure the similarity between points. Parameters used on this data set were k =9and  X  =1 . 5.
 Figure 6 shows the purity measured over the data stream with h =1 , 000. RepStream is seen to classify the can opy types with an accuracy typically  X  85%. The jagged appearance of the purity plots suggest that the algorithm is coping with a more dynamic data set than compared to the network intrusion experi-ment in Section 4.2; a premise confirmed through inspection of the data. Rep-Stream X  X  purity measurements were evaluated against HPStream and CluStream using the results published in [2]. Figure 7 depicts the result of this comparison, showing that the algorithm was able to classify the tree data with consistently more accuracy than the competing algorithms. 4.4 Scale-Up Experiments We investigated the execution time of the algorithm with respect to neighbour-hood connectivity and the length of the da ta stream. Scale up experiments were executed on Mac OS 10.4 running on an Intel 2.33GHz Core 2 Duo processor.
A near linear relationshi p between connectivity and execution time was discov-ered in the network intrusion results in Figure 8a. The forest data set produced a similar relationship as shown in Figure 8b. Execution time with respect to the length of the data stream is shown in Figure 9.
Whereas the tree data set i n Figure 9b shows an expect ed linear relationship between the number of points processed and the execution time, the network data set in Figure 9a displays significant flattening out due to efficient processing of identical points within the stream. Connectivity was set to k = 5 and a density scaler of  X  =1 . 5 was used to process both data sets. This paper has introduced a graph-based incremental algorithm for clustering evolving stream data. Experimental results demonstrated that the algorithm was able to effectively classify both sy nthetic and real world data sets. The algorithm was compared against an incremental implementation of DBSCAN and shown to robustly handle clusters of c omplex shapes, sizes and densities. DBSCAN, in contrast, was shown to be hampered by a static density threshold ill suited towards stream processing. Res ults on real world data sets showed that RepStream was able to more accurately classify well known network intrusion and forest canopy data sets than three of the most popular stream data clustering algorithms: DenStream, HPStream and CluStream.

