
Human activity discovery and recognition plays an im-portant role in a wide range of applications from assisted living to security and surveillance. One such application domina is smart environments. In recent years, due to the increasing aging population and the rising demand for in-place monitoring, assistive technologies such as smart homes have attracted many researchers from different disciplines. A Smart environment refers to an environment which is equipped with different types of sensors, such as infrared motion sensors, contact switch sensors, RFID tags, power-line controllers, etc. The low level sensor data obtained from different sensors is mined and analyzed to detect residents X  activity patterns. Recognizing residents X  activities and their daily routines can greatly help in providing automation, security, and more im-portantly in remote health monitoring of elderly, or people with disabilities. For example, by monitoring the daily routines of a person with dementia, the system can track how completely and consistently the daily routines are performed. It also can determine when the resident needs assistance or raise an alarm if needed.

A variety of supervised methods have already been proposed for human activity recognition in smart environments, e.g. neural networks [1], naive Bayes [2], conditional random fields [3], decision trees [4], Markov models [5], and dynamic Bayes networks [6]. In a real world situation, using supervised methods is not very practical, as it requires labeled data for training. Manual labeling of human activity data is time consuming, laborious and error-prone. Besides, one usually needs to deploy invasive devices in the environment during data collection phase to obtain reliable annotations. Another option is to ask the residents to report their activities. Asking the residents to report their activities puts the burden on the residents, and in case of elderly with memory problems such as dementia it would be out of question.

In an effort to address the annotation problem, recently a few unsupervised methods have been proposed for mining human activity data. Those methods include frequent sensor mining [7], mining discontinuous activity patterns [8], mining mixed frequent-periodic activity patterns [9], detecting activity structure using low dimensional eigenspaces [10], and discov-ering discontinuous varied order patterns [11]. None of these mining approaches take into account the streaming nature of data, nor the possibility that the patterns might change over time. In a real world situation, in a smart environment we have to deal with a potentially infinite and unbounded flow of data. Also the discovered activity patterns can change over time. Mining the stream of data over time not only allows us to find new emerging patterns in the data, but it also allows us to detect changes in the patterns. Detecting changes in the patterns can be beneficial for many applications. For example a caregiver can look at the pattern trends over time and spot any suspicious changes immediately.

In the last decade, many stream mining methods have been proposed as a result of different emerging application domains, such as network traffic analysis, Web click stream mining, and power consumption measurements. Most of the proposed methods try to find frequent itemsets over data streams [12] X  [15]. Also some methods have been proposed for finding frequent sequences over data streams [16] X  X 18]. To the best of our knowledge, no stream mining method has been proposed so far for mining human activity patterns from sensor data in the context of smart environments.

In this paper, we extend the tilted-time window approach proposed by Giannella et al. [13], in order to discover activity pattern sequences over time. The tilted-time window approach finds the frequent itemsets using a set of tilted-time windows, such that the frequency of the item is kept at a finer level for recent time frames and at a coarser level for older time frames. Such a tilted window approach can be quite useful for human activity pattern discovery. For example a caregiver is usually interested in the recent changes of the patient at a finer level, and in the older patterns (e.g. from three months ago) at a coarser level.

Due to the special requirements of our application domain, we cannot directly use the method proposed by Giannella et al. [13]. First of all, the time-tilted approach [13], as well as most of the other similar stream mining methods [16] X  X 18] were designed to find sequences or itemsets in transaction-based streams. The data obtained in smart environment is a continuous stream of unbounded sensor events with no boundary between episodes or activities. Second, as discussed in [11], due to the complex and erratic nature of human activity, we need to consider an activity pattern as a sequence of events. In such a sequence, the patterns might be interrupted by irrelevant events (called a discontinuous pattern). Also the order of events in the sequence might change from occurrence to occurrence (called a varied order pattern). Finding variations of a general pattern and determining their relative importance can be beneficial in many applications. For example in a study, Hayes, et al. [19] found that variation in the overall activity performance at home was correlated with mild cognitive impairment. This highlights the fact that it is important to recognize and monitor all the activities and their variations which are performed regularly by an individual in a daily environments. Third, we also need to address the problem of varying frequencies for activities performed in different regions of the space. A person might spend the majority of his/her time in the living room during the day, and only go to the bedroom for sleeping. We still need to discover the sleep pattern though its sensor support count might be substantially less than the support count of the sensors in the living room.
In this paper, we extend the DVSM method proposed by [11] into a streaming version based on using a tilted-time window [13]. Our proposed method allows us to find dis-continuous varied-order patterns in streaming data over time. As another extension to [11], we also address the problem of varying frequencies to better handle real life data and to find a higher percentage of the interesting patterns over time.
Summarizing the contributions of this paper, first we have introduced a stream mining algorithm for finding activity sequence patterns in non-transaction sensor data over time, based on using multiple temporal granularities. Second our stream mining algorithm is able to find such activity pattern over time even if patterns are discontinuous or varied order or have different frequencies across space. To the best of our knowledge, this is the first stream mining method for discovering human activity patterns from sensor data over time.

The remainder of the paper is organized as follows. First we explain the related stream mining works in more detail in section II. Next we describe the titled-time window in more detail in section III. Our proposed solution is explained in section IV. We then show the results of our experiments on data obtained from two different smart apartments in section V. Finally we end the paper with our conclusions and discussion of future work.

Sequential pattern mining have been studied for more than a decade [20] and many methods have been proposed for finding sequential patterns in data [20] X  X 23]. Compared to the classic problem of mining sequential patterns from a static database, mining sequential patterns over data streams is far more challenging. In a data stream, new elements are generated continuously and no blocking operation can be performed on the data. Despite being more challenging, with the rapid emergence of new application domains over the past few years the stream mining problem has also been studied in a wide range of different application domains. A few such application domains include network traffic analysis, fraud detection, Web click stream mining, power consumption measurements and trend learning [24].

For finding patterns in a data stream, approximation and using a relaxed support threshold is a key concept [15], [25]. The first approach was introduced by Manku et al. [15] based on using a landmark model and calculating the count of the patterns from the start of the stream. Later Li et al [14] proposed methods for incorporating the discovered patterns into a prefix tree. They also designed methods for regression-based stream mining algorithms [26]. More recent approaches have introduced methods for managing the history of items over time [13], [26]. The main idea is that one usually is more interested in recent changes in more detail, while older changes are preferred in coarser granularity in long term.
There also have been several methods for finding sequential patterns over data streams, including the SPEED algorithm [18], methods for finding approximate sequential patterns in Web usage [17], a data cubing algorithm [27] and mining multidimensional sequential patterns over data streams [28]. All of these approaches consider data to be in a transactional format. However, input data stream in a smart environment is a continuous flow of unbounded data. Figure 1 depicts the difference between transaction data and sensor data. As can be seen in Figure 1a, for transaction data, each single transaction is associated with a set of items and is identified by a transaction ID, making it clearly separated from the next transaction. The sensor data has no boundaries separating different activities or episodes from each, and it is just a continuous stream of sensor events over time.

Approaches proposed by sensor stream mining community [29], [30] try to turn a sensor stream into a transactional dataset using techniques such as Apriori technique [20] to group frequent events together. Another method is to simply use fixed or varied clock ticks [30]. In our scenario, using such simple techniques does not allow us to deal with complex activity patterns that can be discontinuous, varied order, and of arbitrary length. Instead, we extend the DVSM method [11] to group together the co-occurring events into varied-order discontinuous activity patterns.

It should be noted that researchers from the ubiquitous computing and smart environment community have also pro-posed methods for finding patterns from sensor data [7] X  X 11]. However none of these approaches address the stream mining problem. To the best of our knowledge this is the first work addressing activity pattern discovery from sensor data over time.

In this section, we explain the tilted window model [13] in more detail. Figure 2 shows an example of a natural tilted-time window where the frequency of the most recent item is kept with a precision of a quarter of an hour, in another level of granularity in the last 24 hours and then again at another level in the last 31 days. As new data items arrive over time, the history of items will be shifted back in the tilted-time window to reflect the changes. Other variations such as logarithmic tilted-time window have also been proposed to provide a more efficient storage [13].

The tilted-time window model uses a relaxed threshold to find patterns according to the following definition.
 Definition 1. Let the minimum support to be denoted by  X  , and the maximum support error to be denoted by  X  , and define the relaxation ratio as  X  =  X / X  . An itemset I is said to be frequent if its support is no less than  X  . If support of I is less than  X  , but no less than  X  , it is sub-frequent; otherwise it is considered to be infrequent.

Using the approximation approach for frequencies allows for the sub-frequent patterns to become frequent later, while discarding infrequent patterns. To reduce the number of fre-quency records in the tilted-time windows, the old frequency records of an itemset I are pruned. Let  X  f j ( I ) to denote the computed frequency of I over a time unit T j , where N j is the number of transactions received within T j , and 1  X  j  X   X  . Here  X  refers to the most recent time point. For some m , where 1  X  m  X   X  , the frequency records  X  f 1 ( I ) , ..., pruned if Equation 1 and Equation 2 hold [31].
Equation 1 finds a point, n , in the stream such that before that point, the computed frequency of the itemset, I , is less than the minimum frequency required within every time unit, i.e., from T 1 to T n . Equation 2 computes the time unit, T within T 1 and T n , such that at any time unit T l and T m , the sum of the computed support of I from T T is always less than the relaxed minimum support threshold,  X  . In this case the frequency records of I within T are considered as unpromising and are pruned. This type of pruning is referred to as  X  X ail pruning X . In our model, we will extend to above defections and pruning techniques for discontinuous, varied order patterns.

In following subsections, first we give an overview of definitions and notations, then we will describe our model in more detail.
 A. Definitions
The input data in our model is an unbounded stream of sensor events, each in form of e =  X  s, t  X  , where s refers to a sensor ID and t refers to the timestamp when sensor s has been activated. Table I shows an example of several such sensor events. We define an activity instance as a sequence of n sensor events  X  e 1 , e 2 , .., e n  X  . Note that in out notations an activity instance is considered as a sequence of sensor events, not a set of unordered events.
 We assume that the input data is broken into batches [ a ..b i ] , and the most recent batch is denoted by B b
As we mentioned before, we use a time tilted-time window for maintaining the history of patterns over time. Instead of maintaining the frequency records, we maintain the  X  X ompres-sion X  records, which will be explained in more detail in section IV-B. Also, in our model as the frequency of an item is not the single deciding factor, and other factors such as the length of the pattern and its continuity also play a role, we will use the term  X  X nteresting X  pattern instead of a  X  X requent X  pattern. The time-tilted window used in our model is depicted in Figure 3. This tilted-time window keeps the history records of a pattern during the past 4 weeks at the finer level of week granularity. The history records older than 4 weeks are only kept at the month granularity. Regarding our application domain and considering its end users, a natural time-tilted window provides a more natural representation vs. a loga-rithmic tilted-time window. For example it would be it easier for a nurse or caregiver to interpret the pattern trend using a natural representation. Second, as we don X  X  expect the activity patterns to change substantially over a very short period of time, we omit the day and hour information for the sake of a more efficient representation. For example, in case of dementia patients it takes weeks and months to see some change to develop in their daily activity patterns. Using such a schema we only need to maintain 15 compression records instead of 365  X  24  X  4 records in a normal natural tilted-time window keeping day and hour information.

To update the tilted-time window, whenever a new batch of data arrives, we will replace the compression values at the finest level of time granularity and shift back to the next level of finest time granularity. During shifting, we check if the intermediate window is full, if so, the window is shifted back even more; otherwise the shifting stops.
 B. Mining Activity Patterns
Our goal is to develop a method that can automatically discover resident activity patterns over time from streaming sensor data. Even if the patterns are somehow discontinuous or have different event orders across their instances. Both situations happen quite frequently while dealing with human activity data. For example, consider the  X  X eal preparation activity X . Most people will not perform this activity in exactly the same way each time, rather some of the steps or the order of the steps might be changed (variations). In addition the activity might be interrupted by irrelevant events such as answering the phone (discontinuous). The DVSM method proposed in [11] finds such patterns in a static dataset. For example, the pattern  X  a, b  X  can be discovered from instances events are discontinuous and have varied orders.

We discover the sequential patterns from the current data batch B  X  by using an extended version of DVSM that is able to find patterns in streaming data and is also able to deal with varying frequencies across different regions of a physical space. After finding patterns in current data batch B  X  , we will update the tilted-time windows, and will prune any pattern that seems to be unpromising.

To find patterns in data, first a reduced batch B r  X  is created from the current data batch B  X  . The reduced batch contains only frequent and subfrequent sensor events, which will be used for constructing longer patterns. A minimum support is required to identify such frequent and subfrequent events. DVSM uses as global minimum support, and it only identifies the frequent events. Here, we introduce the maximum sensor support error  X  s to allow for the subfrequent patterns to be also discovered. We will also automatically derive multiple minimum supports values corresponding to different regions of the space.

In mining real life activity patterns, the frequency of sensor events can vary across different regions of home. If the differences in sensor event frequencies across different regions of the space are not taken into account, the patterns that occur in less frequently used areas of the space might be ignored. For example, if the resident spends most of his/her time in the living-room during the day and only goes to the bedroom for sleeping, then the sensors will be triggered more frequently in the living-room than in the bedroom. Therefore when looking for frequent patterns, the sensor events in the bedroom might be ignored and consequently the sleep pattern might not be discovered. The same problem happens with different types of sensors, as usually the motion sensors are triggered much more frequently than other type of sensors such as cabinet sensors. This problem is known as  X  X are item X  problem in market basket analysis and is usually addressed by providing multiple minimum support values [32].

We will automatically derive multiple minimum support values. To do this, we identify different region of the space using location tags l , corresponding to the functional areas such as bedroom, bathroom, etc. Also different types of sensor might exhibit varying frequencies. In our experiments, we categorized the sensors into motion sensors and interaction-based sensors. The motion sensors are those sensors tracking the motion of a person around a home, e.g. infrared motion sensors. Interaction-based sensors, as we will call them  X  X ey sensors X , are the non-motion tracking sensors, such as cabinet sensors or RFID tags on items. Based on observing and analyzing sensor frequencies in multiple smart homes, we found that a motion sensor might have a higher chance of being triggered than a key sensor in some regions. Hence we will derive separate minimum sensor supports for different sensor categories.

For current data batch B  X  , we compute the minimum re-gional support for different categories of sensors as in Equation 3. Here l refers to a specific location. c refers to the sensor X  X  category, and S c refers to the set of sensors in a category c . Also f T ( s ) refers to the frequency of a sensor s over a time period T .  X 
T ( l ) = 1 /
As an illustrative example, Figure 4 shows the computed Fig. 4: The frequent/subfrequent sensors are selected based on the minimum regional support, instead of a global support. minimum regional sensor support values for a smart home used in our experiments.

Using the minimum regional sensor frequencies, frequent and subfrequent sensors are defined as following.
 Definition 2. Let s be a sensor of category c located in location l . The frequency of s over a time period T , denoted by f T ( s ) , is the number of times in time period T in which s occurs. The support of s in location l and over time period T is f T ( S ) divided by the total number of sensor events of the same category occurring in L during T . Let  X  s be the maximum sensor support error. Sensor s is said to be frequent support is less than  X  c T ( l ) , but no less than  X  s ; otherwise it is infrequent.

Only the sensor events from the frequent and subfrequent sensors will be added to the reduced batch B r  X  , which is then used for constructing longer sequences. We use a pattern growth method as in [9] which grows a pattern by its prefix and suffix. To account for the variations in the patterns, the concept of a general pattern is introduced. A general pattern is a set of all of the variations that have a similar structure in terms of comprising sensor events, but have different event orders [11]. During pattern growth, if an already discovered variation matches a newly discovered of pattern, its frequency and continuity information will be updated. If the newly discovered pattern matches the general pattern, but does not exactly match any of the variations, it is added as a new variation. Otherwise it will be considered as a new general pattern.

At the end of each pattern growth iteration, infrequent or highly discontinuous patterns and variations will be discarded as uninteresting patterns. Instead of solely using a pattern X  X  frequency as a measure of interest, we use a compression objective based on the minimum description length (MDL) [33]. Using a compression objective allows us to take into account the ability of the pattern to compress a dataset with respect to pattern X  X  length and continuity. The compression value of a general pattern a over a time period T is defined as in Equation 4. The compression value of a variation a general pattern over a time period T is defined as in Equation 5. Here L refers to the description length as defined by Minimum Description length principle (MDL), and  X  refers to continuity as defined in [11]. Continuity basically shows how contiguous the component events of a pattern or a variation are. It is computed in a bottom-up manner, such that for the variation continuity is defined in terms of the average number of infrequent sensor events separating each two successive events of the variation. For a general pattern continuity is defined as the average continuity of its variations.
Variation compression measures the capability of a variation to compress a general pattern compared to the other variations. Compression of a general pattern shows the overall capability of the general pattern to compress the dataset with respect to its length and continuity. Based on using the compression values and by using a maximum compression error, we de-fine interesting, sub-interesting and uninteresting patterns and variations.
 Definition 3. Let the compression of a general pattern a be defined as in Equation 4 over a time period T . Also Let  X  and  X  g denote the minimum compression and maximum com-pression error. The general pattern a is said to be interesting if its compression  X  is no less than  X  g . It is sub-interesting if its compression is less than  X  g , but no less than  X  g ; otherwise it is uninteresting.

We also give a similar definition for identifying intersting/sub-interesting variations of a pattern. Let the aver-age variation compression of all variations of a general pattern a over a time period T be defined as in Equation 6. Here the number of variations of a general pattern is denoted by n Definition 4. Let the compression of a variation a i of a gen-eral pattern a be defined as in Equation 5 over a time period T . Also Let  X  v denote the maximum variation compression error. A variation a i is said to be interesting over a time period T if its compression  X  T ( a i ) is no less than  X   X  ( a ) interesting if its compression is less than  X   X  ( a ) than  X  v ; otherwise it is uninteresting.

During each pattern growth iteration, based on the above definitions, the uninteresting patterns and variation are pruned, i.e. those patterns and variations that are either highly dis-continuous or infrequent (with respect to their length). We also prune redundant non-maximal general patterns; i.e., those patterns that are totally contained in another larger pattern. To only maintain the very relevant variations of a pattern, also irrelevant variations of a pattern are discarded based on using mutual information [34] as in Equation 7. It allows us to find core sensors for each general pattern a . Finding the set of core sensors allows us to prune the irrelevant variations of a pattern which do not contain the core sensors. Here P ( s, a ) is the joint probability distribution of a sensor s and general pattern a , while P ( s ) and P ( a ) are the marginal probability distributions. A high mutual information value indicates the sensor is a core sensor.

We continue extending the patterns by prefix and suffix at each iteration until no more interesting patterns are found. A post-processing step records attributes of the patterns, such as event durations and start times. We refer to the pruning process performed during the pattern growth on the current data batch as normal pruning. Note that it X  X  different from the tail pruning process which is performed on the titled-time window to discard the unpromising patterns over time.

In the following subsection we will describe how the tilted-time window is updated after discovering patterns of current data batch.
 C. Updating the Time-Tilted Window
After discovering the patterns in the current data batch as described in the previous subsection, the tilted-time window will be updated. Each general pattern is associated with a tilted-time window. The tilted-time window keeps track of the general pattern X  X  history as well as its variations. Whenever a new batch arrives, after discovering its interesting general patterns, we will replace the compressions at the finest level of granularity with the recently computed compressions. If a variation of a general pattern is not observed in the current batch, we will set its recent compression to 0 . If none of the variations of a general patterns are perceived in the current batch, then the general pattern X  X  recent compression is also set to 0 .

In order to reduce the number of maintained records and to remove unpromising general patterns, we propose the fol-lowing tail pruning mechanisms as an extension of the original tail pruning method in [13]. Let  X  j ( a ) to denote the computed compression of general pattern a over a time unit T 1  X  j  X   X  . For some m , where 1  X  m  X   X  , the compression records  X  1 ( a ) , ...,  X  m ( a ) are pruned if Equations 8 and 9 hold. Here  X  refers to the most recent time point.
Equation 8 finds a point, n , in the stream such that before that point, the computed compression of the general pattern a , is less than the minimum compression required within every time unit, i.e., from T 1 to T n . Equation 9 computes the time unit, T m , within T 1 and T n , such that at any time unit T T 1 and T m , the sum of the computed support of I from T to T l is always less than the relaxed minimum compression threshold,  X  g . In this case the compression records of a within T 1 and T m are considered as unpromising and are pruned.
We define a similar procedure for pruning the variations of a general pattern. We prune a variation a k if the following conditions in Equations 10 and 11 hold.
Equation 10 finds a point in time where the computed compression of a variation is less than the average computed compression of all variations in that time unit, i.e. from T T . Equation 11 computes the time unit , within T 1 such that at any time unit T l within T 1 and T m , the sum of the computed compression of a i from T 1 to T l is always less than the relaxed minimum support threshold,  X  v . In this case the compression records of a i within T 1 and T m are considered as unpromising and are pruned.

The performance of the system was evaluated on the data collected from two smart apartments. The layout of the apart-ments including sensor placement and location tags are shown in Figure 5. We will refer to apartments in Figures 5a and 5b as apartments 1 and apartment 2 . The apartments were equipped with infrared motion sensors installed on ceilings, infrared area sensors installed on walls, and switch contact sensors to detect open/close status of the doors and cabinets. The data was collected during 17 weeks for apartment 1 , and during 19 weeks for apartment 2 . During data collection, the resident in apartment 2 was away for approximately 20 days, once during week 12 and once during week 17 . Also the last week of data collection in both apartments does not include a full cycle. In our experiments, we considered each batch to conation approximately one week of data. In our experiments, we set the maximum errors  X  s ,  X  g and  X  v to 0 . 9 of their corresponding minimum support or compression values, as suggested in literature. Also  X  g was set to 0 . 75 based on several runs of experiments.

To be able to evaluate the results of our algorithms based on a ground truth, each one of the datasets was annotated with activities of interest. A total of 11 activities were noted Fig. 5: Sensor map and location tags for each apartment. On the map, circles show motion sensors while triangles show switch contact sensors. Fig. 6: Total number of recorded sensor event over time (time unit = weeks). for each apartment. Those activities included bathing, bed-toilet transition, eating, leave home, enter home, meal prepa-ration(cooking), personal hygiene, sleeping in bed, sleeping not in bed (relaxing) and taking medicine. Apartment 1 includes 193 , 592 sensor events and 3 , 384 annotated activity instances. Apartment 2 includes 132 , 550 sensor events and 2 , 602 annotated activity instances. Figures 6a and 6b show the number of recorded sensor events over time. As we mentioned, resident of apartment 2 was not at home during two different time periods, hence we can see the gaps in Figure 6b.

We ran our algorithms on both apartments X  datasets. Figures 7a and 7b show the number of distinct discovered patterns over time based on using a global support as in DVSM vs. using multiple regional support as in our proposed method. The results confirm our hypothesis that our proposed method is able to detect a higher percentage of interesting patterns Fig. 7: Total number of distinct discovered patterns over time. using multiple regional support values. Some of the patterns that have not been discovered are indeed quite difficult to spot and also in some cases less frequent. For example the housekeeping activity happens every 2-4 weeks and is not associated with any specific sensor. Also some of the similar patterns are merged together, as they use the same set of sensors, such as eating and relaxing activities. It should be noted that some of the activities are discovered multiple times in form of different patterns, as the activity might be performed in a different motion trajectory using different sensors. One also can see that the number of discovered patterns increases at the beginning and then is adjusted over time depending on the perceived patterns in the data. The number of discovered patterns depends on perceived patterns in current data batch and previous batches, as well as the compression of patterns in tilted-time window records. Therefore, some of the patterns might disappear and reappear over time which can be a mea-sure of how consistently the resident performs those activities.
As already mentioned, to reduce the number of discovered patterns over time, our algorithm performs two types of pruning. The first type of pruning called normal pruning, prunes patterns and variations while processing the current data batch. The second type of pruning is based on tail pruning to discard unpromising patterns and variations stored in titled-time window. Figures 8a and 8b show the results of both types of pruning on the first dataset. Figures 8d and 8e show the results of both types of pruning on the second dataset. Figures 8c and 8f show the tail pruning results in time-tilted window over time. Note that the gaps for apartment 2 results are due to the 20 days when resident was away.

By comparing the results of normal pruning in Figures 8a and 8d against the number of recorded sensors in Figures to month 1-5. 6a and 6b, one can see that the normal pruning somehow follows the pattern of recorded sensors. If more sensor events are available, more patterns would be obtained, and also more patterns would be pruned. For the tail pruning results, depicted in Figures 8b, 8e, 8c and 8f the number of tail pruned patterns at first increases in order to discard the many unpromising patterns at the beginning. Then the number of tail pruned patterns decreases over time as the algorithm is stabilized.
To better see an example of discovered patterns and vari-ation, several patterns are shown in 9. We have developed a visualization software that allows us to visualize the patterns and variations along with their statistics. Figure 9a shows a  X  X aking medication X  activity in apartment 1 that was pruned at third week due to its low compression. Figure 9b shows two variations of  X  X eave home X  activity pattern in apartment 2 . Note that we use a color coding to differentiate between different variations, if multiple variations are chosen to be shown simultaneously. Figure 9c shows  X  X eal preparation X  pattern in apartment 2 .

To see how consistent the variations of a certain general pattern are, we used a measure called  X  X ariation consistency X  based on using the externally provided labels. We define the varication consistency as in Equation 12. Here | v 11 | refers to the number of variations that have the same label as their general pattern, and | v 01 | and | v 10 | refer to the number of variations that have a different label other than their general pattern X  X  label.
Figures 10a and 10b show the average variation consistency for apartment 1 and 2 . As mentioned already, for each current batch of data the irrelevant variations are discarded using a mutual information method. The result confirm that that the variation consistency increases at the beginning, and then it quickly stabilizes due to discarding irrelevant variations for each batch.

To show the changes of a specific pattern over time, we show the results of our algorithm for  X  X aking medication X  activity over time. Figure 11a shows the number of discovered variations over time for  X  X aking medication X  activity. Figure 11b shows the same results in the time-tilted window over time. We can clearly see that the number of discovered varia-tions quickly drops due to the tail pruning process. This shows that despite the fact that we are maintaining the time records over time for all variations, yet many of the uninteresting, unpromising and irrelevant variations will be pruned over time, making our algorithm more efficient in practice.

We also show how the average duration of the  X  X aking medication X  pattern changes over time in Figure 11c. Pre-senting such information can be informative to caregivers to detect any anomalous changes in the patterns. Figure 11d shows the consistency of the  X  X aking medication X  variations over time. Similar to the results obtained for the average variation consistency of all patterns, we see that the variation consistency is increased and then stabilized quickly.

In summary, the results of our experiments confirm that we can find sequential patterns from a steam of sensor data over time. It also shows that using two types of pruning techniques allows for a large number of unpromising, uninteresting and irrelevant patterns and variation to be discarded, in order to achieve a more efficient solution that can be used in practice.
In this paper we showed a method for discovering human activity X  X  sequential patterns over time from a stream of sensor data. We provided an extension of the tilted-time window model for continuity-based, varied order sequential patterns according to the special requirements of our application domain. In the future, we intend to use our model in a fully functional system deployed in a real home to discover human activities over time. We also intend to design anomaly detection methods to detect anomalous changes over time.
