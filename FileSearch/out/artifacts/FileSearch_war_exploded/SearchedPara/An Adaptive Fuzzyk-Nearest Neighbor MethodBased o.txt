 Hui-Ling Chen, Da-You Liu , Bo Yang, Jie Liu, Gang Wang, and Su-Jing Wang Accurately identifying the potentially financial failure of companies remains a goal of many stakeholders involved. Because there is no underlying economic theory of bankruptcy, searching for more accurate bankruptcy prediction mod-els remains the goal in the field of the bankruptcy prediction. A fair amount of models has been developed for bankruptcy prediction. These models have progressed from statistical methods to the artificial intelligence (AI) approach. A number of statistical methods such as the simple univariate analysis, multi-variate discriminant analysis technique, logistic regression approach and factor analysis technique have been typically used for financial applications includ-ing bankruptcy prediction. Recent studi es in the AI approach, such as artificial neural networks (ANN) , rough set theory , support vector machines (SVM) , k -nearest neighbor method (KNN) and Bayesian network models have also been successfully applied to bankruptcy prediction (see [1][2]). Among these tech-niques, ANN has become one of the most popular techniques for the prediction of corporate bankruptcy due to its high p rediction accuracy. However, a ma-jor disadvantage of ANN lies in their knowledge representation. The black box nature of ANN makes it difficult for humans to understand how the networks predict the bankruptcy.

Compared with ANN, KNN is simple, easily interpretable and can achieve acceptable accuracy rate. Albeit these advantages, the standard KNN methods place equal weights on all the selected ne ighbors regardless of their distances from the query point. In this way, once the class has been assigned, there is no indication of the significance of membership to indicate how much the instance belongs to a particular class. An improvement over the standard KNN classifier is the Fuzzy k -nearest neighbor classifier (FKNN) [3], which uses concepts from fuzzy logic to assign degree of membership to different classes while considering the distance of its k nearest neighbors. The FKNN method has been frequently used for the classification of biological data, image data and so on. Nevertheless, only few works have paid attention to using FKNN to classify the financial data. Bian et al. [4] used FKNN as a reference classifier in their experiments in order to show the superiority of the proposed Fuzzy-rough KNN method, which incorporated the rough set theory into FKNN to further improve the accuracy of bankruptcy prediction. However, they did not comprehensively investigate the nearest neighbors k and the fuzzy strength parameter m , which play a significant role in improving the prediction power for FKNN. This study aims to explore the full potential of FKNN by automatically determining k and m to exploit the maximum classification accuracy for bankruptcy prediction.

Besides choosing a good learning algorithm, feature selection is also an im-portant issue in building the bankruptcy prediction models [5], which refers to choosing subset of attributes from the set of original attributes. The purpose of the feature selection is to identify the significant features, eliminate the irrel-evant of dispensable features and build a good learning model. In bankruptcy prediction, genetic algorithms (GA) are usually used to select a subset of input features or to find appropriate hyper-parameter values of a predictor. Compared with GA, particle swarm optimization (PSO) algorithm has no crossover and mu-tation operators, it is simple and computationally inexpensive both in memory and runtime. In this work, we will focus on exploring the PSO-based parameter optimization and feature selection approach. The continuous PSO algorithm will be employed to evolve an adaptive FKNN, where the nearest neighbor k and the fuzzy strength parameter m are adaptively specified. On the other hand, the binary PSO will be used as a feature selection vehicle to identify the most infor-mative features as well.

When dealing with the practical problems, the evolutionary-based methods such as the PSO and GA will cost a lot of computational time. There is an urgent need to improve the performance using high-performance computing techniques. For this reason, it is one of the major purposes of this paper to use a parallel environment to speed up the search and optimization process. Both the con-tinuous and binary time variant PSO are implemented on a multi-core platform using OpenMP (Open Multi-Processing) which is a portable, scalable model that gives programmers a simple and flexible interface for developing parallel appli-cations for platforms [6]. The efficacy of the proposed bankruptcy prediction model PTVPSO-FKNN is compared with th ree reference classification meth-ods on a real-world case. All these classi fiers are compared with respect to the classification accuracy, Type I error, Type II error and the AUC (area under the receiver operating characteristic (ROC) curve) criterion. The experimen-tal results demonstrate that the proposed model can not only obtain the most appropriate parameters but also show high discriminating power as a feature selection tool. Further comparison is also made between the parallel model and serial model. Based on the experiments conducted, it is inferred that the parallel model PTVPSO-FKNN can significantly reduce the computational time.

The rest of the paper is organized as follows. In Section 2, we give a brief description of the fuzzy k -nearest neighbor method (FKNN) and particle swarm optimization algorithm (PSO). Section 3 proposes our model, the simultaneous optimization of relevant parameters and feature subset by the PSO approach in a parallel environment. In the next section, the detailed experimental design is presented, and Section 5 describes all the empirical results and discussion. Finally, Conclusions are summarized in Section 6. 2.1 Fuzzy k -Nearest Neighbor Algorithm (FKNN) The k -nearest neighbor algorithm (KNN) is one of the oldest and simplest non parametric pattern classification methods [7]. In the KNN algorithm a class is assigned according to the most common class amongst its k nearest neighbors. In 1985, Keller proposed a fuzzy version of KNN by incorporating the fuzzy set theory into the KNN algorithm, and named it as  X  X uzzy KNN classifier algo-rithm X  (FKNN) [3]. According to his approach, rather than individual classes as in KNN, the fuzzy memberships of sampl es are assigned to different categories according to the following formulation: where i =1 , 2 ,  X  X  X  ,c ,and j =1 , 2 ,  X  X  X  ,k , with c number of classes and k number of nearest neighbors. The fuzzy strength parameter m is used to determine how heavily the distance is weighted when calculating each neighbor X  X  contribution to the membership value, and its value is usually chosen as m  X  (1 , +  X  ). x  X  x j is the Euclidean distance between x and its j th nearest neighbor x j .And u ij is the membership degree of the pattern x j from the training set to the class i , among the k nearest neighbors of x . There are two ways to define u ij ,oneway is the crisp membership, i.e., each training pattern has complete membership in their known class and non-memberships in all other classes. The other way is the constrained fuzzy membership, i.e., the k nearest neighbors of each training pattern (say x k ) are found, and the membership of x k in each class is assigned as: The value n j is the number of neighbors found which belong to the j th class. In our experiments, we have found that the s econd way lead to better classification accuracy. After calculating all the membe rships for a query sample, it is assigned to the class with which it has the highest membership value. 2.2 Time Variant Particle Swarm Optimization (TVPSO) Particle swarm optimization (PSO) was first developed by Kennedy and Eber-hart [8]. In PSO each individual is treated as a particle in d -dimensional space, and each particle has a position and velocity. The position vector of the i th par-ticle is represented as X i =( x i, 1 ,x i, 2 ,...,x i,d ), and its corresponding velocity as follows: where vector P i =( p i, 1 ,p i, 2 ,...,p i,d ) represents the best previous position of the i th particle that gives the best fitness value, which is known as the personal all the particles in the population, which is known as the global best position (gbest) . r 1 and r 2 are random numbers, generated uniformly in the range [0 , 1]. The velocity v i,j is restricted to the range [  X  v max ,v max ]. Inertia weight w is updated according to the following equation: where w max , w min are the predefined maximum and minimum values of the inertia weight w , t is the current iteration of the algorithm and t max is the max-imum number of iterations. Eq. (5) is also known as Time varying inertia weight (TVIW), which will be incorporated to the TVPSO. c 1 and c 2 are acceleration coefficients, to better balance the searc h space between the g lobal exploration and local exploitation, Time varying a cceleration coefficients (TVAC) have been introduced in [9]. This concept will be adopted in this study to ensure the better search for the solutions. The core idea of TVAC is that c 1 decreases from its equations as in [9]. TVAC can be mathematically represented as follows: and t max is the maximum number of iterations. For the binary PSO, one discrete PSO version introduced by Kennedy and Eberhart [10] was employed to act as the feature selection tool. In the binary PSO, A sigmoid function is applied to transform the velocity from continuous space to probability space: ThevelocityupdateEq.(3)k eeps unchanged except that x i,j , p i,j and p g,j  X  { 0 , 1 } , and in order to ensure that bit can transfer between 1 and 0 with a positive probability, v max was introduced to limit v i,j . The new particle position is updated using the following rule: where sig ( v i,j ) is calculated according to Eq. (8), and rand is a uniform random number in the range [0 , 1]. In this section, we describe the proposed PTVPSO-FKNN model for bankruptcy prediction. As mentioned in the Introduction, the aim of this model is to opti-mize the FKNN classifier by automatically: 1) determining the nearest neighbor k and the fuzzy strength parameter m and 2) identifying the subset of best discriminative features. In order to achieve this goal, the continuous and binary time variant PSO are combined together to dynamically conduct the parameter optimization and feature se lection. The obtained appropriate feature subset can served as the input into the FKNN classifier to conduct the classification task. Here, we first describe the model based on the serial PSO algorithm, termed TVPSO-FKNN, and then implement it in parallel. 3.1 TVPSO-FKNN Model Based on the Serial PSO Algorithm The flowchart of the TVPSO-FKNN model for bankruptcy prediction was con-structed through the following main steps as shown in Fig. 1.  X  Step 1: Encode the particle with n +2 dimensions. The first two dimensions  X  Step 2: Initialize the individuals of the population with random numbers.  X  Step 3: Train the FKNN with the s elected feature vector in Step 2.  X  Step 4: It is well known that higher the AUC value the better the classifier  X  Step 5: Increase the number of iteration.  X  Step 6: Increase the number of population. Update the position and velocity  X  Step 7: Train the FKNN classifier with the feature vector obtained in Step 6  X  Step 8: Update the personal optimal fitness ( pfit ) and personal optimal posi- X  Step 9: If the size of the population is reached, then go to Step 10. Otherwise,  X  Step 10: Update the global optimal fitness ( gfit ) and global optimal particle  X  Step 11: If the stopping criteria are satisfied, then go to Step 12. Otherwise,  X  Step 12: Get the optimal ( k , m ) and feature subset from the best particle 3.2 Parallel Implementation of the TVPSO-FKNN Model on the In this section, we put forward a parallel implementation of TVPSO-FKNN model which is performed on multi-core processor by using OpenMP. The ar-chitecture of the multi-core platform is divided into three lays as shown in Fig. 2(a): 1) TVPSO-FKNN: It consists of a number of particles, which can supply computing requirements. The parallel algorithm controls the iterations of par-ticles and each particle is calculated s eparately. 2) OpenMP: It guarantees to implement parallel synchronization and establish the communications with op-erating system (OS). The main part of OpenMP is scheduler, which provides the system with job scheduling and allocation. 3) Multi-core processor: The job is dispatched by OpenMP via OS.

The pseudo-code of the parallel TVPSO-FKNN is summarized in Algorithm 1. 4.1 Data Description The financial data used for this study was taken from Wieslaw [11] dataset which contains 30 financial ratios and 240 cases in total (112 from bankrupt Algorithm 1. PTVPSOFKNN Polish companies and 128 from non-bankrupt ones between 1997 and 2001). All the observations cover the period spanning 2 to 5 years before bankruptcy toke place. It should be noted that the size of the data set is not that large compared to the majority of bankruptcy pr ediction studies. However, according to [12], the dataset is reliable since increasing the dataset length does not lead to the accuracy increase. Fig. 2(b) illustrates the distribution of the two classes of 240 samples in the subspace formed by the two best features according to the principal component analysis (PCA) algorithm. As shown in this figure, there is apparently strong overlap between the bankrupt companies and non-bankrupt ones.

Data was normalized by scaling them into the interval of [  X  1 , 1]. In order to gain an unbiased estimate of the generalization accuracy, the k -fold CV presented by Salzberg [13] was used to evaluate the classification accuracy. This study set k as 10, i.e., the data was divided into ten subsets. Each time, one of the 10 subsets is used as the test set and the other 9 subsets are put together to form a training set. Then the average error across all 10 trials is computed. The advantage of this method is that all of the test sets are independent and the reliability of the results could be improved. 4.2 Experimental Setup The proposed PTVPSO-FKNN model was implemented using Visual C++ 2008 and OpenMP. For SVM, LIBSVM implementation is utilized, which was orig-inally developed by Chang and Lin [14]. We implemented the PSO algorithm, FKNN and KNN from scratch. The MLP was created, trained and implemented using Matlab neural network toolbox with BP and the training algorithm of Levenberg-Marquardt. The computer is Intel Quad-Core Xeon 2.0 GHz CPU; 4 GB RAM and the system is Windows Server 2003.

The detail parameter setting for P TVPSO-FKNN was set as follows. The number of the iterations and particles was set to 250 and 8, respectively. The searching ranges for k and m are as follows: k  X  [1 , 100] and m  X  [1 , 10]. v max was set about 60% of the dynamic range of the variable on each dimension for the continuous type of dimensions. Therefore, [  X  v max ,v max ] was predefined as [0.6, 60] for parameter k ,andas[0 . 6 , 6] for parameter m . For the discrete type particle for feature selection, [  X  v max ,v max ]wassetas[  X  6 , 6]. As suggested in According to our preliminary experiment, w max and w min were set to 0.9 and 0.4, respectively.

For SVM, we considered the nonlinear SVM based on the popular Gaussian (RBF) kernel, and a grid-search technique [15] was employed using 10-fold CV to find out the optimal parameter values of RBF kernel function. The range of the related parameters C and  X  were varied between C = { 2  X  5 , 2  X  3 ,..., 2 15 } and  X  = { 2  X  15 , 2  X  13 ,..., 2 1 } . For KNN, we found the best result was achieved when k = 1 by using 10-fold CV. Therefore, we selected k = 1 for the subsequent analysis. Concerning MLP, we used the three layer back-propagation network to train ANN. We tried different settings of the number of nodes in the hidden layers (5, 10, 15, 20, 25 and 30) and the different learning epochs (50, 100, 200 and 300) as the stopping criteria for training. The best result was obtained with the hidden layer of 15 and the learning epoch of 200. 4.3 Measure for Performance Evaluation Type I error, Type II error, total classification accuracy (ACC) and the area under the Receiver Operating Characteristic curve (AUC) [16] were used to test the performance of the proposed PTVPSO-FKNN model. They were the most widely used measures to assess the performance of bankruptcy prediction systems [1]. Type I and Type II errors were two important measures which described how well the classifier discriminates between case with non-bankruptcy and with bankruptcy. Type I error measures the proportion of bankrupt cases which are incorrectly identified as non-b ankrupt ones. Type II error measures the proportion of non-bankrupt cases which are incorrectly identified as bankrupt ones. The receiver operating characteri stic (ROC) curve is a graphical display that gives the measure of the predictive accuracy of a logistic model [16]. The curve displays the true positive rate and false positive rate. AUC is the area under the ROC curve, which is one of the best methods for comparing classifiers in two-class problems. 5.1 Experiment I: Classification in the Whole Original Feature As mentioned earlier, in this experime nt we evaluated the effectiveness of the proposed model on the entire feature space with 30 features (financial ratios). In order to verify the effectiveness of t he proposed model, TVPSO-FKNN was compared with three other reference classifiers (SVM, KNN and ANN). Table 1 shows the results achieved with all f our investigated cl assifiers (PTVPSO-FKNN, SVM, KNN and ANN) for the financial data with the form of  X  X verage  X  standard deviation X . It is well known that higher the AUC value the better the classifier is said to be. Accordingly, th e classifiers are arranged in the descending order of AUC in the table. As clearly indicated in the table, PTVPSO-FKNN outperforms all other methods with the classification accuracy of 81.67%, Type I error of 17.58%, Type II error of 19.04% and AUC of 81.69%. MLP is next to PTVPSO-FKNN with classification accuracy of 77.92%, Type I error of 20.84%, Type II error of 21.46% and AUC of 78.71%, followed by KNN and SVM. The superiority of the PTVPSO-FKNN is statistically significant as shown by the paired t -test in Tables (2-3), where the significant level is 5%. The results are interesting and exciting, it suggests that the FKNN approach can become a promising alternative bankruptcy prediction tool in financial decision-making, where SVM and ANN are known to be the best models [2].

The better performance of the propose d model can be explained by the fact that the TVPSO has aided the FKNN classifier to achieve the maximum classi-fication performance by automatically de tecting the optimal nearest neighbor k and the fuzzy strength parameter m . The detailed values of parameters k and m via 10-fold CV using the proposed model is shown in Table 4. From the table, it can be observed that the values of k and m are different for each fold of the data. And according to our preliminary experiment, they can be varied automatically when perform another run of 10-fold CV. The explanation lies in the fact that the two parameters are evolved together by the TVPSO algorithm according to the specific distribution of the training data at hand. It indicates that the optimal values of k and m can always be adaptively specified by TVPSO during each run of the experiment. Moreover, it is interesting to see that the standard deviation for the acquired performance by the PTVPSO-FKNN is much smaller than that of the other three classifiers, which indicates consistency and stability of the proposed model. 5.2 Experiment II: Classificatio n Using the PTVPSO-FKNN Model As described earlier, the proposed PTVPSO-FKNN model aimed at enhanc-ing the FKNN classification process by not only dealing with the parameters optimization but also automatically identifying the subset of the most discrimi-native features. In this experiment, we attempt to explore the capability of the PTVPSO-FKNN to further boost the performance of the FKNN classifier by using the TVPSO. Table 5 lists the best results of PTVPSO-FKNN with and without feature selection for Wieslaw d ataset. As shown in this table, results obtained using PTVPSO-FKNN with feature selection significantly outperforms PTVPSO-FKNN without feature selection in terms of the Type I error, Type II error, AUC and classification accuracy at the statistical significance level of 5%. By using feature selection, the cla ssification accuracy, AUC values, Type I error and Type II error have been improved by 2.5%, 2.55%, 1.71% and 3.38% on average, respectively.

To explore how many features and what f eatures are selected during the PSO feature selection procedure, we further conducted an experiment on the Wieslaw dataset to investigate the detail of the feature selection mechanism of the PSO algorithm. The original numbers of features of the dataset is 30. As shown in Table 6, not all features are selected fo r classification after the feature selec-tion. Furthermore, feature selection has increased the classification accuracy, as demonstrated in Table 5. The average nu mber of selected features by PTVPSO-FKNN is 15.3, and its most important features are X 1 , X 2 , X 4 , X 5 , X 7 , X 9 , X 16 , X 18 , X 20 , X 23 , X 25 and X 27 , which can be found in the frequency of the selected features of 10-fold CV as shown in Fig. 3(a). It should be noticed that important features (financial ratios) se lected by the proposed model are indeed important from the knowledge perspective also as they are related to current liabilities and long term liabilities, current assets, shareholders X  equity and cash, sales, inventory, working capital, net profit, receivables, liabilities, total assets.
To observe the evolutionary process in PTVPSO-FKNN, Fig. 3(b) shows the evolution of the best fitness for fold #1 during 10-fold CV. The evolutionary processes are quite interesting. It can be observed that the fitness curves gradu-ally improved from iteration 1 to 130 and exhibited no significant improvements after iteration 22, eventually stopped at the iteration 130 where the particles reached the stopping criterion(100 successively same gbest values). The fitness increase rapidly in the beginning of the evolution, after certain number of gen-erations, it starts increasing slowly. During the latter part of the evolution, the fitness keeps stability until the stopping criterion is satisfied. It demonstrates that PTVPSO-FKNN can converge quickly toward the global optima, and fine tune the solutions very efficiently. The phenomenon illustrates the effectiveness of PTVPSO-FKNN in simultaneously evolving the parameters ( k and m )and the features through using TVPSO algorithm. 5.3 Experiment III: Comparison between the Parallel In order to reduce further the running time of the serial TVPSO-FKNN model, we implemented the TVPSO-FKNN model on a multi-core platform. To vali-date the efficiency of the parallel version, here we attempted to compare the performance of the PTVPSO-FKNN with that of TVPSO-FKNN. Table 7 re-ported the best results of Type I error, Type II error, ACC, AUC and the average computational time in seconds us ing the two models. It can be seen that PTVPSO-FKNN and TVPSO-FKNN give almost the same results, the minor different results between two models may be attributed to different partitions of the data are chosen when perform different runs of 10-fold CV. Thus, it verifies the correctness of the parallel design and implementation. However, the training time for the TVPSO-FKNN was 3.3 times that of the PTVPSO-FKNN, which indicates that the TVPSO-FKNN has benefited a great deal from the parallel implementation with respect to the computational time. Additionally, it should be noted that only a quad-core processor was used in this experiment, thus the computational time will be further r educed with increase of the cores. This study provides an attractive model PTVPSO-FKNN for bankruptcy predic-tion. The main novelty of this model is in the proposed TVPSO-based approach, which aims at aiding the FKNN classifier to achieve the maximum classification performance. On the one hand, the continuous TVPSO is employed to adaptively specify the two impo rtant parameters k and m of the FKNN classifier. On the other hand, the binary TVPSO is adopted to identify the most discriminative features. Moreover, both the continuous and binary TVPSO are implemented in a parallel environment to reduce further the computational time. The ex-perimental results demonstrate that the d eveloped model performs significantly better than the other three state-of-the-art classifiers (KNN, SVM and MLP) in financial application field in terms of the Type I error, Type II error, ACC and AUC on a real life dataset. Moreover, th e experiment reveals that the PTVPSO-FKNN is also a powerful feature select ion tool which has detected a subset of best discriminative financial ratios that are really important from the knowledge perspective. Furthermore, the propose d model computes rather efficiently owing to the high performance computing technology.

Hence, it can be safely concluded tha t, the developed PTVPSO-FKNN model can serve as a promising alternative early warning system in financial decision-making. Meanwhile, we should note that the proposed model does perform effi-ciently on the data at hand; however, it is not obvious that the parallel algorithm will lead to significant improvement when applying to the financial data with larger instances. Future investigation will pay much attention to evaluating the proposed model in the larger dataset.
 Acknowledgments. This research is supported by the National Natural Science Foundation of China ( NSFC) under Gra nt Nos. 60873149, 60973088, 60773099 and the National High-Tech Research and Development Plan of China under Grant Nos. 2006 AA10Z245, 2006AA10A309. This work is also supported by the Open Projects of Shanghai Key Laboratory of Intelligent Information Processing in Fudan University under the Grand No. IIPL-09-007, the Open Project Program of the National Laboratory of Pattern Recognition (NLPR) and the basic scientific research fund of Chinese Ministry of Education.
