 EUNJU KIM, YU SONG, CHEONGJ AE LEE, KYOUNGDUK KIM, GARY GEUNBAE LEE, and BYOUNG-KEE YI Pohang University of Science and Technology, Korea and JEONGWON CHA Changwon University, Korea ________________________________________________________________________ ________________________________________________________________________ 1. INTRODUCTION Understanding regulations among biological entitie s, such as proteins, genes, molecules, and cellular processes, is a great challenge in computational biology. Knowledge of biological events is scattered throughout nu merous biological publications, which grow exponentially every year. So collecting biological information manually is (mostly) impractical, and NLP communities are more interested in acquiring biological knowledge automatically, especially in biological event extraction between biological entities. understanding the biological processes in a living cell. Many researchers are interested in automatic and efficient processing of large numbers of scientific texts using natural language processing (NLP) technology. Most of the current systems focus on a particular area, such as protein-protein interaction [Blasc hke et al. 1999; Thomas et al. 2000]; gene-protein interactions [Sekimizu et al. 1998]; or molecular binding relationships and interactions between genes or proteins and drugs [Rindflesch et al. 2000]. A number of projects concentrate on the development of an information extraction (IE) system with simple predefined patterns for extracting interaction information. Recently, an HPSG 1 full parser [Yakushiji et al. 2001]; combin atory categorical grammar for bidirectional incremental parsing [Park et al. 2001]; and constructed robust parser technology [Pustejovsky et al. 2002; Daraselia et al. 2004] were applied to identify and extract biomolecular interactions. biological events (most of them used many different hand-crafted rules). But it is time-consuming to construct hand-crafted rules, doing so requires much human effort --these systems are also difficult to apply to othe r domains. Hence, some other researchers [Bunescu et al. 2004] adopted a machine-learning method to generate biological event-extraction rules automatically. But previous machine-learning approaches, especially when applied to the biological domain, suffer from the trade-off between recall and precision. Typically, when precision is high, recall is very low; when recall is very high, precision is low. To make matters worse, pr evious systems that used machine-learning methods could not achieve good performance due to the complexity of free texts that included more than two biological events in a sentence. Although a biological event other biological event. As a result, a simple rule-learning and event-extraction method is limited in its ability to obtain high performance in complex biological texts. learning method to generate rules automatically in order to extract biological events from free texts without human effort. However, in order to overcome the extreme trade-off between recall and precision with a supervised machine-learning method, we conducted verification learning after extracting biological events. So in our system architecture, machine learning occurs in two phases. In the first phase, the system focuses on improving recall while learning the rules automatically in a rule-learning module. Then, in the second phase, af ter extracting biological events via automatically learned rules, the system removes the incorrect bi ological events by verifyin g each event component with a maximum entropy (ME) classification method in an event component verification module. phase and tries to achieve high precision with the verification in the event component verification module in the second phase. chunk and the rule for a biological event in an entire sentence. We do so to cope with the complexity of a biological text where a sent ence contains more than two events and one biological event in a noun chunk can be an entity for the other biological event. That is, text for a biological event which spans a whole sentence. methods. One experiment is to ascertain whether two-phase learning and verification actually improved performance and whether the two-level rule-learning algorithm gave a better performance than the one-level rule-learning algorithm. The other experiment is to see how the verification step can overcome th e notorious trade-off between precision and recall in a supervised machine-learning method. 2. A TWO-PHASE LEARNING ARCHITECTURE Our system adopts a supervised machine-learning method that overcomes the drawbacks of making hand-crafted rules and uses ME classification to verify the automatically generated event components. Moreover, we can focus on high reca ll during the rule-learning phase, which can adjust the trade-of f between precision and recall, since the ME classifier can guarantee better precision during the verificati on phase. As a result, we are conventional rule-learning method). During rule learning, we learn the rules and extract the biological events at two different levels; that is, within noun chunk and outside a noun chunk, to cope with the complexity of biolog ical texts. Our two-phase system architecture in Figure 1 shows the overall learning and extraction/verification process after linguistic preprocessing. extraction and to annotate the corpus needed fo r training. The extraction targets consist of the template element and event. A template element, which consists of entities and which represents the relation classes between entities, is divided into two groups: a biological interaction (BI) an d a chemical interaction (CI). The biological interaction contains the information about how/whether one component affects the other X  X  status biologically (e.g., activate, inhibit, increase.). The chemical interac tion is categorized by kinds of interactions, grouped by the given characteristics; that is, a modification (covalent addition or deletion of a molecule) in a certain small part of the component (e.g., modify, convert, combine, synthesize). An event consists of one  X  X nteraction (I), X  one  X  X ffecter (E), X  and one  X  X eactant (R). X  An  X  X ffecter X  is defined as a template element like P, SM, G, CP, or a nested event provoking other events, and a  X  X eactant X  is similar to the  X  X ffecter, X  but responds to an  X  X ffecter. X  Components for the event, such as I, E, and R, are mandatory and unique. 2.1 Linguistic Preprocessing The system extracts biological events from the ab stracts retrieved from MEDLINE with GPCR 3 related keywords. After tokenizing sentences, the system detects the sentence boundaries and recognizes each biological entity name and classifies it into four categories : proteins, small molecules, genes, and cellular processes. many systems use a full syntactic parser to cope with the grammatical complexities in several domains. However, since current stat e-of-the-art syntactic parser performance is usually less than 87% in complex sentences [Gildea 2001] and the rules, which are constructed from a supervised machine-learning method, are represented as regular expressions, the quality of the rules directly generated from the parsed sentences are questionable. Therefore, we only apply the syntactic parser to catch the syntax structure, in order to split the compound and complex sentences into simple sentences. We then convert the parse trees into the sentence form of the base phrase chunker, whose form is more relaxed and whose state-of-the-art performance is nearly 94.13% [Zhang 2001]. sentences from the full parsing results. For ex ample, the following sentence,  X  X he best studied of these is EDG-1, which is implicated in cell migration and angiogenesis X  is split into  X  X he best studied of these is EDG-1, X  and  X  X DG-1 is implicated in cell migration and angiogenesis X  by using the third rule in the table. 2.2. Two-Level Biological Event Extraction To overcome a knowledge-engineering bot tleneck, we propose a supervised machine-learning method that enables us to learn event-extraction rules automatically. However, biological texts are more difficult to learn th an those in other domains because biological noun chunk can influence the extraction of other long-span events. For this reason, we implemented a two-level learning rule and used it to maximize performance. Among many machine-learning methods and information extraction (IE) rules for free texts, we modified the WHISK algorithm [Soderland 1999], which learns rules formed by context-based regular expressions. The WHISK algorithm, a kind of supervised learning algorithm, induces a set of rules from hand-tagged training examples. This algorithm can support multislot extraction, and each iteration of the WHISK algorithm is done by filling these slots (in our domain, template elemen ts). Because the longer distance between event components makes it more difficult to extract the correct ev ent with the WHISK algorithm, we propose a two-level rule-learning method as a divide-and-conquer strategy (Figure 2). biological event within a noun chunk; we define a long-span rule as one generated from a biological event extended th roughout a whole sentence. long-span biological event. To explain, after learning the short-span rule for a short-span event in a noun chunk, we re-annotate the short-span event as a single noun with a simple symbol. After that, we learn the long-span rule for a long-span event from the re-annotated text (Tables II and III). generated short-and long-span rules at two different levels by using regular expression pattern matching. First, the system extracts th e short-span event with a short-span rule and re-annotates the short-span events to th e text, and then extracts the long-span events with a long-span rule from the re-annotated text. We handle aliases or noun-conjunction phrases with simple lexical rules before we apply the rules that were learned to the sentences, and we also remove the negative sent ences that include  X  X ot, X   X  X ever, X   X  X ail, X  and so on. 2.3 Event Component Verification The system extracts several biological events from texts via automatically generated rules. We, however, cannot guarantee that every extract ed event is correct, since many different maximum entropy (ME) 4 classifier to remove incorrectly extracted events (as in Figure 3). The maximum entropy (ME) approach to language modelling was first successfully applied in Rosenfeld X  X  system [Rosenfeld 1996]. One of the strength of the ME paradigm is its ability to incorporate arbitrary knowle dge sources while avoiding fragmentation. So the ME-based language models can combine n-gram features and other higher level linguistic knowledge in one unified fra mework [Rosenfeld 1996; Wu 2002]. components, and if an extracted template element is not a proper component for any event, then it belongs to the N class. An ME classifier classifies several template elements such as P, G, SM, CP, BI, and CI corresponding to each class they must belong to such as I, E, R, and N. speech) tags, phrase chunks, type of template elements (e.g., P, G, SM, CP, BI, and CI) of neighboring words, and distance between the current template element and previous or next template elements as us eful classification features. components of the events with the learned ME classifier model and remove the events whose components contradict the class assigned by the classification model. from the two-level rule-learning algorithm (Ev1, Ev2, Ev3, Ev4, Ev5 in Table IV) and three entity classes from the ME classifier (I, E, R in Table IV), we confirm whether the 1&lt;/P&gt; {/NP} , {VP} suggesting {/VP} {NP} a functional &lt;BI&gt;link&lt;/BI&gt; {/NP} between {NP} &lt;P&gt;PDGF&lt;/P&gt; signalling and &lt;P&gt;EDG-1&lt;/P&gt; {/NP} Ev1:Requires(I) sphingosine_kinase(E) cell_migration(R) Ev2:Requires(I) EDG-1(E) cell_migration(R) Ev3: Requires(I) EDG-1(E) PDGF(R) Ev4: Link(I) PDGF(E) EDG-1(R) Ev5: Link(I) EDG-1(E) PDGF(R) I : Requires, Link E : EDG-1, sphingosine_kinase, PDGF R : cell_migration, EDG-1 Ev1:Requires(I) sphingosine_kinase(E) cell_migration(R) Ev2:Requires(I) EDG-1(E) cell_migration(R) Ev4:Link(I) PDGF(E) EDG-1(R) class of each extracted entity is the same as the class that the ME classifier generates. In the case of extracted events Ev3 and Ev5, PDGF X  X  class was extracted as  X  X  X  and contradicted by the results of the ME classifier. So we removed Ev3 and Ev5 from our final results. 3. RESULTS OF THE EXPERIM ENTS AND DISCUSSION We evaluated the performance of our system in extracting events, consisting of  X  X nteraction, X ,  X  X ffecter, X  and  X  X eactant X  and performed a ten-fold cross-validation. We used 500 MEDLINE abstracts containing approximately 3,100 sentences and 2,314 biological events in the GPCR-related signal transduction pathway domain, for which biology experts annotated the biological event answers and NE classes. Before learning we split the compound and complex sentences into simple sentences in order to learn the rules for extracting biological events in a re gular-expression format. Since our system is constructed automatically and errors in th e linguistic preprocessi ng phase affect the system X  X  overall performance, we first eval uated the performance of the sentence splitter and the extractor of th e chunking structure (Table V). Due to the complexity of biological texts, we obtained somewhat low performan ce compared to other domains, such as the newspaper domain for instance. performance, we initiated some additional expe riments. We selected 50 abstracts that were linguistically preprocessed by our system . and corrected all the errors to measure the experiment. test with our two-level rule-learning method. This experiment was done with an inner verification process test of 50 abstracts. As a result we obt ained a 66.7 F-measure before correcting linguistic errors, and after correcti ng them we obtained a 67.0 F-measure, an improvement of 0.3 points. The low improvement rate demonstrates that our system is relatively robust against linguistic errors in chunking and splitting sentences. the two-level rule learning method increase performance, and the other to confirm the change in trade-off between precision and re call before and after verification according to the threshold in the first phrase-learning module. sentences among them with two or more bi ological events. So 58.3% of the sentences with at least one biological event actually contain two or more biological events. threshold 5 to 0 in the first learning phase, and improved precision by removing incorrect biological events in the second verification phase. As a result, we obtained 68.0% recall and 38.2% precision before verification in tw o-level rule learning; but after removing incorrect events with our event component verifier, the precision was raised to 53.1%, with an increase in the final F-measure from 48 .9 to 54.6. In addition, we confirmed that two-level rule learning increa ses recall from 58% to 68% before verification, rather than the conventional one-level rule learning. adopted a similar supervised machine-learning method. Even though a direct comparison is not possible, due to the different definitions for the corpus and event structures, the two corpora actually come from the same data domain  X  Medline. Bo th corpora contain similar contents about interactions between biomedical entities. They focus on extracting interacting protein-pairs from 1,000 abstracts, 6 and report a performance of 48.2, which is the best F-measure among the wide range of precision-recall trade-off results. We also performed the same experiments, this time using four full texts containing about 300 sentences and 702 complex biological events, and doubly confirmed that our ideas still improved performance (Table VIII). In our second experiment, four full texts have on average of more than two and fewer than three biological events per each sentence, while 500 abstracts in the first experiment had fewer than one biological event in each se ntence. But in the F-measure score for each experiment, the second one had a larger F-m easure score. This result means that the two-level approach has an advantage even when the sentences have a complex structure. 7 between precision and recall, regardless of the threshold in supervised machine learning. extracted events using the rule in the training corpus were correct; for instance, if all the score to decide the threshold for adjusting the trade-off between precision and recall. For verification, we extracted all the events, regard less of the rule X  X  score, to guarantee high rules with scores below threshold. In other words, we did not verify the events extracted using the rules with scores above threshold. As a result, we could conserve high-quality events extracted from rules with high scores by not verifying them, and improve the recall/precision by removing the low-quality even ts with verification. In Figures 4 and 5, the graph shows that we could maintain high precision and high recall as the verification threshold increases. For the graph before verification case, we used the threshold to eliminate the rules and only applied the rules with scores above the threshold. Therefore, we confirmed that verification after extraction of biological events can actually overcome, with a consistently good performance, the trade-off between precision and recall. 4. CONCLUSIONS AND FUTURE WORK We presented a two-phase approach to extr act biological events by constructing rules with supervised machine learning and later by verifying the extract ed biological events. In the first learning phase, we reduced the human effort by obtaining the rules automatically and focused on the recalls, an d in the second phase, we removed the incorrectly extracted events with an event component verifier to increase precision. In addition to the two phases in the entire ar chitecture, we proposed a two-level rule-learning algorithm to cover both the short-span events in a noun chunk and the long-span events throughout a whole sentence. In the e xperiments, we confirmed that our system contributes to an increase in performance with the two new ideas above: with verification we increased the final F-measure from 48.9 to 54.6; and, with two-level rule-learning before verification using 500 Medline abstracts, recall increased from 58% to 68%. In addition, we could adjust the trade-off between precision and recall with threshold, while conserving extracted high-quality biological events after verification. original sentences directly and call on bi ologists to correct the results manually. In addition, we will construct more training material to learn more meaningful extraction rules by providing an annotation workbench tool, one of the tools under implementation efficiently mining useful and valuable information from rich biomedical text resources. An event-extraction tool displays the results graphically and stores the results in XML format. The workbench tools provide candidate sentences that incl ude interaction words and at least two entities; biologists check each candidate sentence and select the key words that need to be annotated; and the system then annotates the selected interaction words in each sentence with the appropriate tags. Soon, the workbench tools will be integrated into our event-extraction system to provide synergy and beneficial effects. REFERENCES 
