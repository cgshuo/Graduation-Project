 We present an efficient realization of the following interac-tive search engine feature: as the user is typing the query, words that are related to the last query word and that would lead to good hits are suggested, as well as selected such hits. The realization has three parts: (i) building clusters of re-lated terms, (ii) adding this information as artificial words to the index such that (iii) the described feature reduces to an instance of prefix search and completion. An efficient solution for the latter is provided by the CompleteSearch engine, with which we have integrated the proposed fea-ture. For building the clusters of related terms we propose a variant of latent semantic indexing that, unlike standard approaches, is completely transparent to the user. By ex-periments on two large test-collections, we demonstrate that the feature is provided at only a slight increase in query pro-cessing time and index size.
 H.3.3 [ Information Search and Retrieval ]: Query for-mulation, Search process; H.3.1 [ Content Analysis and Indexing ]: Indexing Methods, Thesauruses; H.5.2 [ User Interfaces ]: Interaction styles Design, Experimentation, Human Factors, Performance Index Building, Interactive, Query Expansion, Synsets, Wiki-pedia, WordNet
Adding related terms to the query in order to increase recall is an old and much-researched technique commonly CIKM X 07, November 6 X 8, 2007, Lisboa, Portugal.
 Copyright 2007 ACM 978-1-59593-803-9/07/0011 ... $ 5.00. known as query expansion . A recent, very good overview is provided in [3]. Our work is different from the traditional approach in two respects.

Efficiency The standard way to implement query ex-pansion is to replace each query word by the disjunction (OR) of its related terms, and then merge the individual inverted lists [3]. Since each step of such a merge is loga-rithmic in the number of lists, expansion is typically limited to a few important words. Sophisticated top-k techniques, like in [10], try to prune expansion words which are unlikely to lead to an improved ranking.

Interactivity &amp; context-sensitivity Our feature in-teractively suggests words related to the word currently be-ing typed, and the suggestions are ranked by their ability to lead to good hits together with the preceding part of the query. For example, for the query russia metal from Figure 1, aluminum is high up in the list of words related to metal , because there are many news articles about alu-minum production in Russia. Similar interactive features have been discussed in the literature [7], but with the focus on effectiveness and not on efficiency.

We do not claim novelty for any of these individual points (efficient, interactive, context-sensitive). However, we have not seen them presented in combination, and we want to stress the simplicity with which we realize this feature here, provided that an efficient prefix completion mechanism is available. We remark that synonym search has already been mentioned in [2], but the idea from Section 3, which is key for an efficient implementation, was missing at that time.
The following prefix search and completion operation was presented in [2]: given a prefix p (the partially typed last query word) and a set of documents D (the hits for the preceding part of the query), compute a ranked list of words starting with p and occurring in D , as well as a ranked list of documents from D containing words starting with p . The contribution of [2] was a new index data structure, coined HYB, for efficient support of this operation. The main idea behind HYB is to store unions of inverted lists of groups of words that share a common prefix in a highly compressed format.
The key idea is to add the information we have about related terms as artificial words to the index such that the feature we want becomes a matter of a few prefix completion operations. We realize this as follows: 0. As input, assume we have clusters of related terms. These clusters may overlap, for example the word case may be in one cluster together with cover , shell , etc. as well as in another cluster together with box , chest , etc. 1. For each occurrence of a term &lt;t&gt; that occurs in a cluster same document and at exactly the same position. (Document position is important for proximity and phrase search. We remark that the HYB index does not mind several terms at the same position in the same document.)
Also add, but only once for each such term and in a special document that is used for no other purpose, the artificial term s:&lt;t&gt;:&lt;id&gt; . The number of words in this document is just the total size of all clusters. our feature via one or two prefix completion operations as follows: We first check whether &lt;q1&gt; ... &lt;ql&gt; s:&lt;p&gt; has a unique completion of the form s:&lt;t&gt;:&lt;id&gt; . If so, this completion gives us the id &lt;id&gt; of the cluster con-gives us the desired completions and hits. (Note that the part &lt;q1&gt; ... &lt;ql&gt; is evaluated only once, just after its last letter being typed, and stored by a cache-like mechanism from then on; see [2] for details.)
We implemented and tested our feature for two collec-tions: the TREC Robust collection (1.5 GB, 556,078 doc-uments), and the English Wikipedia (8 GB, 2,863,234 doc-uments). For each of the collections we used a different method to derive the clusters of related terms, one unsu-pervised and one supervised. The following two subsections give details on each of the methods. The results of the ex-periments are given in Section 5.
For the Robust collection, we used a completely unsuper-vised approach based on the technique from [1], as follows. 1. Since Eigenvector computations on large matrices are 2. We obtained a set of related term pairs from these 3. We used the Markov Clustering Algorithm (MCL) al-
Note that this approach makes the result of this unsuper-vised learning algorithm, and its effect on the search results, completely transparent to the user. In contrast, methods in the spirit of latent semantic indexing [5] are often criticized for their incomprehensibility on the side of the user concern-ing why a certain document show up high in the ranking. It would be interesting to verify the significance of this differ-ence in a user study. http://www.coli.uni-saarland.de/~thorsten/tnt http://www.tartarus.org/  X martin/PorterStemmer/perl.txt http://micans.org/mcl Figure 2: One of the clusters of related terms au-tomatically obtained from the Robust collection.
 Edges present in the graph denote term-term re-lations found by the smoothness test from [1]. The cluster itself was then found using the clustering al-gorithm from [11]. Indeed, all the terms in the clus-ter are closely related: most of them are different metals, LME stands for London Metal Exchange, and Richard Mooney is the author of several arti-cles regarding the general topic of metal. For the Wikipedia, we made a straightforward use of Word-Net [6] to obtain clusters of related terms. Namely, we put two words that occur somewhere in Wikipedia in the same cluster if and only if they share the same most frequent synset. E.g., for the term  X  X ar X  the synset corresponding to  X  X uto X , X  X utomobile X , X  X achine X  and  X  X otorcar X  was used, but not the ones corresponding to  X  X ailcar X  or  X  X ondola X . Table 1 shows all synsets for the term  X  X ar X . This heuristic leads to only about 30% more tokens in the index. Using all synets, would spoil both efficiency and usefulness of our feature.

Furthermore, we only used single terms and ignored com-pound nouns in open form ( X  X awn tennis X ), as we build our index for individual terms. 4 The descriptions and the ex-ample phrases for the synsets were also not used, as they do not explicitly contain any synonymy information. We integrated the described feature with the Complete-Search engine, and measured its efficiency on two query sets. The first query set is derived from the 200  X  X ld X  5 queries (topics 301-450 and 601-650) of the TREC Robust Track in 2004 [12]. For the second query set, we started with 100 random queries, generated as follows: For each query, we picked a random document and sampled 1 to 5 terms (with a mean of 2.2 and a median of 2, which are realistic values for web search queries [9]) according to their tf-idf values.
For both query sets, these raw queries were then  X  X yped X 
Inclusion of such compound nouns is theoretically possible, but it was not implemented for this study.
They had been used in previous years for TREC. 1. car, auto, automobile, machine, motorcar (a motor ve-2. car, railcar, railway car, railroad car (a wheeled vehi-3. car, gondola (the compartment that is suspended from 4. car, elevator car (where passengers ride up and down) 5. cable car, car (a conveyance for passengers or freight Table 1: A complete list of the WordNet synsets for the noun  X  X ar X . For our experiments, we assigned each word only to its most frequent synset, so for  X  X ar X  we used the first set in the list above. The term  X  X achine X  would in the end not be used as a synonym for car, as its most frequent synset refers to a different concept. from left to right, using a minimal prefix length of 3. So the raw query  X  X ult lifestyles X  would yield the autocompletion queries cul , cult , cult lif , cult life and so on. Addi-tionally, whenever for a prefix &lt;p&gt; the query s:&lt;p&gt; led to a unique term cluster with id &lt;id&gt; , we added an OR (for which we use the  X  |  X ) with the prefix s:&lt;id&gt;: . E.g., one autocompletion query in the sequence for  X  X irport security X  is airport|s:399: secu|s:385: .
 All experiments were run on a machine with two 2.8 GHz AMD Opteron processors (two cores each, but only one of them used per run), with 16 GB of main memory, operating in 32-bit mode, running Linux.
 Query set Average 90%-tile 99%-tile Max
Robust (all) 32 ms 90 ms 375 ms 970 ms -normal 22 ms 55 ms 329 ms 970 ms -synonyms 57 ms 129 ms 385 ms 655 ms
Wikipedia (all) 64 ms 238 ms 614 ms 1218 ms -normal 42 ms 128 ms 569 ms 1218 ms -synonyms 35 ms 356 ms 799 ms 841 ms Table 2: Breakdown of processing times for both of our query sets. For  X  X ormal X  queries there was no synonymy information to be used.

Table 2 shows that, by using the term clusters, the aver-age processing time increases by roughly 50% (but not more) with respect to queries without synonymy information, and it is still well within the limits of interactivity. Somewhat surprisingly, the maximum processing time is lower for the queries with synonymy information. This is because the queries which take the longest to process are those with a very unspecific last query word, for example, cont . Such words tend to have more than one completion for which synonymy information is available, and in that case our in-terface, as described above, does not show any related terms, but only syntactic completions. [1] Bast, H., and Majumdar, D. Why spectral retrieval [2] Bast, H., and Weber, I. Type less, find more: fast [3] Billerbeck, B. Efficient Query Expansion . PhD [4] Brants, T. Tnt  X  a statistical part-of-speech tagger. [5] Deerwester, S. C., Dumais, S. T., Landauer, [6] Fellbaum, C. , Ed. WordNet: An Electronic Lexical [7] Fonseca, B. M., Golgher, P. B., P  X  ossas, B., [8] Porter, M. F. An algorithm for suffix stripping. [9] Spink, A., Jansen, B. J., Wolfram, D., and [10] Theobald, M., Schenkel, R., and Weikum, G.
 [11] van Dongen, S. Graph Clustering by Flow [12] Voorhees, E. Overview of the Trec 2004 Robust
