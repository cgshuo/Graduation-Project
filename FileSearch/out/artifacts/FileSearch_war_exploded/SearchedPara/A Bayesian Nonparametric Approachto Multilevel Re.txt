 Vu Nguyen 1( Real data is complex. They hardly conform to simple flat structure or a well-defined regular pattern. Multilevel, or hierarchical and nested, data structure persists in almost every day analysis tasks. Patients organized in different cohorts in multiple hospitals; economic activities of a city nested within a state, which is in turn influenced by national economic status and so on. Multilevel analysis [ 11 , 14 , 23 ] is an approach to analyze group contexts as well as the individual outcomes. In multilevel analysis, multilevel regression are commonly used in econometrics (panel data), biostatistics and sociology (longitudinal data) for regression estimation. Examples include panel data measures GDP observations over a period of time tracking in multiple states of the USA or longitudinal studies on a collection of patients X  admissions to a hospital. To the best of our knowledge, almost no work of multilevel regression has attempted to model group context information to form  X  X ptimal X  cluster of groups to be regressed together. The main challenge is how to model the optimal or  X  X orrect X  clustering to leverage shared statistical strengths across groups.
 In this paper, we consider the multilevel regression problem in multilevel anal-ysis where individuals including observations and outcomes are organized into groups. Our modelling assumption is that individuals exhibit similar regression behaviours should be grouped and perform regression task together to lever-age on their shared statistical strengths. For example, children with the same parents tend to be more alike in their physical and mental characteristics than individuals chosen at random from large population. Particularly, we focus on the multilevel regression problem for predicting individuals in unseen groups , the groups do not appear in the training set. For example, in health research -relied on patient X  X  history of electronic medical record (EMR) -patient history records can be empty for patients have not admitted to a hospital before. Pre-dicting individuals in unseen groups using multilevel regression presents another contribution of our work.
 independent observations. Hence, it tends to mis-specify the regression coeffi-cients, leading to poor fitting in overall populations. The well-known approach to multilevel regression is the Linear Mixed Effect model [ 16 , 20 ]. However, it is not well applicable for predicting individuals from unseen groups because the random effect is fixed to the given training groups.
 data group is treated as a task and individual seen as example s. Multi-task regression aims to improve generalization performance of related tasks by joint learning [ 4 ]. A few works have attempted to partition related tasks into task-groups [ 12 ]. Bayesian nonparametric approach is used to overcome the difficulty in defining the degree of relatedness among tasks [ 10 ]. For testing and evaluation, previous works use a proportion of examples in each task for training and the rest is further used for testing. Given a testing example, the task which the example belonged to, is identified from the hierarchical structure of the data. Nevertheless, given a testing example from unseen task, there is no proper way to perform prediction.
 sion (BNMR) model. The model uses a Dirichlet Process as a product base-measure of group-context distribution and regression distribution to discover the unknown number of group clusters and do regression jointly. The group cluster is estimated based on the group-context observation and regression outcome of individuals. The goal is making the related groups strengthen each other in regression while unrelated groups do not affect themselves. In addition, simulta-neously clustering groups and performing regression can prevent from overfitting to each training group. By using group-context information, the proposed model can assign the unseen group into an existing group-cluster for regression. Regression is a large research field. Within the scope of the paper, we focus on the model which can perform multilevel regression where the data presented in groups.
 be more similar than observations from different groups. Standard single level regression models are not robust against violation of the independence assump-tion. That is why we need special multilevel treatment.
 Dealing with grouped data, a popular setting known as multilevel analy-document modelling and clustering [ 18 ].
 We consider a pair of outcome and observation in hierarchical structure ( y R, x ji  X  R d ) where y ji is an outcome (or response) and x ji trial i in group j . The multilevel models are the appropriate choice that can be used to estimate the intraclass correlation and regression in the multilevel data. Specifically, we consider Linear Mixed Effects models which are extensions of linear regression models for data that are organized in groups.
 Linear Mixed Effects Model. The LME model [ 16 ] describes the relationship between a response variable and independent variables in multilevel structure, with coefficients that can vary with respect to one or more grouping variables. A mixed-effects model consists of two parts, fixed effects and random effects. Fixed-effects terms are usually the conventional linear regression part, and the random effects are associated with individual experimental units drawn randomly from population. The random effects have prior distributions whereas fixed effects do not. Linear Mixed Effects model can represent the covariance structure related to the grouping of data by associating the common random effects to observations in the same group. The standard form of a linear mixed-effects model is following: where the regression coefficients for group j :  X  j 0 and Therefore, the final form to predict the individual outcome variable y individual explanatory variables x ji and group explanatory variable c lowed: Fixed effects have levels that are of primary interest and would be used again if the experiment were repeated. Random effects have levels that are not of primary interest, but rather are thought of as a random selection from a much larger set of levels. We present the graphical representation of LME model in Fig. 1a . The common parameter estimation methods for linear mixed effect include Iterative Generalized Least Squares [ 9 ] and Expectation Maximization algorithm.
 3.1 Linear Regression Regression is an approach for modelling the relationship between a scalar outcome variable y and one or more explanatory variables denoted x data are modelled using linear predictor functions, and unknown model param-eters are estimated from the data. Given a data collection y of N units, linear regression model assumes the relationship between the outcome variable y i and the d -dimension vector of observation x takes the form: y i = x T i  X  + i where i is a residual or error term, sion coefficient, including intercept and slope parameters. The solution for  X   X  = X T X 3.2 Bayesian Linear Regression Bayesian linear regression is an approach to linear regression in which the statis-tical analysis is undertaken within the context of Bayesian inference with a prior distribution for parameter  X  . In this setting, the regression errors (or residual) is assumed to follow a normal distribution i  X  X  0 , X  2 . Given a data point x  X  R d and its respond variable y , the likelihood of Bayesian linear regression model with parameter  X  is defined as: Posterior probability distributions of the model X  X  parameter under conjugate prior distribution  X   X  X  (0 , X  0 ) is estimated following: where the posterior mean  X  n =  X  n X  X   X  1 / 2 Y , and posterior covariance  X  with new response y new is computed: 3.3 Bayesian Nonparametric We provide a brief account of the Dirichlet Process Mixture and the Nested Dirichlet Process [ 21 ] which related to our work.
 A Dirichlet Process [ 7 ]DP(  X , H ) is a distribution over discrete random prob-ability measure G on (  X , B ). Sethuraman [ 22 ] provides an alternative construc-tive definition which makes the discreteness property of a draw from a Dirichlet process explicit via the stick-breaking representation: G =  X  iid  X  H, k =1 ,...,  X  and  X  =(  X  k )  X  a  X  X tick-breaking X  process. As a convention, we hereafter write Dirichlet Process has been widely used in Bayesian mixture models as the prior distribution on the mixing measures, resulting in a model known as the Dirichlet Process Mixture model (DPM) [ 1 ].
 Dirichlet Process can also be constructed hierarchically to provide prior dis-tributions over multiple exchangeable groups. One particular attractive approach is the Hierarchical Dirichlet Processes (HDP) [ 24 ] which posits the dependency among the group-level DPM by another Dirichlet process.
 Another way of using DP to model multiple groups is to construct random measure in a nested structure in which the DP base measure is itself another DP. This formalism is the Nested Dirichlet Process [ 21 ], specifically G U  X 
DP (  X   X  DP (  X H )). modelling G j (s) hierarchically as in HDP and nestedly as in nDP yields different effects. HDP focuses on exploiting statistical strength across groups via sharing atoms  X  k (s), but it does not partition groups into clusters. Whereas, nDP emphasizes on inducing clusters on both observations and distributions, hence it partitions groups into clusters. Finally we note that this original definition of nDP in [ 21 ] does not force the atoms to be shared across clusters of groups, but this can be achieved by introducing a DP prior for the nDP base measure [ 18 , 19 ]. In this section, we describe our framework of Bayesian Nonparametric Multilevel Regression (BNMR). Our goal is to simultaneously clustering the groups and estimating regression for individuals . The fundamental assumption is that when the groups are related, the group-level explanatory variable (or group-context observation) is induced in the same distribution component (e.g., Gaussian dis-tribution). Firstly, we aim to use the related groups to strengthen regression esti-mation for improving regression performance (prevent from overfitting to each group) while unrelated groups do not influence themselves. Second, the induced group-context distribution can be used to identify cluster for new groups (based on group-context observations in new groups).
 Iteratively modelling and clustering group context and individual regression would gain benefit and mutually promote each other. First, good groups cluster-ing will produce good regression estimation (e.g. we assume individuals in the same group-cluster have similar regression behavior). Second, the good regression esti-mation in return provides important information for the group-clustering process previously. 4.1 Model Representation We consider data presented in a two-level structure. Denote by J the num-ber of groups, we assume that the groups are exchangeable. Each group j contains N j exchangeable explanatory variable and response variable, repre-sented by x ji  X  X  d ,y ji  X  X  N j i =1 . The collection of level explanatory or group-level context (e.g., age of the patient, population of the state).
 base measure for generating group-context distribution and S is a base measure for generating regression coefficients. We use a product base measure of H to drawn a DP mixture for jointly clustering groups and regression individuals. Particularly, we have: the group-level explanatory observation c j and  X  y j is further used to drawn the individual response variables y ji following: Stick-breaking representation. We further derive the stick-breaking repre-sentation for BNMR (c.f Right Fig. 1b ) where all of the random discrete measures are characterized by a distribution over integers and a countable set of atoms. The random measure G has the form: G = K k =1  X  k  X  (  X  k for each group z j iid  X   X  and generate group-context explanatory variable c F  X  j . Accordingly, the response variables in group j given the cluster z is drawn y ji  X  X  x T ji  X  k , X  2 . 4.2 Inference We derive collapsed Gibbs sampling for BNMR. Due to the conjugacy property, we would integrate out  X  k ,  X  k ,and  X  . The remaining latent variable parameter  X  will be sampled.  X  Sampling z j . The conditional distribution for sampling z is: The first expression p ( z j = k | z  X  j , X  ) is the Chinese Restaurant Process (CPR) with concentration parameter  X  . The second term is the predictive like-lihood of group-context observation under component (or topic) k .Thiscan be analytically computed due to conjugacy of likelihood distribution and prior distribution H . The last term is the likelihood contribution from regression observations (including explanatory and response variables) in group j following Eq. 2 .  X  Sampling concentration parameter  X  is similar to Escobar et al [ 6 ]. Assum-ing  X   X  Gamma (  X  1 , X  2 ) with the auxiliary variable t : p ( t (  X  1 +1 ,J ) where J is the number of groups and  X  t 1  X   X  We integrate out the regression coefficient  X  k for collapsed Gibbs inference. However, for visualization and analysis of the regression coefficient re-computed as p (  X  k | x i , y i ,z i = k,  X  0 ) following Eq 1 . Given unseen groups of data include x Test ji ,c Test y ji . We observe that if  X  k and  X  2 are known, then y Test by We demonstrate the proposed framework on multilevel regression task, especially for regression individuals in unseen groups of data. Throughout this section, unless explicitly stated, the training and testing sets are randomly split, and repeated 10 times. The variables x ji and y ji is centralized to have the mean of 0 as recommended in regression tasks [ 11 ]. Our implementation is using Matlab. For synthetic and Econometric panel data, each iteration takes about 1-2 seconds and it takes 30-35 seconds for Heathcare dataset. All experiments are converged quickly within 30 iterations of collapsed Gibbs sampling. Initialization for con-centration parameter  X  =1,  X   X  Gamma (1 , 2). The conjugate distribution for group-level context is NormalGamma. We use four baseline methods for com-paring the regression performance on individuals of unseen groups followings: 1. Naive Estimation: using the overall average of individuals outcome in train-2. No-Group MultiTask Learning (NG-MTL) [ 2 ]: where all tasks are considered 3. No-Group MultiTask Learning With Context (NG-MTL-Context): where The regression performance is evaluated using two metrics: Root Mean Square Error (RMSE), and Mean Absolute Error (MAE). Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. The MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. The regression algorithm is the ideal when it has lower error in both RMSE and MAE. 5.1 Synthetic Experiment Our goal is to investigate BNMR X  X  ability to recover the true group clusters and number of regression atoms. We first create three univariate Normal dis-tributions  X  k (s) with different variances (Fig. 2 ) for generating group-context observations. Conditional on these context distribution, we initialize three linear regression atoms  X  k (s) with standard deviation for residual error  X  we randomly sample J = 200 groups, each group comprises a group-context c and N j = 20 pairs of observation ( x ji ,y ji ).
 The model recovers correctly the ground truth atoms. Visualizations of the group-context distribution and generated data are plotted in Fig. 2 . For evalu-ation, we split data into 70% number of groups for training and the rest (30% groups) for testing. The performance comparison is displayed in Table 1 so that our model gains great improvement in regression than the baseline methods. 5.2 Econometric Panel Data: GDP Prediction The Panel Data [ 17 ] includes 48 states (ignoring Alaska and Hawaii) and 17 years of GDP collection from 1970 to 1986. There are nine divisions in the United States, e.g., New England, Mid-Atlantic, Pacific, and so on (Fig. 3a ). Each division contains from 3 to 8 states.
 The explanatory variable x ji for each year i in a state j includes 11 dimen-sions, such as public capital stock, highways and streets capital stock, water and sewer facilities capital stock, employees on non-agricultural payrolls, unemploy-ment rate, and so on. The response variable y ji is a GDP.
 We consider the state population (Wyoming has the lowest population of 0.57 millions and the highest population of 38 millions belongs to California, as of 2012) is an explanatory variable for group level. Population is one of the key factor determining the GDP [ 13 , 15 ]. Hence, states which alike number of population tend to have similar GDP outcome than other states in different number of population. We model the context distribution using univariate Gaus-sian distribution. The mean and precision for group context distribution are (  X ,  X  )  X  NormalGamma(4 , 0 . 25 , 0 . 01 , 1) and the standard deviation for regres-sion residual error is set as  X  = 7000.
 the testing set do not appear in the training. We vary the proportion of training states from 40% to 90% and perform prediction on the rest. The number of state clusters are identified as K = 3 (indicating low, mid, and high population). The regression performance of BNMR versus NG-MTL, NG-MTL-Context and LME are plotted in Fig. 3 . We do not include the scores of Naive Estimation into the figure because of its poor performance in this dataset. This poor performance of Naive Estimation can be explained by the high variance in the outcome (e.g., the GDPs of California and Texas are 10-20 times higher than GDPs of Vermont and Delaware). The proposed method achieves the best regression performance in term of RMSE (Fig. 3b ) and MAE (Fig. 3c ) scores. The more state we observe, the more accuracy in prediction we achieve. 5.3 Healthcare Longitudinal Data: Prediction Patient X  X  Readmission Meaningful use, improved patient care and competition among providers are a few of the reasons electronic medical records are succeeding at hospitals. Read-mission interval prediction could be used to help the delivery of hospital resource-intensive and care interventions to the patients. Ideally, models designed for this purpose would provide close estimation of the admission interval for the next admission. Very often, patients come to a hospital without any existed elec-tronic medical records because they may have not been admitted before. This fact causes problem for existing multilevel regression approaches. We aim to use the proposed framework to improve performance for predicting readmission interval on new patients.
 interest is in the chronic Polyvascular Disease (PolyVD) cohort. The collected data includes 209 patients with 3207 admissions in total. We consider the read-mission interval within less than 90 days between two consecutive admissions. We treat a patient as a group consisting of multiple admissions as individuals . The feature for each admission x ji (in patient j ) includes External Factor Code , and Diagnosis Code in 289 dimension.
 The readmission interval outcome y ji indicates how many days between this admission to the next admission. We use patient X  X  age as a group-context c assume that patients within the same  X  X ge region X  would have the similar effects on diseases and readmission gap. For example, under the same diseases, patients in the age of 40-50 would be readmitted to a hospital differently from patients in the age of 70-80 because the prevalence of most chronic diseases increases with age [ 5 ]. The mean and precision for context distribution are(  X ,  X  ) and the standard deviation for regression residual error is specified as  X  = 24. The data is split with 147 patients (70%) for training and the rest of 62 patients are used for testing (as unseen patients). The posterior inference results in K = 6 patient clusters. The univariate Normal distribution of age is plotted in Left Fig. 4 where we discover the patient X  X  age distribution. In addition, we visualize the two conditional regression coefficients (  X  of age 50 and 78 respectively. The estimated  X  k (s) also reveal the correlation among disease codes to patient age clusters (Middle Fig. 4 ). There are several disease codes, such as Inflammatory disorders of scrotum (feature dimension 287), affecting on the elder of 78 rather than the younger of 50 (resulting zero value in vector regression coefficient).
 Our model uses group-level explanatory variable to identify patient X  X  clusters, then do regression using the regression coefficients produced by the patients in the same cluster. Thus, we prevent from overfitting on each training patient and obtain better prediction on testing patients than the three baseline methods (Right Fig. 4 ). We have presented a novel approach for multilevel regression where prediction target is for individuals in new groups. The need of multilevel regression for individuals in unseen groups are commonly encountered in many data domains from econometrics panel data and healthcare longitudinal data domains. Our BNMR provides a join model for clustering groups and do regression for indi-viduals. The unknown number of group cluster and regression coefficients are identified using Bayesian nonparametric setting. By clustering group, the esti-mated regression coefficients are more generalized and do not overfit to each training group.

