 LIPAH, Computer Science Department, Faculty of Sciences of Tunis, University Campus, Tunis, Tunisia E-mail: tarek.hamrouni@fst.rnu.tn 1. Introduction and motivations
With the development of computer tools, we noted these last years a fl ood of information stored in large databases [21]. The need to interpret and analyze these data raises much interest. The setting of new data analysis solutions became then a real challenge for the scienti fi c community. To overcome the lack of extracted knowledge from stored data, new methods were proposed, gathered under the generic term of Knowledge Discovery in Da tabases (KDD) [48,76]. Accordin g to Frawley et al. [50]:  X  X he Knowledge Discovery in Databases indicates the interactive and iterative process for extracting implicit knowledge, previously unknown and potentially useful starting from stored data in databases X . Within a KDD process, the data mining is the step focusing on the mining part of interesting patterns. database management, mathematics, arti fi cial intelligence, etc. In few years, the data mining has become a research fi eld in full progress aiming at exploiting the great quantities of data collected in various domains using computer sciences. The data mining proves to be very useful for different complementary carried out using several techniques such as association rules, neural networks, etc., and models such as decision trees, etc. [76]. 1.1. Frequent itemsets as an important pattern class in data mining
In this paper, we are interested in a key pattern class in data mining, namely frequent itemsets .This class is among the most popular research topic [75]. The extraction of frequent itemsets is usually considered as a starting point for getting association rules. Since its inception in [1], association rule mining has become a fundamental topic in data mining and has been extensively investigated. Its key idea consists in looking for relationships between sets of items, commonly called itemsets , where the presence of some items suggests that others follow from them. A typical example of a successful application of association rules was the market basket analysis [1], where the discovered rules can lead to important marketing and management strategic decisions. In this case, each transaction consists of a list of bought items (or products). The purpose was to identify the groups of items frequently bought together. The the fi nest data which compose a transaction: sales of the elementary items. The mining of associations then aims at fi nding relations or correlations which could exist between products (for example, 80% of customers who buy tomato and salad also buy oil), but also between product sales (for example, when the sales of milk increase then the sales of chocolate increase with a con fi dence of 60%).
The discovered association rules can be used in various tasks, such as depicting purchase dependencies, of objects (or transactions), the frequent pattern mining problem consists of getting out, from a dataset, patterns having a number of occurrences (i.e., conjunctive support or support for short) greater than or Note also that association rules can be related to rules de fi ned in the general GUHA approach [66,67]. 1.2. Why do we need concise representations of frequent itemsets?
In practice, the number of frequent itemsets, and hence association rules, can be overwhelmingly large hampering their effective exploitation by the end-users. In order to reduce the number of mined rules, statistical measures were introduced, amongst the most known are the support and con fi dence [58]. Nevertheless, if the minimum support threshold is set too low or the data is highly correlated, no matter how ef fi cient the frequent pattern mining algorithm is, generating all frequent patterns is impossible. Moreover, the set of patterns presents redundancy in the sense that many patterns convey the same information [6]. To overcome this problem, several proposals have been made to construct only a manageably-sized set of patterns from which we can regenerate all frequent patterns along with to their exact frequencies. Such a reduced set is better known as exact concise (or condensed ) representation . A concise representation only stores a non-redundant cover of all frequent patterns. In many practical situations, this cover is considerably smaller than the complete collection of all frequent patterns. get out all frequent patterns. The purpose of such representations is then to reduce the number of mined patterns to make them manageable by the end-users while preserving as much as possible the hidden and interesting information about data.

Within the traditional association analysis, the conjunction connector  X  linking items  X  got the monopoly [39]. This was motivated by the original application pertaining to market basket analy-sis. In this respect, a growing number of approaches explored the conjunctive search space where items are characterized by the frequency of their simultaneous occurrence (or co-occurrence or conjunctive support ). The aim of such an exploration is to get out a lossless nucleus of itemsets, from which the remaining ones can be derived. Beyond high compactness rates, an exact concise representation of frequent itemsets makes it possible to determine the frequency status of an itemset and to exactly retrieve many exact concise representations of frequent itemsets were proposed in the literature [15,25,29,34,36, 85,103,111,120].

Interestingly enough, these exact representations were also extended to many pattern classes. For example, they are at the roots of different works aiming at concisely representing pattern classes such as associative (classi fi cation) rules [11,18,39,118], sequential patterns [10,104,126], graphs [149,153], trees [9,44], minimal transversals [79] , multidimensional patterns [38,122], etc.

Moreover, in this paper, we focus on exact concise representations of frequent itemsets. It is however important to mention that many approximate concise representations of frequent itemsets were proposed in the literature, like maximal frequent itemsets [16] (and their dual, i.e., minimal infrequent itemsets),  X  -free sets [25], condensed frequent pattern bases [121],  X  -clusters [148],  X  -tolerance closed frequent itemsets [43], etc. Although approximate concise representations offer very high compactness rates and constitute an interesting alternative in the case of noisy data, we did not treat them in this work since they do not allow deriving the exact quality measures of the associated whole set of interesting patterns. Moreover, their accuracy closely depends on the tolerated error bound. Interested readers in approximate representations are referred to the overview proposed in [42]. 1.3. Paper contributions
In the proposed overview, we describe the main concise representations of frequent itemsets that were proposed in the literature. The choice of these repre sentations follows from the fact that they constitute representatives of classes in which the associated representations share common characteristics. In addition, for each surveyed representation, we set up its link with the notion of minimal generator [15]. in which mainly the notion of closed itemset was frequently described ( cf. for example [17,19,39,61, 155]). Then, in this work, we are not only interested in exact concise representations but also in a focus on the key role played by minimal generators in several tasks. The main contributions of the paper are then as follows: 1. We review this notion of exact concise representation and link it to key concepts like the frame-2. We describe equivalence classes of itemsets allowing to partition the set of itemsets into disjoint 3. Compared to a high number of works which focus on closed itemsets, the role of minimal generators 4. We lead a detailed study of the main concise representations of frequent itemsets proposed in the 5. We discuss the concise representations of frequent itemsets with respect to several aspects, like the 1.4. Paper organization
The organization of the paper is as follows: Section 2 presents the basic de fi nitions related to the frequent itemsets search space. The notion of concise representation is then related to those of -adequate representation and MDL principle. The close link between both pattern classes, namely frequent itemsets and association rules, is also established. In Section 3, the notions of equivalence class, closed set, and minimal generator, deriving from the mathematical settings of Formal Concept Analysis, are studied in detail. Section 4 highlights the importance of the notion of minimal generators for representing and deriving pattern classes with or without the use of their closed sets. Section 5 gives an overview of the a discussion of each representation and an analysis of its link with the concept of minimal generator. Section 6 discusses several aspects related to concise representations for frequent itemsets and offers a critical comparative study of the surveyed representations. Conclusions and future work are given in Section 7. 2. Itemset search space
This section presents some basic de fi nitions that will be used in the remainder. 2.1. Extraction context and itemsets In this paper, we will consider datasets represented using binary contexts de fi ned as follows. De fi nition 1. ( Extraction context ) relation ( i.e., M X  X  X I ) . A couple ( o, i )  X  X  if the item i  X  X  occurs in the object o  X  X  . Example 1. Consider the context given in Table 1, used as a running example throughout this paper. matrix, on the contrary of the couple (5 , B ) whose associated cell is not crossed in the matrix. An extraction context can represent several kinds of data according to the associated applications, like market basket analysis, web log analysis, gene expression analysis, to cite but a few. In market basket analysis, each object records a customer purchase. Each item then represents a product. This allows for example to study the effect of the purchasing a given set of products on the remaining ones. On the other hand, in Web log data analysis, each object represents information associated to an access to a given server. In this situation, an item can represent the IP address, date of the access, etc. Here, the main goal can be to detect the suspicious access attempts. In gene expression data analysis, an object can represent an experience carried out on a given patient ( at a given date if several experiments are realized on the same patient ) . An item then refers to one of the studied genes. The main objective can thus be the study of the sets of genes that simultaneously appear as well as those that are present once others are absent.
 With respect to our running example, we will consider ourselves in the remainder in a market basket analysis context. The item A then refers to  X  X ggs X , B to  X  X read X , C to  X  X ugar X , D to  X  X utter X , E to  X  X ilk X , and F to  X  X hocolate X .
 An itemset is a set of items. For example, { C , D , E } is an itemset composed by the items C , D and E . E } .Theterms dataset and ( extraction ) context are also used interchangeably throughout the remainder of the paper. 2.2. Itemset supports: Links and associated constraints
An itemset can be characterized by different kinds of support. The latter are detailed in the following de fi nition.
 De fi nition 2. ( Support of an itemset ) Let K = ( O , I , M ) be an extraction context. We distinguish three kinds of support associated to a non-empty itemset I [36]:  X  Conjunctive support: CSupp ( I ) = |{ o  X  X  :(  X  i  X  I, ( o, i )  X  X  ) }| ,  X  Disjunctive support: DSupp ( I ) = |{ o  X  X  :(  X  i  X  I, ( o, i )  X  X  ) }| ,  X  Negative support: NSupp ( I ) = |{ o  X  X  :(  X  i  X  I, ( o, i ) /  X  X  ) }| .
 Roughly speaking, the different supports are de fi ned as follows:  X  CSupp ( I ) is the number of objects containing all items of I . In this case, the appearance of one item  X  DSupp ( I ) is the number of objects containing at least one item of I . In this case, the presence of  X  NSupp ( I ) is the number of objects that do not contain any item of I .
 Example 2. Consider the context depicted by Table 1. The different supports that can be associated to the itemset BC are: CSupp ( BC )=2 , DSupp ( BC )=5 , NSupp ( BC )=0 . In market basket analysis, the support of  X  bread  X  and  X  X ugar X  indicates the number of customers which purchased simultaneously these two items. While, the supportof X  bread  X  or  X  sugar  X  represents the numberofcustomershaving purchased either  X  X read X  or  X  X ugar X . Finally, the support of NOT  X  bread  X  andNOT  X  sugar  X  refers to the number of baskets in the database do not containing both  X  X read X  and  X  X ugar X .

Note that the conjunctive support of the empty set is equal to |O| since included in all objects. While the disjunctive support is not de fi ned on this pattern since it does not contain any item. The next proposition summarizes important pr operties related to th e itemset s supports. Proposition 1. Let i  X  X  , and I , I  X  X  . The following properties hold [69]:  X  CSupp ( i ) = DSupp ( i ) .  X  CSupp ( I ) DSupp ( I ) for I =  X  .  X  If I  X  I , then CSupp ( I ) CSupp ( I ) .  X  If I =  X  and I  X  I , then DSupp ( I ) DSupp ( I ) .

Given the respective disjunctive supports of the subsets of an arbitrary itemset, we are able to derive its conjunctive support using the inclusion-exclusion identities [51,113]. Furthermore, thanks to the De Morgan X  X  law , we are able to straightforwardly derive its negative support. Lemma 1 shows these important equations.
 Lemma 1. Let I  X  X  be an arbitrary itemset. Its conjunctive and negative supports are respectively derived as follows [51]: Example 3. Consider the context of Table 1. Given the respective disjunctive supports of BC  X  subsets, its conjunctive and negative supports are inferred as follows:
To prune the search space of itemsets, different types of constraints were investigated. Anti-monotone and monotone constraints, de fi ned in the following, are the most used ones [23].
 De fi nition 3. ( Anti-monotone constraint ) Let I  X  X  . A constraint Q is said to be anti-monotone if  X  I  X  I : I satis fi es Q  X  I satis fi es Q . De fi nition 4. ( Monotone constraint ) Let I  X  X  . A constraint Q is said to be monotone if  X  I  X  I : I satis fi es Q  X  I satis fi es Q . Example 4. By setting a minimum conjunc tive support threshold, we de fi ne an anti-monotone constraint, commonly called the frequency constraint. Thus, a frequent itemset has all its subset frequent, while an infrequent itemset has all its supersets infrequent. Dually, the disjunctive frequency constraint, relying on a minimum disjunctive support thr eshold, constitute s a monotone one.
 The next proposition states an important resu lt about the conjunction of constraints of the same type. Proposition 2. The conjunction of anti-monotone ( resp. monotone ) constraints results in an anti-monotone ( resp. monotone ) constraint.
 A proof of this propositio n can be found in [90].

Hereafter, CSupp ( I ) will simply be denoted Supp ( I ). In addition, if there is no risk of confusion, the conjunctive support will simply be called support . The next section focuses on frequent itemsets, induced by the frequency constraint. 2.3. Frequent itemsets
Since in practice we are mainly interested in itemsets that occur at least in a given number of objects, we introduce the notion of frequency [2].
 De fi nition 5. ( Frequency of an itemset ) The frequency of an itemset I  X  X  inacontext K , denoted by Freq ( I ) , is equal to Supp ( I ) |O| . Example 5. Consider the itemset CDE of the context given in Table 1. Since both objects 2 and 4 contain this itemset, Supp ( CDE ) = 2. The frequency of CDE is then equal to 2 purchase dataset, this means that two baskets among fi ve simultaneously contain  X  X ugar X ,  X  X utter X , and  X  X ilk X .

In the remainder, we will mainly use the support of itemsets instead of their frequency. Once a user-speci fi ed minimum support threshold minsupp is fi xed, an itemset can either be considered as frequent or as infrequent ( aka rare ) depending on its support. This is stated by the next de fi nition [2]. De fi nition 6. ( Frequent or infrequent itemset ) denoted minsupp. Otherwise, I is said to be infrequent or rare.
 Example 6. If minsupp = 1, then the itemset CDE is considered as frequent in K since Supp ( CDE ) = 2
By setting the minsupp threshold, we only consider frequent itemsets (and not the whole set of itemsets). Hereafter, we will denote by FI the set of frequent itemsets. The next proposition sheds light on an important property of the set of frequent itemsets. It states that all subsets of a frequent itemset are also frequent. Conversely, the supersets of an infrequent itemset are also infrequent. Proposition 3. Let I  X  X  . We have [2]:  X  If I  X  X I ,then  X  I  X  I , I  X  X I .  X  If I  X  X I ,then  X  I  X  I , I  X  X I .
 This result follows from the fact that the constraint induced by setting minsupp is anti-monotone ( cf. De fi nition 3).
 Example 7. If minsupp = 3, then the itemset CD is frequent in K since Supp ( CD ) = 4 3. As a consequence, based on Propos ition 3, we have its subsets C and D as frequent itemsets. Indeed, if four baskets simultaneously contain  X  X ugar X  and  X  X utter X , necessarily more than four baskets contain  X  X ugar X  and the same applies for  X  X utter X . If the itemset {  X  X ugar X ,  X  X utter X  } is frequent,  X  X ugar X  and  X  X utter X  are then also frequent. On the other hand, the itemset ABC is infrequent since Supp ( ABC ) = 2 &lt; 3. Thus, we have each superset of ABC as infrequent, for example ABCE whose support is equal to 1. Indeed, if only two baskets simultaneously contain  X  X ggs X ,  X  X read X  and  X  X ugar X , then the number of those also containing  X  X ilk X  will necessarily be less than or equal to two.

Let P ( I ) be the set of all subsets of I and ( P ( I ) , )betheset P ( I ) ordered w.r.t. a given order relation on itemsets. The set of frequent itemsets then forms an order ideal (or down-set) in ( P ( I ) , ) when partially ordered w.r.t. set inclusion. An order ideal is de fi ned as follows: De fi nition 7. ( Order ideal ) A subset S of P ( I ) is an order ideal in ( P ( I ) , ) if it ful fi lls the following properties [52]:  X  If I  X  S ,then  X  I  X  I , I  X  S .  X  If I/  X  S ,then  X  I  X  I , I /  X  S .

The set S is downward closed since for each I  X  S , all its subsets are in S . An order ideal splits the negative border, respectively [107]. The positive border contains the maximal , w.r.t. the order relation , elements among those that ful fi ll the constraint associated to the order ideal. While the negative border gathers the minimal , w.r.t. , elements among those that do not ful fi ll the constraint. These borders are formally de fi ned as follows: De fi nition 8. ( Positive, negative border ) Let ( P ( I ) , ) be a partially ordered set of elements, w.r.t. an order relation , and S be a subset of P its negative border B d  X  ( S ) de fi ned as follows [107]: an element belongs to this latter order, then it is the same for all its supersets ( cf. De fi nition 4). Example 8. Let us consider the order ideal obtained t hrough settin g a support constraint on itemsets using a minimum support threshold minsupp. Each itemset having a support greater than or equal to this In this situation, the subset S of P ( I ) is equal to the set FI of frequent itemsets. The positive border B d + ( FI ) contains the maximal, w.r.t. set inclusion, frequent itemsets: B d + ( FI )= { I  X  X | Supp ( I ) infrequent.
 Dually, B d  X  ( FI ) contains the minimal, w.r.t. set inclusion, infrequent itemsets: B d  X  ( FI )= { I  X  X | is then frequent.
 AD , AE , AF , BC , BD , BE , BF , CE , CF , DE , DF , EF } .

The next section describes important concepts on which the de fi nition of a representation for frequent itemsets is based. 2.4. Concise representations of frequent itemsets: Theoretical foundations
Several reported works shed light on the huge number of frequent itemsets that is often extracted from highly correlated contexts or for low minsupp values. In this situation, extracting a subset of itemsets this subset should enable the derivation of the whole set of frequent itemsets, associated to their exact supports. In this case, it is called exact concise representation of frequent itemsets .De fi nition 9 summarizes this concept [35]: De fi nition 9. ( Exact concise representation of frequent itemsets ) to determine whether an arbitrary itemset I is frequent or not, and, if I is frequent, its conjunctive support must be exactly derived from X .
In fact, the concept of concise representation for frequent itemsets derives from a more general frame-work, called the -adequate representation introduced in [106]. Intuitively, an -adequate representation is a representation which can substitute another one in order to answer the same request(s), more effec-tively, possibly at the cost of an error bounded by the parameter . We begin by describing this framework. After that, we adapt it to our context. An -adequate representation is de fi ned as follows [106]: De fi nition 10. ( -adequate representation ) Let S be a class of structures. Let Q be a class of queries for S . The value of a query Q  X  X  on a structure s  X  X  is assumed to be a real number in [ 0, 1] and is denoted by Q ( s ) .An -adequate representation for S , w.r.t. a class of queries Q , is a class of structures R , a representation mapping rep : S X  X  and a query evaluation function m : Q X R X  [ 0, 1] such that  X  Q  X  X  ,  X  s  X  X  , |
Q ( s )  X  m ( Q , rep ( s )) | .

That is, the values of queries from Q on any structure from S can be evaluated using the corresponding representation from R and the query evaluation function m with an error bounded by .
 Example 9. As a class of structures, we have for example S I , the class of all possible binary contexts de fi ned over a set of items I , S D , and S query class for S I can for example be the set Q I  X  X  . If we are for example interested with the frequency queries, we seek representations such as the error made on the frequency computed by rep ( s ) instead of s is at most for any s .

For example, let be a minimum frequency threshold. A frequent itemset has then a frequency greater than or equal to . The collection of the frequent itemsets and their frequencies can be considered an -adequate representation w.r.t. frequency queries. It means that the error on the inference of a frequency for a given itemset starting from this collection is bounded by . Indeed, the frequency of an infrequent itemset, i.e., not belonging to the collection since having an actual frequency strictly lower than ,can be set to 0. While the frequency of a frequent one is known exactly.

In the general case of concise representations of frequent itemsets, the class of structures S I is composedby the different sets of frequent itemsets that can be drawn from all possible binary extraction contexts EC ,de fi ned over a set of items I , a set of objects O , and for a minimum support threshold minsupp . Thus, S I frequency of itemsets of size no more than |I| . This set is as follows: Q the value of Q concise representation of frequent itemsets, R is the application of rep on the different contexts of EC : R = { rep ( K ) |K  X  EC} . Finally, m is the function by which the frequency of an arbitrary itemset is assessed starting from the representation rep .

The concise representation rep is then an -adequate representation of S I (i.e., the structure s corresponds to the set of frequent itemsets associated to a context K X  X C ), the itemset) with an error bounded by .

In this respect, an exact representation of frequent itemsets is an 0 -adequate representation. Indeed, for an arbitrary context and a given minsupp value, it must allow the exact retrieval of the respective frequencies of frequent itemsets. The error must hence be equal to 0 . In fact, this means that no error is tolerated in the case of an exact representation. This is not the case of approximate concise representations, like the  X  -free set-based one [25] and maximal frequent itemsets [16], from which only an approximation is possible when searching for the frequency of an arbitrary itemset.

An exact concise representation is also called perfect cover if it ful fi lls the conditions stated by the following de fi nition [36]: De fi nition 11. ( Perfect cover ) A cover of a set of patterns S is a set S that allows recovering S without information loss. S is said perfect if it is always a subset of S .

It is also important to note that exact concise representations are preferable to the whole set of frequent itemsets w.r.t. the minimum description length principle (MDL principle) [63,128]. This principle states that the best theory describing a set of data is the one minimizing the description length of the theory plus the description length of the data described (or compressed) by the theory. It seeks to minimize the description length of the entire data. The MDL principle is then a practical means for fi nding the best the general case, this principle can be roughly described as follows [63]: De fi nition 12. ( Minimum description length principle (MDL principle )) [63] Let H be a set of theories learned from a set of data D . The description of D usually comprises of two elements, namely the theory and the description of the data given the theory. The MDL principle dictates that the best theory H  X  X  for describing the data D is the one with minimum length, i.e., the one which minimizes the description length formula: in which  X  L( H ) , is called the theory cost, which measures the complexity of the theory H ,  X  L( D | H ) measures the degree to which the theory fails to account for the data D .
 Example 10. If we bring this principle into the context of concise representations of frequent itemsets, then the description length of the theory ( here, a theory corresponds to a concise representation CR of a context K X  X C ) is computed as: L(CR , FI K )= L ( CR )+ L ( FI K | CR ) .

For a group of theories ( concise representations in our case ) , a more complex theory tends to fi tthe data better than a simpler one, and therefore, it has a higher L(CR) value and a smaller L( FI K | CR) value. The theory with the shortest description length has the best balance between these two factors and is preferred. The MDL principle then seeks a concise representation that minimizes L(CR , FI K ) .
The next section focuses on a pattern class closely linked to that of frequent itemsets,namely association rules. 2.5. Association rule mining
As an important topic in data mining, association rule mining research [39] has progressed in various directions since its inception. The derivation of association rules is achieved starting from the set FI of frequent itemsets extracted from a context K , for a minimum support threshold minsupp . The next de fi nitions describe association rules [2]. De fi nition 13. ( Association rule ) An association rule R is a relation between itemsets and is of the form R : I  X  I , such that I and I are two itemsets, and I  X  I =  X  . The itemsets I and I are, respectively, called the premise ( or antecedent ) and the conclusion ( or consequent ) of the association rule R .
 De fi nition 14. ( Support, con fi dence of an association rule ) equal to the ratio between the support of the rule and the support of its premise, i.e., Supp ( I  X  I ) Example 11. The association rule R : AB  X  CD can be mined from the context given in Table 1. It has a support equal to Supp ( ABCD ) = 2. While its con fi dence is equal to Supp ( ABCD ) consider a manager handling the transaction set sketched by Table 1. The rule R allows the manager to know that  X  X ggs X ,  X  X read X ,  X  X ugar X , and  X  X utter X  were sold together twice, i.e., in 40% of the whole set of baskets ( of cardinality equal to 5 ) . Semantically speaking, the rule R can then be understood as follows: t he probab ility to fi nd the  X  X ggs X ,  X  X read X ,  X  X ugar X , and  X  X utter X  items together is equal to 0.4. Wherea s the pr obability to fi nd these items together with a value equal to 0.66 depends on the existence of the  X  X ggs X  and  X  X read X  items together in a basket.

The next de fi nition distinguishes the different kinds of association rules w.r.t. a minimum support threshold and a minimum con fi dence threshold.
 De fi nition 15. ( Valid, exact, approximate association rule ) An association rule R is said to be valid ( or strong ) if [2]:  X  its support value is greater than or equal to a user-speci fi ed threshold, minsupp, and,  X  its con fi dence value is greater than or equal to a user-speci fi ed threshold, denoted minconf. If the con fi dence of R is equal to 1, then R is called exact association rule, otherwise it is termed approximate association rule [14].
 Example 12. Let minsupp = 2 and minconf = 1 example. This rule is valid since it has a support value and a con fi dence value greater than or equal to minsupp and minconf, respectively. On the other hand, it is an approximate rule since its con fi dence is strictly lower than 1.

Given user-speci fi ed minimum support and con fi dence thresholds, the problem of association rule mining can be split into two steps as follows [1]:  X  Extract all frequent itemsets, i.e., having the support value greater than or equal to minsupp .  X  Generate only valid association rules from frequent itemsets. This generation is then limited to rules
These steps are solved by a pioneer algorithm in the data mining fi eld, namely A PRIORI [2]. The second step is relatively straightforward. However, the fi rst one presents a great challenge because the set of frequent itemsets may grow exponentially with |I| . The problem of discovering association rules is indeed an exponential one in the length of the longest frequent itemset. From the point of view of the without accessing the disk resident context. Indeed, the con fi dence of a rule can be calculated without accessing the database since the supports required for its computation can be obtained from the mined frequent itemsets. Therefore, the cost of this step is found to be low compared to that of the frequent itemsets extraction. An algorithm, called G EN -R ULES , is proposed in [1] for generating association rules starting from the set of frequent itemsets. Nevertheless, the number of all valid association rules generated is often very large to be exploited in an effective way by end-users [151]. In addition, it was proven that a large number of rules are redundant in the sense that they convey the same information as others [6,18].

The survival of the association rule extraction technique is thus owed to the retrieval of compactly sized with added-value knowledge. Many approaches were hence proposed for reducing large sized sets of association rules, while preserving the most interesting ones. For example, some works relied dependency , etc. [58,65], while others introduced user-de fi ned constraints during the mining process or as a post-processing step [23,26,90,134]. Another interesting approach relies on concise representations of frequent itemsets which can then help to reduce the redundancy between mined rules since retaining only non-redundant itemsets w.r.t. the associated derivation system. Based on these representations, the mining only focuses on extracting irreducible nuclei of all association rules, commonly called concise representation of association rules or generic bases , from which the remaining redundant association rules can be derived. These generic bases de fi ne a compact set of relevant association rules that is constitute ef fi cient solutions for the long-term storage on secondary memories and the computer-aided management of a set of valid association rules [118]. Interested readers are referred to [6,8,14,18,39,85, 118] for a detailed discussion on the main generic bases proposed in the literature.
 In this respect, in order to reduce the size of pattern sets, several proposals rely on Formal Concept Analysis [52]. One of the main results of the associated mathematical background consists in the notion of equivalence class and the induced characterization of its maximal and minimal elements w.r.t. set inclusion, called closed set and minimal generators respectively. These elements are used in various rules, sequences, graphs, etc. Their study is detailed in the following section in which we will see that closed sets and minimal generators have many dual properties, and some common ones. 3. Equivalence classes, closed itemsets and minimal generators
Formal Concept Analysis (FCA) mathematical foundations [52] have been used as a theoretical basis for various tasks [140]. In our context, some concise representations of frequent patterns are based on FCA. Let us fi rstly recall its basic constructs.
 We begin by de fi ning the Galois connection used to make the link between the power-sets P ( I ) and P ( O ) associated respectively to the set of items I and the set of objects O [52].
 De fi nition 16. ( Galois connection ) Let K =( O , I , M ) be an extraction context. The application  X  is de fi ned from the power-set of objects that are common to all objects o  X  O :
Both functions  X  and  X  constitute Galois operators between the sets P ( I ) and P ( O ) [13,52]. Con-sequently, the compound operator  X  =  X   X   X  is a Galois closure operator . Then, the operator  X  has the following properties [52]: (i) Extensivity :  X  I  X  X  ,I  X   X  ( I ) , (ii) Isotony :  X  I,I  X  X  ,if I  X  I ,then  X  ( I )  X   X  ( I ) , and, (iii) Idempotence :  X  I  X  X  ,  X  (  X  ( I )) =  X  ( I ).

The closure operator  X  associates to an itemset I the whole set of items which appear in all objects where If  X  ( I )= O ,then  X  ( I )=  X  ( O ) . Thus, the operator  X  generates closed subsets of items. Note also that Supp ( I )= |  X  ( I ) | .
 Example 13. Consider the context given in Table 1. Since both items A and C simultaneously appear in objects 1 and 4 share the items A , B , C and D , we have:  X  ( { 1 , 4 } )= ABCD .
  X  ( { 1 , 4 } )= ABCD . Thus,  X  ( AC )= ABCD . In other words, both items B and D appear in all objects where A and C simultaneously occur. Thus, with respect to the considered set of baskets, the purchase of both  X  X ggs X  and  X  X ugar X  implies that of  X  X read X  and  X  X utter X  in the sense that each customer who had purchased  X  X ggs X  and  X  X ugar X  necessarily also bought  X  X read X  and  X  X utter X .

Once applied, the closure operator  X  induces an equivalence relation on the power-set of items P ( I ) splitting it into the so-called equivalence classes [15], which will further be denoted  X  -equivalence classes. A  X  -equivalence class is then de fi ned as follows: De fi nition 17. (  X  -Equivalence class ) A  X  -equivalence class contains a set of itemsets sharing the same set of objects and, hence, having the same support and closure computed using the operator  X  .
 Example 14. Consider the context given by Table 1. Since the itemsets BD and ACD share the same set  X  -equivalence class. So, they have a common support equal to 2, and a common closure, namely ABCD . The next proposition state s that each element of P ( I ) belongs to a unique  X  -equivalence class. Proposition 4. For an extraction context K ,theset P ( I ) of all subsets of I is partitioned into  X  -equivalence classes without any overlapping.
 Proof. Let C both C other hand, it has the same closure as the elements of C to that of C minimal ones are called minimal generators . The respective de fi nitions of these particular itemsets are given below.
 De fi nition 18. ( Closed itemset ) An itemset I  X  X  is said to be closed if  X  ( I )= I [120].

Thus, a closed itemset gathers the maximal set of items appearing in a given set of objects. Closed itemsets are then considered as the fi xed points of the closure operator  X  [98].
 Example 15. Given the context depicted by Table 1, the itemset ABCD is a closed one since it is the maximal set of items common to the set of objects { 1, 4 } . Indeed, the  X  X ggs X ,  X  X read X ,  X  X ugar X , and  X  X utter X  items are all present in both basket 1 and 4. In addition, neither the  X  X ilk X  item nor the  X  X hocolate X  item simultaneously appears in these baskets. The itemset ACD is not closed since all objects containing the itemset ACD also contain the item B .
 The next property states the relation between the support of an itemset and that of its closure. CI containing I , i.e., Supp ( I )= Supp (  X  ( I )) [14].
 The proof of this property is based on the notion of  X  -equivalence class which, by de fi nition, gathers itemsets having the same support.
 Example 16. Since  X  ( AC )= ABCD , we have: Supp ( AC ) = Supp ( ABCD ) = 2.

The set of closed itemsets extracted from K will further be denoted CI , while FCI denotes the set of frequent closed itemsets, i.e., those closed itemsets which are frequent given a minimal threshold of support ( FCI = CI  X  X I ).

The next de fi nition presents the notion of minimal generator . De fi nition 19. ( Minimal generator )  X  An itemset I  X  X  is said to be a minimal generator of a closed itemset I if  X  ( I )= I , and I  X  I  X  A minimal generator can also be de fi ned as follows: I is a minimal generator if no exact rule holds  X  A minimal generator is also called 0-free itemset [25], key itemset [123], key set [136], key Example 17. Consider the CI ABCD described by the previous example. ABCD has AC as a minimal generator (MG) . Indeed,  X  ( AC )= ABCD and the closure of each proper subset of AC is different from ABCD :  X  (  X  )=  X  ,  X  ( A )= AB and  X  ( C )= CD . This means that only the purchase of both  X  X ggs X  and  X  X ugar X  items, and not a strict subset ( i.e., not uniquely  X  X ggs X  or  X  X ugar X  ) implies the purchase of both the  X  X read X  and  X  X utter X  items.
 Considering association rules, the itemset AC is a minimal generator since none of the rules A  X  C and C  X  A is exact. Semantically speaking, this means that none of the item A and C closely depends on the other item in the sense that A appears in a basket without C , and conversely.
 The following corollaries derive from the previous results.
 Corollary 1. Let I be a MG of a CI I . The support of I is equal to the support of its closure, i.e., Supp ( I )= Supp ( I ) .
 Proof. The proof derives from Property 1.
 Corollary 2. If there exists a MG I  X  I such that I  X   X  ( I ) , then Supp ( I )= Supp ( I ) . Proof. Suppose that Supp ( I ) = Supp ( I ). Then, I and I cannot belong to the same class (by de fi nition of a  X  -equivalence class). This is in contradiction with the fact that I is encompassed between I and its closure.
 Thus, a CI occurs within the same set of objects and, hence, has the same support as its generators. A CI then represents a maximal items group sharing the same objects, while its MGs are the smallest incomparable elements describing the objects set. A CI then includes the most speci fi c expression describing the associated objects, while a MG includes one of the most general expressions. Moreover, each  X  -equivalence class can then be concisely represented by its closure and the set of its MGs without information loss . Indeed, each arbitrary itemset I is necessarily encompassed between a CI and at least a MG. In addition, the support of I is equal to that of its closure ( cf. Property 1). Example 18. The CI ABCD has as MG s AC , AD , BC and BD . ABCD is then the largest element within its  X  -equivalence class, whereas AC , AD , BC and BD are the minimal ones. All these itemsets share the of the associated class. For example, ABC is encompassed between the closure ABCD and both MG s AC and BC .
 The set of MGs associated to an extraction context K will further be denoted MG .
 Example 19. For minsupp =1 , Table 2 shows, for each frequent CI , its MG s and its support value.
The next proposition presents interesting results in the case when an itemset is equal or not to its closure.
 Proposition 5. Let I  X  X  . We have [85]:  X  If I =  X  ( I ) ,then I is simultaneously closed and minimal generator and, hence, I  X  X I X  X G .  X  If I =  X  ( I ) ,then  X  I  X  I : I =  X  ( I ) .  X  If I =  X  ( I ) ,then  X  I  X  I : either I /  X  X G or I =  X  ( I ) .
 Example 20. Consider Table 2. We have F =  X  ( F ) . Then, the itemset F is a minimal generator and a purchase of article always depends on that of the  X  X hocolate X  item in all baskets in which  X  X hocolate X  appears,i.e., baskets number 3, 4, and 5. Consider now the itemset AC : AC =  X  ( AC )= ABCD . Its proper equal to their respective closures, as it is the case for the minimal generator ACE =  X  ( ACE )= ABCDEF . Using supports, we can characterize CIs and MGs as follows.
 Proposition 6.  X  I is a closed itemset iff Supp ( I ) &gt; max { Supp ( I ) | X  I  X  X  and I  X  I } .  X  I is a minimal generator iff Supp ( I ) &lt; min { Supp ( I ) | X  I  X  X  and I  X  I } .
 Proof.  X  Let I be a CI and suppose there is an item i  X  X \ I such that Supp ( I )= Supp ( I ) with I = I  X  X  i } .  X  Let I be a MG and suppose there is an item i  X  I such that Supp ( I )= Supp ( I ) with I = I \{ i } .
This means that expanding a CI by an item not already contained in it will decrease the support of the obtained itemset. On the other hand, removing any item from a MG will lead to the increase of the support of the resulting set.
 Example 21. Consider Table 2. The CI CDF has a support equal to 2 which is strictly greater than the maximal support of its proper supersets equal to 1. On the other hand, the MG ACE has a support equal to 1 which is strictly lower than the minimum support of its proper subsets equal to 2. The following corollaries deri ve from the prev ious proposition.
 Corollary 3. Let I , I  X  X  .If I  X  I and Supp ( I )= Supp ( I ) ,then  X  ( I )=  X  ( I ) . Hence, I and I belong to the same  X  -equivalence class.
 Proof. Let I , I  X  X  , I  X  I and Supp ( I ) = Supp ( I ).
 Supp ( K ) since J is a closed itemset (if K has the same support as J , this latter cannot be a closed itemset). Since an itemset has the same support as its closure ( cf. Property 1), we have starting from Supp ( I )= Supp ( I ) .
 We conclude that I and I have the same closure and then belong to the same  X  -equivalence class. Example 22. Consider Table 2. We have BC  X  BCD and Supp ( BC )= Supp ( BCD ) . Then,  X  ( BC )=  X  ( BCD )= ABCD .
 Corollary 4.  X  Each element of the positive border of the set of frequent itemsets, B d + ( FI ) , is a frequent closed Proof.  X  Let I  X  X  d + ( FI ) . The itemset I is frequent since belonging to B d + ( FI ) which by de fi nition  X  Let J  X  X  d  X  ( FI ) . The itemset J is infrequent since belonging to B d  X  ( FI ) whichbyde fi nition Example 23. Let us refer to Example 8 in which B d + ( FI ) and B d  X  ( FI ) are given for minsupp = 3. AB  X  X  d + ( FI ) while AB is a frequent closed itemset for minsupp = 3 ( cf. Table 2 ) . On the other hand, BF  X  X  d  X  ( FI ) while BF is an infrequent minimal generator for minsupp =3 ( cf. Table 2 ) . The next results follow from Propositio n 6, Corollary 3, and Corollary 4.
 Corollary 5. We have B d + ( FI )  X  X CI X  X I .
 Proof. The proof simply derives from: ( i ) FCI  X  FI (by de fi nition of the set FCI ), and ( ii ) B d + ( FI )  X  X CI ( cf. Corollary 4).
 Corollary 6. Let I  X  X  :  X  If I/  X  X I , Supp ( I )= max { Supp ( I ) | I  X  X I and I  X  I } .  X  If I/  X  X G , Supp ( I )= min { Supp ( I ) | I  X  X G and I  X  I } .
 Proof.  X  Let I  X  X  and I/  X  X I .Let maxs = max { Supp ( I ) | I  X  X I and I  X  I } . By Corollary 3, we also  X  Let I  X  X  and I/  X  X G .Let mins = min { Supp ( I ) | I  X  X G and I  X  I } . By Corollary 3, we Example 24. Consider Table 2. We have BCD is neither a closed itemset nor a minimal generator. Using CI s, we have: Supp ( BCD )= max { Supp ( ABCD ) , Supp ( ABCDEF ) } = Supp ( ABCD )=2 .On Supp ( BC ) } = Supp ( AC )= Supp ( BC )=2 .
 The next proposition states the relation, w.r.t. set inclusion, between the MGs of a given closed itemset. Proposition 7. The minimal generators of a closed itemset are incomparable w.r.t. set inclusion. Proof. The proof is based on the minimality status of a MG within its associated  X  -equivalence class. Indeed, let I and I be two MGs of a CI I . Suppose that I  X  I . This necessarily leads to the fact that I is not a MG since not minimal in its class, which is in contradiction with the fact that I is a MG of I .AllMGsof I are then incomparable w.r.t. set inclusion.
 Example 25. Consider for example the minimal generators of the closed itemset ABEF ( cf. Table 2 ) . They are incomparable w.r.t. set inclusion in the sense that none of them is included in another. The next proposition states an important property of the minimal generator set.
 Proposition 8. The set MG of minimal generators that can be extracted from a context K is an order ideal in ( P ( I ) , ) [136].

The last result sheds light on the fact that, if an itemset is a minimal generator, then it is the same for conjunction of two anti-monotone constraints is also an anti-monotone constraint ( cf. Proposition 2), the set FMG of frequent minimal generators ( FMG = MG  X  FI ) is also an order ideal. Thus, all subsets of a frequent minimal generator are frequent minimal generators, whereas if an itemset is not a frequent minimal generator, then none of its supersets is a frequent minimal generator. Example 26. Consider Table 2. The itemset ACE is a frequent minimal generator of the closed itemset the other hand, the itemset BCDE is not a minimal generator since there is at least one of its subsets, for minimal generators.
 The next proposition compare the size of the described sets.
 Proposition 9. For a given context K and a given minsupp value, we have: |B d + ( FI ) | |FCI| |FMG| |FI| .
 Proof. Since each frequent MG is a frequent itemset, we have: |FMG| |FI| . On the other hand, to each frequent CI is associated one or more frequent MGs. It results that: |FCI| |FMG| . In addition, thanks to Corollary 5, we have B d + ( FI )  X  X CI ,andthen |B d + ( FI ) | |FCI| . We conclude that: |B d + ( FI ) | |FCI| |FMG| |FI| .
 Example 27. Consider Table 2. We have: |B d + ( FI ) | =1 , |FCI| =10 , |FMG| =30 , and |FI| =64 . Remark 1. Note that, since a frequent CI may not be a MG ( this occurs when it is not the unique element of its  X  -equivalence class ) , we do not have in general case: FCI  X  FMG . More interesting, in the case where FCI  X  FMG , this means that FCI = FMG . Indeed, having FCI  X  FMG implies that each frequent CI is also a MG .Each  X  -equivalence class associated to a frequent CI is then reduced to a unique element which is both closed and minimal. As a consequence, in such a situation, FCI = FMG .
We now show that both sets FCI and FMG are two closure systems. This result derives from the following proposition in which we prove that the sets CI and MG are two closure systems. Proposition 10. The sets CI and MG are two closure systems in P ( I ) . Thus,  X  X  X  I , I  X  X I : I  X  I  X  X I .  X  X  X  I , I  X  X G : I  X  I  X  X G .
 Proof.  X  Let I , I  X  X I and I = I  X  I . Let us suppose that I is not a closed itemset. This means that:  X  Let I , I  X  X G and I = I  X  I . Since, I is included in a MG, for example I (or I ), and thanks The following results derive from the previ ous proposition.
 Corollary 7. The sets FCI and FMG are two closure systems in P ( I ) .
 Proof.  X  Let I , I  X  X CI and I = I  X  I . Thanks to Pr opositio n 10, I  X  X I . In addition, based on the  X  Let I , I  X  X MG and I = I  X  I . Thanks to Pr opositio n 10, I  X  X G . In addition, based on the Example 28. Consider Table 2. The intersection of both frequent CI s ABCD and CDE is equal to CD whichisalsoafrequent CI . While the intersection of both frequent MG s ACF and BF is equal to F which is also a frequent MG .
 Corollary 8. Let I  X  X  and C los ( I )= min { I  X  X I| I  X  I } . The cardinality of C los is always equal to 1.
 and I = I .Byde fi nition, we have I  X  I and I  X  I . It results that I  X  J , with J = I  X  I . Thanks to Propos ition 10, we have J  X  X I . In addition, J  X  I and J  X  I since I = I .Thisisin contradiction with the fact that I and I are in C los . We conclude that the cardinality of C los is always equal to 1.
 Example 29. Consider Table 2 and the itemset BCD . We have C los ( BCD )= min { ABCD , ABCDEF } = ABCD .

The next section discusses the importance of minimal generators in solving several problems, either alone or jointly with closed sets. 4. Importance of minimal generators for representing and deriving pattern classes with or
Standing at the  X  X ntipodes X  of closed patterns (CIs) within their respective  X  -equivalence classes induced by the Galois closure operator, minimal generators (MGs) [14] are the minimal elements of a class while the CIs [120] are the largest. They hence help delimit the classes and ease their detection/traversal. The closed pattern is then the unique maximal set of items characterizing a set of objects. While, often several minimal generators constitute the minimal elements of each class.
The aforementioned link between closed patterns and minimal generators explains why they are often simultaneously used. Indeed, the complementarity of these notions has been proved very useful in many works for concisely representing different pattern classes, like frequent itemsets ( e.g. [92,96, 123,132,146]), association rules [6,8,14,18,39,85,118], associative classi fi cation rules [11,12,93,94], adequate concise representations [132], sequential patterns [10,55,104,141], graphs [149,153], trees [9, frequent CIs and MGs separately ( cf. [17,19] for the former and [15] for the latter), or together [72,92, 96].
Although their study gras ped little interest compared to that paid to CIs, MGs appear to be at the crossroads of many theoretical and practical problem settings related to closure systems. Indeed, the interesting structural properties of the minimal generator set made it a key step for mining important pattern classes as well as for knowledge interpretation. In this section, we describe the main features of minimal generators, whenever used alone or jointly applied with their closed sets. Minimal generators have the following features: (iii) they play a key role in the rule set construction since they are at the origin of a variety of
In the remainder, we describe the main exact concise representations of frequent itemsets that were proposed in the litera ture. Each surveyed representation constitutes a representative of a class of representations designe d in almost the same manner. We also l ead, for each represen tation, a critical discussion as well as an analysis of its link with the concept of minimal generator. Then, we carry out a critical discussion and a comparative study of the surveyed representations. 5. Exact concise representations of frequent itemsets 5.1. Frequent closed itemset-based representation
In this section, we will describe the concise representation based on frequent closed itemsets which got a large interest in the literature since its proposal. 5.1.1. Description
The concise representation based on frequent closed itemsets (CIs) was introduced by Pasquier et al. [120]. The set of frequent CIs is de fi ned as follows: De fi nition 20. ( Set of frequent closed itemsets ) Consider a context K and the closure operator  X  . The set of frequent closed itemsets that can be drawn from K , denoted FCI ,isde fi ned as follows: FCI = { I  X  X |  X  ( I )= I and Supp ( I ) minsupp } [120]. The smallest closed itemset, w.r.t. set inclusion, containing an itemset I is obtained by applying  X  on I . Since I and its closure belong to the same  X  -equivalence class, then we have Supp ( I )= Supp (  X  ( I )) . Example 30. For the context given by Table 1, the set FCI for minsupp =1 is given by Table 2.
Theorem 1 states that the set of frequent CIs represents an exact concise representation of the set FI of frequent itemsets.
 Theorem 1. The set FCI of frequent closed itemsets, associated to their respective supports, is an exact concise representation of the set FI [120].
 Indeed, given an itemset I , thanks to FCI , we are able to determine whether I is frequent or not. In the af fi rmative case, its exact support can be derived from FCI and is equal to the support of the smallest closed itemset containing I ( cf. Property 1). In the remainder, the representation based on FCI will be denoted FCIs rep . 5.1.2. Mining algorithm
Thanks to the large success of this representation, many algorithms were proposed to extract the set of frequent CIs ( e.g. C LOSE [120], C H ARM [152], and LCM [139]). Many structural and/or analytical comparative studies were carried out in the litera ture on these algorithms [19,39,61,155]. In addition, the frequent itemset mining implementations (FIMI) repository [17] offers ef fi cient implementations of several algorithms dedicated to the extraction of frequent CIs Example 31. Consider the context given by Table 1 and minsupp =1 . The application of the A-C LOSE step the set FMG of frequent minimal generators thanks to a levelwise traversal of the search space. For each candidate, it checks whether it is a frequent mi nimal generator using P roposition 6. F or example, AC is a frequent minimal generator since Supp ( AC )=2 minsupp and Supp ( AC ) &lt;min { Supp (  X  ) , Supp ( A ) , Supp ( C ) } =3 .Italsobene fi ts from the key property of the set FMG beinganorderideal ( cf. Proposition 8 ) . For example, since the itemset CD /  X  X MG , its super-set ACD cannot be a frequent minimal generator.

Once the set FMG extracted, A-C LOSE delves in the context to get the closure of each frequentminimal generator. For each element, A-C LOSE computes the intersection of the objects in which it appears. For example, the closure of AC results from the intersection of objects 1 and 4, i.e., ABCD and ABCDEF , and is equal to ABCD .

The obtained set FCI is sketched by Table 2. Given this set, we are able to derive the conjunctive support of any frequent itemset. Suppose we are interested in deriving the support of AB . Since the latter is a frequent CI , then its support is equal to 3. Suppose now we are interested in deriving the support of the itemset ABC . This latter is not a frequent CI . We then search for the smallest frequent CI containing ABC , i.e., the frequent CI ABCD . Since an itemset has the same support as its closure, we have Supp ( ABC )= Supp ( ABCD )=2 . 5.1.3. Discussion
The cardinality of th e representation b ased on fre quent closed items ets cannot exceed the cardinality of the whole set of frequent itemsets. It is hence a perfect cover [120]. Moreover, this representation was extensively used as a starting point for extracting generic bases of rules of association. These bases and con fi dencevalues. Unfortunately, this representation is not very attractive wheneverhandling weakly the reduction ratio of this concise representation becomes very poor.
 5.1.4. Link with minimal generators
Closed itemsets and minimal generators are closely related. Indeed, once the Galois closure operator  X  applied on the power-set of items, it partitions itemsets in  X  -equivalence classes. In each class, a CI is the unique maximal element w.r.t. set inclusion while at least a MG is a minimal one. MGs are the fi rst elements reached within each class what explains why many algorithms rely on these patterns for ef fi ciently extracting CIs.

From a concise representation point of view, frequent MGs do not constitute by themselves an exact concise representation of frequent itemsets. Indeed, they must be augmented by other itemsets, like the clear that the FCIs rep is always smaller than frequent MG-based representations. Nevertheless, the order ideal property of the frequent MG set motivated the ef fi cient extraction of these latter represen-tations [72,85,103]. Note that, as frequent MGs and their closures concisely represent the associated frequent  X  -equivalence classes, their joint use also offer an exact concise representation of frequent itemsets [123].

It is important to mention that, in [132], the authors generalize the concise representation based on frequent closed itemsets to different other concise representations of interesting itemsets. For this purpose, they propose the concept of adequate closure operators as an extension of the Galois closure operator  X  in order to take into account some other interestingness measures and constraints other than the frequency constraint. Note, however, that from a structural point of view, the obtained equivalence classes once an adequate closure operator is applied have a unique maximal element  X  the closed one  X  and one or more minimal elements, as it is the case for  X  . As a consequence, our discussion about the relation between closed itemsets  X  as maximal elements of  X  -equivalence classes  X  and minimal generators  X  as minimal elements  X  remains valid for the case where an adequate closure operator is applied.

The next section proposes a generalization of frequent minimal generators leading to the de fi nition of the concise representation based on frequent non-derivable itemsets. 5.2. Frequent non-derivable itemset-based representation 5.2.1. Description
The notion of non-derivable itemset was introdu ced in [31]. In order to present the non-derivability property, we need to recall the notion of deduction rule, presented in the following de fi nition. De fi nition 21. ( Deduction rule ) Let I , J  X  X  be two itemsets and I  X  J . The deduction rule, linking the support of J to that of its proper subsets which subsume I , denoted by R The deduction rule R Example 32. Let J = ABC .If I = A ,then R ABC ( A ) will offer a lower bound of the support of ABC which is computed as follows:
Suppose now that I = BC ,then R ABC ( BC ) will offer an upper bound of the support of ABC which is computed as follows: The de fi nition of a frequent non-derivable itemset is then as follows: De fi nition 22. ( Frequent non-derivable itemset ) Let J  X  X  be an itemset. J is said to be non-derivable if there is no couple of deduction rules from which
Roughly speaking, an itemset is said non-derivable if the combination of the supports of its proper subsets does not allow to exactly derive its support. Otherwise, it is said derivable . Deduction rules i.e., those for which an access to the context is required for computing their exact supports. These itemsets will be retained in the representation. The second subset contains derivable itemsets, whose respective supports can be exactly derived given those of their associated proper subsets. The next theorem states an important result about deduction rules.
 Theorem 2. Let J  X  X  . The deduction rules associated to J , i.e., {R complete for deducing tight upper and lower bounds on the support of J [30].
 Example 33. Consider the context depicted by Table 1. In order to simplify the notations, we will use in this example the notation S using deduction rules. The set of deduction rules associated to ABC is given by the following system: Let us detail the method for obtaining these rules. Let R the right part of R of Consequently, R
Consider for example the rule R  X  .Since | ABC \{ X  X | =3 ,then  X  (  X  , ABC ) is an upper bound, and we we obtain R
By numerically assessing the above system of deduction rules, we obtain the following system: From rules R  X  and R A , we deduce that S ABC =2 . Let us remark that in this case, using these deduction rules, we are able to exactly compute the support of S ABC without accessing the extraction context. This is nevertheless conditioned by the fact that the associated supports of all proper subsets of ABC must be known.

The next theorem states that the set NDI of frequent non-derivable itemsets is an exact representation of frequent itemsets.
 Theorem 3. The set NDI of frequent non-derivable itemsets, associated to their respective supports, is an exact concise representation of the set FI [34].
 In the remainder, the representation based on NDI will be denoted NDIs rep . This representation is an exact one since the associated supports of the remaining frequent itemsets are derivable using deduction rules, like the support of ABC in Example 33. Otherwise they should have been retained in the representation. 5.2.2. Mining algorithm
The frequent non-derivable itemsets ful fi ll the order ideal property. Indeed,  X  X o be non-derivable X  was shown to be an anti-monotone constraint [34]. Since the conjunction of two anti-monotone constraints, namely  X  X o be non-derivable X  and  X  X o be frequent X , is also anti-monotone ( cf. Proposition 2), then the set NDI , composed by itemsets ful fi lling the constraint  X  X o be frequent non-derivable X , forms an order ideal as stated by the following proposition: Proposition 11. The set NDI of frequent non-derivable itemsets is an order ideal in ( P ( I ) , ) [34]. Such a constraint is used as an ef fi cient way for pruning candidates. In this respect, Calders and Goethals proposed a breadth-fi rst algorithm, called NDI [31], to extract the frequent non-derivable itemsets. Note that in [33], they also proposed a depth-fi rst algorithm, called dfNDI, for mining this is traversed right-to-left, ensuring to reach an itemset after all its proper subsets were already treated. Example 34. Consider the context depicted by Table 1. For minsupp =1 ,theset NDI of frequent non-derivable itemsets is shown by Table 3. 5.2.3. Discussion
The main advantage of this representation is that it has a reduced cardinality for the majority of the real-life contexts. Moreover, it has made possible to de fi ne a new way for characterizing association rules through the so-called non-derivable association rules [60]. Nevertheless, non-derivable itemsets do not have particular semantics being able to bring the end-users with further information about the mined context. Indeed, although the number of frequent non-derivable itemsets is usually less than the number of frequent minimal generators, the collection of the frequent minimal generators might still be more understandable since choosing the minimum value to derive supports from retained patterns is a more natural operation than computing all possible deduction rules [109]. Indeed, they are based on a numerical reduction without any added-value from the structural point of view, contrary to minimal generators and closed itemsets. In addition, the regeneration process of frequent itemsets starting from process of its support is performed in two steps: the fi rst consists in checking whether all its proper subsets are frequent, otherwise it will be infrequent and the process will stop. The second step consists extraction process for a candidate itemset having all its proper subsets frequent non-derivable itemsets, i.e., verifying the anti-monotone constraint of being frequent non-derivable. Note however that some optimizations were proposed by the authors [34], trying to optimize the evaluation cost of deduction rules. 5.2.4. Link with minimal generators
It is worth noting that the representation based on frequent non-derivable itemsets is basically a generalization of minimal generators with respect to the considered subsets of a given itemset. Indeed, for testing if an arbitrary itemset is a minimal generator, its support is only compared with those of its immediate subsets. On the other hand, the frequent non-derivable itemsets rely on a larger neighborhood exploration (also called depth in [32]) since using all proper subsets of an itemset. This explains why the representation based on frequent non-derivable itemsets is smaller than that based on frequent minimal generators. Indeed, the former requires by far more comparisons through deduction rules than the latter. For example, for an itemset of size n ,2 n deduction rules need to be evaluated to check whether it is non-derivable or not, while only n are used for checking if it is a MG or not (i.e., to test its minimality status within the associated  X  -equivalence class).
 becomes, but at the same time, the more complex to be mined. Note however that the determination of the lower and upper support bound may be stopped when their current temporary values become equal. On the other hand, the regeneration process of frequent itemsets starting from frequent non-derivable itemsets is awfully costly [103,110] compared to that starting from frequent minimal generator-based representations [103].

Noteworthily, other exact concise representations can be categorized in the same pool as non-derivable itemsets being also different generalizationsof minimal generators with respectto the used neighborhood. Amongst these representations, we fi nd those based on disjunction-free sets [28,29] and (generalized) disjunction-free generators [85], etc. A uni fi ed view of most of these representations was proposed in [32].

The next section presents an exact concise representation of frequent itemsets resulting from a combi-nation of the concept of non-derivab ility and the Galois closure operator. 5.3. Frequent closed non-derivable itemset-based representation 5.3.1. Description The frequent closed non-derivable itemsets have been introduced by Muhonen and Toivonen [111]. This representation combines the concise representations presented above, namely those based on fre-quent closed itemsets and frequent non-derivable itemsets, respectively. Indeed, its basic idea consists in applying the Galois closure operator  X  on frequent non-derivable itemsets in order to generate a more compact representation than the set of frequent non-derivable itemsets. The next theorem states that the obtained set preserves the exactness of the regeneration process of frequent itemsets.
 Theorem 4. The set CNDI of frequent closed non-derivable itemsets, associated to their respective supports, is an exact concise representation of the set FI [111].

In the remainder, we will denote this concise representation by CNDIs rep . 5.3.2. Mining algorithm
For determining the set CNDI ,the fi rst step consists in extracting the set NDI using one of the dedicated algorithms to this task ( cf. previous section). Then, the second step is devoted to the computation of the respective closures of the elements of NDI by means of an additional access to the Example 35. Consider the context given by Table 1. For minsupp =1 ,theset CNDI of frequent closed non-derivable itemsets is depicted by Table 4. For example, consider the frequent non-derivable itemset A ( cf. Table 3 ) . Since its closure is AB ,then AB  X  X NDI . 5.3.3. Discussion
Since the concise representation CNDIs rep simply gathers the conjunctive closures of frequent non-derivable itemsets, its cardinality is always smaller than or equal to those of NDIs rep and FCIs rep . Nevertheless, its extraction is quite complicated since relying on the extraction of frequent non-derivable itemsets. An additional access to the context is also required to compute closures. The regeneration of frequent itemsets from this representation inherits the same dif fi culty when using frequent non-derivable itemsets. Finally, the representation based on frequent closed non-derivable itemsets also lacks non-derivable ones. 5.3.4. Link with minimal generators
The link of the frequent closed non-derivable itemsets-based representation with minimal generators result of taking closures of a generalization of minimal generators w.r.t. the used neighborhood, namely non-derivable itemsets.

Moreover, the computation of frequent closed non-derivable itemsets can be optimized if we further concentrate on minimal generators. Indeed, each closed non-derivable itemset can easily be shown to be the closure of at least a non-derivable minimal generator. By  X  X on-derivable minimal generator X , we mean an itemset which is both  X  X on-derivable X  and  X  X inimal generator X . Hence, instead of computing the whole set of frequent non-derivable itemsets for which the associated closures must be computed, we can only use the set of frequent non-derivable minimal generators. This set being the result of three anti-monotone constraints, namely  X  X o be frequent X ,  X  X o be non-derivable X  and  X  X o be minimal generator X , will give rise to an order ideal. Indeed, the conjunction of the three aforementioned anti-monotone constraints will also give an anti-monotone constraint.

To get out the set of frequent non-derivable minimal generators, a slight modi fi cation of algorithms dedicated to frequent non-derivable itemset mining has to be performed. Its main aim is to only retain A comparison between the actual support of a frequent non-derivable itemset and the minimum of its immediate subsets supports is hence suf fi cient. The detection of minimal generators within these algorithms will optimize the candidate generation and closure computation steps. Indeed, the number of frequent non-derivable minimal generators is lower than that of frequent non-derivable itemsets.
It is important to note that in [87], the author studied the application of the Galois closure operator  X  itemsets composing a given representation instead of the itemsets themselves. The author proves that this process offers more reduced exact concise representations of frequent itemsets. As shown before, this is the case of the frequent closed non-derivable itemsets-based representation in comparison to that based on frequent non-derivable itemsets.

The next section offers a detailed description of a concise representation for frequent itemsets relying on the disjunctive support, in addition to the conjunctive one. 5.4. Frequent essential itemset-based representation 5.4.1. Description
The representation based on frequent essential itemsets was introduced by Casali et al. [36]. It is based on the exploration of the disjunctive search space where itemset are characterized through their disjunctive support and aims to offer new opportunitie s for a further reduction of the retained itemsets. This representation then relies on the inclusion-exclusion principle [51,113] for deriving conjunctive supports of frequent itemsets starting from the retained patterns in the representation.
In this subsection, we will mainly concentrate on the conjunctive and the disjunctive supports of an Hence, to avoid confusion between both supports, w e will explicitly mention t he nature of the support: conjunctive or disjunctive. Nevertheless, the use of the term  X  frequent  X  is restricted to the conjunctive support in the sense that a frequent itemset has a conjunctive support greater than or equal to minsupp . Let us begin by introducing the de fi nition of frequent essential itemset [36].
 De fi nition 23. ( Frequent essential itemset ) essential itemset if it is simultaneously frequent and essential.
 Example 36. Consider the context given by Table 1 for minsupp =1 . The itemset AB is not an essential itemset since DSupp ( AB )= DSupp ( A )=3 . Whereas AC is an essential itemset since DSupp ( AC ) = 5, in conjunction with the facts that DSupp ( AC ) = DSupp ( A )( since DSupp ( A )=3 ) and DSupp ( AC ) = DSupp ( C )( since DSupp ( C )=4 ) . The itemset AC is also frequent since Supp ( AC )=2 minsupp. The itemset AEF is also an essential itemset. Semantically speaking, each item of an essential itemset, like AEF , appears in at least an object of the context in which the remaining items of the itemset do not appear. Indeed, the basket number 1 w.r.t. Table 1 contains the item A ( i.e.  X  X ggs X  ) but not the item E others. On the other hand, the item  X  X hocolate X  appears in the basket 5, in which both  X  X ggs X  and  X  X ilk X  do not appear.
 Remark 2. It is important to note that De fi nition 23 as originally proposed in [36] does not consider the empty set as an essential itemset. This can simply be explained by the fact that the disjunctive support is not de fi ned for this pattern since it does not contain any item. It is however important for several purposes to consider this pattern as essential and to assign to the empty set the cardinality of the set of objects ( i.e., |O| ) as support. These considerations are important for two main reasons:  X  They ensure that all subsets of an essential itemset are essential ( indeed, if the empty set is not  X  They ensure the correct regeneration of the conjunctive support of the empty set during the expansion
In the remainder, we will denote by FEI the set of frequent essential itemsets that can be extracted from an extraction context K . Example 37. Consider the context given by Table 1 for minsupp =1 .Thesetof FEI is given by Table 5. This table also contains the couple (  X  ,5 ) added as aforementioned to ensure the exact regeneration of the empty set conjunctive support.

The following lemma shows how we can obtain the disjunctive support of a frequent itemset given the set FEI .
 Lemma 2. Let I  X  X I . DSupp ( I )= max { DSupp ( I ) | I  X  I and I  X  X EI} [36].
 Example 38. Consider Table 5. DSupp ( ABC )= max { DSupp ( A ) , DSupp ( B ) , DSupp ( C ) , DSupp ( AC ) , DSupp ( BC ) } =5 .

The following de fi nition presents the set Argmax which, for a given itemset I , contains the frequent essential itemsets included in I and having the maximal disjunctive support value among those of the subsets of I [36].
 De fi nition 24. ( Argmax ) Let I  X  X I and maxDSupp ( I )= max { DSupp ( I ) | I  X  X  and I  X  I } .Theset Argmax ( I ) is equal to: Argmax ( I )= { I  X  I | I  X  X EI and DSupp ( I )= maxDSupp ( I ) } .
 Example 39. maxDSupp ( ABC )= max { DSupp ( A ) , DSupp ( B ) , DSupp ( C ) , DSupp ( AB ) , DSupp ( AC ) , DSupp ( BC ) } =5 . Then, Argmax ( ABC )= { AC , BC } since AC and BC are those essential itemsets included in ABC and having a disjunctive support equal to 5 ( cf. Table 5 ) .

To derive the conjunctive support of a frequent itemset I , a straightforward manner is to use the equality shown in Lemma 1. However, an optimized way of the computation can be performed using an element of the set Argmax associated to I . The following lemma [36] shows how this can be done. Lemma 3. Let I  X  X I and J  X  Argmax ( I ) . We then have: Proof. The proof of this formula is based on the inclusion-exclusion identities ( cf. Lemma 1), and on the fact that  X  I ,J  X  I  X  I : DSupp ( I )= DSupp ( J ) ( cf. Lemma 2).

The following theorem indicates how to derive the conjunctive support of a frequent itemset once the set of frequent essential itemsets is extracted.
 Theorem 5. Let I  X  X I\FEI and J  X  Argmax ( I ) . We then have: Proof. If we apply the inclusion-exclusion identities, we get: support (according to Lemma 3). Among this, we hav e the same number of ite msets with odd cardinality than those with even cardinality. The second part of the sum is then equal to 0.
 It is worth noting that the optimization offered through Theorem 5 does not apply for an essential itemset I since in this case J = Argmax ( I )= Argmax ( I )= I . Indeed, by De fi nition 23, there is no proper subset of I having the same disjunctive support.

Please refer to Example 40 for examples on the derivation of itemsets supports starting from this representation.
 Remark 3. A remark about Theorem 5 concerns the fact that in [36], the authors considered that the itemset J should not be a superset of I . Indeed, the formula was given as follows: In the proof they gave in [37], they claim that this formula results from the following decomposition:
However, if we consider that I = ABCD , J = AB and I = ABC ,then I belongs to the fi rst part of the sum (  X  X  X  ABC , ABC  X  ABCD , and ABC AB ) as well as to the second part ( AB  X  ABC  X  ABCD ) . Hence, both parts of the sum are not disjoint. The formula is then erroneous.
Although their usefulness, the set of frequent essential itemsets suffers from a main limitation. Indeed, having only the information offered by FEI , we are not able to decide whether a given itemset I is frequent or not. To derive this information necessary for deriving the conjunctive support of I ( cf. Theorem 5), Casali et al. augment the set FEI with the set B d + ( FI ) of frequent maximal itemsets. The latter set will be used to check whether I is frequent or not. The following theorem summarizes the concise representation based on frequent essential itemsets.
 Theorem 6. The set FEI of frequent essential itemsets, associated to their respective disjunctive sup-ports, augmented by the set B d + ( FI ) of maximal frequent itemsets, constitutes an exact concise repre-sentation of the set FI of frequent itemsets [36].
 In the remainder, the frequent essential itemsets-based representation will be denoted FEIs rep . 5.4.2. Mining algorithm
To extract the frequent essential itemsets-based representation, Casali et al. proposed a levelwise algo-Proposition 12. The set of frequent essential itemsets is an order ideal in ( P ( I ) , ) [36]. Hence, if I is a frequent essential itemset, then each subset of I is also a frequent essential itemset. In a dual manner, if I is not a frequent essential itemset, then each superset of I cannot be a frequent essential itemset. As explained in Remark 2, the correctness of the previous proposition closely relies on the addition of the empty set as an essential itemset.
 well known levelwise A PRIORI algorithm [2].
 Example 40. Consider the context given by Table 1 for minsupp =1 . The application of the MEP algorithm gives the exact concise representation FEIs rep composed by:  X  The set FEI which is summarized in Table 5, and,  X  The border B d + ( FI )= { ABCDEF } .

Note that we give the conjunctive support of frequent essential itemsets only for the sake of com-pleteness. Indeed, the MEP algorithm does not extract the exact conjunctive supports of frequent essential itemsets. It only checks their frequency status by testing their inclusion in at least an element of B d + ( FI ) [36]. During the regeneration process, in the case where an itemset belongs to FEI , its conjunctive support must also be computed us ing an inclusion-exclusion identity.

Given the set FEI augmented with B d + ( FI ) , we are able to derive the conjunctive support of any frequent itemset. Suppose we are interested in computing the conjunctive support of the itemset DF starting from the disjunctive supports of its subsets, i.e., using Theorem 5. Since DF is a frequent essential itemset, Argmax ( DF )= { DF } . Then, the formula proved in the theorem is reduced to the application of the inclusion-exclusio n identities given in Lemma 1. Hence, Supp ( DF )=  X  DSupp ( DF )+ DSupp ( D )+ DSupp ( F )=  X  5+4+3=2 .
Suppose now that we have to compute the conjunctive support of the itemset CEF . The latter is a to Theorem 5, Supp ( CEF ) can be computed starting from the disjunctive supports of its subsets that do not include CE ,since CE  X  Argmax ( CEF ) . Note that CF also belongs to Argmax ( CEF ) , and can then be selected instead of CE to optimize the computation of CEF  X  support. The conjunctive support of the ( DSupp ( C )+ DSupp ( E )+ DSupp ( F )=  X  5  X  4+4+3+3=1 . 5.4.3. Discussion
To the best of our knowledge, this representation of frequent itemsets is the fi rst one in the literature relying on the disjunctive support as a way for characterizing its elements. For several real-life contexts sential itemsets is lower than that of the representation based on frequent closed itemsets [36]. Moreover, it makes it possible to ef fi ciently determine the disjunctive and negative supports of frequent itemsets. which leads to three main limitations:  X  A heterogeneity within the concise representation: Indeed, the elements of B d + ( FI ) are char- X  An increase in the size of the representation: This becomes clear especially for dense contexts where  X  An external algorithmic dependency: The dependence of any algorithm extracting this concise 5.4.4. Link with minimal generators
Here, we will establish the link between two spaces: the conjunctive search space and the disjunctive search space. In each one, itemsets are characterized using the corresponding support: conjunctive for the former and disjunctive for the latter. To understand where are localized minimal generators and essential itemsets in their respective search space, let us recall their associated characterization. Let I  X  X  :  X  I is a minimal generator iff Supp ( I ) &lt; min { Supp ( I ) | X  I  X  X  and I  X  I } .  X  I is an essential itemset iff DSupp ( I ) &gt; max { DSupp ( I ) | X  I  X  X  and I  X  I } .
Thus, minimal generators and essential itemsets are dually de fi ned w.r.t. the conjunctiveand disjunctive supports, respectively. This derives from the fact that to be frequent w.r.t. a minimum conjunctive support threshold (like minsupp in our case) induces an order ideal. While to be frequent w.r.t. a minimum is a decreasing ( resp. increasing) function of the size of itemsets.
Let us now split the disjunctive/conjunctive itemsets into equivalence classes w.r.t. the associated support in the sense that two itemsets belong to the same equivalence class if they have the same support. With respect to the aforementioned characterization, minimal generators and essential itemsets are the minimal itemsets, w.r.t. set inclusion, within their associated classes.

Since two itemsets can have the same supports while not being present in the same objects (i.e., do not have the same extent), we can re fi ne the aforementioned classes by dividing them into smaller ones according to a tougher constraint: two itemsets belong to the same equivalence class if they verify the same set of objects. This constraint obviously covers the previous one, i.e., the equality of itemset disjunctive equivalence classes [69] w.r.t. the disjunctive support. In both cases, minimal generators and essential itemsets are the minimal elements of their respective classes while their associated closure is unique in the associated equivalence class.

To summarize, the set of minimal generators and the set of essential itemsets have common structural properties in their associated search space. From the point of view of concise representations of frequent itemsets, none of them constitutes an exact representa tion by itself. They must be augmented to ensure the exactness of the regeneration process of frequent itemsets. 6. Discussion and comparative study of concise representations of frequent itemsets We discuss in this section several aspects related to concise representations for frequent itemsets. Then, we carry out a critical comparative study of the surveyed concise representations to highlight their main advantages and limits. 6.1. Discussion on the application areas
In the literature, frequent patterns and their concise representations have been used in several real-life applications. Our goal here is not to provide an exhaustive list of these applications, we only focus on typical and important examples of such applications. For marketing purposes, frequent patterns are used in [27] for product assortment decisions. While the authors studied in [144] maximal-pro fi t item selection with cross-selling effect. In addition, the study of the application of frequent patterns in electronic commerce was carried out in [84]. Several approaches in the literature were interested in applying concise representations of frequent patterns for analyzing medical [127,131] and biological data [5,117], as well as for Boolean gene regulatory network discovery [154], etc. In this respect, minimal generators are used in [97] in order to study risk factors for diagnosis of leukemia disease. They also offer interesting premises for classi fi cation association rules [93,101,124,142]. The impact of considering closed itemsets and minimal generators in feature construction for classi fi cation tasks was joint use of closed itemsets and minimal generators were successfully applied in several tasks [22,56].
Also, new applications of frequent itemsets and their representations were proposed for dealing with recent issues like social network analysis [129], software engineering [99], defect detection [41], anomaly detection [40], privacy-preserving constraints [115], etc.

Several extensions of frequent itemsets and their concise representations have also been used for summarizing pattern sets, like Top-k patterns, cluster-based representative pattern-set, pro fi le-based pattern summarization, etc. [4]. On the other hand, minimal generators and their closures offer summaries on itemsets [11], and on sequences [12]. These covers thus contain fewer rules than the whole set of valid association rules which help their exploitation in practice. For example, rule covers were used in [116] to analyze medical data.
 Concise representations are also used for optimizing inductive sets of mining queries [23,24,59,62]. Some approaches also highlighted the synergy between classical information retrieval techniques and frequent itemsets [100]. Indeed, in this situation, frequent itemsets represent terms co-occurrences, and are then used to determine terms to be used in a query in order to improve the quality of results of an information retrieval system, through for example query expansion [89]. Concise representations can then be used in order to delimit the number of possible expansions of an initial query.
As indicated in the aforementioned sections, concise representations of frequent itemsets have been extended to several complex pattern classes, especially those based on minimal generators and closed itemsets. This is carried out in order to deal with more complex situations and to fi nd solutions to different application requirements. For example, closed and minimal graphs are used for classifying chemical compounds [153]. These patterns are also us ed for concisely representing multidimensional patterns in [38,122].

It is important to conclude this subsection by indicating that closed patterns and minimal generators are the most applied patterns in real-life applications in comparison to non-derivable patterns and essential ones. On the one hand, non-derivable patterns are based on a larger neighborhood which make dif fi cult to guess their semantics. Therefore, once applied, the obtained results are dif fi cult to be analyzed and interpreted by end-users, contrary to closed patterns and minimal generators which respectively represent non-derivable itemsets and the derivation of redundant itemsets supports are much more complex, which constitutes a real hamper for their use in application based on interactivity with end-users like a query answering system [110]. On the other hand, although essential itemsets offer interesting information on disjunctive supports, the practical use of disjunctive itemsets only begins to grasp the interest in some applications where complementary or mutually occurrences of items is privileged [135,138], like software change impact analysis [78], and feature model mining [130], etc. 6.2. Discussion on the performance aspect of dedicated algorithms
From algorithms performances point of view, it is important to note that the algorithms dedicated to the mining of the concise representations of frequent itemsets generate different outputs. Namely, each one derives the set of patterns associated to the concise representation to which it is dedicated. In this situation, the comparison of mining algorithms performances does not make often sense. However, in the general case, once the representations mined, we can compare them with respect to a given target information that needs to be derived (for example, queries w.r.t. a kind of support). As an example, conjunctive supports.

When focusing on the mining algorithms dedicated to a given concise representation, we notice that the representation based on frequent closed itemsets has attracted the greatest interest in comparison to the other concise representations. In this respect, a comparative analytical and/or experimental study of algorithms for mining frequent closed itemsets can be found in [19,61,155]. Among these algorithms, a large part relies on minimal generators for ef fi ciently reaching  X  -equivalence classes and then taking their closures to obtain the targeted frequent closed itemsets.

With respect to the representation based on frequent non-derivable itemsets, the depth-fi rst mining hand, a unique algorithm, namely FIRM, is dedicated to the extraction of frequent closed non-derivable itemsets. The same applies for MEP w.r.t. the frequent essential itemsets-based representation. Both algorithms FIRM and MEP are breadth-fi rst. 6.3. Discussion on the quantitative aspect
Now we focus on the quantitative point of view of concise representations. In the general case, the size of the frequent closed itemset-based representation is incomparable with those based on frequent non-derivable and essential itemsets. This means that none of these three representations is always smaller than the two others or one of them. Thus, a representation can be smaller than another for a given context and minimum support threshold while the contrary may hold when changing either the context or the minimum support threshold. Note however that the positive border of frequent itemsets used in the representation based on frequent essential itemsets to ensure its exactness is included in the set of frequent closed itemsets. Indeed, each element of this border is a maximal frequent itemset and is then a closed itemset ( cf. Corollary 4). However, since essential itemsets are characterized through their respective disjunctive supports, they cannot be compared to closed or non-derivable itemsets based on the conjunctive support.

On the other hand, the representation based on frequent closed non-derivable itemsets is included in that based on frequent closed itemsets. Indeed, each frequent closed non-derivable itemset is obviously frequent closed. In addition, the size of the representation based on frequent closed non-derivable itemsets is always smaller than the size of the representation based on frequent non-derivable itemsets. This is obtained thanks to the non-injectivity property of the closure operator which leads to the fact that several frequent non-derivable itemsets will be mapped to a single frequent closed non-derivable itemsets. Moreover, the representation based on frequent closed non-derivable itemsets is incomparable with that based on frequent essential itemsets.

Interested readers are referred to [32,49,69,73,85] for a detailed experimental study on the quantitative aspectof concise representations of frequent itemsets. Some studies were also interested in the estimation of the maximal cardinality of a pattern belonging to a given representation ( cf. for example [46,86]).
Now, we will compare the surveyed representations through a detailed example w.r.t. the running context used throughout the paper.
 Example 41. This example proposes a comparison of the surveyed representations in terms of quantity. Thus, Table 6 recapitulates the different concise representations of frequent itemsets associated to the dataset shown in Table 1 and minsupp =1 . We classify itemsets belonging to a representation by increasing size.

For each concise representation, its elements are presented using couples representing an itemset belonging to the representation and its associated conjunctive or disjunctive support according to its membership. Hence, if an itemset belongs to FCIs rep , NDIs rep , CNDIs rep or B d + ( FI ) ,then it is associated to a conjunctive support. While, the disjunctive support is shown if it belongs to FEI .
For this dataset, the cardinalities of the different representations are respectively as follows: | FCI s rep | =10 , | NDI s rep | =9 , | CNDI s rep | =5 , and | FEI s rep | =23 . Note also that, in this case, the size of FI is equal to 64.

Recall that to belong to FCIs rep , an itemset must be frequent and having a conjunctive support strictly higher than those of its strict supersets. While an itemset belonging to NDIs rep must be frequent, and having a conjunctive support not exactly derivable using the deduction rules based on the conjunctive supports of all its subsets. The main advantage of NDIs rep is then brought by the large neighborhood explorations to retain or not an itemset within the representation. The concise representation CNDIs rep simply gathers the conjunctive closures of frequent non-derivable itemsets. Consequently, its cardinality is always smaller than or equal to those of NDIs rep and FCIs rep . This is also con fi rmed by the obtained results in this comparison. Moreover, not only the size of CNDIs rep smaller than that of FCIs rep , but also CNDIs rep is included in FCIs rep .Inthis situation, frequent closed itemsets of size greater than or equal to 3 are not retained in CNDIs rep since they do not have any non-derivable itemset as generator. Indeed, the size of the largest frequent non-derivable itemset is equal to 2 and, in this case, the 2-itemsets AB and CD are themselves closed itemsets. On the other hand, although B d + ( FI ) contains a unique element, this context seems to be a worst case for the representation based on frequent essential itemsets, characterized through their disjunctive supports. Note however that in several other cases, this representation is smaller than the remaining representations [36,69]. This comparison also shows that B d + ( FI )  X  FCIs rep since the maximal frequent itemset ABCDEF is proven to be closed.

It is important to mention that although non-derivable itemsets exploit much larger neighborhoods ( for to that of FCIs rep . Note however that the length of the largest itemset in NDIs rep is equal to 2, while it is equal to 6 for FCI s rep . This clearly constitutes an advantage for NDIs rep since limiting the required number of access to the database. Interestingly, taking the closure of frequent non-derivable itemsets to obtain CNDIs rep allows eliminating single items A and B which share the closure AB .The same applies for single items C and D . Note that the items E and F are retained in CNDIs rep since they are equal to their respective closures.

Recall however that, although the size of CNDIs rep is reduced, its computation is awfully costly since it requires the evaluation of 2 n deduction rules for each itemset of size n , to check if it is a frequent non-derivable itemsets or not [34], in add ition to taking its closure whenever it is frequent non-derivable [111]. On the other hand, mining a closed itemset or an essential itemset only relies on support comparisons with a limited neighborhood: the immediate supersets for the former and the immediate subsets for the latter.
From the point of view of  X  -equivalence classes, each frequent closed itemset represent the maximal element of the associated class. In this respect, frequent non-derivable itemsets do not represent the different  X  -equivalence classes. Indeed, the  X  -equivalence classes whose respective frequent closed itemsets are CDE , CDF , ABCD , ABEF , and ABCDEF do not have any of its members being non-derivable. For this reason, these closures do not belong to CNDIs rep .

If we look for the intersection between the different representations, we fi nd that E , F , AB , CD are simultaneously frequent closed and non-derivable itemsets. While among this four itemsets, only E and F are also essential itemsets. 6.4. Comparative study of concise representations of frequent itemsets
We now compare through several criteria the concise representations described in this paper. Note that we restrict our comparison to three of the surveyed representations, namely those based on frequent frequent closed non-derivable itemsets, is a combination of two of the compared representations, namely frequent closed itemsets and frequent non-derivable itemsets. 6.4.1. Axes of comparison
In the light of what was previously presented in this paper, we notice that the exact concise repre-sentations have main differences that we organize according to several criteria. Table 7 summarizes the results of our critical study on the main exact concise representations of the literature. The description of each criterion is as follows: 1. Composition: This criterion focuses on the nature ofthe itemsets contained in a given representation: 2. Main features characterizing the itemsets composing the representation: Here, we shed light on 3. Mining algorithms: In order to extract an exact concise representation, some algorithms are 4. Link with minimal generators: This axis summarizes how a given concise representation is linked 5. Regeneration mechanism: Each concise representation has its proper regeneration mechanism 6. Advantages: This part is dedicated to the main advantages that can have a concise representation De fi nition 25. ( Boolean expression ) A Boolean expression is the logical connection of a set of items using the conjunction, disjunction and negation connectors.
 Example 42. Let A , B and C be three items which represent binary-valued attributes, then ( A  X  B )  X  C is a Boolean expression.
 De fi nition 26. ( Generalized association rule ) Let I be a set of items and x where ( x in common [137].
 Example 43. Let I = { A , B , C , D , E } be a set of items. The rules A  X  B  X  C  X  D and A  X  E  X  D are two examples of generalized association rules.

Generalized association rules allow taking into account and, in addition, to go beyond classical association rules where only co-occurrences of items are taken into consideration. Hence, these rules offer richer knowledge [70,112,137,145]. Indeed, they convey the fi nest items correlations to the end-users. Thus, they help them to obtain a deeper analysis about the mined context, which improves their decisions. Note that in the literature, the term  X  X eneralized X  is also used to indicate rules obtained through the setting of a hierarchy/ta xonomy-based generalization [133]. 6.4.2. Main observations
The main observations on concise representations of frequent itemsets that can be drawn from Table 7 are as follows: 1. The concept of minimal generato r plays a key role in th e setting of each concise representation. 2. The surveyed concise representations extend the concept of minimal generators through different 3. Contrary to frequent closed and non-derivable itemsets-based representations whose elements 4. The derivation of the conjunctive supports of frequent itemsets is straightforward starting from the 5. The representation based on frequent closed itemsets is the unique one exploited in the literature 6. As shown in Section 4, in the literature we notice t hat, contrary to the concept of non-derivable 7. In the literature, many works have been devoted to concisely representing frequent itemsets. It 7. Conclusion
The increasing opportunity of quickly collecting and cheaply storing large volumes of data highlighted situation, the use of data mining tools become of paramount importance in order to transform the stored data into possible useful knowledge through the extraction of patterns ( e.g. itemsets, association rules, clusters, etc.). To help the end-users ef fi ciently and effectively interpreting and analyzing the mined their hidden interesting information.

We were mainly interested in this work in frequent itemsets. This pattern class is one of the most used in data mining. When confronted to real-life applications, the number of frequent itemsets proves to be very large hampering their effective interpretations by the end-users. In this situation, a high number of approaches was devoted to the proposal of concise representations of frequent patterns aiming at only retaining subsets of the whole set, while being able to derive non-retained (or redundant) patterns without information loss. Such subsets are called exact concise representations .

In this paper, we showed the close link between exact concise representations and important notions like -adequate representation and the MDL principle. Under the FCA mathematical settings, we analyzed in detail the characteristics of minimal generators and closed itemsets, which are frequently used in concise representations of frequent patterns. Then, we presented important tasks in which minimal generators are important whenever they are applied, either alone or jointly with closed itemsets. After literature, wh ile making the link between each surveyed class o f representations and m inimal generators. A discussion on several aspects related to concise representations and a comparative study were also proposed. One of their main results is that concise representations are shown to be either based on a generalization/extension of minimal generators, or can be obtained using these latter patterns as an ef fi cient computation mean. In addition, for several data mining tasks, minimal generators and closed itemsets prove to be complementary.

This work can be extended in various directions. First, we considered here exactconciserepresentations as well as to more complex pattern classes, like graphs, trees, etc., which are often extensions of minimal generators and closed itemsets. Interestingly enough, the associated properties of data types and pattern classes should be carefully taken into account. For example, when dealing with sequential patterns, an equivalence class can cohabit more than one closed sequential pattern [104], and not only has a unique closed as it is the case for itemsets. Finally, since minimal generators have several similar constructs in out for itemsets is an interesting issue.
 Acknowledgments We would like to thank the anonymous reviewers for their helpful remarks and suggestions. References
