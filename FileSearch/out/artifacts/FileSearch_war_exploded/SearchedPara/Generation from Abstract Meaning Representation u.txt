 We consider natural language generation from the Abstract Meaning Representation (AMR; Banarescu et al., 2013). AMR encodes the meaning of a sen-tence as a rooted, directed, acyclic graph, where con-cepts are nodes, and edges are relationships among the concepts.
 while abstracting away from surface syntactic re-alizations, and is designed with human annotation in mind, it suggests a separation of (i) engineering the application-specific propositions that need to be communicated about from (ii) general-purpose re-alization details, modeled by a generator shareable across many applications. The latter is our focus here.

Because any AMR graph has numerous valid re-alizations, and leaves underspecified many impor-tant details X  X ncluding tense, number, definiteness, whether a concept should be referred to nominally or verbally, and more X  X ransforming an AMR graph into an English sentence is a nontrivial problem.
To our knowledge, our system is the first for gen-erating English from AMR. The approach is a sta-tistical natural language generation (NLG) system, trained discriminatively using sentences in the AMR bank (Banarescu et al., 2013). It first transforms the graph into a tree, then decodes into a string us-ing a weighted tree-to-string transducer and a lan-guage model (Graehl and Knight, 2004). The de-coder bears a strong similarity to state-of-the-art ma-chine translation systems (Koehn et al., 2007; Dyer et al., 2010), but with a rule extraction approach tai-lored to the NLG problem. Generation of English from AMR graphs is accom-plished as follows: the input graph is converted to a tree, which is input into the weighted intersection of a tree-to-string transducer (  X  4) with a language model. The output English sentence is the (ap-proximately) highest-scoring sentence according to a feature-rich discriminatively trained linear model. After discussing notation (  X  3), we describe our ap-proach in  X  4. The transducer X  X  rules are extracted from the limited AMR corpus and learned general-izations; they are of four types: basic rules (  X  5), synthetic rules created using a specialized model (  X  6), abstract rules (  X  7), and a small number of handwritten rules (  X  8). AMR graphs are directed, weakly connected graphs with node labels from the set of concepts L N and edge labels from the set of relations L E .

AMR graphs are transformed to eliminate cycles (details in  X  4); we refer to the resulting tree as a transducer input representation (TI representa-tion) . For a node n with label C and outgoing edges n L 1  X  X  X  n 1 ,...,n L m  X  X  X  X  n m sorted lexicographically by L i (each an element of L E ), the TI representa-tion of the tree rooted at n is denoted: 2 where each T i is the TI representation of the tree rooted at n i . See Fig. 1 for an example. A LISP-like textual formatting of the TI representation in Fig. 1 is: ( X want-01 ( ARG0 ( X boy )) ( ARG1 ( X ride-01
To ease notation, we use the function sort [] to lex-icographically sort edge labels in a TI representa-tion. Using this function, an equivalent way of rep-resenting the TI representation in Eq. 1, if the L i are unsorted, is:
The TI representation is converted into a word se-quence using a tree-to-string transducer. The tree transducer formalism we use is one-state extended linear, non-deleting tree-to-string ( 1-xRLNs ) trans-ducers (Huang et al., 2006; Graehl and Knight, Definition 1. (From Huang et al., 2006.) A 1-xRLNs transducer is a tuple ( N,  X  ,W, R ) where N Figure 1: The generation pipeline. An AMR graph (top), with a deleted re-entrancy (dashed), is con-verted into a transducer input representation (TI rep-resentation, middle), which is transduced to a string using a tree-to-string transducer (bottom). is the set of nonterminals (relation labels and X ),  X  is the input alphabet (concept labels), W is the out-put alphabet (words), and R is the set of rules. A rule in R is a tuple ( t,s, X  ) where: 1. t is the LHS tree, whose internal nodes are la-2. s  X  ( X  X  W )  X  is the RHS string; 3.  X  is a mapping from X to nonterminals N . A rule is a purely lexical rule if it has no variables.
As an example, the tree-to-string transducer rules which produce the output sentence from the TI rep-resentation in Fig. 1 are: Here, all X i are mapped by a trivial  X  to the nonter-minal X .

The output string of the transducer is the target projection of the derivation, defined as follows: Definition 2. (From Huang et al., 2006.) A deriva-tion d , its source and target projections , denoted S ( d ) and E ( d ) respectively, are recursively defined as follows: 1. If r = ( t,s, X  ) is a purely lexical rule, then 2. If r = ( t,s, X  ) is a rule, and d i is a (sub)-The notation [ x i 7 X  y i ] t is shorthand for the result of substituting y i for each x i in t , where x i ranges over all variables in t .

The set of all derivations of a target string e with a transducer T is denoted where d is a derivation in T .

We use a shorthand notation for the transducer rules that will be useful when discussing rule extrac-tion and synthetic rules. Let f i be a TI representa-tion. The TI representation has the form where L i  X  L E and T 1 ,...,T m are TI representa-tions. 4 Let A 1 ,...A n  X  L E . We use as shorthand for the rule: Note r must contain the variables X 1 ... X n . In (3) and (4), argument slots with relation labels A i have been added as children to the root node of the TI representation f i .

For example, the shorthand for the transducer rules in (2) is: To generate a sentence e from an input AMR graph G , a spanning tree G 0 of G is computed, then trans-formed into a string using a tree-to-string transducer. Spanning tree. The choice of the graph G  X  X  span-ning tree G 0 could have a big effect on the output, since the transducer X  X  output will always be a pro-jective reordering of the tree X  X  leaves. Our spanning tree results from a breadth-first-search traversal, vis-iting child nodes in lexicographic order of the re-lation label (inverse relations are visited last). The edges traversed are included in the tree. This sim-ple heuristic is a baseline which can potentially be improved in future work.
 Decoding. Let T = ( N,  X  ,W, R ) be a tree-to-string transducer. The output sentence is the highest scoring transduction of G 0 : Eq. 6 is solved approximately using the cdec de-coder for machine translation (Dyer et al., 2010). The score of the transduction is a linear function (with coefficients  X  ) of a vector of features in-cluding the output sequence X  X  language model log-probability and features associated with the rules in the derivation (denoted f ; Table 1): score ( d ;  X  ) =  X  LM log( p LM ( E ( d ))) + The feature weights are trained on a development dataset using MERT (Och, 2003).

In the next four sections, we describe the rules extracted and generalized from the training corpus. The basic rules, denoted R B , are extracted from the training AMR data using an algorithm sim-ilar to extracting tree transucers from tree-string aligned parallel corpora (Galley et al., 2004). In-formally, the rules are extracted from a sentence w =  X  w 1 ,...,w n  X  with AMR graph G as follows: 1. The AMR graph and the sentence are aligned; 2. G is replaced by its spanning tree by deleting 3. In the spanning tree, for each node i , we 4. For each aligned fragment i , a rule is extracted See Fig. 2 for examples.

More formally, assume the nodes in G are num-bered 1 ,...,N and the fragments are numbered 1 ,...,F . Let nodes : { 1 ,...,F }  X  2 { 1 ,...,N } and root : { 1 ,...,F }  X  { 1 ,...,N } be functions that return the nodes in a fragment and the root of a frag-ment, respectively, and let children : { 1 ,...,N } X  sider a node aligned if it belongs to an aligned frag-ment. Let the span of an aligned node i be denoted by endpoints a i and a 0 i ; for unaligned nodes, a i =  X  and a 0 i =  X  X  X  (depicted with superscripts in Fig. 2). The node alignments are propagated by defining b (  X  ) and e (  X  ) recursively, bottom up: Also define functions  X  b and  X  e , from fragment indices to integers, as:
For fragment i , let C i = children(root( i ))  X  nodes( i ) , which is the children of the fragment X  X  root concept that are not included in the fragment. Let f i be the TI representation for fragment i . 5 If C i is empty, then the rule extracted for fragment i is: Otherwise, let m = | C i | , and denote the edge labels from root( i ) to elements of C i as A 1 ( i ) ...A m ( i ) . For j  X  { 1 ,...,m } , let k j select the elements c k of C i in ascending order of b ( k j ) . Then the rule ex-tracted for fragment i is: A rule is only extracted if the fragment i is aligned and the child spans do not overlap. Fig. 2 gives an example of a tree annotated with alignments, b and e , and the extracted rules. The synthetic rules, denoted R S ( G ) , are created to generalize the basic rules and overcome data sparseness resulting from our relatively small train-ing dataset. Our synthetic rule model considers an AMR graph G and generates a set of rules for each node in G . S synthetic rule X  X  LHS is a TI represen-tation f with argument slots A 1 ...A m (this is the same form as the LHS for basic rules). For each node in G , one or more LHS are created (we will discuss this further below), and for each LHS, a set of k -best synthetic rules are produced. The simplest case of a LHS is just a concept and argument slots corresponding to each of its children.

For a given LHS, the synthetic rule model cre-(called a concept realization and corresponding (called an argument realization and corresponding to the argument slots). See the top of Fig. 3 for a syn-thetic rule with concept and argument realizations highlighted.

Synthetic rules have the form: where:  X  f is a TI representation.  X  Each A i  X  L E .  X   X  k 1 ,...,k m  X  is a permutation of  X  1 ,...,m  X   X  c  X  W  X  is the realization of TI representa- X  Each l i , r i  X  W  X  and X i  X  X . Let R i =  X  c  X  [0 ,m ] is the position of c among the real-
Let F be the space of all possible TI represen-tations. Synthetic rules make use of three lookup tables (which are partial functions) to provide can-didate realizations for concepts and arguments: a ta-ble for concept realizations lex : F  X  2 W  X  , a table for argument realizations when the argument is on the left left lex : F  X  L E  X  2 W  X  , and a table for argument realizations when the argument is on the right right lex : F  X  L E  X  2 W  X  . These tables are constructed during basic rule extraction, the details of which are discussed below .

Synthetic rules are selected using a linear model with features g and coefficients  X  , which scores each RHS for a given LHS. For LHS = ( f,A 1 ,...A m ) , the RHS is specified completely by c ,c,R 1 ,...,R m and a permutation k 1 ,...,k m . For each node in G , and for each TI representation f in the domain of lex that matches the node, a LHS is created, and a set of K synthetic rules is produced for each c  X  lex ( f ) . The rules produced are the
The 1 ((boy) 2 wants 3 to 4 (ride 5 the 6 ((red) bicycle))) 8 Figure 2: Example rule extraction from an AMR-annotated sentence. Figure 3: Synthetic rule generation for the rule shown at top. In the rule RHS, the realization for ARG0 is blue, the realization for DEST is red, and the realization for ride-01 is black. For a fixed per-mutation of the concept and arguments, choosing the argument realizations can be seen as a sequence la-beling problem (bottom). The highlighted sequence corresponds to the rule at top.
 K -best solutions to: where the max is over c  X  0 ...m , k 1 ,...,k m is any permutation of 1 ,...,m , and R i  X  left lex ( A i ) for i &lt; c and R i  X  right lex ( A i ) for i &gt; c .  X  is used to denote the concept position. is the empty string.
The best solution to Eq. 10 is found exactly by brute force search over concept position c  X  [0 ,m + 1] and the permutation k 1 ,...,k m . With fixed concept position and permutation, each R i for the arg max is found independently. To obtain the ex-act K -best solutions, we use dynamic programming with a K -best semiring (Goodman, 1999) to keep track of the K best sequences for each concept posi-tion and permutation, and take the best K sequences over all values of c and k  X  .

The synthetic rule model X  X  parameters are esti-mated using basic rules extracted from the training data. Basic rules are put into the form of Eq. 9 by Table 2: Synthetic rule model features. POS is the most common part-of-speech tag sequence for c ,  X  X ist X  is the string  X  X ist X , and side is  X  X  X  if i &lt; c ,  X  X  X  otherwise. + denotes string concatenation. segmenting the RHS into the form by choosing c , l i , r i  X  W  X  for i  X  { 1 ,...,m } . An example segmentation is the rule RHS in Fig. 3.
Segmenting the RHS of the basic rules into the form of Eq. 11 is done as follows: c is the aligned span for f . For the argument realizations, arguments to the left of c pick up words to their right, and argu-ments to the right pick up words to their left. Specif-ically, for i &lt; c ( R i to the left of c but not next to c ), l i is empty and r i contains all words between a i and a i +1 . For i = c ( R i directly to the left of c ), l empty and r i contains all words between a c and c . For i &gt; c +1 , l i contains all words between a i  X  1 and a , and for i = c + 1 , l i contains all words between c and a i .

The tables for lex , left lex , and right lex are popu-lated using the segmented basic rules. For each ba-sic rule extracted from the training corpus and seg-mented according to the previous paragraph, f  X  c is added to lex , and A k for i  X  c and right lex for i &gt; c . The permutation k i is known during extraction in Eq. 8.
 The parameters  X  are trained using Ada-Grad (Duchi et al., 2011) with the perceptron loss function (Rosenblatt, 1957; Collins, 2002) for 10 iterations over the basic rules. The features g are listed in Table 2. Like the synthetic rules, the abstract rules R A ( G ) generalize the basic rules. However, abstract rules are much simpler generalizations which use part-of-speech (POS) tags to generalize. Abstract rules make use of a POS abstract rule table , which is a table listing every combination of the POS of the concept realization, the child arguments X  labels, and rule RHS with the concept realization removed and replaced with  X  . This table is populated from the basic rules extracted from the training corpus. An example entry in the table is:
For the LHS ( f,A 1 ,...A m ) , an abstract rule is created for each member of c  X  lex ( f ) and the most common POS tag p for c by looking up p , A 1 ,...A m in the POS abstract rule table, finding the common RHS, and filling in the concept posi-tion with c . The set of all such rules is returned. We have handwritten rules for dates, conjunctions, multiple sentences, and the concept have-org-role-91. We also create pass-through rules for concepts by removing sense tags and quotes (for string liter-als). We evaluate on the AMR Annotation Release ver-sion 1.0 (LDC2014T12) dataset. We follow the rec-ommended train/dev./test splits, except that we re-move MT09 data (204 sentences) from the training data and use it as another test set. Statistics for this dataset and splits are given in Table 3. We use a 5 -gram language model trained with KenLM (Heafield et al., 2013) on Gigaword (LDC2011T07), and use 100 -best synthetic rules.

We evaluate with the Bleu scoring metric (Pap-ineni et al., 2002) (Table 4). We report single ref-Table 4: Uncased Bleu scores with various types of rules removed from the full system. erence Bleu for the LCD2014T12 test set, and four-reference Bleu for the MT09 set. We report ablation experiments for different sources of rules. When ablating handwritten rules, we do not ablate pass-through rules.

The full system achieves 22 . 1 Bleu on the test set, and 21 . 2 on MT09. Removing the synthetic rules drops the results to 9 . 1 Bleu on test and 7 . 8 on MT09. Removing the basic and abstract rules has little impact on the results. This may be because the synthetic rule model already contains much of the information in the basic and abstract rules. Remov-ing the handwritten rules has a slightly larger effect, demonstrating the value of handwritten rules in this statistical system. There is a large body of work for statistical and non-statistical NLG from a variety of input representa-tions. Statistical NLG systems have been built for input representations such as HPSG (Nakanishi et al., 2005), LFG (Cahill and Van Genabith, 2006; Hogan et al., 2007), and CCG (White et al., 2007), as well as surface and deep syntax (Belz et al., 2011). The deep syntax representations in Bohnet et al. (2010) and Belz et al. (2011) share similari-ties with AMR: the representations are graphs with re-entrancies, and have an concept inventory from PropBank (Palmer et al., 2005).

The Nitrogen and Halogen systems (Langkilde and Knight, 1998; Langkilde, 2000) used an input representation that was a precursor to the modern version of AMR, which was also called AMR, al-though it was not the same representation as Ba-narescu et al. (2013).

Techniques from statistical machine translation have been applied to the problem of NLG (Wong and Mooney, 2006), and many grammar-based ap-proaches can be formulated as weighted tree-to-string transducers. Jones et al. (2012) developed technology for generation and translation with syn-chronous hyperedge replacement (SHRG) gram-mars applied to the GeoQuery corpus (Wong and Mooney, 2006), which in principle could be applied to AMR generation. We have presented a two-stage method for natural language generation from AMR, setting a baseline for future work. We have also demonstrated the im-portance of modeling argument realization for good performance. Our feature-based, tree-transducer ap-proach can be easily extended with rules and fea-tures from other sources, allowing future improve-ments.
 The authors would like to thank Adam Lopez and Nathan Schneider for valuable feedback, and Sam Thomson and the attendees of the Fred Jelinek Memorial Workshop in 2014 in Prague for help-ful discussions. This work is supported by the U.S. Army Research Office under grant number W911NF-10-1-0533. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not nec-essarily reflect the view of the U.S. Army Research Office or the United States Government.

