 Streams are often inherently correlated and it is possible to reduce hundreds of numerical streams into just a handful of patterns that compactly describe the key trends and dramatically reduce the complexity of further data processing. Multiple co-evolving streams often arise in a large distributed system, such as computer networks and sensor network s. Centralized approaches usually will not work in this setting. The reasons are: (i) Communication constraint ; it is too expensive to transfer all data to a central node for processing and mining. (ii) Power consumption ; in a wireless sensor network, minimizing information exchange is crucial because many sensors have very limited power. (iii) Robustness concerns ; centralized approaches always suffer from single point of failure. (iv) Privacy concerns ; in any network connecting multiple autonomous systems (e.g., multiple companies forming a collaborative network), no system is willing to share all the information, while they all want to know the global patterns. To sum up, a distributed online algorithm is highly needed to address all the a bove concerns.

To address this problem, we propose a hierarchical framework that intuitively works as follows:1) Each autonomous system first finds its local patterns and shares them with other groups. 2) Global patterns are discovered based on the shared local patterns. 3) From the global patterns, each autonomous system further refines/verifies their local patterns. Given m groups of streams which consist of { n 1 ,...,n m } co-evolving numeric streams, respectively, we want to solve the following two problems: (i) incre-mentally find patterns within a single group ( local pattern monitoring ), and (ii) efficiently obtain global patterns from all the local patterns ( global pattern de-tection ).
 More specifically, local pattern monitoring can be modelled as a function, where the inputs are 1) the new input point S i ( t +1 , :) at time t +1 and the current global pattern G ( t, :) and the output is the local pattern L i ( t +1 , :) at time t + 1. Details on constructing such a function will be explained in section 3. Likewise, global pattern detection is modelled as another function, where the inputs are local patterns L i ( t +1 , :) from all groups at time t +1 and the output is the new global pattern G ( t +1 , :).

Now we introduce the general framework for distributed mining. More specif-ically, we present the meta-algorithm to show the overall flow, using F L ( local patterns monitoring )and F G ( global patterns detection )asblackboxes.
Intuitively, it is natural that global patterns are computed based on all local patterns from m groups. On the other hand, it might be a surprise that the local patterns of group i take as input both the stream measurements of group i and the global patterns. Stream measurements are a natural set of inputs, since local patterns are their summary. However, w e also need global patterns as another input so that local patterns can be represented consistently across all groups. This is important at the next stage, when constructing global patterns out of the local patterns; we elaborate on this later. The meta-algorithm is the following: Tracking Local Patterns. We now present the method for discovering patterns within a stream group. More specifically, we explain the details of function F L (Equation 1). We first describe the intuition behind the algorithm and then present the algorithm formally. Finally we discuss how to determine the number of local patterns k i .

The goal of F L is to find the low dimensional projection L i ( t, :) and the partici-pation weights W i,t so as to guarantee that the reconstruction error
S i ( t, :)  X   X  S i ( t, :) 2 over time is predictably small.

The first step is, for a given k i , to incrementally update the k  X  n i participation weight matrix W i,t , which serves as a basis of the low-dimensional projection for S ( t, :). Later in this section, we describe the method for choosing k i .Forthe moment, assume that the number of patterns k i is given.

The main idea behind the algorithm is to read the new values S i ( t +1 , :)  X  [
S i ( t +1 , 1) ,...,S i ( t +1 ,n i )] from the n i streams of group i at time t +1, and perform three steps: (1) Compute the low dimensional projection y j , 1  X  j  X  k , based on the current weights W i,t , by projecting S i ( t +1 , :) onto these.(2) Estimate the reconstruction error ( e j below) and the energy.(3) Compute W i,t +1 and output the actual local pattern L i ( t +1 , :).

The term  X  is a forgetting factor between 0 and 1, which helps adapt to more recent behavior. For instance,  X  = 1 means putting equal weights on all historical data, while smaller  X  means putting higher weight on more recent data.
In practice, we do not know the number k i of local patterns. We propose to estimate k i on the fly, so that we maintain a high percentage f i,E of the energy E i,t . For each group, we have a low-energy and a high-energy threshold, f i,E and F i,E , respectively. We keep enough local patterns k i , so the retained energy is within the range [ f i,E  X  E i,t , F i,E  X  E i,t ].
 Tracking Global Patterns. We now present the method for obtaining global patterns over all groups. More specifically, we explain the details of function F G .
First of all, what is a global pattern? Similar to local pattern, global pattern is low dimensional projections of the streams from all groups. Loosely speaking, assume only one global group exists which consists of all streams, the global patterns are the local patterns obtained by applying F L on the global group X  this is essentially the centralized approach. In other words, we want to obtain the result of the centralized approac h without centralized computation.
The algorithm exactly follows the lemma above. The j -th global pattern is the sum of all the j -th local patterns from m groups. The Motes dataset consists of 4 groups of sensor measurements (i.e., light inten-sity, humidity, temperature, battery vo ltages) collected using 48 Berkeley Mote sensors at different locations in a lab, over a period of a month.

The main characteristics (see the blue c urves in Figure 1) are: (1) Light mea-surements exhibit a clear global periodic pattern (daily cycle) with occasional big spikes from some sensors (outliers), (2) Temperature shows a weak daily cycle and a lot of bursts. (3) Humidity does not have any regular pattern. (4) Voltage is almost flat with a small downward trend.

The reconstruction is very good (see the red curves in Figure 1(a)), with relative error below 6%. Furthermore, the local patterns from different groups are correlated well with the original measurements (see Figure 2). The global patterns (in Figure 3) are combinations of different patterns from all groups and reveal the overall behavior of all the groups.

The relative reconstruction error as the evaluation metric. The best perfor-mance is obtained when all groups exchange up-to-date local/global patterns at every timestamp, which is prohibitivel y expensive. One efficient way to deal with this problem is to increase the communication period, which is the number of timestamps between successive local/glob al pattern transmissions.Overall, the relative error rate increases very slowly as the communication period increases (see Figure 4). This implies that we can dramatically reduce communication with minimal sacrifice of accuracy. DistributedDataMining. Most of works on distributed data mining focus on extending classic (centralized) data m ining algorithms into distributed en-vironment, such as association rules mining [3], frequent item sets [5]. Web is a popular distributed environment. Several techniques are proposed specifically for that, for example, distributed top-k query [2] But our focus are on finding numeric patterns, which is different.
 Privacy Preserving Data Mining. The most related discussion here is on how much privacy can be protected usin g subspace projection method [1, 4]. Liu et al. [4] discuss the subspace projection method and propose a possible method to breach the protection using Independent component analysis(ICA). All the method provides a good insight on the issues on privacy protection. Our method focuses more on incremental online computation of subspace projection. We focus on finding patterns in a large number of distributed streams. More specifically, we first find local patterns within each group, where the number of local patterns is automatically determined based on reconstruction error. Next, global patterns are identified, based on the local patterns from all groups. We evaluated our method on several dataset s, where it indeed discovered the pat-terns. We gain significant communication savings, with small accuracy loss.
Work partially supported by the NSF under Grants No. IIS-0209107 IIS-0205224 INT-0318547 SENSOR-0329549 IIS-0326322 and the Pennsylvania In-frastructure Technology Alliance (PITA) This publication only reflects the au-thors views.
