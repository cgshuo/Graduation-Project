 Timeline summarization is the task of organizing crucial milestones of a news story in a temporal or-der, e.g. (Kedzie et al., 2014; Lin et al., 2012). A timeline example for the 2010 British Oil spill gen-erated by our system is shown in Figure 1. The task is challenging, because the input often includes a large number of news articles as the story is de-veloping each day, but only a small portion of the key information is needed for timeline generation. In addition to the conciseness requirement, timeline summarization also has to be complete X  X ll key in-formation, in whatever form, must be presented in the final summary.

To distill key insights from news reports, prior work in summarization often relies on feature en-gineering, and uses clustering techniques (Radev et al., 2004b) to select important events to be included in the final summary. While this approach is un-supervised, the process of feature engineering is al-ways expensive, and the number of clusters is not easy to estimate. To present a complete summary, researchers from the natural language processing (NLP) community often solely rely on the textual information, while studies in the computer vision (CV) community rely solely on the image and video information. However, even though news images are abundantly available together with news stories, ap-proaches that jointly learn textual and visual repre-sentations for summarization are not common.
In this paper, we take a more radical approach to timeline summarization. We formulate the problem as a sentence recommendation task X  X nstead of rec-ommending items to users as in a recommender sys-tem, we recommend important sentences to a time-line. Our approach does not require feature engi-neering: by using a matrix factorization framework, we are essentially performing representation learn-ing to model the continuous representation of sen-tences and words. Since most previous timeline summarization work (and therefore, corpora) only focuses on textual information, we also provide a novel web-based approach for harvesting news im-ages: we query Yahoo! image search with sen-tences from news articles, and extract visual cues using a 15-layer convolutional neural network ar-chitecture. By unifying text and images in the low-rank approximation framework, our approach learns a joint embedding of news story texts and images in a principled manner. In empirical evaluations, we conduct experiments on two publicly available datasets, and demonstrate the efficiency and effec-tiveness of our approach. By comparing to various baselines, we show that our approach is highly scal-able and achieves state-of-the-art performance. Our main contributions are three-fold:  X  We propose a novel matrix factorization ap- X  We are among the first to consider representa- X  Our model significantly outperforms various Supervised learning is widely used in summariza-tion. For example, the seminal study by Kupiec et al. (1995) used a Naive Bayes classifier for selecting sentences. Recently, Wang et al. (2015) proposed a regression method that uses a joint loss function, combining news articles and comments. Addition-ally, unsupervised techniques such as language mod-eling (Allan et al., 2001) have been used for tem-poral summarization. In recent years, ranking and graph-based methods (Radev et al., 2004b; Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Fader et al., 2007; Hassan et al., 2008; Mei et al., 2010; Yan et al., 2011b; Yan et al., 2011a; Zhao et al., 2013; Ng et al., 2014; Zhou et al., 2014; Glava  X  s and  X  Snajder, 2014; Tran et al., 2015; Dehghani and Asadpour, 2015) have also proved popular for ex-tractive timeline summarization, often in an unsu-pervised setting. Dynamic programming (Kiernan and Terzi, 2009) and greedy algorithms (Althoff et al., 2015) have also been considered for construct-ing summaries over time.

Our work aligns with recent studies on latent variable models for multi-document summarization and storyline clustering. Conroy et al. (2001) were among the first to consider latent variable models, even though it is difficult to incorporate features and high-dimensional latent states in a HMM-based model. Ahmed et al. (2011) proposed a hierarchi-cal nonparametric model that integrates a Recurrent Chinese Restaurant Process with Latent Dirichlet Allocation to cluster words over time. The main issues with this approach are that it does not gen-erate human-readable sentences, and that scaling nonparametric Bayesian models is often challeng-ing. Similarly, Huang and Huang (2013) introduced a joint mixture-event-aspect model using a genera-tive method. Navarro-Colorado and Saquete (2015) combined temporal information with topic model-ing, and obtained the best performance in the cross-document event ordering task of SemEval 2015. There has been prior work (Wang et al., 2008; Lee et al., 2009) using matrix factorization to per-form sentence clustering. A key distinction between our work and this previous work is that our method requires no additional sentence selection steps after sentence clustering, so we avoid error cascades.
Zhu and Chen (2007) were among the first to consider multimodal timeline summarization, but they focus on visualization, and do not make use of images. Wang et al. (2012) investigated multi-modal timeline summarization by considering co-sine similarity among various feature vectors, and then using a graph based algorithm to select salient topics. In the computer vision community, Kim and Xing (2014) made use of community web pho-tos, and generate storyline graphs for image recom-mendation. Interestingly, Kim et al. (2014) com-bined images and videos for storyline reconstruc-tion. However, none of the above studies combine textual and visual information for timeline summa-rization. We now describe the technical details of our low-rank approximation approach. First, we motivate our approach. Next, we explain how we formulate the timeline summarization task as a matrix factor-ization problem. Then, we introduce a scalable ap-proach for learning low-dimensional embeddings of news stories and images. 3.1 Motivation We formulate timeline summarization as a low-rank matrix completion task because of the following considerations:  X  Simplicity In the past decade, a significant  X  Scalability A major reason that recommender for timeline summarization.  X  Joint Multimodal Modeling A key challenge 3.2 Problem Formulation Since the Netflix competition (Bell and Koren, 2007), collaborative filtering techniques with latent factor models have had huge success in recom-mender systems. These latent factors, often in the form of low-rank embeddings, capture not only ex-plicit information but also implicit context from the input data. In this work, we propose a novel matrix factorization framework to  X  X ecommend X  key sen-tences to a timeline. Figure 2 shows an overview of the framework.

More specifically, we formulate this task as a ma-trix completion problem. Given a news corpus, we assume that there are m total sentences, which are the rows in the matrix. The first column is the met-ric section, where we use ROUGE (Lin, 2004) as the metric to pre-compute a sentence importance score between a candidate sentence and a human-generated summary. During training, we use these scores to tune model parameters, and during testing, we predict the sentence importance scores given the features in other columns. That is, we learn the em-bedding of important sentences.

The second set of columns is the text feature sec-tion. In our experiments, this includes word obser-vations, subject-verb-object (SVO) events, and the publication date of the document from which the candidate sentence is extracted. In our preprocess-ing step, we run the Stanford part-of-speech tag-ger (Toutanova et al., 2003) and MaltParser (Nivre et al., 2006) to generate SVO events based on de-pendency parses. Additional features can easily be incorporated into this framework; we leave the con-sideration of additional features for future work.
Finally, for each sentence, we use an image search engine to retrieve a top-ranked relevant image, and then we use a convolutional neural network (CNN) architecture to extract visual features in an unsu-pervised fashion. We use a CNN model from Si-monyan and Zisserman (2015), which is trained on the ImageNet Challenge 2014 dataset (Russakovsky et al., 2014). In our work, we keep the 16 convo-lutional layers and max-pool operations. To extract neural network features, we remove the final fully-connected-1000 layer and the softmax function, re-sulting in 4096 features for each image.

The total number of columns in the input matrix is n . Our matrix M now encodes preferences for a sentence, together with its lexical, event, and tempo-ral attributes, and visual features for an image highly relevant to the sentence. Here we use i to index the i -th sentence and j to index the j -th column. We scale the columns by the standard deviation. 3.3 Low-Rank Approximation Following prior work (Koren et al., 2009), we are interested in learning two low-rank matrices P  X  the embedding of all candidate sentences, and Q is the embedding of textual and visual features, as well as the sentence importance score, event, and tempo-ral features. Here k is the number of latent dimen-sions, and we would like to approximate M ( i,j ) ' ~p the i -th sentence and ~q j is the latent embedding vec-tor for the j -th column. We seek to approximate the matrix M by these two low-rank matrices P and Q . We can then formulate the optimization problem for this task: min here,  X  P and  X  Q are regularization coefficients to prevent the model from overfitting. To solve this op-timization problem efficiently, a popular approach is stochastic gradient descent (SGD) (Koren et al., 2009). In contrast to traditional methods that require time-consuming gradient computation, SGD takes only a small number of random samples to com-pute the gradient. SGD is also natural to online al-gorithms in real-time streaming applications, where instead of retraining the model with all the data, pa-rameters might be updated incrementally when new data comes in. Once we have selected a random sample M ( i,j ) , we can simplify the objective func-tion: Now, we can calculate the sub-gradients of the two latent vectors ~p i and ~q j to derive the following vari-able update rules: Here,  X  is the learning rate, whereas ` ( i,j ) is the loss function that estimates how well the model approxi-mates the ground truth: The low-rank approximation here is accomplished by reconstructing the M matrix with the two low-rank matrices P and Q , and we use the row and col-umn regularizers to prevent the model from overfit-ting to the training data.

SGD-based optimization for matrix factorization can also be easily parallelized. For example, HOG-WILD! (Recht et al., 2011) is a lock-free paralleliza-tion approach for SGD. In contrast to synchronous approaches where idle threads have to wait for busy threads to sync up parameters, HOGWILD! is an asynchronous method: it assumes that because text features are sparse, there is no need to perform syn-chronization of the threads. In reality, although this approach might not work for speech or image re-lated tasks, it performs well in various text based tasks. In this work, we follow a recently proposed approach called fast parallel stochastic gradient de-scent (FPSG) (Chin et al., 2015), which is partly in-spired by HOGWILD!. 3.4 Joint Modeling of Mixed Effects Matrix factorization is a relatively complex method for modeling latent factors. So, an important ques-tion to ask is: in the context of timeline summa-rization, what is this matrix factorization framework modeling?
From equation (1), we can see that the latent sen-tence vector ~p i will be updated whenever we en-counter a M ( i,  X  ) sample (e.g., all the word, event, time, and visual features for this particular sentence) in a full pass over the training data. An interesting aspect about matrix factorization is that, in addition to using the previous row embedding ~p i to update the variables in equation (1), the column embedding ~q j will also be used. Similarly, when updating the la-tent column embedding ~q j in equation (2), the pass will visit all samples that have non-zero items in that column, while making use of the ~p i vector. Essen-tially, in timeline summarization, this approach is modeling the mixed effects of sentence importance, lexical features, events, temporal information, and visual factors. For example, if we are predicting the ROUGE score of a new sentence at testing, the model will take the explicit sentence-level features into account, together with the learned latent embed-ding of ROUGE, which is recursively influenced by other metrics and features during training.

Our approach shares similarities with some recent advances in word embedding techniques. For ex-ample, word2vec uses the continuous bag-of-words (CBOW) and SkipGram algorithms (Mikolov et al., 2013) to learn continuous representations of words from large collections of text and relational data. A recent study (Levy and Goldberg, 2014) shows that the technique behind word2vec is very similar to im-plicit matrix factorization. In our work, we consider multiple sources of information to learn the joint embedding in a unified matrix factorization frame-work. In addition to word information, we also con-sider event and temporal cues. 3.5 The Matrix Factorization Based Timeline We outline our matrix factorization based timeline summarization method in Algorithm 1. Since this is a supervised learning approach, we assume the cor-pus includes a collection of news documents S , as well as human-written summaries H for each day of the story. We also assume the publication date of each news document is known (or computable).
During training, we traverse each sentence in this corpus, and compute a sentence importance score ( I ) by comparing the sentence to the human gen-erated summary for that day using ROUGE (Lin, 2004). If a human summary is not given for that day, I i will be zero. We also extract subject-verb-object event representations, using the Stanford part-of-speech tagger (Toutanova et al., 2003) and Malt-Parser (Nivre et al., 2006). We use the publication date of the news document as the publication date of the sentence. Visual features are extracted using a very deep CNN (Simonyan and Zisserman, 2015). Finally, we merge these vectors into a joint vector to represent a row in our matrix factorization frame-work. Then, we perform stochastic gradient descent Algorithm 1 A Matrix Factorization Based Time-line Summarization Algorithm training to learn the hidden low-rank embeddings of sentences and features P and Q using the update rules outlined earlier.

During testing, we still extract events and publi-cation dates, and the PredictROUGE function esti-mates the sentence importance score I i , using the trained latent low-rank matrices P and Q . To be more specific, we extract the text, vision, event, and publication date features for a candidate sentence i . Then, given these features, we update the embed-dings for this sentence, and make the prediction by taking the dot product of this i -th column of P (i.e., ~p ) and the ROUGE column of Q (i.e., ~q 1 ). This pre-dicted scalar value I i indicates the likelihood of the sentence being included in the final timeline sum-mary. Finally, we go through the predicted results of each sentence in the timeline in temporal order, and include the top-ranked sentences with the highest sentence importance scores. It is natural to scale this method from daily summaries to weekly or monthly summaries. In this section, we investigate the empirical perfor-mance of the proposed method, comparing to vari-ous baselines. We first discuss our experimental set-tings, including our primary dataset and baselines. Then, we discuss our evaluation results. We demon-strate the robustness of our approach by varying the latent dimensions of the low-rank matrices. Next, we show additional experiments on a headline-based timeline summarization dataset. Finally, we provide a qualitative analysis of the output of our system. 4.1 Comparative Evaluation on the 17 We use the 17 timelines dataset which has been used in several prior studies (Tran et al., 2013b; Tran et al., 2013a). It includes 17 timelines from BBC, and NBC News. Only English documents are included. The dataset contains 4,650 news docu-ments. We use Yahoo! Image Search to retrieve exactly the same topic-based cross-validation setup that was used in prior work (Tran et al., 2013b): we train on eight topics, test on the remaining topic, and repeat the process eight times. The number of training iterations was set to 20; the k was set to 200 for the text only model, and 300 for the joint text/image model; and the vocabulary is 10K words for all systems. The common summarization metrics ROUGE-1, ROUGE-2, and ROUGE-S are used to evaluate the quality of the machine-generated time-lines. We consider the following baselines: Figure 3: Examples of retrieved Web images. The left image was retrieved by using a non-informative sentence:  X  The latest five minute news bulletin from BBC World Service  X . The right image was retrieved using a crucial sentence with a non-zero ROUGE score vs. a human summary,  X  Case study : Gulf of Mexico oil spill and BP On 20 April 2010 a deepwa-ter oil well exploded in the Gulf of Mexico  X .  X  Random : summary sentences are randomly se- X  MEAD : a feature-rich, classic multi-document  X  Chieu et al. (Chieu and Lee, 2004): a multi- X  ETS (Yan et al., 2011b): a state-of-the-art un- X  Tran et al. (Tran et al., 2013b): another  X  Regression : a part of a state-of-the-art extrac-
We report results for our system and the baselines on the 17 timelines dataset in Table 1. We see that the random baseline clearly performs worse than the other methods. Even though Chieu et al. (2004) Table 1: Comparing the timeline summarization per-formance to various baselines on the 17 Timelines dataset. The best-performing results are highlighted in bold . and MEAD (Radev et al., 2004a) are not specifi-cally designed for the timeline summarization task, they perform relatively well against the ETS sys-tem for timeline summarization (Yan et al., 2011b). Tran et al. (2013b) was previously the state-of-the-art method on the 17 timelines dataset. The ROUGE regression method is shown as a strong supervised baseline. Our matrix factorization approach outper-forms all of these methods, achieving the best re-sults in all three ROUGE metrics. We also see that there is an extra boost in the performance when con-sidering visual features for timeline summarization. Figure 3 shows an example of the retrieved images we used. In general, images retrieved by using more important sentences (measured by ROUGE) include objects, as well a more vivid and detailed scene. 4.2 Comparative Evaluation Results for To evaluate the robustness of our approach, we show the performance of our method on the recently re-leased crisis dataset (Tran et al., 2015). The main difference between the crisis dataset and the 17 time-lines dataset is that here we focus on a headline based timeline summarization task, rather than us-ing sentences from the news documents. The crisis dataset includes four topics: Egypt revolution, Libya war, Syria war, and Yemen crisis. There are a total of 15,534 news documents in the dataset, and each topic has around 4K documents. There are 25 man-ually created timelines for these topics, collected from major news agencies such as BBC, CNN, and Reuters. We perform standard cross-validation on Table 3: Comparing the timeline summarization per-formance to the state-of-the-art supervised sentence regression approach on the crisis dataset. The best-performing results are highlighted in bold . this dataset: we train on three topics, and test on the other. Here k is set to 300, and the vocabulary is 10K words for all systems. Table 3 shows the per-formance of our system. Our system is significantly better than the strong supervised regression baseline. When considering joint learning of text and vision, we see that there is a further improvement. 4.3 Headline Based Timeline Summarization: A Qualitative Analysis In this section, we perform a qualitative analysis of the output of our system for the headline based time-line summarization task. We train the system on three topics, and show a sample of the output on the Syria war. Table 2 shows a subset of the time-line for the Syria war generated by our system. We see that most of the daily summaries are relevant to the topic, except the one generated on 2011-11-24. When evaluating the quality, we notice that most of them are of high quality: after the initial hypothesis of the Syria war on 2011-11-18, the following daily summaries concern the world X  X  response to the cri-sis. We show that most of the relevant summaries are also providing specific information, with an ex-ception on 2011-12-02. We suspect that this is be-cause this headline contains three keywords  X  X yria X ,  X  X ivil X ,  X  X ar X , and also the key date information: the model was trained partly on the Libya war time-line, and therefore many features and parameters were activated in the matrix factorization framework to give a high recommendation in this testing sce-nario. In contrast, when evaluating the output of the joint text and vision system, we see that this error is eliminated: the selected sentence on 2011-12-02 is  X  Eleven killed after weekly prayers in Syria on eve of Arab League deadline  X . In this paper, we introduce a low-rank approxima-tion based approach for learning joint embeddings of news stories and images for timeline summarization. We leverage the success of matrix factorization tech-niques in recommender systems, and cast the multi-document extractive summarization task as a sen-tence recommendation problem. For each sentence in the corpus, we compute its similarity to a human-generated abstract, and extract lexical, event, and temporal features. We use a convolutional neural architecture to extract vision features. We demon-strate the effectiveness of this joint learning method by comparison with several strong baselines on the 17 timelines dataset and a headline based timeline summarization dataset. We show that image fea-tures improve the performance of our model signif-icantly. This further motivates investment in joint multimodal learning for NLP tasks.
 The authors would like to thank Kapil Thadani and the anonymous reviewers for their thoughtful com-ments.

