 With the prosperity of mobile market, more and more web search activities go to mobile devices. This raises the requirement of mining mobile search data, which is important for understanding user preferences, interests and activity patterns. Compared with web search from PC, mob ile search data contains rich context information, e.g., time, location, surrounding business and other signals captured by sensors of mobile devices. Previous works of mining search activities focus on analyzing the content of search query, web pages, etc., with limited attentions of mining context information [3]. According to our analysis of mobile search log data, we discover that both search query text and context information can help understand user activities. Table 1 gives examples of three major types of user search activities.  X  Text-Dominated activities can be fully understood by query content, with- X  Context-Dominated activities can be explained by the context informa- X  Both-Dependent activities require both tex t and context information to We can see that both text and context information can help understand the activity of mobile users. However, as far as we know, currently there are few ap-proaches which can model user activities based on text and context information simultaneously.
 In this paper, we propose a graphical model approach, namely the Text and Context-based User Activity Model (TCUAM) to mine user activity patterns using both query text and search context information. The TCUAM model is developed based on Latent Dirichlet Allocation (LDA), by regarding user ac-tivities as latent topics. As there are many noises in mobile log data, TCUAM has difficulty in discovering meaningful patterns. Therefore, we leverage human knowledge to help. We borrow external knowledge of topic-word relationship to build a constrained TCUAM model. The experiments on real mobile log in-dicates that the TCUAM model yields better results compared with text-only and context-only approaches. We also find that the constrained TCUAM model behaves more effectively than the unconstrained TCUAM model.

The rest of this paper is organized as fo llows. Section 2 briefly introduces the related work. The TCUAM model is de fined in Section 3. We describe experi-ments and results in Section 4. Conclusions are given in Section 5. There are mainly two groups of research works which are related to ours. The first is about feature modeling used in mining user activity patterns. Understand-ing user intent from text information such as past queries and user profiles is a common technique for web sea rch personalization. Sieg et al. [2] analyzed user profiles and assigned implicitly derived interest scores to existing concepts in a domain ontology for personalization. Noll et al. [4] implemented personalization using social bookmarking and tagging. Teevan et al. [5] utilized a personaliza-tion technique to leverage implicit information about the users X  interests and activities, including previously issued queries, previously visited web pages and the documents a user has read or created. Besides text information mentioned above, context information is also adopted by researchers to mine user activity patterns. Arias et al. [6] found that it was beneficial to understand user intents and complete desired queries by context information such as time and location. Hattori et al. [7] improved the performance of query refinement by incorporating user context information. Church et al. [8] proposed a novel interface to support multi-dimensional and context-sensitive mobile search, combining context fea-tures such as location, time, and comm unity preferences to offer better search experiences.

The other group of related works is about learning models. The models of utilizing context information can be divided into three stages. In the first stage, context information is manually processed in a certain domain, especially in a geographical system [9,10,11]. In the second stage, researchers begin to use traditional text learning model to tackle context learning pro blems. Algorithms like Bayesian Network, Hidden Markov Model (HMM), Support Vector Machine (SVM) and Conditional Random Field (CRF) have been adopted to model user behaviors [12,13]. In the third stage, unsupervised models are used for learning tasks of large-scale data. Topic model related approaches are adopted in this stage for user activity mining. E.g., Bao et al. [3]triedtomodelcontextinfor-mation by an unsupervised approach based on latent dirichlet allocation (LDA) to discover users X  activities. 3.1 Data and Preprocessing In this work, we mine user activities using mobile search log. The log contains a i  X  N log and it is difficult to obtain satisfactory results without data preprocessing. In traditional approaches, queries with low frequencies are usually regarded as noises and excluded from query log. In our work, we regard the queries which are not very related to context as noises. We introduce a scoring function to calculate the possibility of a query to be noise: v irrelevant feature f i is with the query text, thus the more likely query q will be anoisyquery. f q denotes the frequency of query q ,  X  f 75% stands for the average frequency of 75% queries whose values lie in the middle of all the queries. The more likely the query is considered to be noise.

The smaller value  X  ( q ) takes, the more likely that query q is considered as noise. In practice, an appropriate threshold is chosen to filter out noisy queries. 3.2 Text and Context-Based User Activity Model In this section, we will introduce the Text and Context-based User Activity Model (TCUAM) for mining users X  activities based on Latent Dirichlet Alloca-tion (LDA). Bao et al. [3] has proposed an LDA-based approach to mine user activities using context information. However, context information itself can only explain part of user activities. Our model is designed to utilize text and context information simultaneously for user activity mining.
 to time information. Each session contains data records within 30-minutes time session is generated by a collection of topics, which follow dirichlet distributions. n th observation of query text in the m th session where w m,n,i is the i th word feature name and v i denotes the value of feature f i .

The process of generating text and cont ext information for all the sessions can be expressed as follows. Firstly, draw a query word distribution  X  k for each topic k from dirichlet distribution with parameter  X  . Secondly, for each topic k and feature f , draw a feature-value pair distribution  X  k  X  f from dirichlet tion  X  m and a feature distributions  X  m from dirichlet distribution with parameter  X  and  X  respectively. Then for each session s m , records are generated repeatedly based on the model. For each record r m,n in session s m ,wefirstchooseatopic z m,n according to the topic distribution Multi(  X  m ) . Afterwards, query text and context information are generated resp ectively according to their distributions on topic z m,n . Each word w m,n,i in the query text is generated directly from word is generated from the feature distribution Multi (  X  m ) while the corresponding Table 2 summarizes the generative process of TCUAM.

In practice, we take the whole query as a single word. That is, we use q m,n = w m,n , instead of q m,n = model is shown in Figure 1.
 3.3 Inference of Model To simplify the equations, we define the following symbols. The hyper-parameters in the TCUAM model are denoted as  X  , which include  X  ,  X  ,  X  and  X  .Theob-denotes the n th record in the m th session. q m,n = w m,n stands for the n th ob-a feature-value pair where f i denotes the feature name and v i denotes the value of and  X  = {  X  p } K  X  F p =1 ,where K is the total number of topics and F is the total number of features. Thus, given hyper-parameters, the joint distribution of all observations and hidden variables can be calculated as follows: where N s is the number of sessions, N r isthenumberofrecordsineachsession, and N p is the number of feature-value pairs in the context.

We obtain the joint probability for all observations by integrating over the parameters and latent variables: We use Gibbs sampling to get the approximate estimation of parameters. In Gibbs sampling, each record is assigned to a certain topic under the condition that other records have been labeled. We assume that Text Information and Context Information are generated by activity topics independently and obtain the following equation: where w stands for the vector of words; c stands for the vector of feature-value the vector of topics for all records after excluding the i th record.
The two conditional probabilities on the right side of Eq.(4) can be calculated by [14]: Where  X  k denotes the hyper-parameter of dirichlet distribution for topic k ,and  X  w denotes the hyper-parameter of dirichlet distribution for word w . i = &lt;m,n&gt; the times of word w being observed with topic k after excluding the i th record, n k,  X  i stands for the times of feature-value pair &lt;f,v&gt; being observed with being observed in session m after excluding the i th record.

After the convergence of Gibbs sampling iteration, each observation will be assigned a final topic label. Eventually, the parameters can be inferred as below: 3.4 Constrained TCUAM Model In practice, the unconstrained TCUAM model is unable to achieve satisfactory results due to massive noises in mobile log. Therefore, we borrow some external knowledge about topic-word relationship to help. We leverage a set of websites, which are organized into a list of topics. For each topic, we can use search log to associate queries with websites using the follow-click information. Given a set of topics K = { k 1 ,k 2 ... } , assume that the set of websites for topic k i is each query into word sequences. Thus, the relevant score of topic k i and word w j can be calculated by: We choose top 50 words with the highest relevance scores for each topic and map them to  X  [50  X  1] linearly. For example, if airline is the third relevant word to topic Travel ,  X  ( Travel,airline ) = 48. Thus, we obtain 50 representative words for each topic as external knowledge to guide the activity mining model. The core idea of using this knowledge is to in crease the weight of an unlabeled word in Gibbs Sampling if it is known to be a representative word for a specific topic. The whole procedure of Gibbs sampling is displayed in Algorithm 1, where the variables are defined in Table 3.
 4.1 Data Set In this paper, we carry out our experiments on real mobile logs from a commercial search engine. The data set consists of half a year X  X  mobile logs in California State, USA. Table 4 shows the feature list of text and context information used in our experiment. For period feature, we define its values according to the time range of search activity. We remove the users whose query numbers are less than 50 in half a year time span. The preprocessing procedure described in section 3.1 is applied to clean the dataset. In our experiment, we set the threshold as 0.25.

The external knowledge of topic-word relationship for the constrained TCUAM model is illustrated in Table 5. We have 15 kinds of activity topics which mobile users are specially interested in. For each activity topic, 50 words are selected to be the external knowledge. Because of spa ce limitation, only top 5 words for each activity topic are listed in the table.

Algorithm 1. Gibbs Sampling For Constrained TCUAM 4.2 Experimental Setup In the experiment, we evaluate four models which are described below.  X  X M (Text-based Model) is the baseline of our experiment. The text-based  X  X M (Context-based Model) is proposed by Bao et al. [3] to mine mobile  X  X CUAM (Text and Context-based User Act ivity Model) is an unconstrained  X  X TCUAM (Constrained TCUAM) is a constrained model which uses ex-In order to get a fair comparison of the models above, we adopt the same session segmentation method for all the models. Records are segmented into sessions by time information. Each session contains the records within a time span of 30 minutes. In addition, the number of topics in all the models is set to be 200 experimentally. 4.3 Evaluation The goal of our experiment is to examine whether users X  activity patterns can be mined correctly from mobile logs. Unfortunately, it is difficult to identify auto-matically whether the result patterns mak e sense or not. Therefore, we examine the result topics produced by each mode l manually and assign each topic a score. The score is given according to the following rules:  X 5 : It is a perfect pattern and indicates user activity clearly.  X 4 : It is a good pattern and can give an overall sense of user activity.  X 3 : It is a reasonable pattern and gives some clues of the user activity.  X 2 : It is a bad pattern and includes many noises.  X 1 : It is a non-sense pattern and difficult to be understood.
 The average score (AS) of result topics is calculated after each topic is assigned a score manually. In our experiment, we use AS as the metric to evaluate the performances of different models. 4.4 Results Table 6 shows the results of different models, evaluated by the average score (AS). We can find out that the worst way to mine user X  X  activity is the Context-based Model (CM), whose AS value is 1.995. It indicates that only context information is not enough to determine users X  actual activities. The Text-based Model (TM) achieves 2.295 for AS value, which shows that the text informa-tion is more informative than the context information. By using text and context information simultaneously, the TCUAM model achieves 2.545 for AS value (im-proving 27.6% from Context-based Model and 10.9% from Text-based Model). Therefore, the text information and context information can be utilized collab-oratively to benefit the activity mining approaches. The Constrained TCUAM model enhances the performance further by 11.8%, achieving an AS value of 2.845. Moreover, the knowledge used in the constrained model is easy to be col-lected. Thus, the constrained model can mine user activity topics more precisely without taking too much human efforts.
 4.5 Case Study To get a further understanding of the Constrained TCUAM model, we select some examples to demonstrate the results produced by the model. Table 7 shows two topics discovered by the model. The  X  X sRelevant X  column gives the human judgement that whether the text or context is relevant to the topic. It is easy to infer that the user X  X  activity is  X  X earching for stock information at home in the workday morning X  for the left case and it is  X  X earching for amusement place after dinner outside in the weekend X  for the right case. In this paper, we propose a text and context-based user activity model to mine user X  X  activity patterns from mobile logs. In addition, we introduce a small amount of external knowledge about topic-word relationship to build a con-strained TCUAM model. The experiments were carried out on real mobile logs. The experimental results have indicated that the TCUAM model can yield bet-ter results, compared with text-only and context-only approaches. We can also conclude from the results that the constrained TCUAM model performs more effectively than the unconstrained TCUAM model.

