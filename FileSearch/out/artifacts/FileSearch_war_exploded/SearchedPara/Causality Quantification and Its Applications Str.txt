 Time series prediction is an important issue in a wide range of areas. There are various real world processes whose states vary continuously, and those processes may have influences on each other. If the past information of one process X improves the predictability of another process Y , X is said to have a causal influence on Y . In order to make good predictions, it is necessary to identify the appropriate causal relationships. In addition, the processes to be modeled may include symbolic data as well as numerical data. Therefore, it is important to deal with symbolic and numerical time series seamlessly when attempting to detect causality.
In this paper, we propose a new method for quantifying the strength of the causal influence from one time series to another. The proposed method can represent the strength of causality as the number of bits, whether each of two time series is symbolic or numerical. The proposed method can quantify causality even from a small number of samples. In addition, we propose structuring and modeling methods for multivariate time series using causal relationships of two time series. Our structuring and modeling methods can also deal with data sets which include both types of time se-ries. Experimental results demonstrate that our methods can perform well even if the number of samples is small. G.3 [ Mathematics of Computing ]: Probability and Statis-tics X  time series analysis Algorithms, Theory Information Theory, Entropy, Autoregressive Model, Markov Chain, Time Series Prediction
Time series prediction is an important issue in a wide range of areas such as finance [4], weather forecasting [1], and transportation planning [7]. For example, economists predict economic trends from indicators such as exchange rates, stock prices, and GDPs. The conclusions drawn by the economists then affect traders X  decisions. The actions of the traders are then reflected back into the economic indica-tors, creating a cycle. Thus, the re are various real world pro-cesses whose states vary continuously, and those processes may have influences on each other. When past values of one time series provide significant information about future values of another, the relationship of the two time series is called  X  X ausality X , in distinction from correlation. In order to make good predictions, it is necessary to identify the ap-propriate causal relationships. In addition, the processes to be modeled may include symbolic data (weather, text, etc.) as well as numerical data (temperatures, stock prices, etc.). Therefore, it is important to be able to handle seamlessly mixed symbolic and numerical time series when attempting to detect causality. If causality can be properly evaluated, it is possible to predict multivariate time series by estimating their structure or modeling their dynamics.

Time series prediction for multivariate data is a well stud-ied problem, especially in economics. Common methods are vector autoregressive models (VAR models) and dynamic factor models (DFMs) [11, 4]. VAR models can detect to-tally idealized relationships. The drawback of VAR models is that a large number of samples are required to obtain good parameter estimates. DFMs, on the other hand, avoid the need for a large number of samples by compressing the orig-inal multivariate variables into a smaller set of unobserved factors. However, DFMs cannot describe causal relation-ships among observed variables. Also, in some cases the compression does not work, if the original variables cannot be represented well by a smaller number of factors.
We focus on causality measures in order to solve these problems. Causality measures quantify the strength of a causal influence from one time series to another. Many causality measures have been proposed [9, 6], because detec-tion of causality is a significant challenge in economics [5, 3] and biology [2]. Since causal relationships of just two time series can be estimated from a small number of samples, we expect that it is possible to reduce the number of samples needed for modeling multivariate time series by combining bivariate models. In contrast to the implicit modeling of relationships performed by the compression used in DFMs, using causality measures makes it possible to describe ex-plicit casual relationships between observed variables. How-ever, there is a problem remaining. Conventional causality measures cannot seamlessly handle time series with mixed symbolic and numerical data. The causality measures which can deal with such series are needed.

In this paper, we propose a set of new causality mea-sures, which can represent the strength of a causal influ-ence in a  X  X ommon currency X , regardless of whether each of two variables is numerical or symbolic. This common cur-rency is a bit count. The proposed measures can quantify causality even if the number of samples is small. In ad-dition, we propose structuring and modeling methods for multivariate time series based on causal relationships of two time series. Our methods can also deal with data sets that include both symbolic and numerical time series. Experi-mental results demonstrate that our methods can perform well even if the data is of limited size and includes mixed numerical/symbolic components.

The remainder of this paper is organized as follows. Sec-tion 2 discusses existing causality measures, and proposes the new method. Our structuring and modeling methods are given in Section 3. Section 4 reviews the results of our experiments. Section 5 is a brief conclusion.
We introduce existing causality measures and point out their problems. Then, we propose a set of new causality measures.
The transfer entropy , proposed by Schreiber [10], is an in-formation theoretic causality measure that evaluates causal-ity by calculating the information one variable contains about another.

Assume that X, Y are the time series variables, which in-dicate x t and y t at time t respectively, and that the two variables may be approximated by stationary Markov pro-cesses of order k, l . Then, the dynamics of Y can be ex-pressed by a transition probability p ( y t | y ( l ) t  X  1 denotes ( y t  X  1 ,...,y t  X  l ) T . Given that the past states are known, the entropy of the subsequent state y t is given by the following formula:
Generally, it is necessary to estimate the transition prob-ability because the true transition probability p ( y t | y unknown. When an estimate transition probability q ( y t | y expresses the difference between the two probability distri-butions. This distance can be interpreted as the code length penalty paid for using the model q when the real probabil-ity is p . Kullback-Leibler distance is given by the following formula:
Here, if the current state y t of Y is independent of the past states x ( k ) t  X  1 of X ,then the generalized Markov property , holds. Since the two probability distributions deviate from the generalized Markov property (Equation (1)) if the state of X has some kind of influence on Y , the causality from X to Y can be quantified by the Kullback-Leibler distance. Therefore, the average information about Y contained by X is given by the following formula for the transfer entropy:
This causality measure can be applied to symbolic time se-ries without preprocessings. However, when this measure is applied to numerical time series, some kind of preprocessings or assumptions are needed. In the comparison experiments of this paper, we used the histograms of the embedding vec-tors (na  X   X ve histogram technique). In this case, the number of bins r is needed as an additional parameter.
Continuous transfer entropy proposed by Kaiser et al. [8] is a causality measure derived from transfer entropy by as-suming that numerical time series X, Y are generated by Gaussian processes.

Transfer entropy can be expressed as a sum of Shannon entropies: For processes with Gaussian distributions, Shannon entropy can be expressed as following formula: denotes the determinant of C y ( l )
From Equation (3) and Equation (4), the following for-mula is obtained as continuous transfer entropy.
 Granger causality is the method proposed by Granger [5]. The approach of this method is to examine if the prediction of one variable can be improved by incorporating the past information of another variable.

First, consider the autoregressive model (AR model): where a 0 is a constant term and a  X  R l is a regression coefficient vector, determined by least squares. ( y ) t is white noise with zero mean and  X  2 y variance, ( y ) t  X  N
Next, consider the following regression model: As in the AR model, b 0 is a constant term and b  X  R l , and c  X  R k are regression coefficient vectors determined by least squares. ( y | x ) t is white noise with zero mean and  X 
Here, the modeling performance of the two models can be evaluated by the comparison of  X  2 y and  X  2 y | x . If X has a causal influence on Y, then  X  2 y &gt; X  2 y | x . However, it is not obvious how to compare the two variances, and multiple comparison methods have been proposed such as  X  2 y  X   X  2 y | x and  X  [9, 6]. One issue with Granger causality is that the mag-nitude relation of the measured values can be reversed by using different comparison methods. In the experiments of this paper, we used  X  2 y  X   X  2 y | x as Granger causality.
Granger causality cannot be applied to symbolic time se-ries because it is based on regression models.
We derive a set of new causality measures that deal with symbolic and numerical time series seamlessly by combining the regression model and the information theory.
Let X, Y be numerical time series. When it is assumed that Y is ordered by AR model (Equation (6)), the con-ditional probability distribution p ( y t | y ( l ) t  X  1 following formula:
In AR model, the probability distribution of y ( l ) t  X  1 tivariate normal distribution. Let  X  y ( l ) y the joint probability distribution p ( y t , y ( l ) t  X  1 ate normal distribution given by the following formula: The determinant of the covariance matrix of this distribution
Similarly, as to the joint probability distribution of y t y (7) is assumed.
Since time series data ordered by a regression model is assumed to be a multivariate normal distribution, the fol-lowing formula is obtained by substituting Equation (8) and Equation (9) for Equation (5).
 This causality measure represents the average number of bits of information about Y that is contained in X , within the framework of Granger causality.
Let X be symbolic time series, and Y be numerical time series. When it is assumed that Y is ordered by a normal distribution, the transfer entropy is given by the the follow-ing formula:
Here, consider the Switching AR model: where b 0 and the coefficient which switch corresponding to x ( k )  X  Then, the following formula is obtained.
 This causality measure represents the average number of bits of information about Y contained in X . This measure de-notes how much predictability of y t is improved by preparing a different model for each state of X ( k ) t  X  1 .
Let X be numerical time series, and Y be symbolic time series. When it is assumed that X is distributed according Table 1: Overview of proposed causality measures to a normal distribution, the transfer entropy is given by the the following formula: This causality measure represents the average number of bits of information about Y contained in X .Thismeasure denotes how much the distribution of x ( k ) t  X  1 is changed by taking into consideration not only y ( l ) t  X  1 but also y
By using three proposed causality measures and the ordi-nary transfer entropy, causal influences of all combinations of symbolic and numerical time series can be represented by the average numbers of bits (Table 1). Moreover, the pro-posed method can be utilized directly for the modeling of multivariate time series because this method is based on re-gression models that represent the dynamics of the variables.
Compared to existing methods, the proposed method has some other advantages. The proposed method requires a smaller number of parameters. Though the proposed mea-sures use the two embedding dimension parameters k , l , these are common to all causality measures [9]. In addition, the proposed measures are inva riant to linear transforma-tions or normalization of numerical time series.
Estimation of the causal structure hidden in data is an important and a well studied subject. There are two main kinds of estimation methods. One is to select the best struc-ture by searching and evaluating entire structures, the other is to build the structure by examining each causal influ-ence from one variable to another. The former works well at estimating the true structure if there are enough sam-ples. However, the number of possible structures increases exponentially depending on the number of variables: when the number of variables is N , the number of structures is Figure 1: Overview of proposed structuring method. O  X  ter space created by a data set with many variables. On the other hand, the latter needs fewer samples in order to esti-mate relationships. We focus on this advantage. Even when sufficient samples can be observed, the latter method can sooner model observed time series and make predictions. We propose a new structuring method, which structures multi-variate time series using causality measures. Our causality measures proposed in Section 2 can represent the strength of a causal influence as a bit count, regardless of whether each of two time series is symbolic or numerical. As a re-sult, the proposed structuring method can be applied to data sets which include both symbolic and numerical time series. The detailed method is as follows.

When a data set of N time series are given, N ( N  X  1) causality measures can be calculated, representing each pair of variables but excluding self-interactions. Structuring can be achieved by filtering the N ( N  X  1) values with a thresh-old, leaving behind only the significant causal links (Figure 1).
Modeling of multivariate time series can be realized by combining the bivariate models which are used in calcula-tions of causality measures. In the combination process, the values of the causality measures are used as weights. By us-ing weights based on the values, models which have strong causal influences are stressed, while models with weak causal influences are ignored. The detailed method is as follows.
Let Y denote the objective numerical variable, and X 1 , ..., X N  X  1 denote the other variables. Then, the modeling of Y can be realized by combining the regression models y causality measure T X i  X  Y : where, if X i is a numerical time series, and, if X i is a symbolic time series, In the above formulation, all causal relationships are taken into account. However, the model can be simplified by fil-tering the values of the causality measures with a threshold T thre . The filtering can be realized by the following process-ing:
Unlike normal VAR models, our proposed method can model data sets that include not only numerical but also symbolic time series. In addition, this method has some other advantages. First, the model can be estimated even from a small number of samples because the model is made by combining bivariate models. If all variables are numer-ical, the required number of samples is independent of the number of variables, while normal VAR models need many more samples. Second, when new variables are added to the already learned model or unnecessary variables are deleted from it, the bivariate models which are used in it are avail-able for the estimation of a new model. In the case of VAR models, the model must be estimated from the beginning.
In this section, we first examine the performance of the proposed and existing causality measures. The data sets used for evaluation have arbitrary combinations of numerical and symbolic data (with the exception of symbolic-symbolic data, which just gives the transfer entropy). Next, we con-duct experiments on structuring and modeling methods by examining whether relationships among multivariate time series can be estimated by combining causal relationships of two time series.
In the first experiment, we examine the performance of causality quantification methods for numerical time series. We compared the ability of the different methods to dis-tinguish the presence or absence of a causal influence on bivariate data sets. Each data set consists of two numerical time series C 1 and C 2 . C 1 and C 2 are constructed using by the following model: where 1 ,t and 2 ,t are white noises with zero mean and unit variance, 1 ,t  X  N (0 , 1) , 2 ,t  X  N (0 , 1). In this model, C has a causal influence on C 1 whereas C 1 does not on C 2 We generate 100 independent data sets from random ini-tial values, and compare the proposed measure with trans-fer entropy (TE), continuous transfer entropy (CTE), and Granger causality (GC). We set two embedding dimension parameters of causality measures to k =1and l = 1 accord-ing to the model of data sets. As to TE, we compare three different parameters (the numbers of bins), r =2, r =4, and r = 8. In this experiment, we change the number of samples N = 100, 200, 500, 1000, 2000, 5000, and 10000.
Figure 2 depicts the result. The horizontal axis denotes the number of samples used in calculation of causality mea-sures. The vertical axis denotes ratios of causality measures T erations. The smaller T C 1  X  C 2 /T C 2  X  C 1 is, the more clearly Figure 2: The performance of causality measures when varying the number of samples (from numeri-cal data to numerical data). the presence or absence of causality is distinguished. We ob-serve that the proposed measure, CTE, and GC successfully indicate the presence or absence of causality because these three methods do not quantize numerical time series. Note that the graphs of these methods overlap. Though the three methods do not differ in performance on the pure numeri-cal data sets, the proposed measure has the advantages that it describes the dynamics of time series, and represents the strength of causal influences as the number of bits. As to TE, the score of r = 2 is better than r =8. Thisisbecause, as the number of bins increases, more samples is needed for the exact estimation of probability distributions. In fact, T 2  X  C 1 of r = 2 converges near N = 1000 whereas that of r = 8 does not even at N = 10000. TE is very sensitive to the parameter r .
In the second experiment, we examine performance of causality quantification from symbolic to numerical time se-ries, using trivariate data sets. Each data set consists of two symbolic time series S 1 , S 2 , and one numerical time series C . S 1 , S 2 ,and C are ordered by the following model: Figure 3: The performance of causality measures when varying the number of samples (from symbolic data to numerical data). where t is white noise with zero mean and unit variance,  X  N (0 , 1). In this model, C is influenced by S 1 ,notby S . We generate 100 independent data sets from random ini-tial values, and compare the proposed measure with transfer entropy (TE) of the parameter r =2, r =4,or r =8. We set two embedding dimension parameters to k =1and l =1 according to the model of data sets. We change the number of samples N = 100, 200, 500, 1000, 2000, 5000, and 10000.
Figure 3 shows the result. The horizontal axis denotes the number of samples used in calculation of causality mea-sures. The vertical axis denotes ratios of causality measures T 2  X  C /T S 1  X  C (means over 100 repetitions). The smaller T 2  X  C /T S 1  X  C is, the more clearly the presence or absence of causality is distinguished. As evident from Figure 3, the proposed measure performs better than TE because the pro-posed method does not quantize numerical time series, on the other hand, TE is very sensitive to quantization.
In the third experiment, we examine the ability of the proposed method to calculate causality from numerical to symbolic time series. We use trivariate data sets, consisting of two numerical time series C 1 , C 2 , and one symbolic time series S . C 1 , C 2 ,and S are created using the following model: Figure 4: The performance of causality measures when varying the number of samples (from numeri-cal data to symbolic data). where 1 ,t and 2 ,t are white noises with zero mean and unit variance, 1 ,t  X  N (0 , 1) , 2 ,t  X  N (0 , 1). In this model, S is influenced by C 1 ,notby C 2 . We generate 100 indepen-dent data sets from random initial values, and compare the proposed measure with the transfer entropy (TE) using pa-rameter values r = 2, 4, or 8. We set the two embedding dimension parameters to k =1and l = 1. We change the number of samples N = 100, 200, 500, 1000, 2000, 5000, and 10000.

The result is displayed in Figure 4. The horizontal axis denotes the number of samples used in calculation of causal-ity measures, and the vertical axis denotes ratios of causality measures T C 2  X  S /T C 1  X  S (means over 100 iterations). The proposed method still performs better than TE.
In the fourth experiment, we examine the performance of our structuring and modeling methods using a model, consisting of four numerical variables ( C 1 , C 2 , C 3 ,and C and two symbolic symbolic variables ( S 1 and S 2 ). Those six variables have the causal relationship depicted in Figure 5. All of these are generated by simple Markov processes. S 1 and S 2 are subject to the following transition probabilities: Variations of C 1 , C 2 , C 3 ,and C 4 are generated by the fol-Figure 5: Causal relationship of the model which consists of both symbolic and numerical time series. lowing formula: and 0 . 1variance, 1 ,t  X  N (0 , 0 . 1) , 2 ,t  X  N (0 , 0 . 1) , N (0 , 0 . 1) , 4 ,t  X  N (0 , 0 . 1). We generate 100 independent data sets from random initial values. We set the two embed-ding dimension parameters to k =1and l = 1 as indicated by the model used to construct the data sets.

First, we examine the performance of our structuring method with 100 data sets. We structure each data set changing a threshold of calculated causality measures and compute mean of recall, precision, and f-measure by thresh-old, changing the number of samples N = 100, 200, 300, 500, 700, and 1000. We let P denote the number of causal links that can be correctly estimated, Q denote the number of causal links that is present in the original structure of Figure 5, and R denote the number of causal links that is present in the estimated structure. Then, the recall and the precision are defined as: Recall = P/Q ,Precison= P/R .Because of tradeoff between these two scores, the total performance Figure 6 shows relati onships between recall and precision. Each line of Figure 6 ends halfway because, if all causality measures is weaker than the threshold used in the filtering phase, no links will be estimated, so P = R =0. Figure7 displays the relationship between maximum f-measure and the number of samples used. We observe that our method successfully discovered the structure of a comparatively sim-ple data set, even though it includes both symbolic and nu-merical data.

Next, we compare the prediction accuracy of the model-ing methods by using cross validation with 100 data sets. We use the learned models to predict values of numerical variables at a given time step by looking at the values at the previous time step. We compare three methods: (1) AR model of each variable, which disregards causal influences, (2) switching VAR model, which switches VAR models ac-cording to the combination of states of the two symbolic variables, (3) our modeling method. In this experiment, we change the number of samples N = 100, 200, 300, 500, 700, and 1000. The result is displayed in Figure 8. The horizon-Figure 6: Recall-precision graph of the proposed structuring method on data which consists of both symbolic and numerical time series. Figure 7: F-measure of the proposed structuring method on data which consists of both symbolic and numerical time series, when varying the number of samples. tal axis denotes the number of samples. The vertical axis denotes the mean squared errors of predicted values. As ev-ident from Figure 8, our method makes better predictions than AR because our method takes into account causal re-lationships among variables. Compared to switching VAR, our method performs better when the number of samples is small. This result confirms that it is possible to reduce the number of samples needed for modeling multivariate time series by combining bivariate models.
In the fifth experiment, we conduct the same experiment using genetic regulatory model of [12], whose variables are all numerical. This causal links between genes in this model have a more complex network structure than the models used in the previous experiments. The values of gene expres-sion levels are updated by two processes. First, the values at each step are produced by the following formula: where Y t is a vector which represent the expression levels of all genes at time t . Second, the expression levels are Figure 8: The performance of AR, VAR, and the proposed modeling method on data which consists of both symbolic and numerical time series. restricted by a floor and ceiling function to range from 0 to 100. The matrix A represents the causal relationships of all genes. If the ( i, j )-th element of A is nonzero, the i -th gene has some influence on the j -th gene. The vector T is a constant vector. All elements of T are set to 50, the median value between the maximum and minimum. If a gene expression is at a level above 50, the regulatory effect on the genes occurs as specified in A ; the higher the expression level, the stronger the specified effect. In contrast, if a gene expression is at a level below 50, its effect is in the opposite direction of that specified in A ; the lower the expression level, the stronger the opposite effect. The term models biological noise and is drawn uniformly at random from the range  X  10 to 10. In this experiment, we use 10 different networks with 12 or 13 genes, and generate 10 independent data sets for each network using random initial values, for a total of 100 data sets. We set the two embedding dimension parameters to k =1and l =1.

First, we examine the performance of our structuring method with 10 data sets from one network selected ran-domly. We structure each data set changing a threshold of calculated causality measures and compute mean of recall, precision, and f-measure by threshold, changing the number of samples N = 100, 200, 500, 1000, 2000, 5000, and 10000. Figure 9 displays relationships between recall and precision. Each line of Figure 9 ends halfway, for the same reason as mentioned above. Figure 10 shows the relationship between maximum f-measure and the number of samples. As evident from Figure 10, the f-measure does not change very much as the number of samples increases from 1000 to 10000. The reason is that our method extracts not only true causal rela-tionships but also indirect relationships such as grandparent-grandchild ( X  X  Y and Y  X  Z =  X  X  X  Z )orbroth-ers ( X  X  Y and X  X  Z =  X  Y  X  Z ). Our structuring method cannot determine whether a relationship is direct or indirect because the causality measure consistently reports that one variable has a causal influence on the other. In or-der to apply our method to real world engineering problems, we need to determine how this disadvantage affects actual predictions.

Next, we conduct an experiment to compare the different modeling methods. We use the learned models to predict gene expression levels at a given time step using the in-Figure 9: Recall-precision graph on the genetic reg-ulatory data. Figure 10: F-measure on the genetic regulatory data when varying the number of samples. formation from the previous time step. We compare three methods: (1) AR model of each variable, (2) VAR model, (3) our modeling method. We conduct cross validation for 10 data sets generated from each structure, using a number of samples N = 1000, 2000, 3000, 5000, 7000, and 10000. The result is displayed in Figure 11. The horizontal axis denotes the number of samples, and the vertical axis denotes the mean squared errors of predicted values. Figure 11 shows a similar result for an experiment on data consisting of mixed symbolic and numerical time series.

We discuss the difference in effects of indirect relation-ships between structuring and modeling. In the structuring experiment on genetic regulatory data, indirect relationships were extracted because the causality measures between the corresponding variables were moderately large. The result shows that indirect relationships (grandparent-grandchild or sibling) prevent the estimation of the true structure. How-ever, those indirect relationships may have a positive influ-ence on the modeling results. The proposed causality mea-sures to numerical time series (Equation (10) and Equation (12)) are based on the prediction accuracy of regression mod-els. That is, indirect relationships that create high causality measures can help to make good predictions. This means that, if variables which connect observed variables are not observed, our modeling method can implicitly model effect of Figure 11: The performance of AR, VAR, and the proposed modeling method on the genetic regula-tory data.
 Table 2: Comparing mean of relative errors for AR and the proposed modeling method on the Japanese stock price data.
 the unobserved variables. Indirect relationships are bad for our structuring method but good for our modeling method. Note that our structuring method can estimate simple struc-tures even if structures have both symbolic and numerical variables (Figure 7).
Finally, we applied the proposed modeling method to the real-world data, which consists of the 225 closing stock prices used in the calculation of the Nikkei Stock Average from September 3, 2007 to March 25, 2008. We predict the clos-ing prices by the day, using data of the past 20 business days (about 1 month). In this experiment, we change the embed-ding dimension k, l from 1 to 3. We cannot use VAR of 225 variables to estimate a model from only 20 time steps. We compare the prediction accuracy of the proposed method with AR.

Table 2 shows mean relative errors. The proposed method forecasts better than AR in three kinds of parameters. There are two possible reasons to explain this result. The first rea-son is that stock prices have direct causal influences on each other. If there are causal relationships, then naturally our method can make better predictions by exploiting those re-lationships. The second possible reason is that several stock prices have common causal sources. If there are indirect relationships between stock prices, our method can model those causal sources implicitly and make good predictions.
This result demonstrates that the proposed modeling method is effective even when it is applied to the real world data.
In this paper, we proposed a causality quantification method which can handle mixed symbolic and numerical time series data in a seamless fashion. The proposed method has better causality detection performance than existing methods, especially when the number of samples is small. In addition, we proposed structuring and modeling methods using our causality measures. Because our causality quan-tification method can deal with two types of time series, our modeling methods can also deal with data sets that include both. Experimental results demonstrated that our methods can perform well even if the number of samples is small. In modeling experiments, it is showed that our method can im-plicitly model unobserved variables which connect observed variables. [1] S.P.Charles,B.C.Bates,I.N.Smith,andJ.P.
 [2] Y. Chen, S. L. Bressler, and M. Ding. Frequency [3] C. Dritsaki and M. Dritsaki-Bargiota. The causal [4] G. Elliott, C. W. J. Granger, and A. Timmermann. [5] C.W.J.Granger.Investigatingcausalrelationsby [6] K. Hlav  X  a X ckov  X  a-Schindler, M. Palu X  s, M. Vejmelka, and [7] W.-C. Hong, P.-F. Pai, S.-L. Yang, and R. Theng. [8] A. Kaiesr and T. Schreiber. Information transfer in [9] M. Lungarella, K. Ishiguro, Y. Kuniyoshi, and [10] T. Schreiber. Measuring information transfer. Physical [11] J. H. Stock and M. W. Watson. New indexes of [12] J.Yu,V.A.Smith,P.P.Wang,A.J.Harteminkd,
