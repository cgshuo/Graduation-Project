
Peng Wang 1 , 2 , 3 , Peng Zhang 3 , Yanan Cao 3 ,LiGuo 3 , and Bingxing Fang 4 Data stream classification is an important tool for real-time applications. For example, data stream classification is popularly used in real-time intrusion de-tection, spam filtering, and malicious website monitoring. Compared to data mining models, data stream classification models face extra challenges from the unbounded stream data and the continuously evolving concept (joint probability distribution)[21,18] underneath stream data.

In data stream scenarios, the classification ability of a stream classification model generally decreases w ith time because of the concept evolving reality[1]. For example, in data strea ms, a classification model c N built at time stamp N may classify its synchronous data chunk D N accurately, but its accuracy on in-coming data chunk D N +1 may deteriorate significant ly. This is because that data distributions in D N +1 may be significantly different from the training samples collected at time stamp N (in this paper, samples, records, and instances are interchangeable terms). As a result, in data stream classification, it is important to build the classifier which fits the concept of current data.

Unfortunately, existing data stream classification models, including the incre-mental models[5,8] and ensemble models[12], are based on the assumption that same data is first used for training then for testing. However, in real-world ap-plications, we have to classify the incoming data first and the labeled samples of the incoming data for training tend to lag behind (for example, for fraud be-havior classification in bank, typically it will take days or weeks to find whether the user was actually a fraud or not.). As a result, the classifier does not tempo-rally consistent with test data, as illustrated in Fig.1. This type of approaches regard concepts of data stream as sequence of recurring events, so they can only model the recurring probability of old concepts/classifiers, but cannot fore-cast a new classifier not showing up before. In this paper, we refer to this type of classification models as retrospective prediction , i.e., uses models directly trained from past stream data to classify incoming data. To synchronize the classification model and test data o ndatastreams,wepresentanovel forward classification method. Forward classification uses past classifiers to predict an incoming classifier, which is further us ed to classify incoming test data. Com-pared to the retrospective classification, the classifier used to classify incoming test data is not directly trained from historical stream records.

The main challenge of forward classification is to accurately predict the incom-ing classifier based on the past classifiers, which demands to model the evolution trend underneath the classifiers built from historical stream data. In this paper, we assume that concept evolution is a Markov process, i.e., the current con-cept of data stream is probabilistically determined by its previous state. This assumption is commonly used in data str eam research [17]. Then, based on the observation that the classification boundaries of all the past classifiers can be represented as continuous vectors, we propose to use Linear Dynamic System (LDS)[3,11] as the solution. In this way, tracking the evolving concept is tan-tamount to learning the LDS model based on all the past observed classifiers (continuous vectors), and predicting the incoming classifier is equivalent to in-ferring the next state of the system.
 Forward classification does not always outperform retrospective classification. As a model X  X  performance is closely related to its version space [6,15], we design a flexible learning framework, which can adaptively switch between the forward classification and the retrospective classification, which is based on ensemble learning. In doing so, our learning framework is robust under different concept drifting patterns. We also demonstrate the effectiveness of the proposed method by experiments on both synthetic and real-world data streams.

The remainder of the paper is structured as follows: Section 2 introduces the modeling of the forward classification using Linear Dynamic System (LDS). Section 3 conducts the experiments. Section 4 surveys related work. We conclude the paper in Section 5. In this section, we first describe concept evolution with a graphical model. Then, we discuss how to use Linear Dynamic System (LDS) as the solution. Finally, a forward classification framework is proposed. Consider a data stream S consist-ing of infinite number of records ( x,y ), where x  X  R d is the feature vector and y is the class label. Assume the records arrive chunk-by-chunk. The records arrive at time stamp n are denoted as data chunk D n . The classifier built on D n is denoted as c n . The concept at time stamp n is the joint probability distribution p ( x,y | n ). Fig. 2 is the graphical model describing the concept evolution under the Markov assumption. The solid gray circles stand for the classifiers. The hol-low circles represent the hidden concep ts. The graph can be decomposed into two processes: a evolution process p ( x,y | n  X  1)  X  X  X  p ( x,y | n ) that describes the concept evolution between two neighbo ring concepts, and a modeling process p ( x,y | n )  X  X  X  c n that describes the classifier training from the labeled training data. Noise is also involved in modeling process because the training set usually is a small biased data set sampled from the hidden concept. Based on graph model forward classification is formally defined as: Forward classification: Given W historical classifiers C = { c N  X  W +1 ,  X  X  X  ,c N } which are built consecutively from data stream S , the forward classification aims to predict the incoming classifier c N +1 :
Here, c N +1 is the correct incoming classifier but cannot be known before hand while c N +1 is our prediction. To solve the prediction problem, we use Linear Dynamic System(LDS) as the solution. In a deterministic LDS, a set of linear equations, governs the system evolution. Generally, the evolution of hidden concept is a stochastic process instead of a deterministic one. Thus, we add a random variable (denoted as w ) to model the randomness as shown in Eq. (2).
To model the concept drifting in data s tream with LDS, we assume the classi-fier model c n can be converted to a vector of fixed length, such as linear classifier model y =  X x + b can be represented by the vector [  X ,b ]. And we assume the concept p ( x,y ) can be represented by a vector z . So the concept drifting process equates to the evolving of z . Moreover, to model the probabilistic dependence of follow Gaussian distributions: where A represents the transform matrix that governs how the concept evolves, A  X  z incurred by the irregular concept evolution. B represents the transform matrix that governs how the latent concept maps to the classifier,  X  is the Gaussian noise incurred by the biased sampled training data. Eqs. (3) and (4) can be described as noisy linear equations: and u  X  X  ( u | 0 ,V 0 ) are the Gaussian noises.

We have described classifier prediction problem with LDS, then we will show how to learn the model and the resulting forward classification framework. 2.1 Model Learning The learning problem [10,13] is to find the optimal parameter  X  that maximizes the likelihood function of the observations C = { c N  X  W +1 ,  X  X  X  ,c N } , as in Eq. (8), Z , as in Eqs. (9) and (10). Eq. (10) is comprised of three parts. The first part is the probability of the initial state, the second part is probability of the concept evolution, and the last part is the probability of mapping the latent variables to classifiers. All the three parts are under the Gaussian distribution assumption.

Because p ( C |  X  )= timal solution is hardly achievable. Th erefore, we use the Expectation Max-imization (EM) algorithm to maximize log p ( C |  X  ). The EM algorithm starts with well-selected initial values for the parameters  X  old . Then, in the E -step, we use  X  old to find the posterior distribution of the latent variables p ( Z | C, X  old ). We then take the expectation of the log likelihood w.r.t the posterior dis-tribution p ( Z | C, X  old ). In the M -step, we aim to find  X  new that maximizes cuted until Q (  X , X  old ) converges. The details for the E-step and M-step of EM algorithm for learning LDS can be found in [3]. The basic process is summa-rized in Algorithm 1. The future classifier c N +1 can be predicted based on the parameters  X  and estimated current hidden state z N learned above: Algorithm 1. Learning LDS 2.2 Method Comparison and Selection In this part, we try to answer the following questions: does the forward classi-fication always outperform retrospective classification (e.g., ensemble method)? If the answer is NO, then how to select proper methods for real-world data streams? Here we denote the predicted cl assifier in forward classification as c f , and we use ensemble method as a typical example of retrospective method. As a classifier can be mapped to a point in hyperspace, the ensemble classifier c e will lie at the center of the most recently W classifiers, i.e. c e =(1 /W ) W i =1 c i .
Intuitively, if a data stream evolves continuously with stable patterns, i.e., the transform matrix A is time-invariant, the classifier is predictable; otherwise, the predicted classifier will overfit to the fake pattern. Except the irregular evolving pattern, the random noise will also make it difficult to learn the correct evolving pattern. So forward classification will not dominate retrospective method on all data streams. What X  X  worse, there is no analytic solution for LDS, so c f cannot be directly compared to c e . It raise the problem how to adaptively select between these methods in real-world data stream?
We solve the problem from the view of version space . Version space, in concept learning or induction, refers to a subset of all hypotheses that are consistent with the observed training examples. For data stream, all possible classifiers form the version space. As concept drifts continuously, for an incoming data chunk at time N + 1, the classifier c N +1 may have many possibilities, namely the version space of c N +1 can be large. According to Tong X  X  theory in [16], the larger version space is, the less accurate the classifier tends to be. We illustrate different version space on different concept evolving scen arios in Fig. 3. We can notice that, for data stream with clear evolving patterns, the version space of c f is smaller than c ; while for data stream without clear evolving pattern, the version space of c f is bigger than c e .

Based on the Gaussian noise assumption, c f obeys Gaussian distribution, i.e. c as the version space, which is determined by  X  f . According the analysis in [3], we have c f = c N +1 = N ( BAz N ,BP N B T +  X  ), where P N = AV N A T +  X  .So  X  f = BP N B T +  X  . On the other hand, the covariance of c e , denoted as  X  e ,is  X  e =(1 /W ) can be calculated by  X  =  X  i ,where  X  i is the eigenvector of  X  . By comparing the version space of c f and c e , we can adaptively decide which method to adopt for the data stream on hand. 2.3 The Learning Framework In this part, we introduce the classification framework which combines retro-spective and forward classification. In data streams, it is often very hard to im-mediately obtain labeled records for model updating. In contrast, the proposed framework can avoid such a shortcoming, by tracing the trend of concept drift-ing and forecasting the model that reflect s the current concept, then select the proper classifier based on criteria of version space. Learning from data streams contains both training and testing processes. Our framework mainly focuses on the training process. The framework is summarized in Algorithm 2.
 Algorithm 2. Learning Framework Efficiency Analysis. The time cost of the proposed framework comes from two parts: training base classifiers, and predicting a future classifier. For simplicity, we take the cost of the first part as a constant value O (1). The second part contains two sub-parts: an EM learning process and a prediction process. The E-step, which using the forward and backward recursions, has O ( Wd z d c )timecost, where W is the size of the historical classifier set, and d z is the dimension of latent concept while d c the classifier. The M-step directly updates the parameters, with time complexity of O ( W ). Since we set the max number of iterations for EM as I , the time complexity of EM learning process is O ( WId z d c ). In addition, from Eq.(11), the time complexity of predicting a future classifier is O (1). To sum up, the total time complexity for a loop in the learning framework is O ( WId z d c ). In this section, we first introduce the benchmark methods, followed by the test-bed. The test results on both synthetic and real-world data sets and the analysis will be given in the end.

We compare our method with four state-of-the-art classification method on data stream: ensemble learning[2,19], in cremental learning[ 14], drift detection method(DDM)[7] and random walk model[9]. All of them fall into the category of retrospective learning. 3.1 Data Stream Test-Bed In our experiment, we adopt both synthetic data stream generator and real world data streams as our test-bed.
 Evolving Gaussian Generator. As we have described in the previous sections, the concept of data stream is a joint distribution p ( x,y ). So we can generate a evolving data stream by generating records according to certain distribution and changes the distribution as time passes. For simplicity, we assume a binary clas-sification problem, where the positive and negtive records are generated accord-ing to the Gaussian distribution. To simulate the concept evolving, we gradually change mean of the distribution as time passes. Particularly, we generate data stream with 6 types of concept drifting: stay still , shift , hybrid , spin , random walk and periodic variation .
 Rotating Hyperplane is used as a test bed for CVFDT[8] models. A hyper-plane in a d -dimensional space is a set of points x that satisfies d i =1 w i x i = w 0 , where x i is the i th dimension of the vector x . Records satisfying d i =1 w i x i  X  w 0 are labeled as positive. Otherwise, negat ive. To simulate concept evolution, we let each weight attribute w i = w i + d X  change with time, where  X  denotes the probability that the direction of change is reversed and d denotes that the change degree.
 Sensor Stream. Sensor stream[20] contains information (temperature, humid-ity, light, and sensor voltage) collected from 54 sensors deployed in Intel Berkeley Research Lab. The learning task is to co rrectly identify the sensor ID based on the sensor data. This dataset can be downloaded from website 1 .
 Power Supply. Power Supply stream [20] contains hourly power supply of an Italian electricity compan y. The learning task is to classify the time the current power supply belongs to. This dataset can be downloaded from website 2 . 3.2 Results In Fig.4 we report the algorithm performance w.r.t. different types of concept drifting scenarios. From Fig.4(a), we can observe that our model is as good as the classic methods if there is no concept drifting in the stream data. Fig.4(b) indicates that for concept shifting data stream, our method outperforms oth-ers. This is because when concept drifting follows stable pattern, our method can track the pattern of the changes and more accurately predict future classi-fiers. In Fig.4(c), the drifting pattern is unstable. For example, before t = 10, the concept stays still, classifiers { c 1 ,  X  X  X  ,c 10 } are determined by the parameter  X  error rate of LDS arises, as the classifier predicted with  X  still for the future con-cept. As the drifting records increase, the LDS model can gradually tracking the concept evolution. So the error rate gra dually decreases. In Fig.4(d), the con-cept X  X  evolving rate is fast. We can observe that LDS significantly outperforms other methods for the fast evolving data stream. In Fig.4(e), the concept of data stream evolves in a random walk manner. We can see that LDS can handle the noise factor well for it can switch to r etrospective method when the evolving pattern is blurred. Random walk model also perform well and it can filter out the random noise of { c 1 ,  X  X  X  ,c N } , and track the proper concept, as in this model, A  X  I so it will not learn false drifting patterns. In Fig.4(f), the evolving pat-tern of the data stream is changing periodically. the LDS model is robust to this kind of concept drifting. In summary, our learning framework outperforms other benchmark methods for data streams with regular evolving patterns.

In Table 1, we summarize and compare the performance of different methods on all data streams. Overall, for data streams having regular evolving patterns, the performance of the proposed LDS model outperforms other benchmark meth-ods. For data streams whose evolving is not a stable Markov process, learning methods such as drift detection and random walk perform better.
 Efficiency. From our experiments, we observe that the EM algorithm converges within 100 iterations, so M is manually set to 100. In most cases, when W&gt; 50, the predicted classifier is stable, so W is manually set to 50. With these settings, on our PC with 2.8G Hz CPU, the time cost for predicting the classifier is less than 1 minute. In real-world applications, it usually takes hours for the concept having detectable change, so the framework is efficient. Existing data stream classification models can be categorized into three groups: online / incremental models[8,14], ensemble learning[12,18,19] and drift detec-tion methods [7]. We briefly describe them based on the development trace. In the simplest situation, where the concept of data stream remains stable, for each time window, the classifier has prediction variance due to limited training samples. We can use majority voting method to ensemble these classifiers, be-cause random variance tends to compensate each other. This is the fundamental framework for retrospective classification. For data stream with concept drifting, the majority voting for ensemble is inappropriate. An alternative solution is to use weighted ensemble, where each classi fier is weighted according to their con-sistence with the most recent observed t raining data. For incremental or DDM method, they keep updating the classifier using newly arriving records, enabling the learning model to adapt to new concep ts. For retrospective learning models [17,4], they regard concepts of data stream as a sequence of recurring events and use the most probable concept in the future to classify incoming stream data. Unfortunately, existing weighing and updating approaches, including the proactive learning framework, cannot for ecast a completely new classifier. Thus, they cannot synchronize the classifier to the evolving stream data.

Forward classifier prediction method, on the other hand, uses probabilistic model to define time evolution of the concept. By using the probabilistic model, we can approximate the distribution that maximizes the posterior probability of the model [3]. Moreover, we can predict the optimal incoming classifier by adopt-ing the inference method. That is to say, forward classifier prediction method is able to derive better classification results. In this paper, we present a novel forward classification method for classifying evolving stream data. Due to the temporal evolving of data streams, simply learning classification models from historical data, as existing retrospective clas-sification methods do, is inadequate and inaccurate. So a proper classification design is to capture the evolution trend underneath stream data and use it to predict a future classifier for classification. With this vision and the assumption that the concept evolving can be characterized by Markov process, we propose to model the trend of classifiers using the Linear Dynamic System , through which we can model the concept drifting and pred ict incoming classifier. We also notice that forward classification is not overwhelmingly better than retrospective clas-sification. Then we design the learning framework, which adaptively switches between the forward classification bas ed on LDS and basic ensemble learning method,soitisrobusttodifferenttypesofdatastreams.Experimentsonsyn-thetic and real-world streams demonstrate that our framework outperforms other methods in different types of concept drifting scenarios.
 Acknowledgments. This work was supported by the NSFC (No. 61003167), IIE Chinese Academy of Sciences (No. Y3Z0062101),863 projects (No. 2011AA010703 and 2012AA012502), 973 project (No. 2013CB329606), and the Strategic Leading Science and Technology Projects of Chinese Academy of Sciences (No. XDA06030200).

