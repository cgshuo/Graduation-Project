 Dae Il Kim daeil@cs.brown.edu Michael C. Hughes mhughes@cs.brown.edu Erik B. Sudderth sudderth@cs.brown.edu A recent explosion in the magnitude and complexity of relational datasets motivates algorithms that can dis-cover meaningful latent structure within complex, ob-served networks. Blocks of nodes with similar behavior are called communities , and could represent predators with common prey, proteins that regulate similar func-tions, or individuals with common interests.
 Wang &amp; Wong (1987) proposed the latent stochastic blockmodel (LSB) as a generalization of mixture mod-els to relational datasets, in which each node is as-signed to one of some finite set of communities. The infinite relational model (IRM) (Kemp et al., 2006) used a Chinese restaurant process (CRP) prior on par-titions to group nodes into an unbounded set of com-munities, but still allocates each node to a single com-munity. Airoldi et al. (2008) instead propose a mixed membership stochastic block (MMSB) model, where each node has a distribution over a finite set of latent communities, and chooses potentially distinct commu-nities to generate each observed relationship. Para-metric model selection methods are needed to choose the number of latent MMSB blocks. The hierarchical Dirichlet process (Teh et al., 2006) provides one ap-proach to nonparametric mixed membership modeling, but it has not yet been applied to relational data. Miller et al. (2009) describe a nonparametric latent feature model (NLFM), which uses an Indian buffet process (IBP, (Griffiths &amp; Ghahramani, 2005)) prior to associate each node with a subset of an unbounded collection of latent features. Each instantiated fea-ture then contributes to a generalized linear model of relationship probabilities. Nodal metadata can be in-corporated into their edge likelihood model, but does not directly influence the generation of latent features. While the NLFM leads to useful link prediction al-gorithms, experiments suggested that the recovered features were difficult to interpret and provided lit-tle qualitative understanding of real networks. Choi et al. (2011) similarly incorporate metadata into their edge likelihoods, but within the context of a paramet-ric LSB. Their focus is on estimating appropriate con-fidence sets for the inferred latent structure. Some stochastic block models have modeled hierarchi-cal structure within the latent communities, includ-ing the Mondrian process (Roy &amp; Teh, 2009) and the multiscale community block model (MCSB, Ho et al. (2011a)). The MCSB uses a nested CRP prior (Blei et al., 2010) to associate each node with a finite-depth chain of communities, organized in a tree of potentially unbounded degree. Other block models are designed for dynamic network data (Ho et al., 2011b; Ishiguro et al., 2010; Fu et al., 2009), but our focus here is on static networks.
 The nonparametric metadata dependent relational (NMDR) model proposed in this paper extends prior stochastic blockmodels in two key ways: each node has mixed membership in an unbounded set of communi-ties, and node-specific metadata directly influences the generation of these latent community distributions. In contrast to the simpler likelihood-based way the NLFM uses metadata, our approach leads to intuitive, interpretable communities which also provide accurate link predictions. The NMDR incorporates metadata via a logistic stick-breaking process (Ren et al., 2011), analogously to the doubly correlated nonparametric topic (DCNT) model (Kim &amp; Sudderth, 2011). Un-like the DCNT, which employed a finite truncation for approximate MCMC inference, we use retrospective MCMC methods (Papaspiliopoulos &amp; Roberts, 2008) to develop MCMC learning algorithms for the true, infinite NMDR model. We also develop a likelihood model appropriate for multi-relational networks. Our experiments show recovery of qualitatively interesting structure, and quantitatively accurate link prediction, for social and ecological networks. The NMDR is a Bayesian nonparametric hierarchical extension of the MMSB. We provide an overview of the model focusing on our two major innovations,  X  X p-stream X  incorporation of metadata (Mimno &amp; McCal-lum, 2008) and a stick-breaking representation of the infinite mixed-membership vector. 2.1. Node Metadata For N nodes, we let  X  : i  X  R F denote a feature vector 1 that captures the metadata associated with node i , and  X   X  R F  X  N a matrix of corpus metadata. When no metadata is available, we set  X  : i = 1 to allow learning of the mean frequency of each community.
 For every community k in our unbounded set, we let  X  fk  X  R denote an associated significance weight for feature f in community k , and  X  : k  X  R F a vector of these weights. A Gaussian prior  X  : k  X  N (  X ,  X   X  1 ) reg-ularizes the topic weights, where  X   X  R F is a vector of mean feature responses, and  X  =  X  F I is a diagonal precision matrix. As in standard hierarchical Bayesian regression models (Gelman et al., 2004), we assign con-jugate priors  X  f  X  N (0 , X   X  1 S ),  X  F  X  Gam( a F ,b F ), and  X  S  X  Gam( a S ,b S ).
 Given  X  and  X  , the node-specific score for commu-abusing notation, we can compactly write this trans-formation as v : i  X  N (  X  T  X  : i ,L  X  1 ), where v : i is the in-finite sequence of scores for node i and L =  X  V I is an  X  X nfinite X  diagonal precision matrix. Note that the distribution of v ki depends only on the first k entries of  X  T  X  : i , not the infinite tail of scores for subsequent topics; this makes our retrospective MCMC sampler tractable. The node-specific community scores, which may be any real numbers, are next converted to valid mixed-membership probability distributions. 2.2. A Logistic Stick-Breaking Transformation To allow tractable learning of an unbounded set of communities, we employ a stick-breaking repre-sentation of the community distributions. Stick-breaking constructions are widely used in applications of Bayesian nonparametric models, and lead to conve-nient sampling algorithms (Ishwaran &amp; James, 2001). Let  X  ki denote the probability that node i chooses community k , where P  X  k =1  X  ki = 1. The NMDR con-structs these probabilities as follows: Here, 0 &lt;  X  ( v ki ) &lt; 1 is the classic logistic function, which satisfies  X  (  X  v `i ) = 1  X   X  ( v `i ). This same trans-formation is part of the so-called logistic stick-breaking process (Ren et al., 2011). However, they employ a very different prior distribution for v ki and are mo-tivated by different applications. Our usage of this logistic stick-breaking transformation is inspired by the prior on topic distributions underlying the DCNT model (Kim &amp; Sudderth, 2011). 2.3. Generating Relational Edges The generative process described here applies to multi-relational, directed binary graphs. Generalizations to undirected graphs, or non-binary relations, can be accommodated by slight modifications. Given the mixed-membership distributions for nodes i and j ,  X  : i and  X  : j , we sample a pair of community indicator vari-ables for each directed interaction y ijm . For relation m , source indicator s ijm  X  Mult(  X  : i ) and receiver in-dicator r ijm  X  Mult(  X  : j ). See Fig. 2.
 Once the source and receiver communities have been chosen, binary edge y ijm is chosen from a correspond-ing Bernoulli distribution, y ijm  X  Ber( s T ijm W :: m r For each of the M types of relations, we place a con-jugate beta prior on the entries of the infinite block relation matrix W :: m , so that W k`m  X  Beta(  X  a , X  b ) for some fixed hyperparameters  X  a , X  b .
 Because the number of latent communities is un-bounded, there are infinitely many relationship prob-abilities W k`m , M for each community pair. Dur-ing learning, our inference algorithm marginalizes the entries of W . Resampling of community indica-tors ( s ijm ,r ijm ), given fixed scores v : i ,v : j tractable. Our retrospective MCMC algorithm would remain simple for other likelihood functions with con-jugate priors, for example Poisson for count relations, or Gaussian for real-valued relations.
 In summary, the NMDR generative model is as follows: 1. Sample global parameters: 2. For each node i = 1 , 2 ,...,N : 3. For each relation m = 1 , 2 ,...,M : In applying the NMDR model to real-world networks, we observe some edges y linking a set of nodes and wish to recover the block community structure, param-eterized by  X ,v,s,r,W . In general, potential relations may be observed to be present ( y ijm = 1), observed to be absent ( y ijm = 0), or be unobserved and unknown ( y ijm =?). Assuming unobserved relations are miss-ing at random, as in our experiments, we assign those links uninformative likelihoods during learning. Given observed relationships for some or all node pairs, we employ a Markov chain Monte Carlo (MCMC) method to draw samples from the hidden variables X  posterior distribution. As a primary contribution, our MCMC algorithm performs retrospective moves which allow us to dynamically vary the number of instanti-ated latent communities. 3.1. Retrospective MCMC Bayesian nonparametric models based on unconven-tional stick-breaking priors often use a finite, trun-cated approximation to the true infinite model. While this approach can be effective (Ishwaran &amp; James, 2001), selection of an appropriate truncation level K is challenging. When K is conservatively large, substan-tial computational resources can be expended resam-pling  X  X asted X  variables, and model interpretability often suffers. When K is small, learning and inference are potentially biased, and the benefits which origi-nally motivated the nonparametric approach are lost. To avoid these issues, we implement a dynamic trun-cation technique based on retrospective sampling (Pa-paspiliopoulos &amp; Roberts, 2008) of latent community assignments s and r .
 Consider the resampling of a source indicator s ijm , for relation m from node i to node j , given fixed values of all other indicators and variables. A similar approach can be used for resampling r ijm , or for blocked resam-pling of { s ijm ,r ijm } . Because we employ a conjugate beta prior, our sampler analytically marginalizes the relation parameters W k`m , expressing the posterior in terms of various edge counts. Suppose that r ijm = ` . Excluding node pair ( i,j ), let A \ ij k`m denote the number of directed edges, for relation m , from nodes whose in-dicators associate that pairing to communities ( k,` ). Similarly, let B \ ij k`m denote the number of such node pairs which do not exhibit relation m .
 Let K denote the index of the largest community, in stick-breaking order, which currently has at least one assigned node. The retrospective sampler explicitly instantiates v k : and  X  : k for k  X  K . Computing  X  ki based on these variables, as in Eq. (1), we let  X  for k = 1 ,...,K , and The proportionality constant in Eqs. (3, 4) is selected so that  X  is a properly normalized ( K + 1)-dimensional multinomial distribution. For k  X  K ,  X  k is the poste-rior probability of selecting community k .  X  K +1 is the aggregate posterior probability of the infinite  X  X ail X  of communities with indexes greater than K .
 Algorithm 1 begins by sampling from Mult(  X  ) to de-termine whether s ijm should be assigned to one of the already instantiated communities, or some new community. If the sampled s ijm  X  K , as is com-mon after the first few sampling iterations, we sim-ply choose that community. If not, we select a new community by simulating the logistic stick-breaking prior, since all potential new communities have indis-tinguishable marginal likelihoods. Such dynamic cre-ation of variables is the key to retrospective samplers. Because our likelihood parameters W k`m have conju-gate beta priors, we can exactly compute the poste-rior normalization constant, and the more complex Metropolis-Hastings proposals of Papaspiliopoulos &amp; Roberts (2008) are unnecessary. A related approach has been used for inference in infinite depth nested CRP models (Blei et al., 2010).
 Algorithm 1 Retrospective MCMC resampling of source community s ijm , given a ( K +1)-dim. posterior distribution  X  defined as in Eqs. (3, 4). 1: Draw s ijm  X  Mult(  X  ) 2: if s ijm = K + 1 then 5: Draw  X   X  Ber(  X  ( v s ijm i )) 6: if  X  = 1 then 7: Exit and keep all instantiated variables 8: else 9: Increment s ijm  X  s ijm + 1 10: Goto line 3 11: end if 12: end if 3.2. Conventional MCMC Given s and r , all but a finite subset of the variables in the infinite NMDR model are conditionally inde-pendent of the observed data. For most of these vari-ables, our selection of conjugate priors allows closed form Gibbs sampling updates. For the node-specific community activation variables v : i , which have a non-conjugate likelihood due to the logistic stick-breaking transformation, we instead use a Metropolis-Hastings independence sampler. As in (Kim &amp; Sudderth, 2011), we find that repeated proposals from the prior are suf-ficient for adequate mixing. Please see the supplemen-tal material for detailed resampling equations and the per-iteration cost of NMDR inference. We examine the NMDR X  X  performance on two toy datasets as well as three real-world networks. To measure quantitative performance, we consider link prediction tasks and compare with publicly avail-able implementations of MCMC algorithms for the MMSB (Chang, 2011) and IRM (Kemp et al., 2006). We evaluate via the area under the ROC curve (AUC). For unobserved edges, link probabilities are predicted from posterior samples via a straightforward Bayesian approach, detailed in the supplement. We also qualita-tively examine learned communities, and find that the NMDR model captures a nuanced and useful mixed membership community structure. 4.1. Synthetic Data We analyze two toy datasets, each with 80 nodes, gen-erated by variants of stochastic block models. The first, SynthSingle , is a network where each node is assigned to exactly one of 5 blocks. Blocks have high within-block link probability and low between-block link probability, as shown in Fig. 3. Alternatively, the noisier SynthMixed network exhibits significant mixed membership among 4 blocks (see Fig. 3).
 For each dataset, we simulate the edge removal pro-cess ten times, marking node pairs as unobserved at random with probability 0.5. We train NMDR, IRM, and MMSB models on the remaining edges. We run 3 MCMC chains for each model (6 for NMDR) for 6000 iterations, and use the best chain (in joint log prob-ability) for prediction. We train two MMSB model variants, one with the true number of blocks, and one with K = 20. To evaluate, we report the spread in AUC scores across all 10 random masks in Fig. 3. While the simple SynthSingle data matches the IRM X  X  generative assumptions, the more flexible NMDR model nevertheless performs comparably to other methods. NMDR recovers the true block struc-ture and has near-optimal prediction performance. On SynthMixed data, we find that the NMDR model again has the highest performance (AUC  X  0 . 75), comparable to an MMSB based on the true number of blocks. The NMDR recovers an expected adjacency matrix E [ Y ] in close agreement with the true data, while the IRM suffers from not allowing mixed mem-berships. Given only a coarse upper bound on the true number of communities, MMSB performance also drops (AUC  X  0 . 70). This illustrates the benefits of our better regularized nonparametric model, and the ability of retrospective MCMC methods to automati-cally infer an appropriate set of communities, avoiding an expensive model selection process. 4.2. Sampson Monastery Sampson X  X  1968 investigation of a monastery provides a benchmark dataset for qualitative network analy-sis (Sampson, 1968). Over a 12 month period, he observed interactions between 18 novice monks and surveyed feelings about their peers. Eight relations were recorded: like, dislike, influence, non-influence, esteem, disesteem, praise, and sanctions.
 Sampson described two competing ideological factions. The  X  X oung Turks X , led by Gregory and John Bosco, consisted mostly of a new wave of brothers arriving during month 5 who questioned monastery practices. The  X  X oyal Opposition X  faction, led by Peter, were mostly present from month 1 and favored the status quo. Sampson also noted an  X  X utcast X  group, who were socially rejected by their peers, and  X  X ntersti-tials, X  who oscillated between the dominant groups. We take Sampson X  X  factions as a basis for judging the validity of our model X  X  recovered block structure. Our analysis differs in key aspects from the MMSB analysis in (Airoldi et al., 2008). First, we use data from all 8 surveys, rather than a curated single-relation summary. Second, we incorporate metadata found in Sampson X  X  original thesis. This includes each monk X  X  arrival and departure time, each monk X  X  rank (1 of 4 categories), and binary judgments on sociability and maturity passed by monastery leaders.
 Fig. 4 shows recovered mixed membership structure for each monk, obtained after 10,000 iterations of MCMC inference. Two of these blocks contain individuals from the  X  X oung Turks X  faction, with one of the blocks serving as the primary affiliation for all basic members and another through which leaders (Gregory and John Bosco) act on occasion. Another two blocks corre-spond to the  X  X oyalist X  faction, with one community attracting all members and another assigned mostly to the hardened core of the group (e.g., Peter). Fi-nally, the model allocates all three outcasts to a fifth  X  X utcast X  block. An MDS visualization shows excel-lent correspondence with Sampson X  X  primary factions as well as one interstitial node (Amand).
 To better understand why the model differentiates be-tween leaders and followers, we visualize the learned W for two key relations (influence and sanctions) in Fig. 4. Gregory and John Bosco were influential to monks from all factions (including some Loyalists), and together the pair alone received &gt; 30% of all in-fluence links. The model uses the  X  X T Leader X  block to capture this difference. Among negative sanctions, Sampson X  X  raw data finds most reprimands directed at outcasts, with the rest occuring between competing factions. Both realities are reflected by our model. We find that the model learns intuitive relationships between block membership and the provided meta-data, particularly departure times and personality judgments. Consider a novice lay brother for whom we have no observed relations. Intuitively, varying his  X  X onthDeparted X  covariate should shift his affili-ation. Fig. 4 shows our model predictions: departure near Gregory X  X  expulsion implies  X  X oung Turk X  affili-ation, while remaining longer implies  X  X oyalist X  lean-ings. Similarly, observing personality problems implies  X  X utcast X  status, unless he remains past expulsion. 4.3. Otago Harbour Food Web The Otago Harbour dataset (Mouritsen et al., 2011) contains a single  X  X ho-eats-whom X  binary relationship for 123 organisms from an intertidal mudflat ecosys-tem in New Zealand. In addition to predation links, the dataset contains metadata that broadly classifies each node as one of 21 possible organism types (e.g., annelids, birds), and assigns one of three mobility rat-ings (low, intermediate, high). A variety of organisms populate this food web including secondary predators (ducks, fish), primary predators (rock crabs), and au-totrophs (seagrass). We explore whether unsupervised learning from metadata can contribute to knowledge discovery in complex, real-world networks.
 We train an NMDR model on the entire graph, in-cluding metadata, and use our learned parameters to generate a food web relating organism archetypes. A node now represents a combination of organism and mobility types (e.g., high mobility bird, low mobil-ity snail). As detailed in the supplementary material, edges represent a thresholded probability that organ-isms of these archetypes prey on one another.
 By relating metadata archetypes, the graphs of Fig. 5 abstract the directly observed relationships among individual species. It could help scientists under-stand the canonical predator-prey relationships in this ecosystem. The top two prey choices often reflect meaningful biological relationships. For example, con-sider the self-loop for the high-mobility crab archetype. Carefully examining the raw data, every crab species cannibalistically preys on other crabs, including their own species. Furthermore, as expected the likelihood of being consumed by smaller organisms was near zero for top predators like birds and stingrays. 4.4. Lazega Lawyers Network The Lazega lawyers dataset (Lazega, 2006) is a so-cial network between partners and associates of sev-eral New England law firms. Collected from 1988-1991, it contains three directed binary relations encod-ing friendship, coworker, and advisory relationships among 71 lawyers. The dataset contains a rich set of metadata describing status, gender, office location, years employed, age, practice, and law school. We focus on the quantitative task of link prediction, and compare our NMDR model (with and without metadata) to the IRM and MMSB. 2 Results are shown in Fig. 6. Even without metadata, the NMDR model performs much better than the IRM, demonstrating the importance of mixed memberships in modeling the complex relationships of real social networks. Com-pared to the MMSB, the NMDR without metadata performs similarly or slightly better. The small im-provements might be attributed to the NMDR X  X  ability to learn the number of communities dynamically via retrospective MCMC. Including metadata, the NMDR significantly outperform both the MMSB and IRM, showing the importance of incorporating relevant side information when it is available.
 Finally, we show the benefit of using learned com-munity memberships for visualization. Plotting the raw relationship graph, using the GraphViz (Ellson et al., 2001) force-atlas layout algorithm with equally weighted edges, results in a complex and noisy rep-resentation of the data (Fig. 6(a)). Instead, we can use the variational distance D ij = 1 2 P K k =1 |  X  ki  X   X  between learned community membership distributions to measure node similarity in a more refined way. We assign node affinity weights of 1  X  D ij , threshold these weights at 1 2 to produce a sparse graph, and again ap-ply the GraphViz force-atlas layout. This produces the far more intuitive and informative graph of Fig. 6(b). The NMDR model allows both discrete and continu-ous metadata to inform the community memberships of individual nodes. Retrospective MCMC methods al-low data-driven determination of the number of latent communities, while avoiding expensive and potentially inaccurate truncations during learning. Our experi-ments suggest that the NMDR leads to competitive link prediction algorithms, which can further enhance accuracy by modeling metadata or multiple relations. The intuitive community structures recovered from real-world datasets are especially of interest, given in-terpretability problems reported with some prior non-parametric relational models.
