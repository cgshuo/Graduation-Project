
Sentiment Analysis (also known as opinion min-ing), which aims to extract the sentiment informa-tion from text, has attracted extensive attention in recent years. Sentiment classification, the task of determiningthesentimentorientation(positive,neg-ative or neutral) of text, has been the most exten-sively studied task in sentiment analysis. There is already a large amount of work on sentiment classi-fication of text in various genres and in many lan-guages. For example, Pang et al. (2002) focus on sentimentclassificationofmoviereviewsinEnglish, and Zagibalov and Carroll (2008) study the problem of classifying product reviews in Chinese. During the past few years, NTCIR 1 organized several pi-lot tasks for sentiment classification of news articles written in English, Chinese and Japanese (Seki et al., 2007; Seki et al., 2008).

ForEnglishsentimentclassification,therearesev-eral labeled corpora available (Hu and Liu, 2004; Pang et al., 2002; Wiebe et al., 2005). However, la-beled resources in other languages are often insuf-ficient or even unavailable. Therefore, it is desir-abletousetheEnglishlabeleddatatoimprovesenti-mentclassificationofdocumentsinotherlanguages. One direct approach to leveraging the labeled data in English is to use machine translation engines as a black box to translate the labeled data from English to the target language (e.g. Chinese), and then us-ingthetranslatedtrainingdatadirectlyforthedevel-opment of the sentiment classifier in the target lan-guage (Wan, 2009; Pan et al., 2011).

Although the machine-translation-based methods are intuitive, they have certain limitations. First, the vocabulary covered by the translated labeled data is limited, hence many sentiment indicative words can not be learned from the translated labeled data. Duh et al. (2011) report low overlapping between vocabulary of natural English documents and the vocabulary of documents translated to En-glish from Japanese, and the experiments of Duh et al. (2011) show that vocabulary coverage has a strong correlation with sentiment classification ac-curacy. Second,machinetranslationmaychangethe sentiment polarity of the original text. For exam-ple, the negative English sentence  X  X t is too good to be true X  is translated to a positive sentence in Chi-nese  X   X  X  X  X  X  X  X  X  X  X  X   X  by Google Translate (http://translate.google.com/), which literally means  X  X t is good and true X .

In this paper we propose a cross-lingual mixture model( CLMM )forcross-lingualsentimentclassifi-cation. Instead of relying on the unreliable machine translated labeled data, CLMM leverages bilingual parallel data to bridge the language gap between the source language and the target language. CLMM is a generative model that treats the source language and target language words in parallel data as gener-ated simultaneously by a set of mixture components. By  X  X ynchronizing X  the generation of words in the source language and the target language in a parallel corpus,theproposedmodelcan(1)improvevocabu-lary coverage by learning sentiment words from the unlabeled parallel corpus; (2) transfer polarity label information between the source language and target language using a parallel corpus. Besides, CLMM can improve the accuracy of cross-lingual sentiment classification consistently regardless of whether la-beled data in the target language are present or not. We evaluate the model on sentiment classification of Chinese using English labeled data. The exper-iment results show that CLMM yields 71 % in accu-racy when no Chinese labeled data are used, which significantly improves Chinese sentiment classifica-tionandissuperiortotheSVMandco-trainingbased methods. When Chinese labeled data are employed, CLMMyields 83 %inaccuracy,whichisremarkably betterthantheSVMandachievestate-of-the-artper-formance.

This paper makes two contributions: (1) we pro-pose a model to effectively leverage large bilin-gual parallel data for improving vocabulary cover-age;and(2)theproposedmodelisapplicableinboth settings of cross-lingual sentiment classification, ir-respective of the availability of labeled data in the target language.

The paper is organized as follows. We review re-latedworkinSection2,andpresentthecross-lingual mixturemodelinSection3. Thenwepresenttheex-perimental studies in Section 4, and finally conclude the paper and outline the future plan in Section 5.
In this section, we present a brief review of the re-lated work on monolingual sentiment classification and cross-lingual sentiment classification. 2.1 Sentiment Classification Early work of sentiment classification focuses on English product reviews or movie reviews (Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). Since then, sentiment classification has been investigated in various domains and different languages (Zag-ibalov and Carroll, 2008; Seki et al., 2007; Seki et al., 2008; Davidov et al., 2010). There exist two main approaches to extracting sentiment orientation automatically. The Dictionary-based approach (Tur-ney, 2002; Taboada et al., 2011) aims to aggregate the sentiment orientation of a sentence (or docu-ment) from the sentiment orientations of words or phrases found in the sentence (or document), while the corpus-based approach (Pang et al., 2002) treats thesentimentorientationdetectionasaconventional classification task and focuses on building classifier from a set of sentences (or documents) labeled with sentiment orientations.

Dictionary-based methods involve in creating or using sentiment lexicons. Turney (2002) derives sentiment scores for phrases by measuring the mu-tual information between the given phrase and the words  X  X xcellent X  and  X  X oor X , and then uses the av-erage scores of the phrases in a document as the sentiment of the document. Corpus-based meth-ods are often built upon machine learning mod-els. Pang et al. (2002) compare the performance of three commonly used machine learning models (Naive Bayes, Maximum Entropy and SVM). Ga-mon (2004) shows that introducing deeper linguistic features into SVM can help to improve the perfor-mance. The interested readers are referred to (Pang and Lee, 2008) for a comprehensive review of senti-ment classification. 2.2 Cross-Lingual Sentiment Classification
Cross-lingualsentimentclassification,whichaims to conduct sentiment classification in the target lan-guage (e.g. Chinese) with labeled data in the source language (e.g. English), has been extensively stud-ied in the very recent years. The basic idea is to ex-plore the abundant labeled sentiment data in source language to alleviate the shortage of labeled data in the target language.

Most existing work relies on machine translation enginestodirectlyadaptlabeleddatafromthesource language to target language. Wan (2009) proposes to use ensemble method to train better Chinese sen-timent classification model on English labeled data and their Chinese translation. English Labeled data are first translated to Chinese, and then two SVM classifiersaretrainedonEnglishandChineselabeled data respectively. After that, co-training (Blum and Mitchell,1998)approachisadoptedtoleverageChi-nese unlabeled data and their English translation to improve the SVM classifier for Chinese sentiment classification. Thesameideaisusedin (Wan,2008), but the ensemble techniques used are various vot-ing methods and the individual classifiers used are dictionary-based classifiers.

Insteadofensemblemethods, Panetal.(2011)use matrix factorization formulation. They extend Non-negative Matrix Tri-Factorization model (Li et al., 2009)tobilingualviewsetting. Theirbilingualview is also constructed by using machine translation en-gines to translate original documents. Prettenhofer and Stein (2011) use machine translation engines in a different way. They generalize Structural Corre-spondence Learning (Blitzer et al., 2006) to multi-lingual setting. Instead of using machine translation engines to translate labeled text, the authors use it to constructthe word translation oracle for pivot words translation.
 proving the performance of sentiment classification on two languages (e.g. English and Chinese) . the authors use an unlabeled parallel corpus instead of machine translation engines. They assume paral-lel sentences in the corpus should have the same sentiment polarity. Besides, they assume labeled data in both language are available. They propose a method of training two classifiers based on maxi-mum entropy formulation to maximize their predic-tionagreementontheparallelcorpus. However, this method requires labeled data in both the source lan-guage and the target language, which are not always readily available.
In this section we present the cross-lingual mix-ture model ( CLMM ) for sentiment classification. Wefirstformalizethetaskofcross-lingualsentiment classification. Then we describe the CLMM model and present the parameter estimation algorithm for CLMM. 3.1 Cross-lingual Sentiment Classification
Formally,thetaskweareconcernedaboutistode-velopasentimentclassifierforthetargetlanguage T (e.g. Chinese), given labeled sentiment data D S in the source language S (e.g. English), unlabeled par-allel corpus U of the source language and the target language,and optional labeleddata D T intargetlan-guage T . Aligning with previous work (Wan, 2008; Wan, 2009), weonlyconsiderbinarysentimentclas-sificationscheme(positiveornegative)inthispaper, but the proposed method can be used in other classi-fication schemes with minor modifications. 3.2 The Cross-Lingual Mixture Model
The basic idea underlying CLMM is to enlarge thevocabularybylearningsentimentwordsfromthe parallel corpus. CLMM defines an intuitive genera-tion process as follows. Suppose we are going to generateapositiveornegativeChinesesentence, we have two ways of generating words. The first way is to directly generate a Chinese word according to the polarity of the sentence. The other way is to first generate an English word with the same polarity and meaning, and then translate it to a Chinese word. More formally, CLMM defines a generative mix-ture model for generating a parallel corpus. The un-observed polarities of the unlabeled parallel corpus are modeled as hidden variables, and the observed wordsinparallelcorpusaremodeledasgeneratedby a set of words generation distributions conditioned on the hidden variables. Given a parallel corpus, we fit CLMM model by maximizing the likelihood of generating this parallel corpus. By maximizing the likelihood, CLMM can estimate words generation probabilitiesforwordsunseeninthelabeleddatabut present in the parallel corpus, hence expand the vo-cabulary. In addition, CLMM can utilize words in both the source language and target language for de-termining polarity classes of the parallel sentences.
Figure 1 illustrates the detailed process of gener-ating words in the source language and target lan-guage respectively for the parallel corpus U , from the four mixture components in CLMM. Particu-larly, for each pair of parallel sentences u i  X  U , we generate the words as follows. 1. Document class generation: Generating the 2. Words generation: Generating the words 3. Words projection: Projecting the words onto
CLMM finds parameters by using MLE (Maxi-mum Likelihood Estimation). The parameters to be estimated include conditional probabilities of word to class, P ( w s | c ) and P ( w t | c ) , and word projection scribethelog-likelihoodfunctionandthenshowhow to estimate the parameters in subsection 3.3. The obtainedword-classconditionalprobability P ( w t | c ) can then be used to classify text in the target lan-guages using Bayes Theorem and the Naive Bayes independence assumption.

Formally, we have the following log-likelihood function for a parallel corpus U 2 .
 where  X  isthemodelparameters; N si ( N ti )istheoc-currencesoftheword w s ( w t )indocument d i ; | D s | is the number of documents; | C | is the number of class labels; V s and V t arethevocabularyinthesourcelan-guage and the vocabulary in the target language. | U s | and | U t | arethenumberofunlabeledsentencesinthe source language and target language.

Meanwhile, we have the following log-likelihood function for labeled data in the source language D s .
L (  X  | D s ) = where  X  ij = 1 ifthelabelof d i is c j ,and 0 otherwise.
In addition, when labeled data in the target lan-guage is available, we have the following log-likelihood function.

L (  X  | D t ) =
Combining the above three likelihood functions together, we have the following likelihood function.
L (  X  | D t , D s , U ) = L (  X  | U ) + L (  X  | D s ) + L (  X  Note that the third term on the right hand side (
L (  X  | D t ) ) is optional. 3.3 Parameter Estimation
Instead of estimating word projection probability (
P ( w s | w t ) and P ( w t | w s ) ) and conditional proba-bility of word to class ( P ( w t | c ) and P ( w s | c ) multaneously in the training procedure, we estimate them separately since the word projection probabil-ity stays invariant when estimating other parame-ters. We estimate word projection probability using word alignment probability generated by the Berke-ley aligner (Liang et al., 2006). The word align-ment probabilities serves two purposes. First, they connectthecorrespondingwordsbetweenthesource language and the target language. Second, they ad-just the strength of influences between the corre-sponding words. Figure 2 gives an example of word alignment probability. As is shown, the three words  X  X our de force X  altogether express a positive mean-ing, whileinChinesethesamemeaningisexpressed with only one word  X   X  X  X   X  (masterpiece). CLMM use word alignment probability to decrease the in-fluences from  X   X  X  X   X  (masterpiece) to  X  X our X ,  X  X e X  and  X  X orce X  individually, using the word projection probability (i.e. word alignment probability), which is 0 . 3 in this case.
 Herman Melville's Moby Dick was a tour de force.  X  X  X  X   X  X  X  X  X  X   X   X   X  X  X  X   X   X   X  X   X  X  X   X 
We use Expectation-Maximization (EM) algo-rithm (Dempster et al., 1977) to estimate the con-ditional probability of word w s and w t given class c ,
P ( w s | c ) and P ( w t | c ) respectively. We derive the equations for EM algorithm, using notations similar to (Nigam et al., 2000).

In the E-step, the distribution of hidden variables (i.e. class label for unlabeled parallel sentences) is computed according to the following equations. where Z ( c u of the source (target) language sentence u si ( u ti ) in the i-th pair of sentences u i having class label c j .
In the M-step, the parameters are computed by the following equations.
 where  X  s ( i ) and  X  t ( i ) are weighting factor to con-trol the influence of the unlabeled data. We set  X  s ( i ) (  X  t ( i ) data, 1 otherwise. When d i belongs to labeled data, P ( c j | d i ) is 1 when its label is c j and 0 otherwise. When d i belongstounlabeleddata, P ( c j | d i ) iscom-puted according to Equation 5 or 6. 4.1 Experiment Setup and Data Sets
Experiment setup : We conduct experiments on two common cross-lingual sentiment classification settings. In the first setting, no labeled data in the target language are available. This setting has real-isticsignificance,sinceinsomesituationsweneedto quickly develop a sentiment classifier for languages that we do not have labeled data in hand. In this case, we classify text in the target language using only labeled data in the source language. In the sec-ond setting, labeled data in the target language are also available. In this case, a more reasonable strat-egy is to make full use of both labeled data in the source language and target language to develop the sentiment classifier for the target language. In our experiments, we consider English as the source lan-guage and Chinese as the target language.

Data sets : For Chinese sentiment classification, we use the same data set described in (Lu et al., 2011). The labeled data sets consist of two English data sets and one Chinese data set. The English data set is from the Multi-Perspective Question Answer-ing(MPQA)corpus(Wiebeetal.,2005)andtheNT-CIR Opinion Analysis Pilot Task data set (Seki et al., 2008; Seki et al., 2007). The Chinese data set also comes from the NTCIR Opinion Analysis Pi-lot Task data set. The unlabeled parallel sentences are selected from ISI Chinese-English parallel cor-pus (Munteanu and Marcu, 2005). Following the description in (Lu et al., 2011), we remove neutral sentences and keep only high confident positive and negative sentences as predicted by a maximum en-tropy classifier trained on the labeled data. Table 1 shows the statistics for the data sets used in the ex-periments. Weconduct experiments on two data set-tings: (1) MPQA + NTCIR-CH and (2) NTCIR-EN + NTCIR-CH.

CLMM includes two hyper-parameters (  X  s and  X  ) controlling the contribution of unlabeled parallel data. Larger weights indicate larger influence from the unlabeled data. We set the hyper-parameters by conducting cross validations on the labeled data. WhenChineselabeleddataareunavailable,weset  X  t to 1 and  X  s to 0 . 1 , since no Chinese labeled data are used and the contribution of target language to the source language is limited. When Chinese labeled data are available, we set  X  s and  X  t to 0 . 2 .
Topreventlongsentencesfromdominatingthepa-rameter estimation, we preprocess the data set by normalizing the length of all sentences to the same constant (Nigam et al., 2000), the average length of the sentences. 4.2 Baseline Methods
For the purpose of comparison, we implement the following baseline methods.
 MT-SVM: We translate the English labeled data to Chinese using Google Translate and use the transla-tion results to train the SVM classifier for Chinese.
SVM: We train a SVM classifier on the Chinese labeled data.

MT-Cotrain: This is the co-training based ap-proach described in (Wan, 2009). We summarize the main steps as follows. First, two monolingual SVM classifiers are trained on English labeled data and Chinese data translated from English labeled data. Second, the two classifiers make prediction on ChineseunlabeleddataandtheirEnglishtranslation, respectively. Third, the 100 most confidently pre-dicted English and Chinese sentences are added to thetrainingsetandthetwomonolingualSVMclassi-fiersarere-trainedontheexpandedtrainingset. The second and the third steps are repeated for 100 times to obtain the final classifiers.
 Para-Cotrain: The training process is the same as MT-Cotrain. However, we use a different set of En-glishunlabeledsentences. Insteadofusingthecorre-sponding machine translation of Chinese unlabeled sentences, we use the parallel English sentences of the Chinese unlabeled sentences.

Joint-Train: Thisisthestate-of-the-artmethodde-scribed in (Lu et al., 2011). This model use En-glish labeled data and Chinese labeled data to obtain initial parameters for two maximum entropy clas-sifiers (for English documents and Chinese docu-ments), and then conduct EM-iterations to update the parameters to gradually improve the agreement of the two monolingual classifiers on the unlabeled parallel sentences. 4.3 Classification Using Only English Labeled
The first set of experiments are conducted on us-ing only English labeled data to create the sentiment classifier for Chinese. This is a challenging task, since we do not use any Chinese labeled data. And MPQA and NTCIR data sets are compiled by differ-ent groups using different annotation guidelines.
Table 2 shows the accuracy of the baseline sys-tems as well as the proposed model (CLMM). As is shown, sentiment classification does not bene-fit much from the direct machine translation. For NTCIR-EN+NTCIR-CH, the accuracy of MT-SVM is only 62.34%. For MPQA-EN+NTCIR-CH, the accuracy is 54.33%, even lower than a trivial method,whichachieves55.4%bypredictingallsen-tences to be positive. The underlying reason is that the vocabulary coverage in machine translated data is low, therefore the classifier learned from the la-beled data is unable to generalize well on the test data. Meanwhile, the accuracy of MT-SVM on NTCIR-EN+NTCIR-CHdatasetismuchbetterthan that on MPQA+NTCIR-CH data set. That is be-causeNTCIR-ENandNTCIR-CHcoversimilartop-ics. Theothertwomethodsusingmachinetranslated data, MT-Cotrain and Para-Cotrain also do not per-formverywell. Thisresultisreasonable,becausethe initial Chinese classifier trained on machine trans-lated data (MT-SVM) is relatively weak. We also observe that using a parallel corpus instead of ma-chine translations can improve classification accu-racy. Itshouldbenotedthatwedonothavetheresult for Joint-Trainmodel in this setting, since it requires both English labeled data and Chinese labeled data. 4.4 Classification Using English and Chinese
The second set of experiments are conducted on using both English labeled data and Chinese labeled data to develop the Chinese sentiment classifier. We conduct 5-fold cross validations on Chinese labeled data. Weusethesamebaselinemethodsasdescribed inSection4.2, butweuse natural Chinesesentences instead of translated Chinese sentences as labeled datainMT-CotrainandPara-Cotrain. Table3shows the accuracy of baseline systems as well as CLMM. Table 3 : Classification Accuracy Using English and Asisseen,SVMperformssignificantlybetterthan MT-SVM. One reason is that we use natural Chi-nese labeled data instead of translated Chinese la-beled data. Another reason is that we use 5-fold cross validations in this setting, while the previous setting is an open test setting. In this setting, SVM is a strong baseline with 80.6% accuracy. Never-theless, all three methods which leverage an unla-beled parallel corpus, namely Para-Cotrain, Joint-Train and CLMM, still show big improvements over the SVM baseline. Their results are comparable and all achieve state-of-the-art accuracy of about 83%, but in terms of training speed, CLMM is the fastest method(Table4). Similartotheprevioussetting,We also have the same observation that using a parallel corpus is better than using translations.
 4.5 The Influence of Unlabeled Parallel Data
We investigate how the size of the unlabeled par-allel data affects the sentiment classification in this subsection. We vary the number of sentences in the unlabeled parallel from 2,000 to 20,000. We use only English labeled data in this experiment, since this more directly reflects the effectiveness of each modelinutilizingunlabeledparalleldata. FromFig-ure 3 and Figure 4, we can see that when more unla-beledparalleldataareadded,theaccuracyofCLMM consistently improves. The performance of CLMM is remarkably superior than Para-Cotrain and MT-Cotrain. When we have 10,000 parallel sentences, the accuracy of CLMM on the two data sets quickly increases to 68.77% and 68.91%, respectively. By contrast, we observe that the performance of Para-Cotrain and MT-Cotrain is able to obtain accuracy improvement only after about 10,000 sentences are added. The reason is that the two methods use ma-chinetranslatedlabeleddatatocreateinitialChinese classifiers. AsisdepictedinTable2,theseclassifiers are relatively weak. As a result, in the initial itera-tions of co-training based methods, the predictions made by the Chinese classifiers are inaccurate, and co-training based methods need to see more parallel
Figure 4 : Accuracy with different size of
Figure 6 : Accuracy with different size of sentences to refine the initial classifiers. 4.6 The Influence of Chinese Labeled Data
In this subsection, we investigate how the size of theChineselabeleddataaffectsthesentimentclassi-fication. AsisshowninFigure5andFigure6, when only500labeledsentencesareused,CLMMiscapa-ble of achieving 72.52% and 74.48% in accuracy on the two data sets, obtaining 10% and 8% improve-ments over the SVM baseline, respectively. This indicates that our method leverages the unlabeled data effectively. When more sentences are used, CLMM consistently shows further improvement in accuracy. Para-Cotrain and Joint-Train show simi-lar trends. When 3500 labeled sentences are used, SVM achieves 80.58%, a relatively high accuracy for sentiment classification. However, CLMM and the other two models can still gain improvements. Thisfurtherdemonstratestheadvantages ofexpand-ing vocabulary using bilingual parallel data.
In this paper, we propose a cross-lingual mix-ture model (CLMM) to tackle the problem of cross-lingual sentiment classification. This method has two advantages over the existing methods. First, the proposed model can learn previously unseen senti-mentwordsfromlargeunlabeleddata, whicharenot covered by the limited vocabulary in machine trans-lation of the labeled data. Second, CLMM can ef-fectively utilize unlabeled parallel data regardless of whether labeled data in the target language are used or not. Extensive experiments suggest that CLMM consistently improve classification accuracy in both settings. In the future, we will work on leverag-ing parallel sentences and word alignments for other tasks in sentiment analysis, such as building multi-lingual sentiment lexicons.

