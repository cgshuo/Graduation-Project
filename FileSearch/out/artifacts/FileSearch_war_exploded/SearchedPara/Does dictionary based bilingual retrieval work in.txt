 1. Introduction
Cross-language retrieval, CLIR, is retrieval across languages: the query language differs from the document language. The query language is called the source language and the document language the target language . When there is only one target target language(s), or the documents are translated into the source language. The first alternative is simpler and more pop-ular than the latter. (See Kishida, 2005 ). There are various translation approaches. The most common are the dictionary-based approach, the machine translation (MT) approach, and the corpus-based approach. The dictionary-based approach is based on a machine readable translation dictionary. It is quite popular in CLIR research, because it is simple and cheap.
Machine translation is also simple, because it is possible to input the whole query in an MT system. Queries are typically short, however, or they are just sets of terms, and thus there is often not enough context for an MT system to perform com-petent translation ( Airio, 2008 ). There are free MT systems, for example Altavista Babelfish (see http://babelfish.altavi-sta.com/ ), but Finnish and Swedish are not included in many free systems. Corpus-based translation is based on parallel or comparable corpora and is thus restricted to the topical area of the corpus. (Kishida, 2005 .)
The traditional answer for word form variation is normalization: document words are normalized before indexing, and query words are normalized accordingly. The two common normalization methods are lemmatization and stemming. For morphologically rich languages, like Finnish, German and Slovenian, normalization is vital: retrieval in a normalized index with normalized queries gives statistically significantly better results than inflected retrieval in an inflected (non-normal-1992). According to many studies, normalization is not so important for morphologically simple languages like English dictory results as well (see Krovetz, 1993 ).

Dictionary-based translation mostly produces target queries with lemmas. Depending on the target index, translated words may be lemmatized or stemmed. There are languages lacking the appropriate morphological tools, however. Also, some operational target indexes (for example many Web indexes) are non-normalized. Retrieval in a non-normalized index with a query including only lemmas may produce a poor result. This may be dependent on the morphology of the target lan-guage: English as a target language behaves differently from Finnish.

The aim of the present study is to find out the best ways to perform bilingual dictionary-based retrieval in a non-normal-ized index  X  an index where no stemming, no lemmatization or other similar techniques have been applied.

The translation variants included in a translation dictionary are typically lemmas. If the target index is lemmatized, the matching is perfect. In the case of a stemmed index, translated words must be stemmed accordingly. But what happens when we perform bilingual dictionary-based retrieval in an inflected index? The target query includes lemmas, while the index words are inflected: some of them are lemmas, but not all. If we are dealing with a language with weak inflection, for example English, this might work quite well. English has only four distinctive forms for nouns: two cases (nominative and genitive) in the singular and plural. Finnish, by contrast, has altogether 2000 forms for a noun and 12,000 forms for a verb ( Karlsson, 1983 , 356 X 357). Past research has shown that only about 30% of nouns in a large Finnish text corpus are uments where query words appear only in cases other than the nominative singular will not be retrieved by a query con-taining only words in the nominative singular.
 Approximate string matching is an approach which tries to identify the best matching dictionary words for a given string.
The dictionary may be a list of index words or a translation dictionary. There are various ways to compute the similarity between two strings: the number of common characters may be utilized, or calculation may be based on the number of steps required to transform one string into another. A popular scheme is the use of n -grams: the strings are decomposed into sub-strings of length n consisting of adjacent characters. The degree of similarity between two strings is then computed based on the number of similar n -grams between the compared strings and the total number of unique n -grams of the strings. ( Zobel utilized (see Section 2.1: N -gramming and s -gramming) .

Kettunen and colleagues have developed an approach called FCG (Frequent Case Generation) for inflected retrieval ( Kett-on the statistics of the distribution of word forms in a text sample. According to the authors, the 2 X 9 most frequent word forms are enough to achieve reasonable results, depending on the language pair. FCG has been found to be applicable to sev-eral languages with varying morphological complexity: Finnish, Swedish, German and Russian. (Kettunen et al., 2007.)
Until now, FCG has been applied in monolingual retrieval in an inflected index, and has yielded good results especially for
One might think that a method which performs well in monolingual IR is also good for bilingual retrieval. However, this is not necessarily the case. For example, stemming performs very well in monolingual IR, but may yield quite poor results in bilingual IR, especially when the source language is phrase oriented while compounds are used in the target language. ( Airio, 2006.)
Bilingual retrieval differs from monolingual retrieval in many ways. First, there may exist many translations (relevant and irrelevant synonyms) for each query word. Second, possible compounds and phrases may pose extra challenges for query formulation. Third, untranslatable words and cross-language spelling variants cause problems. Fourth, the FCG approach was developed for processing nouns only, but the there are words belonging to other parts of speech as well among the translations. Thus, the FCG results for monolingual retrieval are not directly applicable to bilingual retrieval.
The present research deals with bilingual dictionary-based retrieval in a non-normalized index. We compare s -gram-based retrieval with FCG-based retrieval. Both approaches have their pros and cons: s -gramming is dependent on the avail-ability of the target index word list, while FCG is dependent on the availability of the software generating word forms for the target language.

We have four language pairs in our test: English X  X innish, English X  X wedish, Finnish X  X wedish and Swedish X  X innish. Finn-ish and Swedish were selected as target languages because they are inflected languages, Finnish being highly inflected and
Swedish moderately so, and thus retrieval in a non-normalized index may cause problems. English (as a weakly inflected language), Finnish and Swedish have been selected as source languages in order to see the possible impact of the variety of source language morphology on the results.

We built two indexes for both target languages, Finnish and Swedish: the non-normalized index and the lemmatized in-dex where compounds were split into their constituents and the constituents were normalized as well. We call the first one hereinafter the inflected index and the second one the lemmatized index . Our baseline is retrieval in a non-normalized index with  X  X  X aw translation X : word forms given by the translation dictionary. We also compare the results with the lemmatized results (lemmatized queries in the lemmatized index). We decided to include lemmatization in our tests even if it is actually outside our focus, because lemmatization has often been the gold standard in earlier research. The string matching tech-niques, s -gramming and FCG, are explained in Section 2, while resources, data, methods, and research questions are de-scribed in Section 3. Section 4 reports the results. Section 5 includes discussion and Section 6 closes the paper with conclusions. 2. String matching techniques 2.1. N -gramming and s -gramming
N -gramming is an approximate string matching technique, which has been utilized in several ways in information retrie-val. In CLIR, n -gramming is often performed for an untranslatable word (or out-of-vocabulary  X  OOV word), because it may be a proper noun existing in the index with a slightly different spelling.

McNamee and Mayfield reported on the HAIRCUT retrieval system in 2004. The system is based on utilizing words and n -grams both in indexing and retrieval. N -grams could span word boundaries but not sentence boundaries. The authors tested their system with eight European languages, in both mono and bilingual retrieval. They found that n = 4 was a good choice for all the languages. (McNamee &amp; Mayfield, 2004 .)
In 2007 Vilares and colleagues applied n -grams in corpus-based translation as well as for indexing and retrieval. They performed 4-gram level alignment for the corpus. For querying, the source language topic was split into 4-grams as well. They performed digram, trigram and 4-gram feature extraction. ( X ilic  X  , Chauchat, Ba X ic  X  , &amp; Morin, 2007.)
Pirkola and colleagues (2002) introduced an extension for n -grams , s-grams , where digrams are combined of both adjacent and non-adjacent characters of words. Here, s refers to the number of skipped characters (0, 1, 2, ... , m 2 skipped charac-ters), where m refers to the number of characters in a word. The character combination index (CCI ) indicates the number of skipped characters when s -grams are formed. Each number in the notation refers to the number of characters between the constituent characters of s -grams. For example, CCI = {1, 2} refers to s -grams composed of characters separated by one char-that two s -gram classes are formed from the string: one with conventional digrams formed of adjacent characters and one with s -grams formed by skipping one character and two characters. Classified s -grams have performed well when matching cross-lingual spelling variants. (J X rvelin, Kumpulainen, Pirkola, &amp; Sormunen, 2006 ).

Padding spaces at the beginning and end of the string are often utilized in n -gramming and s -gramming. If padding is not ola, Visala, Lepp X nen, &amp; J X rvelin, 2003 ).
 The similarity measure for s -grams between two strings S and T with respect to the given CCI is defined as follows: where DS i is the s -gram set of a string, i denoting the s -gram class, | DS
In 2006, J X rvelin and colleagues utilized s -gramming as a language independent translation method for closely related languages, Swedish and Norwegian. They utilized s -grams with CCI = {{0}{1}} and CCI = {{0}{1,2}}. S -gram matching achieved good results. ( J X rvelin et al., 2006 .)
In the present study, s -gramming with CCI = {0, 1} was utilized for approximate string matching for selecting the best matching query words among index words. Thus, s -grams were formed by skipping 0 and 1 characters. No padding spaces at the beginning or end of the strings were used when forming the s -grams. For example, for the string chri , following s -grams were composed: ch, cr, hr, hi and ri. 2.2. The FCG method Kettunen has developed a method called FCG (Frequent Case Generation) for retrieval in an inflected index ( Kettunen &amp;
Airio, 2006 ). The idea of FCG is to generate the desired inflected word forms for a given lemma. For example, when the lem-query containing only one form. The prerequisite for applying FCG is that there must exist a word form generator for the target language. The original query words (nouns and adjectives) are assumed to be lemmas. In practice, this is not an unre-alistic requirement, because users might be expected to supply lemmas as query words when advised to do so, and in dic-tionary-based CLIR translated words are usually lemmas.

FCG is a language specific method. Thus, the method must be tuned separately for each language (most language specific approaches require tuning; for example, stemming requires building stemmers for separate languages). Tuning the FCG meth-od proceeds in the following way. First, the distribution of different case forms for nouns and adjectives is studied through corpus analysis. The aim is to find the most frequent case forms. Here, the size of the corpus is not crucial: the distribution binations of the most frequent case forms (for nouns and adjectives). The results are compared to the best available normal-ization method (lemmatization or stemming). There may be one or more combinations yielding good results. Those with the best results are then used for the FCG method for the language. (Kettunen, 2008; Kettunen, Airio, &amp; J X rvelin, 2007 ).
According to Kettunen and colleagues, six cases (out of 14) cover 84 X 88% of the possible variation of inflectional noun minor role in case distribution and they can be ignored, but plural inflection must be taken into account. Kettunen and col-leagues found that the following two processes were effective for Finnish: responding to into ) and elative (corresponding to from ) in the singular. Airio, 2006 ).

Nine and twelve denote here the numbers of variant keyword forms used in the procedure. They are a fraction of all the possible grammatical noun forms (almost 2000 in Finnish). (Kettunen, 2008 .)
Swedish nouns inflect according to number (singular and plural), case (nominative and genitive) and definiteness (defi-nite and indefinite). Thus, there are altogether eight forms for a Swedish noun. (Ahlgren, 2004 , 42). Kettunen and colleagues discovered the following two Swedish processes:  X  Sv-FCG_2: the two most common noun forms (indefinite and definite singular nominative).  X  Sv-FCG_4: the same forms as Sv-FCG_2 and in addition indefinite and definite plural nominative.

For adjectives, the Swedish FGC has two forms (definite and indefinite positive) (Kettunen et al., 2007 ). 3. Research questions, resources, data and methods 3.1. Research questions
As we have highlighted above, bilingual dictionary-based retrieval in an inflected index is problematic, especially for highly inflected languages. The most usual approach in CLIR is to apply normalization (stemming or lemmatization) in query formulation and indexing. This is not always possible, however. The aim of this study is to test three methods for performing bilingual IR in an inflected index: s -gramming, FCG and their combination. We performed two s -gram runs with differing numbers of target index words selected by s -gramming and two FCG runs with differing numbers of word forms generated by FCG. Our research questions are: 1. Which of the runs performs best: the run with raw translations (word forms given by the translation dictionary), either of the s -gram runs, either of the FCG runs or the combined run? 2. What are the reasons for the possible performance differences between various methods in distinct language pairs? 3. Is the result of the best inflected run commensurate with that of the gold standard, the lemmatized run? 3.2. Language resources and collections The following language resources were used in our tests:
Motcom GlobalDix multilingual translation dictionary (18 languages, total number of words 665,000, 44,000 English entries, 26,000 Finnish entries, 36,000 Swedish entries) by Kielikone plc. Finland (a company providing digital dictionary solutions).
 Lemmatizers FINTWOL, SWETWOL and ENGTWOL by Lingsoft plc. Finland.

Finnish word form generator FGEN from Teemapoint, Finland (a company providing Software, customized tools and ser-vices for natural language processing tasks).
 Swedish word form generator Grim from Numerical Analysis and Computer Science of the Royal Institute of Technology, Sweden.
 English stop word list (429 stopwords), created on the basis of InQuery X  X  default stop list for English (on InQuery, see Callan &amp; Croft, 1992 ).
 Finnish stop word list (773 stopwords), created on the basis of the English stop word list.
 Swedish stop word list (499 stopwords), created at the University of Tampere.

The lemmatizers used in the tests are based on the two-level morphological model. They give all possible base forms for a given inflected word and are capable of splitting compounds (see Koskenniemi, 1983 ).
 Both generators, FGEN and Grim, are rule-based and utilize no dictionaries nor word lists.

We utilized CLEF 2003 datasets (Finnish and Swedish, see Table 1 ), CLEF 2003 relevance assessments and CLEF 2003 Eng-dataset there were relevant documents only for 45 topics and in Swedish for 54 topics.

We also needed training datasets for selecting the numbers of target index words for the s -gram runs (see Section 3.4: runs). The Swedish training dataset and the topics are described by Per Ahlgren (see Ahlgren, 2004 , 61 X 81), and the Finnish ones by Eero Sormunen (see Sormunen, 2000, 59 X 60). The topics in both datasets differ from the CLEF 2003 topics.
As the indexing and retrieval system, we used the Indri search engine of the Lemur toolkit, 1234 . The Lemur Toolkit, 1234 is an open-source toolkit facilitating research in language modelling and information retrieval. It is a cooperative effort be-tween the University of Massachusetts and the Carnegie Mellon University. The Indri search engine is based on a combina-tion of the language modelling and inference network retrieval frameworks. (See The Lemur toolkit, 1234 .) In Indri retrieval, we utilized Dirichlet smoothing with l = 2500. 3.3. Indexing and query translation
We used the following word tokenization rules in indexing: punctuation marks were deleted, and strings broken down by the space character were coded to be indexable words. Capital letters were lowercased before indexing.

Query translation was performed with the UTACLIR system developed at the University of Tampere. UTACLIR processes each query word separately in the following way: First, the word is lemmatized with the source language lemmatizer. If the word is a stop word, processing ends here. Otherwise the lemma(s) are translated utilizing a translation dictionary. The translations may be normalized with the target language normalizer (a lemmatizer or a stemmer depending on the target index type) and stop words are removed. If the word is not translatable, there is the option to use n -gram-based methods.
The target words derived from the same source word are grouped into the same synonym group according to the Pirkola method. ( Airio, Keskustalo, Hedlund, &amp; Pirkola, 2003; Pirkola, 1998.) 3.4. Runs
For all the language pairs, we performed six runs in the inflected index. The baseline run was the run with  X  X  X aw trans-lations X : the translations given by the dictionary formed the query as such, without any processing. If the source word was untranslatable, it was added to the query as such as well. We call this run the raw translation run hereinafter. This run is not dependent on the availability of the target index word list or the FCG software. The raw translation run was se-lected as the baseline run in order to see the true impact of any kind of extra processing on the result: the run was performed with minimum processing  X  source language lemmatization plus dictionary-based translation.

Two of the runs were based solely on the FCG approach: all the translations as well as untranslatable source words were input to the FCG software and the output words were added to the query. The Finnish FCG runs are hereinafter called Fi-FCG_9 run and Fi_FCG_12 run , and the Swedish runs Sv-FCG_2 run and Sv_FCG_4 run .

Two of the runs were based on s -gramming: s -gramming was applied to all the translations as well as untranslatable source words, and the best matching target index words were selected as query words. There are two basic approaches to decide the number of selected target index words: either to base the calculation on  X  X  X orrect X  words among target index words retrieved by s -gramming (words which are inflected forms of the given word), or to base calculation on the retrieval similar words: for example misspelled words or compounds having the original word as a constituent. Thus, we are aiming here at a good retrieval result, not at correct inflected forms of original words. We decided to base the numbers of the se-lected target index words on the retrieval results. In order to do this we performed training runs in our training collections before the actual runs in the test collections for all our language pairs. We tested the performance of queries consisting of various rates of target index words (from one to twelve). In English X  X innish and Swedish X  X innish training runs, the best per-formance was achieved with queries including twelve index words, and the second best with queries including eleven index words. The s -gram runs are hereinafter called Fi-sgram_12 run and Fi-sgram_11 run . The corresponding rates in English X  Swedish and Finnish X  X wedish were seven and ten, and the runs are hereinafter called Sv-sgram_7 run and Sv-sgram_10 run .
The last run in the inflected index was a combined run of FCG and s -gramming: FCG (Fi_FCG_12 or Sv_FCG_4) was applied to translatable words, and s -gramming to untranslatable words. The number of target index words selected by s -gramming here was four: s -gramming was applied to untranslatable words only, and a larger number would possibly have caused noise combined run . This run was performed because it was assumed that s -gramming performs better for untranslatable words than FCG, and it was interesting to know whether the results differ much from other results.

We did not make any distinction between nouns/adjectives/verbs when inputting the words to the FCG software: we wanted to design a simple process, without part of speech tagging. This caused nonsense word forms in the FCG queries (be-cause verbs were treated like nouns or adjectives). This did not affect the result, however, because those word forms were not present in the index, either.

For comparison, we performed the lemmatized run for each language pair: the translated words were lemmatized and s -gramming was applied to the untranslatable words. Retrieval was performed in the lemmatized index. As in the combined run, the number of target index words selected by s -gramming here was four. Contrary to the FCG runs, verbs were also properly handled in the lemmatized run. The lemmatized run is our gold standard, and it is interesting to compare the results of the inflected runs with it. 4. Results
The results of the raw translation runs were different depending on the language pair. When Finnish was the target lan-guage, raw translations performed quite poorly: the mean average precision of the English X  X innish run was 11.2%, and that of the Swedish X  X innish run was 11.7% (see Table 2 and Fig. 1 ). The reason for this is the inflection of the Finnish language: the queries of the raw translation run included only one word form, usually nominative singular, which covers fewer than 30% of nouns. The result of the Finnish X  X wedish run was slightly better (14.3%), because inflection does not have such a remarkable impact in Swedish. On the other hand, Finnish as the source language had a disadvantageous impact on the re-sult: the queries included OOV (out-of-vocabulary) words (words included neither in the dictionary of the Finnish lemmatiz-er nor the translation dictionary  X  for example, proper names). Those words retained their inflected forms following Finnish grammar, and they did not match the Swedish index. The English X  X wedish raw translation run did not have this kind of problem, and the result was much better (18.1%). On the whole, doing something instead of nothing (the raw translation run) almost doubles the result, and with some language pairs almost triples it.

The other runs outperformed the baseline in all language pairs. In English X  X innish, English X  X wedish and Swedish X  X inn-ish, the results were quite even between the other runs, and the combined run achieved slightly better results than the s -gram and the FCG runs. In Finnish X  X wedish, the Sv-sgram_7 run slightly outperformed the SV-sgram_10 run and the com-bined run, and the FCG runs performed more poorly. The visualization of the raw translation run compared with Fi_FCG_12 (and Sv_FCG_4) clearly shows the outperformance of the FCG run over the baseline on the topic level (see Fig. 2 ). The visu-alization of the Fi-sgram_12 (and Sv-sgram_7) run compared with Fi_FCG_12 (and Sv_FCG_4) indicates quite even perfor-mance on the topic level (See Fig. 3 ).

We applied the parametric one-way analysis of variance (ANOVA, see e.g. Nelson, 1998) for statistical testing. The pur-pose of the test is to show the possible differences between the groups. Here the grouping factor was the handling approach of target language queries (raw, FCG, s -gram, and combined). The ANOVA test shows significant differences ( p &lt; 0.05) be-tween the runs in English X  X innish, but not in the other language pairs. The Bonferroni post hoc multiple comparison (be-tween English and Finnish runs) indicates that the raw translation run differs significantly from all the other runs ( p &lt; 0.05). No other statistically significant differences could be found.

We performed the lemmatized run for all the language pairs in order to see whether the results of our runs in the inflected index were commensurate with the gold standard. As expected, the lemmatized run outperformed the other runs in all lan-
Airio, 2006). The mean average precision was 39.0% in English X  X innish, 34.2% in English X  X wedish, 36.2% in Swedish X  X innish and 35.5% in Finnish X  X wedish (see Table 2 ). For each language pair, we compared the best inflected result with the gold stan-dard. In Swedish X  X innish, English X  X wedish and Finnish X  X wedish, the differences were statistically significant ( t -test, p &lt; 0.05), but in English X  X innish, the combined run achieved a result statistically comparable to the lemmatized run. 5. Discussion
There were performance differences between the various string matching methods depending on the language pair, but the differences were not remarkable. We were interested in the performance differences between s -gramming and the FCG method on the query level. Thus, we had a closer look at the query pairs which had performance differences ( P 10%) between the s -gram (Fi-sgram_12, Sv-sgram_7) run and the FCG (Fi-FCG_12, Sv-FCG_4) run. 5.1. Reasons for the performance differences between s-gramming and FCG on the query level
We found five reasons for the better performance of s -gramming: (a) malfunction of FCG with OOV words, (b) the capacity of s -gramming to give the genitive while Swedish FCG did not, (c) spelling variation which s -gramming could handle, (d) source word inflection which s -gramming clarified, and (e) the capacity of s -gramming to find new relevant words. All the query pairs with performance differences fell into these classes except one (a Swedish X  X innish query pair). Only one rea-son could be found for the good performance of FCG, and it was (f) the capacity of FCG to generate correct word forms. Next, we present examples of those cases. 5.1.1. FCG gave erroneous word forms for some OOV words
In some cases, FCG gave erroneous forms for an OOV word. For example, the Finnish FCG process, based on the Finnish word form generator, failed with OOV words ending with the letter n. There are special inflection rules for Finnish words ending with n, but those rules should not be applied to OOV words. Topic 168 deals with the assassination of Rabin. In the English X  X innish run, the corresponding Fi-FCG_12 query included the following forms for the word rabin : rabin rabimet, first one, the original word) are incorrect. The Fi-sgram_12 query included the words rabin, arabin, rabiniin, raabin, rabbin, in this case, the Fi-sgram_12 query outperformed the Fi-FCG_12 query. 5.1.2. S-gramming gave the genitive, while FCG did not The FCG processes did not give all the possible word forms, but only those selected in the tuning phase. There were some FCG queries which would have benefited from more word forms: the genitive was not included in the Swedish FCG process.
The proper names sometimes occurred in genitive in relevant documents, however. Topic 197 deals with the Dayton peace agreement in Bosnia X  X erzegovina. The English X  X wedish Sv-FCG_4 query included the forms bosnia, bosnian, bosnior and bos-niorna for the word bosnia , while the Sv-sgram_7 query included the forms bosnia, bosnias, bosna, bosniaker, bosnich, bosnien and bosnier . The genitive form bosnias is present in many relevant documents, and thus the Sv-sgram_7 query performed better than the Sv-FCG_4 query. 5.1.3. S-gramming found spelling variants across languages
OOV words are often proper names or geographical names whose spelling may vary across languages. Thus, FCG fails when trying to formulate inflected word forms from those words. For example, topic 182 is about the Normandy landings. Normandy is written in Finnish Normandia and in Swedish Normandie . In the Finnish X  X wedish run, the corresponding Sv-
FCG_4 query included the following forms for normandy : normandia, normandian, normandior and normandiorna , while the Sv-sgram_7 query included the words normandie, normandies, normandiet, normandy, normandiska, norman and normann .
The Sv-sgram_7 query included the correct word form as well as the genitive and even the corresponding adjective, and thus achieved a better result than the Sv-FCG_4 query. 5.1.4. S-gramming clarified the source word inflection, while FCG did not
Often the untranslatable word was not recognized by the source language lemmatizer, either. Thus, it was input to FCG in an inflected form. For example topic 175 deals with Everglades environmental damage. The word everglades occurs in an in-flected form evergladesin in the Finnish topic. The corresponding Finnish X  X wedish Sv-FCG_4 query included the forms ever-sgram_7 query included the words everglades, beseglades, vederlades,  X verflyglades, seglades, singlade and segerglad, the first one being the correct one, and thus the retrieval result was better than with the FCG queries.
 In some cases, source language lemmatization was not beneficial. Topic 180 deals with the bankruptcy of Barings. In the
English X  X wedish runs, the source language lemmatizer normalized the word barings into baring . The Sv-FCG_4 query in-cluded the forms baring, baringar, baringarna and baringen , and the Sv-sgram_7 query forms baring, barings, barin, bearing, barringh, barina and daring . Thus, the s -gram query included the right word form barings , and the Sv-sgram_7 query gave a better result than the Sv-FCG_4 query. 5.1.5. S-gramming outperformed FCG because of the capability to find new relevant words
In some topics including only translatable words, s -gramming outperformed FCG. The reason was the capability of s -gramming to introduce relevant new words which are not necessarily inflected forms of the original word. For example, topic 183 is about Asian dinosaur remains. The English X  X wedish FCG queries included the correct inflected forms for the word dinosaur , but the Sv-sgram_7 query included in addition the word dinosaurie X gg ( a dinosaur egg ), which happens to be pres-ent in some relevant documents. Thus, Sv-sgram_7 query outperformed the Sv-FCG_4 query in this case. 5.1.6. FCG outperformed s-gramming because of its capability to generate correct word forms
FCG is a better method for generating correct word forms for a translated word than s -gramming. This applies both to translated as well as OOV words. S -gramming succeeded in finding some inflected word forms, but often it also produced irrelevant words. S -gramming seemed to fail especially when Finnish was the target language, because many Finnish words out of which eight are correct forms but only two present in relevant documents. 5.2. Reasons for the performance differences between methods in distinct language pairs
For each language pair, we counted the query pairs (with performance differences P 10%) affected by the reasons enumer-ated above (See Table 3 ). The total number of query pairs was 45 when Finnish was the target language and 54 when Swed-ish was the target language. The number of queries where FCG outperformed s -gramming because of its capability to generate relevant word forms was quite the same for all the language pairs (it was nine in English X  X innish and English X 
Swedish, and 11 in Swedish X  X innish and Finnish X  X wedish). On the other hand, the number of queries where s -gramming was better was the same for all the other language pairs except Finnish X  X wedish, where it was 12. Finnish X  X wedish was the only language pair where the s -gram runs clearly outperformed the FCG runs (see Table 2 ). Table 3 shows that there are two main reasons for that: spelling variation between languages and source word inflection. This was the only language pair where Finnish was the source language: it is obvious that a highly inflected source language causes difficulties for the FCG method when untranslatable query words are present (if they happen to be in some other form than in their base form).
Even if the number of queries where s -gramming outperformed FCG was even across the other language pairs, the reasons for it were various. FCG gave erroneous word forms only when Finnish was the target language. On the other hand, the gen-itive produced by s -gramming affected the results only when Swedish was the target language. Spelling variants occurred in all other language pairs except English X  X innish. The impact of spelling variants on the results was smaller than expected, however. It should be noted that we only counted the queries with performance differences. There were four more topics with spelling variations, but no performance differences could be attributed to them. The main reason for this is that source/target language spelling variants were so different that s -gramming was not capable to handle them. For example, so much from each other that s -gramming failed to find relevant spelling variants.

We also compared our results to the monolingual FCG results reported by Kettunen in 2008. He also utilized the Lemur search engine in his tests. The average precision of his Finnish lemmatized run (lemmatized index, lemmatized queries) was 50.7%, while the result of the Fi_FCG_12 run was 48.0% and that of the inflected run (inflected index, query words inflected according to the original topic words) 37.5% (see Table 4 ). The corresponding Swedish results were 45.1%, 39.1% (Sv_FG_4) and 37.4%. ( Kettunen, 2008 .) Thus, the difference between our bilingual FCG runs and the bilingual lemmatized runs was clearly greater than it was between the monolingual FCG runs compared with the monolingual lemmatized runs. On the other hand, as stated above, bilingual IR poses extra challenges for FCG. Considering that, FCG performed quite well, and the results are promising.

The monolingual inflected run by Kettunen and colleagues performed quite well compared to our bilingual raw transla-tion run. This is accordance with the results of Kettunen (2006) . He found that the Finnish monolingual inflected queries (words in the forms in which they occur in the topic) performed much better in the inflected index than the lemmatized queries did. Thus, lemmas do not yield a good result in an inflected index. (Kettunen, 2006 ). The query words given by the translation dictionary are most often lemmas. Thus, FCG or s -gramming is vital in bilingual IR when retrieving in an in-flected index. 6. Conclusions
Our first research question was which of the three approaches, s -gramming, FCG or the combined approach, performs best when retrieving in an inflected index. The combined run slightly outperformed the others in all other language pairs except
Finnish X  X wedish. In Finnish X  X wedish the Sv-sgram_7 run was the best (only slightly better than the combined run). The pre-requisites for utilizing the combined method are demanding, however: there must be the target word list as well as the tar-get language FCG software available. S -gramming and FCG proved to be quite good methods for compensating the combined method: they both gave quite even results for all language pairs except Finnish X  X wedish, where s -gramming was superior to FCG.
 Our second research question addressed the reasons for performance differences between language pairs. We found that
FCG performed poorly in Finnish X  X wedish mainly because of source language inflection: OOV words were given to FCG in an inflected form. This problem is associated with laboratory test settings, where topics include inflected word forms, while users might input the words in their base form. Substituting inflected OOV words with lemmas and a re-run of the processes would change the results. This is an interesting future research scenario.

Kettunen and colleagues found in 2008 that in monolingual retrieval, FCG is a competitive method with lemmatization, the gold standard. Our third research question was whether similar results can be achieved in bilingual retrieval with the best performing inflected run. We found that the best performing English X  X innish run, the combined run, achieved statisti-significant. Thus, the best inflected bilingual result was comparable with the gold standard only in one language pair out of four. On the other hand, some kind of target language processing is needed, because retrieval with raw translations yields lation results.

In this research, FCG was utilized only for processing nouns and adjectives. In this respect, lemmatization had an advan-tage over FCG. An interesting issue to study in the future would whether processing the verbs as well has any impact on FCG performance.
 Acknowledgements The Lemur Indri search engine was provided by the University of Massachusetts and Carnegie Mellon University. ENGTWOL (Morphological Transducer Lexicon Description of English): Copyright (c) 1989 X 1992 Atro Voutilainen and Juha Heikkil X .
 FINTWOL (Morphological Description of Finnish): Copyright (c) Kimmo Koskenniemi and Lingsoft plc. 1983 X 1993. TWOL-R (Run-time Two-Level Program): Copyright (c) Kimmo Koskenniemi and Lingsoft plc. 1983 X 1992.
 GlobalDix Dictionary Software was used for automatic word-by-word translations. Copyright (c) 1998 Kielikone plc, Finland.
 Finnish word form generator FGEN by Teemapoint, Finland.
 Swedish word form generator Grim from Numerical Analysis and Computer Science of the Royal Institute of Technology, Sweden.
 This research was supported, in part, by the Academy of Finland Grant No. 204978.
 References
