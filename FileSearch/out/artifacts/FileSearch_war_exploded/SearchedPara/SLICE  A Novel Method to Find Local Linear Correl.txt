 Linear correlations reveal the linear dependencies among several features in a dataset. features may be different in different data subsets. Some clustering methods are developed to find data clusters in subspaces [2, 3, 5, 9]. Correlation clustering methods, such as 4C, try to seek clusters in a linear correlation [6, 7]. The first step of these methods is to generate  X   X  X eighborhoods first. However, CARE is proposed to find local linear correlations. This method adopts PCA to suitable to find linear correlations that exist in data subsets. subsets. We refer such correlations only existed in the subset of dataset as local linear correlations . The main challenge for us is that the number of data subsets is so large complexity of our proposed method is polynomial. Our Contributions. (1) analyzing the limitations of applying current methods on finding linear correlations in data subsets; (2) developing a heuristic algorithm SLICE hyperplanes that represent linear correlatio ns; (3) conducting extensive experiments to world datasets. measures both accuracy and significance of the local correlation. Definition 1 (Significant Local Linear Correlation). Given a data matrix D xx (0  X  j t  X  M , t = 1, 2, ..., m ) is in a significant local linear correlation if following conditions are true: defined parameters are as same as in [1]. The computation cost would be very large if be tested, which is impractical for real-world applications. the data subset within a significant local linear correlation. Suppose the dataset has M established on S can be regarded as a significant local linear correlation . The concept definition of distance from a tuple to a hyperplane firstly. denoted as d ( x , S ), is defined as follows. where f ( S , k ) is defined in Definition 1. 
According to Definition 1 and Definition 2, we can see that if the distance from a this tuple. So, in the process of searching, the tuple with the minimal distance to the hyperplane is the  X  X est X  tuple to be absorbed. Our approach to find the  X  X est X  tuple is computational complexity of PCA, the time complexity of finding the minimum tuple in each step costs O ( n ( d 2 + d 3 )) at most. Fortunately, we can use a pruning strategy to set the initial seeds for searching. Then the whole process can converge very fast. SLICE does not choose the tuples as initial implementation details of SLICE. Algorithm 1. SLICE ( D ,  X  ,  X  , k ) Input: D : a d -dimensional data set D ,  X  ,  X  , k : user defined parameters. Output: SS : data subsets that are in a significant local linear correlation . Begin 1 M  X  | D |, C  X  D , SS  X   X  2 while | C | &gt; d 3 seed  X   X  4 while | seed | &lt; d 5 seed  X  seed  X  RANDOM( C , d ) 6 end 7 S  X  SEARCH( D , seed ,  X  ,  X  , k ) 8 if | S |  X  M  X   X  then 9 SS  X  SS  X  { S } 10 end 11 C  X  ( C  X  S ) 12 end End. be large. So we can see that t is associated with parameter  X  . Our experimental results show that t is less than n in most cases. To evaluate the performance of SLICE, we test it on several synthetic datasets and a real world dataset. SLICE is implemented using Matlab 7.6. The experiments are performed on a 1.8GHz PC with 2G memory running Windows Server 2003 operating system. The characteristics of experimental datasets are presented as follows. In order to evaluate the effectiveness of algorithms, we conduct SLICE on these 500 correlations in these synthetic datasets. 
Next, we compare SLICE with 4C and CARE, since 4C and CARE are mostly recent works close to ours to the best of our knowledge. a) Comparison with algorithm 4C: 4C is a kind of correlation clustering algorithm [6]. This algorithm has to generate  X   X  neighborhoods at first. In the synthetic found in other datasets. b) Comparison with algorithm CARE: In this experiment, we use CARE to find linear correlations in tuple subset. Figure 2 illustrates the hyperplane found by CARE in dataset D300F3C3. Based on this result, we can see the main limitation of CARE is that it is only capable to find the primary linear correlation of the dataset. Due to the results are found in other datasets. just compare our SLICE with CARE in NBA dataset. We use the same parameters in 
CARE 0.090645 * minutes  X  0.976344 * assists  X  0.196303 * rebounds = 0.796832 real world compared the result of CARE. synthetic datasets has 4 predefined local linear correlations. The parameter k = 1, and  X  = 0.0001,  X  = 0.2. The results are showed in Figure 3 and Figure 4. Finding linear correlations in dataset has many real world applications. In this paper, we propose a method to find local linear correlations in data subsets. The full work of this paper could be seen in the place 3 . In future, we plan to integrate user interests in complexity in each execution is a challenging work. 
