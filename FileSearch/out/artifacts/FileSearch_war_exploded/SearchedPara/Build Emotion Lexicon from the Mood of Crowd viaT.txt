 In the research of building emotion lexicons, we witness the exploitation of crowd-sourced affective annotation given by readers of online news articles. Such approach ignores the relationship between topics and emotion expressions which are often closely correlated. We build an emotion lexicon by developing a novel joint non-negative matrix factorization model which not only incorporates crowd-annotated emo-tion labels of articles but also generates the lexicon using the topic-specific matrices obtained from the factorization process. We evaluate our lexicon via emotion classification on both benchmark and built-in-house datasets. Results demonstrate the high-quality of our lexicon.
 emotion lexicon; joint NMF; emotion classification
A basic task in sentiment analysis is classifying the senti-ment polarity (positive or negative) of the given subjective text [8, 11, 13]. However, the binary scheme may be over-simplified. Recently, emotion analysis represents a natural evolution of sentiment analysis by modeling finer-grained emotions, e.g., happy, sad, angry, etc. [9, 14].
Emotion lexicons are the essential resources for emotion analysis. Compared to sentiment lexicons such as Senti-WordNet 1 [1], where each entry is typically labeled with sentiment polarity, emotion lexicons are more complex in the sense that each entry may convey a mixture of multiple emotions which bear different emotion intensity 2 [14].
Most of the existing lexicon construction approaches [3, 12, 15] are based upon a set of hand-coded seed words. Con-sequently, the quality of lexicons is sensitive to the manual http://sentiwordnet.isti.cnr.it/ git.io/MqyoIg Figure 1: The emotion distribution generated by  X  X ood meter X  on a news article seed selection. Today, many news websites (e.g., rappler. com, corriere.it, etc.) allow users to express their feelings about an article with a simple click on a given set of emoti-cons. Figure 1 shows the emotion distribution based on such kind of votes from the crowd regarding an article on rappler.com via an GUI called  X  X ood meter X  which is em-bedded in each of its web page.

Staiano and Guerini [14] proposed a compositional se-mantics method that utilized crowd-based affective anno-tation, where they represented words and emotions in a high-dimensional space based on their occurrences in the document. A deficiency is that they ignored the versatility of affections among various contexts. It cannot distinguish accurately the emotion of words by disregarding different topics where words exist. Since documents and topics are of many-to-many correspondence in a collection, it would be more useful to consider emotions at topic level. Some researchers tried to model topic and sentiment simultane-ously [4, 8] for joint sentiment-topic analysis. However, no work has considered topics when building emotion lexicons.
Intuitively, emotion expressions are pertinent to the top-ics in which they reside. For example,  X  X redictable X  suggests happiness for stock market, but for a movie it implies dis-appointment or even anger. We expect that topic-assisted workaround can produce finer-grained and more accurate en-tries for emotion lexicons. In this paper, we develop a novel joint non-negative matrix factorization model which asso-ciates words with emotions in a low-dimensional semantic space based on hidden topics. An emotion lexicon is built from word-topic and emotion-topic factor matrices, which result from the joint model, using matrix composition.
Emotion lexicons are typically built based on a set of seed words [3, 12, 14, 15]. Xu et al. [15] proposed a graph-based algorithm which ranked words according to a few manually selected seed words. Song et al. [12] and Feng et al. [3] improved this method by supplementing seed words with graphical emoticons or combined their effects. Differently, Staiano and Guerini [14] proposed a compositional seman-tics method using crowd-annotated articles crawled from the Internet. In this paper, we also resort to crowd-annotated articles while we incorporate topic-emotion relationship for lexicon construction which was not considered previously.
Non-negative matrix factorization (NMF) has been widely used in image or text representation. Lee and Seung [5] in-vestigated the properties of the algorithm and emphasized the clustering aspect. Xu et al. [16] applied standard NMF to document clustering. In recent years, different exten-sions [7, 10] have been proposed for solving sentiment analy-sis and sentiment lexicon construction. Li et al. [7] creatively applied orthogonal NMF, proposed by Ding et al. [2], to sentiment classification by incorporating lexical prior knowl-edge. Peng and Park [10] proposed a constrained symmetric NMF method for sentiment lexicon construction, which con-siders synonyms and antonyms simultaneously.
 Lee et al. [6] used a generic semi-supervised NMF (SS-NMF) method which jointly incorporates the data matrix and the (partial) class label matrix into NMF. We base our model on SSNMF for lexicon construction by incorporating different factorization schemes for the supervision matrix, which naturally results in a lexicon from the estimated fac-tor matrices. To our knowledge, this is the first attempt for building fine-grained emotion lexicon based on NMF models.
We first introduce a compositional semantics method [14] for building an emotion lexicon from crowd-annotated news. Then, we review semi-supervised NMF [6] which paves the way for developing our lexicon generation method.
Let D = { d 1 ,...,d | D | } be a set of documents, and W = { w 1 ,...,w | W | } be the complete vocabulary set of the whole corpus. We define a word-document matrix M WD of size |
W | X | D | ,using( w,d ) as index and M WD ( w,d ) as entry value based on raw frequencies f , normalized frequencies nf or tf-idf . Given emotion set E = { e 1 ,...,e | E | } ,wecan represent emotion labels from crowd-annotated resources as a document-emotion matrix M DE of size | D | X | E | whose entry values are based on crowd-sourced affective annota-tion (see Figure 1). Staiano and Guerini [14] built a word-emotion matrix M WE using the compositional semantics (CS) method by multiplying matrices M WD and M DE : An emotion lexicon can be obtained by first applying column-wise normalization to M WE and then scaling its row-wise data that sums up to one.
Non-negative Matrix Factorization (NMF) [5] is an un-supervised algorithm widely used in image or text repre-sentation. A generic semi-supervised NMF (SSNMF) al-gorithm [6] was proposed to incorporate the data matrix X =[ x 1 ,...,x n ]  X  R m  X  n + ,where m is the dimension of data vectors, and the class label matrix Y =[ y 1 ,...,y n ]  X  R c  X  n where c is the number of classes. The objective function, which involves the non-negative two-factor decomposition of X and Y sharing a common factor matrix S  X  R k  X  n + ,is to minimize the following: where  X  is a tradeoff parameter adjusting the importance of the supervised term, A  X  R m  X  k + and B  X  R c  X  k + are ba-sismatricesfor X and Y , U and V are weights matrices, both of which can be fixed as all-ones matrices to make an NMF that fully uses labeled data [6]. Notation || . || 2 denotes the squared sum of all the elements in the matrix and represents element-wise product.
Inspired from SSNMF, we can jointly model the hidden topics and the explicit crowd-based emotions of articles by customizing the factorization process. Let T = { t 1 , ..., t be a set of topics in low-dimensional space with | T | min {| D | , | W |} . Given the word-document matrix M WD document-emotion matrix M DE , we decompose them based on equation 2 by minimizing: J = || M WD  X  M WT M to learn the three topic-specific factor matrices M WT , M and M ET ,where M ET represents the strength that emo-tions are associated with topics. Then, we can get the word emotion distributions by using a variant of compositional semantics approach (see equation 1) as below:
A deficiency of directly applying SSNMF is that the emo-tion modeling is still coarse-grained for lexicon construction which is concerned about word-level emotion. We enhance the model by modeling the emotions of subjective texts using a weighted linear combination of emotion words, which will result in an additional term of the 3-factor decomposition of M DE based on formula 3 as follow: where  X  is a tradeoff parameter, M WD is fixed and con-sidered as word weights, and M WT and M ET are variables whose product happens to be M WE . With the last term, the joint model aims to improve the estimation of the topic-specific factor matrices by approximating the document-level emotions M DE based on the word-level emotions M WE
Computation : Factor matrices M WT , M ET and M DT are first randomly initialized, and then updated iteratively by the following updating formulas: divisions are all element-wise. The update formulas can be easily induced based on the derivatives in [6]. Table 2: Emotion distribution over Rappler dataset
Lexicon Construction :Given M WT and M ET represented in the | T | -dimensional topic space, we can build a word-emotion matrix M WE based on equation 4. After normaliz-ing its entries, we obtain a | E | -dimensional vector for each word w : where each element M WE ( w,e ) indexed by ( w,e )represents the emotion score of word w belonging to emotion category e  X  E ,and Z w = ization term for w (column-wise normalization ensures that different columns for all the emotions are comparable).
Our created emotion lexicon contains 31,806 entries in to-tal. Table 1 presents several example entries. Similar to [14], we lemmatize and Part-of-Speech (PoS) tag all the docu-ments (PoS we considered are adjective, noun, verb and ad-verb), and we only keep those lemma # PoS entries in the lexicon which also appear in WordNet for eliminating noise words. We can see that each entry has at least one main emotion (e.g., monitor # v has two main emotions of afraid and angry ), and our lexicon differentiates the emotions bet-ter by assigning discriminative weighting scores as compared to the CS baseline.
To build our lexicon, we crawled 31 , 107 English news ar-ticles published before 2015-11-06 from rappler.com .We used Standford CoreNLP 3 , an integrated suite of natural language processing tools, to tokenize, PoS tag and lemma-tize all text data. In Table 2, we report the average percent-age of votes for each emotion over all the documents in the corpus. From Table 2, we find that the emotion of happy has a lot more votes than the others, which reflects that read-ers X  emotion preference is consistent to the general observa-tion  X  positive sentiment dominates in real-world data. The crawled resources and generated lexicons have been made publicly available 4 .

To evaluate the lexicon, we applied it for emotion classifi-cation on news headlines as [14] did. We used two datasets: http://nlp.stanford.edu/software/corenlp.shtml https://sites.google.com/site/emolexdata/
Table 3: Emotion label mapping over two test sets (1) A benchmark dataset from SemEval-2007 5 on identify-ing  X  X ffective Text X , which contains 1 k annotated headlines. As SemEval-2007 test set consists of only six emotions, we adopted an emotion mapping method as displayed in Ta-ble 3 to map them to our pre-defined emotions in the lex-icon. (2) A built-in-house dataset with total 31 k headlines of the crawled Rappler articles.

We implement the algorithms using Matlab and run them on a high performance Linux cluster.
We evaluate the quality of the emotion lexicons in two ways: (1) we examine the quality of lexicons created by our method and other competitive methods using the crawled Rappler news articles via an emotion classification task; (2) we compare our created lexicons with publicly available state-of-the-art lexicons in similar size.
We tune the number of topics | T | by performing a grid search over all values of 10  X  x with x  X  X  1 , 2 , ..., 30 tradeoff parameters  X  and  X  are tuned over all values in { 0 . 1 , 1 , 10 , 100 } . The tuning is based on the performance of emotion classification on the headlines in SemEval X  X  trial set and a held-out set which consists of 20% headlines randomly selected from the Rappler articles. Finally, we set | T |  X  =1and  X  = 10. We set the number of iterations as 300, which is large enough for ensuring convergence according to our observation on the drop of J and J values.
For emotion classification, we use a straight-forward voting-based algorithm [12, 14] to assign emotion labels to a test headline h . We conduct element-wise sum over the emo-tion words in the headline by looking up the lexicon and then average the sums by word counts, i.e., V h = 1 Z ber of emotion words in h . We then normalize V h with the min-max normalization and ma p each emotion element into a binary decision with fixed thresholds. We set threshold at 0.5 for SemEval-2007 test set and 0.35 for Rappler test set, empirically 6 . We use F-1 measure to assess the classification performance on each emotion. Tables 4 and 5 show the re-http://nlp.cs.swarthmore.edu/semeval/tasks/
We set a lower threshold for Rappler test set since only a single emotion in each news receives more than 50% votes Table 4: SemEval-2007 emotion classification (F1) sults by averaging 20 independent runs (with random initial matrices) on SemEval and Rappler test sets, respectively.
Our joint models perform better than CS for most emo-tions especially under nf configuration. This indicates that normalized frequency can prevent the bias towards long doc-uments and our method considering topic is effective. More-over, joint model J also performs J at most cases, im-plying the usefulness of considering word-level emotion in decomposition. Surprisingly, the results under tf-idf config-uration are unstable, which suggests that introducing idf is sub-optimal. This is because frequent emotion words, e.g.,  X  X ood X , receive low tf  X  idf , thus are not learned well.
We compare our lexicons with the original lexicons re-leased by Staiano and Guerini [14]. We assess them via emotion classification on the larger built-in-house Rappler test set. Figure 2 demonstrates that our lexicon configured as nf achieves the best results on nearly all emotions, which suggests the high usability of our created lexicon.
We present a joint NMF method which incorporates crowd-based emotion labels on articles and generates topic-specific factor matrices for building emotion lexicons via composi-tional semantics. Experiments conducted on the benchmark and built-in-house datasets demonstrate our method out-performs the competitive methods on emotion classification. Moreover, our created lexicon outperforms the competitive counterpart on emotion classification task. Our future work will study emotion-specific word embeddings for lexicon con-struction using deep learning. Figure 2: Comparison among different lexicons This work is supported by the National Natural Science Foundati on of China (61370074, 61402091) , the Fundamen-tal Research Funds for the Ce ntral Universities (N130604002, N140404012) and the ARC Discovery Project (DP140100545).
