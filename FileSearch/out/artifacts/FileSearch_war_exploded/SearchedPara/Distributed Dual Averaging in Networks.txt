 scription of the distributed dual averaging algorithm.
 tion f tains its own parameter vector x agents: in particular, agent i has local access to only the objective function f directly only with its immediate neighbors j  X  N ( i ) := { j  X  V | ( i,j )  X  E } . setup avoids communication bottlenecks of architectures w ith a centralized master node. and that  X  (0) = 0 . Such proximal functions include the canonical quadratic  X  ( x ) = 1 is strongly convex with respect to the  X  which is strongly convex with respect to the  X  We assume that each function f Many cost functions f tion (1) implies that for any x  X  X and any subgradient g kk  X  denotes the dual norm to kk , defined by k v k  X  := sup k u k =1 h v,u i . The dual averaging algorithm generates a sequence of iterat es { x ( t ) ,z ( t ) }  X  R Here {  X  ( t ) }  X  function  X  and stepsize  X  ( t ) &gt; 0 enforce that the iterates { x ( t ) }  X  In Section 4, we relate the above procedure to the distribute d algorithm we now describe. tributed setting. For all times t , each node i  X  V maintains a pair of vectors ( x At iteration t , node i computes a subgradient g { z j ( t ) , j  X  N ( i ) } matrix with P i  X  V and of positive stepsizes, each node i  X  V updates where the projection  X   X  z in its neighborhood; it then computes the local iterate x convergence of the local sequence { x average b x Convergence of distributed dual averaging: We start with a result on the convergence of the the averaged dual variable  X  z ( t ) := 1 Theorem 1 (Basic convergence result) . Given a sequence { x the updates (4) with step size sequence {  X  ( t ) }  X  f ( b x i ( T ))  X  f ( x  X  )  X  defined quantity b x long the bound on the deviation k  X  z ( t )  X  z  X  ( t )  X  1 / is symmetric and stochastic, it has largest singular value  X  the convergence of our algorithm is controlled by the spectral gap  X  ( P ) := 1  X   X  moreover that  X  ( x  X  )  X  R 2 . With step size choice  X  ( t ) = R spectral gap 1  X   X  et al. [11] establish rates for their Markov incremental gra dient method (MIGD) of p n  X  always lower bounded by 1 / p 1  X   X  P undirected graph G , satisfying A i  X  V , let  X  i = | N ( i ) | = Corollary 1. Under the conditions of Theorem 2, using P = P (a) k -connected paths and cycles: f ( b x (b) k -connected  X  n  X   X  n grids: f ( b x (c) Random geometric graphs with connectivity radius r =  X ( (d) Expanders with bounded ratio of minimum to maximum node d egree: d In general, Theorem 2 implies that at most T to achieve an  X  -accurate solution when using the matrix P ized optimization algorithms, any subgradient method requ ires at least  X  1  X  algorithm. For the quadratic proximal function  X  ( x ) = 1 lower bound on the number of iterations in terms of graph topo logy and network structure: communication matrix P required to achieve a fixed accuracy c &gt; 0 is lower bounded as T constant in network size n  X  X re well-matched in simulations of our algorithm. gence via the two sequences  X  z ( t ) := 1 gradients  X  z ( t ) evolves in a very simple way: in particular, we have Lemma 2 (Nesterov) . Let { g ( t ) }  X  updates (2). For a non-increasing sequence {  X  ( t ) }  X  Our second lemma allows us to restrict our analysis to the seq uence { y ( t ) }  X  Lemma 3. Consider sequences { x Then for each i  X  V and any x  X   X  X , we have Now we give the proof of the first theorem.
 Proof of Theorem 1: Our proof is based on analyzing the sequence { y ( t ) }  X  by the L -Lipschitz continuity of the f By definition of  X  z ( t ) and y ( t ) , we have y ( t ) = argmin in Lemma 2, and as a consequence, we have the bound It remains to control the final two terms in the bounds (7) and ( 8). Since k g tion, we use the  X  -Lipschitz continuity of the projection  X   X  Combining this bound with (7) and (9) yields the running sum b ound Applying Lemma 3 to (10) gives that P T 1  X  ( T ) Dividing both sides by T and using convexity of f yields the bound in Theorem 1. an n  X  n matrix B , we call its singular values  X  symmetric B , we use  X   X  n = { x  X  R n | x 0 , Define the matrix  X ( t,s ) = P t  X  s +1 . Let [ X ( t,s )] (6), we assume w.l.o.g. that z z i ( t )  X   X  z ( t ) = We use the fact that k g k  X  z ( t )  X  z i ( t ) k  X  = has not mixed, while the second consists of steps s for which k [ X ( t  X  1 ,s )] uniform. From the inequality (11), we have k [ X ( t,s )]  X  simply have k [ X ( t,s )] Since t  X  1  X  ( t  X  b t ) = b t and there are at most T steps in the summation, The last inequality follows from the concavity of log( ) , since log  X  we find that for x  X   X  X , Appealing to Lemma 3 allows us to obtain the same result on the sequence x worse constants. Since P T f ( b x i ( T ))  X  1 T We solve a synthetic classification problem, in which we are g iven n pairs of the form ( a R label. Given the shorthand notation [ c ] classifier based on x is given by f f ( x ) := 1 n non-smooth at any point with h a choosing X = { x  X  R d | k x k setting of the step size  X  specified in Theorem 2 and Corollary 1. Figure 2 provides plots of the function error max resulting stepsize is so small that the method effectively j ams and makes no progress. subgradient averaging. Each panel shows the function T the desirable property of having constant network scaling. and for minimization of composite regularized objectives o f the form f ( x ) +  X  ( x ) . Acknowledgements: JCD was supported by an NDSEG fellowship and Google. AA was su p-DMS-0707060 and DMS-0830410. MJW and AA were partially supp orted by AFOSR-09NL184. [3] F.R.K. Chung. Spectral Graph Theory . AMS, 1998. [10] R. A. Horn and C. R. Johnson. Matrix Analysis . Cambridge University Press, 1985.
