 We proposed a method to classify songs in the Million Song Datasetaccordingtosonggenre. Sincesongshaveseveral data types, we trained sub-classifiers by different types of data. These sub-classifiers are combined using both classi-fier authority and classification confidence for a particular instance. In the experiments, the combined classifier sur-passes all of these sub-classifiers and the SVM classifier us-ing concatenated vectors from all data types. Finally, the genre labels for the Million Song Dataset are provided. I.5.2 [ Design Methodology ]: Classifier design and evalua-tion; H.5.5 [ Sound and Music Computing ]: Methodolo-gies and techniques Algorithms, Experimentation Classifier Combination, Song Genre Classification
In music information retrie val, many methods see song genre as important metadata for retrieving songs. As the largest currently available dataset, the Million Song Dataset (MSD) is a collection of audio features and metadata for a million contemporary popular music tracks. However, none of records have any genre labels. The goal of this paper is to automatically classify songs in the MSD according to genre.
Some papers have discussed the importance of multiple data sources in genre classification and proposed methods to use them. Most of these methods [3] concatenated features from different data sources into a vector to represent the song. However, for a huge scale dataset, it is impossible that every instance will have valid data in all data sources. It is inevitable for the classification results to be demoted due to data missing influence in the concatenated vector.
If we imagine classifiers as experts in voting, the accura-cy of each classifier represents the authority of the expert. Because the types of input data are different, the views of experts are not same. Therefore, the confidences to make a correct decision regarding a particular item are also dif-ferent. Hence, the voting result of an instance is related to both the authority of the classifier and the confidence of the classifier to classify the particular instance.

In this paper, we extract features from audio, artist terms, lyrics and social tags to represent songs and train sub-classifi-ers. The trained sub-classifiers are combined to classify song genre. The songs with missing data in certain data types are classified by the remaining data without any negative influ-ence by the missing data.
We apply each data source to train a sub-classifier and we assume that classifier set C contains n sub-classifiers, namely, C = { c 1 ,c 2 ,...,c n } . Furthermore, we assume that songs are distributed into m genres, G = { g 1 ,g 2 ,...,g The voting result is shown in Equation 1.

G ( I k ) = arg max
Auth( c i ) denotes the authority of the classifier c i from 0.0 to 1.0. Auth ( c i ) is estimated by the accuracy of the classification in the validation test.

Conf ( c i ,g j ,I k ) is the confidence of the classifier c sify the instance I k to genre g j .ForNa  X   X ve Bayes, the poste-rior probability is seen as the c onfidence for a c lass. Neural Net has normalized real value output from -1.0 to 1.0. A pos-itive value means the confidence to assign the instance to a positive label. We employ the method proposed by Lee [2] to estimate the confidence for logistic regression. The margin from the instance location to the classification hyperplane is considered to be the confidence of the SVM classifier. The confidences of classifiers are normalized into [0 . 0 , 1 . 0]. The confidence for invalid data is set to 0.0, in order to avoid negative effect caused by invalid data. In our experiment, we applied MSD, MusiXmatch and Last.fm tag datasets to extract features, as shown in Table 1. The records in these data sources are matched via trackID .
AllMusic.com provides genre taxonomy, which consists of 10 major genres with sample songs. 1,138 songs are collected from AllMusic.com and they have valid records in MSD as the ground truth. The distribution of the songs according to genre is shown in Figure 1. (c) MuisXmatch Lyrics features 237,662 Last.fm tags Social tags 505,216
In order to improve classification performance, we con-vert genre classification into a series of binary classifications. Thus, the classification result of a song is a vector of confi-dence to classify the song into a genre. The predicted genre is the one whose confidence is highest.

We extract features from different data sources and trained individual classifiers by each type of features using Na  X   X ve Bayes, Rule Induction, LDA, Neural Net, Logistic Regres-sion and SVM, respectively. The classifiers X  performances are evaluated by 5-folder cross validation. The best perfor-mance classifiers in different types of features are shown in Figure 2.

The four sub-classifiers are combined based on classifica-tion authority and confidence. The resultant combined clas-sifier is significantly better than sub-classifiers and the SVM classifier using concatenated vectors from four data sources as shown in Figure 3 and Table 2. The result is encouraging regarding to the result of genre classification task in MIREX [1]. Furthermore, we apply the combined classifier to classi-fy all of the songs in the MSD and the result is available at http://web.cs.miami.edu/home/yajiehu/resource/genre .
Based on classifier authority and classification confidence, the combined classifier integrates sub-classifiers, which are good at classification of certain data sources. The combined classifier performs with higher accuracy than sub-classifiers and the SVM classifier using concatenated vectors. [1] http://www.music-ir.org/mirex/wiki/2009 . [2] C.-H. Lee. Learning to combine discriminative [3] C.McKay,J.A.Burgoyne,J.Hockman,J.B.L.

