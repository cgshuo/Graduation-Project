 SUK JIN LEE, YUICHI MOTAI, ELISABETH WEISS, and SHUMEI S. SUN , Intelligent and automated data processing is becoming increasingly important for med-ical healthcare systems. With the advent of various medicare analysis and treatment systems, medical data should be managed in intelligent ways. Current developments in radiotherapy systems open a new era for treatment with accurate dosimetry of tho-racic and abdominal tumors [Keall et al. 2006; Bush et al. 2011; Cervino et al. 2011]. Effective radiation treatment requires motion compensation for uncertainty and irreg-ularity originating from systematic or random physiological phenomena [Benchetrit 2000; Nakagawa et al. 2007]. Respiratory motion severely affects precise radiation dose delivery because thoracic and abdominal tumors may change locations by as much as three centimeters during radiation treatment [Berbeco et al. 2005]. Improved target-ing with smaller treatment fields and tumor tracking is desirable in order to spare surrounding normal tissue. Breathing is a dynamic process. In patients with a wide range of respiratory motion, radiation treatment can be delivered by dynamic gating, where radiation is activated only when the respiratory motion is within a predefined amplitude or phase level [Berbeco et al. 2005; Pepina et al. 2011].

In addition to the respiratory motion, system latency attributable to hardware limi-tations and software processing time may affect accurate radiation delivery for tumor-tracking techniques [Keall et al. 2006; Poulsen et al. 2010; Roland et al. 2010]. If the acquisition of the tumor position and the repositioning of the radiation beam are not well synchronized, a large volume of healthy tissue may be irradiated unnecessarily and a tumor may be underdosed [Lu et al. 2006a; Li and Lei 2010]. Due to the latency, for real-time tumor tracking, the tumor position should be predicted in advance so that the radiation beams can be adjusted accordingly to the predicted target position dur-ing treatment [Keall et al. 2006; Kubo et al. 2000]. Therefore, we propose a prediction method for respiratory motion to compensate for uncertainty in respiratory patterns based on the knowledge of multiple patients X  breathing datasets.

A number of prediction methods for respiratory motion have been investigated based on surrogate markers and tomographic images [Murphy and Dieterich 2006; Tang et al. 2007; Ruan 2010; Cervino et al. 2010; Malinowski et al. 2011; Bai and Brady 2011; Sarrut et al. 2007; Jacq et al. 2010]. The previous methods can be further categorized into two approaches: (1) those that are model-based , which use a specific biomechanical or mathematical model for respiratory motion functions or models [McCall and Jeraj 2007; Putra et al. 2008; Ruan 2010; Ehrhardt et al. 2011], and (2) those that are model-free heuristic learning algorithms that are trained based on the observed respiratory patterns [Murphy and Dieterich 2006; Murphy and Pokhrel 2009; Zeng et al. 2007]. Generally, model-based methods include linear approaches and Kalman filter variables that are widely used for the fundamental prediction of respiratory motion among a variety of investigated methods [Putra et al. 2008; Ruan 2010; Kuo et al. 2010].
A potential drawback of model-based approaches is their inability to learn highly irregular breathing patterns from training samples [Murphy and Dieterich 2006]. For accurate prediction of respiratory motion, the breathing pattern information should ap-ply the respiratory motion prediction in order to improve prediction accuracy [Werner et al. 2009]. Based on previous studies, the model-free heuristic learning algorithm can be a key approach for prediction, but it needs a correction method to compensate for irregular breathing signals that characterized a variety of breathing patterns. Ac-cordingly, we have pursued the use of heuristic algorithms to develop system adaptive loops that have the most general approach, that is, neural networks (NN).

The novelty of this proposed strategy is that the breathing pattern information from multiple patients is considered to support tracking accuracy. For accurate and reliable prediction of respiratory motion, we developed a model-free heuristic algorithm of system adaptive loops that have the most general approach for respiratory motion prediction from the breathing patterns of multiple patients.

The contribution of this study is to adopt a clustering method for multiple patients to get more practical breathing-pattern information and to find an accurate prediction process for an individual class. For the clustering based on breathing patterns, we present the feature selection metrics. With each feature metric, we can define a variety of feature combinations and select an optimal feature combination, that is, dominant feature selection (  X  I ), and then we can select the appropriate class number (  X  c )forthe analysis of breathing patterns of multiple patients. Finally, we can predict the respi-ratory motion based on multiple patient interactions, that is, class-based respiratory motion prediction using interactive degree and neuron number selection of RNN. An RNN is a class of neural network with mathematical neural functions and dynamic feedforward/back connections of synaptic weights. We can create a fully connected recurrent neural network by adopting a dynamic internal state of the network and a recursive procedure of past outputs [Mandic and Chambers 2001]. Typically, this network is expressed by three processing layers, that is, the input and hidden and output layers interconnected by adjustable weights [Chen and Chaudhari 2007]. In the input layer, each neuron has input elements u that are mixed with the external inputs, feedback connections, and the unit bias input. Once input elements ( u ) are weighted and then combined into a sum to create an internal activation function of a hidden neuron v , the internal activation of a neuron v i in the hidden layer is fed through a nonlinear activation function to produce the output of the i th neuron y i in the output layer.

In an RNN architecture, feedback connections provide delayed outputs to hidden and output neurons, and these delayed outputs are recursively fed into the network input vector u ( k ). Due to this recursive function, a variety of input elements including noisy internal/external input data and filtered data from network outputs exist at each time instant k so that the input history can potentially improve the processing performance of the network in comparison to feedforward networks. Accordingly, an RNN has a strong capability to process impaired signals, not only an additive white Gaussian noise environment, but also in a highly fluctuating noisy condition over time. We propose to use this network to predict respiratory motions that are mixed with uncertain and irregular breathing patterns. The typical recurrent training algorithm based on gradient descent slowly converges to find a good solution, but it may be inefficient for successive estimations of gradients due to the computational expense [Puskorius and Feldkamp 1994]. We may compensate for such a computational limitation by importing the supervised training of a recurrent network, where recursive information coming from the training data is used for the first iteration of the learning process. That is the basic idea of the Kalman filter [Haykin 2009].

We denote vectors w ( k ) as the weights of entire network, v ( k ) as the recurrent activ-ities inside the network, and u ( k ) as the input signal applied to the network at time k . Here, the system state model and the measurement model of the recurrent network can be expressed using predefined vectors with the process and measurement noise, respectively. We show the supervised-training feedback system of the recurrent net-work using EKF in Figure 1. In this training approach, EKF can lead the actual output vector y ( k ) of the network on the innovation and weight update processes, where the innovation process  X  ( k ) is expressed by the desired response d ( k ) and its estimation, and the weight update process w ( k ) is expressed by the previous weight vector w ( k  X  1) and Kalman gain G ( k ) denoting an integral part of the EKF algorithm. We show the hat symbol ( X ) for predicted or filtered estimate vectors.

Note that in Figure 1, the recurrent network produces the actual output vector y ( k ) resulting from the input vector u ( k ) using the nonlinear measure model, including the internal activation v ( k ) and measurement noise r ( k ). In summary, RNN executes in the supervised-training part of the prediction, whereas EKF executes in the part of the correction with predicted or filtered estimation. We may use this supervised-training method for a particular purpose of training continuous respiratory motion datasets with multiple patient interaction. For the respiratory motion prediction, we propose using a supervised-training feedback system, as shown in Figure 1. The computational complexity of the EKF depends on the requirement capacity to store and update the filtering-error covariance matrix. If an RNN has p output nodes and s weights, the asymptotic growth rate for the compu-tational complexity and storage requirement of the network would be proportional to output nodes ( p ) and weights to the second power ( s 2 ). Here, output nodes and weights correspond to the patient number for predicting the respiratory motion and the state number for the prediction process. For large weights s , we may need highly demand-ing computational resources for these requirements to predict respiratory motions. We may partially release such requirements by using the decoupled extended Kalman fil-ter (DEKF) as a practical remedy to overcoming computational limitations with the computational complexity of an order of p  X  (s / p) 2 [Puskorius and Feldkamp 1994; Haykin 2009].

The key idea of the DEKF is to use interactive state estimates of certain weight groups based on the neural node in such a way that the prediction process operates so-called mutually exclusive weight groups in the recurrent network [Puskorius and Feldkamp 1994]. That leads to the impairing of the computational accuracy of predict-ing respiratory motions based on the recurrent network, because it ignores interactions of excluded weight states. Therefore, we propose a prediction process for each patient based on RNN using a coupling matrix, in which we adapt the coupling technique to comprehensively organize state estimates of multiple markers for predicting respira-tory motions. That approach creates multiple recurrent multilayer perceptron (RMLP) as a part of predictive excitation for separate input markers in Figure 2.
In Figure 2, we denote the marker number ( i ) as the designated marker number for the mutually exclusive groups, where an individual RMLP corresponds to each marker that consists of breathing motion vectors (three-dimensional coordinates) with time sequence k . After finishing the first step of the prediction process for each marker, shown at the EKF block for each marker in Figure 2. We can denote these equations as follows. where d i ( k ),  X  ij , y i ,and G CP i ( k ) are the desired response for the linearized system, the coupling degree in the coupling matrix, the RMLP output for each marker, and the Kalman gain matrix for the marker number i , respectively. For the interactive process of multiple markers, we use the coupling degree  X  ij representing the degree to which component ( i ) depend on one another ( j ), as shown at the coupling matrix block in Figure 2. The coupling degree  X  ij and the coupling matrix, with p  X  p matrix, including all components of coupling degree, can be expressed as follows. where p denotes output nodes for each marker in the recurrent network. We may expect combined relationships between marker i and j if the coupling degree  X  ij is close to one, that is, tight coupling, whereas we may expect released relationships if the coupling degree is far from one, that is, loose coupling. With these coupling effects in mind, the prediction system for multiple patients should organize the whole respiratory motion datasets into some specific breathing motions that associate together in a group based on the respiratory patterns. For such associate processes of the multiple patient inter-actions, we would like to analyze respiratory patterns and extract usable prediction parameters which are repeatedly utilized in the training data of a group in a manner going back to the learning process of the respiratory prediction. This section explains the detailed modeling prediction process based on the breathing patterns of multiple patients. The procedure for the interactive prediction consists of the preprocedure (interactive process for multiple patients) and the intraprocedure (prediction and correction process). We show the interactive process for multiple pa-tients in Figure 3.

In the preprocedure, we would like to get the clustering of respiratory motion based on the breathing patterns of the multiple patients. After the clustering, each class can have the prediction parameters (neuron number for prediction and coupling parameters) for each class. The intraprocedure corresponds to the prediction process for each patient in Figure 2. With the prediction parameters of the preprocedure, the intraprocedure can operate to predict the respiratory motion of each patient. Sections 4.1 and 4.2 explain the clustering method for the group, based on breathing patterns and how to find an optimal neuron number of the prediction process for each class, respectively. Figure 3 illustrates the interactive process involved in forming a clustering based on the breathing patterns of multiple patients. For the first step of CNN, we need to clas-sify the breathing patterns of multiple patients. To extract the breathing patterns, we show feature selection metrics in Table I. Murphy and Pokhrel [2009] showed that the breathing stability can be quantified by autocorrelation coefficient and delay time. Respiratory motion signal may be represented by a sinusoidal curve [Vedam et al. 2004] so that each breathing pattern can have variable measurements of breathing signal amplitude, including acceleration, velocity, and standard deviation [Lu et al. 2006b]. The typical vector-oriented feature extraction, exemplified by principal com-ponent analysis (PCA) and multiple linear regressions (MLR), has been widely used [Mu et al. 2010; Atoui et al. 2010]. Table I shows the feature selection metrics for the clustering of breathing patterns. Breathing frequency also showed diversity in indi-viduals [Benchetrit 2000]. We create Table I based on previous existences of breathing features so that the table can be variable. We randomly selected 7,800 sampling frames (five minutes) for the feature extraction with three marker breathing datasets of each patient.

We pick up feature extraction criteria that are currently available for the breathing patterns in the previous works [Murphy and Pokhrel 2009; Vedam et al. 2004; Lu et al. 2006b]. The feature extraction criteria listed in Table I may be duplicated, but we introduce the following discriminant criteria to find out the most reliable feature set, for example, dominant feature vector I = ( I x , I y , I z ), as three coordinate combinations selected from ten feature metrics, where I x , I y ,and I z correspond to each of the ten feature metric values indexed in Table I, so that we can have 10 C 3 ( = 120) feature combination vectors. The feature metrics for the appropriate clustering of breathing patterns have yet to be determined. The objective of this section is to select the effective feature combination metric (  X  I ) from the candidate feature combination vector ( I ). For the selection of the estimated feature metrics, we use the objective function based on clustered degree using within-class scatter ( S W )and between-class scatter ( S B )[Duda et al. 2001; Lu et al. 2008]. The idea behind the objective function is to minimize within-class scatter and to maximize between-class scatter simultaneously so that each patients X  group can be clustered separately.

Here, the S W is proportional to the number of classes ( c ) and the covariance matrix of feature samples based on each class. Accordingly, the S W can be expressed as S W = c feature combination vectors in the i th class. The S B is proportional to the covariance matrix of the mean ( m i ) for the feature combination vector and can be expressed as S vector in the i th class. m i and m are means of the total feature combination vector and the feature combination vector in the i th class, respectively.

Finally, the objective function J based on S W and S B for selecting the optimal feature combination vector can be written as J ( I ,  X  c ) = argmin( S W / S B ), where I is the candidate feature combination vector for breathing patterns clustering based on the given feature selection metrics, and  X  c is the estimated class number to get the minimum value of the objective function. To select the optimal combination experimentally, we calculate the objective function ( J (  X  )) by fixing the candidate feature combination vector ( I )and increasing the class number c (in our simulation from 2 to 7) in the following equation.
With this equation, we can select the estimated feature combination vector (  X  I ) from the candidate feature combination vector ( I ) with the minimum value of Eq. (4). In the experimental Section 4.2, we will show how to select the estimated feature combination vector (  X  I ) with our simulation results, followed by the estimated number of classes as c . After grouping based on the breathing patterns, we find the optimal neuron number for each group using the Fisher Linear Discriminant [Duda et al. 2001]. We can design the RMLP with multiple hidden layers based on the specific application. In addition, we need to find an optimal hidden neuron number to design for multiple layers so that we can make the proper RMLP design to minimize the calculation cost and to maximize the prediction accuracy. The objective of this section is to select the proper neuron number for hidden layers from a set of nD -dimensional samples identical to the filtering-error covariance matrices for each group. After calculating the D -dimensional sample means for each group, we can obtain the optimization objective function J ( g ) based on the Fisher Linear Discriminant as J ( g ) = argmin( S W / S B ), where g is the number of groups in the given samples.

The criterion based on J ( g ) reminds us that the filtering-error covariance matrices within each group should be minimized and the filtering-error covariance matrices between groups should be maximized in the given number [Duda et al. 2001]. With the objective function J ( g ) in mind, we can find the optimized number of group ( g )for the respiratory prediction in the recurrent network in a manner selecting the smallest J (  X  ) as the optimized group number ( g ). We may decide that the proposed prediction method could be more discriminated by comparing the objective function values J (  X  ) as the discriminant degree at the selected ( g ) [Lee et al. 2011]. This value can be incorporated to train recurrent networks and predict respiratory motions of multiple patients for the proposed prediction process. For the prediction accuracy, we would like to change the prediction time horizon. Here, the term prediction time horizon indicates the time interval window between consecu-tive estimates for predicting the next sensory signal. For the comparison of prediction performance, a normalized metric is used, that is, the normalized root mean squared error (NRMSE) between predicted respiratory motions and actual measurements over all the samples in the multiple patient datasets. The metric is dimensionless in nature so that it can make it possible to compare variable prediction accuracy with different time intervals [Murphy and Dieterich 2006; Yu et al. 2011]. A wide range of breathing motions and uneven breathing patterns can impact the prediction accuracy. We would like to use the prediction overshoot as the reference value to judge how many estimated signals lie outside the confidence level. We will show the prediction overshoot for the influence of the inputs, because the confidence level (so-called marginal value) can be determined by a Jacobian matrix of neural network outputs for each patient. Here, the term overshoot denotes some undesirable estimate values of that predicted results exceeding a certain confidence level. We define this tolerance level as the marginal value, which can be inferred from the estimate process of the uncertainty point estimators or predictors [Chryssolouris et al. 1996; Hwang and Ding 1997; Khosravi et al. 2009].

Typical neural network models can be expressed with a nonlinear recurrent function as follows: y ( k ) = ( x , X  ) +  X  , where x is network inputs and  X  is the true weight collections of the network. We assume that the system noise  X  is independent and identically-distributed with a normal distribution. If the least square estimate of  X  is activated with supervised learning, the linear Taylor expansion for the model y ( k ) can be expressed as  X  y ( k ) = ( x , X  ) + T 0 ( x , X  ), where T 0 is the derivative of ( x , X  )with respect to  X  [Khosravi et al. 2009]. We use the standard asymptotic theory to construct marginal values for nonlinear recurrent networks. An approximate marginal value (  X  ) with 100(1  X   X  ) confidence for the linear model  X  y i (k) can be obtained using a t-distribution function, the standard deviation estimator ( X   X  ), and a Jacobian matrix of neural network outputs with respect to weights [Hwang and Ding 1997; Khosravi et al. 2009]. This marginal value can be used to judge how many predictions lie outside the confidence level, and we will show how many overshoots occur in Section 6.5. For the prediction of respiratory motion, we used patient breathing datasets recorded at the Georgetown University CyberKnife treatment facility. Fiducial markers located around the tumor position are often used to act as surrogates for optical signal tracking to provide real-time information. Each breathing recording has breathing datasets of three markers, where each fiducial marker placed on the chest wall continuously records three-dimensional breathing motions at 26Hz sampling frequency using optical tracking devices. That means potential inputs for predicting of respiratory motions are of breathing motion corresponding to the three coordinates.

The total of 130 patients X  breathing recordings was stored in the database with only a patient serial number. No private information with regards to gender, ethnic, or age is given. Each patient has multiple breathing recordings with different timestamps. The breathing recording time for each patient is distributed from 25 minutes to 2.2 hours, with 66 minutes as the average recording time. In Figure 4, we restricted the breath-ing recording times to discrete values with the unit of five minutes. For example, a 61-minute recording time is quantized to 60 minutes for a variable quantity. The fol-lowing figure shows the frequency distribution of 130 patient breathing recordings.
Each patient X  X  recording was used to train and predict respiratory motion. We used five-minute sampling data for the feature extraction. We can derive 120 ( = 10 C 3 ) feature combination vectors, that is, choose three out of the ten features defined in Table I so that we can span three axis vectors corresponding to the features chosen (shown in the next section). As shown in the Figure 5, using results of the minimum value of H ( I ), we can select the combination number [105, 106, 107, 108, 109, 110, 117, 118, 119, 120] corresponding to the estimated feature combination vectors (  X  I ), that is, the feature combinations with breath frequency (BRF), principal component coefficient (PCA), maximum likelihood estimates (MLE), multiple linear regression coefficient (MLR), and standard deviation (STD). This result also confirms that the three chosen axes can provide the distinct discriminate feature distribution.
Now, we would like to choose the class number ( c ) with the minimum value of the objective function ( J ( c )). The figure shows the clustering of the estimated feature com-bination vector (  X  I ) with respect to the class number ( c = 2 ,..., 7). We calculate the objective function value ( J ( c )) with a different class number. The class number ( c = 5) is chosen to minimize the criterion J with the corresponding class.

By increasing the cluster number ( c ), the estimated class number (  X  c ) is selected to get the minimum of the objective function value ( J ( c )). We notice that the objective function has the minimum when c = 5, as the estimated class number (  X  c )to5.Now we can make the clustering with the estimated class number (  X  c = 5). Accordingly, for the clustering with 130 patient datasets, we have made a clustering with the feature combination vector (BRF, PCA, and MLE) and the estimated class number (  X  c = 5). That means 130 patient datasets are placed into five classes, as shown in Figure 6. For the prediction process, each class has prediction parameters, that is, the optimal neuron number for RMLP based on Fisher Linear Discriminant (Section 4.2) and coupling parameters Eq. (3) that can be experimentally derived for each class.

No clinical information about additional physical conditions was available, but all patients had malignant tumor manifestations in the lung. The selected five classes of breathing patterns may not have any correspondences to any physical condition or disease. The optimal cluster selection was made by the proposed criterion to achieve the best prediction performance of the breathing patterns, given the datasets. We have evaluated the estimation of the respiratory motion by comparing the proposed method CNN with the alternative recurrent neural network (RNN). For the RMLP im-plementation of the proposed CNN, we used a multilayer perceptron with two hidden layers, where the first hidden layer is recurrent and the second one is not. Each hidden layer has two hidden neurons that were chosen based on the Fisher Linear Discrimi-nant (Section 4.2). For the alternate RNN analyzed in this study, we used two hidden layers with nine input neurons and one output neuron, where each input neuron is corresponding to one coordinate of three-dimensional position [Murphy and Pokhrel 2009]. For the network training on both methods, we used 3,000 sampling frames with 26 Hz . Figure 7 shows the estimation performance of the respiratory motion, that is, CNN and RNN, including the measurement and error values. The unit of vertical axis in Figure 7 is normalized for the amplitude of the sensor position corresponding to the real measurement dataset range [  X  1 . 7021  X  10 3 ,  X  1 . 6891  X  10 3 ], that is, the max-imum value as 1 and the minimum value as  X  1. As can be seen in Figure 7(a), the proposed method CNN aligns closer to the measurement values than the other values in Figure 7(b). The standard deviation values of CNN and RNN for these specific data with the 200-second recordings are 0.010 and 0.021, respectively. That means CNN reduces the prediction error by as much as two times compared to RNN. Prediction time horizon represents the time interval window for predicting the future sensory signal. For comparison with RNN, we compare the error performance with respect to a variety of prediction time horizons using the normalized root mean squared error (in Section 5.1).

Figure 8 shows the NRMSE values of all the classes with respect to middle (192 ms) and large (500 ms) time prediction. The red symbols for RNN have more errors than the blue symbols for the proposed CNN over all the classes. The NRMSE for CNN was improved in all of the patients except two in class 1 (patient numbers 8 and 86) and three in class 2 (patient numbers 22, 38, and 51). We also show the average error performance for each class in Table II. In the short time prediction (38 ms), all the classes have improved more than 30%. 50% improvement was achieved in classes 3, 4, and 5 of the large time prediction (500 ms). As shown in prediction error of Table II, the proposed CNN works for any five classes, thus there are no particular differences of error among the five classes because the criterion of feature sections in CNN is designed to minimize the error.

To compare the experimental results with other peer studies, we used experimen-tal results of (i) optimized adaptive neural network prediction (O-ANN) [Murphy and Pokhrel 2009] that is individually optimized to each patient, (ii) adaptive lin-ear prediction (ALP) as a benchmark method, and (iii) kernel density estimation-based prediction (KDE) [Ruan 2010] that is a statistical method for estimating the joint probability distribution of the covariate and response variable using kernel density approximation. The NRMSE using (i) O-ANN was applied to the patient breathing data of the CyberKnife treatment facility at Georgetown University, and (ii) ALP and (iii) KDE were applied to patient data acquired with real-time position management, called the RPM system by Varian Medical, Palo Alto, CA. The error performance for these studies can be improved from the standard RNN; the proposed CNN 47.21% (the best improvement), O-ANN 25.27%, ALP 23.79%, and KDE 33.83%, respectively. We would like to evaluate the prediction accuracy with evaluation criteria using the marginal value (  X  ) in Section 5.2. We add and subtract the marginal value from the measurement values so that we can get the upper and lower bounds for each patient; for example, patient DB35 and DB88 shown in Figure 9. Figure 9 shows the prediction overshoots of regular motion (DB35 in class 1) and irregular motion (DB88 in class 5). In the regular breathing patterns of Figure 9(a), the proposed CNN has no prediction overshoot, whereas the overshoot percentage of RNN is more than 40%. In the irregular breathing pattern of Figure 9(b), the figure shows that most estimation values of the proposed CNN are within the upper and lower bounds, whereas some estimation values of RNN lie outside the confidence level. The time index duration out of the overshoot marginal value (  X  ) for this particular patient is 23.22% using CNN and 46.45% using RNN, respectively.

For the prediction overshoot comparison of all 130 patients, we calculated the num-ber of the total frame and overshoot frames for each patient and show the prediction overshoot frames for the proposed CNN and the alternate RNN with respect to all the classes in Figure 10. Figure 10 shows that most of the prediction overshoot numbers for CNN are much smaller than those for RNN over all the patients, even though there are some exceptions, that is, five patients in class 1 (patient numbers 8, 10, 12, 47, and 86), and three patients in class 2 (patient numbers 20, 22, and 38). For five classes among the 130 patients, we calculate the averaged overshoot frames over the total frame with respect to the prediction time horizon, as shown in Table III. As shown in prediction overshoot of Table III, the proposed CNN does not directly address the criterion of over-shoot regarding the class selection among multiple patients; therefore, the larger size of patients may have relatively large overshoot in the particular class. The averaged overshoot frames of RNN are more than 35% overall the classes, whereas the averaged overshoot frames of the proposed CNN are within 13% in the short time prediction. Note that averaged overshoot frames are less than 7% in the short and middle time prediction of classes 3, 4, and 5. Based on Table III, the proposed CNN shows more reliable prediction in comparison with the alternate RNN over all the patients. In this section, we would like to evaluate the computational complexity of the proposed method. For the comparisons of the computational complexity, we calculate the CPU time used for prediction process over all the total frames.

Table IV shows the average CPU time used for computational complexity over all the patients. The proposed method needs more computational time for the prediction process because it is working with three independent RMLPs for each marker, whereas RNN operates with single target datasets. Moreover, the proposed CNN has a coupling matrix for organizing three independent processes for each marker. Even though the proposed CNN required more computational time, the prediction accuracy should com-pensate for the computational complexity. With enough computer power these days, the computer time would probably be reduced to RNN levels within two years. We set the prediction time horizon in this article from 38.46 ms to 500 ms so that any motion could happen within 15 ms on average for the improved prediction. In this article, we proposed a respiratory motion prediction method for multiple patient interactions using EKF for RNN. When the breathing patterns for the multiple patients are available, all the patients can be classified into several classes based on breathing features. After this clustering, appropriate parameter selections with respect to each class, for example, optimal neuron number for the prediction process of the neural net-work and/or interactive (coupling) degree for the multiple breathing information and so forth, could improve prediction accuracy in comparison to the previous prediction method, because the multiple respiratory information does not have identical relation-ships but relationships that closely resemble one another. That means that when the system for respiratory prediction considers the breathing patterns of multiple patients, it can yield a more accurate prediction performance than when it does not.
For the evaluation criteria of prediction, we showed NRMSE (which is a normalized error value between the predicted and actual signal over all the samples) and pre-diction overshoot as the reference value for judging how many signals lie outside the confidence level. Our experimental results reveal that the proposed CNN needs more computational time to process due to the abundant breathing information and the ad-ditional signal processing and correction process for each RMLP. The proposed CNN, however, can improve NRMSE values by 50% in contrast to the RNN. Moreover, the proposed CNN decreases the number of average prediction overshoot values by 8.37%, whereas the RNN generates prediction overshoot values by more than 40% over all the patients.

