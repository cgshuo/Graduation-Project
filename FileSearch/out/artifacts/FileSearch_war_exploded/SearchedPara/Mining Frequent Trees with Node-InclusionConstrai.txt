 Frequent structure mining is one of the most popular way of data mining because of understandability of its analyzed results. The idea of finding frequent patterns is simple and easy, but for massive databases efficient algorithms to do this task are necessary, and it is not trivial to develop such algorithms. After Agrawal and Srikant developed efficient algorithm Apriori , various efficient algorithms have been developed for frequent itemsets [1], subsequences [2], subtrees [3, 10], subgraphs [6] and so on.
 lyze data. In such cases, they want to find frequent structures that satisfy certain constraints. This can be done by selecting structures satisfying the constraints after enumerating all frequent ones, but it is not efficient when a lot of more fre-quent other structures exist. In order to efficiently find the frequent structures satisfying constraints without enumerating unnecessary frequent ones, some al-gorithms have been also developed for itemsets [9] and subsequences [5]. Data we mine is a set of labeled rooted ordered trees, each of which contains just d special nodes labeled a different label belonging to a set of d special labels. Our mining problem is to find all frequent embedded subtrees [10] containing all d special nodes.
 gram that extracts information necessary for some purpose from Web pages. Most wrappers extract necessary information by pattern matching around the information. Wrapper induction, automatic wrapper construction from train-ing data, can be done by finding common patterns around the information in the data. Most Web pages are HTML documents of which tag structures can be represented by DOM-trees, so finding frequent subtrees of DOM-trees con-taining all nodes with necessary information can be used as a kind of wrapper induction methods, though some additional information like contents of the in-formation and distance between nodes are necessary to construct high-precision wrappers [7].
 trees containing all special nodes. Our algorithm is an extension of TreeMiner algorithm proposed by Zaki [10]. We modified TreeMiner algorithm so as to efficiently generate only candidate subtrees satisfying our constraints. We also report mining results obtained by using our algorithm for the problem of find-ing frequent structures containing the name and its reputation of given Ramen (lamian, Chinese noodles in Soup) shops in Web pages collected by a search engine. 2.1 Notions and Notations In this paper, all trees we deal with are labeled ordered trees defined as follows. A rooted tree T =( N, B ) is a connected acyclic graph with a set N of vertices and a set B of directed edges ( u, v )  X  N  X  N that represent parent-child relation, which satisfies the condition that every vertex but just one vertex ( root )hasjust one parent vertex. For a tree, a vertex and an edge are called a node and a branch , respectively. An ordered tree T =( N, B, ) is a rooted tree ( N, B ) with partial order on N representing a sibling relation, where the order is defined just for all the pairs of children having the same parent. Let L be the set of labels. A labeled ordered tree T =( N, B, ,l ) is an ordered tree ( N, B, )of which nodes are labeled by the label function l : N  X  L .
 of the tree, where the passing order of children of the same parent follows order . Note that, in our notation, any node with subscript i represents the node of id i . other partial order  X  ,an ancestor-descendant relation, by extending the relation so as to satisfy reflexivity and transitivity. If nodes t i and t j are not comparable of t i when i&lt;j .
 mum id r among the ids of t  X  X  descendant nodes. Note that l is always t  X  X  id. by starting with null string, appending the label of the node at its first visit, and appending -1 when we backtrack from a child in a depth-first traversal. For example, tree S 2 in Fig. 1 is encoded as We abuse notation and use the same symbol to represent both a tree and its string encoding.
 subtree composed of the nodes of which id is less than k .
 Definition 1. Let T =( N T ,B T , T ,l T ) and S =( N S ,B S , S ,l S ) be labeled ordered trees. Assume that N T and N S are represented as { t 0 ,t 1 , ..., t n  X  1 } and { s { an embedded subtree of T and i is called an embedding mapping . 1. (Label preserving) 2. (Ancestor-descendant relation preserving) 3. (Sibling relation preserving) support 0 &lt; X   X  1 , a subtree S is frequent if the rate of trees in D that have S as an embedded subtree is at least  X  .
 developed an efficient algorithm for this problem. 2.2 Trees with Special Nodes In this paper, we assume that there are d different special labels which are not members of L , and that every tree in D has just d special nodes labeled different special labels.
 Size of a tree is the number of non -special nodes. For example, the size of tree T in Fig. 1 is 4. A size-k prefix of a tree is the subtree composed of k non -special nodes with k smallest ids and all special nodes. For example, trees S 1 and S 2 in Fig. 1 are the size-3 and size-2 prefixes of tree T , respectively.
 Problem 1 (Constrained tree mining problem). For given D and a minimum sup-port  X  , enumerate all frequent subtrees that have all special nodes. Since all embedded subtrees of a frequent subtree are also frequent, enumerating frequent subtrees in size-increasing order reduces candidates, and as a result it is efficient. Zaki X  X  efficient method [10] for enumerating frequent subtrees in size-increasing order is based on a notion of prefix equivalence class . We first describe his method in the next subsection, then propose modified version of the method for the constrained problem. 3.1 Method for the Problem Without Constraints A prefix equivalence class for a size-( k  X  1) tree P in a size-k tree set G , that is denoted by [ P ] G , is the set of size-k trees in G of which size-( k  X  1) prefix is P . We let [ G ] pre denote the set of all prefix equivalence classes. Every tree T  X  [ P ] with the maximum id. The last node of T can be uniquely represented in [ P ] G by a pair ( x, i ) of its label x and id i of its parent node in P , because the node must be the last child of its parent node in order to preserve tree X  X  prefix. removing 1 one of the last two nodes of T are also frequent, and the size-( k  X  1) prefixes of the two nodes coincides with each other, all size-( k + 1) frequent subtrees can be enumerated by joining two size-k frequent subtrees that belong to the same prefix equivalence class. The relation between the last two nodes of size-( k + 1) tree is parent-child relation or not, thus join operator must generate trees of the both relations if possible.
 operator from [ P 1 ] G and [ P 2 ] G are trivially different because their size-( k  X  1) prefixes are preserved. Thus, by applying join operator to every pair of frequent size-k trees in each prefix equivalence class, we can enumerate all size-( k +1) candidates of frequent trees without duplication. 3.2 Method for the Constrained Problem Our method for the constrained tree mining problem is based on the same idea as Zaki X  X  method mentioned above. Only part we have to consider is how to deal with special nodes. P , and the set [ G ] pre of all prefix equivalence classes in G are defined similarly, though the definition of a size-( k  X  1) prefix is different. The prefix equivalence class for tree S 2 in Fig. 1 is the rightmost tree shown in the same figure, which indicates that there are 8 positions for the last node of a tree in the class. The difference from the case without constraints is that the position of the last node of a tree in each class cannot be uniquely determined by its parent node. For example, there are three positions for the last node with its parent node labeled a in the prefix equivalence class for tree S 2 .
 inserted position in the string encoding of its prefix. For example, in the above case, when the last node is between the nodes labeled a and 2, the tree is encoded as  X  X  b 1 -1 -1 x 2 -1 -1 X  and the prefix of its last node is encoded as  X  X  b 1 -1 -1 2 -1 X . In this case, the position of the last node is specified as (4 , 6), which means that the label x is inserted right after the 4th character and -1 is inserted right after the 6th character, where a string begins with the 0th character. Therefore, three positions for the last node with its parent node labeled a is specified as (4 , 4) , (4 , 6) and (6 , 6).
 string encoding of P . We define join operators  X  in and  X  out on two trees in the same prefix equivalence class as follows.
 prefix equivalence class. Proposition 1. Let T be a size-( k +1) tree ( k  X  2 )andlet ( P, ( x, ( i 1 ,j 1 ))) and ( P, ( y, ( i 2 ,j 2 ))) be the trees generated by removing the second last and the last non-special nodes, respectively. Then just one of the following cases holds. Case II ( P, ( x, ( i 1 ,j 1 )))  X  out ( P, ( y, ( i 2 ,j 2 ))) = T and j 1  X  i 2 Proof. Omitted due to space limitation.
 ( T pair of size-k frequent subtrees belonging to the same prefix equivalence class. Proposition 2. Let F k denote the set of all size-k frequent subtrees for k  X  2 . Let
P P Define Proof. Omitted due to space limitation. 4.1 Algorithm ConstrainedTreeMiner algorithm in Fig. 3 enumerates all frequent embedded subtrees containing all special nodes efficiently. Its algorithmic structure is the same as TreeMiner algorithm [10], but its data structure and join operations are different as mentioned in the previous section.
 Enumerate-F 2 described in the next subsection, the algorithm creates the set F 2 of size-2 frequent subtrees and divides it into the set [ F 2 ] pre of its pre-fix equivalence classes while creating the scope-list 2 L ( S )of S  X  F 2 .Foreach [ P ]  X  [ F 2 ] pre , all larger frequent trees having prefix P canbecreatedfrom [ P ]and {L ( S ): S  X  [ P ] } by recursively applying Enumerate-Frequent-Subtrees procedure. In Enumerate-Frequent-Subtrees procedure, one size larger candi-date subtree is created by joining two subtrees S 1 and S 2 with the same prefix P using operators  X  in and  X  out , and frequency counting for the candidate is done by joining elements in L ( S 1 )and L ( S 2 ) similarly as the original TreeMiner algorithm does.
 tree in D is a non-special node for the sake of simplicity. Note that slight mod-ification is necessary to deal with the case that the least common ancestor is a special node. 4.2 Procedure Enumerate-F 2 Procedure Enumerate-F 2 , which creates the set F 2 of size-2 frequent subtrees and scope-lists for its elements, is the following process for each tree T in D . (See Fig. 4 for examples of each step.) After the execution of this process, [ F 2 ] pre is constructed by selecting all prefix equivalence classes for frequent size-2 trees. Note that F 1 is also constructed by selecting all prefixes for which the prefix equivalence classes have at least  X  X insup X  different trees.
 Step 0 Obtain the paths p i from the root node to each special node labeled i Step 1 Create a subtree U composed of all the paths p 1 ,p 2 , ..., p d .Letaone-Step 2 Create an embedded subtree S of U composed of the root node and all Step 3 Attach insertable position ( s u ,e u )for S to each node u of U . Insertable Step 4 For all node t h in T , do the followings. Let t i k be the least ancestor of t h We conducted an experiment of extracting common structures from DOM-trees of HTML documents. The HTML documents we used in our experiment are Web pages containing the information about a given Ramen (lamian, Chinese noodles in Soup) Shop. Among the most popular 100 Ramen-shops introduced in a popular local town information magazine 3 , we selected the most popular 10 Ramen shops with more than 15 Web pages retrieved by keyword search 4 using a shop name and its telephone number. Totally 301 pages were retrieved and we used 189 pages of them that contain the reputation about a target shop. For each DOM-tree of these 189 pages, we set a name node to the text node containing a target shop name and set a reputation node to the least common ancestor node 5 of the text nodes whose text contains the target reputation. We extracted one tree for one name node, so more than one trees might be extracted from one page. A tree in our experimental data is the subtree of which root is the least common ancestor (LCA) of two special nodes, a name node and a reputation node. The reason why we did not use the whole tree is that we did not want to extract trivial frequent structures like  X  X tml title -1 body  X  X  X  -1 X  that are common to all HTML documents. For each HTML-tag pair of a root node and a reputation node that appears at least 10 times, we applied our algorithm to enumerating all frequent subtrees containing all special nodes.
 shown in Fig. 5. Note that a maximal frequent subtree is a subtree such that its any super-tree is not frequent. Nodes corresponding to the tags with suffixes  X (1) X  and  X (2) X  are a name node and a reputation node, respectively. When the LCA tag of special nodes is  X  X able X ,  X  X r X  or  X  X body X , trivial patterns were enumerated except  X  X able img -1 #text(1) -1 tr td #text(2) -1 -1 -1 X , a pattern that matches DOM-trees of pages using a small image at the beginning of each item. When the LCA tag of special nodes is  X  X ody X ,  X  X d X  or  X  X  X , most pages contain  X  X r X  tag between a shop name and its reputation. When the LCA tag of special nodes is  X  X tml X , the pages contain information of only one shop, and from an enumerated pattern  X  X tml head meta -1 title #text(1) -1 -1 -1 body table td img -1 -1 #text(2) -1 -1 -1 X , we know that most reputations are placed in a table with a image. Structures found in our experiment appear to be too general to specify the place of necessary information. To construct a wrapper, other features of HTML documents like contents of the information and distance between nodes should be additionally used. We have developed such combined method using simpler patterns (path sequences) and text classification [7], which is able to extract nec-essary information from arbitrary Web pages retrieved by a search engine, while most conventional wrappers can do only from the pages in the same site as the training pages. Patterns extracted by ConstrainedTreeMiner possibly improve performance of the combined method in some cases.

