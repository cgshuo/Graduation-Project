 The analysis of large-scale Electrical Medical Records (EMRs) has the potential to develop and optimize clinical treatment regimens. A treatment regimen usually includes a series of doctor orders containing rich temporal and heterogeneous information. However, in many existing studies, a doctor order is simplified as an event code and a treatment record is simplified as a code sequence. Thus, the information in-herent in doctor orders is not fully used for in-depth analysis. In this paper, we aim at exploiting the rich information in doctor orders and developing data-driven approaches for im-proving clinical treatments. To this end, we first propose a novel method to measure the similarities between treatment records with consideration of sequential and multifaceted information in doctor orders. Then, we propose an efficient density-based clustering algorithm to summarize large-scale treatment records, and extract a semantic representation of each treatment cluster. Finally, we develop a unified frame-work to evaluate the discovered treatment regimens, and find the most effective treatment regimen for new patients. In the empirical study, we validate our methods with EMRs of 27,678 patients from 14 hospitals. The results show that: 1) Our method can successfully extract typical treatment regimens from large-scale treatment records. The extracted treatment regimens are intuitive and provide managerial im-plications for treatment regimen design and optimization. 2) By recommending the most effective treatment regimens, the total cure rate in our data improves from 19.89% to 21.28%, and the effective rate increases up to 98.29%.  X  Corresponding Author  X  Information systems  X  Data mining;  X  Applied com-puting  X  Health care information systems; Treatment Regimen; Treatment Recommendation; Electronic Medical Records; Temporal Sets.
The availability of massive Electronic Medical Records (EMRs) has enabled a new paradigm for optimizing health-care practices. Indeed, it becomes a key to success to im-prove health and treat disease by exploring the EMRs data. There are various successful examples, such as health surveil-lance, risk assessment, disease diagnosis, and treatment plan-ning. In particular, the White House X  X  Precision Medicine Initiative will be a data-driven enterprise, using health data of a million or more Americans to catalyze a new era of data-based and more precise medical treatment.

While there are tremendous interests in exploiting EMRs data for improving medical treatment, what have been ob-tained from the analysis of EMRs data is far less than what EMRs can provide [8]. According to [16], one reason is that a patient X  X  outcome is influenced by a lot of factors, such as the age and gender of the patient, disease severity, and treat-ment received. Although EMRs data contain comprehensive information about the patients, diagnosis, and treatments, there is no consensus framework for integrating all the re-lated factors for advanced data modeling. Moreover, EMRs data are heterogeneous and longitudinal in nature. For ex-ample, a treatment record is series of doctor orders, where each doctor order usually consists of medicine name, deliv-ery route, dosage, starting time, and ending time. 1 Overall, it is a non-trivial challenge to analyze the large-scale and complex EMRs data to extract healthcare knowledge and facilitate decision-making in treatment practices.
The definition of doctor order will be given in Section 2.
To this end, in this paper, we focus on two problems: 1) identifying typical treatment regimens from large-scale treatment records; and 2) quantitatively measuring the ef-fectiveness of a typical treatment regimen for a specified patient cohort. Our motivation is that the typical treat-ment regimens are usually used as prototypes when a clini-cal doctor designs the personalized treatment plan for a new patient. As a result, the automatic identification and eval-uation of the typical treatment regimens are essentially im-portant to support the diagnostic and treatment decisions, and ultimately improve the treatment effective rate and the cure rate . The identified typical treatment regimens are also helpful for healthcare researchers and clinical doctors to de-velop new treatment regimens.

To address the aforementioned challenges in identifying and evaluating the typical treatment regimens from the com-plex EMRs data, first, we need an effective method to mea-sure the similarity between treatment records containing se-quential and multifaceted information in doctor orders. Sec-ond, based on the similarity measurements between treat-ment records, we need to group the treatment records to identify the treatment regimens. At the same time, to make the results understandable to the doctors and the patients, we need to extract semantically meaningful descriptions of treatment regimen clusters. In the literature, though many clustering algorithms have been developed, most of the pre-vious efforts focus on assigning each object with a cluster label rather than extracting a semantic description for each cluster [7]. Finally, we also need to estimate the treatment outcome of a typical treatment regimen for a specified pa-tient cohort. As mentioned above, the treatment outcome depends on not only the treatment plans but also other fac-tors, therefore the treatment outcome of the same treatment regimen are often different for different patients. It is nec-essary to develop a unified framework to measure the treat-ment outcome by combining different sources of information in the EMRs data.

Our solution to the challenges and our main contribution in this paper are listed as follows:
In summary, in terms of applications, our method can help the medical decision-making and improve cure and treat-ment effective rates through personalized typical treatment regimen recommendation. In terms of theoretical contribu-tions, the developed similarity measure and semantic density-based clustering for complex heterogeneous and longitudinal data is not hardwired with EMR data hence also applica-ble for other applications. Also, the unified framework for evaluating the treatment outcomes with control factors is a general framework for outcome evaluation in healthcare studies. The framework is also flexible to include more fac-tors if available.
Electronic Medical Records (EMRs) usually contain five categories of information of patients. They are demographic information, diagnostic information, laboratory indicators, doctor orders, and outcomes.

Definition 1 Demographic Information Demographic information is recorded when a patient visits a hospital, which includes the age, gender, address, race and ethnicity, education, and other information of a patient. These in-formation plays an important role in clinical decisions, e.g., therapeutic regimen design and dosage selection. The de-mographic information of a patient can be formalized as
Definition 2 Diagnostic Information Diagnostic in-formation is given by doctors. It consists of disease names and severity of the diseases. Considering a patient (espe-cially aged patient) may suffer from multiple health prob-lems. Diagnostic information can be represented by
Definition 3 Doctor Order An doctor order is a med-ical prescription, which is implemented by a physician or other qualified health care practitioner in the form of in-structions that govern the plan of care for a patient. A doctor order can be represented as where O DN represents the used drug name, O Delivery is the delivery route, which can be by  X  X ntravenous injection X  (IV),  X  X ntramuscular X  (IM),  X  X ral X  (Per os, PO), and so on. O Dose is the dosage each time, O Freq indicates how many times per day. O StartT and O EndT provides the active time of the or-der. For example, a doctor order { Aspirin,PO, 100 , 3 , 4 , 6 } means that the medicine Aspirin is delivered by oral route, 100mg each time (assume the unit is  X  X g X ), three times per day, the order acts from 4-th day to 6-th day.
 An order can be rewritten as order X  X  lasting days, d O = O EndT  X  O StartT + 1. For the simplicity of representation, we define then an order can be simply represented as
Definition 4 Treatment A treatment of a patient is a series of doctor orders related with the patient, which can be represented as where t T 1 is the first treatment day, and t T d T is the last treat-ment day. The treatment lasting d T days. OS k represents the set of orders happened at k -th treatment day, which is OS k = { O k, 1 ,  X  X  X  ,O k,m k } , m k is the number of active orders in k -th treatment day t T k .

Given a series of doctor orders, we can obtain the treat-ment of the patient by where unique () is to eliminate the repeated elements in a set, n is the number of orders related with the patient.
Considering a treatment is often divided into different pe-riods (called treatment courses) in clinical practice, a treat-ment can be rewritten as where a period is defined as Period q = [ q Start ,q End ], then A tilde is added above the logic operation  X  , which means we not only get the union set of OS q Start to OS q End also record the frequency of every O , two O s can be merged if and only if all the elements O DN ,O Delivery ,O Dose ,O are identical. Therefore, OSP q is a set of quintuples. We use O 0 to indicate a quintuple, The symbol prime is used to make the quintuple different from the O defined previously. Finally, a OSP q can be sim-ply represented by where n q is the number of O 0 quintuples.

In order to be easily understood, an example is given, assume a treatment duration is divided into five periods, the first 24 hours, 2-3 days, 4-7 days, 8-14 days, 15th day to the end, which is T = { OSP 1 ,OSP 2 ,  X  X  X  ,OSP 5 } , ev-ery OSP q contains a number of medicine quintuples, each quintuple corresponds to a doctor order that records the medicine name, delivery route, dosage, frequency per day, and repeating times during the q -th period.

Definition 5 Outcome Outcome is evaluated and pre-sented by doctors when a patient leaves hospital. An out-come of a patient can be  X  X ured X ,  X  X mproved X ,  X  X neffective X , or  X  X ead X . We use R to represent the outcome of a patient in this paper.
 Figure 1 illustrates the five categories of information in EMRs. Laboratory indicators are mainly used for judging the severity of disease or evaluating a patient X  X  final out-come, which can be implied by diagnostic information or the outcome, so which are not included in the following model. A treatment of a patient is derived from all the doctor or-ders of the patient, which is the object studied in this paper. Figure 1: Illustration of five categories of informa-tion in EMRs In the following model, the five categories of information are divided into three groups: demographic information and diagnosis information are used as preconditions, treatment consisted of doctor orders are the studied control variable, outcome is used as target.
In this section, we introduce the detail of the proposed methods. Our work consists of four steps: 1) computing sim-ilarities between treatments, 2) clustering treatments, 3) ex-tracting typical treatment regimens from treatment clusters, and 4) treatment regimen recommendation. A treatment de-fined in this paper is much more complex than previously studied ones, which poses non-trivial challenge to similarity measurement and typical treatment extraction. Large vol-ume of EMRs requires efficient clustering algorithm. A lot of related factors are related with outcomes, which means the recommendation should take both preconditions (like age, gender, disease severity) and treatments into consideration. Therefore, we proposed novel methods in each step.
Temporal data is usually defined as recorded information with time stamp. From this perspective, a time series is a set of of real values with time stamp, temporal events are a series of nominal terms with time stamp. In a medical treat-ment, the recorded information includes not only nominal terms like medicine name, delivery route, but also figures like dosage, frequency per day, and repeated times, so the recorded information in a medical treatment are heteroge-neous. The time stamp is also more complex than previously studied ones as it records both starting and ending time. In this case, how to compute similarity between two treatments becomes a challenging problem.

According to section 2, a medical treatment can be divided into different periods and represented as Therefore, the similarity of two treatments can be defined as weighted average of similarities in different periods, where p is the number of periods,  X  s q ( i,j ) is the similarity of OSP iq and OSP jq , which is the similarity of two treatments in q -th period.

Each OSP contains a number of quintuples, where a quin-tuple consists of medicine name, delivery route, dosage, fre-quency, and repeated times. In order to be easily under-stood, we present a toy example of OSP iq and OSP jq Table 1 and 2.

In order to define similarity between OSP iq and OSP jq , we have to develop a method which can compute similar-ity between two such tables. As each table consists of some quintuples (each column is a quintuple), we should first de-fine similarity between two quintuples. OSP iqg is used to represent g -th quintuple in OSP iq , and OSP jqh is used to represent h -th quintuple in OSP jq , then the similarity be-tween OSP iqg and OSP jqh is defined as following:
Firstly, the similarity between OSP iqg and OSP jqh is de-termined by the Drug Names (we use DN for short), if the Drug Names of two quintuples are same, then delivery route, dosage, and frequency per day are considered in a further step; otherwise, the similarity of two quintuples is set 0. Therefore, the similarity of OSP iqg and OSP jqh contains a multiplying term  X  ( DN iqg ,DN jqh ), which equals 1 if DN and DN jqh are the same, and equals 0 otherwise.

Secondly, the delivery (we use DE for short) should be taken into account. The similarity between two deliveries is also described by  X  (  X  ,  X  ) function, which is 1 if two deliveries are the same, and equals 0 otherwise.

Lastly, dosage and frequency per day also has large impact on the treatment effect. We use Dosage-per-Day ( DD ) to describe the similarity in dosage of two quintuples. The DD is defined as O Dose  X  O Freq . The similarity in Dose-per-Day ( DD ) is
To sum up, similarity between OSP iqg and OSP jqh is fi-nally defined as s where the denominator 2 is to ensure the value of similarity drops in [0,1].

After getting similarities between two quintuples like OSP and OSP jqh , the similarity between OSP iq and OSP jq essentially a similarity between two complex sets. Different from previous problems, 1) the appearance times of elements in a set and 2) the similarities between elements, should be taken into account. For example, C 1 = { a,a,a,c,d,d } and C 2 = { a,a,b,b } are two such complex sets, the similarities between elements are given as s ( a,a ) = 1 . 0, s ( a,b ) = 0 . 2, how to define similarity of C 1 and C 2 ? To the best of our knowledge, this problem has not been studied ever before. In this paper, we propose a general method for computing similarity between two such complex sets.

Without loss of generality, we still define s However, the | C 1  X  C 2 | is redefined in this paper, which is where s e gh represents similarity between two elements, A = { a gh } is obtained by solving f h is the appearance frequency of h -th element in set C and f 2 g is that of g -th element in set C 2 . The above formula indicates that A is obtained by allocating the frequencies of elements into a two dimensional table with the goal of maximizing the same part of two sets, therefore A is called allocation matrix.
 Algorithm 1 SetAllo ( S e , f 1 , f 2 ) 1: A = 0 , L = 1 ; 3: ( g,h ) = arg max 8: end
Algorithm 1 presents a greedy algorithm we proposed for solving optimization problem (5), which is guaranteed to get optimal solution.

Combing the above definition and equation (2)  X  (5), sim-ilarity between OSP iq and OSP jq is finally defined as  X  s q ( i,j ) = where f iqg is the repetition times of g -th order in q -th pe-riod of treatment i , { a ijqgh } is the allocation matrix for the computing of | OSP iq  X  OSP jq | .

It X  X  not difficult to prove that the similarity  X  s the following properties: 1) The value of  X  s q ( i,j ) is from 0 to 1; 2) Symmetry. For any i and j ,  X  s q ( i,j ) =  X  s q ( j,i ); 3) Self-similarity.  X  s q ( i,j ) = 1, if and only if OSP the equal sign indicates the two sets contains same elements and the frequencies of elements are also the same.

It can be easily inferred that similarity of two treatments s ( i,j ) also holds the three properties. we only present the proof of property 3 here. s ( i,j ) = 1 means  X  s for each q . That is OSP iq = OSP jq for each q . If two treatments they have same OSP in each period, then the two treatments are same. Therefore, s ( i,j ) = 1 if and only if T i = T j .
The goal of this paper is to extract effective typical treat-ment regimens from EMRs. After getting similarities be-tween treatments, we should first divide all treatments into several clusters, and then extract a typical treatment regi-men from each cluster. Clustering is a technique of parti-tioning a set of objects into multiple groups (called clusters) so that objects in the same cluster are more similar to each other than to those in other clusters [5]. In this section, a Map Reduce enhanced Density Peaks based Clustering (MRDPC) is proposed to accomplish this task.

Our method derives from a recently proposed exemplar-based clustering algorithm [18], which is called Density Peaks based Clustering (DPC). The advantage of DPC is that it can discover clusters with complex shapes, while traditional exemplar-based clustering algorithms can only find spheri-cal clusters. In DPC, two indicators are computed for each object: 1) local density  X  and 2) minimum distance (or max-imum similarity) between the object and any other object with higher local density  X  , where  X  is defined as where  X  ( x ) = 1 if x &gt; 0 and  X  ( x ) = 0 otherwise, s cutoff similarity. The meaning of  X  i is to count the number of objects in object i  X  X  s c -neighborhood.

The second indicator  X  is defined as
Objects with larger  X  and lower  X  values are viewed as ex-emplars. The intuition is that exemplars are the points that they have the highest density in a relative large range. Af-ter identifying exemplars, clustering result can be obtained according to exemplars.

Besides the advantage of discovering clusters with com-plex shapes, DPC is also an efficient clustering algorithm. Even so, DPC can not be directly used in this task. As we mentioned earlier, one of the most well known challenges of mining EMRs is the large volume of patients it records. Image there are 10,000 patients in EMRs, the scale of simi-larity matrix can reach 100 million. Such similarity matrix is difficult to store and deal with. Additionally, the com-putation of similarity matrix will also takes a lot of time and space. In this case, a clustering algorithm which can work with incomplete similarity information becomes very important. The proposed MRDPC is such a clustering algo-rithm. In MRDPC, the total N patients are first randomly divided into m parts, DPC is implemented on each part to get k potential exemplars; then a partial similarity matrix is obtained by computing similarities of selected potential exemplars and all objects, the scale of which is mk  X  N ; Partial DPC (PDPC) is used to determine K final exem-plars according to the partial similarity matrix.
 Algorithm 2 MRDPC ( T , m , k , K ) 1: Divide T into m parts randomly; 2: for g from 1 to m do 7: end 9: end 12: for i  X  PE do 15: end 17: for each i 6 X  E 18: if i  X  PE do 22: end ;
Algorithm 2 presents the proposed MRDPC method. N treatments are divided in step 1, potential exemplars are obtained in step 10. Then, step 11 computes the partial similarity matrix, and step 12  X  16 identify final exemplars from potential exemplar set. Finally, step 17  X  22 assign a cluster label for each treatment.
 We also define the popularity of a treatment cluster as where  X  ( x,y ) = 1 if x = y ,  X  ( x,y ) = 0, otherwise; N is the number of treatments studied.
In most of the previous applications of exemplar-based clustering, an exemplar can be directly used to describe the corresponding cluster. However, a treatment can vary in many different directions as a complex temporal and het-erogeneous data set, which makes a single object (even the object is an exemplar) can not well describe the cluster it be-longs to. In this case, we define the core area of a treatment cluster and extract a semantic description of each treatment cluster by its dense core.

The dense core of a cluster is constructed by k -nearest neighbors of its exemplar. Therefore, a dense core can be represented by a set where e i is the exemplar of i -th cluster,  X  i is the similarity of the exemplar with its k -th nearest neighbor.

In order to extract typical treatment regimen from a dense core, we define the support of a drug in a specified period (e.g., q ) of a treatment regimen (e.g., i ), which is where  X  ( Drug,OSP ) = 1 if Drug is used in OSP ( Drug  X  OSP ),  X  ( Drug,OSP ) = 0 otherwise.

According to formula (11), we can select the drugs used in a specified period of a treatment regimen, which is where  X  is a threshold defined aforehand.

After knowing the main medicines used in a specified pe-riod of a treatment regimen, we make clear the usages of drugs, e.g., deliveries, dosages, lasting days in the period. Therefore, we compute support of Dosage and Administra-tion ( DA ) for every drug, Support iqk ( DA ) = where DA is a triple consists of delivery route, dosage and lasting days of a order.

Based on the clustering result obtained by the method in-troduced in the previous subsection, formula (10) defines a dense core for each treatment cluster. Then, formula (11)  X  (13) extracts a typical treatment regimen from each dense core. A typical treatment regimen includes the names of medicines used in a specified period, the dosages, the de-livery roues, and lasting how many days.
One of the most challenging problem in automatic treat-ment regimen recommendation is how to evaluate a treat-ment regimen, which is because that 1) the care outcome is actually affected by a lot of factors, 2) for different patient cohorts, the most effective typical treatment regimen may be different.
 Figure 2: A framework for treatment regimen rec-ommendation.

In this paper, we propose a general framework to overcome this problem. Figure 2 presents the framework. Five cate-gories of information are recorded in EMRs, the laboratory indicators are mainly used to judge disease severity or help to evaluate outcome, which are implied in diagnostic infor-mation and outcome. So four kinds of medical information are used in our model.
 Doctor orders are mainly used to generate treatments. Then similarities between treatments are computed. Based on the similarities, MRDPC is used to cluster the treat-ments. After clustering, a typical treatment regimen is ex-tracted from each treatment cluster.

We also divide patients into different groups according to demographic information, diagnostic information and out-comes, which is realized by a decision tree model. The pa-tients in a same leaf node is defined as a patient cohort, which means these patients should have had the same out-come with respect to preconditions like age, gender, ..., and disease severity.

For a specified patient cohort, we observe how many typ-ical treatment regimens have been used on the patients in this cohort, and then figure out which treatment regimen can result in the highest effective rate. This framework com-bines a lot of information recorded in EMRs together, which can evaluate the effectiveness of a treatment regimen on a patient cohort comprehensively.
In this section, we test our methods by experiments on real-world EMRs data. We first present a brief description of the studied data set, then extract typical treatment regimens from the large-scale treatment records. A comprehensive validation of our results is given with the data of patients from multiple hospitals.
The EMRs data used in this paper are collected from Hos-pital Information Systems (HIS) of 14 Grade Three Class A (G3CA) hospitals, where G3CA is a certification for the best general public hospitals in China. The 14 hospitals locate in seven cities: Beijing and Shijiazhuang in north China, Shenzhen in south China, Jinan in east China, Changchun in northeast China, Fuzhou in southeast of China, and Xi X  X n in northwest of China.

The methods proposed in this paper can be used to dis-cover and recommend treatment regimens for various dis-eases. To illustrate and test our methods, we focus on the patients with cerebral infarction disease, which is one of the most common diseases in China today. For a cerebral in-farction patient, five kinds of information are recorded: 1) demographic information, 2) diagnostic information, 3) doc-tor orders, 4) clinical laboratory indicators, and 5) treatment outcome. The possible treatment outcome of a cerebral pa-tient can be:  X  X ured X ,  X  X mproved X ,  X  X neffective X , or  X  X ead X . Different kinds of information are associated together by unique patient IDs.

After collecting the EMRs, clinical doctors in China Academy of Chinese Medical Sciences preprocessed the data, they re-moved the erroneous records and unified the diagnostic and medicine names. Finally, we have demographic information for 27 , 678 cerebral infarction patients, and 28 , 659 unique patient IDs are found with doctor orders. 27 , 427 patients of them have both demographic and doctor order information. In the following, we extract the typical treatment regimens of cerebral infarction from doctor orders of 28 , 659 patients. The total number of doctor orders is 1 , 007 , 057. In the doctor orders, 1 , 090 medicines have been used. However, many of them are used to treat other diseases. For example, most of the cerebral infarction patients are aged people and many of them are suffering from multiple diseases at the same time. Therefore, clinical doctors helped us to select 138 medicines that are most relevant to cerebral infarction to better validate our results. We have 363 , 674 doctor orders containing the selected medicines, nearly 13 doctor orders per patient.

As discussed in Section 2, we construct the treatment record for each patient, and each treatment record is fur-ther divided into four periods. Indeed, for cerebral infarc-tion, the treatment in the first two weeks is most responsible for the treatment result, especially the first 24 hours. There-fore, the four treatment periods are: the first 24 hours, 2-3 days, 4-7 days, and 8-14 days. The weights of different peri-ods in computing similarity between treatment records are w = (0 . 4 0 . 2 0 . 2 0 . 2) in Equation (1).
 All the computed similarities can form a matrix of size N  X  N , where N is the number of patients with treatment records. As mentioned above, we have N = 28 , 659, so the scale of similarity matrix is quite large. To further improve the efficiency of treatment clustering for the treatment reg-imen discovery, we use the Map-Reduce enhanced Density Peaks based Clustering method (MRDPC) proposed in Sec-tion 3.2. First, all the treatment records are randomly di-vided into 10 parts, and the Density Peaks based Clustering (DPC) is used to select 100 potential exemplars from each part. Second, the similarities between 10  X  100 potential ex-emplars and all the original treatment records are computed, and the Partial Density Peaks based Clustering (PDPC) is used to find the final exemplar treatments.

Our method divided the N treatment records into four clusters, where each treatment cluster corresponds to a typ-ical treatment regimen. In order to extract a semantic de-scription of each typical treatment regimen, we identify the dense core in each treatment cluster according to Equation (10) and the frequently used medicines in the doctor orders by Equation (11).

Figure 3 illustrates the four extracted typical treatment regimens for cerebral infarction. The four typical treatment regimens are different from each other with different fre-quencies of 9 most popular medicines for this disease. In particular, Typical Treatment Regimen 1 (TTR1) is the most widely used typical treatment regimen with support of 58.33%, where two medicines (Aspirin and Xueshuantong) are used in all of the four treatment periods. Indeed, 100% of patients in the dense core of TTR1 used Aspirin, and more than 80% of them used Xueshuantong. The other medicines are not frequently used in TTR1.

Typical Treatment Regimen 3 (TTR3) is the second pop-ular regimen with support of 24.82%. In comparison with TTR1, Aspirin is still widely used in TTR3, but Xueshuan-tong is replaced by Lumbrokinase and Xuesaitong, which in-dicates Xueshuantong may have the same therapeutic func-tion with Lumbrokinase or Xuesaitong. Though Aspirin is also used in Typical Treatment Regimen 2 (TTR2), its fre-quency is much less than in TTR1 and TTR3. The most popularly used medicines in TTR2 are Shuxuetong, Oza-grel, and Cinepazide. The usages of four medicines in dif-ferent periods are also different. As an emergency medicine, the usage rate of Ozagrel in the first 24 hours is the high-Figure 3: Four typical treatment regimens extracted from EMRs. est, then it declines in the following periods. In Typical Treatment Regimen 4 (TTR4), many medicines are used, especially the usage rates of Edaravone and Alprostadil are higher than the three other typical treatment regimens, but the other six medicines except Aspirin are not used as pop-ular as they are in other treatment regimens.
 Figure 4: An example of an extracted treatment regimen.
Figure 3 compares the typical treatment regimens by the frequencies of medicines. However, a typical treatment reg-imen extracted by our method consists of much more infor-mation than medicine frequencies. Indeed, the daily dosages, deliveries, and active days are all considered in comput-ing similarity between treatment records (see Equation 2). To better show how these medicines are used, we compute Dosage and Administration support for every medicine ac-cording to Equation (13), as shown in Figure 4. We take the third period (4  X  7 days) of TTR2 for example. The first pie shows the different usage manners of Ozagrel, where  X  X V/160/4 X  means the delivery route is intravenous injection (IV), the daily dosage is 160 units, for four days during this period. This usage manner takes 52% support, and is the most common one. The other usage manners of Ozagrel vary mainly in dosage, which can be 80 or 120 units. The usage manners of Cinepazide are almost the same as that of Ozagrel. The most common usage manner of Shuxuetong is  X  X V/6/4 X , which takes 83% support. Aspirin is delivered by  X  X O X  (Per os) instead of  X  X V X .
In Section 3.4, a unified framework is proposed to evalu-ate the effectiveness of the discovered treatment regimens. According to the proposed framework, we first divide the 27 , 678 cerebral infarction patients into homogeneous co-horts by a decision tree. In constructing the decision tree, patients X  demographic information and disease severity are used as independent variables and the treatment outcome is used as dependent variable.

Intuitively, patients in the same leaf node of the con-structed decision tree should have had the same treatment outcome with respect to their physical condition and disease severity. Therefore, for each node, we identify and recom-mend the treatment regimens which can produce the best outcome based on historical records.
 Figure 5: Recommend treatment regimens for two patient cohorts
In our results, there are 36 leaf nodes in the constructed decision tree. Figure 5 presents a visual comparison of four treatments on two cases (leaf node 2 and 17), while Table 3 provides numerical estimates about the cure rate, improved rate, ineffective rate and dead rate obtained by four treat-ment regimens. Specifically, Case 1 includes 4,035 patients in Hospital  X  X 1 X , and Case 2 contains 1,709 patients in hos-pital  X  X 3 X  with  X  X eneral X  severity (relative to  X  X mergency X  and  X  X angerous X  severity). In the first case, most of the patients are cured and improved. TTR4 can result in the highest cure rate and lowest ineffective and dead rate. How-ever, only 0.37% of patients in this group accepted TTR4. Though TTR4 may be effective for the patients under this leaf node, it is not robustly validated. TTR3 with popu-larity of 25.97%, which can produce higher cure rate and lower ineffective and dead rate than TTR1 and TTR2, is the most effective treatment regimen found by our method for the patients in this leaf node.

In Case 2, more than 97% of the patients are diagnosed as  X  X mproved X . Therefore, we mainly compare different treat-ment regimens by the cure, ineffective, and dead rate. Sim-ilarly, TTR4 is not taken into account because of the low popularity. In comparison with Case 1, TTR3 is not the recommended treatment regimen any longer. Indeed, TTR3 is the worst treatment with highest ineffective and dead rate for patients in this case. TTR2 with highest cure rate (two times more than the follower) and lowest dead rate (less than half of the follower) is the most suitable treatment regimen for this patient cohort.
 Table 3: Treatment effects on two patient cohorts. All Patis 54.62 44.34 0.59 0.45 100.00 Patis-T1 54.24 44.55 0.69 0.52 57.25 Patis-T2 53.57 45.32 0.79 0.32 15.64 Patis-T3 56.49 42.94 0.29 0.29 25.97 Patis-T4 60.00 40.00 0.00 0.00 0.37 All Patis 0.23 97.19 0.64 1.93 100.00 Patis-T1 0.00 97.58 0.38 2.04 45.87 Patis-T2 0.79 97.91 0.52 0.79 22.35 Patis-T3 0.19 96.13 1.16 2.51 30.25 Patis-T4 0.00 100.00 0.00 0.00 0.41
The above results show that, our method can recommend an effective treatment regimen to a specified patient cohort for better treatment outcomes. In addition, by comparing the two cases above, we can conclude that, 1) for patients with different physical conditions and disease severities, the most effective treatment regimens are different; 2) the most widely used treatment regimen in clinical, like TTR1, may be not the actually best one; 3) some rarely used treatment regimen may result in even better outcome. These three ob-servations provide important clues for clinical doctors to de-velop new treatment regimens or optimize the present ones.
The previous experiments have shown that our method can extract treatment regimens from EMRs automatically, and recommend the most effective treatment regimen to a specified patient cohort. In the following, we estimate the recommendation effects on all the 27,678 patients from 14 hospitals, in terms of total cure rate and total effective rate.
The total cure rate and total effective rate is defined as where N c and N imp are numbers of patients with cured out-come and improved outcome respectively, N is the number of total patients.
The 27678 patients are divided into 36 patient cohorts according to physical condition and disease severity. We implement our methods on all patient cohorts to find the most effective treatment regimen for each patient cohort. The overall effective rate and cure rate are computed as where  X  r c i and  X  r imp i are expected cure rate and improvement rate of i -th patient cohort, N i is the number of patients in this cohort. The expected cure and improvement rate of a patient cohort are the cure and improvement rate of the patient cohort with the best treatment regimen respectively, where the best treatment regimen for a patient cohort is identified by method shown in Section 4.3.
 Figure 6: Our method can help improve effective rate and cure rate.

Figure 6( a ) demonstrates that, the effective rate of the 27678 patients is promising to be improved from 97.25% to 98.29% by adopting our recommended regimen, while Fig-ure 6( b ) illustrates that the cure rate is promising to be improved from 19.89% to 21.28%. By this experiment, we can conclude that our method can not only extract typical treatment regimens from large-scale EMRs automatically, but also helpful for improving cure and effective rate.
In this section, we review the previous work in the lit-erature related with our work. We will also explain the differences between our methods and the previous ones.
Temporal data mining has become an increasingly hot topic [11, 14]. The key challenge of temporal data mining is to represent the temporal data with flexible and informative structures, which enable easy computation of the similar-ity between temporal sequences, as well as clustering and classification tasks with the sequential data. For continuous time series data, a lot of representation methods and similar-ity measurement methods have been developed [1, 2, 10, 22]. For discrete event sequence data, there have also been recent works with diverse applications [12, 13, 15, 20]. However, a treatment record in this paper is essentially a sequence of doctor orders, which is much more complex than time series and simple event sequence. Therefore, the previous methods are not directly applicable. In this paper, to discover pat-terns from large-scale treatment records, we proposed novel representation and similarity measurement methods for se-quential and multifaceted event sets.

Based on the similarities between treatments, we clustered all treatments into several groups and extracted a typical treatment regimen from each treatment cluster. Cluster-ing has been studied in data mining community for many years, and various of clustering algorithms have been devel-oped [7]. Among them, a popular category suitable for our task of treatment regimen discovery is the exemplar-based clustering [3]. The exemplar-based clustering algorithm first selects a number of exemplars and then assigns the remain-ing objects to their nearest exemplars. However, a disadvan-tage of the exemplar-based clustering is that it can only find spherical clusters. In this paper, due to the temporal and heterogeneous nature of the treatment records, a treatment cluster can be very complicated. Density-Peaks-based Clus-tering (DPC) is a recently proposed exemplar-based cluster-ing algorithm [18], which can discover clusters with complex shapes. Therefore, we derived our clustering method by fur-ther extending the DPC algorithm. In particular, although the original DPC is designed to be efficient, it cannot be di-rectly used if the data size (like number of treatment records in this paper) is truly large. Therefore, a Map-Reduce en-hanced Density Peaks based Clustering (MRDPC) method is presented in this paper, which can efficiently cluster large-volume treatments with huge and incomplete similarity ma-trix. To the best of our knowledge, the MRDPC method has never been discussed in previous literature.

In addition, most of the present clustering algorithms in the literature focus on solely dividing the objects into homo-geneous groups, rare work has been done to extract the se-mantically meaningful descriptions of the identified clusters. Indeed, such semantic extraction from clusters is usually a difficult task, especially for sequential and unstructured data. In this paper, a treatment is much more complex than the objects (or data points) studied in traditional clustering problems. To address this challenge, we extract the seman-tics by constructing a dense core in each exemplar-based cluster. The most similar work to ours is the dense subgraph discovery [9, 17]. However, their work is mainly for discov-ering interesting dense regions, while our work aims at ex-tracting semantic descriptions of clusters. In general sense, frequent pattern mining [4] is also related with our work, but it is not applicable in this study because the treatment records vary in many dimensions, leading to no frequent pat-terns with significant pattern support.

In terms of applications, a lot of recent work has been done in mining the various kinds of EMRs data for action-able insights to improve the quality of healthcare delivery. For example, Zhou et al. [21] proposed PACIFIER method to infer phenotypic pattern from EMRs; Hirano and Tsumoto [6] used occurrence and transition frequency to discover typ-ical order sequences; Liu et al. [12] developed a method to identify most significant and interpretable graphical feature from longitudinal EMRs; Somanchi et al. [19] studied early prediction of cardiac arrest based on demographic informa-tion, hospitalization history, vitals and laboratory measure-ments in patient-level EMRs. However, most of the previ-ous research focused only on part of information recorded by EMRs. In this paper, we would extract typical treatment regimens from treatment records and recommend treatment regimens to new patients according to their demographic as well as diagnostic information. Our work can be deemed a benchmark framework for future healthcare data mining research to integrate all the related factors in EMRs and op-timize the treatment effectiveness based on comprehensive evaluation of the typical treatment options.
In this paper, we investigated how to identify the typical treatment regimens from large-scale treatment records and how to find the most effective treatment regimens for pa-tients. Specifically, we developed an efficient semantic clus-tering algorithm, based on a new method to measure the similarities between treatment records. The new similar-ity measurement and the semantic clustering are applicable for general complex heterogeneous and longitudinal data. Applied on large-scale treatment records, we were able to extract the treatment clusters as the typical treatment regi-mens with semantically meaningful descriptions. Moreover, we designed a unified framework to evaluate the effective-ness of the identified treatment regimens. This framework can recommend the most effective treatment regimens to new patients according to their demographic information and disease severities. Finally, we validated our approach on real-world EMRs data of patients collected from multi-ple hospitals. Experimental results show that our method can improve the treatment cure rate and effective rate. To the best of our knowledge, this work may be the first step towards the automatic development of treatment regimens and treatment recommendations.
This research was partially supported by National Natu-ral Science Foundation of China (71329201, 71171030, and 71421001). Also, it was supported in part by the Rutgers 2015 Chancellor X  X  Seed Grant Program.
 [1] Iyad Batal, Dmitriy Fradkin, James Harrison, Fabian [2] Gustavo E.A.P.A. Batista, Xiaoyue Wang, and [3] Brendan J. Frey and Delbert Dueck. Clustering by [4] Jiawei Han, Hong Cheng, Dong Xin, and Xifeng Yan. [5] Jiawei Han, Micheline Kamber, and Jian Pei. Data [6] Shoji Hirano and Shusaku Tsumoto. Mining typical [7] Anil K. Jain. Data clustering: 50 years beyond [8] Peter B Jensen, Lars Juhl Jensen, and S  X  A  X  yren [9] Victor E. Lee, Ning Ruan, Ruoming Jin, and Charu C. [10] T. Warren Liao. Clustering of time series data: a [11] Weiqiang Lin, Mehmet A. Orgun, and Graham J.
 [12] Chuanren Liu, Fei Wang, Jianying Hu, and Hui Xiong. [13] Chuanren Liu, Kai Zhang, Hui Xiong, Guofei Jiang, [14] Theophano Mitsa. Temporal Data Mining . Chapman [15] Wei Peng, Charles Perng, Tao Li, and Haixun Wang. [16] Adam Perer, Fei Wang, and Jianying Hu. Mining and [17] Lu Qin, Rong-Hua Li, Lijun Chang, and Chengqi [18] Alex Rodriguez and Alessandro Laio. Clustering by [19] Sriram Somanchi, Samrachana Adhikari, Allen Lin, [20] Jingyuan Yang, Chuanren Liu, Mingfei Teng, Hui [21] Jiayu Zhou, Fei Wang, Jianying Hu, and Jieping Ye. [22] Hengshu Zhu, Chuanren Liu, Yong Ge, Hui Xiong,
