 Aryeh Kontorovich karyeh@cs.bgu.ac.il Boaz Nadler boaz.nadler@weizmann.ac.il Roi Weiss roiwei@cs.bgu.ac.il Hidden Markov Models (HMM) are a standard tool in the modeling and analysis of time series with a wide variety of applications. When the number of hidden states is known, the standard method for estimating the HMM parameters from observed data is the Baum-Welch algorithm (Baum et al., 1970). The latter is known to suffer from two serious drawbacks: it tends to converge (i) very slowly and (ii) only to a local max-imum. Indeed, the problem of recovering the param-eters of a general HMM is provably hard, in several distinct senses (Abe &amp; Warmuth, 1992; Lyngs X  &amp; Ped-ersen, 2001; Terwijn, 2002).
 In this paper we consider learning parametric-output HMMs with a finite and known number of hidden states, where the output from each hidden state fol-lows a parametric distribution from a given family. A notable example is a Gaussian HMM, where from each state x , the output is a (possibly multivariate) Gaus-sian, N (  X  x ,  X  x ), typically with unknown  X  x ,  X  x . Main results. We propose a novel approach to learning parametric output HMMs, based on the fol-lowing two insights: (i) in an ergodic HMM, the sta-tionary output is a mixture of distributions from the parametric family, and (ii) given the output parame-ters, or their approximate values, one can efficiently recover the corresponding transition probabilities up to small additive errors.
 Combining these two insights leads to our proposed decoupling approach to learning parametric HMMs. Rather than attempting, as in the Baum-Welch algo-rithm, to jointly estimate both the transition prob-abilities and the output density parameters, we in-stead learn each of them separately. First, given one or several long observed sequences, the HMM out-put parameters are estimated by a general purpose parametric mixture learner, such as the Expectation-Maximization (EM) algorithm. Next, once these pa-rameters are approximately known, we learn the hid-den state transition probabilities by solving a compu-tationally efficient convex quadratic program (QP). The key idea behind our approach is to treat the un-derlying hidden process as if it were sampled indepen-dently from the Markov chain X  X  stationary distribu-tion, and operate only on the empirical distribution of singletons and consecutive pairs. Thus we avoid computing the exact likelihood, which depends on the full sequence, and obtain considerable gains in com-putational efficiency. Under standard assumptions on the Markov chain and on its output probabilities, we prove in Theorem 1 that given the exact output prob-abilities, our estimator for the hidden state transition matrix is asymptotically consistent. Additionally, this estimator is robust to small perturbations in the out-put probabilities (Theorems 2-6).
 Beyond its practical prospects, our proposed approach also sheds light on the theoretical difficulty of the full HMM learning problem: It shows that for parametric-output HMMs the key difficulty is fitting a mixture model , since once its parameters have been accurately estimated, learning the transition matrix can be cast as a convex program. While learning a general mixture is considered a hard problem, recently much progress has been made under various separation conditions on the mixture components, see e.g. Moitra &amp; Valiant (2010); Belkin &amp; Sinha (2010) and references therein. Related work. The problem of estimating HMM parameters from observations has been actively stud-ied since the 1970 X  X , see Capp  X e et al. (2005); Rabiner (1990); Roweis &amp; Ghahramani (1999). While comput-ing the maximum-likelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consis-tent and normally distributed, see Bickel et al. (1998); Chang (1996); Douc &amp; Matias (2001).
 In recent years, there has been a renewed interest in learning HMMs, in particular under assumptions that render the learning problem tractable (Farag  X o &amp; Lu-gosi, 1989; Hsu et al., 2009; Mossel &amp; Roch, 2006; Sid-diqi et al., 2010; Song et al., 2010; Bailly, 2011; Anand-kumar et al., 2012; Balle et al., 2012).
 Additionally, Lakshminarayanan &amp; Raich (2010); Cybenko &amp; Crespi (2011) recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs. These are related to our approach, since with known output probabilities, NNMF reduces to a convex program similar to the one considered here. Hence, our stability and consistency analysis may be relevant to NNMF-based approaches as well.
 Paper outline. In Section 2 we present our problem setup. The HMM learning algorithm appears in Sec-tion 3, and its statistical analysis in Section 4. Section 5 contains some simulation results. Technical details are given in the full version (Kontorovich et al., 2013). Notation. When X  X  X and Y  X  Y take values in a discrete set we abbreviate P ( x ) for Pr( X = x ) and P ( y | x ) for Pr( Y = y | X = x ). When Y  X  Y is continuous-valued, we denote by P ( y | x ) the probabil-ity density function of Y given X .
 For x,w  X  R n , diag( x ) is the n  X  n diagonal matrix with entries x i on its diagonal, x/w is the vector with norm (for w i &gt; 0). The shorthand x . y means x  X  (1 + o (1)) y . Similarly, x . P y means x  X  (1 + o P (1)) y . Finally, for n  X  N , we write [ n ] = { 1 , 2 ,...,n } . Hidden Markov Model. We consider a discrete-time, discrete-space HMMs with n hidden states. The HMM output alphabet, denoted Y , may be either dis-crete or continuous. A parametric-output HMM is characterized by a tuple ( A, F  X  n ,P 0 ) where A is an n  X  n column stochastic matrix, P 0 is the distribution of the initial state and F  X  n = ( f  X  ple of parametrized probability density functions. In the sequel we sometimes write f i instead of f  X  To generate the output sequence of the HMM, first an unobserved Markov sequence of hidden states x = ( x t ) T  X  1 t =0 is generated with the following distribution. where A ij = P ( X t = i | X t  X  1 = j ) are the transition probabilities. Then, each hidden state X t indepen-dently emits an observation Y t  X  Y according to the distribution P ( y t | x t )  X  f x quence y = ( y t ) T  X  1 t =0 has the conditional probability The HMM Learning Problem. Given one or sev-eral HMM output sequences ( Y t ) T  X  1 t =0 , the HMM learn-ing problem is to estimate both the transition matrix A and the parameters of the output distributions F  X  n . The standard approach to learning the parameters of an HMM is to maximize the likelihood As discussed in the Introduction, this problem is in general computationally hard. In practice, neglecting the small effect of the initial distribution P 0 ( x the likelihood, A and F  X  n are usually estimated via the Baum-Welch algorithm, which is computationally slow and only guaranteed to converge to a local maximum. 3.1. A Decoupling Approach In what follows we show that when the output dis-tributions are parametric, we can decouple the HMM learning task into two steps: first learning the output parameters  X  1 ,..., X  n , followed by learning the tran-sition probabilities of the HMM. Under some struc-tural assumptions on the HMM, this decoupling im-plies that the difficulty of learning a parametric-output HMM can be reduced to that of learning a paramet-ric mixture model. Indeed, given (an approximation to) F  X  n  X  X  parameters, we propose an efficient, single-pass, statistically-consistent algorithm for estimating the transition matrix A .
 As an example, consider learning a Gaussian HMM with univariate outputs. While the Baum-Welch ap-proach jointly estimates n 2 + 2 n parameters (the ma-trix A and the parameters  X  i , X  2 i ), our decoupling ap-proach first fits a mixture model with only 3 n param-eters (  X  i , X  i , X  2 i ), and then solves a convex problem for the remaining n 2 entries of the matrix A . While both problems are in general computationally hard, ours has a significantly lower dimensionality for large n . Assumptions. To recover the matrix A and the out-put parameters  X  j we make the following assumptions: (1a) The Markov chain has a unique stationary distri-bution  X  over the n hidden states. Moreover, each hid-den state is recurrent with a frequency bounded away from zero: min k  X  k  X  a 0 for some constant a 0 &gt; 0. (1b) The n  X  n transition matrix A is geometrically ergodic 1 : there exists parameters G &lt;  X  and  X   X  [0 , 1) such that from any initial distribution P 0 (1c) The output parameters of the n states are all dis-tinct:  X  i 6 =  X  j for i 6 = j and the parametric family is identifiable. In addition we assume  X  X bservability X  which will be cast as a full rank condition on specially defined matrices.
 Remarks: Assumption (1a) rules out transient states, whose presence makes it generally impossible to estimate all entries in A from one or a few long observed sequences. Assumption (1b) implies mixing and is used later on to bound the error and the number of samples needed to learn the matrix A. Assumption (1c) is crucial to our approach, which uses the distri-bution of only single and pairs of consecutive observa-tions. If two states i,j had same output parameters, it would be impossible to distinguish between them based on single outputs. 3.2. Learning the output parameters.
 Assumptions (1a,1b) imply that the Markov chain over the hidden states is mixing, and so after only a few time steps, the distribution of X t is nearly stationary. Assuming for simplicity that already X 0 is sampled from the stationary distribution, or alternatively ne-glecting the first few outputs, this implies that each observable Y t is a random realization from the follow-ing parametric mixture model , Hence, given an output sequence ( Y t ) T  X  1 t =0 the output parameters  X  i and the stationary distribution  X  i can be estimated by fitting the mixture model (2) to the observations, typically via the EM algorithm.
 Like its more sophisticated cousin Baum-Welch, the mixture-learning EM algorithm also suffers from lo-cal maxima. Indeed, from a theoretical viewpoint, learning such a mixture model (i.e. the parameters of F  X  n ) is a non-trivial task considered in general to be computationally hard. Nonetheless, under vari-ous separation assumptions, efficient algorithms with rigorous guarantees have been recently proposed (see e.g. Belkin &amp; Sinha (2010)). 2 Note that while these algorithms have polynomial complexity in sample size and output dimension, they are still exponential in the number of mixture components (i.e., in the number of hidden states of the HMM). Hence, these methods do not imply polynomial learnability of parametric-output HMMs.
 In what follows we assume that using some mixture-learning procedure, the output parameters  X  j have been estimated with a relatively small error (say |  X   X  j  X   X  j | = O (1 / where  X  j were estimated from separate observed se-quences of perhaps other HMMs with same output pa-rameters but potentially different stationary distribu-tions, we do not assume that  X  i have been estimated. 3.3. Learning the transition matrix A Next, we describe how to recover the matrix A given either exact or approximate knowledge of the HMM output probabilities. For clarity and completeness, we first give an estimation procedure for the stationary distribution  X  .
 Discrete observations. As a warm-up to the case of continuous outputs, we first consider HMMs with a discrete observation space of size |Y| = m . In this case we can replace F  X  n by an m  X  n column-stochastic matrix B where B ki  X  P ( k | i ) is the probability of observing an output k given that the Markov chain hidden state is i . In what follows, we assume that the size of the output set is larger or equal to the number of hidden states, m  X  n , and that the m  X  n matrix B has full rank n . The latter is the discrete analogue of assumption (1c) mentioned above.
 First note that since the matrix A has a stationary distribution  X  , the process Y t also has a stationary distribution  X  , which by analogy to Eq. (2), is Similarly, the pair ( Y t ,Y t +1 ) has a unique stationary distribution  X  , given by As we shall see below, with a known matrix B , knowl-edge of  X  and  X  suffices to estimate  X  and A . Although  X  and  X  are themselves unknown, they are easily esti-mated from a single pass on the data ( y t ) T  X  1 t =0 : Estimating the stationary distribution  X  . The key idea in our approach is to replace the exact, but complicated and non-convex likelihood function by a  X  X seudo-likelihood X , which treats the hidden state sequence ( X t ) as if they were iid draws from the unknown stationary distribution  X  . The pseudo-likelihood has the advantage of having an easily com-puted global maximum, which, as we show in in Sec-tion 4, yields an asymptotically consistent estimator. Approximating the ( X t ) as iid draws from  X  means that the ( Y t ) are treated as iid draws from  X  = B  X  . Thus, given a sequence ( Y t ) T  X  1 t =0 the pseudo-likelihood for a vector  X  is L ( y 0 ,...,y T  X  1 |  X  ) = Since  X  log( x ) is convex, and both ( Bx ) k and the con-straints are linear in the unknown variables x j , (6) is a convex program, easily solved via standard optimiza-tion methods (Nesterov &amp; Nemirovskii, 1994). However, to facilitate the analysis and to increase the computational efficiency, we consider the asymptotic behavior of the pseudo-likelihood in (6), for T suffi-ciently large so that  X   X  is close to  X  . First, we write Next, assuming that T 1 is sufficiently large to en-sure | ( Bx ) k  X   X   X  k |  X   X  k , we take a second order Taylor expansion of log( Bx ) k in (6). This gives The first term is independent of x , whereas the second term vanishes. Thus, we may approximate (6) by the quadratic program where k x k 2 w = P k w k x 2 k is a weighted ` 2 norm w.r.t. the weight vector w . Eq. (7) is also a convex problem, easily solved via standard optimization techniques. However, let us temporarily ignore the non-negativity constraints x i  X  0 and add a Lagrange multiplier for the equality constraint P x i = 1: min Differentiating with respect to x i yields where W = B | diag(1 /  X   X  ) B . Enforcing the normaliza-tion constraint is equivalent to solving for x  X  = W  X  1 1 and normalizing  X   X  = x  X  / k x  X  k 1 . Note that if all entries of x  X  are positive,  X   X  is the solution of the optimization problem in (7), and we need not invoke a QP solver. Assumptions (1a,1b) that  X  k is bounded away from zero and that the chain is mixing imply that for suf-ficiently large T , all entries of  X   X  will be positive with high probability, see Section 4.
 Estimating the transition matrix A . To estimate A , we consider pairs ( Y t ,Y t +1 ) of consecutive observa-tions. By definition we have that for a single pair, P ( Y t = k,Y t +1 = k 0 ) = X As above, we treat the T  X  1 consecutive pairs ( Y t ,Y t +1 ) as independent of each other, with the hid-den state X t sampled from the stationary distribution  X  . When the output probability matrix B and the stationary distribution  X  are both known, the pseudo-likelihood is given by The resulting estimator is where C kk 0 ij =  X  j B kj B k 0 i . In practice, since  X  is not  X  . Again, (10) is a convex program in A and may be solved by standard constrained convex optimization methods. To obtain a more computationally efficient formulation, let us assume that min k,k 0  X  k,k 0  X  a 2 &gt; 0 (this assumption is removed later, see sec. 4), and that approximate minimization problem is In contrast to the estimation of  X  , where we could ignore the non-negativity constraints, here the con-straints A ij  X  0 are essential, since for realistic HMMs, some entries in A might be strictly zero. Note that if  X   X  =  X  and  X   X  =  X  , the true matrix A satisfies  X  = CA and is the minimizer of (10).

Finally, note that (11) with the standard ` 2 norm and an unknown matrix B is precisely the NNMF func-tional proposed by Lakshminarayanan &amp; Raich (2010). In summary, given one or more output sequences ( y t ) T  X  1 t =0 and an estimate of B, we first make a sin-gle pass over the data and construct the estimators  X   X  and  X   X  , with complexity O ( T ). Then, the stationary distribution  X  is estimated via (9), and its transition matrix A via (11). To estimate A , we first compute the matrix product  X  C |  X  C , with O ( n 4 m 2 ) operations. The resulting QP has size n 2 , and is thus solvable (den Hertog, 1994) in time O ( n 6 )  X  which is dominated by O ( n 4 m 2 ) since m  X  n by assumption. Hence, the over-all time complexity of estimating A is O ( T + n 4 m 2 ). Extension to continuous observations. We now extend the above results to the case of continuous out-puts distributed according to a known parametric fam-ily. Recall that in this case, each hidden state i  X  [ n ] has an associated output probability density f  X  with discrete observations, we assume that an approx-it to construct estimates of  X  and A .
 To this end, we seek analogues of (3) and (4), which relate the observable quantities to the latent ones. This will enable us to construct the appropriate em-pirical estimates and the corresponding quadratic pro-grams, whose solutions will be our estimators  X   X  and  X  A . To handle infinite output alphabets, we map each observation y to an n -dimensional vector  X  ( y ) = ( f  X  1 ( y ) ,...,f  X  n ( y )), whose entries are the likelihood of y from each of the underlying hidden states. As shown below, this allows us to reduce the problem to a dis-crete  X  X bservation X  space which can be solved by the methods introduced in the previous subsection. Estimating the stationary distribution  X  . To obtain an analogue of (3), we define the following vec-tor  X  = E [  X  ( Y )]  X  R n , and matrix K  X  R n  X  n , which play the roles of  X  and B for discrete output alphabets, K ij  X  E [  X  i ( Y ) | X = j ] = With these definitions we have, as in Eq. (3), Thus, given an observed sequence ( y t ) T  X  1 t =0 we construct the empirical estimate and consequently solve the QP In analogy to the discrete case, we assume rank( K ) = n so (15) has a unique solution. Its asymptotic consis-tency and accuracy are discussed in Section 4. Estimating the transition matrix A . Next, fol-lowing the same paradigm we derive an analogue of (4). Bayes rule implies that for stationary chains, We define the matrices  X   X  R n  X  n and F  X  R n  X  n (ana-logues of  X  and B ) as follows. Let Y and Y 0 be two consecutive observations of the HMM, then A simple calculation shows that, as in (4), Since here F plays the role of B, we may call it an effective observation matrix. This suggests estimating A with the same tools used in the discrete case. Thus, given an observed sequence ( y t ) T  X  1 t =0 we construct an empirical estimate  X   X  by where  X  P is given by (16) but with  X  replaced by  X   X  . Consequently we solve the following QP As for the matrix B in the discrete case, to ensure a unique solution to Eq. (20) we assume rank( F ) = n. Remark 1. Instead of (18), we could estimate  X  0 k,k 0  X  E [ f k ( Y ) f k 0 ( Y 0 )] , and recover A from the relation This has the advantage that for many distributions the matrix K can be cast in a closed analytic form. For example, in the Gaussian case, we have whereas F needs to be calculated numerically. Addi-tionally, K does not depend on the stationary distri-bution. The drawback is that in principle, and as sim-ulations suggest, accurately estimating  X  0 may require many more samples, see Kontorovich et al. (2013). In summary, given approximate output parameters (  X   X  1 ,..., Next, we construct the vector  X   X  by a single pass over the data ( Y t ) T  X  1 t =0 . Then the stationary distribution  X  is estimated via (15). Given  X   X  , we calculate the n  X  n matrix F , construct the empirical estimate  X   X  , and es-timate A via (20). As in the discrete observation case, the time complexity of this scheme is O ( T + n 6 ) with additional terms for calculating K and F . First, we study the statistical properties of our esti-mators under the assumption that the output param-eters, (  X  1 ,..., X  n ) in the continuous case, or the matrix B in the discrete case, are known exactly . Later on we show that our estimators are stable to perturbations in these parameters. For simplicity, throughout this sec-tion we assume that the initial hidden state X 0 is sam-pled from the stationary distribution  X  . This assump-tion is not essential and omitting it would not quali-tatively change our results. Due to space constraints, the proofs appear in Kontorovich et al. (2013). To provide bounds on the error and required sample size we make the following additional assumptions: (2a) In the discrete case, there exists an a 1 &gt; 0 such that min j  X  j  X  a 1 . (2b) In the continuous case, all f  X  Finally, for ease of notation we define g  X   X  2 G 1  X   X  . Asymptotic Strong Consistency. Our first result shows that with perfectly known output probabilities, as T  X  X  X  , our estimates  X   X  ,  X  A are strongly consistent. Theorem 1. Let ( Y t ) T  X  1 t =0 be an observed sequence of an HMM, whose Markov chain satisfies Assumptions (1a,1b). Assume rank( B ) = n in the discrete case, or rank( F ) = rank( K ) = n in the continuous case. Then, both estimators,  X   X  of (9) and  X  A of (11) in the discrete case, or (15) and (20) in the continuous case, are asymptotically strongly consistent. Namely, as T  X  X  X  , with probability one,  X   X   X   X  and  X  A  X  A . Error analysis for the stationary distribution  X  . Recall that to estimate  X  in the discrete case, we argued that for sufficiently large sample size T , the positivity constraints can be ignored, which amounts to solving an n  X  n system of linear equations, Eq. (9). The following theorem provides a lower bound on the required sample size T for this condition to hold with high probability, and a bound on the error  X   X   X   X  . Theorem 2. Discrete case : Let  X   X  be given by (5), and  X   X  be the solution of (9). Let  X  B = diag(1 / and  X  1 (  X  B ) be its smallest singular value. Under As-sumption (2a), a sequence of length suffices to ensure that with high probability, all entries in  X   X  are strictly positive. Furthermore, as T  X  X  X  , Next we consider the errors in the estimate  X   X  for the continuous observations case. For simplicity, instead of analyzing the quadratic program (15) with a weighted ` norm, we consider the following quadratic program, whose solution is also asymptotically consistent: This allows for a cleaner analysis, without changing the qualitative flavor of the results.
 Theorem 3. Continuous case : Let  X   X  be given by (14),  X   X  be the solution of (23), and  X  K = diag(1 / Error Analysis for the Matrix A . Again, for sim-plicity, instead of analyzing the quadratic programs (11) and (20) with a weighted ` 2 norm, we consider the following quadratic programs, whose solutions are also asymptotically consistent for  X   X   X  X   X   X  ,  X   X  } : Note that this QP is applicable even if  X  kk 0 = 0 for some k,k 0 , which implies that  X   X  kk 0 = 0 as well. Theorem 4. Discrete case. Let  X  A be the solution of (25) with  X   X  =  X   X  given in (5). Then, as T  X  X  X  , and thus an observed sequence length suffices for accurate estimation. Theorem 5. Continuous case. Let  X  A be the so-lution of (25) with  X   X  =  X   X  given in (19). Then, as T  X  X  X  , and thus an observed sequence length suffices for accurate estimation.
 Remarks. Note the key role of the smallest singular value  X  1 , in the error bounds in the theorems above: Two hidden states with very similar output probabil-ities drive  X  1 toward zero, thus requiring many more observations to resolve the properties of the underlying hidden sequence.
 Inaccuracies in the output parameters. In prac-tice we only have approximate output parameters, found for example, via an EM algorithm. For simplic-ity, we study the effect of such inaccuracies only in the continuous case. Similar results hold in the discrete case. To this end, assume the errors in the matrices K and F of Eqs. (12) and (17) are of the form with k Q k F , k P k F  X  1. The following theorem shows our estimators are stable w.r.t. errors in the estimated output parameters. Note that if K,F are estimated by a sequence of length T , then typically = O ( T  X  1 / 2 ). Theorem 6. Given an error of O ( ) in the output pa-rameters as in Eq. (30) , the estimators given in Theo-rems 3 and 5, incur an additional error of O n r a 2 with r = 1 for estimating  X  , and r = 3 2 for estimating A , and where  X  1 is the smallest singular value of K/L 2 when estimating  X  , and of F when estimating A . running time (sec) We illustrate our algorithm by some simulation results, executed in MATLAB with the help of the HMM and EM toolboxes 3 . We consider a toy example with n = 4 hidden states, whose outputs are univariate Gaussians, N (  X  i , X  2 i ), with A , F  X  n and  X  given by Fig.1 shows the mixture and its four components. To estimate A we considered the following methods: Fig. 2 (left) shows on a logarithmic scale E k  X  A  X  A k vs. sample size T , averaged over 100 independent re-alizations. Fig. 2 (right) shows the running time as a function of T . In these two figures, the number of iterations of the BW step was set to 20.
 Fig. 3 (left) shows the convergence of E k  X  A  X  A k 2 F function of the number of BW iterations, with known output parameters, but either with or without the QP results. Fig. 3 (right) gives E k  X  A  X  A k 2 F as a function of the number of BW iterations for both known and EM-estimated output parameters with 10 5 samples. The simulation results highlight the following points: (i) BW with a random guess of both A and the pa-iterations. It often requires hundreds of iterations to converge, in some cases to a highly inaccurate solution (results not shows due to lack of space); (ii) For a small number of samples the accuracy of QP+EM (method 3) is comparable to BW+EM (method 5) but requires only a fraction of the computation time. (iii) When the number of samples becomes large, the QP+EM is not only faster, but (surprisingly) also more accu-rate than BW+EM. As Fig. 3 suggests, this is due to the slow convergence of the BW algorithm, which requires more than 20 iterations for convergence. (iv) Starting the BW iterations with (  X  i , X  2 i ) estimated by EM and A estimated by QP as its initial values signif-icantly accelerated the convergence giving a superior accuracy after only 20 iterations. These results show the (well known) importance of initializing the BW al-gorithm with sufficiently accurate starting values. Our QP approach provides such an initial value for A by a computationally fast algorithm.
 Acknowledgments. This research was supported by ISF grants #1141/12 and #328/10 and by the Frankel Center for Computer Science.

