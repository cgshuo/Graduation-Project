 In this paper, we discuss our work in progress towards a scalable hierarchical classification system for books using the Library of Congress subject hierarchy. We examine the characteristics of this domain which make the problem very challenging, and we look at several appropriate performance measurements. We show that both Hieron and Hierarchical Support Vector Machines perform moderately well.
 I.5.4 [ Pattern Recognition ]: Applications X  text process-ing ; H.3.6 [ Information Storage and Retrieval ]: Library Automation X  large text archives Experimentation, Performance Hieron, Support Vector Machine, Hierarchical classification
The Internet Archive (http://www.archive.org) has a large collection of books that have been converted into text for-mat. Many of them have standard library catalog records, in which case users can access them through a subject in-dex, but the others are difficult to find. The Library of Congress Classification Outline (LCCO) 1 organizes subjects into a hierarchy with a call number as proxy for subject. If the books were all labeled with a call number, the Internet Archive could provide easier access to all of the books using this tree structure. However, at present less than a third of the books have a Library of Congress call number. 2 Our goal is to automatically classify all of the books so that the Internet Archive can make them more easily available. In this paper, we focus on identifying the major issues in large-scale book classification and the appropriate features, and http://www.loc.gov/catdir/cpso/lcco/
Around 11/2007, we downloaded 37,303 books, of which 28,886 had catalog records but only 8,306 had Library of Congress call numbers.
 on exploring the applicability of the major state-of-the-art classification methods.

There are several characteristics of this domain that make classification more challenging than typical. The most sim-ilar domain is large collections of web documents. However, most web documents have been authored in the last fifteen years, whereas the books in our collection range over several hundred years. Books are also on average much longer than web pages or any of the benchmark collections. Our collec-tion is very heterogeneous, with diverse vocabulary, spelling and style. This poses problems for classifiers which assume similar vocabulary if the subject is similar, and which eas-ily overfit when there are so many features. We have found that even the crude tactic of truncating the book after 10,000 words 3 improves classifier performance. We have also found that aggressive feature selection is essential for good perfor-mance.

Betts et al. [1] described a more costly approach for book classification using named entity extraction. While their approach is interesting, named entity extraction produces features which are very specific to a particular book, and may hinder generalization in the case of our application. They also do not report macro-averaged F 1 or Tree Loss which makes direct comparison difficult.

Another issue is the effectively limitless possible book sub-jects with a challenging power-law distribution. We have found that the LCCO provides a useful way to cluster them into coherent groups. Even so, the resulting classes re-main very imbalanced. Without special care classifiers place nearly all of the books into the few largest classes, which does not help users sift through the books. We are using the macro-averaged F 1 value to identify how well classi-fiers predict rare classes. We also use the micro-averaged F 1 to measure overall accuracy. As the number of classes increases, any classifier will have a corresponding decrease in accuracy. That is a significant factor in our current work with 191 classes, and even more significant as we plan to scale up to tens of thousands of classes. The expected Tree Loss measures the lengths of the paths between true and predicted classes, providing valuable insight into whether the mistakes are minor or serious. These three metrics com-prehensively evaluate the utility of a classification system for our purposes.
For motivation, consider that an author generally intro-duces the subject in the first several pages. M-SVM 87.5% 88.6% 0.58 H-SVM 99.3 96.5 0.02 Hieron 79.3 74.2 0.86 TESTING Micro-F 1 Macro-F 1 Tree Loss M-SVM 34.8% 23.3% 2.61 H-SVM 37.5 23.3 2.17 Hieron 38.1 23.2 2.56 RANDOM 0.5% 0.5% 5.50
Of the books with call numbers, we used 6,591 books for training and 938 for testing. We merged categories in the LCCO as necessary so that there were at least 10 training and 2 testing books per class. This resulted in a tree with 191 classes, maximum depth 7 and diameter 12. We used a bag of words model of the first 10,000 terms from each book.
For feature selection, we looked for features useful for dis-tinguishing between sibling classes. Consider a random vari-able X i t,s representing some statistic s of the frequency of term t in class i . We use several different statistics (docu-ment frequency, term frequency and power-law exponent). We look for terms where the variances are small in the child nodes and relatively large in the parent node. Such terms make useful features for distinguishing between the child nodes. We quantify this with the following equation for the utility U of term t : We selected features where the utility was above a threshold.
We evaluated several machine classification methods. Hi-eron [2] is a linear, large-margin method for hierarchical clas-sification. Hieron learns class prototypes for each node in the tree and is efficient both in training and predicting. We also created multi-class (M-SVM) and hierarchical (H-SVM) implementations of a Support Vector Machine (SVM) using SV M struct as described by Tsochantaridis et al. in [3]. We used a linear kernel, which is common for text classification. We also tried Na  X   X ve Bayes, which we do not show because its performance was not competitive.

We tuned parameters using 5-fold cross-validation over the training set. Since many of our classes have only 10 training samples, 10-fold cross-validation would have suf-fered the faults of leave-one-out cross-validation. All of the classifiers performed best with the most aggressive utility threshold we tried, 87. Hieron X  X  primary parameter was the number of iterations over the training set. The optimal iter-ations for micro-averaged F 1 and Tree Loss was 6, so we re-port results at 6 iterations. The SVM classifiers were tuned for optimal C , but they showed no sensitivity to it due to the data being easily separated.
 In Table 1 we show the micro-and macro-averaged F 1 , and Tree Loss for each method. Interestingly, Hieron performed nearly as well as H-SVM, even though it scales much better, owing to its linear time complexity in the number of training samples, in contrast to SV M struct  X  X  quadratic complexity. Still, there is much room for improvement since even the best classifier misclassifies 62.5% of the books, often badly. Figure 1: Effect of number of iterations of Hieron on F 1 and Tree Loss.
We have discussed the difficulties that arise in classifying large hierarchies of books. We argued that macro-averaged F 1 and tree-induced loss are useful measures of classifier per-formance in this domain and have demonstrated the impor-tance of feature selection. We evaluated several methods for classification, and have shown that Hieron in particular has competitive performance with impressive scalability.
We are continuing to develop additional features that are more specific to books and will have a higher signal to noise ratio. We are also working to identify a loss function that will more accurately reflect users X  classification needs. In many cases, such as when a book is misclassified to a sec-ondary subjects, Tree Loss may overestimate the true loss a user experiences. We would like to thank Brewster Kahle, director of the Internet Archive, for directing us to the text and catalog records for the books available in the Internet Archive. He has also been very supportive of this work. [1] T. Betts, M. Milosavljevic, and J. Oberlander. The [2] O. Dekel, J. Keshet, and Y. Singer. Large margin [3] I. Tsochantaridis, T. Hofmann, T. Joachims, and
