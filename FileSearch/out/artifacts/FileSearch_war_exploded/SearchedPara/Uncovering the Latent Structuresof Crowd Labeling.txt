 Researches and applications in the field of artificial intelligence are relying more and more on large-scale datasets as the age of Big-data comes. Convention-ally, labels of tasks are collected from domain experts, which is expensive and time-consuming. Recently, online distributed working platforms, such as Ama-zon Mechanical Turk (MTurk) , provide a new way to distribute enormous tasks to a crowd of workers [ 1 ]. Each worker only needs to finish a small part of the entire task in this crowd labeling mode, so that the tasks can be done faster and cheaper. However, the labels given by the crowd annotators are less accurate than those given by experts. In order to well recover the true labels, multiple annotators are usually needed to evaluate every micro task. Furthermore, dif-ferent annotators may have different backgrounds and personal preferences, and they may give inconsistent answers to a same question. This phenomenon brings us more difficulties to recover ground truth labels from noisy answers and raises a research topic in the crowdsourcing area.
 On the other hand, the diverse labels can provide us with a lot of additional information for both data characteristics and people X  X  behaviors [ 2 ]. For exam-ple, they may reflect some latent structures of the complicated data, such as the grouping structure of tasks according to their difficulty levels and/or the group-ing structure of annotators according to their similar education background or preferences. In the perspective of psychology, users X  labels actually show their understanding of the given tasks. For example, in a problem of classifying flow-ers in pictures, users X  choices may be influenced by many different features, such as petal color, petal shape, background, size in the picture, etc; and personal choices of different users are influenced by users X  tastes. These features are usu-ally unknown. Some features are significantly related to the flower species and some features are not. So we think the observed user labels are generated from tasks X  latent structures and annotators X  abilities, but not directly from the truth category. By exploring these latent structures, we can have a better understand-ing of the data, and may also accomplish tasks like category recovery better. posed an annotator-specific confusion matrix model, which is able to estimate the ground truth category well. Raykar et al. [ 4 ] extended Dawid and Skene X  X  model by ways, such as taking item features into account or modifying the out-put model to fit regression or ranking tasks. Zhou et al. [ 5 , 6 ] proposed a minimax entropy estimator, which outperforms most previous models in category estimat-ing accuracy, and later on they extended their model to handle ordinal labels. However, none of these models have taken latent structures into account. We extend some of them to learn latent structures from dataset. Welinder et al. [ 7 ] proposed a multidimensional annotation model, which was the earliest to con-sider latent structure in this field. But this model often suffers from overfitting and so performs averagely on many tasks [ 8 ]. Tian and Zhu [ 9 ] also proposed an idea on the latent structure for crowdsourcing but aimed at a different problem; our work draws some inspiration from their nonparametric ideas.
 item belongs to one latent class, and annotators have a consistent view on items of the same class but maybe inconsistent views on items of different classes; and (II) several different latent classes consist in one label category. To recover the latent-class structures, we propose a latent class estimator using a nonparamet-ric prior. We also extend the minimax entropy estimator to fine tune such latent class structures. Under the latent class assumptions, the estimators remain com-pact through parameter sharing. The experimental results on both synthetic and real MTurk datasets demonstrate our methods can disclose interesting and meaningful latent structures, and incorporating latent class structures can bring significant improvements on ground truth label recovery for difficult tasks. We summarize our contributions as: (1) We propose the latent-class assumptions for crowdsourcing tasks. (2) We develop appropriate nonparametric algorithms for learning latent-class structures, and extend previous minimax entropy principle. (3) We present an algorithm to recover category labels from latent classes, and empirically demonstrate its efficiency.
 sourcing models. Sec. 3 introduces latent-class assumptions and provides details of our latent class models. Sec. 4 presents category recovery methods. Sec. 5 shows empirical results for latent class and category recovery. Sec. 6 concludes. We introduce three major methods for label aggregation in learning from crowds. We focus on classification tasks in this paper. In a dataset consisting of M items (e.g., pictures or paragraphs), each item m has a specific label Y affiliated category. Y is the collection of these ground truth category labels, and all the possible label values form a set D . To obtain the unknown ground truth, we have N workers examine the dataset. W nm is the label of item m given by worker n . W is the collection of these workers X  labels. I worker-item index pairs corresponding to W . The goal of learning from crowds is to infer the values of Y from the observations of W . 2.1 Majority Voting (MV) The simplest label aggregation model is the majority voting. This method assumes that: For every worker, the ground truth label is always the most com-mon to be given, and the labels for each item are given independently. From this point of view, we just need to find the most frequently appeared label for each item. We use q md = P ( Y m = d ) to denote the probability that the m th task has true label d , then where  X   X  ,  X  is an indicator function:  X  a,b equals to 1 whenever a = d is true, oth-erwise it equals to 0. The estimated label is represented by Y 2.2 Dawid-Skene Estimator (DS) Dawid and Skene [ 3 ] proposed a probabilistic model, which is widely used in this area. They made an assumption that: The performance of a worker is consistent across different items, and his or her behavior can be measured by a confusion matrix. Diagonal entries of the confusion matrix indicate the probability that this worker gives correct labels; while off-diagonal entries indicate that this worker makes specific mistakes to label items in one category as another. Extensive analysis of this model X  X  error bound has been presented [ 10 , 11 ]. More formally, we use p n to denote the confusion matrix of worker n , with each element p ndl being the probability that worker n gives label l to an item when the ground truth of this item is d .Weuse q d to denote the probability that an item has the ground truth label d . Under these notations, parame-ters of workers can be estimated via a maximum likelihood estimator, argmax P ( W | q , p ), where the margined likelihood is by marginalizing out the hidden variables Y . This problem is commonly solved using an EM algorithm. 2.3 Minimax Entropy Estimator (ME) Minimax entropy estimator [ 5 , 6 ] is another well-performing method which com-bines the idea of majority voting and confusion matrix. This model assumes that: Labels are generated by a probability distribution over workers, items, and labels; and the form of the probability distributions can be estimated under the maximum entropy principle. For example, p nm is a probability distribution on the label of item m given by worker n . To incorporate the idea of majority voting that ground truth labels are always the most common labels to be given, the count of empirical observations that workers give an item a certain label should match the sum of workers X  probability corresponding to these observations within the model. So they come up with the first type of constraints: To combine the confusion matrix idea that a worker is consistent across different items in the same category, the count of empirical observations that workers give items in the same category a certain label should match the sum of workers X  probability corresponding to these observations within the model. So there is another type of constraints: Under these constraints and the minimax entropy principle, we choose minimize the entropy but choose p to maximize the entropy. This rationale leads to the learning problem: subject to constraints (3) and (4). In practice, hard constraints can be strict. Therefore, soft constraints with slack variables are introduced to the problem. Both DS and ME use specific probabilities to represent workers X  behaviors. How-ever, we can dig deeper into the structure of the items. For example, in a flower recognition task, we ask workers to decide whether the flower in a given picture is peach flower or not. When the standard DS estimator is used, the confusion matrix should contain 4 probabilities, that is, the probability that worker labels the picture correctly when it is peach flower; the probability that worker labels the picture incorrectly when it is peach flower; the probability that worker labels the picture correctly when it is not peach flower; and the probability that worker labels the picture incorrectly when it is not peach flower. If there are 2 breeds of peach flowers in the testing set, say mountain peach flowers and flowering peach flowers, then the probabilities that a worker recognizes them as peach flowers correctly might be different. For example, some workers who are very familiar with mountain peach may point out mountain peach flowers as peach flowers with an extraordinary high accuracy, but their accuracy of recognizing flowering peach might be close to random guess. Our experiments show that this phe-nomenon does exist. So we come to one conclusion that the latent structure of items can affect the workers X  labeling results significantly, and we can take this influence into account in our label aggregation algorithm. Latent class structure is one of the simplest latent structures of items. The latent class here refers to a finer level structure of items than the category. In the flower example, the latent classes may correspond to the flower species such as flowering peach and moun-tain peach, while the categories can only recognize both these species as peach flower with no inner structure. If we restrict the number of latent classes to be the same as the number of categories, different classes will naturally correspond to the classification categories. Yet as a general rule, the number of latent classes should be larger than the category number.
 A category of items might be divided into several latent classes, but a latent class belongs to one specific category only. Thus, we make two basic assumptions in the crowd labeling situations:  X  Assumption I. Each item belongs to one specific latent class only.  X  Assumption II. Items in a same latent class belong to a same category. From another point of view, we believe that no label is spam. When the standards of solving our problems match the workers X  own criterion, based on which they make their choices, the DS estimator works well. But if they do not, much information will be left unutilized by this estimator. In order to improve the aggregation performance and uncover more information hiding behind the noisy labels, we build up new models which take latent structures into account. 3.1 Nonparametric Latent Class Estimator (NDS) For the DS estimator, a confusion matrix is used to measure workers X  behavior, with each entry p ndl representing the probability that worker n gives label l to an item when the ground truth of this item is d . Now we realise that the latent classes affect the output labels directly. We can replace the category dimension of the confusion matrix representation with the latent class dimension. Therefore, we have a latent class version confusion matrix p n for each worker. An entry p nkl denotes the probability that worker n gives label l to an item which belongs to latent class k . Similarly we use Z m to represent the latent class that item m belongs to, and use q to denote the probability that each latent class appears, so that q k denotes the probability that an item belongs to latent class k . Probabilistic Model. Since it is hard to decide the number of latent classes K in advance, we put a nonparametric prior on the latent class assignment variable Z , which can represent arbitrary number of classes. The Chinese restaurant process (CRP) is used here, it is a construction of Dirichlet process [ 12 ], and can be described using the metaphor of a restaurant with customers entering and sitting next to tables with different probabilities depending on the tables X  X j relative sizes.  X  c is the discount parameter of this process. We also put a Dirichlet prior Dirichlet(  X  d )onevery p nk , where  X  d is the concentration parameter. So the probabilistic model is represented as follow, the given labels, p is the parameters to learn, and Z is the hidden variable. If annotator n do not give item m a label, the probabilities of all W set to be one.
 Conditional Distribution. To infer their values, we build a Gibbs sampler to get samples from the joint posterior distribution. The conditional distribution for the confusion matrix parameter is So the conditional distribution p nk | Z , W  X  Dirichlet( B hidden variables, when k  X  K , where n k is the number of tasks that have latent class label k . When generating a new class, P ( Z m = k new | Z  X  m , p , W )  X  P ( Z m = k new ) Then we can get samples from the posterior distribution of our model by iteratively updating hidden variables and parameters. 3.2 Latent Class Minimax Entropy Estimator (LC-ME) Many existing estimators can be extended to learn latent class structures. The nonparametric latent class estimator can be regarded as an extension of DS esti-mator, we can also incorporate latent class structures into the minimax entropy estimator. Some constraints need to change for this extension, as detailed below. We still assume that the ground truth label will always get more probability to be given by workers, so the first type constraints remain unchanged. As for the other constraints, now we apply the idea of latent class version DS estimator: When worker n deals with items in latent class k , he may label it as category d with a constant probability. So the constraints can be written as To relax constraints, we introduce slack variables  X  and  X  tion terms. Under these new constraints, the optimization problem is slightly changed comparing with the previous version: To solve this optimization problem, we update {  X  md , X  ndk Since the inference procedure is similar to the original minimax entropy estimator in [ 5 ], we only express the final iterative formula here.
 Step-1: we need to solve a simple sub-problem: where q t mk  X  P t ( Z m = k ) represents the probability that the item m is in latent class k . This optimization task can be solved by gradient descent and any other optimization methods.
 Step-2: the probability distribution of each item X  X  label is point. Then we can get the latent class numbers Z by the peak positions of Since the algorithm is sensitive to the initial point, we use the result of NDS as the latent class number K and the initial point Z of the LC-ME. In order to obtain the ground truth labels, we need to recover the category information from latent classes. According to our second basic assumption that each latent class belongs to one specific category, we can recover the ground truth labels by associating latent classes to categories.
 get the latent class information for items, we can regard items in a same class as one imaginary item, here we call it a hyper-item . Then there are totally K hyper-items, every hyper-item may have several different labels by each worker. This setting has been considered in the original Dawid-Skene estimator. category assignments, which solves a maximum likelihood estimation problem. The margined likelihood of given labels is where n nkd = m  X  W nm ,d  X  Z m ,k is the count of labels that worker n gives to hyper-item k . The EM algorithm for solving this problem also needs some modi-fication. Specifically, we use C k to represent the category of latent class k . Then in the E-Step , the probability distribution is and the estimated category of each latent class is C k = max In the M-Step , we have the update equations: We now present experimental results to evaluate the performance of the proposed models on both one synthetic dataset and real dataset collected from MTurk. We present both quantitative results on ground truth label recovery and quantitative results on latent structure discovery, with comparison to various competitors. 5.1 Synthetic Dataset We designed a synthetic dataset to show the latent class recovery ability of each model. This dataset consists of 4 latent classes and 2 types of workers. We generated 40 items X  parameters for each latent class and simulated 20 workers of each type. We set the confusion matrix for all simulating worker types and randomly sample labels. The probabilistic distribution values of different classes effect of latent structure is more significant. The results on learning latent classes and category recovery are shown below. Sensitivity: We use the NDS model to recover the latent structure of this dataset. Fig. 2(a) shows the learnt latent class number K by models with different parameters. We set  X  d = 2 for all trials, and vary  X  c from 0.1 to 1.60. We can see when parameter changes, the steady state value only changes a little, and all the values are close to the true latent class number. This result shows that our model is insensitive to the discount parameter. So when we use this model to learn latent structures for some purposes, we only need to find a rough range of the parameter with a validate dataset.
 Category Recovery: To evaluate the ground truth category recovery accu-racy, we compare the error rates of NDS with different  X  c Fig. 2(b) that the final accuracy is insensitive to the parameter  X  about 3 . 75% for all parameter settings. We also compare the NDS with other methods. Majority voting achieves error rate 9 . 38%, original Dawid-Skene esti-mator achieves error rate 12 . 50%, both of them are worse than NDS. 5.2 Flowers Dataset To show the semantic meaning of the latent structure learned by our models, we designed a flower recognition task and collected crowd labeling data from MTurk annotators. Four flower species, mountain peach flower, flowering peach flower, apricot flower and sakura, make up the dataset of 200 images. Each species have 50 different pictures. Only mountain peach flower and flowering peach flower are peach flower while apricot flower and sakura are not. Workers were asked to choose whether the flower in picture is prunus persica (peach flower). all the different participants completed more than 10 Human Intelligence Tasks (HIT) on each. And they provided 2366 HIT in total. During the annotating procedure, two hints are shown to make sure that workers can distinguish prunus persica and sakura or distinguish prunus persica and apricot. Each picture was labeled by 11.8 workers and each worker provided 65.7 labels on average. the partitions of different latent classes and different categories in Fig. 3(b) -3(d) . Each subfigure contains a 50  X  4 color matrix, with each entry representing a flower image in the dataset, and each column corresponding to a unique flower species. Specifically, the first column is flowering peach flower, second is sakura, third is apricot flower and forth is mountain peach flower.
 In Fig. 3(a) and Fig. 3(b) , each color denotes one latent class learned by the estimator. We can see that the first three columns almost have pure color boxes, which means these three latent classes are strongly related to the flower species. The fourth column is kind of miscellaneous, which means that lots of mountain peach flowers are misclassified into other species. This is because mountain peach flowers have no distinct features comparing with other flower species. In Fig. 3(c) and Fig. 3(d) , each color denotes a classification category, either peach flower or not. This result comes from putting blue and azure boxes into peach flower category and other two colors X  boxes into another. Fig. 4 shows some representative flower pictures for different latent classes we learned. These results suggest that the structures we learned have explicit semantic meaning, and these latent class patterns could be used in many further applications. Finally, we evaluate the category recovery performance. The average worker error rate in this flower recognition task is 30 . 00%, and majority voting gets an error rate of 22 . 00%. The latent class minimax entropy estimator (LC-ME) wins on this dataset with error rate 11 . 00%, and the nonparametric latent class estimator (NDS,  X  c =1 . 6 , X  d =2)achieves11 . 50%. The original Dawid-Skene estimator (DS) achieves 13 . 00%. The minimax entropy estimator (ME) achieves 13 . 00%. We also generated some sub-datasets with different numbers of workers in order to make more comparisons. Results are shown in Table 1 ,which consistently show the improvements by exploring our latent class assumptions. We have carefully examined the effectiveness of latent class structures in crowd-sourcing. Our methods characterize that items in one dataset can be separated into several latent classes and workers X  annotating behaviors may differ among different classes. By incorporating such fine-grained structures, we can describe the generation mechanism of noisy labels more clearly. Our methods can dis-close meaningful latent classes, as demonstrated in real data experiments. After we get the latent class assignments, a category label recovery algorithm is devel-oped, which is empirically demonstrated to achieve higher accuracies on category recovery tasks. Our latent structure models can preserve the structure informa-tion of data. For the future work, we plan to investigate the effectiveness of such hidden structure information further in handling other interesting tasks, such as online task selection and user behavior analysis.

