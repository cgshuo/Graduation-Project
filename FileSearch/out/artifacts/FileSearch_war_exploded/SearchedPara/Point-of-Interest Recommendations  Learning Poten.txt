 The emergence of Location-based Social Network (LBSN) services provides a wonderful opportunity to build person-alized Point-of-Interest (POI) recommender systems. Al-though a personalized POI recommender system can sig-nificantly facilitate users X  outdoor activities, it faces many challenging problems, such as the hardness to model user X  X  POI decision making process and the difficulty to address data sparsity and user/location cold-start problem. To cope with these challenges, we define three types of friends (i.e., social friends, location friends, and neighboring friends) in LBSN, and develop a two-step framework to leverage the information of friends to improve POI recommendation ac-curacy and address cold-start problem. Specifically, we first propose to learn a set of potential locations that each indi-vidual X  X  friends have checked-in before and this individual is most interested in. Then we incorporate three types of check-ins (i.e., observed check-ins, potential check-ins and other unobserved check-ins) into matrix factorization model using two different loss functions (i.e., the square error based loss and the ranking error based loss). To evaluate the pro-posed model, we conduct extensive experiments with many state-of-the-art baseline methods and evaluation metrics on two real-world data sets. The experimental results demon-strate the effectiveness of our methods.
 Point-of-Interest; Recommendation; Matrix Factorization
Recent years have witnessed the prevalence of smart mo-bile devices and the convenience of accessing wireless net-work, which makes people much easier to acquire their real-time location information. This development stimulates the emergence of location-based social network (LBSN) services such as Foursquare, Jiepang, and Facebook Places. These LBSNs allow users to build connections with each other, and share their experience and check-in information associ-ated with a Point-of-Interest (POI). A variety of such user interaction data with LBSNs provide a good opportunity for developing personalized POI recommender systems. In-deed, the accurate and personalized POI recommendation is a crucial demand in LBSN services. It not only helps users to explore new locations, but also facilitates users to find rel-evant POIs without spending too much time on searching, particularly when they are in a new region.

Although developing a personalized POI recommender sys-tem is a crucial task and could benefit users X  outdoor activ-ities, it is still a very challenging problem due to three rea-sons. First, a user X  X  check-in decision making process is very complex and could be influenced by many different kinds of factors. For example, it is difficult to model the influence of social friends on user X  X  check-in behaviours. We do not know which friend will actually influence user X  X  POI decision, not mention to know how she affects user X  X  choice. Also, the geographical distance might affect user X  X  POI decision. A user often prefers a nearby POI to another one far away. Second, POI recommender system usually suffers a severe challenge caused by extreme sparse check-in data. In real system, there are over millions of POIs. However, a single user usually checks-in a limited number of POIs, which sig-nificantly increases the difficulty of recommendation. Third, when a new POI or a new user enters the system and we do not have its visitor information or her historical check-in information, it is very difficult to recommend new POI to users or recommend POIs to new user.

In the literature, some related works have been proposed to incorporate social network into POI recommendations. For example, [16] placed a social regularization term to con-strain the estimation of user feature vectors with the as-sumption that friends will share the similar interests. Mean-while, some researchers also proposed to take the geograph-ical influence into account to assist POI recommendation. For instance, [28] leveraged a linear model to combine user interest, social network and geographical distance for POI prediction. On the other hand, [15] modeled the geographi-cal neighborhood influence in both instance and region level. In instance level, one user X  X  preference for a location is pre-dicted as a combination of her special preference on this location and the nearest neighborhoods of this location. In region level, it places a group lasso penalty to learn location-specific latent vectors. However, few of these models incor-porate the influence of geographically close users on each other X  X  check-in activities into matrix factorization. The geographically close users may share similar interests and should have potential influence on check-in behaviors [23]. Moreover, few of these models could address user cold-start problem in location recommendation. Motivated by these, we first formally define three types of friends for each user: social friends, location friends and neighboring friends. The social friends of a user refer to the set of users who are socially connected with this user in LBSNs. The location friends of a user denote the set of users who check-in the same locations as this user does. The neighboring friends of a user are those users who are geographically close to this user. Then we novelly incorporate their historical check-ins into matrix factorization model with different loss functions.
Through our analysis on two real-world data sets, we find that users share the similar interests with their three types of friends. Consequently, we propose a two-step framework to elaborate friends X  check-ins. In the first step, we design two approaches (i.e., a linear aggregation based and a ran-dom walk based) to learn a set of friends X  locations that each user most potentially prefers and she never visited. Thus, a user X  X  check-ins are divided into observed check-ins, po-tential check-ins and other unobserved check-ins. In the second step, we develop two loss functions to model these three kinds of check-ins: the square error based loss func-tion and the ranking error based loss function. Specifically, the square error based loss treats user X  X  check-ins as an in-dication of positive, potential and negative preference with varying confidence. The ranking error based loss assumes that the user prefers an observed location over any potential locations, and also prefers a potential location over any un-observed locations. We extensively evaluate our models with many state-of-the-art baseline models and different valida-tion metrics on two real-world data sets. The experimental results not only demonstrate the improvements of our mod-els on POI recommendation, but also show the effectiveness for cold-start problem.

To summarize, the major contributions of this paper are:
In this section, we first introduce some mathematical no-tions, and then provide the definition of friends. At last, we introduce the recommendation framework.
Suppose there are N users and M locations. For conve-nience we will henceforth refer to i as user, f as friend and j as the location unless stated otherwise. Suppose there are C kinds of categories and the category of location j is de-noted as c j . For user i , F i denotes a set of friends which will be further defined and explained in Section 2.2, M o a set of locations checked-in by her, M p i is a set of potential locations learned in Section 3, and M u i is the remaining un-visisted locations. r ij is the check-in frequency of user i on Figure 1: The user u i  X  X  social network and check-ins. location j . In addition, all column vectors are represented by bold lower case letters, all matrices are represented by bold upper case letters, and a numeric value is denoted by lower case letter. A predicted value is denoted with a  X  (hat) over it. The terms location and POI are used interchangeably.
To better understand users X  check-in behaviours, we exam-ine the check-in data collected from Gowalla and Foursquare (Details can be found in Section 5). To clarify the relation between the similarity of pairwise users and their physical distance, we plot their relations in Figure 2(a) and Figure 2(b). The physical distance of two users refers to the dis-tance between their home locations, and the similarity of user i and user f is measured by cosine similarity, given by:
Based on the observation, we find that the physically closer two users live, the more similar their POI interests are. It motivates us to leverage neighboring friends, who are physically neighbors, to learn user X  X  interest in POIs. In ad-dition, social friends who build connections online share the similar interests in POI decisions [16, 1, 5, 22]. Users who check-in similar locations are treated as location friends, and also might have similar tastes. Thus, three types of friends of user i , i.e., neighboring friends, social friends and location friends, might affect her check-in activity, defined as:
Definition 1 (Social Friends). The social friends of user i are the set of users who have socially connected with
Definition 2 (Location Friends). Given a set of lo-cations M o i , which have been checked-in by user i , her loca-j is the set of users who also have checked-in location j .
Definition 3 (Neighboring Friends). Given the home location of user i , the neighboring friends are the set of users
In the example of Figure 1, the target user u i has checked-socially connect with her online. User f 3 has check-ins at locations l 2 and l 5 , and user f 4 has check-ins at locations l and l 4 . f 4 and f 5 have common POIs with user u i , i.e., l and l 3 , respectively. Thus, both of them are the location friends of user u i . In addition, f 5 and f 6 are the target user X  X  neighboring friends due to their physically short distance to her. Thus, { f 1 ,  X  X  X  ,f 6 } are regarded as the friends of user i . In this paper, the friends of user i are defined as: where S ( F l i ) is the set of S most similar friends with the highest cosine similarities and S ( F n i ) is the set of S physi-cally nearest friends with the shortest distance among their (c) Gowalla Data homes 1 . To examine the correlation between friends, we report the complementary cumulative distributions of their similarities in Figure 2(c) and Figure 2(d) on Gowalla and Foursquare, respectively. There are over 5%, 20% and 40% pairs of social, neighboring and location friends which have similarities larger than 0 . 2. Particularly, the friends X  corre-lation is much stronger in Gowalla than Foursquare. The observation shows the importance of friends in LBSNs and motivates us to use friends X  historical check-ins to improve recommendation accuracy.
The recommendation task in this paper is defined as: given users X  historical checked-in locations, we aim at recommend-ing each user with top-K locations that she might be inter-ested in but has not visited before. In this paper, we pro-pose a two-step recommendation framework. Specifically, in the first step, we learn a set of potential locations from three types of friends, which will be introduced in Section 3. In the second step, we incorporate the learned potential locations of each individual into matrix factorization model with different error loss functions, which will be presented in Section 4. At last, we introduce different recommendation strategies for standard recommendation, location cold-start recommendation and user cold-start recommendation.
Social network plays an important role in recommenda-tions [16, 28, 5, 22]. However, only leveraging the historical locations of social friends cannot successfully model user X  X  preference for locations due to that it is difficult to appro-priately model the preference of users who have no social friends, not mention to handle user cold-start problem (i.e., a user has never checked-in any location before). To address these problems, we will exploit the characteristics of three types of friends: social friends, location friends and neigh-boring friends. The earlier section has shown their signifi-cance in LBSNs, i.e., friends would share the similar prefer-ences for POIs. In other words, users might be interested in those locations which have been checked-in by their friends, and have a high probability to check-in them next time. However, the extremely large number of these locations will lead to the inefficiency of computation with the increase of locations, and the inaccuracy of prediction with the increase of noise. Hence, the problem in this section is to find the most potential locations for the target user, defined as: Definition 4 (Problem of Potential Locations).
 friends of target user i have checked-in before but she never visits, the problem is to find top S most potential locations that she might be interested, denoted as M p i . In the experiment, we set S as 10.

To obtain the potential locations of each user i , we propose two methods, i.e., Linear Aggregation and Random Walk , to estimate the probability p pot ij of this user on each location j that her friends have checked-in. Then we rank them by the estimated probabilities and select S locations with the highest probabilities 2 . The learned potential locations will assist to make accurate recommendation in Section 4.
In this section, we propose Linear Aggregation method, denoted as LA , to predict the probability p pot ij that user i prefers location j which has been visited by her friends. Sup-pose Sim ( i,f ; j ) is the similarity between user i and friend f on the preference for location j . A location is possibly checked-in by more than one friends, so we define p pot ij where F j i is the set of user i  X  X  friends who have checked-in lo-cation j . The similarity Sim ( i,f ; j ) incorporates two parts: (1) the similarity of user interest, and (2) the similarity of geographical location. The similarity of user interest can be measured by cosine similarity in Eq.(1). Since a user X  X  check-in probability and the distance from her home to the corresponding location follow a power law distribution [9], we exploit this characteristic to model geographical similar-ity. Hence, we define the probability that a user checks-in a location d -km far away as the following: where a and b are the parameters of power law distribution and could be learned by maximum likelihood estimation. Then the probability of user i to check-in a POI j due to the geographical influence is normalized as: where h i is the home location of user i , and d ( h i ,j ) indicates the distance between the home location of user i and the POI j , and d min is the minimum distance. The distance could be computed by Haversine formula with latitude and longitude. Thus, Sim ( i,f ; j ) is the linear aggregation of similarities on both user interest and geographical location, given by where  X   X  [0 , 1] is a tuning parameter to control the impor-tance of the similarity of user interest.
Random walk with restart has successfully measured the correlation between two nodes in a graph [7, 24]. In this section, we propose a Random Walk method, denoted as RW , to learn the probability p pot ij of user i on location j which has been visited by her friends. We construct a directed
In the experiments, we set S as 500. graph with two kinds of nodes: the users (i.e., the target user and her friends), and the locations checked-in by her and her friends. Let y be a column vector where y i refers to the probability that the random walk is at node i . Also let A be the column normalized transition matrix where a ij denotes the probability that node i jumps to node j . Here we consider three types of transition probabilities: (1) the probability between users measured by the cosine similarity in Eq.(1); (2) the probability from each user to each location which is one if the user checks-in the corresponding location and otherwise is zero; (3) the similarity between a pair of locations ( j and k ) measured by the normalized power-law function which is defined as the following: where d ( j,k ) is the distance between these two locations and the power law parameters are learned with the check-in probabilities and corresponding distances of pairwise loca-tions. Hence, the iteration equation for updating the steady-state probability of each node is given as follows: where x is the column vector of zeros with the elements cor-responding to the target user and her checked-in locations as one, and  X   X  [0 , 1] is the restart probability to return to the target user and her checked-in locations. The steady-state probability is achieved by recursively performing Eq.(6) un-til convergence. Thus, the probability p pot ij is the steady-state probability corresponding to the location j .
In Section 3, for each individual user, we have learned the potential locations from her friends X  information. In this section, the learned potential locations are utilized to make accurate recommendation and address user cold-start problem. Overall, for each user i , we have her three kinds of locations: observed locations M o i , potential locations M and other unobserved locations M u i .

In this paper, we build our recommendation models by leveraging the widely-used matrix factorization techniques [20, 19, 8, 6, 11], where both user and location are mapped into latent low-dimension spaces. Let U  X  R K  X  N and V  X  R
K  X  M be the latent user and location feature matrices, with column vectors u i and v j representing the K -dimensional user-specific and location-specific feature vectors of user i and location j , respectively. A typical prediction for the preference of user i to location j is taken by an inner prod-uct of latent vectors, i.e.,  X  p ij = u T i v j , where P  X  the preference matrix.

However, in LBSNs the category information of POIs af-fects user X  X  check-in decision making process. Users are often used to visiting those POIs which belong to the same cate-gory due to their specific hobbies. For example, users who like eating would have a much higher probability to choose a new POI relevant to food next time, but they have much less chance to check-in a POI about sight . Thus, the prefer-ence of category is another important factor to affect user X  X  decision on a new POI. Here, we introduce the category fea-ture matrix Q  X  R N  X  C , where each entry q ic indicates the preference of user i to category c . Hence, the preference of user i for location j is refined as follows: where c j is the category of location j and  X  is a tuning parameter to indicate that user has a small probability to prefer one location with another category.

Many of the recent works suppose to only model the ob-served rating, which is adapted to explicit feedback datasets. However, the check-in dataset is implicit feedback dataset, where we do not have explicit feedback for user X  X  prefer-ence to locations. In other words, we lack substantial evi-dence on which location the user dislikes. To address user cold start problem and data sparseness problem, we propose to model the observed preference, potential preference and unobserved preference of users for location, simultaneously. Let j , k , h denote the observed location, potential location and unobserved location, respectively. The loss function of general form is given as follows: where E i (  X  ) is the loss function for the observed, potential and unobserved preference of user i for locations, and  X (  X  ) is a regularization term with ` 2 norm which is defined as: where  X  u ,  X  v and  X  q are the regularization constants. We develop two different types of models which use different loss function for E i (  X  ), i.e., the square error based and the ranking error based loss functions, and will be described in the next two sections, respectively.
In this section, we present the Augmented Square error based Matrix Factorization ( ASMF ) model constrained with the square error loss function and its optimization method.
Due to the similar interests between friends, one user might have opportunity to visit those potential locations that her friends have visited before but she never checks-in. We treat each individual user X  X  check-ins as an indica-tion of positive, potential and negative preference associated with different confidence. One user has a high confidence for the positive preference to their checked-in POIs. However, she will have a low confidence for the potential preference to those potential locations and the negative preference to other unvisited locations. Correspondingly, we augment the binary preference variable p ij to a ternary value as follows: where  X   X  [0 , 1] is a potential preference constant, indicating user i has a probability  X  to choose an unvisited location j that her friends have visited before.

Therefore, we propose the augmented square error based matrix factorization model ( ASMF ) to compute the loss E (  X  ) by using the squared error loss function with the ternary variable defined in Eq.(10), given by: where W is the confidential matrix with element w ij as the confidential weight for user i to location j , given by: where  X  is the tuning parameter.
In ASMF model, based on the Eq.(7), Eq.(8) and Eq.(11), the matrices U , V , and Q are learned by minimizing the following regularized optimization problem:
To solve the above optimization problem, we adopt Alter-nating Least Squares (ALS) [8] optimization method due to the accurate parameter estimation and fast convergence rate. We perform ALS method to compute each latent vari-able by fixing the other variables when minimizing the ob-jective function. The updating formulas with respect to U , V and Q are given as follows: where I K is the K -dimension unit matrix, N c is the set of locations with category c , and  X  q ic j is equal to q ic detailed algorithm is reported in Algorithm 1. Specifically, we place the non-negative constraints on Q and project the negative variables to 0 in each iteration.
 Algorithm 1: ASMF Optimization
Complexity Analysis. The complexity of direct com-putation is O ( NMK 2 ) which is extremely inefficient partic-ularly with the increase of locations and users. To improve the efficiency, we design the following updating strategies. For updating u i , we employ the similar trick in [6], i.e., For each category c , P j  X  X  c v j v T j is independent of i and already pre-computed, so the time complexity of this term is O ( CK 2 ) and C is usually very small. The cost time of the second term is O ( n i K 2 ) , where the potential part can be pre-computed and n i is the number of observed locations for which r ij &gt; 0 . In addition, the inverse of a K  X  K matrix costs O ( K 3 ) . Consequently, the re-computation of u i is performed where n is defined as n = P i n i .

Similarly, when updating v j , we have P i w ij  X  q 2 term is independent of j and was already pre-computed. Thus, the total cost time over M locations is O ( nK 2 + MK To update q ic , we can rewrite the crucial expression as number of locations for which r ij &gt; 0 and belongs to cate-gory c . The total complexity of updating Q is O ( NCK 2 + Kn )
In a summary, for each iteration of optimization, the total usually satisfied. In other words, the time complexity of one optimization iteration is in linear proportion to the number of observed check-ins.
In this section, we present the Augmented Ranking er-ror based Matrix Factorization ( ARMF ) model constrained with the ranking error loss and its optimization method.
In check-in dataset, we only have a user X  X  check-in record and do not know how much she dislikes a location. In other words, an unvisited location does not necessarily indicate the user dislikes it. The unobserved data actually is a mixture of negative preference for locations and missing values. It mo-tivates us to consider a ranking error based loss function for modeling the ranking order of user X  X  preference for observed locations, potential locations and unobserved locations. We assume that the user prefers an observed location over all potential locations, and at the same time she prefers a po-tential location over all other unobserved locations. Thus, for user i , the ranking order of her preference over an ob-served location j  X  M o i , a potential location k  X  M p i an unobserved location h  X  X  u i is given as the following:
To this end, we propose the augmented ranking error based matrix factorization ( ARMF ) to compute the loss E (  X  ) by using the ranking error loss function, given by, where  X  ( x ) = 1 1+ e  X  x is the logistic sigmoid function which is introduced to penalize the violated constraints in Eq.(17). As we can see in Eq.(18), the error function does not focus on predicting the right value, but on the ordering of the preference for observed, potential and unobserved locations.
In ARMF model, based on the Eq.(7), Eq.(8) and Eq.(18), the matrices U , V , and Q are learned by minimizing the following regularized optimization problem:
As there is no close-form for each variable with ALS ap-proach, a Stochastic Gradient Descent (SGD) using the boos-trap sampling with replacement algorithm is employed to solve the optimization problem in Eq.(19). The optimiza-tion algorithm is iteratively performed by sampling a tuple ( i,j,k,h ) and updating the corresponding variables, where i is a user, j  X  M o i is her observed location, k  X  M p i potential location, and h  X  X  u i is other unobserved location. More details of optimization are provided in Algorithm 2.
Complexity Analysis. The run time of sampling a tu-ple ( i,j,k,h ) is quite small in each update and can be ne-glected. Hence, the complexity of the optimization algo-rithm is O ( mK ), where m is the total iteration number. In the experiments, m is proportional to the number of ob-served check-ins.
 Algorithm 2: ARMF Optimization
Different from online product consuming, a POI X  X  geo-graphical distance significantly affects the user X  X  check-in decision making process. One user would have a small prob-ability to check-in a location far away, even though she is interested in it. In the example shown in Figure 1, user u has more chance to check-in the locations in the left side than those in the right side. It motivates us to incorpo-rate the geographical influence into user X  X  decision on POIs. Thus, the probability that user i prefers a POI j is: where p G ij is the geographical influence shown in Eq.(4).
Our goal is to recommend unvisited locations for users which they might be interested in. For each individual user, we first predict the probability that this user would check-in each unvisited location and then recommend the top-K lo-cations with the highest probabilities for her. In particular, we adopt the following strategies for recommendation.  X  Standard Recommendation. Similar to traditional recommendation, we consider to recommend the existing users with the existing locations. After learning the model from training data, we exploit Eq.(20) to predict the prob-ability that one user prefers each unvisited location.  X  New User Recommendation. When new users enter the system, we consider to recommend them with the ex-isting locations. First, we need to re-train the models with these new users by leveraging the historical check-ins of their social friends and neighboring friends. As new users do not have check-ins, they do not have location friends but they have neighboring friends. After the latent factors are learned, Eq.(20) is employed for recommendations.  X  New Location Recommendation. When new loca-tions enter the system, we consider to recommend existed users for them. By utilizing the neighboring location char-acteristics, the probability that user i checks-in a new lo-cation j is defined as follows: where  X   X  j is the set of S nearest neighboring locations of location j in the training data and in the experiments S is set as 10. The advantage to exploit the similarity of neighboring locations is that we can handle new locations as soon as they are generated in the system, without need-ing to re-train the model and estimate new parameters.
In this section, we evaluate the proposed models with baseline methods on two real-world data sets.
Datasets. In this paper, we use Gowalla and Foursquare datasets to evaluate the performance of the proposed mod-els. Gowalla contains check-in data ranging from January 2009 to August 2010, and Foursquare includes the check-in data of users who live in California, ranging from Decem-ber 2009 to June 2013. Each check-in record in the datasets includes a user ID, a location ID and a timestamp, where each location has latitude, longitude and category informa-tion. Totally, there are 262 and 10 categories in Gowalla and Foursquare, respectively. Also, data sets have undirected friendship information and user X  X  home information 3 .
To evaluate model X  X  cold-start recommendation perfor-mance, for each data set, we divide it in three steps. First, we remove those users who have visited less than 10 loca-tions and those locations which are visited by less than 10 users. These check-ins are used to evaluate our model X  X  per-formance for standard POI recommendation. In recommen-dation system, we aim to recommend those unvisited loca-tions for users. Therefore, we split the training and testing data as follows: for each individual user, (1) aggregating the check-ins for each location; (2) sorting the location accord-ing to the first time that the user checked-in; (3) selecting the earliest 80% to train the model and using the next 20% as testing. Second, in the rest of check-ins (i.e., locations that are visited by less than 10 users and not included in the training), we use those check-ins whose locations are visited by users in the training data to evaluate the model X  X  performance for new location recommendation. Third, in the rest of check-ins (i.e., users who have visited less than 10 locations), we use those check-ins where users are not in training data to evaluate user cold-start recommendation performance. The data statistics are shown in Table 1.
Experimental Settings. In the experiments, the pa-rameters  X  ,  X  u ,  X  v ,  X  ,  X  and  X  are set to 0 . 15, 0 . 015, 0 . 015, 0 . 5, 0 . 001, and 0 . 1, respectively. In Gowalla dataset,  X  , and  X  q are set to 0 . 3 and 500. In Foursquare dataset,  X  and  X  are set to 0 . 1 and 300. We will discuss the influence of  X  in the Section 5.4.4. The latent feature number is set as 10. Our model can be applied in the general check-in datasets. The home location can be estimated by using the existing approach in [2, 3]
As POI recommender system only recommends the lim-ited locations for users, we quantitatively evaluate our mod-els versus other models in terms of ranking performance, i.e., Precision@K and Recall@K metrics. MAP metric, the mean of the average precision (AP) over all locations in the test-ing, is also adopted in the experiments to evaluate models X  performance. They are formally defined as follows: where S i ( K ) is a set of top-K unvisited locations recom-mended to user i excluding those locations in the training, and T i is a set of locations that are visited by user i in the testing.  X  m i is the number of the returned locations in the list for user i , p ( j ) is the precision of a cut-off rank list from 1 to j , and rel ( j ) is an indicator function that equals to 1 if the location is visited in the testing, otherwise equals to 0.
To comparatively demonstrate the effectiveness of our mod-els, we compare them with the following seven models:  X  USG [28], which combines geographical influence, social network and user interest with collaborative filtering;  X  IRenMF [15], which models geographical influence by in-corporating neighboring characteristics into weighted ma-trix factorization in both instance level and region level;  X  LOCABAL [22], which models two types of social rela-tions: social friends and the users with high global repu-tations, in the framework of matrix factorization;  X  RegPMF [16], which models the influence of social net-work by placing a social regularization constraint on learn-ing user-specific feature vectors between friends;  X  PMF [20], which minimizes the square error loss only us-ing the observed check-ins based on matrix factorization.  X  WRMF [6], which minimizes the square error loss by assigning both observed and unobserved check-ins with different confidential values based on matrix factorization;  X  BRP [18], which optimizes the ordering of the preference for the observed location and the unobserved location.
In this paper, we develop two methods to learn the poten-tial locations for each user (i.e., LA , RW ) and then design two loss functions: ASMF and ARMF . Thus we consider the following combinations: ASMF + LA , ASMF + RW , ARMF + LA , ARMF + RW , which are denoted as ASMF-LA , ASMF-RW , ARMF-LA , ARMF-RW , respectively.
In this section, we evaluate the proposed models for stan-dard recommendation, new location and new user recom-mendation in terms of Precision@K, Recall@K and MAP. In addition, we discuss the influence of  X  in ASMF-LA model.
The performance comparison of our models and baseline models in terms of Precision@K, Recall@K, and Map are shown in Figure 3, Figure 4 and Table 2.

Modeling observed check-ins v.s. modeling all check-ins. From the results, we can see that WRMF and BPR almost outperform LOCABAL , RegPMF and PMF . Even though LOCABAL and RegPMF incorporate social network into matrix factorization, the sparseness of data due to only modeling the observed check-ins results in their poor perfor-mance. Both LOCABAL and RegPMF are slightly superior to PMF . One possible explanation is that social network assists to make more accurate recommendation. Different from them, WRMF not only utilizes the observed check-ins, but also models negative preference for all unvisited loca-tions with a low confidence. But BPR easily leads to bias by only sampling some unvisited locations, which explains why it performs not good in Foursquare data set.

Our models v.s. baseline models. Our models achieve the best performance in both data sets with all evaluation metrics, illustrating the superiority of our approaches. Al-though USG exploits social influence, geographical effect and user interest, its simple linear combination results in the poor performance. As Gowalla covers a much larger area than Foursquare, the clustering result is not good, lead-ing to the worse performance of IRenMF in Gowalla than in Foursquare. ARMF and ASMF have different perfor-mance in two datasets which is consistent with performance of WRMF and BPR . Their similar performance in Gowalla is due to the much more evident spatial clustering phe-nomenon. Two approaches to learn potential locations per-form similarly. But LA is more efficient than RW because it does not require any matrix operation. In addition, the bet-ter performance of our models in Gowalla than in Foursquare is for the sake of (1) the stronger correlation in Gowalla which is reflected in Figure 2(c) and Figure 2(d), and (2) the more detailed category in Gowalla than in Foursquare, where Gowalla has 262 kinds of categories while Foursquare only has 10 different categories.
In this section, we evaluate the model performance of ad-dressing location cold-start problem. To recommend new locations, we predict the check-in probability for each new location and then recommend the top-K locations with the highest probabilities. Note that, among all the baseline methods, only USG and IRenMF can be applied here. Since new locations are never checked-in by any users, USG is re-duced to only model the geographical influence. In addition, the latent location vectors for new locations are not learned in the training, so one user X  X  preference for a new location in IRenMF model is actually dependent on her preferences for this location X  X  neighborhoods. The model performance in terms of precision, recall and MAP is shown in Table 3. (a) Precision@K on Gowalla (a) Precision@K on Gowalla Figure 5: The performance comparison of new user recommendation on Gowalla data set (top) and Fousquare data set(bottom).

Based on the results, we can observe that IRenMF per-forms the worst among all methods on both datasets. Al-though taking advantage of the similarities of neighboring locations, IRenMF fails to appropriately model user X  X  check-in behaviours. It happens likely due to that it does not well exploit the inherent characteristics of geographical dis-tance. On the other hand, our models and USG utilize the power-law distribution to capture the spatial clustering phe-nomenon for user X  X  check-in activities, which is based on the observation over data. Therefore, they have much better performance than IRrenMF model in location cold-start rec-ommendation. Also, our models gain superior performance over USG . A possible reason is that a user X  X  preference latent vector has been learned in the training so that her preference on the target location X  X  neighborhoods can be accurately predicted. However, USG only leverages the geographical similarity between a new location and her historical POIs as prediction. In addition, the performance of ASMF and ARMF is consistent with earlier experimental results.
In this section, we evaluate model X  X  recommendation per-formance for user cold-start problem. When a new user en-ters the system, we do not have her historical check-in infor-mation. As a result, her latent vector cannot be learned and all of these baseline methods could not address this problem. The proposed models elaborate the historical check-ins of a user X  X  neighboring friends (and social friends if she has) to learn her preference vector. Thus, they can be adopted to cope with user cold-start problem. As the proposed aug-menting framework could be adapted to WRMF and BPR based models, we construct the following baseline methods with the similar loss functions in Eq.(18) and Eq.(11): (1) WRMF+LA , denoted as AWRMF-LA ; (2) WRMF+RW , de-noted as AWRMF-RW ; (3) BPR+LA , denoted as ABPR-LA ; (4) BPR+RW , denoted as ABPR-RW . The precision, recall and MAP of these models over two datasets are shown in Figure 5 and Table 4.

From the results, we find that all models have good perfor-mance to address user cold-start problem. The augmenting approach with friends X  historical check-ins significantly ben-efits the location recommendation, in particular user cold-start recommendation. Meanwhile, the successful applica-tion of the augmenting strategy in WRMF and BPR demon-strates that the proposed augmenting strategy can be easily applied in any square error and ranking error based matrix factorization models. Moreover, our models perform much better than the baseline approaches for the sake of exploit-ing geographical influence and category information. ARMF and ASMF perform consistently as above results. Overall, we can see that our models can handle user cold-start prob-lem very well.
The ASMF model treats user X  X  check-in as an indication of positive, potential and negative preference with difference confidence. The parameter  X  shown in Eq.(10) indicates the probability that users will check-in an unvisited location which her friends have checked-in before. In this section, we study the influence of variable  X  . Due to limited space, we only show the performance of ASMF model with Linear Ag-gregation . The precision, recall and MAP of ASMF-LA with different  X  value over two datasets are reported in Figure 6.
Based on the results, we can observe that the performance in all evaluation metrics has similar behaviour with the vary-ing value of  X  . It is observed that ASMF-LA achieves the best performance when  X  is 0 . 3 and 0 . 1 on Gowalla and Foursquare, respectively. The performance then drops dra-matically when  X  goes far away from the maximum point. If the  X  is set as a very small value, it will have no major differ-ence to optimize those potential check-ins and other unob-served check-ins, which makes ASMF-LA difficult to obtain more accuracy prediction. If the  X  is set with a very large value, it will easily generate noise when optimizing both her own and friends X  historical check-ins. It occurs possibly due to some other locations that a user X  X  friends have checked-in but she might be in fact not interested in. As a result,  X  with a large value would probably affect the entire optimization process. Furthermore, the maximum point of  X  on Gowalla is larger than the one on Foursqaure, which indicates that users would have a larger chance to check-in their friends X  POIs on Gowalla. This result is consistent with the observa-tion that the correlation between users in Gowalla is much stronger than that in Foursquare. At last, we find that the performance with different  X  value on Gowalla changes much smaller than that on Foursquare. The more evident spatial clustering phenomenon on Gowalla than that on Foursquare is a reasonable explanation why ASMF-LA has such small change. On Gowalla dataset, geographical distance plays an extremely important role on affecting user X  X  POI decision so that it compromises the prediction result even though user interest has a big change.
Related works about POI recommendation can be grouped into two categories. The first category focuses on mod-eling geographical influence [28, 3, 1, 30, 13, 14, 12, 15, 17]. Specifically, there are several approaches to model geo-graphical distance. For example, some approaches leveraged Gaussian mixture model to characterize user X  X  check-in ac-tivities [3, 1]; While some approaches utilized the kernel density estimation (KDE) to study user X  X  check-in behavior and avoid employing a specific distribution[30, 13]. [28] pro-posed to use a power law distribution to estimate the check-in probability with the distance of any pair of visited POIs due to the spatial clustering phenomenon exhibited in LB-SNs. The user X  X  preference for one location is predicted by a linear model with combining users X  interest, social friends X  interests and geographical influence. Later, [15] considered two types of geographical neighborhood characteristics: in-stance level and region level. Specifically, in instance level, a user X  X  preference for one location is modeled by a com-bination of her preference for this location and the nearest neighborhoods of this location. In region level, it places a group lasso penalty to learn location-specific latent vectors and capture the region effect.

The second category throws light on elaborating social network information [16, 5, 22, 28, 25, 4, 27, 7, 21, 9]. For example, [27, 28] proposed user-based collaborative filter-ing to estimate the unobserved rating by directly using the check-in information of friends. [16] assumed friends would share similar interests and then placed a social regularization term to constrain the objective functions for learning accu-rate user feature vectors. [5] proposed to model four types of social correlations (i.e., local friends, distant friends, lo-cal non-friends and distant non-friends) by using a geo-social correlation model with users X  check-in activities, where the check-in probability was measured as a linear combination of these four geo-social correlations and the corresponding coefficients were learned by a group of features in a logistic regression like fashion. [22] modeled local and global social relations for all users. Specifically, in local context, it mod-els the correlation between users and their friends; while in global context, it uses the reputation of a user in the whole social network as weight to fit observed ratings.

In addition, there are some recommendation works based on content, sentiments and temporal effect [10, 14, 26, 17, 29, 31]. However, our work is different from these existing works. To be specific, we first learn user X  X  potential loca-tions with the check-in information of social friends, loca-tion friends and neighboring friends, and then incorporate them into matrix factorization model using different error loss functions.
In this paper, we proposed a two-step framework for POI recommendation problem, which considers the check-in in-formation of three types of friends, i.e., social friends, loca-Figure 6: The influence of  X  on Gowalla data set (left) and Foursquare data set (right). tion friends and neighboring friends. Specifically, in the first step, we designed two approaches to learn the locations that a user X  X  friends had checked-in before and she was most in-terested in. In the second step, we developed matrix factor-ization based models with two different error loss functions using the learned potential locations. Specifically, the square error based loss extended a binary preference to a ternary variable for the observed check-ins, potential check-ins and other unobserved check-ins, and the ranking error based loss modeled the ranking of user X  X  preference for her visited loca-tions, potential locations, and unvisited locations. Finally, experimental results on two real-world data sets clearly val-idated the improvement of our models over many baseline methods based on different validation metrics.
 This work is partially supported by NIH (1R21AA023975-01) and NSFC (71571093, 71372188, 61572032).
