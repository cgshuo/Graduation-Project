 In recent years, as digital cameras become increasingly affordable and widespread, personal digital photos are growing exponentially and photo sharing through the In-ternet also becomes a common practice. To achieve the potential value of large image collections, users have to be able to search and access images effectively. Image anno-tation, the task of associating textual words to the images, is a good way to reduce the semantic gap and can be used as an intermediate step to image retrieval. It enables users to retrieve images by text queries and often provides semantically better results than content-based image retrieval. In recent years, automatic image annotation based on machine learning has attracted more and more research interests.

Machine learning considers learning a function which can be used to compute the output provided the input [Bousquet et al. 2003]. In methodology, function learning is done by imposing some regularity condition on the function to learn, and minimizing the regularized sum of residual error. In this way, machine learning algorithms can achieve good performance in terms of generalization.

However, when the application area of machine learning is broadened, new appli-cation areas where data are presented with multiple modalities or cross-media in-formation. This puts new demand on machine learning methodology which can deal with more complex data structure and learning among them consistently by sharing knowledge over the whole problem [Li et al. 2009]. For example, in the image an-notation area, images have visual features and textual annotations, and some may even have information like events, categories, users, etc. When the knowledge of so-cial network are introduced, the problem structure becomes further inter-correlated [Chang and Blei 2009]. If we are going to do function learning in the traditional way, then multiple function learning instances should be conducted, such as function from visual features to textual labels (for image categorization), function from meta infor-mation to visual features (for image retrieval), etc. For example, in Chang and Sychay [2003], individual classifiers are trained for each potential annotation labels. Sharing knowledge among different function learning instances are not so straightforward, but in order to achieve better performance, it has to be done.

Statistical modeling and inference are thus introduced into the machine learning area to deal with this problem [Jordan 1999]. In statistical inference, all the variables in a certain problem domain are modeled as random variables, there are also certain latent variables to help modeling the problem in a compact way. And the structure of the problem is modeled as the probabilistic dependency among all these variables. Statistical inference in this case, is a general methodology to infer believes of some variables given the observations of some others.

With these benefits at hand, there are also two major problems of statistical in-ference, one about modeling [Bilmes 2004] and the other about inference [Pearl 1988]. These difficulties require the statistical modeling process to use exponential family dis-tributions together with conjugacy constraints among variables, so that the inference algorithm will not rely too heavily on sampling techniques [Bishop 2007]. Even with these, approximate inferences are still required for relatively large scale problems, such as variational inference and Gibbs sampling, both of which further introduce performance loss. Thus, a relatively weak modeling procedure with its weakness com-plemented by the regularization imposed on is preferred. In this way, the statistical modeling can remain in a certain level of simplicity, but the responsibility to ensure learning performance is achieved by using regularization. This is the main standpoint of this article.

For image annotation, the fundamental problem is how to model the relationship among different modalities, including visual features and textual annotations, associ-ated with the possibly existed latent topics of images, as well as the relationship among different images. Latent topic modeling has long been a promising approach for this problem [Blei and Jordan 2003; Barnard et al. 2003; Monay and Gatica-Perez 2003, 2004]. As is common, model based approaches have the benefit of better efficiency and stability, while it suffers mostly from probably insufficient modeling, that is, when the model does not fully describe the problem domain, the inferred quantities may not be accurate, for example, if data is not distributed in a Gaussian distribution, modeling it with a Gaussian will cause problems. For image annotation, it is always difficult for the probabilistic modeling to be sufficient due to the high variance of image contents.
In the contrast, traditional similarity-based approaches, for example, spectral clus-tering [Belkin and Niyogi 2001] and manifold learning approaches [Belkin et al. 2006; Song and Tao 2010; Zhou et al. 2010], do not have to assume the specific probability structure of data, and requires only a similarity function defined on pairs of data in-stances. Recently, this approach has been shown to be successful in the semi-supervised context [Belkin et al. 2006; Zhou et al. 2005]. When regarded as a regularization, it is also applicable to probabilistic models [He et al. 2009a; Mei et al. 2008; Cai et al. 2008]. We try to introduce this approach into model-based image annotation.

In practice, for images sharing some collective properties, it is reasonable to assume they have similar semantic concepts. Recently, machine learning approaches utilized by such similarity constraints in the graph Laplacian form are applied widely [He 2010; He at al. 2009b, 2009c, 2009d]. In our previous work [Shao et al. 2009], we incorporated the manifold assumption [Belkin et al. 2006] to say that the probabilities of latent topics of images reside on or close to a manifold, so that for images sharing similar visual features or the same annotations, they should have similar probabilities over different latent topics. We then fit the generative model with respect to the manifold structure which is modeled by a nearest neighbor graph. Using graph Laplacian, the manifold structure can be incorporated in the standard EM algorithm as a regularization term [He et al. 2009a; Mei et al. 2008; Cai et al. 2008], and the semi-supervised annotation can be carried out in a consistent fashion. Our experimental results show that the latent topics learned in this way catches better the similarity relationship between images, which reflect some properties of discriminative learning.

In this article, we make use of the regularization with graph Laplacian [He et al. 2009a; Mei et al. 2008; Cai et al. 2008] as a transductive learning approach to put reg-ularization on the variational inference technique. Induced from spectral graph theory and manifold learning theory, Laplacian regularization is a widely adopted framework for regularization on function learning by incorporating with the intrinsic geometry of the manifold structure as well as being compatible with different function learning techniques specifically. When it was used as a transductive learning approach, we don X  X  require the explicit modeling of the manifold structure in the domain of the function. The adjacency graph can be induced from any kind of relational learning scenario or network structure introduced externally to the problem. We then pick a certain set of random variables in the statistical modeling as labels to assign. The believes of the latent random variables, represented as variational distributions, are an analog to the output of the function. We imposed graph regularization on these variational distribu-tions of the latent random variables and estimate them by maximizing the regularized variational free energy.

In the latter part of the article, we first provide a brief introduction of the statistical inference approach, with a focus on the variational inference particularly. Then, we pay some attention to the function-learning framework, where we also investigated the role of regularization in machine learning, which provide a clue for our regularization. Then, we derive and defined the graph regularization term. Two algorithms are designed to solve the optimization, whose feasibility issues are considered in depth in the following section. Finally, we show experimental results on image annotation, compared to two previous approaches as the state-of-the-art. As our work is the combination of graph regularization and variational inference, we first provide a brief description of these two related technologies. We will also describe their strength and shortage in brief. Statistical inference considers the problem of looking for the posterior probability of some random variables given the observations of some other random variables. Vari-ational inference is a powerful statistical inference technique that is approximate but efficient enough to be carried out in practice for median or large scale machine learning problems. In this section, we will briefly introduce this method.

For a directed acyclic graphical model with hidden variables set H , observed variables set V (with observation v , but we ignored this for simplicity), and U U respectively, we have
The general objective of statistical inference is to find the estimated posterior distri-bution
Since the integration usually yield intractable functional forms, making exact statis-tical inference quite difficult in practice. Various approximate inference techniques are proposed in this consideration. Among them, the variational inference is a practically efficient one, and its approximation is relatively tolerable.

The objective of variational inference, is to find a variational distribution q ( H ) ,which approximates the true posterior distribution p ( H | V ) as close as possible. In accordance with specific problem settings, the variational distribution can be either factorized or in a whole, either freeform or parametrized. Its closeness to the true posterior is measured by the Kullback X  X eibler divergence. Here we use the notation f ( x ) p ( x ) to represent the expectation f ( x ) p ( x ) dx ,or p ( V ) can be regarded as a constant. So the maximization can be done with respect to the first two terms in the last line of Eq. (3). This was defined as the variational free energy [Neal and Hinton 1999], The first term is the so-called complete data log likelihood, and the second term is the entropy. The benefit of maximizing this equation is that the functional form of p ( H can be specified by the statistical modeling of the problem, and the expectations in the equation usually has tractable form when certain assumptions are imposed, such as the restriction of exponential family distributions.
 In the variational inference method, the objective is to maximize q ( H ) , Here, Z H ( V ) is the normalization constant depend on the observed values of V .When the variational distribution q ( H ) is freeform, or in another way, nonparametric, it has the following derivation:
In this case, it equals the exact posterior distribution of H . Otherwise, when it is parametric, the parametric form of q ( H ) which is nearest to the posterior distribution in the measure of Kullback X  X eibler divergence is to be estimated.
 Variational method itself does not impose factorizable assumption to the form of q ( H ) . While in practice, the variational distribution is usually further factorized. According to the level of factorization, there are fully factorized variational inference [Jordan et al. 1999] and generalized mean field methods [Xing et al. 2003]. The latter is not the focus of this article thus is not mentioned.

When q ( H ) is fully factorized, it has the form of Note that this does not mean that the posterior distribution p ( H otherwise, inferring any unknown information does not have anything to do with the known information at hand. Rather, it means that the variational distribution used to approximate it can be factorized. When the optimization is done, we regard each esti-mated q ( H ) as a proper approximation to the corresponding true posterior distribution p ( H | U \ H ) .

Once the variational distribution is factorized, the optimized variational free energy can be decomposed into a summation of the expected log likelihoods, In this case, if we look at the terms depend on the variational distribution of a specific H , namely q ( H ) , the variational free energy is,
Thus, in the equilibrium state when all the variational distributions are optimized, the optimal value of q  X  ( H ) depends only on the optimal variational distributions of its Markov blanket, namely q  X  ( pa ( H )) , q  X  ch ( H ) and q is done by each time we pick up a latent variable H at random and update its variational distribution by maximizing the variational free energy F H optimization depends only on the variational distributions or observations of its Markov blanket. Then we iterate this procedure over all the latent variables, until no significant change of the variational free energy F is detected. Other inference scheduling instead of wholly random is also possible, such as the Bayesian EM [Attias 2000].
In methodology, the way how statistical inference solves machine learning problems is by modeling the problem domain with random variables and probabilistic depen-dencies among them, then infer the unknown quantities. It is flexible in the sense that inference can be done in any direction with any pattern of missing values. But the major problem is the difficulty of modeling. For example, the network-structured similarity constraint is usually represented in an undirected Markov random field, but when it comes to latent topic modeling of textual annotations or visual words of images, the model is usually directed Bayesian networks. If we want our model to benefit from both paradigms, we will easily come up with a model in the form of a chain graph, which is rather difficult to do inference usually. In this section, we will introduce the graph regularization approach interpreted in its geometrical background of manifold learning.

In traditional statistical learning, we define the joint probability distribution p ( X of data X and label Y over X  X  Y , according to which training data are sampled for function learning. According to the empirical risk minimization principle [Vapnik 1995, 1998; Hastie et al. 2001], the optimal function estimated has the form of, where V ( y 0 , f ( x 0 )) is the empirical loss of the function computed at the data point x with the ground truth predicate of y 0 .Inthisway, p ( X ) does not have to be estimated. In the task of predicting labels for a given data item, we only have to estimate p ( Y This is the idea of discriminative learning.

In the framework of manifold regularization [Belkin et al. 2006], however, some re-lationship between those two are created. To be more specific, when estimating p ( Y for function learning, we want to put constraint on it at the support of p ( X ) .
To make use of p ( X ) , we need to exploit its intrinsic geometry. In the work of manifold regularization, a particular case is considered where the probability distribution p ( X ) (referred to as the marginal distribution) is supported on a submanifold of an ambient space.

Manifolds are generalizations of curves and surfaces to arbitrarily many dimen-sions. In the simplest terms, these are spaces that locally look like some Euclidean space R d , and on which one can do calculus. The most familiar examples, aside from Euclidean spaces themselves, are smooth plane curves such as circles and parabolas, and smooth surfaces such as spheres, tori, paraboloids, ellipsoids, and hyperboloids. When the manifold is embedded in a high dimensional Euclidean space call it submanifold of R n and this Euclidean space is called ambient space. The formal definition of submanifolds is as follows:
Definition of Submanifolds. Let M be a subset of R n such that for every point x there exists a neighborhood U x of x in R n and d continuously differentiable functions  X  k : U Then, M is called a submanifold of R n of dimension d [He et al. 2009a].

In the work of manifold regularization, the penalty term to ensure the smoothness of the function f is imposed on the function learning objective induced from the Em-pirical Risk Minimization principle, where the regularizer f compactness of the submanifold M [He et al. 2009a]. Here  X  M f is the gradient of f along the manifold M and the integral is taken over the marginal distribution. L is the Laplace X  X eltrami operator, In practice, the manifold structure M is usually unknown, thus Eq.(12) is unable to be calculated. For this reason, a nearest neighbor graph is used to capture the manifold structure. We denote the observation x i  X  X  as nodes. For each x look for its K nearest neighbors, and for each x j in its nearest neighbor set, we connect an edge i , j in between the two nodes. The graph formed in this way is denoted as Weights of the edges are further assigned to form an adjacency matrix S accordance with spectral graph theory [Chung 1997], we can use a discrete equation to approximate the continuous case in Eq. (12) The approximation gets better when there are more data items. The regularization in this equation is then appended to the function learning objective.

If we denote the outputs of the function as f i = f ( x i the previous equation can be rewritten in the form of graph Laplacian, where L = D  X  S is the Laplacian matrix with D = diag ( S adjacency matrix.

In case of transductive learning or semi-supervised learning where not all the data items are with labels, and what we focus on is to label them instead of learning the function f , then the regularizer can be written as In this way, the regularizer is imposed on the labels, not the function. The regularizer in this form based on graph Laplacian can be used in situations where the adjacency graph is not necessarily coming from the intrinsic geometry of p ( X ) . It can be induced from any similarity measure or network structure of the problem. And the regularization is to impose similarity constraints on the label pairs restricted by the adjacency graph. In this section, we show the specific form of graph regularization imposed on the varia-tional inference procedure. We regard variational distributions to estimate as believes associated with the random variables, which are considered as  X  X abels X , and then im-pose graph regularization in a similar way as the function learning or transductive learning in Section 2.2.

In some situation, there may be a certain number of, say N  X  X bjects X  in the problem domain, such as N documents, N images, or N authors, etc. When modeling such a problem domain, each object may be associated with a set of random variables. Among these random variables, some may have an identical sample space over all the objects. For example, if we associate each of the N documents a latent semantic variable of the same kind, then these variables fall in this category. Note that such random variables of a specific object may be either latent or observed. In case that all these random variables regarded as  X  X abel X  are observed, then it is typically a supervised learning scenario. There are also corresponding semi-supervised learning and unsupervised learning scenarios. Similar with these function learning scenarios, our task is to esti-mate the believes associated with these variables, which are represented as factorized variational distributions associated with these variables. By this formulation, we can incorporate the regularization framework in typical function learning. We call such random variables whose variational distributions to estimate can have some form of regularization imposed on as  X  X andom variables for regularization X .

One of the benefits of statistical modeling is to deal with multiple attributes associ-ated with training instances. It is also possible that more than one of such attributes modeled in random variables requires regularization. Each one of such attributes is allowed to have different observation patterns over all objects. To be concrete and with-out loss of generality, in the latter part of this article, we consider the case where each object is associated with one type of random variables for regularization, denoted as Z for the i th object.

As indicated by the shapes, we treat Bayesian estimated latent variables in a same way as observed variables with soft evidences. The former has a variable distribution associated with it, while the latter has a constant one. The distribution associated with each variable Z is represented uniformly as q ( Z ) , no matter whether it is a variational distribution to estimate or a soft evidence observed on this variable. Furthermore, point values, either to be estimated or observed, can be regarded as a distribution represented in Dirac functions  X  ( Z , z  X  ) , thus, they are also in the form of a q ( Z ) formally.
By using these notations, now we can treat q ( Z 1 ) ,..., tion learning in manifold regularization or as labels of the graph Laplacian. Take man-ifold regularization as an example, let q ( X 1 ) ,..., q ( X objects, also modeled as random variables, but with point observed values x The function f to learn in manifold regularization now has a domain Z . Here, X is the sample space of X ,and Z is the sample space of Z .
 the space of all the probability density or mass functions over possible values of X all lie on a manifold M , then the smoothness of function f on the support of M is The corresponding discrete form as a regularization term now becomes the following (check Mei et al. [2008] for the motivation) where d (  X  ,  X  ) is the distance between two probability distributions.
 neighbor graph of the training data instances created to capture the manifold structure. S = S 1 / N 2 is ignored as the regularization term has a hand-tuned weighting constant on it.
Here, we do not specify the form of the distances, for example, they can be KL-divergences [Tao et al. 2009] or Bregman divergences [Si et al. 2010]. In the case when the distance is induced by an inner product, the regularization term can be further written as where L = [ L ij ] is the Laplacian matrix. L = D  X  S . D is a diagonal matrix whose diagonal elements are the row sums of S .

In the case of general graph Laplacian induced from the network structure instead of manifold regularization, there may not even be the observed X part in the statistical modeling. But the regularization term can still be formulated as Eq. (19) with an externally defined adjacency matrix of the network or graph structure.

In both manifold regularization and graph Laplacian cases of the last section, we can append the regularization term to the variational free energy of Eq. (4), yielding a regularized objective function, Here we still assume that all the latent and observed variables in the statistical model-ing are H and V respectively. And U = H  X  V is the set of all the variables. The random variables set Z = { Z 1 ,..., Z N } isasubsetof U .

We argue that such configuration is useful in practice. First, the statistical mod-eling in a graphical model is usually a simplification to the underlying true process [Bilmes 2004], it is unable to involve all the representative random variables in the problem domain nor to capture the full probability dependency among them. Further-more, the variational inference served as an approximate inference technique imposed another level of approximation, which introduces more inference bias into the problem. Graph regularization, thus provide a way to introduce another kind of prior knowledge coming from the network structure of the problem which is originally difficult to be utilized in statistical modeling. Second, we argue that when doing statistical model-ing, preserving a certain kind of simplicity is necessary. For example, when modeling the semantics of documents, it is reasonable to assign a single latent topic variable to each document, otherwise the probabilistic dependency relationship, or the proba-bilistic graphical model in another way, is difficult to specify manually. And with such kind of random variables in the graph, the restriction of conjugacy requirement for the efficiency of computation greatly limited the possible types of generative models one can make use to model these variables. For these reasons, doing statistical modeling in a simple and straightforward way, and then imposing additional level of regularity conditions as constraints is not only necessary but also deserving. Since the regularization term corresponding to one set of random variables involves the variational distribution (or soft evidences) of those variables only, the regularized version only change the variational updating of the corresponding variables. Thus, in this section and the latter part of the analysis, we focus on describing the optimization with respect to the regularized variational distributions in which we are interested. The objective function to maximize is The optimization is done with respect to N variational distributions q ( Z As will be proved in Section 5.1, it suffices to do maximization with each variational distribution separately as in Eq. (22) and iterate over all these variational distribu-tions, similar with the original variational inference procedure. And furthermore, even message passing procedures similar with the variational message passing [Winn and Bishop 2005] can be designed as well In the following two sections, we will show how we do optimization on this maximization problem. A first solution is by using standard Newton X  X  method on the optimization of each variational distribution q ( Z i ) . The optimization scheduling of the whole regularized variational inference process is kept the same as in original variational inference. Each time we pick a random variable and update its variational distribution q ( Z maximizing the regularized variational free energy Q , and iterate this process on all the random variables, until the variational free energy does not change significantly. The validity of such iterative approach needs theoretical justification about its convergence. This is done in Section 5.1. Thus here we are safe to do so. Iteratively updating each random variable is possible and will not cause problem in the case of local maxima searching. We call this algorithm LapVar1. In accordance with the type of the random variable Z i , there are three cases for which the optimization is carried out,  X  Bayesian estimated, nonparametric . A typical scenario for this case is the Bayesian estimated discrete variable. Optimization in this case is done with respect to the multinomial variational parameters of the discrete random variable.  X  Bayesian estimated, parametric . Optimization in this case is done with respect to the variational parameters determined by the specific parametric form of the variational distribution.  X  Point estimated . Optimization in this case is done with respect to the optimal point values.

In the example distribution types of Section 4.3, we will give the detailed derivations of random variables fall in these categories. This solution based on Newton X  X  method is efficient enough and guaranteed to converge to some local maxima or stationary point. But in some situations, when we need even more efficient algorithms, here is a solution, which is used in our image annotation experiments.

To describe the acceleration algorithm, we first have a look at what effects the regularizer takes on to the learning problem. To do this, we can try to compute the Newton X  X  updating step for q ( Z i ) from only the regularization term length  X  ,
From this we see that the role of the regularizer is to make the variational distribu-tions more smooth. Thus, an even more efficient optimization method similar with the generalized EM can be used.

In the optimization, we group together the random variables on which the graph regularization are imposed on, and do variational updating on them at the same time by maximizing the original free energy F . After their variational updating, we do smoothing on them by using Eq. (23) until converge. Along the smoothing process we record the optimal variational distributions for which the regularized variational free energy Q is maximized. If the maximized regularized variational free energy is larger than that in the last major iteration, then the optimization continuous. We call this algorithm LapVar2. As an example, we show the derivation of regularized variational updating equations of a discrete variable, under Bayesian estimation, that is, the random variable has a sample space of a finite integer set, and we estimate a factorized variational distribution of this variable when it is treated as a hidden variable without observation.
When a discrete variable having a sample space with K values is Bayesian estimated, it is associated with K variational parameters. We denote the variational parameters of Z as  X  i = [  X  ik ] K k = 1 (i.e., here  X  ik is equivalent q ( Z to  X  Here the notation  X  q ( Z i ) means the variational distributions except q ( Z
Since we are maximizing the regularized variational energy with respect to is a simplex variable, we need to impose a Lagrange term on to the optimization to ensure the normalization. In this way, the objective function to maximize can be written as The subscript i in the Lagrange multiplier  X  i means that each Z Lagrange multiplier. The gradient vector of Q Z To solve the point with zero gradient, we get the updating vector as In this section, we give some in depth analysis of the proposed graph regularized variational inference algorithm. In this section, we are dealing with the abstract form of the regularized inference problem. By our analysis, both the original variational inference and our graph regularized variational inference are guaranteed to converge to a local minima or a stationary point, and the computational complexity is affordable. In this section, we analyze the convergence properties of our graph regularized varia-tional inference, in the situation that the variational distributions are fully factorized, and the factorized variational distributions are in their non-parametric form abstractly. We begin by check the convergence property of the original variational inference first. In these analysis, we assume that the variational updating procedure of each individual variational distribution is able to locate the local maxima or a stationary point.
First of all, we notice that when maximizing F with respect to the q ( H )  X  X , the con-straints restricting the q ( H )  X  X  normalization as a proper probability or mass density function have to be appended, making the optimization constrained, as formulated here: where 1 ( H ) is a constant function with value one.

With this formulation, to analyze the convergence we need to utilize the necessary and sufficient conditions of constrained optimization.

T HEOREM 1. If the variational updating of each individual variational distribution is guaranteed to converge to a local maxima or a stationary point, then the full variational inference in the form of a constrained optimization in Eq. (28) converges to its KKT point.

P ROOF . First, we define a helper function to simplify the notations, In assumption, for an arbitrary latent variable H  X  H , its variational updating con-verges to its local maxima or a stationary point (marked with the first-order necessary condition in Nocedal and Wright [2006], we have here  X  H is the Lagrange multiplier for the equality constraint and grange multiplier function for the inequality constraint. The left-hand side of line one in Eq. (30) is the gradient  X  h F H .Since F is a multilinear function plus a mutually independent entropy function with respect to all the q H ( h )  X  X , the joint gradient is the conjunction of all the individual gradients, The constraints are also mutually independent among all the q ( H )  X  X . So the first order necessary condition for the full variational inference problem can be written as Provided that Eq. (30) is satisfied for any H  X  H , we can easily verify that Eq. (32) is satisfied as well, thus the solution marked with  X  being the local maxima or station-ary point of all the variational updating simultaneously is the KKT point of the full variational inference.

Next, we can prove that the solution above satisfies the second order sufficient con-dition of the constrained optimization [Nocedal and Wright 2006].

T HEOREM 2. The KKT point of the full variational inference obtained in Theorem 1) is also guaranteed to be a local maxima or a stationary point.

P ROOF . The Hessian of the Lagrange function of optimization Eq. (28) is From this we see that the Lagrange function is strictly negative definite. Thus, the second order sufficient condition mentioned in Nocedal and Wright [2006] is satisfied. Thus, the KKT point is a local maxima or a stationary point.

Based on this, we can show the convergence of the graph regularized variational inference as well. The constrained optimization is as follows:
T HEOREM 3. If the updating of each individual variational distribution with the graph regularization imposed on is guaranteed to converge to a local maxima or a stationary point, then the full graph regularized variational inference in the form of a constrained optimization in Eq. (28) converges to its KKT point.

P ROOF . Similar with the proof of Theorem 1, we first form the Lagrange function of the optimization and then show that the first order necessary condition is satisfied. The first order necessary condition is still satisfied, Here is the corresponding sufficient condition,
T HEOREM 4. The KKT point of the full graph-regularized variational inference ob-tained in Theorem 3 is also guaranteed to be a local maxima or a stationary point.
P ROOF . The Hessian of the Lagrange function of optimization Eq. (34) is The first term is strictly negative definite, and the second one is negative semi-definite, so the Hessian in all is negative definite. Thus, the KKT point is a local maxima or a stationary point. The computation complexity of graph regularized variational inference algorithm Lap-Var1 in Section 4.1 is in the same level with the original variational inference algorithm. Both are O ( TN ) , where N is the number of latent random variables, T is the number of major iterations carried out over all the N latent random variables.

In the original variational inference, the variational updating of some variables does not have an analytic form, thus iterative optimization is required to obtain the solution, such as the updating of Dirichlet parameters [Minka 2003].
 While in LapVar1, more random variables require updating steps with optimization. Almost all the variables with graph regularization do so. For this reason, the computa-tion efficiency of LapVar1 is worse than the original variational inference. In practice, the loss of efficiency is affordable. Take the performance improvement into considera-tion, it is worth to do so. However, as many variables may involve minor optimization in each of its iteration, different optimization scheduling differs dramatically in com-putational efficiency. For example, some models extended from algorithms originally carried out by Expectation Maximization may divide the optimization scheduling into two major steps as E step and M step, such as the LDA model where document-topic mixing coefficients are optimized in E step. In this case, as E step itself will optimize the corresponding variational distributions until convergence each time, doing so in graph regularized variational inference usually cause unaffordable computation efficiency. In our experiments, we found that inference scheduling generally does not affect perfor-mance largely. So in our experiments, we all use fully random approach to pick the random variables to update. But we ensure that in each major iteration, each variable is updated exactly once.

In LapVar2, however, since the smoothing is done over all the random variables of one type where a specific graph regularization is imposed on, optimization scheduling has to be changed where all these variables are considered as a whole and updated at the same time. When the original variational updating of these variables has an analytic form and does not require optimization, then LapVar2 is more efficient than LapVar1, almost the same as the original variational inference. However, convergence properties are generally not guaranteed since it is a multiple objective optimization with iterations over different objectives. It can only be used when computational efficiency is very important. In this section, we show performance improvement of our proposed method in the image annotation area. We carry out our method on the mixture of unigram model, and compared to various models without graph regularization.

In the following part, we use a slightly different notation set from the standard graphical model representation [Jordan 1999], which is listed here.
 We compare our approach to the pLSA-Words model [Monay and Gatica-Perez 2004] in Figure 1(a) and the Link-LDA model [Stephen et al. 2004] in Figure 1(b). pLSA-Words is based on the pLSA model [Hofmann 1999, 2001]. It models the corre-lation between textual words and visual words [Csurka et al. 2004] by connecting two pLSA models and share the same mixing coefficients of latent topics. According to the analysis of semantic gap mentioned in Monay and Gatica-Perez [2004], the semantic level of textual words and visual words differs largely. Intuitively, it is to say that the correlation between image contents and the textual words are higher. For this rea-son, the training of the pLSA-Words model requires two stages, separating the textual and visual words. In this article, we use the same strategy when implementing the pLSA-Words model for image annotation.

Link-LDA is based on the Latent Dirichlet Allocation model [Blei et al. 2003]. It also connects the textual and visual words by two separate topic models. And share the mixing coefficients between the models. In addition, the Dirichlet parameters for the generative models of document topic coefficients are also shared between the connected models. The difference of LDA versus pLSA is the introducing of a Dirichlet prior for the document topic coefficients  X  , which itself has been changed to Bayesian estimation. Furthermore, the word-topic coefficients are also turned into Bayesian estimation and appended with a uniform Dirichlet for smoothness. The model we use, named LapMixUnigram, is a connected mixture of unigram model, as illustrated in Figure 2(a). The reason for choosing mixture of unigram as the base model is because of the effectiveness of the discrete variables used as latent topics. It forms a more coarse approximation to the per-word topic models such as pLSA or LDA, but the its simplicity makes it easier for us to impose graph regularization. In this way, the shortage of the model is strengthened by the regularization.

We build an adjacency graph between the images, as illustrated in Figure 2(b). For image i and image j ( i , j  X  X  1 ,..., D } ), if Then, we create an edge between them. The weights of the edges S follows: Here X is either the textual or the visual words of a specific image. In our experiment, we use the second line of Eq. (38) and the first line of Eq. (39).

Since most of the images are not with annotation and we are to annotate them, the word component in Eq. (38) is not so useful in this setting. So we only used the visual part for the creation of the adjacency graph. In another word, the adjacency graph is determined by the visual components of the images. More generally speaking, since the visual words are obtained by clustering the local or global image feature descriptors, so in fact, how to determine the similarity between image pairs, or in another way which image pairs should have an edge in the adjacency graph and how to set the weights, is a big research topic. Especially in the image retrieval area, there are many works talking about how to define distances in the space of image representation, or how to define a proper metric in such a space, such as the Earth Mover X  X  Distance [Rubner et al. 2000]. Particularly, if each image contains several local descriptors in different number, then how to compute the similarity measure of the images based on these descriptor vectors, is a typical problem in the Multiple Instance Learning area. Usually, they treat the vectors associated with an object as samples generated from an individual probability distribution corresponding to this object. So the problem is to estimate the probability distribution of each object and then use the distance or distance like metric to measure the similarity between objects, such as Kullback-Leibler Divergence, Earth Mover Distance, etc. Here, as this is the focus of our article, we will not mention them in detail. What we concern is that under certain regularity condition, can statistical inference methods get better estimated believes. So we simply use our proposed way of specifying the weights of the edges.

After learning, each unannotated image get an estimated variational distribution of its Z variable, which can be regarded as the probability of this image having these latent topics. While the probability of annotated words given the probability of the topics of an image can be obtained in the following way: In this experiment, we use the Corel Image Database as mentioned in Barnard et al. [2003]. It contains 80 CDs of images, with 14000 images in total. Each image is as-sociated with one to five textual annotations. Barnard et al. [2003] extracted about 10 feature vectors for each image, and each vector is of dimension 49, describing a segmentation of the image, including area, position, color statistics, gradient statistics, difference of Gaussian, etc. In order to make the visual words more informative and sta-ble in computation, we did some preprocessing to the feature vectors. We removed the redundant entries, then translate, rescale and nonlinear monotonically transformed the remaining entries so that they all lie in a fixed interval 0 evenly.

In our experiments, we randomly select 10 overlapping subsets, and repeat each of our experiments on these subsets to compute the averaged experimental results, in order to make our results more statistically stable. Each subset has a dictionary of about 150 words. Each subset is further divided into a big set (75%, 5200 images) and a small set (25%, 1800 images). Different from previous image annotation works, in our training procedure, we give the annotations of the small set and try to predict the annotations of all the images in the big set. This matches the practice better. In practice, we usually have a very large image database, but very few of them are annotated. In addition, to better utilize the benefit of semisupervised learning and transductive learning, we don X  X  separate the training and testing stages. All the annotated and unannotated images are put together for learning. The adjacency graph is created on the combined image sets. When evaluating the results of the image annotation, we have several different mea-sures that can be utilized. Like Hit Rate [Zhang et al. 2005], Complete Length [Zhang et al. 2005], Accuracy [Monay and Gatica-Perez 2004] and Normalized Score [Barnard et al. 2003], etc. Here, we choose two from them that are representative and comple-mentary.  X  Accuracy. If we predict the same number of annotations as the number of ground truth annotations, then accuracy is defined as the rate of correctly predicted an-notations. Values are between 0 and 1. The larger the values, the better of the experimental performance.  X  Complete Length. The minimum number of predicted words required for each image to cover all the ground truth annotations. The value is averaged over all the images in an specific experiment. And the larger the values, the worse the experimental performance.

Between them,  X  X ccuracy X  reflects the prediction performance and accuracy of the top predicted words, while the  X  X omplete length X  reflects the overall judgments of the classifier on all the words. These two, altogether, provide a clear quality measurement on the learning algorithms. These are like the relationship between recall and precision, but in the sense that for every query, we have a predicted ranking on all the words.
Note that in our experiments, since the number of ground truth image annotations are usually the same among all the images (about 4), so we don X  X  need any normalization of the accuracy values with respect to the ground truth annotation number. Nor can we normalize the value with respect to the dictionary length. In this article, we provide two baseline measurements to better illustrate the contri-bution of our proposed approach. The first one is the empirical estimation, where the prediction result for each query simply follows the overall term frequency of all the words. And the second one is the Mixture of Unigram model without graph regularization.

From Figure 3 we see that, simple topic modeling is sometimes not so powerful to model the images, where they are even below the empirical estimation. When topic number increases, the algorithm performance of top returned words, in the sense of  X  X ccuracy X , will be improved. The comparison results are illustrated in Figure 4. Figure 5 is random examples from our experiments. From these results, we see that our method works quite stable. That is because the graph regularizer smoothed the solution space and make the estimated more determined by the manifold structure, thus not so prone to the number of latent topics. Link-LDA is supposed to be better than pLSA-Words, but in our annotation experiments, since the number of annotations of each image is too few. In order for these annotations to form a mixture of multinomial model with a high number of latent topics, the mixing coefficients are usually very sparse, this limited the transfer of information among different word-topic components in  X  inference procedure, thus more prone to local maxima. Especially in the experiments when number of latent topics are larger than 30, the mixing coefficients are so few so that the model tend to go to some local maxima which fits the data worse but have a conditional likelihood in  X  and  X  . The resulted model in this case prefer to predict words that are empirically significant. However, in case of the complete length measure Link-LDA is still stably better than pLSA-Words.

Another issue is the closeness of performance between pLSA-Words and our proposed method when number of latent topics are large. This is mostly because of adding regularization to the mixture of unigram model makes the local minima more stable, but different from the original results. Given this experimental results, we see that the regularized results are close to the pLSA-Words with more latent topics. This issue in turn calls for better optimization techniques for the graph regularized models to make it less prone to bad local minima. In this article, we proposed a graph regularized variational inference method as a general inference method, which is particularly suitable for application areas with multiple modalities and the network-structured relationship of one modality can be helpful for the inference problem of other modalities. As a typical example, we choose image annotation to implement and verify our proposed method.

The experimental results in general, show that the graph regularized variational inference, even with very simple base models, will outperform more advanced models without regularization.

A further question is that whether such kind of regularization can be modeled with a globally consistent probabilistic model, such as a chain graph with random field components. And how to do inference efficiently on these regularized models.
