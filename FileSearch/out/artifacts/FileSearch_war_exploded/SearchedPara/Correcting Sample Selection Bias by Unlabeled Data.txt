 School of Computer Science The default assumption in many learning scenarios is that tr aining and test data are independently and identically (iid) drawn from the same distribution. When the distributions on training and test of patterns X and labels Y , we obtain training samples Z = { ( x a Borel probability distribution Pr( x, y ) , and test samples Z  X  = { ( x  X  drawn from another such distribution Pr  X  ( x, y ) .
 usually performed over a more general target population. Be low, we give two examples; but similar situations occur in many other domains. 1. Suppose we wish to generate a model to diagnose breast canc er. Suppose, moreover, that most women who participate in the breast screening test are middl e-aged and likely to have attended the screening in the preceding 3 years. Consequently our sample includes mostly older women and those who have low risk of breast cancer because they have bee n tested before. The examples do not contain very few diseased cases (i.e. a bias in Pr( y | x ) ). 2. Gene expression profile studies using DNA microarrays are used in tumor diagnosis. A common problem is that the samples are obtained using certain proto cols, microarray platforms and analysis techniques. In addition, they typically have small sample s izes. The test cases are recorded under different conditions, resulting in a different distributi on of gene expression values. In this paper, we utilize the availability of unlabeled data to direct a sample selection de-biasing procedure for various learning methods. Unlike previous wo rk we infer the resampling weight di-the assumption that probabilities of the different classes are known [8]. Rather, we account for the of the training and test points in a reproducing kernel Hilbe rt space (RKHS) are close. We call this reweighting process kernel mean matching (KMM). When the RK HS is universal [14], the popula-cautionary result, which states that even granted this idea l population reweighting, the convergence of the empirical means in the RKHS depends on an upper bound on the ratio of distributions (but not on the dimension of the space), and will be extremely slow if this ratio is large. method to a variety of regression and classification benchma rks from UCI and elsewhere, as well as to classification of microarrays from prostate and breast ca ncer patients. These experiments demon-strate that KMM greatly improves learning performance comp ared with training on unweighted data, and that our reweighting scheme can in some cases outperform reweighting using the true sample bias distribution.
 Key Assumption 1: In general, the estimation problem with two different distr ibutions Pr( x, y ) remain unchanged (this particular case of sample selection bias has been term ed covariate shift [12]). However, we will see experimentally that even in situ ations where our key assumption is not valid, our method can nonetheless perform well (see Section 4). We begin by stating the problem of regularized risk minimiza tion. In general a learning method minimizes the expected risk loss. However, since typically we only observe examples ( x, y ) drawn from Pr( x, y ) rather than Pr  X  ( x, y ) , we resort to computing the empirical average To avoid overfitting, instead of minimizing R R reg [ Z,  X , l ( x, y,  X  )] := R emp [ Z,  X , l ( x, y,  X  )] +  X   X [  X  ] 2.1 Sample Correction Pr , however what we would really like is to minimize R [Pr  X  ,  X , l ] as we wish to generalize to test compute the risk with respect to Pr  X  using Pr . Similarly, we can estimate the risk with respect to Pr  X  by computing R emp [ Z,  X ,  X  ( x, y ) l ( x, y,  X  )] .
 The key problem is that the coefficients  X  ( x, y ) are usually unknown, and we need to estimate them where  X  is a reweighting factor for the training examples. We thus re weight every observation represented cases are downweighted.
 Now we could estimate Pr and Pr  X  and subsequently compute  X  based on those estimates. This is or have prior knowledge of the class distributions. Althoug h intuitive, this approach has two major lead to large coefficients  X  and consequently to a serious overweighting of the correspo nding obser-may be overkill: we may be able to directly estimate the coeffi cients  X  to estimate the two distributions. Furthermore, we can regu larize  X  taking prior knowledge into account similar to learning met hods for other problems. 2.2 Using the sample reweighting in learning algorithms Before we describe how we will estimate the reweighting coef ficients  X  to minimize the reweighted regularized risk accompanying technical report [7]).
 Support Vector Classification: Utilizing the setting of [17]we can have the following minim ization problem (the original SVMs can be formulated in the same way) : a discrepancy function between y and y  X  . The dual of (6) is given by generalizes the observation-dependent binary SV classific ation described in [10]. Modifications of existing solvers, such as SVMStruct [17], are straightforw ard.
 minimize m Denote by  X   X  the diagonal matrix with diagonal (  X  matrix K K X  ) +  X  X   X  K X  with respect to  X  . Assuming that K and  X   X  have full rank, the minimization yields the standard penalized regression problem. Essentially, w e rescale the regularizer depending on the pattern weights: the higher the weight of an observation, th e less we regularize. 3.1 Kernel Mean Matching and its relation to importance samp ling Let  X  : X  X  F be a map into a feature space F and denote by : P  X  F the expectation operator Denote by M ( X ) := { (Pr) where Pr  X  P } the image of P under . This set is also often referred to as the marginal polytope . We have the following theorem (proved in [7]): Theorem 1 The operator is bijective if F is an RKHS with a universal kernel k ( x, x  X  ) = h  X ( x ) ,  X ( x  X  ) i in the sense of Steinwart [15].
 The use of feature space means to compare distributions is fu rther explored in [3]. The practical solving the following minimization problem: minimize This is the kernel mean matching (KMM) procedure. For a proof of the following (and further results in the paper) see [7].
 Lemma 2 The problem (10) is convex. Moreover, assume that Pr  X  is absolutely continuous with solution  X  ( x ) of (10) is P r  X  ( x ) =  X  ( x ) P r ( x ) . 3.2 Convergence of reweighted means in feature space Lemma 2 shows that in principle, if we knew Pr and [Pr  X  ] , we could fully recover Pr  X  by solving a simple quadratic program. In practice, however, neither (Pr  X  ) nor Pr is known. Instead, we only have samples X and X  X  of size m and m  X  , drawn iid from Pr and Pr  X  respectively. resulting optimization problem provides us with a good esti mate of  X  . However, it is to be expected empirical estimate of the expectation of  X  is normally distributed: this provides a natural limit on expectations (we will return to this point in the next sectio n).
 Lemma 3 If  X  ( x )  X  [0 , B ] is some fixed function of x  X  X , then given x Gaussian with mean R  X  ( x ) d Pr( x ) and standard deviation bounded by B This lemma is a direct consequence of the central limit theor em [1, Theorem 5.5.15]. Alternatively, it is straightforward to get a large deviation bound that lik ewise converges as 1 /  X  m [6]. Our second result demonstrates the deviation between the em pirical means of Pr  X  and  X  ( x ) Pr in of Pr  X  and Pr (and thus the bound B on the ratio of probability masses is large).
 Lemma 4 In addition to the Lemma 3 conditions, assume that we draw X  X  := { x  X  bound the deviation between the feature space mean of Pr  X  and the reweighted feature space mean of useful upper bound on the outcome of the optimization.
 Lemma 4 implies that we have O ( B p 1 /m + 1 /m  X  B 2 ) convergence in m, m  X  and B . This means or not) should match exactly. 3.3 Empirical KMM optimization to constraints  X  distribution. The objective function is given by the discre pancy term between the two empirical means. Using K We now have all necessary ingredients to formulate a quadrat ic problem to find suitable  X  via In accordance with Lemma 3, we conclude that a good choice of  X  should be O ( B/  X  m ) . Note that (12) is a quadratic program which can be solved efficient ly using interior point methods or any other successive optimization procedure. We also point out that (12) resembles Single Class SVM correction term by means of  X  . Large values of  X  x and are likely to lead to large  X  4.1 Toy regression example on Pr and Pr  X  (namely, Pr  X  must be known, while Pr can be either known exactly, Gaussian with unknown parameters, or approximated via kernel density est imation).
 Our data is generated according to the polynomial regressio n example from [12, Section 2], for 0 . 3 (see Figure 1(a); the blue curve is the noise-free signal).
 We attempted to model the observations with a degree 1 polyno mial. The black dashed line is a best-case scenario, which is shown for reference purposes: it represents the model fit using ordinary least squared (OLS) on the labeled test points. The red line i s a second reference result, derived only from the training data via OLS, and predicts the test dat a very poorly. The other three dashed lines are fit with weighted ordinary least square (WOLS), usi ng one of three weighting schemes: the ratio of the underlying training and test densities, KMM, an d the information criterion of [12]. A summary of the performance over 100 trials is shown in Figure 1(b). Our method outperforms the two other reweighting methods. Figure 1: (a) Polynomial models of degree 1 fit with OLS and WOLS;(b) Ave rage performances of three 4.2 Real world datasets We next test our approach on real world data sets, from which w e select training examples using a deliberately biased procedure (as in [20, 9]). To describe o ur biased selection scheme, we need to define an additional random variable s s = 1 means the i th sample is included, and s i = 0 indicates an excluded sample. Two situations are considered: the selection bias corresponds to our assum ption regarding the relation between the training and test distributions, and P ( s y , i.e. P ( s key assumption 1. In the following, we compare our method (la beled KMM ) against two others: a baseline unweighted method ( unweighted ), in which no modification is made, and a weighting by the inverse of the true sampling distribution ( importance sampling ), as in [20, 9]. We emphasise, however, that our method does not require any prior knowledge of the true sampling probabilit ies. In our experiments, we used a Gaussian kernel exp(  X   X  k x regression algorithms, and parameters  X  = (  X  m  X  1) /  X  m and B = 1000 in the optimization (12). 4.2.1 Breast Cancer Dataset This dataset is from the UCI Archive, and is a binary classific ation task. It includes 699 examples from 2 classes: benign (positive label) and malignant (nega tive label). The data are randomly split into training and test sets, where the proportion of example s used for training varies from 10% to kernel size  X  = 0 . 1 . First, we consider a biased sampling scheme based on the inp ut features, of the experiment for each of the features in turn. Results are a n average over 30 random training/test we consistently outperform the unweighted method, and matc h or exceed the performance obtained using the known distribution ratio. Next, we consider a samp ling bias that operates jointly across multiple features. We select samples less often when they ar e further from the sample mean x over the training data, i.e. P ( s sampling model. Finally, we consider a simple biased sampli ng scheme which depends only on the many positive as negative examples when uniformly sampled) . Average performance for different difference between the training and test distributions bei ng violated, our method still improves the examples have higher weights and negative ones have lower we ights. 4.2.2 Further Benchmark Datasets We next compare the performance on further benchmark datase ts 1 by selecting training data via bution P ( s = 1 | y = 1) = a , P ( s = 1 | y =  X  1) = b (datasets 6 and 7). For the remaining datasets, we generate biased sampling schemes over their fe atures. We first do PCA, selecting the first principal component of the training data and the corres ponding projection values. Denoting the minimum value of the projection as m and the mean as m , we apply a normal distribution with mean m + ( m  X  m ) /a and variance ( m  X  m ) /b as the biased sampling scheme. Please refer to [7] for detailed parameter settings. We use penalized LMS fo r regression problems and SVM for classification problems. To evaluate generalization perfo rmance, we utilize the normalized mean for classification problems. In 13 out of 23 experiments, our reweighting approach is the most accu-cases, despite the additional fact that the data reweightin g does not conform to our key assumption 1). In addition, the KMM always improves test performance compared with the unweighted cas e. Two additional points should be borne in mind: first, we use th e same  X  for the kernel mean match-ing and the SVM, as listed in Table 1. Performance might be imp roved by decoupling these kernel sizes: indeed, we employ kernels that are somewhat large, su ggesting that the KMM procedure is since a reweighting would further reduce the effective numb er of points used for training, resulting in insufficient data for learning.
 4.2.3 Tumor Diagnosis using Microarrays Our next benchmark is a dataset of 102 microarrays from prost ate cancer patients [13]. Each of these microarrays measures the expression levels of 12,600 genes . The dataset comprises 50 samples from normal tissues (positive label) and 52 from tumor tissu es (negative label). We simulate the samples, and we want to perform cancer diagnosis via classifi cation, training on A and predicting on B. We select training examples via the biased selection sc heme P ( s = 1 | y = 1) = 0 . 85 and P ( s = 1 | y =  X  1) = 0 . 15 . The remaining data points form the test set. We then perform SVM classification for the unweighted, KMM, and importance samp ling approaches. The experiment was repeated over 500 independent draws from the dataset acc ording to our biased scheme; the 500 resulting test errors are plotted in [7]. The KMM achieves mu ch higher accuracy levels than the unweighted approach, and is very close to the importance sam pling approach.
 We study a very similar scenario on two breast cancer microar ray datasets from [4] and [19], mea-suring the expression levels of 2,166 common genes for norma l and cancer patients [18]. We train an SVM on one of them and test on the other. Our reweighting met hod achieves significant improve-ment in classification accuracy over the unweighted SVM (see [7]). Hence our method promises to be a valuable tool for cross-platform microarray classifica tion.
 Acknowledgements: The authors thank Patrick Warnat (DKFZ, Heidelberg) for pro viding the mi-croarray datasets, and Olivier Chapelle and Matthias Hein f or helpful discussions. The work is partially supported by by the BMBF under grant 031U112F with in the BFAM project, which is part of the German Genome Analysis Network. NICTA is funded throu gh the Australian Government X  X  Backing Australia X  X  Ability initiative, in part through the ARC. This work was supported in part by the IST Programme of the EC, under the PASCAL Network of Excel lence, IST-2002-506778.
