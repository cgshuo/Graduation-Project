 The aim of the Task Completion Platform (TCP) is to support the rapid development of large numbers of goal-orientated, multi-turn dialogues by simplify-ing the process of specifying a new task. To achieve this, the definition of individual tasks is separated from the mechanics and policy required to conduct a natural language, goal-orientated dialogue. TCP provides the functionality required to manage dia-logues with users, leaving a task author to specify only the information to collect from the user and the interfaces to resources such as data hosted in exter-nal services and applications that will execute ac-tions on behalf of the user. The platform is used to power many multi-turn dialogue interactions as part of the Cortana personal assistant. VoiceXML (VoiceXML, 2000) is a industry stan-dard tool used to build dialogue systems. It is typically used to design system-directed dialogues, where the understanding of user input is constrained at each turn, and there is no opportunity for user ini-tiative. Such dialogues are common in call centre interactive voice response systems, but are of lim-ited utility when more natural interactions are de-sired, such as personal assistant dialogues supported by TCP.
 A more flexible dialogue management platform is RavenClaw (Bohus and Rudnicky, 2009). Raven-Claw systems are composed of a tree structure of agents, with the system at each turn deciding on an execution plan that allows a maximum number of agents to finish their processing. However, most systems built using RavenClaw require custom-built agents; it is difficult to integrate additional tasks into an existing system without having to rebuild the en-tire tree of agents. In contrast, TCP allows the ad-dition of new experiences with only a configuration file change (as discussed in section 4).
 Most similar is ClippyScript (Seide and McDirmid, 2012) which like TCP uses a hier-archical data flow to drive processing (akin to a functional language) as opposed to directed dialogue flow. A key difference is that, in defining tasks in ClippyScript, a dialog act is explicitly tied to a task condition by a rule. Thus, ClippyScript developers directly specify a rule based dialogue policy on a per task basis. In a TaskForm (TCP task definition) dialog acts are declared in association with parameters but when to execute them is not explicitly encoded. This allows for separation of tasks and dialogue policies in TCP.
 Work also exists on dialogue policy transfer ( e.g. Wang et al. (2015)) but such work has typically not focused on easy and rapid definition of a diverse set of tasks, as we did in developing TCP.

The main contributions of our work on TCP in-clude: strong separation between task definition and the shared dialogue policy; rapid new task author-ing, with the platform providing key machine learn-ing (ML) driven dialogue capabilities such as state tracking, dialogue policy learning, flexible selection, and LU model reuse, which significantly reduces the burden on individual task developers; and benefits to users by offering many multi-turn, mix-initiative di-alogue tasks simultaneously. The TCP platform supports execution of a variable number of goal-orientated tasks, which can be mod-ified and improved without changing the core plat-form. The platform has a modular architecture, with the dialogue management process separated into dis-crete units which can also be independently updated and improved. Figure 1 presents the core plat-form modules, loosely grouped as: initial process-ing of input, dialogue state updates, and policy exe-cution. Alternative interpretations of input and dia-logue state are preserved in parallel for each step of the pipeline, with a final ranking step to select the optimal hypothesis and associated dialogue act.
The input to the system is either typed text or transcripts from an Automatic Speech Recognition (ASR) system, in the form of N -best hypotheses or confusion networks. The input is processed by a Natural Language Understanding (NLU) module. Several alternate NLU modules can be used in the platform, e.g. Deoras and Sarikaya (2013). A typical arrangement is described in Robichaud et al. (2014). To support multiple tasks across multiple domains, a collection of NLU models are executed in parallel, each determining the most likely intent and set of slots within their domain. An NLU slot is defined as a container that can hold a sequence of words from the user input, with the label indicating the role played by that text in a task or set of tasks. Together, the detected intent and slots form the semantic frame for that domain. NLU models are contextual (Bhar-gava et al., 2013; Liu et al., 2015), taking into ac-count the state of any task currently in progress.
On each turn, the dialogue state is updated tak-ing into consideration the multiple NLU results. Slot Carry Over (SCO) (Boies et al., 2016) does contex-tual carry-over of slots from previous turns, using a combination of rules and ML models with lexical and structural features from the current and previous turn utterances. Flexible Item Selection uses task-independent ML models (Celikyilmaz et al., 2014; Celikyilmaz et al., 2015) to handle disambiguation turns where the user is asked to select between a number of possible items. The Task Updates module is responsible for applying both task-independent and task-specific dialogue state updates. The task-specific processing is driven by a set of configu-ration files in a new configuration language, Task-Form, with each form encapsulating the definition of one task. Using the TaskForm files, this module ini-tiates new tasks, retrieves information from knowl-edge sources and applies data transformations ( e.g. canonicalization). Data transformations and knowl-edge source look ups are performed using Resolvers , as discussed in section 4.

Dialogue policy execution is split into task-depenent and global policy. The Per Task Policy consists of analysing the state of each task currently in progress, and suggesting a dialog act to execute. The output of the module is a set of dialogue hy-potheses representing alternative states or dialog ac-tions for each task in progress. The number of hy-potheses does not grow uncontrollably; depending on the state of the dialogue during the previous turn and the current input, only a small proportion of all the defined tasks will be active in any one turn. The output dialog hypotheses are ranked using Hypothesis Ranking (HR) (Robichaud et al., 2014; Khan et al., 2015; Crook et al., 2015), which gen-erates a ranked order and score for each hypothe-sis. This acts as a pseudo-belief distribution over the possible dialogue/task states. Hypothesis Selection (HS) policy selects a hypothesis based on contex-tual signals, such as the previous turn task, as well as the rank order and scores. The HS policy may se-lect a meta-task dialog act, such as asking the user to specifically select a task when two or more tasks are highly ranked, or adding an implicit confirmation when the top hypothesis has low confidence. The selected dialog act is rendered to the user and the associated dialog hypothesis informs the next turn. The TaskForm language allows for defining tasks in-dependently of the dialogue policy executed by the platform. Each task is represented as a set of inde-pendent triggers defining under what conditions task execution should begin, a set of parameters defining what information should be collected during the di-alogue, and a set of dialog acts defining what is pre-sented to the user. Additional structural information about a task can be captured through the use of vali-dation conditions (not shown here).

A task trigger defines under what conditions a task may begin executing. These conditions are rep-resented in terms of NLU results: combinations of domains, intents, and slots (presence or absence). Each trigger may also specify a list of must-trigger utterances, as shown in figure 2. At least one trigger must be satisfied for the task to begin execution.
We define a task parameter as a container that holds knowledge items required to complete a task. Each parameter definition specifies how the knowl-edge items ( i.e. its value ) should be produced and what dialog acts are used to solicit relevant informa-tion. An example of a task parameter is shown in figure 3.

The knowledge items that are stored in a parame-ter can be: concrete entities e.g. a particular restau-rant in a city; canonicalized attributes of an item, e.g.  X  X mall X ,  X  X iddle X  or  X  X arge X ; concepts,  X  X elivery X  or  X  X ake-out X ; or labels that index another knowl-edge source. Knowledge items can be retrieved from some knowledge source, e.g. a database or knowl-edge graph, or captured directly in code.

The value of a parameter is provided by an associ-ated piece of code, a resolver implemented outside the TaskForm. In the TaskForm, a resolver defini-tion (optional for platform-provided resolvers) con-tains only a reference to the code assembly, class name, and a list of NLU slot tags and input param-eters which it can process. The parameter defini-tion contains a resolver invocation block which lists a subset of slot tags and input parameters that should actually be used as input to the resolver during the task execution; this allows resolvers to be generic and reusable across multiple parameters and tasks. A platform-provided HTTP resolver allows for easy integration with third party APIs; each HTTP re-solver definition need specify only a mapping be-tween task parameters and API parameters, and a JPATH expression for interpreting the results. There is a many-to-many relationship between NLU slots and the knowledge items (values) that fill a parameter. Dependent on the run-time results of resolution, additional dialog acts may be required to obtain further user input and refine the resolu-tion. E.g. if the NLU slots [place name:Marriott] and [absolute location:Bellevue] are used to index a knowledge source and extract values to fill the task parameter DeliveryAddress , the result may be a list of Marriott hotel locations in Bellevue. If the param-eter specifies that it must hold a single value, further dialog acts will be used to narrow the results. These dialogue policy decisions could not be made by ex-amining the slots in isolation of the resolved values.
As part of the execution of a task, the system may take one or more dialog acts before the value of a pa-rameter is considered  X  X illed X . Allowed acts include:
A dialog act definition captures the information that should be presented to the user when that di-alog act is taken by the system. This information includes: a prompt to be read out, a list of strings to be shown on the screen, as well as hints to prime the NLU during the next turn of the conversation. De-fault definitions are used for any missing sections in each dialog act definition. Figure 4 shows an exam-ple of a dialog act definition, encoding how the user should be prompted to provide the missing value of the DeliveryAddress parameter. We plan to showcase the capabilities of TCP, high-lighting in particular the breadth of the platform and the agility of task development.

The platform is capable of executing multiple tasks using the same underlying policy modules, thus allowing for tasks to be developed separately from the policy definition. To this end we will show the platform supporting a conversational agent capa-ble of setting reminders, ordering pizzas, and reserv-ing movie tickets, restaurant tables and taxis (where these scenarios are hooked up to real third party ser-vices like Domino X  X , OpenTable, Uber, etc. ). Each task is defined by a TaskForm. Users can interact with the system through natural conversation and take initiative at any point, e.g. to cancel a task in progress, provide information out of turn, or change previously-provided information.

Many changes to a task can be done simply by manipulating its TaskForm definition. To illustrate this, we will demonstrate some simple modifica-tions to an existing task, such as changing the task triggers, adding a new parameter, modifying some of the conditions set on parameters, and redefining some of the dialog acts used during task execution. We demonstrated the Task Completion Platform, an extensible, mixed-initiative dialogue management platform targeting goal-directed conversations. The platform supports executing multiple tasks. Each task is defined primarily in terms of extensible NLU models and a single configuration file, thus separat-ing task definition from the system-wide dialogue policy. Tasks can be added or modified without re-quiring a system rebuild. Future work includes ex-tending the platform by allowing multiple tasks to be concurrently in progress, either through nesting or interleaving of tasks, and evaluation of task suc-cess and related metrics.
