 CLIR enables people to retrieve documents written in one language by another lan-guage query. Although CLIR has been advancing rapidly, a major bottleneck remains documents may rank highly, which will cause worse performance (precision, recall etc.) of CLIR. [12] analyzed the shortcomings of dictionary-based approaches and proposed the using the state-of-the-art dictionary cannot avoid the OOV problem. cannot extract effective snippets. Besides, mostly existing query expansion methods for and lower the quality of snippets. 
Extracting MLUs (Multi-Lexical Unit) as candidates from the gathered snippets is the second main problem. If the candidate of OOV is not extracted correctly, the sub-stantial translation of OOV cannot be mined. The most common method for candidate However, most of these continuous strings are invalid lexical units. existing methods. More effective features (distance, surface patterns and phonetic etc.) can be used for OOV translation selection. 
For the above problems, this paper proposes a novel solution to mine high quality translation of OOV for query translation. Briefly, OOV translation mining method consists of three main parts: 1. Bilingual snippets collection. Gather the bilingual snippets containing the OOV in 
English and its translation in Chinese from a search engine. 2. Candidate extraction. Extract MLUs from snippets as OOV translation candidates. the correct OOV translation. OOV expanded with translations of the topic words are sent to search engine to col-lect relevant bilingual web snippets. The translation of topic words based cross-language expansion method can get more relevant bilingual snippets. To enhance the quality of candidates, a variation of frequency change measurement term extraction method is adopted. Features such as frequency, distance, surface patterns and translit-eration are exploited for better translation selection. 
The remainder of this paper is organized as follows. Section 2 presents the related work. Section 3 proposes the solution to bilingual resource collection. In section 4, we present the OOV translation candidates extraction method. Candidates ranking for choosing the OOV translation and experiments are presented in section 5 and section 6 respectively. Finally, conclude the paper in the last section. Nagata &amp; al. [11] firstly attempted to use the web for translating Japanese OOV. They downloaded the top 100 full web pages as reso urce. Lu &amp; al. [9] extracted translations of terms through mining of web anchor texts and link structures. For the dependence on full web pages, these two methods need big network bandwidth, large storage capacity and long computing time. translation. Thus the complexity of collecting bilingual resource by these two ap-proaches is sharply reduced. The main shortcoming, however, is the snippets seldom contain corresponding translations since the source query is not expanded with cross-language words; and most of the snippets returned are usually monolingual, which cannot be used to extract the target language translations. 
Fang &amp; al. [4] segmented the source OOV, and then expanded the terms with cross-language words to collect web resour ce. Sun &amp; al. [15] used forward-backward maximum matching method to segment the source term and looked up the target language translations of segmented units to expand the source term for collecting bilingual snippets. These approaches all exploited cross-language query expansion to collect more relevant bilingual snippets and needed to segment the source term, unfor-component words meanings. Thus segmenting source term will introduce extra noise in query expansion and further lead to translation mining errors. 
Zhang &amp; al. [18] used all substrings of twenty Chinese characters immediately be-fore OOV and twenty Chinese characters immediately after OOV as candidates. and continuous English strings were taken as candidates. Taking the continuous string as candidate or taking substrings of strings before and after OOV as candidates has a OOV can hardly be mined. Chien &amp; al. [2] proposed a variant method of mutual in-formation called Significance Estimation (SE). Silva &amp; al. [13] extracted MLUs from large corpora with Local Maxima algorithm, the formula used in the algorithm is symmetric conditional probability (SCP). Cheng &amp; al. [3] introduced Context De-pendency (CD) to improve SCP for Chinese MLUs extraction. SE, SCP and SCPCD achieved good performance in large corpora situation. OOV contain both the OOV and the translation. Take Kim Dae-Jung as an exam-ple(Kim Dae-Jung is translated as  X   X  X  X  X   X  in Chinese), only 1 snippet in the top 10 in English which cannot be used to extract Chinese translations. Ballesteros &amp; al. [1] most expansion methods in previous researches must segment the source OOV, but the meaning of a source term usually is not the combination of individual word mean-ing in the source term. For example in  X   X  X  X  X   X , which means sarcastic remarks, the meanings of the component characters are  X  X ind X ,  X  X ool X  and  X  X alk X  respectively. The component characters meanings are irrelevant to the meaning of  X   X  X  X  X   X . So an doesn X  X  need segmentation. We first take the OOV as a whole unit with quotation relation to the source OOV in the same topic or domain. After that, we send the OOV together with the translations of the topic words in the target language respectively to a search engine to collect bilingual resource. 
We filter out the non-noun words and English stop words from the bilingual re-source, and then we can get an English noun word list. TF*IDF metric is used to extract topic words from the noun English word list. Then we select the top 5 of the list as the topic words. 
In the previous example of  X  X im Dae-Ju ng X , the topic words extracted from top 20 snippets are  X  X orea X ,  X  X resident X ,  X  X inner X ,  X  X eace X  and  X  X rize X . Their correspond-this example, the cross-language expansion words are  X   X  X  X  (Korea) X ,  X   X  X  X  (president) X ,  X   X  X  X  X  (winner) X ,  X   X  X  X  (peace) X , and  X   X  X  X  (prize) X . Then we send the source OOV  X  X im Dae-Jung X  together with translations of topic words respectively to retrieve bilingual snippets. The quality of these bilingual snippets is greatly improved than using only the source OOV. The translation of the OOV may be either a MLU or a single word. As the scale and domain of the dictionary, conventional dictio nary-based segmentation approaches are hardly be obtained by these approaches. 
The approaches for extracting MLUs from large corpus (SE, SCP, SCPCD) are not quite small. One snippet usually just contains 2 or 3 sentences. Moreover, the snippets are usually fragments of sentences. 
We use Frequency Change Measurement together with Context Dependency (FCMCD) to extract MLUs from the bilingual collection. It combines the Frequency Change Measurement (FCM) [8] and Context Dependency (CD). FCM is based on two observations as follows: the first observation is that the component characters of the term have similar frequencies in a coll ection returned from a search engine. Such guage snippets gathered by  X  X im Dae-Jung X  with cross-language expansion; the sec-extended term drops apparently. The frequency of  X   X  X  X  X  X   X  X s quite lower than that evaluate the probability of string S being a MLU. 
The candidates extracted by FCM still contain some invalid fragments which are sub-sequences of the valid MLUs. Thus some correct candidates will not be extracted by FCM only. In order to deal with this problem, we combine the Context Depend-ency (CD) to improve the quality of candidates since we discovered that valid candi-dates usually have diverse adjacent characters while their sub-terms have relative less and fixed adjacent characters. The CD reflects the degree of a string stands alone as a word. In FCMCD method, Equation (1) is modified as follows. and sentence end mark  X  X  X  were inserted into each sentence at the sentence boundary. If S occurs at the start of the sentence, LN(S) is one. If S occurs at the end of the sen-tence, RN(S) is one. 
We do not simply remove the Chinese stop words from a snippet directly. That will lead to the possibility that the left neighboring character of the stop word and the right neighboring character are extr acted as MLU and thus introduce extra noise. Take the sentence  X   X   X  X  X  X  X  X   X  X  X  X   X   X  X  X  X  X  X  X   X   X   X  X  X  X  X  X   X   X  viz. Former president directly remove the stop word  X   X   X ,  X   X  X   X  may be extracted as MLU, but  X   X  X   X  is an invalid lexical unit in Chinese. A method that combines frequency-distance, surface patterns matching and phonetic features of the Chinese candidates is used in choosing the correct translation(s). 5.1 Frequency Distance Model usually co-occurs with the OOV frequently in the snippets. The nearer the candidate one candidate and the OOV is calculated as: where s is the OOV, t is one candidate. d k (s,t) is the k-th distance between s and t in one snippet, for s and t might co-occur more than once in a snippet. J is the number of the snippets and K is the number of co-occurrence between s and t. The denominator is the max reciprocal of the distance among all the candidates. We adopt the count of may contain several kinds of symbols such as Chinese characters, English characters and punctuation marks etc., which are encoded differently. Thus it reflects more lin-guistic information to take word count as the distance measure. If there are no charac-ter between s and t, the distance is one and so forth. 5.2 Surface Patterns Matching Model Some Asian languages users usually annotate terms with their translations in English precision of the final OOV translation(s). In our solution, some English-Chinese pairs are submitted to a search engine to learn the surface patterns automatically [16], [7]. Some surface patterns obtained by this procedure are listed in table 1. E is one Eng-lish term; C is the Chinese translation of E. probability of being the right translation will increase greatly. The cost of the surface patterns matching is formulated as: where s is the OOV, t is one candidate. The numerator is the number of times that s and t matches the surface patterns. The denominator is the maximum number of matching patterns among all the candidates. 5.3 Transliteration Model Many OOVs are translated based on phonetic pronunciations, which we called trans-literation. Firstly, our transliteration model resolves a sort of matching problem, com-puting the phonetic similarity between the English OOV and Chinese candidates. We already have the Chinese candidates and thus we don X  X  need to generate the Chinese transliterations. Secondly, to avoid the double errors from English phonetic represen-by [14], [10] to segment an English name into a sequence of syllables, computing the probability between an English syllable and a Chinese character to estimate the possi-bility. The aim is to compute the phonetic similarity for selecting the right translation. First of all, we segment the English OOV into a sequence of syllables based on heu-ristic rules and then compute the transliteration cost using the following equation. where P(s,t) is the co-occurrence probability of s and t which is defined as: defined as: here  X  is a decaying parameter, m is the total number of English term syllables and n is the total number of Chinese characters. In order to improve incorrect transliteration mapping between English syllables and Chinese characters, we combine the forward and backward mapping. The final trans-literation cost is defined as the average of forward value and backward value. 5.4 Model Combination We use the frequency-distance model as the baseline model, and re-rank the results by rectly combing with the transliteration mode l value decreases the whole performance. If one source term is transliteration word, the transliteration model value of it is much higher than values of those are not transliteration words. The threshold of the translit-eration model is computed. If the transliteration value of one candidate is greater than the threshold, then we re-rank the candidate by the transliteration value. Otherwise the rank of the candidate stays the same. TDT4 corpora were used in our CLIR experiment. TDT4 contains topics, documents and relevance judgments. This document set contains the complete set of English, Arabic and Chinese news text used in the 2002 and 2003 Topic Detection and Track-number and Title, Seminal Event, Topic Explication Rule of Interpretation. There are 27,142 Chinese documents in TDT4 corpora. We use the title of the topic as our Eng-all the source queries have no OOV; the other 76 queries have 82 OOVs. 6.1 Snippets Collection Experiment We sent the 82 English OOV terms (without cross-language expansion) to search engine to gather snippets and also used our expansion method to gather snippets. We used top 50 snippets returned by search engine for each OOV. Each method gathered we consider this snippet is effective. 
Without expansion method collected 545 effective snippets. With our expansion method collected 2,636 effective snippets. Our proposed snippets collection method can get more 2,091 effective snippets than the no expansion method, the result shows fundamental resource for MLUs extraction and translation selection. 6.2 Candidates Extraction Experiment 50 OOV terms were randomly selected from OOV set. Our expansion method was used to collect snippets for each selected OOV. MLUs were extracted from the 2,500 of 4,200 snippets by SE, SCP, SCPCD, FCM and FCMCD respectively. If one candi-percentage of correct candidates in all candidates. As we do not know the exact num-recall. Table 2 contains the results of MLUs extraction. 
SE, SCP and SCPCD do not work well on th is small size snippets resource. These methods extracted more MLUs, but the preci sions are very low. FCM alone achieves better performance than SCPCD, the precisi on increases 15.74%. FCM together with CD achieves the best performance 91.84% which increases 7.56% precision com-pared to FCM, but the number of MLUs is lower than that of FCM. Using CD can filter more invalid candidates, although it reduces the recall. As for query translation, precision is more important than recall, the high quality of candidate set is the primary element. 6.3 OOV Translation Selection Experiments which is defined as the percentage of terms whose translations are included in the top n returned translations and we implemented the Chi-square and Context Vector (Chi+CV) translation selection method which was proposed in [3]. Each OOV was expanded by our method and then 100 snippets were gathered for candidate extrac-power of each model. 
FD is frequency-distance model. SP is surface patterns matching model. Trl is transliteration model. FD achieves better performance than that of Chi+CV. Chi+CV doesn X  X  use the cross-language expansion and the CV sometimes misguides the selec-tion of the OOV. FD together with SP get further improvement. Top 1 inclusion rate increased 6.1% compared to FD. FD+SP+Trl get the best performance, improving the models are complementary for each other. 100 snippets and 150 snippets to mine translation with FD+SP+Trl for each OOV respectively. The mining result is shown in table 4. 
Using 100 snippets improves the Top 1 inclusion rate by 13.41% compared to us-ing 50 snippets. Using 150 snippets slightly improves Top 1 inclusion rate by 1.22% compared to using 100 snippets. The performance improves when the number of snippets increases. The number of relevant snippets increases when use more snip-pets; the correct OOV translation co-occurs more often and matches more surface patterns with the OOV when using more snippets. However, the main drawback of using more snippets is needs more bandwidth and time for extracting candidates and selecting translation. 6.4 CLIR Experiments constructed with Lucene. Documents were indexed using 2-gram based inverted file index. Mean Average Precision (MAP) values were used to evaluate the performance of retrieval system. Five runs are compared to investigate the performance of different query translation methods. Query disambiguation and relevance feedback [5] were not applied in retrieval because our main aim is to evaluate the improvement of our web based OOV translation mining for query translation. RUN 1: Monolingual retrieval. English titles were translated into Chinese by profes-sional translators and the translated titles are used to retrieve the Chinese documents. This run provides a comparison of  X  X deal X  retrieval case. RUN 2: English Queries were translated using a dictionary (containing 286,932 single word pairs) ignoring the OOV. RUN 3: Translation equivalents were extracted from parallel corpus. This parallel cor-pus was constructed using the method proposed in [17]. There are 760,000 sentences in then the translation of OOV was looked up from the translation equivalents. RUN 4: English queries were translated using the same dictionary in RUN2, and then the translation of OOV was mined using our proposed web based method. the translations of OOV which mined by our web based method. 
Two main reasons account for the poor performance of RUN 2 .First, our dictionary only contains common words, such compound words and proper names in the queries cannot be found in this dictionary. Second, some terms have several translations and we the performance of 30.25% percentage of RUN 1. The improvement is not remarkable because most of the translation equivalent s are common words, thus most OOV cannot be translated. RUN 4 improves the performance greatly with 77.86% percentage of RUN 1. RUN 5 achieves the best performance. That is because the high quality transla-tion equivalents of common words obtained from parallel corpus and the power of OOV translation mining using web are all benefit to the query translation. Our web based OOV translation mining method returns 10 translations for every correct translations; some are the different tr ansliterations using di fferent Chinese char-be used as natural query expansion for OOV. Whether using more translations of OOV improves the performance of CLIR or not? We investigate this problem using the method of RUN4. The result of web method is shown in table 6 using top 1, top3, top5 and top 10 translations of OOV respectively. 
Using top 5 translations achieves the top performance. However, while using top 10 translations the performance drops slightly. The reason is the last 5 translations are usually incorrect and decrease the whole performance. This paper proposes a web-based OOV translation mining for query translation. The topic words based method was used to expand the OOV for collecting relevant bilin-gual snippets. Then an improved Frequency Change Measurement method which combines Context Dependency (FCMCD) is used to extract valid MLUs from noisy, small bilingual snippets. A method using frequency-distance, surface patterns and results show that this method has impressive improvement in English-Chinese CLIR on TDT4 test set. 
For further work, we will combine our candidate extraction method with POS tag-ging to extract more reliable candidates. Semantic relation between OOV and candi-CLIR performance, query disambiguation and relevance feedback will be integrated into our CLIR architecture. The work is supported by the National Natural Science Foundation of China under Grant No 60970057. 
