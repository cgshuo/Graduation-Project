 TONGTAO ZHANG, ARITRA CHOWDHURY, and NIMIT DHULEKAR , During the past 20 years, civilizations all over the world have witnessed cultural as-similation, which has led to language endangerment. It was predicted that 90 percent of mankind X  X  languages would meet their doom by the end of this century [Krauss 1992]. China, one of the countries that can boast of an ancient civilization, has over 5,000 years of long and mysterious history. Currently 292 living languages are spo-ken by 56 recognized ethnic groups. There are more than 85 endangered languages spoken by non-Han minorities in southwestern China [Bradley 2005; Zhao and Song 2011], including Nyushu [Huang 1993], [Zhao and Zhang 2014], Muya [Huang 1985], Namuyi [Zhao and Zhang 2014], Zhuang [Li 2005], Ersu [Sun 1983], Pimu [Sun et al. 2007], Naxi [He and Jiang 1985] and Shuishu [Zhang 1980]. As living  X  X ossils X , these languages are precious and valuable to multiple research disciplines such as studying the origin and evolution of writing systems, preserving unique cultures (e.g., the af-fliction literature and the patio salon culture reflected in the gender-specific Nyushu, and the matrilineal system reflected in Mosuo), religions (e.g., Dongba is mainly used to write scriptures), music (e.g., folk songs in Zhuang), ethnicity and civilization. As Mandarin Chinese ( Putonghua ) is widely taught in the whole country as a national standard and used by young people belonging to minority ethnicities to work in urban Han areas or to communicate with tourists, the population that masters and uses these languages regularly keeps decreasing and aging. Most masters are over 60 years old, and even their own expertise in these languages is declining [Zhao and Zhang 2014]. Apart from the decline in the usage of these languages, the other major crisis is with regards to the veracity of documents written in these languages. Some local business-men have been forging characters and articles (e.g., randomly take components and characters to create fake documents) in these languages for the sake of commercial profit. These languages are thus suffering from the lack of standards from documen-tary orthography and the inadequate electronic support. As a consequence it is getting more convoluted to understand the works of the masters and to properly convey the past efforts of linguistic experts on these documents. Fortunately, in the past decade, extensive linguistic research efforts have been made toward manually documenting and translating traditional articles, and constructing dictionaries for some of these languages. However, such efforts are very expensive without computational support. Moreover, in a long-term endangered language-related project, consolidated standards and rules are required and objective evidence should be provided to ensure the quality and accuracy of recognition, translation and standardization.

One such language under threat of extinction is Nyushu (Simplified Chinese: ; literally  X  X omen X  X  writing X ) [Zhao 1995, 2004a, 2004b, 2005, 2008]. Nyushu was spe-cially created for women in the ancient Hunan province of China. From ancient time to the mid 20th century, Chinese women were not allowed to receive education [Zhao 2004b], and a woman who was publicly literate would bring shame to her family. Thus, many knowledgeable women, though behind the scenes, created and used this coded language to communicate with each other. As the only gender-specific language, Nyushu was kept alive by being passed from one generation of women to the next gen-eration of women. They wrote this script on books, paper, paper fans and handkerchiefs by embroidering, engraving, stamping and calligraphy using bamboo or brush pens. The secrecy of this language lays in the fact that it appeared as normal decoration to men who did not understand or know of its existence. Figure 1 presents Nyushu script on a paper fan and a handkerchief.

Compared to their Chinese counterparts, Nyushu characters are thin, elegant, and generally presented in italicized diamond shapes. Chinese characters are converted into uniform dots, vertical bars, italicized bars and arcs in Nyushu. For example, the character  X  X eart X  is written as  X   X  in Chinese and  X   X  in Nyushu. Each Nyushu character represents a phonogram in the Jiangyong dialect, and can be mapped to a cluster of Chinese characters which share similar pronunciations but different mean-ings (which is called Rebus in Chinese Linguistics). Therefore, there are many fewer Nyushu characters (about 800) compared to Chinese which has approximately 3,500 common characters. In fact, half of the Nyushu language experts can only chant the language, but do not have the same level of expertise in writing the language. More-over, neither was Nyushu promulgated publicly, nor was it taught formally in schools. The masters of Nyushu lacked the opportunity to receive higher education, so there are usually many variants and misspellings in Nyushu handwriting. Another new chal-lenge comes from the low quality of the scanned images, as we can see from the example documents in Figure 1. The old articles were vulnerable to the bad conditions (pres-sure, temperature, etc.) and thus not well preserved. Most documents were captured with old-style roll film cameras and then the photos were scanned to computers several years later. Therefore, recognition and translation methods must be robust enough to handle noisy data.

In comparison to other dominant languages such as Chinese with large labeled corpora available for training, Nyushu X  X  resources are extremely insufficient for state-of-the-art Optical Character Recognition (OCR) and Statistical Machine Translation (SMT). Bai and Huo [2005] utilizes more than 1 million annotated characters for OCR training in order to achieve 98.24% accuracy for Chinese handwritten charac-ters, but there is no annotation with equivalent size for Nyushu characters. Moreover, stains on the articles, low resolution of the photos and distortion from scanners all increase the difficulty for OCR. More importantly, stroke recognition algorithms [Liu et al. 2004, 2013] that have been employed for character recognition cannot be utilized in this context because such recognition systems require users to literally  X  X rite X  a character (e.g., writing capitalized  X  X  X  by adding a  X - X  after writing  X   X ). This allows the algorithm to track the strokes including lengths, directions, positions and order. However, all Nyushu documents are scanned images and, thus, very little knowl-edge about the order of the strokes in each character can be extracted. In place of the traditional stroke-recognition algorithms, we propose a more refined character-segmentation-based recognition algorithm specific to Nyushu. Given a scanned image of the document, our algorithm segments out individual characters from the image, and links these characters to the standard Nyushu characters. The primary advantage of this segmentation algorithm lies in its capacity to negate the necessity for an extensive understanding of the specifics of the language and the variability across hand-written documents, so that both known and novel features can be fully exploited. In addition, we propose a novel lattice representation to compute the visual similarity between each pair of hand-written characters and standard characters. The we apply language mod-eling to jointly select the best linking and translation hypotheses. The data, resources and algorithms we created will be useful to serve as a benchmark for researchers in Computer Vision, Image Processing and NLP communities to work on this endangered language. Moreover, methods from our paper can also be applied to other endangered languages that share similar characteristics with Nyushu. Also, for more languages with scanned handwritten documents only, our methods can help bridging the gap between raw images and clean digitalized texts.

In all, in this research, using Nyushu as a case study, we present the first attempt to develop an end-to-end system to fully understand a scanned hand-written document in an endangered language. We propose a pipe-lined system that (1) automatically recognizes characters and segments a document into characters using contextual in-formation to augment image processing techniques; (2) links the identified characters to the standard Nyushu characters; and (3) translates them into Mandarin Chinese based on visual, semantic and contextual evidence. Most of the previous work on endangered languages focused on  X  X ocumenting X  (e.g., Bird [2009], Bird et al. [2014], and Ulinski et al. [2014]) or constructing resources (e.g., Riza [2008], Lam et al. [2014], and Benjamin and Radetzky [2014]), instead of  X  X escrib-ing X  these languages in terms of lexical, syntactic and semantic analysis [Beale 2014]. A few exceptions include the automatic extraction of grammatical information from in-terlinear text [Bender 2008; Bender et al. 2013, 2014] and Machine Translation [Bird and Chiang 2012; Ombui1 et al. 2014]. However, none of these studies covered methods for automatic typing from scanned documents to digitalized text files. Moreover, none of the aforementioned methods have been applied to non-Mandarin-Chinese languages, even though fairly involved linguistic research has been conducted on these languages since the 1960s.

Compared to traditional Machine Translation work, end-to-end translation of the en-dangered language takes noisy scanned documents (images) instead of clean digitalized texts as input. One of the primary difficulties of working with non-Mandarin-Chinese languages is that most corpora consist of scanned images of the original documents. Thus, a conversion mechanism is required to transform texts from the scanned images into machine-readable formats. Research efforts have been dedicated to developing im-age segmentation algorithms that can segment individual characters from the scanned documents [Zhao et al. 2003; Han et al. 2005; Fu et al. 2006]. The next step after seg-mentation is to map them to their standard counterparts. This step is performed via the computation of features on the characters; these features help distinguishing be-tween characters and being robust to subtle variations in different versions of the same character presented in the database [Trier et al. 1996]. We will show the importance of embracing Image Processing, Computer Vision and linguistic knowledge and resources into the translation procedure. As the final module of the pipeline, our lattice rep-resentation based machine translation system determines candidates across Nyushu and Chinese characters whereas the representation [Wang et al. 2012] provides the ranking of probabilities of candidates of Chinese characters only. We start by converting some of the following data and linguistic resources created by Zhao [1995, 2004a, 2004b, 2005, 2008] into machine readable form. 1 In our work, the corpus (Table I) we use includes 651 documents 2 (222,200 characters) from (Zhao, 2005), which is an authorized collection of 90% of existing Nyushu articles in multiple genres such as poems and biographies. This collection is drawn exclusively from original genuine Nyushu documents, ranging from the classical manuscripts in-herited from ancient times to the articles by the last generation of Nyushu masters up until the end of the 20th century. The variability and vastness of the data is an indi-cator of its thoroughness and authenticity. Each document is hand-written by Nyushu masters (or language experts), without any punctuation and titles and has manual Mandarin Chinese translation which will be used to evaluate our Machine Translation output. All Nyushu documents are raw scanned images and have not been manually aligned with their Chinese translation. There are many variants and misspellings in the Nyushu corpus. For example, all of the following four hand-written characters represent  X  (peace) X : , , and . Zhao [2004a] manually normalized all characters into clusters based on the pronunciation and meaning, and identified the most common character in each cluster as the canon-ical  X  standard  X  character, and the rest were considered as  X  variants  X  of the standard character. For the above example, the most frequent character is extracted as the standard one. 398 standard Nyushu characters were finalized and a Unicode represen-tation was proposed for each standard character [Zhao 2004a]. In this study we exploit this valuable resource as the target set to link hand-written Nyushu characters and also use it to verify the visual features for character comparison. We utilize a Nyushu to Mandarin dictionary manually created in Zhao [2004a, 2004b], which includes the alignment between 398 standard Nyushu characters and 2641 Chi-nese characters with frequency information, derived from the Nyushu corpus. This dictionary also records the frequencies of Nyushu characters representing Chinese characters, for example,  X   X  appears as  X   X  802 times and  X   X  309 times. Because Nyushu is a phonogram language, the mapping between Nyushu characters and Man-darin Chinese characters is many-to-many. Each Nyushu character is designed to represent a cluster of 1-15 Chinese characters sharing similar pronunciations. For ex-ample, both Nyushu characters, and , share the same pronunciation [pa 13 ]in Jiangyong dialect, and so they can both be translated into either the Chinese character  X   X  (quilt) or the character  X   X  (maidservant). Figure 2 depicts the flow diagram of our system to understand a Nyushu document. Given an image of a scanned hand-written Nyushu document, our first step is to automatically segment it into individual characters. This is a hard problem because of the following reasons: (1) Noisy background in the scanned documents. (2) Inherent variability in the hand-writing across various authors.
 (3) Issues related to the text such as overlap between characters, and disjoint compo-We design a multi-stage segmentation algorithm as illustrated in Figure 3.
Thresholding. We start by applying Otsu X  X  thresholding method [Otsu 1979] to sepa-rate the foreground handwritten characters from the background paper (or parchment). This is an intensity-based approach, where we dynamically identify an intensity thresh-old that can accurately segment out the characters and their components from the noisy background. With this method we are able to retrieve most of the components of each character as shown in Figure 3(a).

Column Identification . The thresholded images are then passed to the next step for identifying columns. Since the documents are composed of characters organized in columns read from top to bottom, and right to left, the first step in the segmentation algorithm entails extracting individual columns of text. A vertical  X  X canning window X  slides along the x -coordinate (horizontal direction) and the value of the pixels within the window are summed.

For a column with characters this sum will be non-zero, whereas for the background, which after thresholding only consists of black pixels, the sum will be approximately 0. The intuition for this  X  X canning window X  comes from the fact that in the horizon-tal direction the centroids of characters within the same column vary minimally. We compare the x -coordinate of the local maximum and minimum on the curve and if the difference  X &gt; X  , where  X  is a threshold parameter which is empirically set to 20 pix-els, we can make the maximum as a centroid (center point or line of a patch) and the minimum as a boundary of columns. Figure 3(a) shows this procedure. The columns are stored from right to left with decreasing x -coordinate values.

Character Segmentation . The segmentation of an individual character is carried out by associating the character X  X  components together so as to form a single complete character. This is accomplished by measuring the distance between the core component of the character and its auxiliary components and if the distance ( L 2 norm) between the centroids of these components is less than  X  , which is empirically set to 10 pixels, the components are thus associated to form a single character.

However, since the documents are handwritten, it X  X  highly possible that unequal spacing exists between two consecutive characters. Therefore, multiple characters could be identified as a single character according to the  X  threshold. In order to alleviate this problem, we perform the following two steps: (1) After identifying that the character obtained from the previous threshold consists (2) The second stage consists of splitting multiple character components by comput-
Character Normalization . Once the characters have been segmented from a docu-ment, we normalize these characters (Figure 3(c)) to make every extracted character conform to a predetermined size and position, thereby reducing the variation in shape.
The images are mapped onto a standard image plane in order to ensure that features extracted from all images have the same dimensionality. Let the input image be denoted as f ( x , y ), where x and y are the horizontal and vertical coordinates. The normalized image is denoted as g ( x , y ). The coordinates in the normalized image plane can be obtained from coordinates in the original coordinate system by the following mapping: To simplify this further, we only consider a 1-D normalization; therefore our mapping reduces to We map the coordinates from the input image to the normalized image using coordinate discretization and pixel interpolation.

By discretizing the binary image the mapped coordinates ( x , y ) are approximated with the closest integral coordinates ( x , y ). The pixel value f ( x , y ) is mapped to all pixels in the normalized image ranging from ( x ( x ) , y ( y ) )to( x ( x + 1) , y ( y + 1) ). The normalized image is constructed as a square of side L , where L is set to 64. However, normalized images may not be completely filled because the character ex-tracted could be elongated in either the vertical or horizontal dimension. To alleviate this problem, we partially preserve the aspect ratio of the input image using the tech-nique of Aspect Ratio Adaptive Normalization (ARAN) [Liu et al. 2000] and align the boundaries (the end of stroke projections) of the input image to the boundaries of the normalized image. The aspect ratio of the normalized image, g , is considered as a con-tinuous function of the aspect ratio of the input image, f , and we have g = sin(  X  f / 2), where f = W 1 / H 1 if W 1 &lt; H 1 and f = H 1 / W 1 otherwise, H 1 and W 1 are the height and width of the input image. If the input image is vertically elongated, the vertical dimen-sion in the normalized image plane is filled. The horizontal dimension is centered and scaled according to the aspect ratio ( L  X  g ), and vice versa if the horizontal dimension is elongated. The coordinate mapping functions are as follows: The linear normalization function aligns the boundaries (the end of stroke projections) of the input image to the boundaries of the normalized image. Following segmentation, the next stage is linking each character to a standard Nyushu character. We extract the features from the segmented characters and utilize a classi-fication method for linking.

Input and Output . The linking system is a classification problem: given a train-ing instance matrix X = [ x 1 , x 2 ,..., x n ] and labels L ( x i )  X  X  1 , 2 ,..., C } , where i  X  X  1 , 2 ,..., n } ,and C is the total number of characters in the database, we create a label matrix Y  X  R n  X  C where each entry Y ij = 1if L ( x i ) = j and Y ij = 0 otherwise, i
Then we obtain a confidence matrix with Y t = F ( X t ), where X t = [ x bels with L ( x  X  i ) = arg max j y  X  and y  X  L from X and Y where F ( X )  X  Y and the prediction procedure can be conducted with F ( X t )  X  Y t .

Specifically in our task, the vectors in matrix X and X t are the feature vectors of the segmented characters, and each label represents one standard Nyushu character. A segmented character is considered  X  X inked X  to its standard counterpart which is represented by the label assigned to the segmented character. Moreover, We also refer to Y t as lattice to store multiple linking hypotheses and record it for later use. As an intermediate system in the whole pipeline, the linking system may receive upstream errors and also generate its own errors especially when we merely use the assigned label (with the maximum probability or confidence) for the downstream Nyushu-to-Chinese Machine Translation. A lattice contains multiple linking hypotheses. For example, in our experiments, the 30th character in Yi001 is linked to with the highest probability of 12.7%, unfortunately this linking is incorrect. However, the character with the second highest probability of being linked to the segmented character is , and this is an accurate match. Thus, the lattice helps in increasing the linking accuracy by allowing the linking to be done with a range of potential matches rather than the single best match (we will verify this claim later in the experiment section 5). Feature Extraction . We design image-based statistical features as described in Table II. This results in a feature vector x i of 715 dimensions.
 We utilize a feature selection technique based on spectral graph theory called Spectral Feature Selection ( SPEC ) [Zhao and Liu 2007] to identify the most impor-tant features. This method uses spectral information of the normalized Laplacian of the feature matrix. Given the feature matrix X = [ x 1 , x 2 ,..., x n ] , which consists of n feature vectors, where n is the number of character images, and x i  X  R m .
We use the Gaussian radial basis function (RBF) kernel [Tsuda and Sch  X  olkopf 2004] as a similarity measure to construct the similarity matrix, S , which calculates the correspondence of each feature vector to every other feature vector. A graph G is con-structed where each vertex corresponds to a feature vector and the weights w ij on each of the edges correspond to the entries in S . Given G , its adjacency matrix W is defined as W ( i , j ) = w ij .
 The graph G can be represented by its normalized Laplacian, L , calculated as  X  L = D  X  W ; L = D  X  1 2  X  LD  X  1 2 , where D is the degree matrix constructed using the diagonal of the adjacency matrix, W . According to graph theory, the structural information of a graph can be obtained from its spectrum. This method employs the spectrum of the graph to measure feature relevance and thus realizes spectral feature selection. Two functions are obtained from the normalized cut of the graph, and these functions in conjunction with the spectrum of the graph form three feature-ranking functions. The SPEC feature selection algorithm yields a subset of 203 features for each character image.

We further reduce the feature set by removing correlated features using Pearson X  X  correlation coefficient [Pearson 1895]. After the removal of redundant features, the feature vector is reduced to 175 features.

Linking Algorithm . Since this is a multi-class classification problem where the num-ber of training instances from each class is unbalanced, methods such as Support Vector Machines (SVMs) [Cortes and Vapnik 1995] and its variants suffer from over-fitting due to the rigid requirement for balancedness among instances, and are also time-consuming. Therefore, we choose Random Forest [Breiman 2001] as the classi-fication algorithm to avoid overfitting. Random forest creates a bunch of randomized decision trees and utilizes a majority vote to determine the prediction. The input vector of a test instance will enter the root of each tree and finally reach the leaves through non-leaf nodes where trained rules and conditions are applied. The leaves store the labels which connect to a standardized character. We count the output of the trees and produce the highest vote from all trees as the linked character for a test instance.
With the random forest method, we design two different learning approaches: one approach is the blind test , and the other approach is the leave-one-out methodology. For the blind test approach, we simply train with a single random forest consisting of 1 , 000 decision trees, and test all the instances with it; while for the leave-one-out cross-validation, we use one instance as a test instance and train a random forest model consisting of 1 , 000 decision trees on the rest of the instances (training instances plus other test instances) during each iteration. The final step is to translate the Nyushu character sequence n into a Mandarin Chinese sequence c . The translation procedure is a character-for-character substitution, which we attack with the noisy channel model: arg max c P ( c | n ) = arg max c P ( c ) P ( n | c ) .
We train a Mandarin Chinese character-bigram model P ( c ) on manual translations of the Nyushu corpus (excluding the testing set), interpolating bigram (0.8 weight) with unigram (0.2 weight) probabilities. We derive P ( n | c ) from the Nyushu/Mandarin dic-tionary. We cast these models as finite-state machines [Knight and Al-Onaizan 1998; Casacuberta 2001; Kumar and Byrne 2003], and use the Carmel toolkit [Graehl 1997] to decode the 1-best Nyushu sequence into its most likely Chinese translation. Finite-state machinery lets us alternatively decode the whole Nyushu lattice. In that case, we first exponentiate the lattice probabilities (factor of 8), as Nyushu lattice produc-tion results in fairly flat distributions. For example, Figure 4 shows the probabilities of the lattice X  X  top-10 Nyushu standard-character guesses for a particular image frag-ment (the fourth Nyushu character in Yi001 lattice). Notice that the 1-best guess only outscores the 2-best by a factor of 1.5 (0.092/0.062), and the rest of the probabilities are also within range. Therefore, the disambiguation decision is effectively turned over to the Mandarin Chinese language model, which has strong opinions about the final sequence. Raising the lattice probabilities to the 8th power increases its discriminatory power within the noisy channel -the 1-best guess now outscores the 2-best by a factor of 23. If we view the noisy channel as a log-linear model, this amounts to assigning a weight of 8 to the lattice feature, and a weight of 1 to the language model feature. As the annotation process is time consuming and human experts are scarce, we focus on Nianhua Yi X  X  documents for our experiments. We take the first five documents ( Yi001 -Yi005 ) as the test set and the rest as the training set.
 We collect 4281 correctly segmented and annotated characters to train the linker. Note that there are only 160 unique characters in Yi001 -Yi005 instead of 398 for the whole set, for the sake of simplicity, all instances in the training set cover these 160 classes. We will use Yi003 (Figure 5(a)) as a walk-through example to show the input and output of each step and analyze the errors. Each test document is a poem consisting of 12 sentences of 7 characters. The segmen-tation module successfully segments 380 correct characters from 420 characters, with a 90.48% accuracy. Figure 5(b) shows the segmentation result of Yi003, with errors marked with gray frames.

Comparing the counterparts between Figures 5(a) and 5(b), we can conclude that there are two major challenges: the first challenge is to associate disconnected compo-nents together to build up the complete character, such challenge will trigger omission error and we mark them with solid frames in Figure 5(b); the second challenge is to detect the negligible spacing (boundary) between two characters, it leads to association error and we mark the error with dotted frame in Figure 5(b). Figure 6 shows the ground truth and linking errors with the leave-one-out approach for the document Yi003. Figure 7 presents the linking accuracy of the top 150 hypotheses. The linking (identification) accuracy for the 1-best achieves approach 84% (353/420) and can be pushed to 90% with a deeper detection depth, which provides promising room for Machine Translation to select the best hypotheses. By comparing the linking results with the segmentation results in Figure 5(b), we can see all segmentation errors are propagated into the linking step, except the fourth character in the leftmost column:  X  the segmentation module misses two small dots in the character, but our visual features still successfully link it to the correct standard character.
Moreover, among the whole 420 test instances, we categorize the main linking errors as follows: (1) Two characters with similar structures are mistakenly grouped into the same clus-(2) Partially similar structure can also cause some errors. This type of misclassification (3) Occasionally, characters are linked because one of their components is the same. (4) In a few cases, particularly in clusters that have multiple characters, all 3 types of We evaluate our Nyushu to Mandarin Chinese Machine Translation using the following metrics: (1) Character Accuracy : The percentage of characters that are translated correctly. (2) Word Recall : The percentage of words in gold standard that appear in the system (3) BLEU [Papineni et al. 2002]: The standard Machine Translation evaluation metric. Table III summarizes the overall performance of the test set.
 Table IV presents the output of various methods with leave-one-out approach for Yi003.

We can clearly see that using the language model significantly improves the per-formance of all three measures. In particular, it successfully fixes many errors de-rived from similar pronunciations. These poems were written in a very terse style, so a character-bigram model is sufficient to capture some common phrases. Table V presents some examples corrected by the language model.

The lattice representation effectively propagates multiple hypotheses into the lan-guage model for re-ranking, and achieves further improvement especially on word recall. For example, the fourth character in the second sentence of Yi003 is linked to the standard character ( X  or (father or wife) X ) with the highest probability of 9.1% and linked to the second hypothesis ( X  (house) X ) with a probability of 8.9%. The language model successfully promoted the second hypothesis to the top because the phrase (empty house) X  appears much more often than  X  (empty father) X  or  X  (empty wife) X  in the training corpus.

Many of the remaining errors are out-of-vocabulary person names such as  X  (Yi Shunchao) X ,  X  (Yi Xijun) X ,  X  (He Guangci) X  and  X  (Tang Liying) X .
 In fact many of them were written in characters similar to their original mandarin Chinese forms. Some errors occur on the characters which share similar pronunciations and semantic categories with the correct translations. For example,  X  (grandfather, pronounced as Ye) X  was mistakenly translated into  X  (father, pronounced as Die) X ;  X  (crazy words, pronounced as Wang Yan) X  was mistakenly translated as  X  (rumor, also pronounced as Wang Yan) X . There is another very interesting error.  X  (little uncle, pronounced as Xiao Jiu) X  was mistakenly translated as  X  (thin and old, pronounced as Xi Jiu) X . Although the Mandarin pronunciations are slightly different, but their Jiangyong dialect pronunciations are identical. This phenomena indicate that dialectic features should be taken into consideration when processing and translating phonogram languages such as Nyushu, although current work does not include these features. Nevertheless, such errors are still tolerable because after chanting out the translations the audience can understand the correct meanings based on the contexts. Using Nyushu as a case study, we presented an end-to-end system to tightly couple computational methods from both NLP, Image Processing and Computer Vision, and linguistic knowledge derived from field studies for deep understanding of endangered languages. Linguists such as Zhao [1995, 2004a, 2004b, 2005, 2008] have devoted more than thirty years to the field studies in remote locations without adequate funding support; and the datasets and resources they collected have provided a valuable and authentic jump start for our system development. On the other hand, they have done extensive manual work which would have been dramatically expedited by the inclusion of  X  X achine X  in the loop. In the future we will improve and extend our methods to understand other endangered languages.

