 PAULINE M. BERRY, MELINDA GERVASIO, and BART PEINTNER , SRI International All too often, arranging meetings in an office environment becomes a tedious process. One common method employed is a series of emails to propose, reject, counter-propose, and eventually agree on a time. The effort consumed in such practices motivates the opportunity for forms of automated or semiautomated assistance in scheduling meetings. For example, consider a system that allows users to specify their desiderata (e.g.,  X  X ometime next week X ), and presents the users with satisficing options for the meeting.

Although a number of fully or semiautomated scheduling systems have been developed X  X ome that operate along the lines of the example X  X hey have by-and-large all suffered low adoption rates for two main reasons [Higa et al. 1996; Palen 1999; Tullio et al. 2002]: they fail to account for the personal nature of scheduling, or they demand too much control of an important aspect of an individual X  X  working world.
The personal nature of scheduling is most directly seen in situations where a user X  X  meeting request cannot be fully satisfied. For example, suppose that Alice requests a 90-minute meeting with Bob and Chris next Tuesday afternoon, but no time is available to all during that period. Some individuals may prefer the option of a shortened 60-minute meeting, while others (like Alice) may prefer the full 90-minute meeting Tuesday morning. Most users would like to be presented with both options (more generally, with all relevant options, of which there can be many in such over-constrained situations), but such that the options they most prefer have priority in the presentation. It is these difficult, over-constrained situations with many competing factors and many possible relaxations of the meeting request where scheduling assistance is most useful. Hence, to be of real value here, an automated scheduling assistant must actively account for a user X  X  scheduling preferences.

Time management is personal not only because of individual preferences, but also because of the importance people most often hold to controlling (or at least influencing) decisions over their time. Hence, to be of real value, an automated scheduling assistant must defer to the autonomy and ultimate control of the user.
 This article describes an integrated AI prototype system, called PTIME ( Personalized Time Management ), that provides semiautomated scheduling assistance. The PTIME system has been deployed in a prototype form in our organization. The design and deployment issues pertaining to an early version of PTIME, largely from a software engineering perspective, were reported by Berry et al. [2006]. The approach we take is to combine initial, lightweight elicitation of an individual X  X  scheduling preferences with unobtrusive, online refinement of them. This personalized preference model informs a constraint-based scheduling engine that computes and presents preferred options in response to a meeting request. By initially eliciting the user X  X  preferences, the schedul-ing assistant can offer reasonable scheduling options from first use; by refining its knowledge, the assistant can become progressively more capable and trustworthy over time [Kozierok and Maes 1993].

The technical challenge we address is to adequately capture an individual X  X  schedul-ing preferences in a model and then exploit it in a tractable way to provide scheduling assistance. First, for elicitation, more expressive models better capture the nuances of user preferences (such as the trade-offs between criteria) but require more effort to specify. Second, for automated learning by which a system refines its knowledge, expressive models require significant training (and tend to overfit), while inexpressive models cannot distinguish between candidate schedules that are distinguished by the user. Third, for automated searching for and ranking of candidate schedules (hereafter, constraint reasoning ), it is more difficult to define and reason over complex objective functions, preferences, and constraints.

While prior research has looked at one or more of these aspects (modeling and eliciting, learning, and reasoning), the approaches and resulting systems have rarely sought to encompass all three. For example, representing and learning user prefer-ences but not performing sophisticated reasoning to offer scheduling options [Mitchell et al. 1994]; or representing preferences and performing constraint reasoning but not updating preferences by learning [Haynes et al. 1997; Refanidis 2007].

As we will explain, PTIME addresses these technical challenges through a multi-criteria model of the user X  X  preferences founded on a single additive utility function by which the system can rate alternative schedules. User studies establish that this model captures the expressiveness sought in the calendaring domain. At the same time, the model is amenable to an adapted multicriteria constraint reasoning algorithm for disjunctive temporal constraints, and to Support Vector Machine (SVM) learning for refining the model instance as the system is employed.

After placing our work in context (Section 2), we provide an overview of the PTIME system architecture (Section 3). We describe the development of the preference model (Section 4) and our approach to the elicitation, learning, and reasoning challenges (Section 5). We conclude after reporting on a multifaceted evaluation of the perceived usefulness of the system (Section 6). The preferences literature is rich with qualitative and quantitative models of varying expressive power and computational tractability; for surveys, we refer to Ozt  X  urk et al. [2005] and Goldsmith and Junker [2009]. In particular, there is a sizeable body of lit-erature on the theory and practice of Multicriteria Decision Making (MCDM) [Keeney and Raiffa 1993; Ehrgott and Gandibleux 2002]. The three aspects of finding optimal solutions to a multicriteria constraint optimization problem are: (1) modeling the prob-lem (including elicitation of the user X  X  preferences), (2) deciding on the combination or trade-off of the decision criteria (and thus the nature of the solutions the user wants to seek), and (3) providing an algorithm to derive the optimal solutions of the chosen type.
 The two broad approaches are MultiAttribute Utility Theory (MAUT) [Keeney and Raiffa 1993], which focuses on constructing a global utility function (the aggrega-tion function ), such as a weighted linear sum, and its competitors, notably Analytic Hierarchy Process (AHP) [Saaty 1980] and MultiObjective Combinatorial Optimiza-tion (MOCO) [Ehrgott and Gandibleux 2002].

Given the size of the literature on reasoning with preferences, we focus on quan-titative approaches in Constraint Programming (CP), except to note the qualitative graphical model of Ceteris Paribus nets (CP-nets) [Boutilier et al. 2004]. Researchers in CP have, by and large, focused either on the disaggregation phase (i.e., the modeling aspect), or on the aggregation/optimization phase (i.e., the algorithmic aspect) suppos-ing that an aggregation function is available or the type of solution is decided. The modeling aspect is a recognizably important and difficult part of tackling real-world problems, especially where the problem definition or objective features uncertainty [Gervet et al. 1999; Labreuche and Hu  X  ed  X  e 2005].

Multicriteria optimization problems have been tackled in CP. From MAUT, a common aggregation function is to combine the criteria into a single objective function as a weighted sum. The solving aspect can then be addressed by variants of branch-and-bound search with dominance testing [Focacci and Godard 2002]. Two drawbacks to a weighted sum are its limited expressiveness, for instance, regarding dependency between criteria, and the pragmatic difficulty of setting the weights (and handling the sensitivity of the problem to their values). One main alternative to a weighted sum aggregation of the criteria is to seek the frontier of nondominated solutions; an efficient CP computation method is by Gavanelli [2002].

Preference-Based Search (PBS) [Junker 2002] is a dedicated algorithm for a formal-ism in the MOCO line that can express preferences between as well as over criteria. Similarly in the MAUT line, MultiCriteria Search (MCS) [Le Hu  X  ed  X  e et al. 2006] is based on a succession of mono-criteria searches. MCS is dedicated to an expressive formalism of MAUT that encompasses sophisticated aggregation functions beyond a weighted sum, such as the Choquet integral [Grabisch et al. 2000].
 Despite widespread adoption of calendaring tools (for instance, popular, lightweight, Web-based tools such as Google Calendar), the most common practice for negotiating meetings remains extended email, phone, or instant messaging interactions.
While both commercial (e.g., Microsoft Outlook) and open source (e.g., Yahoo! Zimbra) calendaring systems abound to support centralized solutions within an institution, they leave the task of choosing a meeting time up to the user, thus avoiding the need to ac-tively reason about constraints and scheduling preferences, such as how the user would relax a meeting request when it is over-constrained, which one of the many meeting times to choose when under-constrained, or which room is best for a given type of meeting. As an advanced example, Meeting Maker [PeopleCube, Inc. 2011] supports the user in selecting a time by graphically depicting the availability of participants. The strength of such group calendaring systems is integration with institutional work-flow (e.g., centralized calendar servers, room bookings), but, being calendaring tools rather than personalized assistants, they lack the potential benefit that personalized AI technology could bring.

The value of applying machine learning to user scheduling preferences was rec-ognized early by Kozierok and Maes [1993]. The investigations that have followed X  including Mitchell et al. [1994], Tullio et al. [2002], Oh and Smith [2005], Brzozowski et al. [2006], Krzywicki et al. [2010], and others such as Haynes et al. [1997], Faulring and Myers [2005], and Refanidis [2007] X  X ave emphasized one or more of the three aspects of modeling and eliciting preferences, acquiring them by learning, or reasoning with a preference model, but seldom have the resulting systems have rarely sought to encompass all three. For a survey, we refer to Berry et al. [2007].

To take one example, CMRadar [Oh and Smith 2005] addresses a task similar to ours, and takes the most similar approach. A CMRadar agent helps its user sched-ule meetings by extracting meeting information from email, and generating schedule options using a constraint-based scheduler that takes into account user preferences. The CMRadar preference model is a weighted sum over mainly temporal scheduling features (akin to our earlier work [Gervasio et al. 2005]), whereas PTIME requires a more expressive form to capture trade-offs. CMRadar uses a passive approach to learn user preferences; this contrasts with our online learning. Further, CMRadar learns user preferences (in its model) over meeting timeslots, whereas we learn over whole schedules constructed in response to a scheduling problem. PTIME ( Personalized Time Management ) is an intelligent, personalized assistant that helps users handle email meeting requests, reserve venues, and schedule events. It in-terfaces with commercial enterprise calendaring platforms, and it operates seamlessly with users who do not have PTIME. The system is designed to unobtrusively learn scheduling preferences, adapting to its user over time.

PTIME was part of the CALO project (Cognitive Agent that Learns and Organizes), a large-scale, five-year effort to build an adaptive cognitive assistant situated in the office environment [Myers et al. 2007]. Figure 1 depicts a typical scheduling interaction be-tween user and system. PTIME initially elicits general scheduling preferences (step 0). Given a meeting request (step 1), PTIME computes candidate schedules (possibly re-laxations) and displays a subset of these to the user (step 2), and accepts the user X  X  selected option (step 3). Based on which option the user chooses, PTIME updates the preference model (step 4), which becomes the basis of reasoning over candidate sched-ules for the next scheduling request. The user may reject all the presented schedule options and revise the scheduling request (step 3 to step 2), whether because all the options are unsatisfactory or seeing them stimulates a desire to explore alternatives. Such a paradigm of use embeds the user X  X  autonomy as controlling the process.
The PTIME user organizing the meeting selects an option, taking into consideration other participants X  generic scheduling preferences, which PTIME displays according to privacy settings. This option is presented to invitees and, in the simplest form of negotiation supported by PTIME, the invitees may give feedback and decide whether to accept the meeting request. According to the lead of the meeting organizer, multiple rounds of option generation, user selections, and negotiation may occur. The rounds are linked through a loose notion of episode.

PTIME comprises four main components: a User Interface (UI), a calendar proxy, a constraint reasoner, and a preference learner. The UI (Figure 2) lets the user en-ter meeting constraints and details using a combination of direct manipulation and restricted natural language (through an off-the-shelf natural language package). The calendar proxy provides a common connection between PTIME and a variety of cal-endar servers. The Constraint Reasoner generates scheduling options in response to the meeting request (constraints) entered by the user. It constructs and solves a soft constraint optimization problem with preferences to generate satisficing and relaxed options that account for the user X  X  preferences. The Preference Learner learns unob-trusively (using implicit feedback from the user X  X  natural interaction with PTIME) and incrementally (from each interaction). It is given training instances and queried by both the UI and the constraint reasoner. Before searching for candidate scheduling options, the reasoner queries the preference learner for the current instantiation of the preference model. After the user selects an option, it is sent back as a training instance with the set of all options. Our first model of user scheduling preferences sought to capture temporal preferences for under-constrained meeting requests [Gervasio et al. 2005]. The model was com-posed as a weighted linear sum of features such as meeting start and end times. While it was readily apparent how to reason over and learn this model, the model did not capture nontemporal preferences, such as for meeting participants, and its expres-siveness was too limited to capture how temporal and nontemporal criteria interact, which have a significant role in over-constrained meeting requests. This motivated us to revise PTIME X  X  preference model and, in turn, the system X  X  reasoning and learning capabilities. We began by investigating criteria that commonly influence the scheduling decisions in our target user population. We conducted a series of structured interviews with eleven subjects (managers, administrative staff, and researchers in our organization) focused on how they prefer to schedule their meetings and free time, and how they trade off different criteria to deal with scheduling conflicts. We further asked the participants to keep a record of their schedules over a period of a week, and to record the meeting requests they made and received and how they negotiated meetings with others.
The fivefold foci of the study were event characteristics (e.g., one-on-one versus group meetings), scheduling processes (e.g., iterated refinement of a time), decision factors (e.g., relationship to meeting organizer), preferences ,and scheduling needs . Details may be found in Berry et al. [2007].

In previous studies of user scheduling habits and (semi-)automated calendaring tools, researchers report that people are reluctant to invest in accurately and fully informing a scheduling system of their preferences (to the extent that they can articulate them) unless they are mandated to do so, or unless the elicitation process is not burdensome and they are persuaded of the benefits [Higa et al. 1996; Tullio et al. 2002]. Other studies support our finding that even when people are confident in the behavior and the decisions of a (semi-)automated system, they seek transparency into its reasoning [Beard et al. 1990; Palen 1999].

Our own study and prior work also demonstrates that evaluation of scheduling options is contingent on multiple criteria and their interaction [Kozierok and Maes 1993; Brzozowski et al. 2006]. Accounting for the relative importance of these features is crucial if we are to offer the user-desirable relaxations for over-constrained requests; earlier versions of PTIME could not do so. While some (e.g., Haynes et al. [1997], Gervasio et al. [2005], Oh and Smith [2005], and including our own earlier work) assume no interaction between the criteria in their preference model, which simplifies the learning and solving aspects, this choice limits the expressiveness.

A set of modeling requirements emerge from these various ethnographic investiga-tions. First, the preference model must be populated from intuitive (and thus likely qualitative) statements expressed in terms the user is familiar with, for example, events, people, and calendars. Second, the model must be sufficiently expressive to capture enough of user scheduling preferences X  X eyond day/time preferences X  X o en-able the personalized scheduling task. Third, the model must be explainable to the user, again in terms of familiar, domain-relevant concepts [Mitchell et al. 1994]. Fourth, the model must be able to express multiple criteria and the interaction between them (e.g., between meeting duration and the temporal preferences of other participants). Finally, the model must be tractable for reasoning and learning to support a practical scheduling assistant. The global utility function approach of MultiAttribute Utility Theory (MAUT) [Keeney and Raiffa 1993] meets the preceding requirements, and allows us to balance the competing and simultaneous demands of expressiveness, elicitation, learning, and rea-soning. The calendaring domain demands a model that can express potentially complex ordinal and cardinal preferences over a combinatorial domain (the schedule options). By providing a single (additive utility) function by which the system can rate alterna-tive schedules, a MAUT approach is in principle amenable to the schedule evaluation and preference learning components.

A weighted sum is the simplest and most common example of a MAUT approach, but it cannot express interaction between criteria and it assumes that the criteria are preferentially independent. A more sophisticated MAUT model is the Choquet integral [Grabisch et al. 2000; Labreuche and Grabisch 2003]. The Choquet integral subsumes a weighted sum, and is able to express multicriteria trade-offs such as Pareto-optimal decisions. PTIME employs a pragmatic approximation of a restricted form of the Choquet integral.

Criteria. Based on our user study, augmented by features suggested in prior work in the literature (e.g., Kozierok and Maes [1993], Mitchell et al. [1994], and Brzozowski et al. [2006]), we identified seven criteria consistent across different users: (1) time : scheduling windows for the requested meetings; (2) duration : durations of meetings; (3) overlap : overlaps, ordering constraints, and conflicts between requested and existing meetings; (4) location : locations of meetings; (5) participants : participants in meetings; (6) stability : time or duration changes for existing meetings; and (7) others : preferences of others participating in new meetings or rescheduled existing meetings [Garrido et al. 2000].

We deliberately chose criteria expressed in terms of domain-level concepts familiar to the user to facilitate elicitation of instances of the preference model and explanation of learned preferences. Other criteria, including the stability of a candidate schedule (with respect to new meetings and meetings that run long) and perturbation effects (on the existing schedule), would add richness to the preference model, but the richer model does not prove as amenable to reasoning.

Aggregation Function. Practical applications have indicated that, for the Choquet integral as an aggregation function, the restricted 2-order case is usually sufficient [Marichal and Roubens 2000; Labreuche and Hu  X  ed  X  e 2005]. This restricted case is able to express interactions between pairs of criteria, but not between three or more criteria.
Let N ={ 1 ,..., n } be the set of criteria. In the 2-order case, the Choquet integral can be written as where the coefficients a i , i  X  N ,and a ij , { i , j } X  N , fully specify the model.
In the 2-order case, the coefficient a i  X  [0 , 1] describes part of the relative importance (a greater value indicates greater relative importance). The a ij  X  [  X  1 , 1] are the inter-action indices : they describe the interaction between criteria i and j . a ij &gt; 0 indicates that i and j are complementary criteria, while a ij &lt; 0 indicates that they are sub-stitutive; a ij = 0 indicates no correlation between the two. As formulated before, the second-order terms are symmetric: a ij = a ji  X  i , j .

For n criteria, the 2-order Choquet integral requires only n + ( n 2 ) = n ( n + 1) 2 coefficients to specify the integral, compared to 2 n for the full n -order case. This reduction in the number of coefficients is important not only to reduce the burden of model instantia-tion but also to mitigate the curse of dimensionality and to ensure that learning can converge within a reasonable number of training examples.

We make the hypothesis that a 2-order model trades off expressiveness (being unable to express interaction effects among three or more criteria) with ease of model specifi-cation and explanation in a way suitable for: (1) a constraint-based representation of the scheduling problem, (2) reasoning over this problem representation, and (3) learn-ing revisions to the model. With n = 7 criteria, an instance of the model is specified by 7(7 + 1) = 28 coefficients. The purpose of developing the model for scheduling preferences described in the pre-vious section is to instantiate it for a particular individual, and to make use of the instantiation in order to provide functionality in an interactive application. Hence, be-yond being sufficiently expressive, the model must be feasible to elicitation, reasoning, and learning. Both the elicitation of an initial instance of the preference model ( preference elicitation ) and the specification of a meeting request ( problem elicitation ) share the challenges of eliciting preference information from a user. The perceived benefits from the person-alized system must exceed the perceived costs of the elicitation for users to willingly input information [Peintner et al. 2009]. Users may not fully know the information or be able to express it (at least via the elicitation mechanism offered). Moreover, the very process of elicitation itself is known to reshape X  X nd worse, bias X  X he informa-tion provided; preferences can even be created by the elicitation process [Payne 1993; Viappiani et al. 2006].

Preference Elicitation. The coefficients of a Choquet integral, the goal of our elicitation, can be derived from statements over examples ( X  X  rate this example more highly than that X ) X  X he more common approach X  X r over the model ( X  overlap is more important for me than duration  X ) [Marichal and Roubens 2000]. We chose to explore a form of model-driven preference specification rather than example-driven elicitation for a number of reasons. First, the user X  X  intuitions about the calendaring domain make providing meaningful feedback on the model simpler than on an artificial example. 1 This is especially true for over-constrained examples, where a perception of the calendars and preferences of involved participants is necessary to make an informed judgment over scheduling options. Second, because learning in PTIME uses real-life examples for which the user already has in mind the meeting request, and (to some degree) participants X  calendars and preferences, we can elicit only part of the model. Namely, we do not attempt to elicit the sign of interaction indices a ij , which has been found to be cognitively challenging for users [Bana e Costa and Vansnick 1999]. Third, to encourage adoption of the deployed prototype, we wanted a rapid, one-shot elicitation that would enable users to employ PTIME without an extended elicitation phase. Blending example-driven and model-driven elicitation is part of our future work.
Our approach to preference elicitation combines an interactive, visual interface and a series of simple elicitation invitations . Each invitation is presented as a panel, such as Figure 3, that asks the user to provide some statements of general scheduling preferences. The panels are presented in a graphical  X  X izard X  interface that allows the user to freely step forward and backward, and to ignore any invitation.

Derived from the information entered by the user, we infer qualitative pref-erence statements on and between the criteria, such as  X  X mportance( overlap ) &gt; importance( duration ) X . We compile these statements into quantitative coefficients in the Choquet representation by solving a linear program; for the details of the linear program formulation and its solving we refer to Marichal and Roubens [2000]. 2 The inferred preference statements encompass information regarding both the relative importances of the criteria (precisely, the a i Choquet coefficients), and the trade-offs between criteria pairs (the magnitude of the a ij interaction indices). 3
For instance, in the panel shown in Figure 3, the classification of the criteria into the four buckets speaks to the first aspect ( a i ). From the position of the overlap crite-rion(which is rendered in the UI as  X  X void overlaps X ) in the  X  X ery important X  bucket, the system will infer a value for the corresponding a 3 coefficient close to 1.
Another panel of the wizard (not shown) elicits statements relevant for the inferring information about the a ij . For each criterion, these statements concern whether the criterion is essential (i.e., veto a schedule that scores poorly on the criterion, regardless of other criteria) and whether it is sufficient (i.e., accept a schedule that scores well on the criterion, regardless of other criteria); again, we refer to Marichal and Roubens [2000]. As in previous works (e.g., Labreuche and Hu  X  ed  X  e [2005]), we find in practice that users rarely wish to make such statements (likely because they do not have a sufficient grasp of their own preferences in this regard), but that instead the a ij emerge from the user X  X  behavior as acquired by the preference learner.

The elicitation process is robust to the amount of information, falling back to an uninformative, default instantiation of the model in the case of no information. 4
Problem Elicitation. Our approach to problem elicitation is similarly based on an interactive interface.

The information for our scheduling task can be both broader ( X  X n afternoon next week X ) and more specific ( X  X ob is an optional participant X ) than that required by stan-dard calendaring tools. We seek to elicit not details of the meeting itself, but details of the meeting request, a potentially rich set of soft constraints that will be used to formulate a constrained scheduling problem instance. Since the constraints can be re-laxed, problem elicitation can be seen as elicitation of problem-specific (in contrast to generic scheduling) preferences.

It follows that the deficiencies of common approaches such as selecting a block of time on a calendar interface and then filling in details on a form, or employing Nat-ural Language (NL), are magnified. On one hand, form-based elicitation varies from restrictive, since the user is limited to the fields in the form, to intimidating, if the form contains enough fields to allow expression of rich constraints. Further, users often feel they must fill in a field simply because of its presence [Payne 1993]. On the other hand, unrestricted NL can leave the user unsure of what to enter, especially once the illusion that the system really understands everything entered is (inevitably) broken. Moreover, while forms place restrictions or requirements on the user, NL provides little guidance as to what constraints can be entered.

The left side of Figure 2 shows our problem elicitation interface. Organized around an NL input mechanism (top), the system summarizes the information the user has entered (below the NL entry box), and displays candidate options (middle). Details of the currently selected option are displayed on the bottom. Using the NL interface, the user can readily specify soft constraints (i.e., constraints that may be satisfied only to a degree, in contrast to hard constraints that must be satisfied exactly), such as preferred times (e.g.,  X  X refer early X , or  X  X refer 3pm X ) and locations or optional participants. The user can also flexibly and succinctly specify time windows (e.g.,  X  X ues afternoon X ). The user may also directly manipulate form fields in the familiar way, for example, to change the requested location by picking from a drop-down list.

As the user makes NL statements, manipulates form elements, or manipulates graphical calendar objects, PTIME performs constraint reasoning to compute a set of schedule options. Thus the user sees the list of options updated in near real time. Relaxed options (e.g., not all requested participants included), and options with con-flicts (e.g., overlaps with another event), are depicted with a warning triangle. An explanation, in the form of a simplified summary of the relaxed constraints, and repair suggestions are offered upon hovering over the option.

To the right of the elicitation pane, we provide an interactive calendar with most of the features users have come to expect in calendaring applications (Figure 2 again). The calendar display not only informs the user during problem elicitation, but also augments the user X  X  specification of constraints through the hybrid NL form with the ability to enter temporal constraints by familiar click-and-drag on the calendar view. The calendar display includes options to overlay the day/time preferences and free/busy availability of participants so far requested in the meeting. Options are dynamically depicted on the calendar display as the user examines them. The aim of constraint reasoning is to generate candidate schedule options that opti-mally satisfy the constraints elicited from the user, using the current preference model as the objective function (recall Figure 1). This reasoning must account for the con-straints and preferences in the scheduling problem, and both the current schedule and day/time preferences for all involved participants.

Two questions must be addressed: (1) how to represent the hard and soft temporal constraints in a form that translates into the criteria we have chosen; and (2) how to extend the temporal reasoning beyond the simple objective functions found in the literature to the more expressive Choquet integral.

Representation as MC-DTPP. Our approach is to model the reasoning problem with constraints as a Disjunctive Temporal Problem with Preferences (DTPP) [Peintner and Pollack 2004]. Each constraint in a DTPP defines a valued temporal relationship be-tween two or more variables, called timepoints . In keeping with its parent class of soft constraint satisfaction problems, a DTPP replaces the binary notion of  X  X llowed X  and  X  X ot allowed X  with a numeric degree of acceptability for each combination of assign-ments to the variables in the scope of a constraint.

Formally, a DTPP constraint C p is defined as a disjunction C p = c 1  X  c 2  X  X  X  X  X  c n where each component c q is a binary linear constraint between timepoints x q and y : c q = f q :( y q  X  x q )  X  A q ,inwhich f q is a preference function that maps any assignment of values of x q and y q to a real local preference value A q that reflects the utility of that assignment. Observe that, for the binary temporal constraints c q ,the degree of acceptability for each assignment is represented as a function that maps each possible temporal distance ( y q  X  x q ) to a scalar value. 5
Given an assignment S of values to the timepoints in a DTPP D , the local preference value of a disjunctive constraint C p within D is defined to be the maximum value achieved by any of its disjuncts where S (  X  ) denotes the value assigned to a variable in assignment S .

Using this mechanism, computing a local preference value for each constraint is straightforward given a complete assignment S . The remaining question is how to combine these local preference values into a single value that represents the util-ity of the complete assignment. In previous quantitative constraint-based temporal optimization work, objective functions have been based on simple aggregations of lo-cal preference values, including using the minimum or the sum of all values (e.g., Peintner and Pollack [2004]). These do not easily extend to represent the abstract criteria supported by preference model based on a Choquet integral.

Our approach is to map each constraint to a subset of the criteria, based on the rationale of each constraint. As examples, a soft constraint expressing a set of allowed durations maps to the duration criterion, and a constraint expressing that a person cannot attend two meetings at once maps to the overlap criterion. The mapping is one to many: a constraint can map to multiple criteria.

For a complete assignment S of all timepoints, we find the utility with respect to each criterion by summing the local preference values of all constraints mapped to that criterion. To normalize, we divide each computed utility by the sum of the maximum possible utility of the included constraints. That is, for a criterion i , and the constraints mapped to it, C j  X  C i :
The utilities (3) fit directly into the Choquet integral equation (1), substituting z i = u ( S ). Note that we proscribe the utility functions and their normalization for all users: we did not consider that the calendaring domain warranted enough variance between individuals in terms of the MAUT utility functions, to burden the user by employing a utility function elicitation process such as AHP or MACBETH [Bana e Costa and Vansnick 1999].
 Adding the mapping from constraints to criteria transforms the DTPP into a MultiCriteria DTPP (MC-DTPP) [Moffitt et al. 2006]. To optimally solve an MC-DTPP, a solution must be found that maximizes the value of the Choquet integral equation (1). The computational challenge motivates our choice of the 2-order Choquet integral, which captures at least one level of criteria interaction, but can be represented using the sum of only 1 2 n ( n + 1) terms. It also guides our choice of criteria: criteria such as stability and perturbation, mentioned earlier (Section 4.2), are functions of an entire schedule, and thus do not easily incorporate with the standard DTPP scheme of aggregating over local preference values.

Reasoning Algorithms for MC-DTPP. To enable PTIME to generate scheduling op-tions, we augmented a leading branch-and-bound DTPP approach [Moffitt and Pollack 2006] with special bounding logic and additional heuristics and employed it within the MultiCriteria Search framework [Le Hu  X  ed  X  e et al. 2006].
 We provide a high-level overview of our projected MC-DTPP reformulation and the MCS algorithm as pseudocode in Figure 4, and refer to Moffitt et al. [2006] for details. Function getStrategy () describes the variable and value ordering heuristics used for a particular criterion c . Function maximize ( u c , strategy) finds the maximal value of objective function u c for criterion c , using the given strategy. In our implementation, we choose to optimize the criterion that maximizes the difference between its upper bound and its value in the current solution, and the metavariables corresponding to the constraints in its scope are given higher priority in the variable ordering heuristic. Experiments with criteria selection heuristics showed that this heuristic resulted in the best performance.

We implemented the preceding scheme, using our metaspace search algorithm for the projected MC-DTPP reformulation as the mono-criterion search maximize (  X  ). Benchmark results for the personalized time management domain, described in Section 6.2 to follow, validated the approach. We also implemented a non-MCS branch-and-bound algorithm. The performance of the MCS variant described earlier slightly outperformed this second implementation. We leave the details of this comparison to Moffitt et al. [2006]. From the many solutions generated by constraint reasoning we want to present a subset (the candidate scheduling options) to the user. On one hand, the system must not overwhelm the user with too many options; on the other, it must present enough options so that the user can select one that is acceptable. In general, we want to present the most desirable solutions first (according to the elicited preference model instance). However, the model and any instantiation will generally be an imperfect approximation of the user X  X   X  X rue X  preferences. Moreover, a measure of diversity in the presented solutions can stimulate clarification of the problem and realization of preferences [Weber and Pollack 2007; Peintner et al. 2009].

While the elicited preferences provide a starting point for presenting solutions tai-lored to the user, an effective scheduling assistant should refine its preference model over time. To this end we employ machine learning techniques. Most previous work on recommendation technology involves information filtering [Adomavicius 2005] of the generation of independent items (e.g., Fiechter and Rogers [2000]). In contrast, PTIME generates meetings in response to meeting requests and adds these to a continually evolving schedule.

When learning a preference model as an evaluation function, a popular form due to its simplicity is the weighted linear sum [Brzozowski et al. 2006]. In our earlier work [Gervasio et al. 2005], we modeled user preferences as a weighted linear evalu-ation function over temporal schedule features (i.e., day/time preferences). Candidate scheduling options were represented as feature vectors and training examples con-sisted of the pairwise preferences implied by a user X  X  selection from among presented options. Given these pairwise preferences, we applied Support Vector Machine (SVM) learning techniques for ranking to adjust the weights of the evaluation function to better capture the user X  X  preferences [Joachims 2002]. By relying only on feedback ob-tained through the user X  X  natural interation with the system, we avoid a designated training phase prior to scheduling any meetings, a significant commitment few users would be willing to make [Peintner et al. 2009].
 Multicriteria schedule evaluation fundamentally changes the learning task. In PTIME, instead of boolean features representing temporal properties of a schedule, we have real-valued features representing the degree of satisfaction of higher-level crite-ria u i , each a function of lower-level schedule features. Moreover, because the function being learned is a 2-order Choquet integral rather than a linear weighted sum, the coefficients must obey a i  X  [0 , 1] and a ij  X  [  X  1 , 1], as mandated by the Choquet model.
However, observe that the 2-order Choquet integral can be viewed as a linear weighted sum of a new set of features (criteria) comprising affine combinations of the importance coefficients a i and interaction indices a ij . Thus, we can apply standard SVM learning techniques to learn the coefficients (weights) for the resulting trans-formed function, subject to the constraints on the values of the coefficients. Because the SVM learning problem is essentially a quadratic optimization problem, to ensure that the coefficients learned are valid Choquet coefficients, we could augment the quadratic programming problem with additional constraints. However, simple rescaling of the learned weights into the range [  X  1 , 1] is sufficient for satisfying the constraint on the interaction coefficients, and we found that the SVM learner naturally learns positive weights for the importance coefficients just from the training examples themselves. 6 Thus, in the end, no modification of the input to the SVM learning algorithm proved necessary.

Since both elicited and learned preferences have the same functional form, we use a simple weighting scheme to combine them into the refined evaluation function where solution vector z represents a schedule, A is the vector of coefficients (weights) for z representing the elicited preferences, and B are the learned weights for z . By varying  X  we can vary the relative influence that the initial and learned preferences have on the evaluation of a candidate schedule. By decaying  X  over time, we can dynamically modify this relative weighting to give more consideration to the learned weights with more training examples,
Our conversion of the Choquet model to a linear function over an expanded set of features (i.e., the affine combinations of the a i and the a ij ) ensures that we can continue to use a more easily interpretable linear kernel for the SVM. However, because the extended set of features does not preserve the connection between the importance coefficients a i and the interaction indices a ij (as just noted), there is no guarantee that the resulting learned function will be a well-formed Choquet integral However, the MC-DTPP solving algorithm discussed in the previous section does not rely on a valid Choquet form; it can accommodate a general MAUT objective function and can thus continue to use the learned model. To assess the value of our approach to the trade-offs between representation, reasoning, and learning, we designed experiments to answer the following questions: (1) how well does the preference model capture user preferences in the domain; (2) how well do users X  elicited preferences match their  X  X rue X  preferences; (3) does the constraint reasoner provide preferred solutions in an adequate amount of time; (4) does the preference learner improve the ability to suggest desirable solutions; and (5) how is the entire PTIME system perceived?
Evaluating a preference model in the context of an adaptive assistant in the cal-endaring domain presents particular challenges. First, the literature on preference elicitation makes it clear that the gold standard of the user X  X   X  X rue X  preferences is unattainable [Viappiani et al. 2006; Goldsmith and Junker 2009]. Even were individu-als to have a precise grasp of their scheduling preferences and be willing to share them, they are unlikely to be able to adequately articulate them. Second, decisions based on preferences in this domain are particularly context sensitive. An individual may dis-like early-morning meetings but will always accept them from his manager. Third, our desire for unobtrusive learning limits us to learning on data from users actually scheduling through PTIME. Finally, the ability to gather data to evaluate the prefer-ence model crucially hinges on engineering, usability, and deployment issues [Steinfeld et al. 2007; Peintner et al. 2009]. Any deficiency that hinders users from adopting the system sufficiently adversely impacts data collection and overall evaluation.
To answer our questions, we examined data from three separate studies. The first was a two-part user study involving preference elicitation with the interface described in Section 5.1 and a paper-based scheduling exercise. The study group involved eleven subjects (software engineers, managers, administrative staff, and researchers) from our organization. We asked them to interact with PTIME to elicit an instantiated model of their preferences. We then gave them a hypothetical two-week calendar of a knowledge worker, containing a moderate number of meetings, events, and deadlines, and asked them to schedule a series of 11 events. For each event, we asked each subject to rank 10 options, ties permitted. The primary aim of the study was to investigate the extent to which the elicited preferences correlated with actual ( X  X rue X ) preferences. The second study was aimed at evaluating the efficiency of the constraint reasoner. To gain a sense of how our reasoning algorithms scaled, we generated pseudo-random scheduling problems with increasing numbers of participants.

The last study was the final annual evaluation of the CALO system. This formal eval-uation involved 15 users performing a variety of office-related tasks on their computers, including scheduling meetings. The subjects were encouraged, although not required, to schedule meetings over a four-week period, varying the number of participants, asso-ciated projects, whether it was personal or work, and so on. Subjects scheduled from 12 to 52 meetings each (median: 22); the corresponding logs provided data for evaluating the learning in situ. At the end of the evaluation period, the subjects were asked to fill in a questionnaire regarding their experience with PTIME; follow-up semistructured interviews were conducted. This provided data for evaluating the system as a whole. We used the first user study to answer our first two questions regarding the expres-siveness of the preference model and the adequacy of the elicitation of the model and meeting requests. To quantify the degree of similarity between the elicited and the ac-tual preferences, we computed the Spearman X  X  correlation coefficient [Hogg and Craig 1995] between the rankings provided by the subjects and the rankings induced by the elicited models (  X   X  [  X  1 , 1], with  X  = 1 . 0 indicating identical rankings,  X &gt; 0 indicating positive correlation,  X &lt; 0 negative correlation). This measures how well the elicited model instance approximates the subjects X  actual preferences.

The results, shown in Figure 5, exhibit a weak correlation between the rankings by the subjects and by the models (mean of  X  across subjects and requests = 0 . 26,  X  = 0 . 32). Although the variance between subjects is substantial (mean  X  value across the subjects, averaged over the requests, varies from 0 . 08 to 0 . 42), the situations involving delicate trade-offs between time and participants, such as Request 6, show stronger correlation.

In free-form interviews after the study, subjects expressed satisfaction over the fea-tures in the preference model. These discussions emphasized subjects X  difficulty in understanding of their preferences. Several subjects reported that the process of rank-ing options helped them realize their own scheduling preferences, in particular over the trade-offs between different criteria. This suggests a potential gap between elicited and actual preferences should be expected; example-based methods may be helpful for deeper elicitation.

A more detailed examination of the results indicates that model expressiveness is lacking only in cases outside of the scope of PTIME [Berry et al. 2007]. Our results on the quality of the elicited model point to several causal factors: (1) inadequacies in the elicitation, (2) lack of users X  awareness of their preferences, or (3) inconsistencies in user scheduling decisions. Together, these point to an opportunity for revising the initial model by learning, supporting our overall paradigm. The preference model and constraint reasoning algorithms for systems like PTIME that perform interactive scheduling must support the generation of desirable solutions within a reasonable amount of time. The candidate set must not only be preferred, it must also be diverse. Individuals often prefer to see alternatives [Weber and Pollack 2007] and options can stimulate clarification of the problem and realization of pref-erences [Peintner et al. 2009]. Moreover, often there is not a single unique optimal solution but rather a set of equally good preference-maximizing solutions, an effect amplified with multiple criteria.

The number of solutions presented P must be large enough to include good solutions even before any learning. We chose P = 35, although subsequent experience revealed that the initial model instances performed well enough that P = 15 would have been sufficient.

The search space of the MC-DTPP soft constraint optimization problem that the constraint reasoner solves is exponential in the number of participants and existing events, and linear in the number of locations and the time range considered, that is,
We constructed randomized, structured scheduling instances by populating the cal-endars of ten users with four meetings of varying proximity to each other each within a two-day period. We then randomly chose a time window within that two-day period and a subset of those participants and recorded the time required for the reasoner to generate the top 35 solutions ranked by the preference model. We took the most demanding case for optimization, when the full temporal preference profile of each participant is known. We focused on a single round of schedule generation; negotiation was not permitted.

Benchmarking experiments revealed that for randomly sampled scheduling prob-lems involving four participants and four meetings per user over a two-day time period, the average time to find the top 35 solutions is 0.4 seconds. 7 Increasing the number of participants to six and ten raises the average times to 4.3 seconds and 14.4 seconds, re-spectively. As the problem size increases, the time to find the top P solutions increases markedly. However, our MC-DTPP algorithm still finds high-quality solutions for the largest problems we encounter (10 users, 20 meetings per user). The CALO evalua-tion participants reported satisfaction with the quality and diversity of the solutions presented by PTIME. From the logs of the CALO evaluation we extracted for each subject the following infor-mation for each of the meetings scheduled: the meeting request, the options generated, the options presented, the ranking of the options by the current preference model in-stance, the ratings of options by the user (if any), and the option selected (at most one). 8
We hypothesized that with more learning, the rank of the selected option would converge to the top rank (i.e., 1). The results showed a small but gradual improvement in the rank of the selected option. We also measured the number of times the subjects X  selected option was in the top three. With more learning, the selected option occurs in the top three more frequently (Figure 6, averaged across the 15 subjects, R 2 = 0 . 167).
These results reinforce the value of presenting multiple solutions and PTIME X  X  abil-ity to generate better candidate sets through learning.

While encouraging, these results are not dramatic. However, it is worth bearing in mind that, while the CALO evaluation period was designed to be realistic, it neverthe-less required subjects to invent events for a fake calendar. The majority of the meetings turned out to involve little discriminative opportunity for learning: they were bereft of over-constrained situations. For nearly 65% of the scheduling instances over all the subjects, the constraint reasoner was able to generate at least ten options that did not violate any constraints. Such under-constrained scheduling problems do not require users to consider any trade-offs, thus providing the system with little information as training instances for learning a user X  X  preferences.
Perhaps more important, note we are measuring not against a naive default (e.g., a random ranking, or even a ranking derived from the default uninformed Choquet model instantiation), but against the preference model instance derived from the ini-tial elicitation. To assess the quality of the elicited preference models in the CALO evaluation, we leveraged the optional feedback provided by some subjects. Users could indicate, on a scale of 1 X 4 stars, the desirability of an option. Most subjects provided ratings on very few options (if any), and often for only a small subset of the presented candidate options. Although we cannot draw any general conclusions regarding the average quality of the initial elicited model from this data, some subjects provided enough ratings to provide some insight into this issue.
 The ratings provide finer-grained feedback regarding the options presented by PTIME. For each scheduling instance, for each of the four ratings, we average the rankings of any options given this rating. What we would like to see are the more preferred options (more stars) higher in the rankings than the less preferred ones (fewer stars). Figure 7 shows the plot for one subject; it is representative of the oth-ers. We see that the initial (elicited) model instance for this subject is already quite good, with the more-preferred options ranked higher than the less-preferred ones even prior to learning. The separation between the differently rated options increases with more learning, indicating that the preference learner improves at making distinctions between the more preferred and the less preferred options. To assess the perceived value of the overall PTIME system, we presented subjects in the CALO evaluation with postevaluation questionnaires and conducted semistruc-tured interviews. We aimed to gather subjective opinions of usefulness, usability, and performance (based on standard measures [Van Schaik and Jing 2005]); elicit the ex-tent to which the concept of a system like PTIME could meet user needs; and determine how well understood and trusted the system was.

Figure 8 presents a subset of the results, depicting subjects X  responses to statements on a 5-point Likert scale ([  X  2 , 2]) [Meyers et al. 2005]. By a one-sided t-test against the null hypothesis of indifference to each statement (i.e., mean = 0), we found that subjects express extremely significant agreement ( p &lt; 0 . 001) with the statements  X  X  tool like PTIME could help me in arranging events X  (mean 1 . 33),  X  X TIME allows me to express my meeting requests X  (mean 1 . 10), and  X  X TIME could fit into my way of managing my calendar X  (mean 0 . 762). Agreement with  X  X TIME soon learned my scheduling preferences X  is found highly significant (mean 0 . 917, p &lt; 0 . 01, reduced sample size since not all subjects responded to the question). Agreement with  X  X he interface of PTIME is intuitive X  could be significant (mean 0 . 429, p &lt; 0 . 05).
In interviews, subjects expressed a liking for the expressiveness and intuitiveness of the natural language (when it worked well), for seeing the preferences and availability of other individuals, and for getting others X  opinions. Subjects expressed dislike of the speed and stability of the prototype system, and dislike of the NL (when it did not work as they desired). Across each of the set of calendaring needs identified in our first user study (Section 4.1), subjects expressed highly significant opinion that PTIME would  X  X ake it easier. X  Subjects expressed highly significant opinion in favor of PTIME X  X  hybrid problem elicitation interface. PTIME was perceived as increasing task effectiveness in terms of both speed and quality. We have described an integrated AI prototype system, PTIME , that provides semi-automated scheduling assistance. Our work encompasses expressively modeling user preferences and eliciting an approximation of them, continually refining the preference model through unobtrusive, online learning, and reasoning over the preference model to generate and present preferred schedule options. The technical challenge addressed is to adequately capture an individual X  X  scheduling preferences in a model and then exploit it in a tractable way to provide scheduling assistance. Evaluation of the PTIME system found user satisfaction with the concept and a perceived increase in task effec-tiveness in terms of both speed and quality. The PTIME system has been deployed for testing purposes with nontechnical volunteer users within our organization.
Opportunities for future work manifest in preference modeling, machine learning, and user interaction. First, PTIME X  X  preference model is founded on aggregation through a second-order Choquet form, which can be seen as a form of the Generalized Additive Independence (GAI) model [Fishburn 1967; Dubus et al. 2009]. We would like to explore learning and reasoning over a GAI model in the PTIME context. In addition, our earlier studies made use of example-driven elicitation, which we would like to blend with model-driven elicitation. Second, we would like to explore the scope of machine learning to acquire user preferences regarding event importances and the importance of participants to an event, and also the possibility of automatically accepting or rejecting a meeting request (subject to adjustable autonomy settings). Third, we are motivated to explore richer, user-intelligible explanation of the learned preference model, in order to foster user trust in system operation [Glass et al. 2008]. Fourth, we are considering more elaborate forms of negotiation as part of a full deployment of the PTIME system.
