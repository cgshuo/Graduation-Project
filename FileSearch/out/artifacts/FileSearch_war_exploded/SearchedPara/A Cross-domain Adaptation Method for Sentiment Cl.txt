 Sentiment classification is becoming attractive in recent years because of its potential commerci al applications. It exploits supervised learning methods to learn the classifiers from the annotated training documents. The challenge in sentiment classification is in that the sentiment domains are diverse, heterogeneous and fast-growing. The classifiers trained on one domain (source domain) could not classify a document from another domain (target domain). Moreover, it is impractical to prepare training samples for the coming domain. To make use of unlabeled samples in the target domain and labeled ones in the source domain, domain adaptation is a suitable technology. This paper will present a cross-domain topic indexing (CDTI) method so that a common semantic space is found from the prior between-domain term correspondences and the term co-occurrences in the cross-domain documents. These observations are characterized with the mixture model in CDTI, each component being a possible topic and being shared by the source and target domains. Thus the common topics are found to index the cross-domain content. Our contributions include 1) a probabilistic framework is presented to model the between-domain statistics; 2) EM based algorithm is presented to learn the topic model; and 3) the inference algorithm is presented to obtain the topic distribution for a specific (source or target) document. Our evaluation on the multi-domain sentiment classification shows that CDTI outperforms the state-of-art domain adaptation method, i.e. spectral feature alignment (SFA), and the traditional latent semantic indexing method. H.3.3 [ Information Search and Retrieval ]: Clustering; I.2.6 [Learning]: Concept learning ; I.2.7 [Natural Language Processing]: Text analysis Algorithms, Experimentation Domain adaptation, Latent topic analysis, Sentiment classification, Opinion mining In the virtual world of the web, we are seeing that growing people utilize the platform to freely express their feelings or write their opinions on anything that happens. This results in a huge volume of user generated content (UGC) such as blogs, user reviews, etc. In the paper, we are interesting in the UGC which carries the user X  X  sentiment such as positive or negative opinion on the object. The sentiment UGC is widely scattered in the webs. For example, the Amazon web site 1 hosts a lot of user reviews on the products. The reviews may express the user experiences on a product, the facets which the users like or dislike, and have a scale to measure the overall user likeness while in the IMDB site 2 , the users post their comments on the movies. Most of the reviews are long and contain the detailed expressiveness. In contrary, the user X  X  comments in the twitter 3 are often short but are inst ant and dynamic. In a word, UGC data are diverse, hete rogeneous and fast-growing. The UGC data are informative and useful in improving the business decision. They provide large-scale instant and up-to-date user X  X  experiences on the products. However, it seems impossible to let the human reading and digesting the opinions because of their dynamic and huge size. We need a tool to digest the user opinions through automatically analyzing the reviews. Classifying a review as positive or negative is just a binary classification problem. However, the unique challenges are faced in UGC data. In recent years, sentiment classification is becoming attractive. Many researchers, who are from the different areas such as natural language processing, data mining and information retrieval, work together to address the issues in sentiment analysis, classification and summary [3, 4, 8, 9, 14]. One of challenges is how to learn a good classifier for the target domain in case of only unlabelled documents available. If the source domain is similar to the target domain, i.e. the term usages in two domains are similar, the classifier in the source domain (source classifier) may work well in the target domain (target classifier). However, in most scenarios, the target domain is quite different from the source domain in many facets. Firstly, the topic in two domains may be different, e.g. one about the new launching iPad and another about a book. Secondly, the written languages may be different, one written in Chinese and another in English. Finally, the term usages are different. As an example, we select the two domains book and dvd from the multi-domain dataset used in our experiment explanation. The reviews in the former frequently use the term book, reading, author, chapter, etc., while the latter frequently use the terms dvd, watch, film, scenes , etc. Although the differences exist in the cross-domain, there are still a few cross-domain relations to be exploited to bridge them together. In the above mentioned domains, i.e. book and dvd , some terms are http://www.amazon.com/ http://www.imdb.com/ http://twitter.com/ Data from http://www.cs.jhu.edu/~mdredze/datasets/sentiment/ observed in both domains, e.g. action, American, about , etc. These terms, which are named as pivot features in [6, 8], are the clues which can be used to link the two domains. In cases of documents in the domains written in different languages, the pivot features will be extracted from the translation dictionary [20]. The pivot features are the prior knowledge of the between-domain correspondence. The pivot features divide the terms in each domain into two sets, i.e. one set including domain-independent terms (i.e. pivot features) and the other including domain-specific terms. In order to extract the cross-domain common feature space, we need to extract the cross-domain pair-wise term occurrences from the source and target domains. However, the cross-domain evidences are not obvious like the term occurrences in a single document because the documents in the source and target domain are collected independently and it lacks the pa ir-wise relation between a source document and a target document. One possible way is to propagate the relation through the pivot features such as in [8]. For example, if a source domain-specific term  X   X  co-occurs with a pivot feature  X  , which further co-occurs with a target domain-specific term  X  thus there will be a relation between the two domain-specific terms  X  and  X   X  . From the cross-domain document pair, i.e. a pair of source document and target document, the co-occurrence of a pair of the source-domain term and the target-domain term could be extracted with the help of pivot features. In the recent state-of-art methods on domain adaptation, the observed evidences are often modeled using the bipartite graph and the common space is solved using spectral clustering algorithm [8, 13, 17]. For example, in the recent work of spectral feature alignment (SFA) [8], the bipartite term graph is built from the pair-wise term co-occurrences (i.e. the pair of domain-independent term and domain-specific term). Then the spectral clustering algorithm [18] is exploited to extract the low-dimensional eigen-space. Thus the source-domain document will be represented in the eigen-space. So does the target-domain document. However, if we need to analyze the latent topics in the cross-domain, the clustering algorithms (e.g. K-means) must be run on the documents in both domains, which are represented in the eigen-space. In order to get the topics, two steps are needed. More importantly, when building the bipartite graph, the term co-occurrence is counted at the corpus level without considering the document identities. Therefore, it has no capability to explain how the topics are distributed in a specific document. In the paper, we will present a cross-domain topic indexing (CDTI) method so that the topics are the natural output of learning stage and the topic distribution in a specific document from the source or target domain can be inferred. Rather than modeling corpus-level co-occurrence of the term pair, CDTI uses the mixture model to characterize the source-target pair-wise term occurrences from the specific source-target document pair. The component in the model, i.e. topic model, explains the source-target term pair distribution in a topic,  X   X   X   X   X ,  X  |  X   X  . The topic models are latent in CDTI. In order to estimate them, the EM algorithm is presented. As the topic models are known, the topic distribution for a new document can be inferred whether it is from the source domain or the target domain. The detailed algorithms for learning and inference will be discussed in Section 2. The topic distribution will be used as indexing the document content. Because the source domain and target domain are represented in the same topic space, we expect the source classifier could work better compared with the source classifier trained in the original document feature space. It will be elaborated in the experiments reported in Section 4. CDTI is a novel probabilistic mode l for estimating latent topics from the cross-domain. It works on the cross-domain rather than single domain such as traditional probabilistic latent semantic analysis (PLSA) [15] and latent Dirichlet allocation (LDA) [5]. It characterizes the source-target pair-wise term statistics rather than the term statistics. In particular, its inference algorithm is quite unique in that it needs to integr ate out the source term variables when estimating the document topic distribution for the target domain and vice versa when estimating the topic for the source domain. Our contributions include:  X  Presenting a generative framework to model the cross-domain  X  Presenting the EM based algorithm to learn the topic models  X  Presenting the novel inference algorithm to extract the topic In the next section, we will introduce the problem of cross-domain topic analysis and present the CDTI models. In Section 3, a short discussion is introduced for cross-domain sentiment classification. We report our experiments on the multi-domain sentiment corpus in Section 4. Finally, we will summarize our findings. In cross-domain topic analysis, we need to model the co-occurrence among the source domain term, the target domain term, the source domain document identity, and the target domain document identity. The relation among four variables, i.e. 4-VAR , is more complex than the single domain topic analysis, where there are only two variables, i.e. term and document identity. In the section, we will discuss all issues faced in CDTI. Firstly, we will formulate the CDTI problem. Then we will elaborate the training and inference algorithm s for CDTI. Finally, we will discuss some practical methods to extract 4-VAR co-occurrences. Assume we have two domains, saying source domain  X   X  and target domain  X   X  . The corresponding term and dictionary are denoted document pair  X   X   X   X ,  X   X  , we have a set of pair-wise term observations  X   X   X   X ,  X   X  from the document pair. The 4-VAR co- X   X  .  X  . So the CDTI will solve the following two problems: A) Learning latent topic model : Given the corpus  X  topic (or cluster),  X  , which is characterized by  X   X   X  cross-domain pair-wise term distribution conditioned on the topic, and the topic distribution in the cross-domain corpus,  X   X   X   X  . B) Inferring a topic distribution to represent the document a topic distribution,  X   X   X  |  X   X  for a document  X  . The cross-domain term occurrence  X  is modeled as,  X  is the number of topics and each component P  X   X  possible topic model. Obviously Eq.(1) is a generative model. Thus the likelihood function on the observation collection  X  is formulated as,  X  X   X  X  X   X   X  .  X   X  X  X  X   X   X   X   X ,  X   X ,  X   X ,  X   X   X  Here  X   X  .  X  is the known 4-VAR observation.  X   X   X   X   X , are the unknown model parameters.  X   X   X   X   X ,  X  |  X   X  is the unknown component relating to the topic for a source-target document pair. The unknown parameters can be solved through maximizing the likelihood function in Eq. (2). In practice, it is not so easily solved because of the sum operation in the log-function. Of course, we could use the gradient method to find the solution. But it is impractical and inefficient considering the sizes of the corpus and dictionary. Here we exploit the variational approach [10] to find the solution. We introduce an auxiliary component,  X   X   X  |  X  (Abbreviation is  X . X  X  without confusion) to approximate the topic distribution conditioned on the source-target term pair  X   X  Jensen X  X  inequality and replacing the auxiliary function into Eq. (2), the following function is obtained, We thus get the objective function,  X  , for estimating CDTI model.  X  X   X  X  X   X   X  .  X  X  X   X   X   X  .  X   X  X  X  X   X   X   X   X ,  X  |  X   X   X   X   X   X   X , Obviously, the upper bound in Eq. (4) is equal to the likelihood function Eq. (2). In order to estimate all unknown parameters, we develop an EM algorithm to iteratively update the model parameters and auxiliary parameters by maximizing Eq. (4). E-step:  X   X  .  X  is estimated while fixing  X   X   X   X   X ,  X  |  X   X  ,  X   X   X  . Eq. (4) is thus a function of  X   X  .  X  . Using the Lagrange multiplier It thus results in the function  X   X  (See Eq. (6)).  X   X   X   X   X ,  X   X ,  X   X ,  X   X  is the Lagrange multiplier. The derivative of  X   X  regarding to  X   X   X  |  X   X   X ,  X   X ,  X  Letting Eq.(7) equal to zero, we can obtain  X   X  .  X  as, M-step: Fixing  X   X  .  X  estimated in E-step, we then estimate  X   X   X   X   X   X   X   X ,  X  |  X   X  and  X   X   X   X  . Now we have constraints as, Using the similar method as E-step, we get the parameters as,  X   X   X   X   X ,  X  |  X   X   X  X   X   X   X   X   X   X   X   X ,  X   X ,  X   X ,  X   X   X   X   X  |  X   X   X   X   X   X ,  X  |  X   X   X  X   X   X   X   X   X   X   X   X ,  X   X ,  X   X ,  X   X   X   X   X  |  X   X   X   X   X   X  X   X   X   X  X  X   X   X   X   X   X ,  X   X ,  X   X ,  X   X   X   X   X  |  X   X   X ,  X   X  ,  X   X  and  X   X  are the normalization constants. Figure 1 summarizes the above training procedure. 
Input : source domain documents,  X   X  , target domain document, Output : model parameters  X   X   X   X   X ,  X  |  X   X  ,  X   X   X   X 
Procedure of learning CDPLA: 1. Initialize model parameters,  X   X   X   X   X ,  X  |  X   X  ,  X   X   X  2. E-step: update  X   X  .  X  using Eqs. (8-9). 3. M-step: update model parameters using Eqs. (11-13) 4. Check whether the stop criterion is satisfied. If no, go to If we only look the above equations and learning procedure, CDTI looks similar to PLSA. But their differences are obvious. PLSA only models term-document pair in single domain. In contrary, CDTI operates on the cross-domain and models 4-VAR observation. Because there are more dependencies introduced in CDTI, we will see more flexibility in implementing CDTI. For example, we can relax some dependency to get a simpler model. In sub-section 2.4, some possible implementations are discussed. More interestingly, although the topic model in CDTI represents the source-target term pair distri bution, we could infer the topic distribution for a document coming from single domain by integrating out some parameters (See section 2.3)). The inference problem in cross-domain topic analysis is defined as, Given any target document (or source document)  X   X  source domain training documents  X   X  (or target domain training documents  X   X  ), infer a topic distribution,  X   X   X  |  X   X  From the definition, the inference in CDTI is quite different from the traditional latent topic analysis such as PLSA. In CDTI, we need to re-use the training documents. The reason is in that CDTI needs 4-VAR co-occurrence in inference. For example, when inferring a topic distribution fo r a target domain document, the source domain training documents are needed to extract the 4-VAR co-occurrences. In contrary, the target domain training documents are needed when inferring a topic distribution for a source domain document. As an example, we begin to discuss the inference algorithm for a document coming from the target domain. Clearly, the proposed algorithm is also suitable for the source domain documents. The objective function in inference is defined in Eq. (14), Its difference from Eq. (4) is in that the model parameters  X   X   X   X   X ,  X  |  X   X  are fixed in inference. In Eq. (14), the interesting term is  X   X   X , X   X   X ,  X   X  , which can be learned using the algorithm illustrated in Figure 1. Then the topic distribution is obtained through summing out the uninteresting variable  X   X  , i.e., Eq.(15) is just the topic distribution for the target document. Likewise, the topic distribution for the source document is, The embedding relation in the above inference discriminates CDTI from the existing latent topic analysis methods. In the above discussions, all possible dependencies are considered. It thus results in the high cost of computation and storage and the risk of over-training. Now 4 versions are discussed by relaxing some conditions. Version A: Dependent CDTI (Dep_CDTI) In the version, the source and target terms are dependent. So do the source and target documents. It is discussed in the above. Version B: Term independent CDTI (Tind_ CDTI) In the version, the source and target terms are independent, but the source and target documents are dependent, i.e. Version C: Document independent CDTI (Dind_ CDTI) In the version, the source and target documents are independent. But the source and target term are dependent, i.e., Version D: Both term and document independent CDTI (TDind_ CDTI) In the version, the source and target terms are independent. So do the source document and target document. In the version, both Eq.(17) and Eq.(18) are satisfied. In the section, we discuss a practical way to extract the 4-VAR features from the cross-domain documents. The first step is to link the source domain documents with their paired target domain documents. In the scenario of the paper, we study the text sentiment classification written in the same language. The dictionary in the source domain should have some words which also occur in the target domain. These words are our pivot features [6, 8]. The pivot features are used to bridge the two domains. Excluding the pivot features, each domain also has a set of domain-specific words. The pivot features, the source domain specific features and the target domain specific features are denoted as  X   X  X  X  ,  X   X  X  X  X  and  X   X  X  X  X  respectively. For a pair-wise source domain document  X   X  with its term  X  target domain document  X   X  with its term  X  observation  X   X   X   X   X ,  X   X ,  X ,  X   X   X  is defined as, where  X   X  .  X  measures the association degree between the source domain term and the target domain term and  X   X  .  X  measures the relevance degree between two documents. The definition is flexible and the particular formulation will be based on the prior knowledge and preliminary experiments. One possible way adopted in our experiments is given in Eqs. (20-21). In our experiments, we evaluate the indexing power of CDTI for cross-domain sentiment classification. Thus we give a short introduction on sentiment classificati on. It is a task of predicting the polarity (positive or negative) of a text document, a binary classification problem. There are a lot of papers in the topic. A needed, where a text document is tagged with the positive or negative label. After that, the classifiers such as SVM from the training documents. Finally, the learned classifier is used on a document to predict whether it is positive or negative. In the paper, we are interesting in domain adaptation, a problem of predicting the positive or negative opinion for a target document using the classifier trained on the source domain documents. Due to the domain mismatch, the source classifier will work worse in the target domain. Many techniques are proposed to adapt the source domain classifier into the target domain. For example, SFA [8] is a method to map the source domain document and target domain document in a shared low-dimensional feature space. Then the source linear SVM is trained on the space, which is used to classify the target document. In the section, we will evaluate the proposed CDTI method in the task of sentiment classification. The corpus is the multi-domain sentiment data set, which is used in [6] for studying domain adaptation. Recently it is used by many researchers to evaluate domain adaptation algorithms such as in [8]. The data set contains the product reviews in the Amazon site. Each product is treated as one domain. There are 25 domains in the set, of which four domains, i.e. books (B), dvds (D), electronics (E), and kitchen appliances (K) , are often used [6, 8]. Following the previous work, the four domains are also chosen in the paper. Thus 12 cross-domain sentiment classification tasks are built, letter means the source domain and the second letter means the target domain. We randomly select 100 documents in each domain in our evaluation. The 100 documents are then randomly split into two parts: the training set and testing set. The training set is used to learn CDTI model and to train the classifier. The testing set is used to evaluate the performance. The prior work in other resear chers proved that linear SVM achieved competitive performance in a lot of classification task. It is thus used here 5 . To avoid tuning the SVM configurations, we train a set of SVM classifiers using the costs selected in the range [0.00001, 1000000] 6 and evaluate the classification accuracy in the test set for each trained model. Then the best accuracy that can be achieved is reported. So the reported classification accuracy is the upper bound of accuracy that can be obtained by the linear SVM. We use LIBSVM, http://www.cs ie.ntu.edu.tw/~cjlin/libsvm The accurate cost in each SVM training is calculated as:  X  X  X  X  X  10 X 0.00001  X   X 0 X , The training samples in CDTI include: 1) a labeled training set in the source domain and 2) an unlabeled training set in the target domain (See sub-section 4.1 for data detail). Based on the training documents, the cross-domain latent topic models are learned. Then the topic distributions are inferred for the labeled training set in the source domain and the testing set in the target domain. The SVM, being trained on the source domain training set, is used to predict the polarity of the documents in the target domain testing set. In the paper, we will study the relation between the classification accuracy and the following factors: 1) the implementation versions of CDTI and 2) the size of topics. Then we will evaluate the indexing capability of CDTI. As the comparison, we will build two baseline systems. The first is PLSA based system and the second is spectral feature alignment (SFA) based system [8]. In addition, we train a gold baseline for each domain, where the classifier is trained on the labeled training set of the target domain. In section 2, 4 implementations are discussed. Now we study how the implementation affects on the classification accuracy. The size of topics is 2. The maximal numbe r of cycles is 40. The training set has 30 randomly selected documents from 100 documents and the testing documents are the left 70 ones. The classification accuracy is shown in Table 1. We observe that the TDind_CDTI achieves the average classification accuracy, 55.23%. It performs best among the four. However, the difference is not significant in terms of t-test at the 95% confidence level. Compared with the others, TDind_CDTI needs less computation. So we will use TDind_CDTI to study the property of CDTI hereafter. Table 1. Classification accuracy (%) on 12 tasks for 4 versions of CDTI (TDind is abbreviation of TDind_ CDTI. Similarly for others, Tind, Dind, Dep) Now we study the relation between the topic size and the accuracy based on TDind_CDTI. We split 100 documents in each domain into 50 documents in training set and the left 50 document in the testing set. The topic size is varied from 2 to 8 with a step 2. The average accuracies on 12 tasks are reported in Figure 2. They clearly show that the accuracy is increasing significantly with the increasing size of topics. For example, the accuracy is 57% in case of 2 topics. However, at the 8 topics, it reaches 62.17%. Now we compare the CDTI based system with 2 baselines: one PLSA based system [15] and the other SFA based system [8]. The PLSA is the representative of traditional latent topic analysis in one domain. With comparing with PLSA, we can see how much benefit is achieved by modeling cross-domain relation in CDTI. SFA is the up-to-date feature space based domain adaptation method. It is closer to our method. As a fair comparison, the topic sizes for TDind_CDTI, PLSA and SFA are set to 8. We do not try to optimize it. But based on our preliminary experiments, we find that 8 topics are suitable for our small training documents. For PLSA, we observe the accuracy is becoming worse when the topic size is larger than 8. 
Figure 2. Average accuracy (%) over 12 tasks in selected topic size for TDind_CDTI (X-axis: topic size. Y-axis: accuracy) TDind_CDTI and PLSA (X-axis: the task. Y-axis: accuracy) The accuracies on 12 tasks for PLSA and TDind_CDTI are illustrated in Figure 3. We find that TDind_CDTI significantly outperforms the PLSA method in all tasks except one task K  X  D (In the task, PSAL and CDTI have equal accuracy.). TDind_CDTI achieves the average classification accuracy 62.16%. In comparison, the PLSA system only gets 53.50% accuracy. The improvement is significant in term of t-test at the 95% confidence level. For a few domain adaptation tasks, the improvement is significant. For example, in the task B-&gt;D, the TDind_CDTI increases the accuracy from 48% to 70%, which obtains the 46% relative improvement. The results indicate that although both methods use the same data in learning latent topic model, TDind_CDTI can learn a much better topic space than PLSA from the cross-domain. This proves that incorporating cross-domain correspondence into topic learning can efficiently learn the topic space, in which the discrimination between the source domain document and the target domain document is reduced. It thus makes the source classifier work better in the target domain. The success of SFA on domain adaptation is proved in [8]. It shares some common properties with CDTI, such as modeling the pair-wise term co-occurrence between the pivot feature and the domain-specific feature and mapping the original feature into the low-level semantic space. However, the difference is prominent. CDTI models the document level co-occurrence rather than the corpus level. Thus, the document relation is embedded in the model. It is ignored in SFA. More importantly, CDTI generates a probability model and has a clear explanation for the words distribution in a topic. The SFA method achieves the average accuracy 60.16%. As a comparison, TDind_CDTI achieves the higher accuracy 62.16%, which are comparative. The accuracies on 12 tasks are shown in Figure 4. It is observed that TDind_CDTI performs better than SFA in 7 out of 12 tasks. In some tasks, CDTI significantly outperforms the SFA method. For example, in the task K-&gt;B, the CDTI has accuracy 62% compared to 42% in SFA method. Overall we see that CDTI provide a robust performance. 
Figure 4. Comparison of classi fication accuracy (%) on each task between TDind_CDTI and SFA (X-axis: the cross-domain The accuracies on 12 tasks are shown in Figure 5 for CDTI and the gold baseline. The gold baseline has the average accuracy 66%, which is better than 62.16% for TDind_CDTI. In some tasks, our TDind_CDTI system is even better than the gold baseline. For example, in the task B-&gt;D, TDind_CDTI has the accuracy 70% verse 64% for the gold baseline. Among 12 tasks, we still observe that TDind_CDTI works better in 4 tasks (B-&gt;D, D-&gt;E, D-&gt;K, E-&gt;K). Our further significant test shows that their performance difference is not significant. In the paper, we have proposed cross-domain topic indexing (CDTI) method in order to find the common topic space to facilitate knowledge transfer. We have elaborated the learning algorithm and inference algorithm so that the topic model can be learned from the training documents and the new document can be analyzed to obtain the topic distribution. We have evaluated the proposed models on the multi-domain sentiment dataset and demonstrated its capability to index cross-domain document content. Our experimental results on cross-domain sentiment classification prove that the proposed CDTI outperforms PLSA in terms of index power in cross-domain and is competitive to the state-of-art feature space based adaptation method. [1] A. Argyriou, T. Evgenio and M. Pontil, Multi-task feature [2] B. Chen, W. Lam, I. W. Tsang and T.-L. Wong. Extracting [3] B. Pang and L. Lee. Opinion mining and sentiment analysis. [4] B. Pang, L. Lee and S. Vaithyanathan. Thumbs up? Sentiment [5] D. M. Blei, A.Y. Ng and M. I. Jordan. Latent Dirichlet [6] J. Blitzer, R. McDonald and F. Pereira. Domain adaptation [7] J. Jiang and C. X. Zhai. Instance weighting for domain [8] J.L. Pan, X.C. Ni, J.T. Sun, Q. Yang and Z. Chen. Cross-[9] M. Hu and B. Liu. Mining and summarizing customer review. [10] M.J. Beal. Variational algorithms for approximate Bayesian [11] R. K. Ando and T. Zhang. A Framework for learning [12] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE [13] S. Xie, W. Fan, J. Peng, O. Verscheure and J. Ren. Latent [14] T. Li, V. Sindhwani, C. Di ng and Y. Zhang. Knowledge [15] Thomas Hofmann. Probabilistic Latent Semantic Indexing. In [16] W. Dai, G. R. Xue, Q. Yang and Y. Yu. Co-clustering based [17] W. Da i, O. Jin, G. R. Xue, Q. Yang and Y. Yu. Eigentransfer: [18] H. Y. Zha, Chris Ding, M. Gu, X. F. He and H. Simon. [19] Chih-Chung Chang and Chih-Jen Lin, LIBSVM : a library for [20] J. C. Platt, K. Toutanova, W. T. Yih. Translingual Document 
