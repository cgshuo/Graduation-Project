 Cross language information retrieval methods are used to determine which segments of Arabic language documents match name-based English queries. We investigate and con-trast a word-based translation model with a character-based transliteration model in order to handle spelling variation and previously unseen names. We measure performance by making a novel use of the training data from the 2007 ACE Entity Translation task.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]:Retrieval Models General Terms: Algorithms, Languages
Suddenly newsworthy names pose a challenge to cross lan-guage information retrieval systems that search machine-translated documents. Extensive spelling variation in names, especially those transliterated from a foreign language may render such names out-of-vocabulary for the machine trans-lation component of the system. Relevant documents may be located by queries such as ( X  X adagascar president X ) but with crucial key words ( X  X arc Ravalomanana X ) mistrans-lated. Locating a query name within a given target docu-ment is a valuable component, and may be used as a preci-sion enhancing mechanism, for snippet selection and high-lighting search results, and for enforcing boolean constraints. Locating a name within a document is also a natural com-ponent of systems that focus on complex information needs, such as ( X  X ind statements by &lt; PERSON &gt; on &lt; TOPIC &gt; . X ) In this paper we explore the task of finding the segments of an Arabic document that contain a given English name. A widely available corpus serves as a testbed to compare sim-ple algorithms for cross-language name matching,
The corpus developed for the 2007 ACE Entity Transla-tion task [4] annotates, in English, the names that are found in Arabic documents. 1 The name X  X  presence is annotated for each document segment (a  X  X egment, X  is a sentence-like unit
The task required participants to produce English transla-tions of the names in a given Arabic document. Instead we treat the name as a query.
 Figure 1: P fa vs. P miss for normalized and unnor-malized scores. that may reasonably be translated as a single sentence.) We adapt the corpus to name matching by formulating it as an information retrieval task: the English translations of the names are the queries; the given Arabic document is the  X  X orpus X  and our goal is to locate the segments of the doc-ument that mention the name. The corpus contains 852 named ORGANIZATIONS (452 of which are unique) and 1241 named PERSONS (746 of which are unique.) Nomi-nal and pronominal mentions are ignored. A limitation of the data is that entities do not perfectly align even at the segment level [4] : &gt; 10% of errors are unavoidable.
Although name matching is similar to document retrieval, we seek binary judgments on document segments, not a ranked list of possible candidate documents. Furthermore, the answer must be located more precisely than usual in  X  X ag-of-words X  approaches to document retrieval. Neverthe-less, we expect similar techniques to apply. We generalize a common probabilistic model of crosslanguage IR [6] by intro-ducing a hidden alignment a i between query tokens q i and document tokens d a i , motivated by the parameterization of machine translation models [1]: This family may be used to model either word-to-word as-sociations between the query and the document (as is usual Figure 2: P fa vs. P miss for word-based and character-based scoring. in cross-language IR) or character-to-character assocations, which are necessary to model transliterations. Here t ( q is a matrix of translation probabilities that models query tokens as translations of document tokens, and p 0 ( q )isa background model that allows for query tokens that cannot be obtained as translations of document tokens. If a uniform alignment prior p a is chosen, the model is identical to [6].
We train the various word-to-word parameters of these models on a large collection of parallel corpora (which ex-cludes the ACE Entity translation documents.) We train the character-based parameters with a parallel corpus of au-tomatically extracted names constructed by running named entity detectors [2] on both the English and Arabic parts of a subset of the parallel corpus which has been automati-cally aligned [3] at the level of words. Matching names are then extracted using the word-to-word alignments. The col-lection of English and Arabic names thus obtained is noisy and includes some words outside of the extent of the name (due to errors in the named entity detection and the word alignment.) Note that no data was specifically annotated as training data for this task. For evaluation purposes, we score each query name with each segment in the given document -segments that do not contain the name serve as negative examples.
We describe two experiments within this framework:  X  First, we show that a simple normalization scheme greatly improves the quality of the word-based model. Since the background probabilities p 0 ( q i ) are typically less than the translation probabilities t ( q | d ), we use timated lower bound for p ( q | d ). Fig. (1) contrasts results obtained with the baseline formula compared to results ob-tained by scoring with p 0 divided out: We plot the false alarm probability P fa = N fa /N segments as a function of the miss probability P miss = N miss /N names (with counts aggregated across all names.) The normalized system is superior by a wide margin, across almost all of the curve. This normalization does not normally affect the recall-precision curve of a ranked retrieval system; it matters here because comparisons of scores are made across queries. The system tends to rank correct segments ahead of incor-rect ones; however different queries tend to have different dynamic ranges of scores.  X  The same family of models can also model the translit-eration , as opposed to the translation of names. To model transliteration, the d a i and q i tokens refer to the letters rather than the tokens of the names. The alignment prior for the transliteration model is a first order markov model:[5] We apply this model to the person subset of the queries, since person names are transliterated much more frequently than organization names. We see in Fig. (2) that in the low false-alarm (high precision) part of the curve, the character-based transliteration model has fewer errors than word-based model. It has slightly more errors in the deep recall (low miss rate) part of the curve, as expected: some names are translations, not transliterations.
We have used simple probabilistic models to locate the segments of Arabic documents that contain a given English name. We have shown the importance of a simple nor-malization approach and have contrasted word-based and character-based modeling. We measured performance by adapting data from the ACE 2007 Entity Translation task for a new application. Future work should focus on model combination -selectively applying word-based and character-based models depending upon whether a name is expected to be transliterated or translated.
This work was partially supported by the Defense Ad-vanced Research Projects Ag ency under contr act No. HR0011-08-C-0110. The views an d finds contained i n this material are those of the authors and do not necessarily reflect the position or policy of the U.S. government and no official en-dorsement should be inferred.
