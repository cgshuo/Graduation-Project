 ORIGINAL PAPER Akihito Kitadai  X  Masaki Nakagawa Abstract This paper describes prototype learning for structured pattern representation with common sub-patterns shared among multiple character prototypes for on-line recognition of handwritten Japanese charac-ters. Prototype learning algorithms have not yet been shown to be useful for structured or hierarchical pattern representation. In this paper, we incorporate cost-free parallel translation to negate the location distributions of subpatterns when they are embedded in character patterns. Moreover, we introduce normalization into a prototype learning algorithm to extract true feature dis-tributions in raw patterns to aggregate distributions of feature points to subpattern prototypes. We show that our proposed method significantly improves structured pattern representation for Japanese on-line character patterns.
 Keywords Online recognition  X  Prototype learning  X  Structured character pattern representation 1 Introduction The improvement of recognition accuracy in pattern recognition systems is an important goal. On-line rec-ognition of handwritten Japanese characters has been studied for many years and is of practical importance for PDA, tablet PC, and other pen-or paper-based systems. Many papers have examined numerous meth-ods to discriminate thousands of categories while cop-ing with of stroke-order and stroke-number variations is employed, however, well-trained prototypes greatly improve the performance of classifiers.

The prototype learning algorithm (PLA) is a method to better approximate discrimination boundaries between different categories in a feature space. Learning vector quantization (LVQ) was proposed by Kohonen based on early basic research concerning the PLA [ 13 ]. Much research has since contributed to the improve-ment of the PLA [ 4 , 10 , 24 ]. Although LVQ does not guarantee convergence of the learning results, some improved versions of the PLA have achieved conver-gence (e.g., by employing membership functions) with-out requiring fine tuning of parameters [ 10 , 24 ]. In research concerning fingerprint recognition [ 2 ] and speech recognition [ 7 , 10 ], the advantages of the PLA have been shown.

The genetic algorithm (GA) is another type of PLA [ 6 ], and its effectiveness has been demonstrated in face and facial-feature detection [ 30 ]. However, its effec-tiveness in improving 1-NN classifiers for thousands of categories has not been proved, at least not to our knowl-edge. In contrast, it is well known that LVQ and its variations can improve 1-NN classifiers for thousands of categories. Therefore, we employ generalized LVQ (GLVQ) as our base learning method whose conver-gence is verified experimentally [ 24 ].

The performance of prototype learning for handwrit-ten numeral recognition has also been evaluated [ 24 , 27 ]. Moreover, prototype learning has been proved to be adaptable to character recognition that discriminates several hundred categories [ 15 ]. Recently, some versions of the PLA have been used to improve the accuracy of prototypes that constitute thousands of categories, and their advantages have been demonstrated [ 1 , 16 ].
Structured character pattern representation (SCPR) represents a character pattern as a composite of sub-patterns and their structures, where common subpat-terns are shared among several character patterns that include the subpatterns in their shapes [ 17 , 19 ]. SCPR is suitable for patterns that have structures like Chinese characters and provides advantages in the size reduction of the dictionary (a set of prototype patterns) and the robustness to deformation of common subpatterns. Jap-anese Kanji characters are of Chinese origin and closely resemble Chinese characters. Korean Hangul charac-ters, although they are phonetic characters, also have structural composition similar to that used for Chinese characters, so structured representation approaches have also been applied to these characters [ 14 ].
In addition to SCPR, we previously proposed a structural learning algorithm. It investigates whether a subpattern or the pattern as a whole is non-standard, registers this (sub) pattern, and extends the effect of the registration to all character categories whose shapes include the (sub) pattern [ 18 ]. However, statistical learn-ing for SCPR remains a subject for future study.
Although the PLA has been shown to be useful for an unstructured set of features, we know of no reports on the adaptation of the PLA to SCPR. Akiyama et al. examined the effect of the PLA for unstructured char-acter patterns in the Japanese character set, but did not consider its adaptation to structured patterns [ 1 ].
The level-building hidden Markov model (HMM) [ 22 ] and the Baum-Welch algorithm enable a classi-fier to learn subpatterns in a structural representation as shown by Kim et al. [ 12 ]. However, they employed manual procedures to divide learning sets into subpat-terns, and so did not show the statistical effect of adopt-ing large learning sets. In contrast, our learning method can extract subpatterns robustly from learning patterns so that a large quantity of learning patterns can be used even without a preparatory stage of manual operation.

The HMM often uses parameter tying to robustly estimate parameters from a limited number of learn-ing patterns. Structural learning in the HMM context by tying parameters within a cluster of the same subpat-terns is conceptually possible, but has not yet been at-tempted [ 20 ]. Our method, although not combined with an HMM recognizer, should be able to suggest which parameters need to be tied to perform structural learning with the HMM.

Our method is an extension of prototype learning to structured pattern representation. Recently, a major interest in machine learning has been classifier ensem-bles [ 5 , 8 , 11 , 28 ]. Practical systems that employ these methods have been proposed [ 3 ]. However, prototype learning should be further exploited to enable struc-tured pattern representation for complex patterns such as Chinese characters, because such representation is beneficial for storing prototype patterns effectively and for learning.
 This paper presents a method to adapt the PLA to SCPR. Our aim is to utilize the occurrence of subpat-terns in some character patterns and apply the infor-mation concerning their statistical distributions to other character patterns that share them. Section 2 introduces SCPR and explains how it is used in our on-line rec-ognition system for handwritten Japanese characters. Section 3 describes the learning algorithm. Section 4 presents experimental results. Section 5 draws conclu-sions. 2 Recognition system 2.1 Flow of recognition The recognition flow of our system to recognize on-line handwritten Japanese characters consists of three steps: pre-processing of an input pattern, pattern generation to provide character pattern prototypes and similarity evaluation (Fig. 1 ). We describe the details of each step in the following sections. 2.2 Pre-processing When an input pattern is given, it is first linearly normal-ized to a square size of 128  X  128 pixels and then feature points are extracted as shown in Fig. 2 .Wefollowedthe method employed by Ishigaki et al. [ 9 ] to extract the feature points, which is basically the polygonal approxi-mation method of Ramer [ 23 ].
 2.3 Pattern generation from structured character Kanji characters, ideographic characters of Chinese ori-gin, are mostly composed of multiple subpatterns as shown in Fig. 3 . For our on-line recognition system, each character pattern prototype is registered as a composite of basic subpattern prototypes (primitive in the sense that they are not further decomposed) and structural templates showing how to combine them. Basic subpat-tern prototypes are shared in the SCPR dictionary as shown in Fig. 4 .

All the basic subpatterns as well as the character pat-terns are represented by a square shape with 128  X  128 resolution, and each of them is a sequence of feature points in a time series. When they are included in larger subpatterns or character patterns, their sizes are reduced to bounding boxes in structural templates through lin-ear mapping (Fig. 5 ). In this paper, we call a result of the linear mapping a  X  X apped basic subpattern X , even if the mapping is sometimes identical. Hereafter, we refer to this as an MBS and to the basic subpattern as a BS. We abbreviate a structural template as a ST. Any subpattern can be resized to an arbitrary size of the bounding box in a character pattern when it appears in Japanese character patterns. For instance, the second basic subpattern shown in gray in Fig. 5 is resized to the lower part or the right part in each character pattern, respectively.

Before the start of this study, all the BS prototypes in the SCPR dictionary had already been learned from learning patterns using the k -means method. To employ subpatterns in the learning patterns for clustering, they had been linearly normalized (expanded) to a square size of 128  X  128. Due to the sensitivity of the recog-nition method to stroke order variations, multiple pro-totypes had been registered for each subpattern. As the result of clustering, the average number of prototypes for each category and its standard deviation are approx-imately 4.53 and 5.86, respectively. 2.4 Similarity evaluation based on elastic matching Each BS prototype in the SCPR dictionary is a sequence of feature points, as are the MBS prototypes and character patterns composed from them. The recognition system employs elastic matching between a sequence of feature points of an input pattern and those of every character pattern generated from the SCPR dictionary. Our actual implementation employs faster elastic matching than DP-matching using beam search [ 17 ], but it dose not matter whether the elastic matching is usual DP-matching or its variations.

As the result of the elastic matching, many-to-one or one-to-many correspondences are made between fea-ture points of the input pattern and those of each char-acter pattern generated from the SCPR dictionary. We employ the following steps to extract one-to-one corre-spondences and make similarity evaluation based on it, since it produce higher recognition rate than the simi-larity score by DP-matching [ 17 ]: (i) Fix the character start to character start and the (ii) Discard the stroke start to stroke end correspon-(iii) Fix the stroke end to stroke end correspondences (iv) Discard unfixed correspondences to a feature (v) Fix unfixed one-to-one correspondences (vi) Fix the unfixed rearmost correspondence, and
Figure 6 illustrates the steps. The resultant one-to-one correspondences are also useful for the learning algorithm described in the following sections. 3 Designing the learning algorithm 3.1 Prototype learning algorithm We employ generalized learning vector quantization (GLVQ) [ 24 ] as the basic learning strategy because it is effective for Kanji recognition [ 16 ]. GLVQ updates the genuine prototype (the closest prototype in the cor-rect class) P i and the rival prototype (the closest one in different classes) P j with the learning pattern P l and the learning rate  X  ( t ) as follows.
 P P l = l D 3.2 Application of GLVQ As the result of the one-to-one correspondences between feature points, the feature points of a learning pattern are paired to the feature points of the genuine pattern and those of the rival pattern (Fig. 7 ). The rival pattern is the closest template to the learning pattern whose category is different from that of the learning pattern. We apply character recognition to the learning pattern to obtain the genuine pattern and the rival pat-tern. We improve prototypes in our SCPR dictionary by moving feature points according to formulae ( 1 ) and ( 2 ).
Figure 8 shows one-to-one correspondences of a fea-ture point p l in a learning pattern to p i in the genuine pattern and p j in the rival pattern. We consider the pro-totypes to be better represented by moving p i toward p while moving p j away from p l . The formulae to move each feature point are  X   X   X   X   X   X   X   X   X  x i = x i + 4  X ( t ) l k ( 1  X  l k ) y i = y i + 4  X ( t ) l k ( 1  X  l k )  X   X   X   X   X   X   X   X   X  x j = x j  X  4  X ( t ) l k ( 1  X  l k ) y j = y j  X  4  X ( t ) l k ( 1  X  l k ) l = l d
When a handwriting recognition system employs a sequence of feature points as a prototype, and one-to-one correspondences of the feature points are made between an input pattern and prototypes, the method proposed here is adaptable to the system whether or not SCPR is used. 3.3 Reflection method Each template pattern matched with an input pattern is a pattern generated from the SCPR dictionary, so it is a composite of MBSs. Therefore, a straightforward employment of the prototype learning algorithm may take MBS prototypes as the counterpart of the learning input pattern although the algorithm must improve BS prototypes as depicted in Fig. 9 . We therefore need a method to reflect the learning in BS prototypes.
A simple idea is to map prototype learning of char-acter pattern level to the BS prototype by applying the inverse of the mapping from the BS prototype to the MBS prototype as shown in Fig. 10 . We call the result of the inverse mapping as an  X  X nversely mapped learning pattern (IMLP). Since the bounding box of the MBS prototype is smaller than that of the BS pro-totype, except in the case of identical mapping, the inverse mapping enlarges the bounding box of the learn-ing pattern. Usually, though, handwriting includes noise due to hand vibration, etc., and such noise has little or no correlation with the bounding box size of the learn-ing pattern or the MBS prototype. Thus, the inverse mapping may magnify the noise and reflect it in the subpattern.

An alternative method is to extract the displacement between the MBS prototype and the learning pattern and convert it into a true displacement factor having correlation with the bounding box size of the subpat-tern and the noise factor having no correlation with the handwriting size. To take these two factors X  X he bound-ing box size of the subpattern and the noise X  X nto con-sideration, we propose another reflection method that extracts the true displacement between the MBS pro-totype and the learning pattern and then reflects this displacement in the original square size of the BS pro-totype while suppressing magnification of noise. In the next section, we introduce the displacement normaliza-tion function G ( d , S ), where d is the observed displace-ment and S is the size of the MBS prototype used to extract the true displacement.

Figure 11 shows the process. Each u ( v ) is a feature point of theMBSprototypemappedfrom afeaturepoint v in the BS prototype, and each l ( v ) is a feature point in the learning pattern corresponding to u ( v ). The dis-placement between u ( v ) and l ( v ) is measured and re-flected in the feature point v using G ( d , S ).
By assuming G ( d , S ), we transform GLVQ formu-lae ( 3 )to( 5 )into( 6 )to( 8 ), where S i =( s ix , s iy size of the MBS prototype corresponding to the genu-to the rival.  X   X   X   X   X   X   X   X   X  x i = x i + 4  X ( t ) l k ( 1  X  l k ) y i = y i + 4  X ( t ) l k ( 1  X  l k )  X   X   X   X   X   X   X   X   X  x j = x j  X  4  X ( t ) l k ( 1  X  l k ) y j = y j  X  4  X ( t ) l k ( 1  X  l k )  X  3.4 Displacement normalization Here, we propose a method to normalize the displace-ment between corresponding feature points according to the bounding box size of an MBS prototype. We assume that the bounding box size of the MBS proto-type is correlated with the freedom of movement of each feature point in the MBS prototype because each fea-ture point can move in a wider area if the bounding box size of the MBS prototype is larger. The degree of free-dom of each feature point is the source of the displace-ment between corresponding feature points. By finding the correlation between the bounding box size and the degree of freedom, we should be able to normalize the displacement.

A sufficient number of learning patterns in the same class as the MBS prototype produce a distribution of feature points in the learning patterns corresponding to each feature point in the MBS prototype (Fig. 12 a).
The distribution shows the degree of freedom in movement for each feature point in the MBS proto-type. The average distance from the center of gravity of the distribution to the feature points belonging to the distribution indicates the size of the distribution. By investigating the distances according to the bound-ing box size of the MBS prototype, we estimate the correlation (Fig. 12 b). 3.5 Parallel translation When the displacement from a feature point in an MBS prototype to its corresponding feature point in a learn-ing pattern is measured, it includes not only the displace-ment within the MBS prototype and noise, but also the displacement due to parallel translation of the MBS pro-totype within a character pattern (Fig. 13 ). This factor must be removed before considering the displacement normalization. Although complete removal is difficult, we propose cost-free parallel translation to match the center of gravity of the learning pattern and that of the MBS prototype (Fig. 14 ). The removed displacements may also be used to improve the accuracy of each struc-tural template (ST).

With regard to this learning, an argument might arise: should different shapes mapped from one subpattern be used to train the subpattern? A naive investigation of human recognition would probably lead to a posi-tive answer, but machine learning is less flexible than human learning. Because the number of learning pat-terns for each subpattern amounts to ten or a hundred times the number of character patterns, though, we can use this large number to train a subpattern prototype. Japanese character recognition systems have to recog-nize over 3,000 character categories, so that lacking a sufficient number of learning patterns for each cate-gory would be a serious problem. On the other hand, it might result in the use of considerably different shapes written in bounding boxes of different sizes to train a subpattern. We will deal with this argument after our description of the evaluation experiments in the next section. 3.6 Advantage of making one-to-one correspondences Our learning method is based on reliable one-to-one correspondences of feature points between an input pat-tern and prototypes so that it can automatically extract subpatterns from learning patterns [ 17 , 18 ]. Manual pro-cedures must be avoided for the user interface to an on-line handwriting recognizer, and avoiding such pro-cedures also allows us to apply huge learning sets.
The method works for unstructured patterns as well, since the process to improve feature points (formulae ( 3 ) X ( 5 )) does not depend on structured representation, except for the displacement normalization described in Sect. 3.4 . 3.7 Averaged basic subpattern It is usually better to begin learning from a good starting point. Generating an averaged prototype from a suffi-cient number of learning patterns is an effective solution for non-structured character pattern representation. For the SCPR dictionary, we propose the following method.
Figure 15 shows a process to find a good starting point for a feature point v in a BS prototype. Each u ( v )isa feature point of the MBS prototype mapped from v and each l ( v ) is the feature point corresponding to u ( Each learning pattern is in the same class as the MBS prototype.

Without the normalization, we consider v to be a good starting point if the following formula is satisfied for l (v) , l { l (v)  X  u = With the normalization, it should be as:
By moving every feature point in the BS prototype so as to fill this formula, we can prepare a BS prototype equally representing the learning patterns. We define such a BS prototype as an averaged BS (ABS). 4 Experiments and discussion 4.1 Normalization formulae To derive the normalization formulae described in Sect. 3.4 , we obtained the correlations between the aver-age displacement ( d x , d y ) and the bounding box size S =( s x , s y ) in a MBS using the HANDS-nakayosi_t-98-09 database (which we will refer to as Nakayosi )as showninFig. 16 . This database contains 10,403 on-line Japanese character patterns handwritten by each of 163 writers; i.e., 10,403  X  163 = 1,695,689 patterns in total (Fig. 17 )[ 19 ].
Parallel translation was applied before we measured the displacement. We show the results of the experi-ments using Nakayosi in Fig. 18 . From the results, the average of d x ( D Ax : holizontal direction) and that of d ( D Ay : vertical direction) can be linearly approximated by formulae ( 11 ) for each direction by using the bound-numbers were derived by line fitting to real distribution as shown in Fig. 18 .
 D D
The displacement between feature points l = ( x l , y l ) and u = ( x u , y u ) in Fig. 11 was normalized with the bounding box size S = ( S x , S y ) of the MBS prototype as follows.
 G G
As opposed to formulae ( 12 ), we can express the inverse mapping in Sect. 3.3 with formulae ( 14 ) since the proper formulae for ( 11 )areshownas( 13 ). D Ax ( s x ) = s x , D Ay ( s y ) = s y , (13) G x ( x 1  X  x 2 , S x ) = ( x 1  X  x 2 ) { 128 / S x } ,
G y ( y 1  X  y 2 , S y ) = ( y 1  X  y 2 ) { 128 / S y } . (14) 4.2 Averaged prototype We made three kinds of initial dictionaries for our pro-totype learning using the methods described in Sect. 3.7 as follows:  X  D init -ABS : consisting of the ABSs without normali- X  D init -NABS : consisting of the ABSs with normaliza- X  D init -AIMLP : consisting of the averaged IMPLs
In order to make them, we employed all the charac-ter patterns of the Japanese Industrial Standard (JIS) First level set, a commonly used character set, in the Nakayosi database as learning patterns. (The follow-ing evaluation was made using a different database.) We also made another initial dictionary taking the aver-age of the inversely mapped learning patterns (averaged IMLP) instead of the ABS as a comparison dictionary.
Learning patterns too much deformed away from their genuine prototypes are often harmful for learn-ing. For this reason, we applied our character recogni-tion system to learning patterns and removed patterns when their correct answers were ranked lower than 10th in the recognition candidates. This threshold was determined from the cumulative recognition rates (rate that the correct answer is within the top N candidates) of our recognition system. Fig. 19 shows the rates for Nakayosi .

If we take only learning patterns that the recogni-tion system recognizes correctly, this does not make any learning since they are already recognized correctly. If we tale all the learning patterns, this leads to the drop of learning effect. If we take learning patterns whose correct answers are within the top 10, we can expect that they are not so badly deformed form the genuine prototypes. Although there might be a still better thresh-old, we can see from Fig. 19 that the top 10 candidates include the correct answer by 97.0% and even if we take more candidates, the rate of including the correct answer dose not increase significantly. This threshold implies to employ 97.0% of learning patterns.

Table 1 shows the recognition rates for Nakayosi .In all the experiments reported in this paper, we employ enforced recognition (i.e., no rejection). The  X  Before learning  X  result in the table shows the rate before the learning described above is made. The dictionaries from averaged learning patterns ( D init -ABS , D init -NABS D init -AIMLP ) are somewhat effective, but the advantage of the normalization is not clear as shown for D init -NABS versus D init -ABS and the bad effect of magnified noise due to the inverse mapping is subtle for D init -AIMLP ver-We also attempted to average instances of the same ST so that the learning would start from a better ST in the character pattern prototypes. We created an aver-aged ST (AST) for each character category by taking the average of the displacements that were removed through the parallel translation. We used D init -NABS and Before learning from Table 1 for this revision. The learn-ing data set was again Nakayosi . Table 2 shows the re-sults for the database. Note that this experiment was done using a finer quantization of X-, and Y-positions to determine the effect of ASTs, so that the results differ slightly from those under the same conditions in Tables 1 , 3 , 4 , 5 , and 6 .

The results with or without ASTs show no significant difference. This might be due to the poor representation capacity where each character category has only a single ST for each combination of subpatterns.

We will leave this problem for future study and will not use ASTs in the following experiments. 4.3 Learning algorithm The formulae used to move feature points of a BS pro-The parallel translation is done before these formulae are applied.

Here, again using Nakayosi as the learning set, we made the following three dictionaries:  X  D GLVQ : the initial BS prototypes being ABSs with- X  D GLVQ  X  N : the initial BS prototypes being ABSs with  X  D GLVQ  X  IMLP : the initial BS prototypes being the
We removed learning patterns with too much defor-mation in the same way as we did in the process to create the ABSs.
 Table 3 shows the recognition rates for Nakayosi . These results show the advantage of using the learn-ing algorithm in comparison with the dictionary Before learning , especially the superiority of D GLVQ  X  N . 4.4 Evaluation using testing patterns A fair evaluation must be done using testing patterns not used for learning. The HANDS-kuchibue_d-97-06 data-base(whichwewillrefertoas Kuchibue ) contains 11,951 on-line handwritten Japanese character patterns by each of 120 writers; i.e., 11, 951  X  120 = 1, 435, 440 patterns in total (Fig. 20 )[ 19 ]. We employed 1,434,120 among them in this database (excluding the JIS-2nd level Kanji patterns) as the testing set. Table 4 shows the recogni-tion rates with the improved SCPR dictionaries from Sect. 4.3 .

The results in Table 4 indicate that the learning algo-rithm is effective for the testing pattern set and the nor-malization method further improves the effectiveness.
We also investigated the effect on each writer X  X  pat-tern set when the normalization was used or not used. We have found that the normalization improves the rec-ognition rates for 104 writers among 120. This predomi-nance is verified by t-test with a 99% level of confidence. 4.5 Analysis of experimental results We have divided the character patterns in each data-base into two groups. The  X  X dentically mapped X  group includes character patterns whose dictionary pattern templates are made from BS prototypes without size reduction; i.e., with identical mapping (2,676 character categories with 725,350 patterns contained in Nakayosi , and 738,360 patterns in Kuchibue ). On the other hand, the  X  X apped with reduction X  group includes character patterns whose dictionary pattern templates are made from BS prototypes with size reduction (669 character categories with 792,017 patterns contained in Nakayosi , and 695,760 patterns in Kuchibue ). Tables 5 and 6 show the recognition results.

The prototype learning method with normalization is effective for both the groups, while that without normalization is not very effective for the Mapped with reduction group. Since the recognition rates with D
GLVQ  X  IMLP are lower for both the groups than those with D GLVQ  X  N , we believe the method with inverse mapping is hindered by the noise magnification.
Each instance of a BS in various Kanji patterns may possess its own feature although it inherits the basic pattern feature from the BS prototype. From the results in Tables 5 and 6 , we believe that the normalization effectively aggregates the common features of the BS instances into the BS prototype.

Using the Kuchibue database, Okamoto et al. [ 21 ] employed a data set from 41 writers and obtained an 86.7% recognition rate when applying pattern match-ing to directional features extracted from bit-map data as well as directional-change features extracted from on-line data. For the same data set, our on-line recog-nition system using D GLVQ  X  N achieves 86.8%. The dic-tionary size of the Okamoto X  X  system exceeded several megabytes, and their system partially employed the test-ing data sets for learning. In contrast, our system uses a dictionary of only about 150 KB and achieves the above performance without any testing data sets being used for learning. Comparison of the time complexity is not easy without rebuilding their system on the same platform. Moreover, employment of coarse classification makes the comparison even more difficult. However, we have an off-line recognizer which uses directional features and state-of-the-art recognition algorithms. Our on-line recognizer is roughly three times faster than the off-line recognizer. The average time that our on-line rec-ognizer needs to recognize an input character pattern is less than 10 ms when it is installed on a modern personal computer.

Except for multiple classifier systems, the Okamoto X  X  system [ 21 ] showed the highest recognition rate for the Kuchibue database. The systems reported in [ 1 , 25 , 26 , 29 ] did not perform as well as the Okamoto X  X  method, even for smaller sets or a private database of sample pat-terns. Therefore, we have compared the performance of our system with that of the Okamoto X  X  system. We have focused on on-line features in this research. Employing off-line features to recognize on-line pat-terns is one way to further improve the recognition rate, as Okamoto et al. did, but our strategy of employing offline features is to combine off-line and on-line recog-nizers [ 28 ].

Since the learning method improves each feature point in BS prototypes, it is desirable that the learning method move all feature points in the BS prototypes. Actually, 1,971 BS prototypes have been improved by the PLA with normalization in D GLVQ  X  N and 99.7% (24,909/24,989) of the feature points have been moved by the PLA.

Although PLA is a good method to improve proto-types, PLA does not control the distortion of rival pat-terns. They are just moved away from learning patterns. We show an example of a BS prototype broken by PLA in Fig. 21 .

When a BS prototype has a rarely used stroke order or is deformed seriously, it is hardly improved as a gen-uine pattern but is subject to modification as a rival pattern with the result that it becomes badly distorted. We have visually checked the entire set of subpatterns registered in D GLVQ  X  N and have found 46 broken BS prototypes.

Nevertheless, such a BS prototype is rarely used, so such occurrences have little harmful effect on the rec-ognition rate. 5 Conclusion We have described prototype learning for structured pattern representation composed of subpatterns for on-line recognition of handwritten Japanese characters. The basic strategy of the learning method is to improve feature points in subpattern prototypes. The parallel translation and the normalization that we propose are to ensure the feature distributions in raw patterns are reflected in the subpattern prototypes.

By applying our learning method to on-line handwrit-ten character recognition, we improved the recognition rate for the testing data from 83.1 to 87.2% (a gain of over four points compared to before learning).
Although each occurrence of a basic subpattern in various Kanji patterns may possess its own features, aggregation of multiple occurrences of the basic sub-pattern into its prototype was effective.

A structured pattern representation is composed of structural templates and basic subpatterns. The learning of basic subpatterns was proven to be effective, while that of structural templates was left for future study.
We employed generalized LVQ (GLVQ) as the base learning algorithm since it had been shown to be effective for Kanji pattern learning. Other proto-type learning algorithms combined with the proposed parallel translation and normalization should perform similarly, but this must be verified through evaluation experiments.

Our recognition system manages over 3,000 catego-ries and we are performing experiments on large data-sets of up to 3,000,000 patterns. More detailed analyses of recognition errors are interesting and challenging, but will take a considerable amount of time. Thus, this fur-ther investigation of recognition errors will be part of our future work. References
