 With the rapid development of the Internet, information growth has gone be-yond the capacity of our social infrustucture. Recommendation systems that can suggest users with useful information become a powerful way to solve the infor-mation overload. A successful tec hnique in recommendation systems is collabo-rative filtering (CF) [1]. It has been applied in many areas, such ase ecommerce (e.g., Amazon) and social networks (e.g., Twitter). Two primary approaches to CF are memory based [2] and model based [3,4] algorithms. The basic differ-ence is that memory based algorithms predict the missing rating based on sim-ilar users or items which can be found from the whole user-item rating matrix (Figure 1(a)) using the similarity meas urement (PCC, VSS [5]), whereas model based algorithms explore the training data to train a model, which can make fast prediction using only a few parameters of the model instead of manipulating the whole matrix.

Traditional CF algorithms have several challenges. Due to the sparsity, they cannot make reliable recommendation for lazy users who have rated few items or cold start users who have never rate d any items because of insufficient data to capture their tastes accurately. Mining purely the rating matrix may give un-realistic recommendation. In order to solve these problems, lots of studies have been done. Matrix factorization can sol ve the sparsity problem [4]. Context-aware algorithms [6] that incorporate contextual information have improved the accuracy. With the popularity of onlin e social networks, social recommenda-tion models [7,8,9,10,11] that incorporate social networks information (Figure 1(b)) not only improve the recommendation quality, but also solve the cold start problem.

Even so, there are still some drawbacks. They typically model users X  rating for every item. As the number of items i ncreases, the rating matrix becomes very large so that matrix operations i n all CF algorithms become exceedingly expensive which may even go beyond the physical computation/storage power. Beside that, attention to an individual item does not reveal users X  tastes ex-plicitly, and provides no ability to deal with new items to arrive in the future. There is therefore an urgent need to establish a general system that can provide scalable solutions for both the large amount and dynamic update of data. As nowadays we can easily get a greater variety of data than ever before, informa-tion extraction methods that can extract keyword from item content (Figure 1(c)) are widely adopted. There are cla ssification methods that can accurately classify the items into many categories (Figure 1(d)). Intuitively, for items un-der the same category, their content is relevant, and hence the user X  X  tastes to them may well be similar. This means that we can explore the category structure to find user X  X  similar tastes. Since this information is comparatively static, we can use it to improve the scalability of a recommendation system. However, the current models cannot be adopted to incorporate this information. Therefore, a more flexible recommendation mechanis m that can efficiently integrate this information is needed.
To address the above problems, we apply a new strategy of layered learning toconsider separately different factors i n different layers. Motivated by this idea, we propose a two-phase layered learning recommendation framework integrat-ing various information. The main process is defined as: we first learn user X  X  average tastes to every category of ite ms in phase one, then we regard them as baseline estimates and lea rn more accurate estimates of user X  X  rating for each item with content and social relation en sembled in phase two. We employ matrix factorization to factorize different user preference matrixes : user-category pref-erence matrix and user-keyword preference matrix. According to the two kinds of classification, we design two layered gradient algorithms in our framework, and conduct experiments on real dataset. The experimental result and analysis demonstrate that our framework not only increases the classification accuracy, but also has good performance for dynamic updates of items.

The rest of this paper is organized as follows. In Section 2, we introduce the related work. Our recommendation framework is formulated in Section 3, and experimental results are reported in Section 4. Section 5 is the conclusion. 2.1 Matrix Factorization(MF) Matrix factorization is one of the most popular approaches for low-dimensional matrix decomposition. Here, we review the basic MF method [4]. The rating matrix R  X  R M  X  N ( M is the number of users and N is the number of items) can be predicted by UV T with the user latent factor matrix U  X  R D  X  M and item latent factor matrix V  X  R D  X  N ,where D is the dimension of the vectors. In order to learn the two matrices, the sum-of-squared-error function L is defined (with Frobenius regularization . F ).
 where  X  1 or  X  2 is the extent of regularization and I ij is the indicator function thatisequalto1ifuser i rated item j and equal to 0 otherwise. The optimization problem arg min U,V L can be solved using gradient descent method. 2.2 Classification Based on Flat Approache and Top-Down Classification is an important data analysis method. It can help us better un-derstand data. Classification can be artificial, also can be automatic based on machine learning. According to the divi sion structure, ther earetwomainclas-sification methods: flat approach and top-down approach [12] (Figure 2). Flat approach divides the data into multi-category directly, not considering the hi-erarchical relation between categories. Top-down approach uses the divide and conquer technique: classify the current category into some small-scale subcate-gories, perform the step iteratively until a reasonable classification. In this paper, we introduce the category of items to find the similarity among items. 2.3 Social Recommendation Traditional recommendation systems assume users are i.i.d (independent and identically distributed). In real life, people X  X  decision is often affected by friends X  action or recommendation. How to utilize social information has been extensively studied. Trust-aware models [7,9,13] fusing users X  social network graph with the rating matrix move an important step forward for recommendation systems. Re-cently, social-based models make some further improvements. [10] proposed two better methods to leverage the social relation. [8] revealed two important factors: individual preference and interpersonal influence for better utilization of social information. CircleCon [11] used the domain-specific  X  X rust Circles X  to extend the SocialMF [7]. However, all of them give no consideration to item content and the similarity among items. In this paper, we incorporate this information to elaborate recommendation. We introduce the problem description, basic idea and define notations in Section 3.1, and present two layered gradient algorithms in Section 3.2 and 3.3. 3.1 Preliminaries Because of the weakness of directly modeling every rating mentioned in Section 1, we take advantage of user X  X  tastes to the information of items and indirectly model the rating. Choosing the appropriate category and keyword from the infor-mation, we can present the rating matrix as the combination of the user-category preference matrix and user-keyword preference matrix. The first problem is how to fuse the two matrices into the CF model. We apply the two-phase layered learning strategy: Find user X  X  average tastes to every category and En-semble it with content and social relation . The second problem is how to deal with different classifications. For the flat approach, we directly learn user X  X  tastes to every category , whereas for the top-down approach, we apply the same layered learning strategy: after learning user X  X  average taste to current category, we learn their tastes to the subcategories.

Suppose that we have M users, N items and K keywords. Every item belongs to one category. For the flat approach, we assume that the values of a category are discrete variables in the range c = { 1 , 2 ,...,n } . For the top-down approach, we assume that the category is expressed hierarchically as a string c 1 .c 2 .c 3 .c 4 , where the categories are delimited by the character  X . X , ordered in top-down fashion (i.e., category  X  c 1  X  is a parent category of  X  c 2  X , and category  X  c 3  X  X sa of a category in the i -th layer. The rating matrix is denoted by R  X  R M  X  N .We also have a directed social follow graph G =(  X ,  X  )where  X  represents the users and the edge set  X  represents the following re lationships between users. 3.2 Layered Learning Framework on Flat Approach For the flat approach, we directly learn user X  X  average tastes to every category. Phase One: Find User X  X  Average Tastes to Every Category. We associate user i with factor vector U i  X  R D and category k with factor vector C k  X  R D . R ij can be computed by j belongs to. The sum-of-squared-error function L 1 is defined: We perform gradient descent in U i and C k (Eq.3 and 4) to minimize L 1 .  X 
L where  X  ( k ) is the set of the items belong to category k ,  X  ( j ) is the set of users who have rated item j and  X  u or  X  c is the extent of regularization. After the optimization, we can get the user-category preference matrix R c = U T C .The to item j  X  X  category is taken as the initial prediction to R .
 Phase Two: Ensemble User X  X  Rating with Content and Social Relation.
 Although we have user X  X  tastes to every cat egory, user X  X  prefer ence for individual Algorithm 1. Layered gradient algorithm for flat approach item is around the average estimate. For example, a user X  X  taste to one category is 3, but the user X  X  rating for individual item may be some higher 3.3 or some lower 2.9. We introduce user X  X  preference for item X  X  keywords to help optimize the initial estimates. We associate keyword t with factor vector K t  X  R D .The user-keyword preferen ce matrix is denoted by R K = U T K . I ( j )isthesetof the keywords extracted from item j .User i  X  X  preference for item j  X  X  keywords is new prediction:  X  R ij = base ij +  X  R ij . The error function is redefined: Beside item content, we have social network information. Inspired by SoReg [10], with the same assumption that if user i has a friend f , there is a similarity between their tastes, the regularizatio n term to impose constraints between one user and their friends is formulated as: where F + ( i ) is the set of outlink friends of user i and Sim ( i, f )  X  [0 , 1] is the similarity function. We use PCC to compute this value. We change Eq.4 to L 2 : We perform gradient descent in U i and K z (Eq.7 and 8) to minimize L 2 . where  X  ( z ) is the set of the items that contain the keyword z , F  X  ( i )istheset of inlink friends of user i and |F + ( i ) | / |F  X  ( i ) | denote the number of friends in the set F + ( i )/ F  X  ( i ). The whole algorithm is presented in Algorithm 1. 3.3 Layered Learning Framework on Top-Down Approach In order to adapt our framework to the multi-layer category, we do some adjust-ments to Algorithm 1. The improved algorithm is shown in Algorithm 2. Phase One: Find User X  X  Average Tastes to Every Category. Suppose that the category has L layers. Ca l ( j ) is the category that item j belongs to in the l -th layer. We associate user i with latent factor U l i  X  R D and category k with latent factor C l k  X  R D in the l -th layer. In the 1 st layer, the method is consistent with phase one of Algorithm 1. In the l -th layer, user X  X  taste to to the parent category base l  X  1 ij in the l  X  1-th layer, R ij can be predicted by base l  X  1 ij +  X  R l ij . The sum-of-squared-error function L l 1 given by: We perform gradient descent in U l i and C l k (Eq.10 and 11) to minimize L l 1 in the l -thlayergivenbyEq.9. where  X  l ( k ) is the set of the items belonging to category j in the l -th layer. Then basic estimate base l ij for the category in the l -th layer is given by: base l ij = base l  X  1 ij + U l i T C Ca l ( j ) . Repeat the operation dow n the categories until the Algorithm 2. Layered gradient algorithm for top-down approach lowest layer. Finally, we can get the more accurate baseline estimate base ij = base L ij in the L -th layer.
 Phase Two: Ensemble User X  X  Rating with Content and Social Relation.
 Given the baseline estimate base , the phase is the same as the phase two in Algorithm 1. 4.1 Datasets and Metrics In our experiments, we use the real Tencent Weibo 1 data published by KDD Cup 2012 2 . Beside the social network information, it contains much context information such as keyword, category and timestamp. The items have been organized using four-layer categories, such as  X 1.2.5.8 X ; each category belongs to another category, and all categories together form a hierarchy. This structure is suitable for our framework. We predict user X  X  action to items, where  X 1 X  represents that the user accepts the item, and  X 0 X  otherwise.

We extract a small dataset over a period of time randomly. It is much bigger and richer than other datasets used by [7,11]. The statistics of the dataset are summarized in Table 1.

For the flat approach, we only use the categories in the 4 th layer. The density of the rating matrix is 379598 12518  X  3610 =0 . 84%. We divide the dataset into three parts: the training set R train ., test set R test ,andset R new containing all items
The evaluation metrics we use in our experiments are two popular error met-rics: Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). A smaller MAE or RMSE value means higher accuracy. 4.2 Implementation and Comparisons We compare our algorithms with four state-of-art CF algorithms.  X  PMF [4]: It is a Low-rank matrix factorization based on minimizing the  X  SocialMF [7] is a trust-based model incorporating the mechanism of trust  X  SoReg [10]: It is a matrix factorization model with social regularization,  X  CircleCon [11]: It incorporates the c oncept of circle-ba sed recommendation, We call our Algorithm 1/Algorithm 2 proposed in section 3 LLR1/LLR2. In all the experiments, the trad eoff parameter settings are  X  u =  X  c =  X  k =  X  f =0 . 001.
JAMA 3 is an open matrix package for Java, developed at NIST and the Uni-versity of Maryland. It provides the fundamental operations of numerical linear algebra. All algorithms are implemented using this library. 4.3 Impacts of Different Factors TheNumberofLayersofCategory: The difference between LLR1 and LLR2 is the number of layers of category. The results of LLR1/LLR2 (Figure 3) show in phase one, LLR1 achieves 0.1906/0.2910 on MAE/RMSE, but for LLR2, the training of each layer decreases the values: the training of the 1 st layer and 2 nd layer reduce the values greatly, the training of the 3 rd layer and 4 th layer have made only minor changes to the results of the 2 nd layer, and after the training of the 4 th layer, the values can be reduced to 0.1503/0.2739. Contrasts looked, LLR2 has smaller prediction error than LLR1 in phase one. So our framework benefits more from the top-down approaches than the flat approach. We believe classification based on hierarchy can better model the similarity among items. The Item Content and Social Networks Information: After we get the baseline estimate, we discuss how the content and social information may con-tribute to improving the values. The results of phase two (Figure 3) show we get more accurate estimate of user X  X  rating for individual item: LLR1 and LLR2 achieve 0.1440/0.2751 and 0.1417/0.2702 on MAE/RMSE respectively. For LLR1, this information improves the accuracy as high as 24.44%/5.46% in con-trast to phase one. For LLR2, this information improves as high as 5.72%/1.35%. The improvement demonstrates that the content and social information are help-ful to boost the performance, especially for LLR1, although classification on the flat approach improves much less than LLR2 based on the top-down approach in phase one, the information significantly enhance more accuracy than LLR2 in phase two. Overall, final results show LLR2 achieves better performance than LLR1. 4.4 Analysis of Recommendation Performance Figure 4 shows the results of the algorithms on different amounts of training data (25%, 50%, 75%). We observe PMF has the worst MAE/RMSE. SocialMF and SoReg have almost the same accuracy, both superior to PMF, but SoReg is a bit lower because it uses better social r egularization terms . CircleCon viewed as an extension of SocialMF is better than the three algorithms. This demon-strates only considering the trust circle belong to one category is useful for learn-ing user X  X  tastes. Our algorithms have the minimum of MAE/RMSE: when the training is 25%, LLR2 gets the decrease by 5.57%/2.99% over CircleCon/SoReg , when the training is 50%, the decrease is 13.68%/10.18% over CircleCon, when the training is 75%, the decrease is 20.88%/6.37% over CircleCon. Experiments demonstrate that our algorithms have higher accuracy than purely using the user-item rating matrix, purely utilizing social networks information or purely considering category-specific circles.
 4.5 Performance on Dynamic Update of Items We analyze the performance of our algorithms on dynamic update of items, i.e., addition of new items. Except some very special items, usually we can know the keywords and category of new items before their addition. The predicted value results of our algorithms on training data (25%, 50%, 75%). We observe although the new items are not in the rating matrix, our algorithms still make very good prediction using the new item X  X  category and keywords. In this paper, based on the similarity in the classification, we proposed a novel two-phase layered learning framework, which incorporates the category, item content and social networks information. For two kind of classifications, we de-signed two layered gradient algorithms in our framework. We conducted exten-sive experiments on real data. Comparison results of different phases of LLR1 and LLR2 show that the top-down approaches are more helpful to find user X  X  similar tastes than the flat approach, and item content and social networks in-formation contribute to improve the classification accuracy. The analysis results show that our algorithms outperform other state-of-the-art methods. The results also show that our algorithms has good scalability for the dynamic update of items to cope with addition of new items. Acknowledgement. This work is supported by National Science Foundation of China under its General Pro jects funding # 61170232 and # 61100218, Fun-damental Research Funds for the Central Universities # 2012JBZ017, Research Initiative Grant of Sun Yat-Sen University (Project 985), State Key Labora-tory of Rail Traffic Control and Safety Research Grant # RCS2012ZT011. The corresponding author is Hong Shen.

