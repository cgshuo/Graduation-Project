 Along with the quick expansion of the Web in the past decade, governments around the developed and developing countries have proliferated in recent years [ 1]. In addition to accessing documents published by the governments, people are able to file relatively simple procedural applications on the Internet, and government agencies may reply and even return official documents in electronic formats, thereby saving time and costs of the whole society. problems. Nevertheless, modern techniques are available for releasing legal informa-tion without compromising privacy of individuals, and legal information services are judicial documents of the past lawsuits via the Web using an interface similar to that of Google but more tailored for the needs of searching for judicial documents. Purely offering judicial documents in their original forms does not help ordinary people very much, because understanding the contents of the judicial documents may not be a simple task for everyone. Providing a precise set of keywords to the search engines may judicial document and ask for supports of users X  interest. More specifically, we study methods that would analyze contents of prosecution documents and infer the infringed legal articles implied by the alleged actions in the contents. By doing so we allow users of our system to place queries with prosecu tion documents directly, avoiding the needs to first figuring out a set of keywords for querying our system. practitioners [ 3]. However, we were not able to find many published results for proc-essing legal documents that are written in Chinese. Lai and Huang use a small Chinese legal corpus in demonstrating the applicability of the Dependency Grammar for an-notating Chinese documents [ 4]. Brown builds the CHINATAX system for inference problems that are related to the Commercial law of China [ 5]. In the past few years, we have been working on classification of judicial documents in Chinese for supporting legal consultation [ 6, 7, 8], and this paper reports some strengthening methods for our previous approaches. with real-world judicial documents to obtain a database of instances [ 8], and apply k NN methods for classifying query documents.  X  Under the constraint that each query docu-than 85% of the query documents into one of the 13 prosecution categories. Although systems. Criminal summary judgments involve relatively simple lawsuits, and we can expand the applicability of our system into lawsuits involving general criminal law. In than classifying lawsuits only based on the prosecution categories. Lawsuits belonging classify these lawsuits into finer grains based on the violated articles. classify query documents based on the involved law articles. The classification task is distinctly more difficult than the previous one. Documents of lawsuits that belong to the classify them into different combinations of violated law articles require professional training even for human experts. Consequently, the previous system did not perform learning [ 10] for fine-tuning the influences of the leaned instances on the classification of the query documents. We run tests over query documents that involve larceny and measures, outperforming its predecessor by about 10%. rate on the methods that we propose for enhancing the previous system in Section 3, report results of experimental comparison and evaluation of the previous and the cur-rent classifiers in Section 4, and wrap up this paper with discussions in Section 5. We provide more background information for this research, including the law articles that are of concerned in this paper and how we process judicial documents in Chinese. details about the predecessor system for motivating the current research. 2.1 Laws Governing Larceny a nd Gambling in Chinese Once judges determine the prosecution categories of the defendant, they have to decide behaviors than others. We concern ourselves with three articles for gambling and three articles for larceny in the criminal law in Taiwan [ 2]. gambling cases, article 267 describes cases that involve people who make a living by gambling, and article 268 describes cases that involve people who provide locations or gather gamblers for making profits. Articles 320, 321, and 322 are for cases of larceny. Article 320 describes ordinary larceny cases, article 321 describes more serious larceny cases, and article 322 describes cases that involve people who make a living by steal-ing. A larceny case is considered as seri ous cases when the cases involve breaking in houses or relying on the use of weapons. cited in the prosecution documents. Very simple cases violate only one of these articles, combined applications of these articles are more normal than others in practice. Let A , of other combinations are so rare that we ca nnot reasonably apply and test our learning methods. Hence we will ignore those rare combinations in this paper. 2.2 Preprocessing Judicial Documents in Chinese Unlike most western languages such as English, words in Chinese are not separated by spaces. This special feature requires computer software that does Chinese information processing to segment Chinese strings into words. A machine readable dictionary such so-called  X  X referring longer words X  heuristic, it is not guaranteed that one can segment Chinese text correctly without the help of syntactic and even semantic level informa-tion. In some special cases, different segmentation of the same text string converts the original string to different meanings. The string  X  Kai Fa Zhong Guo Jia X  is one of such peculiar examples.  X  We can treat  X  Kai Fa Zhong Guo Jia  X  as either the combination of  X  Kai Fa Zhong  X  (developing) and  X  Guo Jia  X  (country). The first segmentation inter-prets  X  Kai Fa Zhong Guo Jia  X  as  X  X n expert for developing China X  while the second  X  X  developing country. X  designed particularly for applications in the legal domain, some common legal terms are not available in HowNet. Hence we have to customize HowNet by augmenting it with some legal terms. We rely on the customized HowNet for segmenting Chinese strings, and employ the  X  X referring longer words X  heuristic when necessary. If there are still ambiguities, we will choose one of the alternatives arbitrarily. 2.3 An Instance-Based Approach to Case Classifications classify future problem instances. K NN methods are very common among different incarnations of the concept of instance-based learning. By defining a distance measure between the past experience and the future problem instance, a system selects k past future instance based on the classes of the selected k past experiences. Given a segmented Chinese text as we explained in Section 2.2, we can treat each past experience as a vector of Chinese words. The distance measure can be defined in ways but we take a different approach particularly for legal reasoning. previous work include an algorithmic way of generating instances for instance-based legal reasoning and a modification to the stan dard distance measures that are used in vector models for classifying judicial documents [ 8]. The first achievement allows us to relieve the concerns brought up by Br X ninghaus and Ashley that relying on manually reasoning systems to real-world problems [ 13, 14]. We will not review details on how our algorithms simplify instances that are generated from judicial documents as it is not the main theme of this paper [ 8]. The simplification step removes relatively unimpor-tant words from the learned instances for improving efficiency of the classifier. Since we can augment each instance with the finalized prosecution reason. the document with the segmentation methods we reported in Section 2.2, compare the similarity between the instances stored in the instance database and the query instance, and choose qualified instances from the instance database to vote on the prosecution reason of the query instance using a k NN method. The preprocessing step converts the query document to the same format of instances that are stored in the instance database, leaving the prosecution reason unspecified. For simple referrals, we call the instance database, we consider not only the occurrences but also the orders of words. The orders of matched words must also match for the matched words to be used in the calculation of the similarity between the instances in the instance database and the query instance. common words or OCW s in short. When there are multiple choices of the OCWs, we instances being compared, while we compute portion based on numbers of words in the instances of interest. prosecution reason of the instance and  X  i is the list of ordered keywords that were con-as follows. Example 1. Let X-Y-Z-W-R represent the ordered word list containing five words in an instance, and X-K-Z-W-R-Y-W the ordered word list containing seven words in another instance. There are different OCWs between these instances, e.g., X-Z-W-R, X-R, and X-Y-W. The longest OCW is X-Z-W-R, and the degree of similarity between the in-stances that include these word lists is ( 4/5+4/7 ) /2. The design sketched in Section 2.3 provides pretty good performance for differentiat-ceny-related cases. When we attempted to apply the same methods to further classify performance became less satisfactory. The main reason is mostly because lawsuits that belong to the same prosecution reason often share a significant number of words, so the differences between such cases are more subtle than the differences between cases of different prosecution reasons. As mentioned in Section 2.3, a key feature in our pre-k NN-based classification. The downside of the past approach is that words in the seg-mented text have equal influence on the computation of similarity in (1). Some words should in fact be minimally relevant to the final judgments, some have weak influences, classifier. 3.1 Learning Weights of Keywords  X   X  . Since weights of keywords reflect their relative importance in computing similarity between instances, we confine weights of all keywords to the range of [0, 1]. The initial procedures for training the instances. evaluation of our approach. We create the or iginal instances with the procedures de-introlearn adjusts the weights in the original instances, and we explain the details of the procedure adjust shortly. The third step evaluates the adjusted instances by adopting the updated instances to classify docu-ments of the sec-ond set. The clas-step 3 improves over the previous round of update, the training will continue; otherwise the training will terminate. We will provide the exact definition of  X  X uality of classi-fication X  in Section 4.1. we adjust the weights of the instances. The first step embraces the leave-one-out principle [ 9] to probe the effec-tiveness of the instances in . We use one of the instances in as the query instance, classify this instance with other instances in , and re-cord both correctness of the voting instances and the OCWs that qualify keywords using the formula provided in Section 3.2. After using each instance in as performance between rounds of calling adjust or an instance that votes correctly less than 50% of the time in the most recent execution of adjust will not be allowed to vote at step 3 in introlearn . based on the data recorded at the first step. We modify the weights of keywords of an I instance that is temporarily used as a query instance at step 1, we increase weights of all performance of the classifier by increasing/decreasing the weights of the keywords that participate in correct/incorrect voting of the instances. (  X  ), where  X  (  X  ) depends on the distributions of the occurrences of a keyword  X  in the inverse document frequency that is commonly employed in information retrieval sys-classifying document s. Let Pr be the percentage of occurrences of  X  in instances that  X  the relative frequency Pr max (  X  ) is small. 1]. We will normalize the weights in the instance when this situation occurs. Let  X  max and be the maximum and minimum weights of the instance before normalization. We readjust each weight  X  of the instance to (  X  -)/(  X  max - X  min ). 3.2 k NN Classification Once we have finished training of the weights of the instance, we may classify query documents with a k NN method. The determination of similarity between instances takes the weights of keywords into consideration as shown below. The new score equal weights to all words. query document, compute the total scores in terms of similarity between the voting in-score. Take the classification of cases for gambling for instances. There are four types of summation so that more similar instances have larger influences on the results of voting. 3.3 Selecting System Parameters We decided to take 10 votes in the classification in a less scientific way. We ran a small scale experiment, and found that using about 10 most similar instances led to the best ments. Analogously, we set the learning rate  X  mentioned in Section 3.1 to 0.02 based upon results of small-scale experiments. 4.1 Data Sources and Measures for Classification Quality We evaluated the resulting classifier with judicial documents for gambling and lar-ceny cases. Table 1 shows the quantities of the documents that we used to train and test the performance of our system. We acquired the documents from both the web site of the Judicial Yuan and the Pan-Chiao District Court, Taipei, Taiwan. The leftmost column shows types of documents using the codes that we ex-plained in Section 2.1. As we mentioned trolearn , Tr_2 was used as the procedure introlearn , and the last set Eval was used in the final evaluation. continue to use standard measures for quality. Namely, we used Precision, Recall, and measures of all experiments under consideration. 4.2 Results and Analyses Table 2 shows the performance of the resulting classifier. The leftmost column indi-cates the measures used to evaluate the clas sifier. The top rows indicate types of judi-cial documents and types of cited articles. Numbers in the cells show the performance of the classifiers without and with the augmented keyword weights. The numbers on the left hand sides of the arrows are performance of the classifier that does not employ keyword weights in computing the similarity between instances. fier. The averages of Precision, Recall, and the F measures increased for cases of both gambling and larceny. The improvement on the classification of cases of larceny was One of the reasons for this divergence in improvements is that the previous classifier cases of gambling and larceny, respectively. (The average of 0.77, 0.70, 0.90, and 0.80 is about 0.80.) In contrast, the new classifier got 0.83 and 0.76. were classified. The leftmost column shows types of the test documents, and the top hand sides of the arrows are results that came from the previous classifier, and numbers on the right hand sides are results for the new classifier. For instance, out of the 807 the previous classifier. us to avoid classifying compositive cases, e.g., AB and AC , into simple cases, e.g., A and C . However, statistics in the second and third row indicate that some more simple cases were misclassified, thereby offsetting the overall improvement. AB 185  X  55 2  X  1 1574  X  1721 26  X  10 AC 44  X  22 166  X  140 6  X  6 788  X  836 We report an experience of developing a sample-based query mechanism for providing relieving users the needs to figure out appropriate legal keywords. The current query documents, and classify the query documents based on the involved law articles. The reported work build on and improve our previous system that relies only matching ordered keywords for case classification. domain. For instance, Pannu attemps to find  X  X mportant X  features for classifying legal documents with genetic algorithms [ 15], and Thompson compares different approaches for case classification [ 16]. The approach we employed is special in that we consider further augment the case instances with weights of keywords so that we can classify the different categories based on how the criminals committed the crime. Experiments Although not perfect yet, the results shown in Table 2 are better than the classification quality reported in [ 16] while we confront a more difficut classification task. enhancing the classifier. It is clearly a weak spot in our current approaches that we have not considered to analyze the judicial doc uments from a semantic viewpoint. We can also try to employ other language-modeling techniques that are available in the natural language processing research community. NSC-92-2213-E-004-004 and NSC-93-2213-E-004-004 from National Science Council of Taiwan. 
