 Conditional random fields(CRFs) are a class of undirected graphical models which have been widely used for classifying and labeling sequence data. The training of CRFs is typi-cally formulated as an unconstrained optimization problem that maximizes the conditional likelihood. However, maxi-mum likelihood training is prone to overfitting. To address this issue, we propose a novel constrained nonlinear opti-mization formulation in which the prediction accuracy of cross-validation sets are included as constraints. Instead of requiring multiple passes of training, the constrained formu-lation allows the cross-validation be handled in one pass of constrained optimization.

The new formulation is discontinuous, and classical La-grangian based constraint handling methods are not appli-cable. A new constrained optimization algorithm based on the recently proposed extended saddle point theory is de-veloped to learn the constrained CRF model. Experimental results on gene and stock-price prediction tasks show that the constrained formulation is able to significantly improve the generalization ability of CRF training.
 I.2.6 [ Artificial Intelligence ]: Learning X  Parameter learn-ing ;J.3[ Life and Medical Sciences ]: [Biology and genet-ics]; J.1 [ Administrative Data Processing ]: [Financial] Algorithm, Experimentation Conditional random fields, Constrained optimization, Cross validation, Extended saddle points
We study in the paper new formulations and optimization algorithms for training Conditional Random Fields (CRFs), a class of discriminative probabilistic models for sequence la-beling. CRFs have attracted intensive interest and achieved success in various domains, such as as computer vision [12, 17], natural language processing [10, 16, 15, 13], and bioin-formatics [6]. In general, CRFs model the conditional distri-bution p ( y | x ) between the labeling sequence and the obser-vation sequence. The learning of CRF parameters is tradi-tionally formulated as an unconstrained optimization prob-lem of maximizing the conditional distribution. We propose a constrained formulation for training CRFs in this paper.
A key advantage of CRFs is that they support the use of complex features. In most cases, it is insufficient to include only simple and independent features. Rather, it is nec-essary to use long-range features that are overlapping and inter-dependent. It is hard for traditional generative graphi-cal models, such as hidden Markov models (HMMs), to cap-ture these complex features. The Markovian assumption requires that the current state only depends on the previous one and that the observation depends only on the current state. These assumptions severely limit the possible features that can be included in HMMs. CRFs overcome the above limitations of HMMs [10] by relaxing the independence as-sumptions, allowing overlapping and dependent features to be included and learned in a unified fashion.

The flexibility of CRF models encourages the use of large feature sets with a rich collection of features. During our study, we found that CRF models with a large feature set often suffer from overfitting. A CRF model with the opti-mal parameter set found on the training data often has a significant performance degradation when applied to unseen data. For instance, in a gene prediction task, using the CRF model trained on the training data, we achieved 100% gene level sensitivity and specificity when testing on the same set, comparing to an average of only 2  X  4% accuracy when testing on unseen data.

One existing approach to address the overfitting problem of CRFs is to include a regularization term in the objective function [16, 19] to penalize large weight vectors. A major problem with this approach is that, the regularization factor which controls the penalty strength is hard to control. A randomly selected regularization factor will not be effective in addressing the overfitting problem.

In this paper, we propose a new constrained formulations for CRF training to help overcome the overfitting problem, inspired by the idea of cross-validation. Cross-validation [9] is often used to estimate the accuracy of a classifier and to select models. We propose to use cross-validation in a novel way as a measure to address overfitting. Constraints prescribing the difference of the score of labels generated by the trained CRF model and that of the real labels on the validation sets are added to prevent the model from fitting freely and tightly to the training data.

The constrained formulation has several advantages. First, our experience shows that the cross-validation constraints can effectively help address the overfitting problem, as this approach can enforce an even distribution of validation er-rors across the train ing sets. Second, instead of separating the training and validation phases, we integrate validation into the training process by modeling the validation quality as constraints in the problem formulation. Third, supported by a constrained optimization solver proposed in this paper, we only need one run of constrained optimization, although we have multiple validation sets. Fourth, we create our val-idation sets from the training data, avoiding waste of train-ing data, which is crucial for problems with limiting data available. Further, the constraints are beneficial in difficult training scenarios. We have found that, for CRF training, gradient-based optimization methods may terminate prema-turely at non-optimal points due to a flat terrain near the global optimum [4]. The violated constraints provide addi-tional guidance during search, leading the search to good directions that effectively reduce the objective function.
Since the new constraint formulation is discontinuous and non-differentiable, classic constrained optimization methods, like Lagrangian method, are not applicable. A new con-strained optimization algorithm based on the recently pro-posed extended saddle point (ESP) theory [20, 21] is devel-oped to solve the constrained problem. Unlike the tradi-tional Lagrange multiplier method, in which a set of unique Lagrange multipliers is required, the ESP condition is sat-isfied for an extended range of penalty multipliers, mak-ing the search much easier and more robust. Further, the ESP theory provides optimality conditions for problems with non-differentiable constraints, which is needed in our CRF formulation. Based on the ESP theory, we develop a con-strained solver to efficiently train constraint-based CRFs.
The paper is organized as follows. In Section 2, we review the basics of CRFs and the traditional parameter estima-tion methods. In Section 3, we detail our new constrained formulation. In Section 4, we describe our constrained op-timization algorithm. Experimental results are presented in Section 5 and conclusions given in Section 6.
As shown in Figure 1(a), a CRF is a graphical model based on an undirected graph G =( V, E ), such that Y =( Y v ) v the set of hidden variables, when conditioned on X ,thesetof variables on the observation sequence, obey the Markovian property with respect to the graph: p ( Y v | X, Y u ,u = v )= p ( Y v | X, Y u ,u  X  v ), where u  X  v indicates that u and v are neighbors in G [10]. The fully connected subgraphs of G define a set of cliques C = { X c ,Y c } . Each clique defines a feature for the CRFs.
 Each predefined feature typically returns a binary value. For example, a feature can be defined as: It evaluates to 1 when the previous state is  X  X C X , the current state is  X  X  X , and the observations at time t to t +2 are  X  X TG X . In this paper, we focus on linear-chain CRF, a class of Figure 1: (a) A general graphical CRF model. (b) A linear-chain CRF model.
 CRFs that is computationally tractable and widely used. In linear chain CRFs, each each clique (feature) only involves two consecutive hidden states as shown in Figure 1(b).
Let x and y be the observation and labeling sequences, respectively. By the fundamental theorem of random fields [7], a linear-chain CRF defines the conditional distribution of a label sequence y , given the observation sequence x as W = {  X  k } X  X  K is the corresponding weight vector. Z( x ) is an instance-specific normalization function
Given training data D = { x , y } , to estimate the weights {  X  k } , we typically solve the following unconstrained opti-mization problem to maximize the conditional log likelihood:
It is a convex optimization problem with only one global optimum. The objective function cannot be maximized in a closed form and numerical optimization is used for training.
The partial derivatives of the objective function with re-spect to each feature weight  X  k ,k =1 , 2 ,  X  X  X  ,K takes this form,
In the derivative, the first term is the empirical count of feature f k in the training data, or in other words, the expected number of appearances of f k under the empirical distribution. The second term is the expected number of ap-pearances of f k under the model distribution p ( y | x ; W ) X  p ( x ) [10]. When the model is optimized, the gradient reaches zero and the two expectations will be equal. Hence, CRF training can be viewed as a maximum likelihood training for expo-nential models which tries to find an optimal parameter set to best fit the training data. Therefore, like other maximum Figure 2: Definitions of the training, test, and vali-dation sets in the STMV framework. likelihood methods, CRF training is prone to overfitting the training data.
A common way to avoid overfitting is via regularization, which penalizes weight vectors whose norm is too large. In-stead of maximizing solely the conditional distribution, an  X  2 regularization term is added: where  X  2 is a parameter determining the strength of penalty. The regularized formulation can be viewed as maximizing a posteriori estimation of W , which is assigned a Gaussian prior with zero mean and covariance  X  2 I .

To determine the best regulari zation parameter requires a computationally-intensive parameter sweep. In previous work, part of the training data is held out to find the regu-larization parameter  X  2 first. However, it has been reported that the model accuracy does not appear to be sensitive to the changes in  X  2 ,evenwhen  X  2 isvarieduptoafactorof 10 [18]. Our own experimental results have confirmed it.
A number of other smoothing methods have been used to address the overfitting problems for maximum entropy mod-els [5]. The smoothing method tries to relax the constraint that the model distribution should be exactly the same as the empirical distribution on the training data. The good-Turing smoothing algorithm [14] tries to add a discount to the empirical count of events in the training data. The fuzzy maximum entropy framework encourages the model to fit the training data, while at the meantime adds a prior distribution favoring uniform models. The fat constraints method [11] tries to avoid over-fitting by not exactly sat-isfying the constraints but instead requiring the difference between the empirical and model distributions to be within certain range. It was reported that the Gaussian prior in (5) performs as well as or better than all the other algo-rithms [5].
We propose a constrained formulation for CRF training based on cross-validation. Our approach integrates cross-validation into the training process in a novel way, aiming at avoiding overfitting and finding better models.
A common setting of cross validation is the k -fold cross-validation, in which data D is randomly split into k mutually exclusive subsets D 1 ,  X  X  X  , D k . The predictor is trained and tested k times, each time the whole data set D excluding D ,t  X  1 , 2 ,  X  X  X  ,k is used as the training set and D t as the test set. Such a method is often used for model selection. However, the method wastes 1 /k of the training data and requires k -fold training time.

CRF training for large scale problems is computationally expensive. In a gene prediction task with around 300K bases and 30K features, it takes 5 to 6 hours on our cluster with 20 processors to complete one run of the training process. Since CRF optimization is usually time-consuming, it is very expensive, if not prohibitive, to use the traditional k -fold cross-validation.

We use cross-validation in a single training multiple val-idation (STMV) framework originally proposed for neural network training [22]. Instead of separating the training and validation phases, we integrate validation into the training process by modeling the validation quality as constraints in the problem formulation. We select multiple subsets from the training sequence as validation sets as shown in Figure 2. The entire training set is used for training. This way, we do not waste any training data as the k -fold cross-validation does. Also, this approach can enforce an even distribution of validation errors across the training set and offer flexibil-ity in choosing the validation sets.
As illustrated in Figure 2, we use multiple subsets from the training set as the validation sets. Define to be the score of a specific labeling sequence y for an ob-servation sequence x ,where I is the set of indices in se-quences x and y . Weproposethefollowing constrained CRF (CCRF) formulation: subject to h j ( W )  X   X , Here,  X  is a small positive constant, V = { ( v ( j ) , y are the validation sets extracted from the training data, V is the total number of validation sets, and  X  y ( j ) is the most likely labeling sequence for the observation sequence v found by the Viterbi algorithm under the current model. From the mechanism of Viterbi algorithm, we know that  X  y ) is the sequence with the best score.

Instead of using the prediction accuracy of the validation sets, we use the score difference between the best scoring labeling sequence  X  y i and the desired labeling sequence y in our constraints. We observe that a CRF model learned through unconstrained optimization often has substantial differences of scores on the validation sets. Generally, the performance on the validation set is strongly correlated to the performance of the trained model on unseen data. A trained CRF model giving many wrong predictions on the validation sets tend to perform poorly on the testing data. To ensure non-deteriorated performance on unseen data, we want to make sure that the trained model not only fits the training data, but also the validation sets. In other words, we want to make sure that, for the trained model, the score difference between the most likely sequence  X  y i and the an-notated sequence y i is small for each validation set.
In our formulation, the parameter  X  controls the score difference allowed for each validation set. We set  X  to be a small positive constant. In difficult training scenarios, it may be impossible to reach convergence with  X  =0. Set-ting  X &gt; 0 may allow training to converge faster. Further, suitable relaxation may help avoid overfitting.
The CCRF formulation in (6) has discontinuous and non-differentiable constraints. The constraint for validation set j, j =1 ..V , can be re-written as: where I j is the set of indices of the j th validation set. Note that, for each predefined feature f k ( y ,y, v t ), it is satis-fied when the observation at time t matches v t .Thestate changes of W may lead to changes of the labeling sequence  X  y ) generated by the Viterbi algorithm for each validation set V ( j ) . When the labeling sequence changes, the feature to false) or from 0 to 1 (false to true), resulting in a discon-tinuous g j ( W ).

Since the CCRF problem in (6) has non-differentiable constraints, it cannot be readily solved using existing La-grangian methods that require the differentiability of func-tions. Sampling methods such as simulated annealing and genetic algorithms are too slow. Penalty methods can han-dle such constraints but it is in general difficult to choose proper penalties. In this paper, we propose to solve (6) using the recently developed extended saddle point (ESP) theory [20, 21]. The ESP search has successfully solved dis-continuous optimization problems from AI planning [21] and engineering [20].
The ESP theory can handle nonlinear programming (NLP) problems in a continuous, discrete or mixed space. Here we focus on NLPs with continuous variables. A NLP is de-fined as follows, with functions f , h =( h 1 ,...,h m ) T g =( g 1 ,...,g r ) T defined in real space R : In order to solve CCRF, we assume that f ( x )iscontin-uous and differentiable, but h ( x )and g ( x ) may be non-differentiable.

Definition 1. Apoint x  X  is a CGM, a constrained global minimum of ( P c ), if x  X  is feasible and f ( x  X  )  X  f ( x ) for all feasible x .

While CGM is generally difficult to find for nonlinear problems, a common goal of solving P c is to find a con-strained local minimum x with respect to N CN ( x )= { x : x  X  x  X  and  X  0 } ,the continuous neighborhood of x .
Definition 2. Apoint x  X  is a CLM, a constrained local minimum with respect to the continuous neighborhood of x  X  in P c ,if x  X  is feasible and f ( x  X  )  X  f ( x ) for all feasible x  X  X  CN ( x  X  ) .

The ESP theory is based on the m 1 -penalty function de-fined below.
 Definition 3. The m 1 -penalty function of P c in (8) is where g + ( x )=max(0 ,g ( x )) ,  X   X  X  m and  X   X  X  r are the extended penalty values .

Instead of using a single penalty term as the traditional -penalty, the m 1 -penalty uses multiple penalty parameters  X  and  X  , one for each constraint. The m 1 -penalty can be viewed as a mixture of the Lagrangian function with multi-ple multipliers and the 1 -penalty with non-negative trans-formations on constraints.

Definition 4. Constraint-qualification condition. Apoint x  X  X  v meets the constraint qualification if there exists no direction p  X  X  v along which the subdifferentials of equality and active inequality constraints are all zero. Let the condition is: where C h and C g are, respectively, the sets of indices of equality and active inequality constraints. This qualification is always less restrictive than the KKT regularity condition.
The following theorem gives a necessary and sufficient con-dition for CLMs of NLPs.

Theorem 1. Necessary and sufficient extended saddle point condition on CLM of P c . Suppose x  X   X  X  v satisfies the con-straint qualification, then x  X  is a CLM of P c if and only if there exist finite  X   X   X  0 and  X   X   X  0 such that, for any  X   X  X  X  &gt; X   X  and  X   X  X  X  &gt; X   X  , the following condition is satisfied: for all x  X  X  CN ( x  X  ) ,  X   X  X  m ,and  X   X  X  r .

Theorem 1 differs from the traditional saddle point (SP) condition [1] in a significant way. The traditional SP condi-tion is based on a Lagrangian function and works only for NLPs with continuous and differentiable constraints. Fur-ther, the SP condition is true at unique Lagrange multipli-ers. In contrast, ESP based on the m 1 function works for discontinuous, non-differentiable NLPs and it suffices to find any  X   X  X  X  &gt; X   X  and  X   X  X  X  &gt; X   X  . Computationally, it is much easier to find  X   X  X  X  and  X   X  X  X  in an extended region than finding unique Lagrange multipliers as required by the traditional Lagrangian theory.

Figure 3 shows a general framework that implements the conditions in Theorem 1. The inner loop looks for local min-ima of L c ( x,  X ,  X  ) in the continuous neighborhoods, whereas Figure 3: Iterative implementation of ESP search for locating CLM of P c .  X   X   X  and  X   X   X  are pre-defined upper bounds. the outer loop performs ascents on  X  and  X  for unsatisfied constraints and stops when a CLM has been found.
 Significance of the ESP condition. The ESP condi-tion has several salient advantages over previous constraint handling theory. Unlike the Karush-Kuhn-Tucker (KKT) condition in the Lagrangian theory that works only for con-tinuous and differentiable problems, ESP condition offers a uniform treatment to discrete and mixed problems and does not require the constraints to be differentiable or in closed form. More importantly, unlike the KKT condition that requires finding a set of unique Lagrange multipliers which are oftentimes hard to locate exactly for large prob-lems, ESP condition is satisfied over an extended region of penalty values. In fact, ESP condition is true for any  X   X  X  X  &gt; X   X  and  X   X  X  X  &gt; X   X  ,where  X   X  and  X   X  are finite thresh-olds. Experimental results on discontinuous planning and engineering problems [20, 21] suggest that it is generally much easier to locate suitable penalty values in an extended region than to find the exact Lagrange multipliers.
The ESP condition result is also stronger than the KKT condition in the sense that KKT condition is only necessary but not sufficient. That is, any qualified CLM satisfies the KKT condition, but a point satisfying the KKT condition may not be a CLM . Thus, an algorithm converging to a KKT point may not find a CLM .
We develop a solver that solves the constrained problem (6) based on the ESP search framework in Figure 3. We have recently developed CRF-OPT [4], a package for general unconstrained CRF training, on top of the Toolkit for Ad-vanced Optimization (TAO) [2]. CRF-OPT uses the Limited Memory Variable Metric (LMVM) method, a quasi-Newton method, as the unconstrained optimization algorithm. We develop our constrained CRF solver on top of CRF-OPT. The m 1 -penalty function of (6) is:
Our ESP algorithm consists of two loops. The outer loop updates  X  and the inner loop minimizes L c ( W,  X  )inthe W -space using the LMVM method in TAO. The quasi-Newton X  X  method, LMVM, requires the objective and gradient infor-mation of L c ( W,  X  ) and approximates the inverse Hessian to generate descent directions. Since g j ( W ) is not differen-tiable, we approximate its gradient as follows.

The partial derivative of L c ( W,  X  ), with respect to weight Figure 4: Change of weights influences the most likely sequence selected by the Viterbi algorithm. See text for explanation.  X  ,k =1 ..K , can be expressed as:
The first term,  X  O ( W )  X  X  k , is the gradient of the original ob-jective, and can be calculated efficiently by the forward-backward algorithm [18]. We now focus on computing  X  X  The first term of ( 12) is needed because the most likely sequence  X  y ( j ) of the vali-dation set V ( j ) depends on  X  k .

Figure 4 illustrates the mechanism of the Viterbi algo-rithm and how the change of  X  k will affect the counts of features. Define feature f k as, Let S be the set of possible states ( S = { s 1 ,s 2 ,s 3 ure 4) and let the length of the sequence be T . Before back-tracking, Viterbi will do a forward run. For each state y at time t , it finds out the state at time t  X  1 that will most likely lead to this state, as shown in blue arrows in the figure. Also, the highest probability of reaching state y at time t is remembered in  X  ( t, y ). Then, Viterbi backtracks from time T by starting from the state y ,  X  ( T,y )  X   X  ( T,y ) ,  X  and follows the red arrows in the figure. Let t 1betheposi-tion where the backward process differs. As we change the weight of  X  k , Viterbi finds that state s 1 at time t 1  X  a better chance to lead to s 2 , and backtracks in a different path and changes the labels  X  y t ( j ) ,t  X  [1 ,t 1  X  1] , as shown in green arrows. As a result, the satisfiability of all the fea-tures, not only feature f k , will be changed. The direct effect of changing weight  X  k is the change of the satisfiability of feature f k . That is, the origin of the change is when at one position t where f k ( X  y ( j ) t ,  X  y ( j ) t  X  1 , v ( from 1 to 0.

Note that, in the Viterbi algorithm, most of the computa-tional time is spent on the forward run, and the backtracking process requires little time. Hence, we want to avoid repeat-edly carriyng out the forward runs when approximating the discontinuous term (13).

We detail our approximation scheme when weight  X  k is increased as follows. The case when  X  k is decreased is sym-metric.

For a feature f k ( y ,y, v ), we find out the positions t where v t = v , X  y set of such positions that, when  X  k increases, f k ( X  y ( will change from 0 to 1.

The reason for us to require v ( j ) t = v is that, at each posi-tion t , the feature f k ( y ,y, v )issatisfiedif X  y ( j ) and v ( j ) t = v . Since the observation sequence v ( j the change of the weight  X  k can only affect the changes of the labeling sequence  X  y ( j ) found by the Viterbi algorithm. Therefore, if at time t , v ( j ) t = v , then a change of  X  lead to a change in the satisfiability of f k ( X  y ( j ) t
We require  X  y ( j ) t = y because Viterbi algorithm works in a backtracking way, and the precondition of satisfying the transition ( y ,y )istolet X  y ( j ) t = y . As we assume the weights for other features are fixed when we do approximation, if  X  y t = y , then there is no way change of  X  k can change f
The reason for us to require  X  y ( j ) t = y is obvious. If  X  y y , y has already been chosen as the preceding state for y , then the feature f k has already been satisfied. Increasing the weight  X  k will have no effect on the configuration of the most likely sequence.

For each t  X  X  k , we compute the minimum increase  X  t  X  k of  X  k required to make y the preceding state of y .Let X  y be the preceding state of y originally selected by the Viterbi algorithm.  X  t  X  k can be efficiently calculated from  X  ( y, t  X  ( X  y, t  X  1), and the weights of other active features at time t .

Then, we find the position t satisfying,  X  t  X  k  X   X  t  X  k P k and increase  X  k by  X  t  X  k . By doing so, only the preceding state of y at time t is changed to y . For all the other po-sitions t  X  X  k ,sincetheincreaseof  X  k does not reach their minimum requirement, the configuration will remain the same. Then we can backtrack from y at time t  X  1andeffi-ciently find the most likely sequence, without performing the forward part of the Viterbi algorithm. After having the new most likely sequence, we can acquire the change of counts for all the features with respect to the change of  X  k .The changes are store in a vector  X  A = {  X  A 1 ,  X  A 2 ,  X  X  X 
Finally, we approximate the first term of (12) as shown in (13) by X where c&gt; 0 is a constant for avoiding excessively large derivatives.

Convergence analysis. Since LMVM uses the Armijo stepsize rule [2], convergence to local minimum of L c ( W,  X  ) of the inner loop is guaranteed under very relaxed assump-tions, so long as the direction at any step is a descent direc-tion. Our experience shows that the quasi-Newton directions generated by LMVM, based on the gradient in (11) and (12) always give descent directions of L c ( W,  X  ) at each iteration of LMVM. Therefore, the inner loop converges to a local minimum of L c ( W,  X  )forafixed  X  .

In the outer loop, we update the penalties by where m is the outer loop number.
 Proposition 1. Suppose there is a CLM of(6)thatsatisfies the constraint qualification, then the ESP search algorithm finds a CLM of (6) in a finite number of outer loops, if the inner loop minimizes L c ( W,  X  ) at each major iteration.
We give a sketch the proof here. Consider any CLM W  X  of (6). Since W is a CLM ,wehave, f ( W )  X  f ( W )and g ( W  X  )  X  0, for any infeasible W  X  X  CN ( W ), we can show that there exists a finite threshold  X   X  &gt; 0 such that
L c ( W In a finite number of major iterations,  X  m can exceed any finite threshold  X   X  using the update rules in (15) and (16). Let W m be he point the inner loop stops. Then, as long as the inner loop minimizes L c ( W,  X  ), W m is feasible. Thus, we have g + ( W m ) = 0 and, for any  X   X  X  V , On the other hand, we have Combining (18) and (19) and applying Theorem 1, we see that ( W m , X  m ) is an ESP point and hence W m is a CLM .
Noted that theoretically LMVM guarantees local optimal-ity while Proposition 1 requires global optimality of the un-constrained solver. Empirically, our solver can always sat-isfy the cross-validation constraints in less than 20 major iterations. Since ESP search allows an extended region of suitable penalties, the solver is not sensitive to the penalty update rules. In contrast, it is difficult to control the single penalty in a traditional 1 -penalty function when there are many constraints.
We present experimental results on two applications. We compare the original CRF-OPT package built in TAO with a new version that uses the constrained formulation and solver. We set  X  =0 . 01 for all runs.
Given a DNA observation sequence, consisting of  X  X  X ,  X  X  X ,  X  X  X ,  X  X  X  bases, the aim of gene prediction is to find out the protein coding regions, known as genes, and their associated components, including coding exons, start/stop exons, pro-moters, and poly-adenylation sites [3]. We first illustrate the improvement of the constrained approach on a simple model and then report results on a state-of-the-art gene predictor.
Figure 5 shows a finite state machine representation of the structure of genomic sequences in our implementation. Table 1: The performance of original CRF, regularized CRF (CRF Figure 5: A finite state machine for gene prediction In this model, each node represents a hidden state, such as exon ( C ), intron ( I ), and intergenic region ( NC ). In our model, the introns and exons are further divided into three phases according to the reading frame. Each edge represents a possible hidden state transition with required base observation.

The features used in our model is the state transition and base observation requirement as represented by the edges in Figure 5 and a 5-th order base emission information. In total we have around 7  X  4 6 features.

We test our algorithm on DNA sequences from the pathogenic fungus cryptococcus neoformans. We evaluate performance at the following four different levels: nucleotide-level, exon-level, transcript level, and gene level. For each level, we use the standard sensitivity (Sn) and specificity (Sp) measures defined as Sn = TP TP + FN and Sp = TP TP + FP ,whereTP,FN, FP denote the numbers of true positive, false negative, and false positive labels, respectively [3].
 In Table 1, we compare the performance of the constrained CRF and CRF with regularization. We set the regulariza-tion parameter  X  2 = 100. We use all the 170 genes to con-struct four different data sets. We randomly split the data into 75% training data and 25% test data. For each set, three validation sets, each with 1 / 3 length of the training set, are constructed from the training data.

As shown in the result, our constrained CRF gives bet-ter performance than the unconstrained CRF model using the same feature set. Comparing to the regularization ap-proach, our method has a notable performance boost, es-pecially for the higher-level gene, transcript, and exon level measures. The higher level accuracy is typically more diffi-cult to achieve than the nucleotide level accuracy. To achieve one gene level accuracy will require thousands of consecutive correct predictions on the nucleotide level. The computing time of constrained CRF is about 3 to 4 times longer than unconstrained CRF.

Although the gene prediction model used in previous ex-periment is still a much simplified one, the results show the effectiveness of the proposed work. In the following ex-periment, we integrate these techniques to CONTRAST, a state-of-the-art CRF-based gene predictor [8] to predict fly genomes. By effectively making use of multiple informants, CONTRAST is able to show substantial improvement over previous de novo gene predictors. The main component of this gene predictor is a CRF model with 33,003 features and 41 possible states. Similarly, we constructed validation sets, and added cross-validation guided constraints to the original formulation in CONTRAST. The performance is compared to CONTRAST without regularization, and CONTRAST with regularization terms added. For CONTRAST with reg-ularization, a validation set is reserved and used to tune the regularization factor.

As shown in Table 2, both regularized formulation and our constrained formulation perform better comparing to the original unconstrained formulation. In most of the cases, our constrained formulation is able to improve the gene level accuracies by over 5% percentages, and better than the reg-ularized formulation. We also find that our constrained for-mulation is able to converge with less iterations than that of the regularized formulation.
In this application, we try to predict if tomorrow X  X  stock price will raise or decrease comparing to today X  X , based on historical stock price data. One thing to note is that, the prediction accuracies presented in this section is on the fil-tered stock price data, which has been smoothed, not the raw data.

In this task, the training sequence grows everyday, while the length of the testing sequence is only one, since we only try to predict for the next day. As the raw stock price data is noisy, we apply several preprocessing techniques, includ-ing stock screening, filtering, and transformation. Certain techniques are used later on to map the prediction results of smoothed data back into raw data.
 Here we only focus on the prediction of smoothed data . For each stock, the preprocessed data is stored in sequence ( r , y ), where the observation r is the sequence of price change ratio, and y is the labeling sequence. Given the sequence ( r 1  X  X  X  r T ; y 1  X  X  X  y T ), we try to predict y T +1 . In our applica-tion, y t  X  X  0 , 1 } represents Raise or Fall. We use a 3rd order Table 2: The performance of original CRF, regularized CRF (CRF feature function, We divide the price changing ratio into several ranges. Each atom of the feature function is true when the changing ra-tio falls into the corresponding range. When all the atoms return true, the feature is true. In total, 2000 features are included to aid learning.

We test our algorithm on 1741 stocks that are selected by our stock screening algorithm from all stocks in NASDAQ and NYSE, each of which contains the stock prices from 2002-02-01 to 2007-09-12. For each stock, when we try to predict the price tendency of day T + 1, the data from day 1 to T is used for training. After that, the stock price on day T + 1 and the real price tendency on that day is added to the training sequence for predicting day T + 2. The process is repeated until the last day. We start our prediction on 2006-05-16. For our constrained formulation, the validation sequence is a sequence of data right before the predicted day. If we want to predict the price on day T + 1, the validation sequence will be the data from day T  X  V +1 to T ,where V is the length of the validation sequence. We have set V = 100. Figure 6: The prediction accuracies before and after adding constraints.

We classify the 1741 stocks into different categories ac-cording to the prediction accuracy of the unconstrained CRF. For stocks in each category, we calculate the average predic-tion accuracy of the original CRF model and the constrained CRF model. As shown in Figure 6, the constrained CRF gives much better accuracy when the original unconstrained formulation has low accuracy ( &lt; 85%) and is comparable in other cases. The prediction accuracy of constrained CRF is consistently above 82% for all categories. Note that the accuracy is for predicting smoothed stock price curves. We can achieve around 55%-63% accuracy after translating the prediction back to raw prices. For each stock, the average training time is 25.5 seconds for the unconstrained CRF and 97.5 seconds for the constrained CRF.
In this paper, we present a novel constrained formulation for CRF training. Constraints reflecting cross-validation ac-curacies are added to prevent overfitting and to boost the generalizability of CRF models. The new formulation is dif-ficult since it is discontinuous and nondifferentiable, and classical Lagrangian methods are not applicable. We de-velop a new constrained optimization algorithm based the recently proposed ESP theory to solve the problem. The constrained formulation and optimization algorithm are ap-plied to gene prediction and stock price prediction tasks. The results show that our method is able to achieve sig-nificantly better prediction quality than unconstrained for-mulations, both with and without regularization. The CRF models with constrained formulation can improve the qual-ity of a leading gene predictor as well as give high accuracy for predicting smoothed stock prices. This work is supported by NSF grant IIS-0713109, a DOE ECPI award, and a Microsoft Research New Faculty Fellow-ship. [1] M. Avriel. Nonlinear Programming: Analysis and [2] S. J. Benson, L. McInnes, J. Mor  X  e, and J. Sarich. TAO [3] C. Burge. Identification of genes in human genomic [4] M. Chen, Y. Chen, and M. Brent. CRF-OPT: An [5] S. Chen and R. Rosenfeld. A gaussian prior for [6] A. Culotta, D. Kulp, and A. McCallum. Gene [7] G. GRIMMETT. A theorem about random fields.
 [8] S. S. Gross, C. B. Do, M. Sirota, and S. Batzoglou. [9] R. Kohavi. A study of cross-validation and bootstrap [10] J. Lafferty, A. McCallum, and F. Pereira. Conditional [11] W. I. Newman. Extension to the maximum entropy [12] A. Quattoni, M. Collins, and T. Darrell. Conditional [13] B. Roark, M. Saraclar, M. Collins, and M. Johnson. [14] R. Rosenfeld. A maximum entropy approach to [15] S. Sarawagi and W. Cohen. Semi-markov conditional [16] F. Sha and F. Pereira. Shallow parsing with [17] C. Sminchisescu, A. Kanaujia, Z. Li, and D. Metaxas. [18] C. Sutton and A. McCallum. An introduction to [19] D. L. Vail, J. D. Lafferty, and M. M. Veloso. Feature [20] B. Wah and Y. Chen. Solving large-scale nonlinear [21] B. Wah and Y. Chen. Constrained partitioning in [22] B. Wah and M. Qian. Constrained formulations for
