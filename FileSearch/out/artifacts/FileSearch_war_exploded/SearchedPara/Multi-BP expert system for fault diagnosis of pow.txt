 Deyin Ma, Yanchun Liang, Xiaoshe Zhao, Renchu Guan, Xiaohu Shi n 1. Introduction
In modern times, power system becomes larger and more complex than before. With its fast development, higher demand for the sustainability and stability of power system is of great requirement. However, some common faults in power system have never been resolved very well and are still hindering the stability of power system, such as transmission fault, network distribution fault, power variable fault ( Mizutani et al., 2007 ). Sometimes, even only one fault could destroy the equipments in power system, and might affect the whole power system. An even worse damage could cause conflagration and casualties, and leading to a huge pecuniary loss. Therefore, it is of great significance to do researches for preventing those faults from power system. And fault diagnosis is a powerful tool to guarantee the safety and reliability of power system.

In power system, transformer is a kind of major equipment and plays an important role in power transmission. It can raise voltage so that power can be transported to the user with less loss. On the other hand, the transformer can reduce power into different voltage levels, which can satisfy variety needs of users. Because of its complex structure and function, transformer is tending to cause fault. Unfortunately, transformer fault is very difficult to predict. Moreover, if some accidents take place in transformer, the whole system has no choice but to stop to check and maintain the equipments. Therefore, it is believed that keeping the transformer running in perfect situation plays a key role in power system diagnosis ( Lin and Zeng, 2009 ). High voltage circuit breaker (over 3 kV) is another important element in power system. It has two main functions, namely controlling and protecting. Firstly, it decides when and which parts of the power system should be started or stopped according to the require-ments; secondly, when some errors occur in power networks or equipments, the high voltage circuit breaker will quickly break off the error parts from power system, so that other parts can work without influence. In other words, high voltage circuit breaker is able to control the normal current in power lines, and to deal with the overload current, short-circuit current and other abnormal current within a limited time. When a mistake happens in high voltage circuit breaker, it will usually expand to other parts of the power system and finally lead to a worse accident.

There are some classical artificial intelligence technologies have been used in power system fault diagnosis, for example: the expert system ( Ma et al., 2010 ), artificial neural networks ( El-madany et al., 2011 ; Zhu et al., 2006 ; Huang et al., 2002 ; Karthikeyan et al., 2005 ), decision tree theory ( Qu and Gao, 2008 ) etc. In recent years, some new theories have been applied in this field, such as data mining ( Athanasopoulou and Chatziathanasiou, 2009 ), fuzzy set theory ( Lee et al., 2000 ; Zhang et al., 2010 ), rough set theory ( Li and Wang, 2010 , Li et al., 2011 ), petri-network ( Yang et al., 2004 ), support vector machine ( Eristi and Demir, 2010 ), multi-agent systems ( Zaki et al., 2007 ), and so on. Li and Liu had performed a comprehensive review of the above-men-tioned methods ( Li and Liu, 2010 ). They pointed out that there are some problems in the existing intelligent fault diagnosis expert system theology, such as the difficulty for knowledge gaining and managing, low on-line usage of fault diagnosis, high error rate, poor efficiency of inference process, and so on. Back propagation neural network (BPNN) expert system is an often used method in fault diagnosis. In real applications, BPNN usually has many layers. However, the training time of BPNN will grow exponen-tially with the layer number increasing. While more serious problem is that it is difficult to converge when BPNN has a large number of layers. Another problem is that the diagnostic accuracy of BPNN is still not satisfied. To solve those problems, we propose a so called multi-BP expert system (MBPES) method. In MBPES, the whole BPNN networks are divided into many sub-BP groups within a short depth, saying about 5 layers. In this manner, the consumed training time is greatly reduced and it is easy to achieve the convergence of the training process.
 In the experiments, we firstly compare the performance of BPNN with different number layers according to a XOR problem.
Numerical results show that when the layer number is more than 6, BPNN is very time consumed and even hard to converge. To test the effectiveness of the proposed MBPES method, it is applied to two real power system data sets, namely that the transformer data set and high voltage circuit breaker data set. Experimental results show that MBPES is very efficient, and it is more accurate than two other compared methods. 2. Back propagation expert system
Back propagation (BP) algorithm is one of the most classical and successful learning methods of feed forward artificial neural network, which is based on gradient descent algorithm. For its success, those feed forward neural networks using BP algorithm are always called BPNNs. Fig. 1 shows an architecture of BPNN model with K hidden layers. There are n nodes in the input layer, which is corresponding to the sample vector X  X  dimension. And the inputs of the input layer are the components of the sample X  X  vector. Denote the node X  X  number of the j th hidden layer as N then the outputs of first hidden layer are
Y  X  And the outputs of the other hidden layers are
Y  X 
Suppose the related problem has m expected outputs, then the output layer should have m nodes, and their outputs are
Z  X 
Here w ji is the weight between the j th node of one layer and the i th node of its former layer. The weights should be trained before application. The training method could be referred to Rumelhart et al. (1986) .

BPNN also can be used as an expert system, which is called back propagation expert system (BPES). In BPES, the rules with the form of IF-THEN in knowledge database are represented by the weights of networks. An example of BPNN expert system is shown as Fig. 2 .In the networks, the nodes represented by rectangles are the ante-cedents or consequents of the rules, while the nodes represented by circles are corresponding to the rules. The initial structure of the networks is generated by rules in knowledge database, as well as the values of the weights. If we could obtain enough known sample data, the weights can be improved by training process, even the topology of the networks might be amended. The training algorithm isthesameasthatofBPNN.

In BPES networks, each rule creates a 3-layer sub-network. The first layer represents the antecedents of the rule, the second layer represents the transform relationship including only one node, the third layer represents consequent of the rule, also including one node. Therefore, the nesting of different rules may extend the length of the network structure. Unfortunately, it is often the case in the knowledge database. However, when the BPNN networks have more than 5 layers, the training time and iteration number will grow exponentially and even hard to converge. To solve such problem, a called Multi-BP Expert System (MBPES) is proposed in this paper, in which the networks are divided into sub-networks with small scale. 3. Multi-BP expert system (MBPES) 3.1. The structure of MBPES
In a BPNN, a rule is corresponding to a substructure of the networks with 3 layers. Accordingly, 2 and 3 nested rules are corresponding to a substructure with 5 and 7 layers, respectively.
Because those BPNN networks with more than 5 layers are difficult to train and even hard to converge, we divide the whole networks into sub-networks with 5 or less layers. Fig. 3 shows the division of a BPNN in serial structure.

However, in real applications, rules are not always nested in serial. For example, the inputs of a rule might be the outputs from other 2 or more rules. For 2 independent rules, the accordingly sub-networks are in parallel. Moreover, the inputs of a rule could come from different rules in different layers. For such a compli-cated BPNN, we also need to divide it into sub-networks with 5 or less layers, namely that Multi-BP expert system (MBPES). A classical structure of MBPES is depicted as Fig. 4 . 3.2. The construction algorithm of MBPES
Given a knowledge base, the structure of the MBPES should be determined firstly. To begin with the construction algorithm of MBPES, we look at how to build up a digraph from only one rule ( Shi et al., 2006 ). Denote an empty digraph as F , and assume we have a rule R 1as R 1: IF a 1 AND a 2 THEN b 1 (0.8)
Then, R 1 could be input into F , and a new digraph D is created which is shown as Fig. 5 .

Next, if we have rules which have antecedents or consequents associated with D , they could be added into the digraph. For instance, in Fig. 6 there are seven rules (from R 2to R 8) having related antecedents or consequents to digraph D . Then D can be updated as Fig. 7 shown, which has 5 layers.

However, when more rules are added into digraph, it might exceed 6 layers. Taking aforementioned rules as an example, the antecedents of the following rule R 9 are associated with D : R 9: IF c 1 AND c 2 THEN c 3 (0.8).

But if R 9 is added into D directly, it will be changed into 7 layers. Therefore it is divided into 2 sub-digraphs according to the 5th layer. It is shown in Fig. 8 .

Now considering a knowledge database KD which includes N rules, a MBPES could be built up similarly. Denote R i is the i th rule in KD ( i  X  1,2, y , N ), D is the digraph, D k is the k th divided sub-digraph ( k  X  1,2, y , j ), j is the number of sub-digraphs, L the layer number of D k . Then the main steps of the construction algorithm are described as follows: (1) Initialization: Set i  X  1, j  X  1, D 1  X  F , D  X  { D 1 (2) Determination: If all the rules in KD have been read, namely (3) Input of rule R i : (3.1) Search R i in sub-digraphs.

If ( k , s.t. the antecedents or consequents of R i are related to sub-digraph D k , then check if D k has more than 5 layers. If yes, j  X  X  , create a new sub-digraph D j , input R i into D j , else, input R into D k . go to step (3.3). (3.2) Create a new sub-digraph for R i .

If 8 k , the antecedents or consequents of R i are not related to sub-digraph D k , j  X  X  , create a new sub-digraph D j , input R
D j , go to step (3.3). (3.3) i  X  X  , go to step (2).

The flowchart of the algorithm is depicted in Fig. 9 . 3.3. The training algorithm of MBPES
The constructed MBPES could be considered as a weighted digraph. However, there are lots of noises in the rules saved in KD .
So a training process is necessary to improve the accuracy of the system. By the training process, the weights in digraph are updated according to a real data set, which are more reliable compared to the rules in KD . Even some weights can be deleted and some new ones can be added.

Assume there are J sub-digraphs in MBPES D . Denote D k as the k th of sub-digraphs, N k the output number of D k , T k j expected output and the j th real output of D k , respectively. Then the main steps of the training algorithm are as follows: (1) For each sub-digraph D k ( k  X  1,2, y , J ), define an error function as
E (2) According to the basic BP training algorithm, train each sub-digraph D k . (2.1.) If E k reaches a value less than the error threshold E (2.2.) Else, if E k could not decrease below to E thr within the (3) When all the sub-digraphs finish the training procedures, update the whole structure of MBPES. 4. Results and analysis 4.1. Comparison for different network layer numbers
To test the performance of BPNNs with different layer number, we take XOR problem as an example. In the experiment, the main parameters are set as follows: the inertial weight a is 0.5, the momentum coefficient Z is 0.9, the threshold b is 0.5, and the error threshold E thr is 0.001, respectively. To get the statistical results, each experiment is repeated for 100 times. Numerical results are shown in Table 1 and Fig. 10 . From Table 1 and Fig. 8 , we can see that the training time is raising with the increasing of
BPNN layer X  X  number. On the contrary, the convergence rate is falling in a converse manner. It is noteworthy that there is a steep slope between the layer numbers 5 and 6 for both training time and convergence rate. When the layer number is more than 5, training time for BPNN is increasing exponentially and the convergence rate is decreasing sharply. In fact, that is just the 1.0 1.0 1.0 1.0 0.5 4.2. Experiment on transformer data
Our experimental data used in this section are the real data from the on-site transformer in an electric power design institute. The rules in knowledge base are provided by the engineers in the institute and arranged by authors. There are more than 1200 knowledge rules, of which more than 700 rules are about transformer fault diagnose. For comparison, BPNN, BPES and our proposed MBPES methods are all applied as the inference engines, respectively. There are 150 sample data in all, 100 of which are set as the training data and the other 50 ones are set as the testing data. The first 15 sample data are shown in Table 2 . Each sample contains 8 gas acquisition data (in the unit of m L/L), namely H CH which indicates the real fault type of the sample. In our experi-ment, there are five real fault types: final superheater, medium superheater, primary superheater, spark discharge and arc dis-charge ( Wang et al., 2006 ) etc. For the preprocessing procedure, the values of the eight gas acquisition data are normalized into interval [0,1] using the following equation: y  X  where y i , y min , y max represent the original i -th sample data, the minimum and maximum values of all of the samples with the same input attribute respectively, and y i indicates the normalized i -th sample data.
 Firstly, according to the construction algorithm proposed in Section 3.2 , an MBPES structure has been built using the 700 rules which are related to transformer fault diagnose. And then it is updated according to the learning algorithm in Section 3.3 . The final topology of MBPES is shown as Fig. 11 . It is interesting that our groupment result is highly consistence with the theoretical results in Li (2010) about the relationship between fault type and the partition of gas inputs.

To test the effectiveness of MBPES, it is compared with BPNN and BPES on the prediction results of the 50 test sample data. The comparison results are shown in Table 3 . From the table, it could be found that the correct predicted diagnosis record numbers of BPNN, BPES and MBPES are 39, 40 and 43, with the accuracy rates R R of 78%, 80% and 86%, respectively. Obviously, MBPES outperforms the other two compared algorithms. Taking the first record in Table 2 as an example to describe the output of MBPES, the predicted diagnosis result is  X  X  X inal superheater X  X  which is just met the real fault type of the sample. Furthermore, MBPES gives an advice for the fault type as (1) Please check the wire connector to see whether it is badly (2) Please check the current of iron core touching floor. (3) Please check the iron core insulation resistance. (4) Please check DC Resistance. 4.3. Analysis of vacuum circuit breaker experimental data Similarly as stated in Section 4.2 , MBPES is compared with BPNN and BPES in another real data set in this section. The experimental data are from a power plant, which are related to high voltage vacuum circuit breaker. There are 300 rules and 120 sample data in all. 80 of the sample data are used for learning and the other 40 data are used for testing. Table 4 lists the first 15 sample data, each of them contains 3 current data ( I 1 , I t , t 4 and t 5 are five time points, and the current variation within each time range could reflect mechanics transmission system X  X  working performance. I 1 , I 2 and I 3 are the current values corre-sponding to time points t 1 , t 2 and t 4 , respectively. In this experi-ment, there are 6 real fault types: running properly (ZC), power in low (GD), Jam in the beginning (HKS), Jam in operation mechanism (CHK), Iron core idle running too long (TD), Auxiliary switch contacts badly (FK) ( Lei and Liu, 2010 ). The same as the above experiment, the values are also normalized according to Eq. (5).
According to the construction algorithm and learning algo-rithm, we obtain the final MBPES structure. A sub-digraph is shown as Fig. 12 . Wang had described that the Jam related faults (HKS and CHK) are relevant to the current values at time points t and t 2 ( Wang, 2008 ). Analyzed the inputs and the outputs of the sub-digraph in Fig. 12 , we could find that it is highly concordant with Wang X  X  conclusion.

The comparison results of MBPES, BPNN and BPES are shown in Table 5 . The accuracy rates of BPNN, BPES and MBPES are 80%, 82.5% and 90%, respectively. MBPES is also better than the other two compared algorithms. Taking the first record in Table 4 as an example, the predicted diagnosis result is  X  X  X uxiliary switch contacts badly (FK) X  X , the same with the real fault type of the sample. And an advice for the fault type is given as (1) Please check all the possible leaking points and block them. (2) Please install sealing sleeve in the output link. (3) Please open the heating and drive wave device in the box. 5. Conclusions
In this paper, facing the real data in transformer and high voltage breaker, with serial, parallel and hybrid grouping algo-rithm, we proposed two typical new Multi-BP networks. More-over, they successfully solved the problem of low convergence speed caused by the large number of network layers and also greatly increased the speed of diagnosis. Furthermore, by the comparison with BPNN and BPES, we can see that the results from Multi-BP are more accurate. Using multi-BP network to diagnosis power system, not only can we diagnose the transformer online and offline, but also the system will give us the diagnosis advice quickly.
 Acknowledgment This work was supported in part by the National Natural Science Foundation of China (61073075, 61103092), China Post-doctoral Science Foundation (2011M500613), the Science-Tech-nology Development Project from Jilin Province (20120730, 201215022), Special Fund for Basic Scientific Research of Central Colleges, Jilin University (no. 201103036).
 References
