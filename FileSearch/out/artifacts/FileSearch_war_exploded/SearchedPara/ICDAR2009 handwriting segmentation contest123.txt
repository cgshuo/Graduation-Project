 ORIGINAL PAPER B. Gatos  X  N. Stamatopoulos  X  G. Louloudis Abstract ICDAR 2009 Handwriting Segmentation Contest was organized in the context of ICDAR2009 conference in order to record recent advances in off-line handwrit-ing segmentation. The contest includes handwritten docu-ment images produced by many writers in several languages (English, French, German and Greek). These images are manually annotated in order to produce the ground truth which corresponds to the correct text line and word segmen-tation result. For the evaluation, a well-established approach is used based on counting the number of matches between the entities detected by the segmentation algorithm and the entities in the ground truth. This paper describes the con-test details including the dataset, the ground truth and the evaluation criteria and presents the results of the 12 partici-pating methods as well as of two state-of-the-art algorithms. A description of the winning algorithms is also given. Keywords Handwritten text line segmentation  X  Handwritten word segmentation  X  Document image processing evaluation 1 Introduction One of the most important and challenging tasks in a handwrittenrecognitionpipelineisthesegmentationofhand-written document images into text lines and words. Several problems inherent in handwritten documents such as the dif-ference in the skew angle between text lines or along the same text line, the existence of adjacent text lines or words touching, the existence of characters with different sizes and variable intra-word gaps seriously affect the segmentation and, consequently, the recognition accuracy. Therefore, it is imperative to have a benchmarking dataset along with an objective evaluation methodology in order to capture the effi-ciency of current and new practices in handwritten document segmentation.

Following the successful organization of the ICDAR 2007 Handwriting Segmentation Contest [ 1 ], we organized the ICDAR 2009 Handwriting Segmentation Contest in order to record recent advances in off-line handwriting segmentation. Two new benchmarking datasets, one for text line and one for word segmentation, were created in order to test and compare recent algorithms for handwrit-ten document segmentation in realistic circumstances. For the evaluation, a well-established approach that is also employed by other document segmentation contests [ 1  X  3 ] is used.
 The remainder of the paper is organized as follows. In Sect. 2 , the contest details and an overview of the datasets are described, while, in Sect. 3 , the performance evaluation method and metrics are described. Each of the participating methods is summarized in Sect. 4 and the results of the competition are presented in Sect. 5 . Finally, the winning methods for line and word segmentation are detailed in Sect. 6 , and the conclusions are drawn in Sect. 7 . 2 The contest In this contest, we focused on the evaluation of text line and word segmentation methods using a variety of scanned hand-written documents. Based on these documents, we manually annotated the ground truth for text line and word segmen-tation and created the benchmarking datasets. The authors of candidate methods registered their interest in the compe-tition and downloaded the training dataset (100 document images and associated ground truth from the ICDAR 2007 Handwriting Segmentation Contest [ 1 ]) as well as the corre-sponding evaluation software. At a next step, all registered participants were required to submit two executables (one for text line segmentation and one for word segmentation). Both the ground truth and the result information were raw data image files with zeros corresponding to the background and all other values defining different segmentation regions. After the evaluation of all candidate methods, the testing dataset (200 images and associated ground truth) along with the evaluation software became publicly available [ 4 ].
The documents used in order to build the training and test datasets came from several writers that were asked to copy a given text. All documents did not include any non-text elements (lines, drawings, etc.) and were written in several languages (English, French, German and Greek). The test set was created with the help of 50 writers that were asked to copy 4 pages each one corresponding to a different language. As a result, several produced documents are not written in the native language of the writer. A sample of a handwritten doc-ument image which is part of the test set and samples of text line and word segmentation ground truth annotations can be seen in Fig. 1 . As it can be observed from Fig. 1 , since there were no guidelines given to the writers, the produced images contain all challenging problems for handwritten document segmentation, e.g. difference in the skew angle between text lines or along the same text line, existence of adjacent text lines or words touching, existence of characters with differ-ent sizes and variable intra-word gaps. 3 Performance evaluation The performance evaluation method used was based on counting the number of matches between the entities detected by the algorithm and the entities in the ground truth [ 5 ]. We used a MatchScore table whose values are calculated accord-ing to the intersection of the ON pixel sets of the result and the ground truth.

Let I be the set of all image points, G j the set of all points inside the j ground truth region, R i the set of all points inside the i result region, T ( s ) a function that counts the elements of set s . Table MatchScore ( i,j ) represents the matching results of the j ground truth region and the i result region: MatchScore ( i , j ) = We consider a region pair as a one-to-one match only if the matching score is equal to or above the evaluator X  X  accep-tance threshold T a .If N is the count of ground-truth elements, M is the count of result elements, and o2o is the number of one-to-one matches, we calculate the detection rate (DR) and recognition accuracy (RA) as follows: DR = A performance metric FM can be extracted if we combine the values of detection rate and recognition accuracy: FM = A global performance metric SM for handwriting segmen-tation is extracted by calculating the average values for FM metric for text line and word segmentation.

The performance evaluation method is robust and well established since it is also employed by other document seg-mentation contests [ 1  X  3 ]. It depends only on the selection of the acceptance threshold T a . For this reason, in Sect. 5 we also report on experiments using various acceptance thresh-olds values ( T a ) . 4 Methods and participants We had 12 submissions to the competition, while 4 of them included only a text line segmentation methodology. Brief descriptions of the methods are given in this section. 4.1 CASIA-MSTSeg method Submitted by F. Yin, X.D. Zhou, Q.F. Wang and C.L. Liu of the Institute of Automation of Chinese Academy of Sciences (CASIA) in Beijing, China, and based on [ 6 ]. Con-nected components are first split based on several geometric constraints and then grouped into a tree structure by the min-imal spanning tree (MST) algorithm with the distance met-ric designed by supervised learning. Text lines are extracted from the tree by dynamically cutting selected edges. Con-cerning word segmentation, for each gap between adjacent connected components in a line, 11 geometric features are extracted and fed to an SVM classifier for classifying gaps into between-word and within-word ones. 4.2 CMM method Submitted by A. Hassa X ne and B. Marcotegui of the Cen-ter of Mathematical Morphology in Paris School of Mines, France. A first labeling of the image is applied using the mini-mum number of horizontal intersections with the text. Cases of components with several labels or with labels that have to be merged are then handled based on several rules. For word detection, the average distance between the bounding boxes of the connected components of each line is computed. A distance is considered to be an inter-word distance if it is larger than a threshold. 4.3 CUBS method Submitted by Z. Shi, S. Setlur and V. Govindaraju of the Center for Unified Biometrics and Sensors (CUBS), Univer-sity at Buffalo, SUNY, in New York, USA. The line separa-tion algorithm is based on an improved directional run-length analysis [ 7 , 8 ]. Concerning word segmentation, at each back-ground pixel location, a horizontal background run including the location is traced and the run-length is saved in a new image buffer for each pixel location. A simple thresholding of the new buffer reveals word primitives. Then, the distances between the consecutive word primitives are computed using convex hull distance. A threshold for grouping of the word primitives is calculated based on the mean and variance of the distances. 4.4 ETS method Submitted by D. Rivest-Henault and M. Cheriet of the Ecole de technologie superieure (ETS) of the University of Quebec in Montreal, Canada. Both text line and word segmenta-tion methods are based on text smearing and morpholog-ical operations. Most of the involved operations take into account the local text line orientation. This has the benefit of greatly reducing the frequency of accidental line merging. The text is smeared using a modified version of Weickest X  X  coherence-enhancing diffusion filter, while the smeared image is binarized using Otsu X  X  algorithm. 4.5 ILSP-LWSeg-09 method Submitted by V. Papavassiliou, T. Stafylakis, V. Katsouros and G. Carayannis of the Institute for Language and Speech Processing (ILSP) in Athens, Greece, and based on [ 9 ]. Text line detection makes use of the Viterbi algorithm. Candidate line separators are obtained and combined by minimizing a function which exploits the distance between the separators and the local foreground density. For word segmentation, as a metric of separability between the two sets (inter-and intra-word gap), the negative logarithm of the objective function of a soft-margin linear SVM is used. 4.6 JadavpurUniv method Submitted by R. Sarkar, A. Khandelwal, P. Choudhury, N. Das, S. Basu, M. Kundu, M. Nasipury, D. K. Basu and A. F. Mollah of the CSE Dept., Jadavpur University in Kolk-ata, India. Text line detection is based on Connected Com-ponent Labeling and on comparison of components in a neighborhood. Then, the dimensional features of the com-ponents are analyzed to determine the style of handwriting, and threshold values are set for inter-word spacing in case of both isolated and cursive handwriting. Words are then identified on the basis of difference in intra-word and inter-word spacing. 4.7 LRDE method Submitted by T. Geraud of the EPITA Research and Develop-mentLaboratory(LRDE)inLeKremlin-Bicetre,France.The input image is sub-sampled in both dimensions while turn-ing it into a gray-level image. Then, an anisotropic Gaussian filtering is applied (mainly horizontal). The morphological watershed transform is computed, leading into a partition of the image into regions. To obtain the segmentation into lines, a simple merging procedure is run on the region adjacency graph. Word segmentation is based on attribute morphologi-cal closing as well as on morphological watershed transform. The source code can be downloaded from [ 10 ]. 4.8 PAIS method Submitted by S. Lu, S. Fan, Y. Wen and Y. Lu of the ECNU-SRI Joint Lab for Pattern Analysis and Intelligence System, Shanghai, China. The image is vertically divided into several strips. Potential text lines are detected based on the horizon-tal projection values of each strip in order to estimate the average distance between adjacent text lines. The text lines are then finalized by applying the knowledge of estimated line-distance and reasonable black-to-white traversal num-bers. For word segmentation of each text line, the number of possible words is estimated by the black-to-white traversal numbers. A gap is considered as inter-word gap if it is larger than a threshold calculated by estimated number of possible words. 4.9 AegeanUniv method (text line segmentation only) Submitted by E. Kavallieratou of the University of Aegean in Samos, Greece, and based on [ 11 , 12 ]. The page is verti-cally separated into three areas and for each area, a horizontal projection profile is employed. The valleys with minima less than a certain threshold are considered to be likely beginners of line segments. Sequentially, the area is examined pixel by pixel until an entire white path is outlined. 4.10 PortoUniv method (text line segmentation only) Submitted by J. Cardoso of Faculdade de Engenharia, Uni-versity of Porto in Porto, Portugal and based on [ 13 ]. The image is handled as a graph and the text lines as connected paths between the two lateral margins of the image. The paths to look for are the shortest paths between the two lateral margins while paths through black pixels are favoured. An efficient dynamic programming approach is used to find the minimum paths. 4.11 PPSL method (text line segmentation only) Submitted by A. Alaei, P. Nagabhushan and U. Pal of the University of Mysore in Mysore, India. The text page is ver-tically crumbled into few strip-like structures. In order to get Potential Piece-wise Separation Line (PPSL) between two consecutive lines, the white/black spaces in each strip are analyzed. Next, such PPSLs are concatenated or extended in both directions to produce the complete segmentation lines based on distance analysis of each PPSL with left and right neighboring PPSLs. 4.12 REGIM method (text line segmentation only) Submitted by M. Mezghani, W. Boussellaa and A. Alimi of the Research Group on Intelligent Machines (REGIM) of the University of Sfax in Tunisia and A. Zahour of the Equipe Gestion Electronique de Document (GED), University of Le Havre, France. The methodology is based on (a) docu-ment decomposition into columns and blocks covering all textual elements, (b) classification of the generated blocks using several statistical parameters and (c) text line detec-tion based on a fuzzy base line determination using a fuzzy C-means algorithm. 5 Evaluation results We evaluated the performance of all participating algorithms for text line and word segmentation using Eqs. ( 1 ) X ( 3 ), the test dataset (200 images) and the corresponding ground truth.
The acceptance threshold in order to define a one-to-one matching was set to T a = 95% for text line segmentation and to T a = 90% for word segmentation. The number of text lines and words for all 200 document images was 4034 and 29717, respectively. In order to compare the participant techniques with current state-of-the-art approaches, we also implemented an RLSA [ 14 ] and a projection profiles-based technique [ 15 ]. All evaluation results are shown in Table 1 , while a graphical representation of the evaluation results is given in Figs. 2 , 3 , 4 . In order to get an overall ranking for both text line and word segmentation, we used the global performance metric SM (see Sect. 3 ) in order to compare the 8 algorithms that provide both text line and word segmen-tation results (CASIA-MSTSeg, CMM, CUBS, ETS, ILSP-LWSeg-09, JadavpurUniv, LRDE and PAIS). As it can be observed (Fig. 2 ), the ILSP-LWSeg-09 method outperforms all other methodologies in the overall ranking, achieving SM = 96 . 91%. The ranking list for the first five method-ologies is: 1. ILSP-LWSeg-09 ( SM = 96 . 91% ) 2. PAIS ( SM = 94 . 53% ) 3. CMM ( SM = 93 . 66% ) 4. CUBS ( SM = 93 . 24% ) 5. CASIA-MSTSeg ( SM = 90 . 27% ) Concerning text line segmentation, the CUBS method achieved the highest results with FM = 99 . 53% (Fig. 3 ). The ranking list for the first five methodologies for text line segmentation is: 1. CUBS ( FM = 99 . 53% ) 2. ILSP-LWSeg-09 ( FM = 99 . 05% ) 3. PAIS ( FM = 98 . 52% ) 4. CMM ( FM = 98 . 42% ) 5. CASIA-MSTSeg ( FM = 95 . 68% ) For the word segmentation stage, the ILSP-LWSeg-09 method obtained the highest results with FM = 94 . 77% (Fig. 4 ). The ranking list for the first five methodologies for word segmentation is: 1. ILSP-LWSeg-09 ( FM = 94 . 77% ) 2. PAIS ( FM = 90 . 54% ) 3. CMM ( FM = 88 . 91% ) 4. CUBS ( FM = 86 . 96% ) 5. ETS ( FM = 84 . 93% ) For the sake of clarity, we also compared the first three methodologies concerning text line segmentation, word segmentation as well as the global performance metric SM using various acceptance thresholds values ( T a ) which range from 80% to 98% and interval value equal to 3. The over-all results are represented in the graphs of Figs. 5 , 6 , 7 .In all cases, the winning algorithms outperform the other tech-niques.

As it was mentioned in Sect. 2 , the test set was cre-ated with the help of 50 writers that were asked to copy 4 pages each one corresponding to a different language (English, French, German and Greek). Among all docu-ments, only the Greek documents were written in the native language of the writer. In order to compare the performance of the participating algorithms on documents written in the writers X  native language with that obtained on documents in other languages, we also present the word segmentation results of the best 3 methodologies for each language inde-pendently in Fig. 8 . As it is observed, the ranking for the Greek documents (written in the writers X  native language) as well as for documents of other languages (English, French and German) remains the same compared to the total word segmentation ranking (see Fig. 4 ). It is noticed that the fact that several documents were not written in the native lan-guage of the writer does not seriously affect the results of the contest.
 6 Winning algorithms According to the evaluation results, presented in Sect. 5 , the best performance in text line segmentation is achieved by CUBS method which has been submitted by Z. Shi, S. Setlur and V. Govindaraju. Concerning word segmen-tation, the ILSP-LWSeg-09 method, which has been sub-mitted by V. Papavassiliou, T. Stafylakis, V. Katsouros and G. Carayannis, obtained the highest results. The strong point of the reported as best text line segmentation method (CUBS) is the use of an adaptive local connectivity map (ALCM) generated using a steerable direction filter. This method results to a very high accuracy results ( FM = 99 . 53% ) main idea of the reported as best word segmentation method (ILSP-LWSeg-09) is the use of a gap metric that exploits the objective function of a soft-margin linear SVM in order to separate successive connected components. The perfor-mance of this method is reported to be 94.77% (FM) which means that is still room for improvements. Detailed descrip-tions of the winning algorithms are given in this section. 6.1 CUBS: text line segmentation algorithm Text line segmentation is based on an adaptive local connec-tivity map (ALCM) generated using a steerable direction fil-ter [ 8 ]. The algorithm is designed for solving the particularly complex problems seen in handwritten documents including fluctuating, touching or crossing text lines.

The text line segmentation method consists of the follow-ing steps: (1) Applying a steerable directional filter, a down-sampled version of the input document image is converted into an adaptive local connectivity map (ALCM), which is also a gray scale image. (2) A local adaptive thresholding algorithm is applied on the ALCM to reveal the text line patterns in terms of connected components. (3) A grouping algorithm is used to easily group the connected components into location masks for each text line. (4) Extraction of the text lines is done by collecting the connected components corresponding to the location masks on the original binary document image. 6.1.1 ALCM using steerable filter Let f : R 2  X  R represent any given signal. The document image is the discrete version of this signal with the domain limited to { 0 , 1 ,..., n  X  1 } X { 0 , 1 ,..., m  X  1 } and values in { 0 ,..., 255 } . Then, the adaptive local connectivity map is defined as a transform ALCM : f  X  A (4) by the convolution: A ( x , y ) = where G by an angle  X  0 : E , b = ( x , y ) | When we choose a longer than b , the ellipse E  X  0 a , b is an elongated mask aligned with its long axis in  X  0 direction. Intuitively, using the steerable directional filter G  X  0 ALCM is a convolution that aggregates the pixel intensities within the mask centered at ( x , y ) . When the long axis of the filter is aligned with the direction of a text line, the ALCM greater than the value along any other direction. 6.1.2 Location of text lines Each pixel value in an ALCM image represents the cumula-tive intensity of the foreground pixels in an elliptical neigh-borhood around the pixel in the original document image. A pixel with higher value in the ALCM implies that the pixel is in a dense text region. Therefore, ALCM is binarized for separation of highly-likely text areas from the background [ 16 ]. The binarization algorithm determines a pixel X  X  binary value by considering the pixel intensity distribution in a 5 neighborhood block structure. The 5 neighborhood blocks are 5 n  X  n windows with one in the middle centered at the pixel under consideration and 4 other blocks adjacent to the corner of the center block. A weighted difference between the average pixel intensity in the middle block and that in the other 4 blocks is used to decide the center pixel X  X  binary value. The binarized ALCM consists of connected compo-nents which represent either the entire line or part of a line. 6.1.3 Extraction of text lines The line patterns extracted from the ALCM are location masks for the actual text lines. The text lines in the origi-nal document image are extracted by collection and group-ing of connected components. The connected components for the text in the original document image are generated. After up-sampling the line patterns in ALCM to the scale of the original image, we superimpose the line patterns on the document image. For each text line pattern, all the con-nected components of text touching the pattern are collected and these components together make up the text line. If there are some connected components that do not touch any line pattern, they are grouped with the closest line. Some connected components may belong to more than one line pattern. These components represent characters that cross multiple text lines. For a touching piece, a reference line is drawn between the line patterns. The segmentation algorithm segments the contours of the piece into contour segments. Based on the location of the center of mass of the contour segments relative to the reference line, they are grouped into the corresponding text lines. The text images are recovered using the contour segments. 6.2 ILSP-LWSeg-09: word segmentation algorithm Word segmentation is based on a gap metric that exploits the objective function of a soft-margin linear SVM that sepa-rates successive connected components [ 9 ]. Therefore, word segmentation can be seen as a problem which requires the formulation of a gap metric and the clustering of the gaps in  X  X ithin X  or  X  X etween X  words classes. 6.2.1 Gap metric Considering the pixels of two successive CCs as elements of two distinct classes, the margin of an SVM classifier is used to measure their separability. Let g k be the gap metric between the k -th and the ( k + 1 ) -th CCs of the -th text line. The foreground pixels are divided into two groups, namely, the  X  X eft X  group consists of the pixels of all CCs up to the k -th, and the  X  X ight X  group involves the pixels from the ( k + 1 up to the last CC. Figure 9 b illustrates the group of pixels on the left of  X  X  X  and Fig. 9 c on the right of  X  X  X . The var-iable x m  X  X k  X  R 2 corresponds to the 2-d coordinates of the m -th foreground pixel and y m  X  Y k ={ X  1 , 1 } denotes the group that the m -th pixel belongs to. More compactly, the dataset for the k -th gap is denoted by Z k = ( X k , Since the gap metric will be derived from SVM theory [ 17 ], they consider a subset Z c k of the Z k by keeping only the fore-ground pixels that affect significantly the support vectors of the word separator. Z c k is obtained by splitting each group into non-overlapping horizontal zones of height equal to 2-pixels. For each zone they keep the q right-most pixels for the  X  X eft X  group and the q left-most pixels for the  X  X ight X  group. In this approach, they set q equal to 4. In Fig. 9 d, the selected pixels for the  X  X eft X  group are shown in blue color and the pixels for the  X  X ight X  group are shown in red. The aim for reducing the number of points is to increase the trac-tability of the SVM without altering the resulting gap metric.
The primary objective function for the soft margin SVM for the dataset Z c k is given by L ( w , b , a , X ) = where ( w , b ) define the hyperplane,  X  i are the slack variables, a and  X  i are the Lagrange multipliers, C is a non-negative constant used to penalize classification errors, x i are the fea-set. The value C is chosen to be inversely proportional to |
Z the minimization of L , i.e. the lowest value of L corresponds to the smallest || w || and consequently to the largest margin. Therefore, the gap metric between the k -th and the ( k + CCs of the -th text line is defined as: g Note that the transform in the log domain is introduced to enhance small size differences in L and the minus sign so that the gap metric increases with respect to the margin. 6.2.2 Threshold estimation Using the above mentioned procedure, the gap metrics for every selected pair of successive CCs in the whole document page are calculated. Due to the high variability of writing styles, sizes of letters, etc., a global threshold across all documents would be an inadequate solution. On the other hand, a variable threshold for each text line would not encompass the information of the writer X  X  style. There-fore, the threshold is calculated by taking into account all gap metric values within a given document page.

Let G ={ g m } M m = 1 denotes the set of all gap metrics in a document page. In principle, one should expect that low values correspond to small gaps, i.e.  X  X ithin X  word class, and vice versa. A nonparametric approach for estimating the probability density function [ 18 ] of the gap metrics is calcu-lated as follows: p ( x ) = where K (  X  ) denotes the normal kernel. The threshold is cho-sentobeequal totheminimum betweenthetwomainlobes of the estimated probability density function of the gap metrics. 7 Conclusions ICDAR 2009 Handwriting Segmentation Contest was orga-nized in order to record recent advances in off-line hand-writing segmentation. As it is shown in the evaluation results section, the best performance considering an over-all ranking for text line and word segmentation as well as a ranking only for word segmentation, was achieved by the ILSP-LWSeg-09 method of the Institute for Language and Speech Processing (ILSP) with overall global performance metric SM = 96 . 91% and word segmentation performance metric FM = 94 . 77%. Considering only text line segmen-tation, the best performance was achieved by the CUBS method of the Center for Unified Biometrics and Sensors (CUBS) with performance metric FM equal to 99.53%. It is also recorded that the selection of the acceptance thresholds values ( T a ) in order to define a one-to-one matching does not affect this ranking. Our plans for the construction of the test set of the next contest include the involvement of sev-eral writers that will all write in their native language. This will lead to more realistic and representative paradigms for testing.
 References
