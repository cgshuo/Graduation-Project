 Existing recommender systems mostly focus on recommend-ing individual items which users may be interested in. User-generated item lists on the other hand have become a popu-lar feature in many applications. E.g., Goodreads provides users with an interface for creating and sharing interesting book lists. These user-generated item lists complement the main functionality of the corresponding application, and in-tuitively become an alternative way for users to browse and discover interesting items to be consumed. Unfortunately, existing recommender systems are not designed for recom-mending user-generated item lists. In this work, we study properties of these user-generated item lists and propose a Bayesian ranking model, called Lire for recommending them. The proposed model takes into consideration users X  previous interactions with both item lists and with individ-ual items. Furthermore, we propose in Lire a novel way of weighting items within item lists based on both posi-tion of items, and personalized list consumption pattern. Through extensive experiments on a real item list dataset from Goodreads, we demonstrate the effectiveness of our proposed Lire model.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Filtering List Recommendation; Collaborative Filtering
Recommender systems have become extremely popular because of their wide application and success in domains such as E-commerce (Amazon), Music (iTunes), Movies (Net-flix), and Apps (Apple App Store). E.g., back in 2006, Ama-zon already had 35% of purchases originating from recom-mended items [21].
 Figure 1: User-generated book lists on GoodReads.

Existing recommender systems usually help users find po-tentially interesting items by means of collaborative filtering . Initial works on collaborative filtering mainly focused on neighborhood-based methods [29, 22], which essentially lever-age similarity between items or between users as measured by heuristic functions such as cosine or Pearson correlation . These similarities are calculated based on the ratings pro-vided by (received by) users (resp., items) in the past. More recent works on collaborative filtering mostly focus on latent factor models , which have become widely known from their success at the Netflix Competition [12, 17, 19, 20].
Although existing collaborative filtering works are effec-tive at recommending individual items to users, the pro-posed solutions usually lack flexibility in supporting more complex recommendation scenarios [4]. For example, exist-ing recommendation algorithms are not optimized for rec-ommending user-generated item lists , which are very popu-lar among various applications such as lists of books created by readers on GoodReads [2], lists of twitter users created by users on Twitter [1], and lists of products created by shoppers on Amazon [3].

User-generated item lists are usually deployed as a way to help users organize and share items consumed in the cor-responding application. These user-generated item lists are usually made public by default, so in addition to the main functionality provided by the service (e.g., recommending as well as shopping or consuming items), these lists serve as an alternative way to engage users of the service. For users, ex-ploring user-generated item lists is often a very effective way for browsing and identifying interesting items, as each list contains only a small subset of all items, and items in each list are usually manually organized by other users around a specific theme. E.g., users can find from a book list on French Literature interesting and rare books on this topic, which may not be recognized by the item recommendation engine or through keyword search interface as these books may not explicitly contain the keywords  X  X rench Literature X . An example of user-generated book lists on GoodReads is shown in Figure 1.

However, because of the sheer volume of user-generated item lists, and the complexity of each list (which typically contains tens or even hundreds of items), it is extremely challenging for a standard item presentation interface to help users discover lists which he/she might find interest-ing. Thus users usually have to resort to keyword search to find interesting lists, which again is extremely challenging because of the large number of items within each list, and also the huge number of lists which might match the query.
In this work, motivated by recent study on automatic rec-ommendation of items based on user X  X  previous interaction with the underlying system, we study the problem of how to generalize item recommendation to incorporate lists, and propose algorithms which can automatically find relevant item lists for each user based on her/his previous interac-tions with both lists and items in the corresponding service. Intuitively, these recommended item lists complements ex-isting item recommender system and serve as a way for users to explore items around a small set of themes which might match users X  interest.

We note that in the domain of music, playlists have a similar structure as the user-generated item lists studied in this work, and several existing works have been devoted to developing recommendation algorithms for playlists [7, 9, 8]. However, a huge difference between playlists and the item lists studied in this work is that there usually exists a strong correlation between neighboring songs in a playlist: in most cases songs in a playlist have to be consumed se-quentially. This property has been explored extensively by existing works such as [9], [7]. However, it is clear that for the item lists under our consideration, such as book lists, twitter user lists, and shopping lists, items do not necessar-ily have to be consumed sequentially. In fact, a user might well be interested in only one or a few items in a list and may consume them in no particular order.

To address the limitations of previous approaches in mod-eling users X  item list preference, we propose a new List Rec-ommendation Model called Lire in this work. In Lire , we take a user X  X  item preference into consideration when mod-eling the user X  X  item list preference, where item preferences can be learned from user X  X  previous interaction with individ-ual items. We note that a simple way of aggregating item preferences into list preferences may not work very well. In-deed, one challenge in modeling a user X  X  interest in user-generated item lists is that on websites such as Goodreads, because of the way user interface is presented and the huge number items contained in each list, users usually see just the top items in a list first, and they may often stop browsing an item list when enough items have been explored or con-sumed. To take these facts into consideration, we consider in our model, ingredients which can be leveraged to weight items which are ranked at different positions, and we also learn users X  browsing patterns by fitting a parameter that in-dicates roughly how many items need to be consumed before a user stops browsing an item list.
 We make the following contributions: First, we propose a Bayesian-based ranking model Lire for recommending user-generated item lists, which, unlike playlists, need not be consumed sequentially; Second, in the Lire model, we con-sider the problem of how preferences over individual items can be properly aggregated to model user X  X  interest in an item list; Third, through extensive experiments on a real item list dataset obtained from Goodreads, we show that our Lire model significantly outperforms various previously proposed recommendation algorithms on the task of recom-mending user-generated item lists.

In the rest of this paper, we first define the item list rec-ommendation problem in Section 2.1. Then in Section 2.2, we present some intuitive baseline algorithms which can be applied to the item list dataset to generate list recommen-dations. In Section 3, we introduce our proposed list recom-mendation model. Experimental results comparing different algorithms on Goodreads dataset are presented in Section 4. Related work is discussed in Section 5. Finally, we conclude the paper and present possible future directions in Section 6.
To formulate the item list recommendation problem, con-sider a set of users U = { u 1 ,...,u m } , a set of items T = { t 1 ,...,t n } , and a set of item lists L = { l 1 ,...,l q each list l i  X  L is composed of a subset of items from T .
Let the set of item lists which user u has shown interest in be denoted as L u , L u  X  L , where a list l  X  L u can be a list which u has liked, voted, or commented on. Similar to many other recommendation problems such as those discussed in [12] and [27], typically user feedback on item lists is implicit as compared to explicit ratings which can be found on movie recommendation websites [20].

On most websites such as Goodreads which provide the functionality for creating and sharing item lists, each user u is also associated with a set of items T u , namely the items which u has previously consumed/rated.
 Problem 1. Item List Recommendation: Given T , U , L , for each user u  X  U , based on u  X  X  previously consumed items T u , and u  X  X  previously consumed item lists L u , recom-mend to u the top-N item lists from L \ L u which u will be most interested in.
For many a recommendation application be it item rec-ommendations or item list recommendations, there is typi-cally a long tail distribution w.r.t. the number of user rat-ings/interactions of each item. E.g., most of the items can observe only a few ratings, whereas only a few enjoy much attention from users. Thus this popularity bias becomes an important factor for explaining and understanding the underlying data, as was also observed in the Netflix compe-tition [18].

One simple item list recommendation algorithm thus is to directly leverage the popularity bias and recommend item lists based on the popularity of each list. That is, we sort item lists w.r.t. the number of votes received, and recom-mend to every user the same set of top item lists which have received the highest number of votes. We note that this is very similar to how Goodreads website recommends item lists on every book detail page, i.e., every popular book is likely included in many book lists, and according to our ob-servation, only two of the hottest book lists are shown on the detail page of every book.

We call above algorithm GLB (GLoBal), as the recom-mendation generated using the above approach is based on global statistics and is not personalized. We also consider the following two different personalized variants, among the baselines; these methods are in part motivated by the heuris-tic popularity-based approaches for generating playlists which have been demonstrated to have good performance [8].
The first alternative PPOP (Personalized POPularity) is based on the intuition that a user u may only be interested in item lists which contain items that u is familiar with. Thus instead of recommending the most popular item lists across all users, we recommend the most popular item lists which contain at least one item the user has interacted with before.

The second alternative PIF (Personalized Item Frequency) is based on the same intuition as PPOP that a user u is only interested in item lists which contain items that u is familiar with. But instead of ranking these candidate item lists by popularity, we rank these candidate item lists by how many items the list contains that the user has interacted before. The rationale for this heuristic is that the more books a list contains that the user is familiar with, the more interesting that list to the user. Ties in PIF are broken using popularity of the corresponding item list.
Consider a matrix M L of users X  interest in each list, where each entry y ul is 1 if u has voted list l before, and 0 otherwise. We could simply apply previously proposed collaborative fil-tering algorithms to this matrix M L .

Typical collaborative filtering algorithms are based on la-tent factor models, which were made popular because of their success in the Netflix competition [20]. The nature of the datasets we consider is that user feedback is implicit, i.e., it tends to be in the form of votes. Thus, we adapt the recently proposed BPR method [27], demonstrated to be very effective on implicit feedback data, to item list rec-ommendation.

In BPR [27], each user u is associated with a latent factor w , each item t i is associated with a latent factor h i , then similarly to other latent factor models, the rating  X  x user u on item t i can be predicted based on the dot product w
Because of the nature of the implicit dataset, similar to [27], we assume that items which have been voted by a user are preferred over other items. Thus, we let t i u t j denote that user u prefers item t i to item t j . Following the nota-tion introduced in [27], let D S denote set of triples ( u,t such that t i u t j holds. Then BPR formalizes a learning problem by maximizing the following log-posterior. ln P ( X  | D S )  X  ln P ( D S |  X ) P ( X ) where  X  = 1 1+ e  X  x is the logistic sigmoid function,  X  denotes all the parameters (latent factors of users and items), and each latent factor is assumed to be following a zero mean Gaussian prior. Finally,  X   X  is a model specific regularization parameter.

As discussed in [27], the optimization criteria of BPR is closely related to Area Under the ROC Curve (AUC) [11]. And above posterior in Equation 1 can be optimized through Stochastic Gradient Descent (SGD) which has been demon-strated to be useful for learning various latent factor-based models [17].
As we will discuss in Section 5, the item list recommenda-tion problem resembles the playlist recommendation prob-lem studied before [8, 9]. One important difference is that with playlists, there is an inherent assumption that items in the list are meant to be consumed sequentially, which may not be relevant for user-generated item lists such as book lists or product lists. We adapt algorithms proposed for playlist recommendation for the sake of comparison with the algorithms we develop.

In the literature, one very recent and representative model-based approach for playlist recommendation is LME or La-tent Markov Embedding [9, 10]. In LME, similar to other latent factor models, each item t i is associated with a latent vector h i . Given a playlist l , let each item in l at posi-tion a be denoted as l [ a ]. In order to model the sequential property a playlist l , we consider the probability of each list being  X  X enerated X  as a series of Markov transitions between consecutive songs.
 where the transition probability P ( l [ a ] | l [ a  X  1]) can be mod-eled as a function of the Euclidean distance  X ( h l [ a ] between the two songs under consideration. Let A denote the set of all songs which can following one specific song l [ a  X  1], we denote by Z ( l [ a  X  1]) = P t  X  A e  X   X ( h the summation over transition probabilities w.r.t. all possi-ble next song given l [ a  X  1]. We can then use the following logistic model to estimate P ( l [ a ] | l [ a  X  1]).
Similar to BPR, an SGD-like algorithm can be leveraged to learn the latent factor model in LME by maximizing the likelihood of generating the training playlists. We note that the original model in [9, 10] is not personalized.
In this section, we propose a List Recommendation Model called Lire for the item list recommendation problem. Sim-ilar to previous latent factor-based models, we map users, items, and lists into a joint latent factor space of dimension-ality k . Accordingly, each user u is associated with a vector w u  X  R k , each item t i with a vector h i  X  R k , and each list l with a vector g j  X  R k .
Intuitively, given a user u and an item list l j , u  X  X  inter-est in l j can be captured using two major factors: (i) the overall intrinsic quality of the list l itself, and (ii) the user X  X  aggregate interest in the items in l j . The first factor can be modeled simply as an inner product between w u and g j while the second factor involves aggregating user X  X  prefer-ences over multiple items within l j .

A simple idea to model the relationship between u and items in l j is to assume that each item in l j has an equal influence on user u . Thus we could model the preference of u on l j using the following equation. where | l | denotes the length of list l . In Equation (4), the first component w u g j models user X  X  intrinsic interest in the list as a whole, and the second component models the re-lationship between u and items in l j . We call above model UNIFORM. Note that omitting the second component in Equation (4) amounts to directly factorizing the user list in-teraction matrix M L into user latent vectors and item list latent vectors and using that solely as the model for recom-mendation.

As discussed in Section 4.1, usually different items in the list have different influence on a user. E.g., items which are shown at the top of a list, or items which are shown on the first page of the list if pagings are enabled, obviously have more significant influence on the user. This effect is usually due to the way different items of a ranking list are shown on the user interface, and how users consume items in a list. Similar effect can also be observed in information retrieval [13]. To capture this property, we adopt a function inspired by DCG ( Discounted Cumulative Gain ) [15], in or-der to weight down items which are ranked low in a displayed item list or are shown in later pages in case of a paging en-abled interface. Without any ambiguity, let t i = l j [ i ] denote the i th item in list l j , 1  X  i  X  | l j | , and let h i sponding latent factor associated with t i . constant. We call above model DCG.

Although DCG is able to weight down items with lower position in the displayed list, given the huge number of items which may exist in an item list, items which are ranked low down in a list usually will not be examined by the user. E.g., one list named  X  X est Book Cover Art X  has 4,775 books and it X  X  unlikely a user will dig deep down such lists. Thus, in-corporating these lower ranked items in predicting a user X  X  preference over an item list may introduce lots of noise. In this work, to address this issue, we make the reasonable as-sumption that users browse an item list top down, and stop browsing when enough items have been seen. Note that this threshold number of items which indicates the number of items users consume before stopping, may vary among dif-ferent users, thus needs to be personalized. Even for a spe-cific user, this number may change from list to list, which may motivate us to associate one random variable per user and per list. However, given the sparsity of the dataset, such fine granularity threshold modeling might easily lead to overfitting. Thus we consider in this work a trade-off ap-proach by introducing a personalized granularity controlling browsing threshold  X  u .

We set  X  u =  X   X   X  u . Here,  X  u  X  Z + is a personalized discrete random variable with a positive integer as its value,  X  is a constant which is used to capture a coarse list brows-ing granularity. E.g.,  X  can either be the number of items contained in a single page on the website, or can just be a constant such as 10 items, which captures a finer granular-ity. The value of  X  can be tuned according to the underlying data. In this work, using our Goodreads dataset, we set  X  to be 5 which leads to the best performance on our dataset.
Let I ( i  X   X  u ) be an indicator function which equals 1 if i  X   X  u is true, and 0 otherwise. We could adapt DCG to the following model DCG-T. ization constant. This model captures the idea that user u stops browsing beyond depth  X  u .
In general users X  feedback data on item lists tends to be even more sparse than the feedback on items. This makes learning users X  preference over item lists more challenging. Fortunately, for most applications in which users can create and share item lists, users also can and tend to interact with individual items. E.g., on Goodreads, users can vote for book lists which are generated by other users, and can also add books to their shelves, meaning they either have already read the books, or are interested in reading those books in the future. Thus in addition to the matrix M which captures interactions between users and lists, we also have the matrix M T which captures interactions between users and items.

Motivated by recent effort on Collective Matrix Factoriza-tion [31], we consider that users share their preferences over items and lists. Thus we could potentially leverage informa-tion learnt from users X  item preferences to help mitigate the sparsity issue when modeling users X  list preferences. Con-sidering the fact that the interactions between users and items or between users and item lists are often implicit, e.g., vote on Goodreads and subscription on Twitter, we adapt the framework of BPR [27] for deriving the optimiza-tion criteria for our item list recommendation problem. Let  X  = { W,G,H, X  } be the set of parameters associated with the Lire model. We assume  X  is associated with a zero-mean Gaussian prior. By assuming L u and T u are condi-tional independent given  X , the log of the posterior of  X  given the observed user/item interactions and user/item list interactions can be calculated as follows.
 P ( X ) = ln p ( X  | L u , T u ) = ln p ( L u , T u |  X ) p ( X ) where D L S denotes the set of triples ( u,l i ,l j ) for which l i u l j holds, D T S denotes the set of triples ( u,t which t i u t j holds, And  X   X  are the model specific regular-ization parameters. The relationship between user u , list l and list l j is captured by  X  x L uij ( X ), which can be estimated as  X  x ui  X   X  x L uj . Similarly, the relationship between user u , item t and item t j is captured by  X  x T uij ( X ), which can be modeled
Given P ( X ), we use Maximum-a-Posteriori (MAP) to per-form a point estimation of the parameters of the Lire model. Considering the fact that P ( X ) is differentiable w.r.t. most parameters, one popular way to optimize P ( X ) is through gradient-based algorithms. A naive approach to doing so would be to directly sample quadruples ( l i ,l j ,t i ,t l , l j are positive and negative item list instances for a user u , and t i , t j are positive and negative item instances. More precisely, user u prefers l i to l j and similarly t i to t ever, this introduces a huge sampling space. Hence, we propose an alternating learning framework, where we first sample ( u,t i ,t j ) from D T S , until convergence of P ( X ) ln p ( X  | T u ); then we sample ( u,l i ,l j ) from D L S vergence of P ( X ) L = ln p ( X  | L u ). We iterate above process until the overall posterior converges. We note that the gra-dient of P ( X ) T w.r.t.  X  can be derived in a similar way as in [27], thus in the following, we focus on how a gradient-based algorithm can be applied to P ( X ) L .

Recall from Section 3.1 that during the learning process to maximize P ( X ) L , the threshold parameter  X  u for every user takes on positive integers as values, thus P ( X ) L is non-continous w.r.t.  X . To solve this issue, we further decompose the maximization of P ( X ) L into the following two steps: first, fix  X  u then optimize the remaining model parameters; then fix the remaining model parameters and optimize  X  u . Given a fixed  X  u , the following is the gradient of P ( X ) w.r.t. the model parameter  X  for DCG-T. Similar gradients can be derived for UNIFORM and DCG and we suppress the details. To simplify the notation, we omit mentioning  X  for  X  x T uij ( X ) and  X  x L uij ( X ) if there is no ambiguity. lowing equations how  X   X  x L uj / X   X  can be derived for w , and g in DCG-T, where f indicates an index into the correspond-ing latent factor.  X   X 
Given  X  u =  X   X   X  u ,  X  u may have a small domain given the size | l j | of a list l j . E.g., on Goodreads, when  X  is set to the number of items on a single web page, most lists have size less than 40 web pages. A simple idea thus is to enumerate all possible  X  u and then find the optimal  X   X  u which maximizes P ( X ) L .
However, when  X  is tuned to be at a finer granularity, the cost of above exhaustive search becomes prohibitive. Given the fact that P ( X ) L may not be monotone w.r.t.  X  u based on different possible values of the latent factors, we consider a local search algorithm LocalOpt (Algorithm 1) which finds a local maximum of  X  u .

Algorithm 1: LocalOpt(  X  , X , | l | )
The overall algorithm for learning Lire is listed in Algo-rithm 2. In each iteration of the main loop, we first sam-ple ( u,t i ,t j ) from D T S and update model parameters W , H through Stochastic Gradient Ascent until convergence. Then we sample ( u,l i ,l j ) from D L S , and update model parameters W , G through Stochastic Gradient Ascent until convergence. Finally, we find the optimal  X  through Algorithm LocalOpt for every user. We repeat above three steps until the overall model has converged or the maximum number of iterations has been reached.

Algorithm 2: Lire -Learn( X , D L S , D T S ,  X  )
To evaluate our proposed model Lire and compare it with existing models for item and playlist recommendation, we obtained during one month a 10% sample of all user-generated book lists on Goodreads. As can be found from the Goodreads website, there exist in total around 34,750 user-generated book lists, and our obtained sample includes 3,000 randomly selected book lists from the entire collection.

We filter book lists which have fewer than 5 voters, and the resulting dataset contains 1,998 book lists. For the set of voters obtained from these 1,998 book lists, we again filter Figure 3: Statistics of Goodreads data w.r.t. lists and books out those who have voted less than 5 times within the 1,998 book lists. The total number of unique users left at the end of this process is 3,425. To fit users X  preference over individual items, we also obtained the set of books which have been added to these 3,425 users X  book shelves. The total number of unique books is 105,030.

In Figure 3 (a), we group lists into different buckets based on how many books they contain, and plot the number of lists which belong to each bucket. It can be seen that the ma-jority of the obtained book lists contain only a small number of books, but there does exist book list which contains 4,775 books. The average number of books per list is 109. Simi-larly, in Figure 3 (b), we group books into different buckets based on how many book lists they belong to, and plot the number of books belong to each bucket. Again, there is an obvious power law distribution between the number of lists a book belongs to and the number of books that belong to the same number of books.

Similar statistics of the Goodreads dataset can be ob-served between users and lists, and also between users and books, as shown in Figure 2. In a nutshell, the majority of users interact only with a few lists or books, while a few power users interact with a large number of lists or books.
From the obtained Goodreads dataset, we randomly sam-ple 10% user/list interaction data as the test set, and the remaining data is treated as training set. To simplify the training process, we assume each parameter of the model is associated with the same regularization parameter  X  . Learn-ing rate  X  in the Stochastic gradient descent step, and regu-larization parameter  X  are selected based on grid search. In our experiments, we found that usually setting  X  = 0 . 1 and  X  = 0 . 01 leads to the best performance.
We compare our proposed Lire with the following 5 base-line algorithms as discussed in Section 2.2: 1. GLB; 2. PPOP; 3. PIF; 4. BPR; 5. LME. For BPR and LME, we also used grid search to find the best learning parameter settings. Fi-nally, we consider two variations of Lire  X  Lire -UNIFORM with uniform item weighting, and Lire -DCG-T with item position-based weighting and personalized browsing thresh-old.
AUC is a commonly used metric for testing the quality of rank orderings. Following [27], we use the AUC metric described below to compare the proposed Lire model with the baseline algorithms as it has been demonstrated to be a good metric for evaluating Top-N recommendation tasks [6]. Suppose the set of users, positive book list instance (book lists voted by the user in the test dataset), negative book list instance (book lists which have not been voted either in the training set or testing dataset) in the test dataset are denoted as D test S . Then, the formula to compute AUC is given by: where I ( X  x ui &gt;  X  x uj ) is an indicator function which returns 1 if  X  x ui &gt;  X  x uj is true, and 0 otherwise.
We first test how the granularity parameter  X  of the brows-ing threshold  X  can affect the performance of the Lire model. As discussed in Section 3, on one hand, when setting  X  to a small value, the predicted browsing threshold may lack flexibility in predicting user X  X  browsing pattern across dif-ferent lists. Whereas on the other hand, setting  X  to be a large value, we may incorporate unnecessary items into the prediction of user X  X  interest in a specific list.

The above trade-off is confirmed by our results on Goodreads dataset as shown in Table 1. By fixing the dimensionality of D to be 10, the overall AUC on the test set increases when  X  is varied from 1 to 5, and AUC decreases when we fur-ther increase the value of  X  . We observed similar results for other D settings and suppress them for lack of space. This result indicates that  X  in practice can be tuned based on the actual dataset.
In Figure 4, we demonstrate the convergence behavior of the Lire model. As can be found in this figure, our model converges fairly quickly (around 5 iterations). We note that this convergence result also holds for other dimensionality setting of the latent factors. Figure 4: Convergence of Lire when varying dimen-sionality of the latent factors.
Finally, we compare the performance of Lire with other algorithms as presented in Section 2.2. From Figure 5, we can readily observe that the three baseline algorithms GLB, PPOP, PIF do not perform nearly as well as BPR and Lire . We note that this is in contrast with the result on playlist dataset, where popularity-based methods, and especially personalized popularity-based methods excel [8]. Also the Markov-based approach LME does not perform as well as BPR and Lire . We claim that the reason for this is that user-generated lists such as book lists on Goodreads do not have the sequential consumption property normally assumed by playlist modeling works.

For the two variations of Lire , we can see from Figure 5, both of them perform better than the other algorithms. However, Lire -DCG-T is better than Lire -UNIFORM, for two reasons: (i) Lire -UNIFORM may aggregate more than the necessary number of items X  preference when modeling a user X  X  interest in an item list, and (ii) it ignores the fact that preference over items positioned higher up in the list may have a larger impact on the user X  X  preference for the list. In addition, because Lire -UNIFORM needs to visit all items in an item list during training, training of Lire -UNIFORM is much slower compared with Lire -DCG-T. AUC Figure 5: Quality comparison for various algorithms.
Latent factor models for recommendation have generated significant amount of attention due to their famous success at the Netflix competition [20]. In latent factor models, each observed rating in a recommender system can be explained as a dot product between two learned latent factors corre-sponding to the underlying user and item. Recently, latent factor models have been extended extensively to incorpo-rate additional features such as time [19], context [16], and content features of items [5].

Many existing works on recommender system focus on ex-plicit rating datasets in which ratings can take values from a small domain such as 1 to 5. However, for many recom-mendation scenarios, feedbacks from users take an implicit form, such as whether a user purchased a product, liked a feed, clicked on an item, etc. These implicit data settings create a huge challenging for existing latent factor models, and researchers have recently proposed various models for modeling implicit datasets. One notable work in this direc-tion is BPR [27], in which the authors proposed to solve the implicit data problem through a general Bayesian rank-ing model, which can learn users X  preferences over items by sampling positive and negative/missing entries from the user rating matrix. Another work which proposes to model im-plicit dataset through ranking is CLiMF [30], which instead of optimizing AUC as in BPR, considers Mean Reciprocal Rank as the optimization criterion. In [24], the authors argue that reasoning about preferences between individual items might be too fine a granularity, and propose to lift item preferences to preferences over sets of items. The fo-cus of this work is still on item recommendation, and when aggregating item preferences, the proposed model does not consider the position of an item, and the defined item sets are hidden from users thus there is no need to model how users might view items within a set. Other works on im-plicit datasets include [12], in which the authors propose a different way of modeling implicit datasets by weighting the importance of each observed rating through heuristic func-tions. In [25], the authors propose a more complex model which models the relationship between the original implicit dataset (which can be considered as a bipartite graph be-tween users and items) and random bipartite graphs which captures potential items which users have considered before actually consuming items in the original dataset.

User-generated item lists are similar to playlists as ex-plored in previous works such as [9] and [7]. An important observation made by these works is that neighboring items in a playlist are usually correlated with each other and items in a playlist usually have to be consumed sequentially. E.g., in LME [9], the proposed model assumes that transitions between neighboring items in a playlist satisfy the Marko-vian property, i.e., next song in a playlist depend only on the current song which is playing. Similarly, in [7], the au-thors consider that each song in a playlist is closely related to other songs which are played within the same short time window. An interesting survey of algorithms for modeling playlists is presented in [8].

The proposed item list recommendation problem is also related to recent effort on package recommendation [26, 28, 32]. However, most of these works focus on handling hard constraints specified by users as opposed to learning user X  X  preferences over item lists from previous feedback. In [23], the authors propose a Probability Matrix Factorization -based approach to model user X  X  preferences over travel packages, where each package is composed of a set of places of interest. The focus of this work is on modeling the cost of a package, whereas in our work we focus on how item preferences can be aggregated to model user X  X  preferences over item lists.
Finally, the way we model interactions between users and item lists, and also interactions between users and individual items is closely related to recent efforts on collective matrix factorization [31, 14], which has become a popular way of modeling scenarios with heterogeneous types of interactions through sharing latent factors.
In this paper, we motivated the problem of recommend-ing user-generated item lists and proposed a novel model called Lire for this purpose. Existing works in recommender system usually focus on item recommendation, thus do not consider how user X  X  preference over item lists can be decom-posed into preferences over individual items within the list. Though playlist recommendation considers item lists in a specific setting, the proposed model cannot be applied to other item list settings as studied in this work, due to the fact that items in these lists do not need to be consumed se-quentially. In this work, we identify that there exist multiple challenges on how presentation of an item list in an applica-tion such as Goodreads might impact a user X  X  preference over item lists. And based on our observations from Goodreads book list dataset, we propose to model users X  preferences over item lists by aggregating users X  preferences over individ-ual items of a list, we capture how users perceive an item list by weighting items within a list based on position, and we also consider how many items a user might consume before deciding whether to like this list or not. Through extensive experiments we demonstrate that our proposed model has a better performance compared with many existing recom-mendation algorithms.

There exist multiple directions for future work: first, we can study how temporal information from the dataset can be leveraged to help better model a user X  X  preference over item lists. E.g., we could check whether liking a list will result in a subsequent consumption of an item within the same list. Second, many applications which have user-generated item lists involve social network. This raises the question how social influence can be modeled in Lire . Finally, it X  X  interesting to ask how contents of lists and items can be incorporated into Lire through methods such as [5].
This work was supported in part by the Institute for Com-puting, Information and Cognitive Systems (ICICS) at UBC.
