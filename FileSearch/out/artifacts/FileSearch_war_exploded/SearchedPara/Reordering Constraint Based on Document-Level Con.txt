 Phrase-based statistical machine translation is use-ful for translating between languages with similar word orders. However, it has problems with long-distance reordering when translating between lan-guages with different word orders, such as Japanese-English. These problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation qual-ity.

In order to address these problems, various meth-ods which use syntactic information have been pro-posed. These include methods where source sen-tences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improv-ing translation quality.

In this paper, we propose a method where re-ordering constraints are added to a decoder using document-level context. As the document-level con-text, we use noun phrases which significantly oc-cur in context documents containing source sen-tences. Given a source sentence, zones which cover the noun phrases are used as reordering constraints. Then, in decoding, reorderings which violate the zones are restricted. By using document-level con-text, contextually-appropriate reordering constraints are preferentially considered. As a result, the trans-lation quality and speed can be improved. Ex-periment results for the NTCIR-8 patent transla-tion tasks show a significant improvement of 1.20% BLEU points in Japanese-English translation and 1.41% BLEU points in English-Japanese translation. Patent translation is difficult because of the amount of new phrases and long sentences. Since a patent document explains a newly-invented apparatus or method, it contains many new phrases. Learning phrase translations for these new phrases from the training corpora is difficult because these phrases occur only in that patent specification. Therefore, when translating such phrases, a decoder has to com-bine multiple smaller phrase translations. More-over, sentences in patent documents tend to be long. This results in a large number of combinations of phrasal reorderings and a degradation of the transla-tion quality and speed.

Table 1 shows how a failure in phrasal reorder-ing can spoil the whole translation. In the baseline output, the translation of  X   X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X   X  X  X   X   X   X   X  ( an interlayer insulation film 12 that is a first insulation film ) is divided into two blocks,  X  an interlayer insulating film 12  X  and  X  a first insulating film  X . In this case, a reordering constraint to translate  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X   X  as a single block can reduce incorrect reorder-ings and improve the translation quality. However, it is difficult to predict what should be translated as a single block.

Therefore, how to specify ranges for reordering constraints is a very important problem. We propose a solution for this problem that uses the very nature of patent documents themselves. In order to address the aforementioned problem, we propose a method for specifying phrases in a source sentence which are assumed to be translated as sin-gle blocks using document-level context. We call these phrases  X  X oherent phrases X . When translat-ing a document, for example a patent specification, we first extract coherent phrase candidates from the document. Then, when translating each sentence in the document, we set zones which cover the coher-ent phrase candidates and restrict reorderings which violate the zones. 3.1 Coherent phrases in patent documents As mentioned in the previous section, specifying coherent phrases is difficult when using only one source sentence. However, we have observed that document-level context can be a clue for specify-ing coherent phrases. In a patent specification, for example, noun phrases which indicate parts of the invention are very important noun phrases. In pre-vious example,  X   X   X   X   X  X  X   X   X   X  X  X   X  X  X   X   X   X   X   X   X  is a part of the invention. Since this is not language dependent, in other words, this noun phrase is always a part of the invention in any other language, this noun phrase should be translated as a single block in every language. In this way, impor-tant phrases in patent documents are assumed to be coherent phrases.

We therefore treat the problem of specifying co-herent phrases as a problem of specifying important phrases, and we use these phrases as constraints on reorderings. The details of the proposed method are described below. 3.2 Finding coherent phrases We propose the following method for finding co-herent phrases in patent sentences. First, we ex-tract coherent phrase candidates from a patent docu-ment. Next, the candidates are ranked by a criterion which reflects the document-level context. Then, we specify coherent phrases using the rankings. In this method, using document-level context is criti-cally important because we cannot rank the candi-dates without it. 3.2.1 Extracting coherent phrase candidates Coherent phrase candidates are extracted from a context document, a document that contains a source sentence. We extract all noun phrases as co-herent phrase candidates since most noun phrases can be translated as single blocks in other lan-guages (Koehn and Knight, 2003). These noun phrases include nested noun phrases. 3.2.2 Ranking with C-value The candidates which have been extracted are nested and have different lengths. A naive method can-not rank these candidates properly. For example, ranking by frequency cannot pick up an important phrase which has a long length, yet, ranking by length may give a long but unimportant phrase a high rank. In order to select the appropriate coher-ent phrases, measurements which give high rank to phrases with high termhood are needed. As one such measurement, we use C-value (Frantzi and Anani-adou, 1996).

C-value is a measurement of automatic term recognition and is suitable for extracting important phrases from nested candidates. The C-value of a phrase p is expressed in the following equation: C-value ( p )= where l ( p ) is the length of a phrase p , n ( p ) is the frequency of p in a document, t ( p ) is the total frequency of phrases which contain p as a subphrase, c ( p ) is the number of those phrases.

Since phrases which have a large C-value fre-quently occur in a context document, these phrases are considered to be a significant unit, i.e., a part of the invention, and to be coherent phrases. 3.2.3 Specifying coherent phrases Given a source sentence, we find coherent phrase candidates in the sentence in order to set zones for reordering constraints. If a coherent phrase candi-date is found in the source sentence, the phrase is re-garded a coherent phrase and annotated with a zone tag, which will be mentioned in the next section. We check the coherent phrase candidates in the sen-tence in descending C-value order, and stop when the C-value goes below a certain threshold. Nested zones are allowed, unless their zones conflict with pre-existing zones. We then give the zone-tagged sentence, an example is shown in Table 1, as a de-coder input. 3.3 Decoding with reordering constraints In decoding, reorderings which violate zones, such as the baseline output in Table 1, are restricted and we get a more appropriate translation, such as the proposed output in Table 1.
 We use the Moses decoder (Koehn et al., 2007; Koehn and Haddow, 2009), which can specify re-Moses restricts reorderings which violate zones and translates zones as single blocks. In order to evaluate the performance of the proposed method, we conducted Japanese-English (J-E) and English-Japanese (E-J) translation experiments us-ing the NTCIR-8 patent translation task dataset (Fu-jii et al., 2010). This dataset contains a training set of 3 million sentence pairs, a development set of 2,000 sentence pairs, and a test set of 1,251 (J-E) and 1,119 (E-J) sentence pairs. Moreover, this dataset contains the patent specifications from which sentence pairs are extracted. We used these patent specifications as context documents. 4.1 Baseline We used Moses as a baseline system, with all the set-tings except distortion limit (dl) at the default. The distortion limit is a maximum distance of reorder-ing. It is known that an appropriate distortion-limit can improve translation quality and decoding speed. Therefore, we examined the effect of a distortion-limit. In experiments, we compared dl = 6, 10, 20, 30, 40, and  X  1 (unlimited). The feature weights were optimized to maximize BLEU score by MERT (Och, 2003) using the development set. 4.2 Compared methods We compared two methods, the method of specify-ing reordering constraints with a context document (w/ Context) and the method of specifying reorder-ing constraints without a context document (w/o Context). In both methods, the feature weights used in decoding are the same value as those for the base-line (dl =  X  1 ). 4.2.1 Proposed method (w/ Context) In the proposed method, reordering constraints were defined with a context document. For J-E transla-tion, we used the CaboCha parser (Kudo and Mat-sumoto, 2002) to analyze the context document. As coherent phrase candidates, we extracted all sub-trees whose heads are noun. For E-J translation, we used the Charniak parser (Charniak, 2000) and ex-tracted all noun phrases, labeled  X  X P X , as coherent phrase candidates. The parsers are used only when extracting coherent phrase candidates. When speci-fying zones for each source sentence, strings which match the coherent phrase candidates are defined to be zones. Therefore, the proposed method is robust against parsing errors. We tried various thresholds of the C-value and selected the value that yielded the highest BLEU score for the development set. 4.2.2 w/o Context In this method, reordering constraints were defined without a context document. For J-E translation, we converted the dependency trees of source sen-tences processed by the CaboCha parser into brack-eted trees and used these as reordering constraints. For E-J translation, we used all of the noun phrases detected by the Charniak parser as reordering con-straints. 4.3 Results and Discussions The experiment results are shown in Table 2. For evaluation, we used the case-insensitive BLEU met-ric (Papineni et al., 2002) with a single reference.
In both directions, our proposed method yielded the highest BLEU scores. The absolute improve-ment over the baseline (dl =  X  1 ) was 1.20% in J-E translation and 1.41% in E-J translation. Accord-ing to the bootstrap resampling test (Koehn, 2004), the improvement over the baseline was statistically significant ( p&lt; 0 . 01 ) in both directions. When com-pared to the method without context, the absolute improvement was 1.54% in J-E and 0.25% in E-J. The improvement over the baseline was statistically significant ( p&lt; 0 . 01 ) in J-E and almost significant ( p&lt; 0 . 1 ) in E-J. These results show that the pro-posed method using document-level context is effec-tive in specifying reordering constraints.

Moreover, as shown in Table 3, although zone setting without context is failed if source sen-tences have parsing errors, the proposed method can set zones appropriately using document-level con-text. The Charniak parser tends to make errors on noun phrases with ID numbers. This shows that document-level context can possibly improve pars-ing quality.

As for the distortion limit, while an appropriate distortion-limit, 30 for J-E and 40 for E-J, improved the translation quality, the gains from the proposed method were significantly better than the gains from the distortion limit. In general, imposing strong constraints causes fast decoding but low translation quality. However, the proposed method improves the translation quality and speed by imposing appro-priate constraints. In this paper, we proposed a method for imposing reordering constraints using document-level context. In the proposed method, coherent phrase candidates are extracted from a context document in advance. Given a source sentence, zones which cover the co-herent phrase candidates are defined. Then, in de-coding, reorderings which violate the zones are re-stricted. Since reordering constraints reduce incor-rect reorderings, the translation quality and speed can be improved. The experiment results for the NTCIR-8 patent translation tasks show a significant improvement of 1.20% BLEU points for J-E trans-lation and 1.41% BLEU points for E-J translation.
We think that the proposed method is indepen-dent of language pair and domains. In the future, we want to apply our proposed method to other lan-guage pairs and domains.

