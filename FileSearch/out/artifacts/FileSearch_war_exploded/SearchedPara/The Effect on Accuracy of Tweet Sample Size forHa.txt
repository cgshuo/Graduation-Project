 Twitter is a dynamic environment, accumulating approximately 500 million tweets per day from millions of users worldwide. 1 Hashtags have become the de facto standard for labelling the topic or intent of a tweet within Twitter. Therefore, if we understand the hashtag, we gain a deeper insight into the intent and sentiment of the tweet. Hashtag analysis usually involves breaking down the hashtag or segmenting it into the words that are used in its formation, allowing us to associate the hashtag to other words within a sample of tweets. Hashtag segmentation has been used to assist search engines in providing more accurate been used in the meta analysis of predicting hashtag trends [ 5 ]. which should be chosen so that it matches the domain of the text to be seg-mented. Therefore, dictionaries for hashtag segmentation are best constructed from a random sample of tweets. However, it is unclear how large this sample should be.
 given level of segmentation accuracy? X  To the best of our knowledge, this is the first analysis of the relationship between the number of tweets used to construct the segmentation dictionary and the accuracy of the hashtag segmentation.  X  Identification of the hashtag segmentation Jaccard similarity distribution as  X  The presentation of closely fitting models for each distribution parameter, as  X  A method of predicting the mean and standard deviation of the Jaccard The article will proceed as follows: Sect. 2 introduces the method of hashtag segmentation, Sect. 3 provides an analysis of the distribution of the segmentation accuracy, Sect. 4 examines the change in distribution parameters with respect to the dictionary sample size, and Sect. 5 provides a model of predicting the expected segmentation accuracy. The problem of hashtag segmentation is identical to the problem of string seg-mentation described in [ 7 ], which is also applicable to tasks such as novelty we imagine n  X  1 potential breaks in between each of the n characters which we can turn on or off. If the break is turned on, we segment the string at that point; if the break is off, we don X  X  segment the string at that point. Having n potential breaks implies that we have 2 n  X  1 possible segmentations of the given string. To compute the most likely segmentation, we compute the likelihood of each of the possible 2 n  X  1 segmentations and retain the segmentation with max-imum likelihood. We can see that as n grows this approach becomes infeasible due to the exponentially increasing computation required. Rather than observ-ing all 2 n  X  1 possible segmentations, we can use the more sophisticated approach of dynamic programming (also described in [ 7 ]), reducing the complexity to the order of n 2 .
 bility that a given segmentation of a hashtag would be written by the author of the hashtag. A simple method of computing this probability is to assume each term is independent, therefore the probability of a given segmentation is simply the product of the probability of each word in the segmentation. In doing so, we now only need the probability of each word in the segmentation. An estimate of the probability of an author writing a word can easily be computed from a sample of the author X  X  writing, as the proportion of the fre-quency of the word relative to the number of words in the sample. This set of words and their associated probability is referred to as a dictionary. Tradition text segmentation methods compute their dictionary from a large sample of text with the same writing style as the author (e.g. to segment a string from a news article, the dictionary would be constructed from a sample of news articles). In fact, [ 3 ] found that segmentation is highly dependent on the dictionary used. Note that segmentation methods such as [ 1 ] use additional features of the hashtag to compute the probability of the segmented word sequence (such as the case of the letters). For this analysis, we are concerned with the effect of the number of tweets used to construct the dictionary, therefore we treat the hashtag as a string and use no additional information to remove the variability that would be introduced otherwise.
 The language used in Twitter is unlike the language found in published media [ 4 ]. It contains many short snippets of information that is regularly updated by users worldwide, therefore the language used is constantly evolving. To effectively segment hashtags, we must construct the dictionary based on the language used in Twitter, which means using a random sample of tweets. Unfortunately, it is unclear how large a sample we should take to obtain an acceptable level of segmentation accuracy. In the previous section, we established that a random sample of tweets is required to construct a hashtag segmentation dictionary, but we were unsure of how large a sample to obtain. In this section, we will examine the distribution of the segmen-tation accuracy to take a step towards identifying the required sample size. To begin the analysis, we obtained a random sample of 251171 tweets to use as our tweet pool. All further random samples of tweets were resampled from this pool.
 To compute the segmentation accuracy, we must obtain a random sample of hashtags with known segmentations, which we then compare to the predicted segmentation. To observe the distribution, we also require the random sample to be large. Since hashtags are word sequences that have had the space between words removed, we generated a set of hashtags by sampling one tweet at a time from the pool, sampling a random sequence length from a shifted Poisson distribution (with minimum of 1 and mean 3.5, found through analysis of existing hashtag segmentations), then sampling a sequence of that length from the tweet and combining it to form the hashtag. Doing so allowed us to obtain the hashtag and the true segmentation. To ensure that the segmentation dictionary did not contain the tweet in which the hashtag was generated from, we first obtained a random sample of 100 tweets in which we generated one hashtag from each tweet, we then constructed the dictionary using a sample from the remaining tweets in the pool.
 dles and hashtags from the tweet sample. Numbers and punctuation were also removed and each remaining term was case folded. Stemming and stop word removal were not used to ensure that the dictionary contained the distribution over all words and that good estimates of probabilities were obtained. Initial experiments also showed that using stop word removal and stemming when cre-ating a dictionary, harms the accuracy of the hashtag segmenter. This is likely due to the unique spelling and acronyms used to write informative tweets within the 140 character limit. By not removing stop words and not performing stem-ming, we also remove the variability that would be introduced by the different stop word lists and different stemming algorithms that can be used. able length; if both sets are the same, the hashtag segmentation is correct, but as the number of differing words between sets increases, the accuracy is reduced. To evaluate the similarity between the true and predicted segmentation, we used Jaccard similarity, since it is a measure of set similarity.
 each dictionary size, to obtain 5000 Jaccard similarity scores for each dictionary size. The distribution of the 5000 Jaccard similarity scores is shown in Fig. 1 for dictionaries constructed from tweet samples of size 100, 200, 500, 1000, 2000, 5000, 10000, 20000 and 50000. The histograms show a decreasing distribution with a spike at 1 for all dictionary sizes. This implies that there are many Jaccard similarity scores that have values of 0 and 1 and there are a subset that range between 0 and 1. To examine this further, we plotted the histograms again, with all scores of 0 and 1 removed and found the histogram shape to be similar to a Beta density. By examining the Q-Q plot (shown in Fig. 2 ), comparing the quantiles of the scores to the quantiles of the Beta distribution, we found that this mid-band set of scores is very closely aligned to the Beta distribution. bution model for the probability distribution J of a Jaccard score for a given dictionary size, where the probability of J being 0 is the proportion p 1 is the proportion p 1 , and the probability of J being within 0 and 1 follows a Beta distribution with parameters  X  and  X  , giving us four parameters for the model.
 mixture as the density f J ( x ): where  X  ( x ) is the Dirac delta function, p b =1  X  p 1  X  density function of the Beta distribution. It is possible to easily split f its three components, as long as only one of the terms is non-zero for each x . This is true for our model, as long as both  X  and  X  are greater than 1 (causing the Beta density to be pinned to zero when x = 0 or 1). This property is apparent in our model, since we have allocated the scores of 0 and 1 to the Dirac delta functions, leaving a density of 0 for the Beta density function, so we will assume that both  X &gt; 1and  X &gt; 1. This model separation allows us to easily estimate the model parameters from the data:  X  X  p is the proportion of 0 scores (estimate of p 0 ).  X  X  p is the proportion of 1 scores (estimate of p 1 ).  X  X  p =1  X   X  p 0  X   X  p 1 is the proportion of scores between 0 and 1 (estimate of p  X  X   X  =  X  x b  X  x b (1  X   X  x b ) /s 2 b  X  1 (estimate of  X  ).  X   X   X  =(1  X   X  x b )  X  x b (1  X   X  x b ) /s 2 b  X  1 (estimate of  X  ). where  X  x b and s b are the sample mean and standard deviation of the mid-band (excluding scores of 0 and 1) Jaccard scores. The Beta density parameters  X  and  X  are estimated using the method of moments, which is a good approximation Fitting the model to the set of scores for each dictionary construction size pro-vides us with the parameter estimates and standard errors of  X  p  X   X  in Table 1 , where the standard errors were computed from a bootstrap sample of size 1000.
 sampled tweets used to construct the dictionary. As Dict Size increases, we find that  X  p 1 increases and  X  p 0 decreases, displaying that as more tweets are used to construct the dictionary, the proportion of correct hashtag segmentations increases, and the proportion of incorrect segmentations (containing no correct words) decreases. Examining  X  p b , we also find that the proportion of partially correct segmentations decreases. The statistics  X  x b and s standard deviation of the mid-band Jaccard scores (the set of scores with 0 and 1 removed). We find that the mean increases, while the standard deviation increases, then tapers off to stay around 0 . 15 as Dict Size increases. We also find that  X   X  and  X   X  are greater than 1 for all dictionary sizes and don X  X  seem to be approaching 1, which was a required property for using the Method of Moments to estimate the parameters and the provide the model partitioning. Table 1 shows that as the dictionary size increases,  X  p 0 decreases,  X   X  increases and  X   X  decreases, all as we expect to provide an increase in mean Jaccard similarity. In this section, we will explore the relationships fur-ther to gain a deeper understanding of each parameter of the Jaccard similarity distribution, allowing us to make predictions of what dictionary size is needed to obtain a given expected Jaccard similarity. We will first examine the proportions p and p 1 , then proceed to examine the Beta distribution parameters  X  and  X  . approach 0 and p 0 to approach 1 and Dict Size d decreases. We would also expect p 1 to approach an upper limit that may be less than 1 (meaning that the segmenter never achieves perfection for any dictionary size), and p a lower limit greater than 0 (meaning that there will always be hashtags that cannot be segmented for any dictionary size) as d increases. Therefore, we would expect p 1 and p 0 to be well approximated by a type of sigmoid function (to limit p 1 and p 0 to the [0 , 1] domain) of the log scale of d (to extend d to the real domain). The form of the functions are: The plot of the change in p 1 and p 0 with respect to d is shown in Fig. 3 with the fitted models, weighted by standard error, providing parameters  X   X  2 =0 . 569,  X  3 =4 . 267,  X  4 =0 . 958,  X  5 =0 . 498 and  X  show the 95 % confidence interval of the parameter. We can see that the models for both p 1 and p 0 provide an excellent fit to the simulation.
 relationship, therefore we will examine the relationships between  X  the mid-band) and  X  , since  X  can be calculated from these. The mean  X  the same conditions as the proportion p 1 , therefore we use the same model form. The parameter  X  seems to be decreasing, but plateaus near 5 as d increases. After examining the data, we arrived at the functions: The plot of the change in  X  b and  X  with respect to d is shown in Fig. 4 with the fitted models, weighted by their standard error, providing parameters  X   X  =0 . 406,  X  9 =2 . 181,  X  10 = 399 . 21 and  X  11 =5 . 512. The error bars show the 95 % confidence interval of the parameter. We can see that the models for both  X  and  X  provide an excellent fit to the data. To compute the values for  X  b the mid-band standard deviation, and  X  ,we use the known relationships of the Beta distribution: where  X  b and  X  are given by the previous functions. The plot of the change in  X  and  X  with respect to d is shown in Fig. 5 with the fitted functions. The error bars show the 95 % confidence interval of the parameter. We can see again that the models for both  X  b and  X  provide an excellent fit to the data. We have found that each of p 1 , p 0 ,  X  and  X  can be accurately estimated as functions of d (the number of tweets used to generate the dictionary), in turn describing the Jaccard similarity distribution, once we have obtained fitted values for the 11 parameters.
 Note that a limitation of our analysis comes from taking each tweet sam-ple from the pool of 251171 tweets. This sample size is sufficient for generating hastags, and for dictionaries using a small number of tweets. But when randomly sampling 200000 tweets from the pool to compute a dictionary, the sample size is of the same order as the population being sampled from, therefore the variance introduced by randomly sampling for large dictionaries is reduced when compared to a pure random sample from Twitter. We believe that this will only effect the values of  X  1 ,  X  4 and  X  7 , but further analysis is required to test this effect. The previous section showed that we can model the Jaccard accuracy as a func-tion of d (the number of tweets used to construct the segmentation dictionary). In this section, we will examine how well our model can estimate the four dis-tribution parameters when not included in the parameter fitting process. eleven parameters using all data, excluding the data associated to the desired d . We then used our model to compute the 11 distribution parameters and then predict the mean and standard deviation of the Zero-One inflated Beta distribution for the desired d (using the equations in Appendix A ). This process was repeated for all d . Table 2 contains the mean and standard deviation of the Jaccard scores predicted by the model and computed from the sample data. We find that the predictions from the model are very accurate, showing how closely the sample data follows the model. The results show that this model can be used to compute the expected Jaccard similarity, and hence compute the number of tweets required to construct a dictionary in order to obtain a given expected Jaccard similarity. Using knowledge of the distribution, other statistics can also be computed (such as quantiles for confidence intervals). To assist in computing the required statistics, or for model validation, the source code is available at the authors X  Web site 2 . Hashtag segmentation allows us to obtain a more in depth analysis of Twitter data. Automatic hashtag segmentation requires a domain specific dictionary and therefore should be computed from a random sample of tweets.
 In this article we examined the effect of the tweet sample size, used to create the segmentation dictionary, on the accuracy of automatic hashtag segmentation. We found not only that the accuracy distribution is a Zero-One inflated Beta distribution containing four parameters, but we also found that each of the four parameters can be modelled on the number of tweets used to construct the dictionary.
 This model can be used to predict the distribution and statistics of the accu-racy distribution for automatic hashtag segmentation, when using a given num-ber of tweets to construct the dictionary. The model can also be used to gain deeper understanding into the relationships between the model parameters. The mean and variance of our Jaccard similarity (Zero-One inflated Beta) density function f J ( x )fromEq. 1 is derived from the expected value of J and J
