 Concept-Based Semantic Video Retrieval (CBSVR) usually uses semantic representations of videos to handle user X  X  re-trieval requests. It is obvious that the accuracy of seman-tic video retrieval depends on results of concept detectors, but the detection results are usually imprecise and uncer-tain. In this paper, we propose a multi-information fusion approach (MIF) which is dedicated to solving the problem of uncertain semantic representations of videos for improv-ing retrieval accuracy. This approach is based on a novel two-phase framework that involves the inferring phase and the fusing phase . In the inferring phase, the most relevant concepts to the user X  X  query are chosen by exploring both contextual correlation among concepts and temporal corre-lation among shots. In the fusing phase, the inferred prob-abilities of the related concepts are fused together with the detection results via minimization of potential function to refine the detector prediction. Experiments on the widely used TRECVID datasets demonstrate that our approach can effectively improve the accuracy of semantic concept detec-tion.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Measurement, Experimentation, Performance Concept detector, Semantic space, Contextual, Temporal
Recently, concept-based semantic video retrieval has been proposed by pooling a set of pre-trained semantic concept Figure 1: The detection results of concept detectors. Some imprecise and uncertain results are observed from two points of view: contextual correlation and temporal correlation detectors which can be regarded as intermediate descriptors to bridge the semantic gap [4]. The general method to learn the detectors is based on generic features with labeled video shots by manual annotation. The results of concept detec-tors indicate the probability of target concept X  X  presence in given video shots. However, the detection results of concept detectors are usually imprecise and uncertain. As shown in Figure 1, we observe that some detection results are in con-tradiction with the ground truth. For example, the probabil-ity of concept car presence in video shot S 4 is 0.3, but actu-ally it should have a higher probability according to the con-textual correlation and temporal correlation. From contex-tual correlation among concepts perspective, some concepts often co-occur within the same shot such as the concept car frequently co-occurs with concept outdoor . From temporal correlation among video shots perspective, the concept car coexists within shots from S1 to S6. We can also infer that concept car presented in video shot S 3 should have a higher probability value according to the probability of neighboring shot of S 3 . Since video shots are often visually continuous, once a concept occurs in a shot, it generally spans multiple consecutive shots.

In this paper, we propose a multi-information fusion ap-proach (MIF), which focuses on solving the difficulty of un-certain semantic representations of videos by refining the detection results. This approach is based on a novel two-phase framework that involves the inferring phase and the fusing phase. In the inferring phase, we simultaneously uti-lize the information of contextual correlation and temporal correlation to select the most relevant concepts to the user X  X  query. To model the contextual correlation among concepts, firstly, an orthogonal semantic concept space is built by ex-ploring the concept from the manually labeled ground truth. We filter out the redundant concepts by Affinity Propaga-tion (AP) method [6] before the construction of semantic concept space, because only a few concepts can be used to aid semantic inference. Using all concepts for inference not only increases complexity, but degrades the performance of the semantic space. Secondly, a recursive algorithm is pro-posed to discover the temporal correlation among shots. In the fusing phase, the inferred probabilities of the selected relevant concepts are fused together with prediction values from the concept detectors to refine the detection results.
To the best of our knowledge, there are no other efforts to address the problem of uncertain semantic representations by simultaneously exploring both the contextual correlation and the temporal correlation.
 Figure 2: An overview of multi-information fusion approach, which is based on a two-phase: the infer-ring phase and the fusing phase respectively.
As we known from above, the information of contextual correlation and temporal correlation can be utilized to the inference of semantic concept. To solve the problem of un-certain semantic representation, we propose a method of multi-information fusion, which is based on a two-phase framework, as shown in Figure 2.
To model the contextual correlation among concepts, an orthogonal semantic concept space is built by exploring the concept from the manually labeled ground truth. We hope that the orthogonal semantic concept space has a high cover-age of semantic representation with minimal set of concepts by filtering out the redundant concepts. If we use all the concepts, it is not only increases complexity, but degrades the performance of semantic space. In addition, a recursive algorithm is proposed to discover the temporal correlation among shots.
Given a concept lexicon C = { c 1 , c 2 , ..., c m } , we will be clustering the concept lexicon C into k ( k &lt; m ) clusters, each cluster is represented by the most representative con-cept we called icon-concept. In the initialization phase of affinity propagation, all the concepts are regard as poten-tial icon-concept, and each concept can be seen as node in a full connected graph. The message among the concepts is recursively transmitted via the edges of the graph until a real good set of icon-concept and their corresponding clus-ters emerge. Then we can obtain a new concept lexicon C 0 = { c 1 , c 2 , ..., c k } , which removes the redundant concept and consist of k icon-concepts .
Given the new concept lexicon C 0 = { c 1 , c 2 , ..., c k goal is to construct a semantic concept space which could high coverage the semantic concept and model the contex-tual correlation of concept in a global view. We firstly calcu-late the relationship matrix R, which encapsulate the inter-concept relationship. The concept relationship matrix R will be further decomposed by Karhunen-Loeve transform [5] for deriving the orthogonal basis vector which forms an orthogonal semantic concept space.
 Here, The concept correlation matrix R is defined as:
Then, the eigenvalue decomposition of concept correlation matrix R by calculating where  X  is the diagonal matrix having as elements on its diagonal the respective eigenvalues of correlation matrix R. O is the orthogonal eigenvector matrix corresponding to all the eigenvalue, which is defined by O = ( q 1 , q 2 , ..., q is the normalized eigenvectors of concept correlation matrix R corresponding to the eigenvalue  X  i .

We denote that ( q 1 , q 2 , ..., q v ) T is an orthogonal basis vec-tor of semantic concept space. The orthogonal semantic concept space can be defined as: which is a linear orthogonal space generated by linear com-binations of ( q 1 , q 2 , ..., q v ) T .

Therefore, the orthogonal concept space spanned by or-thogonal basis vectors and modeled with the contextual cor-relation of concepts. It provides a computable space where the query concept mapping can be directly reasoned, be-cause the contextual correlation of concepts is inherently encapsulated in space by similarity measures. Comparing with the similarity of the query concept c t and the concepts in C 0 , the most relevant concepts to the query concept are selected, which will be used to semantic inference in the next section.
For the query concept c t , the probability of presence of c in unlabeled shot s i can be inferred by selecting the most rel-evant concepts from the orthogonal semantic concept space. Here, the selected concepts can be seen as the condition of the query concept occurs in shot. we can obtain the con-dition probability that the query concept occurs given the corresponding condition, we further derive the inferred prob-ability of query concept c t occurs in unlabeled shot s i is defined as: where  X  k is a condition set, which include the related con-cept to the query.  X  (  X  k , s i ) is a condition test function, if shot s i satisfies all of the conditions of  X  k , the condition test function return 1; otherwise return 0. Note that we consider that among the concepts is mutually independent. Algorithm 1 RECURSIV E ( c t , b, f, S,  X  ) Given a query concept c t , two relative distances b and f indicate two can-didate shots which respectively refer to the previous b -shot and the next f -shot apart from the observed shot. A set of labeled shots S , and a condition  X  which is true for each and p is the probability that the query concept ct occurs given  X  o . F is the aforementioned Chi-square test function. The  X  is a user specified threshold. Initially, b =1, f =1, and  X  =true. 1: F b = F ( l c t s 2: F f = F ( l c t s 3: if F b &lt;  X  and F f &lt;  X  then 4: Calculate p , the probability of the occurrence of c i 5: return { ( p,  X  ) } 6: else 7: if F b &gt; F f then 8:  X  =  X   X   X  i  X  b 9: b = b + 1 10: else 11:  X  =  X   X   X  i + f 12: f = f + 1 13: end if 14: end if 15: S =  X  (  X , S ) 16: R tem = RECURSIV E ( c t , b, f, S,  X  ) 17: return R tem
For each concept, we not only employ the contextual cor-relation by semantic concept space, but also discover the temporal correlation from the neighboring shots. It is ob-vious that temporally closer shots should have higher cor-relation than more distant ones. Thus, if shot s i  X  b is not significant correlated to shot s i , then it is not necessary to test further neighbors s i  X  b  X  1 and so on. Instead of find-ing the shot with highest correlation among all candidates, we sequentially test correlations of neighboring shots and gradually add neighbors until the correlation is not signif-icant by a recursive algorithm. We execute the procedure in both forward and backward directions simultaneously by selecting in each iteration the direction with higher correla-tion. The procedure stops when no significant correlation is found. When no correlated shot is found, a set of tuples is returned to represent the temporal correlation in terms of relative temporal order distances.
With exploring the contextual correlation and temporal correlation, we can use them to infer the probability of the query concept c t occurrence in any unlabeled shot s i . The inferred probability with contextual correlation and tempo-ral correlation is defined as P ( l c t s spectively. Given the selected m concepts, we can calculate the inferred probability of c t occurs in s i by following: where P (  X  (  X  k , s i ) = 1) is the probability that unlabeled shot s i satisfies the condition  X  k . In the same way, the inferred probability with temporal correlation can be calcu-lated.

In the fusing phase, the prediction score of concept detec-tors is integrated with the inferred probabilities using the information of contextual correlation and temporal correla-tion. We use d P c t s i to indicate the refined score, which should satisfy the contextual correlation and temporal correlation and approximate to the detection score for each concept in each shot.

When the given query concept c t presents in a unlabeled shot s i , the energy term of c t can be defined as: where  X  and  X  should be adjusted according to the con-cept, because we observed that the reliability of contextual correlation and temporal correlation varies from concept to tained using the concept detector, contextual correlation, temporal correlation for concept c t , respectively. We set APs of most concepts range between 0.3 and 0.5, we set  X  d = 0 . 45 for all concepts; APs  X  textual correlation and temporal correlation are estimated from the annotations.

Then, based on E c t s for multi-information fusion is formed by summing all energy produced by each concept for each testing shot, which is defined as: where n is the total number of shots in the testing set. We can obtain the final refined scores by solving Equation 6. The refined scores are consistent with the contextual correlation and temporal correlation.
To evaluate the performance of the proposed approach, we conducted experiments on the benchmark TRECVID [1] data set. We use the TV05 development set as the training VIREO-374 baseline, Columbia374 baseline and the proposed MIF. Table 1: Performance comparison with two baseline on TV06 test set Concept VIREO-374 Columbia374 MIF Sports 0.392 0.431 0.445 Weather 0.433 0.357 0.459 Meeting 0.295 0.327 0.356 Office 0.081 0.025 0.086 Mountain 0.182 0.229 0.220 Desert 0.045 0.056 0.059 Waterscape 0.098 0.145 0.128 Police Security 0.015 0.015 0.019 Military 0.098 0.122 0.134 Animal 0.006 0.004 0.007 Computer TV 0.273 0.273 0.289 Corporate 0.008 0.005 0.047 Airplane 0.018 0.050 0.054 Car 0.164 0.183 0.191 Flag US 0.269 0.291 0.316 Truck 0.064 0.082 0.082 People March 0.050 0.060 0.068 Explosion Fire 0.165 0.165 0.169 Map 0.286 0.294 0.341 Chart 0.165 0.204 0.181 MAP 0.155 0.167 0.179
Improvement 6.5% 7.3% 15.6% corpus and performed the evaluations on the TV06 test set. We use the annotations of TV05 dataset from Columbia374 [3], which has a lexicon of 374 semantic concepts. We dis-covered the contextual correlation and temporal correlation from these annotations. The optimization was performed independently on each video for simultaneously labeling of all concepts and shots. We describe performance on the 20 officially evaluated concepts in table 1. The concept detec-tors of Columbia374 [3] and VIREO-374 [2] for the test data set are utilized. We use inferred average precision (infAP) to evaluate the results.

As shown in table 1, We observed that the proposed MIF method using the contextual correlation and temporal cor-relation performs best for 16 out of 20 concepts. Overall, the improvement of the concept detectors is 15.6%, which doubles that of the performance of the baseline.

Figure 3 illustrates that our approach improves each of the 20 concepts with ranges varying from 6.7% to 78.8% over the VIREO-374 and Colunmbia374 baseline. In addition, 16 concepts yield more than 25% relative improvement. We observed that some concepts benefit greatly from MIF, e.g.,
Car , Sports and Weather .
In this paper, we proposed a novel approach to solve the problem of uncertain semantic representations to refine the accuracy of concept detectors for improving the accuracy of the semantic video retrieval. This work has two main contri-butions; the first is an exploration of contextual correlation among concepts and temporal correlation among shots. Sec-ond, the refined detector scores can be obtained by fusing the prediction results together with inferred probability of contextual and temporal correlation.
This research was supported by the National Natural Sci-ence Foundation of China (Grant No. 60873011, 60933001), 863 High Tech. Planning Program of China (Grant No. 2009AA01Z150), and National Basic Research Program of
China (Grant No. 2006CB303103). [1] A. F. Smeaton, P. Over, and W. Kraaij. Evaluation [2] Y.-G. jiang, C.-w. Ngo, and J.Yang. Towards optimal [3] A. Yanagawa, S.-F. Chang, L.Kennedy, and W. Hsu. [4] S. F. Chang, W. Y. Ma, and A. Smeulders. Recent [5] Michelle Effros, Hanying Feng, Kenneth Zeger. [6] B. Frey and D. Dueck. Clustering by passing messages
