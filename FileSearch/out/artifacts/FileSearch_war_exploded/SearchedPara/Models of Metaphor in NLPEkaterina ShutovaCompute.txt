 Our production and comprehension of language is a multi-layered computational process. Hu-mans carry out high-level semantic tasks effort-lessly by subconsciously employing a vast inven-tory of complex linguistic devices, while simulta-neously integrating their background knowledge, to reason about reality. An ideal model of lan-guage understanding would also be capable of per-forming such high-level semantic tasks.

However, a great deal of NLP research to date focuses on processing lower-level linguistic infor-mation, such as e.g. part-of-speech tagging, dis-covering syntactic structure of a sentence (pars-ing), coreference resolution, named entity recog-nition and many others. Another cohort of re-searchers set the goal of improving application-based statistical inference (e.g. for recognizing textual entailment or automatic summarization). In contrast, there have been fewer attempts to bring the state-of-the-art NLP technologies to-gether to model the way humans use language to frame high-level reasoning processes, such as for example, creative thought.

The majority of computational approaches to figurative language still exploit the ideas articu-lated three decades ago (Wilks, 1978; Lakoff and Johnson, 1980; Fass, 1991) and often rely on task-specific hand-coded knowledge. However, recent work on lexical semantics and lexical acquisition techniques opens many new avenues for creation of fully automated models for recognition and in-terpretation of figurative language. In this pa-per I will focus on the phenomenon of metaphor and describe the most prominent computational approaches to metaphor, as well the issues of re-source creation and metaphor annotation.

Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the con-cepts. Similarity is a kind of association implying the presence of characteristics in common. Here are some examples of metaphor. (1) Hillary brushed aside the accusations. (2) How can I kill a process? (Martin, 1988) (3) I invested myself fully in this relationship. (4) And then my heart with pleasure fills , In metaphorical expressions seemingly unrelated features of one concept are associated with an-other concept. In the example (2) the computa-tional process is viewed as something alive and, therefore, its forced termination is associated with the act of killing.

Metaphorical expressions represent a great vari-ety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The use of metaphor is ubiq-uitous in natural language text and it is a seri-ous bottleneck in automatic text understanding. In order to estimate the frequency of the phe-nomenon, Shutova (2010) conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various gen-res. They manually annotated metaphorical ex-pressions in this data and found that 241 out of 761 sentences contained a metaphor. Due to such a high frequency of their use, a system capable of recognizing and interpreting metaphorical expres-sions in unrestricted text would become an invalu-able component of any semantics-oriented NLP application.

Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor in-terpretation (identifying the intended literal mean-ing of a metaphorical expression). Both of them have been repeatedly addressed in NLP. Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the inter-action view (Black, 1962), (Hesse, 1966), the se-lectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980) 2 . All of these ap-proaches share the idea of an interconceptual map-ping that underlies the production of metaphorical expressions. In other words, metaphor always in-volves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle ). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff (6) He attacked every weak point in my argu-
According to Lakoff and Johnson (1980), a mapping of a concept of argument to that of war is employed here. The argument , which is the tar-get concept, is viewed in terms of a battle (or a war ), the source concept. The existence of such a link allows us to talk about arguments using the war terminology, thus giving rise to a number of metaphors.
However, Lakoff and Johnson do not discuss how metaphors can be recognized in the linguis-tic data, which is the primary task in the auto-matic processing of metaphor. Although humans are highly capable of producing and comprehend-ing metaphorical expressions, the task of distin-guishing between literal and non-literal meanings and, therefore, identifying metaphor in text ap-pears to be challenging. This is due to the vari-ation in its use and external form, as well as a not clear-cut semantic distinction. Gibbs (1984) suggests that literal and figurative meanings are situated at the ends of a single continuum, along which metaphoricity and idiomaticity are spread. This makes demarcation of metaphorical and lit-eral language fuzzy.

So far, the most influential account of metaphor recognition is that of Wilks (1978). According to Wilks, metaphors represent a violation of selec-tional restrictions in a given context. Selectional restrictions are the semantic constraints that a verb places onto its arguments. Consider the following example. (7) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may in turn in-dicate the metaphorical use of drink . One of the first attempts to identify and inter-pret metaphorical expressions in text automati-cally is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes hand-coded knowledge. Fass (1991) developed a system called met*, capable of discriminating between literalness, metonymy, metaphor and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selec-tional preference violation as an indicator. In the case that non-literalness is detected, the respective phrase is tested for being a metonymic relation us-ing hand-coded patterns (such as CONTAINER-for-CONTENT). If the system fails to recognize metonymy, it proceeds to search the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. E.g., the sentence in (7) would be represented in this framework as ( car,drink,gasoline ), which does not satisfy the preference ( animal,drink,liquid ), as car is not a hyponym of animal . met* then searches its knowledge base for a triple containing a hypernym of both the actual argument and the desired argu-ment and finds ( thing,use,energy source ), which represents the metaphorical interpretation.
However, Fass himself indicated a problem with the selectional preference violation approach ap-plied to metaphor recognition. The approach de-tects any kind of non-literalness or anomaly in language (metaphors, metonymies and others), and not only metaphors, i.e., it overgenerates. The methods met* uses to differentiate between those are mainly based on hand-coded knowledge, which implies a number of limitations.

Another problem with this approach arises from the high conventionality of metaphor in language. This means that some metaphorical senses are very common. As a result the system would ex-tract selectional preference distributions skewed towards such conventional metaphorical senses of the verb or one of its arguments. Therefore, al-though some expressions may be fully metaphor-ical in nature, no selectional preference violation can be detected in their use. Another counterar-gument is bound to the fact that interpretation is always context dependent, e.g. the phrase all men are animals can be used metaphorically, however, without any violation of selectional restrictions.
Goatly (1997) addresses the phenomenon of metaphor by identifying a set of linguistic cues indicating it. He gives examples of lexical pat-terns indicating the presence of a metaphorical ex-pression, such as metaphorically speaking, utterly, completely, so to speak and, surprisingly, liter-ally . Such cues would probably not be enough for metaphor extraction on their own, but could con-tribute to a more complex system.

The work of Peters and Peters (2000) concen-trates on detecting figurative language in lexical resources. They mine WordNet (Fellbaum, 1998) for the examples of systematic polysemy, which allows to capture metonymic and metaphorical re-lations. The authors search for nodes that are rel-atively high up in the WordNet hierarchy and that share a set of common word forms among their de-scendants. Peters and Peters found that such nodes often happen to be in metonymic (e.g. publica-tion  X  publisher ) or metaphorical (e.g. supporting structure  X  theory ) relation.

The CorMet system discussed in (Mason, 2004) is the first attempt to discover source-target do-main mappings automatically. This is done by  X  X inding systematic variations in domain-specific selectional preferences, which are inferred from large, dynamically mined Internet corpora X . For example, Mason collects texts from the LAB do-main and the FINANCE domain, in both of which pour would be a characteristic verb. In the LAB domain pour has a strong selectional preference for objects of type liquid , whereas in the FI-NANCE domain it selects for money . From this Mason X  X  system infers the domain mapping FI-NANCE  X  LAB and the concept mapping money  X  liquid . He compares the output of his system against the Master Metaphor List (Lakoff et al., 1991) containing hand-crafted metaphorical map-pings between concepts. Mason reports an accu-racy of 77%, although it should be noted that as any evaluation that is done by hand it contains an element of subjectivity.

Birke and Sarkar (2006) present a sentence clus-tering approach for non-literal language recog-nition implemented in the TroFi system (Trope Finder). This idea originates from a similarity-based word sense disambiguation method devel-oped by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most simi-lar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: literal vs. non-literal, and they do not clearly de-fine the kinds of tropes they aim to discover. They attain a performance of 53.8% in terms of f-score.
The method of Gedigan et al. (2006) discrimi-nates between literal and metaphorical use. They trained a maximum entropy classifier for this pur-pose. They obtained their data by extracting the lexical items whose frames are related to MO-TION and CURE from FrameNet (Fillmore et al., 2003). Then they searched the PropBank Wall Street Journal corpus (Kingsbury and Palmer, 2002) for sentences containing such lexical items and annotated them with respect to metaphoric-ity. They used PropBank annotation (arguments and their semantic types) as features to train the classifier and report an accuracy of 95.12%. This result is, however, only a little higher than the per-formance of the naive baseline assigning major-ity class to all instances (92.90%). These numbers can be explained by the fact that 92.00% of the verbs of MOTION and CURE in the Wall Street Journal corpus are used metaphorically, thus mak-ing the dataset unbalanced with respect to the tar-get categories and the task notably easier.
Both Birke and Sarkar (2006) and Gedigan et al. (2006) focus only on metaphors expressed by a verb. As opposed to that the approach of Kr-ishnakumaran and Zhu (2007) deals with verbs, nouns and adjectives as parts of speech. They use hyponymy relation in WordNet and word bi-gram counts to predict metaphors at a sentence level. Given an IS-A metaphor (e.g. The world is a stage 3 ) they verify if the two nouns involved are in hyponymy relation in WordNet, and if they are not then this sentence is tagged as con-taining a metaphor. Along with this they con-sider expressions containing a verb or an adjec-tive used metaphorically (e.g. He planted good ideas in their minds or He has a fertile imagi-nation ). Hereby they calculate bigram probabil-ities of verb-noun and adjective-noun pairs (in-cluding the hyponyms/hypernyms of the noun in question). If the combination is not observed in the data with sufficient frequency, the system tags the sentence containing it as metaphorical. This idea is a modification of the selectional prefer-ence view of Wilks. However, by using bigram counts over verb-noun pairs Krishnakumaran and Zhu (2007) loose a great deal of information com-pared to a system extracting verb-object relations from parsed text. The authors evaluated their sys-tem on a set of example sentences compiled from the Master Metaphor List (Lakoff et al., 1991), whereby highly conventionalized metaphors (they call them dead metaphors ) are taken to be negative examples. Thus they do not deal with literal exam-ples as such: essentially, the distinction they are making is between the senses included in Word-Net, even if they are conventional metaphors, and those not included in WordNet. Almost simultaneously with the work of Fass (1991), Martin (1990) presents a Metaphor In-terpretation, Denotation and Acquisition System (MIDAS). In this work Martin captures hierarchi-cal organisation of conventional metaphors. The idea behind this is that the more specific conven-tional metaphors descend from the general ones. Given an example of a metaphorical expression, MIDAS searches its database for a corresponding metaphor that would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a map-ping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been inte-grated with the Unix Consultant (UC), the sys-tem that answers users questions about Unix. The UC first tries to find a literal answer to the ques-tion. If it is not able to, it calls MIDAS which detects metaphorical expressions via selectional preference violation and searches its database for a metaphor explaining the anomaly in the question.
Another cohort of approaches relies on per-forming inferences about entities and events in the source and target domains for metaphor in-terpretation. These include the KARMA sys-tem (Narayanan, 1997; Narayanan, 1999; Feld-man and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accor-dance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual map-ping representation. The ATT-Meta project con-cerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are representations of small discourse fragments. KARMA in turn deals with a broad range of abstract actions and events and takes parsed text as input.

Veale and Hao (2008) derive a  X  X luid knowl-edge representation for metaphor interpretation and generation X , called Talking Points. Talk-ing Points are a set of characteristics of concepts belonging to source and target domains and re-lated facts about the world which the authors ac-quire automatically from WordNet and from the web. Talking Points are then organized in Slip-net , a framework that allows for a number of insertions, deletions and substitutions in defini-tions of such characteristics in order to establish a connection between the target and the source concepts. This work builds on the idea of slip-page in knowledge representation for understand-ing analogies in abstract domains (Hofstadter and Mitchell, 1994; Hofstadter, 1995). Below is an example demonstrating how slippage operates to explain the metaphor Make-up is a Western burqa .
By doing insertions and substitutions the sys-tem arrives from the definition typically worn by women to that of must be worn by Muslim women , and thus establishes a link between the concepts of make-up and burqa . Veale and Hao (2008), however, did not evaluate to which extent their knowledge base of Talking Points and the asso-ciated reasoning framework are useful to interpret metaphorical expressions occurring in text.
Shutova (2010) defines metaphor interpretation as a paraphrasing task and presents a method for deriving literal paraphrases for metaphorical ex-pressions from the BNC. For example, for the metaphors in  X  X ll of this stirred an unfathomable excitement in her X  or  X  X  carelessly leaked report X  their system produces interpretations  X  X ll of this provoked an unfathomable excitement in her X  and  X  X  carelessly disclosed report X  respectively. They first apply a probabilistic model to rank all pos-sible paraphrases for the metaphorical expression given the context; and then use automatically in-duced selectional preferences to discriminate be-tween figurative and literal paraphrases. The se-lectional preference distribution is defined in terms of selectional association measure introduced by Resnik (1993) over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors ex-pressed by a verb and report a paraphrasing accu-racy of 0.81. Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an exten-sive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991; Martin, 1990), it should be noted that the systems utilizing it have a very limited coverage.
One of the first attempts to create a multi-purpose knowledge base of source X  X arget domain mappings is the Master Metaphor List (Lakoff et al., 1991). It includes a classification of metaphor-ical mappings (mainly those related to mind, feel-ings and emotions) with the corresponding exam-ples of language use. This resource has been criti-cized for the lack of clear structuring principles of the mapping ontology (L  X  onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by different class la-bels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creation of other metaphor resources.

The most prominent of them are MetaBank (Martin, 1994) and the Mental Metaphor Data-bank 4 created in the framework of the ATT-meta project (Barnden and Lee, 2002; Agerri et al., 2007). The MetaBank is a knowledge-base of En-glish metaphorical conventions, represented in the form of metaphor maps (Martin, 1988) contain-ing detailed information about source-target con-cept mappings backed by empirical evidence. The ATT-meta project databank contains a large num-ber of examples of metaphors of mind classified by source X  X arget domain mappings taken from the Master Metaphor List.

Along with this it is worth mentioning metaphor resources in languages other than English. There has been a wealth of research on metaphor in Spanish, Chinese, Russian, German, French and Italian. The Hamburg Metaphor Database (L  X  onneker, 2004; Reining and L  X  onneker-Rodman, 2007) contains examples of metaphorical expres-sions in German and French, which are mapped to senses from EuroWordNet 5 and annotated with source X  X arget domain mappings taken from the Master Metaphor List.

Alonge and Castelli (2003) discuss how metaphors can be represented in ItalWordNet for Italian and motivate this by linguistic evidence. Encoding metaphorical information in general-domain lexical resources for English, e.g. Word-Net (L  X  onneker and Eilts, 2004), would undoubt-edly provide a new platform for experiments and enable researchers to directly compare their re-sults. To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source  X  tar-get domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocab-ulary (Deignan, 2006; Koivisto-Alanko and Tis-sari, 2006; Martin, 2006) or for linguistic mark-ers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of iso-lated words, but rather involves reconceptualiza-tion of a whole area of experience in terms of an-other, there still has been surprisingly little inter-est in annotation of cross-domain mappings. How-ever, a corpus annotated for conceptual mappings could provide a new starting point for both linguis-tic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic ) metaphors, that surprise our imagination, and con-ventionalized metaphors, that become a part of an ordinary discourse.  X  X etaphors begin their lives as novel poetic creations with marked rhetorical effects, whose comprehension requires a special imaginative leap. As time goes by, they become a part of general usage, their comprehension be-comes more automatic, and their rhetorical effect is dulled X  (Nunberg, 1987). Following Orwell (1946) Nunberg calls such metaphors  X  X ead X  and claims that they are not psychologically distinct from literally-used terms.

This scheme demonstrates how metaphorical associations capture some generalisations govern-ing polysemy: over time some of the aspects of the target domain are added to the meaning of a term in a source domain, resulting in a (metaphor-ical) sense extension of this term. Copestake and Briscoe (1995) discuss sense extension mainly based on metonymic examples and model the phe-nomenon using lexical rules encoding metonymic patterns. Along with this they suggest that similar mechanisms can be used to account for metaphoric processes, and the conceptual mappings encoded in the sense extension rules would define the lim-its to the possible shifts in meaning.

However, it is often unclear if a metaphorical instance is a case of broadening of the sense in context due to general vagueness in language, or it manifests a formation of a new distinct metaphor-ical sense. Consider the following examples. (8) a. As soon as I entered the room I noticed (9) a. My tea is cold .
Enter in (8a) is defined as  X  X o go or come into a place, building, room, etc.; to pass within the boundaries of a country, region, portion of space, medium, etc. X  6 In (8b) this sense stretches to describe dealing with software , whereby COM-PUTER PROGRAMS are viewed as PHYSICAL SPACES. However, this extended sense of enter does not appear to be sufficiently distinct or con-ventional to be included into the dictionary, al-though this could happen over time.

The sentence (9a) exemplifies the basic sense of cold  X   X  X f a temperature sensibly lower than that of the living human body X , whereas cold in (9b) should be interpreted metaphorically as  X  X oid of ardour, warmth, or intensity of feeling; lacking enthusiasm, heartiness, or zeal; indifferent, apa-thetic X . These two senses are clearly linked via the metaphoric mapping between EMOTIONAL STATES and TEMPERATURES.

A number of metaphorical senses are included in WordNet, however without any accompanying semantic annotation. 6.2 Metaphor Identification 6.2.1 Pragglejaz Procedure Pragglejaz Group (2007) proposes a metaphor identification procedure (MIP) within the frame-work of the Metaphor in Discourse project (Steen, 2007). The procedure involves metaphor annota-tion at the word level as opposed to identifying metaphorical relations (between words) or source X  target domain mappings (between concepts or do-mains). In order to discriminate between the verbs used metaphorically and literally the annotators are asked to follow the guidelines: 1. For each verb establish its meaning in context 2. If you can establish the basic meaning that
Such annotation can be viewed as a form of word sense disambiguation with an emphasis on metaphoricity. 6.2.2 Source  X  Target Domain Vocabulary Another popular method that has been used to ex-tract metaphors is searching for sentences contain-ing lexical items from the source domain, the tar-get domain, or both (Stefanowitsch, 2006). This method requires exhaustive lists of source and tar-get domain vocabulary.

Martin (2006) conducted a corpus study in order to confirm that metaphorical expressions occur in text in contexts containing such lex-ical items. He performed his analysis on the data from the Wall Street Journal (WSJ) cor-pus and focused on four conceptual metaphors that occur with considerable regularity in the corpus. These include NUMERICAL VALUE AS LOCATION, COMMERCIAL ACTIVITY AS CONTAINER, COMMERCIAL ACTIVITY AS PATH FOLLOWING and COMMERCIAL ACTIVITY AS WAR. Martin manually compiled the lists of terms characteristic for each domain by examining sampled metaphors of these types and then augmented them through the use of thesaurus. He then searched the WSJ for sen-tences containing vocabulary from these lists and checked whether they contain metaphors of the above types. The goal of this study was to evaluate predictive ability of contexts containing vocabulary from (1) source domain and (2) target domain, as well as (3) estimating the likelihood of a metaphorical expression following another metaphorical expression described by the same mapping. He obtained the most positive results for metaphors of the type NUMERICAL-VALUE-AS-LOCATION ( P ( Metaphor | Source )= 0 . 069 , P ( Metaphor | Target )=0 . 677 , P ( Metaphor | Metaphor )=0 . 703 ). 6.3 Annotating Source and Target Domains Wallington et al. (2003) carried out a metaphor an-notation experiment in the framework of the ATT-Meta project. They employed two teams of an-notators. Team A was asked to annotate  X  X nter-esting stretches X , whereby a phrase was consid-ered interesting if (1) its significance in the doc-ument was non-physical, (2) it could have a phys-ical significance in another context with a similar syntactic frame, (3) this physical significance was related to the abstract one. Team B had to anno-tate phrases according to their own intuitive defi-nition of metaphor. Besides metaphorical expres-sions Wallington et al. (2003) attempted to anno-tate the involved source  X  target domain mappings. The annotators were given a set of mappings from the Master Metaphor List and were asked to assign the most suitable ones to the examples. However, the authors do not report the level of interannota-tor agreement nor the coverage of the mappings in the Master Metaphor List on their data.

Shutova and Teufel (2010) adopt a different ap-proach to the annotation of source  X  target do-main mappings. They do not rely on prede-fined mappings, but instead derive independent sets of most common source and target categories. They propose a two stage procedure, whereby the metaphorical expressions are first identified using MIP, and then the source domain (where the ba-sic sense comes from) and the target domain (the given context) are selected from the lists of cate-gories. Shutova and Teufel (2010) report interan-notator agreement of 0.61 (  X  ). The eighties and nineties provided us with a wealth of ideas on the structure and mechanisms of the phenomenon of metaphor. The approaches formulated back then are still highly influential, although their use of hand-coded knowledge is becoming increasingly less convincing. The last decade witnessed a high technological leap in natural language computation, whereby manually crafted rules gradually give way to more robust corpus-based statistical methods. This is also the case for metaphor research. The latest develop-ments in the lexical acquisition technology will in the near future enable fully automated corpus-based processing of metaphor.

However, there is still a clear need in a uni-fied metaphor annotation procedure and creation of a large publicly available metaphor corpus. Given such a resource the computational work on metaphor is likely to proceed along the following lines: (1) automatic acquisition of an extensive set of valid metaphorical associations from linguis-tic data via statistical pattern matching; (2) using the knowledge of these associations for metaphor recognition in the unseen unrestricted text and, fi-nally, (3) interpretation of the identified metaphor-ical expressions by deriving the closest literal paraphrase (a representation that can be directly embedded in other NLP applications to enhance their performance).

Besides making our thoughts more vivid and filling our communication with richer imagery, metaphors also play an important structural role in our cognition. Thus, one of the long term goals of metaphor research in NLP and AI would be to build a computational intelligence model account-ing for the way metaphors organize our conceptual system, in terms of which we think and act. I would like to thank Anna Korhonen and my re-viewers for their most helpful feedback on this pa-per. The support of Cambridge Overseas Trust, who fully funds my studies, is gratefully acknowl-edged.

