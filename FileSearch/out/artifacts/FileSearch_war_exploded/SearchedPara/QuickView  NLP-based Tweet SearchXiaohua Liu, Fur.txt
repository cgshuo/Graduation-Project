 Tweets represent a comprehensive fresh informa-tion repository. However, users often have diffi-culty finding information they are interested in from tweets, because of the huge number of tweets as well as their noisy and informal nature. Tweet search, e.g., Twitter 1 , is a kind of service aiming to tackle this issue. Nevertheless, existing tweet search ser-vices provide limited functionality. For example, in Twitter, only a simple keyword-based search is sup-ported, and the returned list often contains meaning-less results.

This demonstration introduces QuickView , which employs a series of NLP technologies to extract useful information from a large volume of tweets. Specifically, for each tweet, it first conducts nor-malization, followed by named entity recognition (NER). Then it conducts semantic role labeling (SRL) to get predicate-argument structures, which are further converted into events, i.e., triples of who did what. After that, it performs sentiment analysis (SA), i.e., extracting positive or negative comments about something/somebody. Next, tweets are clas-sified into predefined categories. Finally, non-noisy tweets together with the mined information are in-dexed.

On top of the index, QuickView enables two brand new scenarios, allowing users to effectively access the tweets or fine-grained information mined from tweets.
 Categorized Browsing . As illustrated in Figure 1(a), QuickView shows recent popular tweets, enti-ties, events, opinions and so on, which are organized by categories. It also extracts and classifies URL links in tweets and allows users to check out popular links in a categorized way.
 Advanced Search . As shown in Figure 1(b), Quick-View provides four advanced search functions: 1) search results are clustered so that tweets about the same/similar topic are grouped together, and for each cluster only the informative tweets are kept; 2) when the query refers to a person or a company, two bars are presented followed by the words that strongly suggest opinion polarity. The bar X  X  width is proportional to the number of associated opin-ions; 3) similarly, the top six most frequent words that most clearly express event occurrences are pre-sented; 4) users can search tweets with opinions or events, e.g., search tweets containing any posi-tive/negative opinion about  X  X bama X  or any event involving  X  X bama X .

The implementation of QuickView requires adapt-ing existing NLP components trained on formal texts, which often performs poorly on tweets. For example, the average F1 of the Stanford NER (Finkel et al., 2005) drops from 90.8% (Ratinov and Roth, 2009) to 45.8% on tweets, while Liu et al. (2010) report that the F1 score of a state-of-the-art SRL system (Meza-Ruiz and Riedel, 2009) falls to 42.5% on tweets as apposed to 75.5% on news. However, the adaptation of those components is challenging, owing to the lack of annotated tweets and the inadequate signals provided by a noisy and short tweet. Our general strategy is to leverage ex-isting resources as well as unsupervised or semi-supervised learning methods to reduce the labeling efforts, and to aggregate as much evidence as pos-sible from a broader context to compensate for the lack of information in a tweet.

This strategy is embodied by various components we have developed. For example, our NER com-ponent combines a k-nearest neighbors (KNN) clas-sifier, which collects global information across re-cently labeled tweets with a Conditional Random Fields (CRF) labeler, which exploits information from a single tweet and the gazetteers. Both the KNN classifier and the CRF labeler are repeatedly retrained using the results that they have confidently labeled. The SRL component caches and clusters recent labeled tweets, and aggregates information from the cluster containing the tweet. Similarly, the classifier considers not only the current tweet but also its neighbors in a tweet graph, where two tweets are connected if they are similar in content or have a tweet/retweet relationship.

QuickView has been internally deployed, and re-ceived extremely positive feedback. Experimental results on a human annotated dataset also indicate the effectiveness of our adaptation strategy.
Our contributions are summarized as follows. 1. We demonstrate QuickView , an NLP-based 2. We present core components of QuickView , fo-
The rest of this paper is organized as follows. In the next section, we introduce related work. In Sec-tion 3, we describe our system. In Section 4, we evaluate our system. Finally, Section 5 concludes and presents future work. Information Extraction Systems . Essentially, QuickView is an information extraction (IE) system. However, unlike existing IE systems, such as Evita (Saur  X   X  et al., 2005), a robust event recognizer for QA system, and SRES (Rozenfeld and Feldman, 2008), a self-supervised relation extractor for the web, it targets tweets, a new genre of text, which are short and informal, and its focus is on adapting existing IE components to tweets.
 Tweet Search Services . A couple of tweet search services exist, including Twitter, Bing social search and Google social search 3 . Most of them provide only keyword-based search interfaces, i.e., return-ing a list of tweets related to a given word/phrase. In contrast, our system extracts fine-grained in-formation from tweets and allows a new end-to-end search experience beyond keyword search, such as clustering of search results, and search with events/opinions.
 NLP Components . The NLP technologies adopted in our system , e.g., NER, SRL and classification, have been extensively studied on formal text but rarely on tweets. At the heart of our system is the re-use of existing resources, methodologies as well as components, and the the adaptation of them to tweets. The adaptation process, though varying across components, consists of three common steps: 1) annotating tweets; 2) defining the decision con-text that usually involves more than one tweet, such as a cluster of similar tweets; and 3) re-training mod-els (often incrementally) with both conventional fea-tures and features derived from the context defined in step 2. We first give an overview of our system, then present more details about NER and SRL, as two represen-tative core components, to illustrate the adaptation process. 3.1 Overview Architecture . QuickView can be divided into four parts, as illustrated in Figure 2. The first part in-cludes a crawler and a buffer of raw tweets. The crawler repeatedly downloads tweets using the Twit-ter APIs, and then pre-filters noisy tweets using some heuristic rules, e.g., removing a tweet if it is too short, say, less than 3 words, or if it contains any predefined banned word. At the moment, we focus on English tweets, so non-English tweets are filtered as well. Finally, the un-filtered are put into the buffer.

The second part consists of several tweet extrac-tion pipelines. Each pipeline has the same configura-tion, constantly fetching a tweet from the raw tweet buffer, and conducting the following processes se-quentially: 1) normalization; 2) parsing including part-of-speech (POS), chunking, and dependency parsing; 3) NER; 4) SRL; 5) SA and 6) classifica-tion. The normalization model identifies and cor-rects ill-formed words. For example, after normal-ization,  X  X oooove X  in  X   X  X  X  I loooove my icon  X  X  X   X  will be transformed to  X  X ove X . A phrase-based trans-lation system without re-ordering is used to imple-ment this model. The translation table includes man-ually compiled ill/good form pairs, and the language model is a trigram trained on LDC data 4 using SRILM (Stolcke, 2002). The OpenNLP 5 toolkit is directly used to implement the parsing model. In future, the parsing model will be re-trained us-ing annotated tweets. The SA component is imple-mented according to Jiang et al. (2011), which incor-porates target-dependent features and considers re-lated tweets by utilizing a graph-based optimization. The classification model is a KNN-based classifier that caches confidently labeled results to re-train it-self, which also recognizes and drops noisy tweets. Each processed tweet, if not identified as noise, is put into a shared buffer for indexing.

The third part is responsible for indexing and querying. It constantly takes from the indexing buffer a processed tweet, which is then indexed with various entries including words, phrases, metadata (e.g., source, publish time, and account), named en-tities, events, and opinions. On top of this, it answers any search request, and returns a list of matched re-sults, each of which contains both the original tweet and the extracted information from that tweet. We implement an indexing/querying engine similar to Lucene 6 in C#. This part also maintains a cache of recent processed tweets, from which the following information is extracted and indexed: 1) top tweets; 2) top entities/events/opinions in tweets; and 3) top accounts. Whether a tweet/entity/event/opinion ranks top depends on their re-tweeted/mentioned times as well as its publisher, while whether an ac-count is top relies on the number of his/her followers and tweets.

The fourth part is a web application that returns related information to end users according to their browsing or search request. The implementation of the web application is organized with the model-view-control pattern so that other kinds of user in-terfaces, e.g., a mobile application, can be easily im-plemented.
 Deployment . QuickView is deployed into 5 work-stations 7 including 2 processing pipelines, as illus-trated in Table 1. The communication between com-ponents is through TCP/IP. On average, it takes 0.01 seconds to process each tweet, and in total about 10 million tweets are indexed every day. Note that QuickView  X  X  processing capability can be enhanced in a straightforward manner by deploying additional pipelines. 3.2 Core Components Because of limited space, we only discuss two core components of QuickView : NER and SRL.
 NER . NER is the task of identifying mentions of rigid designators from text belonging to named-entity types such as persons, organizations and loca-tions. Existing solutions fall into three categories: 1)
Workstation Hosted components the rule-based (Krupka and Hausman, 1998); 2) the machine learning based (Finkel and Manning, 2009; Singh et al., 2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating meth-ods. However, because of domain mismatch, cur-rent systems trained on non-tweets perform poorly on tweets.

Our NER system takes three steps to address this problem. Firstly, it defines those recently la-beled tweets that are similar to the current tweet as its recognition context, under which a KNN-based classifier is used to conduct word level clas-sification. Following the two-stage prediction ag-gregation methods (Krishnan and Manning, 2006), such pre-labeled results, together with other con-ventional features used by the state-of-the-art NER systems, are fed into a linear CRF models, which conducts fine-grained tweet level NER. Secondly, the KNN and CRF model are repeatedly retrained with an incrementally augmented training set, into which highly confidently labeled tweets are added. Finally, following Lev Ratinov and Dan Roth (2009), 30 gazetteers are used, which cover common names, countries, locations, temporal expressions, etc. These gazetteers represent general knowledge across domains, and help to make up for the lack of training data.
 SRL . Given a sentence, the SRL component identi-fies every predicate, and for each predicate further identifies its arguments. This task has been exten-sively studied on well-written corpora like news, and a couple of solutions exist. Examples include: 1) the pipelined approach, i.e., dividing the task into several successive components such as argument identification, argument classification, global infer-ence, etc., and conquering them individually (Xue, 2004; Koomen et al., 2005); 2) sequentially labeling based approach (M ` arquez et al., 2005), i.e., label-ing the words according to their positions relative to an argument (i.e., inside, outside, or at the be-ginning); and 3) Markov Logic Networks (MLN) based approach (Meza-Ruiz and Riedel, 2009), i.e., simultaneously resolving all the sub-tasks using learnt weighted formulas. Unsurprisingly, the per-formance of the state-of-the-art SRL system (Meza-Ruiz and Riedel, 2009) drops sharply when applied to tweets.
 The SRL component of QuickView is based on CRF, and uses the recently labeled tweets that are similar to the current tweet as the broader context. Algorithm 1 outlines its implementation, where: train denotes a machine learning process to get a labeler l , which in our work is a linear CRF model; the cluster function puts the new tweet into a clus-ter; the label function generates predicate-argument structures for the input tweet with the help of the trained model and the cluster; p , s and cf denote a predicate, a set of argument and role pairs related to the predicate and the predicted confidence, respec-tively. To prepare the initial clusters required by the SRL component as its input, we adopt the predicate-argument mapping method (Liu et al., 2010) to get some automatically labeled tweets, which (plus the manually labeled tweets) are then organized into groups using a bottom-up clustering procedure.
It is worth noting that: 1) our SRL component uses the general role schema defined by PropBank, which includes core roles such as A0, A1 (usually indicating the agent and patient of the predicate, re-spectively), and auxiliary roles such as AM-TMP and AM-LOC (representing the temporal and loca-tion information of the predicate, respectively); 2) only verbal predicates are considered, which is con-sistent with most existing SRL systems; and 3) fol-lowing M ` arquez et al. (2005), it conducts word level labeling. Overall Performance . We provide a textbox in the home page of QuickView to collect feedback. We have got 165 feedbacks, of which 85.5% are posi-tive. The main complaint is related to the quality of the extracted information.
 Core Components . We manually labeled the POS, Algorithm 1 SRL of QuickView .
 NER, SRL and SA information for about 10,000 tweets, based on which the NER and SRL com-ponents are evaluated. Experimental results show that: 1) our NER component achieves an average F1 of 80.2%, as opposed to 75.4% of the baseline, which is a CRF-based system similar to Ratinov and Roth X  X  (2009) but re-trained on annotated tweets; and 2) our SRL component gets an F1 of 59.7%, out-performing both the state-of-the-art system (Meza-Ruiz and Riedel, 2009) (42.5%) and the system of Liu et al. (2010) (42.3%), which is trained on au-tomatically annotated news tweets (tweets reporting news). We have described the motivation, scenarios, archi-tecture, deployment and implementation of Quick-View , an NLP-based tweet search. At the heart of QuickView is the adaptation of existing NLP tech-nologies, e.g., NER, SRL and SA, to tweets, a new genre of text, which are short and informal. We have illustrated our strategy to tackle this challeng-ing task, i.e., leveraging existing resources and ag-gregating as much information as possible from a broader context, using NER and SRL as case stud-ies. Preliminary positive feedback suggests the use-fulness of QuickView and its advantages over exist-ing tweet search services. Experimental results on a human annotated dataset indicate the effectiveness of our adaptation strategy.

We are improving the quality of the core compo-nents of QuickView by labeling more tweets and ex-ploring alternative models. We are also customizing QuickView for non-English tweets. As it progresses, we will release QuickView to the public.

