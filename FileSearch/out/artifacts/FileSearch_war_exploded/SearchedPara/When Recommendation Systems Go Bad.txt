 Machine learning and recommendations systems have changed the way we interact with not just the internet, but some of the basic services that we use to organize and run our life. As the people that build these systems, we have a social responsibility to consider how these systems affect people, and furthermore, we should do whatever we can to prevent these models from perpetuating some of the prejudice and bias that exist in our society today. This talk will cover some of the recommendation systems that have gone wrong across various industries, and attempt to provide some solutions for raising awareness and prevention. Approaches that will be explored include using interpretable models, using ensemble models to separate features that shouldn't interact, and designing test data sets for capturing accidental bias. 
