 1. Introduction
Recently, the language modeling approach has become a popular IR model based on its sound theoretical basis and good empirical success ( Gao, Nie, Wu, &amp; Cao, 2004; Hiemstra, Robertson, &amp; Zaragoza, 2004a, information retrieval, the language modeling approach provides a very flexible framework which enables deal-ing with complex relationships among the terms such as bi-terms ( Song &amp; Croft, 1999 ) and syntactic depen-dency ( Gao et al., 2004 ). It also can be incorporated with some advanced techniques to resolve the term mismatch problem, such as query expansion and cluster-based retrieval. Lafferty and Zhai (2001) introduced the concept of query model within the language modeling approach, and regarded retrieval as ranking by KL divergence between the query model and the document language model. The cluster-based retrieval within the language modeling approach was explored by two methods: interpolation ( Kurland &amp; Lee, 2004 ) and cluster-based smoothing ( Liu &amp; Croft, 2004 ).

Until now, however, there were no empirical or theoretical comparisons between the query expansion and the cluster-based retrieval in resolving the term mismatch problem. This paper focuses on the empirical eval-uations for query expansion and cluster-based retrieval on various issues, and thus provides a reasonable direction in developing a theoretical argument between two approaches, which is used as an empirical justi-fication for a new theory. The following summarizes several issues of this paper: (1) What is the effect of using parsimony in query expansion? (2) What is the difference in retrieval performance by each of query expansion and cluster-based retrieval? (3) What is the effect of clustering algorithm in the cluster-based retrieval? (5) Is there a novel method to combine query expansion and cluster-based retrieval?
This paper is organized as follows: In Section 2 , we briefly review the language modeling approach and methods for query expansion and cluster-based retrieval. In Section 3 , experimental results for the above issues are presented and discussed. Finally, a conclusion will be given in Section 4 . 2. Query expansion and cluster-based retrieval in language modeling approach 2.1. Language modeling approach
The language modeling approach in information retrieval ranks the documents according to the likelihood of a query from the document language models ( Ponte &amp; Croft, 1998 ). For a query Q = q ment model h D , the likelihood of a query is derived as follows, under the assumption of term independence.
Regarding the ranking of documents, the language modeling approach is equivalent to Kullback X  X eiber (KL) divergence formulation where a query language model is explicitly introduced as the probabilistic model for modeling approach is generalized to negative KL divergence between the query model and the document language models as follows: p ( w j h Q ) is a query model for the user X  X  query Q , D is a document and p ( w j h for D . Given the query Q , if we use MLE query model P  X  w j by Eq. (2) is exactly the same as the query likelihood P ( Q j D ).
 This formulation explicitly causes the query model estimation to find a good model of P ( w j h formulation is convenient when proceeding our discussion since we consider the query expansion and its com-binations. Thus, from now on, we will follow the formulation of Eq. (2) when discussing the query expansion, and we will use the query likelihood when explaining the cluster-based retrieval, since it does not contain a query model estimation. 2.2. Methods for query expansion
This paper adopts Markov Chain Translation Model (MCTM) as a reference method for global query expansion in the language modeling approach. Basically, MCTM is a variant of a statistical translation model that resolves several inherent limitations of the models. Now, we first introduce MCTM, and then Parsimo-nious Translation Model (PTM) which is parsimonious version of MCTM in detail. 2.2.1. Markov Chain Translation Model (MCTM) MCTM models a random walk process on Markov chain between the terms and the documents ( Lafferty &amp;
Zhai, 2001 ). MCTM defines a translation model between the terms, which basically forms a stochastic Markov ment models containing w . where the mixture weights are given a posterior probability P ( h chain. Random walks can hold several sequential term transitions. As each state transition is performed, the stop event can occur with the probability of (1 a ). If the stop event occurs, then there is no further state transition processes. For simplification and reliability, we only allow cases in which the number of random walks is maximally 1. Then, the state translation probability is generalized as follows: where d ( w , q ) is one if w equals to q and zero otherwise. In other words, t events, where the random walk process starts at word q and immediately stops, or stops at word q after one step when starting at other term w (since all terms stop after one random walk, we ignore the stop prob-ability). As a result, we obtain another Markov chain by using the state translation probability t the single state translation process is performed instead of the random walk process.
 Given the query Q , we can define an expanded query model h random walk process starting at an arbitrary term of a given query is stopped at term w . This new estimation method is formulated as follows: By substituting t a ( w j q ) into this equation, we obtain This paper calls tion of the expansion query model with the MLE query model. 2.2.2. Parsimonious Translation Model (PTM)
However, since the translation probability of Eq. (3) contains co-occurrence information between terms, translation model construction has high computational complexity for large size of documents. Also, without any processing of common terms (non-topical terms) the resulting query model may do not provide reliable retrieval performance. To resolve these problems, the Parsimonious Translation Model (PTM) had been pro-Eq. (3) ( Na et al., 2004 ).

PTM first estimates Parsimonious Document Language models (PDM) for available documents and selects topical terms according to the probabilities of PDM, then estimates the term translation probabilities only from the selected topical terms ( Na et al., 2004 ).
 adopts the select_ratio( P ) method for this experimentation due to its generality.

PDM is a document model which only assigns positive probabilities to selected terms rather than all doc-ument terms. A naive version of PDM is obtained by assigning zero probabilities into terms having low prob-abilities in MLE document models. However, this naive version does not perform term selection based on topicality of terms since the probability of MLE model is only determined by term frequency in a document.
Therefore, instead of the MLE document model, we use a document specific topic model, which is obtained by applying EM algorithm for maximizing the document likelihood. Here, we assume that a sample of the doc-ument is generated from the mixture model which consists of unknown document specific topic model h want to obtain) and global collection model h C . Then, the likelihood of document D is defined as follows: where l is a smoothing parameter and tf( w ; D ) is a term frequency of w in document D . Note that l indicates another smoothing parameter that is different from k . Document specific model is defined as mizes the likelihood. To maximize the document likelihood, the EM algorithm is applied ( Hiemstra et al., 2004a ).

After EM iteration is converged to ~ h D , the selection process is performed, where only highly topical terms are selected and non-topical terms are discarded. For non-topical terms w , its probability P  X  w j
Discarded probability is re-distributed uniformly on selected topical-terms. Let D for given document D . Then, PDM P  X  w j h s D  X  is defined by where Z D is a normalization factor  X  1 =
D is one with the largest size of subsets of terms in document D such that satisfies the constraint
P
PTM is derived by substituting the document language model in Eq. (3) into the parsimonious document language model of Eq. (7) as follows: By using t s ( q j w ) instead of t ( q j w ) in Eq. (5) , the query model based on PTM is obtained as follows: 2.3. Methods for cluster-based retrieval
In the language modeling approach, cluster-based retrieval utilizes a new class of language model  X  cluster language model. Cluster language model is the generative probability model of terms in corresponding a clus-ter where documents are grouped to given some topic. Let Clust be a subset of documents. Then, MLE cluster language model ^ h Clust is formulated as follows:
Two different kinds of cluster-based retrieval methods have been examined in the language modeling approach model semantically smoothed with cluster language model instead of MLE document models ( Liu &amp; Croft, based retrieval reference for several reasons such as its model-independence, and better empirical performance than cluster-based smoothing. 2.3.1. Interpolation method Given a set of whole clusters X , we rewrite the query likelihood from the document model as follows: where Clust is one of the clusters and P (Clust j D ) indicates the degree that document D belongs to cluster Clust.

A naive version of cluster-based retrieval is obtained by assuming that a query is generated only from the cluster not directly from the document. In other words, given the cluster, query generation is condition-is
Kurland and Lee (2004) called the cluster-based retrieval induced from this Eq. (11) the aspect-x method.
This assumption is too strong to perform a reliable retrieval since the effects of query generation from the document is totally ignored. It is more relaxed by allowing query generation of document with some portion. The interpolation method indicates the cluster-based retrieval based on this relaxed assumption ( Kurland &amp; ( Kurland &amp; Lee, 2004 ). As for another relaxed version, multiplication-based combination is used where P ( Q j Clust, D ) is set proportionally to P ( Q j D ) b can be more simplified. Assume that for each document D , c P (Clust j D ) = 0 for all Clust 6  X  c D . Using this, Eq. (12) is written by By taking logarithm,
This paper uses this multiplication-based version of interpolation method for cluster-based retrieval. 2.4. Combining methods for cluster-based retrieval and query expansion 2.4.1. Cluster-based retrieval after query expansion (Q&amp;C)
This performs cluster-based retrieval from query model estimated after query expansion. Q&amp;C is used as the baseline method in our experiments in combining cluster-based retrieval and query expansion due to its simplicity. 2.4.2. Cluster-dependent query expansion (C&amp;Q)
In C&amp;Q, documents are first clustered using some clustering method, co-occurrence information for query ing to rank clusters and query expansion are performed according to the scores of clusters. Expansion terms are extracted based mainly on co-occurrence information in clusters higher scores. Thus, C&amp;Q is a context-dependent query expansion where context is determined from a given query. 3. Experimental results 3.1. Experimental setup
Our experimental database consists of two collections in Korean, and five TREC4 data collections in Eng-lish. Table 1 summarizes the information of the seven data collections. The  X  X # Doc X  X  is the total number of documents,  X  X # D.T. X  X  indicates the average number of unique terms of documents,  X  X # Q  X  X  is the number of topics and  X  X # R  X  X  is the number of relevant documents in each test set. In Korean documents, it is well known indexing unit is used in this experimentation. For indexing English documents, the typical preprocessing step is performed, where stop words are removed and then Poster stemming is applied. 3.2. Effects of parsimony on query expansion
Fig. 1 shows the average precision for three query models in seven different test collections by changing the parsimony level from 0.1 to 1.0. (Results of combining methods will be discussed in Section 3.4 .) The three query models are: the baseline language model using the MLE of the query sample, the query model estimated from the original translation model (Eq. (5) ), and the query model estimated from the parsimonious transla-tion model (Eq. (9) ). Interpolation parameter a is fixed at 0.1, which performed well in all test collections.
As shown in Fig. 1 , for almost all parsimony levels, Parsimonious Translation Model (PTM) significantly improves the baseline in the seven data collections. Remarkably, performance of PTM is better than the performance of the original translation model (OTM) at low parsimony level. In OTM, some noise occurs because common words of query can be expanded by common terms of document. Therefore, compared with the baseline, high accuracy of PTM implies that PTM can effectively eliminate noise of term expansion in
OTM, and select good expansion terms regarding the retrieval performance. The best performance of PTM highly outperforms the baseline from 5% to 25%, and especially, a 25.55% improvement is achieved at TREC4-ZIFF collection.
 Concerning the optimal parsimony level, while for Korean collection the optimal parsimony level is 0.1, for English test collection, the optimal parsimony level is between 0.2 and 0.4. However, performance in TREC4-not in 0.2 X 0.4 but in 0.6 X 0.8. It seems that in TREC4-FR, expansion terms helping retrieval performance have relatively small probabilities value.

Table 2 shows the reduction ratio of the storage size of PTM to OTM across various parsimony levels (0.1 X  0.6 and 1.0). The number in each cell indicates the ratio of the storage size of PTM to that of OTM. Bold numbers corresponds to the parsimony level with the best performance in each collection. In Korean test sets, ratios of the size at optimal parsimony level vary from 0.75% at TREC4-ZIFF to 13.14% at TREC4-AP. At this time, the exceptional phenomenon of optimal parsimony level in TREC4-FR can be interpreted in terms of the size reduction, since degree of size reduction is slowly increased according to the parsimony level. It requires a parsimony level of 0.6 to achieve a size reduction of about 10%.

Fig. 2 shows the curves of the relative ratio to full space size of MCTM among seven test collections. Rel-ative ratio indicates the space size of PTM when the space size of non-parsimonious MCTM is 1. Linear ratio indicates the curve when the ratio is exactly the same as the parsimony level and square ratio indicates the curve when the ratio is exactly the same as the square of parsimony level. When the parsimony level is 1.0, ally, TREC4-ZIFF and TREC4-FR draw very lower curves rather than the square ratio.

In collections other than TREC4-ZIFF and TREC4-FR, while the ratio curve follows the square ratio at test collections, the retrieval performance is at best when the parsimony level is less than 0.4. Thus, we can guarantee that at least the storage size in PTM is 0.4 2 = 0.16 times of the storage size in MCTM.
From these experiments, we can conclude that the parsimonious translation model not only drastically reduces time and space-complexity but also highly improves the retrieval performance at the optimal parsi-that an optimal parsimony level is almost the same for the same language. 3.3. Query expansion vs. cluster-based retrieval
For document clustering, the K -means clustering algorithm is used due to its low time complexity. Similar-ity measure for K -means clustering between a document and a cluster is regarded as negative KL divergence between a parsimonious document language model (set P be 1.0 with select_ratio( P )) and cluster language model as follows:
For the cluster language model, Jerlinek Mercer (JM) smoothing with smoothing parameter 0.25 is used. We randomly select K documents and use them as initial cluster centroids. To perform Cluster-based Retrieval (CR), Eq. (13) is utilized where b is set to be 0.8 which is known to be relatively good in preliminary experimentation.

To calculate the query likelihood of clusters p ( q j c D language models by using an parameter c . In the experimentation, interpolating parameter c is set to 0.8.
The number of clusters in CR is an important parameter in clustering. Instead of analytic determination of the number of clusters, we perform cluster-based retrieval for each different parameter (i.e. 100, 200, 500 and performance in each collection. In five test sets except for TREC4-ZIFF, the best performances are achieved at K = 500.

Overall, the effect of CR differs in each test set. In NTCIR3-KK and TREC4-AP CR is highly effective, improving the baseline with a difference between 2% and 3%, obtaining better performances over OTM. How-that randomly selected initial centroids are not good for those test sets. Due to the local convergence charac-tion, it is likely that the resulting clusters obtained from the local maximum result are not adequate for CR.
We believe that the result can be improved more, if better clustering algorithms with global maximum char-acteristics or good criterions are used.
 3.4. Effects of clustering algorithms in cluster-based retrieval
For analysis of the effects of clustering algorithms for cluster-based retrieval, we consider two clustering algorithms: the Agglomerative and Partitional. The agglomerative clustering methods group the documents into a hierarchical tree structure using bottom-up approaches. For constructing K clusters in agglomerative clustering, clusters are merged until total K clusters are obtained. In other words, the top K disjoint cluster trees in hierarchical clusters are extracted. We use group average criterion for merging clusters ( Kamvar, Klein, &amp; Manning, 2002 ).

The partitioning methods decompose the document set into a given number of disjoint clusters, and are generally used given some predefined criterion functions. K -means clustering belongs to the partitional clus-tering approach. Since the size of KTSET 1.0 is small, we could successfully perform agglomerative clustering at a computationally feasible time.

Fig. 3 shows the results of CR in KTSET 1.0. The number of clusters varies from 10 to 100 increasing by 10. b is the same as the value in Section 3.3 . K -means clustering is unstable according to the number of clusters and sometimes is worse than the baseline. On the other hand, agglomerative clustering outperforms the base-line in all parameters showing a maximum difference of about 6%. In addition, it is always better than
K -means regardless of the number of clusters and more stable than K -means. 3.5. Effects on the number of relevant documents in query expansion and cluster-based retrieval
CR and QE are used to improve recall, so that they will be more effective when a query requires a high recall. This section examines this presumption by using the number of relevant documents ( R ) for quantitative measure of recall requirement. To evaluate, we selected four test collections, in which CR and QE are success-ful having reasonable the number of queries.

Fig. 4 shows the curves for performance increases of CR according to R on the four test collections. Queries in which R is more than three are only selected because a small R can cause the bias of performance. The num-change of performance is. In particular, NTCIR3-KK and TREC4-SJ show correlations with linear shape between R and performance increase.

Table 4 presents the Spearman rank correlation coefficients on these collections. This coefficient is appro-priate because the distributions of the number of relevant documents and the performance increases are unknown ( Gibbons &amp; Chakraborty, 1992 ). A coefficient of 1 indicates a perfect positive correlation and a coefficient of 1 indicates a perfect opposite correlation. Three collections except for TREC4-AP show relatively high correlations. In particular, NTCIR3-KK shows a strong correlation with 0.4553 in K of 1000. less than 3% and 1%, respectively. Thus, NTCIR3-KK and TREC4-SJ show a strong correlation with high confidence. However, TREC4-AP and TREC4-WS show p -values of 60% and 10% p -value, hence we cannot clearly assume the existence of correlation with only their coefficients.

The numbers of last column are correlation coefficients between R and PTM * performance increase. Com-to CR. In other collections, correlation coefficients are less than the best CRs. The reason is that PTM can simultaneously improve not only the recall and but also the  X  X recision X . PTM controls the precision by adding new terms which concretize the original concept of query. Instead, CR can control the precision by changing the weights of documents with cluster smoothing (interpolation). Compared with QE, such operation of QE is very restricted, because QE uses both the term expansion and the term weighting.
Performance of CR will be dependent to the performance of baseline. In other words, the higher perfor-mance of baseline is, the smaller margin of performance improvement is. Thus, when the baseline has a high performance, the correlation may be unclear. For example, Table 5 shows the correlations of CR and R on only queries which are less than a target performance from 0.1 to 0.7 by increasing 0.1. However, there is no special rule to curve situations of all collections. Other collections except for TREC4-WSJ show the stron-gest correlation when baseline performances are less than 0.1. TREC4-WSJ shows the strongest correlation when baseline performances are less than 0.4. Concerning the fact that there is no performance improvement on TREC4-WSJ, we can potentially conclude that CR is effective when baseline performance is poor. In con-cluding this section, CR has correlation of R when the number of clusters is appropriate. In contrast, QE has no clear correlation to R . 3.6. Combining methods of query expansion and cluster-based retrieval
Again, let us look at Fig. 1 . Fig. 1 compares the performance of baseline, PTM * , and two kinds of combi-nation methods of query expansion (QE) and CR (Q&amp;C and C&amp;Q). In this experiments, the interpolation parameters a and b of QE and CR are same to those in individual method.

Concerning Q&amp;C and C&amp;Q, in Korean collection, two methods are successful, showing that they outper-form the baseline and individual methods of QE and CR. Especially, Q&amp;C is better than C&amp;Q. However, two combining methods are not successful in the English test collection. Only in the AP collection the combining methods are successful having a similar tendency to the result in Korean, while they do not improve the indi-vidual methods or sometimes are even worse in other four collections. One possible reason is that the perfor-mance of CR is not good in those collections. In KTSET 1.0, NTCIR3-KK, and TREC4-AP, the best performance of CR is higher than baseline (about 3%) and QTM (about 1.5%). On the other hand, in the other four collections, the performance of CR is higher than the baseline and QTM at most 1% or rather is worse than them. To sum up, combination of QE and CR is meaningful, only if the performance of each method is higher than the baseline. In addition, in such a case, the Q&amp;C is slightly better than the C&amp;Q. Let us consider the relationship between the performance by Q&amp;C and C&amp;Q and performance by CR.
From our additional experiments (we do not give a detail information about this experiment due to the limits of this paper) we found a tendency that performance of Q&amp;C was highly dependent on the performance by dependent on performance of CR and is highly dependent on the number of clusters. It is understandable is formed for each document, resulting in total N clusters given N documents. 4. Conclusion
This paper performed an empirical study of query expansion and cluster-based retrieval in order to resolve the term mismatch problem in a language modeling framework. From this work, several conclusions are derived as follows.

The parsimonious translation model not only remarkably reduces time and space-complexity but also highly improves retrieval performance at the optimal parsimony levels.

Cluster-based retrievals depend on clustering algorithm and the number of clusters. Cluster-based retrieval outperforms the baseline language modeling in almost all cases, but, generally it is worse than the parsimo-nious translation model.

Combination of cluster-based retrieval and query expansion is effective in the case that each query expan-sion and cluster-based retrieval outperforms baseline language modeling. In such case, cluster-based retrie-val after query expansion is slightly better than cluster-dependent query expansion.

For cluster-based retrieval, agglomerative clustering directly using the document-to-document similarities are more effective than partitioning clustering such as K -means based on centroid-to-document similarities.
Performance increase of cluster-based retrievals depends on the number of relevant documents for the given query.
 Acknowledgements
This work was supported by the KOSEF through the Advanced Information Technology Research Center (AITrc) and by the BK21 project.
 References
