 Chih-Yung Tsai  X  Shuo-Yan Chou  X  Shih-Wei Lin  X  Wei-Hao Wang Abstract Due to the popularity of location-based services, determining the location of a device at all times has become a subject of great interests. Although many GPS-based appli-cations have been developed and successfully deployed in various fields, their applicabilities are hindered by the obstruction of the objects in the environment. Essentially, as satellite signals cannot penetrate the walls of buildings, the coverage of GPS systems is limited to outdoor environments. To fully exploit the benefit of location-based services, approaches that determine the location of a device in indoor environments need to be established. This study presents a novel location determination mechanism that uses an indoor WLAN and back-propagation neural network (BPN). A museum is taken as the context of the exam-ple indoor environment. Location determination is achieved using the combined strengths of 802.11b wireless access signals. With a significant number of access points (APs) installed in the museum, hand-held devices can sense the strengths of the signals from all APs to which the devices can connect. Using a back-propagation network, device locations can be estimated with sufficient accuracy. A novel adaptive algorithm is implemented for enhancing the accuracy of the estimation.
 Keywords Location determination  X  Wireless LAN  X  Mobile devices  X  Back-propagation network 1 Introduction How enterprises manage their properties and increase the cost X  X enefit ratio effectively is an extremely important factor affecting their competitiveness. A location determination system plays a crucial part in improving competitiveness [ 7 ]. For example, a freight delivery busi-ness requires a location determination system to accelerate delivery procedures. Conversely, medical departments can monitor the positions of patients, so they can be located quickly. Therefore, an effective location determination system can provide instant data that increase work efficiency. Existing techniques for location determination include the global positioning system (GPS), infrared ray positioning system (IRPS), and radio frequency-based systems. Notably, GPS is the most frequently utilized location determination system. However, GPS system does not work properly in indoor environments, and urban areas due to signal blockage and attenuation that typically reduce overall positioning accuracy. The IRPS signal cannot pass through walls, ceilings, floors or large objects in a room; thus, the emitted signal is commonly reflected by objects. Moreover, a transmitter must be less than 20 feet from what and cannot be covered by transparent objects when accepting a tag. Radio-frequency iden-tification (RFBS) generally adopts spell out (RFID) tags. The RFID technique is still under development, and is relatively expensive.

The hardware architectures of these three location determination systems are typically not easily accessed; however, the wireless local area network (WLAN) technique is extremely popular. Therefore, this study adopts WLAN as a technique for sensing and detecting a location. The WLAN reduces the cost and risk of hardware construction and utilizes existing network resources, which can be used to determine locations and does not affect original network transportation functions.

There are four major positioning techniques used by WLANs [ 9 ]: time of arrival (TOA); time difference of arrival (TDOA); angle of arrival (AOA); and, received signal strength indicator (RSSI). Generally, the advantage of RSSI is that additional circuits or modules are not needed because the wireless module chips already have detection pins and cir-cuits. Therefore, the RSSI can save more power and is easier to build than other methods [ 15 ].
 This study combines the WLAN technique and RSSI signal location determination method. However, it is extremely difficult to predicate indoor signal strength using the RSSI as a signal may take many different routes when transmitted from a transport point to a receive point. Additionally, many factors influence signal strength. Several major factors can cause errors when using the RSSI, including signal attenuation and shadowing effects. That the energy consumption rate in space equals the distance from the transport point to the receive point, is well known. Moreover, multiple signals have different strengths, and phases transmitted to the receive point that change the choice of frequency segments due to signal reconstruction and destruction.

Kaemarungsi [ 8 ] compared the RSSI for different WLAN cards and demonstrated that implementing RF measurement is not equal. Two causes are responsible for varying signal strengthinanenvironment. 1. Temporal variations. When a user is standing at a fixed position ( X = 14 . 4m, Y = 2. Large-scale variation. Signal strength varies over a long distance due to attenuation of
To decrease deviation in location predication resulting from RSSI error, this study adopts an artificial neural network to predict location. Because an artificial neural network has analytical modules, it can adjust the complexity level of each module to match complex signal records.

After inputting RSSI signals and location records, the artificial neural network can produce location determination automatically without any pre-set hypotheses [ 34 ]. Consequently, an artificial neural network is more accurate than other prediction modules [ 2 , 26 , 29 ]. Among various artificial neural networks, the back-propagation neural network (BPN) is most fre-quently adopted. Before applying the BPN to solve problems, parameter settings for BPN architecture, such as hidden layer, learning rate, momentum term, number of hidden neurons, and learning cycle, must be set in advance. The parameter settings for network architectures must be carefully determined to avoid constructing an ineffective network model that signif-icantly increases computational cost and yields worse results.

As many access points exist in most rooms, a wireless card will receive the RSSI from many access points; however, not all signals are useful. Adopting feature-selection approaches to determine whether a signal is beneficial is necessary. The principal benefits of feature selection are as follows: (1) reduces computational cost and storage requirements; (2) deals with degradation of classification efficiency due to the finiteness of training sample sets; (3) reduces training and prediction time; and, (4) facilitates data understanding and visualization [ 1 ]. During feature selection, because each feature is needed to determine whether a signal is useful, the task of finding an optimal subset of features is inherently combinatory. Therefore, feature selection becomes an optimization problem. Thus, an optimal approach is necessary to evaluate all possible subsets.
 This study presents novel optimal parameter settings for BPN architectures and applies it. It Specifies to estimate location using indoor WLAN systems. The remainder of this paper is organized as follows. Section 2 reviews existing studies of the BPNs and feature selection. Section 3 describes the proposed SABPN spell out unless it is common terminology to use the acronym approach to determine the optimal parameter settings for BPN architectures. Section 4 presents experimental results. Finally, use of what is discussed, and conclusions and directions for future work are given. 2 Literature review 2.1 Back-propagation network Among the structures of artificial neural networks, the most widely applied is the BPN, which is a supervised learning network that typically uses a sigmoid function and hyperbolic tangent function as the nonlinear transformation function. This network is suitable for diagnosis and forecasting, and functions of the basic principle of using the gradient steepest descent method to back-propagate input errors, thereby maximizing the error function such that the output estimation approximates the actual value. The operation has two phases [ 3 ]. During the forward phase, input training data are passed forward to the front levels until output is generated at the output level. The output is compared with the actual output value to obtain the error signal of the training data. During the backward phase, the error value is passed backward, level by level, to adjust each value such that the network contracts towards an ideal state, reducing the errors of the output forecast and actual value. This process is called a learning cycle. One can set training specimens to learn through several learning cycles repeatedly until contraction is attained. However, to improve a network, such a training cycle should not be excessively long [ 28 ]; otherwise the weight may excessively match the characteristics of training specimens and inputting new specimens cannot guide it accurately. During the learning stage, the BPN system repeatedly executes two phases.

The architecture of an ordinary BPN consists of three levels [ 30 ](Fig. 3 ). The input level contains several processing units that are input variables for the target problem. The hidden level is utilized to present the interaction between input processing units. In theory, no limits exist for the number of processing levels that can be used, and no standard method exists for deciding it. One must conduct tests on one X  X  own. When the error of the estimated value and actual value reaches a minimum, the optimal number of levels is chosen. The output level consists of one or more processing units to output a predicted value for input data. A neural network depends on its structure, i.e., the number of layers and hidden nodes. A network that has a structure simpler than necessary cannot give good approximations to training patterns [ 4 ]. Furthermore, different problems may require different parameter settings for network. Rule of thumb or  X  X rial and error X  methods are usually used to determine them. However, these methods may lead worse parameter settings for network.

The widely utilized nonlinear transformation function in BPN is a sigmoid function and hyperbolic tangent function [ 24 ]. Sigmoid function is used when X value approximates a positive infinitely large number, and the function value approximates 0. The Hyperbolic tangent function is applied when X value approximates a positive infinitely large number, and the function value approximates 1; when the X value approximates a negative infinitely large number, the function values approximates  X  1. 2.2 Feature selection The BPN requires a dataset to construct a model. A dataset can consist of numerous features; however, not all features are useful during classification. If the dataset has considerable noise and complex dimensionality, the BPN may have limitations when learning classification patterns. Feature selection with neural nets can be considered a special case of architecture pruning [ 16 ], where input features, rather than hidden neurons, are pruned or weighted.
Feature-selection approaches can be categorized into two models: a filter model and a wrapper model [ 14 ]. Statistical approaches, such as factor analysis (FA), independent com-ponent analysis (ICA), principal component analysis (PCA), and discriminate analysis (DA), have been utilized to investigate indirect performance measures, generally based on distance and information measures during feature selection. This model is called the filter model. Even though this model is faster, the resulting feature subset may not be optimal [ 14 ].
Some researchers have argued that when the objective is to minimize the classification error rate of a classifier, and measurement cost for all features is equal, then classification accuracy of the classifier is optimal. In other words, a classifier should be constructed to achieve the highest possible classification accuracy rate, and the features used by the classifier selected as optimal features. This model is the so-called wrapper model. It uses some selection methods to choose feature subsets and then evaluates the result after the classification algorithm calculates the accuracy rate. If the relevant features can be selected or noise can be removed, the classification accuracy rate can be improved.

The wrapper model is widely used for BPN feature selection. Kim and Han [ 11 ] proposed a genetic algorithm (GA) for feature selection in neural networks to predict stock prices. Lezoray and Cardot [ 12 ] developed floating search methods for feature selection; their clas-sification accuracy rate improved following feature selection. Verikas and Bacauskiene [ 27 ] created a neural network-based feature-selection technique, in which a network is trained with an augmented cross-entropy error function. Zhang et al. [ 33 ] applied a GA for feature selection in neural networks for fault defection in industrial manufacturing. Sexton et al. [ 22 ] first calculated network weight of an architecture, pruned the neural network architecture branches under a fixed number of hidden neurons, and finally applied a GA for feature selec-tion. Sivagaminathan and Ramakrishnan [ 25 ] utilized ant colony optimization to optimize a features subset suitable for feeding a neural network. However, these studies did not consider parameter settings for BPN architectures.
Several studies proposed the methods for obtaining optimal parameter settings for BPN selection for find the optimal feature subset that increases performance. Lin et al. [ 13 ]devel-oped a simulated annealing (SA)-based approach to determine the parameter settings of BPN and the feature selection for classification problem. Since the number of learning iterations is set to 500 in their approach, the ability of the system to learn may be limited. 3 SABPN for location determination This study adopts a novel simulated-annealing-based approach (SABPN), which is proposed by Lin et al. [ 13 ], for obtaining the optimal parameter settings for BPN and selecting the beneficial subset of features to have a higher classification accuracy rate. The SABPN is modified in this study to achieve a small mean-square error for the location determination problem and add a variable for determining the number of learning cycle of BPN.

An SA generates a random initial solution when starting its search. The algorithm then generates a new solution from the predetermined neighbourhood of the current solution. The objective function value of the new solution is then compared with the current solution value to determine whether the objective function value of the new solution is better. For the case of minimization, when the objective function value of the new solution is smaller, the new solution is automatically accepted and becomes the current solution from which the search continues. The algorithm then proceeds to another step. High objective function values for the next solution may also be accepted as the current solution with a probability determined by the Metropolis criterion. In applying the SA-based approach to identify the best parameter settings for BPN architectures, the mean-square error of testing data is adopted as the objective function. A small mean-square error indicates a good objective function value.

The learning rate and momentum term to be searched are continuous values. Therefore, the hide-and-seek SA [ 17 , 18 ], which was developed by Romeijn and Smith, can be utilized to solve optimization problems with continuous variables and is adopted in this study to identify the best parameter settings for BPN architectures. The hide-and-seek SA can find an optimal (close to) solution within a per-determined range. The constraints and objective function problem can be non-differentiable, and the feasible region can be non-convex or even disconnected. This algorithm begins at any feasible inside point (solution), follows a random vector according to a current feasible solution, and picks one point from the feasible region as the next solution during the search process. This algorithm generates the next solution in all feasible regions, not merely those limited to the neighbourhood region.

Under the condition of not performing feature selection, SA only needs to determine the values of four decision variables to achieve the smallest mean-square error. The first variable is the learning iteration, the second is learning rate, the third is the momentum term, and the fourth is the number of hidden neurons. When feature selection is required at the same time, the number of decision variables n will become 4 plus the number of features. Each feature sets a variable to decide selection or not; the variable value is between 0 and 1. When the variable value is  X  0 . 5, the feature is not selected. Conversely, when the variable value &gt;0.5, the attribute is selected. Figure 4 shows the solution representation.

The procedure of the proposed SABPN approach is as follows. Initially, temperature T is set as a very large value. The SABPN then randomly generates a feasible initial solution x and objective function value fx = objFun( x ), where objFun( x ) is the objective function of calculating the mean-square error of x .Let fx 1 = fx (this is the initial solution; thus, fx is the smallest objective function value found so far). For each iteration, basing x as the current solution, a feasible solution is randomly chosen from one random vector, which is projected from the current solution x . When the objective function value fy = objFun(y) of y , fy is smaller than fx ,let fx = fy and the current solution x equal y . When fy is larger than fx ,then let the probability of replacing the current solution x with y be expressed as (  X  ( fy  X  fx )/ T ) . When fy is smaller than fx 1 ,set fx 1 equal to fy and the best solution found so far, x opt , equal y ; the temperature is then decreased once. After carrying out C iter iterations, the process finishes. From x opt , the optimal parameter settings for BPN architectures and the beneficial subset of features can be obtained. Figure 5 shows the detailed procedure.

Figure 6 presents the framework for combining an SA with a BPN. The proposed SABPN optimizes the parameter settings of BPN architectures and selects the beneficial subset of features simultaneously. The objective is to minimize the mean-square error of test data. 4 Testing and result This research proposes a WLAM infrastructure, since WLANs have better scalability and less installation and maintenance costs than ad hoc solutions; these are requirements for easily surveying a location system using its own infrastructure and components [ 19 ].
These access points (APs) are D-Link, and the mobile terminal is a personal digital assistant computer running Windows CE. The network operates in the 2.4 GHz license-free (ISM) band with a data rate of 54 Mbps. This study utilized four channels: 1, 6, 7 and 11. The signal strength of these beacon packets was utilized as the received signal strength information (RSSI). The locations of coordinates for measuring signal strength have been chosen and stored on a personal digital assistant.

The WLAN using the 802.11 g standard is located on the ground floor of a building. The ground floor has nine access points (APs). The ground floor is 35 . 6  X  24 . 4 = 872 . 2m 2 ,and has three classrooms, two bathrooms and two rooms for storage. Nine APs were installed on the floor. All APs are Vigor 2600 VG. Figure 7 shows the locations of the APs. The nine access points operate on channels 1, 6, 7, 11 to prevent overlap. This study also defines coordinates of locations on the map and then records signal strength. Figure 8 shows the interface of PDA recording program.

The first textbox containing number 0 is the time counter and displays recording times in seconds. The next textbox can set a time interval for recording signal strength. The coordinates of the location where signal strength is in next two textboxes are recorded. The run button is pressed and the program starts recording signal strength until the time counter counts to the set time interval. The stop button can be pressed to stop the recording at anytime.
Among the 6,600 examples collected, based on the 4:1 ratio [ 23 ], this study randomly selects 5,280 examples as training examples and 1,320 as test examples. Several neural networks were trained using different configurations and learning algorithms. In all cases, the output layer had two neurons corresponding to the X and Y coordinates to estimate. Step1. Find an initial feasible sol u tion x Step2. Repeat C iter times { Step3. O u tp u t the optimal sol u tion x opt .

Experimental results are summarized with the observed accuracy. The average absolute error was calculated for each test as follows: e = 1 p p i = 1 ( Xt i  X  Xo i ) 2 + ( Yt i  X  Yo i ) 2 , where Xt i and Yt i are the correct (target) coordinates, Xo i and Yo i are the X and Y coordi-nates obtained by the neural network, respectively, and P is the number of tests or training patterns.

On the basis of room size and antique of the museum used as this site study, the target was set at a maximum error of 2 m to deliver location-aware information, just as a tour guide delivers information to tourists. To locate people in the museum, a 2-m maximum error was considered to be adequate X  X  person can be reached visually within this range.

Furthermore, given that many location-aware applications do not need to know the exact location of a mobile device but only the area in which it is, these applications tolerate an error from the real location; this error depends on the features of the application. Some applications allow large error values; for example, Marcela, which is used in hospitals allows an error of 4 m. This study sets the error value at  X  2m.
After running a few experiments with several combinations of parameter settings, the terminal search iteration, C iter of the SABPN, was set to 500 to identify the optimal BPN parameter settings (learning rate, momentum term, learning cycle and number of hidden neurons) and feature selection for the network architecture. The learning rate was 0 X 0.45, whereas the momentum term was 0.4 X 0.9. The BPN used one hidden layer and the sigmoid transfer function. The learning cycle was set at 500 X 5,000. The number of neurons in hidden layer was 2 X 22. The number of neurons in the input layer and output layer was 9 (9 signals) and 2 (predicting x and y coordinates), respectively.

Figure 9 shows the BPN system. About 88% of samples fall within 2 m, and the effect of applying SABPN feature selection technique on accuracy was that 92% of samples were within 2 m. Further analysis indicates that the SABPN technique achieves an accuracy of 82% samples falling within 1 m, which is 20% better than that of the BPN system. The accuracy rate of SABPN technique was 56% within 0.5 m. Moreover, as the positioning system data were continuously updated, these errors would soon be corrected and renewed when they move out of range. Consequently, applying SABPN technique improves the precision of location determination. 5 Conclusion and future research Due to the increased use of WLANs and mobile computing devices, and the popularity of location-based services, determining the location of a device at any time is important. Thus, this study implemented a novel location determination mechanism using an indoor WLAN and BPN. Location determination is achieved by capitalizing on the strengths of 802.11b wireless access signals.

With a massive number of APs installed in the museum, hand-held devices can determine the strengths of signals from all APs that to which the devices can connect. Although signal strength is recorded every second, it is not a very effective rate. By adding additional samples in 1 s, the location determination accuracy will be improved. Furthermore, using better APs and WLAN cards, and thus more stable RSSI signals, the accuracy of the estimation and determination can be improved.

The experiment can be divided into several parts to adjust for different conditions such as crowding and times with few people. The different results can be used as agents and applied to the system according to the different conditions. Before applying the enclosing circle technique, this study can compare the SABPN results with other data arrangement approaches to despite the out layers. We believe that it can improve the accuracy of the proposed location-determination approach (Table 1 ).
 References Author Biographies
