 Development of advanced anomaly detection and failure di-agnosis technologies for spacecraft is a quite significant is-sue in the space industry, because the space environment is harsh, distant and uncertain. While several modern ap-proaches based on qualitative reasoning, expert systems, and probabilistic reasoning have been developed recently for this purpose, any of them has a common difficulty in obtain-ing accurate and complete a priori knowledge on the space systems from human experts. A reasonable alternative to this conventional anomaly detection method is to reuse a vast amount of telemetry data which is multi-dimensional time-series continuously produced from a number of system components in the spacecraft.

This paper proposes a novel  X  X nowledge-free X  anomaly detection method for spacecraft based on Kernel Feature Space and directional distribution, which constructs a sys-tem behavior model from the past normal telemetry data from a set of telemetry data in normal operation and mon-itors the current system status by checking incoming data with the model.

In this method, we regard anomaly phenomena as unex-pected changes of causal associations in the spacecraft sys-tem, and hypothesize that the significant causal associations inside the system will appear in the form of principal com-ponent directions in a high-dimensional non-linear feature space which is constructed by a kernel function and a set of data.

We have confirmed the effectiveness of the proposed anomaly detection method by applying it to the telemetry data ob-tained from a simulator of an orbital transfer vehicle de-signed to make a rendezvous maneuver with the Interna-tional Space Station.  X  Address: 4-6-1, Komaba, Meguro-ku, Tokyo 153-8904 Japan Copyright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00. I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database applicationsData Mining Algorithms anomaly detection, time series data, kernel feature space, principal component analysis, von Mises Fisher distribution, spacecraft
Anomaly detection is a key issue in the development of re-cent advanced complex spacecraft. The space environment is very harsh for spacecraft due to a variety of factors such as direct radiation, great temperature difference, risk of clash with space debris, and so on. It is practically impossible to completely eliminate the possibility of anomalies or faults, even if we increase the reliability of the system components to the limit. In addition, the space is so distant from the earth that it is extremely difficult to directly inspect and repair a damaged component. Therefore, early detection of anomalous symptoms in the system behavior is signifi-cantly important to avoid disastrous situations such as loss of control. Although several anomaly detection / diagnosis methods using modern reasoning techniques such as quali-tative reasoning, expert systems and probabilistic reasoning have been developed, they have difficulties in acquiring ac-curate and complete models and knowledge of the spacecraft systems and in monitoring the system behavior exhaustively and efficiently.

One major reason for these difficulties is that conventional anomaly detection systems are heavily dependent on a pri-ori knowledge on the system behavior for each spacecraft. For example, the model-based method[5, 9, 12, 17] requires a perfect dynamics model of the spacecraft, and the ex-pert system[11] demands a set of production rules. In prac-tice, however, preparing such complete and accurate a pri-ori knowledge of the systems is very difficult and expensive, partly because of the so-called  X  X ottle neck of knowledge acquisition X , and partly because of the difference between theory, experiment and actual behavior of the system on the orbit. To make matters worse, the reuse of models and knowledge of the past systems is also limited, because the spacecraft is one of the ultimate custom-made productions in the world, unlike household appliances.

Another difficulty in the anomaly detection and diagnosis for the spacecraft lies in the complexity of the spacecraft sys-tems. Although the spacecraft subsystems (such as attitude control, power supply, and so on) are designed to minimize mutual interference, actual anomalies often occur across sev-eral subsystems, which makes it difficult for human experts and model/knowledge-based detection/diagnosis systems to investigate and understand the phenomena.

For the above reasons, the necessity for  X  X nowledge-free X  anomaly detection methods which are not dependent on a priori expert knowledge such as dynamics models and pro-duction rules is being widely recognized. Fortunately, most modern spacecraft including artificial satellites and orbital transfer vehicles are transmitting multi-dimensional time se-ries called telemetry data containing a variety of low-level system information to ground stations. While the telemetry data is originally for simplistic limit-checking and manual analyses by engineers and experts, recent researches have shown that a variety of data mining techniques can be ap-plicable to this data.

This paper proposes a novel method which detects anoma-lous behaviors of the spacecraft from the vast telemetry data by using the kernel feature space. In this method, teleme-try data at each time point is implicitly transformed into a high dimensional nonlinear feature space by the polynomial kernel. Then the primary causal associations underlying the system behavior are extracted as principal component vec-tors. By detecting some significant changes of the direction of the vectors, it attempts to find unexpected changes in the causal associations of the system behavior, i.e., anomalies.
The remainder of this paper is organized as follows. First, we present a brief review of the conventional approaches to the anomaly detection problem in space systems in Sec-tion 2. Then, we explain the basic concept of the proposed method in Section 3. In Section 4 and 5, we explain the center of the proposed method, the extraction of causal as-sociations and its optimization. In section 6, we show and discuss some results of an experiment. We made use of the telemetry data of a simulated unmanned orbital transfer ve-hicle during the process of rendezvous with the ISS (Inter-national Space Station). Finally, we conclude this study in section 7.
Limit-checking has been the most basic and common tech-nique of detecting anomalies in spacecraft systems for a long time. It constantly monitors some important time series in the telemetry data and checks whether the value is within the pre-defined upper and lower limits. Ref.[7] proposed a method of automatically computing limit values using au-toregressive model. Though the limit-checking has an ad-vantage that it is simple enough to be applied to any types of spacecraft, it lacks flexibility and expressiveness and suf-fers from the problem of false alarms.

In contrast to the limit-checking, the model-based fault detection and diagnosis method will be the most sophisti-cated approach to the problem, in which system models are utilized to simulate the spacecraft behavior and examine the validity of the actual telemetry data. Some researchers use qualitative models[5, 17], while others use mathemati-cal (probabilistic) models[9]. Ref.[12] does not directly de-tect anomalies but intelligently estimates the importance of each sensor information using Bayesian Networks and gives a higher priority to the more important one when it is dis-played on a monitor. The model-based approach would pro-vide an ideal performance if a accurate and complete model and infinite computational power were available. In prac-tice, however, both of them are not available, which limits the applicability of this method.

Expert systems (knowledge-based systems) also have been developed for this purpose, in which knowledge for anomaly detection acquired from human experts is used. The knowl-edge is generally represented in the form of  X  X f-then X  produc-tion rules[11]. Though the expert systems are powerful and flexible, it has a difficulty in preparing a set of accurate and complete knowledge on the spacecraft. This problem has been well known as the bottleneck of knowledge acquisition.
In summary, the above methods of limit-checking, model-based and knowledge-based approaches have a common prob-lem that they are too dependent on the knowledge of human experts.

As mentioned in the previous section, a reasonable ap-proach to this problem is the application of data mining and machine learning techniques to the spacecraft telemetry data. Actually, some researchers have developed anomaly detection methods for spacecraft using the DM/ML tech-niques such as regression tree learning[14], temporal pat-tern clustering[18], association rule mining[19], support vec-tor machine[6] and relevance vector regression[16]. Most of them are based on a common idea that they attempt to de-tect significant unexpected changes in the system behavior by automatically constructing some behavior models induc-tively from a set of training data and comparing them with newly arriving data.

In the subsequent section, we propose a novel anomaly detection method which belongs to this data mining ap-proach. The proposed method regards anomalies as unex-pected changes in the causal associations, and attempts to detect the change by using the kernel feature space.
In the meanwhile, the conventional methods including data mining approaches have other two problems. First, they have defined anomaly in a restricted way. For in-stance, limit-checking is capable of defining only one type of anomaly, in other words, crossing limit values. We regard anomaly phenomena as unexpected changes of causal asso-ciations in a system. This makes it possible for the proposed method to detect various types of anomalies . Second, the conventional methods have difficulties to model the whole behavior of the spacecraft. Although the telemetry data of the spacecraft consists of the various heterogeneous time se-ries data, they have not explicitly made consideration for them. In this paper, we give one consideration for this dif-ficulty by using the kernel method. Figure 1: Image of anomaly phenomena. Some fail-ures cause changes of causal associations in a system.
It is difficult to define what anomalies are in a general sense because the type of anomaly depends on the prob-lem. However, it is a reasonable assumption that some un-expected changes occur in the relationships among system parameters when the system becomes anomalous. Taking a space system for instance, we can see an unexpected change of inertia parameters as anomaly.

In this study, although the behaviors of system (telemetry data) are dynamic, we assume that the causal associations governing such dynamics of the system are almost static be-ing slightly affected by sensor noise, disturbance, operation mode of the system and so on. Then, we define anomalies as following,
Definition 1. Anomalies are some unexpected changes of causal associations in the system such as unexpected disap-pearance, occurrence, or change of coherence degree(dotted arrow in Figure 1) of causal associations (Figure 1). Note that our causal associations mean arbitrary relation-ships among the components, though Figure 1 shows only ones between two components for simplicity.

In this study, each series in the telemetry data is rep-resented as a variable, and nonlinear causal associations among the variables are extracted from the data. We explain the extraction of feature which represents these associations conceptually in Section 3.2 and in 4 in detail.
As we define anomaly above, we must firstly consider how to extract the appropriate features which represent the causal associations among the variables. Unfortunately, lin-ear relations are too simple to model the complex associa-tions inside the spacecraft telemetry data.

In this study, we hypothesize that significant causal asso-ciations among the original variables are supposed to appear as a principal component vector in some appropriate feature space. More specifically, we noticed the product features (so-called  X  X onomials X ) whose effectiveness have been con-firmed in many fields such as pattern recognition research[3]. In Section 4, we explain that the direction of the principal component vector with regard to the data mapped into a Figure 2: Image of training data. Telemetry data are divided into M data subsets. high dimensional feature space represented by product fea-tures can be interpreted as the causal associations inside the system. The anomaly we intend to detect is unexpected changes in this kind of nonlinear associations.

Although it is generally difficult to deal with the high di-mensional feature space directly because of high computa-tional cost, we can implicitly deal with it by using the kernel method which has been noticed because of the great success of the Support Vector Machine[2]. Since we are interested in direction of principal component vector with regard to data mapped into the feature space, we applied the kernel principal component analysis (kernel PCA)[4] to extract the feature vector.

For the purpose of anomaly detection, it is more signifi-cant to estimate the directional distribution of the principal component vector in the normal operation than to predict the most likely principal component vector as a point esti-mate. We explain the optimal estimation of the directional vector which represents the normal data mapped into the feature space the best and the distribution of the princi-pal component vectors in Section 5. The von Mises-Fisher distribution (vMF distribution) is the most natural distri-bution for directional data in that it can be derived using the maximum entropy principle[1, 10].
Here, we clearly describe the problem once more. Let us assume that we have telemetry data in normal operation. The telemetry data have thousands of time series and each element of data point x i is corresponding to each series of telemetry data. Then, we divide them into M data sub-sets, each of which includes N data points, using the sliding window[8] (Figure 2). These data subsets are denoted as D j = { x j i } N i =1 ( j = 1 , . . . , M ).

Then, the proposed method computes the principal com-ponent vector v j corresponding to the subset D j mapped into the high dimensional feature space and learns the direc-tional distribution model modeled as the vMF distribution around the optimal direction r computed from v j .
After learning the optimal distribution model, it computes the occurrence probability of the principal component vec-tor with respect to the real-time incoming telemetry data mapped into the feature space. If this probability is under the pre-defined threshold, it detects anomaly (Figure 3). Figure 3: Image of the proposed anomaly detection method. In learning phase, it extracts principal axes from M data subsets. Then, it learns the distribu-tion of the principal axes. In detection phase, it ex-tract principal axis from online data subset and com-pare it with the learned distribution. If the proba-bility is under the threshold, it detects anomaly.
As mentioned above, we consider that significant causal relationships which characterize the spacecraft system be-havior will become visible in the form of directions of prin-cipal components of the telemetry data, if it is mapped into some appropriate feature space.

Though it will be difficult to find such an appropriate non-linear mapping in a general case, we focused on the product feature space which is implicitly constructed by the polyno-mial kernel in this work.

Suppose we are given a vector x  X  X = R n where most information is contained in the d th order products (so-called monomials) of elements x i of data x , where j 1 , . . . , j d  X  X  1 , . . . , n } such as x 2 1 x on(third order products). These features are referred to as product features . The effectiveness of these features has been confirmed in the many fields such as pattern recognition research[3].

Let us take a look at this feature in a simple example of the telemetry data consisting of two series, in other words, x  X  X  = R 2 . By introducing the product features of degree two ( d = 2), we obtain a nonlinear mapping as below.
Now imagine that the system has a causal association ax 1 + bx 2 2 + cx 1 x 2 = d in terms of x 1 and x 2 , which means that the data lies on a quadratic curve in the original space X (Figure 4 left). This data is mapped through the map-ping function  X  onto a (hyper)plane in the three dimensional Figure 4: Example of nonlinear mapping on product feature space. This is the case, 8 x 2 1  X  3 x 1 x 2 +5 x The data mapped into H are on the hyperplane, and the principal axis represents the data property well. product feature space H , where the linear PCA can be ap-plied for extracting principal axis. We can easily understand that the directions of principal components in the product feature space would change drastically if a non-trivial change occurred in the causal relationships of this system or the sys-tem parameters a, b, c took some unexpected values.
As this example indicates, we can interpret the direction of the data mapped into the feature space H represented by n th order product features as the nonlinear causal associations in the original space X .

A problem of this idea is that it is practically impossible to compute the feature space explicitly when the dimension of the original data ( n ; the number of telemetry data series in this study) and the degree of product feature ( d ) become large. Fortunately, we can deal with the nonlinear map-ping  X  implicitly by using a kernel function which is the dot product in the feature space, where k (  X  ,  X  ) is a kernel function and the notation  X  X  ,  X  X  rep-resents the dot product. Especially, it has been proved that the polynomial kernel, constructs the high dimensional feature space represented by the d th order product features and computes the dot product in that space.

In the remainder of this section, we review briefly the kernel PCA in 4.2 and then define an anomaly metric based on the principal directions of the data in the product feature space in 4.3.
The kernel PCA proposed by Sch  X olkopf, Smola and Muller[4] is an algorithm for computing the principal component vec-tors in a high dimensional nonlinear feature space by ap-plying the kernel method to the classical linear principal component analysis (linear PCA).

In this subsection, we explain how the  X  X irection X  of the telemetry data in the product feature space H is computed using the kernel PCA.
If k is a positive definite kernel function, Mercer X  X  theorem assures that it can be expressed as a dot product in a high dimensional feature space. That is, Then, any algorithm depending only upon dot product can be transformed into another algorithm for the high dimen-sional feature space by replacing the dot product with the kernel function. This technique is called kernel trick .
Though we used the polynomial kernel in this work, the choice of suitable kernels depends on the types of systems and telemetry data. In other words, the proposed anomaly detection method can be applied to various systems other than spacecraft, if we can prepare some suitable kernels.
The m th principal component vector of the j th data set { x the dual eigen value problem, where  X  j mi is the corresponding weight and We assume that v j m is normalized[3, 4].

As described in Section 3, we regard the direction of data { x Therefore, we define as the feature vector. Here,  X  j = (  X  j 1 , . . . ,  X  j m malized eigen value vector. Please note that the feature s in  X  feature space X  and  X  feature vector X  have different meanings in this paper.

Computing the principal components in the high dimen-sional feature space has a certain advantage as below,
Property 1. Using only first m principal eigen vectors, we can eliminate noise.
 The usefulness of this property has also been confirmed in the field of image processing and so on. In this study, we can focus only on causal associations buried in noise because of this property.

In addition, the polynomial kernel of Eq. (5) has the following property,
Property 2. The direction in the feature space H is invari-ant with respect to the scale transformation in the original space, Thereby we can exclude the scale change of the whole system from analysis. It is considered to be very important because the causal associations may be invariant with respect to scale change.

Now, we have one question. Although it is a great advan-tage of the kernel method that it is capable of computing the dot product in the feature space implicitly, is it guaranteed that two different data sets are mapped into an identical
D
D Figure 5: Image of the proposed anomaly metric.
 The larger  X  is, the larger anomaly metric is. feature space when we apply a kernel to them? The answer is Yes . We will give only an intuitive explanation here. For more detail, please consult [3].

Infinite dimensional feature space is constructed both by data and by Mercer kernel in theory. However, since fi-nite data cannot construct infinite feature space, the map  X  into the feature space H is dependent on the data { x j i (Data Dependent Kernel Map[3]). Hence, strictly speaking, the feature space H 1 constructed by the data set { x 1 i different from the feature space H 2 constructed by another data set { x 2 i } N i =1 . However, since the data sets x x i  X  X  are in the same space X , the feature spaces H 1 and H 2 is considered to be approximately identical.
We defined the feature vector in 4.2. The proposed method detects anomaly by monitoring the change of direction of the feature vector. Therefore, we define anomaly metric as following.

Definition 2. Suppose that we have a normal feature vec-v because the difference between directional vectors can be interpreted as the dot product.
 The larger  X  is, the greater the anomaly degree is (Figure 5).

For simplicity, we transform (10) using only the first prin-cipal eigen vector ( m = 1), Here, In general m principal eigen vectors case, we can compute anomaly metric in the same way.
After extracting the feature vectors v j from the M data to compute the optimal directional vector which represents these feature vectors the best. It is natural to suppose that the optimal directional vector is a linear combination of the feature vectors, where c is the normalization constant to satisfy r T r = 1 and w = ( w 1 , . . . , w M ) T is the weight vector which satisfies w
T w = 1. The optimal directional vector r should minimize the sum of anomaly metric between r and v j . Considering that anomaly metric  X  becomes larger in inverse proportion to the dot product  X  r , v j  X  , the optimization problem is ex-pressed as follows, Substituting (13) to (14), Here, and
After all, optimization problem for computing the opti-mal direction r opt becomes the optimization problem for computing the optimal weight w opt , subject to w T w = 1. By introducing a Lagrange multiplier  X  , we can rewrite (18) as, so that
Therefore, the optimization problem becomes the eigen value problem. The optimal weight vector w opt is the first principal eigen vector.

The normalization constant c can be computed from he following equation,
For the purpose of anomaly detection, it is more signifi-cant to estimate the directional distribution of the principal component vector around the optimal direction vector r opt than to predict the most likely principal component vector as a point estimate.

In this study, the feature vector is the directional vec-tor. The most natural distribution for directional data will be von Mises-Fisher distribution (vMF distribution)[1, 10]. Although [1, 10] discuss the utility of a mixture model of the vMF distribution, we applied the single vMF model for simplicity. [20] proposes the anomaly detection method for network systems using vMF distribution.

A p -dimensional unit random vector v is said to have p -variate von Mises-Fisher distribution M p (  X ,  X  ) if its proba-bility density function is given by, where k  X  k = 1,  X   X  0. S p  X  1 denotes the ( p  X  1)-dimensional sphere embedded in R p . The normalizing constant c p (  X  ) is given by, where I p (  X  ) represents the modified Bessel function of the first kind of order p . The vector  X  and  X  correspond to the mean vector and the variance of the Gaussian distribution, respectively. Ref.[1, 10] discuss the maximum likelihood es-timation for this model. The logarithmic likelihood is where u = already computed the optimal direction from the data set { v
Let us write  X  R as, According to Ref.[1, 10], the following equation gives a very reasonable approximation in most cases, Although the Newton-Raphson iteration gives a more accu-rate approximation, we used (27) in this study. See [1, 10] for more detail of this maximum likelihood estimation.
Let us consider the dimension of vMF distribution p . The dimension of the feature space constructed by N data and the kernel function is at most N . Therefore, the directional vector is supposed to have at most N dimension. Consid-ering the kernel PCA performs basis transformation and we apply only the first m th principal component vectors, it is reasonable to approximate p = m 1 .

Once we compute M p (  X , r opt ), the proposed method mon-itors the system by extracting the feature vector v from an incoming data set { x i } N i =1 and computing anomaly metric  X  = Acos | X  r , v  X  X  . If the following probability is smaller than some pre-defined threshold  X  , it detects anomaly, where  X  is the threshold value.

In summary, the anomaly detection system based on the proposed method operates as follows, Step 1. Acquisition of training data : Acquiring the teleme-Step 2. Extraction of feature vector : Extracting the Step 3. Optimization of direction vector : Computing Step 4. Predicting directional distribution : Predict-Step 5. Acquisition of incoming data : Acquiring the real-Step 6. Detecting Anomaly : Computing anomaly metric
We do not make a detailed discussion about computa-tional cost in this paper because we intend to emphasize not on how to reduce it but on how to monitor the changes of causal associations. However since the computational cost is the quite significant issue for anomaly detection system, let us describe some considerations.

The proposed method acquires the model of causal associ-ations from the normal telemetry data in an off-line process. Therefore, the computational cost is not so critical. On the other hand, in the operation phase of the spacecraft, we must detect anomalies in real-time process.

In the detection phase, it is computationally the costliest to compute the anomaly metric  X  r , v  X  in (22) whose order is O ( MN 2 ). Therefore, we can say that it is important to reduce N .
Although principal component vectors of M data subsets are not completely the same, this approximation can be said to be natural because the directional vectors of normal data are considered to strongly distribute around the optimal di-rection r opt .

The term N 2 derives from the dot product of the principal component vectors, If many  X  k 1 i  X  k 2 j become zero, it is expected that we can reduce the computational cost in the second order.
This sparsity can be achieved by the Sparse kernel PCA proposed by Tipping[13] which makes use of the framework of the Bayesian learning. Ref.[13] has confirmed that the small subset of original data can construct the same prin-cipal component vector in the kernel feature space. This algorithm is supposed to greatly reduce the computational cost of the proposed method.
We have confirmed the effectiveness of the proposed method by applying it to the telemetry data of a simulated un-manned orbital transfer vehicle during the process of ren-dezvous maneuver with the ISS provided by Japan Aerospace Exploration Agency (JAXA).

This telemetry consists of 27 time-series variables in to-tal, thirteen of which are from position and attitude con-trol subsystem (AOCS), and the rest are from propulsion subsystem (PS). In more detail, the former group (AOCS telemetry) consists of twelve numerical observation time-series variables regarding the position and attitude of the vehicle and one discrete-valued variable representing a com-mand sequence. The latter group (PS telemetry) consists of fourteen discrete-valued time-series variables, each of which indicates the command input to each of the fourteen thrusters installed in the vehicle.

The state of the spacecraft dynamically varies according to the command and the control low (we did not obtain the knowledge of the control low from JAXA). In addition, the properties of the observation series and the command series are quite different. It is very difficult task to acquire the knowledge from this type of data.
First, we have applied the polynomial kernel k ( x , x 0 ) =  X  x , x 0  X  d . We have empirically set d = 2 since the telemetry data obtained from the simulation are comparatively simpler than the real telemetry data.

Secondly, we have 7500 data points of the normal teleme-try data (950 sec). We divided them into the 25 data sets ( M = 25) which means each subset contains 300 data points ( N = 300).

We set m = 2 as the number of principal components as the result of the trade-off between performance and compu-tational cost.

It should be noted that we used the difference value be-tween time t and t + 1 with regard to the position and at-titude control subsystem instead of its original observation value. This is because the difference value generally has more information than the original observation value itself with regard to the position and attitude control subsystem.
And finally, we have defined the threshold for anomaly detection at  X  = 0 . 03 which corresponds to the three sigma range of the Gaussian distribution ([  X   X  3  X ,  X  + 3  X  ]). Figure 6: The von Mises-Fisher distributions learned by the proposed method and the method using the linear PCA.
To confirm the validity of our hypothesis that the causal associations in the system appear in the principal compo-nent direction in the kernel feature space, we have applied the proposed method and the method using the linear PCA (in other words, using linear kernel k ( x , x 0 ) =  X  x , x the normal telemetry data and have compared their perfor-mances. If the proposed anomaly metric (10) is effective, the proposed method is supposed not to detect anomaly against the threshold computed by (28).

The telemetry data in normal operation was divided to training and test data sets. Using the training data, the pro-posed method and the method using the linear PCA respec-tively have learned the optimal directions r and the vMF distributions M m ( r ,  X  ) in each feature space (the linear ker-nel constructs original linear space). Figure 6 shows the learned vMF distributions. The solid line and the dashed line represent the vMF distributions of the proposed method and the linear PCA method respectively. We can see that the latter is nearly uniformly distributed and obtains no knowledge. On the other hand, the former has the strong peak around the optimal direction r . This result implies that our hypothesis about the causal associations is reason-able. In this case, the threshold for detection is computed as  X   X  0 . 304( radian ) from (28).

Then, we have monitored the anomaly metric  X  (cos  X  =  X  r , v  X  ) of the test data over time and Figure 7 shows the results. The solid line, the chained line and the dashed line represent the result of the proposed method, the method using linear PCA and the limit value  X  for the proposed method respectively. From Figure 6 and Figure 7, we can confirm that the linear model in the original space cannot model the causal associations. And the proposed feature vector and anomaly metric give few false alarms in the nor-mal state.

Next, we confirm that the proposed method is capable of detecting anomalies in the following three anomaly cases. In each case, the ninth thruster which is used for the pitch control has some trouble at 250 [ sec ]. Figure 8 shows the changes of the thruster duty of each case. The lower the thruster duty is, the greater the anomaly is. Figure 7: Changes of anomaly metric of normal telemetry data over time. Figure 8: Changes of the thruster duty over time in each scenario.
 Scenario 1 The thruster periodically passes between the Scenario 2 The thruster duty sinusoidally varies. The pe-Scenario 3 The thruster duty falls down to 30 percents.
In this scenario, The thruster engine periodically passes between the normal state and completely failure state as shown in the top of Figure 8.

Figure 9 shows the result. The upper figure shows the change of anomaly metric. The proposed method succeeded in detecting the anomaly. It looks like the predicted anomaly period is longer than the real one. This is because of the window length of the data set ( N ). In other words, the com-pletely normal data set rarely appears as shown in Figure 10. Figure 9: Change of anomaly metric over time in the scenario 1.
Figure 10: Period of anomaly and data length.
In this scenario, the thruster duty sinusoidally varies as shown in the Figure 8.

Figure 11 shows the result. This result is more interesting than the result of scenario 1. The form of the change of the predicted anomaly metric (upper figure) is quite similar with the one of real thruster anomaly (lower figure). From this result, we could confirm that the proposed method put out quite high performance if the parameters such as N are adequate.
This scenario is the most difficult among three. Even though the ninth thruster duty falls down to 30 percents, the behavior of the spacecraft hardly makes any change because other thrusters compensate for the lack of thruster power. The expert of JAXA said that even experts are supposed to miss this anomaly if they do not carefully monitor the telemetry data.

Figure 12 shows the result. The proposed method cap-tured the slight change of the causal associations and de-tected anomaly.
This paper proposed a novel anomaly detection method for spacecraft using kernel method. The system behavior of the spacecraft dynamically varies over time. This method successfully detects changes in the semi-static causal asso-ciations underlying the system behavior by mapping the telemetry data into a nonlinear feature space and obtain-Figure 11: Change of anomaly metric over time in the scenario 2. Figure 12: Change of anomaly metric over time in the scenario 3. ing the direction of its principal component vector.
The contributions of this paper are as follows.
While we used the simple polynomial kernel in this study, the proposed method can be applied to more heterogeneous multidimensional time-series data if we can design an ap-propriate kernel.

Finally, let us describe our future works. The proposed method is incapable of reasoning the cause of anomaly be-cause the kernel function implicitly computes the dot prod-uct in the high dimensional feature space 2 . We will approach to this difficulty by some means. In addition, we have to consider the optimization problems with regard to the pa-rameter such as the data length N or the number of the principal component vector m .
The authors would like to thank Japan Aerospace Explo-ration Agency (JAXA) for providing the simulation teleme-try data.
Though this is the great advantage of the kernel method, we would like to know what occurs in that space for the purpose of failure diagnosis.
