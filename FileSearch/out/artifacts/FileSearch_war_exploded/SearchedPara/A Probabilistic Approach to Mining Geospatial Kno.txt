 User-generated content, such as photos and videos, is often anno-tated by users with free-text labels, called tags. Increasingly, such content is also georeferenced, i.e., it is associated with geographic coordinates. The implicit relationships between tags and their lo-cations can tell us much about how people conceptualize places and relations between them. However, extracting such knowledge from social annotations presents many challenges, since annota-tions are often ambiguous, noisy, uncertain and spatially inhomoge-neous. We introduce a probabilistic framework for modeling geo-referenced annotations and a method for learning model parameters from data. The framework is flexible and general, and can be used in a variety of applications that mine geospatial knowledge from user-generated content. Specifically, we study three problems: ex-tracting place semantics, predicting locations of photos and learn-ing part-of relations between places. We show our method per-forms well compared to state-of-the-art approaches developed for the first two problems, and offers a novel solution to the problem of learning relations between places.
 I.5.1 [ Pattern Recognition ]: Models X  Statisticals Algorithms information extraction, data mining, geo-spatial, social network
The Social Web sparked a revolution by putting knowledge pro-duction tools in the hands of ordinary people. Today on Social Web sites such as Twitter, Flickr, and YouTube, large numbers of users not only create rich content, including photos and videos, but also annotate content with descriptive labels known as tags , and geo-reference it by associating with it geographic coordinates, known as geo-tags . The implicit relationships between tags and their lo-cations can be mined to learn what places people talk about on the Social Web and how much attention they give to a place, what the extent of it is, and how it relates to other places.

Several researchers have recently investigated approaches to learn-ing relations between concepts from social metadata. Schmitz [13] applies a statistical subsumption model [12] to learn hierarchical relations between tags. He addresses the challenge of the popular-ity vs generality problem using tag frequency. Plangprasopchok et al. [10] learn folksonomies by aggregating many shallow individual hierarchies, expressed through the collection/set relations on Flickr. They address many challenges in their approach, for example, dif-ferences in the level of expertise and granularity for each user.
In this paper we propose a proba bilistic framewo rk for mining geospatial knowledge from social annotations. One challenge in spatial data analysis is the problem of scale. Changing scale can significantly affect spatial statistics [9] and classification results [16]. In the place identification problem studied by [11], researchers ad-dressed this problem by computing statistics at every predefined scale, then used sum of these statistics for significance testing. Meth-ods developed for location prediction [3, 14] also relied on dis-cretizing data. We represent the spatial distribution of a tag as a mixture of Gaussian probability density functions. Such Gaussian mixture models (GMMs) can be estimated directly from data with-out using discretization parameters. Being probabilistic, the model also presents a natural way to deal with noise and uncertainty.
The proposed probabilistic framework is general and flexible and can be used in a variety of geospatial data mining applications. We evaluate its performance on three distinct tasks. In the first task, place identification [11], we classify tags as place names or not place names based on their spatial distributions. In the second task, location prediction [3, 14], we attempt to predict locations of photos given their tags. In the third task, we use the probabilistic framework to learn relations between places.
We focus on analyzing the social photo-sharing site Flickr, which allows registered users to upload photos and videos and annotate them with descriptive labels, known as tags . Tags are used to de-scribe the image X  X  subject (e.g.,  X  X nimal X ,  X  X amily X ), properties, as well as where the image was taken (e.g., X  X alifornia X ). In addition to tagging photos and videos, Flickr also allows users to geo-tag ,or geo-reference, content by attaching geographic coordinates to it.
The implicit relation between tags and locations of photos an-notated with those tags can tell us much about how people think of places and relations between them. We model tags and pho-tos in terms of spatial probability distributions or density functions. Spatial distribution of tag w can be written as P ( X | w ) ,where X represents locations of photos tagged with w . Then, we can easily model spatial probability distri bution of a photo as a superposition of probability distributions of all tags in that photo.

We start by modeling probability distribution of each tag sep-arately. Using a sufficient number of Gaussian components, and by tuning the parameters of each components and adding them linearly, most continuous distributions can be approximated [2]. Moreover, probabilistic models can address the challenges of noise, uncertainty and ambiguity. However, there still remains a challenge to using GMMs to model spatial distribution of tags, as the number of components may not be known beforehand, and using too many components puts us in danger of overfitting the data. The section below proposes a solution to this problem.

Tag Distribution as a Mixture of Gaussians: Gaussian mixture model is a superposition of K Gaussians: where each Gaussian density N ( x |  X  k ,  X  k ) is called a component of the mixture with mean  X  k and covariance matrix  X  k . Parameter  X  , called the mixing coefficient, gives the weight of the k th com-ponent, or the fraction of all data points that are explained by that component. It has a value between 0 and 1, and K k =1  X  k
The Gaussian mixture model is specified by the number of mix-ture components, each governed by parameters  X  k , X  k ,  X  given model, we use expectation-maximization (EM) algorithm [4] to estimate model parameters  X  k , X  k ,  X  k . EM is an iterative algo-rithm with two major steps: expectation (E) and maximization (M) step. The E step estimate  X  ( z nk ) from the current parameter val-ues where  X  ( z nk ) can be viewed as as res ponsibility of component k generate x n . The M-step updates the values of  X  k , X  k  X  ( z nk ) of the previous step. The process continues until conver-gence. The convergence is usually defined by when the log like-lihood function or finding parameters changes below some thresh-old [2].

How many mixture components K should we use to model each tag? By using more components (increasing the number of model parameters), one can usually get the model to better describe the data. However, this may lead to overfitting, where a very complex model explains every point in the training data set, but it cannot generalize, and therefore, has no predictive power on test data. We can reduce this problem by penalizing model for its complexity (e.g., using AIC or BIC) The BIC is used for model selection in statistics. It avoids overfitting by i ntroducing a penalty term for the number for parameters in the model [8].

Our model selection process is very simple. We estimate model parameters using the EM algorithm to get the maximum likelihood estimate L ( K ) with respect to the number of components K .We then choose the values of K that minimizes the BIC value of the model: K =argmin K BIC ( K ) . Thus, each concept has differ-ent number of components. About 34 % of the tags in our data set have between one and ten components, 57 % have between 11 and 20 components and 9 % of the tags have more than 20 components (the maximum number of components we consider is 30).
One of the main challenges of mining user-generated content is to extract structured knowledge from a set of annotations. This is done by exploiting their usage patte rns. Modeling the distribution of a tag as a mixture of Gaussians offers a general and flexible framework for data mining applications in the geospatial domain. In this section, we study the problems of place identification, loca-tion prediction, and learning part-of relations between places. The goal of the first task is to learn whether or not a tag refers to a place based on its spatial distribution. The goal of the second task is to geo-reference a photo based on its tags. Our approach ex-ploits the structure in the data by probabilistically modeling the relations between a photo X  X  location and its tags using the Gaus-sian mixture model. The goal of the third task is to learn relations between places, for example, that  X  X isneyland X  is in  X  X alifornia X . This approach can be used to learn novel relations that do not ex-ist in official gazeteers, but may reflect common folk knowledge,  X  X anta monica X  is in  X  X os angeles X . Our proposed algorithm com-pares spatial distribution of two tags and if the distribution of a geographically broader term, e.g.,  X  X alifornia X , substantially over-laps the distribution of the more localized term, e.g.,  X  X isneyland X , then we learn that  X  X alifornia X  subsumes  X  X isneyland X .

Data collection: The data for the experiments was collected from the social photo-sharing site Flickr. We used the Flickr API to re-trieve informa tion about more than 14 m illion geo-ta gged photos created by 260K distinct users. These photos were tagged over 89 million times with 3 million unique tags. As a preprocessing step, we filter out tags which were used by fewer than 100 people. To create the training data set for learning GMM parameters of the distribution of a given tag, we sample a single photo from each of the remaining users uniformly from a 100 km grid described in [3]. After these preprocessing steps, the training set contains 2.5M photos with 192K distinct users and 11K distinct tags.
Rattenbury et al. [11] observed that  X  X lace tags exhibit spatial usage patterns that are significantly geographically localized X  [11]. While these photos can be found all over the world, they are much more dense around California. Rattenbury et al. [11] proposed a quantitative method to identify place tags. Their solution relied on multi-scale analysis method that they called Scale-Structure Identi-fication. They tackle problem of MAUP by clustering data at many different values of the scale parameter r and combine entropy val-ues at different scales. Their method is used as the baseline in this experiment. We use the same int uition to distinguish between place or non-place tags, but analyze the spatial patterns of the tags using the probabilistic modeling framework.

Model-Based Place Identification: Instead of discretizing data at different scales, we work w ith a continuous probability density function. We decide whether a tag is well-localized by examin-ing the continuous entropy of P ( X | w ) . The intuition behind our method is as follows. People usually use non-place tags everywhere in the world, for example, people use the tag  X  X phone X  all over the globe. This tag has very high uncertainty, thus, it is unlikely that we can predict locations of photos tagged  X  X phone X . In contrast, the tag  X  X lcatraz X  is highly localized. In other words, it has low uncertainty in the geospatial domain.

Entropy is used to measure uncertainty of a distribution. In this application, we use entropy to estimate the uncertainty of P ( X the spatial distribution of the tag w . There are advantages to using entropy in continuous space. First, geographic locations occur in continuous space. To estimate entropy in continuous space, there is no need for discretization parameters. Once entropy is estimated, it can be directly manipulated, e.g., compared to a threshold,without further processing as in discrete entropy method.
 The continuous entropy of tag w can be estimated by Table 1: Comparison of the model-based approach (gmm) to baseline on the place identification task.
 There is no analytic form for computing the entropy. Instead, we estimate it using the Monte Carlo method [6]. The idea is to draw asample x i from the probability distribution P ( x ) such that the expectation of log P ( x ) ,  X  E P ( x ) (log P ( x )) = H ( P ) . Monte Carlo method is used because, according to [6], Monte Carlo sam-pling has highest accuracy for approximation for high enough num-ber of samples; however, it is computationally expensive. A better runtime approximation can be obtained by more sophisticated ap-proaches discussed in [6]. The Monte Carlo approximation of en-tropy can be expressed as: where x i is a sample from the distribution P ( x ) . As the number of samples n grows large, H MC ( P )  X  H ( P ) . If a tag X  X  entropy is lower than some threshold  X  ,then P ( x | w ) is judged to be localized, and we identify the tag w as a place name:
Evaluation: To compare the performance of different methods on the place identification task, we need a ground truth about place names. For this purpose we use GeoNames (http://geonames.org), a geographical database containing over eight million place names from all over the world.

We use standard precision and recall metrics to evaluate the per-formance of baseline and the proposed model-based method on the place identification task. Precision measures the fraction of tags that were correctly predicted to be place names relative to the num-ber of all tags that were predicted to be place names. Recall mea-sures the fraction of place names in GeoNames that were predicted to be place names. However, precision and recall are sensitive to threshold value; therefore, we compute the performance as the precision-recall curve. Aggregate metrics, including AUC (area un-der precision-recall curve, maximum f1 score (Max F1), and mini-mum classification error rate (Min CE), are reported in Table 1. As we can see from these results, our method performs slightly better than baseline. Its true advantage, however, is flexibility, as the same probabilistic framework can be used to address different geospatial data mining tasks, as shown below.
We apply the probabilistic model to solve a different problem, namely, find the most likely geographic location of a photo given its tags. Previous researchers framed the location prediction problem as one of classification [3, 14]. Crandall et al. [3], for example, used the mean-shift clustering algorithm to separate photos into distinct clusters, with each cluster representing a class of locations. The tags of the photos in the cluster are used as prediction features. Their method computes the probability of a class and probability of each feature given the class. Then, given a new photo with some tags, they use a naive Bayes classifier to predict the class the photo belongs to. Their method is used as the baseline in this experiment.
Model-based Location Prediction: We model a photo as a proba-bility density function P ( x ) in continuous space. Our model-based approach allows us to express the relationship between a photo X  X  lo-cation and its tags, whose distributions were learned from the train-ing data. In previous section we have already computed P ( x where x is a geographic location and w is a tag. We will show that we can model a probability density function of a photo with this density function.

The assumption in our model is that tag frequency in one photo is one, i.e., a user does not repeatedly use the same tag in a photo. Thus, the probability distributio n of each tag in a photo is uniform. Given W = { w i } , the set of tags in a photo, then using the as-sumption above, P ( w i )=1 / | W | ,where | W | denotes the num-ber of tags in the photo. Probab ility density function of a photo is a superposition of bivariate Gaussian distributions because each component, P ( x | w ) , is superposition of bivariate Gaussian distri-butions. The distribution p ( x ) can be interpreted as probability of the photo X  X  location. Therefore, the best guess of location x of a photo is the mode of p ( x ) , in other words, location x that corre-sponds to the maximum value of p ( x ) . We can ignore the term P ( w ) , because it is constant, independent of the photo X  X  location. However, P ( x ) of a photo is a non-linear function. To optimize this function numerically, in current imple-mentation, we use Matlab implementation of a numerical method called Nelder-Mead Simplex Method [7].

Evaluation: We use methodology described in [3] to prepare the test data set for evaluating the proposed method. The test set is created by randomly selecting 5000 users, then choosing a photo at random from each user. Thus, the test data set consists of 5000 photos from 5000 users. Finally, photos from the users in the test set are removed from the training set to prevent bias that may come from having the same users in the training and test data sets. Figure 1: Comparison of performance of different methods in terms of the error between the photos X  predicted and actual locations. (a) Distribution of errors in the test set. (b) Cumu-lative distribution function of errors produced by the proposed method (gmm) and baseline.

We hide the actual locations of photos in the test set and use our method and baseline to predict their locations. We compare per-formances between our method and baseline using Geographical distance [15] between predicted ( prd ) and actual ( act ) locations by using haversine formula. Figure 1(a) shows the distribution of prediction errors made by the model-based approach as a his-togram, where each bin corresponds to a unit of 100 km. The bins corresponding to the lowest errors have the highest frequency, im-plying that our method results in small prediction errors most of the time. Figure 1(b) compares the cumulative probability distribution (CDF) of the errors made by the proposed method (gmm) and base-line. The proposed method has highe r probability for lower errors, meaning that it produces better predictions than the baseline.
Evaluation: Existing location prediction methods suggest using gazetteers to improve prediction accuracy [1, 5, 14]. The key idea is that place-related terms, e.g.,  X  X oldengate X , should have higher weight than non-place-related terms, e.g.,  X  X phone X , in classifica-tion. Figure 2: Using tag entropy to improve location prediction from tags. (a) Scatter plot of the prediction error (in units of 100 km) vs entropy of photo X  X  representative (lowest entropy) tag. (b) CDF of prediction errors after filtering out photos whose tags are not well localized. Each line corresponds to a different filtering threshold, i.e., the lowest entropy value for the most localized tag in the photo.

Our model-based method can integrate tag X  X  spatial uncertainty to come up with better, more accurate location predictions. Intu-itively, localized tags tend to have higher predictive power; there-fore, tags that have low entropy will produce a lower error on the location prediction task. Figure 2(a) validates this assumption. It plots the entropy of the representative (most localized) tag of each photo vs error of the predicted location. We can use these results to filter out photos the locations of which we cannot confidently predict. We repeat location prediction experiment, keeping pho-tos whose representative tag X  X  entropy value is below some thresh-old. Figure 2(b) shows the CDF of the prediction error for different values of entropy threshold. The line that shows the CDF of the predicted error for threshold of 12 (which overlaps the results for threshold=9) corresponds to the CDF of the model-based predic-tion error without filtering (Fig. 1(b)). The figure shows that we can get much more accurate predictions (lower errors) for photos that use well-localized tags, and the more localized the tags, the better the performance. In fact, the performance is much better than baseline.
In this section we describe how to use the proposed framework to learn relations between places, for example,  X  X ocal X  is part of  X  X alifornia X  (represented as  X  X alifornia X   X   X  X ocal X ). Our approach is inspired by probabilistic subsumption [12]: given two concepts w and w 2 , if the occurrences of instances of w 2 can explain most of the instances of w 1 , but not vice versa, we say that w 2 w ,or w 2 refers to a broader concept than w 1 . Transposed to the geospatial domain, this implies that the spatial distribution of the more general parent tag, e.g.,  X  X alifornia X , should subsume the spa-tial distribution of the child tag, e.g.,  X  X ocal X . Schmitz [13] used probabilistic subsumption to learn broader-narrower relations be-tween Flickr tags, which we use as baseline in our experiments.
Model-based Method for Learning Relations: We can view the problem of learning relations as finding a broader distribution as-sociated with a parent place that can well enough approximate the distribution of the child place. For example, for a given tag w distribution P ( x | w i ) , the problem is to find P ( x proximate P ( x | w i ) well enough, where w i = w j .For P ( x that can adequately well approximate P ( x | w i ) , we learn the rela-tion w j  X  w i .Weuse cross entropy to quantify this intuition.
Cross entropy measures the  X  X ifference X  in information content between two probability distributions and can be interpreted as the average information for discriminating between them. The cross entropy of distributions P and Q , H ( P,Q ) , is asymmetric, mean-ing that H ( P,Q ) = H ( Q, P ) . We can use cross entropy to mea-sure information difference between spatial distributions of two tags. The cross entropy of the child tag with respect to its par-ent should be low compared to the cross entropy of the same child tag with respect to an irrelevant term, since less information is re-quired to differentiate the distribution of the child tag from that of the parent, rather than from the distribution of an irrelevant tag. For example, let tag w 1 =  X  X ocal X , tag w 2 =  X  X alifornia X  and tag w 3 =  X  X alaysia X . Then, because  X  X alaysia X  has no spatial relation with  X  X ocal X  but  X  X ali-fornia X  has. Therefore, we can learn a relations between tags as follows: given tag w 1 and w 2 , w 2 is a parent of w 1 if and only if
The parent concept is usually geographically broader than the child concept. If w 1 can approximate w 2 well enough and w also approximate w 1 well enough, they could potentially be syn-onyms. Therefore, we need to add two more conditions. First, the child tag distribution cannot approximate the parent tag distribution by the reverse condition. Second, the parent tag is geographically broader than the child tag, which can be measured using its entropy H ( P ( x | w )) . This changes the formulations of the relation learning problem. Given tags w 1 and w 2 , w 2 is a parent of w 1 if and only if w 1 and w 2 satisfy the following three conditions: where the cross entropy and entropy are defined as: H P ( x | w 1 ) ,P ( x | w 2 ) =  X  Entropy in continuous space is defined as the expectation E of log( P ( x | w )) with respect to itself, while cross entropy of the distributions P ( x | w 2 ) and P ( x | w 1 ) is defined as the expectation of log( P ( x | w 2 )) with respect to the distribution P ( x P ( x | w i ) is given by Equation 1. Table 2: Comparison max F-score of the model-based approach (gmm) to baseline on the inducing relation task.

There is no analytic form for computing the cross entropy. Thus, we estimate it using the Monte Carlo method [6]. The idea is same with the approximation of entropy in the place identification sec-tion. The Monte Carlo approximation of cross entropy is: where x i is a sample from the distribution P ( x ) . As the number of samples n grows large, H MC ( P,Q )  X  H ( P,Q ) . Evaluation: We evaluate our methods on three test sets: U.S. states, countries, and continents. The U.S. states set is seeded by tags such as  X  X l-abama X  . The countries set is seeded by tags such as  X  X ermany X . The continents set is seeded by five tags  X  X frica X ,  X  X sia X ,  X  X urope X ,  X  X orthamerica X , and  X  X outhamerica X . The different granularity lev-els of the seed terms illustrate the challenges of mining geospatial knowledge, including the popularity vs. generality problem. We use GeoNames to measure the quality of learned relations. We construct the ground truth as follows. For each seed in the test set, e.g.,  X  X labama X , we identify the corresponding geoid in GeoN-ames, e.g., geoid corresponding to Alabama, and extract the names of all geoids within it. Then, using methodology described in Sec-tion 3.1, we filter these child places, keeping only those places that match Flickr tags in our data. For each child place, we then cre-ate a relation seed  X  child , or  X  X hild place is in seed place, X  for example,  X  X labama X   X   X  X obil X .

We use precision and recall to evaluate learned relations. Preci-sion measures the fraction of the learned relations that exist in the ground truth, and recall measures the fraction of relations in the ground truth that the method was able to learn. The maximum F-score is used to quantify the aggregate performance of the method.
Maximum value of F-score (max-f1) attained by the two meth-ods on the data sets are shown in Table 2. The max-f1 score of our method on the U.S. states data set is a little lower than the max-f1 score of baseline. However, on the countries or continents data sets our method performs significantly better than baseline. We conclude that for learning relations between places, our method is more robust than baseline.
We present a probabilistic framework that models each tag in continuous space as a mixture of Gaussian distributions, the pa-rameters of which can be estimated by analyzing a corpus of geo-referenced and annotated photos. The probabilistic framework is flexible and can used to solve a number of geo-spatial data min-ing problems. Once the distribution P ( x | w ) is estimated, it can be used in a number of geospatial applications within one frame-work. For example, we identify place names by looking for tags that have low entropy: H ( P ( x | w )) &lt; X  . To predict the location of a photo with tags W , we look for the maximum of the tag dis-tributions: x predict =argmax x w  X  W P ( x | w ) . It is also easy to combine these methods to improve results of location prediction by using only spatially informative tags. Similarly, we can learn relations between places represented by tags w 1 and w 2 simply by comparing the cross entropy of their probability distribution. Our method performs better than baseline at different spatial scales. We can continue comparing cross entropy of tags to arrange the learned relations within a taxonomy of places. In summary, the advantages of our framework are its simplicity, flexibility and competitive per-formance in mining noisy user-generated geospatial data. This material is based upon work supported by the National Science Foundation under Grant Nos. IIS-0812677 and CMMI-0753124. [1] E. Amitay, N. Har X  X l, R. Sivan, and A. Soffer. Web-a-where: [2] C.M.BishopandS.S.EnLigne. Pattern recognition and [3] D. J. Crandall, L. Backstrom, D. Huttenlocher, and [4] A. Dempster, N. Laird, and D. Rubin. Maximum likelihood [5] C. Gouv X a, S. Loh, L. F. F. Garcia, E. B. Fonseca, and [6] J. R. Hershey and P. A. Olsen. Approximating the Kullback [7] J. C. Lagarias, J. A. Reeds, M. H. Wright, and P. E. Wright. [8] A. R. Liddle. Information criteria for astrophysical model [9] S. Openshaw. The modifiable areal unit problem . Geo Books [10] A. Plangprasopchok, K. Lerman, and L. Getoor. A [11] T. Rattenbury and M. Naaman. Methods for extracting place [12] M. Sanderson and B. Croft. Deriving concept hierarchies [13] P. Schmitz. Inducing ontology from flickr tags. In WWW [14] P. Serdyukov, V. Murdock, and R. Van Zwol. Placing flickr [15] R. W. Sinnott. Virtues of the Haversine. Sky and telescope , [16] Y. Yang and G. I. Webb. Discretization for naive-Bayes
