 ORIGINAL PAPER K. C. Santosh  X  Bart Lamiroy  X  Laurent Wendling Abstract This paper develops a structural symbol recog-nition method with integrated statistical features. It applies spatial organisation descriptors to the identified shape fea-tures within a fixed visual vocabulary that compose a sym-bol. It builds an attributed relational graph expressing the spatial relations between those visual vocabulary elements. In order to adapt the chosen vocabulary features to multiple and possible specialised contexts, we study the pertinence of unsupervised clustering to capture significant shape varia-tions within a vocabulary class and thus refine the discrimina-tive power of the method. This unsupervised clustering relies on cross-validation between several different cluster indices. The resulting approach is capable of determining part of the pertinent vocabulary and significantly increases recognition results with respect to the state-of-the-art. It is experimentally validated on complex electrical wiring diagram symbols. Keywords Spatial relations  X  Visual vocabulary  X  Shape descriptor  X  Unsupervised clustering  X  Symbol recognition 1 Introduction Graphics recognition has an extremely rich state-of-the-art literature in symbol recognition and localisation. However, most methods are targeted towards isolated line symbols, not for composed symbols connected to a complex environ-ment [ 12 , 27 ]. Considering the problem of symbol localisa-tion in real documents, composed of individual parts and constrained by spatial relations for instance, one needs to be able to extract visual parts, characterise their shape descrip-tion and formalise the possible links that exist between them. This integration of spatial relations and shape description of the extracted visual parts is going to be the core of this paper.
Among the existing state-of-the-art, structural approaches provide powerful representations, conveying how parts are connected to each other. However, relations [ 38 , 44 ] do not exploit shape information as shape descriptors do. On the other hand, especially when symbols are not in simple linear andisolatedform,butarecomposedofmanyelements,some-timesexhibitingsubtledifferences,globalsignal-basedshape descriptors cannot provide optimal retrieval performance.
In this paper, we aim to combine both structural and sta-tistical approaches and try to avoid the shortcomings of each of them. To do so, we decompose symbols by expressing their various parts in a fixed visual vocabulary, using spa-tial relations, graphs and signal-based descriptors to describe the whole shape. This paper is the extension of previous work [ 41 , 44 , 51 ] where we have established the significance of spatial relations for symbol recognition. 1.1 Related work Studies related to the inclusion of spatial relations for symbol recognition, symbol representation and matching techniques as well as the performance analysis of several different struc-tural approaches can be found in Cordella and Vento [ 11 , 12 ], Llad X s et al. [ 26 , 27 ]. It seems to us that some of their limita-tions may be addressed by looking at their possible integra-tion with statistical approaches.

In Cordella and Vento [ 11 ], shape analysis for symbol recognition has been comprehensively addressed. Their con-text mainly consists of isolated binary shapes. In paral-lel, statistical approaches like global signal-based descrip-distortions, since they tend to filter out small detail changes. This is unfortunately inconvenient in our context where sym-bols may either be very similar in shape X  X nd only differ by slight details X  X r either be completely different from a visual point of view. Symbols may also be composed of other known and significant symbols and need not necessary be connected. Moreover, the previously mentioned meth-ods difficultly accommodate with connected or composite symbols and their major drawbacks are due to deformation, composition with other symbols (which, in Yuen et al. [ 59 ] leads to unstable centroid detection, and thus errors in the ring projection) and occlusion over the boundary (leading to unstable tangents in shape context (SC) [ 4 ], for instance). In some cases, researchers have been integrating descrip-to increase their performance, partially based on the idea pre-sented in Tombre et al. [ 52 ] that off-the-shelf methods are primarily designed for applications where line symbols are isolated. In these statistical approaches, signatures are sim-ple with low computational cost. However, discrimination power and robustness strongly depend on the selection of an optimal set of features for each specific application.
Besides global shape-based symbol description, another idea is to decompose the symbols into either vector-based primitives like points, lines, arcs, etc., or into meaningful parts like circles , triangles , rectangles , etc. These methods fall under structural approaches. They are then represented as attributed relational graphs (ARG) [ 8 , 10 ], region adja-cency graphs (RAG) [ 26 ], constraint networks [ 1 ]aswellas deformable templates [ 54 ]. Their common drawback comes from error-prone raster-to-vector conversion. Those errors can increase confusions among different symbols. Further-more, variability of the size of graphs leads to computational complexity in matching. However, structural approaches pro-vide a powerful representation, conveying how parts are connected to each other, while also preserving generality and extensibility. Several other approaches are more focused on computing symbol signatures by taking some regions of interest in the document image [ 15 , 37 , 56 ]. These methods aim at providing faster matching in comparison with graph matching.Ontheotherhand,theyaredependentontheregion of interest detector.

The overall conclusion is that one needs an appropriate image description so that the advantages of statistical fea-tures can be integrated with the expressiveness of structural approaches, thus providing generality and extensibility prop-erties. This was already mentioned in Tombre [ 50 ]: ... the very structural and spatial nature of the infor-mation we work with makes structural methods quite natural in the community. Their efficient integration into methods which also take full advantage of statisti-cal learning and classification is certainly the right path to take.

An interesting example that uses shape descriptions and relations to form a RAG is found in Bodic et al. [ 7 ]. The vector-based RAG is based on segmented regions which are labelled as vertices and geometric properties of adjacency relations are used to label edges. However, the approach is limited once segmented regions change with image transfor-mations.

In the framework of stroke-based hand-drawn symbol recognition, two studies are interesting to consider [ 22 , 25 ]. The first one is related to template-based matching. The other one uses an ARG where the vertices represent geo-metric primitives like lines and arcs, and the edges rep-resent the geometric relationships between them. Match-ing is primarily based on graph matching or graph iso-morphism [ 29 ] and is conceptually similar to [ 57 ]. These approaches perform well as long as the vertices are well separated and segmented (which is the case, since they are taken from online strokes and thus vectorisation difficul-ties are avoided). Recently,Coustaty el al. [ 13 ] introduced an interesting approach where a Galois lattice is used to clas-sify structural signatures extracted by using the Hough trans-form. These structural signatures are based on a topological graph using five topological relations computed between the segments as well as their lengths (based on connected and disconnected topological configurations). The paper reports that Galois lattice-based classification is very robust to noise. This, however, may not provide consistent performance when symbols are found with other graphical elements or with possible texts within the image. Furthermore, since it is very dependent on the Hough transform-based segment extraction, it cannot easily incorporate more statistical shape descriptions and therefore is not suitable for our study.
Our approach is to integrate shape descriptors with spa-tial relations between the visual primitives that compose the symbol. In what follows, an outline of the proposed method will be explained. 1.2 Outline of the proposed method Global signal-based descriptors can only be applied to iso-lated patterns. Bag-of-words approaches are widely used to overcome this problem, but require extensive training sets on the one hand, and do not take into account the global structure or arrangements between the extracted visual words. Further-more, they usually lose the human-intuitive visual semantics of the symbol. In cases where not many training samples are available, or too costly to obtain; where the symbols X  visual data itself are very redundant and overlapping, and where it is important that the symbol description matches a human sense of semantics, bag-of-words approaches are ill-suited. In previous work, we addressed some of these issues [ 44 ] and studied the possibility of having human semantics cen-tred approaches [ 41 ].

We assume that there is no extensive training set available (in our experimental setup, we use a catalogue of known symbols for aircraft electric wiring diagrams [ 53 ], for which only one single instance for each symbol class is available) but that there is enough human expertise available to pro-vide knowledge of what is considered discriminant between the various symbols. Therefore, the main idea behind the approach developed in this paper is to use a set of well defined, robust, high level visual part extractors, segment-ing shapes into these discriminant elementary parts, we will refer to as visual vocabulary . The driving motivation behind this is that a library of well mastered, robust and generic extraction tools can replace statistical bag-of-words learning techniques when insufficient learning data are available, or as we shall show in Sect. 2.2 , if the generic tools are not discriminant enough, it can be combined with unsupervised clustering techniques, to improve their discriminative power.
Once the symbols are segmented into their vocabulary parts, we can use the spatial relations between them [ 44 ]to express the global spatio-structural information of the shape. However, these relations do not express shape information in the same way shape descriptors do. The spatial relation descriptors express global pixel distributions between iden-tified areas. The areas themselves are the result of the previ-ously mentioned vocabulary extractors.

Figure 1 depicts how our system operates. First visual primitives are extracted from a symbol. On the one hand, they give structural information of the elementary shapes they represent. On the other hand, computing spatial rela-tions expresses how these different shapes are positioned to one another within the symbol. The shapes are taken as nodes and the relations as arcs in an attributed relational graph rep-resenting the symbol. The recognition process relies on graph matching (which in this case is fairly trivial, as explained in Sect. 2 , since all graph nodes are uniquely labelled and all instances of one specific vocabulary type are merged into one single node).

Unfortunately, our first experiments showed limitations when the vocabulary extraction operators were too broadly defined. The core of this paper is therefore to address this problem by introducing unsupervised clustering on the broad visual vocabulary classes, in order to refine them into more visually discriminant subclasses. This is made possible by the fact that, once segmented from their initial images, they form a sufficient number of training samples.

The remaining of the paper is organised as follows. We start by explaining our symbol description in Sect. 2 , and more specifically, how spatial relation distributions are used as arc attributes between two vertices in our ARG frame-work. We then discuss unsupervised vocabulary clustering via shape analysis, allowing us to subdivide nodes into discriminant sub-shapes. In Sect. 3 , our symbol recogni-tion process is explained. Full experiments are reported in Sect. 4 and provides details of our unsupervised clustering and its validation by using several different cluster validation indices. The paper is concluded in Sect. 5 . 2 Symbol description This section describes the general symbol description approach we use: first, we describe the visual vocabulary, how it is obtained and the resulting ARG. Second, we extend this approach by introducing a more refined analysis of the visual data segmented from the vocabulary, in order to auto-matically detect visually coherent subclasses, using unsuper-vised classification. 2.1 Graph via visual vocabulary As explained before, we are going to construct an ARG based on extracted visual components, linked together with their relative spatial distribution relations. 2.1.1 Visual vocabulary While, in the general case, the extracted vocabulary can be of any kind and from any type of features, related to what is visually pertinent in the application context under considera-tion, our current vocabulary is related to electrical symbols. It can be easily extended or modified by using different vocab-ularies and other visual cues to adapt to other domains.
We define a set of well-controlled visual primitives as a vocabulary . They are extracted with the help of classi-cal image analysis operators [ 16 , 24 , 33 ]. Our vocabulary set consists of circles , corners , loose end extremities and thick (filled) components. Figure 2 shows a few examples. 1. Circle primitive 2. Corner primitive 3. Extremity primitive 4. Thick primitive On the whole, our current implementation is based on [ 16 , 33 ] that uses a straightforward histogram high-pass filter, following the line thickness in the document image.
In what follows, we shall refer to the set of vocabulary types as, 2.1.2 Graph-based representation Ratherthanusingthedetectedelementsasabasisforexpress-ing and computing spatial relations, we group them together according to their types, as shown in Fig. 2 . In a sense, a symbol is decomposed into (in our case) four layers, each of which represents either all thick components, all circles, all corners or all extremities.

The symbol can then be represented by a complete ARG as a 4-tuple G = ( V , E , F A , F E ) where  X  V is the set of vertices,  X  E  X  V  X  V is the set of graph edges,  X  F  X  F Previously mentioned approaches address only either topo-logical or directional relations. Managing both comes at high computational costs. Even then, no existing model fully inte-grates topology. Our approach [ 42 , 44 ] unifies both topolog-ical and directional information into one descriptor without any additional running time cost. Given two nodes, 1. it first uses their topological configuration to find a unique 2. from that reference point, a radial line is rotated over 3. a directional relational histogram is computed at each More formally, the proposed graph can be expressed as G =
Since this forms a complete graph, it is obvious that there exist r = t ( t  X  1 ) 2 edges for t attribute types. The major inten-tion of having fixed and completely labelled attributes is to avoid the NP-hardness of the matching problem [ 44 ] and also to keep coherence as vocabulary elements are semantically different. 2.1.3 Limitations and graph extension Due to shape and size variation of the thick patterns, the discriminative power of this description (and therefore, the resulting retrieval performance) is sub-optimal [ 44 ]. Taking a closer look at the extracted thick patterns from different symbols (Fig. 3 ), it is obvious that the shape and size of the thick pattern is related to category of the symbol from which it is assumed to be extracted. For instance, a thick pattern coming from a junction is different from a triangle-shaped one, such as a significant part of a diode symbol or from an arrow: , . Therefore, and in order to better distinguish these cases in the current ARG framework [(cf. Eq. ( 2 )], we integrate shape descriptors and apply the shape features to label vertices.

Representing a single complete vertex via a global signal-based descriptor does not sufficiently exploit all available information since it is a collection of similar vocabulary type instances. We therefore introduce the following approach: since the number of thick patterns can be different from one symbol to another, the vertex labelled with the thick vocabu-lary type will be split into more specialised thick sub-vertices. This is done separately for all individual thick patterns. S where K is the number of thick patterns in a symbol. For any symbol, there thus obtain { G  X  }  X  = 1 ,..., K ARGs. Figure 4 shows a description of the proposed approach.
According to our description (cf. Fig. 4 ), matching time will basically be increased in accordance with the number of thick patterns that compose the symbol. To reduce such a high time processing, we propose to use thick pattern cluster-ing. The main idea developed in the next section is to refine the notion of thick patterns, by collectively considering all components extracted from the symbol set, to compute indi-vidual shape descriptors on each of the components and to apply unsupervised clustering to generate a set of visually similar subclasses within the thick pattern class as illustrated in Fig. 4 . 2.2 Shape-based thick pattern clustering As said before, the main idea is to perform thick patterns clustering using shape descriptors so that patterns with dif-ferent global appearances will fall under different clus-ters or groups. The collected thick patterns in a cluster are assumed to be extracted from similar types of sym-bols. Since we have no a priori knowledge of the num-ber of shape variations or the number of thick patterns in a database, we are required to perform unsupervised clustering. 2.2.1 Our clustering framework We basically follow two steps [ 20 , 34 ] as explained below: Step 1. Find the similarity or dissimilarity between every
Ways to choose and experimental validation of what com-bination of descriptor and metric give the best results are developed further in this paper.
 Step 2. Group the similar thick patterns in the form of a hier-
Applied to our specific context, we consider the similarity matrix from all thick patterns. An agglomerative hierarchical clustering scheme consists in erasing rows and columns in this similarity matrix each time clusters are grouped together. While grouping, similarity is based on the chosen metric and linkage method. At every merge, we update the similarity matrix by deleting the rows and columns and replacing the merged distance values by the above linkage value. We repeat the process until all clusters are merged or it reaches a pre-set cluster-threshold.Figure 5 shows an example of a den-drogram using agglomerative hierarchical clustering. In this illustration, the clustering process ends up with a single clus-ter. The similarity between pairs is simply taken from one of the above linkage distance computations. For instance, clus-ters c 1 and c 2 are merged at a distance of 1 . 5. This is also called the dendrogrammatic distance .

Untilnow,wehavesimplifiedthewholeclusteringprocess in two steps. However, there remain two unanswered ques-tions. 1. Testing all possible combinations between both descrip-2. What is the optimal number of clusters, or how and where
Choices and experiments related to both cluster construc-tion and validation will be developed in the next sections. 2.2.2 Cluster verification Cluster analysis is highly sensitive to 1. shape descriptors, 2. distance metric selection and 3. linkage measure.

Approaches that use a different combination of distance metric and linkage method may yield different results (the choice of shape descriptors will be handled later). Further-more, since the optimal combination depends on what shape signatures and data are being considered we need a dynamic approach to determine that optimum. Therefore, we are going to use the cophenetic correlation coefficient [ 9 , 35 , 46 ]for every combination and choose the best one before cluster validation.

In hierarchical clustering, the height of the link represents the distance between two clusters. This height is known as cophenetic distance.

Consider the original data S = { s i } having been clustered to produce a dendrogram Z .Let  X   X  be the average value of all distance measures  X ( s i , s j ) between the data samples and  X  z be the average of the Z i , j , then the cophenetic correlation coefficient can be expressed as [ 9 ] where Z i , j is the dendrogrammatic distance between the model points from the linkage function. The dendrogram-matic distance is the height of the node at which these two points are first joined together. Figure 5 gives an example.
The cophenetic correlation coefficient expresses a com-bined measure between these two different sets of values: One is from distance metric and another is from linkage function. Therefore, if the clustering is valid, the linking of patterns in a cluster tree should have a strong correlation with the distance between the clusters themselves. That is, the cophenetic correlation coefficient closer to 1 is the one corresponding to the most accurately clustered patterns. To illustrate the idea, we take a set of arbitrary features to see how the cluster verification works and how we obtain the best combination of a distance metric and a linkage method. Fig-ure 6 provides an example. We have provided the cophenetic correlation coefficient for all possible pairs of combinations. In this example, the combination of Euclidean distance met-ric and the average-linkage clustering method is found to be the best compared to others because the cophenetic correla-tion coefficient closer to 1. This means that we do not need to use remaining pairs for cluster validation. In Fig. 6 , the num-ber of combinations can be increased by using some more distance metrics. This illustration is only intended to be a general overview of how this concept works. 2.2.3 Cluster validation In this part, we will be focussing on determining the correct number of clusters. The number of clusters has an influence on the overall aimed recognition performance. For example,  X  if too many clusters are defined, they will be small in  X  if fewer clusters are defined, they will automatically be
The evaluation measures that are applied to judge vari-ous aspects of cluster validity are traditionally classified into supervised and unsupervised approaches. In our case, since we do not have external input to fix the number of clusters, we use unsupervised techniques. Unsupervised measures of cluster validity are often based on internal indices: cluster cohesion and separation. 1. Cluster cohesion refers to compactness or tightness of the 2. Cluster separation refers to isolation of the clusters and
Within the framework, the indices we are going to use to validate clusters are as follows: 1. Dunn index (DU) [ 17 ] 2. Davies X  X ouldin index (DB) [ 14 ] 3. Silhouette index (SI) [ 36 ] 4. Score function (SF) [ 39 ]
To attest the cluster validation indices, we take the exam-ple from Fig. 6 and try to deduce the best number of clusters. In Fig. 7 we can see that every cluster validation index con-verges at two clusters. 3 Symbol recognition 3.1 Graph matching principle The recognition framework principally follows the cor-responding relation alignment (presented in Santosh et al. [ 44 , 45 ]) for matching two graphs: G 1 and G 2, where G ( V , E , F Dist. ( G 1 , G 2 ) = where  X   X (, ) computes the distance between two spatial relation  X  F 1 (resp. F 2) is the function computing the spatial rela- X   X  : E 1  X  E 2 is the correspondence function mapping
Furthermore, as described in Sect. 2 , a symbol S has K number of thick s and we have a set of { G  X  } K  X  = 1 ARGs rep-resenting it. Note that K varies from one symbol to another. Now, we can represent a query symbol S q ={ G q  X  } K  X  = a database symbol S db ={ G db  X  } K  X  = 1 . To compute the simi-larity between the two symbols, the main idea is to find the best matched graphs pair. This means that we compute the distances between all possible pairs of graphs. That is, any database graph G db  X  that is matched with any query graph G is sufficient to find similarity between the symbols: S q
Let us take any pair of symbols S  X  and S  X  to formally compute the minimum distance between them, ( S  X  , S  X  ) = min
Figure 8 shows threepossiblecases torealisegraphmatch-ing between them, without considering thick pattern cluster-ing. Considering whole database symbols { S db } db = 1 ,..., DB the closest candidate for any query symbol S q , can be com-puted as, min db (( S q , S db )) . Note that, we are not just looking for the closest candidate, but also retrieving data-base symbols for any provided short-list. In the following part, we explain about how retrieval can be handled. 3.2 An inclusion of thick pattern clustering in graph The aforementioned mentioned matching concept suffers from heavy computation as soon as the number of thick increases. To recover this, we are going to use thick pattern clustering, as mentioned before.

Step 1. For each query symbol, the first step is to allocate
Step 2. Once the cluster(s) is(are) selected, then the sym-As a consequence, for matching, we have not taken 1. all database symbols; and 2. all graphs related to a particular database symbol. This means that a limited number of database symbols are used,i.e., { S db } db = 1 ,..., DB ,where DB  X  DB .Inaddition,for each particular database symbol S db , the number of graph matchings can be reduced to  X  K  X  K . Clustering thus, helps to reduce running time. 3.3 Retrieval and ranking The previously defined distance (, ) provides an idea of how similar/dissimilar a database symbol is, with respect to a query. In order for this similarity measure to fall into an appropriate range, we normalise (, ) to [ 0 , 1 ] by taking all filtered database symbols DB , (, ) = Now the matching score, m . score ( S q , S db ) = 1  X  ( S q , S db ) . For any provided short-list, ranking can be made based on the decreasing order of matching score. 4 Experiments In order to measure the impact of the vocabulary clustering compared to using relations only [ 44 ], we have used the same dataset and experimental protocol.

We use well-known state-of-the-art of shape descriptors used for thick pattern (vocabulary) clustering: 1. Zernike moments (ZM) [ 23 ], 2. R -signature [ 47 ], 3. SC [ 4 ], 4. Generic fourier descriptors (GFD) [ 60 ] and 5. DTW-Radon (lets say D -Radon) [ 43 ]. 4.1 Dataset, ground-truth and evaluation metric 4.1.1 Dataset Figure 11 gives an overview of the dataset we are using for our experiments. The global dataset is composed of roughly 500 different symbols, taken from electrical wiring diagrams [ 53 ]. It contains symbols that are either very similar in shape X  X nd only differ by slight details X  X r, on the other hand, are completely different from a visual point of view. Symbols may also be composed of other known and significant symbols and need not necessary be connected. 4.1.2 Ground-truth and evaluation metric Since there is no absolute ground-truth associated with our dataset, we have asked 6 volunteers to manually select what they consider as  X  X imilar X  symbols, and we have merged their inputs to reduce possible subjective bias. They have chosen the candidates which have similar visual overall appearance or contain significantly similar parts with respect to the cho-sen query. In our testing protocol, we consider that a result returned from an algorithm is correct if at least one evaluator has selected the same result among similar items. In more for-mal terms, for each query, the  X  X round-truth X  is considered to be the set of symbols formed by the union of all human-selected sets. In Fig. 11 , we have provided a few samples of query symbols and the corresponding lists of relevant sym-bols.

For every query, we rank the symbols at the output based on the distance measure described in Sect. 3 . Since the num-ber of similar symbols, according to the ground-truth, may vary a lot from one query to another, we use retrieval effi-ciency [ 21 ] as a measure for retrieval quality. For a chosen query and for a fixed number of K returned symbols, it can be expressed as,  X  where n is the number of returned relevant symbols and N the total number of relevant symbols in the dataset. Note that  X  K computes the traditional recall if N  X  K and computes precision otherwise. The main advantage of this is that the average retrieval efficiency curve is not biased even with different quantities of ground-truth for different queries, which happens when using the precision metric with N &lt; K . 4.2 Thick pattern clustering The goal of this section is to illustrate how choices of descrip-tors and cluster validation indices can have an influence on the obtained clusters. The way of actually selecting the best clustering parameters will be discussed in Sect. 4.3 .Weare considering the application of various shape signatures on thick patterns. Since discrimination power of shape descrip-tors vary from one to another, the number of clusters will obviously be different. Furthermore, a change in cluster vali-dation indices also impacts the results, as we shall show here. We are going to test different shape descriptors and perform various clustering and cluster validation indices on each of them in Sect. 4.3 . The following section uses GFD [ 60 ]as an example. 4.2.1 Clustering using GFD We have sampled the GFD parameters from 4 to 12 for the radial and from 6 to 20 for angular frequencies. For each of these values, we have computed the Dunn and DB clustering indices. Figure 12 shows the effect of these changes on the number of clusters obtained. For example, we get 33 clusters from Dunn and 30 clusters from DB when we take radial and angular frequencies values of (6, 16). For more clarity, each value in Fig. 12 (i.e., number of clusters in red box, for instance), we have provided a complete illustration in Fig. 13 about how cluster validation indices select different number of clusters. The observation is that depending on the chosen parameters (i.e., GFD parameters) and criteria (i.e., validation indices), the final number of clusters can vary widely.
Using this framework, and for visual illustration, Fig. 14 shows a few clusters and their corresponding patterns from the DB cluster validation index. 4.2.2 Clustering using other shape descriptors For the remaining shape descriptors, mentioned before, like SC, Zernike moments, R -signature, D -Radon, a similar clus-ter validation process has been carried out. In Sect. 4.3 ,the effect of the use of all shape descriptors on retrieval per-formance will be presented. This goes with the appropriate choice of cluster validation index. 4.3 Results and analysis 4.3.1 Related previous work Since the approach is the extension of a previous work, we admit some of the points and conclusions described in San-tosh et al. [ 44 ] and get directly to the point for comparisons with the existing state-of-the-art. For clarity, we recall some of the experimental setup choices, such as the use of retrieval efficiency, as described in Sect. 4.1 , which has been system-atically computed for values of K = 1 to 10, over 30 queries, for all experiments described in this section. 1. In the previous approach, called RLM [ 44 ], we have stud-2. Similarly, a series of experiments reported in Santosh 3. Furthermore,wehavealsocomparedRLMtopixel-based
Figure 15 gives an overview of the observed performance differences between all tested methods. 4.3.2 Integrating vocabulary clustering with spatial Following the reported results in Fig. 15 , in this section, we aim to see how the integration of thick pattern selection (with spatial relations) improves the retrieval performance. Our query thick pattern selection is based on clustering men-tioned in Sect. 2.2 . Clustering performance is based on shape signatures and cluster validation indices. Therefore, we take both into account in order to assess a suitable combination for this application.

Figure 16 shows the comparison of performance of clus-ter validation indices for different shape descriptors. In the tests, we observe and analyse retrieval performances on a one-to-one basis. Overall, GFD outperforms all, but D -Radon performs almost equally having a marginal difference. Zernike moments, shape context and R -signature are lagging behind.

Selection of shape descriptors does not only provide a complete process, while it needs to account cluster vali-dation indices, on the other hand. As said previously, dif-ferent cluster validation indices provide different results. As a consequence, overall retrieval performance is affected. As shown in Fig. 16 , for all shape descriptions, Dunn and DB indices provide almost similar advancements, while the remaining silhouette and sore-function do not. Therefore, either Dunn or DB index will be the appropriate choice for this application. For a quick visual illustration, as an example to describe the shape of thick , the first seven ranked database symbols retrieved are as follows, A few more queries are illustrated in Fig. 17 where D -Radon is used to describe the shape of the thick for clustering and DB index is used to validate the cluster. In this illustra-tion, the first symbol on the top always corresponds to the query symbol and retrieved symbols are ranked from top to bottom based on the order of similarity. These retrieval exam-ples provide an idea of how far the retrieval performance after integrating vocabulary clustering has been advanced. After integrating vocabulary clustering, we have found that retrieval symbols are visually better ranked in addition to its efficacy.

Along with relational signature matching, query thick pat-tern selection via clustering advances retrieval performance. However, no surprising difference is observed. The major reason is that not all query symbols contain thick pattern in their vocabulary type sets. In other words, absence of thick vocabulary type means ranking has been made only through relation alignment, with eventually no change in retrieval performance. 5 Conclusions In this paper, we have presented the concept to describe the shape of the extracted visual vocabulary that shows sig-nificant shape variations and integrate relations that exist between them. Keeping the ARG framework, our intelligent concept of using shape descriptor via clustering provides an immediate retrieval applications. We have comprehensively studied unsupervised clustering and evaluated with several different well-known validation indices. In our tests, we have observed the behaviour of the well-known state-of-the-art shape descriptors.

Very specifically, we have employed thick pattern cluster-ing and use the related clusters with respect to the query for relation alignment. Clustering of thick patterns thus opens a global concept that it can be applied for any other visual primitives. Overall, we bring an attention to the use of a hybridapproachinsymbolrecognitionsinceitcombinesboth worlds: structural and statistical.
 References
