 While of significant interest in linguistics and phi-losophy, humor had received less attention in the computational domain. And of that work, most re-cent is predominately focused on humor recognition. See (Ritchie, 2001) for a good review. In this pa-per we focus on the problem of humor generation. While humor/sarcasm recognition merits direct ap-plication to the areas such as information retrieval (Friedland and Allan, 2008), sentiment classifica-tion (Mihalcea and Strapparava, 2006), and human-computer interaction (Nijholt et al., 2003), the ap-plication of humor generation is not any less sig-nificant. First, a good generative model of humor has the potential to outperform current discrimina-tive models for humor recognition. Thus, ability to generate humor will potentially lead to better humor detection. Second, a computational model that con-forms to the verbal theory of humor is an accessi-ble avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theory of Humor (SSTH) (Attardo and Raskin, 1991) -a widely accepted theory of verbal humor and build a generative model that conforms to it.

Much of the existing work in humor generation had focused on puns and punning riddles -hu-mor that is centered around wordplay. And while more recent of such implementations (Hempelmann et al., 2006) take a knowledge-based approach that is rooted in the linguistic theory (SSTH), the con-straint, nevertheless, significantly limits the poten-tial of SSTH. To our knowledge, our work is the first attempt to instantiate the theory at the fundamental level, without imposing constraints on phonological similarity, or a restricted set of domain oppositions. 1.1 Semantic Script Theory of Humor The Semantic Script Theory of Humor (SSTH) pro-vides machinery to formalize the structure of most types of verbal humor (Ruch et al., 1993). SSTH posits an existence of two underlying scripts, one of which is more obvious than the other. To be humor-ous, the underlying scripts must satisfy two condi-tions: overlap and incongruity. In the setup phase of the joke, instances of the two scripts are presented in a way that does not give away the less obvious script (due to their overlap). In the punchline (res-olution), a trigger expression forces the audience to switch their interpretation to the alternate (less likely) script. The alternate script must differ sig-nificantly in meaning (be incongruent with the first script) for the switch to have a humorous effect. An example below illustrates this idea ( S 1 is the obvi-ous script, and S 2 is the alternate script. Bracketed phrases are labeled with the associated script). Of the early prototypes of pun-generators, JAPE (Binsted and Ritchie, 1994), and its successor, STANDUP (Ritchie et al., 2007), produced ques-tion/answer punning riddles from general non-humorous lexicon. While humor in the generated puns could be explained by SSTH, the SSTH model itself was not employed in the process of generation. Recent work of Hempelmann (2006) comes closer to utilizing SSTH. While still focused on generating puns, they do so by explicitly defining and applying script opposition (SO) using ontological semantics. Of the more successful pun generators are systems that exploit lexical resources. HAHAcronym (Stock and Strapparava, 2002), a system for generating hu-morous acronyms, for example, utilizes WordNet-Domains to select phonologically similar concepts from semantically disparate domains. While the de-gree of humor sophistication from the above systems varies with the sophistication of the method (lexi-cal resources, surface realizers), they all, without ex-ception, rely on phonological constraints to produce script opposition, whereas a phonological constraint is just one of the many ways to generate script op-position. ConceptNet (Liu and Singh, 2004) lends itself as an ideal ontological resource for script generation. As a network that connects everyday concepts and events with a set of causal and spatial relationships, the re-lational structure of ConceptNet parallels the struc-ture of the fabula model of story generation -namely the General Transition Network (GTN) (Swartjes and Theune, 2006). As such, we hypothesize that there exist paths within the ConceptNet graph that can be represented as feasible scripts in the sur-face form. Moreover, multiple paths between two given nodes represent overlapping scripts -a nec-essary condition for verbal humor in SSTH. Given a semantic network hypergraph G = ( V, L ) where V  X  Concepts , L  X  Relations , we hypothesize that it is possible to search for script-pairs as seman-tic circuits that can be converted to a surface form of the Question/Answer format. We define a circuit as two paths from root A that terminate at a common node B . Our approach is composed of three stages -(1) we build a script model (SM) that captures likely transitions between concepts in a surface-realizable sequence, (2) The script model (SM) is then em-ployed to generate a set of feasible circuits from a user-specified root node through spreading activa-tion, producing a set of ranked scripts. (3) Ranked scripts are converted to surface form by aligning a subset of its concepts to natural language templates of the Question/Answer form. Alignment is per-formed through a scoring heuristic which greedily optimizes for incongruity of the surface form. 3.1 Script model We model a script as a first order Markov chain of relations between concepts. Given a seed concept, depth-first search is performed starting from the root concept, considering all directed paths terminating at the same node as candidates for feasible script pairs. Most of the found semantic circuits, however, do not yield a meaningful surface form and need to be pruned. Feasible circuits are learned in a su-pervised way, where binary labels assign each can-didate circuit one of the two classes { feasible, infeasible } (we used 8 seed concepts, with 300 generated circuits for each concept). Learned tran-sition probabilities are capable of capturing primi-tive stories with events, consequences, as well as appropriate qualifiers of certainty, time, size, loca-tion. Given a chain of concepts S (from hereon re-ferred to as a script) c 1 ,c 2 ...c n , we obtain its likeli-hood Pr ( S ) = Q Pr ( r ij | r jk ) , where r ij and r jk directed relations joining concepts &lt; c i , c j &gt; , and &lt; c j , c k &gt; respectively, and the conditionals are computed from the maximum likelihood estimate of the training data. 3.2 Semantic overlap and spreading activation While the script model is able to capture seman-tically meaningful transitions in a single script, it does not capture inter-script measures such as over-lap and incongruity. We employ a modified form of spreading activation with fan-out and path con-straints to find semantic circuits while maximizing their semantic overlap. Activation starts at the user-specified root concept and radiates along outgoing edges. Edge pairs are weighted with their respective transition probabilities Pr ( r ij | r jk ) and a decay fac-tor  X  &lt; 1 to penalize for long scripts. An additional fan-out constraint penalizes nodes with a large num-ber of outgoing edges (concepts that are too gen-eral to be interesting). The weight of a current node w ( c i ) is given by: w ( c i ) = X Termination condition is satisfied when the activa-tion weights fall below a threshold (loop checking is performed to prevent feedback). Upon termina-tion, nodes are ranked by their activation weight, and for each node above a specified rank, a set of paths (scripts) S k  X  X  is scored according to:. where  X  k is decay-weighted log-likelihood of script S k in a given circuit and | S k | is the length of script S k (number of nodes in the k th chain). A set of scripts S with the highest scores in the highest rank-ing circuits represent scripts that are likely to be fea-sible and display a significant amount of semantic overlap within the circuit. 3.3 Incongruity and surface realization The task is to select a script pair { S i ,S j i 6 = j }  X  S  X S and a set of concepts C  X  S i  X  S j that will align with some surface template, while maximiz-ing inter-script incongruity. As a measure of con-cept incongruity, we hierarchically cluster the entire ConceptNet using a Fast Community Detection al-gorithm (Clauset et al., 2004). We observe that clus-ters are generated for related concepts, such as reli-gion, marriage, computers . Each template presents up to two concepts { c 1  X  S i ,c 2  X  S j i 6 = j } in the question sentence ( Q in Figure 2), and one concept c 3  X  S i  X  S j in the answer sentence ( A in Figure 2). The motivation of this approach is that the two concepts in the question are selected from two dif-ferent scripts but from the same cluster, while the an-swer concept is selected from one of the two scripts and from a different cluster. The effect the generated two-liner produces is that of a setup and resolution (punchline), where the question intentionally sets up two parallel and compatible scripts, and the answer triggers the script switch. Below are the top-ranking two-liners as rated by a group of fifteen subjects (testing details in the next section). Each concept is indicated in brackets and labeled with the script from which the concept had originated: We evaluate the generated two-liners by presenting them as human-generated to remove possible bias. Fifteen subjects ( N = 15 , 12 male, 3 female -grad-uate students in Mechanical Engineering and Com-puter Science departments) were presented 48 high-est ranking two-liners, and were asked to rate each joke on the scale of 1 to 4 according to four cat-egories: hilarious (4), humorous (3), not humor-ous (2), nonsense(1) . Each two-liner was generated from one of the three root categories (12 two-liners in each): priest, woman, computer, robot , and to normalize against individual humor biases, human-made two-liners were mixed in in the same cate-gories. Two-liners generated by three different al-gorithms were evaluated by each subject: Script model + Concept clustering (SM+CC) Script model only (SM) No concept clustering is Baseline Loops are generated from a user-specified
We compare the average scores between the two-liners generated using both the script model and con-cept clustering (SM+CC) ( MEAN =1.95, STD =0.27) and the baseline ( MEAN =1.06, STD =0.58). We observe that SM+CC algorithm yields significantly higher-scoring two-liners (one-sided t-test) with 95% confidence.
We observe that the fraction of non-humorous and nonsensical two-liners generated is still significant. Many non-humorous (but semantically sound) two-liners were formed due to erroneous labels on the concept clusters. While clustering provides a fun-damental way to generate incongruity, noise in the ConceptNet often leads of cluster overfitting, and as-signs related concepts into separate clusters.
Nonsensical two-liners are primarily due to the in-consistencies in POS with relation types within the ConceptNet. Because our surface form templates assume a part of speech, or a phrase type from the ConceptNet specification, erroneous entries produce nonsensical results. We partially address the prob-lem by pruning low-scoring concepts (ConceptNet features a SCORE attribute reflecting the number of user votes for the concept), and all terminal nodes from consideration (nodes that are not expanded by users often indicate weak relationships). Through observation of the generated semantic paths, we note that more complex narratives, beyond questions/answer forms can be produced from the ConceptNet. Relaxing the rigid template constraint of the surface realizer will allow for more diverse types of generated humor. To mitigate the fragility of concept clustering, we are augmenting the Con-ceptNet with additional resources that provide do-main knowledge. Resources such as SenticNet (WordNet-Affect aligned with ConceptNet) (Cam-bria et al., 2010b), and WordNet-Domains (Kolte and Bhirud, 2008) are both viable avenues for robust concept clustering and incongruity generation. Acknowledgement This paper is for my Babishan -the most important person in my life.
 Huge thanks to Max Kelner -those everyday teas at Mattins and continuous inspiration.
 This work was supported in part by NSF CDI Grant ECCS 0941561. The content of this paper is solely the responsibility of the authors and does not neces-sarily represent the official views of the sponsoring organizations.

