 Previous studies on search engine click modeling have iden-tified two presentation factors that affect users X  behavior: (1) position bias: the same result will get a different num-ber of clicks when displayed in different positions and (2) externalities: the same result might get more clicks when displayed with results of relatively lower quality than whe n shown with higher quality results. In this paper we focus on analyzing the sequence of user actions to model users X  click behavior on sponsored listings shown on the search results page. We first show that temporal click sequences are good indicators of externalities in the advertising domain. We then describe the positional rationality hypothesis to explain both the position bias and the externalities, and based on this hypothesis we further propose the temporal click model ( TCM ), a Bayesian framework that is scalable and compu-tationally efficient. To the best of our knowledge, this is the first attempt in the literature to estimate positional bias, ex-ternalities and unbiased user-perceived ad quality from user click logs in a combined model. We finally evaluate the pro-posed model on two real datasets, each containing over 100 million ad impressions obtained from a commercial search engine. The experimental results show that TCM outper-forms two other competitive methods at click prediction. H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; I.2.6 [ Artificial Intelligence ]: Learning; G.3 [ Probability and Statistics ] Algorithms, Experimentation Sponsored search, advertising, externalities, Bayesian m odel, click log analysis, click-through rate
This work was done when the first author was on a summer internship with Yahoo! Labs.

Commercial web search engines typically generate revenue by presenting sponsored results as well as organic web resul ts to satisfy a user query. The most commonly employed pay-ment model is  X  X ay-per-click X , where an advertiser pays the search engine when a user clicks on their ad [4]. The cost of a click depends on the quality and bid of competing ads, and is usually determined by a second price auction [10]. Spon-sored search enables the advertisers (1) to target their cam -paigns to very specific markets by bidding only on the search terms interesting to them, (2) to explore different markets with minimal risk (there is no cost unless there is a click), and (3) to iterate and improve quickly their campaigns by using immediate feedback from performance. The combi-nation of these features makes sponsored search one of the most attractive and profitable advertising approaches [11] .
The objective of the search engine in the sponsored search model is to maximize its revenue over the long term [2]. This involves a delicate balance of possibly conflicting objecti ves: (1) maximize the revenue per search (RPS), (2) minimize the negative impact of ads on the user experience, and (3) maximize the return on investment for advertisers. Esti-mating the probability that users click on ads displayed in response to their queries is essential to sponsored search, because accurate predictions are necessary to address the objectives above. In particular, the click probability is a factor in ranking, placement, filtering, and pricing of ads.
Several studies have been published recently analyzing user click behavior in organic web search [1, 15, 16, 5, 9, 6, 13] and in sponsored search advertising [17, 19, 20]. Joachi ms et al. [15, 16] conducted an eye-tracking experiment to un-derstand the decision making process of users when browsing search engine results. An important finding of this study, now well known as position bias , is that users tend to click less on documents that are shown in lower positions, even when the results were presented in reverse order. To ex-plain the position bias phenomenon, Richardson et al. [19] proposed the examination hypothesis , which assumes that a result must be examined before being clicked, and the prob-ability of being clicked after being examined depends on its user-perceived quality. Craswell et al. [7] later proposed the cascade hypothesis , which assumes that users always ex-amine results in order from top to bottom. Under this as-sumption, results displayed at the top are more likely to be examined than results shown at the bottom, regardless of their quality. The cascade model proposed in [7] makes another strong assumption: the user session ends after the first click on a result. This assumption clearly fails to ex-plain sessions with multiple clicks. Most of the subsequent research on click modeling for search results have focused on relaxing this assumption. The Click Chain Model [13] and the Bayesian Browsing Model (BBM) [18] both allow the user session to continue with a probability that is de-pendent on the relevance of the clicked ad. The dynamic Bayesian network model proposed by Chapelle and Zhang [6] also lets the user session continue after a click, but in t heir model the probability of continuing the session depends on the quality of the landing page. Their model is the first to separate the perceived relevance of the ads from the actual quality of the landing page.

The click models discussed so far do not account for the attractiveness or relevance of the results below when consi d-ering the probability of click on a particular ad. In Guo X  X  [13] and Chapelle X  X  [6] models, the probability of click for the results might be affected by the results shown immediately above them, since the examination probability depends on the previous result X  X  (or landing page X  X ) quality. However , the click probabilities cannot be influenced by the results presented below. This can be a significant limitation, es-pecially in sponsored search, where the advertisers compet e and pay for the user X  X  attention. In advertising, the effect o f the set of ads on the user behavior is widely accepted and referred to as externalities . Ghosh et al. [12] proposed the rationality hypothesis to explain this behavior. Under the ir hypothesis users are assumed to be rational. Given a set of ads displayed, a user first compares the qualities of the ads and clicks on the best one. Kempe and Mahdian [17] later proposed a variation of the cascade model based on this hypothesis. Instead of using the top to bottom order of scanning the ads, their model allows each user to have a different ordering over the positions. Unfortunately both o f these models were used only in the context of analyzing the auction mechanisms, therefore there are no results on the accuracy of the click models proposed, or even analysis to show that the externalities exist in the data.

In this paper, our objective is to first show that exter-nalities are indeed present in the sponsored search domain and then investigate how to explain both position bias and externalities in a combined model. We exploit the tempo-ral order of user X  X  actions for this analysis. Our contribu-tions can be summarized in three points. First, we present a statistical analysis demonstrating that temporal user cl ick sequences are good indicators of ad externalities. Second, we propose the positional rationality hypothesis which ex-plains both position bias and externalities. Third, based o n this hypothesis we develop the temporal click model ( TCM ), which has the properties: (1) Foundation: To the best of our knowledge, this is the first attempt in the literature to estimate positional bias, externalities and unbiased user-perceived ad quality from user click logs in a combined model; (2) Framework: TCM is based on a strict Bayesian frame-work. Closed-form representations of the ad quality and use r behavior posteriors can be derived using this framework, making it scalable and computationally efficient to handle the challenges imposed by the voluminous click logs; (3) Effectiveness: TCM consistently outperforms two state-of-the art models in a number of metrics at click prediction.
In the online advertising literature [12], externalities a re often considered a primary factor influencing user click be-havior. In this section we present a click log analysis indi-cating this effect exists in real data sets.

Our goal is to analyze how the click behavior of users on a particular ad changes depending on the quality of the rest of the ads. We focus on ad impression sequences with exactly two ads. Showing that externalities exist for ad set s with only two ads proves the existence of externalities for longer sequences as well. We collected two real data sets in March 2009 from a commercial search engine. One of the data sets consists of queries that have exactly two ads shown on top (north) of the organic web search results, and the other contains ad impressions that were shown at the bottom (south). We will refer to these data set as N orth A d D ata( NAD ) and S outh A d D ata( SAD ), respectively.
Since there is no ground truth for ad quality, we use em-pirical click-through rates (CTR) as a proxy. For each ad impression sequence we calculate the CTR of the ad in Posi-tion 1 and Position 2 separately, and compare the CTRs at these two positions using the following approach: We group all impressions with similar CTRs at Position 1 in one bin and plot the average CTR at Position 2. This way we can use the CTRs at Position 1 as quality measure (since each bin contains ads with similar CTRs) and the average CTR at Position 2 as the click metric. Results are shown in the top row of Fig. 1. We see that as the quality in one position increases (x-axis) from 0 to about 0.2, CTR of the other po-sition (y-axis) also increases. However, when the quality o f one position keeps increasing further, the CTR of the other position starts dropping. This observation suggests that t he high quality ads (CTR &gt; 0.2 in these graphs) could affect the click rates of the other ads adversely. Note that the graphs for SAD dataset doesn X  X  show the decrease, but that the absolute value of the max CTRs in these positions are much lower than the ones in North. Still, we see that around 0.1 the curve starts to saturate.

We also examine if the quality of ads in one position in-fluences which ads user clicks first. For this, we group all impressions with similar CTR at Position 1 in one bin and plot the percentage of events where the first click occurred at Position 2 and vice versa. Results are shown in the bot-tom row of Fig. 1. We observe that when CTR in Position 1 increases users prefer to click first on Position 1. This ob-servation verifies that users are rational: they compare the qualities of both ads and choose the better one to click first. Hence, the temporal click sequences of users can be used to learn ad externalities.

Analyzing the first click graphs in more detail shows that users aren X  X  completely rational, and that they are biased by the position of the ads. For example, in the left bottom two plots of Fig. 1, when CTR at Position 1 is 0.2, the per-centage of first click at Position 2 is around 0.2 too. In other words, the probability of clicking Position 1 first is around 0.8. But, when CTR at Position 2 is 0.2, the probability of clicking Position 2 first is around 0.6. The reason for this behavior could be that users may be trusting the ranking of the search engine more if they don X  X  think the ad at Position 2 is much better than the one at Position 1 and don X  X  use their ranking to take over the ranking of search engine.
Based on the above observations, we propose the posi-tional rationality hypothesis: Users examine both ads to-gether and assess their qualities, and then users compare their qualities. If the ad at Position 2 is much better than ad at Position 1, users would consider clicking the ad at Position 2 first instead of the ad at Position 1.
We first introduce definitions and notations, and next specify and discuss the temporal click model.

A user starts a query session by submitting a query to the search engine. The search engine retrieves the ads that match the user query and finds the ranking that optimizes the objective function and presents them to the user in differ -ent slots on the results page, alongside organic web results . The set of ads presented to the user can be represented as an ad impression sequence A = &lt;a 1 ...a D &gt; , where a ad presented in position i and D is the total number of slots. An ad a i in this sequence is shown at a higher position (i.e. ranked higher) than ad a j if i &lt; j . The clicked ads can be represented as a sequence as well, a sequence of click events ordered by their time of click: C = &lt;c 1 ...c T &gt; , where T  X  D and c i corresponds to the ad in position i . We call this sequence the temporal click sequence.

To study the impact of ad externalities, we focus on ad im-pression sequences with two ads only. For an ad impression sequence A = &lt;a 1 a 2 &gt; , there are five possible click sequences: &lt;&gt; , &lt;a 1 &gt; , &lt;a 1 a 2 &gt; , &lt;a 2 &gt; and &lt;a on the same ad in the same position are discarded in this model. To simplify notation and have sequences of equal lengths, we will use the symbol 2 to indicate a no-ad-clicked action. We can then rewrite the five possible click sequences as: &lt; 22 &gt; , &lt;a 1 2 &gt; , &lt;a 1 a 2 &gt; , &lt;a refer to these sequences as click sequences type 1..5.
The temporal click model can be described as a generative process as illustrated in Fig. 2(Left). User submits a query and sees an ad impression sequence A = &lt;a 1 a 2 &gt; . She can either examine or ignore the ads . We treat this user behav-ior as a probabilistic event, represented by a binary random variable E . The probability of examining ads, denoted as P ( E = 1 | A ) , is set to a global model parameter  X  , i.e.,
If the user decides not to ignore the ads, she examines both of them as the position rationality hypothesis states, and picks one. We denote the perceived quality of ads a 1 and a 2 by R a 1 and R a 2 , respectively, where R a i  X  [0 .. 1] . Our model says that the quality of a 2 has to be greater than that of a 1  X  X  by a margin of U a 1 for the user to ignore the search engine X  X  ranking and pick a 2 . Otherwise she picks a 1 . U can be viewed as the advantage of being ranked in position 1 . We treat this user behavior as a probabilistic event, too. Let F be the random variable to represent the first ad the user picks, then the probability of picking a 1 or a 2 would be: where 1I is the indicator function.

Once the user picks an ad a i , whether she clicks it or not depends solely on its quality, R a i . Thus, the probability of being the first clicked ad c 1 or not having a click at all is:
If the user does not click on the ad she picked our session model terminates. If, however, she clicks on that ad she can re-consider the ad that was skipped. Our model assumes that the probability of re-considering the other ad depends on the difference of the perceived qualities of the two ads. The higher the relative perceived quality of the clicked ad, the smaller the probability of re-considering the skipped a d. In TCM , we model this probability as a linear function of the difference in qualities with a scale factor  X  and a bias term  X  . We let S be the random variable representing the skipped ad, and derive the following probabilities:
Again, once the user decides that she will consider the variable of Ad a 1 ; and observed click sequence &lt; c 1 skipped ad a j , whether she clicks or not depends on its per-ceived quality only. Thus the probability of having a second click c 2 on a j or not having a second click at all has the form:
Since we ignore multiple clicks on the same ad at the same position our session model ends after this step. However, we still need to specify the probabilities for the case where th e user ignores the ads in the first step. If the user ignores both of the ads, she considers neither, and if she doesn X  X  conside r either one of the ads, she clicks none:
We complete the specifications of our Bayesian framework by introducing priors on R a i s and U a i s. Although any form priors are possible, we follow [13, 18] in choosing the iid non-informative uniform priors within [0 , 1] . We show the graphical model representation of TCM in Fig. 2(Right).
To guarantee that we have a well-defined model, we have to put constraints on the parameters of the model such that the probability of any click sequence generated by this mode l is between 0 and 1. We describe these constraints in the following lemma.

Lemma 3.1. The temporal click model is well-defined if its parameters satisfy the constraints:  X  1  X   X   X  1 , 0  X   X   X  1 , 0  X   X   X  1 ,  X   X   X  and 0  X   X  +  X   X  1 .
Now that the TCM model is formally presented we illus-trate how it explains the position bias and ad externalities .
Let X  X  consider the two extreme cases of the TCM . If we set the position advantage variable U a 1 to be 1, then the quality difference R a 2  X  R a 1 can not be greater than U a 1 because 2  X  R a 1  X  1 . In this case, user never considers clicking a first, regardless of its quality. Only after a 1 is clicked could have a chance. In other words, TCM with U a 1 = 1 would roughly correspond to the cascade model described in [7].
On the other hand, If we set the user variable U a 1 to be 0, the user would always be fully rational. She would always pick the ad with better quality first, regardless of it s position, like the rationality hypothesis proposed in [12] that explains ad externalities.

In a nutshell, the position advantage variable U a 1 is a tradeoff between position bias and ad externalities, and it gives us the flexibility to learn both of them from click data by finding its posterior probability.

To generalize our model to more than two ads we can assume that each ad except for the last one, has a corre-sponding position advantage; and that an ad would only be picked first if its quality beats all the other ads. After the first ad is picked the same process can be used to select the second ad and so on and so forth.

In reality, most search engines, for example Google, Ya-hoo! and Bing, receive a large fraction of ad clicks from the ads displayed on the top of organic search results. Improv-ing the accuracy of click prediction in this premium slot wil l have a profound effect on the overall click yield and revenue. Those engines show less than five ads in the top. Therefore, we believe that the proposed model is potentially useable since it can be easily generalized and applied to the limited number of ads that can be displayed in the top. In fact, the proposal model on two ads is practicable too and it can be applied to the bottom slot of Bing and Yahoo! where at most two ads could be shown.
In this section, we propose algorithms for the TCM . We first present the closed form posterior distributions of use r-perceived ad quality and ad position advantage; then explai n how to estimate the model parameters  X  = {  X , X , X  } ; finally we show how to use them to predict the click-through rate of any given ad impression sequence.
N } and C = { C 1 ,C 2 ,...,C N } be their corresponding ad impression and click sequences respectively. We assume tha t in A there are M distinct ads indexed from 1 to M , and let R = { R 1 ,R 2 ,...,R M } be the corresponding user-perceived ad quality variable and U = { U 1 ,U 2 ,...,U M } be the position advantage variable.

We assume that the ad impression and click sequences in different sessions are independent of each other, given R and U m . We can then compute the posteriors of R m and m using the Bayes principle:
Since P ( R m ) and P ( U m ) are already known, we only need them, we have to integrate out all hidden random variables other than R m and U m . We show that P ( C n | R m ,A n ) and P ( C n | U m ,A n ) have closed forms by demonstrating integra-tion on a specific case of P ( C n | R m ,A n ) . In this particular case, the ad impression is A n = &lt;a 1 a 2 &gt; , click sequence is n = &lt;a 2 a 1 &gt; and m = a 2 . After applying the Bayes rule and uniform priors on R a 1 and U a 1 we get Eq.(13): We first integrate out hidden variables E , F and S in Eq.(13) by applying model specification. To generate the must be 1 , m , a 1 . Applying Eq.(1,2,4,7,8), we get Eq.(14).
Next, plugging Eq.(14) back into Eq.(13) and integrating out random variables R a 1 and U a 1 , gives us the closed-form only on the click sequence type and the position of Ad m in A n , independent of the other ads. There are five click sequence types (as described in 3) and two possible position s. click sequence type and i -th position. The functional form of  X  k,i (  X  ) for all k and i is listed in Table.1. Finally, the posterior of R m has the unnormalized closed form: where N m k,i is the number of sessions that the click sequence is k -th type and Ad m appears at i -th position in the ad impression sequence.
 We can get the unnormalized closed form of posterior of m , similarly. We let  X  k (  X  ) be the closed form of P ( C for k -th click sequence type and m at Position 1 of A n . P ( C n | U m ,A n ) will be a constant if m is at Position 2 of sequences of length 2. The functional form of  X  k (  X  ) is also given in Table. 1. The closed form of the posterior of U m
Because of the potential dimensionality curse introduced by large N m k,i , we follow [13] and utilize the midpoint rule to numerically normalize P ( R m | C , A ) and P ( U m | C , A ) . For example, the normalizing constant of P ( R m | C , A ) can be approximated by with B equal-size bins on [0 .. 1] .

Once normalized with an appropriate B , both density function and cumulative distribution function of posterio rs of R m and U m could be evaluated at desired precision.
We use the maximum likelihood principle to estimate the model parameters  X  = {  X , X , X  } . We want to maximize the out the R a i s and U a i s as described in the previous section. The exact derivation is omitted to save space.

By summing log likelihood of all click sequences, we get the following log-likelihood function: where N i represents the number of instances of click se-quence type i in C .

By setting the derivative of log likelihood function L (  X  ) on  X  to zero and also considering model constraints listed in Lemma 3.1, we get a closed form function to estimate  X  :
Unfortunately, there are no closed form solutions for  X  and  X  . But, it is not hard to verify that the log likelihood function L (  X  ) is concave in  X  and  X  under the parameter con-straints listed in Lemma 3.1. Therefore, we can utilize con-vex optimization techniques to find approximate solutions. In our implementation we used a barrier method combined with the Newton X  X  method [3]. Since there are only two pa-rameters to estimate, this is a simple optimization problem .
Given the model parameters and posteriors, we can use the mid-point rule to estimate the posterior probability of any click sequence. For example the probability of click sequence &lt;a 2 a 1 &gt; is: where P a 1 (  X  ) and P a 2 (  X  ) are normalized density functions of posteriors of R a 1 and R a 2 , and F a 1 (  X  ) is cumulative distri-bution of posterior of U a 1 .

Once we have the probabilities of individual click sequence s, we can compute the click through rate of any ad, CTR ( a i in an ad impression sequence A = &lt;a 1 a 2 &gt; by taking the sum of probabilities of all click sequences that include a click on that particular ad a i :
To implement the inference algorithm proposed above, we for computing posteriors of R m and U m , and { N k } k =1 .. 5 for estimating model parameters. Obviously, a sequential scan of data could provide those statistics. However, to be able to apply the TCM to petabyte-scale data requires par-allelization. In this section we describe how to leverage th e MapReduce paradigm [8] for this purpose.

MapReduce is a programming framework to parallelize Algorithm 1 Map( A , C ) -Mapping a query session Input: A : ad impressions of a query, C : click log. Output ( a, v ) : a is the ad index; v is sufficient statistics of a for one session. 1: for each ad impression sequence n = 1 ,...,N do 2: Set k be the click sequence type of C n 3: for each position i = 1 , 2 do 4: v = 0 ; 5: v [ k  X  2 + i  X  3] = 1 ; 6: Emit( a n i , v ); 7: end for 8: end for Algorithm 2 Reduce( a , vectList ) Input: a is the ad index; vectList is a list of vectors associ-ated with a .
 Output ( a, N a ) : N a is sufficient statistics of a for all ses-sions. 2: for each v in vectList do 3: N a + = v ; 4: end for 5: return ( a, N a ) ; computational tasks by expressing them as pairs of Map and Reduce functions. The implementation of MapReduce infrastructure frees programmers from the practical issue s of running algorithms over a cluster of computers, such as load -balancing, fault tolerance and data distribution problems .
Algorithm 1 and 2 are the implementation of a pair of Map ically, the Map function reads each session from input and emits a set of intermediate (key, value) pairs, where the key is the ad index and the value is this ad X  X  sufficient statis-tics of that session. The MapReduce infrastructure then groups together all values with the same intermediate key and passes them to the Reduce function. The Reduce func-tion accepts an intermediate key and a list of values for the key. It summarizes those statistics and outputs the final re-sult. The idea behind the MapReduce framework is that a large scale dataset could be broken down into small chunks and each chunk is fed to a Map function that will be run on an individual computer. The Reduce function is used for summarizing results from all chunks to get the complete result on the whole dataset.
We conduct experiments to evaluate the performance of the TCM . The evaluation criterion in both cases was the accuracy of the predicted click-through rates. The ranking produced by ordering the results based on estimated CTRs are often used in literature [6] for model comparison pur-poses. However, in sponsored search, the final ranking pre-sented to the user is a product of an auction mechanism. For our end goal, the accuracy of the click prediction mat-ters most. One of the differentiating properties of TCM compared to other state of the art models [13, 18, 6] is that TCM considers temporal sequences, and predicts the prob-abilities of sequences of clicks. Since the existing method s completely ignore the time of clicks, we are unable to com-Figure 3: Summary of Datasets: NAD (left) and SAD (right). pare the performance of TCM on this task to any other method.
We evaluate our model on two data sets: NAD and SAD , which are introduced in Section 2. NAD and SAD have around 0.3 and 1.1 million distinct queries with 0.1 and 0.65 billion sessions each, respectively. For the very fre-quent queries, direct statistics can do well on CTR predic-tion because there are many historical observations for the se queries. In order to prevent the model evaluation from be-ing dominated by these samples, only queries with less than 3% and 5% queries in NAD and SAD respectively. A sum-mary of the query frequency distributions in the two data sets is provided in Fig. 3.

Because our model aims at learning externalities between ads, we evaluate our model on the estimating the CTR of ad impression sequences instead of an individual ad. Therefor e, we design and use the following leave-one-out experimental protocol: 1. Retrieve all the sessions related to a given query; 2. Consider each distinct ad impression sequence in those 3. Hold out as test sessions all the sessions with this ad 4. Train our model and baselines on the remaining ses-5. Compute the true CTRs from test sessions; 6. Compute the Mean-Square-Error (MSE) between the 7. Average the error on all ad impression sequences, weighte d
We considered two baseline models for model compar-isons. One is naive CTR statistics ( NS ), and the other is Bayesian browsing model ( BBM ) [18], a state-of-the-art model in click modeling literature.

Given training data A and C and an ad impression se-quence A = &lt;a 1 a 2 &gt; , the baseline NS simply uses the empiri-cal CTR of a i in training data, i.e., the percentage of clicks on a i at position i .
 The BBM model follows the examination hypothesis as TCM does. But, TCM differentiates itself from BBM in several ways. For example, BBM examines one ad at a time and TCM examines both at the same time, in order to model externalities. Moreover, BBM ignores temporal informatio n, and therefore it treats two click sequences &lt;a 1 a 2 &gt; and &lt; Figure 4: Accuracy in predicting the CTR of ad impressions from queries with different frequencies (Left: NAD dataset, Right: SAD dataset). Both TCM and BBM are significantly better than NS for all query frequencies. TCM is noticeably better than BBM on less-frequent queries but shows similar performance on frequent ones.

Figure 5: Accuracy in predicting the CTR at Position 2 for varying query frequencies (Left: NAD dataset, Right:
SAD dataset). Both TCM and BBM are significantly better than NS for all query frequencies on both datasets. TCM is noticeably better than BBM on all queries of NAD , and on less-frequent queries of SAD .

Figure 6: Average percentage of first click at Position 1 for varying query frequencies (Left: NAD dataset, Right: SAD dataset). The probability that users click Position 1 first f or frequent queries tends to be higher than less frequent queri es.
Figure 7: Percentage of queries where TCM performs as good or better than BBM for varying query frequencies (Left:
NAD dataset, Right: SAD dataset) a 1 &gt; as the same. Given an ad impression sequence A and the click sequence C = &lt;c 1 c 2 &gt; , the BBM specification is as follows: where  X  1 ,  X  2 and  X  3 are model parameters. Please refer to [18] for the details of BBM inference algorithms. We compare TCM to the two baselines on predicting the CTR of ad impressions. As described in the experimental protocol, mean square error is used as the evaluation metric [14]. Fig. 4 reports the prediction accuracy of three method s on both datasets NAD and SAD for varying query frequen-cies. Both TCM and BBM are significantly better than NS across all query frequencies. Our model TCM is noticeably better than BBM on less-frequent queries but shows similar performance on frequent ones.

One obvious reason for the similar performance of TCM and BBM on frequent queries is that frequent queries have more sessions available for training and have more uniform click patterns than less-frequent ones. Even the naive meth od NS tends to close the performance gap with TCM and BBM on frequent queries.

We present more detailed analysis of the data in Fig. 6 to better understand this behavior. This figure shows the percentage of first clicks at Position 1 for different query frequencies. We see that the probability of clicking the ad in Position 1 first is higher for the frequent queries. This graph could suggest that the users consider ads in Position 1 more frequently in these very frequent queries. It X  X  quite possible that search engine users are trained to consider to p results more for the frequent queries via positive reinforc e-ment: the more user feedback there is, the better the search engine ranking will be; as the search engine rankings im-prove users will trust search engine X  X  ranking more. If this is the case, the assumption that the users will examine both of the ads before clicking would not hold for the frequent queries. Since TCM uses this positional rationality assump-tion, degradation in performance for the frequent queries would not be surprising. Fig. 7 further verifies this claim. It presents the percentage of queries that TCM performs as good or better than BBM for varying query frequencies on the two data sets. The percentage goes down as the query frequency increases.
TCM performs noticeably better than BBM on less-frequent queries. But, what contributes to this improvement?
We compare TCM , BBM and NS on predicting the CTR at Position 2 of ad impressions. Fig. 5 presents the accuracy results for varying query frequencies as measured by mean square error. Both TCM and BBM are significantly better than NS for all query frequencies on both datasets NAD and SAD . TCM is noticeably better than BBM on all queries of NAD , and on less-frequent queries of SAD as before, but the magnitude of improvement is much bigger. Therefore, TCM performs better than BBM mainly because it predicts clicks at Position 2 better. m and U m for different cases
Predicting user click behavior is crucial to the sponsored search business model. In this paper, we first presented statistical analyses demonstrating that externalities ex ist in this domain and that temporal click sequences are good in-dicators of externalities. We proposed the positional rati o-nality hypothesis to explain both position bias and exter-nalities. Based on this hypothesis, we further developed th e temporal click model.
 We evaluated the proposed model on two real data sets. We presented results showing that our model outperforms one of the state of the art click models, BBM [18], on mid to lower decile queries. We believe the results presented in this paper are convincing evidence that the time and order of user actions contain useful information about the user X  X  click behavior.

We would like to extend our model to incorporate time users spend on the landing pages, which could provide us a direct measure of user satisfaction, and therefore improv e our estimate of ad quality. Another extension is to model repeated clicks, which are not rare in click logs. Repeated clicks could be viewed as the re-judgement of users on ad quality. Being able to model them could be helpful to im-prove the accuracy of our click prediction.
