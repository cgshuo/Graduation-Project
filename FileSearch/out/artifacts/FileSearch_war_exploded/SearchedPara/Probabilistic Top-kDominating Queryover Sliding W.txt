 Spatial database has drawn atte ntion in recent decades. Beckmann et al. [1] design the R-tree as an index for efficient computation. Roussopoulos et al. [8] study nearest neighbor queries, and propose three effective pruning rules to speed up the computation. They also the extend nearest neighbor queries to k nearest neighbor queries, which operator, and propose an SQL syntax for the skyline query.

Top-k dominating query is first studied by Yiu et al. [10], which retrieves the top-k objects that are better than the largest number of objects in a dataset. This is quite different from the skyline query in [4] that retrieves objects which are not worse than other objects.

Uncertain data analysis is of importance in many emerging applications, such as sensor network, trend prediction and moving objects management. There has been a lot of works focusing on uncertain data management, [5,11] to cite a few.
 In this work, we study probabilistic top-k dominating query over sliding windows. We employ the data model with sliding windows as used in [9,13]. In sliding windows, data is treated as a stream, and only recent n objects are considered.

There are some closely related work, seen in [7,12]. However, they study objects with multiple instances. Besides, their query is to get top-k dominating objects from the total data set. While our paper studies objects from append-only data stream. And our main concern is to maintain top-k dominating objects from recent N objects where N is the window size.

Probabilistic top-k dominating query is desirable in various real-life applications. Ta-ble 1 evidences a scenario of house rental, where answering such type of query can be beneficial. Lessees are interested in knowing the top-1 house from all recent 4 advertise-ments. Each advertisement is associated with its house ID, post time, price, distances to supermarket and trustability. Trustability is derived from Lessee X  X  feedback on the lessors product quality; this  X  X rustability X  v alue can also be regarded as the probability that the house is the same as what it claims.

We assume lower price and closer to supermarket are preferred and lessees do not care about other attributes. We also assume that lessees want a house that are better than the most of others. A top-k dominating ( k =1 ) query would retrieve { H 1 } as the {
H 4 } is the result for the next sliding window { H 2 ,H 3 ,H 4 ,H 5 } . However, we may also notice that H 4 is of low trustability. It is more reasonable to take the trustabil-ity into consideration. We model such on-line selection problem as probabilistic top-k dominating query against sliding windows by regarding on-line advertisements as an append-only data stream. This query will be formally defined in Section 2. Hence, the probabilistic top-k dominating query over sliding windows provides a more reasonable solution under the given scenario.

In summary, we make the following contributions in this paper:  X  We identify the problem of probabilistic top-k dominating query over sliding win- X  We develop novel algorithms to continuously compute the top-k dominating ob- X  We conduct extensive experiments to demonstrate the correctness and efficiency of Organization. The rest of the paper is organized as follows. In Section 2, we present background information and formally define the problem. Sections 3 and 4 present the techniques for processing top-k dominating query over sliding windows. Experimental results are provided and analyzed in Section 5. Section 6 concludes the paper. This section introduces the background information, and defines the problem. 2.1 Background When comparing two objects, if one object p is not worse than another q in all aspects and p is better than q in at least one aspect, we say p dominates q . Formally, we have Definition 1.
 Definition 1 (Dominate). Consider two distinct d -dimensional objects p and q , and for 1  X  i  X  d , and there exists j , such that p [ j ] &lt;q [ j ] .
 Based on Definition 1, [10] develops a sco re function to count the number of objects dominated by an object as Consequently, top-k dominating query in a data set is to retrieve the top-k objects with maximal  X  ( p ) in the data set.

Given a sequence data stream DS of uncertain data objects, a possible world W is a subsequence of DS ; i.e., each object  X  from DS can be either in W or not. For  X  the product of probabilities of all objects which appear in W and 1  X  the probabilities of all objects which do not appear in W ; i.e., P ( W )=  X   X  W P (  X  )  X   X /  X  W (1  X  P (  X  )) .
We compute the  X  function in Equation (1) for every object in the certain possi-ble world W . For a top-k dominating query over sliding window, probability of each qualified possible world W is accumulated in order to get the overall probability. 2.2 Problem Definition In many applications, a data stream is append-only; that is, there is no deletion of data element involved. In this paper, we study the top-k dominating problem by employing the append-only data stream model. Given an uncertain data stream DS consisting of n uncertain objects, sliding window size W , probability threshold q ,weuse l to measure the dominating ability of each object in a sliding window. That is, an object dominates at least l objects in possible worlds, of which the total probability is over q in a sliding window of size W . Thus, top-k dominating over sliding windows maintains the top-k objects which are ranked according to l over sliding windows with regards to threshold q . Example 1. Consider the running example in Table 1, where we need the top-1 house over a sliding window of size N =4 , and probability threshold q =0 . 6 .Wehavein total 16 possible worlds in each windo w. When a window contains { H 3 ,H 4 ,H 5 ,H 6 } , P ( H 5) = 1 . First, we compute the dominating number of each object in every possible world(asshowninTable2).Whencomputing l value, we sum up the probability of each possible world according to the number of objects it dominated in descending or-and H 4 gets 50%(38 . 25% + 6 . 75% + 4 . 25% + 0 . 75%) . H 3 and H 5 are both 0, since they do not dominate others. Therefore, we have H 3 .l =0 , H 4 .l =0 , H 5 .l =0 ,and H 6 .l =1 ; and hence, H 6 is the top-1 object in the probabilistic top-1 dominating query with probability threshold =0 . 6 over the sliding window { H 3 ,H 4 ,H 5 ,H 6 } . 2.3 Dominance Relationships We implement our techniques based on the R-tree. Thus, we define the following rela-tionships between a pair of entries E and E in the R-tree. E.min denotes the lower-left corner of the minimum bounding box (MBB) of the objects contained by E ,and E.max denotes the upper-right corner of MBB. Note if an entry contains only one object  X  , E.min = E.max =  X  .
 An entry E is said to fully dominate another E ,iff E.max  X  E .min or E.max = E .min , denoted as E  X  E .Anentry E partially dominates E ,iff E.max  X  E .min, E.min  X  E .max , denoted as E  X  partial E .Anentry E does not domi-nate E ,iff E.min  X  E .max , denoted as E  X  E . As depicted in Figure 1, E 2 fully dominates E 3 , E partially dominates E 2 ,and E 1 does not dominate E . As aforementioned, we may calculate the dominating score by the finding maximal l whose accumulating possibility of all the qualified possible worlds is over q .However, this can be rather time-consuming due to the exponential number of possible worlds; i.e., there are 2 N possible worlds, where N is the number of all objects.
We observe that the complexity can be reduced by viewing the problem from another perspective. Instead of enumerating possible worlds, we retrieve the largest l in the condition, where at least l objects exist of M objects, where M is the number of all dominated objects.

Specifically, let m i,j denote the probability that exactly i objects out of j objects relations. Equation (2), known as Poisson-Binomial Recurrence [6], is widely used in uncertain database analysis [2,3]. Applying Equation (2), we propose a dynamic programming al-gorithm that efficiently computes l value of a certain object, encapsulated in Algorithm 1.
Algorithm 1 takes  X  and  X  as inputs, where  X  is the object of which we need to compute l value, and  X  contains all the objects which are dominated by  X  . A matrix is used to store the intermediate result, initialized in Line 2 . Then, we use Equation (2) to till f is less then q (Lines 15 -17 ), and i  X  1 is returned as the result.
Algorithm 1 . calDS (  X ,  X  ) Correctness and Co mplexity Analysis. It is immediate that Algorithm 1 correctly computes the l value. The most time-consuming part is the loop in Lines 7  X  13 ,and thus, the complexity of algorithm is O ( |  X  | 2 ) .
 Example 2. Consider the running example in 2.2. We only compute H 4 and H 6 ,since {
H 3 ,H 4 ,H 5 ,H 6 } is H 6 . A naive solution to retrieving top-k dominating objects over sliding windows is to visit each object every time the window slides. When visiting an object, it also gets all the ob-jects it dominates by traversing R-tree and then computes its l value using Algorithm 1. Eventually, it chooses k objects with maximal l values. We observe that this tedious process can be accelerated. Given a probability threshold q and a sliding window with size N , Algorithm 2 shows how we process every arriving object.

Algorithm 2 . Probabilistic top-k dominating over Sliding Windows
When a new object  X  new comes, if there are exactly N objects in the window, we remove the oldest object  X  old . Then, we use function insert (  X  new ) to update the l value of objects. Finally we collect the top-k dominating objects using min-heap.
In the following subsections, we present novel algorithms to efficiently execute Al-gorithm 2. We first introduce the data structure, then provide our algorithm to handle the situation when a new object is inserted ( insert (  X  new ) ), followed by an algorithm to deal with a removed old object ( remove (  X  old ) ). 4.1 Aggregate R-Trees and Heap each object as aggregate information. Specifically, P is the probability of the object, l is the measure of dominating ability regarding probabilistic threshold q . Additionally,  X  top-k dominating is the last column of matrices that we use to compute l by Algorithm 1. Note that each column only depends on the p revious column. In another word, when a new object  X  new comes, keeping last column of the matrix is enough to update the l value.

By storing these aggregate information, we do not have to recalculate the l value of all objects when a new object comes. We only need to update  X  top-k dominating and l value every time a new object comes.
In addition, we maintain the top-k dominating objects in a min-heap; i.e., we insert the first k objects into a min-heap. For each following object having larger l than the minimum object in the heap, we first dequeue the minimal object, and then insert the new object into the min-heap. 4.2 Insert When a new object  X  new comes, we need to consider all the objects dominating it (denote as S 1 ) and being dominated by it (denote as S 2 ). To this end, we process the following tasks: 1) compute S 1 and S 2 by traversing the aggregate R-tree, 2) update l of each object in S 1 ; and 3) compute l of the new object.
 Algorithm 3 describes the steps we take to handle an insertion. R is the aggregate R-tree we used to store all objects in current sliding window. S 3 is used to collect all the entries which partially dominate  X  new , S 4 is used to collect all the entries which are partially dominated by  X  new ,and S 34 is used to collect the entries which partially dominate  X  new and are partially dominated by  X  new . First, we classify all the entries to namely S 1 and S 2 ,using probe1 , probe2 and probe3 (Lines 7 -9 ). So far, we have finished task 1). Then, task 2) is done by updating all the entries in S 1 using update (Line 10 ). Afterwards, we achieve task 3) by computing l of  X  new (Line 11 ).
Algorithm 3 . insert (  X  new )
Algorithm 4 shows how we refine S 3 . Note that all the entries in S 3 cannot be dominated by  X  new . We add entries dominating  X  new to S 1 (Line 4 in Algorithm 4), and leave entries which partially dominate  X  new in S 3 (Line 5 in Algorithm 4).
Algorithm 4 . probe1 ( S 3 )
The ideas behind Algorithm 4 and Algorithm 5 are similar. We add entries which are dominated by  X  new to S 2 (Line 4 in Algorithm 5), and leave entries which are partially dominated by  X  new in S 4 (Line 5 in Algorithm 5).

Algorithm 5 . probe2 ( S 4 )
S 34 is special in that it may contain entries which dominate  X  new and entries which are dominated by  X  new . Thus, we first partition them (Lines 1 -8 ), and apply probe1 and probe2 thereafter.

Algorithm 6 . probe3 ( S 34 )
Algorithm 7 describes the update of S 1 . For each object at leaf node, we update its l and  X  top-k dominating by using  X  new . As a consequence, the time complexity of the update is O ( l ) .

Algorithm 7 . update1 ( S 1 )
We analyse the worst case complexity of Algorithm 3; i.e., when every object is dominated by all the previous objects. Let N denote the window size. In this case, S 1 contains all N objects. Immediately, the most time consuming part is in Line 11 ,and thus, the time complexity is given by O ( N 2 ) .
 Since Algorithm 3 is complicated, we give an example below.
 Example 3. Regarding the example in Table 1. We assume windows size N =4 , prob-abilistic threshold q =0 . 6 , and there are exactly H 1 ,H 2 ,H 3 in current window. H 4 comes as  X  new .Before H 4 comes, we use Algorithm 1 to compute the corresponding l values of H 1 ,H 2 ,H 3 . As an example, the first three columns in Table 3 shows how to The aggregate information of other objects are listed in the first three rows of Table 4. When H 4 comes, according to Algorithm 3, we firs t collect all objects dominating H 4 in S 1 and all objects dominated by H 4 in S 2 . Here, we have S 1= { H 1 } ,S 2= {
H 2 ,H 3 } . Then, we update l and  X  top-k dominating of H 1 . Using Equation (2), we get the 4 -th column in Table 3. Because (0 . 3825 + 0 . 4925)  X  P ( H 1) &gt;q =0 . 6 ,the l Finally, we compute l and  X  top-k dominating for H 4 . Because P ( H 4) &lt;q =0 . 6 ,we have l =0 and  X  top-k dominating =  X  . Therefore, the top-1 dominating query for window { H 1 ,H 2 ,H 3 ,H 4 } is H 1 .

H 1(0 . 80) H 2(0 . 90) H 3(0 . 85) H 4(0 . 5) 4.3 Expire When  X  old expires, the l value of each object dominated by  X  old will not change. There-
Algorithm 8 . remove (  X  old )
The update process of S 1 is shown in Algorithm 9. For each object at leaf node, which are dominated by the object in  X  .

Algorithm 9 . update2 ( S 1 )
Similarly, we provide a worst case complexity analysis of Algorithm 8. When all objects dominate all previous obj ects, we need to re-calculate l value of all remaining objects. Therefore, the time complexity is given by O ( N 3 ) ,where N is the window size.
 Correctness. The correctness of our techniques is guaranteed by computing the exact l value of each object in current sliding window. Besides, we get the top-k dominating objects using a min-heap. This i s also correct because the k objects are guaranteed to have larger l values than these not in the min-heap. This section reports the experimental studies. 5.1 Setup We ran all experiments on a MacBook Pro with Mac OSX 10 . 8 . 1 , 2 . 26 GHz Intel Core 2 Duo CPU and 4 G 1333 MHz RAM. We evaluated the efficiency of our algorithm against sliding window size, dimensionality, and probabilistic threshold, respectively. The default values of the par ameters are listed in Table 5.

Parameters are varied as follows:  X  sliding window size: 2k, 4k, 6k, 8k, 10k  X  dimensionality: 2, 3, 5  X  probabilistic threshold: 0.1, 0.3, 0.5, 0.7, 0.9 We ran all experiments with 100 windows, and repeated all experiments 10 times to get an average execution time. The execution time in each following figure is the running time for processing 100 windows. 5.2 Evaluation Figures 2, 3 and 4 show the results when window size is varied. In Figure 5, we vary the threshold probability to see the running time of baseline algorithm. In Figure 6, we vary the threshold probability to see the running time of the efficient algorithm. From the figures, we see that the efficient algorithm outperforms the baseline algorithm in all cases.
As shown in Figures 2, 3 and 4, when window size increases linearly, the running rithms. Moreover, we conclude, by comparing Figures 2, 3 and 4, that the running time decreases greatly with the increase of dimensionality. This is because the most time-consuming part of the baseline algorithm is to compute l ; i.e., collect all objects and apply Algorithm 1 to compute l . With higher dimensionality, there is a smaller  X  for each object. Similar conclusion can be drawn for the efficient algorithm.
From Figures 5 and 6, when threshold grows, the running time decreases. With larger threshold, there are more objects being pruned, i.e. objects whose probability is lower than threshold. In addition, this effect is more obvious with low dimensionality, as more objects to be pruned by the algorithm in the lower dimensional space. In this paper, we have investigated the problem of top-k dominating query in the con-text of sliding window on uncertain data. We first model the probability threshold based top-k dominating problem, and then present a framework to handle the problem. Ef-ficient techniques have been presented to process such query continuously. Extensive experiments demonstrate the effectiveness and efficiency of our techniques.
