 Rafael B. Pereira a ,  X  , Alexandre Plastino a , Bianca Zadrozny d , 1. Introduction
Given a training set where each instance is described by a vector of attributes and by a class label, the classi fi cation task can be stated as the process of correctly predicting the class label of a new instance or a set of new instances described by their attribute values. One of the main research issues in classi fi cation is to design accurate and ef fi cient classi fi cation algorithms and models that work for data sets that are large both in terms of the number of instances as well as the number of attributes.

Classi fi cation techniques are traditionally categorized as eager or lazy. Eager strategies work on a training set to build an explicit classi fi cation model that maps unlabeled instances to class labels. At classi fi cation time, they simply use the model to make class predictions. Well-known eager techniques include decision trees [21,22], neural networks [23], associative classi fi ers [16] and SVMs (Support Vector Machines) [2].

Lazy strategies, on the other hand, do not construct explicit models and delay most processing of the training set until classi fi cation time, when the instance to be classi fi ed is known. The most well-known lazy technique is k-NN (k-Nearest Neighbors) [3,4], in which the class label of an instance is estimated based on the class labels of neighboring instances. The Naive Bayes algorithm [5] can be used as an eager or lazy technique. If all conditional and a priori probabilities are previously calculated, before any instance is submitted for classi fi cation, it can be seen as an eager strategy. However, if we decide to compute the necessary probabilities for a particular instance only during classi fi cation time, it can be considered a lazy technique. There are also lazy versions of traditional eager techniques such as lazy decision trees [7], lazy rule induction [8] and lazy associative classi fi cation [25]. In these approaches, when an instance is presented for classi fi cation only the part of the model needed to classify the particular instance is constructed.

The performance of a classi fi cation method is closely related to the inherent quality of the training data. Redundant and irrelevant attributes may not only decrease the classi fi er X  X  accuracy but also make the process of building the model or the execution of the classi fi cation algorithm slower. In order to avoid these drawbacks, attribute selection techniques are usually applied for removing from the training set attributes that do not contribute to, or even decrease, the classi fi cation performance [11,17]. These techniques are traditionally executed as a data preprocessing step, making the attribute selection de fi nitive from that point on. The classi fi cation process itself is executed over the reduced training set.
In this paper, we propose a new general attribute selection strategy, whose main characteristic is to postpone the selection of relevant attributes  X  in a lazy fashion  X  to the moment when an instance is submitted for classi fi cation, instead of eagerly selecting the most important attributes. Our hypothesis is that knowing the attribute values of an instance will allow the identi fi cation and selection of the best attributes for the correct classi fi cation of that speci fi c instance. Therefore, for different instances to be instance. We expect that based on the proposed lazy selection technique the adopted classi fi er will be able to achieve better predictive accuracy than it is possible with an eager attribute selection strategy.
This paper is organized as follows. In Section 2, we describe the attribute selection task in more detail and review related work. In Section 3, we motivate and propose our general lazy attribute selection strategy. We also present a speci fi c instantiation of this strategy that uses an entropy-based criterion to rank attributes. Experimental results using the proposed lazy strategy in conjunction with the k-NN and Naive Bayes classi fi ers are presented in Section 4. Finally, in Section 5, we make our concluding remarks and point to directions for future work. 2. Attribute selection
According to [11], attribute selection techniques are primarily employed to identify relevant and informative attributes. In general, besides this main goal, there are other important motivations: the improvement of a classi fi er X  X  predictive accuracy, the reduction and simpli fi cation of the data set, the The main motivation of the attribute selection strategy proposed here is improvement in classi fi cation accuracy.

Attribute selection techniques can generally be categorized into three categories: embedded,wrapperor fi lter [18]. Embedded strategies are directly incorporated into the algorithm responsible for the induction of a classi fi cation model. Decision tree induction algorithms can be viewed as having an embedded technique, since they internally select a subset of attributes that will label the nodes of the generated tree. Wrapper and fi lter strategies are performed in a preprocessing phase and they search for the most suitable attribute set to be used by the classi fi cation algorithm or by the classi fi cation model inducer. In wrapper selection, the adopted classi fi cation algorithm itself is used to evaluate the quality of candidate attribute subsets, while in fi lter selection, attribute quality is evaluated independently from the classi fi cation algorithm using a measure which takes into account the attribute and class label distributions. In general, wrapper techniques achieve higher predictive accuracy than fi lter strategies since they evaluate candidate attributes subsets using the same algorithm that will be used in the classi fi cation (testing) phase. However, since wrapper strategies require several executions of the classi fi cation algorithm, their computational costs tend to be much higher than the cost of fi lter strategies. There are also hybrid strategies which try to combine both approaches [20].

In this paper we chose to concentrate on developing a lazy attribute selection that follows the fi lter strategy. The motivation for this choice is twofold. First, among the three types of attribute selection strategies, the fi lter strategy is the easiest to analyze and evaluate in an isolated manner, since it is independent from the classi fi cation algorithm. Secondly, it is much faster than the wrapper approach.
Filter strategies are commonly divided into two categories. Techniques of the fi rst category, as exempli fi ed by Information Gain Attribute Ranking [27] and Relief [14,15], evaluate each attribute individually and select the best ones. Attributes that provide a good class separation will be ranked higher and therefore be chosen. The second category is characterized by techniques which evaluate subsets of attributes, searching, heuristically, for the best subset. Two well-known strategies of this group are Correlation-based Feature Selection [12] and Consistency-based Feature Selection [19].
As detailed in the next section, the lazy attribute selection strategy that we propose in this paper is based on individual evaluation of attributes, using entropy [21] to measure the relevance of each attribute. 3. Lazy attribute selection
In conventional attribute selection strategies, attributes are selected in a preprocessing phase. The at-tributes which are not selected are discarded from the data set and no longer participate in the classi fi cation process.

Here, we propose a lazy attribute selection strategy based on the hypothesis that postponing the selection of attributes to the moment at which an instance is submitted for classi fi cation can contribute to identifying the best attributes for the correct classi fi cation of that particular instance. For each different instance to be classi fi ed, it is possible to select a distinct and more appropriate subset of attributes to classify it.

Below we give a toy example to illustrate the fact that the classi fi cation of certain instances could take advantage of attributes discarded by conventional attribute selection strategies. In addition, some of the attributes selected by conventional strategies may be irrelevant for the classi fi cation of other instances. In other words, the example illustrates that attributes may be useful or not depending on the attribute values of the instance to be classi fi ed. In Table 1, the same data set, composed of three attributes  X  X , Y , and the class C  X  is represented twice. The left occurrence is ordered by the values of X and the right one is ordered by the values of Y . It can be observed in the left occurrence that the values of X are strongly correlated with the class values making it a useful attribute. Only value 4 is not indicative of a unique class value.

Furthermore, as shown in the right occurrence, attribute Y would probably be discarded since in general its values do not correlate well with the class values.

However, there is a strong correlation between the value 4 of attribute Y and the class value B ,which would be lost if this attribute were discarded. The classi fi cation of an element with value 4 in the Y attribute would clearly take advantage of the presence of this attribute.
A conventional attribute selection strategy  X  which, from now on, we refer to as an  X  X ager X  selection strategy  X  is likely to select attribute X in detriment of Y , regardless of the instances that are submitted for classi fi cation. According to [18], a key advantage of lazy approaches in general is that they can respond to unexpected queries in ways not available to eager learners, since they do not lose crucial information that can be used for generating accurate predictions.

Hence, the main motivation behind the proposed lazy attribute selection is the ability to assess the attribute values of the instance to be classi fi ed, and use this information to select attributes that discriminate the classes well for those particular values. As a result, for each instance we can select attributes that are useful for classifying that particular instance.

In this paper, we chose to use the e ntropy concept [27] to evaluate the quality of each attribute value for the classi fi cation of an instance. Speci fi cally, entropy will be used to measure how well the values of the attributes of an instance determine its class. The entropy concept is commonly used as measure of attribute relevance in eager and fi lter strategies that evaluate attributes individually [27], and this method has the advantage of being fast.

Let D ( A Let { c in D , represented by Ent ( D ) ,isde fi ned by where p i is the probability that an arbitrary instance in D belongs to class c i .

Let { a j and 1 i k j , be the partition of D composed of all instances whose value of A j is equal to a ji .The entropy of the class distribution in D , restricted to the values of attribute A j ,1 j n , represented by Ent ( D, A j ) ,isde fi ned by
Thus we de fi ne the entropy of the class distribution in D , restricted to the value a ji ,1 i k j ,of attribute A j ,1 j n , represented by Ent ( D, A j ,a ji ) , as follows: The concept de fi ned in Formula 2 is used by the eager strategy known as Information Gain Attribute Ranking [27] to measure the ability of an attribute to discriminate between class values. Formula 3 will be used in our proposed lazy selection strategy to m easure the class discrimination ability of a speci fi c value a ji of a particular attribute A j . The closer the entropy Ent ( D, A j ,a ji ) is to zero, the greater the chance that the value a ji of attribute A j is a good class discriminator.

The input parameters of the lazy strategy are: a data set D ( A I [ v 1 ,v 2 ,...,v n ] to be classi fi ed with its attribute values; and a number r ,1 r&lt;n , which repre-sents the number of attributes to be selected.

In order to select the r best attributes to classify I , we propose to evaluate the n attributes based on a lazy measure ( LazyEnt ), de fi ned in Formula 4, which states that, for each attribute A j ,ifthe discrimination ability of attribute A j ( Ent ( D, A j ) ) then the former will be considered for ranking A j . The choice of considering the minimum value from both the entropy of the speci fi c value and the overall entropy of the attribute was motivated by the fact that some instances may not have any relevant attributes considering their particular values. In this case, attributes with the best overall discrimination ability will be selected.
 Then, the measure proposed to a ssess the qua lity of each attribute A j is de fi ned by where min () returns the smallest of its arguments.

After calculating the value LazyEnt ( D, A j ,v j ) for each attribute A j , the lazy strategy will select the r attributes which present the r lowest LazyEnt values. 4. Experimental results
We implemented the lazy strategy described above within the Weka tool [26]  X  version 3.4.11  X  and tested it in combination with different classi fi ers. The lazy selection occurs when the classi fi er receives a new instance to be classi fi ed. Since for each new instance a distinct subset of attributes must be considered by the classi fi er, the attributes not selected by the lazy strategy for a given instance are not removed from the data set, but only disregarded by the classi fi cation procedure.

As a baseline for comparison we used the eager attribute selection strategy most similar to our lazy strategy, which is the Information Gain Attribute Ranking technique [27]. This technique is available within the Weka tool with the name  X  X nfoGainAttributeEval X . Both of them use the entropy concept for ranking attributes, are supervised strategies and need to know in advance the number of attributes that should be selected.
 The strategies were initially tested on a large number of data sets from the UCI Machine Learning Repository [1]. A total of 40 data sets which have a wide variation in size, complexity and application area were chosen. Table 2 presents some information about these data sets: name, number of attributes, number of classes and number of instances.
The entropy measure used to eva luate the quality of each attribute i n our proposed tec hnique requires discrete attribute values. Therefore we adopted the recursive entropy minimization heuristic proposed in [6] to discretize continuous attributes and coupled this with a minimum description length criterion [24] to control the number of intervals produced over the continuous space.
 We have incorporated our lazy attribute selection strategy into two distinct classi fi cation techniques. In Subsection 4.1, we present the results obtained with the lazy k-Nearest Neighbor classi fi er and, in Subsection 4.2, we present the results obtained with the Naive Bayes. In Subsection 4.3, we explored a method for estimating if the lazy attribute selection strategy is most likely to have a better performance than the eager approach. And in Subsection 4.4, we evaluated the lazy strategy in larger data sets from the NIPS 2003 challenge of feature selection [10].
 4.1. Experimental results with k-NN
The k-NN algorithm assigns to a new instance to be classi fi ed the majority class among its k closest instances, from a given training data set [3,4]. The distance between each training instance and the new instance is calculated by a function de fi ned on the values of their attributes. Hence, the use of lazy attribute selection implies that the calculation of the distances will be done using different subsets of attributes for different instances to be classi fi ed.
 We compared the results of the original k-NN implementation available within the Weka tool, called IbK, with that obtained with our adapted version of this implementation which executes the lazy attribute selection before classifying each test instance. Both of them were executed with different values of the parameter k : 1, 3 and 5. In all experiments reported in this work, parameters not mentioned are set to their default values in the Weka tool.

Initially, we report the results obtained by both eager and lazy selection strategies when executed with three speci fi c data sets: Wine, Heart-Hungarian and Vowel. The main goal of this fi rst analysis is to show some results in detail so that our experimental methodology can be better understood. Also, it gives some evidence that the lazy strategy can indeed outperform the eager strategy for some data sets.
Tables 3, 4 and 5 show the predictive accuracies obtained by the k-NN algorithm, using both eager and lazy selection, with parameter k equal to 1 (columns 2 and 3), k equal to 3 (columns 4 and 5), and k equal to 5 (columns 6 and 7), for the Wine, Heart-Hungarian and Vowel data sets. Each row of these tables represents the execution of the selection strategies with a fi xed number of attributes to be selected. The fi rst column indicates the number of attributes to be selected as a percentage of the total number of attributes in the data set  X  the absolute number appears in parentheses. The last line (100%) represents the execution using the whole attribute set, that is, when no attribute selection is performed. Each value of predictive accuracy is obtained by a 10-fold cross-validation procedure [13]. When comparing the two attribute selection strategies, bold-faced values indicate the best behavior.

Table 3 shows the results for the Wine data set. We can observe that the lazy strategy presented much better results than the eager strategy, regardless of the number of attributes we choose to select. The results with the lazy strategy are also better than the ones obtained without attribute selection. The lazy strategy was able to reach 100% of accuracy when just 3 out of 13 attributes were selected, when k was equal to 3 and 5. These fi rst results are evidence that the lazy strategy can be better than the eager approach and better than the execution of the classi fi er without attribute selection.

Table 4 presents the results obtained with the data set Heart-Hungarian. In this experiment, the eager strategy, mainly with number of attributes limited to 50%, had a better behavior than the lazy strategy. Both strategies presented the same accuracies when the number of selected attributes is greater than 60%. Also, with both strategies we are able to obtain better results than with no attribute selection.
A third kind of result, shown in Table 5 for the Vowel data set, represents the cases where the selection of attributes does not contribute to the classi fi cation process. The results for this data set show that neither the lazy nor the eager strategies were able to outperform the results obtained without any attribute selection. This indicates that all attributes in this data set contribute to the overall classi fi er performance. It is worth observing that, in this experiment, the lower the number of selected attributes the worse is the accuracy, for both strategies.

In Table 6, we summarize the results obtained by both eager and lazy strategies when executed for the 40 UCI data sets, using 1 -NN, 3-NN and 5-NN classi fi ers. For each data set and classi fi er, we compare the accuracy of the strategies when we vary the percentage of attributes selected from 10% to 90% with a regular increment of 10%. The  X  X azy X  and  X  X ager X  columns indicate the number of times each strategy obtained the higher predictive accuracy considering these nine different executions. Superior behavior is reported by bold-faced values. The  X  X ies X  column represents the number of ties, that is, when both strategies obtained exactly the same accuracy. The last row reveals the total sum of best results obtained with each strategy.

As can be observed in the last row of Table 6, regardless of the k value, for most of the data sets the lazy strategy achieved a greater number of better results than the eager strategy. When k is equal to 1, the lazy strategy obtained 220 times the best results against 87 times for the eager strategy, with 53 ties. For k equal to 3 and 5, the behavior is very similar.

For the data sets Letter, Mol-Bio-Splice, Pendigits and Wine, the lazy strategy obtained the best results in all nine tests, regardless of the k parameter. For the data sets Chess-kr-vs-kp, Ionosphere, Labor, Primary-Tumor, Spambase, for at least one value of k , the lazy strategy achieved the best result in all nine tests. For no combination of data set and parameter k , the eager strategy was able to beat the lazy strategy in all nine tests.

For k equal to 1, in 28 out of the 40 data sets, the lazy strategy obtained a number of best results greater than the number of eager best results and greater than the number of ties. The eager strategy proceeded this way only 7 times. For k equal to 3 and 5, theses numbers of times were again 28 for the lazy and 7 for the eager strategy, which indicates a regularity in the results and that the good behavior of the lazy strategy does not greatly depend on the value of parameter k .

Up to this point, we have compared the strategies considering that they would select the same number of attributes. In the next analysis, we evaluate the results in a hypothetical scenario where we would know the best number of attributes to be selected for each strategy. In Table 7, for each data set, we report the best accuracies obtained with each attribute selection strategy considering the nine different selection percentage values. For 1-NN, 3-NN and 5-NN, we present, in the  X  X ager X  and  X  X azy X  columns, the best accuracy obtained by each strategy. The number in parentheses represents the percentage of attributes selected with which this accuracy was obtained. The  X  X o Sel X  columns represent the accuracy obtained when no attribute selection was executed. For each data set and each k-NN group, the bold-faced values selection strategy achieved the best overall result, out of the 40 UCI data sets.

We observe that, in this scenario, regardless of the parameter k , the lazy strategy tends to achieve greater accuracies than the eager strategy. For k equal to 1, the lazy strategy achieved the best accuracy 28 times whereas the eager strategy achieved the best accuracy 21 times. For k equal to 3, the results were 29 for the lazy strategy and 15 for the eager strategy. And for k equal to 5, similar results were obtained: 26 for the lazy strategy and 17 for the eager strategy. We note that for just a few of the data sets, the attribute selection is not useful, that is, for about 10 data sets the executions without attribute selection  X  reported in the  X  X o Sel X  column  X  obtained the best result. Another remarkable result is that for some data sets, like Wine, Audiology, Hypo-Thyroid and Ionosphere, the maximum accuracy was obtained with a relatively small number of selected attributes.

In the results presented so far, we have compared accuracies without taking into account statistical signi fi cance. Next, we employ the paired two-tailed Student X  X  t-test technique with the goal of identifying which compared predictive accuracies are actually signi fi cantly different.

In the comparisons we conducted before, each predictive accuracy value was calculated as the average of a 10-fold cross-validation procedure. Now, we look at the 10 individual results from each fold to apply the paired t-test analysis. Table 8 presents the result of this statistical analysis. Each row represents the results obtained by a different application of k-NN, with k equal to 1, 3 and 5. The second and third columns represent the numbers reported in the last row of Table 6, which is the number of times each strategy (eager and lazy) obtained the better accuracy value. In parentheses, we fi nd the number of times each strategy obtained the better accuracy, considering a statistical signi fi cance with a p-value less than 0.05, which means that the probab ility of the difference of performance being due to random chance alone is less than 0.05. The last column shows the number of cases in which the two accuracy values were equal. We can observe that the results with the lazy strategy were again superior to the ones with the eager strategy. For the 1-NN executions, the lazy strategy obtained the best results with statistical signi fi cance 87 times against just 7 times for the eager strategy. For 3-NN and 5-NN the results are similar and show a better performance of the lazy strategy.

We also note that after taking into account the statistical signi fi cance test, the lazy strategy achieved an accuracy better or equal to the eager strategy in 82.5% of the data sets, regardless of the number of attributes selected. This indicates that selecting the attributes in a lazy way is generally a better choice than performing the eager selection in a preprocessing phase. 4.2. Experimental results with naive bayes
Similarly to the experiments with k-NN, the lazy selection strategy was assessed in combination with the Naive Bayes classi fi er, which is a classi fi cation technique based on the Bayes theorem. The classi fi er applies this theorem assuming that the attributes contribute in an independent manner to the likelihood of the value of the class  X  and although this premise is not always accurate, it usually yields reasonable results in practice.

We have incorporated the lazy attribute selection into the eager implementation of the Naive Bayes classi fi er available within the Weka tool, called NaiveBayes. The lazy attribute selection was executed within the algorithm just before the actual classi fi cation takes place. The Naive Bayes predictor consid-ered only the r attributes sel ected in a lazy manner to compute its pr obabilitie s, for each test instance. In the same manner as in the k-NN experiments, this implies that for different instances distinct subsets of attributes were used. The experiments were executed with the default parameter settings in the Weka tool, using the original Naive Bayes classi fi er. No other relevant features were altered to implement the lazy selection.

Table 9 shows the number of times each strategy, either lazy or eager, achieved a higher accuracy than the other, for the nine executions in which we varied the percentage of attributes between 10% and 90%, in increments of 10%. As seen in the last row labeled  X  X otals X , the results show a prevalence of the lazy strategy over the eager strategy, even though this prevalence is less pronounced that the one we observed with k-NN.

In Table 10 the best accuracies for each selection strategy are presented for the Naive Bayes classi fi er, similarly to what was shown in Table 7 for the k-NN classi fi er. The lazy strategy achieved the best accuracy in 27 cases and the eager strategy in 24 cases. These results show that a considerable number of data sets can bene fi t from the lazy selection.

Finally, a Student X  X  t-test was performed for the Naive Bayes results, with the same parameters used before for the k-NN results, i.e., p = 0.05 with a paired two-tailed setup. The results are the following: the eager strategy prevailed 118 times over the lazy strategy, but only 25 times with statistical signi fi cance. The lazy strategy outperformed the eager strategy 195 times, and from these 80 times with statistical signi fi cance. In 47 tests a de fi nitive tie occurred.
 It is worth reporting that the computational cost introduced by the lazy strategy into the k-NN and Naive Bayes classi fi cation procedure is not considerable. The averageexecutiontime of the lazy selection procedure for each instance vari ed from 0.08 millis econds (fo r the Autos data set ) to 0.31 m illisec onds (for the Lymph data set). This is negligible considering that for these two data sets the average execution time of the 3-NN classi fi cation of an instance was 1.7 and 10.4 m illiseconds. T hese experiments were performed on a 2.0 GHz Intel Core 2 Duo CPU 4400 with 2 Gbytes of RAM. 4.3. Predicting the lazy strategy effectiveness
In spite of the promising results showed before, we can see that it is not always the case that selecting attributes in a lazy fashion is preferable to executing an eager selection. Therefore, it could be interesting to have a method for estimating when the lazy strategy is most likely to be useful.

Intuitively, the lazy strategy is more valuable when there is a great variation in the entropy derived from each different value of an attribute. When this is the case, some attributes are likely to be important for some of the instances but not for the others. Therefore, we need to evaluate for each attribute A j , 1 j n ,ofadataset D ( A differences between the value Ent ( D, A j ) and each of its values Ent ( D, A j ,a ji ) ,1 i k j , for each value a ji of the attribute A j . This average value is then de fi ned by:
For each data set, we can compute the metric V ( D ) by taking the average of the values V ( D, A j ) for all attributes A j . The higher this value, the most likely it is that the data set D would bene fi t from the lazy strategy. However, to de fi ne a more speci fi c and appropriate metric, we need to take into account the number of attributes to be selected. Therefore, for a data set D and a percentage x of attributes to be selected, we calculate the metric V ( D, x ) by the average of the V ( D, A j ) values for the set of attributes with the highest x %valuesof V ( D, A j ) . Analogously, the higher the V ( D, x ) value, the most likely it is that the data set D would bene fi t from the lazy strategy when selecting x % of the attributes.
Figure 1 shows that a high value for this metric does indeed imply a better con fi dence in the superiority of the lazy attribute selection. This analysis is based on all executions of the lazy and eager strategies with the 1-NN classi fi er, taking as input all the 40 UCI data sets ( D ) and the variation of the percentage ( x )of selected attributes from 10% to 90%, in increments of 10%, which represents a total of 360 executions per strategy.

For each threshold value in the horizontal axis the correspondent percentage value in the vertical axis, in Curve 1, represents the percentage of the cases where the lazy strategy achieved higher predictive accuracy than the eager strategy out of all the 360 cases where the respective value of V ( D, x ) is greater than or equalto the correspondingthreshold value in the horizontal axis. In Curve 2, only the comparisons with statistical signi fi cance, out of the 360 cases, are considered in the percentage calculation.
The leftmost point of the Curve 1 indicates that, for all combinations of D and x in which V ( D, x ) 0 (in all 360 cases) the lazy strategy in about 61.1% of the time (or 220 out of 360 executions) achieved better results than the eager strategy. When we restrict the experiments to just the data sets D and value x in which V ( D, x ) 0.2 the lazy strategy prevailed 64.9% of the time (148 out of 228 executions) and for V ( D, x ) 0.4, the results indicate 77.3% of prevailing lazy executions (or 34 out of 44 total executions).
 The same occurs in the experiments conducted with a statistical signi fi cance analysis, represented by Curve 2: the higher the value of V ( D, x ) , the most probable it is that the lazy selection strategy achieves a better result than the eager strategy.

Similar results were obtained with the 3-NN, 5-NN and Naive Bayes classi fi ers, showing that indeed this metric can be used to estimate with more conviction whether the lazy strategy is able to yield a superior result for a speci fi c data set, given the percentage of attributes to be selected. 4.4. Experiments with large data sets
The experiments with the UCI data sets revealed that the k-NN and Naive Bayes classi fi ers bene fi t from the lazy attribute selection in most cases.

For these data sets the number of features varies, between 8 and 69, so we cannot infer from these experiments the behavior of the lazy attribute selection for data sets with a much larger number of attributes.

In order to evaluate if the lazy selection is scalable and effective on larger data sets, additional experiments were performed with data sets from the NIPS 2003 challenge on feature selection [10]. This competition took place in the NIPS 2003 conference, and made available fi ve data sets to be used as benchmarks for attribute selection methods.

The experiments with these large data sets were performed as follows. There were three sets of instances per data set  X  training, validation and test  X  and the class label of each instance was provided only for the training and validation data. These two collections were merged in one data set, and the cross-validation procedure adopted in the earlier experiments was also employed for them. Table 11 summarizes the characteristics of each NIPS data set: name, number of attributes, number of classes and their distribution, and the total number of instances.
 The same procedure to discretize continuous attributes was adopted for these data sets, except for the Dorothea, which has only binary attributes (0/1).
 Some irrelevant and random attributes, referred to as  X  X robes X  in [10], are present in these data sets. In many cases, these attributes were discretized into a single bin by the discretization procedure. When this happened, we removed the attribute from the data set.

Table 12 shows the number of times each strategy achieved a higher accuracy on these data sets, using the same procedure from the earlier experiments: nine executions with the percentage of attributes selected varying from 10% to 90%. Again, a major predominance of best results for the lazy strategy was achieved. Also, the total number of victories taking into account statistical signi fi cance con fi rmed a higher number of successes with the lazy selection.

The best accuracies achieved by each strategy are shown in Table 13. Each result is summarized for the fi ve data sets, using both the k-NN and Naive Bayes classi fi ers. For each data set and classi fi er, we compare the accuracy of the strategies when we vary the percentage of attributes selected from 10% to 90% with a regular increment of 10%. The  X  X azy X  and  X  X ager X  rows present the best accuracy obtained by each strategy. The number in parentheses represents the percentage of attributes selected with which this accuracy was obtained. The  X  X o Sel X  rows represent the accuracy obtained when no attribute selection was executed. For each data set and each classi fi er, the bold-faced values indicate the best result obtained.

Similarly to the experiments with the UCI repository, the results with larger data sets from the NIPS 2003 feature selection challenge have also presented favorable results for the lazy strategy. For three data sets  X  Arcene, Gisette and Dexter  X  the best overall accuracies were reached by the lazy strategy. The data set Madelon seems not to bene fi t from any of the attribute selection strategies, and the Dorothea data set was the only one for which the eager approach achieved better accuracy values. These results indicate that the lazy strategy can lead to a better behavior also for larger data sets. 5. Conclusions
In this paper, we have proposed using a lazy strategy to perform attribute selection for the classi fi cation problem. Although our strategy is general, here we concentrated on a speci fi c version based on entropy ranking and compare it with the analogous eager strategy. Our experimental results show that by postponing the choice of attributes to the moment when a new instance is ready to be classi fi ed, we can in most cases improve the accuracy of classi fi cation, when compared with the attribute selection performed eagerly as a data preprocessing phase. We have also proposed a metric that can be used to predict if a speci fi c data set might take advantage of the lazy attribute selection approach.

The proposed lazy selection strategy is naturally able to work embedded in lazy classi fi ers. Thus, it is particularly appropriate for traditional lazy classi fi cation techniques, such as k-NN, for eager techniques that can be easily implemented in a lazy scenario, such as Naive Bayes, and for lazy versions of other eager techniques, such as lazy decision trees, lazy associative classi fi cation and lazy rule induction. In an extreme case, one could also consider using the lazy selection strategy in combination with a traditional eager technique. When an instance is presented for classi fi cation the most appropriate attributes would be selected in a lazy fashion and then used to construct a model for that instance using the eager technique. This would be computationally expensive because a complete model would be constructed for each instance, bu t could still be pro fi table given the potential gain in predictive accuracy associated with lazy selection as shown in th is paper (and reca lling that predictive accura cy is normally considered signi fi cantly more important than computational time in classi fi cation).

Even though the entropy is usually a good measure for assessing the relevance of an attribute, it has some drawbacks that could be avoided by employing other ranking measures for attribute selection, such as the gain ratio, chi-square or gini index measures. Therefore, we plan to conduct experiments with other measures in the near future. We also plan as future work to extend the lazy attribute selection model to fi lter strategies that evaluate subsets of attributes instead of weighting them individually, like Correlation-based Feature Selection [12] and Consistency-based Feature Selection [19]. Furthermore, we expect to be able to apply the lazy idea to a wrapper attribute selection technique, and evaluate its results and performance. Acknowledgement The development of this work was supported by CAPES, CNPq and FAPERJ research grants.
 References
