
Carnegie Mellon University of n people, but can only gather identity information when they w alk near certain sensors. Such Identity Management Problem [2], and is known to be N P -hard. Permutations pose a challenge for constraints associated with permutations.
 which factors as: clothing for each individual.
 previous timestep: P (  X  ( t +1) | z (1) , . . . , z ( t ) ) = P as being analagous to an Assumed Density Filter [6]. Symmetric Group . For permutations on n objects, the Symmetric Group will be abbreviated by S a distribution P is related to certain marginals of P . For references on this subject, see [3]. Definition 1. A representation of a group G is a map  X  from G to a set of invertible d matrix operators which preserves algebraic structure in th e sense that for all  X  representation matrices , and we will refer to d ial representation  X  we define the 1st order permutation representation of S maps a permutation  X  to its corresponding permutation matrix given by: [  X  For example, the permutation in S
The  X  entry, [  X  unordered permutation representation ,  X  pairs of objects, ( [  X  (  X  )] And the list goes on to include many more complicated represe ntations.  X   X  G . We write this as  X   X   X  .
 a representation  X  is reducible if there exist smaller representations  X  where  X  is defined to be the direct sum representation : matrices C for which C  X  1  X   X   X  C =  X  of copies of the irreducible  X  Describing the irreducibles of S that there is a natural way to order the irreducibles of S irreducibles in this order as  X  permutation representation (  X  formed by the first 3 irreducibles.
 always be assumed to be orthogonal. 3.1 The Fourier transform sinusoids by group representations.
 Definition 2. Let f : G  X  R be any function on a group G and let  X  be any representation on G . The Fourier Transform of f at the representation  X  is defined to be:  X  f of As in the familiar case, there is an inverse transform given b y: where k indexes over the collection of irreducibles of G .
  X  f distribution, then  X  P The Fourier Transform at  X 
Thus, if P is a distribution, then  X  P probabilities of the form P (  X  ( { i, j } ) = { k,  X  } ) . correspond to more complicated marginals. operation is called. Naively, the Fourier Transform on S Fast Fourier Transforms for functions on S discuss methods for obtaining the models in Section 7. 4.1 Fourier prediction/rollup We will consider one particular type of transition model  X  th at of a random walk over a group.  X  the convolution theorem (see also [3]): Proposition 3. Let Q and P be probability distributions on S be the function [ Q  X  P ] (  X  b Q
Then assuming that b P ( t ) b P 4.2 Fourier conditioning We showed earlier that the normalization constant P can be implemented by simply dividing each Fourier coefficie nt by the scalar present a convolution-based conditioning algorithm which we call Kronecker Conditioning , which, convolution, smears the information at an irreducible  X  Fourier transforming the pointwise product Our approach to Fourier Transforming the point-result of an inverse Fourier Transform. Hence, the goal will be to find matrices A  X  f ,  X  g ) such that for any  X   X  G , where A inverse Fourier Transform (Equation 2): Tr ( U  X  V ) = ( Tr U )  X  ( Tr V ) . Applying this to Equation 4, we have: where the last line follows by standard matrix properties. T he term on the right,  X  irreducibles. This means that if  X  transform C
The  X  symbols here refer to a matrix direct sum as in Equation 1, k indexes over all irreducible representations of S number of copies of each  X  the z find the Clebsch-Gordan series/coefficients for each pair of representations (  X  the Kronecker product inside Equation 5 using the Clebsch-G ordan series/coefficients yields the desired Fourier Transform, which we summarize here: ordered pair of irreducibles (  X  Fourier tranform of the pointwise product f g is: where A k X  See the Appendix for a full proof of Proposition 4. The Clebsc h-Gordan series, z important role in Equation 6, which says that the (  X  product at  X  So z Clebsch-Gordan coefficients. We will also make precomputed coefficients available on the web. Fourier transform of P only at irreducibles  X  while  X  X igglier X  functions require more. For example, when B = 3 , B is the set  X   X  conditioning is given in Figures 1 and 2.
 To combat this problem, we present a method for enforcing non nnegativity. Projecting to a relaxed marginal polytope The marginal polytope , M , is the set of marginals (rows and columns sum to one and all entries are nonnegative) , and satisfy lower-order marginal consistency (different high-order marginals are consiste nt at lower orders). the bandlimited function in M  X  which is closest to P ( t ) in an L we employ the Plancherel Theorem [3] which relates the L distance metric in the Fourier domain.
 Proposition 5. X to the linear constraints which define M  X  .
 We remark that even though the projection will always produc e a Fourier transform corresponding The Identity Management problem was first introduced in [2] w hich maintains a doubly stochastic idea, but formulated the problem in log-space. Figure 1: Pseudocode for the Fourier Prediction/Rollup Algorithm.
 Figure 2: Pseudocode for the Kronecker Conditioning Algorithm.
 that the Clebsch-Gordan coefficients, C marginals, which, as we show in our experimental results, is fundamental in practice. Willsky [8] was the first to formulate a nonabelian version of the FFT algorithm (for Metacyclic necessary given the n ! complexity of inference for the Symmetric group. drawn at random to be observed or swapped. For validation we m easure the L it is clear that our algorithm scales gracefully compared to the exact solution (Fig. 3(c)). called to allow for m 2 pairwise swaps amongst the m external tracks. The number of mixing events is approximately the same as the n umber of observations. For each discriminative appearance models, neither of which our pro blem afforded. As (Fig. 3(e)) shows, we developed the Kronecker Conditioning algorithm which pe rforms a convolution-like operation uation on data from a camera network shows that our methods ou tperform well when compared to ing a principled method for approximate inference for probl ems with underlying group structure. Acknowledgments This work is supported in part by the ONR under MURI N00014071 0747, the ARO under grant W911NF-06-1-0275, the NSF under grants DGE-0333420, EEEC-5 40865, Nets-NOSS 0626151 Guestrin was also supported in part by an Alfred P. Sloan Fell owship. We thank Kyle Heath for helping with the camera data and Emre Oto, and Robert Hough fo r valuable discussions.
