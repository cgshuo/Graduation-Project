 In this paper, we proposed a unified strategy to combine query log and search results for query suggestion. In this way, we leverage both the users X  search intentions for pop-ular queries and the power of search engines for unpopular queries. The suggested queries are also ranked according to their relevance and qualities; and each suggestion is de-scribed with a rich snippet including a photo and related description.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  query formulation, search process Algorithms, Design, Experimentation Query suggestion, query representation, log session mining
In Web search, users tend to use terms as queries but not natural language. And they seldom adopt advanced op-tions such as Boolean operators but would like to refine the queries themselves. Therefore, the query suggestion is very necessary to help users formulate queries. Actually, query suggestion has been considered as a must-have feature for search engines, as well as an active topic in academic re-search. Existing query suggestion approaches could be clas-sified into two categories based on the data they used. One is log-based [2, 3] and the other is search result-based [1]. Query log-based approach and search result-based approach have their own merits and weaknesses, which make them suitable for different kind of queries. This observation mo-tivates us to investigate a new method by integrating both of them in a real system.
To provide suggestions for both popular and unpopular queries, we introduce a unified feature representation for queries. Both the corresponding search results and query log sessions are leveraged as the context information. Then, to rank the suggestions, both the similarities and query fre-quencies are calculated, which are similar to dynamic ranks Figure 1: The flowchart of search-based query sug-gestion which is similar to web search. and static ranks (PageRank) of Web pages respectively. The process of query suggestion could be seen in Fig. 1.
In the following, we will introduce two kinds of context information: search results and query log sessions.
Instead of using whole Web pages, only the title and snip-pet of the Web pages from top search results are used to generate keywords. A query q i could be represented as: where r sr i,j represents the relevance between q i and the j phrase and M is the number of all possible phrases in a given language such as English:
Considering that some non-popular queries may have only few results, normalized frequency of the words are used in the left part, where p j is a word, D i,j is the number of occurrences of the considered word p j in the set of titles and snippets of current q i . Similar to the tf-idf weighting, we use the multiplication of phrase frequency and inverse query frequency to weight phrases. Q is the query set, SR i is the search result content corresponding to q i .
The other context is query log session. The queries co-occurring with the user submitted query in a certain number of query log sessions could be used as key phrases. Queries are related if they appear in a substantial number of user query log sessions (consecutive queries). Query log session-based algorithms leverage the knowledge of query usage his-tory from numerous users. Therefore, useful queries, which do not contain the original query strings, could be suggested. We also represent q i as: where M is the number of all possible phrases. Similarly its weighting function can be expressed as follows: where p j is a phrase, N i,j is the number of occurrences of p in the sessions of current query q i , Q is the query set, and log i is the log session content corresponding to query q i .
We can combine the two parts of phrases for a query q i together as: F i =  X   X F
We use a constant 0 . 5 for both  X  and  X  in the experiment.
For a new submitted query q sub , we can also represent this query through the method presented in Section 2.1 and the relevance score of a suggested query q sug for the user submitted q sub is: The left part of the score R represents the similarity be-tween query q sug and q sub , and the right part Q represents the quality (popularity) of query q sug . Similar to a search engine, both dynamic rank and static rank are considered and linearly combined as in Web search.
Users may not know the relationship between suggestions and original query. Describing the relationship between the suggested query and the input query may help users to fur-ther formulate their queries, as shown in Fig. 2.
Based on the proximity strategy for queries in search en-gine, we submit two query terms together to a search en-gine. We can also represent this joint query q joint (joint two queries with a blank) similarly. Then the relevance of snippets be expressed as follows: Figure 3: Comparison of the F-measures and satis-factions for different frequency groups and systems.
In the experiment, we used 3 month query log data of a commercial search engine in 2007. We divided the top queries into 7 groups based on their frequencies, and ran-domly sampled 10 queries from each group for testing. Four commercial search engines were selected for the comparison.
Seven subjects were invited to rate the suggestions with 5-point scores ( X  X recisely related X ,  X  X pproximately related X ,  X  X omehow related, but unclear or useless X ,  X  X pproximately unrelated X , and  X  X learly unrelated X ). The higher a score is, the more relevant the suggestion is. We randomly se-lected suggestions of 20 queries for each person. And sug-gestions of each query were labeled by at least two per-sons. We transformed the 5-point scores to precision by ( Score  X  1) / 4  X  100% and recall by N i /N T  X  100% , where N represents the number of queries in a group and N i the num-ber of queries with at least one suggestion. The F-measures of different groups are shown in the top part of Fig. 3. Our method consistently has the best performance.

High relevance doesn X  X  necessarily mean better user expe-rience. For example, for  X  X om Cruise X , suggestions such as  X  X om Cruise Picture X ,  X  X om Cruise Photos X , and so on are relevant but duplicate. Therefore, diversity and other prop-erties that can not directly reflected by relevance are also important for query suggestion. Therefore, we also conduct a blind test. We built a labeling tool with five columns each corresponds to a suggestion method and fit them into the columns randomly. For each method, only the top 8 sugges-tions were kept. Users were asked to rank the five results using score 1  X  5. The satisfaction ratio was then calcu-lated as ( Score  X  1) / 4  X  100% . The result is presented in the bottom part of Fig. 3. The performance of our method is quite good for both top queries and long tail queries. [1] M. Sahami and T. D. Heilman. A Web-based kernel [2] Z. Zhang and O. Nasraoui. Mining search engine query [3] Q. Zhao, S. C. H. Hoi, and et. al. Time-dependent
