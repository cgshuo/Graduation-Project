 In the aspect of a Demand-Side Platform (DSP), which is the agent of advertisers, we study how to predict the win-ning price such that the DSP can win the bid by placing a proper bidding value in the real-time bidding (RTB) auction. We propose to leverage the machine learning and statistical methods to train the winning price model from the bidding history. A major challenge is that a DSP usually suffers from the censoring of the winning price, especially for those lost bids in the past. To solve it, we utilize the censored re-gression model, which is widely used in the survival analysis and econometrics, to fit the censored bidding data. Note , however, the assumption of censored regression does not hold on the real RTB data. As a result, we further pro-pose a mixture model, which combines linear regression on bids with observable winning prices and censored regression on bids with the censored winning prices, weighted by the winning rate of the DSP. Experiment results show that the proposed mixture model in general prominently outperforms linear regression in terms of the prediction accuracy. Categories and Subject Descriptors: H.3.5 [Informa-tion Storage And Retrieval]: Online Information Services; I.2.6 [Artificial Intelligence]: Learning Keywords: Demand-Side Platform, Real-Time Bidding, Display Advertising, Learning with Partial Labels
In recent years, programmatic advertising has been taking over the online ad industry. To enable automatic selling and purchasing ad impressions between advertisers and publish-ers through real-time auctions, Real-Time Bidding (RTB) is quickly becoming the leading method according to the white paper by Google Inc. [8].

In contrast to the traditional online ad market, where a certain amount of impressions is sold at a fixed rate, RTB al-lows advertisers to bid each impression individually in real time at a cost based on impression-level features. In the RTB paradigm, publishers manage and sell their invento-ries of ad impressions via the Supply-Side Platform (SSP) while advertisers can bid and manage their ads across multi-ple inventory sources via the Demand-Side Platform (DSP). While an impression is loaded in a web browser, informa-tion about the user reading this webpage will be passed to the advertisers. DSP, on behalf of the advertisers, will help decide whether to bid the impression and set a bid to the ad exchange. Usually RTB takes the second price auction, where the advertiser with the highest bidder wins and pays the second highest bid. Interested readers are referred to the introduction and tutorials in [17] and [19] for more details about RTB.

Since a DSP is the agent of advertisers, it has to know how to compute the bid properly. The common paying models for the advertiser include cost-per-mille (CPM) for each im-pression, cost-per-click (CPC) for each click, and cost-per-action (CPA) for each conversion. Therefore, DSPs usually estimate the click-through-rate (CTR) and/or the conver-sion rate of the impression so that they can set a proper bid for advertisers to maximize their profits or maximize the rev-enue with a limited budget. From the standpoint of DSP in the RTB exchange, we propose in this paper to predict the winning price of the bid directly. The main reason is that the winning price is usually the same as the cost of winning the bid. There is usually a budget constraint for DSPs to bid the impressions, and the cost is hence an important fac-tor of the bidding decision making as stated by Zhang et al. [21]. Furthermore, the winning price is an indicator of the importance of an ad impression or the importance of a user in the market. The information of the market value might help DSPs predict the CTR and conversion rate. Our ex-periment shows that adding the winning price to the feature sets in the prediction of CTR can increase the AUC value from 0.708 to 0.733 1 .

Apparently, DSPs meet a grand challenge to predict the winning price. Ghosh et al. [7] first described that the partial observable exchange makes them hard to explore the pattern of winning prices. According to the mechanism of the modern RTB display advertising, the winning price is only observable for the DSP who wins the bid. For the lost bids, DSPs can only observe the lower bound, which is their own bidding price. Moreover, the modern RTB process introducing the soft floor price makes the winning price of some winning bids also unobservable, of which more details
The data of the experiment is the day 2013-06-07 of the dataset iPinYou session 2. The details of the dataset and the features are shown in Sec. 4.1. are given in Sec. 2. In such cases, only the upper bound or the lower bound of the winning price, which is the paying price of the bid, is observed. This kind of partially observed winning price is called censoring , and is handled in many fields such as survival analysis [12] and econometrics [15].
To solve the problem of predicting the winning price for a DSP, say D i , we propose to learn a mixture model of winning price from historical bids, where the winning prices are either observable or unseen for D i . Our rationale is as follows. Intuitively, we can train a linear regression model based only on the bids, of which the winning price is ob-servable to D i (or for simplicity, we call these bids winning bids of D i hereafter). Apparently, the model could be over-fitting to these limited winning bids. As a result, we further propose to use the censored regression model [9] to consider also the censored data, which are the bids with unobservable winning prices (or we call them losing bids of D i hereafter for simplicity). However, the real bidding data in fact vi-olate an assumption of the censored regression model: the pattern of winning prices on observed data and that on cen-sored data should be consistent. We will show this violation in Sec. 4.2. To remedy the violation, we propose to mix the result of linear regression model and that of the censored regression model, weighted by the winning rate of D i on a bid. This is because the linear regression model works better on the winning bids in general and the censored regression model takes the censored information into account. There-fore, if the winning rate, which is the chance that D i wins the bid, is higher, then the linear regression model accounts for more percentage in the mixture model, and vice versa.
Our contributions can be summarized as follows. We are the first, to our knowledge, to predict the winning price on the censored data by applying the censored regression model. Furthermore, we propose an approach to predicting the winning rate for a DSP on a bid and leverage it to mix the results of the linear regression model on winning bids and the censored regression model. We conduct a series of experiments on real RTB data sets from two existing DSPs. Experiment results show that our proposed mixture model outperforms the baseline methods in all cases in terms of having the smaller predicting errors. This shows the effec-tiveness of our proposed model in practice.

The rest of the paper is organized as follows. Section 2 reviews the auction process of RTB and describes the chal-lenge of modeling winning prices. Section 3 presents our methodology to predict the winning price. The experiment results are provided in Section 4. We give a brief litera-ture survey related to our topic in Section 5, followed by the conclusion in Section 6.
In this section, we describe the mechanism of modern RTB and define the winning price we discussed in this paper. Also, we show the availability of the true winning price in different bidding cases and thus the challenges of modeling it.
We only focus on the interaction between a DSP and the ad exchange in the RTB process. Suppose we are the DSP and our bidding price is b . The winning price we discuss here refers to the price value that we, as a DSP, have to offer at least to win the bid. In the current RTB process, the publishers can set a soft floor price and the hard floor price for each ad impression. If all the bids from all DSPs are below the hard floor price, the impression will fail to be sold. In this case, the winning price is the hard floor price set by the publisher of the ad impression. On the other hand, if there is at least one bidding price greater than the hard floor price, the winning price is then the highest bidding price from all other DSPs.

Usually RTB runs a second-price auction. Suppose the highest bidding value of all other DSPs is b 2 and we win the bid, then we only need to pay b 2. Thus the winning price is b 2. In practice, however, the winning price is affected by the soft floor price set by SSPs at the same time. If b is smaller than the soft floor price of the ad impression, RTB will ask the winner to pay b . If b is larger than the soft floor price of the ad impression and b 2 is smaller than the soft floor price, RTB will ask the bidder to pay the soft floor price instead of b 2. In this case, the winning price is left-censored , which means we only know an upper bound of the winning price. If we lose a bid, the winning price is not available and generally right-censored , i.e., our bidding price is a lower bound of the winning price. The winning price of each bid can be known by us only if the RTB process makes the bidding price public or every DSP makes its own bidding public. In summary, the auction process and the resulting data censoring are shown in Fig. 1.
The goal of this paper is to learn the winning price, in the aspect of a DSP, with historical RTB bids and to deal with the problem of various winning price censoring at the same time. We aim to propose a machine-learning based model that can help a DSP to predict the winning price and thus decide the bidding price.
In this section, we describe the proposed method to pre-dict winning price. We state the true, but unavailable in practice, model of the winning price and how we approxi-mate it with a statistical model in Sec. 3.1. The modeling of the censored data is introduced in Sec. 3.2. We show how and why to use the estimated winning rate to mitigate the impact of the unrealistic assumption in Sec. 3.3.

For ease of presentation, we assume that all winning bids are observed and all losing bids are right-censored in the following content. We will also show how to extend our model to left-censored data.
Suppose there are J DSPs, D 1 ,...,D J , in the RTB mar-ket and without loss of generality the following process is described from the standpoint of DSP D 1 . For the i th bid, we denote the true winning price by v i , the observed one by w , and the bid placed by D 1 by b i . If D 1 wins the bid, then w i = v i . Otherwise, w i =0.

In practical RTB, SSPs will deliver several features of the ad impression for sale to all DSPs with the bid request, which are denoted by x 1 i here. Of course, DSPs themselves can collect features other than x 1 i of the bid on their own and do not make them available to others. We denote the features collected and observed only by D 1 as x 2 i and features collected by other DSPs and unknown to D 1 as x 3 i example, according to the report of iPinYou [21], the feature User Tags is only observed by iPinYou. Hence this feature belongs to x 2 i for iPinYou and is deemed as x 3 i by other DSPs in the market.

In the bidding process, each DSP offers a price according to its bidding strategy function f j (  X  ), which could be either deterministic or stochastic, for D j and the available features. Therefore, the ad exchange receives bids f 1 ( x 1 i ,x 2 ..., and f J ( x 1 i ,x 3 i ). Suppose the hard floor price of the pub-lisher, which is the webpage owner of the auctioned impres-sion, is denoted as f p ( x 1 i ) because the publisher is one of the public feature. Then we can model the true winning price of the i th bid for D 1 as D 1 will win the impression if it offers the price higher than v .

In reality, x 3 i , and thus v i in Eq. (1), is unknown to D We propose to use a linear regression model to approximate the true winning price as follows. D ,  X  T x i captures the expected value of the winning price, and  X  i is assumed to be an independent and identically dis-tributed ( i.i.d. ) and normally distributed random variable with zero mean and  X  2 variance. With Eq. (2), we can pre-dict the winning price v i based on the features x i and the vector  X  . Therefore, we call  X  an estimator in the following content.

Although the linear regression model with i.i.d. normal distributed assumption of  X  i may not be the best fit for predictive analysis, as we can see, this model is generally elegant and effective to capture the censored information, which we will discuss in the next subsection, compared to other sophisticated model.

We use the negative log-likelihood function to measure how good Eq. (2) can approximate the observed winning price: where W represents all the historical bids that D 1 wins and thus it observed the true winning prices.  X  is the probability density function (pdf) of the standard normal distribution. The vector  X  lm can be learned from historical bidding data by finding the value that minimizes Eq. (3). In Eq. (3), the estimator  X  lm learns the winning bids of D . However, we may lose too much winning price infor-mation from those bids that D 1 lost. Second, the winning price from the observed data usually is lower than the win-ning price of the censored data as shown in Sec. 4.1, and the estimator  X  lm hence usually underestimates the winning price on the censored data. Therefore, in this section we de-scribe how to apply the censored regression model to explore the information from those losing bids.

The linear regression described in Eq. (2) predicts not only the winning price but also the winning rate. That is, the probability that D 1 will win the i th bid, can be derived from Eq. (2) as follow.
 where  X  is the cumulative density function of the standard normal distribution. Note that one can modify Eq. (4) to the left censoring case by changing  X  &lt;  X  to  X  &gt;  X  properly. There-fore, the censored regression model can be modified to in-clude the unobserved winning price due to the soft floor price discussed in Sec. 2.
 The idea of censored regression is to combine Eq. (3) and Eq. (4). Eq. (3) measures how well the model in Eq. (2) approximates the observed data and Eq. (4) measures how well the model in Eq. (2) approximates the censored data. Following the principle of maximum likelihood and the Tobit model [16], the estimator  X  clm is learned via minimizing the negative log-likelihood function as follows.

X where W represents the set of all the winning bids and L represents the set of all the losing bids of D 1 , respectively.
Apparently, Eq. (5) is a mixture of winning price predic-tion in Eq. (2) and the winning rate prediction in Eq. (4). Because the censored regression learns from more data com-pared to the linear regression, which learns from the winning bids only, the estimator of the censored regression  X  supposed to have a smaller variance compared to the esti-mator  X  lm .

However, there is an important assumption for deriving the likelihood function in Eq. (5): the pattern of the winning prices on the observed data should be the same as that of the winning prices on censored data. In Eq. (2), the estimator  X  is a realization of the pattern of winning price because  X  describes the changes of winning price after changing the features x i . More specifically, the assumption for deriving the likelihood function in Eq. (5) is that  X  estimator on the observed data and that on the censored data are the same. If these patterns are different, the estimator  X  clm becomes a mixture of two different  X  s. Therefore, the estimator  X  is biased when it is used to predict the winning price on the observed data. Similarly, the estimator  X  lm is biased when it is used to predict the winning price on the censored data.
In practice, the estimator  X  lm usually underestimates the winning price, and  X  clm usually provides higher estimation than  X  lm does because it learns the censored data.
We will further show in Sec. 4.2 that the patterns of the winning price on the observed data are different from those on the censored data in practice. Therefore, it is hard to conclude that  X  clm will be better than  X  lm or not because the assumption is invalid. To solve this problem, we propose a mixture model in the next subsection.
We introduce the censored regression to learn the pat-tern of winning price from both observed and censored data. However, the patterns on the observed and censored data are inconsistent, which may violate the assumption of the censored regression model. Therefore, in this section, we propose a mixture model to address the effect of mixing dif-ferent patterns.

The winning rate prediction provides the likelihood of the bid whether it is going to be observed or not. Therefore, we use the predicted winning rate as the weight to mix the esti-mator  X  lm and the estimator  X  clm . That is to say, we predict the winning price according to the following equation.
Unlike that of the estimator  X  clm , the performance of the estimator  X  mix is better than that of the estimator  X  lm the winning rate prediction is accurate enough. Our reasons are as follows. If the winning rate prediction is absolutely correct, i.e. the winning rate is 1 on the observed data and 0 on the censored data, the estimator  X  lm outperforms on the observed data and the estimator  X  clm outperforms on the censored data, the performance of the estimator  X  mix will be the same as that of  X  lm on the observed data, and will be the same as that of  X  clm on the censored data. That is to say, the winning rate helps  X  mix to pick the better estimator.
Note that, in practice, the winning rate prediction will not be absolutely correct and the estimator  X  clm might not out-perform  X  lm on the censored data. Also, the winning price on the censored data is usually higher than the winning price on the observed data because these bids are lost due to the bidding price is not high enough. Therefore,  X  lm underesti-mates the winning price at censored data while  X  clm provides a higher estimation. If  X  clm underperforms, it suggests that  X  clm overestimates too much. Interestingly,  X  mix aggregates the merits of these two estimators and provides a better esti-mation.  X  mix gives higher estimation than  X  lm does because  X  clm is higher and  X  mix gives more conservatively lifting of the estimation compared to  X  clm .

We will compare these estimators  X  lm ,  X  clm , and  X  mix all data, observed data and censored data in Sec. 4.3 and Sec. 4.4.

To realize the mixture model, however, we understand that Eq. (4) is not directly applicable to predict the winning rate P ( v i &lt; b i ). First, the accuracy of Eq. (4) depends on the distribution of the random variable v i . Therefore, the accuracy is affected by the accuracy of the winning price pre-diction. Second, predicting winning rate with Eq. (4) with the estimator  X  lm or  X  clm might introduce hidden depen-dency because we already mix them to derive the estimator  X  mix . In view of these, we do not use the model in Eq. (4) directly.

Instead, we use the logistic regression to predict the win-ning rate used in Eq. (6) The logistic regression describes the winning rate based on the features directly, so it is not derived from Eq. (2). There-fore, it is not affected by the accuracy of the winning price and it does not introduce any hidden dependency from any estimator derived from Eq. (2).
In this section, we shall address the following questions. (1) Are the patterns of the winning price on the observed data and those on the censored data different? (2) Does the censored regression model have better performance on predicting winning price compared to the linear regression model trained from only the historical winning bids? (3) Does the proposed mixture model successfully mitigate the violation of the censored regression model and leverage the results of both linear and censored models?
For the following experiments, we use two real datasets, the iPinYou RTB data set 2 and the Bridgewell dataset Since both the two DSPs can only provide the winning prices of their own won bids, we simulate the bidding results of both winning and losing bids as follows. For each historical bid, we divide the bidding price originally offered by each DSP by a factor as the new bidding price. If not specified, the factor is set to 2. The new bidding price is compared to the original winning price to produce the simulated winning (new bidding price &gt; original winning price) and losing bids. As such, we can always have the ground truth of the winning price of each bid and the pattern of the winning prices will not vary. Note that winning bids and observed data are used interchangeably, and so does losing bids and censored data . Although the winning price is obtained from our simulation results instead of randomly drawn from the winning prices in the real market, we believe the experimental study of the winning price pattern conditioned on the simulated winning and losing bids reveals reasonable trends accordingly. We release the codes for experiments on the iPinYou dataset on https://github.com/wush978/KDD2015wpp .

There are three seasons of RTB records on the iPinYou dataset. We use the data of season 2 and season 3 because the private feature User Tags , which corresponds to x iPinYou, is not provided in season 1. All the features we used from the logs of iPinYou are shown in Table 4. These features are categorical and converted to binary features via hashing trick proposed by Weinberger et al. [18]. This kind http://data.computational-advertising.org/ The dataset is sampled from the real RTB logs from Bridgewell Inc. ( http://www.bridgewell.com.tw/index. html ) , which is one of DSPs in Taiwan. of feature extraction is widely used in the literature such as He et al. [10], Zhang et al. [21] and Chapelle [3]. The hash size in the experiments is set to 2 20 .

The proposed mixture model of the winning price requires the winning rate as input which is predicted by the simulated bidding result. According to Zhang et al. [20], the expected KPI, which is defined according to different business models and usually is the expected CTR or the expected conversion rate, is an important feature for predicting winning rate. As a result, we put the expected CTR into the feature set x . Because the iPinYou dataset only provides the log of click events instead of the expected CTR directly, we estimate the CTR on our own by the logistic regression as stated by Zhang et al. [21]. The accuracy of our expected CTR is shown in Table 5. Compared to the benchmark reported by Zhang et al. [21], the total AUC of our model is only 0 . 0009 lower than theirs. Hence, the expected CTR is good enough for being a part of x .

To simulate the online environment, we predict CTR and the winning rate in an online fashion. After receiving a bid request, the model predicts the corresponding CTR and the winning rate immediately. Then we check whether the impression that occurs ten minutes ago is clicked or not and update the CTR model. Similarly, we check the result of bidding that occurs one minute ago and update the winning rate model. The updated model takes effect immediately. Both the CTR and winning rate models are optimized by FTPRL proposed by McMahan et al. [13].

There are 9-day logs in the Bridgewell dataset. These logs record the bidding history for a specific advertiser. Un-like the iPinYou dataset, there are real expected KPI in the dataset, so we estimate the winning rate according to the features and expected KPI directly. The features we used are similar to those in the iPinYou dataset. Because there are some extremely high winning prices in the Bridgewell dataset, we convert the winning prices to a logarithmic scale before using them.

The data are split by the day according to the occurrence time of the bid request. Table 1, Table 2 and Table 3 show the basic statistics of the dataset, where each row shows the statistics of a specific day. In these tables, # of bids and # of win. bids are the count of total bids and simulated winning bids respectively. WR is the resulting simulated winning rate which equals # of win. bids / # of bids. EWR is the expected winning rate according to our winning rate model in Eq. (7). WR AUC is the Area Under Curve (AUC) of our winning rate model based on our simulated bidding results. Avg. WP , Avg. WP on W , and Avg. WP on L are the average winning price on all bids, the winning bids, and the censored bids, respectively.

It can be seen that the characteristics of the three datasets are very different. First, the winning rate varies significantly among three tables. Also, the proportions of the winning bids to the total bids are also different. The number of winning bids is almost equal to the number of losing bids on the Bridgewell dataset while the number of winning bids is around 4.88 times as many as the losing ones on the iPinYou Season 2 dataset.

Example Feature Name 183.18.197.* IP 216 Region 236 City 2 AdExchange 3d68edb4b8f5bba8bea6782e33c8e228 Domain e63cfda49ec2a36a0cafcd646906227b URL 3844656199 AdSlotId 250 AdSlotWidth 250 AdSlotHeight OtherView AdSlotVisibility
Na AdSlotFormat 7321 CreativeID 6 weekday 02 hour 2259 adid 10684,10102,10006 usertag Table 4: Example features of the iPinYou dataset [21].
To answer question (1), we observe the patterns of the winning price in two ways. First, we read the average win-ning price on both winning and losing bids as shown in Ta-ble 1, Table 2, and Table 3. We can see that the average winning prices on losing bids, which are the values in col-umn Avg. WP on L , are usually higher than the average winning prices in column Avg. WP on W in Table 3. This Table 5: The performance of our CTR model of the iPinYou dataset. shows one difference of the patterns of the winning price on the winning and the losing bids.

Furthermore, we use the linear regression model and ob-serve the estimator learning the winning bids only, denoted by  X  w lm , and the estimator learning the losing bids only, de-noted by  X  l lm , by minimizing Eq. (3). Because there are too many features, we minimize Eq. (3) numerically via the L-BFGS-B algorithm proposed by Byrd et al. [2] with L 2 reg-ularization. The parameter of L 2 regularization is selected via progressive validation on the winning data. Note that the estimator  X  l lm is not available in reality because the win-ning prices on the losing bids are unknown to the DSP. Each estimator learns one day of the data and its performance is tested using the data in the very next day.

The Mean Squared Error (MSE) between the true win-ning price and the estimated winning price evaluated on the winning bids of each day by either  X  w lm learning from the winning bids or  X  l lm from the losing bids in the previous day are shown in Fig. 2. We can see that  X  w lm outperforms  X  in terms of having smaller MSE. In contrast to the result of Fig. 2,  X  l lm has smaller MSE on the losing bids compared to  X  lm as shown in Fig. 3. In contrast,  X  l lm outperforms.
The results here also show that the winning price patterns on the winning and losing bids are different, otherwise the results of the two estimators should be similar. To amelio-rate this effect, we consider the interaction [1] between the estimated winning rate and the features used to train the model. In other words, the model is trained by considering both the original features, i.e., Table. 4, and the features after interaction with the estimated winning rate. In this way, the different patterns of winning and losing bids can MSE Figure 2: Mean Squared Error (MSE) of linear re-gression on the winning price based on the winning bids,  X  w lm , and based on the losing bids,  X  l lm result is evaluated on the winning bids. thus be differentiated with the aid of the estimated winning rate.
To answer question (2), we conduct experiments to com-pare the estimator from the linear regression  X  lm on the winning bids only, and the estimator from the censored re-gression model  X  clm on both the winning and losing bids. Note that we cannot see the true winning price of the losing bids thus they are censored.

It is difficult to solve Eq. (5) with the parameter  X  numer-ically. The  X  usually diverges to infinity. In the experiment, we treat  X  as a tuning parameter and replace it heuristically with the sample standard deviation of the observed winning price. The optimization function is solved numerically via L-BFGS-B algorithm with L 2 regularization. The parame-ter of L 2 regularization is the same as the one of  X  lm . Then we calculate the MSE value of them on the losing bids of the same day to see the performance of the estimators at the censored data.

In Fig. 4, we can see that  X  clm outperforms  X  lm by having smaller MSE values. To explore the reason, we compare the average estimated winning price and the average true winning price at the censored data.

The average winning prices from different estimators are shown in Fig. 5. y true represents the average true winning price, and y lm , y clm , and y mix are the average estimated winning price by  X  lm ,  X  clm , and  X  mix , respectively. The censoring in the second price auction is due to high winning price. Hence, the winning price at observed data is usually lower than at censored data as shown in Table 1, Table 2, and Table 3. Consequently, the average winning price from  X  lm , i.e. y lm , is lower than the true average winning price, i.e. y true , in all experiments as shown in Fig. 5. MSE Figure 3: Mean squared error (MSE) of linear re-gression on the winning price based on the winning bids,  X  w lm , and based on the losing bids,  X  l lm result is evaluated on the losing bids.

On the other hand,  X  clm learns from the censored data, and it hence has higher average estimated winning prices compared to  X  lm as shown in Fig. 5. However, it is hard to tell the relationship between the average estimated win-ning price from  X  clm and the average true winning price. Fig. 5 suggests that different data sources have different re-lationships. On the dataset iPinYou Season 2 and season 3,  X  clm still underestimates the winning price on the cen-sored data on average. Therefore, it is not surprising that the MSE value of  X  clm is better than  X  lm because the latter gives even lower estimation on average.  X  clm overestimates the winning price on the Bridgewell dataset sometimes. Be-cause the difference between y clm and y true is lower than the difference between y lm and y true ,  X  clm has smaller MSE than  X  lm does in Fig. 4.

In summary, the overall MSE value of  X  clm is lower than that of  X  lm . This result depends on the bias, i.e., the dif-ference between the predicted winning price and the true winning price, of  X  clm on the censored data. It turns out that the predicted winning price of  X  lm is lower than the true one and the winning price estimated by  X  clm is higher than the one predicted by  X  lm .
To answer the question (3), we conduct experiments to compare estimators  X  lm ,  X  clm and  X  mix at the same time. All of them learn from the data of a specific day as a train-ing day via minimizing the objective function. The detailed optimization is the same as Sec. 4.2 and Sec. 4.3.

The results are shown in Fig. 6, Fig. 7 and Fig. 8. A very interesting point is that the performance of  X  mix is close to the better one of the other two estimators  X  lm and  X  Sometimes,  X  mix is the best of the three.

Fig. 5 shows that the value of estimated winning price by  X  mix is between that by  X  lm and that by  X  clm . In all exper-MSE Figure 4: Mean Square Error of the winning prices on the losing bids. The evaluation is conducted on the same day of the training data. iments, the bias, which is observed via the difference of the average predicted winning price and average true winning price as shown in Fig. 5, of  X  mix on the censored data is less than  X  lm . The bias of the  X  mix exceeds  X  lm only if the  X  extremely overestimates the winning price on the censored data. It is not likely to happen in the real case because  X  also learns from the observed data whose winning prices are lower. As shown in our experiments, there is no  X  clm which extremely overestimates the winning price on censored data.
Although the characteristic of the dataset and the per-formance of the predicted winning rate, which are shown in Table 1, Table 2, and Table 3, are different, the results of our model are still robust compared to the linear regression, i.e. the model ignoring the censored data. If we change the ratio of the bidding price at the beginning of the simulation,  X  mix consistently outperforms  X  lm as shown in Fig. 9.
In summary, our experiments show that  X  mix outperforms  X  lm . We therefore conclude that the proposed framework in-deed enhance the prediction of the winning price. The main reason is that the  X  lm underestimates the winning price on the censored data and the proposed model lifts the estima-tion on the censored data properly. In addition, when com-pared to the censored regression, our model is much more robust.
While many existing reports study good bidding strategies for maximizing the revenues of either DSPs or SSPs [11, 6, 5], the issue of predicting the winning price of a bid has not been well explored yet. Zhang et al. [20] proposed a framework to optimize the bidding strategy for DSPs, of which the cost of a bid, usually the same as the winning price, is a required input. As the winning price is not available in many cases, they used the bidding price as the upper bound of the cost instead. Ghosh et al. [7] proposed adaptive bidding algo-rithms under a fixed budget with user-specified constraints. Figure 5: The average winning price estimated by different models on the losing bids.
 They considered both the settings with fully and partially observed winning price information. For the latter case, they simply assumed the winning price was drawn i.i.d. from a CDF P , as their main goal is to win more bids when con-trolling the cost. All the above reports justify that knowing the winning price in RTB is important in practice. In this study we aim to further provide a systematic method based on machine learning and statistics to predict this value.
Cui et al. [4] studied the prediction of winning price, but on the seller side. Unlike Ghosh et al. [7] modeling the winning price by i.i.d. CDF P , they modeled the winning price with the mixture-of-log-normal distribution on various targeting attributes. Since their study target is for SSPs, they did not address challenges of data censoring. Also, they paid attention to the global distribution of the winning price while we focus on the prediction of the winning price conditioned to the features, i.e., the case when only some features are available for DSPs.

Reisinger and Driscoll [14] studied the publisher-advertiser information asymmetry for SSPs. Their future work in-cludes using the censored regression to construct the full bid distribution for SSPs because the floor price can be treated as dynamic left-censoring . Our work can be regarded as similar to their future work, but we are studying the bid distribution conditioned on the partially observed features and designing the prediction method for DSPs explicitly.
To our knowledge, we are the first to predict the winning price on the DSP side and with the censored data. We study the censored regression and extend it heuristically for the RTB data. We show that the accuracy of the winning price model can be enhanced prominently by cooperating with the censored information.
In this paper, we studied the prediction of winning price for DSPs in the RTB process when only partial features and only the winning price of historical winning bids were MSE Figure 6: Mean squared error of the predicted win-ning price. able to be observed. We showed that the prediction per-formance was improved by taking the censored information into account. Because the patterns of the winning price on the observed data and unobserved data are different in RTB, which violates the assumption of censored regression, we further proposed a mixture model to combine the power of linear regression on observed data and censored regres-sion on both observed and censored data. Since the linear regression model works better on the winning bids in general and the censored regression model takes the censored infor-mation into account, we proposed to weight the two models according to the winning rate, which shows the probabil-ity that a DSP wins a bid. If the winning rate was higher, the linear regression model accounted for more percentage in the mixture model, and vice versa. From experiments on three real RTB datasets we showed that the proposed mixture model outperformed the model with observed data only.

For future work, we will seek finer and more sophisticated models that can better fit the censored winning price. Also, we would like to study the effect of introducing winning price prediction on real applications of RTB and online advertising such as designing bidding strategy, exploring the potential of new campaigns, and estimating the CTR and the conversion rate.
This study was supported in part by the Ministry of Sci-ence and Technology of Taiwan, R.O.C., under Contracts MOST103-2221-E-001-006-MY2 and MOST103-3111-Y-001-025. The authors would also like to thank Bridgewell Inc. for providing the RTB logs in this work. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. MSE Figure 7: Mean squared error of the predicted win-ning price on the winning bids. [1] T. Brambor, W. R. Clark, and M. Golder.
 [2] R. H. Byrd, P. Lu, J. Nocedal, and C. Zhu. A limited [3] O. Chapelle. Modeling delayed feedback in display [4] Y. Cui, R. Zhang, W. Li, and J. Mao. Bid landscape [5] J. Feldman, M. Henzinger, N. Korula, V. S. Mirrokni, [6] J. Feldman, A. Mehta, V. Mirrokni, and [7] A. Ghosh, B. I. Rubinstein, S. Vassilvitskii, and [8] Google. The arrival of real-time bidding. 2011. MSE Figure 8: Mean squared error of the predicted win-ning price on the losing bids. Figure 9: Mean square error of the predicted win-ning prices with different winning/losing bid ratio on the iPinYou dataset on 2013-10-20. [9] W. H. Greene. Censored data and truncated [10] X. He, J. Pan, O. Jin, T. Xu, B. Liu, T. Xu, Y. Shi, [11] R. M. Karp, U. V. Vazirani, and V. V. Vazirani. An [12] J. Klein and M. Moeschberger. Survival Analysis: [13] H. B. McMahan, G. Holt, D. Sculley, M. Young, [14] J. Reisinger and M. Driscoll. Pricing externalities in [15] W. Schnedler. Likelihood estimation for censored [16] J. Tobin. Estimation of relationships for limited [17] J. Wang, S. Shen, and S. Seljan. Real-time bidding: A [18] K. Weinberger, A. Dasgupta, J. Langford, A. Smola, [19] S. Yuan, J. Wang, and X. Zhao. Real-time bidding for [20] W. Zhang, S. Yuan, and J. Wang. Optimal real-time [21] W. Zhang, S. Yuan, J. Wang, and X. Shen. Real-time
