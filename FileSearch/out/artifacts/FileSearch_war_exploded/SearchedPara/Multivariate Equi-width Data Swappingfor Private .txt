 Private data publication has been widely studied in statistical disclosure control and privacy preserving data mining areas. The core task for a qualified publi-cation is to disturb data in a way that does not lead to disclosure of sensitive information, but maintains data utility as much as possible. Many existing stud-ies [1,10,7,11] are focused on developing algorithms performing univariate data perturbation, which operates each variable in a dataset individually. However, many real-world applications with multivariate data are required to guarantee data utility of several variables (or attributes), which have closer correlations than with others. This paper discusses the utilisation of data swapping for mul-tivariate data perturbation.

As the name implies, data swapping is to disturb a dataset by exchanging values of sensitive variables among data tuples. This method is a natural so-lution to protect confidential information from identity disclosure [10,7], while maintains lower-order statistics of a dataset with its value-invariant property. Equi-depth swapping is a widely used solution to guarantee each bin contain-ing roughly the same number or frequency of data tuples, so as to provide the same level of privacy protection for all entities. However, this approach intro-duces the computational complexity as O ( n 3 ) ,where n is the size of dataset in multivariate scenarios. In addition, it performs ineffectively on preserving data utility for distance-based applications, such as data mining on interval data and multivariate density estimation with histogram, where bins are determined by their relative distances ra ther than relative orders.

This paper considers the use of data swapping with equi-width partitioning, which ensures the width of each bin approximately the same, to overcome the drawbacks above. However, Equi-Width Swapping (EWS) can preserve data privacy at the similar level as EDS for large datasets. It is motivated by the idea that, the value-invariant method hides the detailed partitioning information such as swapping distance. Our analysis shows that, this approach can achieve good tradeoff between data utility and privacy.

The remainder of this paper is organized as follows. Section 2 presents a brief overview of the related literature. In Section 3, we provide algorithms for both MEDS and MEWS. Section 4 presen ts an exclusive analysis on privacy for the methods above. Section 5 discusse s experimental results to justify the effectiveness of MEWS. Finally, we c onclude this paper in Section 6. Data swapping was first introduced in [4] as an efficient value-invariant approach for statistical disclosure control, and the following work [9] extends the idea to preserve numerical data. Moore et a l. [8] described a popular local swap-ping method based on equi-depth partitioning with univariate ranking. In this method, a term called swapping distance defines the depth of each swapping domain, i.e., the number of tuples in each interval for swapping. Then it ranks and localizes data tuples in the light of a specified variable in each iteration, and then swaps candidates in each interval randomly. However, this study is limited with its assumption that the data is uniformly distributed.

The work in [3] follows the idea of ranking but performs random sampling as localization. Although it provides good maintenance of correlations among variables, this technique has been proved highly inefficient [6] and provides prac-tically no protection from a ttacks. A recent work [11] pro poses a swapping-like method named data shuffling, which is based on joint and/or conditional distri-bution of variables in the original dataset, in order to minimize disclosure risk of sensitive data. A comprehensive study of data swapping and its applications can be found in [5]. In this section we first introduce some basic notation that will be used in the remainder of this paper. Let X = { x 1 ,x 2 , ..., x n } be a dataset. Let A de-note the set of all attributes { A 1 ,A 2 , ..., A m } and x [ A i ] denote the value of attribute A i for a tuple x . We define swapping set as a set of attributes {
A i , ..., A j } X  A ( i&lt;j ) for simultaneous perturbation , denoted by S ,and let S represent the set of all other attributes. Then we use x [ S ] to denote a Algorithm 1. Multivariate EDS x onto the attributes in S . Without loss of generality, we assume there is only one swapping set containing the first p attributes A 1 ,A 2 , ..., A p , and it is not a unique set to identify individuals. 3.1 Multivariate EDS This section presents a heuristic method for multivariate equi-depth swapping. The idea is to cluster tuples based on Euclidean distance between each other and then swap attribute values in the swapping set simultaneously. We define k = As the assumption that the swapping set consists of the first p attributes, the swapping distances for these attributes are equal, i.e., k [ A 1 ]= k [ A 2 ]= ... = k [ A p ]= k . Algorithm 1 describes the process o f perturbing a dataset according to its swapping set. The perturbation for attributes in S is omitted here since it is exactly the same as in univariate EDS [7].

In Algorithm 1, the computational complexity of computing the most distant tuples x r and x s is O ( n 2 ) . The swapping process only costs O ( k 2 ) .Thereare # EDS is O ( n 3 k ) ,where k is the swapping distance. In real-world cases, k n ,thus the complexity is O ( n 3 ) finally. We can improve this algorithm by calculating a symmetrical distance matrix in advance. This will reduce the time complexity to while the original method only has O ( n ) . As the size of data set growth, the distance matrix becomes impractical to be stored in memory.

Since MEDS only considers the relative ordering among tuples for clustering, it inherently leads to errors in many distance-based applications, such as data mining on interval data and density estimation with histogram. These require a perturbation method to maintain not only the ordering but also quantitative properties of the bins including bin width, distance between bins and relative distance between tuples. Moreover, this method only guarantees data utility in bins formed with the p variables in swapping set. That is, if a data user is willing to explore the published data in lower-dimension (e.g., a subset of swapping set), Algorithm 2. Multivariate EWS it may cause unacceptable errors. In the fo llowing section, we shall discuss a multivariate swapping technique to improve data utility in the cases above while preserving data privacy. 3.2 Multivariate EWS To get around of the deficiencies of MEDS , we propose Algorithm 2 by redefining t [ A i ] is the width on A i . It implies that the value change for each swapping candidate is at most t . Moreover, to split a dataset with continuous attributes, every bin resulted by univariate partitioning will not be empty if partition degree is larger than a threshold. However, for a multivariate partitioning, many bins may not hold any tuple even with a very small threshold. These empty bins have no use for analysis of utility and privacy. Therefore, we modify the definition of partition degree [7] for MEWS as follows: Definition 1 The partition degree is the number of non-empty bins formed by splitting the original dataset, denoted by d  X  N .
 Let d total denote the total number of bins and for a partitioning PT i ,wehave d of allocating process is O ( n ) . The worst case of the iteration step is when d  X  1 bins contain one tuple each, and the other bin contains the rest n  X  d +1 tuples. Thus, the computational complexity of Algorithm 2 is O ( dn ) . While in real-world applications, d n ,wehavethecomplexityas O ( n ) .
 The Pruning Scheme. Although the idea of Algorithm 2 is straightforward, it is even challenged by selecting swapping distance t . Theoretically, there exist many partitionings with small differences are duplicate and meaningless. We introduce the Pruning scheme that determines a proper domain of swapping distance efficiently.
 Step 1: Calculate or assign a upper bound t ub for t ;
Step 2: Compute a lower bound t lb for t ; Step 3: Reduce the number of partitionings to a finite number.
 The first step guarantees data utility of a published dataset, since a too-large t can make perturbed data useless due to its unacceptable bias. Step 2 considers data privacy of a published dataset. The idea behind is to ensure that each non-empty bin must hold at least two tuples for data exchanging. The final step is to further remove the redundant candidates. we define Minimal Depth Bin (MDB) to represent a bin that contains the least number of tuples corresponding to t and let N  X  represent the number of an MDB. Then, we say two partitionings partitionings lead to the same swapping result in MDB and the number of sets of similar partitionings are limited in a finite dataset, the Pruning scheme finally reduces the number of partitionings to a finite number. (The details of selections can be found in the extended version due to space limits.) MEWS theoretically guarantees zero-loss of utility among variables in swapping set, which makes this approach applicable to a large category of applications of multivariate data analysis. We dedicate this section to discuss how good MEWS is in terms of preserving privacy.
 As the concept of privacy may have vario us concerns, we des cribe the privacy, P , for the entire dataset as the probability of revealing a swapping pair who has the highest disclosure risk in the database ,whichis P = max ( Pr ( X = x i )) (1  X  i  X  n ) . The disclosure risk for a tuple can be computed as, tionings according to the Pruning scheme. Then, we can compute the privacy for MEDS and MEWS with the following lemmas.
 Lemma 1. Given n data tuples and swapping distance k , the privacy for MEDS is where q ed is the number of possible partitionings and c 1 is a small constant in the range of [  X  +0 . 2 , 1 . 2] .
 The proof of Lemma 1 is omitted here and a similar process can be found in [7] if interest. The above Lemma shows t hat, if a dataset is large, the privacy provided by MEDS is only relative to the number of possible partitionings rather than the number of tuples in a bin.
 Lemma 2. Given a dataset X and swapping distance t , the privacy for MEWS is, where q ew is the number of possible partitionings and c 2 is a small constant within the range [  X , 1] .
 Although the proof of the lemma is omitted due to space constraints, one can see the privacy provided by MEWS is only relative to the number of possible partitionings which is the same as MEDS.

Based on Lemma 1 and 2, let us consider perturbing a large database, which is quite common in data mining. Generally speaking, MEDS provides more possible partitionings than MEWS does, i.e., q ed  X  q ew . But for a dataset with large size of tuples, the domain of swapping distance will be large even with the Pruning scheme. That is, q ew can still be large enough for protecting data. Moreover, with thesamesizeofMDB N  X  , the two approaches result in different partition degree d parameter for privacy measuring. It also implies that MEWS can provide good performance on preserving privacy as MEDS. We will show further analysis on privacy based on specific distributed datasets in the experimental part. 5.1 Privacy on Binormal Distribution As the privacy for MEWS is sensitive to data distribution, it is deserved to explore relations between privacy and di stribution paramet ers by generating a where  X  is the correlation coefficient of attributes X and Y . In addition, a data suppression is adopted to restrict domains of attributes within the range [  X  2 , 2] , which is reasonable because most of spa rse data will be cleaned before data analysis.

The results in Table 1 show that the privacy P for MEWS has direct relation-ships with three factors:  X  , t ub and n . For a large dataset (e.g., n = 100 , 000 ), the disclosure probability is very small ( P  X  7% ) even the attributes are not highly related, and turns to large ( P  X  30% ) while the correlations of attributes are small and the size of data is not large (e.g., the up-left corner of the table). Since most datasets for data mining are very large, and attributes in a swapping set generally have very close relations (otherwise the swapping set will make no sense for data analysis), we can observe that the MEWS method can provide good data protection. This is not intuitive but reasonable because constraints on equi-width partition is much more relaxed than that on equi-depth partition. This property is held only in the context of local data swapping rather than other local perturbation approaches. 5.2 Comparison of Data Utility Since swapping distance has various definitions for MEDS and MEWS, we con-sider the impact of partition degree on the correlation matrix here. Given a multivariate dataset X ,let  X  ij be correlation coefficient of X i and X j and  X  ij be the corresponding coefficient once d ata have been swapped using a specified method. Then, the bias of the correlation is  X  X  ij = average  X  X  and the standard deviation  X   X  X  as utility metrics. The experiments are run over one synthetic and two real datasets: 1) Syn100k ,contains 100 , 000 data tuples and four variables, which the first two variables are generated with the standard binormal distribution with  X  =0 . 5 and others are generated indi-vidually with the standard normal distribution; and 2) Abalone and MagicTele , are both formed by their continuous variables in [2].

Table 2 shows that, the  X  X  decreases as the partitio n degree increases, which is intuitive and reasonable. In most cases, MEWS performs better than MEDS, especially when the partition degree is not large. For example, the  X  X  resulted by MEDS is twice more than that by MEWS in both sythetic datasets and much higher in the real datasets. In addition, during the experiment, we find that MEWS provides more steady performance than MEDS. It implies that the variance of  X   X  X  for MEDS is larger than that for MEWS.

It should notice that, even the experimental results show that MEWS can achieve a better parametric utility in our tested data, this can not be guaranteed in other cases. We can easily construct some datasets that fit better to MEDS. However, the MEWS method is still a good alternative for commonly used data distributions.
 This paper explores the use of multivariate equi-width swapping as a tool for private data publication. It makes primary benefits on two different grounds. First, the time complexity of the algorithm is linearly proportional to the size of a dataset, which makes this approach quite efficient especially for applying on very large datasets. Then, it provides ex cellent preservation on distance-based data utilities, which has great potential for use in the real-world data analy-sis. Compared to the multivariate equi-depth swapping which provides uniform privacy protection for each tuple, the proposed method s till performs quite rea-sonably on privacy protection. In our future work, the basic MEWS method can be optimized to achieve more efficient variants for specified applications. Applying this approach in distributed private data publication offers another interesting direction.

