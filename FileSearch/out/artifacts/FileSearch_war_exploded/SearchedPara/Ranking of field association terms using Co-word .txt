 1. Introduction
Information retrieval (IR) is the science of searching for information in documents, searching for docu-ments themselves, searching for metadata which describe documents, or searching within databases, whether relational stand-alone databases or hypertext networked databases such as the Internet or world wide web or intranets, for text, sound, images or data. In brief information retrieval (IR) involves finding some desired puting similarity between texts and user queries use the whole words available in the queries and texts; this trend is inefficient for processing large text in heterogeneous subject areas.

Humans can recognize the field by finding the specific words, these words called Field Association terms (FA terms). So it may be more effective if the search engines could pick these words, FA terms, from the queries and use them as the bases of searching process. The concept of FA terms introduced in many papers,
In this paper, a study using Co-word analysis to FA terms in sports field will be used to achieve retrieval of documents that consider the bibliometric relationships between FA terms.

Bibliometric studies aim to explore the relation between concepts, ideas and problems in science and social bibliometrics is Co-citation analysis. Since small 1973, the concept was introduced and defined as  X  X  X he fre-Foo, 2001 ).

In this paper Co-word analysis, that counts and analysis the co-occurrence of key words in the publications on a given subject will be used to measure the relations among a selected sample of FA terms in sports field.
Many studies used the total frequency to judge the relatively weight of words in corpus ( Burstein et al., about the distribution of these words among all documents. Also in many cases words that have a high total frequency may be located in a few numbers of documents whereas other words that have lower total frequency may have more importance and have more strong relations with other words. Also formulas that counts terms weight depending on  X  X  X F * IDF X  X  avoid many problems resulting because of depending on absolute frequency of depending but these formulas neglect totally the relations between the term and other terms.
In this paper, co-citation analysis will be used to enable the machine to get information about relations between FA terms in a specific field (sports field) over a set of documents, using these information an auto-matic ranking of FA terms can be achieved. Then based on this ranking a scheme will be proposed to arrange search results of queries based on the relation between FA terms contained in the query.

The calculations throw this paper were done twice. First using absolute frequency, second based on a for-mula derived from  X  X  X F * IDF X  X  formula.

This paper will be organized as follows: Section 2 discusses field association terms, document field tree and how to determine FA terms. Section 3 discusses Co-word analysis and a brief discussion of the general meth-odology used in such studies. Section 4 discusses the idea of this paper and compares the expected effect of presents the conclusion and possible future work. 2. Field association terms (FA terms)
It is natural for people to identify the field of document when they notice specific words. These specific words are referred as Field-Association terms (FA terms); specifically, they are words that allow us to recog-a passage, and can be also used to classify different fields among passages. For these reasons FA terms can be used as a clue to identify a passage field. FA terms can be either words or phrases ( Uddin, Elmarhomy, Atlam, &amp;Fuketa,Fuke ).

For example FA term could be a word (e.g.,  X  X  X ame X  X ), a phrase (e.g.,  X  X  X ictory and defeat X  X ) or a right trun-words that indicate each subject matter category in the classification scheme. Since the basic concept behind discriminating words. Moreover, FA terms are not the same as subject words. In the sense that FA terms are obtained from a document but subject words may not shown in a document, FA terms could be better dis-criminator words than subject words. On the other hand, many of the FA terms are non-subject bearing words, such as  X  X  X ase X  X  or  X  X  X se X  X . While the semantic differences among FA terms are small, FA terms choices are used in a document is mainly a matter of personal style. In addition, FA terms seem to be terms with high idf in general so they play an important role in passage retrieval ( Elmarhomy et al., 2006 ). 2.1. Document field tree
A document field tree structure ranks relationships between document fields ( Aoe, Morita, &amp; Mochizuki, paths are manually assigned. For example, path  X  SPORTS /Ball Games/Tennis  X  describes the document field  X  SPORTS  X  as Super-field of  X  Ball Games  X  of sub-field  X  Tennis  X  .

A document field can be ranked as: a super-field, a sub-field or terminal fields. FA terms are grouped according to how well they indicate specific fields. FA terms have deferent rank to associate with document fields; so five field levels can be used to classify FA terms according to document fields. These levels can be defined as follows.
 Level 1: Perfect-FA terms are associated with one sub-field.

Example:  X  X  X itcher X  X ,  X  X  X ammy Sosa X  X  and  X  X  X ational League X  X  are associated with sub-field  X  Baseball  X  only. Level 2: Imperfect FA terms are associated with more than one sub-field in one super-field.
Example:  X  X  X oal X  X  and  X  X  X oalkeeper X  X  are associated with sub-fields  X  Soccer  X  and Hockey  X  of super-field Level 3: Super-FA terms are associated with one super-field.
 Example:  X  X  X eam X  X  and  X  X  X layer X  X  are associated with super-field (  X  SPORTS  X  ).
 Level 4: Multiple-FA terms are associated with more than one sub-field of more than one super-field. Example: Winner is associated with super-field  X  SPORTS  X  and sub-field  X  POLITICS/Election  X  . Level 5: Non-Specific FA terms do not specify sub-field or super-field and also include stop words. Example: Articles, prepositions, pronouns.

For extracting FA terms from hierarchically categorized corpora. It consists of the following two steps: 1. Determine candidates for FA Terms by means of defining leaves for words extracted from classified corpora. 2. Determine the precise FA Terms for single words.
 More details and algorithms can be found in Atlam, Morita, Fuketa, and Aoe (2002), Atlam, Elmarhomy,
Morita, Fuketa, and Aoe (2006) and Fuketa et al. (2000) . 3. Co-word analysis
Bibliometrics is a type of research method used in library and information science. It utilizes quantitative may use bibliometric methods of evaluation to determine the influence of a single writer, for example, or to describe the relationship between two or more writers or works. One common way of conducting bibliometric research is to use the Social Science Citation Index, the Science Citation Index or the Arts and Humanities Citation Index to trace citations.
 Co-word analysis is a method used to establish a subject similarity between two documents. If papers A and
B are both cited by paper C, they may be said to be related to one another, even though they do not directly cite each other. If papers A and B are both cited by many other papers, they have a stronger relationship. The more papers they are cited by, the stronger their relationship is. ( http://www.ischool.utexas.edu/ palmquis/ courses/biblio.html ).
 Many studies used Co-word analysis ( Bhattacharya &amp; Basu, 1998; Callon, Courtial, &amp; Laville, 1991;
Coulter, Monarch, &amp; Konda, 1998; Courtial, 1994; Ding et al., 2001; Law &amp; Whittaker, 1992; Leydesdorff &amp; Hellsten, 2006; Rip &amp; Courtial, 1984 ). The general methodology in these papers can be summarized in Fig. 2 .

The first step is to extract key words, some papers extract key words from keywords lists, abstracts and lainen, 1993 ).

The second step is data standardizing: in Co-word analysis, once a research subject is selected, a matrix based on the word co-occurrence is built. The value of the cell of two words is decided by the times these two words both appear in the same document. The higher co-occurrence frequency of two words means the closer relation between them. The matrix is then transformed into a correlation matrix by using a specific correlation coefficient ( Ding et al., 2001 ).

The final step (Data Mapping): Data Mapping or Multi Dimensional Scaling (MDS) is a method for visu-objects. For this purpose some papers use a specific programs like LEXMAPPE program ( Cambrosio 1998 ).
 and to calculate the links between the FA terms. The studies mentioned before used Co-word analysis to present valuable information to the human to understand the relations between data involved. In this paper,
Co-word analysis will be used to introduce the information to the machine to achieve more efficient retrieval. 4. Retrieval system based Co-word analysis
Similar text searching calculates the degree of similarity between the user X  X  text input and the database texts. A text with a high degree of similarity becomes output search result.

Some methods used in search engines show results in arranging that reflect the degree of similarity between query and documents. The document that has a highest similarity with the query come first then the document
Other common arranging method is  X  X  X erm frequency/inverse document frequency X  X . This method considers the distribution of words and their frequencies, then generates numerical weights for words that signify their in many documents are given substantially less weight than words that are more relevant semantically or appear in comparatively few documents. In addition to term weighting. Finally, pages can be ranked using link analysis that considers the nature of each page in terms of its association with other pages namely, by the number of other pages that point to it or a hub by the number of pages it points to. ( http://www.sciam. com/article.cfm?chanID=sa006&amp;articleID=0006304A-37F4-11E8-B7F483414B7F0000 ).

Since all these methods depend on the absolute frequency of words in the query and documents or link analysis, then arranging results according to these methods ignore completely the relations between words in the query and the results that may be irrilevant come in the first. Also ordinary methods in computing sim-ficient for processing large text in heterogeneous subject areas. This paper presents an arranging scheme of search results ,that considers relations between FA terms in the query. The system picks the FA terms from the query then make a ranking of these FA terms, depending on this ranking the query results arranged. Fig. 3 dealing methods and for new method which considers index of words X  links based on Co-word analysis. 5. Co-word analysis steps 5.1. Over view the steps of Co-word analysis steps
Fig. 4 summarizes the steps of the method; the steps that arranged in the same level are made separately. A code developed to achieve the whole work except the step of clustering. Minitab was used to achieve this step.
The whole experiment was made twice. In the first experiment the absolute frequency was used and in the sec-ond a weights based on  X  X  X F * IDF X  X  were used. The results shown here are those based on  X  X  X F 7 shows a comparison between results using these two methods.

The following subsections explain the details of the method. 5.2. Selecting FA terms list and the corps
The corpus (7660 article, 41 MB) was got from CNN newspaper, sports section. These article represents weekly reports about players news, results in different sports, local and international championships and so on. Some of these documents were short, around 90 words, other documents was some long, about 7000 words. To avoid the effect of documents length on the experiments formula (a) in Section 5.3 was used to reflect both local and global importance of the word. This corpus was chosen to be distributed over 11 sub-fields of the field sports. Table 1 shows these sub-fields and number of documents got for each sub-field. A folder for each sub-field was established and the documents for this sub-field are stored in that folder.
A random sample of these documents (337) was chosen to represent the database that will be used in the Co-word analysis and the whole corpus will be used in the evaluation experiments.

The FA terms extracted from this corpus automatically were 1572 FA terms. This number through stem-ming and manual processing reduced to 175 FA terms. All these terms were non-stop list words the following scheme was used to reduce their number. 1. A steaming procedure was used to reduce all terms that have the same stem to a unique term for example golf + golfer = golf, champion + champions + championship = champion. This procedure reduce the extracted terms to 620 FA term. 2. Terms with total frequency of 1 or 2 among the selected corpus were ignored. This reduced the extracted
FA terms to 450 FA term. 3. Finally, 175 from these 450 FA term were randomly chosen to perform the experiments. Table 2 shows a sample of those FA terms. 5.3. Co-occurrence matrix
To generate the co-occurrence matrix, the first step is to build a C code to calculate the weight for each FA term in the list in every document in the corpus. The comparison between every FA term and every token was made according to stem of each. The following formula was used to calculate the weight w in a document k where d tf ( x ) the number of times the FA term x appears in the document. k , log(d tf + 1) for all words in the document k , U the number of unique words in the document k , N the total number of documents, nf ( x ) the number of documents containing the FA term x . log  X  d tf  X  x  X  X  1  X  =  X 
P to avoid the effects of differences in document lengths. log  X 
Formula (a) is derived from the classic known formula  X  X  X F  X  X  X F * IDF X  X  means that a calculations based on formula (a) were performed. For more details about this for-mula and its implications see ( http://www.miislita.com/term-vector/term-vector-5-mysql.html#References ).
Table 3 gives the variations of weights of some selected FA terms in the sub-field  X  X  X olf X  X  among some doc-uments of the corpus. The co-occurrence of two words in a document is the minimum weight of these two words in that document. From Table 3 , the weight of the words  X  X  X olf X  X  and  X  X  X in X  X  in the document in the document  X  X  X olf14.txt X  X  is 0.13213.

The second step is to present the results to another C code that calculate the co-occurrence matrix. The input of this program is the FA terms list and their weights in each document of the corpus. The output of the program is A symmetric matrix 175 * 175 the cell in row x and column y represent the co-occurrence of keyword x and y according to the following equation: ple of the resulting matrix. 5.4. Correlation matrix (standardizing data)
To calculate the correlation factor r between each two FA terms in the list ( Table 5 ) the following formula is used where X , Y represent the corresponding rows of FA terms in the co-occurrence matrix.
 5.5. Clustering using Minitab
The correlation matrix presented to the MINITAB and wards method used to produce the clusters. Many trials were made to select the most suitable number of clusters, Only numbers that gave a similarity more than 55% were considered, so the number of clusters was 13 with similarity level of 59.13% and the number of clus-ters was 15 with similarity level 68.86%.

Decreasing the number of clusters means that many of FA terms that have a weak relations will be clus-tered to the same clusters. From the other side increasing the number of clusters means that some of FA terms than 50% to choose a suitable one. In this experiment the trial that gave 13 clusters was chosen. 5.6. Counting the linking matrix
A C program was built to count the links for each keyword and lists those keywords that have links with this keyword.

The correlation matrix was presented to this code and the output is a symmetric matrix the cell in row X and column Y represent the cosine between vectors X and Y in the correlation matrix. According to the equation:
If the angle between correlation vectors of keyword x and keyword y was less than a given threshold then there shows the number of links for some FA terms in the list. To help the ranking process we hope to choose a discriminative threshold (angle) as much as possible. From Table 6 , we notice that when we narrow the angle choose the angle = 15 then 15 FA words from 18 FA terms in Table 6 has zero links. From the other hand when we increase the angle the number of links increase till we reach a level that many FA terms have the same high number of links. For example in Table 6 when we choose angle = 50 we notice that many FA terms have a tremendous increasing in the number of their links. So we will choose the threshold according to the following criteria: the suitable threshold is the minimum angle that guarantee that at most one FA term has a zero link. From Table 6 we notice that the angles 38.5, 39 and 40 guarantee this condition the minimum = 38.5 so the threshold chosen for our experiment = 38.5. 5.7. Comparing clusters
A comparison between clusters was made to make a ranking of the clusters. The comparison will be accord-ing to: (a) Number of FA terms that belong to a specific cluster. (b) Number of links : the sum of all links of all keywords that belong to the cluster. (c) Link key : the numbers of FA terms that have links and belong to these clusters.

Average link/key : the number of links/link key for the cluster. Table 7 shows the ranking of the 13 clusters, key words, the highest number of links and the highest number of link keys has the rank 13. 5.8. Ranking for FA terms
The final step is to arrange the FA terms according to number of links, if some words have the same num-and belong to the same class they will arranged according to the co-occurrence frequency, finally if some words have the same number of links, belong to the same class and have the same co-occurrence frequency they will be arranged according the formula used to count the term frequency ( the absolute frequency or  X  X  X F * IDF X  X  weights). Table 8a shows a sample of the arranged FA terms according to this scheme. In this table, FA terms  X  X  X akanonami X  X  and  X  X  X akanohana X  X  has the same number of links and belong to the same cluster but the sum of co-occurrence frequencies of  X  X  X akanonami X  X  is greater than the sum of co-occurrence frequencies of  X  X  X akanohana X  X  so  X  X  X akanonami X  X  get a higher rank than  X  X  X akanohana X  X .

Comparing ranking of FA terms Table 8a in contrast of ranking in Table 8b that depend only on the total of absolute frequency and ranking in Table 8c that depend on  X  X  X F using the total frequency or  X  X  X F * IDF X  X  of the individual terms only. Ranking based on Co-word analysis con-siders relations between terms so it is expected to achieve more better ranking to FA terms based on Co-word analysis. 6. Arranging scheme
The following is the proposed scheme to arrange the retrieved documents by a search engine based on a query. The scheme contains two main steps. Step 1 is a preprocessing of FA terms contained in the query to divide these FA terms to a number of sets. Any set that contains a single FA term will be neglected for the scheme will be stopped and the browser will show the results without further processing. Step 2 aims to arrange the resulting documents based on step 1.
 The details of this scheme can be summarized as follows:
Step 1: Preprocessing of FA terms in the query:
Step 2: Arranging steps: Present the query to the search engine and let C be the set of results.
Fig. 5 shows an application to the minor arranging scheme assuming F ={ f
Example : Suppose that from a query we extracted the following FA terms:  X  X  X inland X  X ,  X  X  X olf X  X ,  X  X  X re-race X  X  and  X  X  X atch X  X .

The ranking of these FA words gives  X  X  X atch X  X  (81 links) as the first FA term then  X  X  X olf X  X  (50 links) as the second FA term then  X  X  X inland X  X  (6 links) as the third FA term and  X  X  X re-race X  X  (0 links) as the last FA term.
Applying the preprocessing scheme (1,2 and 3) we get the sets { X  X  X atch X  X ,  X  X  X olf X  X  X , { X  X  X inland X  X  X  and { X  X  X re-for further processing. The FA terms  X  X  X atch X  X  and  X  X  X olf X  X  belongs to the same cluster so the minor arranging set F .
 7. Evaluation experiment
For this experiment, 150 queries are designed and presented to the search engine, the 150 queries were of the field sports considered in the original corpus (7660 articles from CNN newspaper, sports section. (41 MB): see Section 5.2 ).

The details of the procedures followed in this experiment can be summarized in the following steps: 1. Design queries: All terms in the whole corpus were extracted using a standard stop list and a stemming procedure to get a list of all unique terms in the whole corpus. 150 queries were performed, the basis of these queries were the FA terms and frequent words chosen randomly from the list of all unique terms and some stop words. Every query was designed to reflect a specific sub-field. Some of these samples shown in Table 9 . 2. A matrix W of weights was designed, each column represent a term in the list of all unique terms and rows represent documents. The element in the column x and row k is the weight of the term x in the document k . was added to the end of the matrix W to get the matrix WQ . 4. We used SVD (single value decomposition) to decompose the matrix WQ . In this experiment the 80 approximation was used. ( Kolda &amp; O X  X eary, 1998 ). 5. The cosine similarity was used to calculate the similarity between every document and the query and doc-uments with a positive similarity were retrieved. sample of the experiments. For every query the first top results were considered to be the set D that the arranging scheme will be applied on it. After getting the arranged set the number of relevant documents among the first 50 results of the set D was counted before and after the arranging process.
The Relevancy measure used in this experiment is the product of three measures Scoring measure, Scope measure and Human measure. The three measures can be explained as follows: (a) Scoring measure: Given a query Q , containing keywords q (b) Scope measure: If the document belongs to the same subject of the query (i.e. the same sub-field) the (c) Human relevancy: This measure consists of three degrees ( strong, moderate and weak) and these scores
Steps from 1 to 5 were applied to the whole corpus twice. The first was performed using the absolute fre-quencies and the second using the  X  X  X F * IDF X  X  weight the search processes are done over the original corpus was got.

For comparison between ordinary approach and the new one. The precision was calculated according to the following equations.
 In this experiment, number of first top results is equal to 50.

Table 10 shows the average precision for each 5 subsequent queries for ordinary and the new approach in the case of using the absolute frequency and in the case of using  X  X  X F parison between the precision of the ordinary and the new approach. In this figure each point represents the average of each subsequent five queries.

Comparing the ordinary approach and the new approach depending on the absolute frequency we got the following results.

Among the top 50 results the number of relevant documents increased for 36 queries after applying the arranging scheme, and among the remaining 14 results the number of relevant documents was the same for 7 queries after applying the arranging scheme, and the number of relevant documents was decreased for the remaining 7 queries after applying the arranging scheme. Also the average of relevant number of documents after applying the arranging scheme was 34.92 documents and the average of relevant number of documents before applying the arranging scheme was 29.92 documents. The average precision for the new approach was 71.7% whereas the precision for the ordinary approach was 53.3%. This means that the new approach achieved a better precision than the ordinary approach by 18.3%.

Comparing the ordinary approach and the new approach depending on the  X  X  X F ing results:
Among the top 50 results the number of relevant documents increased for 34 queries after applying the arranging scheme, and among the remaining 16 results the number of relevant documents was the same for 6 queries after applying the arranging scheme and the number of relevant documents was decreased for the remaining 10 queries after applying the arranging scheme. Also the average of relevant number of documents after applying the arranging scheme was 38.6 documents and the average of relevant number of documents before applying the arranging scheme was 31.6 documents. The average precision for the new approach was 78.46% whereas the precision for the ordinary approach was 61.2%. This means that the new approach achieved a better precision than the ordinary approach by 17.2 %.

Also comparing ordinary approach based on  X  X  X F * IDF X  X  weights and the new approach based on the abso-lute frequency got the following results:
Among the top 50 results the average of relevant number of documents the new approach based on the absolute frequency was 34.9 documents and the average of relevant number of documents ordinary approach based on  X  X  X F * IDF X  X  weights was 31.6 documents. The average precision for the new approach based on the absolute frequency was 71.7% whereas the precision for the ordinary approach based on  X  X  X F was 61.2%. This means that the new approach based on the absolute frequency achieved a better precision than the ordinary approach based on  X  X  X F * IDF X  X  weights by 10.5 %. 8. Conclusion
In this paper, Co-word analysis has been used to develop a method to rank FA terms in sports field. From ranking using Co-word analysis, since the frequency or  X  X  X F the word among the whole data. Also ranking was introduced to the search engine to achieve a better retrieval that considers the relations between FA terms. The new approach using Co-word analysis performing about 18% in precision better than the ordinary approach depending on absolute frequency and the new approach using Co-word analysis performing about 17% in precision better than the ordinary approach depending on  X  X  X F * IDF X  X  weights.

The expected future work is to apply the Co-word analysis in building FA terms dictionary in the sports the similarity between the query and the documents in the database and study the effect of using Co-word analysis on the retrieved results.
 Acknowledgements
I express my thanks to the Egyptian Ministry of Higher Education for giving me this opportunity to study for my Ph.D. courses at Japan, and because the work described in this paper was supported in total by the Egyptian Government Mission (Ministry of Higher Education, Egypt) Grant No. 1/7/03/04.
 References
