 Formulating and reformulating reliable textual queries have been recognized as a challenging task in Information Re-trieval (IR), even for experienced users. Most existing query expansion methods, especially those based on implicit rele-vance feedback, utilize the user X  X  historical interaction data, such as clicks, scrolling and viewing time on documents, to derive a refined query model. It is further expected that the user X  X  search experience would be largely improved if we could dig out user X  X  latent query intention, in real-time, by capturing the user X  X  current interaction at the term level di-rectly. In this paper, we propose a real-time eye tracking based query expansion method, which is able to: (1) au-tomatically capture the terms that the user is viewing by utilizing eye tracking techniques; (2) derive the user X  X  laten-t intent based on the eye tracking terms and by using the Latent Dirichlet Allocation (LDA) approach. A systematic user study has been carried out and the experimental results demonstrate the effectiveness of our proposed methods. Category and Subject Descriptors: H.3.3 [Information Search and Retrieval] Keywords: Eye Tracking, Query Expansion, Real Time, Implicit Relevance Feedback, LDA
Query expansion based on relevance feedback has long been studied for its ability of finding out more relevant doc-uments against ambiguous queries that users might type in. Compared with explicit relevance feedback that often causes the users extra cognitive overhead, implicit relevance feed-back (IRF) has the advantage of obtaining the useful feed-back information from the user interaction data to better infer users X  search intention [6], yet without requiring the users explicit relevance judgments.

Traditional implicit feedback based query expansion meth-ods usually return static results according to the searchers X  historical log data, which cannot fully meet searchers X  dy-namic information needs. Recently various real-time IRF approaches have been proposed [12] [7] [11], to better im-prove search performance and users X  search experience. For example, Singh et al [11] argued that a query expansion framework should expand user X  X  search query dynamically based on user X  X  implicit feedback provided at the time of searching, in order to provide sufficient clues to reflect what the user wants.

Eye Tracking has been used in IR for its ability to record users X  eye movement data, which can reveal the users X  cogni-tive process when going through the retrieved documents in a natural way. Gwizdka et al. [5] have thoroughly examined the relevance of a document and cognitive effort a user may take using eye movement data. Ajanki et al. [1] designed an eye tracking experiment, in which participants were asked to search for relevant documents given a topic, and then the gaze locations were used to find relevant terms to reformu-late the queries. However, they had to avoid scrolling the text due to the risk of missing some gaze location to word mappings. Furthermore, this work was not concerned about real-time query expansion.

Buscher et al. [3] used eye tracking to extract words based on optical character recognition (OCR) technology, and as-sign different words with different weights according to the words being read or skipped. They have proved that apply-ing eye tracking as a new data source is feasible for implicit feedback. However, a limitation is that using OCR tech-nique to extract words could not operate in real-time, i.e., the words can not be immediately grabbed when users are reading them. Furthermore, the number of words extracted by using eye trackers may be too small to fully express the users X  search intention.

To tackle the problems described above, we propose a re-al time eye tracking based query expansion model via latent topic modeling. Different from Buscher et al. [3], we use a screen word-capturing technique to capture words that the searcher is reading in real-time, from which we could infer what the searcher is currently interested in. In our approach, we will have already refreshed the result list according to the captured words when the searcher clicks on the refresh or the next page button. The words captured by eye tracker are used to expanding the original query. According to [2], doc-uments can be considered as being generated by different latent topics, each of which is a probability distribution of words. Based on this assumption, we apply LDA to further derive the searcher X  X  latent information needs, which natu-rally relate to the words the user pays attention to. Our experiments show that combining the words captured by eye-tracking and the related latent topics can improve the retrieval effectiveness.
In this section, we first introduce how we capture a set of terms (or words), denoted as W Eye , from the screen using an eye tracker when the user is viewing the returned docu-ments. The words in W Eye can be considered as words of interest (WoI) and should be properly weighted. We then use LDA to model user X  X  latent topical preferences by ex-tracting another set of terms W LDA from the topics that are ranked according to W Eye . Finally, we combine the weights of the each word in W Eye and W LDA by different strategies to expand the original queries.
Gwizdka et al. [5] have revealed that a user might gaze for a longer time on relevant words than non-relevant ones, and the user X  X  pupil diameter will expand when seeing interest-ing words during reading. Accordingly, we develop a WoI capture method to capture the words a user is interested in, based on the user X  X  real-time eye-tracking activity.
To begin with, the high accuracy of modern eye trackers allow us to use suitable APIs to obtain the exact set of raw coordinates { X i ,Y i } on the screen in the millimeter level, for the regions where a user gazes on. In addition, there are existing screen word-capturing technologies for captur-ing words based on mouse cursors, as long as the mouse cursor stay steady over a word for a certain period. There-fore, we could replace the mouse cursor positions with the coordinates set { X i ,Y i } provided by eye tracking. However, the eye tracker X  X  sampling frequency is 300 HZ . Thus the coordinates in { X i ,Y i } may change too fast for the mouse-based screen word-capturing system to capture. To solve the problem, we adopt a real-time fixation filtering method [9] to cluster the raw coordinates in order to generate more stabi-lized fixation coordinates. Considering the mean minimum time to acquire the full meaning of a word is 151ms [10], we filter out those clustered fixation coordinates that last less than 151 ms. After we get the stabilized fixation coordi-nates, we can make use of the screen word-capturing tech-nique to capture words with eye tracking in real-time. The captured words (after removing the stopwords but without doing stemming) W Eye = { w Eye 1 ,w Eye 2 ,  X  X  X  w Eye s } ( s denotes the number of words in W Eye ) are written into a temporary file for each user in each search session, which is archived or deleted after the session is completed.

Different from the traditional off-line extracted eye move-ment features such as regression ratio, which can be only calculated after collecting all eye movement data, we sim-ply record 4 real-time computable features for each captured word w , namely fixation times FT w , fixation duration FD left eye pupil diameter LEP w and right eye pupil diameter REP w .
Our weighting scheme for WoIs takes into account the traditional term frequency and the eye tracking features re-flecting user X  X  interest.

For each term t in W Eye , we first normalize its term fre-quency as follows: where L t represents the normalized score for term t . wf represents the frequency of each term t and wf Eye max denotes the max frequency of the terms in W Eye . C is a positive integer constant to guarantee L t falls into the range from 0 to 1.

Furthermore, we use eye-tracking information to measure the searcher X  X  degree of interest in the term t , denoted as I where FT t and FD t represent the fixation times and fixation duration for t , respectively. The parameters  X  and  X  are coefficients for combining different features.

The function G t denotes the changing rate of pupil diam-eters of searcher X  X  both eyes, and it can be calculated by: where LEP t and REP t denote the pupil diameters of the user X  X  left eye and right eye, respectively, and s is the number of words in W Eye .

Finally, the overall weight of each term t in W Eye is com-puted as:
A document may consist of several latent topics, yet users may be just interested in one or two of them. Furthermore, users often tend to check a small number of documents in the search engine result pages (SERP) to find out the informa-tion they need. Thus it is likely that the number of captured words of interest W Eye may remain too small to fully model the user X  X  latent intention. To tackle this problem, we adopt LDA, a probabilistic laten topic model to further locate user-s X  latent search intention. LDA assumes that documents are generated by different latent topics which are probabilistic distributions over different words. Practically, we train a topic model by LDA using all the documents in the test collection, and use Gibbs sampling to conduct approximate inference of all the parameters in LDA.

Given a query Q = { q 1 ,q 2 ,  X  X  X  q l } (where l denotes the number of terms in the query) and a WoI set W Eye first rank the topics according to the probabilities that they generate Q and W Eye , and choose the top M words ranked in each topic distribution to expand the original query. The formula for ranking topics is given as follows: where P ( z n ) is the probability for a topic z n generating Q and W Eye ; f Q j and f W Eye j denote the frequency of term q in the query Q and the frequency of w Eye j in W Eye respec-tively.  X  is a constant parameter to balance the combination between Q and W Eye . In addition,  X  and  X  are the hyper-parameters used in LDA.

We then rank all the topics in descending order according to Formula (5). Then we choose top M words from each of the top ranked N topics for each query Q . Consequently, a total of M * N words are selected, forming a new set of WoIs, denoted as W LDA , which can be used for query expansion.
For each term t in W LDA , the weight  X  LDA t is calculated as below: where z i is one of the top ranked N topics and P ( t | z probability that topic z i generates the term t .

Now we get two sets of WoIs W Eye and W LDA , and all of them contain useful information for inferring users X  search intention. Therefore, it is reasonable to integrate them in order to achieve better search performance. We use W
Eye + LDA to denote the union of W Eye and W LDA . If a term appears in both W Eye and W LDA , we sum up its weights from the two sets and then normalize the summed weight into the range between 0 and 1. After we have calculated the weight of each term, we use Lemur toolkit 1 and Indri 2 search engine to implement our algorithm and to generate the expanded queries from W Eye where Q represents the original query and  X  is the com-bination coefficient.
To verify whether the proposed eye tracking based query expansion can improve retrieval performance, we have con-ducted an empirical study consisting of a series of user task-based experiments.

We implemented two proposed approaches for eye-tracking based query expansion. The first method we take only uses the eye-tracking WoIs W Eye , denoted as Eye -QE . We use Eye -LDA -QE to denote the another one, which combines eye-tracking and latent topic modeling, i.e., W Eye + LDA query expansion. For comparison, we take two traditional methods as baselines. The first one is a classical language model LM [13], which performs well in most cases without query expansion. The second baseline, RM 3 [8], is a widely accepted query expansion approach for its power in boosting the search performance.
In our experiment, participants are required to complete a number of ad-hoc retrieval tasks, with queries and doc-uments selected from the TREC AP8890 collection (to be detailed in the next subsection). We recruited 20 postgrad-uate students from three different departments to diversify http://www.lemurproject.org/ http://www.lemurproject.org/indri.php the users X  background. They are all seated in front of a 23 X  LCD monitor at a screen resolution of 1920*1080 pix-els. The eye tracker we employ is Tobii TX300, which has a sample frequency of 300 HZ and the accuracy is 0 . 3  X  of visual angle. Before conducting the experiment, each partic-ipant has to make a calibration to ensure the eye movement data captured at high precision. The participants are then instructed to complete several queries in front of the eye tracker, and for each query they have to find at least 5 rel-evant documents based on the description and narrative of the query.
Traditional query expansion methods can perform badly upon the so-called  X  X ard X  queries. In our experiment, the hard queries are determined by the low average precision of the retrieval results using the RM3 model. We expec-t our models would perform better especially when dealing with those queries. Considering that reading too many doc-uments may increase the participants X  cognitive burden and may even exhaust them, we select 6 queries for all partici-pants, including 4 hard queries and 2 normal queries, from AP8890 data set. During the process of searching for rele-vant documents, the average number of documents the par-ticipants examined is about 10. After all participants have finished all the queries we collected almost 20*6*10=1200 documents in total and each participant was paid 10 $ for about 1 hour of work.
In this section, we present our experiment results of the 4 comparative methods we have described.

We use the Mean Average Precision (MAP) as the main performance indicator, as it has been widely used and have a good discrimination power. We first compare the MAP scores of our proposed methods with the traditional models. For each query, we first calculate the Average Precision (AP) score by averaging all the 20 participants X  AP scores. Then, we average all the queries X  AP scores to obtain MAP for our proposed model. The results are shown in Table 1, under the manually selected optimal  X  . The statistical significance is indicated by * (p &lt; 0.05, one-way ANOVA) and ** (p &lt; 0.01). The results demonstrate that using the words Eye -LDA -QE 0.3508 102.3%** 26.51%* of interest captured by eye trackers is feasible and improves search performance dramatically. Further improvement is achieved by combining eye tracking and LDA model, thus verifying that employing LDA model to enrich WoIs can help dig out user X  X  latent search intention to a large extent.
To investigate the impact of WoIs captured by eye-tracking on query expansion, we test different settings of the param-eter  X  . The dynamic MAP scores along with changing  X  are shown in Figure 1. We can see that, when  X  is small (meaning more weight is given to the original query), RM 3 is better than our proposed model. The possible reason is that smaller  X  limits our captured WoIs to take an effect. However, with the increase of  X  , our models Eye -QE and Eye -LDA -QE become to outperform LM and RM 3. Both our proposed models achieve the best performance when  X  is larger, implying that the captured WoIs contain more re-sultful information than the original query.

As Granka et al. [4] pointed out, the majority of searchers usually examine the documents that are ranked higher, espe-cially the top two documents. It is essential to rank relevant documents higher in order to improve the users X  search ex-perience. Therefore, in addition to MAP, we also averaged the 20 participants X  Precision at K scores to as another per-formance indicator. The results (the best performing runs under different  X  ) are shown in Figure 2. We can find that our proposed models, especially the Eye -LDA -QE model, perform much better than the other ones when K is smaller. By taking advantage of latent topic derivation through LDA, we can more precisely locate user X  X  hidden search intention and improve search experience.
In this paper, we have proposed to expand the original query using the words of interest captured by eye track-ing in real time. Moreover, considering the words captured by eye tracker are limited due to the insufficient feedback data, the user X  X  latent search intention may not be fully ex-pressed. Therefore, we also train a latent topic model using LDA and then rank the topics, based on which the generat-ed words can be used to further enrich the expansion model. The experimental results have demonstrated that capturing the words of interest based on eye-tracking can considerably improve the retrieval performance. Further, combining the eye-tracked words and the words in topic models can gener-ate further improvement.

In the future, we will test our models on a larger-scale by recruiting more participants on larger datasets. We can further take into account the user X  X  reading sequence or the reading pattern in a feedback-based query expansion mod-el. Moreover, given that the number of mobile searchers is growing rapidly, it will be interesting to explore if and how we could use cameras on mobile devices to track user X  X  gaze to better capture user X  X  preferences.
This work is supported in part by them Chinese Nation-al Program on Key Basic Research Project (973 Program, grant No.2013CB329304, 2014CB744604), the Chinese 863 Program (grant No. 2015AA015403), the Natural Science Foundation of China (grant No. 61272265, 61402324), and the Research Fund for the Doctoral Program of Higher Ed-ucation of China (grant No. 20130032120044).
