 1. Introduction
Mental models are internal knowledge structures that serve as proxies for people to interact with the external world ( Craik, 1943; Gentner &amp; Stevens, 1983; Johnson-Laird, 1983 ). In the fields of human computer interaction (HCI) and infor-mation retrieval (IR), researchers generally postulate that people employ mental models to interact with various systems (e.g., Norman, 1983; Young, 1983 ); specifically, mental models describe  X  X  X ow a system works, its component parts, the pro-edge about mental models can, when appropriately transformed, effectively inform system design and user instruction ( Carroll &amp; Olson, 1987; Young, 2008 ). Thus, there is a continuous effort in HCI and IR to better understand mental models Papastergiou, 2005; Rieh, Yang, Yakel, &amp; Markey, 2010 ).

In the past several decades, research on mental models, particularly in Information Science (IS), mainly focused on exam-ining: (1) features, attributes, or characteristics of mental models (e.g., incomplete, not scientific, and parsimonious) (e.g., Papastergiou, 2005 ); (2) elements or content of people X  X  mental models of IR systems (e.g., Makri et al., 2007; Westbrook, 2006 ); and (3) the impact of mental models on people X  X  information searching behavior and performance (e.g., Borgman, 1986; Dimitroff, 1992 ).

In these studies, researchers gradually found that the features, composition, or quality of people X  X  mental models of an IR system could be affected by various factors, including users X  individual differences, such as computer experience (e.g., Thatcher &amp; Greyling, 1998 ), educational status and academic background (e.g., Zhang, 1997 ), gender (e.g., Zhang, 2008b ),  X  and level of familiarity with a hypertext system (e.g., Otter &amp; Johnson, 2000 ), system images, particularly system feedback (e.g., Muramatsu &amp; Pratt, 2001 ), and environmental or contextual factors, mainly training conditions (e.g., Borgman, 1986; Savage-Knepshield, 2001 ).
 retically, it could enhance our knowledge of the nature of mental models and their roles in people X  X  interaction with IR sys-tems. Practically, it can inform the design of systems that are able to facilitate users in building better understanding of the systems. Thus, it is worthwhile to initiate a series of studies to investigate the relationship between mental models and fac-tors involved in interactive information searching. This study is an attempt to explore the impact of search tasks, an impor-tant contextual factor, on people X  X  mental models of a consumer health information system, MedlinePlus.
 Bystr X m &amp; J X rvelin, 1995; Ingwersen, 1996; Ingwersen &amp; J X rvelin, 2005; Toms et al., 2007; Vakkari, 1999; Wildemuth &amp;
Hughes, 2005 ). People X  X  mental models of IR systems are constructed, developed, validated, and modified when they com-plete tasks ( Katzeff, 1990 ). Thus, tasks can affect the development of mental models by constraining the range of interactions that a user has with the system. However, little is currently known about how tasks affect mental models.
 health information portal. The site X  X  content is updated often, and it has a large user base. A recent Pew study reported that eighty percent of adult Internet users in the US have searched for health information on the web ( Fox &amp; Jones, 2009 ). Many more web-based consumer health information systems are appearing ( Kim &amp; Chang, 2007 ). We expect that this study could also inform the development of such systems. 2. Related literature models on people X  X  performance on search tasks. Studies showed mixed results. Some found that better mental models led to faster completion of tasks, fewer errors, and more results (e.g., Dimitroff, 1992; Kerr, 1990 ). Some reported that mental mod-els did not have a significant impact on recall, precision, number of documents that subjects saved ( Savage-Knepshield, 2008b ). Others found that the effect of mental models on people X  X  information searching behavior and performance was con-tingent on the complexity of tasks. Better mental models led to better performance on complex tasks but not on simple tasks (e.g., Borgman, 1986; Halasz &amp; Moran, 1983 ).
 tempted to understand the nature of mental models in relation to tasks. For example, based on the research on people X  X  use of pocket calculators, Young (1983) suggested that one type of the subjects X  mental models of calculators was based on task-action mapping. A task/action model encompasses a core set of corresponding relationships between tasks and ac-tions. In such mental models, new tasks are expressed as variants of the core tasks. Subsequently, sequences of actions cor-responding to the new tasks are derived from the core actions that correspond to the core tasks. diSessa (1986) distinguished two types of mental models, structural and functional models, in terms of contextual specificity. Structural models contain information about the internal structure of the system and are independent of specific tasks; while functional models are task related and contain information about how to use a selected set of functions to perform a specific task. reported to have a significant impact on people X  X  information searching behavior and experience ( Li, 2009 ). For example, Liu,
Gwizdka, Liu, and Belkin (2010) found that subjects who performed difficult tasks spent significantly more time, issued more queries, and examined more unique content pages to complete the tasks than those who performed easy tasks. In using an experimental IR system, White, Ruthven, and Jose (2005) found that subjects preferred explicit relevance feedback for less complex tasks and implicit relevance feedback for more complex tasks. Capra, Marchionini, Oh, Stutzman, and Zhang (2007) found that subjects who performed lookup tasks were more satisfied with the trial IR system than who performed explor-atory tasks.
 study found ( Savage-Knepshield, 2001 ), the author investigated the impact of tasks on the quality of mental models, specif-ically, whether combinations of two types of tasks, a standard task and an aspectual task, affected the quality of subjects X  mental models of an experimental IR system. She found that subjects who performed identical tasks over two different trials (1 week apart) did not improve their mental models X  accuracy and completeness, whereas subjects who performed different tasks in the two trials showed increased congruency in their mental models.
 fact that different types of tasks have impact on mental models. Rather, we need to learn how tasks, specifically their various facets or characteristics, might affect, shape, or constrain people X  X  mental models of a system.
 views or think-aloud protocols (e.g., Katzeff, 1990; Slone, 2002 ); (2) asking people to draw their mental images of a system (e.g., Efthimiadis &amp; Hendry, 2005; Papastergiou, 2005; Zhang, 2008b ); and (3) imposing different training conditions on subjects and assuming that subjects who received different training developed different mental models of a system (e.g., Borgman, 1986; Savage-Knepshield, 2001 ).

There are limitations associated with these methods. Verbal accounts are affected by subjects X  ability to articulate their thoughts. Meanwhile, people tend to justify or rationalize what they have done in verbal protocols rather than describe what extremely time-consuming. Drawings are often hard to interpret; a picture has different meanings to different people. Also, drawings are not effective in conveying subjects X  understanding of certain underlying mechanisms of IR systems, such as information organization and relevance ranking ( Zhang, 2008a ). The training method tends to impose a pre-defined struc-ture of the system to subjects. Furthermore, this method assumes that users who received model-based instructions will de-velop better models of the system than those who received procedure-based instructions. This assumption is problematic, as studies have shown that some users are able to construct a model of a system in the absence of any instructions ( Neumann &amp; Ignacio, 1998; Shrager &amp; Klahr, 1983 ).

In addition to measuring mental models, exploring tasks X  impact on mental models also calls for the comparison of men-tal models. Comparing mental models requires not only effective, but also efficient methods to represent the models. Given the limitations of those popular methods, a new approach needs to be employed. Concept listing is proposed as an alterna-tive method in this study. Concept listing is a variant of the word association method, a method based on the principle of learning by contiguity. The principle argues that objects once experienced together tend to become associated in the mind and are often recalled together in the same order of sequence or coexistence as they were initially experienced ( Wettler &amp; respond as rapidly as possible with the concepts that come to mind.

Cramer (1968) pointed out that concept listing provides an efficient means to elicit key concepts that people have about a domain. Pejtersen (1991) employed the concept listing method to study people X  X  mental models of IR systems and found that subjects X  responses clearly indicated various facets of their conceptual framework of the systems. Wang, Bales, Reiger, and Zhang (2004) used the method to explore the development of students X  knowledge structure of a subject domain, informa-tion organization, over a semester. They found that the number of terms that students contributed increased over the semes-ter, and the quality of their vocabulary improved as well. More importantly, concepts listed by some subjects formed distinct clusters on particular topics in the subject domain. 3. Method 3.1. Subjects
Thirty-eight undergraduate students (20 females and 18 males) majoring in non-medical-related subject areas, such as art history, communication studies, business, geography, mathematics, or psychology, were recruited to participate in the study through a campus-wide email list for undergraduates. The age of the subjects ranged from 18 to 22 years old ( Mean = 21, SD = 1.07), and none had ever used MedlinePlus before the study.
 Previous research suggested that spatial ability might affect people X  X  mental models of information systems ( Chen, 2000; man, &amp; Derman, 1976 ). 3.2. Tasks
Two types of tasks were defined in the study: simple and complex tasks. The complexity of a task was determined by three factors: (1) the clarity of the information required to answer the question ( Marchionini, 2006; Rasmussen, Pejtersen, 1990 ); and (3) the extent to which a higher level cognitive activity, such as synthesizing information, is required to complete the task ( Bilal, 2001; Marchionini, 2006; Rasmussen et al., 1990 ). A simple task is a well-defined question where it is clear what information is required. The answer to a simple task is located on one page, and little cognitive effort is required to solve the task. A complex task is an open-ended question. The desired information is less clear, and the answer to a complex task is often located on multiple pages. High-level cognitive activities, such as information comparing, interpreting, and syn-thesizing, are required to tackle a complex task.

To be realistic, tasks in the study were selected from Yahoo! Answers, a question and answer website where people post their own questions and answer questions posted by peer users. Some of the tasks were directly used for the study, while others were modified to suit the scope of the MedlinePlus system. For every task, a scenario was provided.

To ensure that each task was correctly categorized as a simple or a complex task, two information professionals special-izing in medical information were asked to rate the complexity of each task. Before the rating, they were given the definition of task complexity, as described above, and instructed to perform every task using MedlinePlus. Tasks used for this study were those whose complexity was agreed on by both raters. An example of a simple task is: An example of a complex task is: 3.3. Measuring mental models semi-structured interviews. In the concept listing protocol, subjects were asked to list concepts related to the MedlinePlus system in the order that the concept appeared in their mind. Each concept was viewed as a memory node, and the list of concepts was viewed as the result of subjects X  cognitive process of making sense of and representing the system. By this means, concept listing does not impose pre-defined structures on the subjects; rather, it allows subjects X  mental structure to emerge from the concepts and the order in which the concepts were listed.
 solve problems (e.g., Mayer, 2002 ). A pilot test of the concept listing protocol suggested that the method had a limited capac-ity to elicit the procedural knowledge. Therefore, semi-structured interviews were employed. In the interviews, subjects were presented with a hypothetical task, as shown below, and asked to describe steps that they plan to follow to solve the task.

They were also asked to describe their impressions of MedlinePlus. After the interviews, subjects were asked to draw their perceptions of MedlinePlus. Due to the space limit, the drawings will not be analyzed and reported here. 3.4. Procedure exploring MedlinePlus freely. After the exploration, subjects were asked to describe their impressions of MedlinePlus. Then, they were randomly assigned to two groups, the simple task group and the complex task group, within gender. Subjects in the simple task group performed 12 simple tasks and those in the complex task group performed three complex tasks. Upon the completion of the tasks, subjects X  mental models of MedlinePlus were measured by: (a) a concept listing protocol where, for five minutes, subjects listed concepts concerning MedlinePlus in the order that the concepts appeared in their mind; (b) a semi-structured interview where subjects described the steps that they plan to follow to solve a hypothetical task using
MedlinePlus, as well as their impressions of the system; and (c) a drawing task in which subjects drew their perceptions of MedlinePlus. After the three measurements, subjects were instructed to finish a series of other tasks, including an exit interview at the end of the study. These tasks did not have an impact on the theme and the results reported in this paper; thus, they are not introduced here. 3.5. Data analysis The concepts contributed by the subjects in the concept listing protocol were analyzed using a grounded theory approach. The coding unit was a concept. When multiple concepts were involved in a concept-listing entry, the entry was assigned multiple codes. A coding schema was developed by coding a subset of the concepts. The schema consisted of five top cate-gories: system, content, information organization, interface, and heuristics of using the system. The first four referred to ma-jor components of MedlinePlus, respectively, the overall MedlinePlus system, its content, its information organization, and its interface. The heuristics of using the system were rules of thumb that subjects developed concerning how to use the sys-tem. Each top category had a varied number of sub-categories. Each sub-category was one aspect from which the top cate-gory was represented. Details of the sub-categories will be reported in the results section. The schema was then applied to code the rest of the concepts. Here are several coding examples: Concepts contributed by subjects Assigned codes Lung cancer Content: specific Alphabetical Information organization: schema Well organized Information organization: evaluation Tabs Interface: element Search Interface: function CDC System: agencies involved For example, the code for  X  X  X ung cancer X  X  meant that lung cancer was a specific topic covered by the content of MedlinePlus.
The author coded all the concepts and a second coder coded 10% of the data. The inter-coder agreement (Krippendorff X  X  a ) was 78.4% in the first round of coding ( Krippendorff, 2004 ). A review session between the two coders revealed that the majority of the disagreements appeared at the second level of the code. For example, the second coder initially coded  X  X  X IH X  X  as  X  X  X ystem: similar sites. X  X  After the discussion, she agreed with the author and coded it as  X  X  X ystem: agencies in-volved. X  X  After the review, the inter-coder reliability reached 95.7%.

Subjects X  descriptions of the steps that they plan to follow to tackle a hypothetical task were transcribed and analyzed using content analysis. Subjects X  descriptions of their impressions of MedlinePlus were transcribed as well. On occasion, the transcripts used to facilitate the interpretation of some concepts listed by the subjects in the concept listing protocol. 4. Results 4.1. Characteristics of the subjects
Table 1 summarizes the demographic information of the two task groups, their spatial ability as measured by the ETS VZ-2 test, and the time that each group spent completing their corresponding tasks.
 T-tests show that the two groups were similar in age, computer experience, spatial ability, and time spent finishing the tasks. 4.2. Subjects X  mental models of MedlinePlus
This section first provides a general overview of the composition of the subjects X  mental models of MedlinePlus, followed by an overview of the two groups X  shared model of the system. Both overviews will set the stage for the discussion of the differences between the two task groups X  mental models. 4.2.1. General overview
The content analysis of the concepts that subjects contributed in the concept listing protocol suggested that subjects in both the simple and the complex task groups perceived and represented MedlinePlus in terms of four components: System: the overall MedlinePlus rather than any part of it Content: the content included in MedlinePlus representations and evaluations tended to form clusters. For example, subjects represented the content in MedlinePlus with regard to its subject, information type, format, and presentation, and they evaluated the content with respect to its quality, utility, attributes, and quantity, as well as some specific sections of the content. Table 2 summarizes the aspects from which each component was represented and evaluated.
 represented by one group but not the other were the audience and similar sites aspects of the system component. However, on a number of aspects, as shown in bold, the two groups showed qualitative differences in their representations or evalu-ations, which will be reported in the section of tasks X  impact on mental models.

The pragmatic how-to aspect of the mental models was represented by subjects X  descriptions of their plans to solve a hypothetical task using MedlinePlus. Three distinct strategies (A X  X ) were indentified based on the content analysis of the transcripts. Strategy A is a general searching strategy: subjects submit a search query to the system and then inspect the search results. Strategy C is a general browsing strategy: subjects follow links from the homepage to the page where the an-swer is located. Strategy B is a combination of searching and browsing, where subjects reach the health topic page pertaining to a disease or condition of interest by searching the disease or condition and then browse the links on the health topic page to find relevant information. Strategy B is more closely aligned to the capabilities of MedlinePlus and requires fewer clicks to reach the desired information. The three strategies were mentioned by subjects in both groups.

Furthermore, the analysis of the concepts that subjects contributed in the concept listing protocol revealed that subjects formed heuristics based on their interactions with MedlinePlus. Heuristics refer to rules of thumb concerning what work well, what do not, what is easy, and what is difficult to do within MedlinePlus. For example, one subject commented that  X  X  X yping in a question does not work well. X  X  Because heuristics could impact subjects X  strategies of using a system, they were considered as a part of the pragmatic aspect of the subjects X  mental models of MedlinePlus. The two groups developed dif-ferent heuristics, which will be discussed in the section of tasks X  impact on mental models. 4.2.2. Shared mental models of MedlinePlus
Besides the compositional similarities, the two groups X  mental models of MedlinePlus also had many semantic similari-ties. Table 3 shows the representations and evaluations of the system shared by the two groups.

In terms of the pragmatic knowledge of how to use the system, most of the subjects in both groups reported that they would use multiple strategies in combination to solve the hypothetical task. In addition, the two groups shared heuristics concerning looking for information in the system: both groups developed a conflicting view, pointing out, at the same time, that it was  X  X  X asy to find information on specific topics X  X  and  X  X  X pecific searches [are] difficult. X  X  4.3. Tasks X  impact on subjects X  mental models of MedlinePlus
In this section, the differences between the two task groups X  mental models of MedlinePlus are reported in terms of the subjects X  representations and evaluations of the four components, their procedural knowledge of solving problems using MedlinePlus, and the heuristics for using the system. 4.3.1. Tasks X  impact on subjects X  representations and evaluations of the system component
In representing MedlinePlus as an integrated system, the two groups differed in their perceptions concerning the usage, behavior, and audience of the system, as well as similar sites to the system. In evaluating the system component, they dif-fered in their opinions concerning the attributes and usability of the system. Table 4 illustrates the differences.
In representing the usage of MedlinePlus, the simple task group valued the practical usefulness of MedlinePlus; for exam-ple, one subject pointed out that it could be used for seeking medical help. In contrast, the complex group viewed the system from an educational perspective, with four subjects pointing out that it was a starting point for doing research and could educate households. In representing the behaviors of MedlinePlus, the simple task group focused on the general behavior of the system, such as aggregation and pop-up windows (noted by five subjects); whereas the complex task group focused more on specific instances experienced. For example, one subject noticed  X  X  X ome links did not work X  X  and another commented  X  X  X he search function tends to bring up several links to the same article (on different sites). X  X 
The two groups also each had a unique aspect from which they perceived the system component: three subjects in the complex task group represented the audience (layman and doctors) for MedlinePlus, and two subjects in the simple task group represented similar sites (Google) to MedlinePlus.
 usability of the system. Concerning the attributes, six subjects in the simple task group recognized that MedlinePlus was information-rich, legitimate, search-heavy, and allowed personalization; whereas the complex task group focused more on the complexity of the system, with two subjects pointing this out explicitly. Concerning the usability, both groups agreed that MedlinePlus was usable, but subjects in the simple task group expressed more positive feelings toward the usability of the system, such as fast, responsive, and convenient (noted by 13 subjects). Meanwhile, three subjects in the simple task group were critical, pointing out that the system was more difficult to use and harder than Google and that it was poor for browsing. 4.3.2. Tasks X  impact on subjects X  representations and evaluations of the content component and presentation of information. In evaluating the content, they differed in their opinions about the quantity of information and paid attention to different sections of the content in the system, as shown in Table 5 .
 kidney problems, than subjects in the complex task group (8 out of 19), and the representations of the two groups had little overlap. An inspection of the concepts revealed that most of the specific subjects were from the task descriptions.
In representing the types of information in MedlinePlus, subjects in the simple task group (5 out of 19) identified types of information that convey mostly factual information, such as fact sheets, FAQs, reports, and what-to-do articles, whereas subjects in the complex group (11 out of 19) identified types that convey mostly complex and debatable information, such as scholarly and academic articles, clinical trials, and tutorials. In representing the presentation of information in
MedlinePlus, both groups listed  X  X  X verview X  X  as a way in which information was presented. However, subjects in the simple task group (7 out of 19) identified more additional forms of information presentation, such as summaries, tables, diagrams, and figures.
 and focused on evaluating different sections of the content. In terms of the quantity of information, both groups recognized that MedlinePlus contained an overwhelmingly large amount of information, but the complex group was more critical, with linePlus information is scant. X  X  shown in the table, subjects in the simple task group (4 out of 19) evaluated summaries, descriptions, and overviews. For example, one subject commented that  X  X  X rug summaries [are] easy to navigate and especially good. X  X  Subjects in the complex task group (6 out of 19) focused more on evaluating the encyclopedia and tutorials, with one subject stating that  X  X  X dditional content for the encyclopedia would be nice. X  X  4.3.3. Tasks X  impact on subjects X  representations and evaluations of the information organization component illustrated in Table 6 .

In representing information organization schemas in MedlinePlus, the complex task group provided a more comprehen-sive view than the simple task group. In addition to the basic information organization schemas, such as alphabetical and anatomic, five subjects in the complex task group also pointed out that the information was organized hierarchically, and some of the information was organized based on the applicable demographic.

In evaluating the information organization, the simple task group commented at a very general level, pointing out that the information was well organized. Conversely, the complex task group evaluated information organization at multiple levels, from general information organization ( X  X  X ell organized X  X ), to specific information organization elements, such as sub-in the complex task group were more critical, with eight of them pointing out that information in MedlinePlus was not optimally organized and that  X  X  X oncepts were not very tied together. X  X  They also commented that  X  X  X ometimes there was too much information, too many subgroups X  X  and  X  X  X onsolidation of information X  X  was needed. 4.3.4. Tasks X  impact on subjects X  representations and evaluations of the interface component The differences between the two groups in representing and evaluating the interface of MedlinePlus are illustrated in Table 7 .

As shown in the table, in representing the results, the two groups showed different focuses. Subjects in the simple task group (3 out of 19) perceived features of the results in MedlinePlus, such as the domain from which the results were from, the reliability of the source, and whether the results were pre-formulated, whereas the complex task group X  X  perceptions focused more on the organization of the results, with two of them pointing out that the search results were organized into categories.
 Correspondingly, the two groups expressed different evaluations and emotions about the search results in the system. Two subjects in the simple task group thought that the results were reliable, and another one expressed curiosity about the ranking mechanisms, whereas the complex task group reflected on more aspects of the results, such as quantity ( X  X  X ots group was more critical, with seven subjects pointing out limitations of the results. A few examples are illustrative: one sub-ject reported conflicting results, one reported repetitive hits, one commented that there were  X  X  X oo many results, X  X  and the other commented that breaking results into categories was  X  X  X ot helpful. X  X 
The two groups also developed different opinions about the navigation supported by the interface. Both groups recog-nized that the interface was streamlined and easy to navigate, but the complex task group was more critical, with two sub-system. X  X  4.3.5. Tasks X  impact on subjects X  procedural knowledge of using MedlinePlus
As has been mentioned, subjects described three distinct strategies when asked to propose means to solve a hypothetical task using MedlinePlus: a general search strategy (strategy A), a browsing strategy (strategy C), and a combination of search-ing and browsing (strategy B). Table 8 shows the number of subjects who planned to use each strategy. If a subject planned to use multiple strategies, the subject was counted multiple times.

As shown in the table, the two groups showed significant differences in their proposed use of strategies A and B. Fisher X  X  exact tests suggest that subjects in the complex group were more likely to adopt strategy A than those in the simple task group ( p = 0.039), while subjects in the simple task group were more likely to adopt the strategy B ( p = 0.022). 4.3.6. Tasks X  impact on heuristics of using MedlinePlus
The two groups also formed different heuristics for using MedlinePlus after the completion of their corresponding tasks, as shown in Table 9 .

Concerning looking for information in MedlinePlus in general, both groups had conflicting views; some thought it was easy, and some thought it was difficult. But two subjects in the simple task group also pointed out that the system was easy for  X  X  X eneral search X  X  and  X  X  X uided searches, X  X  when none in the complex task group recognized such.

As shown in the table, the two task groups also developed heuristics concerning different decision-making points in the information searching process. One subject in the simple task group formed a heuristic for accessing information: you can get  X  X  X verything you need basically if you are willing to read multiple articles. X  X  Another subject in the group formed a heu-ristic for using information types in MedlinePlus: it was  X  X  X ard to find answers outside of FAQ sites. X  X  One subject in the com-plex task group developed a distinctive heuristic for processing information, pointing out that it was  X  X  X arder to relate topics to one another. X  X  5. Discussion and conclusions tem ( Card, Moran, &amp; Newell, 1983; Nielsen, 1989 ) and influence the ways in which the system will be used (e.g., Vakkari, 2003 ). Research on mental models has been exploring factors affecting mental models, with the intention to identify means of helping people develop better mental models of a system so as to use the system more effectively. However, little is known about the impact of tasks, an important contextual factor that has a significant impact on the design and use of sys-tems, on mental models construction. This study presents an effort to explore the impact of task complexity on people X  X  mental models of MedlinePlus.
 listing protocol to elicit subjects X  mental models of MedlinePlus. In this methodological endeavor, we learned that, compared to more traditional methods like interviews and think-aloud protocols, the concept listing protocol was efficient: it took sub-jects only five minutes to complete. It was also effective in eliciting perspectives from which subjects perceived the system and in representing elements of the mental models (such as objects and functions in MedlinePlus) and subjects X  evaluations of the elements. However, it has a limited capacity in eliciting procedural knowledge. Therefore, we supplemented the con-cept listing protocol with a semi-structured interview to elicit subjects X  procedural knowledge of using MedlinePlus to solve particular tasks. In the interviews, subjects were asked to describe steps that they would take to solve a hypothetical task using MedlinePlus. They were also asked to describe their general impressions of the system. The descriptions helped the interpretation of some ambiguous concepts in the concept listing protocol.

The analysis of the mental models of the two groups, the simple and complex task groups, after they completed their cor-responding tasks, revealed that their mental models of MedlinePlus had many structural and semantic similarities. Both groups represented the system in relation to four components: MedlinePlus as an integrated system, the content, the infor-mation organization, and the interface of the system. Meanwhile, they formed emotions or evaluations about each of the components. They both also developed general heuristics for using the system and were able to articulate strategies when asked to use the system to solve a new task.

However, the two groups differed in their perceptions and evaluations of some aspects of the system and strategies of using the system. This result suggests that mental models should not be studied only in relation to the user and the system. People employ mental models to interact with the external world ( Johnson-Laird, 1983 ) and mental models are constructed as a result of the interaction between the knowledge in the mind and the knowledge in the world ( Jonassen &amp; Henning, 1999 ). In order to better understand people X  X  mental models of information systems, it is necessary to consider relevant con-textual factors that exist in the environment, such as tasks. In the following several paragraphs, the differences of the two groups X  mental models of MedlinePlus will be discussed in relation to the features of the tasks.

First, the clarity of the information required by the two types of tasks defined in the study was different. The simple tasks were factual questions and the answers to them involved minimum ambiguity, while the complex tasks were research-oriented questions with exploratory nature. This feature could account for the differences that the two groups had in their representations of the usage of the system and the types and presentations of information in the system. Concerning the usage of the system, the simple task group developed a practical view, thinking MedlinePlus as a place for seeking medical help; whereas the complex task group perceived the system from a more educational point of view, thinking the system as a good educational site that could support research. In representing information types, the simple task group perceived information types that provide factual information useful for completing the simple tasks, such as fact sheets and what-to-do articles, whereas the complex task group represented information types that provide more in-depth information required by the com-task group perceived more presentation forms that were likely to contain factual information, such as summaries and figures.
Second, the distribution of the answers for the two types of tasks was different. Answers to the simple tasks were located at one place, whereas answers to the complex tasks were distributed at multiple places. Finding answers from multiple places requires more exploration of the system. Therefore, it is possible that subjects in the complex task group developed more specific representations of MedlinePlus. This speculation was supported by the finding that, in representing the sys-tem X  X  behavior, the simple task group focused on general behavior of the system, such as pop-up windows, but the complex task group focused more on specific instances, such as  X  X  X ome links did not work X  X  and  X  X  X he search function tends to bring up several links to the same article. X  X  It was also found that in representing information organization in MedlinePlus, the com-plex task group pointed out more types of information organization schemas.

Third, the cognitive demand of the tasks was different. Answers to the simple tasks were explicit and easy to recognize, therefore, did not require high-level cognitive activities, whereas answers to the complex tasks were indefinite and required subjects to relate, compare, judge, and synthesize information. The difference in cognitive demand might explain the two groups X  differences in the heuristics they developed for using MedlinePlus. The simple task group developed heuristics cor-responding to less cognitively demanding activities: accessing and using information types in the system, while the complex task group developed heuristics concerning a more cognitively demanding activity, processing information, pointing out that MedlinePlus was limited in helping them relate one topic to another.

The three features of the complex tasks, exploratory, distributed answers, and high cognitive demand, work together to make completing the complex tasks more difficult than completing the simple tasks. The joint effect of the three aspects could lead to some differences in the two groups X  evaluations of MedlinePlus. The simple task group thought that Medline-Plus was resourceful, information was well organized, the interface was streamlined, and the results were reliable. However, the complex task group thought that the system was complex, information was scant and not effectively organized, the interface was hard to navigate, and the results were conflicting, repetitive, and not well organized.

The two groups also differed in their perceived strategies for completing new tasks using MedlinePlus. The simple task group was more likely to adopt a strategy more aligned to the capacity of MedlinePlus, for future tasks. The complex task group was more inclined to adopt a general search strategy. An inspection of the navigation path for answers to the two types of tasks suggested that the path to the answers to the simple tasks tended to reveal the information architecture of MedlinePlus, thus helping users recognize and adopt the more system-specific strategy. A comment from a subject in the simple task group supported this speculation:
The tasks are an effective way of learning how to navigate the site. That helped a lot. If I hadn X  X  had that purpose, I would have wandered a lot more.
 The complex task group X  X  preference for the general search strategy might be attributable to their need to synthesize and integrate information from different places.
 ple task group contributed significantly more concepts to represent the specific content in MedlinePlus and the majority of these concepts were from task descriptions. This could be explained by the fact that, in the study, the simple tasks outnum-bered the complex tasks, therefore, provided more scenarios and medical terms.
 satisfaction with an IR system. The results of this study suggested that users X  perceptions and evaluations of IR systems might also be influenced by various features of a task, such as the clarity of information required by the task, distribution of its answers, the cognitive demand, the level of difficulties in completing the task, the degree to which the navigation path for the answer matches with the system X  X  information structure, and the descriptions of the task. This finding suggests that in evaluating IR systems, researchers need to consider the potential impact of tasks. A system that functions well with one type of tasks might not work as well for other task types. A more comprehensive approach that takes into consideration dif-ferent types of tasks users would carry out using a system is needed to achieve a more accurate evaluation of the system. The potential impact of tasks also calls for more research to understand the nature of self-reported evaluative measures that are widely used in studies evaluating IR systems and more research on how to validate these measurements used in. descriptions of the steps that they would take to complete a task. In future studies, it would be beneficial to observe people X  X  natural behavior of using the system and examine the relationship between their actual behavior and their mental models. It is also worthwhile to further explore whether behavior mediates the impact of task factors on mental models. Second, the subjects in the study were undergraduate students. This group of users is young and has a relatively low level of health infor-mation needs. Searching for health information is highly personal and often has critical consequences; therefore, it is worth-while to explore how patients or caregivers, who are actually in need of health-related information, use the system.
Borlund, 2000 ). In future studies, it would also be worthwhile to explore the impact of these features on people X  X  mental models of an IR system. Enhanced knowledge of the relationships between tasks and people X  X  mental models of a system not only could improve our understanding of the nature of users X  self-reported evaluations of systems, but it could also have of a system ( Card et al., 1983 ), but also to help designers develop informed models of end users, which is considered critical for designers ( Hammond, Jorgensen, MacLean, Barnard, &amp; Long, 1983 ). Secondly, it could inform the design of out-of-the-box demos for software applications and instructional materials to help users learn the systems and develop an optimal under-standing of the systems.
 Acknowledgements
Paul Solomon, Diane Kelly, Javed Mostafa, and Peiling Wang. I would also like to thank Andrew Dillon and the anonymous reviewers for their insightful comments on earlier drafts of this article.
 References
