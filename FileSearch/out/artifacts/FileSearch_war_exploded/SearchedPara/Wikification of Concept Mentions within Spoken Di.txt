 Linking mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Espe-cially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wiki-fication (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014).

But writing and reading are not the only ways for exchange of information, since many commu-nications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations.

In this work, we focus on the following differ-ences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers are engaged in a dialogue session, while the texts in newswire or microblogs are mostly written by a single author. Thus, the viewpoint of each speaker should be considered separately or jointly depending on the situation. Secondly, the correspondence between mentions and concepts in spoken dialogues tends to be dependent not only on the contexts explicitly mentioned in a given di-alogue, but also on other information inferred by speakers based on their background knowledge. The other difference is that spoken utterances are more likely to be informal and noisy than writ-ten sentences, which makes expressions more am-biguous and variable.

To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for an-alyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is deter-mined, and then a ranking is performed on the fil-tered candidates to identify the concept that is the most relevant to the mention.

While many researchers have worked on link-ing named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases includ-ing not only named entities or base noun phrases, but also complex or recursive noun phrases in a di-alogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. Figure 1: Overall architecture of three-step ap-proach for Wikification on spoken dialogues 2.1 Mention Analysis The first step in our proposed approach (Figure 1) is analyzing the following four types of binary properties of a given mention: linking validity ( LV ), in-dialogue reference ( ID ), domain rele-vance ( DR ), and speaker relatedness ( SR ).
Linking validity of the mention is determined by the decision whether it is matched with any Wikipedia concept or not. Since only the men-tions assigned with positive validity values are proceeded to the further processes, this classifi-cation can be considered as a joint task for target mention identification and NIL detection.

Another type of analysis focuses on the refer-ences between the mention and the linking his-tory. If the mention is matched with one in the set of concepts for the previous mentions in the same session, it has a positive value for the in-dialogue reference property.

The other two types of properties are defined for indicating the relevances of the mention to the contents that are specific to the target domain or the profiles of each speaker in the conversation. For these analyses, the whole Wikipedia collection is partitioned into subsets according to the domain or speaker-relevances. In this work, the concepts in these subsets are automatically collected with no manual effort by utilizing the domain knowl-edge also from Wikipedia. First, we retrieve the  X  X ist X  or  X  X ndex X  pages in Wikipedia that are re-Figure 2: Examples of annotations for mention analysis: SR G and SR T denote guide and tourist relatedness, respectively. lated to the topic or the profile of a speaker. Then, all the articles listed on these seed pages are col-lected and considered as the related concepts in the corresponding sets.

Since every property has a positive or a negative value as a result, each analysis can be considered as a binary classification problem. In this work, we train support vector machines (SVM) (Cortes and Vapnik, 1995) from the dialogues annotated with the corresponding labels as shown in Figure 2 based on the features listed in Table 1. 2.2 Candidate Generation After analyzing the above property values of a given mention, a set of concepts to be disam-biguated are selected from Wikipedia. These can-whole Wikipedia collection with the fields of ar-ticle title, section title, redirection, category, and body texts. Each query to the search engine is pre-pared with the combination of the mention phrase and its analyzed properties as constraints for fil-tering. If the value for in-dialogue reference is positive, the searching is restricted to the set of concepts linked with the previous mentions in the same session. Similarly, the domain relevance and speaker relatedness values provide the filter-ing condition within the corresponding subsets in-troduced in Section 2.1.

One practical issue on this candidate generation step is how to combine the multiple constraints when we have more than one positive proper-ties for a given mention. The simplest way is taking the intersection of the corresponding con-straints. However, we should consider the fact that the properties assigned automatically can be erroneous, since none of the analyzer is perfect. Table 1: List of features for training the models for mention analysis For the noisy cases, the intersection-based filtering could be risky, because the errors are also jointly accumulated. To circumvent the impact of errors from the previous step, we also try to use the union of the constraints and compare it with the intersec-tion case later in Section 3. 2.3 Candidate Ranking In this work, linking a given mention to its most relevant concept is determined by ranking SVM (Joachims, 2002) which is a pairwise rank-ing algorithm learned from the ranked lists. For each pair of a mention m in the training data and its candidate concept c , the ranking score s ( m, c ) is assigned as follows: s ( m, c ) = where f ( m ) is the annotation of m in the train-ing dataset. The list of candidates assigned with their scores provides the relative orders for a given mention, and it can be converted into a set of Table 2: List of features for training the ranking SVM model pairwise constraints which are trained by ranking SVM with the features in Table 2. 3.1 Data To demonstrate the effectiveness of our approach to Wikification on spoken dialogues, we per-formed experiments on a dialogue corpus which consists of 35 sessions collected from human-human conversations in English about tourism in Singapore between actual tour guides in Sin-gapore and tourists from the Philippines. All the recorded dialogues with the total length of 21 hours were manually transcribed, then the 31,034 utterance were pre-processed by Stanford stituent trees provided by the parser is consid-ered as an instance for Wikification and manu-ally annotated with the corresponding concept in Wikipedia. 34,949 mentions have been linked to the concepts in Wikipedia.
 As a pool for candidate generation, we built a Lucene index based on Wikipedia database dump as of January 2015 which has 4,797,927 articles and 25,577,464 sections in total. From this collec-tion, 11,128 and 27,186 articles have been consid-ered as Singapore-related and Philippines-related concepts, respectively, for the filtering based on domain and speaker relevances. Features LV ID SR G SR T M 86.29 69.15 71.10 72.94 M+U 86.90 70.43 70.43 68.85 M+D 86.17 71.09 70.56 71.52 M+W 86.21 68.96 70.66 71.86 M+U+D 86.82 72.37 70.12 68.30 M+U+W 86.84 70.13 70.19 68.78 M+U+D+W 86.77 72.20 69.94 68.10 Table 3: Comparisons of the performances in F-measure of mention analyzers with different combinations of features: M,U,D,W denotes mention-level, utterance-level, dialogue-level, and Wikipedia features, respectively 3.2 Mention Analysis Based on the annotated dialogues, we built four mention analyzers for LV , ID , SR G , and SR T , where SR G is for the guides and SR T is for the tourists in the conversations. In this work, only the information where each speaker is from was con-sidered as a profile to analyze the speaker-related properties. Since all the guides participated in the data collection are from Singapore and the main topic of the conversations is also about Singapore, we omitted DR which should have the same re-sults as SR G in the experiments.

For each analyzer, we trained the SVM models the evaluations were performed in five-fold cross validation to the manual annotations with preci-sion, recall, and F-measure.

Table 3 compares the performances of the seven combinations of feature sets for each analyzer. Based on these results, we selected the model that achieved the best performance for each analyzer to process the mentions for the further steps. 3.3 Candidate Generation For each mention in the corpus, we prepared four sets of candidates with different filtering con-straints. While the first baseline set was retrieved with no filtering, the others were generated ac-cording to the procedure described in Section 2.2. When more than one positive values were pro-vided from mention analyzers, intersection and union operators were applied for combining mul-tiple constraints. In the last set, the property val-ues manually annotated in the training data were Table 4: Comparisons of the performances of Wikification on spoken dialogues considered as the correct constraints, which is in-tended for comparing with the others to investigate the influence of errors in mention analysis. For ev-ery set, we retrieved top 100 candidates satisfying the given constraints from the Lucene index with Wikipedia collection and added one more special candidate for NIL detection. 3.4 Candidate Ranking For each set of candidates, we trained a ranking ble 2. Both training and testing the ranking models were performed also based on five-fold cross vali-dation with the same divisions as the former eval-uation. After getting the ranking results, we took the top-ranked candidate for each list and consid-ered it as a result of Wikification for the corre-sponding mention.
 Table 4 compares the final performances of Wikification obtained by ranking on the candi-dates generated with different sets of constraints. Both approaches, intersection and union, outper-formed the baseline by 12.60 and 13.50 in F-measure, respectively. While the intersection strat-egy contributed to produce more precise outputs than the others even including the case with man-ual filtering, the other proposed approach with union achieved more gain in recall with slightly better F-measure than the former one. This paper presented a Wikification approach for spoken dialogues. In this approach, a set of dialogue-specific properties were analyzed for generating concept candidates. Then, supervised ranking was performed on these candidates to identify the relevant concepts. Experimental re-sults show that the proposed constraints help to improve the performances of the task on spoken dialogues.
