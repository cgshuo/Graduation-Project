 Outlier detection has recently become an important problem in many industrial and financial app lications. In this paper, a novel feature bagging approach for detecting outliers in very large, high dimensional and noisy databases is proposed. It combines results from multiple outlier detection algorithms that are applied using different set of features. Every outlier detection algorithm uses a small subset of features that ar e randomly selected from the origi-nal feature set. As a result, each outlier detector identifies differ-ent outliers, and thus assigns to all data records outlier scores that correspond to their probability of being outliers. The outlier scores computed by the individual outlier detection algorithms are then combined in order to find the better quality outliers. Experi-ments performed on several synthetic and real life data sets show that the proposed methods for combining outputs from multiple outlier detection algorithms provide non-trivial improvements over the base algorithm. H.2.8 [Database Management] : Database Applications (data mining, scientific databa ses, spatial databases) Algorithms, Performance, De sign, Experimentation. Outlier detection, bagging, feature subsets, integration, detection rate, false alarm. The explosion of very large da tabases and the World Wide Web has created extraordinary opportunities for monitoring, analyzing and predicting global economical , geographical, demographic, medical, political and other proce sses in the world. However, despite the enormous amount of da ta being available, particular events of interests are still quite rare. These rare events, very often called outliers or anomalies, are defined as events that occur very infrequently (their frequenc y ranges from 5% to less than 0.01% depending on the application) . Detection of outliers (rare events) has recently gained a lot of attention in many domains, ranging from detecting fraudulent tr ansactions and intrusion de-tection to direct marketing, and medical diagnostics. For example, in the network intrusion detec tion domain, the number of cyber attacks on the network is typically a very small fraction of the total network traffic. In medical databases, when classifying the pixels in mammogram images as cancerous or not, abnormal (cancerous) pixels represent only a very small fraction of the en-tire image. Among all users that visit an e-commerce web site, those that actually purchase are quite rare -for example less than 2% of all people who visit Am azon.com X  X  website make a pur-chase, and this is much higher than the industry average. Al-though outliers (rare events) are by definition infrequent, in each of these examples, their importance is quite high compared to other events, making their de tection extremely important. The problem of detecting outliers (rare events) has been variously called in different research communities: novelty detection [23], chance discovery [24], outlier/anomal y detection [3, 5, 10, 19, 27, 36], exception mining [29], mining ra re classes [11, 16-18], etc. Data mining techniques that have been developed for this problem are based on both supervised a nd unsupervised learning. Super-vised learning methods typically build a prediction model for rare events based on labeled data (the training set), and use it to clas-sify each event [11, 16, 18]. The major drawbacks of supervised data mining techniques include (1) necessity to have labeled data, which can be extremely time consuming for real life applications, and (2) inability to detect new types of rare events. On the other hand, unsupervised learning met hods typically do not require labeled data and detect outliers (ra re events) as data points that are very different from the norma l (majority) data based on some measure [5]. These methods are typically called outlier/anomaly detection techniques, and their success depends on the choice of similarity measures, feature selection and weighting, etc. Outlier detection algorithms can detect new types of rare events as devia-tions from normal behavior, but on the other hand suffer from a possible high rate of false positives , primarily because previously unseen (yet normal) data are also recognized as out-liers/anomalies, and hence flagged as interesting. In this paper, we focus on unsupervised methods for outlier detection. Many outlier detection algorithms [3, 10, 19, 27, 31] attempt to detect outliers by computing the distances in full dimensional space. However, in very high dimensional spaces, the data is very sparse and the concept of similarity may not be meaningful any-more [3, 6]. In fact, due to the sparse nature of distance distribu-tions in high dimensional spaces, the distances between any pair of data records may become quite similar [6]. Thus, by using the notion of similarity in high dimensional spaces, each data record may be considered as potential ou tlier. It has been shown recently that by examining the behavior of the data in subspaces, it is pos-sible to develop more effective algorithms for cluster discovery [28] and similarity search in high dimensional spaces [1, 2, 4]. It has been shown that this is also true for the problem of outlier detection [3], since in many applications only the subset of attrib-utes is useful for detecting a nomalous behavior. In the example shown in Fig. 1, data records A and B can be seen as outliers only when certain two dimensions are selected (in Fig. 1b data record A is seen as outlier, in Figure 1c data record B is observed as outlier, in Figure 1d both data records A and B may be detected as outliers), while in other two-dime nsional projections they show average behavior (Fig. 1a) [3]. In addition, when significant num-ber of features in a database is considered noisy , finding outliers in all dimensions typically do not result in effective detection of outliers, while at the same time it is difficult to identify a few relevant dimensions where th e outliers may be observed. Furthermore, it is well known in machine learning that ensembles of classifiers can be effective in improving overall prediction performance. These combining techniques typically manipulate the training data patterns single cl assifiers use (e.g. bagging [9], boosting [14]) or the class labels (e .g. ECOC [20]). In general, an ensemble of classifiers must be both diverse and accurate in order to improve prediction of the whole. In addition to classifiers X  accuracy, diversity is also required to ensure that all the classifiers do not make the same errors. Ho wever, it has been shown that standard combining methods (e .g. bagging) do not improve the prediction performance of simple local classifiers (e.g. k-Nearest Neighbor) due to correlated pred ictions across the outputs from multiple combined classifiers [9, 20] and their low sensitivity to data perturbation. Nevertheless, local classifiers are extremely sensible to the selection of features that are used in the learning process, and prediction of their ensembles can be decorrelated by selecting different feature repres entations (e.g different set of features) [6, 25]. Since many outlier detection techniques that compute full dimensional distances are also local in their nature, they are also sensitive to the selec tion of features used in distance computation. In addition, presence of noisy and irrelevant features can significantly degrade the performance of outlier detection. In this paper, we propose a novel feature bagging framework of combining predictions from multiple outlier detection algorithms for detecting outliers in high-di mensional and noisy data sets. Unlike standard bagging approach where the classifica-tion/regression models that are combined use randomly sampled data distributions, in this approach outlier detection algorithms are combined and their diversity is improved by sampling random subsets of features from the original feature set. Due to aforemen-tioned sensitivity of outlier detection algorithms to the selection of features used in distance computation, each outlier detector identifies different outliers and a ssigns different outlier scores to data records. The outlier scores are then combined in order to find the better quality outliers than the outliers identified by single outlier detection algorithms. It is important to note that th e proposed combining framework can be applied to the set of any outlier detection algorithms or even to the set of different outlier detection algorithms. Our experimental results performed on synthetic and real life data sets have shown that the combining outlier detection algorithms provide non-trivial improvement over the base algorithm. Outlier detection algorithms are typically evaluated using the detection rate, the false alarm rate, and the ROC curves [26]. In order to define these metrics, let X  X  look at a confusion matrix, shown in Table 1. In the outlier detection problem, assuming class  X  X  X  as the outlier or the rare class of the interest, and  X  X C X  as a normal (majority) class, there are four possible outcomes when detecting outliers (class  X  X  X ), namely true positives (TP), false negatives (FN), false positives (FP) and true negatives (TN). Table 1. Confusion matrix de fines four possible scenarios when classifying class  X  X  X  Actual Outliers 
Actual Normal From Table 1, detection rate and false alarm rate may be defined as follows: Detection rate gives informati on about the number of correctly identified outliers, while the false alarm rate reports the number of outliers misclassified as normal data records (class NC). The ROC curve represents the trade-off be tween the detection rate and the false alarm rate and is typically shown on a 2-D graph (Fig. 2), where false alarm rate and detection rate are plotted on x-axis, and y-axis respectively. The ideal ROC curve has 0% false alarm rate, while having 100% detection rate (Figure 2). However, the ideal ROC curve is hardly achieved in practice, and therefore researchers typically compute detection rate for different false alarm rates and present results on ROC curves. Very often, the area under the curve (AUC) is also used to measure the perform-ance of outlier detection algorithm. The AUC of specific algo-rithm is defined as the surf ace area under its ROC curve. The AUC for the ideal ROC curve is typically set to be 1, while AUCs of  X  less than perfect  X  outlier detection algorithms are less than 1. In Figure 2, the shaded area corresponds to the AUC for the low-est ROC curve. Most of outlier detection techniques can be categorized into four groups: (1) statistical approaches , (2) distance based approaches, (3) profiling methods and (4) mode l-based approaches. In statisti-cal techniques [5, 7, 12], the data points are typically modeled using a stochastic distribution, and points are determined to be outliers depending on their relationshi p with this model. However, most statistical approaches ha ve limitation with higher dimen-sionality, since it becomes increasingly difficult and inaccurate to estimate the multidimensional distributions of the data points [3]. Distance based approaches [3, 10, 19, 27, 35, 37] attempt to over-come limitations of statistical techniques and they detect outliers by computing distances among points. Several recently proposed distance based outlier detection algorithms are based on (1) com-puting the full dimensional distan ces of points from one another using all the available features [19, 27] or only feature projections [3], and (2) on computing the densities of local neighborhoods [10]. In addition, a few cluste ring-based techniques have also been used to detect outliers either as side products of the cluster-ing algorithms (points that do not belong to clusters) [2, 31] or as clusters that are significantly sma ller than others [13]. In profiling methods, profiles of normal behavior are built using different data mining techniques or heuristic-bas ed approaches, and deviations from them are considered as in trusions. Finally, model-based approaches usually first charact erize the normal behavior using some predictive models (e.g. repli cator neural networks [15] or unsupervised support vector machines [13, 21]), and then detect outliers as the deviations from the learned model. Detection rate Figure 2. The ROC Curves for different detection algorithms On the other hand, extensive research was devoted to classifier ensembles in recent years. There were numerous techniques pro-posed in literature for combining classification algorithms [9, 11, 14, 17, 20]. However, it is important to note here that the problem of combining outlier detection algorithms is not exactly the same to the problem of classifier ensembles due to several reasons. First, in classifier ensembles, classification algorithms deal with combining discrete outputs (class la bels) typically using different types of voting techniques. In combining outlier detection algo-rithms, the outlier scores or rankings of the algorithms are com-bined instead of class labels, a lthough some classifier ensembles also combine rankings (or class probability estimates) from single classifiers through averaging. S econd, classifiers that are com-bined typically have complete know ledge of training data records and their labels (supervised lear ning) while outlier detection algo-rithms typically deal only with data records without any labels (unsupervised learning). However, some classifier ensembles that do not use class labels effectivel y (e.g. bagging) are very similar to combining outlier detection algorithms. Finally, certain classi-fier ensembles (e.g. boosting [14]) can control the combining process by observing the error rate, which is not possible in com-bining outlier detection algorithms since the label is not given and it is not known in advance what da ta records are really outliers. Outlier detection algorithms that we utilize in this study are based on computing the full dimensional distances of the points from one another as well as on computing the densities of local neighborhoods. In our previous work [21]], we have experimented with numerous outlier detection algorithms in the problem of network intrusion detection, and we have concluded that the den-sity based outlier detection approach (e.g. LOF) typically achieved the best prediction performance. Therefore, in this study, we have chosen the LOF approach to illustrate our findings. The main idea of this method [10] is to assign to each data exam-ple a degree of being outlier. This degree is called the local outlier factor (LOF) of a data example. Data points with high LOF have more sparse neighborhoods and ty pically represent stronger out-liers, unlike data points belonging to dense clusters that usually tend to have lower LOF values. To illustrate advantages of the LOF approach over the simple nearest neighbor approach, consid er a simple two-dimensional data set given in Figure 3. It is apparent that the density of the cluster C 2 is significantly higher than the density of the cluster C Due to the low density of the cluster C 1 it is apparent that for every example p 3 inside the cluster C 1 , the distance between the example p 3 and its nearest neighbor is similar to the distance be-tween the example p 2 and the nearest neighbor from the cluster C , and the example p 2 will not be considered as outlier using the simple nearest neighbor ( NN ) scheme. On the other hand, LOF approach is able to capture the example p 2 as outlier due to the fact that it considers the density around the points. Nevertheless, the example p 1 may be detected as outlier using both NN and LOF approaches, since it is t oo distant from both clusters. We propose two novel techniques fo r combining outlier detection algorithms. Their general framework is shown in Fig. 4. The pro-cedure for combining outlier detection techniques proceeds in a series of T rounds, although these rounds may be run in parallel for faster execution. In every round t , the outlier detection algo-rithm is called and presented with a different set of features F is used in distance computation. The set of features F t selected from the original data set, such that the number of fea-tures in F t is also randomly chosen between  X  d /2  X  and ( d -1), where d is the number of features in original data set. When the number of features N t in F t is selected, N selected without replacement from the original feature set. Every outlier detection algorithm, as a result, outputs different outlier score vector AS t that reflects the probability of each data record from the data set S being an outlier. For example, if AS &gt; AS t (j) , data record x i has higher probability of being outlier than are T outlier score vectors each corresponding to a single outlier detection algorithm. The function COMBINE (Figure 4) is then used to coalesce these T outlier score vectors AS t , t = unique anomaly score vector AS FINAL , which is lastly used to as-sign a final probability of being an outlier to every data record from the data set. Figure 4. The general framework for combining outlier detec-tion techniques The problem of combining outlier score vectors is conceptually quite similar to the problem of me ta search engines [32, 33, 34] where different rankings returned by individual search engines are combined in order to provide the pages that are most relevant to the search string. In both problems, there is no label that helps to understand how relevant the search results are and the rank of results from individual algorithms is important in the combining process, since it gives the notion of result relevance. Motivated by several approaches used in meta s earch engines, in this paper we explore two variants of the func tion COMBINE that integrates the outputs of multiple outlier detection algorithms. The first variant, denoted as Breadth First approach, is presented in Figure 5. Figure 5. The Breadth-First scheme for combining outlier detection scores  X  Given: Set S {( x 1 , y 1 ), ... , ( x m , y m )} x i  X  Normalize data set S  X  For t = 1, 2, 3, 4, ... T  X  Combine the anomaly score vectors AS t and output a AS FINAL = COMBINE( AS t ), t = 1, ..., T  X  Given: AS t , t = 1, ..., T , and m is the size of data set S and  X  Sort all outlier score vectors AS t into the vectors SAS  X  Let AS FINAL and Ind FINAL be empty vectors.  X  For i = 1 to m Figure 6. Illustration of the Breadth-First approach for com-bining outlier detection scores. The Breadth-First combining method first sorts all the outlier detection vectors AS t into the sorted vectors SAS t and returns indi-ces Ind t that give the correspondence between the sorted elements of the score vectors and the original elements of the sorted vec-tors. For example, Ind t (1) = k means that in the t -th outlier detec-tion score vector AS t , data record x k has the highest anomaly score AS ( k ). Thus in Figure 6, AS 1,1 corresponds to the data record that is ranked as the most probable outlier by Algorithm 1, AS sponds to the data record that is ranked as the second most prob-able outlier by Algorithm 1, and so on. After sorting all outlier score vectors AS t , the Breadth-First ap-proach simply takes the data records with the highest anomaly score from all outlier detection algorithms (scores AS AS 3,1 , ..., AS t,1 in Figure 6) and inserts their indices in the vector Ind FINAL , then takes data records with the second highest anomaly score (scores AS 1,2 , AS 2,2 , AS 3,2 , ..., AS t,2 pends their indices at the end of the vector Ind FINAL , and so on. If the index of the current data record is already in the vector Ind , it is not appended again. At the end of the Breadth-First method, the index Ind FINAL contains indices of the data records that are sorted according to their probability of being outlier, and the vector AS FINAL contains these probabilities. The final results of the Breadth-First method are in general sensi-tive to the order of outlier detection algorithms. However, the differences are minor since vari ations may happen only within T rankings ( T is generally much smaller than the total number of data records), since at every i -th pass we go through T indices for data records ranked at i -th place in the outlier detection vector. The second variant of the function COMBINE, denoted as Cumu-lative Sum approach, is presented in the Figure 7. Figure 7. The Cumulative Sum approach for combining outlier detection scores This combining method first creates the final outlier score vector AS
FINAL by summing all the outlier score vectors AS iterations, then sorts the vector AS FINAL and finally identifies the data records with the highest ou tlier scores as outliers. For exam-ple, data record NC 1 in Figure 8 may be ranked as the first outlier by Algorithm 1, ranked as fourth by Algorithm 2, ..., and ranked as second by Algorithm t . In the cumulative sum approach we sum all the scores that correspond to data record NC AS 1,1 , AS 2,4 , ..., and AS t ,2 , and then sort all data records NC 1, ..., m according to newly computed score. Figure 8. Illustration of the Breadth-First approach for combining outlier detection scores It is important to note that this method is analogue to the ranking method in the meta search engi nes where the ranks are summed, but it is more flexible since in the ranking method an outlier de-tected by a single algorithm may not be detected in the final deci-sion especially if it is ranked low by other detection algorithms. On the other hand, in the Cumulative Sum approach, the outlier that is detected by a single algorithm may have very large outlier score, and after all summations are performed may still have suf-ficiently large final outlier score to be detected. This fact is ex-tremely important in the scenarios where outliers are visible only in a few dimensions, since in that case it is sufficient to select relevant features only in a sm all number of iterations, compute high outlier scores for these featur e subsets and thus cause that these outliers are ranked high in the final score. Our experiments were performed on several synthetic data and real life data sets summarized in Table 2. In all our experiments, we have assumed that we have information about the normal be-havior (class) in the data set. Therefore, in the first training phase, we have applied outlier detection algorithms only to the normal data set (without any outliers) in order to set specific false alarm rates, and in the second (testing) phase, we have applied outlier detection algorithms to test data se ts (with all outliers). Using this procedure we can achieve better detection performance that using completely unsupervised approach. Our first synthetic data set (synth etic -1 in Table 2) has 5100 data records, wherein 5000 data records correspond to normal (major-ity) behavior, and 100 data records represent outliers. The data set has five original (contributing) f eatures that determine which data records are outliers (Figure 9). Normal behavior (blue points in Figure 9) is modeled as a Gaussian distribution of five original contributing features, while the outliers (red crosses in Figure 9) are points that are far from the ge nerated Gaussian distribution. We added 5 noisy features in orde r to test robustness of  X  X eature bagging X  approach to the detection performance. Our experiments on the synthetic-1 data set were performed using only LOF approaches. The computed ROC curves for this sce-nario for LOF approach, Breadth-First and Cumulative Sum ap-proaches employing LOF as single outlier detection algorithm are presented in Figure 10.  X  Given: AS t , t = 1, ..., T , and m is the size of each vector AS  X  Sum all anomaly scores AS t from all T iterations as follows:  X  For i = 1 to m  X  Return AS FINAL Algorithm 1 
Algorithm 1 Figure 9. Distribution of two contributing features for the synthetic-1 data set (blue points represent normal behavior, red crosses represent outliers) . Analyzing ROC curves from Figure 10, it can be observed that LOF approach applied with five original and five noisy features has much worse ROC curve than LOF approach that used only five original features. This was reasonable to assume since den-sity computations in LOF approach are significantly influenced by noisy and/or irrelevant features, and thus the LOF performance also degrades. However, when the proposed methods for combin-ing outlier detection algorithms are applied on the synthetic-1 data set with five original and five noisy features, it can be ob-served that they were able to alleviate the effect of noisy features and to outperform single LOF approach. Furthermore, the Cumu-lative Sum combining method has very similar ROC curve as the LOF approach only with 5 original contributing features. Figure 10. ROC curves for single LOF approach and two combining methods employing LOF approach when applied to the synthetic-1 data set with 5 original and 5 noisy features. The number of combined outlier detection algorithms for all data sets was set to 10. The figures are best viewed in color On the other hand, the Breadth First approach is slightly worse than the Cumulative Sum , but still better than LOF approach with both contributing and noisy features. That means that if there are irrelevant features in the data se ts, combining methods are able to decrease the influence of noisy features regarding the detection performance. Depending on the number of relevant and irrelevant features this decrease can vary. Our earlier experiments also show that this decrease is rather sma ll if the number of irrelevant fea-tures significantly outnumbers the num ber of relevant features. To investigate the influence of the noisy features to the detection performance, we have created two additional synthetic data sets with 10 and 20 noisy features in addition to five contributing fea-tures. Instead of ROC curves, for these two data sets we have reported areas under the curve (AUC), since AUC allows us to easier compare all three scenarios. From Table 3, it can be ob-served that with increasing num ber of noisy features, the gap between single LOF and the combining methods is indeed de-creasing. That means that the combining methods can alleviate the influence of the noisy features only till a certain level. The AUC of ideal ROC curve corresponds to 1, and it is computed using the trapezoidal rule. Table 3. AUC (areas under the curve) for single LOF, cumula-tive sum and the breadth first approaches depending on the number of noisy features in the data set. 
Number of noisy features Single LOF Our second synthetic data set (syn thetic-2 data set) has also 5050 data records, wherein 5000 data records correspond to normal (majority) behavior, and 50 data records represent outliers. This data set has 8 features and all 8 features are responsible for de-termining the outliers, i.e. the data set does not have any noisy features. Like in the synthetic-1 data set (see Figure 9), the nor-mal behavior in this data set corresponds to a Gaussian distribu-tion of eight contributing features, while analogously to the first data set the outliers are data points far from the normal behavior. The computed ROC curves for this data set for LOF approach, Breadth-First and Cumulative Sum approaches are presented in Figure 11. Note that ROC curves for the synthetic-2 data set use different axis scale than ROC curves for the synthetic-1 data set in order to observe true differences. Figure 11. ROC curves for single LOF approach and two combining methods employing LOF approach when applied to the synthetic-2 data set. The number of combined outlier detection algorithms for all data sets was set to 10. It can be observed from Figure 11 that in the scenario when all features that determine the outliers are important, there is a slight decrease in detection performance of combining methods. How-ever, this decrease is minor (e.g. for false alarm = 4%, detection rate was decreased approximately only 1% for the breadth first approach and only 2% for the cumulative sum approach. For the false alarm of 10% all three methods achieve 100% detection rate, so the only differences are for the lower false alarm rates. The degradation in performance of the combining methods compared to the single LOF approach is understandable since combining methods do not use all the features in any of the iterations, but at the same time due to the nature of the generated data set all the features are important for detecting outliers. However, in real life scenarios, it is hardly the case that all the features are relevant for detecting outliers. To check this claim, we also performed ex-periments on numerous real life data sets. All real life data sets used in our experiments have been used earlier by other researchers for the problem of detecting rare classes [11, 22, 25, 30]. These da ta sets are summarized in Table 2. Since rare class analysis is conceptually the same problem as the outlier detection, we employed those data sets for the purpose of outlier detection, where we det ected rare classes as outliers. In addition to the data sets reported in Table 2, we have also used several data sets from UCI reposito ry [8] that do not directly cor-respond to the rare class problem s or outlier detection problems but can be converted into bina ry problems by taking one small class (with less than ~10% proportion present in the data set) and remaining data records or the bi ggest remaining class as a second class. Therefore, we selected the following data sets for the con-version into binary data sets: a nn-thyroid, LED, letter recognition, segment, and shuttle. The same procedure was used earlier [18] when experimenting with the rare class learning. Using this tech-nique, we have formed additional 50 data sets. Some of the data sets selected to perform the e xperiments have both continuous and discrete features. Since LOF approach is based on computing distances between data records, measuring a distance between two discrete (categorical) values is not always straightforward. In our implementation, for computing distances between data records that have discrete attributes we have used the concept of inverse document frequency (IDF) already used in outier detection prob-lems [38], where each value of categorical attribute is represented with the inverse frequency of its appearance in the data set. When performing experiments on COIL 200 [30], mammography [11] and rooftop [22] data sets, we did not change any class dis-tribution. However, in the original lymphography data set [8], there are four classes, but two of them are quite small (2 and 4 data records), so we merged them and considered them as outliers compared to other two large classes (81 and 61 data records). When performing experiments on KDDCup X 99 data set, we se-lected to detect the smallest in trusion class (U2R), which had only 246 instances. Since the outliers ar e detected as deviations from the normal behavior, we have m odified original data set (311029 data records with five classes) such that the new data set con-tained only the data records from the normal class (60593 data records) and from the U2R class. In such modified data set, we have tried to detect the U2R class using outlier detection algo-rithms. Finally, for satimage data set we chose the smallest class to represent outliers and collapsed the remaining classes into one class as was done in [11]. This procedure gave us a skewed 2-class dataset, with 5809 major ity class examples and 626 minor-ity class examples (outliers). For 50 created binary data sets, we have typically selected one of the smallest classes and then con-verted either the remaining data records or the biggest remaining class into the majority class. Therefore, for ann-thyroid data set we have detected classes 1 and cl asses 2 as outliers vs. the class 3 as the normal (majority) class. Similarly, for shuttle data set we have created five data sets by sel ecting classes 2, 3, 5, 6 and 7 to be detected as outliers compared to the biggest remaining class 1. For other real life data sets (LED, letter recognition, and seg-ment), we have simply selected each of the classes to be detected as outliers and merged all remaining classes to correspond to the normal (majority) class. For our experiments performed on fi rst six real life data sets from Table 2, the computed ROC curves for LOF approach, Breadth-First and Cumulative Sum approaches are presented in Figure 12. Due to the lack of space the experimental results for remaining 50 created binary data sets were presented using areas under the curves (AUC) (Table 4). The computed AUCs, for chess, LED, letter, segment and shuttle data sets have been averaged over all generated data sets for the origin al data set. For example, there were 26 binary data sets generated from the original letter data set (since there are 26 classes), and AUCs were averaged over all these 26 data sets when reporting e xperimental results in Table 4. Table 4. AUC (areas under the curve) for single LOF, cumula-tive sum and breadth first approaches for 50 real life data sets obtained by converting original data into binary problems. Data set Single LOF approach Cumulative sum approach ann-thyroid class1 vs. class 3 0.869 0.869 0.856 ann-thyroid class2 vs. class3 0.761 0.769 0.753 
LED (average) 0.699 0.695 0.703 letter (average) 0.816 0.820 0.818 segment (average) 0.820 0.845 0.825 shuttle (average) 0.825 0.839 0.834 Analyzing Figure 12 and Table 4, it can be observed that both, Cumulative Sum and Breadth First combining methods outper-formed single LOF outlier detection approach on all real life data sets. The improvements in the detection performance were the smallest (approximately 5% in de tection rate for chosen false alarm rate) on the COIL 2000 data set (Figure 12a) and on the satimage data set (Figure 12f). This was probably due to the poor performance of individual outlier detection algorithms on these two data sets, so combining their outputs could not lead to signifi-cant improvements. When detecting outliers on the rooftop data set (Figure 12b), the improvements were slightly better than for the Coil 2000 data set, but again not large due to weak perform-ance of individual outlier detection algorithms. Nevertheless, the improvements in detection rate for the false alarm rates ranging from 10% to 50% are not small and they vary from 4% to 14%. The greatest enhancements in outlier detection were achieved for the mammography (Fig. 12d) and KDD Cup X 99 (Figure 12e) data sets. For those data sets single outlier detection results had respec-tively reasonable detection performance, so combining their out-puts further improved overall resu lts. However, when performing experiments on lymphography data set (Figure 12c), the detection rate of a single LOF approach was 100% already at 10% false alarm rate, so the combining met hods could not improve detection performance very much. In order to illustrate even such a slight improvement of combining methods for this data set, we reported their ROC curves only for small false alarm rates (less than 0.15). From Table 4, it can be observe d that the small improvements were also achieved for those binary data sets that were created by taking one small class as outlier cl ass and remaining data records as a second class. This can be explained by the fact that the re-maining classes that were merged together to form a single major-ity class were quite different, so it was not possible to distinct separated class from the remaining data. It can be also observed that in two data sets when the binary data sets were created by taking the small class as outlier cl ass and the biggest one as the normal class, the improvements of the combining methods were more apparent. Finally, it can be observed that for a ll 66 real life data sets used in our experiments and for all values of false alarm rate, both com-bining methods were consistently better than the single LOF ap-proach. The only exceptions are the lymphography data set, KDDCup X 99 data set and certain ge nerated data sets from LED and letter data sets, where for low false alarm rates (less than 0.05 for lymphography data set, less than 0.1 for KDDCup X 99 data set and less than 0.2 for data sets created from LED and letter data sets) detection rates of all three approaches were quite similar. A novel general framework for combining outlier detection algo-rithms was presented. Experiment s on several synthetic and vari-ous real life data sets indicate that proposed combining methods can result in much better detection performance than the single outlier detection algorithms. The proposed combining methods successfully utilize benefits from combining multiple outputs and diversifying individual predicti ons through focusing on smaller feature projections. Data sets us ed in our experiments contained different percentage of outliers, different sizes and different num-ber of features, thus providing a diverse test bed and showing wide capabilities of the proposed framework. The universal nature of the proposed framework allows that the combining schemes can be applied to any combination of outlier detection algorithms thus enhancing their usefulness in real life applications. Although performed experiments ha ve provided evidence that the proposed methods can be very successful for the outlier detection task, future work is needed to fully characterize them especially in very large and high dimensi onal databases, where new algo-rithms for combining outputs from multiple outlier detection algo-rithms are worth considering. It would also be interesting to ex-amine the influence of changing the data distributions when de-tecting outliers in every round of combining methods, employing not only the distance-based but al so other types of outlier detec-tion approaches. This work was partially supported by Army High Performance Computing Research Center contract number DAAD19-01-2-0014, by the ARDA Grant AR/F30602-03-C-0243 and by the NSF grant IIS-0308264. The content of the work does not neces-sarily reflect the position or policy of the government and no official endorsement should be inferred. Access to computing facilities was provided by the AHPCRC and the Minnesota Supercomputing Institute. [1] C. Aggarwal, Re-designing distance functions and distance-[2] C. Aggarwal and P. Yu, Findi ng Generalized Projected Clus-[3] C.C. Aggarwal, P. Yu, Outlier Detection for High Dimensional [4] R. Agrawal, J. Gehrke, D. Gunopulos and P. Raghavan, [5] V. Barnett and T. Lewis, Outliers in Statistical Data . New [6] K. Beyer, J. Goldstein, R. Ra makrishnan and U. Shaft, When [7] N. Billor, A. Hadi and P. Velleman BACON: Blocked Adap-[8] C. Blake,C. Merz, UCI Repository of machine learning data-[9] L. Breiman, Bagging Predictors, Machine Learning , vol. 24, [10] M.M. Breunig, H.P. Kriegel, R.T. Ng a nd J. Sander, LOF: [11] N. Chawla, A. Lazarevic, L. Hall,K. Bowyer, SMOTEBoost: [12] E. Eskin, Anomaly Detection over Noisy Data using Learned [13] E. Eskin, A. Arnold, M. Prer au, L. Portnoy, S. Stolfo, A [14] Y. Freund, R. Schapire, Expe riments with a New Boosting [15] S. Hawkins, H. He, G. Willia ms, R. Baxter, Outlier Detec-[16] M. Joshi, R. Agarwal, V. Kumar, PNrule, Mining Needles in [17] M. Joshi, R. Agarwal and V. Kumar, Predicting Rare [18] M. Joshi and V. Kumar, CRE DOS: Classification using Rip-[19] E. Knorr and R. Ng, Algorithms for Mining Distance based Out-[20] E. Kong and T. Dietterich, E rror-Correcting Output Coding [21] A. Lazarevic, L. Ertoz, A. Ozgur, J. Srivastava and V. [22] M. Maloof, P. Langley, T. Binf ord, R. Nevatia and S. Sage, [23] M. Markou and S. Singh, Novelty detection: a review X  X art [24] P. McBurney and Y. Ohsawa, Chance Discovery , Advanced [25] R. Michalski, I. Mozetic, J. Hong and N. Lavrac, The Multi-[26] F. Provost, T. Fawcett, Robus t Classification for Imprecise [27] S. Ramaswamy, R. Rastogi, K. Shim, Efficient Algorithms [28] A. Strehl, J. Ghosh, Cluste r ensembles -a knowledge reuse [29] E. Suzuki, J. Zytkow, Unified Algorithm for Undirected Discov-[30] P. van der Putten, M. van So meren, CoIL Challenge 2000: [31] D. Yu, G. Sheikholeslami a nd A. Zhang, FindOut: Finding [32] A. E. Howe, D. Dreilinger, SavvySearch: A meta-search [33] S. Lawrence, C. L. Giles, I nquirus, the NECI meta search [34] B. U. Oztekin, G. Karypis, V. Kumar, Expert Agreement and [35] S. D. Bay, M. Schwabacher: Mining distance-based outliers [36] S. Papadimitriou, H. Kitagawa, P. B. Gi bbons, C. Faloutsos: [37] P. Sun, S. Chawla, On Local Spatial Outliers, In Proceedings [38] L. Ertoz, Similarity Measures, PhD dissertation , University 
