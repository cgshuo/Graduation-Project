 The rapid growth of the information on the Internet demands intelligent information agent that can sift through all the available information and find out the most valuable to us. In recent years, recommender systems [1, 2] are widely used in e -commerce sites and online social media and the majority of them offer recommendations for items belonging to a single domai n. Collaborative Filtering (CF) algorithm [3] is the most widely used method for recommender systems and it can be boiled down to analyzing the tabular data, i.e., the user -item rating matrix.
 and the items rated are very limited. Thus the rating matrix is very sparse. The sparsi-ty problem has become a major bottleneck for most CF methods. To alleviate this difficulty, recently a number of Cross -Domain Collaborative Filtering (CD CF) meth-ods have been proposed [ 4 ]. CDCF methods exploit knowledge from auxiliary do-mains (e.g. movies, which has relatively more user preference data) containing addi-tional user preference data to improve recommendation on a target domain (e.g. books, whi ch has relatively less user preference data). They can effectively relieve the sparsity problem in the target domain. Currently, CDCF methods can be categorized into two classes. One class assumes shared users or items [ 5 , 6 , 7, 8 ]. This assumption is an i mportant and commonly appeared case in many large -scale websites. For in-stance, Amazon website contains different domains, including books, music CDs, DVDs and video tapes. They share the identical users though their items are totally different. This is al so the scenario studied in this paper. The other class do not require shared users or items [ 9, 10 ].
 ly neighborhood based CDCF (N -CDCF), which can be considered as the cross -domain version of a memory -based method, i.e., N -CF [11] . Likewise, the traditional matrix factorization (MF) model can also be developed to solve the CDCF problems. The cross -domain version of a matrix factorization method is denoted by MF -CDCF [ 6 ], in which an augmented rating matrix is constructed by horizontally concatenating all the rating matrices in different domains. W ith this matrix in hand, any classical MF a lgorithm, such as UV Decomposition (UVD) model [12] , can be exploited to construct user factor matrix and item factor matrix. These factor matrices are used for prediction. Both N -CDCF and MF -CDCF accommodates items from all domains into a single matrix so as to employ single -domain CF methods. However, single domain models assume the homogeneity of items. Obviously, items in different domains may quite heterogeneous, and the above two models fail to take this fact into account. ratings (like and dislike) to alleviate the sparsity problem in numerical ratings. They propose a novel transfer learning framework, Transfer by Collective Factorization (TCF). However, they require user s and items of the target rating matrix and the aux-iliary like/dislike matrix be both aligned besides the heterogeneity of the two matri-ces. In addition, they can only deal with the scenario of one auxiliary domain. which is a multi -task learning (MTL) [ 13 ] version of UV decomposition model. CMF couples rating matrices for all domains on the User dimension so as to transfer knowledge through the common user -factor matrix. Hu et al. [ 6 ] propose a general-ized Cross Domain Triadic Factorization (CDTF) model over the triadic relation user -item -domain. Since not all the auxiliary domains are equally correlated with the target domain (for example, the task of predicting user preferences on books should be more related to predicting user preferences on movies than predicting user preferences on food), CMF and CDTF consider the different degrees of relatedness between each auxiliary domain and the target domain. This is an advantage of them o ver N -CDCF and MF -CDCF. However, CMF does not provide a mechanism to find an optimal weights assignment for the auxiliary domains. Though CDTF assigns the weights based on genetic algorithm (GA), the performance is susceptible to the setting of the initial population.
 based knowledge transfer (CBT) for recommender systems. CBT achieves knowledge transfer with the assumption that both auxiliary and target data share the cluster -le vel model (RMGM). RMGM is derived and extended from the FMM generative model [ 14 ], and we can consider RMGM as a MTL version of CBT with the same assump-tion. Both CBT an d RMGM require two rating matrices to share the cluster -level rating patterns. In addition, CBT and RMGM cannot make use of user side shared information, and only take a general explicit rating matrix as its auxiliary input. Hence, both CBT and RMGM are no t applicable to the problem studied in this paper. CDCF algorithm by Integrating User Latent Vectors of auxiliary domains (CDCFIULV). We first extract the location information of a user -item interaction in the target domain as the feature vector, and use the corresponding rating information as the label. Thus we can convert the recommendation problem into a classification problem. However, the two -dimensional feature vector is n ot sufficient to discrimi-nate the different rating classes, {1, 2, 3, 4, 5}. In our experimental tests, the classifi-cation model cannot obtain a satisfactory result. Hence we require more features in the classification model.
 the user, representing the user feature in the recommender system, and the second dimension of the feature vector is the location information of the item, representing the item feature in the recommender system. Inspired by this observation, we try to expand the feature vector in the target domain with some other significant features of users or items. Since we assume that the auxiliary domains contain dense rating data and share the same aligned users wi th the target domain, it is possible to extract user features from the auxiliary domains. In this scenario, we use the user latent vector obtained by UV decomposition model from the auxiliary domains as the extra fea-tures and add them to the feature vector in the target domain. As a result, we can ef-fectively expand the feature vector for the classification problem. Our classification -based model has three advantages, (a) the hidden knowledge in the auxiliary domains can be transferred to the target domain effectively via the user latent vectors; (b) the importance of the features will be adaptively adjusted during the training process; (c) it can easily deal with the scenario of multi auxiliary domains.
 ed works on CDCF methods. Section 3 proposes our CDCFIULV model. In Section 4, we conduct extensive experiments to test the performance of the proposed algo-rithm. We conclude the paper and give future works in Section 5. Some of the earliest work on CDCF was carried out by Berkovsky et al. [ 5 ], who deployed several mediation approaches for importing and aggregating user rating vectors from different domains. Currently, CDCF methods can be categorized into two classes. One class assumes shared users or items [ 5 , 6 , 7, 8 ], and the other class requires shared users and items in different domains [ 9 , 1 0 ].
 CDCF ( N -CDCF ). As neighborhood based CF (N -CF) computes similarity between users or items, which can be sub -divided into two types: user -based nearest neighbor (N -CF -U) and item -based nearest neighbor (N -CF -I), the N -CDCF algorithm can also be divided into two types: a user -based neighborhood CD CF model (N -CDCF -U) and an item -based neighborhood CDCF model (N -CDCF -I). For simplicity, we only give a detail review on N -CDCF -U, and the detail method of N -CDCF -I is in the same manner.
 U u u u  X  denote the users in  X  and belonging to the domain k D ( 0 km  X  X  X  ), where n ( k ) denotes the item set size of 
D . For a user -ba sed CDCF algorithm, we first calculate the similarity, tween the users u and v who have co -rated the same set of items. The similarity can be measured by the Pearson correlation: mains D co -rated by  X  and  X  ; , ui r and , vi r are the ratings on item i given by users  X  and  X  respectively; u r and v r are the average ratings of user  X  and v for all the items rated respectively. Then the predicted rating of an item p for user  X  can be calculated by a weighted average strategy [11]: where who rated item p .
 all the domains may be more accurate. However it is not very reasonable to replace ence will vary on different domains. Thus the performance of N -CDCF -U is not al-ways satisfactory.
 to solve the CDCF p roblems straightforward. We can pour all the items from different domains together and then an augmented rating matrix, M D , can be built by horizon-tally concatenating all matrices as shown in Fig . 1 .
 Thus we can use MF model to obtain the latent user factors and latent item factors. These latent factors are used for prediction. In this paper, the MF model on CDCF problems is denoted as MF -CDCF . MF -CDCF accommodates items from all do-mains into a single matrix so as to employ single -domain MF. However, single do-main model assumes the homogeneity of items. Obviously, items in different domains may quite heteroge neous, so like N -CDCF -U, MF -CDCF fails to take this fact into account.
 Factorization ( TCF ), to transfer knowledge from auxiliary data of explicit binary ratings (like and di slike), which alleviates the data sparsity problem in numerical rat-ings. TCF collectively factorizes a 5 -star numerical target data R and a binary like/dislike auxiliary data, and assumes that both user -specific and item -specific latent feature matrices ar e the same. Besides the shared latent features, TCF uses two inner matrices to capture the data -dependent information, which is different from the inner matrix used in CBT [ 9 ] and RMGM [1 0 ]. TCF requires users and items of the target rating matrix and the auxiliary like/dislike matrix be both aligned. Also, they can only deal with the scenario of one auxiliary domain. Hence, it is not applicable to the prob-lem studied in this paper.
 CMF jointly factorizes multiple matrices with correspondences between rows and columns while sharing latent features of matching rows and columns in different ma-trices. Hu et al. [ 6 ] propose the CDTF model, in which they consider the full triadic relati on user -item -domain to effectively exploit user preferences on items within dif-ferent domains. They represent the user -item -domain interaction with a tensor of or-der three and adopt a tensor factorization model to factorize users, items and domains into la tent feature vectors. The rating of a user for an item in a domain is calculated by element -wise product of user, item and domain latent factors. A major problem of tensor factorization however, is that the time complexity of this approach is exponen-Both CMF and CDTF need to adjust the weights of the auxiliary domains according to the similarities between the auxiliary domains and the target domain.
 ratings in the auxiliary rating matrix into an informative and yet compact cluster -level rating pattern representation referred to as a codebook. Then, they reconstruct the target rating matrix by exp anding the codebook. CBT achieves knowledge transfer patterns (codebook). Further, Li et al. [1 0 ] propose a RMGM model. In this model, the knowledge is shared in the for m of a latent cluster -level rating model. Each rating mat rix can thus be viewed as drawing a set of users and items from the user -item joint mixture model as well as drawing the corresponding ratings from the cluster -level rating model. RMGM is a MTL versi on of CBT with the same assumption. Both CBT and RMGM require two rating matrices to share the cluster -level rating patterns. They data (e.g. movies). Hence they are no t applicable to the scenario studied in this paper. 3.1 Convert the recommendation problem into a classification problem Assume D 1 is the target domain, and U 1 and I 1 are the sets of users and items in do-main D 1 . We model the standard recommendation problem in the target domain D 1 by a target function 11 : y U I R  X  X  X  . We represent each user -item interaction where u L and i L denote the location information of user u and item i respectively. Thus we can represent each user -item interaction as a training sample, and the origi-nal rating problem can be converted into a classification problem. We use Fig . 2 to illustrate our method. the same manner, we can also represent other user -item interactions as training sam-ples. Thus the rating matrix can be converted into a training set and we can convert the recommendation problem into a classification problem. 3.2 Feature vector expansion The training samples of the conver ted classification problem have only two location features. However, the two -dimensional feature vector is not sufficient to discriminate the different rating classes, {1, 2, 3, 4, 5}. In our experimental tests, the classification model with two -dimensiona l feature vector cannot obtain a satisfactory result. Hence we require more features in the classification model . Note that the first dimension of the feature vector represents the user feature in the recommender system, and the second dimension of the fea ture vector represents the item feature. Inspired by this observation, we try to expand the feature vector in the target domain with some other significant features of users or items.
 user set. In addition, we also assume that the auxiliary domains contain dense rating data. Thus it is possible to extract the user features from the auxiliary domains and transfer them to the target domain. In our model, we first use the UV decompos ition model to obtain the user latent vectors from the auxiliary domains. We will use the user latent vectors to expand the user feature vector in the target domain. As shown in Fig . 3 , i n any auxiliary domain, the UV decomposition model maps both users an d items to a joint latent factor space of dimensionality f . In this model, each item i is associated with a latent vector f is associated with a latent vector f factors. The resulting dot product, T item i . This approximates user u 's rating on item i , which is denoted by  X  lowing form To learn the latent vectors ( p u and q i ), the UV decomposition model minimizes the regularized squared error on the set of known ratings Here,  X  is the set of the ( u , i ) pairs for which r ui is known. The constant  X  controls the extent of regularization to avoid over -fitting and is usually determined by cross -validation [15]. An effective approach to minimi ze optimization problem (4) is sto-chastic gra dient descent, which loops through all ratings in the training set. For each given training case, the system predicts r ui and computes the associated prediction error Then it modifies the parameters by a magnitude proportional to  X  (i.e., the learning rate) in the opposite direction of the gradient, yielding: Next, we will give the reason why we select the user latent vectors as the user features in the auxiliary domains. Firstly, since we assume the a uxiliary domains contain suf-ficient rating data, the UV decomposition model can obtain relatively accurate user latent vectors. In other words, the accuracy of the user latent vectors can be guaran-teed. Secondly, as the UV decomposition model can find a lo w -rank approximation for the rating matrix [12] , so the user latent vectors are a good low -dimensional repre-sentation of the user features, which will make the classification model more efficient. with the latent vectors of user u from the auxiliary domains. Thus the user -item inter-sents the latent vector of user u in the i -th auxi liary domains. 3.3 Classification problem solving Many traditional classification algorithms can be employed to solve the converted classification problem. In this part, we employ Support Vector Machines (SVMs) [16] to solve the problem. For a two -class classi fication problem, let training set where n i xR  X  , { 1, 1} i y  X   X   X  , 1, , il  X  . SVMs solve the following optimization where C is a penalty factor, i a ( 1,..., il  X  ) is a La grange multiplier, and ( , ) K  X  X  X  is a kernel function. Then * b can be computed in the following form The decision function can be represented in the following form where sgn( )  X  is a sign function. Since the converted classification problem in thi s proach [17] , which transforms a c -class problem into c two -class problems. Also we select the following radial basis function (RBF) as the kernel function [ 16 ] , where  X  is a width parameter, x and y are n -dimensional vectors in the original fea-ture space. functions. Hence our model can adaptively select significant features during the train-ing process. 3.4 The proposed algorithm We summarize our algorithm, a model -based CDCF algorithm by Integrating User Latent Vectors of auxiliary domains (CDCFIULV) in Algorithm 1 .
 Algorithm 1 : the CDCFIULV algorithm Input : the rating matrix M in the target domain; the rating matrix M 1 ,...,M s in the aux-iliary domain Output : the missing ratings in the target domain Method : (1) Convert the recommendation problem in the target domain into a classification problem; (2) Perform UV decomposition in each auxiliary domain to obtain the user latent vec-tors; (3) Expand the feature vectors with the user latent vectors; (4) Train a classifier on the o btained training set; (5) Predict the missing ratings. In this section, we conduct extensive experiments to test the performance of the pro-posed algorithm. We compare our algorithm to six state -of -the -art algorithms, name-ly, N -CF -U, UVD, N -CDCF -U, MF -CDCF, CMF, and CDTF, where N -CF -U and UVD are two single domain CF algorithms, and N -CDCF -U, MF -CDCF, CMF and CDTF are four cross domain algorithms. All experiments are run on 2.20 GHz, Intel (R) Core (TM) i5 -5200U CPU with 8GB main memory und er window 7. All algo-rithms are implemented with Matlab 2015B on top of two open source libraries for recommender systems: MyMediaLite [1 9 ] which implements most common CF ap-proaches including Matrix Factorization, and LibSVM [ 20 ] which implements SVMs lea rning algorithms. 4.1 Data sets We conducted our experiments on Amazon dataset [ 21 ] which consists of rating in-formation of users in 4 different domains: books, music CDs, DVDs and video tapes. The dataset contains 7,593,243 ratings on the scale 1 -5 provided b y 1,555,170 users over 548,552 different products including 393,561 books, 103,144 music CDs, 19,828 DVDs and 26,132 VHS video tapes.
 able to compare our approach with them. I n detail, we selected Book and Music CD as the target domain to evaluate respectively. We filtered out users who have rated at least 50 books or 30 music CDs so that there are enough observations to be split in various proportions of training and testing d ata for our evaluation. Finally, 2,505 users were selected, and in addition we retrieved all items rated by these users in these four domains and set aside top K rated items for each domain respectively. Table 1 shows the statistics of the data for evaluat ion. Then, we constructed rating matrices over filtered out data for each domain.
 To simulate the sparse data problem, we constructed two sparse training sets, TR 20 and TR 75 , by respectively holding out 80% and 25% data from the target domain Book, i.e. the remaining data of target domain for training is 20% and 75%. The hold -out data server as ground truth for testing. Likewise, we also construct two other training sets TR 20 and TR 75 when choosing Music as the target domain. 4.2 The setting of the compared methods (1) N -CF -U: A user -based neighbor hood CF model. In this experiment, we use k =10 closest users. tent factor space of dimensionality f . In the empirical tests, we observed that the per-formance is rather stable when f is in the range of [30, 70]. Here we simply set f =50 from the range . The weight of the regularization terms  X  is determined by cross -validation. The learning rate  X  is a constant typically having a value between 0.0 and the learning rate is too large, then oscillation between inadequate solutions may occur. In this paper, for simplic ity, we set 0.3  X   X  . k =10 closest users. domains on the User dimension so as to transfer knowledge through the common user -factor matrix. domains as target domain to perform prediction and others as auxiliary domains to borrow knowledge. We use the same setting as in [6]. tion problem into a classification problem, then expands the feature vectors w ith user latent vectors from the auxiliary domains, and finally employs SVMs to solve the classification problem. In this experiment, we also set f =50 and 0.3  X   X  . The parame-ters in the SVMs are determined by cross -validation. 4.3 Evaluation Protocol We used mean absolute error (MAE) as evaluation metrics in our experiments. MAE is defined as where T denotes the set of test ratings, rating. A smaller value of MAE means a better performance. 4.4 Results The comparison results are reported in Table 2 .
 As shown in Table 2, the five CDCF models (N -CDCF -U, MF -CDCF, CMF, CDTF and CDCFIULV) all perform better than UVD and N -CF -U, because UVD and N -CF -U are single domain CF algorithms which cannot deal with the sparsity problem ef-fectively. The performances of N -CDCF -U and MF -CDCF are roughly equal. Since both N -CDCF -U and MF -CDCF fail to consider the differences among domains, as expected they perform worse than the three mo dels (CMF, CDTF and CDCFIULV) which take this differences into account. Our model CDCFIULV perform much better than CMF and CDTF. This is because the classification -based model can adaptively implement feature selection from the whole feature vector accord ing to the perfor-mance of the classification. However, CMF does not provide a mechanism to find an optimal weights assignment for the auxiliary domains. Though CDTF assigns the weights based on genetic algorithm (GA), the performance is susceptible to the setting of the initial population.
 performance improvements. Because with the number of training ratings increasing, the training set size of the converted classification prob lem is increased greatly. Thus the classification model can effectively avoid over -fitting, and the performance can be improved. N -CDCF -U also achieves a not bad performance when the data is relative dense, i.e. TR 75 , but the performance decreases very fas t when the data becomes sparser. Because when the data are sparse, the total similarity used in N -CDCF -U cannot represent the local similarity in the target domain well. However, according to Eq. (1) , with the number of training ratings increasing, the tot al similarity can repre-sent the local similarity in the target dom ain better. In this paper, from the perspective of classification, we propose a model -based CDCF algorithm by Integrating User Latent Vectors of auxiliary domains (CDCFIULV). We e xpand the feature vectors in the target domain with u ser l atent v ectors obtained from auxiliary domains . Hence the hidden knowledge in the auxiliary domains can be classifie rs for the converted classification problems. Since SVMs can implement fea-ture selection by adjusting the kernel functions , so our model can adaptively select significant features during the training process. The experiment results have shown that CDCFIULV significantly outperform all other state -of -the art baseline algorithms at various sparsity levels .
 main with some other significant features of users , in the future we will also explore how to expand the feature vector with some other significant features of items. This work is sponsored by the National Natural Science Foundation of China (No. 61402246), a Project of Shandong Province Higher Educational Scienc e and Tech-nology Program (No. J15LN38), Qingdao indigenous innovation program (No. 15 -9 -1 -47 -jch), and the Natural Science Foundation of Shandong Province (ZR2016FQ10).
