 Extracting information from web pages is an important prob-lem; it has several applications such as providing improved search results and construction of databases to serve user queries. In this paper we propose a novel structured predic-tion method to address two important aspects of the extrac-tion problem: (1) labeled data is available only for a small number of sites and (2) a machine learned global model does not generalize adequately well across many websites. For this purpose, we propose a weight space based graph reg-ularization method. This method has several advantages. First, it can use unlabeled data to address the limited la-beled data problem and falls in the class of graph regular-ization based semi-supervised learning approaches. Second, to address the generalization inadequacy of a global model, this method builds a local model for each website. Viewing the problem of building a local model for each website as a task, we learn the models for a collection of sites jointly; thus our method can also be seen as a graph regularization based multi-task learning approach. Learning the models jointly with the proposed method is very useful in two ways: (1) learning a local model for a website can be e ectively in-uenced by labeled and unlabeled data from other websites; and (2) even for a website with only unlabeled examples it is possible to learn a decent local model. We demonstrate the ecacy of our method on several real-life data; experimental results show that signi cant performance improvement can be obtained by combining semi-supervised and multi-task learning in a single framework.
 Categories and Subject Descriptors: H.3.m [Informa-tion Storage and Retrieval] Miscellaneous -Information Ex-traction, Web General Terms: Algorithms, Experimentation Keywords: Information Extraction, Semi-supervised learn-ing, Multi-task learning, Structured Predictions
Extracting information from web pages is an important problem. It has several web applications such as providing improved search results, serving user queries related to re-views, pricing information of products, etc., using databases constructed from information extraction. We consider the problem of domain-centric extraction where a schema cor-responding to a domain of interest is given. The goal is to extract attributes speci ed by the schema from a collection of pages. Examples of a domain include Books , Restaurant , Publications etc. The schema for the Books domain will have attributes such as Title , Author , Publisher and Price . The pages for this domain are obtained from a collection of websites like www.amazon.com , www.booksamillion.com , etc. Similarly, a schema for the Publications domain will have attributes such as Author , Title , Conference , Pages etc., and these can be extracted from home pages of faculty members of di erent universities.

In all these examples, the attributes of interest are often organized either as records in a list page or as a single record in a detail page. Each record is a set of attribute values of one entity, e.g., a Book or a Publication . Unsupervised meth-ods [11, 39, 3, 25] are very successful in extracting records from list pages using structural patterns present in one or more web pages. In the case of a detail page, the informative region of the web page plays the role of a record and it can be obtained using methods such as the ones proposed in [38]. Therefore, throughout this paper we will assume that records are given and focus on the ner and challenging problem of extracting attributes from records. It is worth noting that the unsupervised methods mentioned above are inadequate for solving this attribute extraction problem. The problem is challenging due to the following reasons: (1) there are wide variations in presentation style of information across the websites. For example, attribute ordering , font size , font type (e.g., italic, capital), html tag structures, etc., are often di erent, (2) the number of websites is large, and (3) some of the attributes are optional (may not be present in all the records) and some of the attributes are missing (in all the records from a website). These reasons also make it hard to build a global model that generalizes well across the websites .
Other challenges arise from the approach taken to address the extraction problem. For example, the wrapper induc-tion [19, 27] method requires supervision; it utilizes labeled data to learn extraction rules on the HTML tag structure of pages. The need to have labeled data for each website and the presence of noisy structures within a website makes this method impractical for scaling to a large number of websites.
In recent years there has been a signi cant amount of re-search work done in building machine learned models for web information extraction. [5, 1, 29, 30, 41] apply sequen-tial models like Hidden Markov Models (HMM), Conditional Random Fields (CRF) and Markov Logic Networks (MLN) to segment instances such as citations and addresses. All these methods focus on building a global model. Global models do not generalize well across websites whenever there are wide variations in structure and formatting across the websites (as frequently observed in domain-centric extrac-tion problem). We demonstrate this issue using CRF models on the attribute extraction problem from records. This issue is expected to arise even when sophisticated models like hi-erarchical CRFs (HCRF) [41] and MLNs [30] are used. The key reason for this is that important features (e.g., attribute ordering, font type) that are discriminative within a site tend to become less e ective whenever these features vary widely in the training examples from di erent websites. This prob-lem can be alleviated by building local models where these discriminative features can be e ectively made use of. Note that although we use a simple CRF model in our attribute extraction problem to demonstrate the usefulness of local models, our approach is quite generic and can be extended with HCRFs and MLNs. Therefore, our intention in this pa-per is not to demonstrate superiority over any of the existing information extraction methods using HCRF or MLN mod-els; hence, we do not make any such comparisons. Our fo-cus is on demonstrating the usefulness of building machine-learned local models and how these models can be e ectively learned jointly when the labeled examples are scarcely avail-able.

Building machine-learned models in supervised and semi-supervised settings require labeled data. In our problem context, getting labeled data from each website is extremely dicult as the number of websites is large. Furthermore, it is expensive to get a large amount of labeled data even for a few websites, particularly for structured data (such as a sequence or a tree) where the number of nodes and attributes is large.

The aim of the paper is to address two important aspects of the domain-centric extraction problem: (1) limited la-beled data is available only for a small number of websites but plenty of unlabeled data is available from all the web-sites in a collection, and (2) a machine-learned global model does not generalize adequately well across many websites.
Our approach is based on connecting examples from dif-ferent websites through a graph and learning local models for the websites jointly via graph regularization (Section 4). It exploits the fact that although there are variations in the presentation styles across the websites, there is useful com-mon information that exists across the websites. For ex-ample, attributes such as Author , Title , Conference , Pages have (similar) content features that are common across the websites; our approach makes good use of such information.
We propose a weight space based graph regularization method. Our method has several advantages. First, it can use unlabeled data to address the limited labeled data prob-lem and falls in the class of graph regularization based semi-supervised learning (SSL) approaches. In this aspect, our work is related to [20, 2]. But, our formulation is much sim-pler and a lot easier to implement with publicly available software packages for structured predictions; unlike [20, 2] we directly work in the weight space formulation instead of the dual formulation.

Next, to address the generalization inadequacy of a global model, we propose to build a local model for each web-site. Furthermore, we suggest to learn the local models jointly to address the limited labeled data aspect; again, the weight space based graph regularization method can be used for joint learning. Viewing the problem of building a local model for each website as a task, our method can also be seen as a graph regularization based multi-task learning (MTL) approach. Learning the models jointly via the pro-posed method is useful in two ways: (1) learning a local model for a website can be e ectively in uenced by labeled and unlabeled data from other websites to get improved per-formance; and (2) even for a website with only unlabeled examples it is possible to learn a decent local model for it (which is not possible even for wrapper learning approaches). Thus, our method addresses the limited labeled data aspect via a uni ed framework for semi-supervised and multi-task learning. From a multi-task learning viewpoint, our work is related to [13]. However, our formulation goes beyond binary/multi-class problems, applies to structured predic-tion models, and is suitable for web information extraction. We are not aware of any work on multi-task learning that addresses the problem of learning local structured prediction models for totally unlabeled websites.

We conduct experiments on several real world datasets constructed from web pages of domains such as Books , CS-Faculty , Seminars and MLConfs . The experimental results demonstrate the e ectiveness of the proposed method for semi-supervised , multi-task and semi-supervised multi-task (combined semi-supervised and multi-task) learning scenarios. The results also show that the performance of lo-cal models built for totally unlabeled websites is better than that of the global model.
Consider the problem of extracting attributes from a given set of records. Let x and y denote the input and output rep-resentation of a record. We choose a suitable tokenization and view each record as a sequence of nodes; x is a sequence of feature vectors that are functions of the textual content and/or certain structural properties of these nodes; y is a sequence of labels assigned to these nodes where each label belongs to a label space Y . For example, the label space of a publication record could be f Author ; Title ; Date ; Conference ; Pages ; Others g . We use the terms record , exam-ple and sequence interchangeably in this paper.
 Data: Assume that we have a set of labeled and unlabeled examples. These examples come from a collection of web-sites: S = f S 1 ;S 2 ;:::;S M g . Let S L denote the set of web-sites which contain at least one labeled example. Websites in S L can also have unlabeled examples. Let S U denote the set of websites in which we have only unlabeled ex-amples; jS U j and jS L j denote the cardinalities of S U S . Let ( x ( m ) i ; y ( m ) i ) denote the i -th example in S set in S m . Let L m and U m denote the set of indices of the labeled and unlabeled sequences from S m . Thus, a label y i is available only if S m 2 S L and i 2 L m . Finally, let T
M = [ M m =1 T m where M = f 1 ;:::;M g . Problem Formulation (Local Models): We are inter-ested in building a local probabilistic model p ( y j x ; W for each website S m to extract the attributes from the se-quences. W m denotes the local model weight vector of S m Thus, given a set of labeled and unlabeled examples from S , the goal is to learn the local model weights W = f W m m = 1 ; 2 ;:::;M g .

When we have only labeled examples, we can build the local models by optimizing the objective function L ( T M de ned as: 2 where &gt; 0 is a regularization constant. Note that in the absence of connections between the learning tasks of the web-sites, (1) becomes separable. For such a case, the local model for each website is built separately using only the labeled ex-amples from that website. We will refer to the models built in this scenario simply as the Local models.
 Problem Formulation (Global Model): Traditional ex-traction models learn a global weight vector W that is same for all websites. When we have only labeled examples, the global model is built by optimizing the objective function L ( T M ; W ) de ned as: jS 2 We will refer to the model thus built as the Global model.
Recall the two main goals of this paper: (1) to address the limited labeled data problem and (2) to overcome the generalization inadequacy of a global model. We address these problems through a graph regularization based semi-supervised multi-task learning method. The use of unlabeled examples results in semi-supervised learning. The problem of building a local model for each website can be viewed as one task; and, learning the models jointly results in multi-task learning. Now, the objective functions (1) and (2) are not adequate for semi-supervised learning (SSL) as there are no terms that involve unlabeled examples. It is also not adequate for multi-task learning (MTL) because there are no terms that connect the multiple tasks. Thus, to facilitate SSL and MTL we propose to add a weight space based graph regularization term G ( W ) to the objective functions (1) and (2) . Before we present our approach, we give details of the probabilistic model for sequences that we use in this paper.
We now make precise, the probabilistic model p ( y j x ; W ) for sequences used in the previous section. Given a record, we pose the problem of extracting attributes as a sequence labeling problem. For this purpose, we use the conditional random eld (CRF) model [21]. CRF is a Markov ran-dom eld that de nes a conditional distribution of the la-bels y of a sequence conditioned on the input x in the fol-lowing form: p ( y j x ; W ) = 1 Z denotes the model weights; C is the set of cliques present in the sequence; y c denotes the components of y present in a clique c ; ( ) is a potential function that takes non-negative values; and, Z x is the partition function de ned as Z x = P expressed as: ( x c ; y c ) = exp( P k w k f k ( x c ; y c f ( x c ; y c )s are feature functions. Then, we have: In linear chain sequence labeling problems [21], common fea-ture functions are represented as f k ( x c ; y c ) where c is either a node clique c with y c 2 Y or an edge clique c connect-ing two adjacent nodes in a sequence, with y c 2 Y 2 . Thus, we have two types of feature functions, namely, node and edge feature functions. In general the individual feature functions take real values; in many cases they are boolean. For example, a node feature function f k ( x c ; y c ) = I ( x AddressDictionary ) ^ ( y c = Address ) is TRUE when the tex-tual content of x c is in the address dictionary and assigned label Address . Here, I ( ) is the indicator function taking value 1 when the argument is TRUE and 0 otherwise.
In supervised learning, the CRF model weights W are learned using a set of labeled training examples, T = f ( x i = 1 ;:::;n g by minimizing a regularized negative log likeli-hood function: L ( T; W ) = 2 jj W jj 2 1 n P n i =1 log p ( y Thus, the function in (1) is L ( T M ; W ) = P M m =1 L ( T The objective functions (such as L ( T; W )) considered in this paper do not have closed form solutions to their minimizers; so, the optimal solutions are obtained by using optimization techniques like L-BFGS. Finally, using the learned weights, the optimal labeling of a new sequence (referred as inference) is de ned as: ^ y = argmax y p ( y j x ; W ), and is obtained using the Viterbi algorithm.
In this section we present our weight space based graph regularization method. This method can be used in one of the following three modes: (1) semi-supervised learning using labeled and unlabeled examples; (2) multi-task learn-ing of local models; and (3) combined semi-supervised and multi-task learning of local models. The third combined set-ting is especially powerful since local models can be learned even for websites with only unlabeled examples .

Our approach is to construct a graph that connects se-quences from same or di erent websites. The basic idea is to make use of common information that exist across the sequences in in uencing the node labels of the sequences. That is, if two nodes belonging to two di erent records have nearly the same features ring then these nodes are highly likely to have the same label. We illustrate this idea through some examples.

Consider two publication records, one each from two dif-ferent conference websites. Such records consist of nodes with labels such as Author , Title , Aliation . For exam-ple, suppose we have node j and the node features are: I ( FirstLetterCapital ( x j )), I ( x j 2 AuthorDictionary ), I ( x TechTermDictionary ) and I ( ContainsPunctuation ( x j +1 us say node j has label Author . The contents of this node may be such that the three features other than I ( x TechTermDictionary ) re. Suppose there is another node j with content such that the same set of features re. It is very likely that the node j 0 also has the label Author . For some other node j 00 let us say the feature I ( x j 2 AuthorDictionary ) also does not re. It is likely that j 00 also has Author as the label, but to a lesser extent than j 0 . Thus, it is reasonable to capture our belief that two nodes have the same label by using a similarity score computed from their feature vectors (e.g., the number of features that are commonly red) 1 .
We can extend this idea to connect an edge (i.e., a pair of adjacent nodes) in one record to an edge in another record. In this case, for computing similarity we concatenate the feature vectors of the two nodes that constitute the edge. If two edges have similar concatenated feature vectors then it is very likely that both have the same label pairs. Connecting such edges (i.e., putting pressure to make them have the same label pairs) is certainly very useful for improving a local model since the same label ordering is expected in all records of one website. Even in the case of edge connections going across websites with di erent attribute ordering, the edge connections are useful in handling self transitions such as ( Title , Title ) and ( Author , Author ).
 Which features should we use for determining similarity? Clearly, using global features that are useful both within and across websites is a good idea. Within a local model, it is also helpful to use local features. For example, XPath features (i.e., html tag structure with some DOM node properties) are very useful for structured pages, where DOM nodes with the same XPath are expected to have the same label. Simi-larly, we may expect an attribute to have the same format-ting properties, e.g., FontSize , FontType (i.e., bold, italic), etc. Due to the local nature of such features, we can connect nodes using these features only within each website and not across websites.

To encode our expectation that similar nodes (or edges) have same label (label pair) , we enforce their class marginal probabilities to be close , through regularization. Note that marginal probability computation takes the entire sequence into account. Below, we formalize the above idea, and facil-itate SSL and MTL by adding a graph regularization term G ( W ) to the objective functions (1) and (2).
 Graph Regularization: The graph regularization term is a function de ned on a graph G . The graph G consists of a set of vertices ( V ) and connections ( O ). To avoid confusion, we use the terminologies ( node , edge ) for the CRF cliques in the input sequences, and ( vertex , connection ) for the graph G . Each vertex has a score vector and each connection has a weight . A connection weight is a similarity score computed using features of the vertices involved in the connection. The vertices correspond to the nodes and edges of the sequences. Then, the graph regularization term is de ned using the con-nection weights and vertex scores. As we show below, the vertex scores are dependent on the model weights . Thus, the method derives the name weight space based graph regular-ization. The basic idea is to regularize the model weights by constraining the scores of a pair of vertices to be close when their connection weight is large. Before we de ne the graph regularization term, we rst explain how: (1) vertices are formed and connected, (2) connection weights are com-puted and (3) vertex scores are assigned.
 Vertices and Connecting Sequences: The role of G is to connect the sequences using some similarity measure. From section 3, we know that a sequence is characterized by a set of node and edge cliques, where an edge connects two ad-
Relational information has been used for collective clas-si cation of web documents; see for example, [23, 17, 33]. However, our work is di erent as we work with structured prediction models in the information extraction context; fur-thermore, we build local models. jacent nodes. We connect two sequences by connecting the cliques of the sequences. Thus, each clique forms a vertex in G . With this de nition, a vertex v is indexed by a 3-tuple ( m;i;c ) where c is a clique in the i -th sequence from the m -th website. Let N and E denote the sets of node and edge cliques in the collection of sequences. We have V = N [ E and jVj = jNj + jEj . Two cliques (vertices) are connected only if they are of the same type. In other words, a node (edge) clique is connected only to other node (edge) cliques . Graph Structure: G is constructed by connecting cliques of labeled and unlabeled sequences obeying the above type constraint. Thus, G has two separate components which we refer to as node graph G N and edge graph G E .
 Connection Weights Computation: We now give de-tails on nding the connection weight v;v 0 for each connec-tion ( v;v 0 ) 2 G . From Section 3 we know that the feature functions f k ( x c ; y c ) are dependent on di erent features illus-trated above. There will be many such features for a clique c and we collect these features into a feature vector F v . Note that for an edge clique we collect feature vectors of both the nodes into a single feature vector. Using feature vectors of the vertices in a connection, we set the connection weight as: v;v 0 = D ( F v ; F v 0 ) 0, a similarity score between the feature vectors. An example of a similarity score is the inner product of the two feature vectors. Thus, when the feature vectors of the two vertices ( v;v 0 ) are similar, v;v 0 ! 1 and when they are dissimilar v;v 0 ! 0.

The connection weights of G N and G E can be collected into two separate matrices, N and E . Note that N is of size jNj jNj and E is of size jEj jEj . When the number of examples (particularly, with the unlabeled exam-ples) is large these matrices can be huge. Therefore, it is useful from storage and computational viewpoints to con-struct sparse matrices by connecting each vertex to only its k nearest neighbors. In our information extraction applica-tion, the number of features is small; therefore, de ning a distance metric and nding nearest neighbors are not di-cult.
 Vertex Scores Computation: To encode our expectation that vertices having similar feature vectors have the same la-bel, we assign the class marginal probability distribution as the score vector for each vertex. Note that for each clique c , the marginal probability distribution is de ned over all possible label assignments of y c . Thus, the score vector is of size jYj for a node clique, and is of size jYj 2 for an edge clique. Let us call this score vector of a vertex v as ( g notational simplicity we have suppressed the dependence of g v on the weights and the nodes associated with the clique. Graph Regularization Term G ( W ) : Given G , vertex scores, g v ; 8 v 2 V and connection weights, v;v 0 ; 8 ( v;v O , we de ne G ( W ) as: where N and E are regularization constants; D ( ) is a di-vergence measure such as Kullback-Leibler or squared error loss; Z N and Z E are graph normalization 2 terms de ned
Other graph normalization schemes such as normalizing the connection weights by the degree of a vertex are also pos-sible. For example, use ~ v;v 0 = v;v 0 P graph normalization schemes can also be used. Thus, the graph regularization term connects the sequences by con-necting their cliques. The rst and second terms represent contributions from the node graph G N and the edge graph G
E respectively. The model weights are regularized by con-straining the scores of the cliques to be close whenever the similarity score between the cliques is large.

With the introduction of (4) the objective functions asso-ciated with the Local and Global models in (1) and (2) get modi ed to L ( T M ; W ) + 2 P m : S L ( T M ; W ) + jS U j 2 jj W jj 2 + G ( W ) respectively. Note that weight regularization corresponding to S U is also added.
The complexity of function and gradient computations of g v is O ( j F j V ) where j F j and V are the feature size and sequence length respectively; this causes the optimization of the above mentioned objective functions to be expen-sive for large datasets. Therefore, to reduce the compu-tational cost, we use an alternate score vector. From (3), we see that the score of a sequence ( x ; y ) can be de ned as: H ( x ; y ) = P c 2C h c ( x c ; y c ; W ) where h c ( x P k w k f k ( x c ; y c ) is the score contribution from clique c and is dependent on y c . Thus, for each clique c , we compute g v comprising of the scores corresponding to all possible la-bel assignments of y c . Note that g v is linear in the model weights; therefore, the function and gradient computations are cheap.

There is an additional advantage associated with using the alternate score vector. Since g v is linear in the model weights and v;v 0 0 ; 8 v;v 0 2 V , each of the sub-terms in (4) is quadratic in the model weights, and is convex. Note that (2) and (1) are also convex. Therefore, adding (4) to (2) or (1) results in a convex optimization problem with a unique solution. This solution is easily and dependably ob-tained by using optimization techniques like L-BFGS. The alternate score is not just cheaper; our experimental results (see the next section) show that very good generalization performance is achieved with it. Finally, with learned W , the Viterbi algorithm is used to make predictions. Learning Scenarios: Let us revisit the three modes of us-ing G mentioned at the beginning of this section. We make use of G for two purposes. It is used to connect the exam-ples (labeled and unlabeled), and it is also used to connect multiple tasks by connecting the examples of two di erent tasks. We show below how di erent learning scenarios can be created by setting up the graph in di erent ways. In each scenario the solution is obtained by using optimization tech-niques like L-BFGS (as in supervised learning). (1) Semi-supervised Learning : In the Global model sce-nario, G connects the examples (labeled and unlabeled) across all the websites ( S ). In the Local models scenario, G con-nects the examples (labeled and unlabeled) only within each website. In this scenario, the examples from S U are not used, and the local models can be learned independently as there are no connections between the examples from di er-ent sites. In these scenarios, the unlabeled examples are also used to learn the models. We refer the models built in these scenarios as SSL-Global and SSL-Local model(s) respectively. (2) Multi-task Learning : This is applicable only in the set Z N = 1 jNj . Similar normalization can be done for all the vertices in G E and set Z E = 1 jG Local models scenario and assume that there are only labeled examples (i.e., S U is empty and all the unlabeled sets U S
L are empty). The graph connects the labeled examples of any two di erent tasks. We refer the model built in this sce-nario as MTL models and all the models are learned jointly . Thus, the local model of a website is in uenced by the la-beled examples from other websites. This is useful when the number of labeled examples in each website is small. (3) Semi-supervised Multi-task Learning : In this sce-nario, the graph connects labeled and unlabeled examples of any two tasks. Furthermore, all the models are learned jointly . We can also have only unlabeled examples from a website. 3 Thus, unlike the above mentioned SSL and MTL learning scenarios, we can learn a local model for such a totally unlabeled website as well. The models built in this scenario are referred as SSL-MTL models.
In this section, we report experimental results with real life datasets which demonstrate the e ectiveness of our graph based regularization method in semi-supervised , multi-task and semi-supervised multi-task learning scenarios. Learning Scenarios: As explained in Sections 2 and 4, we consider various learning scenarios and they are sum-marized in Table 1. These scenarios arise due to the fol-lowing variations: (1) the composition of dataset (labeled examples ( Lab. ), unlabeled examples ( UnLab. ) and a com-bination), (2) model learning ( independent (abbreviated as indep. ) and joint ); also, we have SL : Supervised , : SSL : Semi-supervised and MTL: Multi-task learning, (3) con-nection ( within sites and across sites) and (4) number of models ( jS L j and jS U j denote the number of labeled and un-labeled websites).
 Datasets: We constructed four datasets Books ; Seminars , CS-Faculty and ML-Confs . Each dataset consists of a col-lection of list pages and each list page has multiple records. The list pages were collected from di erent websites and grouped per website to facilitate local model learning. The Books dataset has pages from eight business websites like www.amazon.com with one page per site. In most pages, the number of records per page varies from 15 to 100. Each record represents attributes (given below) of a book. The Seminars dataset has pages from ve university websites and there were 2 4 pages per website. The number of records per website is around 50. Each record represents attributes of seminar announcement. The CS-Faculty dataset has pages from ve university websites with one page per website. The number of records per page is around 40. Each record rep-resents attributes of a faculty in a university. The ML-Confs dataset has 5 websites with one page per site and each page has around 50 records representing paper details (from ICML and KDD conferences).
 Attributes: The attributes for each dataset are given as: Books: Title , Author , Publisher , Price , ISBN Seminars: Title , Speaker , Date , Aliation , Host
The local model weights for a completely unlabeled website is derived using only the weight and graph regularization terms. Therefore, closed form expression can be obtained in the case when the squared error graph regularization term de ned in (4) is used. CS-Faculty: Title , Name , Position , Education , Research Inter-ests , Phone , e-mail ML-Confs: Title , Author , Aliation , PaperID In each dataset, there is also an attribute Others which cap-tures any text that does not fall under the above categories. We manually labeled all the attributes in each record for all the datasets.
 Features: We used only global features in all our experi-ments. 4 The records were tokenized at word level. Of course, one could use simple segmentation models and this would help in improving the performance further. The content features were de ned at a higher level of abstraction. Thus, the number of features was small. For numeric attributes like Date , Price , Phone , ISBN , PaperID , we used features such as ContainsNumber , ContainsPriceSymbol , Has3Digits , Has10Digits , HasMonth , ContainsAMPM , etc. We used a dictionary of person names for attributes such as Author , Speaker , Host and had a feature InPersonNameDictionary . We also had dictionaries for other attributes Title , Research Interests , Position etc, and these dictionaries were constructed from the dataset. These types of content features were used to generate the node and edge features of the CRF model. Train-Test Split: We used 70% of the total dataset for training and 30% for testing. Note that the split happens for each website so that we can evaluate the performance for the local models at the site level. The training set was split into two sets: (1) labeled examples and (2) unlabeled ex-amples. We varied the percentage of labeled examples from 5-40% and evaluated the performance. Note that in many cases, the number of labeled records per site is 1 when the percentage of labeled examples is small. Finally, note that as we increase the percentage of labeled examples, the size of the unlabeled examples reduces. This is because the train-ing set size is xed.
 Evaluation Metric: We evaluated the F-score performance for each attribute on the test data. Due to space constraint, we present only average F1-score performance computed us-ing all the tokens (attributes). In the experiments that in-volve partial labeled websites (that is, S m 2 S L ) and totally unlabeled websites ( S m 2 S U ) we also report the performance on the test sets of partially labeled websites and totally un-labeled websites separately .
 Graph Construction and Parameter Settings: To con-struct G we used inner product of the feature vectors of the cliques to compute similarity scores. To restrict the graph size, we used k -nearest neighbors and set k = 20. We en-sure that an unlabeled example is connected to a labeled This is done to show a proof of concept of our approach. Inclusion of local features can boost the performance of our method signi cantly. example within one hop . This helps in getting improved performance. For graph normalization, we used Z N = Z E = P ization, we set = 0 : 01. Due to computational reasons, we did not use cross-validation (CV) to set these parameters. Using CV would help in getting improved performance.
We conducted several experiments with each experiment focusing on a di erent learning scenario. In all the experi-ments we used 3 partially labeled websites (PLS) (i.e., jS 3). We indicate explicitly whenever totally unlabeled web-sites were included; we experimented with jS U j = 1 and 2. We evaluated the performance on varying combinations of the websites in S L and S U . Due to space constraint, we present only some of the results. 1. Local versus Global :
We used three websites as the dataset and varied the per-centage of labeled examples. The results are shown in the top row of Figure 1. Two key observations can be made. (1) As the number of labeled examples per website increases, the performance of the Local models is signi cantly better than the Global model; this emphasizes the need for Local models. (2) When the number of labeled examples per web-site is insucient, node features from other websites help; as a result the Global model is better (except the case of Books dataset). In the Books dataset we had at least 8% more records per site on average than the other datasets; therefore, Local models were able to learn better even with 5% labeled data per site. 2. Local versus MTL :
The dataset is same as the one used in the Local models scenario. The results are given in the bottom row of Fig-ure 1. It is clearly seen that the MTL local models learned jointly using graph regularization outperform the Local mod-els learned independently. On comparing the two rows in Figure 1, we also see that the performance of the MTL model outperforms the Global model. It is seen that our weight space based graph regularization with MTL helps in making use of labeled examples from other websites constructively (even in the presence of variations across the websites); and, the improvement is signi cant (3% 8%) when very few la-beled examples are available. Thus, the proposed method addresses both the limited labeled data and generalization inadequacy problems. 3. Global versus SSL-Global:
We expand the dataset used in the experiment to build the Global model by including unlabeled examples. Fig-ure 2 shows the performance comparison of the Global and SSL-Global models. When the number of labeled examples is not very small, SSL-Global model outperforms the Global Global Model. Bottom Row: Local versus MTL Models. jS j = 3 and jS U j = 0 . jS
L j = 3 and jS U j = 0 . Local and MTL models. jS L j = 3 and jS U j = 0 . mance -SSL-Local , MTL and SSL-MTL models. jS L j = 3 and jS SSL models on test sequences of partially labeled sites (PLS -jS model on Books , Seminars and CS-Faculty datasets. In the ML-Confs dataset, the graph is not that good (compared to other datasets), possibly due to weaker features for the attribute Title , resulting in no improvement; this is also ob-served in SSL-Local and SSL-MTL models discussed below. 4. Local versus SSL-Local:
From Figure 3 we see that the performance of SSL-Local is better than Local in most cases and it is signi cant in some cases. The performance is slightly inferior only in one case, on the MLConfs dataset (when the number of labeled examples is high). 5. SSL-Local versus MTL: We also compare the performance of Local models with Semi-supervised ( SSL-Local ) and Multi-task ( MTL ) learning. Figure 3 shows that the performance improvement obtained using multi-task learning is signi cantly higher. Note that in the MTL scenario, the connections are between the la-beled examples across the sites. Thus, the weights are ad-justed more appropriately by trading-o between the likeli-hood term and graph regularization term. In semi-supervised learning, there are also connections between unlabeled ex-amples. Therefore, there is more freedom. Recall the within one hop condition used in our graph construction. Thus, the scores of the connections having only unlabeled examples are regularized only indirectly through the score propaga-tion between the labeled and unlabeled examples, resulting in lesser gain. 6. SSL-MTL:
Recall from Table 1 that SSL-MTL combines semi-supervised and multi-task learning. Figure 4 depicts the performance comparison of various local model learning scenarios. We have already seen that MTL models outperform Local mod-els. Here, we see that combined Semi-supervised Multi-task learning provides signi cant additional gain in sev-eral cases (see for instance, Books and Seminars datasets). Thus, the proposed method is e ective in combining semi-supervised and multi-task learning in a single framework. 7. Totally Unlabeled Websites:
The aim of this experiment is to demonstrate that good local models can be built even for websites with totally un-labeled examples. We evaluate the performance on the par-tially labeled sites (PLS) and totally unlabeled sites (TUS). From Figure 5 (one and two totally unlabeled sites), the following observations can be made. (1) In the case of PLS, SSL-MTL models perform better than the SSL-Global model on Books and CS-Faculty datasets; on the remaining datasets, they are comparable. (2) In the case of TUS, SSL-MTL models perform better in many cases, viz., Books , Sem-inars and CS-Faculty datasets; it is comparable to SSL-Global on ML-Confs dataset. These results clearly demonstrate that decent local models can be built for websites with completely unlabeled examples using our method, though the accuracy is a ected by the degree of similarity between the di erent sites. 8. Varying Unlabeled Website:
In practice we can at most have a few websites with la-beled examples. These partially labeled sites are used to build the local models for totally unlabeled websites. One practical scenario is to build a local model for one TUS at a time . The aim of this experiment is to evaluate the proposed method in this scenario. Figure 6 shows the results obtained on the Books dataset, where we built SSL-MTL models with 3 xed PLS and varied 1 TUS. The results show that the per-formance on PLS is almost same. As one would expect some variations in the performance are seen across the totally un-labeled websites. This is because the diculty of a website varies in terms of several optional and missing attributes in the sequences. However, we get decent performance on all TUS. Figure 6: Varying Unlabeled Site Scenario -Aver-age F1-score performance of SSL-MTL models on the Books Dataset. The website numbers used as PLS ( jS L j = 3 ) and TUS ( jS U j = 1 ) in a set of 8 websites are indicated. [7, 31] present comprehensive surveys on existing tech-niques of web information extraction.

As we indicated in section 1, unsupervised learning tech-niques such as RoadRunner [11], DEPTA [39], and cluster-ing based techniques [3, 25] are useful for extracting records from list pages via repetitive patterns in the HTML tags of one or more pages. They are ine ective for the ner problem of attribute segmentation.

There exist several methods for attribute extraction from many websites using minimal/weak supervision [1, 26, 40, 28, 24, 10, 9, 34, 15]. Let us look at some representative ones. To learn wrappers for new websites, Chuang et al. [9] pro-pose a method for synchronized data extraction using con-textual information from reference websites. In contrast, our solution is based on machine-learned discriminative models. Senellart et al. [34] trained CRF models using high precision annotated records which are obtained using domain knowl-edge. Gupta et al. [15] address the problem of constructing a table for n-tuple record type queries. After collecting a set of list pages from the web using the queries, they build inde-pendent local CRF models using annotated records obtained from an existing database and extract attributes of inter-est. The extracted records are then added to the database. This is a pipelined approach that works only when there are matching records across the websites; our method does not require that assumption. Unlike [34, 15] we build the models jointly and make use of unlabeled examples.

Among the SSL approaches for sequence learning [20, 2, 36, 37, 18, 35], our method is closely related to [2, 35]. As in our method, [2] connects cliques of the sequences. While our method is weight space based and simple, [2] optimizes in dual space which requires computationally intensive ma-trix inversion (cubic in graph size). [35] proposes a graph regularization based SSL approach for a POS tagging do-main adaptation problem; unlike our method, their method alternates between model parameter learning and marginal probability smoothing using graph regularization. None of the above mentioned approaches build local models jointly and they do not learn local models for new websites.
There has been a signi cant amount of work on multi-task learning [6, 14, 13, 4, 22, 16]. Of these only [13] builds local models using a graph that connects multiple tasks; even this work does not build a model for a task with totally unlabeled examples. Also, the main focus of these papers is not on the structured outputs problem for information extraction.
In other related work on domain adaptation [32, 12, 8], the approach of Duan et al. [12] is more close to our ap-proach. However, our graph construction procedure is dif-ferent; also, like [8] it only addresses a multi-class classi ca-tion problem and not the structured output problem. Fur-thermore, unlike our approach none of the above mentioned works learn the models jointly.
In this section, we discuss several extensions that are pos-sible in this framework. The graph regularization term that we used in this paper is based on squared error loss. An alternative way is to regularize using Kullback-Leibler (KL) divergence computed using probability scores of cliques. This can be done by de ning the probability score for a label as-signment y as p v ( y ) = 1 Z edge clique) where Z v is a normalizing constant. Next, the graph G plays a very important role in getting improved per-formance. Using di erent similarity measures and graph normalization schemes can also be useful. Another possibil-ity is to group the content features into various sub-groups and construct a graph for each sub-group. From local mod-eling viewpoint, local features like XPath based features are very useful. Therefore, adding local features into the model and constructing a graph based on these local features will help in boosting the performance signi cantly on the to-tally unlabeled websites. Use of entropy regularization [18] for semi-supervised learning has been explored. Extending this to semi-supervised multi-task learning is another interesting direction. Finally, note that although we only experimented with sequences, the framework is general and is applicable to more complex structured outputs such as trees, graphs, etc. Also, it can be used to build structured support vector machine (SVMStruct) models.
In this paper we proposed a weight space based graph reg-ularization method for semi-supervised , multi-task and semi-supervised multi-task learning. We demonstrated its e ectiveness in the three learning scenarios for web in-formation extraction. The results clearly demonstrate that the method is useful in addressing the issues of limited la-beled data and inadequacy of a global model in generalizing well across websites. An added advantage is that we can learn decent local models for websites without any labeled data also, which is not possible even for wrapper learning approaches. Our method is scalable since we can learn the local models for unlabeled websites in parallel using a xed set of partially labeled websites. Furthermore, the newly labeled websites obtained through learning can be used to learn subsequent unlabeled websites (by updating the exist-ing list of labeled websites).
 Acknowledgments: The authors are thankful to the anony-mous reviewers for their helpful comments. [1] E. Agichtein and V. Ganti. Mining reference tables for [2] Y. Altun, D. McAllester, and M. Belkin. Maximum [3] M. Alvarez, A. Pan, J. Raposo, F. Bellas, and [4] R. K. Ando and T. Zhang. A framework for learning [5] V. Borkar, K. Deshmukh, and S. Sarawagi. Automatic [6] R. Caruana. Multi-task learning. In Machine [7] C.-H. Chang, M. Kayed, M. R. Girgis, and [8] B. Chen, W. Lam, I. Tsang, and T.-L. Wong.
 [9] S.-L. Chuang, K. C.-C. Chang, and C. Zhai.
 [10] E. Cortez, A. S. da Silva, M. A. Goncalves, and E. S. [11] V. Crescenzi, G. Mecca, and P. Merialdo. Roadrunner: [12] L. Duan, I. W. Tsang, D. Xu, and T.-S. Chua. [13] T. Evgeniou, C. A. Michelli, and M. Pontil. Learning [14] T. Evgeniou and M. Pontil. Regularized multi-task [15] R. Gupta and S. Sarawagi. Answering table [16] J. Honorio and D. Samaras. Multi-task learning of [17] D. Jensen, J. Neville, and B. Gallagher. Why [18] F. Jiao, S. Wang, C.-H. Lee, R. Greiner, and [19] N. Kushmerick, D. S. Weld, and R. Doorenbos. [20] J. La erty, Y. Liu, and X. Zhu. Kernel conditional [21] J. La erty, A. McCallum, and F. Pereira. Conditional [22] Q. Liu, X. Liao, and L. Carin. Semi-supervised [23] Q. Lu and L. Getoor. Link based classi cation. In [24] I. R. Mansuri and S. Sarawagi. Integrating [25] G. Miao, J. Tatemura, W. Hsiung, A. Sawires, and [26] M. Michelson and C. A. Knoblock. Unsupervised [27] I. Muslea, S. Minton, and C. Knoblock. Hierarchical [28] P. Papotti, V. Crescenzi, P. Merialdo, M. Bronzi, and [29] F. Peng and A. McCallum. Accurate information [30] H. Poon and P. Domingos. Joint inference in [31] S. Sarawagi. Information extraction. Foundations and [32] S. Satpal and S. Sarawagi. Domain adaptation of [33] P. Sen, G. M. Namata, M. Bilgic, L. Getoor, [34] P. Senellart, A. Mittal, D. Muschick, R. Gilleron, and [35] A. Subramanya, S. Petrov, and F. Pereira. Ecient [36] J. Suzuki and H. Isozaki. Semi-supervised sequential [37] Y. Wang, G. Ha ari, S. Wang, and G. Mori. A rate [38] T. Weninger, W. H. Hsu, and J. Han. CETR -content [39] Y. Zhai and B. Liu. Web data extraction based on [40] C. Zhao, J. Mahmud, and I. V. Ramakrishnan.
 [41] J. Zhu, Z. Nie, J. Wen, B. Zhang, and W. Ma.
