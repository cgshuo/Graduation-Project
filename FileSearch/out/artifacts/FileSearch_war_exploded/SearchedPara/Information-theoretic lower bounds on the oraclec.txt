 understanding the computational complexity of convex optimization is a key issue. various classes of convex optimization problems. A typical outcome of such analysis is an upper Such analyses have been performed for many standard optimization alogrithms, among them gradi-results.
 in the seminal work of Nemirovski and Yudin [8] (hereafter referred to as NY). One obstacle to mization problems in a Turing Machine model. They avoided this problem by instead considering a authors obtained a series of lower bounds on the computational complexity of convex optimization notes by Nemirovski [7].
 NY [8] in two ways. First, our lower bounds have an improved dependence on the dimension of the corresponding complexity with absolute loss. Our proofs exploit a new notion of the discrepancy between two functions that appears to be natural for optimization problems. They are based on a and an application of information-theoretic lower bounds for the estimation problem. and then define the oracles considered in this paper. 2.1 Convex optimization in the oracle model Convex optimization is the task of minimizing a convex function f over a convex set S  X  R d . following question: given any class of convex functions F , what is the minimum computational labor any such optimization method would expend for any function in F ? x in this paper, these values are corrupted with zero-mean noise with bounded variance. Given some number of rounds T , an optimization method M designed to approximately minimize T steps as quantity. 2.2 Minimax error we can define the minimax error error over all S  X  S , given by the function  X  is clear from the context, we simply write  X  ( F ) .
 It is worth noting that oracle complexity measures only the number of queries to the oracle X  X or with evaluating the gradient). 2.3 Types of Oracle evaluations; consequently, any oracle  X  in this class can be written as where b f ( x ) and ent values respectively (i.e., E b f ( x ) = f ( x ) and E b f ( x ) and convex function f is any vector v  X  R d such that Stochastic gradient methods are popular examples of algorithms for such oracles. Notation: For the convenience of the reader, we collect here some notation used throughout the  X 
H (  X , X  ) := P stochastic oracle optimization. We begin by analyzing the minimax oracle complexity of optimiza-for all x,y  X  S .
 diameter of S is also bounded by 1, this automatically enforces that | f ( x ) | X  1 ,  X  x  X  S . a constant c (independent of d ) such that Remarks: This lower bound is tight in the minimax sense, since the method of stochastic gradient (see Chapter 5 of NY [8]). Also, even though this lower bound requires the oracle to have only bounded variance, we will use an oracle based on Bernoulli random variables, which has all mo-bounded moments where we get slower rates (again, see Chapter 5 of NY [8]). The above lower bound is obtained by considering the worst case over all convex sets. However, easily obtain a corollary of Theorem 1 that quantifies this intuition.
 R  X  . Then there is a universal constant c such that, Remark: The ratio r  X  R a particular application of above corollary, consider S to be the unit ` 2 ball. Then r  X  = 1  X  R  X  = 1 . which gives a dimension independent lower bound. This lower bound for the case of the ` ball is indeed tight, and is recovered by the stochastic gradient descent algorithm [8]. For this class of functions, we obtain a smaller lower bound on the minimax oracle complexity of optimization.
 Then there is a universal constant c such that, Once again there is a matching upper bound using stochastic gradient descent for example, when follows again.
 In comparison, Nemirovski and Yudin [8] obtained a lower bound scaling as  X  1  X  as opposed to the bounds provided here. Obtaining the correct dependence yields tight minimax state a result for general function classes. 3.1 An application to statistical estimation R this is exactly the problem of computing the -accurate optimizer of a convex function, assuming the previous sections would apply. Our bounds, then allow us to deduce the oracle complexity of under which expectation is taken. From our bounds, it is straightforward to deduce: over all possible distributions is  X  d/ 2 . over all possible distributions is  X  ( d/ ) .
 an oracle with lower variance. common to our proofs. 4.1 High-level outline Our main idea is to embed the problem of estimating the parameter of a Bernoulli vector (alter-In more detail, the proofs of Theorems 1 and 2 are both based on a common set of steps, which we describe here.
 of functions G  X  F that we use to derive lower bounds. Any such subclass is parameterized by  X  |V| X  (2 / g  X   X  X  (  X  ) has the form are bounded over the convex set S with a Lipschitz constant independent of dimension d , and the the proofs of Theorems 1 and 2.
 Step II: Optimizing well is equivalent to function identification. In this step, we show that if x functions f,g , we define and only if x  X  f = x  X  g , so that we may refer to it as a semimetric.
 the quantity Note that x  X   X  denotes a minimizing argument of the function g  X  .
 Lemma 1. For any g ( Thus, if we have an element Proof. For a given From the definition of  X  (  X  ) in (10), for any  X   X  X  ,  X  6 =  X  , we have which implies that g  X  ( Suppose that we choose some function g  X   X   X  G (  X  ) , and some method M T is allowed to make T true function g  X   X  . Recall the definition (2) of the minimax error in optimization: Lemma 2. Suppose that some method M T has minimax optimization error upper bounded as Then the method M T can construct an estimator Proof. Given a method M T that satisfies the bound (11), we construct an estimator set From Lemma 1, there can exist only one such  X   X  V that satisfies this inequality. Consequently, using Markov X  X  inequality, we have P  X  [ Maximizing over  X   X  completes the proof.
  X   X  X  can be identified. Step III: Oracle answers and coin tosses. We now demonstrate a stochastic first order oracle  X  lying in the set presents noisy value and gradient samples from g  X  according to the following prescription:  X  Pick an index i t  X  X  1 ,...,d } uniformly at random.  X  Draw b i  X  Return the value and sub-gradient of the function constant is independent of d since the function values and gradients are bounded on S . Step IV: Lower bounds on coin-tossing Finally, we use information-theoretic methods to lower bound the probability of correctly estimating the true vertex  X   X   X  X  in our model.  X  uniformly at random is revealed at every round. Then for all  X   X  1 / 4 , any estimator distributions P T  X  for  X   X   X (  X  ) . In particular, using the proof of Lemma 3 in [11] we get: In our case, we upper bound b as follows: b = KL ( P T  X  || P T  X  0 ) = Each term KL ( P  X  i ( X t ) || P  X  0 with parameters 1 / 2 +  X  and 1 / 2  X   X  . A little calculation shows that note that P [ claim. 4.2 Proofs of main results We are now in a position to prove our main theorems. Proof of Theorem 1: By the construction of our oracle, it is clear that, at each round, only one coin is revealed to the method M T . Thus Lemma 3 applies to the estimator In order to obtain an upper bound on P [ subclass G base of F C . For i = 1 ,...,d , define: P [ Substituting  X  = 18 yields T =  X  d 2 for all d  X  11 . Combining this with Theorem 5.3.1 of NY [8] gives T =  X  d 2 for all d .
 R these dependences into account gives the desired result.
 Proof of Theorem 2: In this case, we define the base class is identical to Theorem 1.
 The reader might suspect that the dimension dependence in our lower bound for strongly convex possible value of  X  under the assumptions of the theorem. 4.3 A general result function class F . The proof is similar to that of earlier results.
 c X  q d T .
 Acknowledgements We gratefully acknowledge the support of the NSF under award DMS-0830410 and of DARPA under award HR0011-08-2-0002. Alekh is supported in part by MSR PhD Fellow-ship.
 [1] D.P. Bertsekas. Nonlinear programming . Athena Scientific, Belmont, MA, 1995. [3] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In NIPS . 2008. [4] S. Boyd and L. Vandenberghe. Convex optimization . Cambridge University Press, Cambridge, [6] J. Matousek. Lectures on discrete geometry . Springer-Verlag, New York, 2002. [7] A. S. Nemirovski. Efficient methods in convex programming. Lecture notes . [8] A. S. Nemirovski and D. B. Yudin. Problem Complexity and Method Efficiency in Optimiza-[9] S. Shalev-Shwartz and N. Srebro. SVM optimization: inverse dependence on training set size. [10] Nesterov Y. Introductory lectures on convex optimization: Basic course . Kluwer Academic
