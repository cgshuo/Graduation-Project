 In the paper we show that diagnostic classes in cancer gene expression data sets, which most often include thousands of features (genes), may be effectively separated with simple two-dimensional plots such as scatterplot and radviz graph. The principal innovation proposed in the paper is a method called VizRank, which is able to score and identify the best among possibly millions of candidate projections for visual-izations. Compared to recently much applied techniques in the field of cancer genomics that include neural networks, support vector machines and various ensemble-based ap-proaches, VizRank is fast and finds visualization models that can be easily examined and interpreted by domain experts. Our experiments on a number of gene expression data sets show that VizRank was always able to find data visualiza-tions with a small number of (two to seven) genes and ex-cellent class separation. In addition to providing grounds for gene expression cancer diagnosis, VizRank and its visu-alizations also identify small sets of relevant genes, uncover interesting gene interactions and point to outliers and po-tential misclassifications in cancer data sets.
 J.3 [ Life and Medical Sciences ]: [Biology and Genet-ics]; I.2.1 [ Artificial Intelligence ]: Applications and Ex-pert Systems X  Medicine and Science Algorithms Gene Expression Analysis, Cancer Diagnosis, Machine Learn-ing, Data Mining, Data Visualization
DNA microarrays simultaneously measure the expression of thousand of genes in a biological sample to determine which genes are differently expressed in various cells and tissues. Gene expression measurement may provide for a powerful tool in uncovering the genetic mechanisms causing the loss of cell cycle control and the consecutive development of cancer. Several recent studies of different cancer types [1, 2, 10, 13, 17, 18, 19, 20] have demonstrated the superior performance of gene expression profiles for cancer classifi-cation when compared to standard morphological criteria. The ultimate goal of this approach is improvement and in-dividualization of treatment and detection of pathogenomic biological markers of different tumors for earlier diagnosis and prognosis.

Gene expression data analysis is characterized by extreme-ly high data dimensionality due to thousands of gene expres-sion values measured for each sample on an array. At the same time, the number of samples (patients) is far smaller. The analysis of this peculiar and noisy data has been chal-lenged by a number of different approaches in bioinformatics that include feature subset selection to focus only on genes that bear most information on the cancer type, unsupervised and supervised machine learning methods, and various vi-sualization techniques.

In unsupervised analysis of cancer gene expression data, a standard procedure is to select a set of the most informative genes and then use them in principal component analysis (PCA) [13]. It has been shown that, under appropriate gene selection, visualization of data using the first two principal components may reveal separated clusters, each comprising the data of a prevailing diagnostic class. While such an approach can demonstrate that diagnostic classes may be separated by gene expression data, the clinical and genomic interpretation of the results is hard as each component may combine expression of tens or hundreds of genes.

To use the diagnostic class information in the learning process, a number of recent studies supervised machine learn-ing techniques such as artificial neural networks [13], k -nearest neighbors with weighted voting of informative genes [10] and support vector machines (SVM) [9, 21]. While it was recently shown that SVM are a method to uncover mod-els with most reliable classifications [21], such classification models often combine relatively weak contributions of up gene expressions. to thousands of genes and are therefore hard to understand and interpret by the domain experts.

The research reported in this paper aimed to investigate how  X  X ard X  are gene expression cancer data sets in terms of finding good and simple classifiers. Our working hypothesis was that visualizations that include only a few genes and use the untransformed gene expression data can provide for a clear separation of diagnostic classes. Differently from the related work, we address the problem of finding good visu-alizations directly with an algorithm that uses a powerful heuristic to search through a space of possible data projec-tions and a machine learning approach that evaluates and assigns a score for each projection. The visualization scoring and search algorithm called VizRank and exploration of its utility in the analysis of cancer expression data sets are two principal contributions of this paper. Using two planar geo-metric visualizations, namely scatterplot when visualizing two genes and radviz for visualizations with three genes or more, we show that we are always able to find simple visu-alizations which include only a handful of genes and provide for a clear split of diagnostic classes.

Two examples of such graphs visualizing gene expression data on leukemia are shown in Figure 1. Besides being simple, allowing to depict both individual role of visualized genes and their interactive effects, these visualizations also identify relevant genes for cancer prediction and can provide grounds for identification of potential outliers.
In the paper, we first introduce the two geometric visual-ization methods used, scatterplot and radviz. Components of VizRank, which include search algorithm, a method for scoring of visualizations, and a search heuristic are presented next. We then use VizRank on a set of eight cancer gene ex-pression data sets, where we report on the role of the heuris-tic, experimentally assess how likely it is to find a good and simple visualization, and present the best visualization for each of the data sets. We show that these simple visual-izations provide clear separation of diagnostic classes and include biologically relevant genes.
Many techniques exist that can be used to visualize mul-tidimensional data. VizRank method proposed in this pa-per can be applied to any geometric visualization method, that is, any method where data instances are visualized as points in a two-dimensional space and the values of visual-ized features only influence the position of the data point in the graph, and not its size, shape or color. In this pa-per we present results using two such methods  X  a scatter-plot, a method for visualizing data using two features, and radviz, which can concurrently visualize a larger number of features. Since scatterplot is perhaps the simplest and well-known multi-dimensional visualization method, we here in detail describe only radviz.

In radviz [12], m visualized features are represented as anchor points equally spaced around the perimeter of a unit circle (see Figure 1.b for example). Data instances are shown as points inside the circle, and the position of the instance within a graph can be explained using a physical analogy with multiple springs. There are m springs attached to the instance point, one for each of the feature anchors. The stiff-ness of each spring in terms of Hooke X  X  law is determined by the corresponding feature value  X  the greater the value, the greater the corresponding stiffness. The point representing the data instance is then placed at the position where the sum of all spring forces equals 0 (see [4] for mathematical details). To bring values of features on the same scale and to allow for a simpler interpretation of radviz graphs, features are standardized to the interval between 0 and 1.
Figure 1.b shows an example of a radviz graph; the graph shows  X  X prings X  for a selected data instance, this being close to the anchor with gene SET bearing the largest standard-ized expression (0.61) and somewhere in-between anchors for genes CD19 and PARG with a similar expression (0.54 vs. 0.47, respectively). The  X  X ttractive force X  of other three genes in this particular graph is smaller.

In radviz the points that have approximately equal values of features that lie on the opposite sides of the circle will lie close to the center of the circle. On the other hand, the points with one of the features having a much larger value than others will lie close to the anchor of that feature. The particular visualization using a selected set of features will therefore largely depend on the position/order of feature an-chors. Placing two highly correlated features that are good at discriminating between classes on the opposite side of the circle will make them useless in the visualization, since their joint effect will be cancelled out. On the other hand, they might generate a projection with well separated classes if their anchors are placed adjacently. The  X  X orrect X  place-ment of feature anchors was for instance crucial for a nice separation of classes in Figure 1.b, where the three anchors (genes) on the left side of the circle attract data points from the ALL class and anchors (genes) on the right side of the circle attract points with AML class value.
The two visualizations in Figure 1 can be considered in-teresting because the data instances that belong to different class are well-separated. They show data projections for which we can visually infer rules for discriminating between different class values. When features are in abundance, the main question is how to find the most informative data pro-jections as the manual search through the projection space is not feasible.
We have developed a method called VizRank to enable an automatic, algorithm-based search for the most informative data visualizations. For a given data set and a visualization method, VizRank returns a ranked list of most informative data projections along with the numerical assessments of their  X  X nterestingness X . In this way the data analyst is re-lieved of the unguided search through numerous possible projections, and can focus only on the top-rated visualiza-tions that can provide the best insight into the data.
VizRank evaluates each by generating a corresponding vi-sualization using a selected visualization method and com-putes its score based on how well the visualization separates the instances of different class. In other words, the visu-alization score is related to how likely it is for an analyst to spot a visual pattern in the projection that reveals some regularity in the domain.

VizRank solves the problem of projection assessment by applying a machine learning method on the graphically rep-resented data and estimates the accuracy of the induced classifier. Input to machine learning are x and y coordi-nates of the points representing data instances in the as-sessed graph and their corresponding class labels. The esti-mated predictive accuracy of the classifier on this data set is then used as a score for the particular projection. Notice that if the data instances in the projection are clearly sep-arated, the predictive accuracy for some machine learning algorithms is expected to be high. High visualization scores computed in this way are therefore indicators of usefulness of a visualization.

We use k -nearest neighbor ( k -NN) with Euclidian distance metrics as a supervised machine learning method for visu-alization scoring. When applied to our 2-dimensional visu-alizations, Euclidian distance well matches the intuitive dis-tance used by human observer when viewing the graph [5]. Using this distance metrics, k -NN predicts class value of an instance by observing the class distribution of its k near-est instances in the evaluated projection. If the prediction matches the true observation, this would mean that an in-stance is surrounded by instances with the matching prevail-ing class. Since k -NN does not impose any constraints on decision boundaries that separate instances from different classes, we believe this method may be the most suitable for our visualization scoring and may well match the interest-ingness as seen from the perspective of human analysts.
In our experiments, we use leave-one-out evaluation sche-ma to obtain the predictive accuracy of a k -NN classifier. For a parameter k , we have followed the recommendation by Dasarathy [6] which, to classify each instance, uses a neighborhood of k = of instances in the data set. To make the method less sen-sitive to the choice of k we also use weighted voting, where contribution of each instance in the neighborhood decreases with the distance, so that close neighbors have greater in-fluence on the prediction than those farther away from the instance being classified.
There are several measures (scoring functions) we could use to evaluate the performance of k -NN classifier. One of the most often used measures is classification accuracy that is defined as the proportion of correctly classified instances. For the purpose of projection evaluation we found that clas-sification accuracy is too crisp as it considers only if the example was correctly or incorrectly classified and ignores the prediction uncertainty. As an example, Figure 2 shows two radviz projections of the MLL data set that both have 100% classification accuracy. However, the visualization on the left has a much nicer separation of the classes and should therefore be favored over the projection on the right.
When prediction is based on the weighted proportion of the neighboring instances belonging to each class, k -NN can be regarded as a probabilistic classifier. To appropriately consider the predicted class probabilities, we measure the projection interestingness as an average probability P that the classifier assigns to the correct class: Here, N is the number of instances in the data set, and P
C ( y i | x i ) is the probability assigned to the correct class value y i for example x i by the classifier C . Using this mea-sure we can take into account the prediction uncertainty for examples in Figure 2.b that lie on the boundary be-tween MLL and AML group and lower the projection value accordingly. Average probabilities assigned to the correct classes P for these two projections are 99.63% and 97.98%, and 97.98% (b). respectively, favoring the visualization with a clearer class separation.
In the data sets with thousands of features, such as those on cancer gene expressions, number of possible possible data projections is extremely high. Using a data set with m features, there are m ( m  X  1) / 2 different scatterplot projec-tions. For SRBCT, the smallest data set in terms of num-ber of the features considered in this paper, the number of different scatterplot visualizations is 2,656,508. For radviz method, the number of different projections is even consid-erably higher, since the method can concurrently visualize a larger number of features and has to consider different placement of these in the graph. Even for a computerized method it is therefore impossible to exhaustively search over all possible projections and search heuristic must be used in-stead.

The search heuristic we developed for VizRank starts by estimating the predictive quality of each single feature us-ing the ReliefF measure [15]. Other feature scoring function may be used instead, but we choose to use ReliefF since it can detect feature interactions and could possibly assign higher scores to features that could be overlooked using some other, univariate analysis measure. Next, for each projec-tion, a rough estimate of its usefulness is computed as the sum of ReliefF X  X  values for features that are present in the projection. VizRank then assesses projections starting with those with those most promising according to sum-of-ReliefF value. As we show in the next section, such heuristic is suc-cessful and allows VizRank to evaluate only a small subset of projections to find those with best class discrimination.
We have used eight cancer gene expression data sets to evaluate the proposed approach. Experiments on these data sets were not only an academic exercise to assess our algo-rithms: the data sets come from recent clinical studies for which the problem of finding most informative genes and gene interactions is still open and highly relevant.
In our experimental study we have considered eight pub-licly available cancer gene expression data sets with two to five distinct diagnostic categories, 40 to 203 samples (pa-tients) and 2308 to 12625 features (gene expressions). The basic information on these is summarized in Table 1.
Three data sets, leukemia [10], diffuse large B-cell lym-phoma (DLBCL) [19] and prostate tumor [20] include two diagnostic categories. The leukemia data consists of 73 tis-sue samples, including 48 with acute lymphoblastic leukemia (ALL) samples and 25 with acute myeloid leukemia (AML), each with 7074 gene expression values. The DLBCL data set includes expressions of 7070 genes for 77 patients, 59 with DLBCL and 19 with follicular lymphoma (FL). The prostate tumor data set includes 12533 genes measured for 52 prostate tumor and 50 normal tissue samples.

The other five data sets analyzed in this work are mul-ticategory. The mixed lineage leukemia (MLL) [1] data set includes 12533 gene expression values for 72 samples ob-tained from the peripheral blood or bone marrow samples of affected individuals. The ALL samples with a chromo-somal translocation involving the mixed lineage gene were diagnosed as MLL, so three different leukemia classes were obtained (AML, ALL and MLL). The small round blue cell tumors (SRBCT) data set [13] consists of four types of tu-mors in childhood, including Ewing X  X  sarcoma (EWS), rhab-domyosarcoma (RB), neuroblastoma (NB) and Burkitt X  X  lym-phoma (BL). It includes 83 samples derived from both tu-mor biopsy and cell lines and 2308 genes. For the analysis of the brain tumor gene expression data, we used the A1 data set [18] that includes 40 embryonal tumor samples of the top-ranked scatterplot and radviz projection. the central nervous system (10 medulloblastomas (MD), 10 malignant gliomas (MG), 5 rhabdoid tumors (Rh), 6 prim-itive neuroectodermal tumors (PN) and 4 normal cerebella (Nc)) and 7129 genes. The glioblastoma data set [17] con-sists of 50 brain tumor samples, including 28 glioblastomas and 22 anaplastic oligodendrogliomas that are additionally classified as classic (CG, CO) or non-classic (NG, NO). The last data set is the lung cancer data set [2] that contains 12600 gene expression values for 203 lung tumor samples (139 adenocarcinomas (AD), 21 squamous cell lung carci-nomas (SQ), 20 pulmonary carcinoids (COID), 6 small cell lung cancers (SMLC) and 17 normal lung samples (NL)).
All data sets except the SRBCT were obtained from Affy-metrix gene chips and are available at http://www.broad.-mit.edu/cancer/. The SRBCT gene expression data set was obtained from cDNA microarrays and is available at http://research.nhgri.nih.gov/microarray/Supplement/.
In the study, we let VizRank evaluate a large number of projections and were interested in the distribution of evalua-tion scores. It turns out that only a relatively small propor-tion of visualizations bear high interestingness score as as-signed by VizRank. For instance, Figure 3 shows that among 5,000 top-ranked scatterplots identified by our heuristic in the MLL data set, there only a few projections scored above 90%. The fast drop in the projection scores is welcomed and indicates that there are only a few projections that are most relevant and are needed to be considered for a detailed in-spection by an analyst. We have observed similar projection score distributions on other data sets, also when increasing the total number of evaluated projections.
Our hypothesis is that the utility of search heuristic would allow VizRank to reduce the number of projections it needs to evaluate, and search over projections with consequently highest projection scores first. The later is important in terms of user X  X  interface, and would allow to present pro-jections with good class separation even within the first few seconds of the search time.

We have compared a heuristic search and a search with a random selection of projections in terms of the best pro-jection found. Figure 4 shows the results on SRBCT data set: the plot shows the score of the best-found projection Figure 3: Visualization scores for the best 5,000 scatterplot projections of the MLL data set. Visual-izations were ranked based on their score, starting with best-scored visualization. as a function of a number of projections being evaluated. The value of heuristic is clear, as when compared to a ran-dom search allows to find much better projections even if only a few have been considered. For the reasons of brevity the results on other data sets are not shown here, but are qualitatively very similar to those shown in Figure 4. For each of the cancer gene expression data sets we used VizRank to find top-ranked scatterplot and radviz visual-izations. Due to extremely large number of possible projec-tions, for each data set VizRank was constrained to evaluate only 200,000 projections as selected by the search heuristic. The typical performance of VizRank on such data sets using a Pentium 4 PC with 2.4GHz processor is about 30 projec-tions per second, so the typical evaluation time for 200,000 projections was about two hours.

Although the radviz method can in principle visualize an arbitrary number of features, this has a significant influ-ence on interpretation value of the visualization. Also, if Figure 4: The importance of the heuristic for fast identification of top-ranked projections. The figure shows projection score for the best found projections on the SRBCT data set using radviz method with and without the use of heuristic. the method is able to find visualizations with clear sepa-ration of diagnostic classes using only a small number of features, these should be preferred over visualizations with many features. For this reason, we have only investigated radviz projections with 3 to 7 features.

Visualizations with highest VizRank scores for MLL, pros-tate, DLBCL, glioblastoma, brain tumor, and lung cancer data sets are shown in Figure 6, for leukemia in Figure 1.b, and for SRBCT in Figure 5.a. The best radviz visualizations scored higher than the best scatterplots. The best scored radviz visualizations included anywhere from five (MLL) up to seven features (glioblastoma and brain tumor). Most of the visualizations show a clear separation of instances from different diagnostic classes, with the only exception of brain tumor (two outliers) and lung cancer, where instances of the AD class group together but are placed within the group with prevailing SQ class. Interestingly, the adenocarcino-mas in the lung cancer data set are also histologically not a unique class. It was reported by Bhattacharjee et. al [2] that seven adenocarcinomas express high levels of squamous-associated genes and also display histological evidence of squamous features. In addition to these seven mixed AD-SQ tumor samples, 12 other adenocarcinomas were suspected to be extrapulmonary metastases, thus adding to histological diversity of the AD class.
One could claim that in the space of a very high number of projections there is always a chance to find a projection with good or even excellent class separation. Even for a random data set, if using enough features, VizRank could then find an excellent projection and would, in this sense, overfit the data.

Our theoretical analysis, though, points to a quite dif-ferent conclusion. The probability that a random planar geometric visualization will offer a clear separation of the instances with different class is: where N denotes a number of instances in the data set and c is the number of different class labels. The above for-mula was derived by computing the probability that in such visualization instances are grouped within c clusters, each containing only instances of the same class.

If, for example, we compute the chance that a random vi-sualization of SRBCT data set offers a clear class separation, we obtain the probability of 2 . 57  X  10  X  49 (SRBCT data set has 83 instances and 4 class values). Notice that this prob-ability is low, and even with high number of projections the chances that we will find one with clear separation, if the data would be random, are slim.

To address this issue in an experiment, we have randomly permuted the class values in the SRBCT data set and used VizRank to rank the projections. We evaluated 500,000 most promising radviz projections as identified by our heuris-tic. The best found projection is shown in Figure 5.b. Notice that the resulting visualization is almost completely uninfor-mative as the classes overlap. We performed a similar exper-iments on all other data sets and observed similar results, i.e. , none of the visualizations found separated the classes well.

Using this results together with the biological interpreta-tion of results in our case studies (see next section), we can conclude that the clear separation of classes in the shown projections could not be attributed to chance but are rather a demonstration of a true regularity in the data.
We studied the biological relevance of genes appearing in the best visual projections. We assumed that most useful genes in discriminating different tumor types would mostly be markers of different tissue or cell origin and not be nec-essary related to cancer pathogenesis. However, many of the genes appearing in the best radviz projections are anno-tated as cancer or cancer-related genes according to the atlas of genetics and cytogenetics in oncology and haematology (www.infobiogen.fr/services/chromcancer/index.html). For example, BAX, DNTT, CD22 and TOP2B genes shown in the two projections of the MLL data set (Figure 2) are can-cer related.

On the other hand, for the prostate data set, where we try to differentiate tumor and normal tissue samples based on gene expression profile, one would expect the  X  X arker X  genes to be cancer related. We support our hypothesis by ascertaining that all six genes used in the best radviz projec-tion (Figure 6.b) are cancer related according to the cancer gene atlas.

We here present a biological interpretation of the genes used in the best visualizations of the MLL data set. One can observe in Figure 2.b that instances with ALL class la-bel lie closer to the anchor points of the DNTT and CD22 gene than instances either in MLL or AML diagnostic class. This finding is consistent with the work of Armstrong et al. [1], in which they report on genes DNTT and CD22 to be specifically expressed in ALL. There is also a well-founded biological explanation for the appearance of the CD22 and DNTT genes in some of the best projections sep-data set, where the class labels were randomly permuted. arating different classes of the MLL data set. It was proven that the presence of cytoplasmic CD22 protein, a human B-lymphocyte-restricted antigen, is a useful marker for B-cell precursor acute lymphocytic leukemia [3]. There is evidence also that terminal deoxynucleotidyl transferase (DNTT) is a unique DNA polymerase expressed in the lymphoid pre-cursors of B-and T-cell lineage at the earliest recognizable stages of lymphopoiesis. DNTT is also expressed on their malignant counterparts, making it an important marker in distinguishing lymphoblastic leukemia from other haemato-logic neoplasms [16].

Instead of considering only the best rated visualization, we can examine several top ranked projections to find genes that are relevant in the differentiation of different cancer types. Therefore it is valuable to know if a particular gene is present only in one good projection or if it appears in several top ranked projections. In Figure 7 we show a plot that lists the first 20 genes present in the top-rated scatterplot projections of the MLL data set. For each pair of genes (one from the x and one from the y axis), a black box indicates if their scatterplot projection is ranked among the best 500. The figure shows that the three genes  X  MME, POU2AF1 and LGALS1  X  stand out in the number of their appearances in the top-ranked projections. Interestingly, all three genes are among the specifically expressed genes in MLL, ALL or AML leukemic samples reported by Armstrong et al. [1]. In their work, MME and POU2AF1 are the first and tenth gene, respectively, most highly correlated with ALL, while LGALS1 is the eight most highly correlated gene with MLL compared with the remaining two classes.

We found similar biological relevance of genes that partic-ipated in the best visualizations of other data sets. It turns out that VizRank does not only find good projections which can well separate the diagnostic classes, but at the same time also finds genes that were already experimentally proven to be relevant in the diagnosis of different cancer types. Most of our visualizations included in this paper point to non-Figure 7: Genes on the x and y axis are the first 20 genes from the list of top-ranked scatterplot pro-jections of the leukemia data set. Each black box indicates that the corresponding genes on the x and y axis form a scatterplot that is ranked as one of the best 500 scatterplots. linear gene interactions, giving VizRank an advantage over univariate feature selection algorithms prevailingly used in the current related work in the area.

Tumorigenesis in humans is a multi-step process, where the steps reflect four to seven stochastic genetic alterations lung cancer data sets. and shown in radviz. that drive the progressive transformation of normal human cells into highly malignant derivatives [11]. During the pro-cess of this transformation gene regulatory networks are dis-rupted causing alteration in the expression of many genes. We can not, in general, assert that the genes shown in the best ranked projections are those that are responsible for the cancer transformation. However, these genes can clearly be used to differentiate between different cancer types and moreover, some of them are known pathognomonic markers of special cancer types, while others might turn out to be so in the future.
Perhaps most striking and to a good degree unexpected result from experiments reported in this work is that we found a simple geometric visualizations that clearly visually differentiate among cancer types for all cancer gene expres-sion data sets investigated. This finding complements recent related work in the area that demonstrates that gene expres-sion cancer data can provide ground for reliable classifica-tion models. However, our  X  X isual X  classification models are much simpler and comprise much smaller number of genes when compared to those of, say, recently published artifi-cial neural networks and support vector machines models that most often use anywhere from 50 features (genes) and encrypt their relation with the diagnostic class in at best hard-to-interpret model.

VizRank, a method we propose to find the most infor-mative visualizations, is relatively fast: good visualizations with clear class separations are often provided to an exper-imentalists within minutes, with subsequent small improve-ments in the score of best rated visualization by letting the program run further.

The approach presented here is of course not limited to cancer gene expression analysis, and can be applied to search for good geometric visualizations on any class-labeled data set that includes continuous or nominal features. VizRank is freely available within a Scatterplot and Radviz widget in Orange open-source data mining suite [7, 8] (see Figure 8). [1] S. A. Armstrong, J. E. Staunton, L. B. Silverman, et [2] A. Bhattacharjee, W. G. Richards, J. Staunton, et al . [3] D. Boue and T. LeBien. Expression and structure of [4] C. Brunsdon, A. S. Fotheringham, and M. Charlton. [5] J. E. Cutting and P. M. Vishton. Perceiving layout [6] B. W. Dasarathy. Nearest neighbor (NN) norms: NN [7] J. Dem X sar and B. Zupan. From experimental machine [8] J. Dem X sar, B. Zupan, G. Leban, and T. Curk. Orange: [9] L. M. Fu and C. S. Fu-Liu. Multi-class cancer subtype [10] T. R. Golub, D. K. Slonim, P. Tamayo, et al . [11] D. Hanahan and R. Weinberg. The hallmarks of [12] P. E. Hoffman, G. G. Grinstein, K. Marx, et al . DNA [13] J. Khan, J. S. Wei, M. Ringnr, et al . Classification [14] D. Komura, H. Nakamura, S. Tsutsumi, et al . [15] I. Kononenko and E. Simec. Induction of decision trees [16] L. Liu, L. McGavran, M. A. Lovell, et al . Nonpositive [17] C. L. Nutt, D. R. Mani, R. A. Betensky, et al . Gene [18] S. L. Pomeroy, P. Tamayo, M. Gaasenbeek, et al . [19] M. A. Shipp, K. N. Ross, P. Tamayo, et al . Diffuse [20] D. Singh, P. G. Febbo, K. Ross, et al . Gene expression [21] A. Statnikov, C. F. Aliferis, I. Tsamardinos, et al . A
