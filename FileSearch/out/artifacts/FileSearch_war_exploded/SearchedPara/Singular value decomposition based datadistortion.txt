 REGULAR PAPER Shuting Xu  X  Jun Zhang  X  Dianwei Han  X  Jie Wang Abstract Privacy-preserving is a major concern in the application of data mining techniques to datasets containing personal, sensitive, or confidential information. Data distortion is a critical component to preserve privacy in security-related data mining applications, such as in data mining-based terrorist analysis systems. We propose a sparsified Singular Value Decomposition (SVD) method for data dis-tortion. We also put forth a few metrics to measure the difference between the distorted dataset and the original dataset and the degree of the privacy protection. Our experimental results using synthetic and real world datasets show that the sparsified SVD method works well in preserving privacy as well as maintaining utility of the datasets.
 Keywords Singular value decomposition  X  Data mining  X  Data distortion  X  Privacy protection  X  Security 1 Introduction With the widespread availability of modern computing technology, the advance storage devices, data of various kinds are collected at an unprecedented speed and scale. The need for understanding and making use of the collected data sparks renewed interest in studying and developing data mining techniques, i.e., the use of computer-aided statistical techniques to  X  X omb X  through large amount of data for automatic and semi-automatic exploration and pattern discovery. Today, data is one of the most important corporate assets of companies, governments, and research institutions [ 11 ] and is used for various private and public interest. rity has been flourishing since the U.S. Government encouraged the use of such technologies [ 25 ]. However, government access to and use of personal information in commercial databases raise concerns about the protection of privacy and due process [ 10 ]. Recent privacy criticism from libertarians on DARPA X  X  1 Terrorism Information Awareness Program led to the defunding of DARPA X  X  Information Awareness Office. Thus, it is necessary that data mining technologies designed for counterterrorism and security purpose have sufficient privacy awareness to protect the privacy of innocent people. Unfortunately, most existing data mining technolo-gies are not very efficient in terms of privacy protections, as they were originally developed mainly for commercial applications, in which different organizations collect and own their databases, and mine their databases for specific commercial purposes. In the cases of security and counterterrorism, data mining may mean a totally different thing. Government may potentially have access to any databases and may extract any information from these databases. This potentially unlimited access to data and information raises the fear of possible abuse.
 tions, but integrated at a centralized location (data warehousing). Alternatively, data can be collected and stored at distributed locations. Different data storage patterns may have different privacy concerns. If the data storage is centralized, the major privacy concern is to shield the exact values of the attributes from the data analysts. Thus, data distortion is a technique that is usually considered in such a situation [ 1 , 18 ]. On the other hand, in a distributed database situation, the major privacy concern is to maintain the independence of the distributed data ownership and to prevent the exchange of exact values of the attributes between different parties of the distributed database ownership. This concern is related to the issue of data mining in a distributed environment [ 3 , 15 ]. This paper deals with the first situation, i.e., we study data distortion techniques for a centralized database. may be used in some terrorist analysis systems and other data mining applica-tions. We assume that the vector-space model [ 12 ] is used to build the popula-tion datasets for analysis. A dataset can be represented by a matrix A . Each row of the matrix represents an object, and each column of the matrix represents an attribute. In modeling populations with individual persons, the dataset matrix is usually sparse, as many of the attributes are not taken by most of the objects si-multaneously. The objects can be individual persons of the general population. The attributes can be a person X  X  name, address, age, home address, credit card numbers, etc. Thus, information contained in such datasets is highly confidential. The confidentiality of the personal information should not be compromised in the process of data mining applications.
 or authorized users have the right to access the original data. The analysts will only see the distorted dataset matrix  X  A , not the original dataset A . The distorted dataset matrix does not have an obvious meaning for the individual attributes. The matrix  X  A cannot be used to reconstruct the original matrix A , without knowing the error part E = A  X   X  A . In this way, the analysts, who will run the data mining algorithms on the distorted dataset matrix  X  A , will not be able to know the origi-nal attributes or the distribution of the attributes, unless appropriate permission is granted by higher level officials to do so. Thus, data mining techniques applied on the distorted datasets will maintain the inherent property of privacy protection. in protecting privacy in some terrorist analysis systems. We propose a sparsified Singular Value Decomposition (SVD) method for data distortion. There are some publications about using SVD-related methods in counterterrorism data mining [ 21 ], novel information discovery [ 22 ] and information extraction [ 23 ], etc. How-ever, to the best of our knowledge, there has been no work on using SVD-related methods in data distortion. We also propose some metrics to measure the dif-ference between the distorted dataset and the original dataset and the degree of privacy protection. Our experimental results using both synthetic and real world datasets will show that the sparsified SVD method is very efficient in keeping both data privacy and data utility.
 model of terrorist analysis system with privacy protection, some data distortion methods and the proposed sparsified SVD method. We put forth some data distor-tion measures in Sect. 3 . We briefly introduce the data utility measure in Sect. 4 . The computational experiments are carried out and the results are discussed in Sect. 5 . We sum up this paper in Sect. 6 . 2 Analysis system and data distortion 2.1 A simplified model terrorist analysis system A simplified model terrorist analysis system can be consisted of two parts, the data manipulation part and the data analysis part. As illustrated in Fig. 1 , we assume that only the data owner or authorized users can manipulate the original data. After the data distortion process, the original dataset is transformed into a completely different data matrix and is provided to the analysts. All actions in the data analysis part are operated on the distorted data matrix. For example, the analysts can apply data mining techniques such as classification, relationship analysis, or clustering, on the distorted data. As the data analysts have no access to the original database without the authorization of the data owner, the privacy contained in the original data is protected. k -anonymity protection [ 24 ] and its variance have been used in similar scenarios, but they do not work for data distortion. 2.2 Data distortion Data distortion is one of the most important parts in the proposed model terrorist analysis system. The desired distortion methods must preserve privacy, and at the same time, must keep the utility of the data after the distortion [ 29 ]. Some data distortion methods based on random value have been proposed and applied in [ 2 , 8 , 18 ]. We will review two of the commonly used random value data distortion methods, as well as propose a class of SVD-based methods for data distortion in this section. 2.2.1 Uniformly distributed noise In this method, the original data matrix A is added by a uniformly distributed noise matrix N u [ 2 ]. N u is of the same size as A , and its elements are random numbers chosen from the continuous uniform distribution on the interval from C 1 to C 2 . The distorted matrix  X  A u is:  X  A u = A + N u . 2.2.2 Normally distributed noise Similarly, as the previous method, here the original data matrix A is added by a normally distributed noise matrix N n , which has the same size as A [ 2 ]. The elements of N n are random numbers chosen from the normal distribution with parameters mean  X  and standard deviation  X  . The distorted matrix  X  A n is:  X  A n = A + N 2.2.3 SVD Singular Value Decomposition (SVD) [ 16 ] is a popular method in data mining and information retrieval [ 9 ]. It is usually used to reduce the dimensionality of the original dataset A . Here we use it as a data distortion method.
 The rows of the matrix correspond to data objects and the columns to attributes. The singular value decomposition of the matrix A is [ 16 ] where U is an n  X  n orthonormal matrix, = diag [  X  1 , X  2 ,..., X  s ] ( s = min { m , n } ) is an n  X  m diagonal matrix whose nonnegative diagonal entries are in a descending order, and V T is an m  X  m orthonormal matrix. The number of nonzero entries in the main diagonal of is equal to the rank of the matrix A . order), the SVD transformation has the property that the maximal variation among the objects is captured in the first dimension, as  X  1  X   X  i for i  X  2. Similarly, much of the remaining variations is captured in the second dimension, and so on. Thus, a transformed matrix with a much lower dimension can be constructed to represent the original matrix faithfully. Define where U k contains the first k columns of U , k contains the first k nonzero diag-onal entries of ,and V T k contains the first k rows of V T . The rank of the matrix A k is k . With k being usually small, the dimensionality of the dataset has been reduced dramatically from min { m , n } to k (assuming all attributes are linearly in-dependent). It has been proved that A k is the best k dimensional approximation of A in the sense of Frobenius norm.
 function. The removed part E k = A  X  A k can be considered as noise in the original dataset A [ 5 ]. Thus, in many cases, mining on the reduced dataset A k may yield better results than mining on the original dataset A . When used for privacy preserving, the distorted dataset A k can provide protection for data privacy, at the same time it may keep the utility of the original data as it can faithfully represent the original data. 2.2.4 Sparsified SVD We propose a data distortion method that is better than SVD in preserving privacy: a sparsified SVD.
 which are smaller than a certain threshold ,in U k and V T k , to zero. We refer to this operation as the dropping operation [ 13 ]. For example, given a threshold value if | v dropped elements, we can represent the distorted data matrix  X  A k ,as The sparsified SVD method is equivalent to further distorting the dataset A k .De-note E = A k  X   X  A k ,wehave The data provided to the analysts is  X  A k , which is twice distorted in the sparsified SVD method.
 will only keep the important features of the original matrix A , thus it can maintain the utility of A . At the same time, the data is twice distorted, which makes it even harder to reconstruct or estimate the value of entries in A .If A is large, the sparsity of  X 
A k can help reduce the memory cost and the computational cost. Therefore, we believe the sparsified SVD method can work as a good data distortion method. reducing the storage cost and enhancing the performance of SVD in text retrieval applications. Several sparsification strategies were proposed and experimented in [ 13 ]. The one that we used in this paper is the simplest one. 3 Data distortion measures Some data privacy metrics have been proposed in literature [ 1 , 2 ]. However, the metric used in [ 2 ] has been proved to be incomplete [ 1 ], and the one used in [ 1 ] needs to know the density function of each attribute a priori, which may be difficult to obtain for the real world datasets. We propose some data distortion measures to assess the degree of data distortion which only depend on the original matrix A and its distorted counterpart,  X  A . 3.1 Value difference After a data matrix is distorted, the value of its elements changes. The value dif-ference (VD) of the datasets is represented by the relative value difference in the Frobenius norm. Thus, VD is the ratio of the Frobenius norm of the difference of  X  A from A to the Frobenius norm of A : For example, for the following dataset A e , its distorted data matrix  X  A e is obtained by applying the Sparsified SVD with k =2and = 0 . 001. Then the VD value computed for this distortion is 0.3136.
 3.2 Rank difference After a data distortion, the rank of the magnitude of the data elements changes, too. We use several metrics to measure the rank difference of the data elements. elements of an attribute are distorted, the rank of the magnitude of each element changes. Assume that the dataset A has n data objects and m attributes. Rank i j Rank i j denotes the rank in ascending order of the distorted element A ji .ThenRP is defined as: If two elements have the same value, we define the element with the smaller attribute can be represented as Rank 1 =[ 1342 ] T . After the distortion, Rank 1 =[ 2143 ] T . The total change of rank for this attribute is 4. We can calculate the total change of rank for the other attributes and get RP = 1.25. in each column after the distortion. It is computed as: where Rk i j indicates whether an element keeps its rank during the data distortion process: For example, the rank vector of the second attribute in A e is [ 2413 ] T ,andafter the distortion, it is still [ 2413 ] T . Thus, all the elements keep their original rank. RK for this example is 0.25.
 compared with the other attributes. Thus, it is desirable that the rank of the average value of each attribute varies after the data distortion. Here we use the metric CP to define the change of rank of the average value of the attributes: where Rank AV i is the rank in ascending order of the average value of attribute instance, the rank vector of all attributes in matrix A e is: [ 2341 ] T . The rank vector for the distorted matrix  X  A e is: [ 4312 ] T . Then the total change of rank is 6, so CP is equal to 1.5.
 keep their ranks of average value after the distortion. So it is calculated as: where Ck i is computed as: In the previous example, CK = 0 . 25.
 the more the original data matrix A is distorted, which implies the data distortion method is better in preserving privacy. 4 Utility measure The data utility measures assess whether a dataset keeps the performance of data mining techniques after the data distortion, e.g., whether the distorted data can maintain the accuracy of the data mining techniques such as classification, cluster-ing, etc. In this paper, we choose the accuracy in Support Vector Machine (SVM) classification as the data utility measure.
 cessfully applied to many applications like face identification, text categorization, bioinformatics, etc. [ 6 , 7 , 19 ].
 and y i  X  X  X  1 , 1 } for all i , SVM classification can be stated as a quadratic pro-graming problem: where C is a user-selected regularization parameter, and  X  i is a slack variable accounting for errors. After solving the quadratic programming problem, we can get the following decision function: where 0  X   X  i  X  C .
 put space into some feature space F . Here we use a kernel function, K ( x , x i ) = ( x ), ( x We substitute K ( x , x i ) for the dot product, which maps the input space into some reproduced kernel feature space. Then Eq. ( 1 ) can be rewritten as: 5 Experiments and results We conduct some experiments to test the performance of the data distortion meth-ods: SVD, sparsified SVD (SSVD), adding uniformly distributed noise (UD) and adding normally distributed (ND) noise.
 5.1 Synthetic dataset First, we compare the performance of the four data distortion methods using a synthetic dataset. The dataset is a 2000 by 100 matrix (Org), whose entries are randomly generated numbers within the interval [1, 10] obeying a uniform dis-tribution. We classify the dataset into two classes using a randomly chosen rule: If then record i is assigned to class 1, otherwise, it is assigned to class  X  1. We use SVM classification [ 17 ] to construct the classifier and a 5-fold cross validation to obtain the classification results. The uniformly distributed noise is generated from the interval [0, 0.8]. The normally distributed noise is generated with  X  = 0and  X  = 0 . 46. The parameters of UD and ND are chosen so that the VD value of UD, ND, and SVD is approximately equal. That is, we will compare these methods under the condition that they change approximately the same percentage of value after the data distortion. For SVD and SSVD, the rank k is chosen to be 85, and in SSVD, the dropping threshold value is 0.001. The parameters k and are chosen so that SVD and SSVD can obtain the highest classification accuracy.
 applying the data distortion methods. In this experiment, both UD and ND keep the rank of the average value of each attribute. Thus, they do not work well for providing privacy protection. Both SVD and SSVD are better in keeping the pri-vacy for the elements and the attributes. SSVD is even better than SVD. It has the highest value in RP, and its RK value is the smallest, which means fewest el-ements keep their rank of magnitude after the distortion. Its CP value is almost four times higher than that of SVD. The CK value for SSVD is 0.02, which means nearly all the attributes change their rank in average value after the distortion. For SVD, only about 20% of the attributes change their ranks. The Accuracy column in Table 1 shows the percentage of the correctly classified data records. Here all the distorted methods obtain almost the same accuracy as using the original data. With the increase of k in SVD, VD and CP decrease while RK, CK and Accur acy increase. But with the increase of in SSVD ( k = 85), there is no observable trend of change in data distortion or utility measures. It implies that the performance of SSVD is relatively stable within the chosen range of the threshold value . 5.2 Real world dataset For a real world dataset, we download some information about 100 terrorists from nationality, different sibling relationships, pilot training, locations of temporary residency, wedding attendance, meeting attendance, etc. The original matrix is of dimension 100  X  42. To test the real world dataset, the uniformly distributed noise is chosen from the interval [0, 0.09]. The normally distributed noise is generated with  X  = 0and  X  = 0 . 05. The rank k for SVD and SSVD is chosen to be 25. The dropping threshold value in SSVD is 0.001. Like dealing with synthetic dataset, we use SVM classification to construct the classifiers and a 5-fold cross validation to obtain the classification results.
 related with Bin Laden and those are not. There are 19 terrorists in the dataset who have direct relationships with Bin Laden, for example, the persons who reported to him, who had met him, who were associates of him, and so on. The accuracy of classifying the original dataset is 67%. The UD and ND methods keep this accuracy, while using SVD the accuracy rises to 70%. The accuracy obtained by using SSVD is 69%, also improves a little bit from UD and ND. Thus, SVD and SSVD are a little better in keeping data utility.
 of UD, ND and SVD to be almost the same. For privacy protection, UD does not perform well. It does not change any rank of the elements in attributes, and has the lowest CP and a high CK values. ND is better than UD but is significantly worse than SVD in CK measure. The CK value obtained by using ND is 0.27, while SVD reduces it more than a half to 0.12. Among the four distortion methods, SSVD is the best to preserve privacy in this experiment. It has the highest RP and the lowest RK values, which means it is the best in keeping the privacy of the rank of the individual elements. It also has the best CP and CK values, which means it also exceeds other methods in changing the rank of the magnitude of attributes.
 world dataset. This time the terrorists are grouped according to whether they have relationship with the terrorist organization Al Qaeda. There are 17 terror-ists in the dataset who were members or leaders in Al Qaeda. The previous tar-get attribute about whether a person has relationship with Bin Laden is inserted classification task. All the distorted matrices are generated from the new original matrix.
 is the best for the classification result, it improves the accuracy (70%) over using the original dataset (67%). The other three methods decrease the accuracy slightly. For privacy protection, SSVD works best in keeping the privacy of each elements. It has the highest RP value but lowest RK value. Its CP value is slightly lower than those of ND and SVD, but its CK value is more than three times lower than that of ND, and six times lower than that of SVD. SVD is not outstanding in preserving privacy in this experiment. ND exceeds it in RP and CK values. In this example, SSVD is still the best in keeping the privacy of data.
 6 Concluding remarks We proposed to use the sparsified SVD method for data distortion in a simpli-fied model terrorist analysis system. The experimental results show that, among the four data distortion methods we compared, SSVD is the best in preserving data privacy. It is also efficient in keeping data utility. SVD works well, too. Both are better than the standard data distortion methods which add noise straightfor-wardly to the database. We believe that the SVD-based methods can be used in data mining techniques for data distortion purpose in order to protect privacy and other sensitive information contained and visible in the original datasets. Further research can be done to find out the relationships between the data distortion mea-sures proposed in this paper and other well-known privacy measures. Other SVD sparsification strategies [ 13 ] can also be tested in the data distortion applications. It should be pointed out that the application of the proposed SVD-based data dis-tortion methods is not limited to the terrorist analysis systems. Many data analysis processes in which there is a need for data distortion may benefit from the pro-posed SVD-based data distortion methods.
 [ 4 , 14 ]. Fortunately, for the current and many other applications in data mining and information retrieval, we need only to compute SVD corresponding to the first few largest singular values. The data distortion and SVD computation are consid-ered as a data preprocessing and preparation procedure, a reasonable amount of computational cost in this phase may be tolerable. On the other hand, we can em-ploy clustered SVD strategies [ 14 ] to reduce the computational cost substantially when the datasets are large. In many privacy preserving data mining applications, it is possible that values of only certain attributes in the database have to be dis-torted. The SVD can be applied to the submatrix consisting of these attributes only. The distorted data can be incorporated into the entire database for the data mining purposes.
 References
