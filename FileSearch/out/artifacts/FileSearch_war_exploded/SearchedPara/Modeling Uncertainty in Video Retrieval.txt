 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Retrieval models General Terms: Algorithms, Experimentation, Theory Keywords: Multimedia Retrieval, Video Retrieval, Proba-bilistic Information Retrieval, Concept Based Search
The need for content based multimedia retrieval increases rapidly because of ever faster growing collection sizes. How-ever, retrieval systems often do not perform well enough for real-life applications. A promising approach is to detect se-mantic primitives at indexing time. Currently investigated primitives are: the uttering of the words and the occurrence of so-called semantic concepts, such as  X  X utdoor X  and  X  X er-son X . We refer to a concrete instantiation of these primitives as the representation of the video document. Most detector programs emit scores reflecting the likelihood of each prim-itive. However, the detection is far from perfect and a lot of uncertainty about the real representation remains. Some retrieval algorithms ignore this uncertainty, which clearly hurts precision and recall. Other methods use the scores as anonymous features and learn their relationship to rele-vance. This has the disadvantage of requiring vast amounts of training data and has to be redone for every detector change.

The main contribution of our work is a formal retrieval model of treating this uncertainty. We conceptually con-sider the retrieval problem as two steps: (1) the determina-tion of the posterior probability distribution given the scores over all representations (using existing methods) and (2) the derivation of a ranking status value (RSV) for each repre-sentation. We then take the expected RSV weighted by the respresentation X  X  posterior probability as the effective RSV following advantages: (a) that step (2) is easier achieved than using the machine learning alternative and (b) that it benefits from all detector improvements.

To verify (a) we investigated representations consisting of concept occurrences and use a RSV proportional to the prob-ability of relevance given the concept representation. The resulting ranking function corresponds to work from Fuhr on probabilistic indexing [2] where the posterior probability of a concept is the probability that a document is correctly indexed with a term. In [1] we show that we can effectively select useful concepts and reliably determine their weights without training data. We use the fact that concept detec-tors are based on a vast amount of training shots which are annotated with concept occurrences. First, we transform the annotated collection into a text collection using concept descriptions from Wikipedia. Upon an information request we execute a query on the text collection and use the con-cept annotations in the top-ranked shots to select concepts and to calculate the weights for each concepts.

For (b), our recently submitted work simulates concept de-tectors to study the performance behavior of retrieval mod-els under given detector characteristics. We build a proba-bilistic model of the detector scores which we use to generate a set of random detector outputs for an annotated collection. We find, that our retrieval method is consistently better than other techniques and with a detector performance of 0 . 60 MAP yields a search performance applicable in reality. We also find that the detector MAP is not always strongly correlated with search performance.

In future work, we will therefore include new detector performance measures to select concepts and estimate their weights. While a concept could be valuable for answering an information need its detector might perform poorly. In this case it might be preferable to lower the weight of the concept or to exclude it from search. We plan to use measures from information theory, which also consider the variance of the scores, to quantify the detector performance.

Other future work will show that our framework is not specific to concepts and will integrate uttered word prim-itives. Related work proposed to use the expected word counts from a spoken document in a general text retrieval function. However, current text retrieval functions are not linear in their word counts. Therefore does the RSV us-ing the expected word counts differ from the expected RSV from real word counts weighted by the posterior probability of these word counts to be the actual representation. Since the number of possible representations is clearly too big to calculate the precise expected value, we plan to use sampling techniques to approximate the expected value.
