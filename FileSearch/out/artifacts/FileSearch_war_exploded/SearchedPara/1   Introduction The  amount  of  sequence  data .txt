 The amount of sequence data generated by experimental biologists and made available via Internet databases is growing at an increasing rate. For example, SWISS-PROT [2], the leading protein sequence database, consists of 170140 entries, sequences with properties that can occur anywhere along the length of the sequence. Manual experimental annotation in a biologist X  X  laboratory is reliable but time consuming and expensive. Automatic annotation is fast and cheap. 
The case study presented in this paper is the problem of determining signal can a machine learning system discover the rules underlying the form and nature of a signal peptide? destination within the cell. Proteins need to have this  X  X ddress X  because they serve a multitude of functions, such as being reaction catalysts and transport molecules [12]. work is also useful when designing new drugs, which are often created in the form of proteins and therefore must have the correct signal attached to them [3]. 
Once a protein reaches its destination, its signal peptide is no longer needed. By a rest of the protein. An important point is that the signal peptide is always cleaved at possible to predict this unique cleavag e point for a newly sequenced protein? the training sequences. The frequencies of the features are determined and converted into probabilities, and then Bayes X  Theorem is applied to predict the posterior probability of a cleavage point given each feature. When a test sequence is presented, cleavage site. 
This relatively simple Bayesian method is comparable to state-of-the-art neural network methods. Furthermore, this method can provide rudimentary explanations (in biologists trying to understand the nature of signal peptides. 
In the next section, the biological and machine learning background to this paper is mentions some issues for future research to address. 2.1 Biological Background residues and their standard abbreviations are listed in Table 1. to the variability in the length of a signal peptide [3]. This is followed by a so-called near the cleavage point, there is typically a c-region , consisting of around five mostly uncharged amino acids. This structure is depicted in Figure 1, using the sequence for human growth hormone as an example. signal peptide for cleavage when it finally arrives [12]. 
It should be noted that each of these regions are not necessarily a contiguous run of once by sequences of non-hydrophobic residues. This contributes to the difficulty of making predictions. 2.2 Signal Peptide Prediction Background The earliest signal peptide prediction method was known as  X  X he (-3,-1) rule X  [12, 8]. This basically followed from the observation that positions  X 3 and  X 1 upstream (i.e. to proved inadequate as the amount of data has increased. 
Chou [3] extended the (-3,-1) rule wh en he introduced the subsite coupling point. Although Chou reports that the results are encouraging, this method was trained on different data than the other methods were trained on and so it is difficult to make comparisons. An important point is that both of these approaches operate directly on variable-length sequences. 
In contrast, more recent machine learning approaches do not operate directly on the variable length sequences but instead preprocess the sequences into fixed length sequence length is, say, 34, then 24 fixed length records would be produced from this single original sequence. Such preprocessing fits well with existing machine learning tools because they demand fixed-length data, but it does have a number of drawbacks. 
The main one is that since each original sequence only has a single cleavage point, there is going to be a high abundance of negative examples (in a single sequence, only positive; the rest are labelled negative). Many machine learning algorithms given this evenly, a considerable number of negative examples have to be discarded  X  a situation that could result in important information being lost. The currently best-known and most widely used machine learning solution is the neural network had a feedforward architecture and was trained on fixed length, sparsely encoded records derived from a  X  X oving window X  [8]. Hidden Markov high accuracy between signal sequences and non-signal sequences. SignalP version 3 [1] is a refinement of both the neural network and hidden Markov model approaches, prediction accuracy results as reported by Bendtsen et al. [1]. Different neural network architectures have failed to prov ide a significant improvement over Signal P (see, e.g., [4, 9]). 
There are number of points worth mentioning about these results. Firstly, separate predictors were trained from data from three different sources: Eukaryotes (being all Prokaryotes (bacteria): Gram-positive and Gram-negative. Other approaches do not subdivide the data at all and therefore the results are not directly comparable. 
One significant weakness of the SignalP evaluations was that they performed only required for statistical significance [14]. 
Support Vector Machines (SVMs) have also been applied to this problem. Vert [11] developed a new SVM kernal for strings and applied his method to cleavage not subdivide the data. He reports 68% accuracy in predicting the cleavage point. 
Some authors have attempted to incorporate residue properties into their systems to improve prediction accuracy. Recently, Smith [10] used a na X ve Bayes-based text mining approach and reported accuracy comparable to Vert X  X  SVM approach Blomaps using the WEKA machine learning workbench [14] and came to the conclusion that a particular encoding called BLOSUM62 combined with na X ve Bayes produced the best results. 
One difficulty when comparing these approaches is the lack of a standard benchmark dataset. It should be noted that Vert [11], Smith[10], and SignalP version authors have generated their own datasets from the SWISS-PROT database, and therefore it is quite possible that differences in accuracy are largely due to differences in data. To date, the SignalP2 dataset is publicly available but the SignalP3 dataset is not available. 3.1 Dataset Description used. 
The dataset in this study is the same dataset used to train SignalP version 2. Each cleavage site; and thirdly, an annotation showing which residues are part of the signal peptide, which are part of the mature protei n, and which is the cleavage site (defined as the first residue of the mature protein) . Figure 2 below depicts two sample records taken from the dataset. The method by which this dataset was derived is worth briefly mentioning. SWISS-PROT contains protein sequences bot h with experimentally verified cleavage Only sequences with experimentally-verified cleavage points were included in the example having an origin in a virus gene [7]. 
The next step in the dataset creation was homology reduction. Many protein sequences occurring in nature are homologous, that is, they share long common subsequences which may include the signal peptide. This means that simple string alignment could result in a very high accuracy when predicting cleavage points on test sequences homologous to the training sequences. To eliminate this potential source of discarded one of the sequences. By this method, more than 50% of the sequences in the dataset were discarded. 
The final dataset contains 1666 protein sequences, of which 1137 are Eukaryote sequences, 697 are Gram negative Prokaryote sequences, and 280 are Gram positive Prokaryote sequences. 3.2 Training Method and Model training data, and applying it to the prediction of signal peptide cleavage points. This approach is relatively simple, fast to train, and as shall been seen in the next section, has accuracy comparable to existing systems. 
The basic idea is to define a set of features that protein sequences can have, extract from the training set the frequencies of those features, and convert those frequencies into posterior probabilities. This set of features and their posteriors will be referred to cleavage point at each position along a test sequence given all the features on the test sequence. 
What are the features? I define two types of feature: a pattern of residues that may occur anywhere along a sequence, and a pattern of residues at a fixed position relative human growth hormone sequence depicted in Figure 1. I have used an  X  X  X  symbol to denote patterns with a position specified. 
The following features were extracted from the training set because they resulted in (e.g. see the first and third rows of Table 3); and all the diresidue sequences separated by exactly one position (e.g. see second and fourth rows of Table 3). However, only the position-specific diresidue sequences (i.e. those with an  X  X  X  symbol) starting at  X  3 were extracted. The reasoning for this is that such an approach makes the standard simplifying na X ve Bayes assumption (i.e. that the occurrence of a residue at a particular position relative to the cleave point is independent of the residues at other considered non-independent. By having a specific feature for the diresidue pattern at (-3,-1), the system can therefore effectively model the (-3,-1) rule mentioned earlier. 
Now, for every feature, a probability is calculated. Suppose f is a single residue or training set, in both signal and non-signal portions of the sequences. For example, if cleave(c)) is defined as the fraction of occurrences in the training set of the feature at a particular fixed position relative to the known cleavage point. For example, from the dataset, the prior probability of the single-residue feature L , P(L) , is 0.127, but P(L@-1|cleave(0)) = 0.019 and P(L@-15|cleave(0)) is 0.285. positions (-3,-1), as mentioned above. how the priors and conditionals are combined to compute the overall probability of a sequence with positions relative to some position c. The training model consists of a posterior probability for every feature present in the training data. 
We now come to the prediction algorithm. Given a test sequence with an unknown cleavage point, the system predicts a score for every position c on the test sequence. posterior probability is the predicted cleavage point. Figure 3 depicts the output of the system when tested on the sequence for human growth hormone depicted in Figure 1 predicted probability of a cleave at the actual cleavage site is 0.87. I evaluated the method described in the previous section using Leaving One Out Cross Validation (LOOCV) on the SignalP version 2 dataset (the dataset for SignalP3 Gram positive Prokaryotes, and Gram negative Prokaryotes subsets. 4.1 Accuracy Compared to computationally more expensive methods such as neural networks, this approach results in comparable testing accuracy. Table 4 compares the accuracies same dataset. A comparison with other versions of SignalP is not as useful because of the different datasets being used. As can be observed, the Bayesian method is consistently 1-2% less accurate than reliable LOOCV method. The difference may also reflect the independence positions (-3, -1) as non-independent contributes to a large proportion of the accuracy. If this feature is not extracted, and instead only two independent features for positions  X 3 and  X 1 are used, then the accuracy is reduced by about 25%.) 
I also tested the predictive performance of the Bayesian approach when trained on the entire SignalP2 dataset without subdivision. Again, LOOCV was applied. The accuracy for this experiment was 71.2%, which compares favourably with Vert X  X  SVM approach [11] that achieved 68% accuracy, albeit on the (mostly similar) SignalP1 dataset. 
Aside from raw accuracy, one can also consider how close erroneous predictions are from the actual predictions. In Figure 4, the distribution of predicted cleavage sites against proximity to the real cleavage site are depicted following LOOCV on the (91.4%) lie within  X 5 and +5 of the actual cleavage site even though the raw accuracy is 71.2%. It is quite possible that many of these predictions are correct, but have been misclassified by the experimental biologist, as suggested by Hiller et al. [4]. performed an analysis on the results of the LOOCV experiment applied to the entire dataset, and found a positive correlation between posterior probability and true positive rate. The result of this analysis is depicted graphically in Figure 5. 
Clearly, predictions with a high posterior probability are to be considered more confident than predictions with a low posterior probability. For example, where the best predicted cleavage point has a probability of only 0.5 or above, the true positive rate was only rate is between 85% and 90% -quite a significant increase. 4.2 Explanations The Bayesian method has one significant advantage over neural network approaches: namely, the ability to extract the reason for the system making a particular prediction. Figure 6, the features contributing to the human growth hormone prediction shown in Figure 3 are listed in decreasing order of individual posterior. 
It can be seen that the biggest contributor to the prediction is the presence if Ala at predictor, and this is followed by the occurrence of Leu at multiple positions from  X 6 and 4 also has a high posterior. points along protein sequences has been presented. I have shown that computationally more expensive approaches are not necessarily better in terms of accuracy than simpler Bayesian approaches, and the Bayesian approach described here can offer some degree of explanations for its predictions. Some of the issues involved in applying data mining techniques to biological datasets (such as dealing with variable length sequences) have also been explored. 
