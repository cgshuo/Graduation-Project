 Recently [16] resorted the Permuterm index of Garfield (1976) as a time-efficient and elegant solution to the string dictio-nary problem in which pattern queries may possibly include one wild-card symbol (called, Tolerant Retrieval problem). Unfortunately the Permuterm index is space inefficient be-cause its quadruples the dictionary size. In this paper we propose the Compressed Permuterm Index which solves the Tolerant Retrieval problem in optimal query time, i.e. time proportional to the length of the searched pattern, and space close to the k -th order empirical entropy of the indexed dictionary. Our index can be used to solve also more so-phisticated queries which involve several wild-card symbols, or require to prefix-match multiple fields in a database of records.
 The result is based on an elegant variant of the Burrows-Wheeler Transform defined on a dictionary of strings of vari-able length, which allows to easily adapt known compressed indexes [14] to solve the Tolerant Retrieval problem. Exper-iments show that our index supports fast queries within a space occupancy that is close to the one achievable by com-pressing the string dictionary via gzip , bzip2 or ppmdi . This improves known approaches based on front-coding by more than 50% in absolute space occupancy, still guaranteeing comparable query time.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing; E.4 [ Coding and Information Theory ]: Data compaction and compression; F.2.2 [ Analy-sis of Algorithms and Problem Complexity ]: Nonnu-merical algorithms and Problems X  Pattern matching Algorithms, Theory, Experiments.  X 
Partially supported by Yahoo! Research grant on  X  X ata compression and indexing in hierarchical memories X . Indexing a dictionary of strings, Wild-Card searches, Data Compression, Burrows-Wheeler Transform.
String processing and searching tasks are at the core of modern web search, IR and data mining applications. Most of such tasks boil down to some basic algorithmic primi-tives which involve a large dictionary of strings having vari-able length. Typical examples include: pattern matching (exact, approximate, with wild-cards,...), the ranking of a string in a sorted dictionary, or the selection of the i -th string from it. While it is easy to imagine uses of pattern matching primitives in real applications, such as search en-gines and text mining tools, rank/select operations appear uncommon. However they are quite often used (probably, unconsciously!) by programmers to replace long strings with unique IDs which are easier and faster to be processed and compressed. In this context ranking a string means mapping it to its unique ID , whereas selecting the i -th string means retrieving it from its ID (i.e. i ).

As strings are getting longer and longer, and dictionaries of strings are getting larger and larger, it becomes crucial to devise implementations for the above primitives which are fast and work in compressed space. This is the topic of the present paper that actually addresses the design of compressed and efficient data structures for the so called tolerant retrieval problem, defined as follows [16].
Let D be a sorted dictionary of m strings having total length n and drawn from an arbitrary alphabet  X . The tol-erant retrieval problem consists of preprocessing D in order to efficiently support the following WildCard( P ) query op-eration: search for the strings in D which match the pattern P  X  ( X   X  { X  X  ) + . Symbol  X  is the so called wild-card symbol, and matches any substring of  X   X  . In principle, the pattern P might contain several occurrences of  X  ; however, for prac-tical reasons, it is common to restrict the attention to the following significant cases:
In this paper we extend the tolerant retrieval problem to include the two basic rank/select primitives discussed above: There are two classical approaches to string searching: Hashing and Tries [1]. Hashing supports only the exact Membership query; its more sophisticated variant called minimal ordered perfect hashing [17] supports also the Rank operation but only on strings of D . All other queries need however the inefficient scan of the whole dictionary D !
Tries are more powerful in searching than hashing, but they fail to provide an efficient solution to the PrefixSuf-fix query. In fact, the search for P =  X   X   X  needs to visit the whole subtrie descending from the trie-path labeled  X  , in order to find the strings that are suffixed by  X  . Such a brute-force visit may cost O ( |D| ) time independently of the number of query answers (cfr [2]). We can circumvent this limitation by using the sophisticated approach proposed in [7] which builds two tries, one storing the strings of D and the other storing their reversals, and then reduce the PrefixSuffix query to a 2D-range query, which is eventu-ally solved via a proper efficient geometric data structure, in O ( |  X  | + |  X  | + polylog ( n )) time. The overall space occupancy would be  X ( n log n ) bits, 1 and there is a large constant hid-den in the big-O notation due to the presence of the two tries and the geometric data structure.

Recently [16] resorted the Permuterm index of Garfield [11] as a time-efficient and elegant solution to the tolerant retrieval problem above. The idea is to take every string s  X  D , append a special symbol $ , and then consider all the cyclic rotations of s $. The dictionary of all rotated strings is called the permuterm dictionary , and is then indexed via any data structure that supports prefix-searches, e.g. the trie. The key to solve the PrefixSuffix query is to rotate the query string  X   X   X  $ so that the wild-card symbol appears at the end, namely  X  $  X   X  . Finally, it suffices to perform a prefix-query for  X  $  X  over the permuterm dictionary. As a result, the Permuterm index allows to reduce any query of the Tolerant Retrieval problem on the dictionary D to a prefix query over its permuterm dictionary . The limitation of this elegant approach relies in its space occupancy, as  X  X ts dictionary becomes quite large, including as it does all rotations of each term. X  [16]. In practice, one memory word per rotated string (and thus 4 bytes per character) is needed to index it, for a total of  X ( n log n ) bits.

In this paper we propose a compressed permuterm index which solves the tolerant retrieval problem in optimal query time, i.e. time proportional to the length of the queried string, and space close to the k -th order empirical entropy of the dictionary D (see Section 2 for definitions). The latter is an information-theoretic lower bound to the output size of any compressor that encodes each symbol of a string with
Throughout this paper we assume that all logarithms are taken to the base 2, whenever not explicitly indicated, and we assume 0 log 0 = 0. a code that depends on the symbol itself and on the k im-mediately preceding symbols. Known effective compressors are gzip 2 , bzip2 3 and ppmdi 4 .
 Our result is based on a variant of the Burrows-Wheeler Transform here extended to work on a dictionary of strings of variable length. We prove new properties of such BWT, and show that known compressed indexes [8, 14] may be eas-ily adapted to solve the Tolerant Retrieval problem without any loss in time and space efficiency.

We experiment our solution over various large dictionar-ies of URLs, hosts and terms, and compare it against some classical approaches to the Tolerant Retrieval problem men-tioned in [16, 17] such as tries, front-coded dictionaries, and ZGrep . 5 Experiments show that tries are much space con-suming, and ZGrep is too slow to be used in any applicative scenario. As mentioned in [17], and confirmed by its use in most open-source search engines (e.g. Lucene ), front-coding is the best known approach in terms of time/space trade-off. Our compressed permuterm index improves the space occupancy of front-coding by more than 50% in ab-solute space occupancy, resulting close to gzip , bzip2 and ppmdi . The query time is comparable to front-coding, tak-ing few  X  -secs per searched character. The flexibility of our compressed index allows to trade query time for space oc-cupancy, thus offering a plethora of solutions for the Tol-erant Retrieval problem which may well adapt to different applicative scenarios (see Section 3.3). We can thus safely state that it is no longer the case that a Permuterm index is an elegant approach which quadruples the dictionary size!
Let T [1 , n ] be a string drawn from the alphabet  X  = { a 1 , . . . , a h } . For each a i  X   X , we let n i be the number of occurrences of a i in T . The zero-th order empirical entropy of T is defined as:
Note that | T | H 0 ( T ) provides an information-theoretic lo-wer bound to the output size of any compressor that encodes each symbol of T with a fixed code [17].

For any string w of length k , we denote by w T the string of single symbols following the occurrences of w in T , taken from left to right. For example, if T = mississippi and w = si , we have w T = sp since the two occurrences of si in T are followed by the symbols s and p , respectively. The k -th order empirical entropy of T is defined as:
We have H k ( T )  X  H k +1 ( T ) for any k  X  0. As usual in data compression [13], we will adopt | T | H k ( T ) as an information-theoretic lower bound to the output size of any compressor that encodes each symbol of T with a code that depends on the symbol itself and on the k immediately pre-ceding symbols.
Available at http://www.gzip.org
Available at http://www.bzip.org
Available at http://pizzachili.di.unipi.it/utils A grep over gzip -ed files, available on all Linux platforms. Figure 1: Example of Burrows-Wheeler transform for
In [6] Burrows and Wheeler introduced a new compression algorithm based on a reversible transformation now called the Burrows-Wheeler Transform (BWT from now on). The BWT transforms the input string T into a new string that is easier to compress. The BWT of T , hereafter denoted by bwt ( T ), consists of three basic steps (see Figure 1): 1. append at the end of T a special symbol $ smaller than 2. form a conceptual matrix M ( T ) whose rows are the 3. construct the string L by taking the last column of the Every column of M ( T ), hence also the transformed string L , is a permutation of T $. In particular the first column of M ( T ), call it F , is obtained by lexicographically sorting the symbols of T $ (or, equally, the symbols of L ). Note that when we sort the rows of M ( T ) we are essentially sort-ing the suffixes of T because of the presence of the special symbol $. This shows that: (1) there is a strong relation between M ( T ) and the suffix array data structure built on T ; (2) symbols following the same substring ( context ) in T are grouped together in L , thus giving raise to clusters of nearly identical symbols. Property 1 is crucial for designing compressed indexes (see e.g. [14]), Property 2 is the key for designing modern data compressors (see e.g. [13]).
For our purposes, we hereafter concentrate on compressed indexes. They efficiently support the search of any (fully-specified) pattern Q [1 , q ] as a substring of the indexed string T [1 , n ]. Two properties are crucial for their design [6]: (a) Given the cyclic rotation of rows in M ( T ), L [ i ] pre-(b) For any c  X   X , the ` -th occurrence of c in F and the
As an example, the 3rd s in L lies onto the row which starts with sippi $ and, correctly, the 3rd s in F lies onto the row which starts with ssippi $ . That character s is T [6]. Figure 2: The algorithm of [8] to find the contiguous
In order to map characters in L to their corresponding characters in F , [8] introduced the following function: where C [ c ] counts the number of characters smaller than c in the whole string L , and rank c ( L, i ) counts the occurrences of c in the prefix L [1 , i ]. Given Property (b) and the alphabetic ordering of F , it is not difficult to see that character L [ i ] corresponds to character F [ LF ( i )]. For example in Figure 1 we have LF (9) = C [ s ] + rank s ( L, 9) = 8 + 3 = 11 and, in fact, both L [9] and F [11] correspond to T [6].

Array C is small and occupies O ( |  X  | log n ) bits, the im-plementation of function LF (  X  ) is more sophisticated and boils down to the design of compressed data structures for supporting Rank queries over strings. The literature offers now many theoretical and practical solutions for this prob-lem (see e.g. [14, 3] are references therein).
 Lemma 1. Let T [1 , n ] be a string over alphabet  X  and let L = bwt ( T ) be its BW-transform. 1. For |  X  | = O ( polylog ( n )) , there exists a data structure 2. For general  X  , there exists a data structure which sup-Given Property (a) and the definition of LF, it is easy to see that L [ i ] (which is equal to F [ LF ( i )]) is preceded by L [ LF ( i )], and thus the iterated application of LF allows to move backward over the text T . Of course [6], we can compute T from L by moving backward from L [1] = T [ n ].
Ferragina and Manzini [8] made one step further by show-ing that data structures for supporting Rank queries on the string L are enough to search for a pattern Q [1 , q ] as a sub-string of the indexed text T . The resulting search procedure is now called backward search and is illustrated in Figure 2. It works in q phases, each preserving the invariant: At the end of the i -th phase, [ First , Last ] is the range of contiguous rows in M ( T ) which are prefixed by Q [ i, q ]. Backward search starts with i = q so that First and Last are determined via the array C (step 1). [8] proved that the pseudo-code in Figure 2 maintains the invariant above for all phases, so at the end [ First , Last ] delimits the rows prefixed by Q (if any). Plugging Lemma 1 into Backward search , [9, 3] obtained: Theorem 1. Given a text T [1 , n ] drawn from an alphabet  X  , there exists a compressed index that takes q  X  t rank to support Backward search ( Q [1 , q ]) , where t rank is the time cost of a single rank operation over L = bwt ( T ) . The space usage is bounded by nH k ( T ) + o ( n log |  X  | ) bits, for any k  X   X  log |  X  | n and 0 &lt;  X  &lt; 1 .

Notice that compressed indexes support also other oper-ations [14], like locate and display of pattern occurrences, which are slower than Backward search in that they require polylog(n) time per occurrence. We do not go into further details on them because one positive feature of our com-pressed permuterm index is that it will not need these (so-phisticated) data structures, and thus it will not incur in this polylog -slowdown.
The way in which the Permuterm dictionary is computed immediately suggests that there should be a relation between the BWT and the Permuterm dictionary of the string set D . In both cases we talk about cyclic rotations of strings, but in the former we refer to just one string, whereas in the lat-ter we refer to a dictionary of strings of possibly different lengths. The notion of BWT for a set of strings has been considered in [12] for the purpose of string compression and comparison. Here, we are interested in the compressed in-dexing of the string dictionary D , which introduces more challenges. Surprisingly enough the solution we propose is novel, simple, optimal in time and entropy-bounded in space.
Let D = { s 1 , s 2 , . . . , s m } be the lexicographically sorted dictionary of strings to be indexed. Let $ (resp. #) be a symbol smaller (resp. larger) than any other symbol of  X . We consider the doubled strings b s i = s i $ s i . It is easy to note that any pattern searched by WildCard( P ) in the Tolerant Retrieval problem matches s i if, and only if, the rotation of P mentioned in Section 1 is a substring of b s i . For example, the query PrefixSuffix(  X   X   X  ) matches s i iff the rotated string  X  $  X  occurs as a substring of b s i .
 Consequently, the simplest approach to solve the Tolerant Retrieval problem with compressed indexes seems to boil down to the indexing of the string b S D = # b s 1 # b s 2 by means of the data structure of Theorem 1. Unfortunately, this approach suffers of various inefficiencies in the indexing and searching steps. To see them, let us  X  X ompare X  string b S
D against the string S D = $ s 1 $ s 2 $ . . . $ s m  X  1 $ s is a serialization of the dictionary D (and it will be at the core of our approach, see below). We note that the  X  X upli-cation X  of s i within b s i : (1) doubles the string to be indexed, because | b S D | = 2 |S D | X  1; and (2) doubles the space bound of compressed indexes evaluated in Theorem 1, because we can prove that | b S D | H k ( b S D )  X  = 2 |S D | H k ( S D where the second term comes from the presence of symbol # which introduces new k -long substrings in the computation of H k ( b S D ). Point (1) is a limitation for building large com-pressed indexes, being their construction space a primary concern [15]; point (2) will be experimentally investigated in Section 4 where we will show that a compressed index built on b S D may be up to 1 . 9 times larger than a compressed index built on S D .

Our Compressed Permuterm index works on the plain string S D , and is built in three steps (see Figure 3): 1. Build the string S D = $ s 1 $ s 2 $ . . . $ s m  X  1 $ s 2. Compute L = bwt ( S D ). 3. Build a compressed data structure to support Rank
Our goal is to turn every wild-card search over the dic-tionary D into a substring search over the string S D . Some of the queries indicated in Section 1 are immediately imple-mentable as substring searches over S D (and thus they can be supported by standard compressed indexes built on S D ). But the sophisticated PrefixSuffix query needs a differ-ent approach because it requires to simultaneously match a prefix and a suffix of a dictionary string, which are possibly far apart from each other in S D . In order to circumvent this limitation, we prove a novel property of bwt ( S D ) and deploy it to design a function, called jump2end , that allows to mod-ify the procedure Backward search of Figure 2 in a way that is suitable to support the PrefixSuffix query. The main idea is that when Backward search reaches the beginning of some dictionary string, say s i , then it  X  X umps X  to its last character rather than continuing on the last character of its previous string in D , i.e. the last character of s i  X  1 prisingly enough, function jump2end ( i ) consists of one line of code: and its correctness derives from the following two Lemmas.
Lemma 2. Given the sorted dictionary D , matrix M ( S D ) satisfies the following properties:
Proof. Refer to Figure 3 for an illustrative example. The three properties come from the sorted ordering of the dic-tionary strings, the definition of the special symbols $ and #, the cyclic rotation of the string S D to form the rows of M ( S D ), and the lexicographic ordering of these rows. The previous Lemma immediately implies the following one:
Lemma 3. Any row i  X  [1 , m ] is prefixed by $ s i $ and the next row ( i + 1) ends with the last character of s i .
This  X  X ocality X  property is the one deployed by function jump2end ( i ), proving thus its correctness.

We are now ready to design the procedures for searching and displaying the strings of D . As we anticipated above the main search procedure, called BackPerm search , is derived from the original Backward search of Figure 2 by adding a step which makes a proper use of the function jump2end : 3 : First = jump2end ( First ); Last = jump2end ( Last ); It is remarkable that the change is minimal (just one line of code!) and takes constant time, because jump2end takes O (1) time. Let us now comment on the correctness of the new procedure BackPerm search (  X  $  X  ) in solving the sophis-ticated query PrefixSuffix(  X   X   X  ) . We note that Back-Perm search proceeds as the standard Backward search for all characters Q [ i ] 6 = $. In fact, the rows involved in these search steps do not belong to the range [1 , m ], and thus jump2end is ineffective. When Q [ i ] = $, the range [ First , Last ] is formed by rows which are prefixed by $  X  . By Lemma 3 we also know that these rows are prefixed by strings $ s j with j  X  [ First , Last ], and thus these strings are in turn pre-fixed by $  X  . Given that [ First , Last ]  X  [1 , m ], Step 3 this range of rows to [ First + 1 , Last + 1], and thus correctly identifies the new block of rows which are ended by the last characters of the strings s j (Lemma 3). After that, Back-Perm search continues by scanning backward the characters of  X  (no other $ character is involved), thus eventually find-ing the rows prefixed by  X  $  X  .

Figure 4 shows the pseudo-code of two other basic proce-dures: Back step ( i ) and Display string ( i ). The former proce-dure is a slight variation of the backward step implemented by any current compressed index based on BWT (see e.g. [8, 14]), here modified to support a leftward cyclic scan of every dictionary string. Precisely, if F [ i ] is the j -th character of some string s k i , then Back step ( i ) returns the row prefixed by the ( j  X  1)-th character of that string if j &gt; 1 (this is a standard backward step), otherwise it returns the row pre-fixed by the last character of s k i (by means of jump2end ). Procedure Display string ( i ) builds upon Back step ( i ) and re-trieves the string containing the character F [ i ] (or equiva-lently, the string whose suffix prefixes the row i of M ( S
Using the data structures of Lemma 1 for supporting rank queries over strings, we obtain: Theorem 2. Let S D be the string built upon a dictionary D of m strings having total length n and drawn from an alphabet  X  , such that |  X  | = polylog ( n ) . We can design a Compressed Permuterm index such that: Figure 4: Algorithm Back step is the one devised in [8] for standard compressed indexes here modified to support a leftward cyclic scan of a dictionary string. Algorithm Display string ( i ) retrieves the string con-taining the character F [ i ] . All time bounds are optimal. Space occupancy is bounded by
Proof. For the time complexity, we observe that func-tion jump2end takes constant time, and it is invoked O (1) times at each possible iteration of procedures BackPerm search and Display string . Moreover, Back step takes constant time, by Lemma 1. For the space complexity, we use the rank data structure of Lemma 1 (case 1).

If |  X  | =  X ( polylog ( n )), the above time bounds must be multiplied by a factor O (log log |  X  | ) and the space bound has an additive term of o ( n log |  X  | ) bits and it holds for any k  X   X  log |  X  | n and 0 &lt;  X  &lt; 1 (Lemma 1, case 2). We are left with detailing the implementation of Wild-Card , Rank and Select queries for the Tolerant Retrieval problem. As it is standard in the Compressed Indexing lit-erature we distinguish between two sub-problems: counting the number of dictionary strings that match the given wild-card query P , and retrieving these strings. Based on the Compressed Permuterm index of Theorem 2 we have:
Theorem 3. Let D be a dictionary of m strings having total length n , drawn from an alphabet  X  such that |  X  | = polylog ( n ) . Our Compressed Permuterm index ensures that: The space occupancy is bounded by nH k ( S D )+ o ( n ) bits, for any k  X   X  log |  X  | n and 0 &lt;  X  &lt; 1 .

According to Lemma 1 (case 2), if |  X  | =  X ( polylog ( n )) the above time bounds must be multiplied by O (log log |  X  | ) and the space bound has an additive term of o ( n log |  X  | ) bits and it holds for any k  X   X  log |  X  | n and 0 &lt;  X  &lt; 1. We also remark that our Compressed Permuterm index can support all wild-card searches without using any locate -data structure, which is known to be the main bottleneck of compressed indexes [14]: it implies the polylog-term of their query bound and most of the o ( n log |  X  | ) term of their space cost (see Theorem 1). The net result is that our Compressed Permuterm index achieves in practice space occupancy much close to known compressors and very fast queries, as show in Section 4.
It is interesting to note that, instead of introducing func-tion jump2end and then modify the Backward search proce-dure, we could have modified L = bwt ( S D ) just as follows: cyclically rotate the prefix L [1 , m +1] of one single step (i.e. move L [1] = # to position L [ m +1]). This way, we are actu-ally plugging Lemma 3 directly into the string L . It is then possible to show that the compressed index of Theorem 1 applied on the rotated L , is equivalent to the compressed permuterm index introduced in this paper (details in the full paper).

In [16] the more sophisticated wild-card query P =  X   X   X   X   X  is also considered and implemented by intersecting the set of strings containing  X  $  X  with the set of strings containing  X  . Our compressed permuterm index allows to avoid the materialization of these two sets by working only on the compressed index built on the string S D . The basic idea consists of the following steps:
The number of Back step  X  X  invocations depends on the length of the strings of D which match PrefixSuffix(  X   X   X  In practice, it is possible to engineer this paradigm to re-duce the total number of Back step s (see [10], FM-indexV2). The above scheme can be also used to answer more complex queries as P =  X   X   X  1  X   X  2  X  . . .  X   X  k  X   X  , with possibly empty  X  and  X  (details in the full paper).

We finally observe that our search paradigm might re-sult useful in other indexing contexts. For example, given a database of records consisting of string pairs  X  name i , surname one could be interested in searching for all records in the database whose field name is prefixed by string  X  and field surname is prefixed by string  X  . This query can be im-plemented by invoking PrefixSuffix(  X   X   X  R ) on a com-pressed permuterm index built on a dictionary of strings b s = name i 2 ( surname i ) R , where 2 is a special symbol not occurring in  X  and x R denotes the reversal of string x . Given the small space occupancy of our solution, one could think to build many indexes, specifically one per pair of fields on which a user might want to execute these types of searches!
We downloaded from http://law.dsi.unimi.it/ various crawls of the web X  X amely, arabic-2005 , indocina-2004 , it-2004 , uk-2005 and webbase-2001 . We extracted from uk-2005 about 190Mb of distinct urls, and we derived from all crawls about 34Mb of distinct hosts. The dictionary of urls and hosts have been lexicographically sorted by reversed host-domain in order to maximize the longest common-prefix (shortly, lcp ) shared by strings adjacent in the lexicographic order. We have also built a dictionary of (alphanumeric) terms by parsing the TREC collection WT10G and by drop-ping (spurious) terms longer than 50 characters. These three dictionaries are representatives of string sets usually manip-ulated in Web search and mining engines.
 Statistics DictUrl DictHost DictTerm
Size (Mb) 190 34 118 |  X  | 95 52 36 # strings 3 , 034 , 144 1 , 778 , 927 10 , 707 , 681 Avg len strings 64 . 92 18 . 91 10 . 64 Max len strings 1 , 138 180 50 Avg lcp 45 . 85 11 . 25 6 . 81 Max lcp 720 69 49
Total lcp 68 . 81% 55 . 27% 58 . 50% gzip -9 11 . 49% 23 . 77% 29 . 50% bzip2 -9 10 . 86% 24 . 03% 32 . 58% ppmdi -l 9 8 . 32% 19 . 08% 29 . 06% Table 1 reports some statistics on these three dictionaries: DictUrl (the dictionary of urls), DictHost (the dictionary of hosts), and DictTerm (the dictionary of terms). In par-ticular lines 3-5 describe the composition of the dictionaries at the string level , lines 6-8 account for the repetitiveness in the dictionaries at the string-prefix level (which affects the performance of front-coding and trie, see below), and the last three lines account for the repetitiveness in the dic-tionaries at the sub-string level (which affects the perfor-mance of compressed indexes). It is interesting to note that the Total lcp varies between 55 X 69% of the dictionary size, whereas the amount of compression achieved by gzip , bzip2 and ppmdi is superior and reaches 67 X 92%. This proves that there is much repetitiveness in these dictionaries not only at the string-prefix level but also within the strings. The net consequence is that compressed indexes, which are based on the Burrows-Wheeler Transform (and thus have the same bzip2 -core), should achieve on these dictionaries significant compression, much better than the one achieved by front-coding based schemes!
In Tables 2 X 3 we tested the performance of four (com-pressed) solutions to the Tolerant Retrieval problem: CPI is our Compressed Permuterm Index of Section 3.2. In
FC data structure applies front-coding to groups of b ad-Trie is the ternary search tree of Bentley and Sedgewick Recently [4] proposed a cache-oblivious variant of the String B-tree data structure using Fc in its leaves. We were unable to get from the authors the source code of this solu-tion in order to test it. We leave to the full paper a com-parison with this and other cache-oblivious approaches. We just note here that their space-occupancy will be larger than the Fc experimented in this paper. Code at http://www.cs.princeton.edu/  X  rs/strings/ .
Zgrep is a grep -based approach over gzip -ed files available on
Theorem 3 showed that Cpi supports efficiently all queries of the Tolerant Retrieval problem. The same positive fea-ture does not hold for the other data structures. In fact Fc and Trie support only prefix searches over the indexed strings. Therefore, in order to implement the PrefixSuf-fix query, we need to build these data structures twice  X  one on the strings of D and the other on their reversals. This doubles the space occupancy, and slows down the search per-formance of at least a factor 2 because we need to first make two prefix-searches, one for P  X  X  prefix  X  and the other for P  X  X  suffix  X  , and then we need to intersect the two candidate lists of answers. If we wish to also support the rank/select primitives, we need to add to the trie some auxiliary data that keep information about the in-order numbering of its nodes. In Table 2 we account for such  X  X pace doubling X , but not for the auxiliary data, thus giving a space-advantage to these data structures wrt Cpi . It is evident the large space occupancy of ternary search trees because of the use of pointers and the explicit storage of the dictionary strings (without any compression). As predicted from the statistics of Table 1, Fc achieves a compression ratio of about 40% on the original dictionaries, but more than 60% on their reversal. Further, we note that Fc space improves negligi-bly if we vary the bucket size b from 128 to 1024 strings. Our experiments show that the best space/time trade-off is achieved when b = 32. In summary, the space occupancy of the Fc solution is more than the original dictionary size, if we wish to support all queries of the Tolerant Retrieval problem! As far as the variants of Cpi are concerned, we note that their space improvement is significant: a multi-plicative factor from 2 to 7 wrt Fc , and from 40 to 86 wrt Trie .

A special comment deserves ZGrep which was considered in our experiments just for the sake of completeness, since it is the usual approach taken by programmers and users of Linux platforms to search over their compressed files. Its space occupancy is the one of gzip (Table 1), but its time ef-ficiency is very poor X  few tens of seconds per single query X  because ZGrep is forced to decompress and scan the whole dictionary at any search operation.

In Section 3.1 we mentioned another simple solution to the Tolerant Retrieval problem which was based on the com-pressed indexing of the string b S D , built by juxtaposing twice every dictionary string of D . In that section we argued that this solution is inefficient in indexing time and compressed-space occupancy because of this  X  X tring duplication X  pro-cess. Here we investigate experimentally our conjecture by computing and comparing the k -th order empirical entropy of the two strings b S D and S D . As predicted theoretically, the two entropy values are close for all three dictionaries, thus implying that the compressed indexing of b S D should require about twice the compressed indexing of S D (recall that | b S D | = 2 |S D | X  1). We have then built two FM -indexes: one on b S D and the other on S D , by varying D over the three dictionaries. We found that the space occupancy of the FM index built on b S D is a factor 1.6 X 1.9 worse than our Cpi-Fmi
The open-source search engine Lucene , available at http://lucene.apache.org/ , uses b = 128 so this is one of the solutions we test.
 Table 2: Space occupancy is reported as a percent-age of the dictionary size. Recall that Trie and Fc are built on the dictionary strings and their rever-sals in order to support PrefixSuffix queries.
 Method 10 60 5 15 5 10 Trie 0 . 1 0 . 2 0 . 4 0 . 5 1 . 2 0 . 9 FC-32 1 . 3 0 . 4 1 . 5 1 2 . 5 1 . 7 FC-128 3 . 2 1 . 0 3 . 4 1 . 8 4 . 6 2 . 8 FC-1024 26 . 6 5 . 2 24 . 6 11 . 0 25 . 0 14 . 6 CPI-AFI 1 . 8 2 . 9 1 . 6 2 . 5 2 . 9 3 . 0 CPI-CSA-64 4 . 9 5 . 6 4 . 3 5 . 2 5 . 4 5 . 7 CPI-CSA-128 7 . 3 8 . 0 6 . 9 7 . 6 7 . 6 8 . 3 CPI-CSA-256 11 . 8 14 . 1 11 . 8 12 . 5 12 . 8 13 . 2 CPI-FMI-256 11 . 9 9 . 8 19 . 3 15 . 5 22 . 5 20 . 1 CPI-FMI-512 16 . 2 13 . 4 28 . 4 23 . 1 34 . 2 30 . 3 CPI-FMI-1024 24 . 1 20 . 7 46 . 4 38 . 4 57 . 6 50 . 1 Table 3: Timings are given in  X  secs/char averaged over one million of searched patterns, whose length is reported at the top of each column. Value b denotes in CPI-FMI-b the bucket size of the FM-index, in CPI-CSA-b the sample rate of the function  X  [10], and in FC-b the bucket size of the front-coding scheme. We recall that b allows in all these solutions to trade space occupancy per query time. built on S D . So we were right in conjecturing the inefficiency of the compressed indexing of b S D .

We tested the time efficiency of the above indexing data structures over a P4 2 . 6 GHz machine, with 1 . 5 Gb of inter-nal memory and running Linux kernel 2 . 4 . 20. We executed a large set of experiments by varying the searched-pattern length, and by searching for one million patterns per length. Since the results were stable over all these timings, we report in Table 3 only the most significant ones by using the no-tation microsecs per searched character (shortly  X  s/char ): this is obtained by dividing the overall time of an experiment by the total length of the searched patterns. We remark that the timings in Table 3 account for the cost of searching a pattern prefix and a pattern suffix of the specified length. While this is the total time taken by our Cpi to solve a Pre-fixSuffix query, it is an optimistic evaluation for Fc and Trie because they also need to intersect the candidate list of answers returned by the prefix/suffix queries! Keeping this in mind, we look at Table 3 and note that Cpi allows to trade space occupancy per query time: we can go from a space close to gzip  X  ppmdi and access time of 20 X 57  X  s/char (i.e. CPI-FMI-1024 ), to an access time similar to Fc of few  X  s/char but using less than half of its space (i.e. CPI-AFI ). Which variant of Cpi to choose depends on the application for which the Tolerant Retrieval problem must be solved. We defer the tests on the Display string to the full paper.
We finally notice that, of course, any improvement to com-pressed indexes [14] will immediately and positively impact onto our Cpi , both in theory and in practice. Overall our experiments show that Cpi is a novel compressed storage scheme for string dictionaries which is fast in supporting the sophisticated searches of the Tolerant Retrieval prob-lem, and is as compact as the best known compressors! [1] R.A. Baeza-Yates and B.A. Ribeiro-Neto. Modern [2] R.A. Baeza-Yates and G. Gonnet. Fast text searching [3] J. Barbay, M. He, J.I. Munro, and S. Srinivasa Rao. [4] M. Bender, M. Farach-Colton, and B. Kuszmaul.
 [5] J. L. Bentley and R. Sedgewick. Fast algorithms for [6] M. Burrows and D. Wheeler. A block sorting lossless [7] P. Ferragina, N. Koudas, S. Muthukrishnan, and [8] P. Ferragina and G. Manzini. Indexing compressed [9] P. Ferragina, G. Manzini, V. M  X akinen, and [10] P. Ferragina and G. Navarro. Pizza&amp;Chili corpus [11] E. Garfield. The permuterm subject index: An [12] S. Mantaci, A. Restivo, G. Rosone, and M. Sciortino. [13] G. Manzini. An analysis of the Burrows-Wheeler [14] G. Navarro and V. M  X akinen. Compressed full text [15] S. Puglisi, W. Smyth, and A. Turpin. A taxonomy of [16] C. D. Manning, P. Raghavan and H. Sch  X ulze.
 [17] I. H. Witten, A. Moffat, and T. C. Bell. Managing
