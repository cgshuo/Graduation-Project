
Ecole Normale Sup  X  erieure and HEC Paris a random reward, whose distribution is determined by the identity of the arm selected. The distributions associated with the arms are unknown to the decision maker whose goal is to maximize the expected sum of the rewards received.
 We assume that the decision maker knows a dissimilarity function defined over this space that constraints bound on the mean-payoff function from below at each maxima. We also assume that the decision maker is that the diameters of these sets shrink at a known geometric rate when measured with the dissimilarity. Our work generalizes and improves previous works on continuum-armed bandit problems: Kleinberg [6] sense with respect to these environments.
 The goal of this paper is to further these works in a number of ways: (i) we allow the set of arms to be a generic topological space; (ii) we propose a practical algorithm motivated by the recent very successful of the mean-payoff function around the maxima only, and not a global property, such as Lipschitzness in the whole space. This allows us to obtain a regret which scales as e O ( maxima (which are in finite number) and bounded away from the maxima outside of these neighborhoods. of the input space. We also prove a minimax lower bound that matches our upper bound up to logarithmic factors, showing that the performance of our algorithm is essentially unimprovable in a minimax sense. Besides these theoretical advances the algorithm is anytime and easy to implement. Since it is based on ideas that have proved to be efficient, we expect it to perform well in practice and to make a significant impact on how on-line global optimization is performed. We consider a topological space X , whose elements will be referred to as arms. A decision maker  X  X ulls X  the arms in X one at a time at discrete time steps. Each pull results in a reward that depends on the arm chosen and which the decision maker learns of. The goal of the decision maker is to choose the arms so as to maximize the sum of the rewards that he receives. In this paper we are concerned with stochastic environments. Such an environment M associates to each arm x  X  X a distribution M x on the real line. The support of these distributions is assumed to be uniformly bounded with a known bound. For the sake to be measurable (all measurability concepts are with respect to the Borel-algebra over X ). The function f : X  X  R thus defined is called the mean-payoff function . When in round n the decision maker pulls arm X n  X  X  , he receives a reward Y n drawn from M X n , independently of the past arm choices and rewards. contains only Dirac distributions.
 According to the process that was already informally described, a pulling strategy  X  and an environment M X Then the decision maker gets a rewards Y n drawn from M X n , independently of all other random variables in the past given X n .
 seen by the application of the tower rule. 3.1 Trees of coverings We first introduce the notion of a tree of coverings. Our algorithm will require such a tree as an input. increases (cf. Assumption 1).
 Remark 1. Our algorithm will instantiate the nodes of the tree on an  X  X s needed X  basis, one by one. In fact, at any round n it will only need n nodes connected to the root. 3.2 Statement of the HOO strategy selected.
 at round n + 1 is picked by following a path from the root to a node in S n , where at each node along the 1  X  N h,i ( n )  X  n for all nodes ( h,i )  X  X  n . Let the time-points when the path followed by the algorithm went through ( h,i ) : The corresponding upper confidence bound is by definition its B  X  X alue to be B h,i ( n ) = +  X  . The B  X  X alues for nodes in T n are given by we conjecture that it is O ( n log n ) on average. The dissimilarity will be used to capture the smoothness of the mean-payoff function. The decision maker of the algorithm: P h,i are disjoint for 1  X  i  X  2 Remark 2. A typical choice for the coverings in a cubic domain is to let the domains be hyper-rectangles. this example, if X = [0 , 1] D and ` ( x,y ) = k x  X  y k  X  then we can take  X  = 2  X   X /D , X  1 = (  X  2 = 1 / 8  X  .
 The next assumption concerns the environment.
 Definition 2. We say that f is weakly Lipschitz with respect to ` if for all x,y  X  X  , at any point. Thus, weak-Lipschitzness is a property that lies somewhere between a growth condition on the loss around optimal arms and (one-sided) Lipschitzness. Note that since weak Lipschitzness is defined Assumption 2. The mean-payoff function f is weakly Lipschitz.
 a proof can be found in the appendix. c &gt; 0 , then all arms in P h,i are max { 2 c,c + 1 }  X  1  X  h -optimal.
 The last assumption is closely related to Assumption 2 of Auer et al. [2], who observed that the regret of a continuum-armed bandit algorithm should depend on how fast the volume of the sets of  X  -optimal arms shrinks as  X   X  0 . Here, we capture this by defining a new notion, the near-optimality dimension of the mean-payoff function. The connection between these concepts, as well as the zooming dimension defined by Kleinberg et al. [7] will be further discussed in Section 7.
 the size of the sets X  X  in terms of  X  , and then state our main result.
 (with the usual convention that inf  X  = +  X  ).
 such that for all n  X  1 , also for d 0 = d .
 Remark 3. We can relax the weak-Lipschitz property by requiring it to hold only locally around the maxima. the details from this extended abstract. We first state three lemmas, whose proofs can be found in the appendix. The proofs of Lemmas 3 and 4 rely on concentration-of-measure techniques, while that of Lemma 2 follows from a simple case study. Let us the root to ( h,i ) . Then we have E
N h,i ( n )  X  u + Lemma 3. Let Assumptions 1 and 2 hold. Then, for all optimal nodes and for all integers n  X  1 , Lemma 4. Let Assumptions 1 and 2 hold. Then, for all integers t  X  n , for all suboptimal nodes ( h,i ) such that  X  h,i &gt;  X  1  X  h , and for all integers u  X  1 such that u  X  8 ln n ( X  f  X  and N h,i ( t ) &gt; u  X  tn  X  4 . with a union bound leads to the following key result.
 all n  X  1 , We are now ready to prove Theorem 1.
 depth h in the tree. Lemma 4 bounds the expected number of times each node ( h,i )  X  J h is visited. Since  X  h,i &gt; 2  X  1  X  h , we get radius  X  2  X  h , we have that constant introduced in the definition of the near-optimality dimension).
 T potentially infinite, while T 2 is finite.) of the forecaster, no two such random variables are equal, since each node is picked at most once. We decompose the regret according to the element T j where the chosen nodes ( H t ,I t ) belong to:
E R n = E Lemma 1 the corresponding domain is included in X 4  X  course still included in X 4  X  corresponding domain is included in X 4  X  played at most once, one gets is in I h  X  1 , by Lemma 1 again, we have that P h,i  X  X 4  X  the chosen arm X t belongs also to P H 0 then bound the regret from T 3 as |J h | X  2 |I h  X  1 | . Substituting this and the bound on |I h  X  1 | , we get Fourth step. Putting things together, we have proved The packing dimension of a set X is the smallest d such that there exists a constant k such that for all dimension of d whenever ` is a norm. If X has a packing dimension of d , then all environments have a In fact, this bound can be shown to be optimal as is illustrated by the theorem below, whose assumptions appendix.
 n  X  4 d  X  1 c/ ln(4 / 3) , all strategies  X  are bound to suffer a regret of at least where the supremum is taken over all environments with weakly Lipschitz payoff functions. Several works [1; 6; 3; 2; 7] have considered continuum-armed bandits in Euclidean or metric spaces and of e
O ( functions with only a local H  X  older assumption around maximum (with possibly higher smoothness degree similarly to our near-optimality dimension, but using covering numbers instead of packing numbers and the prove that the zooming dimension and near-optimality dimensions are equal.
 Our main contribution compared to [7] is that our weak-Lipschitz assumption, which is substantially weaker than the global Lipschitz assumption assumed in [7], enables our algorithm to work better in some common situations, such as when the mean-payoff function assumes a local smoothness whose order is larger than maxima x  X  of f (the number of maxima is assumed to be finite): Under this assumption, the result of Auer et al. [2] shows that for D = 1 , the regret is  X (  X  = 1 / X  ). Our result allows us to extend the condition (as defined in Remark 3) and that the near-optimality dimension is 0 . Thus our regret is e O ( i.e., the rate is independent of the dimension D .
 be Lipschitz w.r.t. the metric then the zooming dimension becomes D (  X   X  1) / X  , while the regret becomes e behavior of the function around its maximum (or finite number of maxima) is known then global optimization suffers a regret of order e O ( smoothness spaces.

