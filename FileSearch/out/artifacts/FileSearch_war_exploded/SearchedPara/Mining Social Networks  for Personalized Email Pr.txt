 Email is one of the most prev alent communication tools today, and solving the email overload problem is pressingly urgent. A good way to alleviat e email overload is to automatically prioritize received messages according to the priorities of each user. However, research on statisti cal learning methods for fully personalized email prioritization (PEP) has been sparse due to privacy issues, since people are reluctant to share personal messages and importance judgm ents with the research community. It is therefore importa nt to develop and evaluate PEP methods under the assumption that only limited training examples can be available, and that the system can only have the personal email data of each user during the training and testing of the model for that user. This paper pres ents the first study (to the best of our knowledge) under such an assumption. Specifically, we focus on analysis of personal so cial networks to capture user groups and to obtain rich features that represent the social roles from the viewpoint of a particular user. We also developed a novel semi-supervised (transductiv e) learning algorithm that propagates importance labels fro m training examples to test examples through message and user nodes in a personal email network. These methods together en able us to obtain an enriched vector representation of each ne w email message, which consists of both standard features of an email message (such as words in the title or body, sender and rece iver IDs, etc.) and the induced social features from the sender and receivers of the message. Using the enriched vector repr esentation as the input in SVM classifiers to predict the importance level for each test message, we obtained significant perfo rmance improvement over the baseline system (without induced social features) in our experiments on a multi-user data collection. We obtained significant performance improve ment over the baseline system (without induced social features ) in our experiments on a multi-user data collection: the relativ e error reduction in MAE was 31% in micro-averaging, and 14% in macro-averaging. I.7.m [ Computing Methodologies ]: Document and Text Processing X  Miscellaneous ; I.5.3 [ Computing Methodologies ]: Pattern Recognition X  Clustering ; I.5.4 [ Computing Methodologies ]: Pattern Recognition X  Applications Algorithms, Experimentation, Security, Human Factors, and Languages. Email Prioritization, Social Network, and Text Mining. Email is one of the most pr evalent personal and business communication tools today; however, it is not without significant drawbacks. In contrast to teleph one conversations or face-to-face meetings, communication through email is asynchronous in the sense that we receive messages (after some spam filtering) in the same way regardless of our level of interest, and a single sender can flood multiple receivers (unlike telephone or instant messaging). Users are left with the burden of having to process a large volume of email messages of differing importance. This tedious task has been shown to cause significant negative effects on both personal and organization performance [6] [20]. There is an urgent need to solve this information overload problem; i.e., we need to develop systems that automatically learn personal priorities for each user, and that identify personally interesting and important messages for user X  X  attention. Many statistical learning techniqu es have been studied in support of email-based prediction ta sks, including supervised, unsupervised and semi-supervised methods for spam identification [21][22], folder recommendation [23], recipient reminding [24], action-item identification [25], social group analysis [26], etc. In spite of the wide variety of efforts and significant accomplishments, pe rsonalized email prioritization (PEP) remains an under-explored problem. Thorough investigations and conclusive so lutions have been rare, mainly due to privacy issues in collecti ng personal data for training and testing. Unlike spam filtering where people are less concerned with sharing individually labele d spam messages, PEP requires personal judgments of the importa nce levels of non-spam email messages. Few are willing to share this data due to privacy concerns. Companies who have access to customers X  email messages (like Google, Yahoo! and Microsoft) cannot share such data with academic institutes for the same reason. Personal importance judgments are also missing from the Enron corpus, which has been used as a benchmark dataset in email research and evaluations. A message important for an Enron employee might not be equally important for a high-level manager. In short, there is no publicly available dataset th at contains personal importance judgments by real users and on personal messages, leaving researchers no choice but to go through a process of collecting private data under strict IRB (Institutional Review Board) guidelines. Such data collecti on processes are costly, time consuming, tedious, and difficult to scale to a large number of users with diverse criteria in judging the importa nce of email messages. As a result, PEP remains an area which has not been well studied thus far. This paper presents the first study with several statistical classification and clustering methods (including our new approach) addressing the PEP problem based on personal importance judgments by multiple users. We constructed a new dataset of anonymized email me ssages from each user, and used parts of the data to train person alized models and other parts to test the effectiveness of those models. Our primary research question is:  X  X ow can we effectively learn user-specific models for accurate prediction of pers onalized importance using only small amounts of labeled training data and limited observations on personal communications with others? X  Specifically, our contributions in this paper include: 1) We created a new collection of anonymized personal email 2) We proposed a fully personalized methodology for technical 3) We developed a supervised classification framework for 4) We present an empirical evalua tion of the proposed approach In predicting the importance of email messages, the sender information is one of the most indicative features. For example, we may have multiple user groups such as project teams or social activity groups, and ema il reflects membership in such social groups naturally through co-recipient list. Often the messages sent by the members of the same group tend to share similar priority levels; thus, capturing sender gr oups would be informative for predicting the importance of messages. Since we have a limited amount of training data, it is very likely that in the test data we encounter a sender who does not have any labeled instances in the training set. However, if we can identify this user as a member of a group based on unsupervised clustering, then we can infer that user X  X  importance from that of other group members. In other words, the clustering produces equivalent classes of users base d on their communication patterns in a personal social network. These clusters are used later by SVMs as input features (in addition to a standard bag-of-word representation) to each message (Sections 2.3 and 5.3). As a result, senders without labeled me ssages can also receive non-zero weight through these clusters, effectively addressing the data sparse problem in PEP. We construct a personalized social network for each particular user using only the emai l data of that user. There are two reasons for this: Practicality  X  X e want our method to not rely on the unrealistic assumption that multi-user private data are always available for system developm ent and model optimization. Personalization  X  X e want the social netw ork best representing the user X  X  own social activity; a global social network may include noisy features and de-emphasize personalization in the inductive learning of important feat ures through the network. Let us use a graph G =( V , E ) to represent the email contact network where vertices V correspond to the email contacts (users) in the network, and edges E correspond to the messages sending events among users. The edges are un-weighted, i.e., E ij =1 if there is (at least) a message from user i to user j , and E ij =0 otherwise. We choose the Newman clusteri ng algorithm, which has been reported to successfully find social structures in large organizations [17][18]. It defines the edge-betweenness as a normalized number of shortest paths going through a specific link from all-pairs shortest paths. If a link has a high edge-betweenness score, it means that the link is crucial between two boundary nodes of two different highly-connected clusters. The algorithm assumes that members in a highly-connected cluster have many communication passages within the cluster, but not many links outside the cluster. Based on this assumption, it deletes links with high edge-betw eenness scores, which results in disconnect components as clusters. One way to control the granularit y level of clusters is to pre-specify the number of desired clus ters. This numbe r may be based on domain knowledge about the network or automatically determined by an algorithm whic h certain optimization criterion or a heuristic measure. The Organization Risk Analyzer (ORA) [5] picks the number that yields the largest decrease in the sum of edge-betweenness per cluste r. We use ORA in this work. Figure 1 shows embedded clusters in a network where ORA selects 27 as the number of clusters. We want to measure the social im portance levels of contacts, and this can be done without labeled training data. Instead, the personal contact network induced from senders and recipients link relations provides useful informa tion about the centrality of each contact in the network. For instance, the Newman Cluster #1 in Figure 1 is highly connected with others and the person in the center of the cluster may be an important person in the network. We examine multiple graph-based metrics to characterize the social centrality of each node, which have been commonly used in social network analysis (SNA) or link structure analysis. Figure 1 The clusters produced using the Newman clustering algorithm based on the email contact network of a user: nodes are the senders, and node sizes are adjusted to reflect the average importance of members in each cluster. For node i , we define InDegreeCent ( i ) as the normalized number of unique senders who sent email to contact i : where } 1 , 0 {  X  personal email social network. A high in-degree may indicate that the recipient is a popular person. OutDegreeCent ( i ) is defined as the normalized number of people who receive email from contact i . Having a high out-degree may also mean certain kind of importance, e.g., as an announcement sender or a mailing-list organizer. TotalDegreeCent ( i ) is defined as the normalized number of unique senders and recipients wh o had email communication with node i . That is, it is the simple average of the in-degree and out-degree of the node: Clustering Coefficient of node v , denoted as ClustCoef(v) , measures the connectivity among the neighborhood of the node. where { } 0 , 0 : ) (  X   X  = Boykin and Roychowdhury [2] used this metric to discriminate spam from non-spam email messages based on the neighborhood connectivity of the recip ients of messages. The clique count of a node v is also a neighborhood metric where the clique is a fully connected sub-graph. The clique count of a node v , ClqCnt(v) , is the number of clique sub-graphs which contain the node v . A large clique count means that the node v is connected to large and well-connected sub-graph and node v is located in the center of the sub-graph. Although it is not a global social metric, it measures wider network centrality than degree-based centralities or cl ustering coefficients. Betweenness centrality of a node v , BetCent(v) , is the percentage of existing shortest paths out of all possible paths that goes through the node v . A node with high betweenness centrality means that the corresponding pers on is a contact point between different social groups. where  X  is the number of shortest path between j and k that goes through i . This metric has been used in social network analysis [17]. difference between ) ( i HITSAuth and degree-based centrality is that HITS is recursively define d, taking the transitivity of popularity into account. ) ( i HITSAuth is defined as follows: Let us use an N -by-N matrix to define the adjacency matrix whose elements are defined as } 1 , 0 {  X  = only if there is a link from i to j , i.e., if and only if there is at least one message sent from person i to j . The ) ( i HITSAuth calculated by finding the principle eigenvector r of matrix We computed the PCC (Pearson Correlation Coefficient) values of each social metric with respect to the human-labeled importance levels of email messages in our dataset. The PCC values are indicative about how usef ul each social metric feature would be for predicting the import ance of messages based on the metric alone (i.e., not count ing the interactions among the metrics). Figure 2 shows the absolute values of the correlation coefficient scores. The multi-metric PCC values differ from user to user, which is not surprising. For user 1, as an example, Clustering Coefficient, Clique C ount and HITS Authority scores are highly informative, but In-degree, Out-degree and Total-degree are not. But for User 5, HITS Authority score is not a good predictor but in-degree is highly informative. Using multiple metrics we improve the robus tness of the predictions. So far we have focused on unsupervised feature induction to enrich the representation of email contact persons. Now let us focus on another way to leverage personal email so cial networks, i.e., to propagate the importance values of labeled email messages (the training examples) to other messages and corresponding contact persons. We propose a ne w solution for Semi-supervised Importance Propagation (SIP) as the following. Figure 3: An example of bipartite email network: circles are contact persons and rectangles are email messages. Some email messages have human-assigned importance values but others do not. The network enables us to propagate the partially available importance values from messages to persons, and vice versa. As shown in Figure 3, we use a bipartite graph to represent the interactions between email contacts (circles) and email messages (boxes); we call this graph a personal email network. Let N be the number of email contacts and M be the number of messages, the two types of edges in the graph can be represented using matrix A ( N by M ) and matrix B ( N by M ), respectively where A person i sends message j , and A i,j = 0 otherwise; B received message j , and B i,j = 0 otherwise. importance values which are available for some messages in the graph, and propagate them thro ugh the links among messages and contact persons. To be specific, le t us treat each importance label (among 1, 2, 3, 4 and 5) as a  X  X ategory X , and use vector by-1) to indicate the labels of messages with respect to category k as: otherwise. The importance propa gation from messages to persons (receivers) is calculated as propagation from persons (senders) to messages is calculated as each time step (t) is calculated by: transformation of the starting vector partially available importance values (at a specific level) of messages, and the transformatio n is uniquely defined by which is induced from the persona l email network. It is well understood in link analys is that if matrix T BA C = is irreducible and if t is sufficiently large, then eigenvector of C . However, as C is induced from an arbitrary email collection, the irreducible property of the matrix is not guaranteed. Even if C happens to be irreducible, its principal eigenvector is still insensitive to the starting vector is not what we want. We first put them in probability framework and to address both issues, we make a linear interpolation: 1) We define 2) We normalize the matrix C column-wise by replacing its 3) We make a linear interpolati on of the link-structure matrix Finally, we define the SIP (Semi-supervis ed Importance Propagation) method iteratively as: vector equation: The solution consisting of the expected impor tance score of each contact person after iterative SIP. A pplying this method to each importance level, we obtain vectors vectors provide 5 additional features (with the corresponding weights) in the enriched repres entation of the contact person of each email message, in the input vector for importance prediction using a SVM. Our formulae for SIP are quite similar to those in PageRank [3], Topic Sensitive PageRank (TSPR) and Personalized PageRank (PPR) methods when a topic distri bution is used to represent the interest of each user [10]. In fact our SIP method is intrigued by the TSPR and PPR work. The main differences in our problem and the SIP solution are: We recruited 25 experimental subj ects, mostly from the Language Technologies Institute at the Carnegie Mellon University, including eight faculty members, five staff persons and twelve graduate students. Each subject was requested to label at least 400 non-spam messages during a one-month period. The five importance levels are: absolu tely non-important, relatively non-important, neutral, important, a nd most important. Only seven users actually submitted more than 200 messages with importance labels, which we use to construct the dataset for the experiments in this paper. Table 1 summarizes the dataset statistics. Table 1: Summary Statistics of collected dataset (7 users) We applied a multi-pass preprocessing to email messages. First, we applied email address canonicalization. Since each person may have multiple email accounts, it is necessary to unify them before applying social network anal ysis. For instance,  X  X ohn Smith X  john.smith+@cs.xxx.edu,  X  X ohn X  smith@cs.xxx.edu and  X  X ohn Smith X  john747@gmail.com might be the email addresses of the same person. We used regular expression rules and a longest string matching algorithms to identify email addresses which may belong to the same user. We then manually checked all the groups and corrected the errors in the process. We also applied word tokenization and stemming usi ng the Porter stemmer; we did not remove stop words from the title and body text. title , and body text in email messages. Let us use a v -dimensional vector to represent those features for each email message where v is the vocabulary size. We call it the basic feature (BF) sub-vector. The social-network based features are represented as follows:. We use a m -dimensional sub-vector to represent the Newman cluster (NC) features (Section 2) where m be the number of clusters produced by the clustering algorithm: each element of the sub-vector is 1 if the user belongs to the corresponding cluster, or 0 otherwise; each user can belong to one and only one cluster. We also use another sub-vector (7 -dimensional) to represent the social importance (SI) features per user, whose elements are real-valued (Section 0). In addition, we use a 5-dimensional sub-vector to represent the five SIP scores per user, i.e., the mixture weights of the user at the five importance le vels. The concatenation of those sub-vectors together with the basi c feature (BF) vector yields a synthetic vector per email message as its full representation. We use five linear SVM classifiers for the prediction of importance level per email message . Each classifier takes the vector representation of each me ssage (as described in the above section) as its input, and produces a score with respect to a specific importance level. The importance level with the highest score is taken as the predicted im portance level by our system for the input message. We used the standard SVM package and tuned the margin parameter C in the range from 10 to 10 3 . We tuned the parameter with ten-fold cross validation of training data; we repeat the random split 10 times, and report the average performance on the test sets. To obtain a performance baseline, we ran the SVM classifiers with the basic features (BF) only as the input vectors. We also ran the classifiers with additional features, namely, BF+NC for using basic features plus the Newman-cluster (NC) features, BF+SI for using basic features plus the social importance (SI) features, BF+SIP for using basis features plus SIP features, and their complete combination, namely BF+NC+SI+SIP. We use MAE (Mean Absolute Error) as the main evaluation metric, which is standard in evaluating systems that produce multi-level discrete predictions. MAE is defined as: where N is the number of messages in the test set, importance leve l of message i , and level for that message. Since we ha ve five levels of importance, the MAE scores range from zero (the best possible) to four (the worst possible). performance average over multiple users. One way is pooling the computing the MAE on the pool. This way has been called micro-averaged MAE. The other way is to compute the MAE on the test instances of each user and then take the average of the per-user MAE values. This wa y has been called as macro-averaged MAE. The former gives each instance an equal weight, and is possibly dominated by the system X  X  performance on the in (0.01, 0.05]; two stars indicate the p-values equal or less than 1%. user an equal weight instead. Both methods can be informative; therefore we present the evaluation results in both metrics. statistical significance of performance improvement for SVMs with using different feature types in the input vectors. For example, for comparing SVM using BF+SI and the baseline SVMs (using BF only), we calculated the difference in the absolution error of the former and the absolution error of the latter on each test instance, and used the mean of the per-instance differences to estimate the p-value under the hull hypothesis (which assumes a zero mean). Figure 4 shows the performance curves of SVM runs with different representation schemes for email messages. Detailed scores in macro-averaged MAE are given in Table 2. It can be observed that BF had the worst performance. Using the social-network based features (NC, SI and SIP) features in addition significantly reduced the importanc e prediction errors in most cases for the training-set sizes we tested. On average, the relative error reduction in macro-averag ed MAE is 14%, i.e., from 0.8510 to 0.7449 (see the last row of Tabl e 2 and Figure 4b). The relative error reduction in micro-averaged MAE reduction (not shown explicitly in Table 2 but observa ble in Figure 4a) is 31%, i.e., from 0.7759 to 0.5909. All the training-set sizes are relatively small, compared to large data collections used in benchmark evaluations for text categorization, e.g., the RCV1 news-story collection has 780,000 training exam ples for 103 categories. This personal social networks and se mi-supervised importance can be effectively leveraged for addressi ng such the paucity of labeled training data. of all the features (BF+NC+SI+SIP) is significantly better than adding each type of the social-network feature alone in most cases (graph a in Figure 4). As for using micro-average MAE as the performance measure (graph a in Figure 4), the complete combination of features had best results when the training-set sizes was not small (from the size of 50); BF+SI was the best for small training sets (of size 20). These observations suggest that social importance was better captured for most of the users when the training-set sizes were relatively small. Overall, using each type of social network feature alone may not be sufficient for characterizing the social roles and personal social networks of all the users. On the other hand, usi ng the combining all the features enables us to model users with complementary features and hence to predict personal priorities robustly. Our detailed performance analyses (omitted here due to the space limit of the paper) on a per-user basis confirmed the above assertion. Statistical learning methods for performing email-based prediction tasks are becoming an increasingly important research area. We briefly discuss related methods with respect to their relevance to our work. Among the early efforts in email prioritizatio n, Horvitz et al. [11] built an email alerting system which used Support Vector Machines to classify newly arrived email messages into two categories, i.e., high or low in terms of utility. Probabilistic scores were also provided along with the system-made predictions. Personalization, however, was not considered in their method, and social network analysis was not their technical focus. discover social structures auto matically from email messages. Figure 4 Performance curves in MAE (Mean Absolute Error). The horizontal axis is the training-set size used in the learning phase of SVMs. The vertical axis in graph (a) is the micro-averaged MAE, and in graph (b) is the macro-averaged MAE. A lower value in MAE means the better performance. They found that the automatically-di scovered social structures are quite similar, or consistent, with human interpretation of organizational structures. They also used email social networks to identify social leaders. However, they did not use the social network analysis (clusters or leadership scores) to prioritize email messages. users in two ways, i.e., by sender clusters and by recipient clusters, respectively. The senders were cl ustered based on similarity of their recipient lists, and the recipients were clustered based on similarity of their sender lists as well; email contents were not used. They examined the use of those clusters in spam detection, i.e., to separate spam me ssages from non-sp am messages. Prioritization among non-spam messages, however, was not addressed. as enriched features to represent email messages and a Bayesian classifier to detect spam messages. Martin et al. [15] used the out-degree (the number of unique recipients) and in-degree (the number of unique senders) of each person in an email social network to detect worms whic h propagated through the email messages. Prioritization among n on-spam messages was again not addressed by those methods. social importance of individuals ba sed on the observations in the email fields: from, to and cc, and in the recorded actions of replying and reading. They used these metrics for retrieving old email messages rather than prioritizing incoming email messages importance prediction of email messages. They collected email data from multiple users and induced social clusters of users. For each user, some clusters are treated as  X  X mportant X  and the others are not. The importance of each test instance of email message is predicted based on the cluster membership of its sender: if the sender belongs to an important cluster, then the messages is considered important; ot herwise, it is predicted as not important.. The fundamental difference in thei r method from ours is that their clusters were induced from a co mmunity social network, not based on personal social networks. In addition, they only focused on social associations, not taking any textual features into account in the modeling and the pr ediction of importance. associate senders, email folders and messages, and a random-walk algorithm (e.g., a PageRank lik e method) to leverage the associations in predicting folders and recipients for email messages. . Email prioritization, personalized or otherwise, was not addressed in their approach. learning approaches to email-based tasks. However, how to fully leverage personal email social networks in combination with email content for personalized em ail prioritization has not been studied in depth. Leveraging the good ideas in previous work and developing new techniques furthe r with respect to personalized email prioritization is the unique focus and main contribution in this paper. This paper presents the firs t study of personalized email prioritization under the assumption that only personal email data are available during the training and testing of the system. Specifically, we focus on social ne twork analysis to capture user groups in each personal social networ k, and to obtain rich features for representing their user-centric social importance. We further developed a novel semi-supervised (transductive) learning algorithm that propagates im portance values among nodes (messages or people) in each pa rtially labeled and personal email network. These methods enable us to obtain an enriched vector representation of each new email message, as the basis of accurate modeling of individual users and for generating robust predictions for individual users in email prioritization. The effectiveness of the proposed approach is strongly evident in our experiments on personal email data from multiple users. larger number of users and in a longer time period for thorough evaluation. We are also interested in a comparative study on different clustering algorithms a nd graph-mining techniques with respect to their effectiveness in mining social networks for personalized email prioritization. This work is supported in parts by the Defense Advanced Research Project Agency (DARPA) under contract NBCHD030010, by the National Science Foundation (NSF) under grant IIS_0704689, and by Brain Korea 21 Project, the School of Information Technology, KAIST, in 2009. Any opinions, findings, conclusions or recommendations e xpressed in this material are those of the authors and do not n ecessarily reflect the views of the sponsors. [1] CEAS 2005 -Second Conferen ce on Email and Anti-Spam, [2] P. O. Boykin and V. P. Roychowdhury. Leveraging social [3] S. Brin and L. Page. The anatomy of a large-scale [4] J. Cadiz, L. Dabbish, A. Gupta, and G. D. Venolia. [5] K. M. Carley, D. Columbus, M. DeReno, J. Reminga, and I. [6] L. A. Dabbish and R. E. Kraut. Email overload at work: an [7] R. B. Einat Minkov and W. Co hen. Activity-centred search [8] L. C. Freeman. The Devel opment of Social Network [9] L. H. Gomes, F. D. O. Castro, V. A. F. Almeida, J. M. [10] T. Haveliwala, S. Kamvar, and G. Jeh. An analytical [11] E. Horvitz, A. Jacobs, and D. Hovel.Attention-sensitive [12] J. M. Kleinberg. Authoritative sources in a hyperlinked [13] R. Likert. A technique for th e measurement of attitudes. [14] K. B. Lisa Johansen, Mich ael Rowell and P. McDaniel. [15] S. Martin, B. Nelson, A. Sewani, K. Chen, and A. D. Joseph. [16] C. Neustaedter, A. J. B. Brush, M. A. Smith, and D. Fisher. [17] M. E. J. Newman. Modularity and community structure in [18] J. R. Tyler, D. M. Wilkinson, and B. A. Hube rman. Email as [19] S. Wasserman and K. Faust. Social Network Analysis: [20] M. Wattenberg, Rohall, S. L., D. Gruen, and B. Kerr. E-mail [21] Joshua Goodman, Gordon V. Cormack, and David [22] M. Mojdeh and G. V. Corm ack, Semi-supervised Spam [23] B. Klimt and Y. Yang. The Enron Corpus: A New Dataset [24] R. Balasubramanyan, V. Carv alho and W. Cohen, CutOnce -[25] P.N. Bennett and J. Carbonell (2007). Combining [26] A. McCallum, X. Wang and A. Corrada-Emmanuel. Topic [27] D. Alwin, and J. Krosnick,  X  X he reliability of survey attitude 
