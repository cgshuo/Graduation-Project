 In contrast to search-based approaches, critiquing-based recom-mender systems provide a navigation-based interface where users are enabled to critique displayed recommendations as a means of preference elicitation. In this paper we present R E C OMMENT approach to natural language based unit critiquing. We discuss the developed prototype and present the corresponding user interface. In order to show the applicability of our concepts, we present the results of a user study. This study shows that speech interfaces have the potential to improve the perceived ease of use as well as the overall quality of recommendations.
 H.4.2 [ Information System Applications ]: Types of System  X  De-cision support; H.5.2 [ Information Interfaces and Presentation ]: User Interfaces  X  Evaluation/methodology, Interaction styles, Nat-ural language, Voice I/O Knowledge-based recommender systems; critiquing-based recom-mendation; speech interfaces; applied speech recognition
Critiquing-based recommender systems are a form of conversa-tional recommender systems that employ user-articulated critiques on the currently recommended item as a means of preference elic-itation. Over the last decade these systems have attracted a sig-nificant amount of academic interest and have repeatedly shown to provide high quality recommendations while requiring relatively little effort from the user [7, 16, 18].

A multitude of different approaches to critiquing-based recom-mendation have been proposed over the years. Unit critiquing based recommenders use a single, directional critique of the recom-mended item to improve their recommendations [4]. For example, the unit critique  X  X ess X  on the attribute  X  X rice X  would cause the rec-ommender system to search for a cheaper product [6, 13]. So-called compound critiques may be used to critique multiple attributes in the course of a single feedback cycle [14]. Different approaches of finding the optimal set of compound critiques to present to the user have been explored with the apriori method outlined in [14], and es-pecially the application of multi-attribute utility theory described in [25] being particularly notable. Orthogonally to the used critiquing method, valuable information may also be extracted from the users evolving preferences over the course of a recommendation session by maintaining a user preference model. For example, incremental critiquing systems keep track of recent critiques in a recommenda-tion session and try to find products that not only fit the current-but also previously articulated critiques [21]. More recently, an experience-based critiquing approach has been introduced that uses the final, accepted product of similar critiquing sessions (of differ-ent users) as the next recommendation [15]. This approach has since been improved upon with the introduction of nearest neigh-bor compatibility critiquing that selects the product of a comparable critiquing session that best fits the current users preference model as the next recommendation [12].

Clearly, a substantial body of research has been dedicated to help improve critiquing-based recommenders by employing intelligent prediction algorithms. The major motivation of this work is to re-duce the number of interaction (critiquing) cycles needed to iden-tify an item of relevance for the user. With the same goal but a dif-ferent approach we introduce a natural language interface for unit critiquing based recommenders.

Natural language interfaces have remained largely unexplored in existing recommender systems that instead support user interac-tions through mouse, keyboard, and touch devices. While natural language processing remains a hard task in general, its complexity in severely limited domains is manageable [2]. Some fundamentals of applied dialog systems for recommender systems are discussed in [1] and a prototype of a natural language speech-based recom-mender system, the Adaptive Place Advisor, was presented in [24]. The latter proved to be promising, but user feedback was limited to providing specific attribute values which may be unsuitable for more complex domains where users are less aware of the prob-lem space and preferences are subject to incompleteness or rapid change [22]. Recently, a speech-based natural language recom-mender system was mentioned as a promising future research di-rection in [8].

The major contributions of this paper are the following. We present R E C OMMENT 1 , a speech-based unit critiquing-based rec-ommender system that demonstrates how speech recognition can
Portmanteau of  X  X ecommend X  and  X  X omment X . enable natural language communication with conversational rec-ommender systems. W e discuss the implementation of a prototype for the domain of digital compact cameras and report the results of an empirical study that compares the performance of R E MENT with standard unit critiquing approaches. We show that our novel user interface significantly reduces the number of re-quired critiquing cycles and demonstrate how natural language un-derstanding can help to improve future recommender systems.
The remainder of this paper is organized as follows. In Sec-tion 2 we discuss related research to position our work in relation to the state of the art in critiquing-based recommendation. Section 3 presents the algorithms and components of the developed prototype in detail. The conducted empirical study to analyze the impact of R
C OMMENT is discussed in Section 4. The results of this study are reported in Section 5. We conclude the paper with Section 6.
The R E C OMMENT implementation of unit critiquing is largely based on the original ideas of the FindMe systems developed by Burke et. al. [6]. An initial product is presented and unit critiques can be articulated by the user. After each critique, a new best-matching product is suggested, completing the feedback cycle. An example critique for the digital camera domain would be  X  X ore optical zoom X , introducing a  X  X maller than the value of the currently shown product X -constraint on the optical zoom attribute [6, 21].
As mentioned earlier, compound critiques are often used in cri-tiquing recommender systems to reduce the number of required in-teraction cycles [14]. Compound critiques impose multiple con-straints in a single feedback cycle (e.g.,  X  X ore optical zoom but less weight X ). The inclusion of such critiques in R E C OMMENT was considered but they were ultimately omitted because their se-lection criteria reveals implicit information of the problem domain that is hard to represent equivalently in both interfaces, thus possi-bly skewing the results of the study. For example, showing the com-pound critique  X  X arger sensor size but more expensive X  as an op-tion in the traditional interface (control group) not only provides the user with another critiquing option but also exposes a correlation between sensor size and price that might otherwise be unknown to the user [20]. However, mentioning the same proposed critique (as text) in the speech-based interface would certainly guide the user X  X  choice of words not just in this critiquing cycle but from then on, because the sentence also contains the information that  X  X arger sen-sor size X  and  X  X ess weight X  are understood commands. In an effort to make the different interfaces more comparable, support for com-pound critiques was therefore not included 2 .

A user preference model consisting of recently added critiques is tracked across several feedback cycles in a manner very simi-lar to the incremental critiquing approach presented in [21]. How-ever, R E C OMMENT does not permanently remove recommended products from the search space, but instead temporarily biases the recommender against them to avoid the problem of diminishing choices [17].

R E C OMMENT uses the current sales rank of a popular online re-tailer to add a prior probability to the products in its database. In a sense this could be compared to experience-based critiquing as described in [15] in that it also harnesses information from other users X  buying decisions. However, instead of detailed critiquing information, only the accepted products influence current recom-mendations.
The speech-based input accepts more than one condition during a feedback cycle but it treats them as a collection of unit critiques.
R E C OMMENT starts directly with the most popular product in the domain instead of first requiring an initial query (see, e.g., [6]). To ensure quick adaption to a user X  X  preferences, the traditional unit critiquing recommendation algorithm was relaxed to not en-force similarity with the current recommendation. This property is however naturally re-introduced through the maintained user pref-erence model as returned products will become more and more sim-ilar once the user X  X  requirements have been sufficiently determined to codify underlying intentions. Additionally, a special utility func-tion discourages large jumps through the search space for critiqued attributes (see Section 3.1.3).

Finally, it is interesting to note that Burke et. al. already presented natural language queries in their seminal paper on the FindMe systems [6] as examples of how a critique might be for-mulated. On the subject of renting a movie, the authors refer to a possible user thinking  X  X hat would be good, but it X  X  too violent for my kids. X  leading to a new critique on the  X  X evel of violence X  attribute. Had the user in their example actually articulated this thought, a system like R E C OMMENT could have extracted the con-tained critiquing information automatically.
This section outlines the developed R E C OMMENT prototype.
R E C OMMENT is based on a unit critiquing algorithm that ex-ploits iteratively added, user-defined critiques. The final recom-mendation in each step is ensured to fulfill at least the last given critique. From this subspace, the item with the overall highest util-ity rating in regards to the user preference model is selected (see Subsection 3.1.1 for more information about the maintained user preference model and Subsection 3.1.3 for details about the calcula-tion of the utility value of a single critique). Unfulfillable critiques are rejected. For example, if the user requests a less expensive product than the cheapest one, a warning message will be shown briefly, telling the user that there are no such products. This basic algorithm is outlined in Algorithm 1.

Over the course of a recommendation session, a user preference model is maintained. It contains the 15 most recent critiques, lin-early weighted based on their age.
Each new critique is checked against the preference model. Cri-tiques that contradict or refine existing constraints replace their older equivalents [21]. If a feedback cycle is undone by the user (by selecting the  X  X ack X  button or giving an equivalent voice com-mand, depending on the interface; see Section 3.3), any newly added constraints from this cycle are removed and any replaced critiques are restored, essentially restoring the system state before the last given critique.

In order to curb the problem of unreachable products that are  X  X vershadowed X  by numerically better matching but potentially less appealing ones, each feedback cycle also adds a product 6 = current critique as suggested in [16]. Because this constraint is subject to the same aging process and eventual removal, R MENT does not suffer from diminishing choices [17].
The 100 most frequently sold compact digital cameras were re-trieved from the popular online retailer Amazon 3 and their sales rank was added to the domain database to act as a prior probability for the selection process. Because of this additional information, the first suggested product presented to a new user is the most pop-ular product of the domain based on recent sales.
In order to be able to represent critiques such as  X  X uch cheaper X  or  X  X  little bit cheaper X , the base utility expressed by each cri-tiqued numerical attribute is not just a binary measure ( X  X heaper X ) but rather represents the distance of an implicitly expressed goal. The measure of distance between two numerical values is shown in Formula 1 (for non-numerical attributes the distance is either 0, for equal values, or 1 otherwise). The algorithm to calculate the utility value from this calculated distance is outlined in Algorithm 2.
The utility function has been designed such that it tries to avoid large jumps in the product space based on a single critique and in-stead tries to stay within a certain acceptance region from the last shown product. A piecewise function was selected that has the fol-lowing properties. If the critique is violated, the utility value will be negative, otherwise positive. Attribute values that are very different or too close to the current recommendation are assigned lower util-ity values than products closer to the deduced implicit goal. Given symmetric relations and both lower and upper bounds specified for one attribute, traditional, linear (triangular) acceptance functions would theoretically create an optimal region between those bounds, therefore having the combined utility function only depend on the age (weight) of the individual critiques. In contrast, the non-linear approach outlined in Formula 1 provides what we believe to be a better representation of the user X  X  goal (see Figure 2 for an exam-ple). The implicit goal can be influenced with what we call a  X  X od-ifier factor X . The modifier factor is extracted from adjectives to the critique (e.g.,  X  X uch cheaper X ) and defaults to 1.0, representing a desired 50 % change of the attribute value 4 . A selection of sample adjectives influencing the modifier factor can be found in Table 1.
For example, a critique of  X  X arger than 50 X  for a given attribute would result in R E C OMMENT trying to find a product with an at-http://www.amazon.com
In order to make  X  X maller than X  and  X  X arger than X  relationships symmetric, the percentage is always calculated from the larger value to the smaller value.

Sample adjectives Modifier factor Deduced desired change  X  X lightly X  0.2 10 %  X  X ery X  2.0 100 %  X  X ot X  -1.0 -50 %
Table 1: Sample adjectives that affect the modifier factor. tribute v alue of around 100 (modifier factor: 1.0; refer to Figure 1 for a plot of the utility function). A subsequent critique of  X  X maller X  (from the new position of 100) would result in the recommender trying to find a product with a value of around 75 5 for the given attribute (refer to Figure 2 for a plot of the utility function of a com-bination of both critiques). Had the second critique instead been  X  X  little bit smaller X , the expressed implicit goal would have instead been a value of around 95 (see Figure 2).
 Figure 2: Utility function of the subsequent critiques x &gt; 50 and x &lt; 100 as well as x &gt; 50 and x &lt; slightly 100 .
Traditional interfaces, including the mouse-based interface de-veloped for R E C OMMENT , have not been expressive enough to capture such nuances in a user X  X  critiquing input. To the best of the authors X  knowledge, this feature of the speech-based interface is therefore a novel approach for critiquing recommender systems and presents one of the main advantages of natural language inter-faces for recommender systems.
In practice, this value would be around 73 as the older critique would have already aged once and thus would have reduced influ-ence on the overall utility of the product.
Any speech-based natural language interface needs to address a number of challenges that arise when processing spontaneous speech: Speech disfluencies like filler words, repetitions, and false starts (self-interruption) are common [23]. Additionally, dialectal speech, emotive speech patterns and even occasional laughs or an-gry snorts exacerbate the situation for speech models that are usu-ally trained on manually cleaned utterances articulated in a neutral, sometimes almost clinical tone.

A sufficiently well performing speech recognizer is an essential component of any successful speech-based user interface. There-fore, a custom, domain specific solution for Austrian German the domain of digital cameras was developed using the Simon tem and the CMU SPHINX speech recognition framework 8 .
The speech model represents the target language and can be bro-ken into the following parts. (1) the dictionary, containing the set of recognized words as well as their phonetic transcriptions; (2) a (context-infused) word probability model (N-Gram) that forms the language model (LM) and (3) a learned representation of how the individual phones that make up the spoken words are pronounced, stored in the acoustic model (AM).
For the purpose of our digital camera project, a custom 3-gram language model was developed based on the accepted sentence fragments of the parser (refer to Section 3.2.2). The training cor-pus itself was split into three parts. (1) the basic sentence frag-ments expected during critiquing ( X  X heaper X ,  X  X  bit smaller X , etc.), (2) a training corpus for explicit value elicitation ( X  X ore than 5 megapixel X , etc.) and (3) the base corpus modeling standard Ger-man 9 . Separate 3-grams of these three components were built and mixed into a final language model heavily focusing on expected, domain specific sentence fragments. Based on experimentation on recordings from pilot testers of early prototypes, the mixture weights shown in Table 2 were selected. These mixture weights
Example sentences used in this paper are translated from German. http://simon.kde.org http://cmusphinx.sourceforge.net/
Created from a recent dump of the German Wikipedia. (lambdas) govern the influence of the individual N-Grams on the resulting language model. A higher value of  X  represents more in-fluence ( P  X  i = 1 ).

An existing acoustic model built from various data sources such as Voxforge 10 , LibriVox 11 and supplemental data from profes-sional speakers from the spoken language corpus of the ADABA database 12 was adapted with a small speech corpus recorded from the interactions of pilot testers with early prototypes using the max-imum a posteriori probability speaker adaption [10].
To interpret the output of the speech recognition system, a cus-tom parser was developed. It identifies attributes (mapping to properties of the products of the problem space), pre-and post-binding relationships (which may be conditioned on certain at-tribute types), as well as modifier factors ( X  X  bit X ,  X  X ot X ) and com-mands ( X  X heaper X ).

The system supports regular expressions with optionally pro-vided arguments. For example, the post-binding relationship  X  X ore than X  and the attribute  X (\d+) Euro X  13 matches the recognition re-sult  X  X ore than 100 Euro X  and creates a corresponding critique. Commands without explicit values ( X  X ore expensive X ) are inter-preted to relate to the currently shown product.

Default relationship targets enable R E C OMMENT to understand  X  X arger X  as referring to object size while also interpreting  X  X arger sensor size X  correctly.
 Compound critiques (e.g.,  X  X an you show me a smaller Canon? X ) are broken into their individual relationships and added as separate, equally prioritized unit critiques. R E C OMMENT antees that at least one of these constraints will be fulfilled by the next recommended product but will of course prefer products that are closer to all the constraints in the current user model with the just added constraints naturally receiving the highest priority (see Section 3.1.1).
 The language description itself is stored in an easily extendable XML file. The final NLP rules used for the empirical study rec-ognize more than 300 different command fragments which can be combined to form millions of different sentences.
Simple, unit critiquing-based user interfaces were developed for both the mouse-and the speech-based interaction methods.
Instead of an initial query, the user starts immediately with the  X  X est matching X  product. In lieu of critiquing information, the prior probability dominates the selection process resulting in the most sold product being shown initially (see Subsection 3.1.2).
Both interfaces use auditory cues to inform the user of any of the following three events:  X  X ew recommendation generated X ,  X  X ailed to find a matching product X  and  X  X topped recording X  (after the user releases the PTT switch; only triggered in the speech-based inter-face). The first two mark both possible outcomes of the end of a critiquing cycle. http://voxforge.or g http://librivox.org http://www-oedt.kfunigraz.ac.at/ADABA/
In Perl Regular expressions,  X  X d+ X  match one or more digits whereas the surrounding parenthesis mark the subexpression that R
C OMMENT will treat as the extracted attribute value.
The traditional, mouse-based user interface shown in Figure 3 is very similar to other unit critiquing interfaces such as the FindMe systems and, except for the lack of compound critiques, especially the Qwikshop system [5, 21].

Next to the unit critiquing controls themselves, the interface also provides a  X  X ack X  button to remove critiques from the user prefer-ence model. This was added to encourage users to browse for even better matching products after finding an acceptable one without fearing to be unable to return to the current recommendation. The speech-based interface is depicted in Figure 4 14 .
A simple, energy-based automatic voice activity detection was implemented, but was ultimately deactivated in an effort to make users X  speech more focused on the task at hand and to avoid possi-ble accidental recognition results brought on by, e.g., talking with the person conducting the study. Instead, R E C OMMENT uses a  X  X ush to talk X  (PTT) methodology similar to a walkie-talkie, re-quiring users to press and hold a button while giving voice com-mands.

The original interf ace is in German, the screenshots show a trans-lated version.

The measured noise level is shown in the user interface at all times as a moving bar under the PTT button (VU meter). This was included to instill a sense of an actively listening system, especially for users who had not used speech-based interfaces before.
Because study participants were not informed about what kind of sentences would be interpreted correctly (see Section 4), the system instead showed correction hints as needed. These sparse in-structions were displayed only in case of multiple successive recog-nition errors or when a sentence was already partially recognized (in which case the instructions referred specifically to this partial match). A state diagram of this process, including some examples, is shown in Figure 5. Correction hints, just like correct recognition results, are shown inside the VU meter control element discussed above and automatically hidden after 3.5 seconds. Again, these measures were taken to encourage free articulation by minimizing guidance as much as possible without compromising learnability.
To examine the hypothesis that speech-based recommender sys-tems can outperform traditional interfaces, we conducted an empir-ical study.
The test group, consisting primarily of undergraduate and post-graduate students, was split into two groups, each consisting of 40 users for a total of 80 participants. One group, henceforth referred to as group A, used the speech-controlled interface whereas the other group, group B, used the mouse-based interface.

A more detailed breakdown of both groups can be found in Ta-ble 3.
Each participant was instructed to imagine buying a new digital compact camera. To this end, users were told to try to think about Characteristics Group A Group B Male 35 33 Female 5 7 Total 40 40 Median age 24 22 Personally own camera 67.5 % 60 % Seeked help when buying this camera 19.4 % 26.7 % Table 3: Demography of the test groups of the empirical study. a camera that best fits their personal needs and use R E C to find such a product. Participants were asked to ignore product dimensions that were not included in the recommendation interface (e.g. display size, shutter speed, etc.).

Both groups received purposefully minimal instructions regard-ing the actual user interface. The group using the mouse-based interface was simply told to  X  X se the buttons X  to find products that matched their requirements whereas the instructions for the speech-based interface were limited to an equivalent sentence and a small note explaining the PTT system (see Section 3.3).
 Specifically, the group testing the developed natural language inter-face did not receive any kind of tutorial or list of supported voice commands but was instead told to  X  X ry it out X  in an effort to encour-age users to use their own words when interacting with the system.
Direct feedback was collected with a questionnaire that was filled out by each participant immediately after completion of the assigned task. This questionnaire included questions about the par-ticipant X  X  knowledge of the domain, the quality of the last given recommendation, questions about the general usability as well as questions designed to gauge the user X  X  personal impression of the used interaction method.

The standard usability survey scale presented in [3] was used but had to be slightly adapted to better fit the tested system. Specifi-cally, questions related to the  X  X arious functions X  or the  X  X nconsis-tency X  potentially introduced by a rich feature set were not appli-cable to R E C OMMENT and were thus removed. Additionally, the question about the user  X  X requently using X  the presented system was reworded to instead ask if the user could see themselves using the system when purchasing his or her next digital compact cam-era. In order to maintain the same scale of 0 to 100 as the original SUS, the final multiplier of the calculation formula was increased, giving the remaining questions more, equally distributed, weight.
To evaluate R E C OMMENT , a database of currently available, compact digital cameras was assembled. Product data, images, and recent pricing information for a total of more than 600 distinct mod-els was collected from various online retailers and compiled into a single database.

The following feature set was collected: Model*, Manufac-turer*, Price ( e )*, Resolution (Megapixel)*, Sensor size (inches)*, Sensor type*, Size (w X h X d)*, Weight (gram)*, Internal memory (megabyte), Digital zoom (times), Optical zoom (times)*, External storage. Features marked with a * were selected for inclusion in the final interface after receiving feedback from early pilot testers. The 100 most popular cameras were additionally tagged with their current product sales rank (see 3.1.2).
In this section we will present the results obtained from the con-ducted empirical study.
An adequately performing speech recognition component is a necessary prerequisite for the potential success of any speech-based user interface. To determine the recognizers X  performance we will look at both the perceived and the actual recognition accuracy. To judge participants X  impressions, they were asked to rate the perfor-mance of the speech recognition as part of the questionnaire. The generally very positive result can be seen in Figure 6 15 Figure 6: Participants X  perception of the speech-recognition ac-curacy ( [ 1 , 4] , higher is better).

For the purposes of our evaluation, all recorded dialogs were manually transcribed after the completion of the study. To ac-curately evaluate the acoustic model and the recognizer itself, we compared the resulting (parsed) critiques (from the recogni-tion results) with the critiques extracted from the manually tran-scribed reference set. In this context, sentences such as  X  X heaper, please X  and, e.g.,  X  X heaper, pepper X  are therefore treated as equal because their difference does not impact R E C OMMENT  X  X  perfor-mance. Sentences consisting of more than one command or in-cluding modifying adjectives (see Section 3.1.3) where the system only captured part of the intention, are treated as partial errors. To establish a frame of reference, Google X  X  speech recognition web service 16 was used to transcribe the samples recorded during the course of the study. The results of the comparison of both recogni-tion systems can be seen in Figure 7. As can be seen, our custom recognition component based on Simon and PocketSPHINX man-ages to significantly outperform the off-the-shelf online service for our limited domain and proved to be sufficiently accurate for the purposes of this study. Figure 7: Comparison of the developed recognizer in compari-son with a state of the art, off-the-shelf online service.
The results were verified with a counter question. Questionnaires where either both questions were answered positively or both neg-atively have been removed before interpreting the results http://www.google.com/speech-api/v1/recognize?lang=de
The natural language parser was evaluated by manually review-ing spoken commands of utterances and comparing them with the system X  X  interpretation. Out of 384 sentences collected as part of the study, only 21 sentences (5.5 %) failed to parse correctly (in part or completely). Most of these errors were due to unexpected constructs like  X 7 optical zoom X  with notable exceptions being se-mantically complex commands like  X  X redit card size X  or  X  X ighest resolution for 120 Euro X  or commands referencing earlier critiques like  X  X ven more X . The majority of sentences referred to a single attribute, i.e., unit critiques were the predominant interaction mode (used in 85.7% of the cases) whereas compound critiques were rarely used. 74 sentences included references to explicit values and 12 used modifier factors (see Section 3.1.3). Table 4 shows an overview of the recognized sentences and Table 5 shows the be-ginning of a sample recommendation session.
 Sentence
I am looking for a camera with 12 megapixel and a weight of around 200 gram.
 This camera with the same properties just smaller.
 An even smaller camera.
 Optical zoom of 14 times would be better.

More optical zoom. [...]
To determine the usability of our created interfaces, we included a slightly modified version of the standard usability scale in the questionnaire (see Section 4.3). We compared the resulting SUS scores of the participants using the mouse-based interface (group B) with those using the speech-based interface (group A). Addi-tionally, for comparison purposes, we also present the reported us-ability of those 24 users that reported that the recognizer under-stood them well as a separate group. All three results are shown in Figure 8.
 While the increase in perceived usability between group A and B is not entirely conclusive (p = 0.13), the users that reported to be well understood by R E C OMMENT clearly preferred the speech-based interface over the traditional one (p &lt; 0.02). Moreover, par-ticipants of group A answered more favorably  X  X es X  on the question asking if they would use R E C OMMENT before next purchasing a digital camera than the control group, suggesting increased user satisfaction (mean of group A: 3.1, group B: 2.7; p &lt; 0.5).
Despite using the same basic recommender algorithm, the re-ported recommendation quality and efficiency differed substan-tially. Participants using the speech-based user interface reported to like the last presented product better than those using the tradi-tional user interface (p &lt; 0.05). A more detailed breakdown of their answer to the related question on the questionnaire can be found in Figure 9. Figure 9: User score of last recommended item ( [1 , 4] , higher is better).

Furthermore, users of the speech-based interface used consider-ably fewer interaction cycles before arriving at the desired product (see Figure 10). However, although the sessions were not timed, it is worth mentioning that this may not directly translate into signifi-cantly shorter overall session length (seconds) because articulating preferences by voice is obviously more time consuming than click-ing a button.
In this paper we presented R E C OMMENT , a new approach to critiquing-based recommender systems using a speech-controlled natural language interface. We compared the speech-based inter-face with a traditional, mouse-based user interface in an empirical study. The results show that users of the speech-based interface found overall more satisfactory products, required less interaction cycles and were more likely to want to use the system again.
Without further research, it is hard to draw definitive conclu-sions as to why users reliably reached better fitting products with the speech-based interface, but it may be argued that users spent less time exploring the product space and instead concentrated on their actual needs, likely because of the increased effort required to formulate a voice command. This and other theories should be further explored in future work.

The speech recognition and natural language parsing compo-nents used in R E C OMMENT , while sufficient for basic functional-ity, certainly leave much room for improvement, including support for other languages than German. The surprisingly low amount of compound critiques in natural interaction should also be inves-tigated further. Monitored user sessions with a voice controlled, compound critiquing system could also yield valuable insight into hidden correlation between attributes by detecting patterns of fre-quently co-occurring attributes in user input.

Moreover, future works should also compare and contrast the performance of speech-based interfaces for alternate recommender approaches (e.g., constraint-based recommenders [11]).

Some users also had trouble to adjust to talking to what essen-tially still looked like a traditional computer program. Integration of speech output and an avatar to talk to has been shown to lower this entry barrier [19]. Moreover, human conversational speech also includes other, subtle emotional cues that can be extracted by an appropriate system [9]. Future systems could integrate this additional information to influence (e.g., the weight of) the de-duced constraints to potentially improve recommendation quality even further.
The work presented in this paper has been partially funded by the Austrian Research Promotion Agency (Casa Vecchia, 825889) [1] D. Bridge. Towards conversational recommender systems: A [2] E. Brill and R. J. Mooney. An overview of empirical natural [3] J. Brooke. Sus-a quick and dirty usability scale. Usability [4] R. Burke. Knowledge-based recommender systems. In [5] R. D. Burke, K. J. Hammond, and B. Yound. The findme [6] R. D. Burke, K. J. Hammond, and B. C. Young.
 [7] L. Chen and P. Pu. Evaluating critiquing-based recommender [8] L. Chen and P. Pu. Critiquing-based recommenders: survey [9] R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Votsis, [10] S.-J. Doh. Enhancements to transformation-based speaker [11] A. Felfernig and R. Burke. Constraint-based recommender [12] M. Mandl and A. Felfernig. Improving the performance of [13] K. McCarthy, L. McGinty, and B. Smyth. Dynamic [14] K. McCarthy, J. Reilly, L. McGinty, and B. Smyth. On the [15] K. McCarthy, Y. Salem, and B. Smyth. Experience-based [16] L. McGinty and J. Reilly. On the evolution of critiquing [17] D. McSherry and D. W. Aha. The ins and outs of critiquing. [18] P. H. Z. Pu and P. Kumar. Evaluating example-based search [19] L. Qiu and I. Benbasat. An investigation into the effects of [20] J. Reilly, K. McCarthy, L. McGinty, and B. Smyth.
 [21] J. Reilly, K. McCarthy, L. McGinty, and B. Smyth.
 [22] J. Reilly, J. Zhang, L. McGinty, P. Pu, and B. Smyth. [23] E. Shriberg. Toerrrr X  X s human: ecology and acoustics of [24] C. A. Thompson, M. H. Goeker, and P. Langley. A [25] J. Zhang and P. Pu. A comparative study of compound
