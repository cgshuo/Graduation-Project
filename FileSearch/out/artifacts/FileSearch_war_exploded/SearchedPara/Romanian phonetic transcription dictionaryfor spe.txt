 J X zsef Domokos  X  Ovidiu Buza  X  Gavril Toderean Abstract This paper intends to present a machine readable Romanian language pronunciation dictionary called NaviRo. The dictionary contains 138,500 unique words from the DexOnline dictionary together with their phonetic transcriptions in speech assessment method phonetic alphabet. The development of the pronunciation dictionary and the performed validation tests are also described in the paper. NaviRo pronunciation dictionary is freely available on the project website ( http://users. utcluj.ro/~jdomokos/naviro ) in plain text, Hidden Markov Model Toolkit and Festival speech synthesis system dictionary format. There are also available for download the used grapheme and phoneme sets and the audio samples for the used phonemes. The use of these resources is completely unrestricted for any research purposes in order to speed up Romanian language speech technology research.
 Keywords Phonetic transcription dictionary  X  Pronunciation dictionary  X  Grapheme to phoneme (G2P) conversion  X  Letter-to-sound mapping  X  Letter-to-phoneme (L2P) transcription  X  Romanian language 1 Introduction Natural language is the most common way for humans to interact with each others and also it is desirable to be used in communication with machines. This can explain the commercial success of modern large vocabulary continuous speech recognition (LVCSR) systems and their applications such as dictation systems, telephone speech transcription and call-centre applications, speaker independent automatic broadcast news transcription and indexing, lecture transcription, meeting transcription, voice command applications, voice search and so on (Saon and Chien 2012 ). In the past years there has been a significant growth in multimodal human computer interface (HCI) research including speech recognition based HCI (Sebe 1926 ). But speech recognition systems are mainly developed for English language although the used techniques are mostly language independent. The lack of freely usable linguistic resources is the main problem in development of LVCSR systems for other languages.
 Romanian language is a resource scarce language (Cristea and Fora  X  scu 2006 ; Burileanu et al. 2010 ; Stan et al. 2010 ). There are just a few freely usable language resources such as transcribed and annotated speech corpora or pronunciation dictionaries. In this way only an insignificant number of speech recognition systems exist to deal with the Romanian language. Excepting the recently introduced Google Voice Search, there is no other fully functional free to use LVCSR system for Romanian although there are reported several Romanian language automatic speech recognition (ASR) systems (Munteanu and Vizitiu 2008 ; Militaru et al. 2009 ; Buzo et al. 2013 ). This is the main reason which calls for further research in this domain.
Pronunciation dictionaries are very useful resources for spoken language technology. These resources are widely used in ASR and text to speech (TTS) synthesis applications (Burileanu et al. 2010 ; Bisani and Ney 2008 ) because they are at the base of automated segmentation of speech at phonetic level (Ga  X  nd Castro 2002 ), and also predicting the pronunciation of a written word is an important sub-task of all speech production systems (Davel and Barnard 2008 ). In case of some languages such as Romanian, considered under-resourced, the existence of a pronunciation dictionary can considerably speed up ASR and mainly TTS system development.
 From the existing English language pronunciation dictionaries we can mention the CMU (Carnegie Mellon University) Pronouncing Dictionary http://www.speech. cs.cmu.edu/cgi-bin/cmudict , the BEEP (British English Example Pronunciations) http://www.eng.cam.ac.uk/comp.speech/Section1/Lexical/beep.html or the OALD (The Oxford Advanced Learners Dictionary) http://oald8.oxfordlearnersdictionaries. com/ . Any of these resources can be used for grapheme-to-phoneme transcription in large vocabulary continuous speech recognition and text-to-speech system develop-ment. For the Hungarian language the electronic pronunciation dictionary of Hungarian wordscanbefoundon-lineat http://beszedmuhely.tmit.bme.hu/mksz/index.php .Tothe best of our knowledge there is no large, machine-readable pronunciation dictionary available for Romanian language excepting the one used in RSS corpus. This corpus contains about 65,000 words transcribed using letter-to-sound rules automatically learned by a classification and regression tree (CART; Stan et al. 2010 ).
The studied specialized literature (Stan et al. 2010 ; Burileanu 2002 ; Jitca  X  et al. 2002 , 2003 ; Toma and Munteanu 2009 ; Ordean et al. 2009 ; Domokos et al. 2011 , 2012 ; Boros  X  et al. 2012 ) shows that there exist some automatic grapheme-to-phoneme transcription systems for Romanian, and also some small, hand built phonetically transcribed databases are reported which could be used for training and testing such systems, but these applications and resources are not freely available. In the most important papers, grapheme-to-phoneme transcription for the Romanian language is handled using rule-based systems (Toma and Munteanu 2009 ), artificial neural network based machine learning systems (Burileanu 2002 ; Jitca  X  et al. 2002 , 2003 ; Domokos et al. 2011 ) and hybrid systems that use transcription rules and machine learning to solve the ambiguities of rules (Ordean et al. 2009 ; Domokos et al. 2012 ).
 Acoustic Modelling subsystem of every LVCSR system is dominated by Hidden Markov Models (HMMs) over the past decades. This model shows the best performances in LVCSR systems which handle large vocabularies of words, making impossible to collect enough representation for each word to train word HMMs (Livescu et al. 2012 ; Jurafsky and Martin 2008 ; Young et al. 2006 ). Instead LVCSR systems use subword units like phones, syllables or graphemes that occur more often in reasonably size speech corpora. The most widely used subword units are the phonemes and context dependent phonemes (i.e. triphonemes or quintphonemes). The latest has the advantage that it can handle the effects of coarticulation. In a typical language there are tens of thousands of triphone units (Livescu et al. 2012 ; Jurafsky and Martin 2008 ). This makes it difficult to train speaker independent triphone HMMs for under resourced languages.

Phonetic transcription is a time consuming task for resource scarce languages with no phonetic transcription dictionaries. Graphemes can successfully substitute phonemes in case of phonetic languages. As Romanian is a language with strong phonetic nature, a good choice in this case seems to be to use context dependent trigraphemes as subword units and to build HMMs for these trigraphemes. In this way it is possible to skip the grapheme-to-phoneme conversion task. There is some recent research reported in the literature about using grapheme models instead of phoneme models for speech segmentation (Stan et al. 2012 ; Domokos et al. 2013 ). Anyway an open research question for Romanian language is how well can graphemes substitute phonemes in acoustic modelling.

Although for speech recognition task grapheme to phoneme transcription is not necessary because graphemes can successfully substitute phonemes in case of phonetic languages, in the case of speech synthesis applications this step is more difficult to be skipped.

The work presented in this article is related to the NaviRo research project ( http://users.utcluj.ro/~jdomokos/naviro ) with the main objective to create a Romanian language voice driven Internet browsing demo application which works with the most popular WEB browsers like Mozilla Firefox, Google Chrome, Opera and Internet Explorer and to show how Romanian language speech recognition based multimodal HCIs can be constructed. An important subtask of this project is the development of a large Romanian language pronunciation dictionary to be used for the recorded speech database phonetic transcription.

The outline of the paper is as fallows: Sect. 2 presents the specific Romanian language grapheme and phoneme set and some classifications on both graphemes and phonemes, Sect. 3 presents the development steps of the pronunciation dictionary and discussions on different implementation stages, Sect. 4 include validation test results with conclusions and finally Acknowledgements and References are presented. 2 The used grapheme and phoneme set The used grapheme set contains the 31 characters used for modern Romanian writing according to the second edition of DOOM X  X he spelling, orthoepic and morphological dictionary of Romanian language (Institutul de Lingvistica  X  Iorgu 2005 ). This grapheme set is presented in Table 1 .

Romanian language graphemes can be classified as simple graphemes and complex (or composed) graphemes. The simple graphemes (the 31 alphabet letters noted with a single letter, and presented in Table 1 ) coincide with the written letters and can denote one or more phonemes. Complex graphemes in Romanian (in total 10) are formed from 2 or 3 letters and denote one single phoneme (the complex graphemes in Romanian are: ch, gh, ce, ci, ge, gi, che, chi, ghe, ghi; Beldescu 1984 ).
Simple graphemes can be monovalent or polyvalent. Monovalent graphemes always denote one single phoneme therefore they can be easily transcribed into their phonetic form. The polyvalent graphemes can lead to ambiguity in case of their transcription because they can be transcribed to more than one phoneme.
Complex graphemes are monovalent, they can be phonetically transcribed without any problems. Most of the simple graphemes are monovalent too [ ^ a ,d,f,h, according to Institutul de Lingvistica  X  Iorgu ( 2005 )] and therefore they can be easily transcribed.
 Most of polyvalent graphemes are marking vocals [a, a  X  , X   X  , e, i, o, u, y according Beldescu ( 1984 ), or just e, i, o, w, y according to Institutul de Lingvistica  X  Iorgu ( 2005 )], but there are also some polyvalent graphemes which denote consonants [b, c, g, k, n, x according to reference Beldescu ( 1984 ), or c, g, h, k, q, x according to Institutul de Lingvistica  X  Iorgu ( 2005 )]. These polyvalent graphemes raise many problems in Romanian language grapheme-to-phoneme transcription.

According to the specialized literature, Romanian phonetic inventory generally contains seven vowels, 2 X 4 semivowels and 21 consonants. Table 2 shows the SAMPA (speech assessment method phonetic alphabet) coding of the phoneme set used for the development of our dictionary. It contains 32 different phonemes including also the phonetically null unit (or silence) [sil].

In Table 2 we have used the following notations:  X  @ stands for Romanian a  X  grapheme (i.e. arma  X  );  X  1 stands for Romanian  X  and  X  graphemes (i.e. rom ^ a n,  X   X  nalt);  X  k replaces character c (i.e. cot, arc);  X  i_0 represents short i from the end of the words (i.e. lupi);  X  j represents the grapheme i when pronounced as semivowel (i.e. iar, oaie);  X  S is for Romanian character  X  (i.e. s  X al);  X  ts replaces character  X  (i.e. a  X  X  );  X  tS stands for the grapheme groups ce , ci (i.e. ceramic  X  , cioc  X  nitoare);  X  e_X , o_X replaces the semivowels ea and oa (i.e. deal, seara  X  , soare, oala  X  );  X  dZ for the grapheme groups ge , gi (i.e. gem, gin);  X  Z stands for character j (i.e. joi).

So grapheme-to-phoneme transcription problem for the Romanian language is not trivial. In some cases even phonetician experts have divergent opinions, see Institutul de Lingvistica  X  Iorgu ( 2005 ), Beldescu ( 1984 ). Often it is not enough to take into account just the recommendations from the Romanian Language Orthographic, Orthoepic and Morphological Dictionary. Grapheme monovalence changes if we are taking into account syntactic phonetics. This makes Romanian language continuous speech phonetic transcription even more difficult. 3 Development of the pronunciation dictionary 3.1 5k words pronunciation dictionary Our initial grapheme-to-phoneme conversion system is based on the system described by Sejnowski and Rosenberg ( 1987 ) and adapted for Romanian by Burileanu et al. ( 1999 ; Burileanu 2002 ). Therefore the system is based on a parallel structure having 30 similar artificial neural networks (ANNs) with 25 common inputs. Each network is designed and trained to detect the presence of an articulatory feature from the 30 features used to encode the Romanian language phonemes (Table 1 ). The networks have to point out the presence or the absence of one articulatory feature at their output.

The words intended to be transcribed are previously preprocessed and coded in order to be presented at the input of the ANNs. Preprocessing means that the beginning and the end of each word is appended with two white space characters and after this, the input words are split into five character long sequences and each character is binary coded on 5 bits. The five character long sequences (coded as 5  X  5 = 25 bit information) are presented at the input of each neural network (hence we can deduce the number of network inputs). Always the central grapheme from the sequence of five graphemes is analysed, the other four graphemes represent contextual information (two graphemes for the left context and two graphemes for the right context). The coded grapheme sequences at the input of the system are shifted grapheme by grapheme until all the component graphemes are presented to the input (Burileanu et al. 1999 ).
 Input words preprocessing, grapheme coding and phoneme coding according to Burileanu et al. ( 1999 ) have been implemented with a proprietary Java application, using regular expressions. This application also generates the training and testing sets for the neural networks. This application can also replace characters that are not part of the used grapheme set with their correspondences. The application was briefly presented in Domokos et al. ( 2011 ).

The networks output form a 30 bit long binary sequence. Each network is trained to indicate the presence or the absence of one particular articulatory feature from Table 3 (value 0 if the feature was not detected, and value 1 for reporting the presence of that feature).

The used neural networks are totally connected MLP (multilayer perceptron) with two hidden layers. The internal structure and the number of neurons in the hidden layers were determined based on some experimental testing. The structure with the best results has 25 inputs given by the number of input bits used to encode the five input graphemes, eight neurons in the first hidden layer, five neurons in the second hidden layer and one output to indicate the corresponding articulatory feature presence or absence. The structure of the used 30 feed-forward neural networks is presented in Fig. 1 a.

The neurons from the hidden layers have tansigmoidal transfer function and the output level has pure linear transfer function. The input weights of the network are grouped into the Input Weigth matrix IW[25  X  8], and the Layer Weights are stored in 2 matrices LW1 and LW2 with the dimensions LW1[8  X  5] and LW2[5  X  1] respectively.

The entire structure of the 30 parallel networks system is presented on Figs. 1 b and 2 , depending on which task is involved. Figure 1 b shows the training phase of the system and Fig. 2 shows the system when used for grapheme-to-phoneme conversion.

Discussion on the ANN based transcription system For training and preliminary testing the system we have manually built a database containing 1,004 phonetically transcribed Romanian language words. The words were transcribed by phonetician experts and were collected from some linguistic resources available in published form (Institutul de Lingvistica  X  Iorgu 2005 ; Beldescu 1984 ). The database contains a total number of 5,497 phonemes. For training and testing, the phonetically transcribed word set was randomly divided in three parts: training set, validation set and test set in proportion of 80, 10 and 10 % respectively.
 Network training was performed in Matlab environment, using Levenberg X  Marquardt back-propagation (trainlm) training function, mse (mean squared normalized error) performance criterion and early stopping validation vectors are used to stop training early if the network performance on the validation vectors fails to improve or remains the same for 20 train epochs. Network training is quick, it takes less than 1 min for each network on a usual laptop computer with Intel Core2 Duo CPU P8400 @ 2.26 GHz, and 2 GB memory, but training time can be further improved by perform parallel training process on multiple workstations or on multiprocessor stations.

When testing the system, the neural networks generate one by one the 30 bit code indicating the presence or the absence of the 30 articulatory features based on the input grapheme codes. The output feature vector is compared with the encoded vectors of the phonemes used. The distance between the output vector and each coded vector is calculated using Manhattan distance function. System response is chosen as the vector with the smallest distance, replacing the correlation table method described in Burileanu et al. ( 1999 ).

The trained system performs grapheme-to-phoneme transcription with an average accuracy of 92.83 % at the phoneme level. Table 3 shows the error percentage for each articulatory feature used. The features with the biggest error percentage are the Closed, Front and type 2. We have investigated why these three articulatory features were so weekly recognized and the answer is that there were not enough examples for this features in the training set. We than increase the size of the manually transcribed words to 2,383. Retraining the system, grapheme-to-phoneme conver-sion accuracy achieved 97.72 % at phoneme level.

In comparison with the networks of different sizes presented in Burileanu et al. ( 1999 ; without giving the exact dimensions) our system brings a simplification on implementation. After several experiments, we have found that by altering the structure of hidden layers only insignificant improvements of the recognition results can be achieved. 3.2 100k+ words pronunciation dictionary To develop the 100k+ pronunciation dictionary we have used the largest online dictionary for Romanian language, the DexOnline X  X nline Explanatory Dictionary http://www.dexonline.ro . DexOnline dictionary is freely available and can be used in accordance with the terms of GNU General Public License. It can be downloaded from the Internet also as a mysqldump generated SQL file. The database can be easily restored on a MySQL relational database server (also available for free download at http://www.mysql.com ).

DEXOnline database is organized in multiple tables. The most important three tables from the point of view of exporting dictionary words are: inflectedform, definition and lexem.

The inflectedform table contains all the inflected word-forms recorded in the database. This is the largest table from Dexonline. By selecting all the distinct wordforms from this table we get a total number of 992,979 records. This is the maximum size of pronunciation dictionary we can create based on DEXOnline. We have exported these words in distinct text files separated by the first grapheme of the words, one word per line, thus resulting input files with a reasonable number of records in the order of several tens of thousands per file.

The definition table is a smaller table containing the definitions recorded in database. A total number of 126,563 definitions are available.

The lexem table contains just the base forms of words from the dictionary, totally 139,509. Some of these words are foreign language words and therefore they are not included in the pronunciation dictionary. We have exported also these two tables in text format with UTF-8 character encoding, one word per line in order to perform automatic grapheme-to-phoneme conversion. Some additional operations were performed for resolving input character mapping such as:
After this preprocessing stage we extracted from the lexem table a word list of 138,500 entries.

For the development and testing of the 100k+ words pronunciation dictionary we have used the freely available Dictionary Maker application created by the Human Language Technologies Research Group of the Meraka Institute, South Africa http://dictionarymaker.sourceforge.net/ . This software application was developed to facilitate the creation of an electronic pronunciation dictionary in a target language.
A Dictionary Maker project can be started with either a word list or an initial dictionary or both (Davel and Barnard 2003 ). The word list defines the words that will be used to create the dictionary. For our experiments the word list consists of words exported from the DexOnline dictionary. Importing an initial dictionary will provide rules that can be used to predict pronunciations for words in the word list. If the initial dictionary is small, the predictions will not be very accurate, but will improve through the bootstrapping verification process. If no dictionary is imported, there are no initial grapheme-to-phoneme prediction rules available, and therefore no initial pronunciation predictions will be given by the system. The user then has to provide the entire pronunciation. In this later case the development of a large pronunciation dictionary is a very time consuming task.
 Dictionary Maker use a modified implementation of Kohonen X  X  Dynamically Expanding Context (DEC) algorithm, a popular instance-based learning algorithm that predicts phoneme realization based only on grapheme context. DEC is used to extract rules of the form (Davel and Barnard 2008 ): (left context, grapheme, right context) ! phoneme.

Generating a new pronunciation is a simple procedure: each grapheme in the word is considered in turn, and the rule describing the largest matching context is used to predict the phoneme to be generated (Davel and Barnard 2003 ).
We have used Dictionary Maker with the 5k transcribed words as initial dictionary. The 5k words were transcribed using our previously presented ANN based automated grapheme-to-phoneme transcription system (Domokos et al. 2011 ). In this way we have enough grapheme-to-phoneme prediction rules so that the transcriptions returned by Dictionary Maker do not need many corrections. Changes are needed only for exceptions from the standard pronunciation. The system architecture is depicted in Fig. 3 .

To achieve the best transcription results we have over-tested the 5k word pronunciation dictionary using Dictionary Maker application.

We have recorded and segmented the Romanian phonemes for the used phoneme set, using Audacity, the free, cross-platform sound editor application http://audacity.sourceforge.net/ . The utterances were recorded by a young male speaker, fluent in Romanian language, the first author of this paper. These audio files were provided to Dictionary Maker in order to be used for generation of the sounded version for each transcription for the words included in the word list. We built the used grapheme and phoneme sets for Romanian language as a Dictionary Maker .gra and a .pho file respectively.

The system runs through the word list word by word, predicts a pronunciation and sounds out the phonemes of the word. The user listens to the generated pronunciation variant and provides a verdict with consideration to the accuracy of the word pronunciation pair choosing one of the answers, according to Dictionary Maker tutorial found on http://dictionarymaker.sourceforge.net/ :
Even in this way the pronunciation dictionary development is a time consuming task, but the role of the human in this process is only to supervise and correct eventual errors of the system. The system can work also unsupervised by human factor by using a self-developed, modified version of Dictionary Maker application. This option gives the possibility to perform automatic grapheme to phoneme conversion using the Dictionary Maker, without sounding out the resulting transcription and without user confirmation. In this automatic mode, the words from the word list are taken one by one, grapheme-to-phoneme conversion is performed using the DEC algorithm and grapheme-to-phoneme conversion rules are updated after each transcribed word.

The created dictionary was exported in text format with UTF-8 character encoding and it is available in 2 more different formats: Each phoneme is delimited by spaces in [pronunciation] sequence.

Discussions on the 100k+ words pronunciation dictionary Some selected fragments from the developed NaviRO pronunciation dictionary in text format are presented in Table 2 .

The generated pronunciation dictionary together with the belonging language resources (the used grapheme and phoneme sets, the recorded and segmented audio samples for the used phoneme set) can be freely downloaded from the NaviRO project website ( http://users.utcluj.ro/~jdomokos/naviro ), and the use of this resources for any research purpose is completely unrestricted in order to promote Romanian language speech technology. 4 Evaluation of the dictionary We performed evaluation test of the generated pronunciation dictionary, since the quality and the consistence of the dictionary is crucial for the use in further research. We use 80 % of the dictionary (110,800 words) to train the Phonetisaurus WFST-driven grapheme-to-phoneme converter downloadable from http://code.google.com/ p/phonetisaurus/ . We retain 10 % of the dictionary for development and 10 % for testing purposes. The joint sequence N-gram model needed by Phonetisaurus was estimated using the MIT Language Modeling toolkit (MITLM; Bo-June and Glass 2008 ).

Using the training part of the dictionary we performed alignment, N-gram estimation and language model conversion to word finite state transducer. At phoneme level we have a total number (T) of 117,737 tokens in reference. After generating pronunciations for the word list included in the test dataset we found 117,485 matches (M), 157 substitutions (S), 131 insertions (I) and 95 deletions (D). Such we have 99.79 % correct transcriptions calculated as the ratio of matched and total tokens: M/T. Token error rate (ER) was 0.33 % (calculated as (S+I+D)/T) and accuracy computed as 1.0-ER was 99.67 %.

At the word level we had a number of 13,850 sequences (S) of which 13,507 were correctly generated sequences (C) and 343 error sequences (E). Therefore the word error rate computed as E/S was 2.48 % and the transcription accuracy at the word level was 97.52 % calculated as 1.0-E/S.

The evaluation results on both phoneme and word level are showing that the dictionary is consistent enough to be used for further research. 5 Conclusions and future works We have designed and implemented a system to allow a speaker fluent in the Romanian language to easily develop a pronunciation dictionary without having expert linguistic knowledge or advanced programming skills.

With this system we have created the first 100k+ words (the exact number of words is 138,500) machine-readable Romanian language pronunciation dictionary based on the words from the lexem table of DexOnline.
 We appreciate that the resulting pronunciation dictionary is very useful for Romanian language LVCSR system and text-to-speech system development.
The authors cannot guarantee the accuracy of the dictionary, nor its suitability for any specific purpose. In fact, we expect some errors, omissions and inconsistencies to remain in the dictionary however the entries were manually checked. Any suggestions, corrections and observations are welcomed. We intend to continually update the dictionary by correcting existing entries and by adding new ones. From time to time a new version will be posted on the project website.

As future work we can mention that our final goal is to generate a 1 million word pronunciation dictionary based on the inflected forms from the DexOnline dictionary so we welcome input from users in order to increase dictionary size and cover pronunciation variants. This 100k words dictionary will be a good input for Dictionary Maker in order to perform grapheme to phoneme mapping for the inflected words from DexOnline X  X  inflectedword table. Once all the near 1 million inflected forms are transcribed, the resulting dictionary will be ready to be used for continuous speech phonetic transcription generation. We also intend to train a model and deploy it as a web service for online Romanian grapheme-to-phoneme transcription.

We are also interested to generate pronunciations for Romanian person names and institutions names because the needed word lists can be easily collected from the Internet. All these resources will be publicly available on the project website. References
 J X zsef Domokos  X  Ovidiu Buza  X  Gavril Toderean Abstract This paper intends to present a machine readable Romanian language pronunciation dictionary called NaviRo. The dictionary contains 138,500 unique words from the DexOnline dictionary together with their phonetic transcriptions in speech assessment method phonetic alphabet. The development of the pronunciation dictionary and the performed validation tests are also described in the paper. NaviRo pronunciation dictionary is freely available on the project website ( http://users. utcluj.ro/~jdomokos/naviro ) in plain text, Hidden Markov Model Toolkit and Festival speech synthesis system dictionary format. There are also available for download the used grapheme and phoneme sets and the audio samples for the used phonemes. The use of these resources is completely unrestricted for any research purposes in order to speed up Romanian language speech technology research.
 Keywords Phonetic transcription dictionary  X  Pronunciation dictionary  X  Grapheme to phoneme (G2P) conversion  X  Letter-to-sound mapping  X  Letter-to-phoneme (L2P) transcription  X  Romanian language 1 Introduction Natural language is the most common way for humans to interact with each others and also it is desirable to be used in communication with machines. This can explain the commercial success of modern large vocabulary continuous speech recognition (LVCSR) systems and their applications such as dictation systems, telephone speech transcription and call-centre applications, speaker independent automatic broadcast news transcription and indexing, lecture transcription, meeting transcription, voice command applications, voice search and so on (Saon and Chien 2012 ). In the past years there has been a significant growth in multimodal human computer interface (HCI) research including speech recognition based HCI (Sebe 1926 ). But speech recognition systems are mainly developed for English language although the used techniques are mostly language independent. The lack of freely usable linguistic resources is the main problem in development of LVCSR systems for other languages.
 Romanian language is a resource scarce language (Cristea and Fora  X  scu 2006 ; Burileanu et al. 2010 ; Stan et al. 2010 ). There are just a few freely usable language resources such as transcribed and annotated speech corpora or pronunciation dictionaries. In this way only an insignificant number of speech recognition systems exist to deal with the Romanian language. Excepting the recently introduced Google Voice Search, there is no other fully functional free to use LVCSR system for Romanian although there are reported several Romanian language automatic speech recognition (ASR) systems (Munteanu and Vizitiu 2008 ; Militaru et al. 2009 ; Buzo et al. 2013 ). This is the main reason which calls for further research in this domain.
Pronunciation dictionaries are very useful resources for spoken language technology. These resources are widely used in ASR and text to speech (TTS) synthesis applications (Burileanu et al. 2010 ; Bisani and Ney 2008 ) because they are at the base of automated segmentation of speech at phonetic level (Ga  X  nd Castro 2002 ), and also predicting the pronunciation of a written word is an important sub-task of all speech production systems (Davel and Barnard 2008 ). In case of some languages such as Romanian, considered under-resourced, the existence of a pronunciation dictionary can considerably speed up ASR and mainly TTS system development.
 From the existing English language pronunciation dictionaries we can mention the CMU (Carnegie Mellon University) Pronouncing Dictionary http://www.speech. cs.cmu.edu/cgi-bin/cmudict , the BEEP (British English Example Pronunciations) http://www.eng.cam.ac.uk/comp.speech/Section1/Lexical/beep.html or the OALD (The Oxford Advanced Learners Dictionary) http://oald8.oxfordlearnersdictionaries. com/ . Any of these resources can be used for grapheme-to-phoneme transcription in large vocabulary continuous speech recognition and text-to-speech system develop-ment. For the Hungarian language the electronic pronunciation dictionary of Hungarian wordscanbefoundon-lineat http://beszedmuhely.tmit.bme.hu/mksz/index.php .Tothe best of our knowledge there is no large, machine-readable pronunciation dictionary available for Romanian language excepting the one used in RSS corpus. This corpus contains about 65,000 words transcribed using letter-to-sound rules automatically learned by a classification and regression tree (CART; Stan et al. 2010 ).
The studied specialized literature (Stan et al. 2010 ; Burileanu 2002 ; Jitca  X  et al. 2002 , 2003 ; Toma and Munteanu 2009 ; Ordean et al. 2009 ; Domokos et al. 2011 , 2012 ; Boros  X  et al. 2012 ) shows that there exist some automatic grapheme-to-phoneme transcription systems for Romanian, and also some small, hand built phonetically transcribed databases are reported which could be used for training and testing such systems, but these applications and resources are not freely available. In the most important papers, grapheme-to-phoneme transcription for the Romanian language is handled using rule-based systems (Toma and Munteanu 2009 ), artificial neural network based machine learning systems (Burileanu 2002 ; Jitca  X  et al. 2002 , 2003 ; Domokos et al. 2011 ) and hybrid systems that use transcription rules and machine learning to solve the ambiguities of rules (Ordean et al. 2009 ; Domokos et al. 2012 ).
 Acoustic Modelling subsystem of every LVCSR system is dominated by Hidden Markov Models (HMMs) over the past decades. This model shows the best performances in LVCSR systems which handle large vocabularies of words, making impossible to collect enough representation for each word to train word HMMs (Livescu et al. 2012 ; Jurafsky and Martin 2008 ; Young et al. 2006 ). Instead LVCSR systems use subword units like phones, syllables or graphemes that occur more often in reasonably size speech corpora. The most widely used subword units are the phonemes and context dependent phonemes (i.e. triphonemes or quintphonemes). The latest has the advantage that it can handle the effects of coarticulation. In a typical language there are tens of thousands of triphone units (Livescu et al. 2012 ; Jurafsky and Martin 2008 ). This makes it difficult to train speaker independent triphone HMMs for under resourced languages.

Phonetic transcription is a time consuming task for resource scarce languages with no phonetic transcription dictionaries. Graphemes can successfully substitute phonemes in case of phonetic languages. As Romanian is a language with strong phonetic nature, a good choice in this case seems to be to use context dependent trigraphemes as subword units and to build HMMs for these trigraphemes. In this way it is possible to skip the grapheme-to-phoneme conversion task. There is some recent research reported in the literature about using grapheme models instead of phoneme models for speech segmentation (Stan et al. 2012 ; Domokos et al. 2013 ). Anyway an open research question for Romanian language is how well can graphemes substitute phonemes in acoustic modelling.

Although for speech recognition task grapheme to phoneme transcription is not necessary because graphemes can successfully substitute phonemes in case of phonetic languages, in the case of speech synthesis applications this step is more difficult to be skipped.

The work presented in this article is related to the NaviRo research project ( http://users.utcluj.ro/~jdomokos/naviro ) with the main objective to create a Romanian language voice driven Internet browsing demo application which works with the most popular WEB browsers like Mozilla Firefox, Google Chrome, Opera and Internet Explorer and to show how Romanian language speech recognition based multimodal HCIs can be constructed. An important subtask of this project is the development of a large Romanian language pronunciation dictionary to be used for the recorded speech database phonetic transcription.

The outline of the paper is as fallows: Sect. 2 presents the specific Romanian language grapheme and phoneme set and some classifications on both graphemes and phonemes, Sect. 3 presents the development steps of the pronunciation dictionary and discussions on different implementation stages, Sect. 4 include validation test results with conclusions and finally Acknowledgements and References are presented. 2 The used grapheme and phoneme set The used grapheme set contains the 31 characters used for modern Romanian writing according to the second edition of DOOM X  X he spelling, orthoepic and morphological dictionary of Romanian language (Institutul de Lingvistica  X  Iorgu 2005 ). This grapheme set is presented in Table 1 .

Romanian language graphemes can be classified as simple graphemes and complex (or composed) graphemes. The simple graphemes (the 31 alphabet letters noted with a single letter, and presented in Table 1 ) coincide with the written letters and can denote one or more phonemes. Complex graphemes in Romanian (in total 10) are formed from 2 or 3 letters and denote one single phoneme (the complex graphemes in Romanian are: ch, gh, ce, ci, ge, gi, che, chi, ghe, ghi; Beldescu 1984 ).
Simple graphemes can be monovalent or polyvalent. Monovalent graphemes always denote one single phoneme therefore they can be easily transcribed into their phonetic form. The polyvalent graphemes can lead to ambiguity in case of their transcription because they can be transcribed to more than one phoneme.
Complex graphemes are monovalent, they can be phonetically transcribed without any problems. Most of the simple graphemes are monovalent too [ ^ a ,d,f,h, according to Institutul de Lingvistica  X  Iorgu ( 2005 )] and therefore they can be easily transcribed.
 Most of polyvalent graphemes are marking vocals [a, a  X  , X   X  , e, i, o, u, y according Beldescu ( 1984 ), or just e, i, o, w, y according to Institutul de Lingvistica  X  Iorgu ( 2005 )], but there are also some polyvalent graphemes which denote consonants [b, c, g, k, n, x according to reference Beldescu ( 1984 ), or c, g, h, k, q, x according to Institutul de Lingvistica  X  Iorgu ( 2005 )]. These polyvalent graphemes raise many problems in Romanian language grapheme-to-phoneme transcription.

According to the specialized literature, Romanian phonetic inventory generally contains seven vowels, 2 X 4 semivowels and 21 consonants. Table 2 shows the SAMPA (speech assessment method phonetic alphabet) coding of the phoneme set used for the development of our dictionary. It contains 32 different phonemes including also the phonetically null unit (or silence) [sil].

In Table 2 we have used the following notations:  X  @ stands for Romanian a  X  grapheme (i.e. arma  X  );  X  1 stands for Romanian  X  and  X  graphemes (i.e. rom ^ a n,  X   X  nalt);  X  k replaces character c (i.e. cot, arc);  X  i_0 represents short i from the end of the words (i.e. lupi);  X  j represents the grapheme i when pronounced as semivowel (i.e. iar, oaie);  X  S is for Romanian character  X  (i.e. s  X al);  X  ts replaces character  X  (i.e. a  X  X  );  X  tS stands for the grapheme groups ce , ci (i.e. ceramic  X  , cioc  X  nitoare);  X  e_X , o_X replaces the semivowels ea and oa (i.e. deal, seara  X  , soare, oala  X  );  X  dZ for the grapheme groups ge , gi (i.e. gem, gin);  X  Z stands for character j (i.e. joi).

So grapheme-to-phoneme transcription problem for the Romanian language is not trivial. In some cases even phonetician experts have divergent opinions, see Institutul de Lingvistica  X  Iorgu ( 2005 ), Beldescu ( 1984 ). Often it is not enough to take into account just the recommendations from the Romanian Language Orthographic, Orthoepic and Morphological Dictionary. Grapheme monovalence changes if we are taking into account syntactic phonetics. This makes Romanian language continuous speech phonetic transcription even more difficult. 3 Development of the pronunciation dictionary 3.1 5k words pronunciation dictionary Our initial grapheme-to-phoneme conversion system is based on the system described by Sejnowski and Rosenberg ( 1987 ) and adapted for Romanian by Burileanu et al. ( 1999 ; Burileanu 2002 ). Therefore the system is based on a parallel structure having 30 similar artificial neural networks (ANNs) with 25 common inputs. Each network is designed and trained to detect the presence of an articulatory feature from the 30 features used to encode the Romanian language phonemes (Table 1 ). The networks have to point out the presence or the absence of one articulatory feature at their output.

The words intended to be transcribed are previously preprocessed and coded in order to be presented at the input of the ANNs. Preprocessing means that the beginning and the end of each word is appended with two white space characters and after this, the input words are split into five character long sequences and each character is binary coded on 5 bits. The five character long sequences (coded as 5  X  5 = 25 bit information) are presented at the input of each neural network (hence we can deduce the number of network inputs). Always the central grapheme from the sequence of five graphemes is analysed, the other four graphemes represent contextual information (two graphemes for the left context and two graphemes for the right context). The coded grapheme sequences at the input of the system are shifted grapheme by grapheme until all the component graphemes are presented to the input (Burileanu et al. 1999 ).
 Input words preprocessing, grapheme coding and phoneme coding according to Burileanu et al. ( 1999 ) have been implemented with a proprietary Java application, using regular expressions. This application also generates the training and testing sets for the neural networks. This application can also replace characters that are not part of the used grapheme set with their correspondences. The application was briefly presented in Domokos et al. ( 2011 ).

The networks output form a 30 bit long binary sequence. Each network is trained to indicate the presence or the absence of one particular articulatory feature from Table 3 (value 0 if the feature was not detected, and value 1 for reporting the presence of that feature).

The used neural networks are totally connected MLP (multilayer perceptron) with two hidden layers. The internal structure and the number of neurons in the hidden layers were determined based on some experimental testing. The structure with the best results has 25 inputs given by the number of input bits used to encode the five input graphemes, eight neurons in the first hidden layer, five neurons in the second hidden layer and one output to indicate the corresponding articulatory feature presence or absence. The structure of the used 30 feed-forward neural networks is presented in Fig. 1 a.

The neurons from the hidden layers have tansigmoidal transfer function and the output level has pure linear transfer function. The input weights of the network are grouped into the Input Weigth matrix IW[25  X  8], and the Layer Weights are stored in 2 matrices LW1 and LW2 with the dimensions LW1[8  X  5] and LW2[5  X  1] respectively.

The entire structure of the 30 parallel networks system is presented on Figs. 1 b and 2 , depending on which task is involved. Figure 1 b shows the training phase of the system and Fig. 2 shows the system when used for grapheme-to-phoneme conversion.

Discussion on the ANN based transcription system For training and preliminary testing the system we have manually built a database containing 1,004 phonetically transcribed Romanian language words. The words were transcribed by phonetician experts and were collected from some linguistic resources available in published form (Institutul de Lingvistica  X  Iorgu 2005 ; Beldescu 1984 ). The database contains a total number of 5,497 phonemes. For training and testing, the phonetically transcribed word set was randomly divided in three parts: training set, validation set and test set in proportion of 80, 10 and 10 % respectively.
 Network training was performed in Matlab environment, using Levenberg X  Marquardt back-propagation (trainlm) training function, mse (mean squared normalized error) performance criterion and early stopping validation vectors are used to stop training early if the network performance on the validation vectors fails to improve or remains the same for 20 train epochs. Network training is quick, it takes less than 1 min for each network on a usual laptop computer with Intel Core2 Duo CPU P8400 @ 2.26 GHz, and 2 GB memory, but training time can be further improved by perform parallel training process on multiple workstations or on multiprocessor stations.

When testing the system, the neural networks generate one by one the 30 bit code indicating the presence or the absence of the 30 articulatory features based on the input grapheme codes. The output feature vector is compared with the encoded vectors of the phonemes used. The distance between the output vector and each coded vector is calculated using Manhattan distance function. System response is chosen as the vector with the smallest distance, replacing the correlation table method described in Burileanu et al. ( 1999 ).

The trained system performs grapheme-to-phoneme transcription with an average accuracy of 92.83 % at the phoneme level. Table 3 shows the error percentage for each articulatory feature used. The features with the biggest error percentage are the Closed, Front and type 2. We have investigated why these three articulatory features were so weekly recognized and the answer is that there were not enough examples for this features in the training set. We than increase the size of the manually transcribed words to 2,383. Retraining the system, grapheme-to-phoneme conver-sion accuracy achieved 97.72 % at phoneme level.

In comparison with the networks of different sizes presented in Burileanu et al. ( 1999 ; without giving the exact dimensions) our system brings a simplification on implementation. After several experiments, we have found that by altering the structure of hidden layers only insignificant improvements of the recognition results can be achieved. 3.2 100k+ words pronunciation dictionary To develop the 100k+ pronunciation dictionary we have used the largest online dictionary for Romanian language, the DexOnline X  X nline Explanatory Dictionary http://www.dexonline.ro . DexOnline dictionary is freely available and can be used in accordance with the terms of GNU General Public License. It can be downloaded from the Internet also as a mysqldump generated SQL file. The database can be easily restored on a MySQL relational database server (also available for free download at http://www.mysql.com ).

DEXOnline database is organized in multiple tables. The most important three tables from the point of view of exporting dictionary words are: inflectedform, definition and lexem.

The inflectedform table contains all the inflected word-forms recorded in the database. This is the largest table from Dexonline. By selecting all the distinct wordforms from this table we get a total number of 992,979 records. This is the maximum size of pronunciation dictionary we can create based on DEXOnline. We have exported these words in distinct text files separated by the first grapheme of the words, one word per line, thus resulting input files with a reasonable number of records in the order of several tens of thousands per file.

The definition table is a smaller table containing the definitions recorded in database. A total number of 126,563 definitions are available.

The lexem table contains just the base forms of words from the dictionary, totally 139,509. Some of these words are foreign language words and therefore they are not included in the pronunciation dictionary. We have exported also these two tables in text format with UTF-8 character encoding, one word per line in order to perform automatic grapheme-to-phoneme conversion. Some additional operations were performed for resolving input character mapping such as:
After this preprocessing stage we extracted from the lexem table a word list of 138,500 entries.

For the development and testing of the 100k+ words pronunciation dictionary we have used the freely available Dictionary Maker application created by the Human Language Technologies Research Group of the Meraka Institute, South Africa http://dictionarymaker.sourceforge.net/ . This software application was developed to facilitate the creation of an electronic pronunciation dictionary in a target language.
A Dictionary Maker project can be started with either a word list or an initial dictionary or both (Davel and Barnard 2003 ). The word list defines the words that will be used to create the dictionary. For our experiments the word list consists of words exported from the DexOnline dictionary. Importing an initial dictionary will provide rules that can be used to predict pronunciations for words in the word list. If the initial dictionary is small, the predictions will not be very accurate, but will improve through the bootstrapping verification process. If no dictionary is imported, there are no initial grapheme-to-phoneme prediction rules available, and therefore no initial pronunciation predictions will be given by the system. The user then has to provide the entire pronunciation. In this later case the development of a large pronunciation dictionary is a very time consuming task.
 Dictionary Maker use a modified implementation of Kohonen X  X  Dynamically Expanding Context (DEC) algorithm, a popular instance-based learning algorithm that predicts phoneme realization based only on grapheme context. DEC is used to extract rules of the form (Davel and Barnard 2008 ): (left context, grapheme, right context) ! phoneme.

Generating a new pronunciation is a simple procedure: each grapheme in the word is considered in turn, and the rule describing the largest matching context is used to predict the phoneme to be generated (Davel and Barnard 2003 ).
We have used Dictionary Maker with the 5k transcribed words as initial dictionary. The 5k words were transcribed using our previously presented ANN based automated grapheme-to-phoneme transcription system (Domokos et al. 2011 ). In this way we have enough grapheme-to-phoneme prediction rules so that the transcriptions returned by Dictionary Maker do not need many corrections. Changes are needed only for exceptions from the standard pronunciation. The system architecture is depicted in Fig. 3 .

To achieve the best transcription results we have over-tested the 5k word pronunciation dictionary using Dictionary Maker application.

We have recorded and segmented the Romanian phonemes for the used phoneme set, using Audacity, the free, cross-platform sound editor application http://audacity.sourceforge.net/ . The utterances were recorded by a young male speaker, fluent in Romanian language, the first author of this paper. These audio files were provided to Dictionary Maker in order to be used for generation of the sounded version for each transcription for the words included in the word list. We built the used grapheme and phoneme sets for Romanian language as a Dictionary Maker .gra and a .pho file respectively.

The system runs through the word list word by word, predicts a pronunciation and sounds out the phonemes of the word. The user listens to the generated pronunciation variant and provides a verdict with consideration to the accuracy of the word pronunciation pair choosing one of the answers, according to Dictionary Maker tutorial found on http://dictionarymaker.sourceforge.net/ :
Even in this way the pronunciation dictionary development is a time consuming task, but the role of the human in this process is only to supervise and correct eventual errors of the system. The system can work also unsupervised by human factor by using a self-developed, modified version of Dictionary Maker application. This option gives the possibility to perform automatic grapheme to phoneme conversion using the Dictionary Maker, without sounding out the resulting transcription and without user confirmation. In this automatic mode, the words from the word list are taken one by one, grapheme-to-phoneme conversion is performed using the DEC algorithm and grapheme-to-phoneme conversion rules are updated after each transcribed word.

The created dictionary was exported in text format with UTF-8 character encoding and it is available in 2 more different formats: Each phoneme is delimited by spaces in [pronunciation] sequence.

Discussions on the 100k+ words pronunciation dictionary Some selected fragments from the developed NaviRO pronunciation dictionary in text format are presented in Table 2 .

The generated pronunciation dictionary together with the belonging language resources (the used grapheme and phoneme sets, the recorded and segmented audio samples for the used phoneme set) can be freely downloaded from the NaviRO project website ( http://users.utcluj.ro/~jdomokos/naviro ), and the use of this resources for any research purpose is completely unrestricted in order to promote Romanian language speech technology. 4 Evaluation of the dictionary We performed evaluation test of the generated pronunciation dictionary, since the quality and the consistence of the dictionary is crucial for the use in further research. We use 80 % of the dictionary (110,800 words) to train the Phonetisaurus WFST-driven grapheme-to-phoneme converter downloadable from http://code.google.com/ p/phonetisaurus/ . We retain 10 % of the dictionary for development and 10 % for testing purposes. The joint sequence N-gram model needed by Phonetisaurus was estimated using the MIT Language Modeling toolkit (MITLM; Bo-June and Glass 2008 ).

Using the training part of the dictionary we performed alignment, N-gram estimation and language model conversion to word finite state transducer. At phoneme level we have a total number (T) of 117,737 tokens in reference. After generating pronunciations for the word list included in the test dataset we found 117,485 matches (M), 157 substitutions (S), 131 insertions (I) and 95 deletions (D). Such we have 99.79 % correct transcriptions calculated as the ratio of matched and total tokens: M/T. Token error rate (ER) was 0.33 % (calculated as (S+I+D)/T) and accuracy computed as 1.0-ER was 99.67 %.

At the word level we had a number of 13,850 sequences (S) of which 13,507 were correctly generated sequences (C) and 343 error sequences (E). Therefore the word error rate computed as E/S was 2.48 % and the transcription accuracy at the word level was 97.52 % calculated as 1.0-E/S.

The evaluation results on both phoneme and word level are showing that the dictionary is consistent enough to be used for further research. 5 Conclusions and future works We have designed and implemented a system to allow a speaker fluent in the Romanian language to easily develop a pronunciation dictionary without having expert linguistic knowledge or advanced programming skills.

With this system we have created the first 100k+ words (the exact number of words is 138,500) machine-readable Romanian language pronunciation dictionary based on the words from the lexem table of DexOnline.
 We appreciate that the resulting pronunciation dictionary is very useful for Romanian language LVCSR system and text-to-speech system development.
The authors cannot guarantee the accuracy of the dictionary, nor its suitability for any specific purpose. In fact, we expect some errors, omissions and inconsistencies to remain in the dictionary however the entries were manually checked. Any suggestions, corrections and observations are welcomed. We intend to continually update the dictionary by correcting existing entries and by adding new ones. From time to time a new version will be posted on the project website.

As future work we can mention that our final goal is to generate a 1 million word pronunciation dictionary based on the inflected forms from the DexOnline dictionary so we welcome input from users in order to increase dictionary size and cover pronunciation variants. This 100k words dictionary will be a good input for Dictionary Maker in order to perform grapheme to phoneme mapping for the inflected words from DexOnline X  X  inflectedword table. Once all the near 1 million inflected forms are transcribed, the resulting dictionary will be ready to be used for continuous speech phonetic transcription generation. We also intend to train a model and deploy it as a web service for online Romanian grapheme-to-phoneme transcription.

We are also interested to generate pronunciations for Romanian person names and institutions names because the needed word lists can be easily collected from the Internet. All these resources will be publicly available on the project website. References
