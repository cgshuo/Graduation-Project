 This paper investigates whether Web comments are of descrip tive nature, that is, whether the combined text of a set of comment s is similar in topic to the commented object. If so, comments may be used in place of the respective object in all kinds of cross-m edia re-trieval tasks. Our experiments reveal that comments on textual ob-jects are indeed descriptive: 10 comments suffice to expect a high similarity between the comments and the commented text; 100 -500 comments suffice to replace the commented text in a rankin g task, and to measure the contribution of the commenters beyo nd the commented text.
 Categories and Subject Descriptors : H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing X  Abstracting meth-ods ; H.4.3 [Information Systems Applications]: Communicatio ns Applications X  Bulletin boards General Terms : Experimentation Keywords : Comment Descriptiveness, Cross-media Retrieval
Comments are among the oldest kinds of user-generated conte nt on the Web and virtually all types of objects are being commen ted, be it texts, images, songs, videos, products, and personal p rofiles. Commenting may be another means to harness the wisdom of the crowds, which X  X nlike tagging, blogging, and wikiing X  X s no t per-ceived as labor. However, comment boards are often flooded wi th all kinds of junk and spam, which may be a reason why research has widely neglected comments as a source of information. Related Work. The only work which attempts to assess the intrinsic value of comments can be found in [8]. The authors investigat e the impact of comments on blog search and report that the recall p er query increases up to 15% if comments are included in a keywor d search. However, their evaluation covers only a single retr ieval task that is based on 40 queries X  X n terms of both scale and signific ance our analysis goes beyond this work. Other researchers use co m-ments of a special type, namely product and movie reviews, in or-der to facilitate online shopping (e.g. [10]), or to evaluat e sentiment analysis models [9]. Some use comments to extract sentences from blog posts for summarization purposes [2, 5]. Note that the r elation of comments to the commented object is not analyzed in partic ular.
Cross-media retrieval is a subproblem of multimedia inform a-tion retrieval in which the text surrounding a non-textual o bject has always been used to extract annotations [3, 6, 7]. Interesti ngly, comments have not been considered in this respect.

Let D denote the set of comments related to an object x , and let d denote the concatenated text of all comments from D . To measure how much d describes the topic of x we need a retrieval model, which consists of a representation function and a rel evance function. The former captures features of d and x to represent them as d and x respectively. The latter function maps d and x onto the interval [0 , 1] , which indicates the range from no to maximum rel-evance. The reliability of a relevance value depends on the c hoice and quality of the two functions. Often, vector-based repre senta-tions are employed and relevance is measured with the cosine sim-ilarity between vectors.

A small number of retrieval models exist which are capable of representing arbitrary objects in a cross-media feature sp ace. They are trained on human-annotated corpora, but none of them con tain any comments. However, commenting itself happens to be a cro ss-media phenomenon, and, a considerable amount of comments ca n be found on texts, such as blog posts or news articles. Under t he assumption that the activity of commenting on text is not fun da-mentally different from that of commenting on non-textual o bjects we restrict our experiments to the text domain. If the assump tion holds and if comments on texts prove to be descriptive, it fol lows that comments on non-textual objects are descriptive as wel l. Note that the validity of our assumption is a research question fo r cog-nitive information retrieval since commenting is a cogniti ve task. That said, our intuition defines well-intentioned commenti ng on an object x as describing x partially, up to a point, at which something new is contributed or an opinion is expressed. We expect that , com-pared with comments on texts, comments on images and videos a re more often opinion exclamations, so that larger amounts of c om-ments are needed to reach certain degrees of descriptivenes s. Evaluation Corpus. A rich resource for comments on text docu-ments is the Slashdot news Web site, where news articles are p ub-lished and commented in a community-driven process. The com -munity is very active so that each article gets a considerabl e number of comments. We have downloaded all 17 948 articles publishe d between January 2006 and June 2008, including the Web pages linked from each article and about 3.8 million comments. Methodology. Two retrieval models are employed in the experi-ments: the well-known vector space model (VSM) and the expli cit semantic analysis model (ESA), a collection-relative gene ralized VSM [1, 4]. In short, the latter represents a document x as vec-tor of x  X  X  similarities to the documents of an index collection. Our index collection contains 10 000 randomly selected Wikiped ia doc-uments, and the similarity of x to each index document is computed using the VSM. To compare document representations both mod -els use the cosine similarity. Note that we choose basic retrieval models to ascertain whether descriptiveness can be measure d re-liably. We have conducted three experiments on the evaluati on corpus whose results are shown in Table 1. A detailed descrip -tion of each experiment is given next to the table. In particu lar, it is our goal to determine the amount of comments on a document x necessary to reach a certain degree of descriptiveness. Hen ce, we use 5 subsets of the evaluation corpus which comprise only the documents which got at least | D | X  i  X  X  1 , 10 , 100 , 500 , 1000 } comments. The experiments were repeated for each subset (= t able rows), and, each experiment was repeated for each x in a subset. If an x had | D | &gt; i comments a random subset D i  X  D , | D was chosen for the respective experiment.
 Conclusion. Experiment 1 reveals that 10 comments are sufficient to reach a considerable similarity between a document and it s com-ments compared to the baseline, Experiment 2 reveals that 10 0 to 500 comments are sufficient to reach a moderate rank correlat ion, and Experiment 3 reveals that 100-500 comments contain a mea -surable commenter contribution that is not contained in the original document. Particularly, Experiment 3 demonstrates ESA X  X  c apabil-ity to measure more than just overlap similarity and shows th at the similarities measured in Experiment 1 cannot be attributed solely to duplicated text. Further, Experiment 3 may be interpreted a s an in-dicator of the amount of comments necessary to capture the to pics of non-textual objects. In all experiments the retrieval qu ality in-creases with the number of comments per document, | D i | . Hence, comments on text documents can be called descriptive and it r e-mains to be investigated whether our initial assumption hol ds that commenting is not entirely media-dependent.
