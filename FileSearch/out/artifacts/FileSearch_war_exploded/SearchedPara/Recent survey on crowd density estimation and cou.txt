 1. Introduction
In current decades, human population in the world is increas-ing dramatically. This growth, as a result from movement and urbanization worldwide, has indirectly made crowd phenomenon increasing. Large gatherings of people can be observed at covered areas such as in building halls, airports and stadiums as well as in open areas like at walkways, parks, sport events and public demonstrations. The purpose of the gatherings has important effect on the large scale properties and behaviours of the crowd.
Therefore the analysis of crowd dynamics and behaviours is a subject of great interest in many scienti fi c researches in psychol-ogy, sociology, public services, safety and computer vision.
Crowd turbulence is a typical reason for crowd disasters, resulting from pushing, mass-pani c, stampede or crowd crushes, and causing an overall loss of control ( Helbing et al., 2014 ). Many example tragedies could illustrate this problem like Water Festival stampede 2010 in
Colombiawheremorethan380personsdied( Wang et al., 2013; Illiyas et al., 2013 ). Another famous crowd crush example that has been studied much happened in 2010 Love Parade music festival in
Germany, where 21 persons died and more than 500 were injured in astampede( Krausz and Bauckhage, 2012; Helbing and Mukerji, 2012 ),
Fig. 1 . Some other deadly examples are shown in Table 1 .Toprevent such deadly accidents, early automatic detection of critical and unusual situations in large scale crowd is req uired. It would certainly assist, as a result, to make appropriate decisions for emergency and safety control. extensively studied in recent years by computer vision researchers ( Shah et al., 2007; Hu et al., 2004 ). It has accurate data processing, ef fi cient information fusion and requires much fewer human operators. In reality, it has a great advantage compared to the traditional CCTV technologies which require a large number of human operators, high human resource cost, to constantly monitor surveillance cameras. Crowd analysis is one of the most challen-ging tasks in such intelligent visual surveillance systems. It can be used for automatic detection of critical crowd level, detecting and counting people, and also detecting of anomalies and alarming crowd fl aws. Furthermore it can be used for tracking individuals or a group of people in a crowd ( Aggarwal and Ryoo, 2011 ). process in crowd analysis because crowd density is one of the basic descriptions of the crowd status. Automated crowd density estimation and counting is receiving much attention for safety control and plays an essential role in crowd monitoring and management. It could be used for developing service providers in public places, or supplying the current state of waiting customers. As well as it could be used for measuring the comfort level of the crowd and detecting potential risk to prevent overcrowd disasters. In visual monitoring systems, the crowd size is one of the important primary indicators for detecting threats like rioting, violent protest, fi ghting, mass panic and excite-ment ( Junior et al., 2010; Dittrich et al., 2012; Chen et al., 2010 ). and counting methods for surveillance which were presented by researchers in recent past. It should be pointed out that some survey papers in this fi eld have been already published in the past, such as Junior et al. (2010) and Zhan et al. (2008) . However, although the survey papers ( Junior et al., 2010; Zhan et al., 2008 ) reviewed many crowd analysis techniques, they did not speci cally focus on crowd density estimation and counting techniques.
Therefore, the aim of this paper is to fi ll these holes by reviewing techniques of crowd density estimation and people counting, which is not covered in the previous review papers.

This work is organized as follows: Section 2 describes systems of crowd density estimation and count ing including the direct approach which are model-based and trajectory-clustering-based analysis ( Section 2.1 ) and presents methods of indirect approach which are pixel-based, texture-based, and c orner points-based analysis in Section 2.2 . Section 3 provides general problem and future possibilities in crowd density estimation research. Section 4 shows benchmark datasets that were used in crowd density estimation and counting.
Finally, the conclusion is presented in Section 5 . 2. Crowd density estimation and counting systems
Generally, the problem of people density estimation and counting of crowd can be divided into two main approaches: direct and indirect approaches ( Conte et al., 2010a ). The direct approach (also called object detection based) tries to segment and detect each individual in crowd scenes and then counting them using some classi fi ers ( Zhao et al., 2008; Rittscher et al., 2005; Brostow and Cipolla, 2006 ). In this method, counting people can be provided simultaneously as long as peoplearecorrectlysegmentedbuttheprocesscanbemorecomplex when a severe crowd or occlusions occurred ( Hou and Pang, 2011 ). In the indirect approach (also call ed map, measurement, or feature based), people counting is carried out normally using the measure-ments of some features with learning algorithms or statistical analysis of the whole crowd to achieve counting process ( Albiol et al., 2009;
Ryan et al., 2009; Zhang and Li, 2012 ). This method is considered to be more robust compared to direct methods. The taxonomy of people counting and density estimation methods is presented in Fig. 2 . 2.1. Direct crowd estimation approach
Direct approaches attempt to determine the number of people by identifying single persons and their locations simultaneously. The count is then trivially attainable, as long as people are correctly segmented, and not affected by pers pective and people densities. On the other hand, detecting people becomes a more complex task in the presence of crowded and occlusion conditions which often provide unreliable results. These problems have been treated by adopting part-based detectors, such as head only detector ( Lin et al., 2001 ), Omega shape (  X  ) 1 detector formed by heads and shoulders ( Li et al., 2008; Xing et al., 2011 ) or pedestrian detector ( Khatoon et al., 2012 ). Nevertheless, these efforts to mitig ate occlusions are still not applic-able in very crowded scenes which are of main interest for people counting and density estimation ( Fradi and Dugelay, 2012a ).
The detection-based methods can be further classi fi ed into two approaches: model-based and traject ory-clustering-based approaches. The fi rst approach tries to segment, detect every single person, and then counting them using a model or appearance of human shapes ( Zhao et al., 2008; Rittscher et al., 2005; Haritaoglu et al., 1999; Zhao and Nevatia, 2004; Leibe et al., 2005; Ma et al., 2012 ). The second approach attempts to detect every independent motion in the crowd scene by clustering interest points on people tracked over time and then count the people ( Brostow and Cipolla, 2006; Rabaud and Belongie, 2006; Cheriyadat et al., 2008 ). In the following subsections, some well-known examples are presented. 2.1.1. Model-based analysis
Model-based approach attempts to segment and detects every single individual in the crowd scene and then counting them using a model or appearance of human shapes. Examples of model-based analysis are monolithic detection and head-like detection. These techniques are described as follows:
Monolithic detection : Rittscher et al. (2005) proposed a system for crowd segmentation on a video sequence based on Expectation Maximization (EM) formulation which has shape parameters for all potential individuals and treats feature assignments. In their work, the image features were partitioned using likelihood func-tion which is parameterized on the shape and location of potential individuals in the scene. Then, maximum joint likelihood was estimated by using a variant EM formulation. It should be noted that this approach is exhibited to be robust with respect to partial occlusion, shadows and clutter. In addition, it is suitable to operate over variety of camera setups. However, the drawback of this system is a high cost and low exibility ( Liu et al., 2005 ).
Jones and Snow (2008) described a scanning window type pedestrian detector using spatiotemporal (appearance and motion) information ( Viola et al., 2005 ). They used three types of are appearance Haar-like fi lter, absolute difference Haar-like a shifted difference fi lter for capturing moving objects. They have trained eight different pedestrian detectors for eight motion directions using AdaBoost learning algorithm ( Schapire and Singer, 1999; Freund and Schapire, 1995 ). Moreover, this algorithm is used to take the advantage of both motion and appearance information to construct the classi fi er and detect a walking person.

Leibe et al. (2005) presented an algorithm for pedestrian detection in crowded scenes by using a combination of local and global features via a probabilistic top-down segmentation approach. More speci they combine local information from sampled appearance features (based on a scale-invariant extension of the Implicit Shape Model) with global features (Chamfer matching) to get the probability of a person presents. Their experiment results show that the system can detect dependably and localize pedestrians in dif fi cult crowded scenes, even with severe overlapping.

Head-like detection : Lin et al. (2001) proposed a detection approach for the crowd estimation by wavelet templates and vision-based techniques. In their work, the Haar wavelet transform (HWT) is applied for feature extraction of the head-like contour. Then, this featured area is processed by su pport vector machines (SVM) to classify it as the contour of a head or not. Eventually, the perspective transforming technique of computer vision is used for more accurate crowd density estimation. This method is limited to some complex situation when the contours of the heads are not clear and the computational loading is too heavy speci fi cally on real-time applications ( Lin and Lin, 2006 ).

Gall and Lempitsky (2009) presented an improved Hough forests method for pedestrian detection. Based on the random forest, they take a more discriminative approach to object part detection and train a class-speci fi c Hough forest in a supervised way. It is able to map the image patch appearance directly to the probabilistic vote about the possible position of the object cen-troid. Later, they presented a more general formulation of Hough forest framework that can be applied for tracking and action recognition beside object detection ( Gall et al., 2011; Gall and
Lempitsky, 2013 ). They showed that this method is robust to partial occlusions and atypical part appearances.
 model as ellipsoid to detect and track people in crowd. Their proposed method is based on head top detection by removing the foreground blobs and from remaining foreground boundary peaks.
Later, they improved their method by using a more accurate 3D model using three ellipsoids ( Zhao et al., 2008 ). In addition, the people detection and tracking problem was formulated as a
Maximum A Posteriori (MAP) problem simultaneously. The occlu-sion problem is performed by considering a joint probability for multiple humans based on Markov Chain Monte Carlo (MCMC) approach. A sophisticated sampling method, data-driven MCMC, was employed to direct the Markov chain dynamics and get the best con fi guration for the MAP problem. This algorithm works well even under low resolutions. However, it depends on an accurate foreground contour and thus it is dif fi cult to get a good foreground for people. 2.1.2. Trajectory clustering based analysis every independent motion in the crowd scene by clustering the interest points on people being tracked over time. Then the counting step is a subsequent process. Some examples of this approach are presented next.

Bayesian clustering framework to detect individuals movements in crowds. The main idea of their algorithm is that a pair of points that move together is likely to be part of the same entity. Their method tracks and probabilistically groups image low level fea-tures into clusters to represent moving independent entities,
Fig. 3 a. In addition, the space  X  time proximity and the trajectory coherence of image space were used as the probabilistic criteria for clustering. It is interesting to note that it performs a one-shot data association and does not require any training stage to track individuals. However, this system can fail if strong arm move-ments present with rigid motion scenes.
 motions generated by multiple instances of an individual in a crowd. They have developed a highly parallelized Kanade Lucas
Tomasi (KLT) tracker ( Shi and Tomasi, 1994; Tomasi and Kanade, 1991 ), in order to extract a large set of low-level features for object movement detection from the scene. In addition, KLT tracker has been combined with temporal and spatial fi lter with a trajectory set clustering method to identify the number of moving objects in a scene, Fig. 3 b. They used three different real-world datasets to validate and show the robustness of their approach. This feature tracking mechanism can handle occlusion and crowded scenes better. On the other hand, it is still based on segmenting indivi-duals on the crowd rather than treating a group as a single entity, as well as it is assumed that the scene is homogeneous.
Sidla et al. (2006) presented a motion detection and tracking system to count people in very crowded situations. Their algorithm detects human head-shoulder regions (  X  -like shape) and masked by region of interest (ROI) fi lter to detect individuals. Then the pedestrian motion is analysed using Kanade Lucas Tomasi (KLT) tracking points and Kalman fi lter to compute the co-occurrence matrix feature vector for active shape models. Finally, the counting of passing people is performed by using a virtual gateway and a simple trajectory-based heuristic. Their algorithm is robust for individual tracking, but on the other hand, it is hard to count individual in a crowd scene by using trajectories.

Cheriyadat et al. (2008) presented an object detection system based on coherent motion region detection for counting and locating individuals in the presence of high density and occlusions.
They consider a single moving object coincide to a single coherent motion region by tracking low-level features of objects, and then output a set of independent coherent motion regions as a group of point tracks. To solve the problem of overlapping moves that can be happened by camera's perspective, their greedy algorithm can select the good disjoint set.

The aforementioned methods are unsupervised learning and totally depending on clustering individual motions. However, in many times, people just remaining static like standing or sitting, exhibiting some occasional articulated movements, which caused false individual detection. In addition overlapping could be hap-pened by sharing more than one individual the same trajectory. 2.2. Indirect crowd estimation approach
The indirect approach methods usually extract several local and holistic features from groups of people in foreground image. These methods are more ef fi cient because detecting features are easier than detecting persons. For this reason, many features of foreground pixels have been used such as foreground area ( Hou and Pang, 2011; Ryan et al., 2009; Chan et al., 2008; Marana et al., 1999; Davies et al., 1995;
Paragios et al., 2001 ), texture features ( Chan et al., 2008; Marana et al., 1999; Rahmalan et al., 2006 ), histograms of edge orientation ( Ryan et al., 2009; Chan et al., 2008; Kong et al., 2005 ), or edge count ( Ryan et al., 2009; Chan et al., 2008; Davies et al., 1995 )tocountand estimate crowd density by a regression function, like linear ( Davies et al., 1995; Paragios et al., 2001 ), Gaussian process ( Chan et al., 2008 ), or neural networks ( Hou and Pang, 2011; Ryan et al., 2009; Kong et al., 2005, 2006; Cho et al., 1999; Marana et al., 1997 ). All of these methods mostly have presented that the relationship between the foreground area and the number of people in the scene is nearly linear. However, this relation usually fails by the presence of the occlusions and perspective problem.

Many techniques have been proposed in the literature to overcome the effects of perspective problem. Such as a geometric factor was proposed to weight pixels according to its locations on the ground plane ( Paragios et al., 2001 ), a geometric correction (GC) to bring all the objects at different distances to the same scale ( Ma et al., 2004 ), a perspective map to weight all extracted features from image ( Chan et al., 2008; Fradi et al., 2012 ), and Inverse Perspective Mapping (IPM) to compute the distance of each group of individuals from the camera ( Conte et al., 2010a ). Moreover, additional features have been used to mitigate the occlusions problem. For example histograms of edge orientations ( Kong et al., 2005 ), edge count ( Davies et al., 1995 ), by using a great quantity of features ( Chan et al., 2008 ), or by measuring the ratio between the number of interest points in the group and the areacoveredbythegroupitself( Conte et al., 2010a ).

In addition, these approaches suffer in complex scenes from some problems such as
Edge-based features can be highly incorrect in the presence of complicated background and uneven textures of human clothes.
The foreground and background segmentation process becomes amoredif fi cult task in crowded scene.

Extracting big features amount means very time consuming, especially edge feature extraction.

Hence, some approaches have been proposed to utilize local features rather than holistic features to deal with these issues and to reduce the required training data. More details are presented in the following subsections. 2.2.1. Pixel-based analysis
Pixel-based analysis depends on very local features to estimate the number of people in a crowd scene. Because this method utilizes low-level features, most of the pixel-based methods are focused on crowd density estimation rather than identifying individuals. Most of these techniques use a removal background technique as the fi rst step, for example, background subtraction is used only on reference image ( Davies et al., 1995; Hussain et al., 2011 ) or automatic background generator to get arti fi cial background image ( Yin et al., 1996 ).
Velastin et al. (1993, 1994a,b) and Davies et al. (1995) proposed one of the earliest and well-known crowd density estimation approaches in computer vision. The authors suggested two automatic techniques using pixel-level information. The fi rst method is to separate pedes-trian pixels by inspecting a three-pixel-neighbourhood of the differ-ence between the frame and a background-only reference image. In the second method, they applied fast three-pixel-neighbourhood edge detector to the image to get edge magnitude and re fi ned further by thinning the edges for more enhancement, Fig. 4 .ByusingaKalman fi ltering approach, they presented linear models to map the resulted binary images of foreground pixels or edges to the number of people. A geometric correction is included to reduce the prospective distortion problems of cameras.

Cho and Chow (1999) and Cho et al. (1999) proposed a feed forward neural network (FFNN) based crowd estimation system by using a hybrid of least squares with global optimization algo-rithms. In their study, they extracted features from subway station video recording with three indexes, which are represented by length of edges of the crowd objects, the crowd objects density and the background objects density. A fast edge detection scheme is proposed based on binary image thresholding for more practical crowd estimation. The crowd classi fi cation is performed by the hybrid global learning algorithm which combines the least-squares method together with random search, simulated anneal-ing, and genetic algorithm. Their results conclude that the combi-nation of least-square and random search algorithm is the fastest among the three hybrid combinations.

Yang et al. (2003) developed a system of people segmentation and estimation in crowded scenes using a group of simple image sensors from side and top view. In this system, they projected the 3D silhouette cones from the scenes of visual hull in a plane and then intersected them in 2D. A geometric algorithm is then introduced to compute bounds on the number and possible locations of people using the extracted silhouettes. To solve the problem of the sensi-tivity of silhouette intersection to noise, they use thresholding background subtraction to force silhouettes to become overestimates. A drawback of this system is some objects may be cannot be seen in very crowded situations, especially in public areas, from all views and therefore, impossible to localize individually.

Ma et al. (2004) proposed a pixel-counting based system for crowd density estimation. They derived a succeeded mathematical relation of geometric correction and proved that it can be carried out directly with the foreground pixels regardless of their relative position in the scene. The main idea is to weight a foreground segment according to the pixel at its base on the ground plane. By using an oblique camera, the weight is assigned to every pixel depending on the reference row and the vanishing point of the ground plane. Then human objects are counted based on a linear relationship. This algorithm can be carried out when there are no severe occlusions between people.
Choudri et al. (2009) presented pixel-based crowd counting system with a robust selective background model. They proposed a method for detecting true-foreground, which is counting only human-classi fi ed pixels rather than foreground pixels. Human region detector is used to fi lter parts of human like heads. The system can reduce the loss of people by using a more robust people counting based classi fi er when they get absorbed into the background after being slow or stationary. Same depth map estimation in Hou and Pang (2011) is used for scale-weighting and approximate the number of people in an image.

Hussain et al. (2011) proposed an automatic pixel-based crowd density estimation system (CDES) for scenes taken from at Masjid al-Haram. First, a combination of background removal, using a reference image, and edge detection is applied to frames for feature extraction. Then, this extracted foreground blob pixels are scaled to correct perspective distortion and act as input for the back propagation neural network (BPNN) to estimate the number of people. A supervised training is carried out to classify the crowd into fi ve distinct groups, from very low to very high. This system is highly accurate and can particularly make 100% detection from very low to low crowd densities. However, missed and false detection cases can be possibly caused by very high crowd density level mainly due to high occlusion.

Table 2 presents a summary of pixel based estimation methods that are used mostly to estimate the density of the crowd in four to fi ve density levels. 2.2.2. Texture-based analysis
One of the image properties which have received high attention from many researchers is texture. Texture based methods explore a coarser grain and requires the analysis of image patches compared to pixel-based methods. It is mainly used to estimate the number of people rather than counting persons in a scene.
 dense crowds tend to present fi ne textures, while images of low density crowds tend to present coarse texture. In their work, a statistics method of Grey Level Dependence Matrices (GLDM) ( Haralick, 1979 ) was used to carry out on digitized images for extracting crowd density features. Four GLDM measures were used: contrast, homogeneity, entropy, and energy. Then, these features are used by a Kohonens Self-Organizing Mapping (SOM) neural network ( Kohonen, 1990 ) to classify the crowd images according to fi ve density classes (which are very low, low, moderate, high, and very high) as depicted in Fig. 5 . They combined the crowd estimation algorithm presented in Marana et al. (1999) with Minkowski Fractal Dimensions (MFD), which requires only one feature, as an advantage compared to GLDM and
Fourier spectrum. In this work, the background scenes should be relatively smooth and free from objects which is not practical in real world.
 terms of texture analysis and three different classi fi ers for crowd density estimation problem ( Marana et al., 1998b ). They compared and assessed the performance between the following four meth-ods: GLDM, straight line segments, Fourier analysis, and fractal dimension for texture extraction analysis. In addition, they com-pared three types of crowd estimation classi fi ers which are SOM neural network, statistical Bayesian classi fi er and fi tting function-based approach. The best results they found provided by Bayesian classi fi er when they combine two GLDM texture descriptors (Contrast 0 and Homogeneity 0). In their work, only four GLDM measures were used: contrast, homogeneity, entropy, and energy. proposed texture extraction method by using a combination of multi-scale analysis and Support Vector Machine (SVM). In their work, the algorithm initially transforms the image of crowd into multi-scale formats based on 2D discrete wavelet transform (DWT) and maps to a multi-dimensional feature space. Then estimate the density of crowd using tree-structure SVM-based classi fi er to recognize the feature vector of a crowd image with four different density levels: low, moderate-low, moderate-high, and high density. This hybrid feature extraction method gives better results compared to Marana et al. (1997, 1999) and Davies et al. (1995) in terms of the computational complexity. On the other hand, this system can have less performance with the non-uniform crowds.

Kong et al. (2005, 2006) proposed a learning-based method for counting people by exploiting global feature histograms which is more powerful compared to using simple features as Cho et al. (1999) and Regazzoni and Tesei (1996) . It includes view invariant feature normalization procedures, with respect to relative density and orientation scale, to deal with camera perspective. The training features involve edge orientation and blob size histograms which were resulted from edge detection and background sub-traction. The training is performed in a supervised way based on linear fi tting and feed-forward neural network to relate the detected feature histograms and the number of pedestrians in the crowds.

Rahmalan et al. (2006) proposed Translation Invariant Orthonor-mal Chebyshev Moments (TIOCM) technique used in texture analysis to measure crowd density in an outdoor scene. The extracted features were then classi fi ed into fi ve ranges of crowd density by using SOM neural network. Three different test and training datasets are used (morning, afternoon and combination of both). In their analysis, they evaluated TIOCM with GLDM and MFD and indicate that the method based on TIOCM presented the best results, while
MFD had the worst results. In addition, they found that there is no big deference between TIOCM and GLDM under all conditions, however GLDM requires more time for image classi fi cation.
Wu et al. (2006) presented an automatic method to estimate locally and globally the crowd density and detect abnormal crowd density by using texture analysis and support vector machines (SVM). A perspective projection model is used to generate a series of multi-resolution image cells, Fig. 6 a. Then, the GLDM ( Marana et al., 1997 ) is applied for each cell to extract textural feature vectors.
These vectors are rescaled and fed into a SVM training system to relate the 15 textural features with the actual density of the scene.
The SVM method is used to solve the nonlinear regression and classi fi cation problems of detecting abnormal density distribution.
All experiments on real crowd videos show the effectiveness of the proposed system. However, the drawback of this approach is that when system initial's setup is changed a new training procedure is required.

Chan et al. (2008) presented a privacy-preserving system for crowd estimation with different directions of movements. In their work, the crowd is segmented into components of different motions by using the mixture of dynamic textures motion model.
Then, for each segment region they extract various holistic low-level features. These features are segment features (area, peri-meter, perimeter edge orientation, perimeter area ration), internal edge features (total edge pixels, edge orientation, Minkowski dimensions) and texture features (homogeneity, energy, entropy).
Gaussian process regression is applied to relate between features and the number of people per segment. They also used Bayesian Poisson regression (BPR) instead in Chan and Vasconcelos (2009, 2012) for more discrete process adequacy. The proposed system used 30 features in total which affects the complexity of the regression stage.

Ma et al. (2008a,b) presented a local image texture based system for crowd density estimation. They proposed Advanced Local Binary Pattern (ALBP) feature vector as mult i-scale texture descriptor, which is initially introduced in Ojala et al. (2002) . It presents high distinctive power in handling noise and dealing with multi-scale 16 information. In addition, more accurate crowd degree in unconstrained environ-ments can be calculated by adopting an image cell-based training method without using any previous reference image or many image sequences, Fig. 6 b. Con fi dence-based soft classier and weighting mechanismwereusedtogivemorecredibilityandreasonablecrowd estimates, Fig. 6 b. They proved that their proposed method has the best performance compared to Grey Level Dependence Matrix (GLDM) ( Marana et al., 1997 ) and Edge Orientation Histogram (EOH) ( Kong et al., 2005 ).

Zhang and Li (2012) proposed a novel accumulated mosaic image difference feature (AMID) approach to represent compli-cated random motion patterns (like turning around, wandering about, and turning heads) for more accurate foreground detection. They proposed a new notion, which is intra-crowd motions, to describe random tiny motions happening in stable crowds and found to be one of the inherent characteristics of high-density crowds. Then they used AMID feature to represent these local intra-crowd motion patterns effectively to achieving accurate crowd density estimation. In their work, normalization process was applied on the obtained foreground based on the perspective distortion correction model. This model was used to estimate crowd density for observed areas.

Table 3 presents properties of all those techniques such as image feature, regression model, learning methods and if that applied in holistic or local level on the image. 2.2.3. Corner point based analysis
Rather than segmenting or attempti ng to distinguish individuals in each frame, a recent indirect different approach has been proposed by Albiol et al. (2009) . In one word, the authors propose the use of moving corner points, based on the concept of Harris algorithm ( Harris and Stephens, 1988 ), as features to estimate number of moving people. Despite their simplicity, this method obtained the highest performance at Performance Evaluation of Tracking and Surveillance (PETS2009) contest participants in people counting ( Ellis et al., 2009; Ellis and Ferryman, 2010 ) during the eleventh IEEE international workshop. Later, this method is used and developed extensively by many researchers whether used in holistic or local level. Some details of this approach are presented in the following examples.
By using a statistical method, the basic idea of Albiol et al. (2009) work is to detect moving corner points along with their associated motion vectors as features on a holistic level. They used a multi-resolution block-matching technique ( Tekalp, 1995 ) between adjacent frames to select moving corner points under threshold and remove the static corner points (see Fig. 7 a), probably the background and static objects. Then the number of people can be estimated with linear proportional relation between these selected moving points and persons. The advantages of this approach are it does not need for individual segmenting or tracking which reduces the complexity of the system. On the other hand, the hypothesis of this system speci fi cally does not take into account the perspective effects and the people density which led to decrease the accuracy in large depth variations and crowded moving groups.

Conte and colleagues ( Conte et al., 2010a,b,c; Donatello et al., 2010 ) presented a more sophisticated technique of keypoint clustering, built upon the work of Albiol et al. (2009) ,thatconsidersmoreseveral factors and could affect the relation between points and individuals. One problem they solved is the effectiveness of perspective camera.
They applied graph-based clustering algorithm ( Foggia et al., 2008 )to compute the number of SURF interest points ( Bay et al., 2008 )andget the distance of each cluster by using Inverse Perspective Mapping (IPM). Another problem they solved is the effectiveness of people density by measuring the ratio between the number of interest points of the group and the area occupied by the group itself. Finally, the number of moving points, distance and density of each cluster is fed as input to the Support Vector regressor (  X  -SVR) to estimate of the number of people. Their work is more accurate and robustness compared to the work in Albiol et al. (2009) .
 combining information collected from many cameras, instead of using one camera, to mitigate the o cclusion problem. Their algorithm detects the corrected corner points on the ground plane which are associatedwiththepeoplepresentinthescenetocomputetheir motion vector. Then, according to the distance they apply weights and get the mean number of points per person during the training process to estimate people in the scene. They used more than one view as advantage in order to decrease the incidence of occlusions and consequently the reliability in the counting result.
Conte et al. (2013) continued their improvements and proposed a more robust real time method for counting moving pedestrians in a scene. Their system is much faster, simpler in implementation and does not require a complex setup procedure compared to Conte et al. (2010a) . They subdivided the entire scene into smaller horizontal zones to deal with the perspective distortion (see Fig. 7 b). Each zone has a special size depending on its distance weights from the camera.
The results of people counting separately carried out for each zone and summed up at the end. They evaluated three methods of points classi fi cation approaches which are the window search, the three step search and the local-difference method. The fi rst two methods are based on motion estimation and the third is based on colour intensity variations. In their experiments, they conclude that the local-difference classi fi cation algorithm is much sim pler and less computational process, even though the three methods have almost the same people estimation accuracy.

Acampora et al. (2011) did experiments on indirect counting people approach to analyse and evaluate the performance between two trainableestimatorswhichareAdaptiveNeuro-FuzzyInferenceSystems (ANFIS) and  X  -SVR regressor. First, the approach detects the interest points using a feature detector from the state of the art, and then out the static points based on the motion vector estimation. In their work, they used a PETS2009 dataset for evaluation and proved that the neuro-fuzzy based estimator has more ef fi ciency compared to highly density crowd. Furthermore, the  X  -SVR based estimator works better for low density crowd.

Fradi and Dugelay (2012b) proposed an indirect people count-ing system based on interest points measurements and single feature regression. This preliminary work includes the perspective normalization at pixel level instead of assigning one distance value to each group of individual feature for more accuracy. Scale-invariant descriptor (SIFT) ( Lowe, 2004 ) has been used, which is more robust towards scale, rotation, and af fi ne transformations as compared to Harris corner and SURF detectors ( Juan and Gwun, 2009 ). It detects the locations of interest points as maxima/ minima of the difference of Gaussians in scale-space. In addition, density based clustering is used by applying shape technique which is more reliable to extract the shape of a set of points than the bounding box proposed in Conte et al. (2010a) . Finally, all evaluations have shown that this method is able to maintain a linear relationship between the proposed feature and the number of people under heavy occlusion situations and serious perspective distortions compared to Conte et al. (2010a) and Chan et al. (2008) .
Liang et al. (2014) present a crowd fl ow tracking and counting approach based on feature points. They improved SURF point detecting process by employing a three-frame difference algo-rithm. To reduce the time complexity, the binary image of moving foreground is exploited as a mask image to detect SURF feature points that really belong to the moving crowd, Fig. 7 c. Then, they improved Density Based Spatial Clustering of Application with Noise (DBSCAN) clustering algorithm to cluster the only motion feature points for more enhancement. Finally, a Lucas Kanade local optical fl ow with Hessian matrix method is used with a support vector regression machine to estimate the moving orientation and count the crowds in fl ow (see Fig. 7 d). The experimental results showed that their method is more accurate than Conte et al. (2010b) .
 3. General problems and possible future researches
From this literature review, we noticed that the density estima-tion and people counting of crowd in public service is very important for safety life. Such a good crowd estimation system should be real-time, robust to severe occlusions and adaptable enough to effectively detect and deal with both moving and still crowds. Therefore, most of the existing works that do not satisfy all these properties need to be improved. Table 4 presents the problems of each techniques depending on the proposed taxonomy of Fig. 2 : Most recent researches focus only on moving pedestrian counting.
Somehow their systems face some error problems when interfer-ing happened between static and d ynamic people in video scenes.
As well as interfering with different kinds of static and dynamic objects.

Different and more challenging environmental places (instan-taneously changed illumination, complex background, indoor and outdoor scene, and different crowd levels).

Detecting multi-group with order and disorder movements, abnormal behaviours or common fl ows behaviours like bottle-necks, fountainheads, lanes, arches, and blocking.

In practical life, some real visual actions in fi lming pedestrians are rare to reproduce and highly unsafe such as blocked exit and collapse persons in the crowd. A new virtual dataset,
AGORASET dataset, which is based on computer graphics imagery for image synthesis part of pedestrians is proposed in Courty et al. (2014) . Nevertheless, it still needs to synthesis a virtual ground truth data for crowd simulation that can be used extensively by crowd analysis techniques. 4. Benchmark datasets used in crowd density estimation and counting
In the literature, some video-sequence datasets have been used by crowd estimation and counting techniques for performance trainings, testing and evaluations. Table 5 shows some of these benchmark datasets:
The Mall Dataset ( http://www.eecs.qmul.ac.uk/ccloy/dow-nloads_mall_dataset.html ): The Mall pedestrian database was provided by Chen et al. (2012) for crowd counting and pro research. It was captured in a shopping mall using a publicly
LIBRARY Dataset ( http://www.vision.ucsd.edu/ vrabaud/ ): It is the fi rst dataset used for crowd counting and proposed by
Rabaud and Belongie (2006) , and it consists of 1000 elevated view frames of a crowd of 20  X  50 persons.

It is worth mentioning that UCSD and Pets2009 datasets are more commonly used in the recent researches in spite of its focus only on moving pedestrians. Fig. 8 presents picture example for each dataset. 5. Conclusion
In this work, we presented a review study on people counting and crowd density estimation methods for surveillance based on computer vision. There are two main different approaches: direct and indirect approaches. The direct approaches track and count people simulta-neously, as long as people are correctly segmented. Detection based methods try to determine the number of people by identifying individuals and their locations simultaneously. It can be divided into model-based and trajectory-clustering-based approaches. The approach tries to segment and detect every single person in the crowd scene and then counting them using a model or appearance of human shapes. The second approach attempts to detect every independent motion in the crowd scene by clustering interest points on people tracked over time.

On the other hand, the indirect approach relates between a set of measurement features and learning algorithms of the whole crowd to carry out counting and estimating process. It can be divided into three approaches: pixel-based analysis which relays on exploiting local features to count and estimate the number of people in a crowd scene, texture-based analysis which explores a coarser grain of image patches, and corner point-based analysis which estimates the density of people by detecting moving corner points along with their associated motion vectors as features.
In direct crowd estimation approach, identifying individuals is mostly appropriate in lower density crowds. However, this task is becoming dif fi cult and complex when detecting persons in highly den-ser crowds or with the presence of occlusions. Therefore, many recent works mostly bypass the challenge of detecting individuals, despite the current advances of computer vision and pattern recognition techni-ques, in order to save some processing time. Instead, they focus more on indirect crowd estimation approaches on a learning mapping between a set of measured features and the number of persons.
 Acknowledgements This research work is fully supported by Malaysia Ministry of
Higher Education, The Malaysia International Scholarship (MIS), and Malaysia Ministry of Education Fundamental Research Grant Scheme (FRGS) Grant no. (203/PELECT/6071291).
 References
