 Given a spatial data set placed on an n  X  n grid, our goal is to find the rectangular regions within which subsets of the data set exhibit anomalous behavior. We develop algorithms that, given any u ser-supplied arbitrary likelihood function, conduct a likelih ood ratio hypothesis test (LRT) over each rectangular region in the gr id, rank all of the rectangles based on the computed LRT statistics, a nd re-turn the top few most interesting rectangles. To speed this p rocess, we develop methods to prune rectangles without computing th eir associated LRT statistics.
 H.2.8 [ Database Management ]: Database application X  data min-ing, spatial databases and GIS Algorithms, Experimentation
Discovering subsets of database data that are spatially clo se to one another and exhibit anomalous behavior is of key importa nce in many application areas. For example, consider our motiva t-ing application of mining antimicrobial (antibiotic) resi stance pat-terns. Antimicrobial resistance in nosocomial (hospital a cquired) bacterial infections is a key public health problem. Antimi crobial drugs are the first and sometimes only means of attacking bac-terial infection, but due to use and misuse over time, antimi cro-bials become less useful as bugs become resistant due to sele ctive pressures. The result is that common, often mild, nosocomia l in-fections such as staph can become deadly with no effective tr eat-ment. The Antimicrobial Resistance Management (ARM) datab ase (http://www.armprogram.com) consists of antimicrobial r esistance data for nearly 400 hospitals over a 15-year period, and pres ents an opportunity to study the epidemiology of antimicrobial res istance. Over those 15 years, the trend in resistance rates is general ly up-ward. However, a key question that we would like to answer is: Is the trend uniformly upward over time, or are there spatial regions that works for almost any underlying likelihood function, t hat can be used to radically cut down on the number of likelihood rati o tests that must be run when searching for anomalous spatial region s.
The LRT is a hypothesis test that facilitates the comparison of two models: one parametric stochastic model associated wit h the hypothesis that there is an anomaly, and another associated with the hypothesis that there is no anomaly X  X he so-called  X  X ull mod el". Both parametric models are embodied by identical likelihoo d func-tions L (  X  | X ) , where X contains the values output by the underly-ing stochastic process, and  X  is a set of parameters coming from the parameter space  X  . The (restricted) parameter space  X  0 allowed under the null model is the complement of the parameter space al-lowed in the case of anomalous data, denoted as  X   X   X  0 . To check for an anomaly using the LRT, two hypotheses H 0 :  X   X   X  0 and H a :  X   X   X   X   X  0 are compared by computing the statistic:
This statistic is computed by first computing a maximum like-lihood estimate (MLE) under both parameter spaces  X  0 and  X  , and then computing the ratio of the likelihoods obtained via the two MLEs. Wilks [12] showed that the asymptotic distributio n of  X ( X ) =  X  2 log  X  (which we subsequently refer to as the LRT statistic ) is chi-squared with ( p  X  q ) degrees of freedom under the null hypothesis that  X   X   X  0 . p is the number of dimensions (or free parameters) in  X  , and q is the number of dimensions in  X  0 . Thus, to check for an anomaly at confidence level  X  , one checks whether  X ( X )  X  c , where c is a non-negative number computed by finding how far out in the tail of a chi-square distribution one has to go to find (1  X   X  ) % of the mass.

For a very simple example of the sort of case where the LRT is applicable, imagine that we wish to test whether the disease rate within a spatial area A is different than the disease rate outside of the area. We assume that the underlying stochastic process t hat generates the number of cases of disease is binomial: each pe rson who lives in A has a certain, unknown probability of becoming ill in a given time period, and we wish to check whether this probabi lity is different in A than it is outside of A . For each A , X = { k A } where k A is the number of observed diseased individuals inside of A . The set of model parameters  X  contains an unknown probability or rate of infection p A , and the known number of individuals n A who live inside of A . For a given A , if the null hypothesis holds and  X   X   X  0 , then p A = p  X  A and the disease rates are the same within and without the given spatial area.
 The likelihood function L () would then be a binomial function:
The degrees of freedom of the null distribution is one, since there is one more free parameter allowed in  X  than in  X  0 .
 One can easily use the LRT as a basis for spatial anomaly searc h. First, all contiguous, rectangular areas in a grid are searc hed, and the value of the LRT statistic is computed over each of them. T hose areas with the greatest value for the statistic are returned to the user for further examination as potential anomalous areas.
The LRT has been used before for spatial anomaly detection. F or example, the LRT test forms the basis for the spatial scan sta tistic Since the generative process is modeled via a PDF that is assu med to be the same across all cells, determining whether the gene ra-tive process differs from cell-to-cell is equivalent to det ermining whether the parameters to the process differ within and with out A .
Note the word  X  X ubstantially X  in the definition of the two hy-potheses. When we are trying to test whether the generative p ro-cess in two different cells (or two groups of cells) differs, we are not interested in comparing every aspect of the generative p rocess (or every parameter). There will be natural spatial variati ons in the generative process that we want to ignore. For example, when we are testing whether the trend of antimicrobial resistance i s the same inside of an area A as it is outside of A , differences in the starting point of the trend are uninteresting.

As a result, our framework differentiates two types of param e-ters for a cell X  X  PDF: the  X  X hared parameters X  and the  X  X ocal pa-rameters X . The set of  X  X hared parameters X  is the subset of  X  that is forced to be identical among each member of a group of cells. T he shared parameters are used to model within-group cell-simi larity, and it is from within the set of shared parameters where we find the particular data property or properties that are indicat ive of an anomaly. Those shared parameters that the user is actually i nter-ested in testing to see whether they are the same within a regi on A and outside of the region A are called the  X  X est set X , and are denoted by T . The test set is a non-empty subset of the shared parameters.
The  X  X ocal parameters X  are those parameters within  X  that are customizable to each cell. They generally capture the unint eresting or anticipated spatial variation of the data across differe nt cells. Sometimes, the precise values for local parameters may be kn own and supplied beforehand by the user (such as the number of peo ple living in a spatial region). Other times, local parameters m ay be unknown before the test is run, and their values are inferred (such as the initial resistance rate when checking for different t rends in antimicrobial resistance rates).
 Example. Recall that in our motivating application, we want to find a spatial area where the trend in antimicrobial resistan ce is different inside of the area than it is outside of the area. We assume that the observed number of resistant cases in a cell is gener ated via a sample from a binomial random variable, where the numbe r of microbes observed in year y is n y , the probability of resistance in a given year y is p y , and the linear function p y =  X   X  y + p 0 is used to model the trend of antimicrobial resistance rate ove r many When detecting anomalous regions, we want to know whether th ere is an area A where the rate of change in resistance over time differs within A and outside of A . In this case, the rate of change  X  is a shared parameter that is assumed to be uniform inside of A , and uniform outside of A . The question is whether  X  has a single value for the entire grid. Thus, the test set T = {  X  } . In contrast, p 0 is a local parameter that allows the trend to have a different st arting point in each cell. p 0 for each cell is unknown and must be inferred from the data. The number of microbes n y observed in year y is also a local parameter, but it is available to the testing fra mework and need not be inferred.

In this case, the two hypotheses that we are comparing become : 1. f ( A ) would return the number of microbial infections in 2. For a cell c in a spatial area A , L accepts each n y and k y , 3. MLE 0 performs a binomial MLE for an input spatial area. 4. Finally, MLE 1 performs two similar binomial MLEs, ex-
Running the naive algorithm in Figure 1 can be quite expensiv e, but the computational difficulty is not necessarily associa ted with enumerating all of the local spatial regions; even for a 100  X  100 gird this should take only a few seconds. Rather, the computa -tional difficulty is associated with actually computing MLE 1 and MLE 0 for every candidate area in the grid . Thus, we will con-sider pruning strategies that still enumerate all of the O ( n 4 ) local spatial areas in the grid, but can often inexpensively tell u s before any MLEs are ever computed that it is impossible for the curre nt LRT statistic to have a large or interesting value.
First, we point out that this model is exceedingly general. T he only constraint of any significance is that we require statis tical in-dependence of data generation across cells.

Second, there is the issue of statistical significance of the regions returned as the result of the search. Since our framework rel ies on the LRT, the null distribution is known once the likelihood f unction is defined and it is quite easy to associate a p value with each dis-covered region. The only difficulty is that an appropriate mu ltiple-hypothesis-testing correction [4] must be used to account f or the fact that O ( n 4 ) individual hypothesis tests have been performed.
If a user is uncomfortable with either the use of an asymptoti c null distribution (because he or she is suspicious of relyin g on asymp-totics) or the use of a multiple-hypothesis-testing correc tion (be-cause he or she is worried that this will compromise the power of the underlying statistical test), then a Monte-Carlo metho d can be used to associate a p value with each result. Specifically, a large number of spatial grids can be generated under the null hypot hesis, and the search for the most anomalous region can be performed in each. By counting how many of the grid replicas have a LRT stat is-tic greater than the one obtained on the real data, one obtain s an appropriate p value. The Monte Carlo method makes the pruning algorithms presented subsequently much more important. Si nce we are only interested in knowing how many of the grid replicas h ave larger LRT statistic than the one obtained on the real data, w e will supply the largest LRT statistic from the real data as an init ial cut off value to the remaining replicas, which may result in trem endous speedup comparing to the naive Monte Carlo method.
 Figure 3: Illustration of the second tight bound criterion. (a) Three subregions evenly cover the target region. (b) Three s ub-regions unevenly cover the target region, with one big subre -gion dominating the other two. 1. All cells within R 1 share the same set of values for all shared 2. All cells within R 1 share the same set of values for all shared
Obviously, the former two constraints used by MLE 1 ( A, f ( G )) to choose  X  R 1 are more strict than the later two constraints used by MLE 0 ( f ( R 1 )) to choose  X   X  R true. Likewise, L (  X  R 2 | X R 2 )  X  L (  X   X  R
Thus, one can partition A into two arbitrary subregions, then invoke MLE 0 on each of those subregions independently, and use the result to upper-bound the value of L (  X  A | X A ) that would be obtained via a call to MLE 1 ( A, f ( G )) . Taking this to its logical conclusion, by induction, one can always give an upper bound to the value of L (  X  A | X A ) obtained via MLE 1 for A = R 1  X  R 2  X  R 3  X  ... by invoking MLE 0 ( f ( R i )) separately for each R i (see an example in Figure 2). A similar argument holds for L (  X   X  A | X  X  A ) .
Our basic tactic will be to pre-compute a number of strategic ally-chosen result sets from calls to MLE 0 , and use those to attempt to avoid expensive calls to MLE 1 by upper-bounding the quantity of the result. If these upper bounds are tight, it will often be p ossible to prune A without ever calling MLE 1 . A and  X  A with a set of regions for which an MLE 0 has already been pre-computed. There are many possible precomputations and till-ing methods, and the manner in which A (and  X  A ) is tiled can have a significant effect upon the quality of the bound that is achi eved.
In practice, there are two over-riding considerations when tiling a region in order to bound the value of L (  X  A | X A ) : 1. The region should be tiled with as few tiles as possible. 2. For a fixed number of tiles, it is generally better to have a
It is easy to argue why adding more tiles than that are strictl y needed is generally a bad idea. Under MLE 0 , only one value for every parameter in the shared set is allowed. However, if A is cov-ered with n tiles, then n different values of the parameters in the shared set are allowed, with one parameter value per tile. Th us, adding more and more tiles has the effect of adding more and mo re
Procedure Tile_A( x 1 , y 1 , x 2 , y 2 , low, high ) 1. Let mid=(low+high)/2 //base case rectangle log-likelihood */ //recursive case 4. If ( y 2  X  mid) 6. Else If ( y 1 &lt; mid and y 2 &gt; mid) 8. Else If ( y 1  X  mid) we use the smallest number of tiles. Figure 4 (c) and (d) illus trate an example where we use two level 2 rectangles (numbered 2 and 3) and one level three rectangle (numbered 7) to tile the give n A .
Now we turn our attention to the tiling methods for  X  A . There are two different tiling strategies that we employ: The radial method. As illustrated in Figure 6 (a), in a clock-wise order, we elongate the edges of a rectangle A until the edges hit the grid borders.  X  A is then divided into four rectangles denoted  X  A 1 to  X  A 4 , which are used to tile  X  A . We can do the same thing in a counter-clockwise order, which is depicted in Figure 6 (b) . In order to tile any given  X  A using the radial method, the precomputed set should contain all the rectangles that share at least one corner with the grid. This set can be obtained by considering all of t he intersection points on the grid. We connect each intersecti on point on the grid with the four corners of the grid. This produces fo ur diagonals, each of which creates one rectangle in our precom puted set. Since there are O ( n 2 ) intersection points, there are O ( n 2 ) rectangles in our precomputed set.
 The sandwich method. As illustrated in Figure 6 (c), if we elon-gate the two vertical edges of A in both directions until they reach the borders of the grid,  X  A is divided into four rectangles, denoted  X  A 1 to  X  A 4 . We use these four resulting rectangles to tile  X  A . In the same fashion, we can do this horizontally as illustrated in F igure 6 (d). In order to tile any  X  A using this method, we need to pre-compute all the rectangles that share two corners with the gr id. In Figure 6 (c), these rectangles are  X  A 2 and  X  A 4 . Notice that these two rectangles are in the the precomputed set for the radial meth od, so we can reuse them. Also, since we want to avoid any additional precomputations to bound  X  A 1 , we call the Tile_A procedure from the previous subsection to upper bound  X  A 1 . We can upper bound  X  A 3 in similar fashion. As a result, with no additional precompu ta-tion, we can obtain the bounds using the sandwich method.
We have discussed four methods to bound  X  A (Fig 6); in practice, we compute each and choose the tightest bound on L (  X   X  A | X  X  A ) .
The final search algorithm in Figure 7 modifies the naive algo-rithm. At each iteration, the new algorithm obtains an upper bound for the current LRT statistic, and compares the upper bound w ith the current cutoff related to the k th largest  X  discovered so far. If the upper bound is less than the cutoff, the current region is pruned. Otherwise, the exact value for the LRT statistic is computed . Table 1: Average pruning rates and accuracy for 50 trials on a 128  X  128 grid. The pruning rate is pruned rectangle # total rectangle # . Test Avg Pruning Rate Accuracy Null (standard) 99.9994% no false alarm Null( city population) 99.9996% no false alarm Hot spot p = 0 . 003 99.9712 % 100% Hot spot p = 0 . 01 99.9722 % 100% Table 2: Average pruning rates and accuracy for 50 random trials on a 256  X  256 grid.
 squared with one degree of freedom. For our tests, we run 50 tr ials on a grid size of 128  X  128 . To test the scalability, we also consider a grid size of 256  X  256 . Our initial cutoff value for pruning was chosen to correspond to an overall false positive rate of 5%. In all tests, we seek the top subregion.

We ran two different sets of experiments where the null hypot h-esis was in fact true. In the first, the underlying n c values are rela-tively uniform, where n c was always sampled from a Normal(  X  = 1  X  10 4 ,  X  = 1  X  10 3 ) distribution. The  X  X uccess X  rate for each cell was set to 0.001. In the second case, there was a single densel y-populated region, or simulated  X  X ity". We randomly selecte d an area of size 12  X  12 , and within this area, n c was always sam-pled from a Normal(  X  = 1  X  10 5 ,  X  = 5  X  10 3 ) distribution. We recorded the pruning rate (the number of rectangles pruned/ the total rectangles), and checked if there were false alarms.
 We also simulated a case where the alternative hypothesis ho lds. The setup was the same as the standard null case, except that w e randomly pick a 4  X  3 region as the  X  X ot spot X . In one set of tests (the  X  X ubtle anomaly case"), the success rate for generatin g each k c was set to 0.003. In the other (the  X  X xtreme anomaly case"), t he success rate was set to 0.01. Results are given in Tables 1 and 2. Discussion. In general, the results shows very high pruning power. Taking into account the precomputated MLEs, the pruning rat es realized on the 128  X  128 grid would on average reduce the number of tests required by a factor of 31.1 to 31.4 compared to the na ive algorithm. On the 256  X  256 grid, our framework would reduce the number of tests required by a factor of 63.4.

Also, with an overall 0.05 level test, our framework did not fi nd any false alarms in tests where the null hypothesis held. The to-tal lack of false alarms (even at a significance level of 0.05) may result from our application of a conservative Bonferroni co rrec-tion. On the other hand, in both the  X  X ubtle anomaly X  and  X  X x-treme anomaly X  cases, the framework had 100% detection accu -racy. Overall, these results show that the framework seems t o be both safe and effective. Application Description. 357 U.S. hospitals participate in the ARM program, where each year, for each (bacteria/antimicro bial drug) combination, each hospital submits the number of isol ates (bacteria instances) tested, as well as the number of times t hat the bacteria was found to be susceptible to the given drug. As des cribed in the introduction, our goal is to find local spatial regions where the temporal trend of antimicrobial resistance change within the region is significantly different than the trend outside of t he region. Experimental Goal. We wish to experimentally test whether our Table 3: LRT framework time (in days) vs. naive algorithm for  X  X rend" model. n  X  n LRT time LRT pruning Naive time Speedup 16  X  16 0.15 96.5286% 2.6 17.3 32  X  32 1.13 97.6303% 35.9 31.8 64  X  64 11.9 98.0431% 544 45.7 Table 4: LRT framework time (in days) vs. naive algorithm for  X  X age" model. n  X  n LRT time LRT pruning Naive time Speedup 16  X  16 0.29 78.8396% 1.28 4.41 32  X  32 2.01 86.1219% 14.0 6.97 Experiment Setup. For the bacteria-antimicrobial combination of S. aureus and Nafcillin, we extracted data from the ARM datab ase for 203 hospitals that provided data in the time period from 2 000 to 2004, inclusive. All of the hospitals were organized into an n  X  n spatial grid. We first sort the hospitals using the longitude of their physical locations. They are then grouped into n equi-depth buckets. The placement of hospitals into the n buckets determines which column of the grid each hospital belongs to. Similarly , we sort all hospitals on latitude, partition them n ways, and use the partitioning to determine the rows.
 We tested three different grid sizes: n = 16 , 32 , and 64 , and use our framework to find the spatial region that most strongly re jects the null hypothesis. For each grid size, we recorded both the prun-ing rate and the wall-clock running time. Since MLE 0 requires one second over the entire data set, there is a strong relatio nship between the pruning rate and running time; enumerating all o f the cells in the grid is inexpensive compared to running one or mo re MLEs for each area in the grid. Also, due to the high cost of run -ning the MLE, in order to compare our methods with the naive method of simply running an MLE over each area, we had to resor t to sampling. For each iteration of the naive method of Algori thm 1, before we invoke MLE 0 over A and  X  A , we flip a coin having a 1% chance of obtaining a  X  X ead X  result. If the result is a  X  X ea d X , we compute the LRT statistic by running the MLE. Otherwise, w e skip the rectangle. While the result of running this samplin g-based algorithm will be useless, the running time is expectedly 1 100 of the time required to run the naive algorithm to completion. All r esults are presented in Table 3.
 Discussion. We observed a speedup of between one and two orders of magnitude with respect to the naive algorithm, with the sp eedup increasing with increasing grid size. The results are quite striking. For example, in the 64  X  64 case, our framework took about 12 days to finish running. On the other hand, the naive method is e sti-mated to take 544 days, or about one and a half years! Thus, in t his real application, the pruning strategies that the proposed framework utilizes can turn a computation that is totally infeasible t o one that may still be expensive X  X ut is possible in a time frame that is likely acceptable in most epidemiological settings. Application. Our data comes from a 5% sample of the 2000 U.S. census data. 2 Each database record contains data describing a single person, where we know (a) the person X  X  annual wage, (b ) the person X  X  highest educational attainment level, and (c) the place where the person works. Annual wage is an integral number. Th ere are eighteen classes of educational attainment, such as Bac helor X  X  degree, Master X  X  degree, etc. For privacy reasons, the plac e of work attribute in this data is described in terms of the Public Use Mi-http://usa.ipums.org/usa/ 3. MLE 0 in this problem is an implementation of the EM al-4. MLE 1 is two invocations of MLE 0 with X A and X  X  A , re-Experimental Setup. We extracted data for fourteen, contiguous U.S. states, forming a rectangle from Arizona to Indiana, co ver-ing 330 PUMAs. The 330 PUMAs were organized into an n  X  n grid using a method identical to the one used for the ARM data. We used n = 16 and 32 . We used our framework to look for the top subregion X  X hat is, the one with the largest LRT statisti c value. Since MLE 0 relies on an iterative EM implementation, it is expen-sive to run. We used sampling to obtain the estimated wall-cl ock time for the naive method. The results are presented in Table 4. Discussion. We find that we still achieve good performance com-pared to the naive method, even in a small grid size. However, the pruning rate and speedup, while significant, are not as drama tic as with the other two data sets. It appears that there is some par ticu-lar aspect of this application which results in the bound com puted by the framework not being quite as tight as in the other two ca ses. Still, in the case of the 32  X  32 grid, the framework is able to reduce the required time from two weeks down to two days.
Detecting anomalous spatial regions have been a popular res earch topic. Two lines of research have been popular in this area. O ne is spatial clustering, which includes CLARANS [10], DBSCAN [5 ], and STING [11] etc. The other group focuses on the performanc e study on detecting statistical significant spatial or spati al-temporal cluster (hot spot) [8, 9, 2, 1]; most papers in this second lin e of work are based on Kulldorff X  X  spatial scan statistic (SSS)[6, 7] . The SSS is used to detect non-random spatial clusters of event occur rence. Conditioned on the observed event counts, and assuming even t in-dependence, the SSS is expressed in the following form: where C A is the aggregate event count for area A , and C G is the ag-gregate event count for the entire spatial region. P A and P G are the population sizes for zone A and the entire spatial region, respec-tively. Monte Carlo methods is employed to obtain the empiri cal null distribution of the test statistic.

Since obtaining null distribution is expensive for Kulldor ff X  X  spa-tial scan statistic, several methods have been proposed for address-ing the performance issue [9, 8, 1, 2]. These methods differ f rom
