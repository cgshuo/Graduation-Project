 Query suggestion aims to suggest relevant queries for a given query, which help users better specify their information needs. Previously, the suggested terms ar e mostly in the same language of the input query. In this paper, we extend it to cross-lingual query suggestion (CLQS): for a que ry in one language, we suggest important to scenarios of cro ss-language information retrieval (CLIR) and cross-lingual keyword bidding for search engine advertisement. Instead of relying on existing query translation technologies for CLQS, we present an effective means to map the input query of one language to queri es of the other language in the query log. Important monolingua l and cross-lingual information such as word translation relations and word co-occurrence similarity with a discriminative m odel. Benchmarks show that the resulting CLQS system signifi cantly outperforms a baseline system based on dictionary-based query translation. Besides, the resulting CLQS is tested with French to English CLIR tasks on TREC collections. The results demonstrate higher effectiveness than the traditional query translation methods. H.3.3 [ Information storage and retrieval ]: Information Search and Retrieval  X  Query formulation Algorithms, Performance, Experimentation, Theory. translation, query sugge stion, query expansion Query suggestion is a functionality to help users of a search engine to better specify their information need, by narrowing down or expanding the scope of the search with synonymous queries and relevant queries, or by suggesting related queries that have been frequently used by othe r users. Search engines, such as Google, Yahoo!, MSN, Ask Jeeves, all have implemented query suggestion functionality as a valuable addition to their core search method. In addition, the same t echnology has been leveraged to recommend bidding terms to online advertiser in the pay-for-performance search market [12]. 
Query suggestion is closely rela ted to query expansion which extends the original query with new search terms to narrow the scope of the search. But differe nt from query expansion, query suggestion aims to suggest full queri es that have been formulated by users so that the query integrity and coherence are preserved in the suggested queries. 
Typical methods for query sugge stion exploit query logs and document collections, by assuming that in the same period of time, many users share the same or similar interests, which can be expressed in different manners [12, 14, 26]. By suggesting the related and frequently used formul ations, it is hoped that the new query can cover more relevant documents. However, all of the existing studies dealt with mono lingual query suggestion and to our knowledge, there is no published study on cross-lingual query suggestion (CLQS). CLQS aims to suggest related queries but in a different language. It has wide a pplications on World Wide Web: for cross-language search or for suggesting relevant bidding terms in a different language. 1
CLQS can be approached as a query translation problem, i.e., to suggest the queries that are tran slations of the original query. commercial machine translation systems can be used for translation. However, these kinds of approaches usually rely on static knowledge and data. It cannot effectively reflect the quickly shifting interests of Web user s. Moreover, there are some problems with translated queries in target language. For instance, This work was done while the author was visiting Microsoft Research Asia. the translated terms can be reasonable translations, but they are not popularly used in the target language. For example, the French query  X  X liment biologique X  is translated into  X  X iologic food X  by Google translation tool 2 , yet the correct formulation nowadays should be  X  X rganic food X . Therefore, there exist many mismatch cases between the translated terms and the really used terms in target language. This mismatch ma kes the suggested terms in the target language ineffective. 
A natural thinking of solving this mismatch is to map the queries in the source language a nd the queries in the target language, by using the query log of a search engine. We exploit the fact that the users of search engines in the same period of time have similar interests, and they submit queries on similar topics in different languages. As a resu lt, a query written in a source language likely has an equivalent in a query log in the target language. In particular, if the user intends to perform CLIR, then original query is even more likely to have its correspondent included in the target language query log. Therefore, if a candidate for CLQS appears often in the query log, then it is more likely the appropriate one to be suggested. 
In this paper, we propose a method of calculating the similarity between source language query and the target language query by exploiting, in addition to the tr anslation information, a wide spectrum of bilingual and monolingua l information, such as term co-occurrences, query logs with click-through data, etc. A discriminative model is used to learn the cross-lingual query similarity based on a set of manually translated queries. The model is trained by optimizing the cross-lingual similarity to best fit the monolingual similarity between one query and the other query X  X  translation. Besides bei ng benchmarked as an independent module, the resulting CLQS system is tested as a new means of query  X  X ranslation X  in CLIR task on TREC collections. The results show that this new  X  X ranslation X  method is more effective than the traditional query translation method. 
The remainder of this paper is organized as follows: Section 2 introduces the related work; Section 3 describes in detail the discriminative model for estimati ng cross-lingual query similarity; Section 4 presents a new CLIR approach using cross-lingual query suggestion as a bridge acro ss language boundaries. Section 5 discusses the experime nts and benchmarks; finally, the paper is concluded in Section 6. Most approaches to CLIR perform a query translation followed by a monolingual IR. Typically, queries are translated either using a bilingual dictionary [22], a machine translation software [9] or a parallel corpus [20]. 
Despite the various types of resources used, out-of-vocabulary (OOV) words and translation disambiguation are the two major bottlenecks for CLIR [20]. In [7, 27], OOV term translations are mined from the Web using a search engine. In [17], bilingual knowledge is acquired based on anchor text analysis. In addition, word co-occurrence statistics in the target language has been leveraged for translation di sambiguation [3, 10, 11, 19]. http://www.google.com/language_tools 
Nevertheless, it is arguable that accurate query translation may not be necessary for CLIR. Indeed, in many cases, it is helpful to introduce words even if they are not direct translations of any query word, but are closely related to the meaning of the query. This observation has led to the development of cross-lingual query expansion (CLQE) techniques [2, 16, 18]. [2] reports the enhancement on CLIR by post-translation expansion. [16] develops a cross-lingual relevanc y model by leveraging the cross-lingual co-occurrence statistics in parallel texts. [18] makes performance comparison on multiple CLQE techniques, including pre-translation expansion and post-translation expansion. However, there is lack of a unified framework to combine the wide spectrum of resources and recent advances of mining techniques for CLQE. 
CLQS is different from CLQE in that it aims to suggest full queries that have been formulat ed by users in another language. As CLQS exploits up-to-date query logs, it is expected that for most user queries, we can fi nd common formulations on these topics in the query log in the target language. Therefore, CLQS also plays a role of adapting the original query formulation to the common formulations of similar topics in the target language. 
Query logs have been successfully used for monolingual IR [8, 12, 15, 26], especially in monoli ngual query suggestions [12] and relating the semantically relevant terms for query expansion [8, 15]. In [1], the target language query log has been exploited to help query translation in CLIR. A search engine has a query l og containing user queries in different languages within a certain period of time. In addition to query terms, click-through informati on is also recorded. Therefore, we know which documents have been selected by users for each query. Given a query in the source language, our CLQS task is to determine one or several similar queries in the target language from the query log. 
The key problem with cross-lingua l query suggestion is how to learn a similarity measure betw een two queries in different languages. Although various statisti cal similarity measures have been studied for monolingual term s [8, 26], most of them are based on term co-occurrence statistic s, and can hardly be applied directly in cross-lingual settings. 
In order to define a similar ity measure across languages, one has to use at least one translation tool or resource. So the measure is based on both translation relati on and monolingual similarity. In this paper, as our purpose is to provide up-to-date query similarity measure, it may not be sufficient to use only a static translation resource. Therefore, we also in tegrate a method to mine possible translations on the Web. This method is particularly useful for dealing with OOV terms. 
Given a set of resources of diffe rent natures, the next question is how to integrate them in a prin cipled manner. In this paper, we propose a discriminative model to l earn the appropriate similarity measure. The principle is as follows: we assume that we have a reasonable monolingual query simila rity measure. For any training query example for which a translation exists, its similarity measure (with any other query) is transposed to its translation. Therefore, we have the desired cr oss-language similarity value for this example. Then we use a discriminative model to learn the cross-language similarity function which fits the best these examples. 
In the following sections, let us first describe the detail of the discriminative model for cross-lingua l query similarity estimation. Then we introduce all the features (monolingual and cross-lingual information) that we will use in the discriminative model. In this section, we propose a di scriminative model to learn cross-lingual query similarities in a principled manner. The principle is as follows: for a reasonable mono lingual query similarity between two queries, a cross-lingual correspondent can be deduced between one query and another que ry X  X  translation. In other words, for a pair of queries in different languages, their cross-lingual similarity should fit the monolingual similarity between one query and the other query X  X  translation. For example, the similarity between French query  X  X ages jaunes X  (i.e.,  X  X ellow page X  in English) and English query  X  X elephone directory X  should be equal to the monolingual simila rity between the translation of the French query  X  X ellow page X  and  X  X elephone directory X . There are many ways to obtain a m onolingual similarity measure between terms, e.g., term co-occurrence based mutual information and 2  X  . Any of them can be used as the target for the cross-lingual similarity function to fit. In this way, cross-lingual query similarity estimation is formulated as a regression task as follows: 
Given a source language query f q , a target language query and a monolingual query similarity ML sim , the corresponding cross-lingual query similarity CL sim is defined as follows: where
Based on Equation (1), it would be relatively easy to create a training corpus. All it requires is a list of query translations. Then an existing monolingual query sugge stion system can be used to automatically produce similar query to each translation, and create the training corpus for cross-lingua l similarity estimation. Another advantage is that it is fairly easy to make use of arbitrary information sources within a di scriminative modeling framework to achieve optimal performance. 
In this paper, support vect or machine (SVM) regression algorithm [25] is used to learn the cross-lingual term similarity function. Given a vector of feature functions f between weight vector and the feature vector in a kernel space as follows: where  X  is the mapping from the input feature space onto the kernel space, and w is the weight vector in the kernel space which will be learned by the SVM regression training. Once the weight vector is learned, the Equation (2) can be used to estimate the similarity between queries of different languages. 
We want to point out that in stead of regression, one can definitely simplify the task as a bi nary or ordinal classification, in which case CLQS can be categorized according to discontinuous relevancies, e.g., strongly relevant, weakly relevant, and irrelevant . In either case, one can resort to discriminative classification approaches, such as an SVM or maximum entropy model, in a straightforward way. However, the regression formalism enables us to fully ra nk the suggested queries based on the similarity score given by Equation (1). 
The Equations (1) and (2) construct a regression model for cross-lingual query similarity estimation. In the following sections, the monolingual query si milarity measur e (see Section 3.2) and the feature functions used for SVM regression (see Section 3.3) will be presented. Any monolingual term similarity measure can be used as the regression target. In this paper, we select the monolingual query similarity measure presente d in [26] which reports good performance by using search user s X  click-through information in query logs. The reason to choose this monolingual similarity is that it is defined in a similar context as ours  X  according to a user log that reflects users X  intention and behavior. Therefore, we can expect that the cross-language term similarity learned from it can also reflect users X  intention and expectation. 
Following [26], our monolingual query similarity is defined by combining both query content-base d similarity and click-through commonality in the query log. 
First the content similarity between two queries p and q is defined as follows: where ) ( x kn is the number of keywords in a query x , the number of common keywor ds in the two queries. 
Secondly, the click-through based similarity is defined as follows, where ) ( x rd is the number of clicked URLs for a query x , and 
Finally, the similarity betw een two queries is a linear combination of the content-based and click-through-based similarities, and is presented as follows: where  X  and  X  are the relative importance of the two similarity measures. In this paper, we set , 4 . 0 =  X  and 6 . 0 = practice in [26]. Queries with similarity measure higher than a threshold with another query w ill be regarded as relevant monolingual query suggestions (MLQ S) for the latter. In this paper, the threshold is set as 0.9 empirically. This section presents the extracti on of candidate relevant queries from the log with the assistance of various monolingual and bilingual resources. Meanwhile, feature functions over source query and the cross-lingual relevant candidates are defined. Some of the resources being used here , such as bilingual lexicon and parallel corpora, were for query translation in previous work. But note that we employ them here as an assistant means for finding relevant candidates in the log rather than for acquiring accurate translations. In this subsection, a built-in-hous e bilingual dictionary containing 120,000 unique entries is used to re trieve candidate queries. Since multiple translations may be associated with each source word, co-occurrence based translation di sambiguation is performed [3, 10]. The process is presented as follows: Given an input query } { language, for each query term fi w , a set of unique translations are Then the cohesion between the tran slations of two query terms is measured using mutual informati on which is computed as follows: where . ) ( ) ( , ) , ( ) , ( Here ) , ( y x C is the number of queries in the log containing both x and y , ) ( x C is the number of queries containing term x , and N is the total number of queries in the log. Based on the term-term cohesion defined in Equation (6), all the possible query translations are ranked using the summation of the term-term cohesion  X  top-4 query translations is denoted as ) ( query translation ) ( the same keywords as T from the target language log. The retrieved queries are candidate target queries, and are assigned dict as the value of the feature Dictionary-based Translation Score . Parallel corpora are precious re sources for bilingual knowledge acquisition. Different from the bilingual dictionary, the bilingual knowledge learned from parallel corpora assigns probability for each translation candidate which is useful in acquiring dominant query translations. In this paper, the Europarl corpus (a set of parallel French and English texts from the proceedings of the European Parliament) is used. The corpus is first sentence aligned. Then word alignments are derived by training an IBM translation model 1 [4] using GIZA++ [21]. The learned bilingual knowledge is used to extract candidate queries from the query l og. The process is presented as follows: Given a pair of queries, f q in the source language and target language, the Bi-Directional Translation Score is defined as follows: where ) | ( given by IBM model 1 which has the following form: where ) | ( derived from the word-aligned corpora. The reason to use bidirectional translation probability is to deal with the fact that common words can be considered as possible translations of many words. By us ing bidirectional translation, we test whether the translation words can be translated back to the source words. This is helpful to focus on the translation probability onto the most specific translation candidates. Now, given an input query f q , the top 10 queries } { highest bidirectional translation scores with f q are retrieved from the query log, and ) , ( value for the feature Bi-Directional Translation Score . OOV word translation is a major knowledge bottleneck for query translation and CLIR. To overcome this knowledge bottleneck, web mining has been exploited in [7, 27] to acquire English-Chinese term translations base d on the observation that Chinese terms may co-occur with their English translations in the same web page. In this section, this web mining approach is adapted to acquire not only translations but semantically related queries in the target language. with the source query in many web pages, they are probably semantically related. Therefore, a simple method is to send the source query to a search engine (Google in our case) for Web pages in the target language in or der to find related queries in the target language. For instance, by sending a French query  X  X ages jaunes X  to search for English pages, the English snippets containing the key words  X  X ellow pa ges X  or  X  X elephone directory X  will be returned. However, this simple approach may induce significant amount of noise due to the non-relevant returns from the search engine. In order to improve the relevancy of the bilingual snippets, we extend the simple approach by the following query modification: the orig inal query is used to search with the dictionary-based query keyword translations, which are unified by the  X  ( and )  X  ( OR ) operators into a single Boolean query. For example, for a given query abc q = where the set of translation entries in the dictionary of for a is } , , { one web query. 
From the returned top 700 snippets, the most frequent 10 target queries are identified, and are associated with the feature Frequency in the Snippets. Furthermore, we use Co-Occurrence Double-Check (CODC) Measure to weight the association between the source and target queries. CODC Measure is proposed in [6] as an association measure based on snippet analys is, named Web Search with Double Checking (WSDC) model. In WSDC model, two objects a using a as query (forward process), and a can be found by using b as query (backward process) by web search. The forward process counts the frequency of b in the top N snippets of query a , denoted as ) @ ( a b freq . Similarly, the backward process count the as ) @ ( b a freq . Then the CODC association score is defined as follows: CODC measures the association of two terms in the range between 0 and 1, where unde r the two extreme cases, are of no association when 0 ) @ ( = or 0 ) @ ( = our experiment,  X  is set at 0.15 following the practice in [6]. 
Any query e q mined from the Web will be associated with a For all the candidate queries 0 Q being retrieved using dictionary (see Section 3.3.1), parallel data (see Section 3.3.2) and web mining (see Section 3.3.3), mono lingual query suggestion system (described in Section 3.1) is called to produce more related queries in the target language. For each target query monolingual source query ) ( Q with the highest mono lingual similarity with e q , i.e., Then the monolingua l similarity between e q and ) ( used as the value of the e q  X  X  Monolingual Query Suggestion Feature . For any target query 0 Q q  X  , its Monolingual Query Suggestion Feature is set as 1. For any query 0 Q q e  X  , its values of Dictionary-based Translation Score, Bi-Directional Translation Score, Frequency in the Snippet, and CODC Measure are set to be equal to the In summary, four categories of features are used to learn the cross-lingual query similarity. SVM regre ssion algorithm [25] is used to learn the weights in Equation (2). In this paper, LibSVM toolkit [5] is used for the regression training. 
In the prediction stage, the candidate queries will be ranked using the cross-lingual query simila rity score computed in terms similarity score lower than a threshold will be regarded as non-relevant. The threshold is learned using a development data set by fitting MLQS X  X  output. In Section 3, we presented a di scriminative model for cross lingual query suggestion. However, obj ectively benchmarking a query suggestion system is not a trivial ta sk. In this paper, we propose to use CLQS as an alternative to query translation, and test its effectiveness in CLIR tasks. The resulting good performance of CLIR corresponds to the high qua lity of the suggested queries. 
Given a source query f q , a set of relevant queries target language are recommended using the cross-lingual query suggestion system. Then a mono lingual IR system based on the BM25 model [23] is called using each } { e q q  X  as queries to retrieve documents. Then the re trieved documents are re-ranked based on the sum of the BM25 scores associated with each monolingual retrieval. In this section, we will benchmark the cross-lingual query suggestion system, comparing its performance with monolingual query suggestion, studying the cont ribution of various information sources, and testing its effectiven ess when being used in CLIR tasks. In our experiments, French and English are selected as the source and target language respectively. Su ch selection is due to the fact that large scale query logs are readily available for these two languages. A one-month English query log (containing 7 million unique English queries with occurrence frequency more than 5) of MSN search engine is used as the target language log. And a monolingual query suggestion system is built based on it. In addition, 5,000 French queries are selected randomly from a French query log (containing around 3 million queries), and are manually translated into English by professional French-English translators. Among the 5,000 Fren ch queries, 4,171 queries have their translations in the English query log, and are used for CLQS training and testing. Furthe rmore, among the 4,171 French queries, 70% are used for cross-lingual query similarity training, 10% are used as the development data to determine the relevancy threshold, and 20% are used for testing. To retrieve the cross-lingual related queries, a built-in -house French-English bilingual lexicon (containing 120,000 unique entries) and the Europarl corpus are used. Besides benchmarking CLQS as an independent system, the CLQS is also tested as a query  X  X ranslation X  system for CLIR tasks. Based on the observation that the CLIR performance benchmark measures the quality of CLQS in terms of its effectiveness in helping CLIR. To perform such benchmark, we use the documents of TREC6 CL IR data (AP88-90 newswire, 750MB) with officially provided 25 short French-English queries pairs (CL1-CL25). The selection of th is data set is due to the fact that the average length of the queries are 3.3 words long, which matches the web query logs we use to train CLQS. Mean-square-error (MSE) is used to measure the regression error and it is defined as follows: where l is the total number of cross-lingual query pairs in the testing data. 
As described in Section 3.4, a relevancy threshold is learned using the development data, and onl y CLQS with similarity value above the threshold is regarded as truly relevant to the input query. In this way, CLQS can also be benchmarked as a classification task using precisi on (P) and recall (R) which are defined as follows: where CLQS S is the set of relevant queries suggested by CLQS, S is the set of relevant queries suggested by MLQS (see Section 3.2). 
The benchmarking results with va rious feature configurations are shown in Table 1. 
Table 1. CLQS performance with different feature settings ( DD : dictionary only; DD+PC : dictionary and parallel corpora; DD+PC+Web : dictionary, parallel corpora, and web mining; DD+PC+Web+MLQS : dictionary, parallel corpora, web mining and monolingual query suggestion) 
Table 1 reports the performan ce comparison with various feature settings. The baseline syst em (DD) uses a conventional query translation approach, i.e., a bilingual dictionary with co-occurrence-based translation disa mbiguation. The baseline system only covers less than 10% of th e suggestions made by MLQS. Using additional features obviously enables CLQS to generate more relevant queries. The most significant improvement on recall is achieved by exploiting MLQS. Th e final CLQS system is able to generate 42% of the queries suggested by MLQS. Among all the feature combinations, there is no significant change in precision. This indicates that our methods can improve the recall by effectively leveraging various information sources without losing the accuracy of the suggestions. Besides benchmarking CLQS by comparing its output with MLQS output, 200 French queries are randomly selected from the French query log. These queries are double-checked to make sure that they are not in the CLQS training corpus. Then CLQS system is used to suggest relevant Eng lish queries for them. On average, for each French query, 8.7 relevant English queries are suggested. Then the total 1,740 suggested English queries are manually checked by two professional English/French translators with cross-validation. Among the 1,747 suggested queries, 1,407 queries are recognized as relevant to the original ones, hence the accuracy is 80.9%. Figure 1 shows an example of CLQS of the French query  X  X errorisme interna tional X  ( X  X nternational terrorism X  in English). In this section, CLQS is tested w ith French to English CLIR tasks. We conduct CLIR experiments us ing the TREC 6 CLIR dataset described in Section 5.1. The CL IR is performed using a query translation system followed by a BM25-based [23] monolingual IR module. The following three diffe rent systems have been used to perform query translation: (1) CLQS: our CLQS system; (2) MT: Google French to English m achine translation system; (3) DT: a dictionary based query translation system using co-occurrence statistics for translation disambiguation. The translation disambiguation algorithm is presented in Section 3.3.1. Besides, the monolingual IR perfo rmance is also reported as a reference. The average precision of the four IR systems are reported in Table 2, and the 11-point precision-recall curves are shown in Figure 2. ( Monolingual : monolingual IR system; MT : CLIR based on machine translation; DT : CLIR based on dictionary translation; CLQS : CLQS-based CLIR) The benchmark shows that us ing CLQS as a query translation tool outperforms CLIR based on machine translation by 7.4%, outperforms CLIR based on dictiona ry translation by 25.2%, and achieves 87.6% of the m onolingual IR performance. 
The effectiveness of CLQS lies in its ability in suggesting closely related queries besides accurate translations. For example, for the query CL14  X  X errorisme international X  ( X  X nternational terrorism X ), although the machine tr anslation tool translates the query correctly, CLQS system still achieves higher score by recommending many additional rela ted terms such as  X  X lobal terrorism X ,  X  X orld terrorism X , etc. (as shown in Figure 1). Another example is the query  X  X a pollution caus X e par l'automobile X  ( X  X ir pollution due to automobile X ) of CL6. The MT tool provides the translation  X  X he pollution caused by the car X , while CLQS system enumerates all the possible synony ms of  X  X ar X , and suggest the following queries  X  X ar pollution X  ,  X  X uto pollution X ,  X  X utomobile pollution X . Besides, other rela ted queries such as  X  X lobal warming X  are also suggested. For the query CL12  X  X a culture  X cologique X  ( X  X rganic farming X ), the MT tool fails to generate the correct translation. Although the correct translation is neither in our French-English dictionary, CL QS system generates  X  X rganic farm X  as a relevant query due to successful web mining. The above experiment demonstrat es the effectiveness of using CLQS to suggest relevant queri es for CLIR enhancement. A related research is to perform query expansion to enhance CLIR [2, 18]. So it is very interesting to compare the CLQS approach with the conventional query expansion approaches. Following [18], post-translation expansi on is performed based on pseudo-relevance feedback (PRF) technique s. We first perform CLIR in the same way as before. Then we use the traditional PRF algorithm described in [24] to se lect expansion terms. In our experiments, the top 10 terms are selected to expand the original query, and the new query is used to search the collection for the second time. The new CLIR perfo rmance in terms of average precision is shown in Table 3. Th e 11-point P-R curves are drawn in Figure 3. Although being enhanced by pseudo-relevance feedback, the CLIR using either machine transl ation or dictionary-based query translation still does not perform as well as CLQS-based approach. Statistical t-test [13] is conducted to indicate whether the CLQS-based CLIR performs si gnificantly better. Pair-wise p-values are shown in Table 4. Clearly, CLQS significantly outperforms MT and DT without PR F as well as DT+PRF, but its superiority over MT+PRF is not significant. However, when combined with PRF, CLQS significant outperforms all the other methods. This indicates the higher effectiveness of CLQS in related term identification by leveraging a wide spectrum of resources. Furthermore, post-transl ation expansion is capable of improving CLQS-based CLIR. This is due to the fact that CLQS and pseudo-relevance feedback ar e leveraging different categories of resources, and both approaches can be complementary. In this paper, we proposed a new approach to cross-lingual query suggestion by mining relevant que ries in different languages from query logs. The key solution to th is problem is to learn a cross-lingual query similarity measur e by a discriminative model exploiting multiple monolingual and bilingual resources. The model is trained based on the principle that cross-lingual similarity should best fit the m onolingual similarity between one query and the other query X  X  translation. Figure 2. 11 points precision-recall on TREC6 CLIR data set 
Table 3. Comparison of average precision (AP) on TREC 6 without and with post-translation expansion. (%) are the relative percentages over the monolingual IR performance 
Table 4. The results of pair -wise significance t-test. Here p-value &lt; 0.05 is considered statistically significant 
The baseline CLQS system applies a typical query translation approach, using a bilingual dictionary with co-occurrence-based translation disambiguation. This approach only covers 10% of the relevant queries suggested by an MLQS system (when the exact translation of the original query is given). By leveraging additional resources such as para llel corpora, web mining and log-based monolingual query expansion, the final system is able to cover 42% of the relevant queries suggested by an MLQS system with precision as high as 79.6%. 
To further test the quality of the suggested queries, CLQS system is used as a query  X  X ranslati on X  system in CLIR tasks. Benchmarked using TREC 6 French to English CLIR task, CLQS demonstrates higher effectiveness than the traditional query translation methods using either bilingual dictionary or commercial machine translation tools. 
The improvement on TREC French to English CLIR task by using CLQS demonstrates the high quality of the suggested queries. This also shows the strong correspondence between the input French queries and English que ries in the log. In the future, we will build CLQS system between languages which may be more loosely correlated, e.g., English and Chinese, and study the CLQS performance change due to the less strong correspondence among queries in such languages. [1] Ambati, V. and Rohini., U. Using Monolingual Clickthrough [2] Ballestors, L. A. and Croft, W. B. Phrasal Translation and [3] Ballestors, L. A. and Croft, W. B. Resolving Ambiguity for [4] Brown, P. F., Pietra, D. S. A., Pietra, D. V. J., and Mercer, R. [5] Chang, C. C. and Lin, C. LIBSVM: a Library for Support [6] Chen, H.-H., Lin, M.-S., and Wei, Y.-C. Novel Association [7] Cheng, P.-J., Teng, J.-W., Chen, R.-C., Wang, J.-H., Lu, W.-[8] Cui, H., Wen, J. R., Nie, J.-Y., and Ma, W. Y. Query [9] Fujii A. and Ishikawa, T. Applying Machine Translation to [10] Gao, J. F., Nie, J.-Y., Xun, E., Zhang, J., Zhou, M., and [11] Gao, J. F., Nie, J.-Y., He, H., Chen, W., and Zhou, M. [12] Gleich, D., and Zhukov, L. S VD Subspace Projections for [13] Hull, D. Using Statistical Testing in the Evaluation of [14] Jeon, J., Croft, W. B., and L ee, J. Finding Similar Questions [15] Joachims, T. Optimizing Sear ch Engines Using Clickthrough [16] Lavrenko, V., Choquette, M., and Croft, W. B. Cross-Lingual [17] Lu, W.-H., Chien, L.-F., and L ee, H.-J. Anchor Text Mining [18] McNamee, P. and Mayfield, J. Comparing Cross-Language [19] Monz, C. and Dorr, B. J. Iterative Translation [20] Nie, J.-Y., Simard, M., Isabelle, P., and Durand, R. Cross-[21] Och, F. J. and Ney, H. A Sy stematic Comparison of Various [22] Pirkola, A., Hedlund, T., Kes husalo, H., and J X rvelin, K. [23] Robertson, S. E., Walker, S., Hancock-Beaulieu, M. M., and [24] Robertson, S. E. and Jones, K. S. Relevance Weighting of [25] Smola, A. J. and Sch X lkopf, B. A. Tutorial on Support Vector [26] Wen, J. R., Nie, J.-Y., and Zh ang, H. J. Query Clustering [27] Zhang, Y. and Vines, P. Using the Web for Automated 
