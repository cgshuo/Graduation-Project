 Social sensing is based on the idea that communities or groups of people can provide a set of information similar to those obtainable from a sensor network. Emergency man-agement is a candidate field of application for social sensing. In this work we describe the design, implementation and de-ployment of a decision support system for the detection and the damage assessment of earthquakes in Italy. Our system exploits the messages shared in real-time on Twitter, one of the most popular social networks in the world. Data mining and natural language processing techniques are employed to select meaningful and comprehensive sets of tweets. We then apply a burst detection algorithm in order to promptly iden-tify outbreaking seismic events. Detected events are auto-matically broadcasted by our system via a dedicated Twitter account and by email notifications. In addition, we mine the content of the messages associated to an event to discover knowledge on its consequences. Finally we compare our re-sults with official data provided by the National Institute of Geophysics and Volcanology (INGV), the authority re-sponsible for monitoring seismic events in Italy. The INGV network detects shaking levels produced by the earthquake, but can only model the damage scenario by using empirical relationships. This scenario can be greatly improved with direct information site by site. Results show that the sys-tem has a great ability to detect events of a magnitude in the region of 3.5, with relatively low occurrences of false pos-itives. Earthquake detection mostly occurs within seconds of the event and far earlier than the notifications shared by INGV or by other official channels. Thus, we are able to alert interested parties promptly. Information discovered by our system can be extremely useful to all the government agencies interested in mitigating the impact of earthquakes, as well as the news agencies looking for fresh information to publish.
 H.2.8 [ Database Management ]: Database Applications X  Data mining ; K.4.1 [ Computers and Society ]: Public Policy Issues X  Human safety Design, Evaluation, Reliability Social sensing, social mining, decision support system, dis-aster management, event detection
Social Media (SM) is the most effective, sophisticated and powerful way to gather preferences, tastes and activities of groups of users in the context of Web 2.0 [23]. This amount of information generates an in-depth knowledge of one or more specific issues 1 . Therefore, SM users could be regarded as social sensors, namely as a source of information about situations and facts related to the users (e.g., their pref-erences or experiences) and their social environment [31]. Emergency Management is a promising field of application for Social Sensing since it is possible to exploit the content shared on SM to gather up to date information on emerging situations of potential danger. These techniques allow for the acquisition of greater situational awareness which can be used to promptly alert interested parties. In the case of an emergency or a disaster, critical information needs to http://beautifuldata.net/2013/01/social-sensors/ be urgently collected so as to speed up decision making by emergency services, advising affected people, and notifying government authorities. We refer to Early Warning Systems (EWS) as those information systems able to timely detect occurring events of social concern and thus able to deliver appropriate warnings [27]. By  X  X vent X  we mean a poten-tially dangerous situation that takes place in a finite period of time.

We aim to use spontaneous reports from users on SM as our source of information. Our focus is on reports about events causing social and safety concerns, such as natural disasters. This study is based on Social Networks (SN), a specific type of SM particularly suitable for hosting this kind of analysis. The reason for this choice is due to the large number of users involved in SN and their high level of interaction. The advantage of exploiting SN compared to traditional methods of investigation lies in the sponta-neous participation of the users, in that their contribution is made without pressure or influence from others. Twitter is particularly suitable as a source of data for social sensing platforms. This is due to the fact that its users generally talk about what they are doing, and therefore what is hap-pening around them. Analysing messages shared by Twitter users is a good way to quickly obtain details of the impact of the event.

In this paper, we will focus on reports related to earth-quakes in Italy. In the Euro-Mediterranean region Italy is one of the countries with the highest seismic hazard together with Greece and Turkey. In Italy, the relationship between the damage caused by earthquakes and the energy released is much higher than in other countries with high seismicity, such as California or Japan. This is mainly due to the high population density and the considerable fragility of italian artistic and monumental heritage 2 . As suggested in [24], the highly seismic nature of Italy makes it one of the best countries where to carry out a study on the detection of earthquakes based on Twitter data. In addition, the grow-ing use of Twitter during the last few years seems to favour a successful study (in 2013 active users increased by 40% in the world and 50% in Italy [25]).

The National Institute of Geophysics and Volcanology (INGV) is the reference scientific institution of the Italian Civil Protection for seismic and volcanic risks, as it has over-all responsibility for seismic and volcanic monitoring in Italy. On the basis of specific agreements, it is in charge of de-tecting and communicating the occurrence of earthquakes. In addition, a protocol exists which indicates which actions must be carried out by INGV at 2, 5, 10 and 30 minute intervals after the earthquake according to the magnitude of the event. In the case of an earthquake with magnitude equal to or greater than 4, one of the products to be released is the so-called ShakeMap. A ShakeMap is an estimation of the shaking level distribution in the epicentral area in terms of peak ground-motion parameters and of instrumentally de-rived intensities. The application of a ShakeMap is the iden-tification of the area where damage is probable in order to define where to concentrate the rescue teams and organize a prompt emergency response. The model is constrained with real observations coming from seismic stations connected in real-time. The limited number of stations in Italy does not allow to obtain an accurate indication of the real shaking. http://www.protezionecivile.gov.it/jcms/en/homepage.wp As a result, the opportunity to check whether damage has in fact occurred is limited. The integration of seismic sta-tion data with information discovered from social sensors will increase the number of  X  X tations X  and the reliability of a ShakeMap. This could help the Civil Protection to better evaluate the type and the degree of assistance required in the earthquake-stricken area.

The system described in this paper is aimed at provid-ing a valuable decision support tool for INGV researchers and analysts. Our objective is to leverage experiences de-scribed in previous works in order to design and imple-ment a system for the detection, alerting and assessment of the consequences of earthquakes. We plan to integrate the EARS (Earthquake Alert and Report System) platform with the other tools that INGV already exploits such as the ShakeMaps. Information discovered with this system can be used to acquire a greater and more fine-grained context awareness during earthquake emergencies. It can help model damage scenarios with fresh data automatically collected site by site and exploit on-the-ground community knowledge which would be otherwise inaccessible.

The remainder of this paper is organized as follows: Sec-tion 2 describes the related work. Section 3 details our de-sign and implementation choices, Section 4 describes the frontend application. Section 5 describes the results of our study and Section 6 draws the conclusions and describes fu-ture work.
Several initiatives, both in scientific and in application en-vironments, have been developed with the aim of exploiting information available on SM. Anyway despite the interest in the fields of crisis and emergency management, to date the task of the automatic assessment of the consequences of disasters has not been studied yet. To the best of our knowledge previous works have only focused on the event detection and information dissemination tasks. In literature descriptive and general approaches are opposed to practical, sector-based experiences.
In [3] we highlighted the lack of a comprehensive approach to the problem of emergency management on SM. We de-scribed an architectural approach, we designed the compo-nents necessary for an event detection system and finally we evaluated the feasibility of the proposed solution. In [3] we did not address implementation and deployment challenges but the promising results we have achieved paved the way for the design and deployment of the EARS system which is discussed in this paper.

Researchers in [24] and [25] had the goal of creating an early warning system (EWS) for the real-time detection of earthquakes and tornadoes in Japan based on bayesian statis-tics. The proposed system was able to timely detect 67.9% (53 of 78) of the earthquakes with JMA (Japan Meteorolog-ical Agency) scale 2 or more which occurred in two months. In these works data acquisition is performed via the Twit-ter Search API 3 which accesses only a portion of all the tweets produced. This limitation can be negligible for large scale events but can impair event detection for events felt by a small number of social sensors. As described in Sec-https://dev.twitter.com/docs/api/1.1/get/search/tweets tion 3 our approach to the data acquisition exploits the Twitter Streaming API 4 which delivers all the tweets pro-duced worldwide that match the search criteria. Moreover the system described in [24] and [25] only focuses on the event detection task.

In [9] is described another system for the detection of earthquakes based solely on Twitter data. Again data ac-quisition is performed via the Twitter Search API and has the same limitations previously described. The system is evaluated with different settings according to the sensitivity of the event detection module. However, even with its best configuration the system could only detect 48 globally dis-tributed earthquakes out of the 5,175 earthquakes reported during the same time window by the USGS.

The SMART-C project [1, 2] describes a high level, multi-modal framework for emergency detection and alert dissemi-nation. The proposed solution is capable of collecting and in-tegrating data from different sources such as SN, blogs, tele-phone land line communications, SMS, MMS. The project aims to improve two-way communications between the emer-gency response personnel and the population. Unfortunately the work presented in [1, 2] mainly focuses on architectural and privacy issues without dealing with the implementation and deployment of the proposed solution.

Other works related to the emergency management have studied communication patterns and information diffusion in SN in the aftermath of disasters. The study described in [7] shows how SN can be used as a reliable source of spatio-temporal information. Researchers investigate Twit-ter activity during a major forest fire in the south of France in July 2009. Other similar studies have been carried out in [8, 14, 18] showing the importance of SN in the commu-nications after a disaster. These studies encourage the ex-ploitation of this information and motivate the development of systems such as the one that we are proposing.

As a generic approach, we can mention the European ini-tiative Alert4All 5 . This project aims to create a framework to improve the effectiveness of warning messages and com-munications with the population in case of disasters at pan-European level. Again the focus is on the role of SM in the emergency communications [15, 19].
Together with the scientific studies previously described, in the last few years there has been an increasing number of applications encouraging participatory sensing in the fields of urban management and personal safety. These applica-tions are mainly developed for mobile devices and allow users to share concise reports of civilian issues. Such tools gener-ally perform simple tasks, lack a solid scientific background and don X  X  employ techniques of information analysis. While a small number of these applications have become widely used in some cities or regions, the vast majority never man-aged to attract a significant user base. Moreover information shared on these tools is fragmented among the various ap-plications and cannot be exploited to acquire full knowledge about the reported issues.

One of the most interesting local initiatives is represented by Emergenza24 6 , the experimental version of the italian https://dev.twitter.com/docs/streaming-apis http://www.alert4all.eu/ http://www.emergenza24.org/  X  X ocial Network for Emergency Management X . This plat-form exploits a dedicated Twitter account to gather sponta-neous reports of emergencies in Italy. Although reports di-rected to Emergenza24 are fairly common, it is clearly stated in the official website that only messages with a specific syn-tax are automatically captured. In Section 3 we highlight how the vast majority of emergency reports do not follow any specific format or syntax and often present grammati-cal mistakes or slang words. We believe that this poses a serious limitation to the effectiveness of the initiative. Simi-larly, the italian SMEM platform (Social Media Emergency Manager) 7 tried to promote the use of the #smem hashtag to report emergencies or other social issues. This initia-tive did not receive much interest by Twitter users and was aborted in 2012.

Authors of [5,29] describe a system to improve situational awareness during emergencies in Australia. The proposed system is interesting, but [5, 29] lacks an in-depth explana-tion of the methodologies adopted and any kind of system evaluation. The SHIELD system [26] exploits wi-fi and blue-tooth technologies to track the frequency and duration of encounters between users of the application. SHIELD ex-ploits this information to infer the trust level between users. The system automatically selects a set of users to call with the aim of reducing the response and rescue times for vic-tims of micro-criminality in the U.S. university campuses. Although proximity-based applications can be very effective for small scale events, this approach is hardly applicable to the field of earthquake emergency management.
In this section, we discuss the EARS system as shown in Figure 1. The system X  X  architecture is derived from the studies we carried out in [3]. Here we turn our attention to the implementation and deployment issues and we discuss decisions and trade-offs made when making design choices for the EARS system. The main components of the EARS backend system are described in the remainder of this sec-tion. The web application frontend is discussed in Section 4.
The role of this module is very important because the sys-tem only operates on data collected in this phase. Errors at this stage, especially regarding the loss of data, have to be minimized since they will propagate throughout the system thus impairing the ability to detect events. The data acqui-sition module must meet both data completeness and data specificity requirements. This clearly represents a trade-off between the number of messages gathered and their rele-vance to the earthquake detection and damage assessment tasks. Although this module does not perform any analysis on collected data, it is possible to overcome this trade-off by fine-tuning the keywords used to collect data.

In order to select the best set of keywords we started mon-itoring terms reported in the literature [24], [9], [3] together with other words related to earthquakes in the italian lan-guage. We progressively restricted the initial set of 9 key-words by eliminating the ones that did not show a correla-tion between their frequency of usage and the seismic events reported by INGV. We discarded those keywords, such as  X  X rollo X  (wreckage) and  X  X repa X  (crack), specifically related http://www.socialmediaemergencymanager.com to the damage assessment task; those keywords, such as  X  X isma X  (seism) and  X  X agnitudo X  (magnitude), that are often used in official communications rather than in spontaneous user reports; and those keywords, such as  X  X rema X  (shakes) and  X  X remando X  (shaking), that are too generic and therefore not specifically related to earthquakes. The keyword fine-tuning process lasted roughly two months. At the end of the process we concluded that the most selective italian words to collect tweets about ongoing earthquakes are  X  X erremoto X  (earthquake) and  X  X cossa X  (tremor). It is worth noticing that our set of keywords for earthquake detection differs from the sets used in [24] and [9]. Even though the keyword selection process in previous works is not thoroughly detailed, we can conclude that the best keywords for the event detection task are language specific. We believe that this poses a limitation to the possibility to easily redeploy this kind of systems to other regions of the world.

Among the methods provided by Twitter for information extraction, the EARS system exploits the Streaming API to open a persistent connection with a stream of tweets. By us-ing this connection, new tweets containing the selected key-words can be collected. In contrast with the Search API used in the studies described in [24] and [9], which gives access only to a subset of all the tweets produced, the Streaming API potentially makes it possible to capture all the tweets matching the search criteria.

A limitation can arise considering that, as the connection can potentially access the entire flow of tweets produced in the world, Twitter delivers at most 1% of the total traffic and automatically cuts off the excess. However, our system never suffered from such a limitation over the seven month period it was used. To guarantee the robustness and the reliability of the system we also implemented additional mechanisms that manage rate-limit and generic connection problems in the use of the APIs.
Using keywords to query Twitter makes it possible to gather messages potentially related to an event. However, not all the messages gathered in this process relate to an on-going earthquake. Some messages can be misleading for the event detection module and must be filtered out as noise [9]. By noise we refer to the messages containing the query key-words but which are not related to the type of event to de-tect. In [3] we have identified two different sources of noise: (i) messages in which the keyword is used with a different meaning from the one related to the searched event and (ii) messages in which the keyword refers to a past event. Exces-sive levels of noise in collected messages lead to false detec-tions by the system. However filtering too much may result in the loss of useful messages and thus in the impossibility to detect important events. Therefore this task presents an-other crucial trade-off related to the accuracy of the filtering process. In EARS we overcame this trade-off by employing data mining techniques.

Our system performs data filtering by cleaning data in 2 steps. A pre-filtering phase applies raw rules to discard tweets that clearly do not refer to an ongoing seismic event. Tweets not discarded in the pre-filtering phase are then an-alyzed with data mining techniques to perform a more fine-grained selection. Studying the characteristics of the mes-sages shared on Twitter in the aftermath of seismic events lead us to the observation that genuine reports of earth-quakes do not follow any information diffusion model and are not influenced by other reports. This scenario rapidly evolves over time as the news of the earthquake spreads over the different medias and subsequent reports are in growing percentage influenced by other news. We concluded that the best results for the event detection task could be achieved by considering only spontaneous and independent messages. Following these guidelines we created a set of rules to apply during the pre-filtering phase. This means that EARS dis-cards retweet messages, reply messages and messages shared by accounts belonging to a blacklist of 345 Twitter pro-files that periodically publish information about past seismic events.

During the implementation and deployment of the system we also faced a challenge because the keyword  X  X erremoto X  means earthquake not only in italian but also in spanish and portuguese. Twitter natively provides a language detection mechanism that EARS exploits. Unfortunately Twitter lan-guage detection follows a best effort approach and proved to be highly inaccurate [12]. This initially lead our system to produce false detections based on messages in spanish and portuguese which contained the word  X  X erremoto X . To mitigate this issue in EARS we employ natural language pro-cessing techniques for the language detection and we discard those messages that do not appear to be in italian language.
Another possible flaw for all social mining systems lies in the vulnerability to intentional attacks performed by mali-cious users. Security concerns can arise if groups of people collude to generate fictitious tweets referring to an earth-quake. In [3] we discussed the problem and proposed a solution based on fake account detection in order to miti-gate the impact of such attacks. In the EARS system we exploit a classifier trained to distinguish between fake and real accounts [6]. The classifier has been trained on a set of 3900 equally distributed fake and real accounts and was able to correctly classify more than 95% of the accounts of the training set. We bought around 3000 fake accounts from 3 different sellers and randomly chose 1950 of them to be part of the training set. Similarly we created a set of 1950 verified real accounts by asking volunteers to fill a captcha or by manually checking them. The trained model is passed to the Weka tool [13] every time a new message is collected so as to infer the class (fake, real) of the user who posted it. Messages posted by fake users are automatically discarded by the system. In addition users repeatedly triggering false detections are added to the account blacklist. To further protect the system from harmful attacks we only consider for the event detection task a maximum of one message per user. In addition, messages which contain exactly the same text are only taken into consideration once. While we un-derstand that these solutions do not fully solve the problem of malicious attacks, we are confident that our efforts rep-resent a first response to security concerns in social mining systems. As a consequence of the adopted solutions poten-tial attackers are required to put more effort into the creation of plausible accounts.

After the pre-filtering phase, a more sophisticated filtering process is performed by a classifier that infers the class of a tweet starting from a trained model. Again we exploited Weka to train and generate our classifier. During the offline training phase the classifier has been trained using two dis-tinct sets of messages: tweets related and tweets not related to a seismic event in progress. Tweets of the training set were manually classified using an ad-hoc interface. Our anal-ysis on the messages reporting earthquakes has highlighted a few interesting characteristics that help distinguish between tweets related and tweets not related to an ongoing seismic event. Tweets referring to an earthquake are generally very short, they present fewer punctuation than normal tweets and often contain slang or offensive words. This is because people reporting an earthquake are usually scared about the event and the content of the messages they write tend to represent this situation. Instead, tweets referring to official news of an earthquake or talking about a past earthquake present a longer, more structured message. Tweets not re-lated to a recent earthquake also include a higher number of mentions and URLs than spontaneous earthquake reports. Thus we defined the following set of features that takes into account the results of the previous analysis:
Training the classifier with this set of features produced correct classifications in more than 90% of the tweets of the training set. The classifier was obtained using the decision tree J48, corresponding to the Java implementation of the C4.5 algorithm [22] with a 10-fold cross validation [28]. The prediction is performed at run-time by invoking the classifier every time a message passes the pre-filtering phase. As Weka generally needs less than a second to predict the class of a new tweet, it is feasible to use the fine-grained classifier filter in the EARS real-time system.

Figure 2 shows the comparison between the numbers (y axis) of all collected tweets (Figure 2a) and the tweets that passed the filtering phase (Figure 2b) during a seismic event of low magnitude. The earthquake occurred in Modena, Italy, September the 4th, 2013 at 09.03 a.m. The blue plot is related to all the collected tweets. The green plot shows the tweets that passed the pre-filtering phase and, finally, the red plot represents the tweets after the filtering phase with the classifier. As shown in Figure 2 without an accurate filtering process it would have been difficult to notice the peak in the messages related to users reporting the earthquake. In fact reports for small scale events are usually overwhelmed by the number of noisy messages. In our experience the filtering process eliminated 88% of the collected messages.
The detection of an event is triggered by an exceptional growth in the frequency of the messages that have passed the filtering phase. The better the filtering phase the easier is the task of event detection. Event detection in social me-dia is a topic that has been widely studied in literature. To accomplish this task researchers in [24] exploit a temporal model based on bayesian statistics, the use of peak detec-tion algorithms is investigated in [17]. The work discussed in [21] introduces the concept of Corrected Conditional En-tropy (CCE) and shows how it can be exploited to detect irregularity in time series.

In our system we adopt a novel approach based on a burst detection algorithm. A burst is defined as a large num-ber of occurrences of a phenomenon within a short time window [30]. Burst detection techniques are commonly ap-plied to various fields such as the detection of topics in data streams. Our system triggers the detection of a seismic event when it identifies a burst of messages referring to an earth-quake. Figure 4 shows the arrival times of messages during an earthquake occurred at 00:09 a.m, August 27, 2013 in Umbria and Marche regional districts. After T1, the oc-currence time of the earthquake, a big burst of tweets was recorded by our system.

Works in [10], [32] and [16] discuss various burst detection algorithms. In EARS we chose to employ a simplified ver-sion of the hierarchical algorithm proposed in [10] since it is computationally light and can adapt well to both big and small bursts. An efficient algorithm is necessary because of
Figure 4: A burst of tweets registered after an earthquake the real-time nature of our system and the ability to detect both big and small bursts fits well with the need to identify large scale and small scale events.

The detection of a burst is based on the calculation of the frequency ( C freq ) of messages in a short-term time window. Assuming L SW = Length of the short-term time window and N SW = Messages in the last short-term time window , then: A burst is detected when such frequency exceeds a given threshold T h . The threshold to trigger a burst depends on a reference frequency ( R freq ) calculated over a long-term time window. Assuming L LW = Length of the long-term time window and N LW = Messages in the last long-term time window , then: The size of both the short and long time windows along with the threshold represent implementation trade-offs and are closely linked to the characteristics of the events to de-tect. Shortening the short-term window makes the system respond faster since less time is required to detect a burst. However it also limits the possibility to detect events that receive a small number of reports. Widening the short-term window increases the number of events detected by the sys-tem since it is easier to reach the threshold over a longer period of time. Anyway it also exposes the system to more false detections and increases response times. Similarly, low-ering the threshold allows for the detection of smaller scale events but also increases the risk of false detections.
During the fine tuning phase of the system we tried differ-ent combinations of settings. We achieved the best results with the following settings: Setting a minimum threshold of only 3 messages per minute greatly increases the sensitivity of the system. As discussed in Section 5, this setting allowed EARS to detect 100% of the earthquakes with a magnitude of 3.5 or more reported by at least one user.
Damage assessment (DA) is the process that allows emer-gency management personnel to determine the impact and the consequences of an emergency on communities and in-frastructures. Typically, the DA process takes place in the aftermath of an emergency and involves specialized person-nel who assess the consequences by visiting the location of the event. EARS exploits information shared by people di-rectly involved in the event to automatically perform this task without the need to transport personnel over the vari-ous potentially damaged locations.

Every new message collected after the detection of an earthquake is associated to the event and contributes to the creation of a corpus of reports. As the event unfolds, the system repeatedly analyzes the growing corpus of reports to extract valuable information from it. Among the infor-mation that EARS is capable of extracting are coordinates and toponyms of locations and emerging n-grams. Loca-tions mentioned in the reports are most likely places struck by the seismic event. To accomplish this task we make use of TagMe, a service of text annotation and disambiguation developed at the University of Pisa [11]. This tool can be specifically set to work with tweets and outputs a list of tags with the description of the terms and other related informa-tion. We then extract the coordinates associated to the to-ponyms disambiguated by TagMe via SPARQL [20] queries to DBpedia [4]. To further expand the set of messages as-sociated to an earthquake the system automatically opens a new streaming connection to Twitter servers. We exploit this adaptive connection to collect messages produced in or mentioning the possible locations struck by the earthquake. This augmented message corpus is used to perform the dam-age assessment task by mining both the textual descriptions and the multimedial content retrieved (eg: videos, photos).
EARS is a decision support tool designed for INGV re-searchers and analysts. Its web frontend enables temporal, geographical and content analyses both at event and mes-sage level.

Figure 3 contains a screenshot of the web application show-ing a chronologically ordered summary of events of interest. Events detected by EARS are listed on the right hand side of the screen while events reported by INGV are listed on the left hand side. This screen allows for a quick evaluation of the system behavior by highlighting confirmed and uncon-firmed events. Specifically, a red background is associated to events reported by INGV but not detected by EARS, an orange background is associated to events detected by our system but not yet confirmed by INGV. Finally a green background is associated to events detected by EARS and confirmed by INGV. Every listed event, both confirmed or unconfirmed, can be expanded in another window showing all the details associated to it.

The event details window is organized in three views:
The temporal view, shown in Figure 7, contains a graph of the message frequency over time. The red colored area in the graph identifies the event duration as estimated by EARS. This is not the duration of the physical event but in-stead the time interval in which the system collects relevant messages for the event itself. This temporal view immedi-ately indicates the number of relevant messages and their distribution over time.

The geographical view displays a map of the region af-fected by the event. The map contains a red marker for the epicenter of the event and a small green marker for each geocoded message. Geocoded messages include both mes-sages carrying Twitter GPS data and messages geocoded by EARS as explained in Section 3.4. Beside the map a time slider allows to reproduce the evolution of the event from its detection time to its end. Moving the slider X  X  handle af-fects information displayed in the geographical and messages views. This component shows the geographical distribution of collected messages as the event evolved in time. It also lists the the messages collected during the  X  X ifespan X  of the event. Figure 5 shows an analysis of the spatio-temporal evolution of the earthquake that struck Caserta and Ben-evento the 20 th January 2014.

The message view provides a chronological ordered list of the relevant messages collected by EARS. Every message is described by its time of creation, the author X  X  username and its textual content. Multimedia content is automatically displayed inside the message box. In addition an icon high-lights geocoded messages. Clicking on the icon highlights the selected message in the map provided by the geographi-cal view. Viceversa clicking on a marker in the geographical view shows the content of the related message. Figure 6 shows an excerpt of the messages view. In addition to the chronological list of messages, this view contains a list of the most used n-grams and a list of the most used anno-tated tags. These two lists are extracted from the whole corpus of messages associated to an event.
Together with the EARS system we have developed a sim-ulator designed to read and analyze data already collected by our real-time application. The advantage of using this simulator lies in the possibility to progressively tune the system and rapidly test it against already collected data. This approach also makes it possible to evaluate our system with stronger metrics than the ones used in other similar works [24, 25], [9] and [5, 29].

The evaluation dataset consists of all the messages col-lected by EARS over a 70 days period. By using the simula-tor we were able to analyze the whole evaluation dataset in less than 3 hours. The simulator performs the same analy-ses as the EARS system and in addition outputs a report of the performance of the system. For the system evaluation we exploited official data published by the National Insti-tute of Geophysics and Volcanology (INGV), the authority responsible for monitoring seismic events in Italy. INGV uses different channels, including Twitter, to distribute de-tailed information about seismic events having magnitude 2 or more, which have been detected by their equipment. We cross-checked the events detected by the simulator against the official reports provided by INGV. We classified earth-quake detection results as in the following: True Negatives are meaningless, as it would mean counting the number of earthquakes that did not happen and that our system did not detect.

We also computed the following evaluation metrics:
Table 1 summarizes event detection evaluation against all the earthquakes registered by INGV from 2013-07-19 to 2013-09-23.

Results show that the detection of earthquakes with mag-nitude lower than 3 is very difficult. This is because the majority of these earthquakes are only detected by equip-ment and not by people. For events with a magnitude equal to or greater than 3 . 5, results show a good performance of the system in terms of F-Measure. This is especially signif-icant given that seismic events of a magnitude around 3 are generally detected only by a very small number of people. In our study, for such earthquakes we always registered less than 10 tweets per event.

As the ultimate goal of the EARS system is to assess the consequences of earthquakes, light seismic events only de-tected by seismographs clearly do not pose any threat to communities and infrastructures. Earthquakes of interest are those actually felt by the population at large. There-fore we re-evaluated the system against those earthquakes that generated at least one report on Twitter. Results are displayed in Table 2 and show an overall improvement in the system performances. It is worth noticing that EARS achieves flawless results for earthquakes of magnitude 4.0 or more and also performs very well on earthquakes which have a magnitude in the region of 3.5.
EARS (Earthquake Alert and Report System) is a deci-sion support environment for earthquake crisis management deployed for INGV researchers and analysts. The proposed system can clearly provide useful information on the conse-quences of seismic events. Such information is inferred from on-the-ground social sensors seconds after the detection of an earthquake. EARS can be integrated with other already established systems in order to help identify the areas where damage is probable. Information discovered by this system helps define where to concentrate the rescue teams and or-ganize a prompt emergency response.

In Section 3 we discussed the design, implementation and deployment challenges faced during the development of EARS. These challenges are common to the majority of social min-ing systems even though they are not fully addressed in sim-ilar works. We proposed technical solutions for the most relevant issues which emerged from our work. Results sug-gest the effectiveness of such solutions although we are aware that further improvements may lead to even better perfor-mances. Among the issues we discussed is the problem of security. To the best of our knowledge EARS is the first emergency management system to employ security mecha-nisms in order to deter and minimize the effect of malicious attacks. Although we understand that these mechanisms are not sufficient on their own, we believe that they represent a good starting point towards addressing security issues of such applications. False detections are probably the most critical issue of EARS and require further investigation and effort. We manually verified that language detection prob-lems have been the cause of several false detections by the system. These problems are primarily caused by Twitter X  X  best effort language detection approach and by the limited length of tweets. We adopted a solution based on natural language processing but we plan to exploit user account in-formation as well to further improve the detection. Other problems contribute to the number of false detections reg-istered, the vast majority of which is related to mistakes in the data filtering process.

Over the past seven months we have been developing and testing the EARS system against earthquakes reported by INGV. During this period of time none of the earthquakes that struck Italy have caused serious consequences on com-munities or infrastructures. The highest magnitude regis-tered since July 2013 was 4 . 9 degrees when two earthquakes struck Ancona and Macerata on the 21 st of July 2013 and Caserta and Benevento on the 29 th of December 2013. De-spite the lack of significant data reporting injuries to the population or damages to the infrastructures we have de-veloped a system capable of inferring the consequences of earthquakes. However access to historical Twitter data, es-pecially related to the earthquakes in Emilia Romagna in 2012 and L X  X quila in 2009, could prove crucial for future improvements in the damage assessment area. For this rea-son we are looking forward to the upcoming Twitter Data Grants program for research 8 .

In the future we will apply our system to other contexts such as wildfires, traffic jams, landslips and floods. We also plan to experiment with other sources of data like Facebook public posts and Google search activity data. [1] N. Adam, J. Eledath, S. Mehrotra, and [2] N. R. Adam, B. Shafiq, and R. Staffin. Spatial https://engineering.twitter.com/research/data-grants [3] M. Avvenuti, S. Cresci, M. La Polla, A. Marchetti, [4] C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, [5] M. A. Cameron, R. Power, B. Robinson, and J. Yin. [6] S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, [7] B. De Longueville, R. S. Smith, and G. Luraschi. [8] P. Earle, M. Guy, R. Buckmaster, C. Ostrum, [9] P. S. Earle, D. C. Bowden, and M. Guy. Twitter [10] R. Ebina, K. Nakamura, and S. Oyanagi. A real-time [11] P. Ferragina and U. Scaiella. Fast and accurate [12] S. Hale, D. Gaffney, and M. Graham. Where in the [13] M. Hall, E. Frank, G. Holmes, B. Pfahringer, [14] A. L. Hughes and L. Palen. Twitter adoption and use [15] F. Johansson, J. Brynielsson, and M. N. Quijano. [16] J. Kleinberg. Bursty and hierarchical structure in [17] A. Marcus, M. S. Bernstein, O. Badar, D. R. Karger, [18] A. Murakami and T. Nasukawa. Tweeting about the [19] S. Nilsson, J. Brynielsson, M. Gran  X asen, C. Hellgren, [20] J. P  X erez, M. Arenas, and C. Gutierrez. Semantics and [21] A. Porta, G. Baselli, D. Liberati, N. Montano, [22] J. R. Quinlan. C4.5: programs for machine learning , [23] A. Rosi, M. Mamei, F. Zambonelli, S. Dobson, [24] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake [25] T. Sakaki, M. Okazaki, and Y. Matsuo. Tweet analysis [26] G. S. Thakur, M. Sharma, and A. Helmy. Shield: [27] N. Waidyanatha. Towards a typology of integrated [28] I. H. Witten and E. Frank. Data Mining: Practical [29] J. Yin, A. Lampert, M. Cameron, B. Robinson, and [30] X. Zhang and D. Shasha. Better burst detection. In [31] A. Zhou, W. Qian, and H. Ma. Social media data [32] Y. Zhu and D. Shasha. Efficient elastic burst detection
