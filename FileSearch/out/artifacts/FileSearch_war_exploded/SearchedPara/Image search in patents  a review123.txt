 ORIGINAL PAPER Naeem Bhatti  X  Allan Hanbury Abstract To verify the originality of an invention in a patent, the graphical description available in the form of patent drawings often plays a critical role. This paper intro-duces the importance, requirements, and challenges of a patent image retrieval system. We present a brief account of the work done in the specific and related areas of the patent image domain. We begin with a review of work done deal-ing specifically with retrieval and analysis of images in the patent domain. Although the literature found dealing with patent images is small, there is a significant amount of work that has been done in related areas that is useful and applica-ble to the patent image area. From a methodological point of view, we present an overview of the algorithms developed for the retrieval and analysis of CAD and technical drawings, diagrams, data flow diagrams, circuit diagrams, data charts, flowcharts, plots, and symbol recognition.
 Keywords Patent images  X  Technical drawings  X  Diagrams  X  Data charts 1 Introduction A patent is a complex legal document which is granted by a state to allow an inventor a monopoly in exploiting an inven-tion for a fixed period of time in return for public disclosure of the invention. With the growing technological advancement, large numbers of patent applications are being submitted to patent offices worldwide. In a patent, the inventor describes the innovation using textual as well as graphical descrip-tion. The graphical description in a patent filing can include technical drawings, figures, diagrams, data flow diagrams, flowcharts, plots, and graphs.

In order to confirm the novelty of a newly submitted patent application, the inspection of visual contents contained in the patents is becoming overwhelmingly important. This is because the technological specifications are more appropri-ately demonstrated by technical figures in many domains. The potential benefits and the crucial role which the non-textual elements in a patent can play in patent search are described in [ 1 ]. To make the patent examination on the basis of graphic images more effective, a system for image search in patents is a natural requirement. The use of visual con-tents in the retrieval systems for patents is becoming even more important because the often inconsistent and rapidly changing terminology in emerging technology leads to some related documents being unfindable by the systems which only take textual cues into account. To take into account, the visual information of the graphical objects with textual information can overcome the limitations introduced by ter-minology inconsistency, as similar technical drawings could be retrieved despite their transformations in scale, transla-tion, rotation as well as affine transformations. The lack of systemic efforts to develop a patent search tool exploiting the visual contents are discussed in [ 53 ]. The potential benefits of including the visual content information in a patent search system can be in the form of increased efficiency as well as accuracy in retrieving related patents. The recall perfor-mance of the system could also be increased, which would be helpful in avoiding potential infringement-related issues.
Besides the potential benefits of a patent image retrieval system, the research challenges involved in the development of such a system should also be identified. Almost all patent images are bi-level images (black and white), colorless, and mostly textureless with the exception of some low-texture patent images. A few examples of patent images are shown in the Fig. 1 . The existing content-based image retrieval (CBIR) techniques mostly exploit the color and texture features of the images [ 18 , 80 ], which make them less useful in the patent image domain. The technical information in patent images is depicted using geometric shapes and their spa-tial arrangements. To capture the contents in patent images, shape information, geometric as well as spatial relationships between geometric structures will be the target information to be explored.

Comprehensive surveys of the work done in the general content-based image retrieval domain are available [ 18 , 80 ]. The aim of this paper is to introduce the importance, require-ments, and challenges of a patent image retrieval system, as well as to provide a historical account of the work done in the specific and related areas of the patent image domain. Although the literature found dealing with patent images is small, we begin by an overview of the work done specifically for patents. However, there is a significant amount of work that has been done in related areas, which could be useful if applied to the patent image area.

The requirements and challenges of a generic patent image retrieval system are briefly overviewed in Sect. 2 . The key approaches and techniques developed for patent image retrieval are discussed in Sect. 3 . The large amount of work done in areas related to patent figures such as CAD and technical drawings, diagrams, graphs, plots (2D plots, 3D plots), tables, data charts, and symbol recognition is dis-cussed in Sect. 4 , and a conclusion is drawn in Sect. 5 .A short version of this paper was published in the PaIR 2011 workshop [ 32 ]. 2 A patent image retrieval system Given the importance of image search in patent documents as explained in Sect. 1 , an efficient patent image retrieval (PIR) system is of great importance to patent experts to make patent search more targeted and hence to consume less effort and time. It will help to deeply understand the content of a filed patent document, to examine the images contained in it (with the help of visual contents and comparison with the retrieved visually similar images), and to find its relevant patent docu-ments. Embedding the visual search capability into a patent search system that is based on textual data only can increase the precision without compromising recall performance of such a system [ 53 ].

Vrochidis et al. [ 90 ] have presented some requirements for the architectural design of a PIR framework. Based on the objective of a PIR system (discussed above), a set of requirements and challenges defined for a generic PIR system is presented:  X  Full-image search. A PIR system should be able to  X  Sub-image search. Considering a patent image com- X  Category-based image search. The category-based  X  Rotation, scale and affine invariance. To get high recall  X  Run time performance/scalability. Due to the millions  X  User adapted search/relevance feedback/on-line  X  Semantic-level interpretation of the images. Asystem The architecture of a PIR framework based on the aspects described above as the requirements and challenges of a generic PIR system is proposed in Fig. 2 . Each of the func-tional aspects of the PIR framework can be implemented by developing sophisticated techniques to meet the require-ments and challenges set for it. 3 Specific methods for patent images Most of the developed patent search systems use textual and metadata information. Very little published work is available on image search in patent databases. A patent search system PAT V I S [ 43 ], which is an enhanced version of PATExpert [ 91 ], was developed by Koch et al. The system integrates vari-ous search facilities including full text search as well as image similarity search based on the vector space model; however, the implementation details of the patent retrieval sub-system based on images are not given. In the domain of intellectual property, most of the technological advancement is seen in the area of trademark search [ 21 , 38 , 48 ] and computer-aided design and technical drawings domain [ 26 , 28 , 35 , 55 , 81 , 87 ]. Targeting trademark retrieval, van Leuken et al. [ 48 ] capture the spatial layout of the closed shapes identified from the con-stant curvature segments of the trademark images. Taking a review of the existing trademark search techniques, Schietse et al. [ 75 ] discuss the practice and challenges in trademark image retrieval. Treating only patent image search, few works [ 17 , 37 , 86 , 90 , 99 ] are available. We give a short overview of each of these in the following. 3.1 Relational skeletons A patent image retrieval system using only the image con-tents was developed by Huet et al. [ 37 ] in 2001. It employed relational skeletons as the main approach. As a first step, to capture the geometric structure of the images, Voronoi skeletonization is used to extract line patterns in the image. A polygonization technique is employed to create line seg-ments (sub-lines) from the line patterns.
The two main relational features  X  X elational angle X  and  X  X elation position X  are calculated for a line in relation to another line. Furthermore, the pairwise attributes based on these two main attributes are calculated as shown in Fig. 3 . Two retrieval algorithms are employed in the system: Graph based retrieval and Histogram based retrieval:  X  In graph-based retrieval, to increase the influence of local  X  In the histogram-based retrieval, a 2-dimensional his-The experimental evaluation is performed on an EPO data-base, in a window of 30 best results the similar images to the query are counted. The recall measure is used for performance evaluation. An average result over 57 queries on a database of 180 patents is shown, where the graph-based retrieval is the best performer in full image as well as sub-image search. The total time for a query is not reported explic-itly; however, the authors mention a  X  X onsiderable amount of time X  which depends upon the size and complexity of the images taken for comparison. 3.2 Edge orientation autocorrelogram (EOAC) A content-based image retrieval system for a US patent data-base, PATSEEK, was developed by Tiwari et al. [ 86 ]. The system provides a graphical interface for the user, where the user can provide keywords which must be contained in the patents to be retrieved. An image grabber is employed in the system, which grabs the image pages from the pages obtained by keyword search in the patent database. Images are segmented from the image pages and are stored in the database, and the feature extraction is done. Image segmen-tation is performed based on the connected components or blocks approach. In the next step, Canny edge detection is performed on each image, and the edges having less than 10 % of the maximum possible intensity are discarded. The gradient of edges IS quantized to 36 bins with 5 degrees each. A matrix is formed with 36 rows and 4 columns where each element indicates the number of the edges having similar ori-entation. The L1 and L2 distance measures are employed for similarity matching, 200 images are used for evaluation, and 100 % recall rate is reported for 9 out of 15 queries and 32 % for the rest of the images; however, the number of returned images is not given. A shortcoming of this approach is the total time for a query, which is reported as about 90 seconds. Further, the approach involves critical user-defined angle and amplitude thresholds for edge similarity and a threshold for nearest neighbor search. 3.3 Contour description matrix A patent image retrieval system was developed specifically dealing with design patent images. A design patent is a US patent granted on the ornamental design of an item. The sys-tem is based on a contour description matrix approach and was developed by Zhiyuan et al. [ 99 ] in 2007. First, each image is transformed to gray scale and Canny edge detection is performed to extract contour information. A shape center is found in the image to form a polar axis and convert each edge point to a polar coordinate system. To capture the radial and angular distribution information in the image, the approach divides the image into grids with r and  X  range specifications. In each grid, a ratio between edge points to all the points is calculated which forms the elements of a contour descrip-tion matrix. Each point of the matrix is a function of r and Euclidean distance is used for similarity calculation, and the approach introduces a parameter to give preference weight-ing to the radial as well as angular information. The evalua-tion experiments are performed for more than 2,000 design patent images, and performance curves are shown relating to recall as well as precision rates. However, the number of images returned and the time taken for one query are not reported. 3.4 Adaptive hierarchical density histogram (AHDH) In an attempt, to exploit the local as well as global con-tent information in patent images, Vrochidis et al. [ 90 ] proposed a framework called PATMEDIA in 2009. The framework allows hybrid query submission as text based, content based, and concept based (retrieval of images that depict the concepts of technological domain of interest). However, the content-based patent image search is the main functionality of the developed framework. To capture the content of patent images, the approach calculates the adap-tive hierarchical density histogram. The main idea is to cal-culate the distribution of black pixels on the white plane. The method calculates the density estimation at local as well as global level. The approach involves a pre-processing stage to reduce noise and to normalize the image. It calculates the centroid of image plane, divides the image plane into four regions based on the centroid, and calculates the distribution of black pixels in each region which will be the local density estimation. The system follows the query by example para-digm to implement the image retrieval. The approach uses the L1 distance measure to calculate the similarity between the query image and images from the database.

The experimental evaluation is performed using an EPO patent database. The 110 query images are chosen from a total of 2,000 patent images extracted from 200 EPO patents. Precision and recall metrics are used for performance evalua-tion. In the first experiment, an average result of 86.9 % for the manually identified visually similar images to a query image in the retrieved set of 25 most similar images is reported. In the second experiment, a distance threshold is employed to discriminate relevant from irrelevant images, and a 77.4 % recall rate for 49 % precision is reported. A total time of 1s for a query and concerning the scalability of the system a retrieval time below 10 s for 10,000 images are reported. A compari-son with PATSEEK [ 86 ] is also performed, and the compar-ison with the content-based functionality of the developed framework is shown to perform better as is clear from Fig. 4 .
Sidiropoulos et al. [ 78 ] extended the work in [ 90 ] by intro-ducing quantized relative density features. The hierarchical partitioning of an image is obtained by using the technique of adaptive hierarchical geometric centroids [ 95 ]. The parti-tions of an image are divided into higher and lower levels by an experimentally determined threshold for partition levels. For higher partition levels, the density features (distribution of black pixels in a sub-region) are computed. At the lower partition levels, a relative density feature defined by the den-sity of a sub-region compared to the ratio of the sub-region area over the region area is employed. The relative density feature is computed at the sub-regions and quantized to a lex-icon of 16 combinations which are obtained based on the four full or empty sub-regions (a sub-region is said to be full if the relative density feature value is  X  1 else empty) of a region. AHDHs are obtained by concatenating the density features and the quantized relative density features. Experimental evaluation is performed by using a publically available patent image database 1 containing 1,317 images. A performance comparison is presented with the approaches of the edge ori-entation autocorrelogram (EOAC) [ 62 ] and the adaptive hier-archical geometric centroids [ 95 ] where the AHDH reveals superiority on both of these approaches as shown in Fig. 5 . A downside of AHDH is that they are not capable of retriev-ing sub-images or image parts and are sensitive to rotation. 3.5 Fisher vectors-based patent retrieval Csurka et al. [ 16 ] proposed a Fisher Vectors-based [ 71 ] approach. They use SIFT-like local orientation histograms as low-level features and represent patent images using Fisher Vectors. The similarity between images is obtained by com-puting the dot product of two Fisher Vectors. To compare the set of images in a query patent with the set of images in prior art, two strategies mean (average distance of all pairs of images in the two sets) and max (maximum distance of all similarities on pair of images) are used. Secondly, a pre-classification of images by using an image-type classifier (based on the same Fisher Vectors representation) is inte-grated in the retrieval system, and the mean and max values are computed for the images predicted to belong to the same class. As a third approach, assuming the class of  X  X bstract drawing X  to be the most relevant for patent search, similarity computations are only performed for the set of images which are predicted to belong to this class.

The proposed Fisher Vector-based representations are evaluated in the image-based patent retrieval task of the CLEF-IP 2011 track. This task had a dataset of 23,444 patents containing 291,566 images to be indexed, and 211 query patents containing 4,004 images. The max strategy is found to perform always better than mean and to consider only the drawings class in patent retrieval is found as the best option for this task in comparison with not using classifi-cation and classification into all classes. The authors also proposed a text-based patent retrieval approach exploit-ing different fields (title, abstract, International Patent Classification-codes, citations) of the patent. Presenting a multi-modal patent retrieval system, they combine the pro-posed visual and text-based approaches using the weighted late fusion technique (stronger weight 20 for the textual approach and a weak weight 1 for the visual approach). The multi-modal patent retrieval results show that the visual information combined with the textual information always improves the results; however, the overall gain is small, being 1 % (compared to the textual information only) for both MAP (mean average precision) and NDCG (normal-ized discounted cumulative gain) measures. An interest-ing result is that a late fusion of a poor performing visual approach with the best text approach shows best patent retrieval results. It is shown that a retrieval system exploit-ing both the visual and textual information performs bet-ter than a retrieval system based on textual information only. 3.6 Indexing flower patent images using domain knowledge A flower patent is one of the few uses of color in patent images. The flower patent database contains flower images submitted as a part of application to patent a flower in the U.S. Patent and Trademark Office. Das et al. [ 17 ] proposed an indexing method for the flower database using the spe-cific domain (flower patent) knowledge. The developed sys-tem provides the facility to query as an example flower image and by using the name of the color of the query flower image. The authors developed an iterative segmen-tation algorithm to segment the flower from the background using domain knowledge. The color composition of the seg-mented flower is used as the feature for retrieval in the flower database.

The experiments are performed using a flower database of 300 images which includes: 100 images from the U.S. patents flower database, 100 images from CD-ROM col-lections with complex backgrounds, 100 images from cat-alogs of flowering plants, photographs, and colored fruits. Fifty queries of different types are tried with 25 queries by name and 25 queries by example. The average pre-cision obtained is reported as 88 %, and the precision is 66 % at the 100 % recall rate. The authors reported to have only two wrong segmentation results in the database of 300 images. 3.7 Discussion Regarding the proposed features of a generic PIR system, the approaches overviewed above (except the flower patent image approach, in this paper we emphasize binary images which are mostly contained in patent documents) are ana-lyzed in Table 1 . The Relational skeleton approach [ 37 ]uses line segments to represent the image, which makes it sensi-tive to the image transformations like rotations, translations, and scaling. The authors attempted to overcome its sensitiv-ity by computing the pairwise relations between lines but this could not be said to be perfectly dealt with, as the method is reported to perform reasonably well for some images and poorly for others. Also, the evaluation of the method is per-formed on 180 patents for 57 queries, which is a rather limited number of patent images.

PATSEEK [ 86 ] is independent of the image transforma-tions like translation and scaling. The approach is computa-tionally inexpensive as the size of the feature vector is small (144 real numbers). However, the approach uses two user-defined thresholds (angle and amplitude thresholds) making it scale variant. To deal with the rotation variations in patent images, PATSEEK provides an possibility to the user to spec-ify the rotation angle (between 0  X  and 180  X  ) for the query image. The major drawback of the system is its retrieval time which is about 90 s for a query.

The Contour Description Matrix approach [ 99 ]isinvari-ant to scale, translation, and rotation transformations of the images due to its usage of the shape center (center of the edge image) and encoding the radial and angular information in the image. The approach is developed specifically to deal with design patent images and needs to be explored or improved to deal with all kinds of patent images. There is no information given about the run time performance of the system; how-ever, the dimensions of the Contour Description Matrix are dependent upon the image resolution making it computation-ally expensive for the databases containing high-resolution images.

The AHDH approach [ 78 , 90 ] is evaluated involving a total of 2,000 patent images and reported to perform better than EOAC [ 62 ] and Yang X  X  Centroid [ 95 ]. The approach is com-putationally inexpensive due to the short feature vector (of length 140 at the partitioning level of 10) and could not be said to be scale invariant as it needs two thresholds to be manually set: the image partitioning threshold (set as 10) and the quantization level threshold (set as 3). The geomet-rical invariance is mentioned as the major drawback of the approach.
 Among all above-discussed approaches, the Fisher Vectors-based patent retrieval [ 16 ] is better evaluated using the 291,566 images provided by the CLEF-IP track 2011. The approach employed low-level features (SIFT-like ori-entation histograms) which are not rotation invariant and tried to tackle the rotation variances in images by artifi-cially rotating training images. The best results shown in the image-based patent retrieval task are obtained by con-sidering only images predicted to belong to the abstract drawings class; however, the selection of the abstract draw-ings class is based on intuition and is not tested against other classes individually. The Fisher Vectors representation classifies the patent images with high accuracy (approach-ing 91 %) but performs poorly in the image-based patent retrieval task. Moreover, combining the visual information with the textual information only improves the retrieval results by 1 % compared to retrieval by textual infor-mation only. The system incorporates a category-based classification module to restrict the similarity computa-tions to the images belonging to the same class, but an overall run time performance of the system is not reported.

Most of the approaches are not user adaptive and never tested extensively in large-scale databases. The sub-image search is seldom implemented (it is possible in [ 16 ]asitis based on local features but is not implemented in the system). The category-based search is missing in [ 37 , 86 ], and in [ 90 ], it is based on text of the caption, while it is not tested exten-sively in [ 16 ]. Semantic-level interpretation is not present in any systems. However, these approaches can be seen as an early attempt toward patent image retrieval. The miss-ing features and the few proposed approaches targeting PIR emphasize the need for research efforts in this field in an attempt to realize all the proposed features of a generic PIR system. 4 General methods applicable to patent images Patents contain different types of figures. The patent draw-ings ontology created by Vrochidis et al. [ 90 ]asshownin Fig. 6 specifies the five classes of figures that occur in patents: photo, diagram (including block, state, and circuit diagrams), flowchart, technical drawing, and graph. The automatic cat-egorization of figures into pre-defined types is an initial step to enable the patent retrieval system to use the content infor-mation in the retrieval process. In [ 90 ], the categorization of figures is achieved based on textual cues only which fol-lows the formal structure of figure categories given in [ 91 ], whereas in [ 61 ], the global features such as texture and geo-metrical features are taken into account to categorize the fig-ures based on their functionality in scientific documents. Lu et al. [ 60 ] propose a fully automatic system to classify the figures into pre-defined classes and to extract data from 2D plots. The system uses a supervised learning algorithm to classify images found in the documents into five pre-defined classes: photograph, diagram, 2D plot, 3D plot, and other (including pie chart, subfigures etc). The classification is achieved in a photograph and non-photograph paradigm; the non-photograph images are further classified into four cat-egories. First, the images are extracted using off-the-shelf tools, the global features (average gray level, block level texture features), and part features (a part of an image with special properties e.g., a line or a circle) [ 88 ] of the image are extracted. SVM [ 39 ] is employed for learning and clas-sification. Recently, for the patent image classification task of the CLEF-IP 2011 track (9 different categories of patent images), the Fisher Vectors-based approach [ 71 ] proposed by Csurka et al. [ 16 ] demonstrated a classification accuracy close to 91 % (with an EER less than 5 %) using a linear classifier.

Blostein et al. [ 7 ] presented a survey of techniques used in the development of a diagram recognition system and identi-fied the challenges as the diversity of the diagram types, the level of interpretation, noise presence, and the interpretation of diagram notations. The various approaches developed for diagram recognition are discussed, including blackboard sys-tems [ 20 ], stochastic grammars [ 12 ], Hidden Markov Models [ 44 ], kernel of recognition [ 70 ], and schema-based systems [ 40 ].

Even though there is little work done directly on image retrieval in patents, a large amount of work are available for figure types that are found in patents. Even though this work has been done for different applications, it is often equally applicable to patent image search. In the following sub-sections, we review work that has been done outside the patent domain on four of the five figure classes given in the Fig. 6 . Photo retrieval is not considered as there are already extensive reviews on photo retrieval [ 18 , 80 ]. 4.1 CAD and technical drawings The use of 2D drawings to specify the technical aspects of a design in the engineering fields has been the source of CAD and technical drawings production. To reuse and share the technical designs (CAD and technical drawings) from the designs, library is an important aspect to create new technical designs and requires the indexing and retrieval of the techni-cal drawings. Indexing and retrieval of the technical drawings using the textual cues only were explored in [ 4 , 13 ]; however, the use of drawing content information in the process has remained the main focus of the research community.

To m b r e [ 87 ] presents the state of the art in engineering drawing analysis dealing with lower level methods involved (such as segmentation, vectorization, recognition of basic graphical features, symbol recognition, and 3D reconstruc-tion) and states the related development achieved from a methodological point of view. The survey also describes applications and challenges in the field of engineering draw-ings analysis. The author has covered the main approaches published to the year 1998, so in this paper, we focus on the approaches presented in recent years. In the context of engi-neering drawing recognition, Cordella et al. [ 15 ] and Chhabra [ 11 ] consider symbol recognition. The authors present an overview of the related approaches with specific applications and discuss the open issues in the domain. In an attempt to exploit the graphical knowledge of objects found in engi-neering drawings, a number of approaches [ 59 , 93 , 94 ]have been proposed. Weber et al. [ 92 ], starting with the definition of a technical drawing (a line-based representation of scale of a part or assembly which consists of different views, slices and other additional information), give a detailed overview of the existing search techniques for technical drawings and proposes a procedure to deal with the problems (missing structure and different layouts of drawings) encountered in retrieval of technical drawings in DXF (Drawing Interchange Format). The author divides the existing approaches accord-ing to the format of the drawings they deal with pixel-based approaches and vector-based approaches. They state that the latter approaches should be used for a retrieval system.
We give a brief overview of the approaches described in [ 92 ] and other related approaches found in the literature, cat-egorized by the basic approach used in the following. 4.1.1 Topological information by modeling spatial Park and Um [ 68 ] partition the drawing into blocks and decompose the blocks into all possible constituent primitive shapes. The blocks are transfered to a graph structure, and the topological information is taken into account by mod-eling two types of spatial relationships: inclusion and adja-cency relations. Leung and Chen, working on retrieval of hand-drawn sketches [ 49 , 69 ], estimate shape types from each stroke using heuristics and exploit geometrical relationships for matching. They extend their approach further and extract a bi-stroke feature called a hyper stroke feature and exploit spatial relationship inclusion only with geometrical relation-ship between multiple strokes for matching.

Fonseca et al. [ 26 ], working on the idea of Park and Um, capture the topological information of the drawing by isolat-ing polygons and model the spatial relationships of polygons in the form of a topology graph. The topology graphs are described by graph spectra and stored in multidimensional vectors using an indexing structure called the NB-tree devel-oped earlier by Fonseca et al. [ 28 ], which supports indexing of vectors of variable dimensions. Moreover, the geometrical features such as area and perimeter ratios of a polygon are also captured to incorporate geometrical information into the matching phase. Fonseca et al. [ 27 ] extend their approach fur-ther working on retrieval of complex vector drawings using simple sketches as query. The approach simplifies the draw-ing by removing small-scale lines and polygons to get dom-inant shapes. To support partial matching, the graph spectra are computed at graph as well as sub-graph levels. The topo-logical information is captured by modeling the spatial rela-tionships at three levels: inclusion, adjacency, and disjoint as shown in the Fig. 7 . Sousa et al. [ 82 ] extended the work of Fonseca et al. by using weights for the adjacency links. The proposed approach integrates spatial proximity into the topological information and shows its effect as 1 % increase in precision of the system.

Liang et al. [ 51 ] present an approach for content-based sketch retrieval introducing relevance feedback. The devel-oped approach is similar to [ 54 ] as both decompose the drawing into geometric primitives, however [ 51 ] captures the topological relationships, whereas [ 54 ] captures the spa-tial relationships between the geometric primitives. The approach develops a graphical structure of the sketch (draw-ing) by decomposing it into basic geometric primitives (such as lines and curves) and establishes eight topological relationships between the primitives. The eight graph spec-trum descriptors are computed from the primitive relation-ships which can have different dimensions depending upon the number of primitives in different sketches. To calcu-late similarity between sketches, multi-dimensional spec-trum descriptors are mapped into one dimension (Euclidean norm) following the principle of dimensionality reduction. The Euclidean distance is used as similarity measure between the query and the drawing in the database. To provide the user with satisfactory retrieval results, the approach introduces a relevance feedback mechanism using the strategy of feature vector adjustment [ 98 ] which constructs a new feature vector point closer to the relevant drawings.

In Fig. 8 , the flowchart of the approach presented by Liu et al. [ 55 ] is shown. In the pre-processing step of the approach, the lines and curves in a line drawing are detected. The spatial relationships of the detected primitives are used to capture the local neighborhood structure of a local patch in the drawing. A primitive is considered as a reference and four geometric cues such as relative length, relative dis-tance, relative minimum distance (the minimum distance between the neighbor and the reference primitives divided by the length of the reference), and relative angle are used to describe the spatial relationships between the reference and neighbor primitives. The direction histogram of each primitive is calculated to describe the shape appearance. For each local neighborhood structure of a model, the k near-est candidate structures in the drawing image are obtained by matching. The correspondence between the model and candidate structures is estimated in a parameter space trans-formation. The correspondence points are accumulated by using the mean shift mode detection technique [ 14 ]inacir-cular search window. By thresholding the obtained modes, the detection results are obtained. The experiments are per-formed on synthetic as well as real engineering drawings. The ratio of the intersection between two regions and the union between them is taken as spatial overlap to detect the performance.

The approaches discussed above considered the content information alone dealing with the concepts based on geom-etry and topology. Another approach developed by Love et al. [ 57 ] takes both text and content information into account and uses GT (group technology) code to represent a drawing. The GT code encodes the geometry information at part level as well as the material and production process information into strings of digits or characters. 4.1.2 Shape appearance A simple approach to capture the shape appearance in the form of 2D histograms was presented by Osada et al. in 2002 [ 66 ]. The approach decomposes a drawing into line segments, generates random points on the lines, and samples the points uniformly. A drawing is described by a distance distribu-tion of Euclidean distance calculated between every possible pair of randomly selected points. The Minkowski distance is used as similarity measure between two histograms. Liu et al. in 2004 [ 54 ] presented an attributed graph approach to capture the shape appearance. The approach finds the eight-connected neighbors of each pixel and links these pix-els together to form a rough primitive. The rough primitives are rearranged into meaningful primitives (curves, straight lines) by a merge and split process. In the merging process, the collinearity, space gaps, tangent directions, and the spa-tial difference between two rough primitives are considered. An attributed graph is formed by taking the primitives as nodes and spatial relationships between the nodes as edges. The appearance of the primitives such as circular, straight, or angular form the node attributes and the spatial relationships between the two primitives such as relative angle, relative position, and relative distance form the edge attributes. Mean field theory is applied to measure the graph similarity.
To capture shape appearance, Pu and Ramani [ 73 ]pro-posed two approaches: 2.5D spherical harmonics and 2D shape histograms for the retrieval of 2D drawings. To describe the shape in a drawing as a spherical function of the amount of energy, the shape contains at different fre-quencies, the authors define a sphere whose center coincides with the center of the drawing X  X  bounding box and of radius enclosing the drawing completely. A set of rays is generated from the center of the sphere, and a spherical function is defined on the intersection points of the rays and the draw-ing. The spherical function is transformed from 2D space to 3D space. A rotation invariant descriptor of the spherical function is calculated by applying the fast spherical harmon-ics transformation method. All the steps involved are shown in Fig. 9 . To capture the shape information by computing 2D shape histograms, Pu and Ramani use the approach pro-posed by Osada et al. in 2002 [ 66 ]. Further, they combine the two approaches proposing a weight combining strategy. The retrieval results show that the combined approaches per-formed better than the individual approaches.

Lu et al. [ 59 ] proposed an approach for the recognition and integration of architectural drawings for the evaluation of architectural projects. The graphical primitives such as parallel lines, overlap lines, and grid lines are detected and classified to T, L, and X type shapes using shape-based meth-ods. The candidate shapes satisfying pre-defined rules are identified from the detected shapes, and a parallel pair of two shapes is recognized as a parallel pair (PP) segment. The recognized PP segments are removed from the drawing to simplify it. In the simplified drawing, architectural sym-bols are recognized based on the attributes, relations, and geometry of remaining lines. The architectural tables found in drawings are identified, and their contents are integrated in the overall recognition process. The developed approach is evaluated for 217 real-life drawings and 40 synthetic draw-ings. An overall recognition rate of 86.41 % for high-level architectural objects in real and synthetic drawing datasets is reported.

The same authors (Lu et al.) proposed a knowledge-based system [ 58 ] for the interpretation of complex engineering drawings. The proposed system consists of a knowledge rep-resentation phase and an interpretation phase as shown by the framework of the system in the Fig. 10 . In the knowl-edge representation phase, the system describes the geomet-ric shape of each engineering entity (domain-independent dimension or a domain-dependent engineering object) with internal and external descriptors. In the internal descriptor, the system finds common features of an engineering object and describes their relational constrains such as parallelism and perpendicularity with each other. While in the external descriptor, the inter entity relations such as references, inher-itances (the appearance of one entity in different drawings with different details), and reflections are described. From these developed descriptors, a hierarchical descriptor-based knowledge representation is created in order to organize the various types of engineering objects. Based on the devel-oped knowledge representation, an interpretation system for the engineering drawings is proposed. The new drawings are first converted to the content-oriented high-level descriptors and then are interpreted at four target levels as project, draw-ing, engineering entity, and graphical primitive. The system is tested for 271 architectural engineering drawings of 19 different types, and high recognition rates are reported. It is claimed that the proposed approach also works for the draw-ings of other domains such as flowcharts and tables. 4.1.3 Contour matching Berchtold and Kriegel, working on the management and retrieval of industrial CAD parts, developed a system [ 6 ] which provides the user the facility for query by example, by sketch, and by thematic attributes such as functionality or material. The system represents the CAD parts by extract-ing 2D contours as well as thematic attributes. The parts are retrieved by matching the contours, ignoring any spatial rela-tionship between and shape information.

Hou and Ramani [ 35 ] present an approach to capture the shape information at a global level in a divide and conquer paradigm. They postulate that the creation of the parametric-based design and the stretching or bending in part mod-els introduces dissimilarities at a global level which cannot be captured considering only local deformations. Following the strategy of integrated shape matching for contours, the approach first computes the contours of engineering draw-ings and represents the shape information as higher level structure and low-level geometry. In higher level structure computation, the end points of geometric primitives like lines and arcs are extracted to use as the feature points. The end points are extracted using an adaptation of the idea of dis-crete curve evolution [ 47 ]. They use the relative relevance measure [ 35 ] to quantify the dominance of points carrying visual significance in the contour evolution process instead of the relevance measure used in [ 47 ]. The higher level structure is defined by the topology of the feature points. For low-level geometric representation, the approach computes the turning angle (direction of a contour) of a feature point and takes the shape context of a point into account. The turning angle gives the absolute measure of the local geometry whereas the shape context encodes the relation between the feature points and the global shape as shown in Fig. 11 . The combination of both properties gives a geometric structure representation. To retrieve similar drawings, they first use the higher level structure representation and then the geometrical represen-tation. 4.1.4 Classifier combination and relevance feedback A query to the retrieval system as well as the retrieved results are presented through a user interface. Due to the limita-tions of the system interface and unfamiliarity of the user with the existing engineering drawing images in the data-bases, it is difficult for the user to translate his/her needs about the query precisely. Moreover, for the same query, dif-ferent persons and the same person at different times may have different perceptions about the accuracy of the retrieved results, which poses the requirement of a relevance feed-back facility in the retrieval system for the user to refine the retrieved results. Liang et al. [ 52 ] presents the mechanisms of implicit and explicit feedback in a content-based engineer-ing drawing retrieval system as shown in Fig. 12 . Explicit feedback is introduced through a fuzzy feedback mechanism where a retrieval result is marked as relevant, irrelevant, and uncertain (partly relevant). The feature weight of retrieved drawings is increased or decreased according to their rele-vance to the query. In the implicit feedback mechanism, the approach preserves the habits of the user in the interactive process of recognition and maps it to a weighted vector. By introducing the interactive process of relevance feedback, the system attempts to approach the retrieval intentions of users. In another approach, Liang et al. [ 51 ] use the strategy of feature vector adjustment [ 98 ] to introduce the relevance feedback mechanism where a new feature vector point is constructed closer to the relevant drawings. To better model the relevance feedback problem, in another approach [ 50 ],s Linag et al. treat it as a biased learning problem. Taking into account the imbalanced dataset (where the number of the negative instances are significantly larger than the positive ones), they handle it as a biased classification problem and employ the biased SVM (BSVM) [ 33 ]. The BSVM employs a pair of concentric hyperspheres to incorporate the princi-ples of both the one-class SVM and binary SVM and finds an optimal hypersphere. Sketches which lie inside the optimal hypersphere are taken as positive examples and otherwise as negative examples, and bias is achieved by giving more weight to the positive class as compared to the negative ones. The whole mechanism of incorporating the on-line relevance feedback using BSVM is shown in Fig. 13 .

While providing an overview of the approaches developed based on learning and classifier combination for drawing retrieval, Hou and Ramani [ 34 ] present a new classifier com-bination approach with a relevance feedback mechanism. To develop a sketch-based retrieval system for 3D objects, they use complement shape descriptors for each individual classifier and perform supervised learning to get probabil-ity estimates of data being classified by different classifiers separately. The classification outputs from training data are used to develop optimal weights for a weighted linear com-bination model for the classifiers. A new combination rule Adaptive Minimum Classification Error (AMCE) is devel-oped by introducing a user-defined parameter to leverage the preference between minimizing log-likelihood error and minimizing classification error. The classifier having better performance individually is given more weight in the com-bination model. The system incorporates relevance feedback from the user to provide a list of part categories from sketch classification, which is further used to refine user-specified shape similarity retrieval. However, the approach does not support partial matching. 4.2 Diagrams A diagram is a visual representation of concepts and the rela-tion between them with lines, arrows, and shapes. A diagram is a model drawn to outline the construction and functioning of a developed system [ 67 ]. A comprehensive understanding of a diagram representation of data is described in [ 24 , 67 ]. The constituent components of a diagram are represented by 2D shape items like rectangles, diamonds, ovals, etc., and the relation between these components is represented by lines and arrows. To represent the flow of information in a two-dimensional geometric symbolic form using 2D shapes, the diagrams take the forms of block, state, tree, network, trellis, etc. The types of diagram include: circuit diagrams, chemical structure diagrams, data flow diagrams, etc. The interpreta-tion, recognition, and retrieval of diagrams are useful for indexing the documents. In the description of an algorithm, the functional blocks and flow of information between these blocks are described using a diagram. We provide a brief overview of the approaches developed to deal with diagram types important for patents in the following. 4.2.1 Circuit diagrams Circuit diagrams consist of electronic components like tran-sistors, resistors, capacitors, etc., as shown in Fig. 14 .Barta et al. [ 5 ] investigate the theoretical aspects of a Bayesian net-work approach to object recognition in document images and perform simulations for a sample circuit diagram extraction. They develop a tree representation of a diagram from low-level components and store it in a hierarchical data struc-ture. Each low-level component serves as a root node of the tree structure, and the number of root nodes is used to quantify the state of diagram while taking into account the electrical connections between the nodes. Fenga et al. [ 25 ] implemented an on-line circuit diagram recognition system based on two-dimensional dynamic programing. The system divides the strokes into small segments and groups them into all possible combinations where each group is called a sym-bol hypothesis. Assigning a label to each symbol hypothesis, the contextual likelihood for each hypothesis is calculated, and a decision function is minimized to correctly recognize each symbol. 4.2.2 Data flow diagrams Data flow diagrams (DFDs) are widely used as a means to express data transformations and functional dependencies of a system in both the technical (information systems, logic models etc.) and non-technical fields (business administra-tion etc). A sample data flow diagram is shown in Fig. 15 . The analysis, understanding and retrieval of DFDs, is helpful to develop DFDs for new systems and in reverse engineering problems.
 Bruza et al. [ 9 ] provide guidelines to assign semantics to DFDs and propose a transformation of DFDs for their better understanding. To analyze the logical structure of a DFD, Butler et al. [ 10 ] presented an approach based on calculus of communication systems (CCS) [ 63 ]. The approach parses a DFD to generate a DFD tree and then translates the DFD tree into a logical structure while introducing the new trans-lation rules. The logical structure of a DFD is useful to find its equivalence with other DFDs. Exploring further the use-fulness of CCS [ 63 , 64 ] and  X   X  calculus [ 65 ], Butler et al. developed a formalized representation of DFD to express it as set of tuples. The tuples include the set of node identifiers, function identifiers, data flow (arrow) identifiers, and arrow relations. To test how much the true information of a DFD is expressed by the developed formalized representation, the Edinburgh Concurrency Workbench (CWB) [ 79 ] was used. The CWB is useful in analyzing the possible behaviors of a system. 4.2.3 Flowcharts A kind of drawing close to DFDs are flowcharts which are also in use to express the graphical representation of data and process relationship. There is no literature found on the interpretation of flowcharts in documents; however, we present some related work from interpretation of hand-drawn flowcharts. In an attempt to provide the students a concrete software environment for algorithm creation, graphical visu-alization, and debugging, Atanasova et al. [ 3 ] developed a flowchart interpretor system. The system checks the correct-ness of created flowchart and responds with corresponding messages in case of an error. The main motive is to assist the algorithm understanding by using the algorithm animation principles and visualization. The system provides the inter-pretation facility of the visualized flowchart in a manual as well as in an automatic way.

For the recognition, understanding and to improve esthet-ics of flowcharts, Szwoch [ 83 , 84 ] presented a system propos-ing novel extension of graph grammar as FlowGram graph grammar. The author defines the graph rewriting rules, cri-terion, and measures for flowcharts esthetics and in addi-tion creates an application flowchart analyzer to evaluate the proposed solutions. A new open flowchart format named FlowChartML is proposed to exchange low-and high-level information between flowcharts. Yuan et al. [ 96 ]inanattempt to introduce pen computing for visual teaching of program-ing concepts developed a system which facilitates teachers to draw the top-down design flowcharts and translate them into C programs. They extract features from a stroke and use independent component analysis (ICA) to get fixed length feature vectors dealing with the variable length of strokes. A set of fuzzy SVMs are employed as first-stage classifiers to get the posterior probabilities which serve as a probabil-ity evaluator of observations in the hidden states of HMMs. A HMM is employed as a final classifier to recognize the flowchart sketches. The developed hybrid SVM-HMM algo-rithm is shown to perform better than the traditional HMM algorithm. 4.2.4 Domain-independent approaches The recognition systems discussed above are developed tar-geting a specific kind of diagram. However, all diagrams relating to different domains share some similarities as well as differences in their appearance. To handle domain-independent and domain-specific issues in diagram recog-nition , a few approaches exist in the literature. This type of work targets the diagram domain independent issues sep-arately and provides an interface to incorporate domain-specific recognition systems. The main purpose of this type of framework is to handle the complexity of the problem as well as to enhance the efficiency of the systems. Lank [ 46 ] developed a framework as an interactive system for diagram recognition which comprises of a drawing area, segmentation routines, character recognition tool, and an interface to incor-porate domain-specific recognition components. The draw-ing area is used for the creation of drawing as well as for the presentation of results. In the segmentation phase, the author extends a stroke, finds the intersection of different strokes, and considers the intersecting strokes as a single compo-nent. The interactive behavior of the framework is tested by developing and incorporating systems for UML, Mathemat-ics, and molecular diagrams. Another approach addressing the same issue is presented by Plimmer et al. [ 72 ] in which they implemented a toolkit approach for sketched diagram recognition. They review the existing sketch tools and report their common as well as different features in a table. The developed approach mentions the domain-independent steps as to classify the strokes into drawing or writing strokes and identify the basic primitive shapes as lines, circles, rectan-gles whereas the domain dependent steps as to identify the meaningful components and the relationships between them. For stroke recognition, they use and enhance the Rubin [ 74 ] algorithm and use a diagram library of example components to classify the diagram components. The extensibility of the algorithm is achieved by providing domain-specific plug-in libraries.
 To deal with all kinds of vector diagrams found in PDF documents, Futrelle et al. [ 31 ] proposed a statistical approach. The approach first parses each page of the PDF document to extract multiple diagrams and sub-diagrams by analyzing white space gaps and computes a feature vector for the occurrences of primitives like rectangles, lines or curves, horizontal, vertical lines. A support vector machine [ 39 ]is used with an inner-product kernel for learning and classifica-tion. An overall classification accuracy of 91.7 % is reported for separating bar graphs from non-bar graphs gathered from 20,000 biology research papers. 4.3 Charts Another symbolic and visual representation of data is in the form of charts. To enhance the understanding of quantita-tive data and their relationships, data charts such as line charts, pie charts, bar charts etc., are used. In the follow-ing, we discuss briefly the various techniques developed for the recognition and retrieval of these chart types. Data charts help in the description as well as analysis of quantitative data in academic, business, and scientific fields. Two docu-ments can be compared on the basis of the information drawn from the data charts. The information of data charts can also serve as an additional criterion for search engines to improve the retrieval of documents. Shukla et al. [ 77 ] presented an approach for the recognition and quality assessment of data charts exploiting the combined textual as well as graphical information.To recognize the chart types and interpret the data information from the chart, Huang et al. [ 36 ] proposed a model-based approach. At the first step, they separate text and graphics information based on connected component analy-sis followed by a filtering process. An OCR technique is used to retrieve the text. Edge detection is performed on the graph-ical portion; a straight line segment is found and extended to find complete lines or arcs. The relationships between lines and arcs such as parallelism, perpendicularity, and conver-gence are used to recognize the chart types using the model-based approach. To interpret the data found in chart images, the authors exploit the attributes of the objects found during the type recognition step of a chart. To handle the many data points found in charts like line charts, the authors sampled the space between x axis and y axis to collect a series of data. However, the sampling rate inversely affects the precision of the system.

Another model-based approach is proposed by Zhou et al. [ 100 ], who developed virtual chart models based on ergodic hidden Markov models in which it is possible to reach any state from any other state. The approach extracts the prin-cipal invariant features such as the number of transitions of the transition variance function between the background and the foreground of the image in the x direction, gradi-ent angle, and the two transition values before and after a feature position. For the principal variant features, the approach records the locations of the transition feature at which the principal invariant features are selected. These locations are maximum six in the proposed system and used as training features in model parameter estimation. Chart model matching is achieved by calculating the probability of observation vectors obtained from extracted principal fea-tures.

There are approaches developed to deal with only spe-cific types of data charts like bar charts [ 101 ] and cir-cular charts [ 2 ]. Targeting the tachograph disks (circular charts which record information about a driver X  X  activ-ity), Antonacopoulos et al. [ 2 ] exploit the position, cen-ter, and orientation characteristics for information extrac-tion from the complex circular charts. In [ 101 ], Zhou et al. developed an extension of the Hough transform called the modified probabilistic Hough transform algorithm (MPHT) to detect parallel line clusters. They reconstruct the bar patterns using parallel lines and also perform correlation of the text primitives with the corresponding bar pat-terns.

A plot is a non-photographic image that contains a two-dimensional or three-dimensional coordinate system. It consists of lines, curves, and a series of points repre-senting the quantitative relationship between the dependent and independent variables [ 60 ]. In [ 8 , 41 , 59 ], algorithms to extract metadata information from 2D plots are proposed. The approach from [ 60 ] first binarizes the images and per-forms a customized Hough transformation to detect candi-date axis lines. The characteristic visual features such as the relative length, relative position, and relative location are extracted and used to detect axis lines from the can-didate lines. Using axis lines, the image is segmented into three regions: x axis region, y axis region, and curve region [ 41 ].
 To extract the text from the figure, a text block extraction tech-nique [ 41 ] is proposed for the region-segmented image. In a figure, the text and data occur in a mixed form, so the direct application of an OCR technique is not possible. A connected component analysis is employed as a pre-processing step to identify individual letters as text blocks before using OCR. The approach implements the separation of fused characters by using average size and standard deviation of the width of an individual connected component (single character). A ver-tical profile of large connected components is calculated and separated where the minimum is found. The results of text extraction are verified manually on 504 randomly selected 2D images.

To extract the numerical data , Browuer et al. [ 8 ] detect data points from the data regions ( x -axis, y -axis and curve region) and data from the solid line curves in the 2D plots. To extract data, Lu et al. [ 60 ] first filtered out the curved lines from the 2D plot figure by using an extension of the k-median filtering algorithm [ 76 ]. Valid thin line segments from these filtered curved lines are obtained by applying thin-ning, primitive chain coding (PCC) [ 76 ], and noise reduction techniques. Intersection line segments and non-intersection line segments are identified and categorized into L type, M type, and R type intersections as shown in Fig. 16 . An algo-rithm is designed to construct the curves based on the set of line segments detected, and the plots are redrawn. The perfor-mance is measured manually by the matched correspondence between original plot and redrawn plots for 2,000 plots from documents from the CiteSeer database. The whole process is shown in Fig. 17 . 4.4 Symbol recognition In Sect. 2 , for the sub-image search feature of a generic patent image retrieval system, we have mentioned that a patent image can be considered to be composed of different geo-metric objects arranged in a spatial configuration. An inter-esting pattern or an object of interest (geometric object) in a patent image can analogously be seen as a graphical symbol which is under investigation by the pattern recognition com-munity in the symbol recognition domain [ 11 , 56 ]. Defining a symbol in general as  X  a graphical entity with a particu-lar meaning in the context of a specific application domain , X  Llados et al. [ 56 ] presented an overview of the state of the art in symbol recognition from an application and methodolog-ical point of view. They provided an overview of the symbol recognition methods developed in the literature in view to application domains like logic circuit diagrams, engineering drawings, architectural drawings, and maps. Taking symbol spotting as a middle-line technique combining symbol recog-nition and segmentation, Delalandre et al. [ 19 ] presented an overview of the performance evaluation of the symbol recog-nition and spotting systems from the literature. Fornes et al. [ 30 ] presented a rotation and scale invariant approach based on the dynamic time warping technique [ 45 ] for hand-drawn symbol recognition. The method is evaluated for music and architectural symbols and is reported to outperform the state of the art methods. Escalera et al. [ 22 ] proposed a shape-based descriptor based on their previously proposed blurred shape model (BSM) [ 23 ]. The authors improve its rotation sensitivity using a correlogram structure to code the spa-tial arrangement of the object characteristics called circular BSM. The proposed descriptor is evaluated in symbol detec-tion and categorization for architectural and old-music-score image datasets. The multi-class categorization evaluation is performed on the gray-level and MPEG-7 datasets.

In the field of graphical document image analysis, var-ious shape descriptors [ 29 , 42 , 97 ] play an important role in symbol recognition. In an attempt to classify the dif-ferent existing shape descriptors in the literature, Terrades et al. [ 85 ] proposed a taxonomy of descriptors in order to unify them under different categories. The authors mention that a shape descriptor best suited to a given application can be selected from the literature in view to its strengths and weaknesses. Valveny et al. [ 89 ] characterized a set of standard shape descriptors, performing their evaluation on two shape databases, namely: GREC X 2003 graphic symbol database and the MPEG-7 contour databases, proposing a framework based on different performance measures (homo-geneity, separability, recognition rate, and precision/recall). The authors concluded that the General Fourier Descrip-tor (GFD) [ 97 ] and Zernike moments [ 42 ] demonstrate best recognition rates.

Concerning the sub-image or part-based search in patent images, the symbol recognition approaches like [ 22 , 30 ], which are rotation as well as scale invariant and able to categorize multi-class graphic symbols can be employed in implementing a PIR system. Shape descriptors like GFD and Zernike moments can also be used to describe geomet-ric objects found in patent images, which have not yet been investigated in this application domain. 4.5 Discussion of approaches in relation to type of drawings For different types of drawings available in patent documents, a number of different approaches have been developed for their analysis and retrieval. We categorize these approaches from a methodological point of view and their targeted type of drawings in Table 2 . The classification of patent drawings into different classes is feasible (with accuracy approaching 91 % [ 16 ]), and each category of patent drawing can be treated using a specific method developed targeting a specific type of drawing. This also makes the implementation of category-based search in a PIR system feasible.

Among the different approaches reviewed above (target-ing CAD and technical drawings, diagrams, and charts), a common feature extracted is the graphical geometric primi-tives: line segments, horizontal and vertical lines, intersecting line segments, arcs, curves, circles, rectangles, and polygons. The spatial, geometrical, and topological relationships: inclusion, adjacency, disjointness, parallelism, perpendicu-larity, convergence, relative angle, relative length, relative position, and relative location between these primitives are captured (in the form of attributed graphs or 2D histograms).
The geometric primitives capture the local information and their relationships tend to capture the global informa-tion of the drawings. The exploitation of the local as well as global information has been the focus of the research community in order to better represent drawing images. However, the potential of local and global information at individual level or exploiting them collectively using machine learning techniques is rather little explored (only four approaches [ 31 , 34 , 60 , 96 ]). Another approach is to combine the two different approaches capturing both of these types of information (local and global), which is reported to show better performance by Pu and Ramani [ 73 ].

Other than the approaches developed dealing with spe-cific diagram types, a few domain-independent approaches (Sect. 4.2.4 ) are developed in the literature for diagram recognition. The extraction of basic primitive shapes is taken as domain independent and finding the relationships between these primitives as a domain dependent issue. This kind of strategy (specifying and dealing the domain independent and dependent issues separately) needs to be explored further by extending its scope to other patent draw-ings. The development of approaches in view to classify-ing the domain independent and domain-dependent objects (graphic geometric objects, symbols) in engineering draw-ings can make them more useful in other application domains.

Most of the developed approaches in the literature report high recognition rates, whereas they have been mostly eval-uated on a rather limited number of drawings (217 real-life drawings obtained from real-world data [ 59 ], 271 architec-tural drawings [ 58 ]), and need to be evaluated on large-sscale databases to explore their usefulness, scalability, and short-comings. 5 Conclusion Regarding patent image retrieval, little research work has been done. The work done so far involves the development of a similarity metric for binary patent image retrieval. Although the PATMEDIA system presents a patent image retrieval framework exploiting the image contents, no research work has yet been presented using characteristic features of spe-cific types of patent images. Much research has been done on the retrieval of technical drawings in the area of technical document analysis and has direct application to the patent image domain, but has yet to be explored. Mentioning the importance and challenges of visual retrieval in the patent domain, we emphasize the need for further research. In the presented patent image retrieval approaches, Precision X  X ecall curves and maximum F score have been used as evaluation measures. Experiments have generally been done on small datasets, where the ground truth was generated by the authors and occasionally validated by patent experts. Availability of new datasets such as MAREC 2 and the organization of patent image analysis and retrieval eval-uation tracks in the CLEF-IP evaluation campaign 3 is a pos-itive sign encouraging further research in this important but rather neglected area of visual search in the intellectual prop-erty domain. References
