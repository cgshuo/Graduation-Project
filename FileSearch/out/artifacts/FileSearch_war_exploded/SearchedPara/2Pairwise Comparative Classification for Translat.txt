 In the 1990s, Lenita Esteves, a Brazilian author, translated The Lord of the Rings ,the famous fantasy novel that became a bestseller in 2001 with the release of its first film, into Portuguese. When the film was translated and shown in Brazil, Esteve claimed that all the subtitles had been taken from her translation, including the names and some lines of poems, without her permission. Esteves sued both the publishing house and the distributor of the film, claiming her share in the profit. The publishing house scorned that claim with the justification that, according to market practices, the translators are not paid for copyrights but for the task of translation [Esteves 2005].
This story marks the beginning of the challenges that translators face and their attempt to claim their own voice and identity in the field. Up to that point, market practice ignored the intellectual property of the translator. This was the starting point of this research and a good justification for pursuing the topic of translator stylometry. Can we prove that the translator has a signature in the translated text? If so, how can we define the stylometric characteristics that can be used for such a claim?
Detecting the translator of a text is an important problem and can serve in a range of functions. In the legal domain, it can be used to resolve intellectual property cases [Coulthard and Johnson 2010]. In education, it can be used to detect plagia-rism in translation classes or to address the differences between experts and learners [Castagnoli 2009].

The art of translation is a complex process. Good translation does not stop at the level of mapping words; rather, it extends to mapping meaning, mental pictures, imag-ination, and feelings. During the process of a translator translating a piece of text, s/he is trying to maintain the spirit of the original work. Nevertheless, s/he also has to make many personal decisions, including the choice of words, discourse markers, modal verb selection, length of sentences, frames, and his/her own understanding of the original text. Such decisions constitute his/her own distinctive style. Using these distinctive markers to identify the translator is the aim of this translator stylometry study.
In 1995, Venuti discussed the concept of translator invisibility [Venuti 1995]. He echoed the aim of a good translation that was originally introduced by Shapiro  X  X  good translation is like a pane of glass. You only notice that it X  X  there when there are little imperfections X  X cratches, bubbles. Ideally, there shouldn X  X  be any. It should never call attention to itself X  Venuti [1995]. This concept ignores the effect of the translator X  X  own identity on his or her translation. Translator invisibility is a tricky concept that has been criticized in the linguistics literature [Hanna 2008; Pym 1996]. Baker and Xiumei highlight the translator X  X  difficulty in separating their personal views and attitudes when translating a text, thus offering evidence of the existence of translator X  X  style [Baker 2000; Xiumei 2006].

Translator stylometry is an under-researched area in the field of computational lin-guistics. It is used to refer to the identification of stylistic differences that distinguish the writing style of different translators. In fact, it was treated as a noise affecting the original text [Hedegaard and Simonsen 2011]; Hedegaard and Simonsen were working on attributing the original authors of translated text and considered the translator effect in the text as a noise that challenged identifying the author of the text rather than recognising the translator X  X  intellectual contribution to the work. Mikhailov and Villikka X  X  research claimed that translator stylometry cannot be detected using com-putational linguistics [Mikhailov and Villikka 2001].

Based on recent linguistic and literary research, we argue that each translator has left a signature in his/her text. The low signal of such a signature does not mean that it does not exist. In this research, we are readdressing this question of the existence of translator stylometry considering the development of authorship techniques in the past few years. We also examine the features that can be used to distinguish different translators. Scenario 1: John and Jerry sent two independent translations of a movie to HEH Production Ltd. The company chose John X  X  translation and the movie was a great success, generating a large income for John. Jerry raised a case in the court arguing that the translation that was used in the movie is his own. The court needs to decipher the correct translator for the translation of the movie to provide a verdict for the case.
Scenario 2: The police acquired a hard disk with two anonymous translations of a text. One translation framed the original text in a way that incurred serious political consequences. Prior surveillance operations identified that the disk X  X  owner was in contact with two translators. The police intercepted previous translations of these two translators from previous surveillance operations. The police needs to resolve the dilemma of attributing the anonymous translations found on the hard disk to the correct translator.

The above hypothetical examples demonstrate two scenarios where the methodology and technique proposed in this article can be used. The possible applications for this ar-ticle are enormous, but the above two scenarios provide two contexts that demonstrate the potential and application of the contribution and techniques of this article.
Koppel and Schler [2004], Koppel et al. [2004], and Koppel and Winter [2014a] dis-tinguished between the attribution and verification problems. Authorship attribution attempts to learn models that discriminate between two or more authors given a suffi-ciently large corpus of their previous work. Authorship verification attempts to answer the question: Given a corpus of written texts by one author, if a new, but anonymous, piece of text arrives, is it authored by that author? These two problems provide two additional contexts in which our research can contribute [Koppel and Schler 2004; Koppel et al. 2004; Koppel and Winter 2014a].

Our work addresses the attribution problem but is applied to translators. As we dis-cussed above and in the rest of this article,  X  X ranslatorship X  attribution and verification come with their unique challenges that make the problem harder.

The task of identifying translator stylometry is highly challenging and while it has been researched in linguistics and sociolinguistics, it has been under-researched in computational linguistics. Existing techniques from the area of authorship attri-bution failed to extract identifiable signatures of the translators from their writ-ings/translations [Mikhailov and Villikka 2001; Rybicki 2012]. That raised a question why these existing techniques failed with the translator stylometry problem. Is it only because of the linguistic challenge, or is there something else? We found that when the text length changes, the boundaries that can split features into classes fail. For ex-ample, we may find a splitting condition  X  X 1 &gt; a X  may work well for short text size but may fail for large text documents. Interestingly X  X uring our investigations X  X e found a special phenomenon that not only is related to the case of translator stylometry but can also be extended to other types of problems. Alterations in text size in translated texts do not occur randomly but are related to the source (original) text in the case of translation. That means that each pair of parallel translations has a link between them, which is the original text. Therefore, we will manipulate different translations as paired data. That is also valid for the case of repeated measurements or any linked pair of data records that belongs to the same source.

This innovative technique is possible with the application of computational linguis-tics and constitutes a novel domain of research in the translator stylometry. Maintain-ing that relationship of the paired data allowed us to consider the change in values of the features in a fresh way. Rather than using the univariate condition  X  X 1 &gt; a, X  we are now able to consider a relation between value of A1 for the first instance in the pair and the value of A1 for the second instance of the pair; hence, the importance of defining this special type of classification problem. In this type of classification problem, obser-vations are taken from the same subjects, different subjects on the same phenomenon over time, or in different circumstances. Repeated measurements may result in data that occur in pairs or groups. For example, one item of the pair is a measurement for one translation while the second item is a measurement for another translation. Limited research exists on classification problems for these types of paired data. We will call this type of a classification problem a Comparative Classification Problem (CCP) to describe a general case of a group of records with more than two classes. In the case when the data occur in pairs, we call it Pairwise CCP (PWCCP).
 To demonstrate the problem, we use two translations: the translation of the Holy Quran as a good example for an Arabic-English translation and French-English trans-lations. The original language for the Holy Quran is the Arabic language. For many years, it was forbidden to translate it because no translation can capture the exact words of the original text. The existence of 1.57 billion Muslims of all ages living in the world today [Cooperman et al. 2009], and the fact that less than 17.83% of Mus-lims are Arabic native speakers, led to the translations of the meaning/interpretations of the Holy Book. Nowadays, the Holy Book has been translated into many different languages. In this article, we will focus on the translations from Arabic to English to demonstrate the use of PWCCP. The second dataset example is an English translation of a famous classic French novel to represent another suitable example of PWCCP as well.

An initial definition of this problem using the Holy book dataset is presented here, while a more general formal definition of the problem is presented later in the article. Assume chapters o 1 ... o n , where n represents the number of chapters representing the original text in the Arabic language. Let v 1 ... v n be the corresponding translations, with the cardinality of the vector v , | v |= m representing the number of translators for each chapter. Let us also assume that we know the translators (i.e., labelled data) and, as such, the order of elements in v follows the order of translators c 1 ... c m . Given additional chapters o n + 1 ... o n + u and the corresponding translations V n + 1 ... V n + u , where V is defined as a set of translators (i.e., the elements are un-ordered), the problem is how to map every element in V to the corresponding translator c . This can be seen as ordering V into V or simply having a bijection from V onto the set of translators c 1 ... c m . We will call this class of problems as CCP and when m = 2, we will call it PWCCP.

In CCP, the data are clearly not independent. While in the above example each translator independently translated the text, they all translated the same piece of text. Traditional classification trees and relational learning techniques are not designed to solve this problem.

In this article, we introduce  X  X WC4.5 X  as a modified version of the well-known C4.5 algorithm for PWCCP. C4.5 was modified by dynamically inducing relationships be-tween paired instances. For the purpose of evaluation, we used two real-world corpora in the area of translator stylometry analysis to demonstrate the performance of PWC4.5 compared to C4.5 on PWCCP. The field of linguistics offers immense opportunities for exploring stylistic variation. Linguistic studies explore the language system at different levels: the phonetic, phono-logical, morphological, lexical, syntactic, and semantic levels. Observing the variation at these different levels shows the linguistic variation in different groups as well as be-tween individuals. These variations may appear in the differences in accent, variation in word choice or word spelling, punctuation choices, or preferences in grammatical syntactic patterns. McMenamin [2002] provided an interesting example of written variation that included 23 different forms of the word  X  X trawberry X  on different signs in the roads of one state.

Linguistic variation is observed between groups and between individuals. For ex-ample, sociolinguistics studies the language of social groups such as teenagers or lan-guage use that distinguishes cultural groups such as Chinese Australians and Italian Australians. Linguistic variation is affected by factors such as age, culture, race, ge-ography, social class, education level, and specialization. Despite the existence of sim-ilarities in writing produced by specific groups of language users, there are still some individual decisions made by the writer who can contribute to individual distinctive markers [Holmes 2013]. These distinctive markers can be used to identify stylometry. McMenamin emphasizes the existence of individual linguistic variations:  X  X o two in-dividuals use and perceive language in exactly the same way, so there will always be at least small differences in the grammar each person has internalized to speak, write, and respond to other speakers and writers X  [McMenamin 2002].

The analysis of variation is the first step in the identification of style-markers, as style is about distinctiveness. In the next subsection, we are going to discuss how linguistic variation is used in forensic linguistics and authorship attribution, how these problems are connected with translator stylometry, and how linguistic variation can be used for translator stylometry identification. 3.1.1. Forensic Linguistics. Although authorship attribution is not a new research area, the forensic linguistics research area is considered new. The first appearance of the phrase  X  X orensic Linguistics X  was found in 1968 by Jan Svartvik in an analysis of statements by Timothy John Evans [Olsson 2008]. After that, the growth of forensic linguistics was slow until the beginning of the 1990s. This period established forensic linguistics as an important field, as the first expert linguistic evidence was used in the court [Olsson 2008] in a murder trial at the Old Bailey in 1989. This resulted in the International Association of Forensic Linguists being founded in 1992 and the International Journal of Speech, Language and the Law being founded in 1994.
Forensic linguistics is defined as the scientific study of language as applied to forensic purposes and contexts [McMenamin 2002]. Forensic linguistics does not focus on hand-writing recognition or the source of writing notes. Forensic linguistics is concerned with author identification and stylometric analysis [de Vel et al. 2001; Stamatatos 2008; Pavelec et al. 2008; Koppel et al. 2009; Pavelec et al. 2009], author profiling [Van Halteren 2004; Koppel et al. 2002], discourse analysis [Hyland and Paltridge 2011], and forensic phonetics [Jessen 2008; Campbell et al. 2009].
 There is a noticeable gap between forensic linguistics and computational linguistics. Forensic linguists usually analyze a small amount of texts manually looking for small details, while computational linguistics scientists try to find the stylometry by counting things and use quanitative and numerical analysis by looking at things that are easily countable. There is a need to reduce this gap by taking advantage of the strengths of computational linguistics in quantifying forensic stylistics. The use of computational tools can contribute to forensic linguistics and facilitate the process. 3.1.2. Authorship Attribution. The authorship attribution problem is not a recent research area. H. B Witter traced back some Biblical authorship disputes to 1711 [Olsson 2008]. In 1785, Wilmot challenged the literary field by claiming that Bacon is the real author of Shakespeare plays [Olsson 2008]. Another famous authorship dispute is the Federalist Papers, which is one of the most studied problems in this research area [Bourne 1897; Mosteller and Wallace 1964; Rudman 2005; Jockers and Witten 2010].

The development of computational tools, the growing interest in forensic analysis, the advances in humanities scholarship, and electronic commerce have led to a growing interest in the authorship attribution problem. This general problem was subdivided into specific sub-problems: Author identification is the more general one, where the concern is to identify who wrote a piece of text from a set of candidate authors by analysing their writing styles. Another form of the problem is author profiling, in which you attempt to identify the gender, age group, or origin of the author. Author verification is the last sub-problem, where the objective is to answer if this text is writtenbyaclaimedauthor.
 Features Researchers used a range of stylistic features for attributing authorship. These features can be categorized into five main groups: Lexical, character, syntactic, semantic, and application-specific features.

Lexical Features include all the features that are associated with analysing the sentence as a sequence of tokens or words, such as word length [Mendenhall 1887], sentence length [Morton 1965], word frequencies, word n-grams, vocabulary richness, stop words, and typo errors.

Character Features involve analysis of the text as a sequence of characters, for ex-ample, counting character types as letters, digits, or punctuations. Another example is counting character n-grams as fixed or variable in length. Compression methods for authorship attribution analyse the text as a sequence of characters as well.
Syntactic Features are being used when the analysis is done on the syntactical level where a similar syntactic pattern can be captured. This group includes frequencies of Part-of-speech (POS) and Chunks, the sentence and phrase structure, frequencies of rewriting rules (Baayen et al. 1996), and function words.

Semantic Features need deeper analysis for capture. Semantic dependency graphs were used by Gamon [2004] for author identification. McCarthy and others [Dufty et al. 2006] used the synonyms and hypernyms of words to extract semantic measures. Defining a set of functional features that associate certain words or phrases with semantic information was another approach introduced by Argamon et al. [2007].
Application-Specific Features are important if the attribution is related to a specific application like HTML Editor in e-mails or online forums, that is, attributing the author of an e-mail message or the writer in online forums. In such cases, there are specific features that are specific to these applications, like the text organization and layout, font colour count, font size count, the use of indentation, and paragraph length or some structural features such as greetings and farewells in messages [Abbasi and Chen 2005a, 2005b].
 Methods Since the early 1900s, different approaches have been used by researchers for the authorship attribution problem. These approaches have been classified by Koppel et al. [2009] into three groups: the univariate analysis approach, the multivariate analysis approach, and the machine-learning approach.

The univariate analysis approach is the simplest one, whereby the analysis is done based on one feature or attribute, such as average word length, vocabulary size, oc-currences of vowel-initial words, or two-to three-letter words. One of the well-known techniques in forensic linguistics is the cumulative sum (CUSUM) technique, which was introduced by Morton and Michaelson [1990]. In this method, the cumulative sum of the deviations of the measured variable is calculated and plotted in a graph to com-pare different author X  X  styles. Although this method was used by forensic experts and was accepted by the court, Holmes and Tweedie [1995] criticized this method as being unreliable in regard to its stability when evaluated with multiple topics.

Dealing with one feature at a time is a limitation of the univariate methods that cannot be ignored and that has led to the need of multivariate analysis. Principal component analysis (PCA) is a good example for the multivariate analysis approach. The first usage of PCA in this research area was by Burrows in 1987 with a set of the 50 highest-frequency words for the analysis of the Federalist Papers [Burrows 1987, 1989]. It has shown a high level of accuracy in the authorship attribution field over the years [Holmes et al. 2001; Burrows 2002; Binongo 2003; Abbasi and Chen 2008; Hoover and Hess 2009]. Another example of multivariate analysis is cluster analysis. This approach was examined by Hoover on different datasets with different features [Hoover 2003a, 2003b, 2004a, 2004b; Hoover and Hess 2009].

The third group includes the approaches that used Machine-learning methods to construct classifiers. These include the following: Support Vector Machine (SVM) [Stamatatos 2008; Abbasi and Chen 2008; Varela et al. 2011; de Vel et al. 2001; Zheng et al. 2006; Koppel and Winter 2014b], neural network [Tweedie et al. 1996; Zheng et al. 2006; Stanczyk and Cyran 2008; Tearle et al. 2008; Pavelec et al. 2009; Tsimboukakis and Tambouratzis 2010], and decision trees [Zheng et al. 2006]. The benefit of their scalability allows us to handle more features smoothly in addition to the fact that they are less susceptible to noisy data [Koppel et al. 2007; Stamatatos 2006; Madigan et al. 2005].

The interest in machine-learning algorithms for this research area led to multiple comparative studies among these methods. One of these studies, conducted by Zheng et al. [2006], compared decision trees, back propagation neural network, and support vector machines using four groups of stylistic features that included lexical, syntac-tic, structural, and content-specific features. SVM introduced higher accuracy than both the decision tree and neural networks in this study. Pavelec et al. conducted a comparison between a compression algorithm called Prediction by Partial Match-ing and a Support Vector Machine classifier [Pavelec et al. 2009]. Results using the same testing protocol showed that both strategies produced very similar results but with different confusion matrices. In 2010, Tsimboukakis and Tambouratzis [2010] conducted a comparative study between both neural network and support vector ma-chines. Their study resulted in introducing higher accuracy by the proposed neural network approach (multilayer perceptron MLP based). However, it needed a smaller set of parameters. Another example is the comparative study conducted by Jockers and Witten [2010]. They evaluated five classification methods: Delta [Argamon 2008; Burrows 2002], k-nearest neighbors, support vector machine, nearest shrunken cen-troids, and regularized discriminate analysis. This study suggested that both nearest shrunken centroids and regularized discriminate analysis outperformed the other clas-sification methods. The above discussion highlights the contribution of computational linguistics to the study of authorship attribution. This study emerges from the growth in computational linguistics tools to address the problem of translator stylometry. 3.2.1. The Linguistic Challenge: Fidelity and Transparency (from Theory to Practise). Venuti described the practice of the translators in the society and in the translations them-selves with the term invisibility. He claimed that this is what readers and publishers expect from the translator. Shapiro asked translators to confine themselves to trans-parency [Venuti 1995]. Although Venuti urged translators to be more visible in terms of claiming intellectual property, he still argued that high-quality translations are as-sociated with fidelity X  X oyalty to the original text X  X hus confirming the negligible role of translators. Both terms, fidelity and transparency , have affected translation theo-ries in the past few decades, but both of them are too ideal to be attained in practice. Moving from theory to practice, we see how the translators are highly affected by their beliefs, backgrounds, understanding, and cultural boundaries. Their identities affect their translations [Hanna 2006].

The literature in many fields discussed the existence of translator styles. For ex-ample, in 2000, Baker discussed the existence of translator style in saying,  X  X t is as impossible to produce a stretch of language in a totally impersonal way as it is to handle an object without leaving one X  X  fingerprints on it X  [Baker 2000]. He suggested studying translator styles using forensic stylistics rather than literary stylistics.
Xiumei used relevance theory to explain the translator X  X  style [Xiumei 2006]. The findings from Xiumei X  X  research demonstrated that, while the translator tries to bal-ance between the original author X  X  communicative intentions and the target reader X  X  cognitive environment, s/he is still influenced by his/her own preferences and abilities; the outcome of all of that introduces his/her style.

In 2010, Winters discussed how a translator X  X  attitude influences his/her translation [Winters 2010]. Winters, who used two German translations of the original novel The Beautiful and Damned (1922), written by F. Scott Fitzgerald, showed that different translators X  views affect the macro level of the novel. Furthermore, he discussed how this, from his point of view, extended to influence the readers X  attitude.
 Scholars have used different linguistics approaches to detect translator styles. While Winters used loan words and code switches [Winters 2004] and speech-act report verbs [Winters 2007], Kamenick  X  a explored how explicitness contributes to translators X  style [Kamenick  X  a 2008]. Wang and Li looked for translator X  X  fingerprints in two parallel Chinese translations of Ulysses using keyword lists. They identified different prefer-ences in choosing keywords by different translators. They also found differences on the syntactic level by analysing clause positions in the sentences [Wang and Li 2012].
In linguistic studies of translator identification, the researcher would rely on a very small sample of translators and text; mostly in the order of two translators and a few pieces of text. This manual process, was constrained in the sample size and relied on linguistic expertise and deep linguistic knowledge of the researcher. The current proposal of using computational tools in solving translator stylometry has the potential to speed up the process and expand the application to a larger number of texts. 3.2.2. The Computational Linguistic Challenge. The sample of articles reviewed above and others [Winters 2010; Xiumei 2006; Angermeyer 2009] have shown that linguistics offers evidence for the existence of stylometric differences between translators in ways that affect the translated texts. However, the area of automatic identification and feature extraction of translator stylometric features has not experienced an equivalent breed of research. The only attempt that we are aware of was in 2001 by Mikhailov and Villikka [2001]. They tried to find  X  X tylistic fingerprints X  for a translator by extracting three lexical features comprising  X  X ocabulary richness, X   X  X ost frequent words, X  and  X  X avourite words. X  Their experiment was done on Russian fiction texts in addition to their Finnish translations. The lexical features that they used in the research failed to find stylistic fingerprints for different translators. Their conclusion was summed up in their title, whereby it is not possible to differentiate among translators. While this conclusion is inconsistent with traditional linguistic studies, it seems that it has been sufficient to turn away researchers from this line of research since the mid-2000s.
The only other related research that was found was introduced by Li et al. [2011] in 2011. They tried to capture differences in the translation style of two translations by calculating type/token ratios, sentence length, and vocabulary, but the analysis in that study was based on linking these differences with the styles in terms of translators X  social, political, and ideological context of the translations. Still, Li et al. X  X  research does not address our question of who translated this piece of text. Authorship Attributions. In these three types of problems, we are trying to identify the writer of the text by detecting stylistic variation among writers. Although the focus is on identifying the distinctive stylistic features for all the problems, the type of features may differ widely.

In forensic linguistics, most of the time the data are limited. Thus, when attempting to identify individual features in a case, finding unique features of the questioned person specifically may work. For example, in the case of  X  X enny Nicholl, X  the question was: Is this writer/perpetrator the author or not? This type of analysis depends on the variations of each case. It cannot be generalized to the translator stylometry problem. Our research is unique in that it introduces an automated and general approach that may work in identifying any translator.

In authorship attribution problems, we discussed earlier the five groups of features that are used for identifying authors. Baker suggests that the study of translator styles should resemble forensic stylistics more than literary stylistics [Baker 2000]. Thus, lexical features are the most frequent groups of features that are affected by translator choices rather than the original text. For this reason, we evaluated the existing lexical methods in this research. However, as the evaluated methods did not introduce acceptable results, there was a need to employ a new approach in the problem of translator stylometry. Classical classification algorithms used in the machine-learning literature assume an independent and identically distributed (iid) dataset where instances are sampled independently and from the same identical distributions. This assumption ignores the underlying relations that may exist among features across different instances [Ganiz et al. 2011; Wang et al. 2013]. However, many real-life problems violate the iid assumption. Non-iidness is associated in the literature with dependency and hetero-geneity. Dependency in non-iidness is usually referred to as coupling. This coupling may be among objects, attributes, values, relations, or methods.

The iid assumption obstructed traditional data-mining techniques and machine learning from identifying the underling patterns that may exist among objects, at-tributes, and values [Ganiz et al. 2011]. Classification problems with repeated measure-ments violate the iid assumption. As such, they require a different treatment. Previous research on classification with repeated measurements was mainly conducted in med-ical applications. Brenning and Lausen [2008] and Adler et al. [2011a, 2011b] worked on the medical domain. Their research emphasized the need to use repeated measure-ments for a subject when the data are limited. They used different resampling-based methods. Brenning and Lausen [2008] used an ensemble of k decision tree classifiers, while Adler et al. [2011a, 2011b] used k -fold cross validation to resample the k number of observations that are taken from the same subject.

The above literature on repeated measurements still treats instances independently despite the fact that the underlying measurements may come from the same subject; therefore, a level of dependency is expected. In some applications, such as in forensic sciences, the dependency in the data may be leveraged to improve the detection rate. In this article, we will use an example of a real-world dataset in the area of computa-tional linguistics. We will attempt to analyze a problem in the sub-area of translator stylometry.

For a general classification problem, a bag of instances that provides the description of the attributes and their domains can be denoted by B ( A  X  C ), where A denotes the set of n input attributes A = { a 1 ,..., a i ,..., a n } and C represents the set of k classes variable (target attribute) C = { c 1 ,..., c i ,..., c k } .

A traditional classification problem can be defined as follows: Given a set S with input attributes set A = { a 1 ,..., a i ,..., a n } and a nominal target attribute C , the goal is to find a model/classifier that can map previously unseen instances to the appropriate class that belongs to the target attribute c  X  C as accurate as possible.

In the case of supervised classification, a training set is defined as a collection of instances (also known as records, rows, or tuples) that may contain duplicates. Each instance is an individual, independent example of the concept to be learned. These instances are characterized by a vector of predetermined attribute values as follows: where, v j i is the value of attribute j in instance i , n is the number of attributes, and m is the number of instances.

CCP is a special type of classification problem. The goal of CCP is to find a model that maps unseen instances to the appropriate predefined classes in one-to-one corre-spondence for each group of instances. Instances are grouped in blocks of records in both the training and testing data set, where each block of records consists exclusively of classes of instances; one instance per class. Thus, if one instance in this group is misclassified, there is at least one other instance in the group that will also be misclas-sified. Values of the same attribute for the block of records are collected into a single vector as attribute id, and | v i j |= k .

Instances in CCP can be represented as follows:
The definition of supervised CCP is as follows: Given a training set S with input attributes set A = { a 1 ,..., a i ,..., a n } and a nominal target attribute C , and a test set of instances V ={ V m + 1 ,..., V m + u } ,inwhich u is the size of the test set, the goal is to find a bijection mapping from every element in each V i to the corresponding class or target attribute c  X  C .

To avoid the confusion from switching between a vector representation for the train-ing set and a set representation for the test set, we will adopt the notation V i ( p j ) to represent the value of attribute i .Weuse p j as an index for the order of the measurement.

For example, in a PWCCP, j = 2 since we have a pair of instances, and V 1 ( p 1 ) denotes the value of the first attribute for the first instance of the pairs. We will use the notation p while the second instance is classified as class c 2 . In a paired classification, the only other alternative would be p 1  X  c 2 , p 2  X  c 1 .

We will also use the following functions and notations to establish a relationship between the two instances in a pair.
Figure 1(a) shows how PWC4.5 targets the relationship between paired instances within one variable at a time, and Figure 1(b) shows the output for that framework.
We can now define a synthetic problem to demonstrate the concept of PWCCP. As-sume V 1 ( p 1 ) is always the minimum of { V 1 ( p 1 ), V 1 ( p 2 )} in a set of data as shown in Figure 2. It is clear that V 1 is the key variable that discriminates between the two classes while V 2 is not a useful feature. On the one hand, a traditional decision tree such as C 4 . 5 could not identify the existing relationship among paired instances based on V 1 . C 4 . 5 classified the instances based on feature values as shown in Figure 3. That resulted in poor accuracy of classification. On the other hand, PWC4.5 is a classi-fier that can detect the relationship and produces a decision tree that represents this relationship as seen in Figure 4.

If we extend the previous example to two dimensions, then  X  X xample 2 X  presents this case. In Example 2 shown in Figure 5, there is a relationship based on both variables V 1 and V 2 , in which the relationships are p 1 is labelled as C 1 if V 1 ( p 1 )isthe Otherwise, p 1 is labelled as C 2 . Again, C4.5 failed to identify these relationships and put all of the instances into one leaf as shown in Figure 6, and Figure 7 shows the prospective decision tree that can represent these relationships. To uncover the hidden patterns or phenomena that may exist between each pair of in-stances, we need to consider the values of the attributes for these instances at the same time rather than working with each of them individually. Numerical attributes may hold hidden information that can be seen by comparing the values of each pair together. pair of instances. We may find this relationship occurring regardless of the actual val-
We need a special classifier that is able to capture the relationship between the values of the same attribute for the two parallel translations. It should be able to treat the two instances as one pair with interdependent information in relation to both classes. As we need to capture the hidden pattern in the relationship between the attribute values of the paired instance, we need to evaluate this relationship. Thus, for each numerical attribute, rather than using the traditional method of searching the best split point that C4.5 uses, a new method of search is used. In this method, we consider the new vector that holds information for the two items that represent a single pair. Values of the evaluated attributes for both items are compared together to induce the relationship. This relationship is used as a possible outcome for the relationship condition. Then, the gain ratio is calculated based on the new outcomes. The attribute-based relationship that introduces the highest gain ratio is then selected as the best split attribute.
PWC4.5, a technique based on the C4.5 decision tree algorithm, is used to solve this problem. We choose C4.5 as a well-known decision tree algorithm that uses information gain ratio to nominate preferred attributes for building the classifier. Advantages and limitation of C4.5 are discussed earlier in the background section. The pseudo code of the PWC4.5 algorithm is presented in Algorithm 1.
 The first step of Algorithm 1 transforms each pair of data records into a single record. This transformation relies on a binary relationship between the corresponding values of each attribute in the pair. The class that gets associated with the transformed record is chosen at random to maintain class balancing. Notice that this class distribution balancing step is followed by an ordering step to ensure that the correct class is as-sociated with the correct corresponding vector. Once this transformation is complete, the algorithm moves to the growing (step 2) and pruning (step 3) of the decision tree. These two steps are identical to C4.5, except that, instead of working with values for the attributes, the algorithm is adjusted to work on the binary relationships. We first acknowledge the work of Koppel and Winter [2014a] on authorship attribution, where the authors formulated the authorship attribution problem from the perspective of the following question: Given a pair of documents/texts, have they been written by the same author? They used a similar baseline experimental protocol to evaluate their methodology, but our methodology differs.

We baseline PWC4.5 against the classical C4.5 in two different ways. First, we use the paired dataset directly, thus ignoring the interdependency among the records. This baselining strategy is equivalent to a straightforward application of C4.5 to the transla-tor stylometry problem. Second, we modified the paired dataset using a transformation to combine the pairs and eliminate the dependency between records.

In this second case, we used a transformation that converts a pair of records into a single instance suitable as an input to C4.5. We call this transformation Gradient-Based Transformation (GBT). GBT takes as inputs the two pairs as vectors and outputs the difference between the two vectors. This difference represents the change between the two pieces of text; thus, it represents an approximation of the gradient between the two texts.

GBT is suitable in this article as a baseline. However, if the size of the set of records exceeds 2, then GBT cannot be used. Meanwhile, PWC4.5 relies on operators on arbi-trary sets. We used two different datasets: The first dataset is parallel Arabic-to-English transla-tions of the Holy Quran . The Holy Quran is divided mainly into 114 surah (pl. suwar), which are also known by some as chapters , although they are not equal in length. The length of the surah varies from 3 ayat or verses to 286 ayat. Thus, we will be using the terms chapters and verses for clarity. We used the translations for 74 chap-ters of the Holy Quran representing 6 of the 30 parts and cover both small and large chapters.
 The second dataset is parallel English translations of a classic French novel called Twenty Thousand Leagues Under the Seas (French title: Vingt mille lieues sous les mers ) by the French writer Jules Verne (1869 X 1870). The first translation was written by Lewis Mercier in 1872, and the second translation was prepared by Frederick Paul Walter in 1991. The original book consists of two parts. The first part is 24 chapters, and the second part includes 23 chapters. All 47 chapters have been included in this analysis. 5.2.1. Features. As we discussed earlier, we are targeting the translator style by de-tecting the repeated patterns in the translator X  X  writing. We extracted three types of feature groups as follows: (1) Vocabulary Richness (2) Stop Words (3) Character n-grams 5.2.2. Experimental Design. For the Arabic-to-English dataset: To get the most out of this dataset, which contains seven translators, we used all the possible combinations that can be obtained by taking two translators at a time from the whole dataset, C (7 , 2) = 7! / (2!(7  X  2)!) = 21. Therefore, we have 21 possible combinations of these seven translators. We collected the extracted features for each pair as a single dataset file that being used for training and testing separately. In that way, we have now 21 translator stylometry identification problems that we are evaluating using the different methods that we discussed here. For the French-to-English dataset, we only have a single pair of translators to evaluate as we were only able to get these two translations of the same original novel.

In this experiment, we evaluated the three groups of textual features discussed earlier using three classification methods: The first one is C 4 . 5, which represents the traditional technique where independent prediction is considered, with no respect to the relation between paired data. The second method is the GBT, which is used to consider the existence of the relationship between the paired data through simple transformation. Finally, the third method, which is the PWC 4 . 5, was introduced to consider the relationship as an internal component of the classification algorithm itself. 5.2.3. Arabic-English Results and Analysis. For this experiment, three feature groups have been evaluated: a Vocabulary Richness group that included 5 attributes, stop words that included 127 attributes, and, finally, n-grams, which included 300 at-tributes as described earlier. The dataset contains 74 parallel translations for the seven translators. We used all 21 possible combinations of the seven translators. For each pair of translators, we have 74  X  2 instances, which equals 74 parallel translations.
In order to avoid over-fitting, we decided to split the dataset into training and testing sets with a ratio of 2/3 for the training and 1/3 for the testing. To evaluate the effec-tiveness of the algorithm without being affected by how these 74 pairs will be split, we decided to generate 10 different splits using these 74 sample pairs. To generate these 10 different splits, we loop the nominated pair of translator 10 times:  X  X or each pair of parallel translations, a random number is generated between 0 to 1.  X  X f this number is less than 2/3, then it means it belongs to the interval [0,0.667], and then this pair goes to training dataset; otherwise, it belongs to ]0.6667,1], and then this pair is considered for the testing dataset.
 These 10 generated datasets were evaluated by C4.5, GBT with C4.5, and then by PWC4.5 to compare the accuracy in each case. A one-tailed paired t-test with confidence level of 95% (alpha = 0 . 05) was carried out to evaluate if the accuracy of PWC4.5 is significantly better than the accuracy of C 4 . 5, and between PWC4.5 and GBT as well. The question that we address in this experiment is as follows:  X  X ill classification accuracy for paired data improve by handling the pair simultaneously? X  Thus, the proposed hypothesis will be as follows:  X  X he average accuracy of PWC4.5 is better than traditional C4.5. X  As described in PWC4.5 Pseudocode, labelling the two paired instances as p 1 and p 2 is generated randomly with equal opportunity between the two instances. Therefore, this randomness may have caused some variation in the generated decision tree. Consequently, we ran each experiment 10 times.
 We followed the same steps for each pair of translators. For all 21 pairs of translators, PWC4.5 performance was significantly better than C4.5. Results of vocabulary richness are summarized in Table I.

Results of stop words are summarized in Table II. Results of n-grams are summarized in Table III. These results demonstrated that PWC4.5 always outperformed C4.5 in this experiment.

For VR, the overall average of the accuracy of PWC4.5 is 84.89% in comparison to an average accuracy of 55.20% for the C4.5 and 81.59% for GBT with C4.5. Al-though the difference between PWC4.5 and GBT is not big, the t-test showed that PWC4.5 is significantly better than GBT. Six of 21 cases achieved an accuracy of more than 95% in the case of PWC4.5. These were the cases of Asad-Daryabadi, Asad-Pickthall, Asad-YousifAli, Daryabadi-Raza, Pickthall-Raza, and Pickthall-YousifAli. However, C4.5 failed to capture this style for these four cases, where the accuracy of C4.5 was 71.24%, 68.31%, 62.17%, 50.82%, 51.35%, and 50.00% for the 6 cases respectively.

We consider that any classifier that is able to correctly classify more than 66.67% of the testing data is acceptable as being able to capture differences between classes. Then, we can conclude that PWC4.5 is able to distinguish between 18 pairs of translators of 21 cases, while C4.5 was only able to distinguish between four pairs out of the 21 studied cases.

Although good results were achieved by GBT, PWC4.5 outperformed GBT. In order to evaluate the difference in the performance between the two methodologies, a one-tailed t-test was used to compare GBT to PWC4.5 (alpha = 0 . 05). P ( T &lt; = t )one-tailed was 0.0011. Therefore, H 0 was rejected, and the alternative hypothesis of H 1:  X  ( PWC 4 . 5) &gt; X  ( GBT ) was accepted.

Stop word frequencies introduced better results than vocabulary richness for the identification of translator stylometry, with an average accuracy of 76.65% using C4.5, 86.55% using GBT with C4.5, and 88.33% using PWC4.5. We also notice that PWC4.5 maintained the superiority over both GBT and C4.5 as with the vocabulary richness case using the same t-test. Additionally, n-grams followed the same pattern of results but with much higher accuracy in the case of C4.5, with an average accuracy of 88.58%. Nevertheless, PWC4.5 outperformed both GBT and traditional C4.5 significantly.
When all features are combined together in Table IV, PWC4.5 significantly outper-formed GBT and C4.5. 5.2.4. French-English Results and Analysis. On the second dataset, using VR, C4.5 achieved 88.36% accuracy. Transforming the original attributes into V1(p1)-V1(p2), GBT, to inform C4.5 about the relation between the paired dataset yielded higher accu-racy of 97.26%. PWC4.5 outperformed both C4.5 and the proposed transformation and achieved accuracy of 99.75%. It was able to classify all cases correctly. Table V summa-rizes the results of evaluating the different methodologies using the second dataset. A paired one-tailed t-test was used to compare PWC4.5 to both C4.5, and the proposed transformation, value of P ( T  X  t ) one-tailed of (C4.5,PWC4.5) was 6 . 47 E  X  06, and was 2 . 04 E  X  03 for the case of (GBT,PWC4.5). In both cases the initial hypothesis was are accepted with alpha = 0 . 05.

However, for the cases of stop words and n-grams, C4.5 achieved better accuracy of 99.29% and 99.29%, respectively, while PWC4.5 achieved 97.80% and 99.24%. We need also to highlight that the difference between C4.5 and PWC4.5 was very small and it was statistically not significant using the t-test.

When all features are combined together in Table VI, PWC4.5 performs best, despite that the difference from C4.5 is not necessarily significant. This article addressed the task of translator stylometry by employing computational tools. While previous research focused on a small number of texts and has not been able to solve the translator stylometry problem, this research employed new techniques in the field with promising results.

This article studied the classification problem of paired data while considering the relationships between the paired instances. Traditional Classification methods ignores such relationships and treat the instances individually. Thus, there is a loss in the information that can be mined if such relationships are considered. In this article, we proposed Comparative Classification as a novel type of classification. We solved the special case of the Pairwise Comparative Classification Problem by proposing a new model, PWC4.5, which can address this problem. We carried out two experiments with two real-life datasets, to evaluate the performance of PWC4.5 in comparison to traditional C4.5. Our results demonstrated that if we take into account the dependency in the data, we can obtain better classification for pairwise comparative datasets. These results are promising and encourage further investigation in the area of PWCCP. PWC4.5 can be applied for different types of paired data, such as data with repeated measurements in storytelling.

The Arabic-English dataset seems to be more complex than the novel dataset. In this particular case, PWC4.5 has shown significantly better results. With more features, C4.5 seems to improve its performance. Nevertheless, PWC4.5 is more consistent in its better performance. The current formulation of PWC4.5 addressed the PWCCP problem only, which is the binary case of CCP. In order to extend the PWC4.5 algorithm to address any CCP classi-fication problem, the real challenge will be in replacing the current function that repre-as Minimum, Equal, or Maximum with another function that is capable of representing a scale or a range of values to represent relations in case of multiple classes. Inves-tigating the choice of this new function is a recommendation for future work of this research.

In the current work, we focused on translator attribution, where the problem is to discriminate among a number of translators. It would be interesting to extend this work to translator verification; that is, given a corpus of translations by a specific translator, we need to decide whether he/she is also the translator of a given anonymous piece of translation.

