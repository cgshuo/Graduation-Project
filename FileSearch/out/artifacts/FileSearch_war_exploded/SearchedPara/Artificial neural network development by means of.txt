 1. Introduction
Arti fi cial neural networks (ANNs) have risen from 1960s as a novel way to mimic the human brain. The learning ability of ANNs makes them a powerful tool for various applications, such as classi fi cation ( Zhang, 2000; Cantu-Paz and Kamath, 2005;
Castellani and Rowlands, 2009; Rivero et al., 2010; Castellani, 2013 ), clustering ( Du, 2010 ), vision ( Weimer et al., 2013; Zaidan et al., 2014 ), control systems ( Li et al., 2014; Czajkowski et al., 2014 ), prediction ( Muttil and Chau, 2006; Chen et al., 2008; Chen and Wang, 2010; Taormina et al., 2012; Weizhong, 2012; Khashei and Bijari, 2012; Coban, 2013 ), and many others ( Rabu X al and
Dorado, 2005 ). Designing the network architecture and training it are the most important problems with exploiting ANNs. In supervised problems, the task of training is the adaptation of the network weights so that the ANN can map a set of prede fi input patterns to the desired corresponding outputs. BackPropagation (BP) algorithm ( Rumelhart et al., 1986 ) is the most known ANNs training algorithm. Selecting effective input features, determining the number of hidden neurons, and the connectivity pattern of neurons is the task of designing the ANN topology that affects the network  X  s leaning capacity and general-ization, and usually needs to be performed by experts; they have to experiment on different topologies to fi nd a suitable one.
Evolutionary neural networks (ENNs) refer to a class of research in which evolutionary algorithms (EAs) are used in the ANN designing and/or training. EAs are population-based, stochas-tic search algorithms stimulating the natural evolution. As EAs search globally and can handle in fi nitely large, non-differentiable and multimodal search space of architectures, this fi eld has been interested by many researchers and ANN developers.

ENNs can be followed in three major groups. The fi rst is the adaptation of the ANN weights by EAs, a form of the ANN training. The second group of works is the use of EAs for designing the architecture of ANNs, and the third is the Topology and Weight Evolving of ANNs (TWEANN) that includes the methods proposed to simultaneously evolve the weights and architecture. In the following, some of the important research lines in ENNs are reviewed; the more complete and state-of-the art reviews can be found in Yao (1999) and Azzini and Tettamanzi (2011) . 1.1. ANN training algorithms
In the evolutionary training of ANNs, the network architecture is fi rstly determined, usually by experts. As the training of ANNs can be formulated as a search problem, the EA is used for exploring and exploiting the search space for fi nding an optimized set of weights. Binary representation of the connection weights is one of the earlier works in this area ( Whitley, 1989; Caudell and Dolan, 1989; Whitley et al., 1990; Cantu-Paz and Kamath, 2005 ). However, some of researchers have used suitable real encoding
EAs ( Montana and Davis, 1989; Deb et al., 2002 ). Since evolution startegy (ES) and evolutionary programming (EP) algorithms are well-suited for real vector optimization, they have been employed in this area ( Fogel et al., 1995; Heidrich-Meisner and Igel, 2009 ).
An ANN training algorithm is always a well-known benchmark for new approaches developed in EA  X  s research area; the generalized generation gap parent-centric recombinatin (G3PCX) algorithm introduced by Deb et al. (2002) , for example, has been used in the empirical study performed by Cantu-Paz and Kamath (2005) to compared with a binary encoded genetic algorithm (GA). In order to improve the ANN training process, a local search may be embedded into an EA ( Topchy and Lebedko, 1997 ). 1.2. ANN designing algorithms
The architecture of an ANN is of great importance because it affects the learning capacity and generalization capability of the
ANN. Gradient-based search approaches such as constructive and destructive algorithms may be used in the automatic design of the architecture of ANNs ( Frean, 1990; Sietsma and Dow, 1991 ).
Nevertheless, the main drawback of such methods is that they are quite susceptible to fall in local optima ( Angeline et al., 1994 ).
In the evolutionary design of the architecture, there are two approaches for representing solutions. In the fi rst approach, called direct encoding, all of the network architecture details are encoded in a chromosome. Assuming the ANN as a directed graph and using an adjacent matrix for representing its genotype is a common direct encoding method. In this way, each entry is a binary number representing the presence or absence of a connec-tion between two nodes ( Miller et al., 1989; Kitano, 1990; Belew et al., 1991; Cantu-Paz and Kamath, 2005 ). This representation can also be employed to prune the connections of a network trained with full connectivity pattern ( Reed, 1993 ). The other approach is indirect encoding, where only some characteristics of the archi-tecture of an ANN are encoded in a chromosome. In the indirect encoding approach, some aspects of the destination network and/ or network generation (mapping process) are prede fi ned. For example, if we know that a fully connected architecture is suitable for our problem, it is suf fi cient to only encode the number of hidden layers, the number of neurons in each layer and the parameters of BP algorithm in a chromosome. The knowledge added to the algorithm reduces the search space and usually leads to a compact encoding.
 There are several types of indirect encoding in the literature.
Kitano (1990) has introduced a grammar based indirect represen-tation encoding production rules in a chromosome instead of an adjacent matrix of the network. In the genotype to phenotype mapping, the production rules are decoded to generate the adjacent matrix; transforming the matrix to the corresponding network is then straightforward. Compact genotype is the main advantage of this method. Siddiqi and Lucas (1998) have shown that direct encoding can be at least as good as the Kitano method. Fractal representation inspired by regularity, symmetry and self-similarity of live organisms is another indirect encoding scheme that may be more plausible than other encoding schemes ( Merrill and Port, 1991 ). Gruau (1993, 1994) has introduced a cellular encoding as an indirect representation that is motivated by cell division in biology.

Cantu-Paz and Kamath (2005) have empirically evaluated, in addition to ENN methods for ANN training, also various ENN methods for feature selection ( Kohavi and John, 1997; Yang and Honavar, 1998 ) and ANN designing on classi fi cation problems.
Yang and Chen (2012) have proposed an evolutionary constructive and pruning algorithm to design the network topology, where its weights are optimized through BP. Furthermore, Soltanian et al. (2013) have applied a grammatical evolution (GE) algorithm ( Ryan et al., 1998 ), called GE-BP, to design the architecture of an ANN, where the BP algorithm is used for the network evaluations against training data. 1.3. Simultaneous evolution of the ANN topology and weights
Yao and Liu (1997) have developed a TWEANN method based on EP, called EPNet, for simultaneously evolving the architecture and weights of an ANN, in which no crossover operation is utilized. NeuroEvolution of Augmenting Topologies (NEAT), presented by
Stanley and Miikkulainen (2002) , is another successful system in this area. A hypercube based NEAT with an indirect encoding has also been introduced by Stanley et al. (2009) . Compact genotype, input as well as output scalability, and utilizing the geometry of the problem domain are the most important advantages of their system. Motsinger et al. (2006) and Tsoulos et al. (2008) have used GE for construction and training ANNs with one hidden layer.
Castellani and Rowlands (2009) have developed a TWEANN method for recognizing wood veneer defects, and reported that there are no differences in accuracy between architectures using one and two hidden layers. Rivero et al. (2010) have applied genetic programming (GP) to design and train a feedforward ANN with any arbitrary architecture, and Oong and Isa (2011) have presented a global-local balanced GA to simultaneously design and train an arbitrary connected feedforward ANN. More recently,
Castellani (2013) has compared evolutionary ANN designing and whole ANN development algorithms with classical feature selec-tion and designing methods.

However, there are also other types of ANNs and EAs combina-tion in the literature. Evolving the neuron transfer functions ( Stork et al., 1990 ), the learning rule and parameters of BP ( Bengio et al., 1990; Baxter, 1992 ), and ANN ensembles ( Yao and Islam, 2008; Huanhuan and Yao, 2010; Felice and Yao, 2011; Donate et al., 2013;
Ghazikhani et al., 2013 ) are other research lines in the ANN evolution. ANN ensembles originate from the idea of divide-and-conquer algorithms. Experiments have shown that EAs are good choice to automatically divide the problem space, and thus, ENN ensembles have attracted many researchers attention in the literature ( Yao and Islam, 2008 ).

The major drawback of the ANN training algorithms described in Section 1.1 is the expert  X  s effort needed for designing the network topology. The major disadvantage of the ANN designing algorithms described in Section 1.2 is that the search space is complex and noisy because the fi tness assigned to a given architecture is dependent to the learning method. The methods described in Section 1.3 are free from these problems. However, most of them suffer from inability of using the problem domain knowledge, while some of them are extremely dependent to the expert.
 As mentioned earlier, the TWEANN method proposed by
Tsoulos et al. (2008) uses GE for designing the network topology as well as optimizing its weights. That is, their method encodes both the network topology and its weights using a context free grammar (CFG) in Backus  X  Naur form (BNF). The GE approach, fi rstly introduced by Ryan et al. (1998) , has been applied to successfully solve a range of problems (see, e.g., Ryan et al., 2002; O  X  Neill and Ryan, 2003; Motsinger et al., 2006; Chen et al., 2008; Chen and Wang, 2010 ). As stated by Tsoulos et al. (2008) , the use of GE to evolve ANNs has the bene fi t of allowing easy shaping of the resulting search, in addition to leading to a compact encoding. However, GE does not seem to be much suitable for real vector optimization, i.e., for optimizing the connection weights, and may cause some problems such as high destructiveness of variation operators, thus destroying information evolved during the search. Accordingly, the algorithm introduced by Soltanian et al. (2013) uses GE only for designing the network topology, while its weights are optimized through BP. Nevertheless, this type of combination leads to a complex and noisy landscape, the major disadvantage of ANN designing algorithms. In order to overcome the drawbacks of the methods of Tsoulos et al. (2008) and
Soltanian et al. (2013) , this paper proposes a new TWEANN method, called GEGA, in which GE is adopted to design the network topology while GA is incorporated for weight adaptation.
Indeed, GEGA employs a hybrid of direct and indirect encodings: a grammatical encoding to indirectly represent the topology and a real encoding to directly represent the connection weights with the aim of achieving a better global  X  local search in the space of weights. To the best of our knowledge, this is the fi rst paper of applying such a combination to the whole development of ANNs.
It is noteworthy that, although there are some other algorithms for real vector optimization (such as ES and EP algorithms), GA is well-matched for weight adaptation due to the fact that GE is mainly a
GA but with a grammatical encoding, and consequently, the similarities between GA and GE allow us to combine them in one algorithm. Like the methods of Tsoulos et al. (2008) and
Soltanian et al. (2013) , GEGA is capable of generating any feedfor-ward ANN with one hidden layer. GEGA can utilize expert knowl-edge about the problem on hand in order to more ef fi ciently search in the in fi nite space of topologies, although it needs to invest a minimal expert's effort for customization. Moreover, another contribution of this paper is to propose a novel adaptive penalty approach that encourages smaller topologies. This allows GEGA to generate much simpler ANNs that have better general-ization ability and also are easy to implement. To evaluate the performance of GEGA, extensive experiments are performed on real world classi fi cation datasets, and the results are statistically compared against other well-known and state-of-the-art algo-rithms in the literature.

The rest of the paper is organized as follows. The next section describes the proposed algorithm. The contributions of some GEGA components and computational results are analyzed in Section 3 , followed by Section 4 discussing the characteristics of GEGA. Finally, Section 5 concludes the paper. 2. Proposed algorithm
The topology and the connection weights of an ANN are simultaneously determined by GEGA. The network topology includes the neurons in the input layer, i.e., the selected features, the neurons in the hidden layer, and the connectivity among the neurons. Since it is expected that simpler ANNs lead to more generalization ability, a penalty approach is proposed to simplify ANNs through the evolution process. The general structure of GEGA whose output is a feedforward ANN is shown in Fig. 1 . The representation, genetic operators and the proposed penalty method are then described in details in the following subsections. 2.1. Representation
Designing an appropriate genotype representation is the fi step in applying an EA to a particular problem. In GEGA, a hybrid of direct and indirect encodings is employed in which each chromo-some includes two parts: one for the network topology and the other for its weights. The topology is indirectly represented by a vector of integer numbers in the range of [0, 255]. The number of genes in the topology part of each chromosome in the initial population is set to be equal to 100. This part is then decoded to the corresponding topology by a generation grammar; some characteristics of the network are pre-determined in the generation grammar. However, the connection weights are directly encoded as a vector of real numbers. If there is m input neurons and h hidden neurons, the number of connections is at most h ( m  X  2) because each hidden neuron has, respectively, one output connection, (at most) m connections with the input neurons, and one connection for the bias. Accordingly, the number of genes in the weight part of a chromosome in the initial population is set to be equal to int ( m  X  2), where int is an integer number randomly selected between 1 and 10 for each chromosome. It is noted that the number of genes in the weight part as well as in the topology part of chromosomes may change during the evolution process. To generate the network topology, a BNF grammar is employed.
BNF grammars are widely used as tools to describe programming languages and expressions. BNF is a notation for expressing a CFG by means of production rules, and has been used as the main grammar description tool of languages by the founders of GE ( Ryan et al., 1998; O  X  Neill and Ryan, 2001 ). A language  X  s BNF grammar contains some symbols (terminal symbols) that can be presented in a valid sentence of the language, and some non-terminal symbols used in the generation process of a valid sentence. A BNF grammar is shown by a tuple { N , T , P , S }, where N denotes the set of non-terminal symbols, T the set of terminal symbols, P the production rules and S the start symbol beginning the generation process. The proposed CFG, which is able to generate any feedforward ANN with one hidden layer, is shown in Fig. 2 ,where x 1 , ... , x features, w stands for weights, and sig denotes the sigmoid activa-tion function for hidden neurons (of course, for the output neuron function returning values between 0 and 1 is frequently used in
ANNs, although one can easily embed a different nonlinear function in the proposed CFG for neuron activation. Mapping a chromosome to the corresponding ANN is done by generating the network topology through the grammar, and then, assigning the weights to the network  X  sconnections.
 For a problem with two input features x 1 and x 2 and one output O , Fig. 3 illustrates an example of a chromosome representation.
The steps of the generation process are presented in Fig. 4 . The start symbol o S 4 begins the process. Since it is a non-terminal symbol, it must fi re a production rule; in the proposed grammar, o S 4 has two production rules o Node 4 and o Node 4  X  o S 4 to be fi red. To determine which one is fi red, the remainder of the fi rst entry of the topology part when divided by the number of production rules is used; the remainder is 1 and so the production rule with index 1, that is, o Node 4  X  o S 4 ,is fi red. By continu-ing in this fashion, until there is no non-terminal symbol in the generated sentence, the generation process terminates success-fully. It is noted that, by means of wrapping ( Ryan et al., 1998 ), genes can be used multiple times. In other words, the integers from the beginning of the topology part of a chromosome are used again when the end of the vector is reached. However, after a pre-speci fi ed number of wraps, if the sentence is not valid, the chromosome is called an invalid chromosome.

From the generated topology string shown in Fig. 4 , the resulting network has two hidden neurons; the fi rst hidden neuron, H1, has two connections with x 1 and x 2 , while the second one, H2, has only one connection with x 2 . If the weights given in
Fig. 3 are inserted in the generated sentence, the following string, which is then the input to the output neuron of the ANN shown in
Fig. 5 , is yielded: 5 : 2 sig 5 : 9 1  X  4 : 3 x 2  X  3 : 8  X  X  X  4 : 0 sig 0 : 2 2  X 
Since H2 has no connection with x 1 , the corresponding weight indicated in Fig. 5 with a grey colored background is ignored; recall that the positions of the weights corresponding to each hidden neuron in the weight part of a chromosome are fi xed.
Finally, we would like to mention that when the network resulting from the topology part of a chromosome has a number of hidden neurons (say ht ) that is not equal to the number of neurons served by the weight part (say hw ), the smaller one of ht and hw will dictate the number of hidden neurons. Therefore, if ht is smaller than hw , the additional genes in the weight part are ignored, otherwise zero weight is assigned to each connection associated with the additional hidden neurons of the resulting network, thus ignoring those neurons.
 2.2. Crossover operator
By recombining the gene-codes of two parents, crossover as the main genetic operator produces two solutions in as yet unvisited regions of the search space. For each pair of parents, the crossover operator which is a combination of two different crossovers is applied according to a crossover probability P c . Among many possible crossovers, the one-point crossover, which is the most common crossover operator in the literature and is faster than other operators, is executed on the topology part of the two chromosomes, while the intermediate recombination is applied to the corresponding weight part working by taking the average of the two parental alleles for each gene. Fig. 6 illustrates an example of the crossover operation; the second offspring is created in the same way with the parental roles reversed. 2.3. Mutation operator
After the crossover process, the mutation operator performed by varying the gene values of a chromosome is applied to each resulting offspring. It aims at preventing the algorithm from trapping in local optima by exploring new solution spaces. The proposed algorithm utilizes four types of mutation operators. First, a new gene is added to the topology part of the chromosome with a probability of P m ; the gene position as well as its value is randomly chosen. For every gene in the topology part, with probability P m a new value is then chosen at random from the range [0, 255]. Moreover, with probability P m /2 a neuron is added or deleted to/from the weight part of the chromosome by adding/ deleting ( m  X  2) genes. Then, for every gene in the weight part, an amount randomly drawn from a Gaussian distribution with mean zero and a standard deviation, which is selected at random from {0.2, 0.5, 1, 2, 5}, is added to the current gene value. Fig. 7 illustrates an example of the mutation operation. 2.4. Selection mechanisms
The parent selection mechanism is applied to the current population with a size of m to select, with replacement, a number of parents equal to m . The parents then undergo the crossover and mutation operations. Among many possible selection techniques, the rank-based selection mechanism ( Eiben and Smith, 2003 )is adopted in this paper to select individuals for reproduction. This mechanism allows a chromosome to become parent with a probability that is based on its rank in the population, rather than based on its absolute fi tness value. All individuals are according to their fi tness. If the fi ttest individual is assigned rank and the worst rank 1, the probability of selecting individual with rank j is then calculated linearly as follows: Pr  X  j  X  X  2 s where s is a parameter between 1 and 2 determining the selection pressure. Obviously, this selection mechanism preserves a con-stant selection pressure in the evolutionary search, thus avoiding the drawbacks encountered by fi tness proportionate selection.
Furthermore, after having created m offspring of the parents, the survivor selection mechanism is applied to select m individuals among both the current population and their offspring to form the next generation. The above rank-based selection mechanism but with an elitist strategy is adopted to select individuals for survival.
Elitism is frequently used in addition to other selection mechan-isms in order to avoid losing the best found individuals during generations. First, a prede fi ned percentage P elit of the new popula-of the rank-based selection mechanism. 2.5. Fitness evaluation
An appropriate measure to evaluate the fi tness of an ANN is the mean squared error (MSE), where the error per pattern is the difference between the ANN's output and the desired (target) output; here, low MSE means high fi tness. Let r be the number of training patterns. The MSE for individual i (which is an ANN) is then calculated as follows:
MSE  X  i where d z and o iz are the desired output and the output of indi-vidual i for pattern z , respectively.
 However, GEGA aims at providing an ANN that has not only low
MSE on the training set, but also high generalization on unseen data. As the generalization ability of an ANN may decrease because of over fi tting problems, a novel adaptive penalty approach is incorporated into GEGA to reach much simpler ANNs, thus leading to more generalization ability. In addition to having good general-ization capability, simple ANNs are easy to implement and also provide better opportunities to extract knowledge. Accordingly, in order to reward parsimony, the error (i.e., the training fi function to be minimized in the evolution process) for individual i is de fi ned as follows:
E  X  i
 X  X  MSE  X  i  X  X  p co h  X  i  X  X  3  X  where h  X  i  X  is the number of hidden neurons of individual i and p co the penalty coef fi cient.

Rivero et al. (2010) have tested the values 0, 0.00001, 0.0001, 0.001, 0.01 and 0.1 for the penalty coef fi cient, and claimed that 0.00001 returns good results for most of the problems. However, determining an appropriate coef fi cient is a problem-dependent, time-consuming process that needs to try-and-test different values. Besides, in the literature on constrained optimization, there are various automatic techniques to determine a penalty coef fi cient. Nevertheless, such methods are appropriate when the boundary between the feasible and infeasible regions is known; whereas there is no exact upper bound on the number of hidden neurons when evolving an ANN.

In this paper, however, an adaptive method exploiting the population information is proposed to determine the penalty coe-f fi cient so that it prevents the algorithm from unnecessarily producing complex ANNs, i.e., ANNs with a large number of hidden neurons. Let MSE and h be, respectively, the average MSE and the average number of hidden neurons over the current pop-ulation. The penalty coef fi cient is then calculated at each genera-tion as follows: p q  X  h  X  = MSE  X  4  X  where q  X  h  X  is an increasing function in h .

The rationale behind this de fi nition is to allow a higher penalty if the algorithm reaches more complex ANNs. More speci fi whenever it reaches ANNs with a small number of hidden neurons but with a high MSE, a low penalty then tends to generate more complex ANNs in subsequent generations with the hope of improving the MSE. Obviously, in the beginning of the evolution, the algorithm is expected to attain such ANNs due to the encoding-speci fi c process employed for initializing the population.
Hence, incorporating the proposed penalty approach into GEGA, which most likely starts with small network structures, has an advantage of forcing it to incrementally explore more complex structures by decreasing the penalty coef fi cient. On the other hand, whenever the algorithm reaches ANNs with a large number of hidden neurons having a low MSE, a high penalty then tends to generate simpler ANNs with the same or even a lower MSE in subsequent generations. Note that as the evolutionary process proceeds, the algorithm is expected to attain ANNs having a low
MSE. So, another advantage of the penalty approach is that it encourages smaller topologies leading to more generalization ability when needed.

Furthermore, in order to make the contribution of the penalty to the fi tness no more than that of the MSE, following preliminary experiments the increasing function q  X  h  X  is de fi ned by q  X  h  X  X  h where h max , an approximate upper bound on the number of hidden neurons, is set to be equal to r 1, as a three-layered feedforward ANN with r 1 hidden neurons (with sigmoid activa-tion functions) can give any r input-target relations exactly ( Tamura and Tateishi, 1997 ). It is noted that  X  r 1  X  1 : 4 scale the contribution of the penalty term. Taking Eqs. (4) and (5) into account, the error stated in Eq. (3) can then be rewritten as
E  X  i
 X  X  MSE  X  i  X  X  h 3. Performance evaluation
To validate GEGA and make comparisons with other ENN alg-orithms, seven well-known classi fi cation problems used by most methods are chosen from the University of California at Irvine (UCI) repository of machine learning databases ( Blake and Merz., 1998 ). Prior to conducting experiments, however, the numeric features in the data are linearly normalized to the interval [ 1,  X  1], the nominal features (except for the class labels) are encoded with the 1-in-C coding, where for a C -class problem one of the C outputs is set to 1 and the others to 0, and the binary values are encoded as a single 0 or 1. Such a preprocessing phase is the usual approach used for classi fi cation purposes (see, e.g., Cantu-Paz and
Kamath, 2005 ). Table 1 presents the brief description of the datasets after preprocessing the data; for each dataset, the number of input features, classes as well as patterns is given.
Due to the stochastic nature of the proposed algorithm, it must be run multiple times for each dataset, and then, comparisons with other ENN algorithms are made by performing proper statistical tests. When comparing classi fi cation algorithms, the most common technique is k -fold cross-validation to measure the accuracy of the algorithms and then the use of t -tests to con the results are signi fi cantly different ( Cantu-Paz and Kamath, 2005; Rivero et al., 2010 ). In k -fold cross-validation, the data D is randomly divided into k non-overlapping sets D 1 , D 2 , ... algorithm runs k times; in each run i (1 r i r k ), the algorithm is trained with D \ D i sets and tested on D i . In this paper, all experi-ments are performed in 2-fold cross-validation, where the data is divided in two halves and the algorithm runs two times; in each fold, the algorithm is trained with one half and tested on the other half, and vice versa. More speci fi cally, in each run of the algorithm, the training set is used to calculate the error stated in Eq. (6) during the evolutionary search, while the test set is used to measure the classi fi cation accuracy of the best ANN found in the search process as an estimation of its generalization performance.
Moreover, each experiment is repeated 5 times, where the data division in each experiment is done independently, thus having 10 runs of the algorithm. This method of experiment, suggested by
Dietterich (1998) , is known as 5 2 cross-validation and has been used by many other ENN algorithms, including those with which GEGA is compared.

Furthermore, to assess the signi fi cance of the differences between the results obtained by GEGA and other ENN methods, under 0.05). To statistically compare the performances of ENN methods, the two following criteria are used: the average classi-fi cation accuracy as the primary criterion and the average number of hidden neurons as the secondary one. This latter criterion is important since simple ANNs are easy to implement and provide better opportunities to extract knowledge, in addition to leading to high performance in the generalization measured by the classi cation accuracy. In a similar way as in Castellani (2013) , if there is no statistically signi fi cant difference between the performances of two algorithms on a given dataset according to the primary criterion, the secondary criterion is then taken into account. If again there is no statistically signi fi cant difference, the two algorithms are said to perform equally on the dataset, and both are awarded 1 point. But, in the case where there is statistically signi fi cant difference between their performances according to the primary or secondary criteria, the algorithm performing better is awarded 2 points and the other zero point. The overall perfor-mance of each algorithm is then calculated by summing all the points achieved in the pairwise comparisons on all the datasets. Note that for a given dataset an algorithm can obtain at least one point, since it is compared with itself as well.

In the remainder of this section, we fi rst analyze the contribu-tions of some GEGA components and then compare the perfor-mance of GEGA against many other well-known and state-of-the-art ENN algorithms in the literature. However, before conducting formal experiments, it is necessary to set the numeric parameters involved in GEGA. We have empirically determined these para-meters; in a preliminary experiment, different combinations of the parameter values have been tested. The settings observed to be superior are given in Table 2 . In the experiment, it has been observed that the performance of GEGA is not too sensitive to make small changes in the values chosen for the numeric para-meters (in the following, some experimental results concerning other settings of one of the parameters, P m , will be shown, although relatively large changes are made in the value given in Table 2 ). 3.1. Performance analysis of GEGA components
In this subsection, the contributions of the mutation operator and the adaptive penalty approach to the performance of GEGA are analyzed and validated through experiments. Following Rivero et al. (2010) , to evaluate different settings of the proposed algorithm, the MSE, rather than the classi fi cation accuracy, of the generated ANNs on test sets in 5 2 cross-validation is measured. 3.1.1. The contribution of the mutation operator
Mutation is applied to one solution and produces one new solution. Thus, by creating the div ersity within the population, it can prevent the algorithm from trapping in local optima. However, if the probability of mutation is selected to be at a high level, mutation would destroy information evolved during the search, that is, the solutions resulting from this operation may inherit nothing from their parents. In other words, the probability of mutation can have a signi fi cant effect on the algorithm  X  s performance. Accordingly, experiments with P m  X  0.01, 0.02, 0.04, 0.05, 0.07, 0.08, and 0.10 are performed. The results concerning average MSE of the generated
ANNs for fi ve randomly selected datasets are summarized in Table 3 , where best values are indicated in boldface. To show the impact of each of the four components of the mutation operator, Table 3 also gives the results of GEGA for the following cases: Case 1. There is no gene addition to the topology part, Case 2. There is no topology modi fi cation,
Case 3. There is no neuron addition/deletion to/from the weight part, Case 4. There is no weight modi fi cation, Case 5. There is no mutation at all.

It can be seen from Table 3 that P m  X  0.05 is a suitable choice for most of the datasets and provides the best performance on average, while GEGA has the worst performance in case 5 , i.e., when mutation is not applied at all. It is noted that the results reported in Table 3 for cases 1  X  4 are concerned with P m
Moreover, the results indicate that all the components of the mutation operator have signi fi cant impact on the performance of
GEGA, especially weights modi fi cation through Gaussian perturba-tion and topology modi fi cation through random resetting. 3.1.2. The contribution of the adaptive penalty method
To evaluate the contribution of the proposed adaptive penalty approach, experiments with four other alternatives are performed.
One alternative is the case in which no penalty approach is incorporated into GEGA at all, i.e., when the penalty coef p co is set to 0. As other alternatives, the static penalty method suggested by Rivero et al. (2010) is incorporated into GEGA in which the penalty coef fi cient p co takes the values of 0.00001 (as recom-mended by the authors), 0.001, and 0.0001. The results obtained for fi ve randomly selected datasets are summarized in Table 4 ,which gives for each dataset and each scenario (including the proposed penalty approach and the four other alternatives) the average MSE and number of hidden neurons of the generated ANNs.

It can be seen from Table 4 that the proposed penalty approach results in a low MSE for most of the datasets and provides the best performance on average, while GEGA has the worst performance when p co  X  0. Moreover, in terms of the number of hidden neurons, the proposed approach leads to the best results for almost all datasets, while p co  X  0, and 0.00001 provide the worst performance on average.

For the Breast Cancer dataset, Fig. 8 illustrates the effect of the proposed penalty approach on the evolution of GEGA in terms of the average MSE and the average number of hidden neurons in the population, that is, MSE and h . In order to track the progress of the evolutionary process, the MSE values measured on the training set are plotted in Fig. 8 .
 As shown in Fig. 8 , in the beginning of the evolutionary process,
GEGA reaches ANNs with a high MSE and a small number of hidden neurons. Allowing a low penalty then tends to incremen-tally explore greater topologies in the subsequent generations, thus generating more complex ANNs with a lower MSE. Whenever the algorithm reaches ANNs with a large number of hidden neurons having a low MSE, allowing a high penalty then tends to generate simpler ANNs with a lower or the same MSE in the subsequent generations. As can be seen in Fig. 8 , GEGA with the proposed adaptive penalty approach is able to fi nd ANNs with a low MSE and a small number of hidden neurons after about 50 generations. 3.2. Comparison with other ENN methods
In this subsection, computational experiments are conducted to evaluate the performance of GEGA and make comparisons with many other alternative ENN methods. The average and standard deviation of the classi fi cation accuracies of the generated ANNs on test sets in 5 2 cross-validation, as well as the average and standard deviation of the number of hidden neurons of the generated ANNs are measured; the standard deviation may be used as a measure of stability.

Due to the fact that the CPU time needed to solve a problem is affected by a lot of factors such as computer platforms and programming skills, it is not a practicable measure to use when comparing results with any other previously reported ones. So, to measure computational time, the computational effort which is a more universal measure is used. Following Rivero et al. (2010) , the computational effort is calculated for each algorithm by multi-plying the effort needed in evaluating every individual with the population size and the number of generations. The effort needed in evaluating an individual is measured using the number of times training patterns is passed through the corresponding ANN. After calculating the computational efforts of alternative ENN methods, to conduct a fair comparison, GEGA is allowed to run for almost the same computational effort. 3.2.1. Comparison with training algorithms The fi rst category of the alternative ENN methods consists of ANN training algorithms evolving only the connection weights.
G3PCX ( Deb et al., 2002 ) and GA ( Cantu-Paz and Kamath, 2005 ) are two methods that fall in this category. G3PCX and GA use real and binary representations of the connection weights, respec-tively, to train three-layered, fully connected feedforward ANNs.
G3PCX and GA require less computational efforts, and conse-quently, the population size of GEGA has been set in this experi-ment to 100, instead of 500. Table 5 provides a comparison between the results of GEGA and those of G3PCX and GA taken from Cantu-Paz and Kamath (2005) . The best results concerning average classi fi cation accuracy (in percentage) and average num-ber of hidden neurons are indicated in boldface. The computa-tional efforts of G3PCX as well as GA are calculated based on the corresponding results reported in Cantu-Paz and Kamath (2005) .
It can be seen from Table 5 that GEGA results in a high classi fi cation accuracy for most of the datasets and provides the best performance on average. Moreover, in terms of the number of hidden neurons, GEGA leads to the best results for all datasets.
Table 6 statistically compares the performances of GEGA and the two alternative ENN methods by means of the mentioned approach. As seen, GEGA evolving both the topology and the connection weights of ANNs provides the best overall performance as well. 3.2.2. Comparison with designing and TWEANN algorithms The second category of the alternative ENN methods consists of ANN designing algorithms evolving only the network topology, in which the connection weights are optimized through BP. The methods presented by Cantu-Paz and Kamath (2005) , namely the GA feature selection (GA-FS), the matrix method (MM), the pruning method (PRM) and the parameter method (PAM), and GE-BP ( Soltanian et al., 2013 )are fi ve methods that fall in this category. GA-FS uses a binary encoded GA to select a subset of the input features, and MM as well as PRM utilizes a binary matrix representing the connectivity of an ANN. In PAM, the number of hidden neurons, the parameters for BP and the range of initial weights are found by means of a GA. Moreover, GE-BP uses a vector of integers for encoding the network topology, with a CFG-based decoder. The results of GA-FS, MM, PRM and PAM are taken from Cantu-Paz and Kamath (2005) (of course, no results concerning number of hidden neurons of the ANNs generated by
MM, PRM and PAM have been reported in Cantu-Paz and Kamath (2005) ); while, to have a suitable comparison, the results of GE-BP are obtained from the experiments performed. Besides, the com-putational efforts of GA-FS, MM, PRM, as well as PAM are calculated based on the corresponding results reported in Cantu-Paz and Kamath (2005) .
 The last category of the alternative ENN methods consists of
TWEANN algorithms that, like GEGA, simultaneously evolve the topology and the connection weights. GE ( Tsoulos et al., 2008 )and uses a vector of integers for encoding the topology and the connection weights and a BNF grammar for decoding, while GP is a method to design and train ANNs by means of a tree-based GP algorithm. The results of GP, including its computational efforts, are taken from Rivero et al. (2010) ; while, to have a suitable comparison, the results of GE are obtained from the experiments performed.
Table 7 provides a comparison between the results of GEGA and those of the designing and TWEANN algorithms mentioned above.
The best results concerning average classi fi cation accuracy (in percentage) and average number of hidden neurons are indicated in boldface. GEGA, GE-BP and GE are allowed to run for almost the same computational effort as MM, PAM and GP, since GA-FS and in particular PRM require relatively less computational efforts.
It can be seen from Table 7 that GEGA results in a high classi fi cation accuracy for most of the datasets. Although GP provides the best performance on average, it has not used all the datasets; if only the four datasets used by GP are considered, GEGA has an average of 90.92 which is higher than that of GP. Moreover, in terms of the number of hidden neurons, GEGA leads to the best results for almost all datasets. Table 8 statistically compares the performances of GEGA and the seven alternative ENN methods by means of the mentioned approach. As seen, GEGA leads to the best results for almost all datasets and provides the best overall performance as well. 4. Discussion
As shown in the previous section, in terms of the classi fi accuracy and the number of hidden neurons, GEGA evolving both the topology and the connection weights of ANNs provides the best overall performance among the ENN methods in the study. In this section, however, some other characteristics of GEGA are described in details. 4.1. Minimal dependency with the expert
In the evolutionary training of ANNs, the network topology must fi rst be determined, which may require an excessive amount of expert's effort. In the evolutionary design of ANNs, some human efforts are required too; PRM ( Cantu-Paz and Kamath, 2005 ), for example, initially needs a trained network. Moreover, the other
TWEANN methods are usually not completely independent from the expert; GP ( Rivero et al., 2010 ), for example, has, in addition to a number of GP parameters, also three parameters including the penalty coef fi cient, tree height and maximum number of inputs to each neuron that have to be set by the expert. However, one characteristic of the TWEANN method proposed in this paper is that it needs to invest a minimal expert's effort for customization.
GEGA has six numeric parameters listed in Table 2 to be set by the user; clearly, the determination of the appropriate values of such parameters is unavoidable for any other ENN algorithms too.
Except for the parameters, there is only the increasing function q  X  h  X  used by the proposed penalty approach to be de fi ned. Never-theless, as the problems used in the experiments have a variety of complexities, it can be concluded from the results that the function de fi ned by Eq. (5) is useful for other classi fi problems as well. 4.2. Automatic selection of the features
Removing redundant and irrelevant features is very important in the generation of classi fi ers. These features yield no additional and useful information for the classi fi cation task, and even may reduce the accuracy. Automatic techniques of feature selection are typically divided into fi lter, wrapper, and embedded methods ( Blum and Langley, 1997 ). Filter methods select a subset of the features prior to learning based on some criterion. Since these methods consider the features independently and the feature selection criterion may not perfectly match to the classi accuracy, they are prone to failure. To select a subset of the features in a wrapper method, a number of candidate solutions, subsets of the input features, are evaluated on the classi accuracy results, thus allowing a more precise evaluation. More-over, embedded methods select a subset of the features and train the classi fi er simultaneously. The method proposed in this paper,
GEGA, falls in the category of embedded feature selection approaches. To see that GEGA can avoid redundant and irrelevant features, Fig. 9 , for example, presents one of the networks generated for the Sonar dataset with an accuracy of 73.08. As can be seen in the fi gure, only 12 out of 60 input features are selected to solve the problem with high accuracy, that is, not so many features are signi fi cant to solve it.

To further see the ability of GEGA to automatically select the features, a comparison between the average percentage number of features selected by GEGA for each dataset and that of GA-FS ( Cantu-Paz and Kamath, 2005 ) is given in Table 9 , where best values are indicated in boldface. GA-FS is a wrapper method which uses a binary encoded GA to select a subset of the input features that will then be used to train the network. The results in Table 9 correspond to the experiment previously reported in Table 7 .In addition, the results of GA-FS are calculated based on the corre-sponding results reported in Cantu-Paz and Kamath (2005) . The comparison shows that GEGA outperforms GA-FS in terms of the feature selection, in particular for the three datasets with higher number of features, namely, the Credit-German, Sonar, and Iono-sphere datasets. Recall that, from Table 7 , GEGA results in a higher classi fi cation accuracy than GA-FS, except for the Breast Cancer and Heart-Cleveland datasets. In conclusion, although GEGA selects a much smaller number of features for the three largest datasets used in the study in particular, it results in a higher classi fi cation accuracy than GA-FS; this con fi rms the ability of GEGA to select the most relevant input features. 4.3. Generation of simple ANNs
The main goal of this paper is undoubtedly to propose a system that can produce ANNs with not only low error on the training set but also high generalization on previously unseen data, measured by the classi fi cation accuracy on the test set. However, the generalization ability of an ANN may decrease as a result of over fi tting problems occurring when the ANN topology is too large. Accordingly, as stated previously, the proposed adaptive penalty approach is incorporated into GEGA to simplify ANNs generated through the evolution process, thus leading to more generalization ability. The results given in Tables 5 and 7 indicate that GEGA outperforms on average all the nine other algorithms in terms of the classi fi cation accuracy (as explained earlier), and also produces ANNs with a much smaller number of hidden neurons. Taking into account these results as well as the ability of GEGA to select a small subset of the input features, it can thus be concluded that GEGA which takes advantage of a desirable penalty approach generates suf fi ciently simple ANNs that have high generalization capability.

In Table 5 , when comparing GEGA with the two ANN training algorithms, GEGA generates ANNs with an average of 3.6 hidden neurons which is much smaller than that of G3PCX as well as GA. This is, of course, not surprising since G3PCX and GA train ANNs with fi xed topologies, namely three-layered, fully connected feedforward ANNs. Moreover, in Table 7 , when comparing GEGA with the two ANN designing algorithms with known results concerning average number of hidden neurons and the two TWEANN algorithms, again GEGA producing ANNs with an aver-age of 2.5 hidden neurons is considerably superior; however, unlike the training algorithms, all these algorithms design the network topology. Indeed, due to the fact that during the evolution process GEGA penalizes, in an appropriate manner, the number of hidden neurons, it can produce ANNs with a much smaller number of hidden neurons (and thus connections). We observe, for example, that the network shown in Fig. 9 has only 2 hidden neurons and 18 connections, which is much simpler than the network traditionally used for the Sonar dataset having 10 hidden neurons and 620 connections ( Opitz and Maclin, 1999 ). Simple
ANNs not only lead to high performance in generalization but also are important because of their easy implementation as well as better opportunities they provide to extract some knowledge. 4.4. Exploiting expert knowledge
Another advantage of GEGA which lies in using GE to design the network topology is that it can exploit expert knowledge about the problem on hand in order to more ef fi ciently search in the in space of topologies. Indeed, expert knowledge can be exploited through introducing bias into the proposed CFG. Suppose we know that some of the input features are more signi fi cant than the others to solve the problem  X  such information can even be achieved through other feature selection techniques, such as methods requiring the least computation time. The proposed CFG can then be modi fi ed to incorporate this knowledge, so that the given features are more likely to be selected than the others.
Fig. 10 , for example, presents a modi fi ed version of the CFG for a problem with two input features in which the importance of the fi rst feature is twice the importance of the other. With this modi fi ed grammar, we can expect that the algorithm converges easily towards promising regions of the search space.
Furthermore, a minimum number of hidden neurons can be considered for the population  X  s individuals by easily modifying the fi rst production rule. For example, the following rule generates topologies with at least 2 hidden neurons: o
S 4 -::  X  o Node 4  X  o Node 4 j o Node 4  X  o S 4 while the following rule generates topologies with at least 3 hidden neurons: o
S 4 -: 5. Conclusions and future work
To simultaneously evolve the topology and the connection weights of ANNs, this paper proposes a new combination of GE and GA that needs to invest a minimal expert  X  s effort for custo-mization. To ef fi ciently search the in fi nite space of topologies as well as connection weights, the proposed system uses gramma-tical encoding for the topology representation and real encoding for the weights representation in a chromosome. Using GE to design the network topology can also help the user introduce other advices into the algorithm to make the search more directed.
Moreover, to simplify ANNs generated through the evolution process, the system utilizes a novel adaptive penalty approach that encourages smaller topologies leading to more generalization ability when needed. To assess the performance of the proposed algorithm, extensive experiments are performed on real world classi fi cation datasets and the results are statistically compared against other well-known and state-of-the-art ENN algorithms in the literature. The computational results demonstrate the super-iority of our algorithm over the other methods as it provides the best overall performance in terms of the classi fi cation accuracy and the number of hidden neurons. The proposed system is well-suited to the whole development of ANNs for classi fi cation, and classi fi cation, etc., even though it may be applicable to other situations such as prediction and control systems after some adjustments.

The algorithm proposed in this study, however, needs some mechanism to prevent the weights from taking extreme or too small values. It also needs some more suitable crossover operator that will be more adapted to the suggested chromosome encoding and not some generic crossovers as those in the paper. These issues point to directions for future research efforts. As another direction for future research, it would be interesting to add the ability to generate ANNs with more than one hidden layer and even recurrent ANNs. Moreover, it would be interesting to evolve the neuron activation functions, in addition to evolving the topology and the connection weights of ANNs.
 References
