 This paper focuses on a method for the stylistic segmenta-tion of text documents. Our technique involves mapping the change in a feature throughout a text. We use the linguistic features of conjunction and modality, through taxonomies from Systemic Functional Linguistics. This segmentation has applications in automated summarization, particularly of large documents.
 I.7 [ Document and text processing ]: Segmentation Algorithms, Languages Systemic Functional Linguistics, Text Segmentation
This paper introduces a method for automatic stylistic segmentation of a document. The intention is to determine introductory, conclusive or transitional segments within a document; the motivation being that such sections should be valuable in text summarization tasks. Current methods of text segmentation [8, 2, 5] focus on finding topical shifts between segments; these methods have excellent utility for document indexing and searching, however they fall short when applied to the task of document summarization [7]. One problem stems from the typical summarization tech-nique of extracting salient sentences [3] from each section; in a lengthy document, this yields either an unacceptably long summary or one which fails to represent possibly im-portant topics [4]. A second problem arises in that both introductory and conclusive paragraphs have great topical similarity with their preceeding or following passages, thus often represented as a single section by traditional methods.
We show the results of stylistic segmentation on formal scientific writing, analyzing their agreement with the true headings in each document. Our technique involves map-ping the changes in types of conjunction and modality ex-pressed over the course of a text; this differs from previous approaches of finding new terms [2] or lexical cohesion [5] methodologies. For this purpose we utilize Systemic Func-tional Linguistic features as a theoretical framework; how-ever, the method may conceivably be used with any similar topic-independent feature set.
What is lacking from topic-based segmentation may be replaced with stylistic segmentation; for this we use fea-tures independent of the topic of sections. These features are derived from the taxonomies of Systemic Functional Lin-guistics (SFL) [1]. The first feature group used is conjunc-tion, mapping the way clauses or sentences are linked to each other. Second is the expression of modality, concern-ing modal verbs like can, must, and should, used to modify verbal events. Contained within modality lies the third fea-ture group exploring the degree of modality; e.g.  X  X an X  is weaker than  X  X ust X .

Systemic Functional Linguistics represents language as a message, in the form of independent systems describing var-ious stylistic choices. Each system contains options repre-senting the author X  X  chosen stylistic representation; the sys-tem of EXPANSION, for instance, describes conjunction. Within this system exist three options: Extension, which links clauses giving different information together; Enhance-ment, which qualifies information in one clause by another and Elaboration, which deepens a clause by clarification or exemplification.
 The two subsystems of modality are TYPE and VALUE. The former represents a choice between Modalization, ex-pressing the likelihood or frequency of an event, and Mod-ulation, expressing its ability or necessity; VALUE has the three options High, Median and Low and accordingly repre-sents the degrees of modality.

Our first step was to extract the section headings from the pdf documents by using links within the documents them-selves. The section headings are then replaced with an inert identifier to ensure they are not inadvertently affecting the automatic segment detection. The documents were then an-
Inert  X  in this context  X  indicates that the identifier is not lexical in nature and cannot be recognized by the section detection software. It is, however, easily found when com-paring found to true sections. alyzed according to 250-token windows, sliding the window one 25 token section at a time (90% overlap). Within each of these windows the relative frequencies of each option within a system were recorded: This generates a vector for each option, from which its slope is estimated. If the rate of change within a window is high enough then each of the 10 25-token sections within it is marked as a likely section break by that feature. Our sys-tem relies on two thresholds: tSlope determines what is con-didered a high slope while tAgree is what fraction of features must have at least this slope to indicate a section boundary.
Document segmentation is a highly subjective task which usually involves finding the boundaries by hand, a laborious process. To avoid such, we utilize highly structured text in our evaluation; our corpus consists of 368 formal scientific articles from four different fields. Each article is divided based on the authors X  placement of section headings.
The first step in this investigation was to evaluate the vi-ability of the system manually; to that effect graphs were constructed of the features changing over time -see Fig-ure 1. The vertical lines are the true sections; they tend to correspond to regions where many of the feature curves have a high slope. Further evaluation was performed using the familiar F-measure, with balanced precision and recall. This measure is somewhat crude for this task (see [6]), however we believe it remains useful for preliminary study.
Figure 1 is a visual indication of the generated data; ver-tical lines indicate true sections, while the curves represent the value of each feature used. The thresholds were used from 0 to 2 for tSlope and 0 to 1 for tAgree to obtain the F-measures mapped in Figure 2. Our best result, F =0 . 635, occurs with tSlope =1 . 6and tAgree = . 3%; here precision and recall are P = 63% and R = 65%. The precision in-dicates many false sections are found; we hypothesize that this is due to stylistic changes independent of marked sec-tion boundaries. The recall is expected in that this system is not intended to find topical boundaries, which are quite prevalent in some documents. Previously reported results on the textTiling [2] algorithm were F = . 3556 on a single document; the vecTile [5] improves this to F = . 515, on a corpus of 5 popular-science papers.
We have presented a new technique for linguistic analysis: mapping the change of linguistic features over the course of a document. To explore the power of this technique it was applied with Systemic Functional Linguistic features to a subtask of document segmentation. Even as a generic segmentation tool, this technique shows merit; further study will examine its particular strengths and weaknesses.
