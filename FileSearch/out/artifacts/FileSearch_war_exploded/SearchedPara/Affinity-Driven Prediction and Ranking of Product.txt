 Large online product review websites ( e.g., Epinions , Blippr ) have recently come into being containing information related to various types of products. Typically, each product in these sites is associated with a group of members who have provided ratings and comments on it. These people form a product community . A potential member can join a product community by giving a new rating to the product. We re-fer to this phenomenon of a product community X  X  ability to  X  X ttract X  new members as product affinity .

The knowledge of a ranked list of products based on prod-uct affinity is of much importance to be utilized for imple-menting policies, marketing research, online advertisement, and other applications. In this paper, we identify and ana-lyze an array of features that exert effect on product affin-ity and propose a novel model, called AffRank , that utilizes these features to predict the future rank of products accord-ing to their affinities. Evaluated on a real-world dataset, we demonstrate the effectiveness and superior prediction qual-ity of AffRank compared to baseline methods. Our experi-ments show that features such as affinity rank history , affin-ity evolution distance ,and average rating are the most im-portant factors affecting future rank of products. H.3.3 [ Information Search and Retrieval ]: Information Search and Retrieval X  Information Filtering ;J.4[ Computer Applications ]: Social and Behavior Sciences X  Sociology Algorithms, Experimentation Social networks, community evolution, product community, product review, product ranks, ratings
Large online product review websites ( Epinions 1 , Blippr 2 ) have recently come into being containing information re-lated to many categories of products. Within these websites, individual users are allowed to publish their comments or give ratings on different products. Besides, they can set up friendships by linking to each other. Figure 1 depicts the structure of such a product review site. Observe that for a particular product ( i.e.,  X  2 ), there is a group of people who have given ratings and published their comments on it ( i.e.,  X  ,  X  3 ). These people form a community ( i.e.,  X  2 ). In other words, each product in a product review site is associated with a community [6]. In the sequel, we refer to such a community as product community . Clearly, these communi-ties are a potential gold mine for all kinds of marketing and business analysts as users X  comments and ratings toward a particular product may affect other consumers X  purchasing behavior [6].

A new user (member) can join a product community by giving a new rating to the product. Hence, the growth of a product community X  X  size can be implicitly measured by the slot. We refer to this phenomenon of a product community to  X  X ttract X  new users as product affinity . Specifically, it is measured by the number of new ratings a product receives from new members during a particular time period. In fact, existing product review websites often display a ranked list of products that received the most number of new ratings on a daily, weekly, or monthly basis. We refer to this ranked product list at a particular time slot as affinity rank .For example, consider Figure 2. It depicts two affinity ranks of top-5 movies extracted from the Blippr website during weeks  X   X  2and  X   X  1, respectively. Observe that Ninja Assassin and Sherlock Holmes received the most number of new ratings.
The affinity ranks of products in the past weeks/months highlight the popularity of products among new users in the (recent) past. Although such historical information is im-portant for several applications, prediction of future affinity ranks of products is even more important to marketing and business strategists. For example, reconsider Figure 2. Sup-pose in week  X   X  1 a company intends to put advertisements on five movie products during week  X  . Then, it makes sense to predict 5 most popular products at time  X  so that op-timum benefit can be achieved. That is, it is desirable to predict the affinity ranks of products in the near future. In this context, instead of just listing most popular products, ranking them based on their affinity ranks makes more sense as a company may allocate different shares of their advertise-ment budget depending on the popularity of the products. Note that such top- X  products may vary considerably at two different time points. For instance, consider the top-5 prod-ucts during weeks  X   X  2and  X   X  1 in Figure 2. Observe that Sherlock Holmes moved from rank 5 to the top rank in suc-cessive weeks. Further, Invictus first appeared in the top-5 list in week  X   X  1whereas Crazy Heart failed to remain in the top-5 list in this week.

Recent research on ranking products in product review websites have primarily focused on evaluating a product by the strength of connections among its users [6] or by the features related to a particular product item ( i.e., price, released time etc.) [3]. However, these techniques are not designed to predict the ranks of products based on their affinities. In this paper, we propose a novel quantitative model called AffRank that utilizes historical and evolution-ary affinity information as well as other features to predict the future ranks of products according to their affinities. We propose three features, namely affinity rank history , average ratings ,and affinity evolution distance , related to the prod-uct communities that may exert significant effect on affinity. In particular, affinity rank history represents the historical affinity ranks of products over time; average ratings mea-sures the average of ratings received by a product at a given time point; and affinity evolution distance measures the dis-tance between affinity evolution of a pair of different prod-ucts. To the best of our knowledge, these features have not been studied systematically in the literature.
In this section we describe the features that are used in our ranking model. All the values for these features are normalized into the interval [0,1] using Min-Max Normal-ization. We begin by introducing the real-world dataset we have used for our study. Table 1 describes the Blippr dataset was crawled using Blippr api 4 till August, 2009. It includes user ratings toward 75 different products.
Affinity Rank History. Recall that each product  X   X  is associated with an affinity rank at time  X  , denoted by  X  Since the affinity rank of a product depends on the number of new users (product affinity), here we characterize the evo-lutionary behaviors of product affinity and affinity rank. We first investigate how the affinity changes between consecu-tive time points in the history. We denote the number of new users for product  X   X  at time slot  X  as  X   X   X  =  X  C  X  all products  X   X  and time  X  . It indicates that the product affinity for all the products discussed in this paper is more likely to increase spikily and drop down smoothly .Asaffinity is the number of new users associated to a product within a time interval, this phenomenon reflects the speed of growth of product community size. It suggests that the speed of growth tends to increase to a peak in a short time and di-minishes slowly subsequently. This phenomenon is generally applicable for most products, although we do acknowledge that in some specific categories (e.g., car batteries) this may not be true.

We now investigate the change of affinity rank between consecutive time slots in the history for each product. In particular, the change of affinity rank for a product between times  X   X  1and  X  is measured as follows.
 We calculate the count for each  X   X   X  (  X   X  ) value over all prod-ucts and time slots. The distribution of  X   X  is reported in Figure 3(b). Clearly, it follows a long-tail distribution. If we fit the curve in Figure 3(b) using power law mod-els at both the left and right sides of  X   X  =0separately, the exponents equal to -1.51 for the negative changes where  X   X   X  1 (  X   X  ) &gt; X   X  (  X   X  ) and -1.53 for the positive ones. The ex-ponents are so close that the distributions of positive  X   X  and negative  X   X  are almost symmetrical. Besides, such a (a) Affinity intensity evolu-tion. Figure 4: Affinity intensity evolution and Lag be-tween the average rating evolution and AIC. phenomenon also indicates that the change of rank is most probable to be within a small range. Note that the afore-mentioned phenomenon also exists for each specific category of products. Thus, the rank of a product at any time slot is highly related to its previous rank. In the next section, we shall exploit the symmetric property of  X   X  instead of asymmetric  X   X  in our AffRank model.

Affinity Evolution Distance. We now analyze and compare the evolutionary nature of different product affini-ties. We begin by introducing the notion of affinity intensity . Let  X  U  X   X   X  be the number of new users towards product  X  time slot  X  . Then the affinity intensity of  X   X  at  X  is defined slots over which the affinity is normalized.

Figure 4(a) reports the evolution of affinity intensity val-ues of five different products over time. Note that the label in front of a product name indicates the category of the product. The  X  -axis denotes the number of weeks since the product first appeared in the website, while  X  -axis repre-sents the affinity intensity towards the product over differ-ent weeks. In the sequel, we refer to such curve as Affinity Intensity Curve ( aic ). Observe that out of the five aic in Figure 4, the aic of Twitter and Gmail look similar ,the two products of game also exhibit similar aic while that of TheDarkKnight is quite different from the rest. In other words, these curves show that products in the same category tend to have similar affinity evolution patterns.

We compute the distance between different curves using the dtw (Dynamic Time Warping) distance with Sakoe-Chiba band [7] which adds a window constraints  X  to the warping path found by dtw algorithm. Our results show that the average distances between products in the same category are always smaller than those from different cate-gories for all values of  X  [5].

We compute affinity evolution distance for a product  X   X  at time  X  (denoted by  X   X   X  )usingthenotionof dtw distance. Since we intend to measure how similar an aic of a product is compared to the product in the same category with most number of new users, we quantify  X   X   X  by measuring the dtw distance between the aic of a product  X   X  and the aic of product  X   X  whose affinity rank is the highest in the same category. The formal algorithm is given in [5].

AverageRating. Let R  X   X  be the bag of ratings that prod-uct  X   X  received during time slot  X  . Then the average rating of  X  during  X  , denoted by R  X   X  , is defined as: R  X   X  = 1 Figure 4(b) depicts the aic of Gmail in Blippr dataset as well as its average rating evolution. Observe that the evo-lutions of affinity intensity and average rating follow similar trend except that there is a certain delay  X  between the peaks of the two curves. In general, most of the  X  values fall in the interval [0 , 3] [5]. Hence, we incorporate the average users X  ratings for  X   X  [0 , 3] days as a feature in our affinity rank prediction model. If we denote the upper bound of  X  as  X  , then this feature can be computed as R  X   X   X   X  1  X   X   X  [0 , X  ].
As the affinity rank of a product is highly related to its ranks in the near past, it can be modeled by an arx (Au-toRegressive model with exogenous inputs) model [2]. Specif-ically, the arx model of orders  X  and  X  is given as follows. In this equation,  X  is the time series data ( i.e., product ranks in various different time slots),  X  is the number of exogenous input features;  X  1 ,..., X   X  and  X  1 , 1 ,..., X   X , X  are the param-eters to be estimated from the training data. Both  X  and  X  are the orders in the model to be manually determined before model estimation. In our context,  X  is the order of product rank which determines the number of previous prod-uct ranks to be considered in the modeling;  X  is the order of feature determining the number of past time slots from which the values of the corresponding features to be involved in the model estimation. The variable  X   X   X   X , X  is the value for feature  X  at time  X   X   X  ,and  X   X  is white noise. The estimation of the arx model is efficient as it solves linear regression equations in analytic form. Also, the solution is unique and always satisfies the global minimum of the loss function [2].
In the arx model, the order of product rank  X  and the order of feature  X  need to be manually determined. A com-mon way of selecting  X  and  X  is to fix the value of  X  (or  X  ) and try a range of values for  X  (or  X  ); for each pair of  X  and  X  values, evaluate the accuracy of the model estimated using a measure called fpe [1]. A smaller fpe value means a more accurate model. Based on the fpe measures, we set  X  =5and  X  = 1 for our experimental study. Also, we use thelatest10weeksdatatoestimatethe arx model. The algorithm to predict the affinity ranks using the learned arx model is given in [5].
In this section, we report experimental results on Blippr dataset (Table 1). To evaluate the accuracy of predicted product rank against the gro und-truth rank at a given time slot, we adopted Normalized Discounted Cumulative Gain ( ndcg )measure:  X  X  X  X  X  X  @  X  = 1  X  from 5 to 25 at the step of 5 to evaluate the accuracy of the rank involving top- X  ranked products. We define the relevance of a product  X   X  to be the inverse of its ground-truth on the definition of relevance (i.e.,  X  X  X  X   X  ). However, for a given relevance definition, ndcg well reflects the accuracies of different ranking models.

We compare the performance of the proposed AffRank with three other methods.
 LazyRank . This model predicts product rank at time slot AR . AR model refers to the AutoRegressive model without AffValueRank . With AffValueRank , instead of predicting
As reported in Figure 5, the proposed AffRank model out-perform all three baseline models for every  X  value. Overall, AffValueRank is the second best performing model followed by AR .The LazyRank model performs the worst. Consider-ing the features involved in the four models, the experimen-tal results show that, (i) product affinity rank can be better predicted using the past few product ranks than the sin-gle last rank (i.e., AR &gt; LazyRank ), (ii) the extra features besides the product rank lead to better prediction (i.e., Af-fValueRank &gt; AR ), and (iii), product affinity ranks can be better predicted than the affinity values (i.e., AffRank &gt; Af-fValueRank ) probably due to the smoother distribution of product affinity ranks than affinity values.
 Table 2 shows an example of predicted affinity rank in Blippr . The second and third columns show the top-10 ranked products in weeks 12 and 13 of year 2009, respec-tively. The remaining 3 columns list the predicted ranks using different models. Obviously, our model AffRank accu-rately predicts the top 10 products in week 13 although the exact ranks for products Google Earth , Google and Tweetie for iPhone are not accurate. Besides, our model also detects that Google Earth will acquire more affinity than Google in week 13. Compared to week 12, there are four products newly listed in top-10 (i.e., Tweetie for iPhone , The Dark Knight , The Shawshank Redemption ,and Watchmen ). Our AffRank predicted all four accurately, AffValueRank missed one of them, AR missed two of them, and the LazyRank missed all four.
In this paper, we proposed a predictive model called Af-fRank , that utilizes an array of features to predict the fu-ture rank of products according to their affinities in prod-uct review websites. Informally, product affinity refers to a product community X  X  ability to  X  X ttract X  new members and is measured by the number of new ratings during a spe-cific time slot. We formulate the product affinity prediction problem as an autoregressive model with exogenous inputs (features). We have identified three features, namely affinity rank history, affinity evolution distance, and average rating, for predicting product affinity. Specifically, we discovered several interesting findings related to these features which we exploit in our model. Firstly, the affinity of a product for most products in Blipper tends to increase spikily and decrease smoothly. Secondly, the average dtw distances be-tween products in the same category are always smaller than those between products from different categories. Thirdly, as the average rating increases the affinity intensity increases accordingly within 3 days. Our experimental study demon-strate the effectiveness and superior prediction quality of AffRank compared to three baseline methods.
