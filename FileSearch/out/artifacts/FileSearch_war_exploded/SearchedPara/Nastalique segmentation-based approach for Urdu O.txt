 ORIGINAL PAPER Sarmad Hussain 1  X  Salman Ali 1  X  Qurat ul Ain Akram 1 Abstract Much work on Arabic language optical char-acter recognition (OCR) has been on Naskh writing style. Nastalique style, used for most of languages using Arabic script across Southern Asia, is much more challenging to process due to its compactness, cursiveness, higher con-text sensitivity and diagonality. This makes the Nastalique writing more complex with multiple letters horizontally over-lapping each other. Due to these reasons, existing methods used for Naskh would not work for Nastalique and there-fore most work on Nastalique has used non-segmentation methods. The current paper presents new approach for segmentation-based analysis for Nastalique style. The paper explains the complexity of Nastalique, why Naskh based techniques cannot work for Nastalique, and proposes a segmentation-based method for developing Nastalique OCR, deriving principles and techniques for the pre-processing and recognition. The OCR is developed for Urdu language. The system is optimized using 79,093 instances of 5249 main bodies derived from a corpus of 18 million words, giving recognition accuracy of 97.11%. The system is then tested on document images of books with 87.44% main body recog-nition accuracy. The work is extensible to other languages using Nastalique.
 Keywords Urdu OCR  X  Segmentation-based  X  Classifica-tion and recognition  X  HMMs  X  Arabic  X  Naskh  X  Nastalique Grapheme inventory  X  Ligatures  X  Main bodies  X  DCTs Nastalique is the preferred writing style of Arabic script based languages spoken across Pakistan, Iran, Afghanistan and India, including Baluchi, Kashmiri, Pashto, Persian, Pun-jabi(Shahmukhi),Seraiki,Urdu,andmanyothers,beingused by a population of more than 200 million people. 1 This writ-ing style was originally formulated in fourteenth century CE to optimize the use of paper, an expensive commodity at the time. However, in accomplishing this task of more tightly packing letters in same space, the writing system became considerably more complex compared to its preceding styles. Arabic script written in earlier styles, like Naskh, was already complex, with cursive writing and context sensitive shaping.
In Arabic script, one or more individual letter and diacrit-ics (vowel marks, etc.) join to form a ligature [ 1 ] and ligatures are grouped to form the words. There is no concept of space between words in calligraphy, though in typing it is used to either ensure correct shaping of ligatures [ 2 ].Themainstroke of the ligature is called main body [ 3 ], and secondary strokes arereferredtoas aerab or diacritics. Nastalique makes the system much more complex because it has (i) significantly more contextual shaping rules for a letter based on which letters precede and follow it, (ii) significantly more corre-sponding shapes for each letter, (iii) diagonal joining of letters, instead of horizontal joining to fit more text com-pactly in the same space compared to Naskh and other Arabic writing styles, (iv) letter graphemes which may overlap ver-tically, and (v) due to compact spatial placement of main bodies, much more irregular and unpredictable placement of associated diacritical marks. Many of these complexities are explained in more detail in [ 4 , 5 ](see[ 6 ] for a detailed grammatical analysis of Nastalique writing style). Due to these complexities, once the graphemes of constituent let-ters are cursively fused into ligature, it becomes very hard to determine where the composing letters start or end. Even to spatially predict the first letter in the ligature is difficult. This makes segmentation a complex task in the recogni-tion process. Consequently, much of the earlier work for developing Optical Character Recognition systems (OCR) for Nastalique has been ligature based, and only initial work on segment-based OCRs has been done, which try to recog-nize the constituent letter graphemes directly.

Though ligature-based recognition (also referred to as segmentation-free approach) is easy to train; this technique has two major limitations. First there are many more liga-tures than letter-based graphemes. Analysis of 18 millions words of Urdu text corpus [ 7 ] gives a total ligatures count of about 24,000, whereas the total graphemes for Urdu is about 1000. 2 Second, even if a system is trained for all the existing ligatures, it will not work for the new ligatures added in the language as new words are either formulated or transliter-ated into Urdu. Therefore, a segmentation-based approach is necessary for manageability and scalability of an OCR. The current paper develops a segmentation-based approach for extracting Urdu Nastalique text from document images. Different approaches exist in the literature for the classifica-tion and recognition of cursive scripts. During classification and recognition, initially images are classified into different classes based on shapes similarity. Then, in training phase, the features of an image are given to the classifier along with label of class so that it can learn the shapes. In the recognition phase, using learned information the classifier recognizes an input image class based on extracted features. For the classifier point of view, two types of approaches exist: (1) character-based classification and recognition, in which extracted features of images along with characters labels are given to the classifier for training and recognition, and (2) word/ligature-based classification and recognition, in which the extracted features of images along with the word/ligature classes labels are used for training and recognition. The current state of the art techniques of these categories are dis-cussed below.

Character-based classification and recognition deals with classification of input images into different character classes. The extracted features along with the characters transcrip-tion are then used for the training and recognition. There are two main categories of character-based classification and recognition. In first category, the input image is segmented into constituent characters or smaller primitives. These seg-ments are then classified into different classes for training and recognition.Thetechniquesusedinvariousscriptsexploitthe properties of these scripts. The current section reviews some of these techniques focused on both optical and handwriting recognition tasks.

Letters in Devanagari script are segmented by removing its top line, but the computation of the top line for handwrit-ten text is not a trivial task. Shaw et al. [ 8 ] use morphological operator along with horizontal window of size 1  X  27 to detect the head line of Devanagari script. Hidden Markov Mod-els (HMMs) are used for recognition of 118 letters after the segmentation of words. The system has 81.63% character recognition accuracy and 84.31% word recognition accu-racy, using 22,500 images for training and 17,200 images for testing data.

For Naskh writing style, a segmentation approach for handwritten words of Arabic language is reported in [ 9 ]. The main bodies (of ligatures) are separated, and then segmenta-tion points are computed using horizontal and vertical gradi-ents based on the baseline. They address over-segmentation by ignoring the segmentation points in loops, at edges, and using characteristics of letter shapes. Testing on 200 hand-written Arabic images from IFN/ENIT database gives 92.3% segmentation accuracy. Cheung et al. [ 10 ] use the projection profile and Convex Dominant Points (CDPs) for the segmen-tation of Arabic words into fragments. The fragments of the Arabic words are computed, and then smoothed chain codes are extracted for recognition. They report recognition accu-racy of 90% on images of books, without further details on training and testing data. Mehran et al. [ 11 ] use vertical pro-jection of the line image, first derivative of upper contour, and distance between pen tip and base lines, for the segmentation of main bodies of ligatures into characters. These junction points are used for training a Neural Network (NN). Then segmentation points are marked using the trained NN. The reported accuracy of the segmentation is 98.7%. Following segmentation, normalized values of structural and statistical features are used for the recognition using Support Vector Machines (SVMs). Total of 40,000 samples of main bodies containing 175,632 graphemes are used to train the system, with overall 98.3% character level and 90.17% word level accuracy.

Very limited work has been done on segmentation of char-acters for the Nastalique writing style. Safabakhsh and Abidi [ 12 ] present a segmentation-based technique for the recog-nition of handwritten words. They first remove ascenders and descenders from ligatures to reduce false traversal of right to left order. Then two different segmentation methods are employed and tested on 350 main bodies. First approach uses the singularities and regularities to segment the liga-tures with 77.62% segmentation accuracy. The second uses the local minima, overlapping of stroke information and join-ing position with previous character to extract the candidate segmentation points, giving 95.68% segmentation accuracy. Following segmentation, Fourier descriptor, structural and discrete features are used for recognition using continuous-density variable-duration HMMs, giving 96.8% recognition accuracy. Javed and Hussain [ 13 ] thin the ligatures and then segment them at branch points. These segmented thinned strokes are windowed and Discrete Cosine Transform (DCT) features are computed for each window. The DCT vectors from the sequence of windows for each segment are used to train the HMMs for recognition, and sequenced to formulate the ligature. The test data have synthesized images of 1692 high-frequency ligatures formed by the subset of six of the 21 character classes (see [ 5 ]) at 36 font size. The system has 92.73% base form recognition accuracy. Muaz [ 14 ] extends this segmentation-based approach to include all 21 charac-ter classes of Urdu. The system is tested on 2494 ligatures synthesized at 36 font size, giving an accuracy of 92.19%.
In second category of character-based classification and recognition, features are extracted from images without doing image segmentation. These features along with char-acter labeling are used by classifier for the training and recognition. Sankaran and Jawahar [ 15 ] use bidirectional Long-Short Term Memory (LSTM) model of Neural Net-works for recognition of Devanagari text. They extract contextual information including top foreground pixel dis-tance from the baseline, bottom foreground pixel distance from the baseline, ink-background transitions, number of black pixels and span of foreground pixels using sliding window. The system has been tested on 67,000 words and has 94.35 and 84.87% character recognition accuracy for clean and degraded document images, respectively. The cor-responding word recognition accuracy is 91.38 and 77.85%.
Al-Muhtasebetal.[ 16 ]useverticalslidingwindowhaving three pixels width and height equal to the text line. Sixteen features are computed by dividing the window into different sizes and computing the number of black pixels from each sub-window. Character transcription of a ligature is used for training of HMMs based on these features. A total of 2500 text lines are used for training and 266 for testing, with a total of 46,062 words and 224,109 characters. Eight different fonts have been applied on these text lines and image corpora of these are synthesized separately. Text line images are nor-malized to have height of 80 pixels. The testing gives 99.90, 99.68, 99.34, 98.78, 98.09, 99.70, 98.83 and 97.86% accu-racy for Arial, Tahome, Akhbar, Thuluth, Naskh, Simplified Arial, Traditional Arabic and Andalus fonts, respectively. Al-Khateeb et al. [ 17 ] evaluate different features for the recognition of Arabic language handwritten words. The fea-tures such as mean pixel value of overlapped blocks, first 100 DCT coefficients, first five DCT coefficients extracted from non-overlapping frames, Hu moments and wavelet transforms are computed from normalized word image. The testing is done on IFN/ENIT database with 32,492 Arabic words. The DCT features have 80.75% recognition accuracy where as overlapping blocks, and moment invariant features have 77.75 and 75.75% recognition accuracy using NNs. Al-khateeb et al. [ 18 ] use intensity features for the automatic segmentation and alignment of Arabic language handwritten words using HMMs. The images are normalized to have fixed height. They use a sliding window with three pixels width and height equal to line height. Window is further divided into 15 sub-windows vertically to extract 30 intensity features. These features are used to train the HMMs, with post-recognition re-rankingusingstructuralfeatures.TheyuseIFN/ENITAra-bic handwritten database for training and testing. The system has 82.32% accuracy before re-ranking and 83.55% with re-ranking on v2.0p1e dataset. Khorsheed [ 19 ] extracts three different intensity features including simple intensity, hori-zontal intensity and vertical intensity from each sub-divided window and use HMMs for classification. The data set having 1500 line images is generated containing 116,743 words and 596,931 letters. These images have been synthesized using different computer generated Arabic fonts. All lines have been normalized to 60 pixels height. Using training data of 1500 and testing data of 1000 line images, authors report 87.6, 86.0, 88.0, 89.5, 92.1 and 92.4% recognition accuracy for Thuluth, Naskh, Simplified Arabic, Traditional Arabic, Tahoma and Andalus fonts, respectively, with window hav-ing 12 cells of 3  X  3 size and one pixel horizontal overlap.
Ul-Hasan et al. [ 20 ] present the recognition system of printed Urdu Nastalique using bidirectional LSTM networks. The synthesized Urdu Nastalique data set is used to develop and test this approach. This data set consists of 10,063 syn-thetically generated text lines. Each text line image has been normalized to a fixed height. A 30  X  1 window is moved along the text line image, and pixels values are used as the feature set. The character transcription is used for training and recog-nition. The Recurrent Neural Networks (RNNs) are used for the contextual processing of the characters of text line images. Testing on synthesized data of 2003 text line images gives 94.85% character recognition accuracy for trained data model which has only four positional shapes for each char-acter.

In addition to character-based classification and recogni-tion, techniques for word/ligature-based classification and recognition also exist in literature for the recognition of Nastalique text [ 21  X  27 ].

In this paper, a new hybrid approach for character-based classification and recognition is proposed for Nastalique writing style of Urdu. A new approach is proposed to extract the sequence of features of main body which directly corre-sponds to its character sequence. These extracted sequenced features along with the character class (see [ 5 ]) transcriptions are fed to HMMs for training and recognition. The existing segmentation-based techniques for Nastalique writing style primarily segment the main body into smaller pieces before classification. Such techniques have under-segmentation and over-segmentation issues. In addition, mostly techniques are reported on limited synthesized data set at larger font sizes. The details of the presented technique are given below. Character-based(orsegmentation-based)techniquesusedfor Naskh writing style divide the text into lines. The lines have a character sequence c 1 ... c n , along which a sliding window is moved to extract the corresponding observation sequence o ... o
The observation sequence is used to recognize the cor-responding character sequence. These characters are then grouped into ligatures based on their recognized shapes. So the character sequence C is formed, given the observation sequence O ,asshowninEq.( 1 ).
 P ( C | O ) = P ( c As this is not straightforward to calculate, Eq. ( 1 ) is computed by applying Bayes X  theorem, as in Eq. ( 2 ).
 P ( C | O ) = P The character sequence with maximum probability would be selected as the required sequence, if all characters are con-sidered as candidates. Thus, based on the Eq. 2 , the solution among multiple possibilities is as follows: C = argmax Equation 3 is a comparison of probability between different character sequences, each divided by the same probability P ( O ) which is common therefore can be ignored, simplify-ing to the following: C = argmax The computation of  X  C is not straightforward, therefore by taking the Markov assumption that the character is only dependent on its previous character (bigram probability), P (
C ) is simplified. In addition, P ( O | C ) can also be sim-plified by assuming that each observation o i in observation sequence O is dependent only on its corresponding character c . Therefore, Eq. 4 can be approximated by Eq. 5 .
 C = argmax Normally, the observation sequence is computed using the features extracted from the horizontally sliding window. The horizontally sliding window divide the ligature image into vertical slices (see Fig. 2 a) and then features are computed. This technique works for Naskh writing style, as in this case the letters are placed along the baseline and are not overlap-ping vertically, as shown in Fig. 2 a. However, in Nastalique writing style two issues arise due to which this Naskh based technique cannot be applied. First, due to its complex shapes and diagonality, the characters are vertically overlapping, as shown in Fig. 2 b. This would create a different vertical slice (window contents) for the same letters in different contexts. Second, the positioning of a letter is not on baseline but also depends on (i) its place in the ligature, (ii) contexts of the ligature, and (iii) length of the ligature. Thus, the same letter can occur at different positions within a vertical slice used to window the main body (causing further change in window contents).

Both factors impact the windowing process concurrently, as in Fig. 3 . Figure 3 a, b show different ligatures in Naskh style. Even though the contents of the two ligatures are differ-ent, their windows have same contents for the same letters, e.g., compare windows (1) through (5) in Fig. 3 e, f. Same character sequence is also presented in Nastalique style in Fig. 3 c, d. However, in addition to change in shaping, signif-icant overlapping is also visible. If vertical slicing is now done, it is evident from the vertical slices that both con-tents and placement of signal change, e.g., compare windows (1) through (5) in Fig. 3 g, h. Therefore, the horizontal slid-ing window along the line cannot be used for Nastalique to extract the features for observations uniquely and consis-tently for different characters.

To address these challenges introduced by the Nastalique writing style, the computation of Eq. 5 is organized using a different method. In this method, there are three distinct differences from the methods used for Arabic language in Naskh writing style. First, the traversal is not along the base-line, but along the contour of the ligature main body itself. The contour of main bodies for this traversal is extracted by thinning them. Second, the windowing is not done as a complete vertical/global slice of the main body, but a series of small local windows is used which capture the current letter. This avoids vertically overlapping portions of other surrounding letters. Finally, as Nastalique is written diago-nally, with only the last letter on the baseline, the traversal for Nastalique is done starting from the ending point of the main body toward its beginning (in the reverse order), whereas mostly techniques of Naskh style for Arabic language tra-verse from right to left along the writing direction. This is in continuation of the earlier work [ 13 , 14 ], with the differ-ence that in earlier work the ligature is segmented and each segment is separately recognized and then concatenated to identify the ligature. The traversal sequence presented in this paper ensures the consistent traversal of characters and their strokes. In this paper, though the models are based on charac-ters, the series of characters are recognized using a  X  X anguage model X  for the occurrence of various characters (alphabet, ) within the main bodies (vocabulary, V).

In summary, a new approach to extract the features set for observation sequence is presented which corresponds to the character sequence of Nastalique writing style.

After the main bodies have been binarized [ 29 ] and sep-arated, their thinned contours are extracted. The final point of the thinned image is computed, and a consistent traversal of the main body is defined in such a way that all character strokes are traversed in consistent reverse order of writing direction.

Each main body is windowed along this contour starting from the final point of the main body using defined traversal sequence. The series of windowed vectors produced are fil-tered using DCTs so that observation sequence can be defined for HMMs to model Eq. 5 . The grapheme set is defined which is also challenging for Nastalique writing style due to its com-plexities. The process flow of these steps is given in Fig. 4 . The details of each of these steps are given in subsequent sections. 3.1 Thinned contour of ligature graphemes for traversal The thinned version of main body is formed to traverse it for generating the windowed sequence for recognition pur-pose. Thinning is done using the algorithm proposed in [ 30 ]. Though in most cases the algorithm performs well, due to variation in quality of printing, it presents some challenges due to noisy data including spurious branches and spurious loops, discussed below.

Spurious branches are created during thinning if the main body is noisy at its edges, introduced due to printing quality. Figure 5 gives two instances of the same main body, in which the noisy version in (b) creates spurious thinned branches, not part of the thinned contour produced by the less noisy version in (a).

Based on analysis of the main bodies, the data from 14 point size show that all the spurious branches are less than six pixels. Thus, a simple check which removes all those branches which have pixels length less than or equal to five address this noise. However, in removing these branches, some short length correct branches of initial shapes of (MEEM) and (BEH) letters are also removed. Figure 6 a shows that the initial (MEEM) branch is correctly thinned and retained. However, in Fig. 6 b as the thinned branch is less than six pixels, it is truncated while removing spuri-ous branches, causing an error. This issue is addressed by marking all the main bodies for which branches are trun-cated. Later in recognition process, both main body character sequences are generated with and without truncated initial character for marked cases.
The salt noise in the main body introduces a false loop in the thinned version of main body. This is shown in Fig. 7 . Different algorithms exist in the literature for the removal of salt noise [ 31  X  33 ], but for the efficiency, all white pixels which have seven black neighbors are filled, to avoid gener-ating the false loops. The removal of salt noise is done before applying thinning algorithm.

This is done only in the cases where high frequency errors occur in the recognition phase to minimize performance cost. 3.2 Detection of final point of the thinned ligature In order to traverse the thinned image, a consistent starting point must be identified for each type of main body. The way Nastalique is written, and the initial point of a ligature is very complex to determine. It is not necessarily the right most or topmost free point, even though Nastalique is written from top right to bottom left, because it would depend on the combination of the initial letters. However, the final letter always has a predictable shape, independent of its context, resting on the baseline. Thus, it is easier to determine the final point and traverse toward the initial point of the ligature main body (in reverse).

Even though the ending point is more predictable, it depends on the class of the final letter [ 5 ]. The thinned image of the main body is scanned from bottom to left of its bound-ing box rightward and upward till a black pixel is found. The first black pixel found is stored and marked as the Pivot .Five different classes are defined based on the last character of the main body to mark the final point. The details of the classes along with their final point marking process are given below. Class-1 This class has all those main bodies which have last Class-2 The main bodies which have last character in the Class-3 The third class has all those main bodies which Class-4 For the isolated form of { (HEH GOAL)}, a free Class-5 Isolated form of { (ALEF)} is treated as a special The presence of spurious branches makes the task of finding the final point more difficult because free points of spuri-ous branches may be selected instead of the final point of the main body. If false start point is selected then it would produce wrong traversal of thinned image and would not recognize the main body trained on a different traversal sequence. 3.3 Traversal of thinned ligature contour The feature vector formation for recognition is done in three steps. The thinned contour of the main body is traversed starting from the final point of the main body as determined through the algorithm discussed in the previous section. As the contour is traversed, the corresponding portion of the original image of main body is windowed and filtered to extract the relevant information. The series of these features are used to recognize each main body in terms of charac-ter sequence. The process is discussed in more detail in this section.

As discussed, each main body is traversed from final point in reverse. To extract the feature set from the contour of lig-ature main body so that sequence of observation sequence correspondstothesequenceoflettersshapes,traversalshould have four basic principles. First, each letter should be tra-versed completely and no portion of a letter should remain un-traversed. Second, each letter should be completely tra-versed before starting to traverse another letter. Third, the sequence of traversal of letters should be exactly reverse of the sequence in which they are written (and read), as traversal is done in reverse order. Finally, within a letter, consistency of traversal is desired, i.e. if the letter has multiple branches, the various branches should be traversed in the same sequence for all instances of a letter in different main bodies. Though the consistency within a letter is needed, it is not necessary to traverse these branches within a letter in the sequence these are written.

Insimplecases,thetraversalstartsfromthefinalpoint,and each thinned contour is traversed by moving to its immediate neighbor. A pixel which is already traversed is marked to ensure that it is not traversed again. However, in many cases a pixel may have more than one un-traversed neighboring pixels due to branching, as shown in Fig. 10 .

In such cases, proper branch has to be selected for tra-versal to ensure that a single letter is completely traversed before traversing the next. This selection of branch is not a trivial task. In some cases the branch that is to be selected first is leading upward, as in Fig. 10 a and other cases it may be downward, as in Fig. 10 b. This becomes much more com-plex if there are multiple branch points in letters. The (HEH DOACHASHMEE), shown in Fig. 11 , illustrates this com-plication.

Significant amount of data is analyzed to devise a solu-tion for this complex problem. Eventually, a decision matrix is evolved, with priorities assigned to each direction in neigh-bors of a branch point, as shown in Fig. 12 .Themark x denotes the current branch point and numbers indicate priority of the branch in that direction, with the larger number indicating higher priority. The branch whose first pixel lies in the higher priority direction is traversed first, while other branches are stacked based on their compara-tive priority (most significant pushed last on the stack) and traversed later according to their priority order. A branch which is already stacked may be stacked again (if it is not traversed already). In the same way, the next branch point is extracted from the stack if a free point is found during the traversal of the previous branch. This process is repeated until all stacked points are traversed and last traversal ends at free point indicating complete traversal of the thinned image.

The algorithm using the priority matrix allows for correct traversal decision in Urdu ligatures. In Fig. 10 both ligatures are traversed in the sequence of branch numbers. The case of (HEH DOACHASHMEE) in Fig. 11 is more complex and is illustrated here. After starting from the computed final point (tail of letter), first Branch 1 is traversed. At the first branch point, Branches 4 and 2 are stacked using decision matrix for Priorities of branches. Then Branch 2 is extracted from the stack and traversed, until the next branch point is reached. At this stage, Branches 6 and 3 are stacked. As per priority, Branch 3 (having higher priority as in Fig. 12 )is traversed until the next branch point is reached. At this time, Branches 5 and 4 are added to the existing stack (note that Branch 4 is added to the stack for the second time). Branch 4 is then extracted and traversed, followed by Branch 5 (which is now at the top of the stack, as no further un-traversed branches are left). At the final branch point, Branches 7 and 6 are stacked. Then Branch 6 is popped and traversed, and finally Branch 7 is extracted and traversed, completing the traversal of (HEH DOACHASHMEE) before moving to the next letter. It should be noted that the writing scheme for (HEH DOACHASHMEE) would be 76(6)5423(4)1 (where ( x ) denotes duplicate traversal). However, the reverse tra-versal scheme is 7654321. As discussed, the consistency of traversal is required for recognition, and it may not agree with the writing scheme. 3.4 Observation sequence for a ligature The main body is traversed so that its spatial features can be extractedforrecognitionusingHMMs.ThoughearlierNaskh based systems have windowed ligatures using global bound-ing boxes, the current methodology uses a new technique for Nastalique in which a smaller local fixed window is used along the stroke of the main body having center of the win-dow on the thinned contour. The window size is selected by experimentation. If it is too small it can be totally immersed in the black portion of the thick stroke. However, if it is too large it can contain portions of vertically overlapping charac-ters. Thus, a variety of odd length square windows of w  X  w sizes are used for this experiment, where w ranges from 11 till 33 pixels in length. The window dimension is an odd number to ensure window alignment on the original stroke with its center on the thinned contour.

The windowing of the main body starts from the final point of the main body. The first window is placed on original stroke such that its center coincides with this final point. The next window is moved such that center is placed at each successive black pixel by traversing along the thinned image of the main body (in reverse of writing direction), creating maximal overlap of the windows in the process. This is shown in Fig. 13 .

Recognition accuracy derived from various window sizes is compared for this purpose. All one and two character lig-atures of Urdu (a total of 207 main body types) are used for the comparison. A total of 30 tokens for training, and at least 15 for testing, are used for each type as described in Sect. 4 . The results are analyzed to select the optimum window size for 14 point size text. For the computation of the feature set from window of size w  X  w centered at each thin contour point, DCT [ 34 ] coefficients are computed.

While traversing the main body, a vector of coefficients is extracted from each window by calculating the DCTs of its contents. As low-frequency components of the image in the window give significant information about the region of interest, the top-left coefficients of DCT can be used instead of the whole matrix. Again, to find the optimal level of low-pass filtering, system is tested after separately training the system by taking 6, 10, 15, 28, and 45 DCT coefficients from the top-left of the window. The same training and testing data are used as for determining the windows size, as discussed above. The selected window sizes of w  X  w where w = 11, 13, and 15 are used for testing of optimal feature vector length. The results (discussed later) show that this is independent of the window size. 3.5 Inventory of Nastalique graphemes In order to develop a training model, a fundamental deci-sion is to define the set of unique graphemes which form the ligatures. Normally in Naskh, a letter has maximum of four shapes in initial, medial, final and isolated contexts [ 16 ]. Detailed analysis of Nastalique writing style [ 5 , 6 ] shows that there are multiple shapes of a single letter in initial, medial and final positions, summarized in Table 1 . The number of shapes of a letter ranges from 1 to 40 according to [ 6 ]. In this paper, 20 out of 21 character classes are selected for recog-nition and according to the analysis [ 6 ], total unique shapes of these classes of letters are 488.

First, a detailed analysis is undertaken to see whether all such shapes should be separately encoded or should these be merged into initial and medial positions. This analysis shows that the variation in shape in any of these contexts is caused by two reasons: (i) the change in shape of the letter itself, and (ii) change in shape of the joiner between two letters (though this part is also considered part of the current letter). Some letters change their core shape contextually in addition to the joining part [cases (i) and (ii) above] while others maintain the core shape but only change the joining part [case (ii) above] across different contexts. For example, letter (BEH) in Fig. 14 a changes its initial shape based on the following characters, whereas the letter (TAH) in Fig. 14 b only changes the joining part. Therefore, tri-grapheme model of HMMs (by using Markov assumption of order two) is eventually used (as dis-cussed in the next section), to capture change of shape with change in context. All basic unique shapes of letters at four positions are used for initial training and recognition. Fur-ther, the detailed analysis of the shapes has shown that some characters have shapes with large similar endings, e.g., { (JEEM), (AIN)} and { (SEEN), (SAD)}, causing con-fusion. To minimize this confusion, for example between (SAD) and (SEEN), the shapes of these letters are further divided, e.g., separating the Sir (head) from the Daera (semi-circle at the end) [ 6 ], encoding them as Daera + SAD_Sir , Daera + SEEN_Sir , instead of just SAD and SEEN. As a consequence, a total of 47 graphemes for all main bodies are used for analysis of shapes based on the HMM recognition results.

Although overall recognition results are encouraging (dis-cussed in Results section), but one and two character classes recognition results are very low. After doing detailed analy-sis of the results, it is observed that tri-grapheme model of HMMs works reasonably well for the letters which only change joining portions, as in Fig. 14 b but unable to han-dle the letters which completely change their shapes in the context, as in Fig. 14 a. Therefore these characters are han-dled separately. The letters in set { (BEH), (JEEM), (SEEN), (SAD), (MEEM), (HEH GOAL)} change their shapes at initial position therefore each of these let-ters is separately modeled by different graphemes based on different contexts in the ligatures. The letters in { (BEH), (JEEM), (SEEN), (SAD)} also change their shapes at medial position in different contexts, which are modeled separately. In the same way, letters shapes are separately defined which are different at final and isolated positions, while the rest are modeled with the single shape. In addi-tion, shapes of the Daera for set { (SEEN), (SAD), (QAF), (LAM), (NOON), (YEH)} are also defined separately to improve the recognition results. Hence, starting from 47 graphemes, the number is incrementally increased by testing and analysis of the errors. The main bodies with higher number of recognition errors are either (i) sub-divided based on contextual shaping differences, or (ii) broken into smaller consistent units, where there are confusions across shapes. A total of 250 shapes are finalized based on results. The details of number of shapes for each letter according to the positions are given in Table 1 . The sample graphemes sequences of 47 vs. 250 graphemes sets are given in Table 2 . 3.6 Training and recognition The HMM model  X  = ( A , B , X ) [ 35 ] implemented by Sphinx toolkit [ 36 ] is used for training and decoding. In the HMM model, A,B and  X  correspond to transition proba-bilities, emission probabilities and initial state probabilities, respectively. The input vector consists of DCT-based fea-ture vectors for characters sequence of each main body. The corpus discussed in Sect. 4 is used to train the system. In the training phase, the Baum Welch algorithm is used to maximize the observation sequence probabilities P ( O |  X ) incrementally. The system is trained, with a sequence of five states (where the default is three states, which does not work well for the current system due to the complex-ity of the shapes). No manual segmentation of main bodies is conducted. The prior probability, i.e., P ( C ) of Eq. ( 5 )is computed using language model and observation likelihood P ( O | C ) is computed using the grapheme model. The lan-guage model is developed based on the available Urdu text corpora [ 7 , 37 , 38 ] explained in Sect. 4 . The weighted prior probability of language model is combined with the likeli-hood model of observation sequence. The weight threshold of prior probability is set as 9.5 which is optimized on the data. A lexicon is developed which maps the sequence of recognized graphemes to respective one of the main bod-ies. All 5249 main bodies are defined using letters grapheme sequence from the inventory of 250 graphemes (explained in previous section) for output. Sample entries of the lexicon are shown in Fig. 15 .

For decoding, Viterbi-type beam search algorithm is used which computes ranked list of high probability character sequences using the optimized HMM  X  =(A,B,  X ) , and input observationsequence.Thetop n highestprobabilitycharacter sequences CS ={ cs 1 , cs 2 , cs 3 ,..., cs n } with probabilities {
P  X  X  X   X  P Urdu ligatures may be formed by joining one or more charac-ters. To make the system robust, the system must be trained on all types of Urdu ligature main body classes. Currently no standard image data set is available. One way is to generate synthetic data set by extracting all possible valid ligatures from the Urdu text corpora. In this paper, two types of data are used; (1) synthetic data, and (2) real data. To generate the syntheticdata, text corporahaving18millionwords collected from online sources [ 7 ], text extracted from CLE Urdu Text Corpus for 14 to 40 point sizes [ 37 ] and one million words of CLE Urdu Digest Corpus [ 38 ] are used. This cumula-tive corpus has a total of 149,465 unique words of Urdu, which are formed by a total of 23,951 unique ligatures. If the diacritics on these ligatures are ignored, they give 10,374 unique main bodies. Among them, 5249 main bodies are short-listed based on frequency of occurrences, as per the distribution given in Table 3 below. The selected main bod-ies cover 93,018 high frequency words out of the 149,465 unique Urdu words. The ligature string of these main bodies is printed at 14 font size and scanned to generate synthetic data set. The connected components of ligature images are extracted and diacritics and noisy connected components are removed using dimensional features to have only main body instances. These main body instances are distributed into dif-ferent main body classes using character class information (see [ 5 ] for details).

In addition to the synthetic data set, the main body instances are also collected from document images of Urdu books. In this paper, this data set is called real data set. The main body instances at 14 font size are extracted from image corpus available at [ 39 ]. This image corpus is gathered from 500 text pages of 100 books, by scanning five different pages from each book. This corpus has diversity of publish-ers, publication dates, publishing quality, paper quality and domains. The extracted main bodies are manually cleaned and distributed into different classes using character class information.

By using real and synthetic data set of main body classes, the training and testing data is extracted. An experimental study has been carried out to see the optimal number of training samples. Based on results, 30 samples are used for training and 15 samples are used for testing. To make the system robust, 50% of the training data is collected from real data and remaining 50% is collected from synthetic data set. Therefore, where available, 15 real data samples and 15 synthesized data samples are used for training. If insufficient ( &lt; 15) number of real data samples is available, additional synthesized samples are added to keep the total sample count to 30. In addition, at least 15 non-overlapping (not used in training) real data samples for each main body class are also kept to test system. Where insufficient real data (less than desired samples count for training or testing) is available to cover both training and testing, real samples are preferred to be used for testing. For the current system, sufficient real data (having 15 samples) are captured for 584 main bodies for training, and 1823 additional main bodies have insuffi-cient real data. Remaining types of 5249 main bodies classes are trained using completely synthesized data. Each step in the process explained above has been sepa-rately tested, and the results are given here. The testing data discussed in Sect. 4 has been used to test the system. The accuracy results of each phase of the system are given in sub-sequent sections. 5.1 Final point computation accuracy After thinning and filtering, the first step is to determine the final point of the thinned ligature. Wrong detection of final point can cause erroneous traversal and eventually misrecog-nition of the main body. Therefore, it is crucial to accurately identify the final point of the main body, which is starting point of the traversal. The computed final point is marked withspecificcoloronthethinnedmainbodyimage.Theman-ual pass has been carried out to check whether the marked point is correct final point or not. This manual inspection of at least 15 or more samples of each of the 5249 types shows an overall accuracy of 99.83%. For 5249 main body classes, the accuracy is also computed according to the character class of last letter of the ligature and is given in Table 4 .
The final point finding algorithm gives the promising results as can be seen in Table 4 . The deterioration in the results is mainly due to the main bodies of Class-3. Some-times due to the sample variation, the Damon and (YEH BARREE) are not detected and false start point is marked, but these instances are rare. Other errors are due to quality of input image causing distortion of the main body stroke resulting wrong identification of start point. 5.2 Traversal sequence computation accuracy The traversal starts from computed final point, as per the scheme already presented in Sect. 3.3 . The traversal of main body in context of consistent character sequence and consis-tent branch sequence for each character is a complex task due to complex shaping characteristics of Nastalique. The main bodies having single branch point for each character or no branch point for complete main body stroke have consistent and straightforward traversal. The main bodies which have complex characters such as (HEH DOACHASHMEE) and (KAF) etc. add complexity in the traversal sequence. An automatic way cannot be used for verification of traversal of 79,093 main bodies. Therefore, the sequence of traversed strokes is colored using the defined scheme, where each color indicates specific sequence number. A manual pass is then carried out to verify traversal sequences of all main bodies using colored thinned image and accuracy is computed. The accuracy is reported as per character length of main body image as can be seen in Table 5 .

The majority of the errors are due to the wrong identifica-tion of the start point. Other errors are due to the main bodies which have (KAF+ALEF) and (HEH DOACHASH-MEE). For these shapes, the branch priority matrix does not work consistently due to the variation of the shapes, distorted shapes due to poor paper, printing and scanning quality. 5.3 Optimal feature vector computation accuracy As the main body is traversed, sequence of feature vectors are generated by selecting low-frequency components of DCT of the windowed portions. In order to determine the optimal length of the feature vector, accuracy of recognition is com-puted for different feature vector lengths from 6 to 45 for three window sizes. The subset having 206 main bodies con-taining one and two letters formed by initial and final shapes of all the 20 letter classes is used for this analysis. HMMs are trained on each combination of selected feature vector length of low-frequency DCT coefficients and window sizes. Thirty tokens for training and 15 tokens for testing are used, as dis-cussed in Sect. 4 . The accuracy of the system is measured in terms of the accurate result of the top recognized option in output character sequences CS . As shown in Fig. 16 ,the results indicate that feature vector length of 15 gives most accurate results. Interestingly, this process is independent of the window size, as is more clearly visible in the Fig. 16 . 5.4 Optimal window size computation accuracy After finalizing the feature vector length, the window size is optimized by doing experiments of different values of win-dows size. Again same data set of 206 main bodies is used. The different systems using different window sizes from 11  X  11 to 33  X  33 and feature vector of top-left 15 DCT coef-ficients are trained and tested. Again for this analysis, the accuracy of the system is measured in terms of the accurate top recognized option in CS . The results presented in Fig. 17 show that the grapheme recognition accuracy saturates for window sizes larger than 19  X  19. Window sizes 23  X  23 and 29  X  29 provide most accurate results; however, window size of 23  X  23 is finalized as it gives better performance. 5.5 Grapheme recognition accuracy After setting of optimal window size and feature vector length, the complete data of 5249 main body types discussed in Sect. 4 are used for the training of HMMs. During test-ing, at least 15 tokens of each main body type are tested on the trained model. The grapheme recognition accuracy is computed automatically by using annotated grapheme sequence of each main body image of test data. The recogni-tion result is considered as correct if the top ranked character sequence is the desired option. The overall accuracy of 96.49% is achieved without removal of spurious branches. This accuracy is increased to 97.15% by truncating the spu-rious branches introduced through the thinning process (see Fig. 5 ).

In addition, the accuracy of the system is also computed separately on data with and without removal of salt noise to see the impact. The system without removal of salt noise has 97.15% recognition accuracy, whereas it has 97.17% recognition accuracy after removal of salt noise.

As discussed in Sect. 3.5 , accuracy of the system may vary with the size of the grapheme inventory. Both sub-division of letters into sub-units and labeling of different shapes of same letter are done and tested. Initially to set up, the granu-larity of shapes, e.g., dividing (SEEN) and (SAD) into sub-units, is tested for the 206 types which include one and two letters main bodies. This division improves the overall accuracy over 206 types from 97.41 to 97.52% and therefore incorporated in the system. The size of inventory is gradually increased based on the analysis of the misrecognition. Dif-ferent unique graphemes for a letter, based on the position such as (BEH) at initial and medial positions are defined based on the variations of the shapes. Hence, the graphemes are increased from 47 to 250, based on shape analysis of errors. The accuracy results of each character class with 47 graphemes and 250 graphemes are given in Table 6 .
After maturing the system on 5249 main body types, addi-tional testing is done on document images scanned from different books of 14 font sizes. Total of 25 pages scanned from 22 different books having variety of paper, print and page transparency qualities are used. The samples text lines of these pages are shown in Fig. 18 . The samples of line images are given in Fig. 18 a, and corresponding recog-nized ligatures are given in Fig. 18 b. The desired graphemes sequence of each ligature main body is defined manually. In addition, the desired ligature strings of all ligatures are also marked to automatically compute main body (character class grapheme sequence) and ligature (character sequence) recognition accuracy. For the testing of document images, the recognition results are computed based on the existence of desired output in the ranked list of character sequences. The separate diacritics recognition system is used for recognition of diacritics. Then lookup table is used which maps the recog-nized main body and diacritic sequence to the respective ligature string. The recognition results are reported accord-ing to the length of ligature. The main body recognition and ligature recognition accuracies are reported in Table 7 .The significant change in the recognition accuracy for the doc-ument images can be seen in Table 7 . As can be seen in Table 6 , the overall impact of accuracy results of 250 classes versus 47 classes is not as significant while tested on the data discussed in Sect. 4 . The overall recognition accuracies are 97.15 and 97.11% for 47 and 250 grapheme classes, respec-tively. As anticipated, with increase in classes, the overall accuracy actually falls slightly. However, even though the overall system accuracy deteriorates slightly, the scanned document text recognition accuracy significantly increases. This is because, though the overall accuracy is calculated uni-versally over all classes of 5249 main bodies being tested, in document images the distribution of main bodies according to number of character classes is skewed as can be seen in Table 7 . Majority of the main bodies formed by one, two and three characters occur much more frequently than the main bodies which have many more characters cursively joined. Because the system based on 250 grapheme classes has much higher accuracy for these main bodies of classes (as shown in Table 6 ), it performs better on document images. The testing data of scanned document have 18,409 ligatures. The overall main body recognition accuracies for 47 graphemes and 250 graphemes are 77.17 and 87.79% respectively. The ligature recognition accuracies are 77.8 and 88.07% for 47 and 250 graphemes respectively. The entries of lookup table for the recognized main bodies and diacritics sequence also handle some misrecognized main bodies and output correct ligature string using recognized diacritics sequence. Especially the confusing letters such as (SEEN) and (BEH) are han-dled in lookup table using recognized diacritics. As can be seen in Table 7 , for some cases, ligature recognition accuracy is low as compared to the main bodies, this is mainly because of the misrecognition of diacritics or some noisy connected components which are erroneously marked as diacritics. The details of diacritics recognizer and look up table are not in scope of the current paper.

The recognition results of proposed segmentation-based system on document images are promising. The majority of errors are due to the spurious branch removal process. For such cases, respective character is misrecognized. In addi-tion, medial shapes of (BEH) and (SEEN) are also confused by the HMMs. These cases are resolved during the recognition of ligature string using recognized main body and diacritics sequences from look up table. The diacrit-ics eventually help to remove such confusions of (BEH) and (SEEN) etc. In addition, main bodies having (KAF+ALEF) and (GAF) also cause errors in the recog-nition of respective character(s) of main bodies.

The analysis shows that a document image of 14 font size has on average 737 ligatures per page. The per page main body recognition accuracy is 87.44% and ligature recogni-tion accuracy is 87.76%. The overall grapheme recognition accuracy of proposed system is 96.57% on the testing data discussed in Sect. 4 . The major reason for the misrecogni-tion of scanned document text is distortion in the page image causing broken and joined connected components of main bodies (as can be seen in Fig. 19 ) and erroneous thin image which affects overall accuracy of the next processes such as spurious branch removal, consistent traversal and eventually HMMs recognition.
 In this paper, segmentation-based technique using HMMs as a classifier is proposed for the recognition of Nastalique text. The existing feature extraction approaches which are based on horizontal traversal of text lines for observation sequence of HMMs work well for Naskh. These approaches are not applicable to Nastalique writing style due to global vertical windows. Therefore, a new approach to extract features for observation sequences is proposed. This approach uses char-acter traversal along the thinned contour of the main body to address the complex shaping and overlapping characteris-tics of Nastalique. Further, local (smaller) window sizes are used to extract observation sequence. The different stages including, thinning, start point detection, consistent traver-sal of strokes and feature vector computation are developed and fine tuned. Due to complex shaping, character classes are incrementally changed from 47 to 250 to improve the accuracy results. The overall recognition accuracy is 97.11% tested on 79,093 instances of 5249 main body classes. The proposed system is also tested on document images of differ-ent books with 87.44% main body recognition accuracy. This type of segmentation-based system is fully capable of recog-nizing any new Urdu words because the recognition of the system is based on character classes (unique shapes without dots) not on characters, e.g., [ 20 ] or ligatures, e.g., [ 22  X  27 ]. The presented system will recognize characters class sequence of new ligature. The separate diacritics recognizer will recognize the diacritics sequence and will eventually recognize ligature string using look up table. The ligature-based [ 22  X  27 ] and character-based [ 20 ] techniques for the recognition of Nastalique text would not be able to handle new Urdu words. To develop the system, a detailed charac-ter class contextual shaping analysis has been carried out on the huge data. This character class-based classification and recognition system reduces training data for the classifier to learn efficiently and effectively as compared to the character based [ 20 ] and ligature based [ 22  X  27 ] systems. The system already covers most high-frequency ligature words extracted from the corpus. One to one comparison of presented and existing systems for the recognition of Nastalique text is not possible due to unavailability of standard training and testing data set. Almost all the presented techniques are trained on the synthetic data set of larger font sizes. Some techniques have missing information about data set, ligature coverage, character coverage and font size.

The system can be easily extensible to other font sizes as well. An experiment study has been conducted to train and test main bodies of 16, 22 and 36 font sized text. After doing minor changes, i.e., tweaking the values of window size, feature vector length and some thresholds, the systems have reasonable recognition accuracies. In future, the system is being extended to include unknown contextual character class sequence shapes of lower frequency words and corre-sponding main bodies.

