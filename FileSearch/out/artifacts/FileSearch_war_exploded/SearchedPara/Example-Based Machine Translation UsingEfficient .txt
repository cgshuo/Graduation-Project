 TAKAO DOI, HIROFUMI YAMAM OTO, and EIICHIRO SUMITA ATR Spoken Language Communication Research Laboratories 1. INTRODUCTION
Since the concept of analogy-based machine translation was advocated [Nagao 1984], many Example-Based Machine Translation (EBMT) methods have been proposed as concrete forms of the concept. An EBMT system retrieves the translation examples that are most similar to an input expression and ad-justs the examples to obtain the translation. The translation example unit is usually a phrase and the translations of phrases are combined into a transla-tion of the input sentence. Although a phrase looks like a suitable translation example unit because of its generality for covering various sentences, there is a risk of mixing errors or producing unnatural translations while combining phrases into a sentence [Somers 2003]. On the other hand, the risk can be reduced if the translation example unit is a sentence. A translation example similar enough to an input sentence, as a whole, results in an accurate and natural translation of the input sentence. Of course, an EBMT system whose translation example unit is a sentence (hereafter, we call this a sentence-wise
EBMT system), suffers from the problem of narrow coverage, because a sen-tence is a longer unit and its generality is lower. To achieve a sufficiently broad translation coverage by using sentence-wise EBMT, we must prepare a large-scale parallel corpus and, therefore, an efficient method is needed to retrieve translation examples from a large-scale corpus.

Sumita [2003] proposed the Dp-match Driven transDucer (D 3 wise EBMT method and demonstrated its effectiveness in Japanese-to-English translation in a travel conversation domain. In this EBMT method, translation examples are sentence pairs of source and target languages, and sentences are expressed as word sequences. When translating an input sentence, the sys-tem retrieves the translation examples whose source sentences are the most similar to the input sentence using the measure of edit-distance. Translation patterns are then dynamically generated by considering differences between the input sentence and the translation examples. D 3 keeps and retrieves trans-lation examples that are not abstracted more than the word sequences given in a corpus. Furthermore, the changes in the target sentences of translation examples are kept as small as possible while generating translations. There-fore, if there are examples similar enough to given input sentences, natural translations are produced.
 In this paper, we propose a retrieval method for D 3 to use a large-scale corpus. An efficient retrieval method for EBMT has much in common with Translation
Memory (TM). Research efforts on TM [Sato 1992; Cranias et al. 1997; Planas and Furuse 1999; Baldwin and Tanaka 2001] focus on filtering algorithms for the sentences that are to be retrieved and/or matching algorithms between two sentences. The methods adopting filtering algorithms, first, filter sentences out, and then, for each of the sentences left as candidates, repeat the matching proce-dure between the two sentences X  X  candidate and the input. In Cranias et al. [1997], for example, while a similarity is defined between word sequences of two sentences, the filtering process uses a clustering technique, where clusters are represented by their centers. In this system, omissions can occur from the viewpoint of the similarity definition, that is, similar sentences can exist in clusters that are not selected. Another study on TM [Rapp 2002] proposes re-trieval based on an exact match at the level of parts-of-speech. However, this retrieval method cannot deal with a flexible matching of D tions and deletions of words and considers semantic similarities. This paper proposes an efficient retrieval method without omissions as a solution for the problem of searching for the sentences with the least edit-distance among a corpus. This method does not repeat the matching procedure between two sen-tences, but proceeds with concurrently matching between the input sentence and sentences in a corpus, where the sentences are expressed as a graph.
In experiments for performance evaluation, we use a corpus comprising hun-dreds of thousands of sentences from a travel conversation domain. First, we evaluate the fundamental performance with respect to translation quality and processing time. We then evaluate the effect of using larger corpora. Finally, we conduct experiments combining D 3 and other techniques to further compensate for the narrow coverage.

The following sections give an overview of D 3 , an overview of the retrieval method, a description of the search algorithm of the method, and a performance evaluation. 2. D 3 OVERVIEW 2.1 Configuration
As shown in Figure 1, D 3 uses three linguistic resources: a bilingual corpus, a bilingual dictionary, and thesauri. The bilingual corpus is part-of-speech tagged and is a set of sentence pairs, one of which is in the source language and the other is in the target language of the concerned translation direction. Each sentence of a pair is the translation of the other. D 3 utilizes sentence pairs in the bilingual corpus to translate input sentences. Hereafter we call the sentence pairs translation examples. The bilingual dictionary is used in the phases of pattern generation and word substitution. Thesauri are prepared both for the source language and for the target language which are used in the phases of example retrieval and pattern generation. 2.2 Algorithm
As shown in Figure 1, the translation process consists of four phases: (1) exam-ple retrieval, (2) translation pattern generation, (3) translation pattern selec-tion, and (4) target word substitution. These phases are as follows. 2.2.1 Example Retrieval. The example retrieval step scans the source parts of all translation examples in the bilingual corpus. By measuring the distances between the word sequences of the input and example sentences, the algorithm retrieves the examples with the minimum distance. If the minimum distance is not small enough, the examples are not useful for translation. There-fore, we use a threshold for the distance. If there are no examples within the given threshold, the retrieval, and, furthermore, the whole translation process fails with no output. The distance between word sequences is defined as dist in
Eq. (1), the edit-distance, including a semantic factor. In this equation, L and L example indicate the word numbers of the input sentence and the source sentence of the example. I and D are the numbers of insertions and deletions, respectively. Substitution is considered as the semantic distance between two substituted words, described as SEMDIST . Substitutions are permitted only between content words of a common part of speech. Following this equation, dist is the total value of insertions, deletions, and substitutions normalized by the lengths of the word sequences. SEMDIST is defined using a thesaurus and ranges from 0 to 1 and is the division of K (the level of the least common ab-straction in the thesaurus of two words) by N (the height of the thesaurus) according to Eq. (2) [Sumita and Iida 1991].
We show a sample translation process in the Japanese-to-English direction below. (1-j) is the input and (2-j) is the source sentence of a translation example, where the shaded parts represent the differences between two sentences. (1-j) (2-j) Because  X   X  and  X   X  are completely dissimilar in the given thesaurus,
SEMDIST is 1 and, therefore, the dist, becomes (0 + 0 + 2 The dist can be calculated by a standard dynamic programming technique X 
DP-matching [Cormen et al. 1989], which indicates not only the distance, but also the different parts between two sentences. 2.2.2 Translation Pattern Generation. Translation patterns are generated based on the translation examples retrieved. In a translation pattern, some source words that are different from the words in the input, and the target words corresponding to the source words are substituted with variables. We decide which parts in bilingual sentences correspond to each other, by using the bilingual dictionary and thesauri. 2 When we find corresponding parts, we do not have to align all the words. Instead, we assume that nonvariable parts cor-respond together as a whole. This keeps most parts of the example unchanged and, therefore, reduces the risk of mixing errors or producing unnatural translations.

For example, (2-e) is the target sentence of the translation example whose source part is (2-j), where the shaded parts correspond to each other. (2-j) (2-e) I do not like the .

From this correspondence, the translation pattern is generated, where the source part is (2-j-p) and the target part is (2-e-p). The variable binding by the input is (1-j-b). (2-j-p) (2-e-p) I do not like the . (1-j-b) X =  X   X  2.2.3 Translation Pattern Selection. Because there may be multiple trans-lation examples with the same distance, multiple translation patterns can be generated. This requires us to select the most suitable one from among these translation patterns; we use heuristic rules for this purpose. If there are mul-tiple patterns, we select one, such as: (1) the one with the smallest gaps with the input; (2) the one with the largest number of retrieved translation exam-ples that generates the same translation pattern; and (3) the one with the largest sum of word frequencies in the translation pattern against the corpus.
The  X  X ap X  in (1) considers the number of variables corresponding to no target words and the number of insertions and deletions in the matching with the input sentence. If the heuristic rules cannot select one, a random selection is done. 2.2.4 Target Word Substitution. For the selected translation pattern, we get the translation words for the source words bound to the variables using the bilingual dictionary, 3 and instantiate the variables within the target part of the pattern by the translation words.

In the sample process we are using, the variable binding in the target part is (1-e-b). We finally get the translation sentence (1-e). (1-e-b) X =  X  X olor X  (1-e) I do not like the . 2.2.5 Insertions and Deletions. In the sample process we have used to de-scribe the algorithm so far, the difference between the input and the source sentence of the translation example is a substitution. However, we allow inser-tions and deletions. Insertions, which occur only in the input, are not built into the translation pattern and are ignored in the target word substitution phase.
Deletions, which occur only on the example side, are unbound variables in the source part of the translation pattern and the same variables in the target part, if they exist, are substituted with null strings in the target word substitution phase.

Insertions and deletions cause an omission of information in the input or the translation example. The definition of the distance dist places the priority on the substitutions of semantically similar words over insertions and deletions. After considering the priority, allowing insertions and deletions gives D against phenomena in spoken language, such as the omission of particles. 3. EXAMPLE RETRIEVAL
Among the processing phases described in the previous section, example re-trieval tends to take the greatest part of the translation processing time. The measure for selecting examples is the edit-distance, defined in Section 2.2.1.
The example retrieval process is used to retrieve all of the sentences, whose edit-distance against a given input sentence are the least and within a given threshold from among the candidate sentences, which are all of the source sen-tences in translation examples. This distance is defined by the relation of two sentences and can be calculated using DP-matching between the two sentences.
Therefore, the candidate sentences of the least distance can be achieved by re-peating DP-matching between a candidate and the input. However, because the procedure of such a naive algorithm takes time in relation to the number of translation examples, it is difficult to implement real-time processing for translation using a large-scale corpus on ordinary computers. Consequently, we propose an efficient retrieval method using the classification of candidates, word graphs, and an A  X  search algorithm. This method does not produce omis-sions. That is, in the definition of the distance dist and a given threshold, the retrieval result of this method is the same set of sentences as the case of using
DP-matching sequentially. 3.1 Candidate Set Classification
Candidate sentences are classified by the number of content words and the number of functional words. This makes it possible for candidates to be filtered according to the numbers of content words and functional words in the input sentence and the distance threshold. That is, the least possible distance can be calculated on the assumption that all content words are the same as each other and all functional words are the same as each other. The classes of the least possible distance greater than the threshold are filtered out. The smaller the least possible distance of the class, the sooner the search process is applied to the class. If a candidate of distance smaller than the threshold is found in a class, the threshold is updated with the distance of that candidate. The smaller threshold can filter out more classes. The retrieval algorithm using classes is described as follows, where the retrieval in a single class is a black box. 1. Let S be empty,  X  be the given distance threshold, and Q be the list of classes whose least possible distances are not greater than  X  ; the class with smaller distance is former in Q .
 2. Terminate and return S as the solution of this algorithm if Q is empty or 3. Perform the retrieval in the class at the head of Q with 4. Branch by the conditions as follows, where dist ( S ) represents the distance 5. Delete the head element from Q and return to 2.

The search algorithm for retrieving sentences from a single class is described in Section 4, where we utilize the precondition that all sentences in a class have the same number of content words and the same number of functional words and, therefore, the same number of words. 3.2 Word Graph
For each group classified by the numbers of content words and functional words, illustrates an example of a word graph, which is a directed graph, consisting of nodes and edges, and has start and goal nodes. A node is represented with its identifier, such as a number in the figure. An edge consists of a word as label, a source node, and a destination node. Each possible path from the start node to the goal node corresponds to a candidate sentence. Common word sequences in multiple sentences share the same edges. The word graph is compressed so that the number of nodes is the minimum by the method of converting finite state automata [Brzozowski 1962]. By using the word graph, the search process concurrently scans all the sentences in a class.
 3.3 A* Search Algorithm
The result of matching between two word sequences is represented as a se-quence of substitutions, insertions, and deletions. We call the result a matching sequence. The search process in a class is to search for the matching sequences of the least distance among all possible matching sequences between the input sentence and each sentence of the class. We use an A* search algorithm [Nilsson 1971] to solve the search problem.

Generally in an A* search algorithm, the state of the least-estimated cost is selected and extended into successor states. In our search problem, the state means an incomplete matching sequence between the input sentence and a path from the start node to the goal node in a word graph. 4. SEARCH
The method for selecting a sentence class from among classes, which are com-piled into word graphs, is described in Section 3.1. In this section, we focus on the search process using the word graph for a class. A word graph consists of nodes and edges and it has start and goal nodes. An edge has three attributes: source, destination, and label, whose contents are as follows: source : Source node. destination : Destination node. label : Word for the condition of transition from the source to the destination. 4.1 State Space Representation
We represent the search problem using the state structure, operators, and the definitions of initial state and goal state. 4.1.1 State. A state has four attributes: paths, node, input, and trans, whose contents are as follows: paths : List of partial matching sequences. node : Node in the word graph indicating that matching has proceeded until this node. input : Partial word sequence of the input sentence not used for matching yet. trans : Indicator of operators available to this state.

An exact match, a substitution, an insertion, and a deletion in matching sequences of the paths are represented as records, including a label and a word or words: (E, word ), (S, graph word , input word ), (I, input word ), and (D, graph sequence in the paths, where matching sequences have the same cost. The cost of a matching sequence is the sum of costs of the records in it. The costs are defined as 0 for an E record, 1 for an I record, and 1 for a D record. The cost for an S record is defined as twice the semantic distance between the words in the record, except that it is a small positive value when the distance is 0. small value gives us the minimum cost of an S record. 4.1.2 Operators. A state is expanded into a successor state by an opera-tor. We use five operators, four of which correspond to operations of matching process, that is, an exact match, a substitution, an insertion, and a deletion, re-spectively, called E-operator, S-operator, I-operator, and D-operator. The other operator is called T-operator, which controls interstate transition; that is, it controls the application order of other operators.

These five operators are defined as follows. While each T-operator and I-is represented with a dot such as s .trans that means the trans attribute of the state s . For each operator, we describe the condition where the operator application.

T-operator :
E-operator :
S-operator :
I-operator :
D-operator : In the definitions above, the selection from S-operator and NIL means
NIL otherwise. We judge that the possibility exists if the head of s .input is a content word and there is an edge whose source is s .node and whose label has the same part of speech, but is not identical to the head of s .input. The selection from E-operator, S-operator, and NIL means E-operator if there is an edge whose source is s .node and whose label is the head of s .input; otherwise, it is the same as the selection from S-operator and NIL. T-operator does not proceed to the actual matching process, but controls the application order of other operators through the trans attribute.
 The second condition of D-operator prohibits a D record after an I record. That is, we make it a rule to pu t a D record before an I record in a sequence of
I and D records in order to avoid the redundancy of the multiple appearance of what are essentially the same matching sequence. 4.1.3 Initial and Goal States. In the initial state, the paths attribute is a list of an empty matching sequence, the node attribute is the start node, the input attribute is the whole word sequence of the input sentence, and the trans attribute is the E-operator. A goal state is such a state whose node attribute is the goal node and whose input attribute is empty. 4.2 Search Algorithm
From the state space formed using the definitions of the initial state, the oper-ators, and the goal states, we search for the goal states of the minimum cost.
As an initial condition, an upper limit of cost is given, which is a given distance threshold multiplied by the sum of the lengths of the input sentence and a candidate sentence in the word graph. 4.2.1 Evaluation Function. We define the evaluation function f follows: of the state and can be calculated from s .paths. If s is a goal state, f a goal state.

All sentences in a word graph have the same number of content words and the same number of functional words. Therefore, we can tell the numbers of content words in the input sentence, content words in the word graph, func-tional words in the input sentence, and functional words in the word graph, which are untreated in the state s . Here, these numbers are represented as
C on the numbers of untreated words, is expressed as h ( s ) below.
Furthermore, on the assumption that one of the operators E, S, I, and D is applied to the state s where the application of T-operator precedes if necessary, the lower limit of the cost from s to a goal state is expressed as h ( s , o ), where E-operator : h ( s ).
 S-operator : h ( s ) plus the minimum cost of an S record.
 D-operator :
H c + 1 if there is no edge whose source is s .node and whose label is a functional word,
H f + 1 if there is no edge whose source is s .node and whose label is a content word, 1 plus the minimum value between H c and H f otherwise, where By using these values, h  X  ( s ) is defined as: (1) h ( s ,E-operator) if s .trans is
E-operator; (2) the minimum value among h ( s ,S-operator), h ( s ,I-operator), and h ( s ,D-operator) if s .trans is S-operator; and (3) the minimum value be-tween h ( s ,I-operator) and h ( s ,D-operator), if s .trans is NIL. 4.2.2 Algorithm. The search algorithm is described below, where OPEN is a list of unexpanded states and CLOSED is a list of expanded states. The sameness of states in 5. means that two states are the same if they have the same value for each attribute except the paths. 1. Set the value of the upper cost limit and let OPEN be a list including the 2. Terminate unless OPEN has a state of cost within the upper cost limit. 3. Remove a state s of the least value of f  X  from OPEN and put s into CLOSED. 4. If s is a goal state, keep s as a solution, and replace the value of the upper cost limit with the cost of s and return to 2. 5. Expand s into all of its successor states and for each successor state s ,if f  X  ( s ) is within the upper cost limit, branch by the conditions: (a) if there is no same state as s in either OPEN or CLOSED, put s into (b) if there is the same state as s whose cost is larger than that of s in (c) if there is the same state as s whose cost equals that of s in CLOSED, (d) if there is the same state as s whose cost equals that of s in OPEN, add 6. Return to 2. 4.2.3 Optimization Based on Word Graph Characteristics. Word graphs tend to have the a larger number of edges originating from the start node than edges originating from another node. Therefore, when D-operator is applied to a state whose node attribute is the start node, many successor states are generated consuming processing time, which is the case when the head of a matching sequence is a D record. We prepare a series of pseudo edges and nodes originating from the start node to avoid the generation of a large number of successor states. This time, when D-operator is applied to a state whose node is the start node, the state is expanded to a successor state whose node is the first pseudo node. The first pseudo node is the source of edges whose labels are the second words of candidate sentences and the edges flow into the ordinary network. A state of the first pseudo node is expanded into a state of an ordinary node by E-operator or S-operator and into a state of the second pseudo node by
D-operator. It can be deduced from the possible maximum distance threshold how many steps of pseudo nodes we should prepare. On the condition that the length of a candidate sentence is L and the length of the series of D records on the head of a matching sequence is d , the input sentence with the least possible distance is the sentence made from the candidate by deleting d words in the head. The distance is then d / (( L  X  d ) + L ). If this distance is greater than the maximum distance threshold , we can give up the search. Therefore, d / (( L  X  d ) + L )  X  is the constraint on d and it deduces d maximum integer of d under this condition is the number of steps of pseudo nodes we should prepare. 4.3 Example
We next, present an example of the search process. In this example, we search for the sentences most similar to the input  X   X , whose literal English translation is [all/get arranged/POLITE/PAST], from the word graph in
Figure 2. The input word sequence is ( ), where the words are treated as their base forms. A state is represented by [paths, node, input, trans, f value], where the numbers attached to the nodes in Figure 2 are used for the node attribute.  X  indicates the minimum cost of an S record. The semantic distance between  X   X  and  X   X  is assumed to be 1.0 and that between  X   X  and  X   X  is assumed to be 0.7. The initial state is s 0 below on the setting. s 0 = [(()), node-0, ( ), E-operator, 0]
E-operator and T-operator are available to s 0. Through the application of these operators, successor states s 1 and s 2 are generated and OPEN becomes s 2 } . s 2.trans is NIL because there is no edge whose source is node-0 and whose label has the same part of speech of  X   X  except for the identical word. s 1 = [(((E, ))), node-1, ( ), S-operator,  X  ] s 2 = [(()), node-0, ( ), NIL, 2]
Then, s 1 is selected from OPEN and expanded, because f  X  f  X  ( s 2). S-operator and T-operator are available to s 1. For the edge of  X   X  and the edge of  X  , X  the condition of S-operator is examined and only the edge of  X   X  whose semantic distance with  X   X  is smaller than 1, is proved available. Furthermore, s 3 is generated through S-operator, s 4 is generated through T-operator, and OPEN becomes { s 2, s 3 s 4 } . s 3 = [(((E, ), (S, ))), node-3, ( ), E-operator, 1.4] s 4 = [(((E, ))), node-1, ( ), NIL, 2]
Then, s 3 of the least f  X  value in OPEN is selected and expanded. We achieve the solution s 7 by applying E-operator twice to s 3. s 7 = [(((E, ), (S, ), (E, ), (E, ))), node-9, (), NIL, 1.4]
Figure 3 illustrates the state chart of this example. The search proceeds straight ahead to the solution, except for the branches generated by T-operator. 5. EVALUATION
We evaluated the performance of D 3 through experiments on Japanese-to-English translation in a travel conversation domain using a large-scale corpus. 5.1 Experimental Conditions
We employed a Japanese-and-English parallel corpus, the Basic Travel Ex-pression Corpus (BTEC) [Takezawa and Kikui 2003], which is a collection of
Japanese sentences and their English translations usually found in phrase books for foreign tourists. The statistics of the corpus are shown in Table I. For experiments, a training set 5 of 152,170 sentence pairs and a test set of 510 Japanese sentences were extracted from the corpus.

We also used a bilingual dictionary and thesauri previously developed for another MT system in the travel conversation domain [Sumita et al. 1999]. The hierarchies of the thesauri are based on the Kadokawa Ruigo-shin-jiten [Ohno and Hamanishi 1984].

To evaluate translation quality, we employed objective and subjective mea-sures as follows. The objective measures used were the BLEU score [Papineni et al. 2002] and Multireference Word Error Rate (mWER) [Ueffing et al. 2002], which were calculated with the test set. BLEU compares the system output with a set of reference translations of the same source text by finding sequences of words in the reference translations that match those in the system output.
Therefore, achieving a higher BLEU score means that the translation results can be regarded as being more adequate translations. Since mWER indicates the error rate based on the edit-distance between the system output and the reference translations, achieving a lower score by mWER means that the trans-lation results can be regarded as more adequate translations. The number of references was 16 for these measures.

For the subjective measure (SM), each translation result was graded into one of four ranks by a bilingual human translator, who was a native speaker of the target language, American English. The four ranks were (A) perfect: no prob-lem in either information or grammar; (B) fair: easy-to-understand with some unimportant information missing or flawed grammar; (C) acceptable: broken, but understandable, with effort; and (D) nonsense: important information has been translated incorrectly [Sumita et al. 1999]. In experimental results, we present the SM as the cumulative relative frequencies of the evaluation ranks: A, AB, and ABC. ABCD is shown as an output rate.

In each experiment, the distance threshold was 1/3 in default of an explicit mention. We used a personal computer with a Pentium 4, 2 GHz processor. D was implemented with Allegro Common Lisp 6.2. 5.2 Basic Performance Some translation results are shown in Table II and the evaluation is shown in
Table III. The rate for rank A is high, which means the translation quality is high. On the other hand, about 8% of the inputs have no translation results.
The average processing time is 0.2 s and the maximum time is 3.3 s. Efficient processing is achieved by the proposed retrieval method. The number of word graphs constructed from the training set was 335, where the average number of nodes and that of edges per word graph were 728 and 996, respectively. The number of word graphs accessed in the retrieval process for an input sentence was 13.7, on average. 5.3 Translation Quality Compared to Human Ability
To appreciate the translation quality intuitively, we compared the quality with human ability using the method of Sugaya et al. [2001]. In this method, MT out-put and translations made by persons of various TOEIC 6 scores, which indicate their proficiency at English, the target language of the translation experiment, evaluated by paired comparison, and the TOEIC score in equilibrium, which is deduced by regression analysis.

This time we employed five persons with TOEIC scores from 420 to 965, whose native language is Japanese, the source language of the translation di-rection. The results of the paired comparison are shown in Table IV, from which
D achieved a TOEIC score of 870. According to the TOEIC guidelines, scores higher than 860 are classified into the highest rank. Consequently, we can say that D 3 demonstrated a high level of quality in this experiment. 5.4 Translation Quality Compared to Other Sentence-Wise Retrieval Method
D , as a sentence-wise EBMT, is expected to be high on translation quality if there are examples similar enough to given input sentences. Here, we evaluate the effectiveness of the retrieval measure used in D 3 , that is, the measure of edit-distance by comparing with another measure that uses bags of content words, modality, and tense, and that is used for another sentence-wise EBMT system. 5.4.1 Method for Comparison. For comparison, we used the retrieval method of Example-Based Rough Translation (EBRT) [Shimohata et al. 2003], another sentence-wise EBMT system. EBRT retrieves  X  X eaning-equivalent sentences X  from a corpus. A meaning-equivalent sentence to an input sentence is defined as a sentence that shares the main meaning with the input sentence and does not contain information additional to that contained in the input sen-tence. In practice, EBRT regards a sentence that satisfies the following condi-tions as a meaning-equivalent sentence: (1) it has the same modality and tense as the input sentence; (2) for each content word, the identical word or one of its synonyms is included in the input sentence, where synonymy is based on a thesaurus; and (3) at least one content word in it is included in the input sen-tence. Modalities and tenses are distinguished by heuristic rules using surface clues, mainly particles and auxiliary verbs. When more than one sentence is meaning-equivalent to an input sentence, a sentence is selected by considering the number of identically common content words with the input sentence, that of synonymously common content words, that of common functional words, and that of different functional words.

From the translation of the selected meaning-equivalent sentence, by re-placing the corresponding parts of synonyms with their translation words, the translation of the input sentence is generated. The procedures for finding the corresponding parts and replacing target words are the same as those of D described in Sections 2.2.2 and 2.2.4.

A translation experiment of EBRT was performed with the test set, the train-ing set, the bilingual dictionary, and the thesauri described in Section 5.1. The distinguishing rules for modality and tense were manually developed consid-ering corpora, including the corpus used in the experiment. 5.4.2 Difference. EBRT judges similarity by considering individual con-tent words and abstracted modality and tense. On the other hand, D not only individual words but also the order of words, where information such as modality or tense is treated uniformly by the matching of word sequences.
The sample results in Table V show a typical difference between the two methods. In this table, an input sentence, translation examples retrieved, and translation outputs are shown. D 3 retrieves the sentence, where  X   X  is sub-stituted with  X   X  and  X   X  is substituted with  X   X . EBRT cannot retrieve the sentence because  X   X  and  X   X  are not synonyms for each other in the given thesaurus, although D 3 can find the substitutions from the matching of word sequences. EBRT instead retrieves the sentence whose set of content words is a subset of that of the input sentence. The translation of D is perfect in meaning, while the translation of EBRT is fair, but not perfect in meaning because of the missing  X  X amera. X  5.4.3 Evaluation. Table VI shows the evaluation of the translation results of D 3 and EBRT. The evaluation measures, except for the BLEU score, indi-cate that D 3 achieved higher translation quality than EBRT. D coverage than EBRT with the higher ABC rate. D 3 also shows higher rate of high-quality translations, that is, the A rate of D 3 is 12% higher. Because both systems are the same with respect to the processing phases after retrieval, we can reason that the difference was caused by the difference of retrieved sen-tences and, therefore, that the retrieval method of D 3 is more effective than that of EBRT regarding translation quality. 5.5 Narrow Coverage Problem
Although the translation quality is high, Table III also shows that the ABC rate is no more than 83.3%. The system cannot produce acceptable translations on 16.7% of the test set, including the cases of no output on 8.2%. Figure 4 shows the relationship between the distance and the translation accuracy using the subjective measure. This figure shows that the accuracy clearly decreases as the distance increases, implying that D 3 cannot handle distant examples.
This narrows down the coverage, the ABC rate where the system can produce acceptable translations.

The narrow coverage is a substantial problem for D 3 because it has no mech-anism to translate an input when no translation examples similar to the whole input sentence can be found. D 3 can thus be regarded as an MT method of high quality but narrow coverage. With regard to this problem, the effect of corpus size and complementary methods are investigated in the following experiments. 5.6 Effect of Using Larger Corpora
We used a large-scale corpus to widen the coverage and to achieve sufficiently high translation quality. To investigate the effect of corpus size, we evaluated the performance under the conditions of using twice, one-half, one-quarter, or one eighth size of the training set. Table VII shows the sizes of the training sets by the total the numbers of Japanese sentences and the numbers of different
Japanese sentences. This table also shows the number of test sentences that exactly match a training sentence out of 510 test sentences. Under the double-size condition, 300K, we used sentence pairs from the remaining part of BTEC, after extracting the original training and the test sets. For other conditions, we randomly took sentence pairs off the original training set.

As shown in Table VIII, the coverage, i.e., the ABC rate and other measures indicating translation quality increase as the corpus size increases. The sub-jective measure and objective measures roughly correspond to each other. Table IX shows the results using the distance threshold value of one-quarter.
The processing time is clearly reduced compared to Table VIII, although the output rate naturally decreases. It is possible to suppress the increase of the processing time and to maintain the output rate by decreasing the distance threshold and increasing the corpus size. In this case, the distance between a translated input and retrieved examples decreases, which leads to a higher quality of the translation. That is, the combination of translation quality, output rate, and processing time can be adjusted by the combination of the corpus size and the distance threshold. For example, the result for the corpus size of 300K in
Table IX significantly achieves higher quality and wider coverage while having a close output rate and taking only 10% more processing time compared to the corpus size of 75K in Table VIII.

Figure 5 illustrates the relationship between corpus size and average pro-cessing time with axes of logarithmic scale. Although the processing time in-creases as the corpus size increases, the increasing scale is not linear but about a one-half power with respect to the corpus size. 5.7 Further Improvement for Coverage
To compensate for the narrow coverage, we tried two methods: splitting input sentences into smaller chunks and backing up D 3 by another MT engine of medium quality and wide coverage. We report on the experiments using these methods. 5.7.1 Effect of Input Sentence Splitting. Even in the case where translation examples similar to the whole input sentence are not pears to be a promising way to reduce the narrow coverage prob-lem. For example, the input sentence,  X  English translation is [this/package/OBJ/Japan/IND-OBJ/send/want/ FORMAL/CONCLUSION/CONJ/most/fast/way/ABOUT/what/CONCLUSION/
QUESTION], can be split into two sentences,  X  translating the two subsentences and arranging the results in the same order gives us the translation of the input sentence. Of course, this approach may portions, and confliction between the translations. However, it is expected to produce a better translation in such a case that there is no similar example for the input sentence, as a whole, the split positions are adequate sentence boundaries, and each portion has similar examples. In other words, wider coverage is expected by achieving an acceptable translation in the case that only a nonsense translation or no translation can be produced for an input sentence without splitting.

In the experiment, we split input sentences based on an N-gram language model and sentence similarity by the method of Doi and Sumita [2005], where the sentence similarity was calculated using the same definition of distance as in D 3 . The translation results of split portions were concatenated into the trans-lation of the whole input.

The number of split sentences and that of split positions were 47 and 59, respectively, out of the test set of 510 sentences. Table X shows the evaluation of the translation results with sentence splitting. The evaluation measures except for the BLEU score indicate that wider coverage and higher translation quality are achieved in the splitting condition compared to the baseline. However, the gain is not a very large one, since is assumed that the reason why is that many of the input sentences are short.

The evaluation classified by the input length is shown in Table XI. This table shows the effect of the sentence splitting method on input sentences of different lengths, i.e., less than 6, from 6 to 10, and greater than 10. The effect is observed to be large for long sentences of lengths greater than 10. In these sentences, all measures indicate a significant improvement. 5.7.2 Effect of Cooperation with Other MT. We employed another
EBMT system, the Hierarchical Phrase Alignment-Based Translator (HPAT) [Imamura 2002]. HPAT is an EBMT whose translation expression unit is a phrase. The mechanism of HPAT is as follows. In the learning process, bilingual sentence pairs are parsed into bilingual trees, equivalent phrases are extracted from the bilingual trees, and transfer patterns are generated from the equiva-lent phrases. Translation is performed according to the transfer patterns. The source parts of the transfer patterns are utilized to obtain the source struc-ture. The structural changes are then performed by mapping source patterns to target patterns.

HPAT has a higher coverage than D 3 , because HPAT uses phrase translation units, which are shorter and more general than the sentence units used by
D 3 . On the other hand, it is more possible for HPAT to mix errors or produce unnatural translations than D 3 . HPAT and D 3 are expected to complement each other.

In the experiment, HPAT used training corpora consisting of 72,365 sentence pairs in the bilingual travel conversation corpus of Spoken Language (SLDB) [Takezawa and Kikui 2003] adding to the 152,170 sentence pairs also used by
D 3 . Translation rules were refined by the method of Imamura et al. [2003]. The evaluation of the results of HPAT is worse than the baseline of D and better on AB and ABC in Table XII. As shown in Figure 4, the accuracy of the translation produced by D 3 is strongly related to the distance. Therefore, we decided simply by distance which translation, D 3 or HPAT, should be selected.
We selected the result of D 3 if the distance was within 0.1, where the accuracy is high as shown in the figure, and selected that of HPAT otherwise.
Table XII also shows the evaluation under the condition of D
HPAT, where 341 translations are outputs of D 3 and 169 are those of HPAT. The evaluation measures, except for the BLEU score, indicate that higher transla-tion quality and wider coverage are achieved under the condition of D up by HPAT, compared to the individual systems of D 3 and HPAT. This experi-mental result demonstrates the possibility of D 3 when cooperating with other MT systems.
 6. CONCLUSION
We reported on a retrieval method of D 3 , a sentence-wise EBMT, and the evalu-ation of its performance using a large-scale corpus. Although the sentence-wise
EBMT can produce natural translations, if there are examples similar enough to given input sentences, it has a substantial narrow coverage problem. To reduce this problem, a large-scale parallel corpus is required and, therefore, an efficient method is needed to retrieve translation examples from a large-scale corpus.
We proposed an efficient retrieval method using the measure of edit-distance without omissions. The proposed method utilizes search-space division, word graphs, and an A  X  search algorithm.

In experiments for performance evaluation, we used a bilingual corpus com-prising hundreds of thousands of sentences from a travel conversation domain.
In Japanese-to-English translation, we investigated translation quality and processing time. D 3 achieved a high-quality translation ability by using a large corpus and also achieved efficient processing by using the proposed retrieval method.
 The authors X  heartfelt thanks go to Kadokawa-Shoten for providing the Ruigo-
Shin-Jiten. The research reported here was supported in part by a contract with the National Institute of Information and Communications Technology entitled  X  X  study of speech dialogue translation technology based on a large corpus. X 
