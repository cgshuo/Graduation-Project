 Memory-based methods for collaborative filtering predict new ratings by averaging (weighted) ratings between, re-spectively, pairs of similar users or items. In practice, a large number of ratings from similar users or similar items are not available, due to the sparsity inherent to rating data. Consequently, prediction quality can be poor. This paper re-formulates the memory-based collaborative filtering problem in a generative probabilistic framework, treating individual user-item ratings as predictors of missing ratings. The final rating is estimated by fusing predictions from three sources: predictions based on ratings of the same item by other users, predictions based on different item ratings made by the same user, and, third, ratings predicted based on data from other but similar users rating other but similar items. Existing user-based and item-based approaches correspond to the two simple cases of our framework. The complete model is however more robust to data sparsity, because the different types of ratings are used in concert, while additional ratings from similar users towards similar items are employed as a background model to smooth the predictions. Experiments demonstrate that the proposed methods are indeed more ro-bust against data sparsity and give better recommendations. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Filtering Algorithms, Performance, Experimentation Recommender Systems, Collaborative Filtering, Smoothing, Similarity Fusion Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00.
Collaborative filtering aims at predicting the user inter-est for a given item based on a collection of user profiles. Commonly, these profiles either result from asking users ex-plicitly to rate items or are inferred from log-archives ([7]). Research started with memory-based approaches to collabo-rative filtering, that can be divided in user-based approaches like [1, 5, 9, 14] and item-based approaches like [3, 15]. The former approaches form a heuristic implementation of the  X  X ord of Mouth X  phenomenon. Memory-based approaches are widely used in practice, e.g., [5, 11].

Given an unknown test rating (of a test item by a test user) to be estimated, memory-based collaborative filtering first measures similarities between test user and other users (user-based), or, between test item and other items (item-based). Then, the unknown rating is predicted by averaging the (weighted) known ratings of the test item by similar users (user-based), or the (weighted) known ratings of sim-ilar items by the test user (item-based).

In both cases, only partial information from the data em-bedded in the user-item matrix is employed to predict un-known ratings (using either correlation between user data or correlation between item data). Because of the sparsity of user profile data however, many related ratings will not be available for the prediction, Therefore, it seems intuitively desirable to fuse the ratings from both similar users and sim-ilar items, to reduce the dependency on often missing data. Also, methods known previously ignore the information that can be obtained from ratings made by other but similar users to the test user on other but similar items. Not using such ratings causes the data sparsity problem of memory-based approaches to collaborative filtering: for many users and items, no reliable recommendation can be made because of a lack of similar ratings.

This paper sets up a generative probabilistic framework to exploit more of the data available in the user-item matrix ,by fusing all ratings with predictive value for a recommendation to be made. Each individual rating in the user-item matrix is treated as a separate prediction for the unknown test rating (of a test item from a test user). The confidence of each individual prediction can be estimated by considering both its similarity towards the test user and that towards the test item. The overall prediction is made by averaging the individual ratings weighted by their confidence. The more similar a rating towards the test rating, the higher the weight assigned to that rating to make the prediction. Under this framework, the item-based and user-based approaches are two special cases, and these can be systematically combined. By doing this, our approach allows us to take advantage of user correlations and item correlations embedded in the user-item matrix. Besides, smoothing from a background model (estimated from known ratings of similar items by similar users) is naturally integrated into our framework to improve probability estimation and counter the problem of data sparsity.

The remainder of the paper is organized as follows. We first summarize related work, introduce notation, and present additional background information for the two main memory-based approaches, i.e., user-based and item-based collab-orative filtering. We then introduce our similarity fusion method to unify user-based and item-based approaches. We provide an empirical evaluation of the relationship between data sparsity and the different models resulting from our framework, and finally conclude our work.
Collaborative filtering approaches are often classified as memory-based or model-based. In the memory-based ap-proach, all rating examples are stored as-is into memory (in contrast to learning an abstraction). In the prediction phase, similar users or items are sorted based on the mem-orized ratings. Based on the ratings of these similar users or items, a recommendation for the test user can be gener-ated. Examples of memory-based collaborative filtering in-clude user-based methods [1, 5, 9, 14] and item-based meth-ods [3, 15]. The advantage of the memory-based methods over their model-based alternatives is that less parameters have to be tuned; however, the data sparsity problem is not handled in a principled manner.

In the model-based approach, training examples are used to generate a model that is able to predict the ratings for items that a test user has not rated before. Examples in-clude decision trees [1], aspect models [7, 17] and latent factor models [2]. The resulting  X  X ompact X  models solve the data sparsity problem to a certain extent. However, the need to tune an often significant number of parameters has prevented these methods from practical usage. Lately, researchers have introduced dimensionality reduction tech-niques to address data sparsity [4, 13, 16]. However, as pointed out in [8, 19], some useful information may be dis-carded during the reduction.

Recently, [8] has explored a graph-based method to deal with data sparsity, using transitive associations between user and items in the bipartite user item graph. [18] has extended the probabilistic relevance model in text retrieval ([6]) to the problem of collaborative filtering and a linear interpolation smoothing has been adopted. These approaches are however limited to binary rating data. Another recent direction in collaborative filtering research combines memory-based and model-based approaches [12, 19]. For example, [19] clusters the user data and applies intra-cluster smoothing to reduce sparsity. The framework proposed in our paper extends this idea to include item-based recommendations into the final prediction, and does not require to cluster the data set a priori.
This section introduces briefly the user-and item-based approaches to collaborative filtering [5, 15]. For M items and K users, the user profiles are represented in a K  X  M user-item matrix X (Fig. 1(a)). Each element x k,m = r indicates that user k rated item m by r ,where r  X  X  1 , ..., | r |} if the item has been rated, and x k,m =  X  means that the rating is unknown.
 The user-item matrix can be decomposed into row vectors:
X =[ u 1 ,..., u K ] T , u k =[ x k, 1 ,...,x k,M ] T ,k =1 where T denotes transpose. Each row vector u T k corresponds to a user profile and represents a particular user X  X  item rat-ings. As discussed below, this decomposition leads to user-based collaborative filtering.

Alternatively, the matrix can also be represented by its column vectors: where each column vector i m corresponds to a specific item X  X  ratings by all K users. This representation results in item-based recommendation algorithms.
User-based collaborative filtering predicts a test user X  X  in-terest in a test item based on rating information from similar user profiles [1, 5, 14]. As illustrated in Fig. 1(b), each user profile (row vector) is sorted by its dis-similarity towards the test user X  X  profile. Ratings by more similar users contribute more to predicting the test item rating. The set of similar users can be identified by employing a threshold or select-ing top-N . In the top-N case, a set of top-N similar users S ( u k ) towards user k can be generated according to: users k and a . Cosine similarity and Pearson X  X  correlation are popular similarity measures in collaborative filtering, see e.g. [1, 5]. The similarity could also be learnt from training data [9]. This paper adopts the cosine similarity measure, comparing two user profiles by the cosine of the angle be-tween the corresponding row vectors.

Consequently, the predicted rating x k,m of test item m by test user k is computed as (see also [1, 5]) where u k and u a denote the average rating made by users and a , respectively.

Existing methods differ in their treatment of unknown ratings from similar users ( x a,m =  X  ). Missing ratings can be replaced by a 0 score, which lowers the prediction, or the average rating of that similar user could be used [1, 5]. Al-ternatively, [19] replaces missing ratings by an interpolation of the user X  X  average rating and the average rating of his or her cluster.

Before we discuss its dual method, notice in Eq. 2 and the illustration in Fig. 1(b) how user-based collaborative filter-ing takes only a small proportion of the user-item matrix into consideration for recommendation. Only the known test item ratings by similar users are used. We refer to these ratings as the set of  X  X imilar user ratings X  (the blocks on item similarity (d) Rating prediction based on rating similarity. with upward diagonal pattern in Fig. 1(b)): SUR k,m = { x a,m | u a  X  X  u ( u k ) } . For simplicity, we drop the subscript k, m of SUR k,m in the remainder of the paper.
Item-based approaches such as [3, 11, 15] apply the same idea, but use similarity between items instead of users. As illustrated in Fig. 1(c), the unknown rating of a test item by a test user can be predicted by averaging the ratings of other similar items rated by this test user [15]. Again, each item (column vector) is sorted and re-indexed according to its dis-similarity towards the test item in the user-item matrix, and, ratings from more similar items are weighted stronger. Formally (see also [15]), Where item similarity s i ( i m , i b ) can be approximated by the cosine measure or Pearson correlation [11, 15]. To remove the difference in rating scale between users when computing the similarity, [15] has proposed to adjust the cosine sim-ilarity by subtracting the user X  X  average rating from each co-rated pair beforehand. We adopt this similarity measure in this paper. Like the top-N similar users, a set of top-N similar items towards item m , denoted as S i ( i m ), can be generated according to:
Fig. 1(c) illustrates how Eq. 3 takes only the known simi-lar item ratings by the test user into account for prediction. We refer to these ratings as the set of  X  X imilar item ratings X  (the blocks with downward diagonal pattern in Fig. 1(c)): the subscript k, m of SIR k,m in the remainder of the paper.
Relying on SUR or SIR data only is undesirable, espe-cially when the ratings from these two sources are quite of-ten not available. Consequently, predictions are often made by averaging ratings from  X  X ot-so-similar X  users or items. We propose to improve the accuracy of prediction by fusing the SUR and SIR data, to complement each other under the missing data problem.

Additionally, we point out that the user-item matrix con-tains useful data beyond the previously used SUR and SIR ratings. As illustrated in Fig. 1 (d), the similar item ratings made by similar users may provide an extra source for pre-diction. They are obtained by sorting and re-indexing rows and columns according to their dis-similarities towards the test user and the test item respectively. In the remainder, this part of the matrix is referred to as  X  X imilar user item rat-ings X  (the grid blocks in Fig. 1(d)): SUIR k,m = { x a,b S ( u k ) , i b  X  X  i ( i m ) ,a = k, b = m } . The subscript SUIR k,m is dropped.

Combining these three types of ratings in a single collab-orative filtering method is non-trivial. We propose to treat each element of the user-item matrix as a separate predictor. Its reliability or confidence is then estimated based upon its similarity towards the test rating. We then predict the test rating by averaging the individual predictions weighted by their confidence. The remainder of the section gives a prob-abilistic formulation for the proposed method.
Users rate items differently. Some users have a prefer-ence for the extreme values of the rating scale, while others rarely deviate from the median. Likewise, items may be rated by different types of users. Some items get higher rat-ings than their  X  X rue X  value, simply because they have been rated by a positive audience. Addressing the differences in rating behavior, we first normalize the user-item matrix be-fore making predictions.

Removing the mean ratings per user and item gives indi-vidual predictions as where p k,m ( x a,b ) is the prediction function for the test item k rating made by test user m ,  X  x a and  X  x k are the average rat-ings by user a and k ,and  X  x b and  X  x m are the average ratings of item b and m . Appendix A derives that normalizing the matrix by independently subtracting the row and column means gives the same result.
Let us first define the sample space of ratings as  X  r = { X  , 1 , ..., | r |} (like before,  X  denotes the unknown rating). Let x a,b be a random variable over the sample space  X  r , captured in the user-item matrix, a  X  X  1 ,...,K } and b  X  { 1 ,...,M } . Collaborative filtering then corresponds to es-timating conditional probability P ( x k,m |P k,m ), for an un-known test rating x k,m , given a pool of individual predictors
Consider first a pool that consists of SUR and SIR ratings only (i.e., x a,b  X  ( SUR  X  SIR )).

P ( x k,m | SUR , SIR )  X  P ( x k,m |{ p k,m ( x a,b ) | x a,b  X  SUR  X  SIR } )(6) We write P ( x k,m | SUR , SIR ) for the conditional probability depending on the predictors originating from SUR and SIR . Likewise, P ( x k,m | SUR )and P ( x k,m | SIR ) specify a pool con-sisting of SUR or SIR predictors only.

Now introduce a binary variable I 1 , that corresponds to the relative importance of SUR and SIR . This hidden vari-able plays the same role as the prior introduced in [6] to cap-ture the importance of a query term in information retrieval. I 1 = 1 states that x k,m depends completely upon ratings from SUR , while I 1 = 0 corresponds to full dependency on SIR . Under these assumptions, the conditional probability can be obtained by marginalization of variable I 1 :
P ( x k,m | SUR , SIR ) = = P ( x k,m | SUR , SIR ,I 1 =1) P ( I 1 =1 | SUR , SIR )+ By definition, x k,m is independent from SUR when I 1 =1, so P ( x k,m | SUR , SIR ,I 1 =1)= P ( x k,m | SUR ). Similarly, P ( x k,m | SUR , SIR ,I 1 =0)= P ( x k,m , | SIR ). If we provide a parameter  X  as shorthand for P ( I 1 =1 | SUR , SIR ), we have
P ( x k,m | SUR , SIR ) = P ( x k,m | SUR )  X  + P ( x k,m | SIR )(1  X   X  )(8)
Next, we extend the model to take into account the SUIR ratings:
P ( x k,m | SUR , SIR , SUIR )  X  P ( x k,m |{ p k,m ( x k,m ) | x a,b  X  SUR  X  SIR  X  SUIR
We introduce a second binary random variable I 2 ,that corresponds to the relative importance of the SUIR predic-tors. I 2 = 1 specifies that the unknown rating depends on ratings from SUIR only and I 2 = 0 that it depends on the ratings from SIR and SUR instead. Marginalization on vari-able I 2 gives:
P ( x k,m | SUR , SIR , SUIR ) = = P ( x k,m | SUR , SIR , SUIR ,I 2 =1)  X  Following the argument from above and providing a param-eter  X  as shorthand for P ( I 2 =1 | SUR , SIR , SUIR ), we have
P ( x k,m | SUR , SIR , SUIR ) = P ( x k,m | SUR , SIR )(1  X   X  )+ P ( x k,m | SUIR )  X  (11) Substitution of Eq. 8 then gives:
P ( x k,m | SUR , SIR , SUIR ) = P ( x k,m | SUR )  X  + P ( x k,m | SIR )(1  X   X  ) (1  X   X  )+ Finally, the following equation gives the expected value of the unknown test rating: The resulting model can be viewed as using importance sam-pling of the neighborhood ratings as predictors.  X  and  X  con-trol the selection (sampling) of data from the three different sources.
The next step is to estimate the probabilities in the fusion framework expressed in Eq. 13.  X  and  X  are determined experimentally by using the cross-validation, for example following the methodology of Section 5.3. The three remaining probabilities can be viewed as estimates of the likelihood of a rating x a,b from SIR , SUR ,or SUIR , to be similar to the test rating x k,m . We assume that the probability estimates for SUR and SIR are proportional to the similarity between row vectors s u ( u k , u a )(Section For SUIR ratings, we assume the probability estimate to be proportional to the combination of s u and s i . To combine them, we use a Euclidean dis-similarity space such that the resulting combined similarity is lower than either of them. This results in the following conditional probability esti-mates:
P ( x k,m = r | SUR ) =
P ( x k,m = r | SIR ) =
P ( x k,m = r | SUIR ) =
After substitution from Eq. 15 (for readability, we put the detailed derivations in Appendix B), Eq. 13 results in: where W It is easy to prove that unified weight matrix to combine the predictors from the three different sources.
Sum as Combination Rule  X  and  X  control the impor-tance of the different rating sources. Their introduction re-sults in a sum rule for fusing the individual predictors (Eq. 12 and 16.). Using the independence assumption on the three types of ratings and the Bayes X  rule, one can easily de-rive a product combination from the conditional probability ([10]). However, the high sensitivity to estimation errors makes this approach less attractive in practice. We refer to [10] for a more detailed discussion of using a sum rule vs. the product rule for combing classifiers.

Unified Weights The unified weights in Eq. 17 provide a generative framework for memory-based collaborative fil-tering.

Eq. 17 shows how our scheme can be considered as two subsequent steps of linear interpolation. First, predictions from SUR ratings are interpolated with SIR ratings, con-trolled by  X  . Next, the intermediate prediction is interpo-lated with predictions from the SUIR data, controlled by  X  .Viewingthe SUIR ratings as a background model, the second interpolation corresponds to smoothing the SIR and SUR predictions from the background model.

A bigger  X  emphasizes user correlations, while smaller  X  emphasizes item correlations. When  X  equals one, our algo-rithm corresponds to a user-based approach, while  X  equal to zero results in an item-based approach.

Tuning parameter  X  controls the impact of smoothing from the background model (i.e. SUIR ). When  X  approaches zero, the fusion framework becomes the mere combination of user-based and item-based approaches without smoothing from the background model.
We experimented with the MovieLens 1 , EachMovie 2 ,and book-crossing 3 data sets. While we report only the Movie-Lens results (out of space considerations), the model behaves consistently across the three data sets.

The MovieLens data set contains 100,000 ratings (1-5 scales) from 943 users on 1682 movies (items), where each user has rated at least 20 items. To test on different number of train-ing users, we selected the users in the data set at random into a training user set (100, 200, 300 training users, respec-tively) and the remaining users into a test user set. Users in the training set are only used for making predictions, while test users are the basis for measuring prediction accuracy. Each test user X  X  ratings have been split into a set of observed items and one of held-out items . The ratings of observed items are input for predicting the ratings of held-out items.
We are specifically interested in the relationship between the density of the user-item matrix and the collaborative filtering performance. Consequently, we set up the following configurations: For consistency with experiments reported in the literature, e.g., [9, 15, 19]), we report the mean absolute error (MAE) evaluation metric. MAE corresponds to the average absolute deviation of predictions to the ground truth data, for all test item ratings and test users: where L denotes the number of tested ratings. A smaller value indicates a better performance. http://www.grouplens.org/ http://research.compaq.com/SRC/eachmovie/ http://www.informatik.uni-freiburg.de/  X  cziegler/ BX/
We first report some properties of the three types of in-dividual predictions used in our approach. Table 1 illus-trates the availability of the top-4 neighborhood ratings in the MovieLens data set. The first column contains the top-4 SUR ratings, the first row the top-4 SIR ratings; the remain-ing cells correspond to the top-4x4 SUIR ratings. We ob-serve that only about half of these ratings are given. Table 2 summarizes recommendation MAE of individual predic-tors (applying Eq. 5) using leave-one-out cross-validation. Clearly, more similar ratings provide more accurate predic-tions. While SUIR s ratings are in general less accurate than SUR sand SIR s, these may indeed complement missing or unreliable SIR and SUR ratings.
Recall the two parameters in Eq. 17:  X  balances the pre-dictions between SUR and SIR ,and  X  smoothes the fused results by interpolation with a pool of SUIR ratings.
We first test the sensitivity of  X  , setting  X  to zero. This scheme, called SF1 , combines user-based and item-based ap-proaches, but does not use additional background informa-tion. Fig. 2(a) shows recommendation MAE against vary-ing  X  from zero (a pure item-based approach) to one (a pure user-based approach). The graph plots test user sparsity 5 and 20, and test item sparsity settings  X  &lt; 5 X  and uncon-strained. The value of the optimal  X  demonstrates that in-terpolation between user-based and item-based approaches ( SF1 ) improves the recommendation performance. More specifically, the best results are obtained with  X  between 0 and 0 . 9. This optimal value emphasizing the SUR ratings may be somewhat surprising, as Table 2 indicated that the SIR ratings should be more reliable for prediction. How-ever, in the data sets considered, the number of users is smaller than the number of items, causing the user weights s ( u k , u a ) to be generally smaller than the item weights s ( i m , i b ). When removing the constraint on test item spar-sity, the optimal  X  shifts down from about 0 . 9 for the two upper curves ( X  &lt; 5 X ) to 0 . 6 for the two lower curves (un-constrained). A lower  X  confirms the expectation that SIR ratings gain value when more items have been rated.
Fig. 2 (b) shows the sensitivity of  X  after fixing  X  to 0 The graph plots the MAE for the same four configurations when parameter  X  is varied from zero (without smoothing) to one (rely solely on the background model: SUIR ratings). When  X  is non-zero, the SF1 results are smoothed by a pool of SUIR ratings, which we called fusion scheme SF2 .We observe that  X  reaches its optimal in 0 . 8 when the rating data is sparse in the neighborhood ratings from the item and user aspects (upper two curves). In other words, smoothing from a pool of SUIR ratings improves the performance for sparse data. However, when the test item sparsity is not constrained, its optimum spreads a wide range of values, and the improvement over MAE without smoothing (  X  =0) is not clear.

Additional experiments (not reported here) verified that there is little dependency between the choice of  X  and the optimal value of  X  . The optimal parameters can be identified by using the cross validation from the training data.
Like pure user-based and item-based approaches, the size of neighborhood N also influences the performance of our fusion methods. Fig. 3 shows MAE of SF2 when the number of neighborhood ratings is varied. The optimal results are obtained with the neighborhood size between 50 and 100. We select 50 as our optimal choice.
The next experiments investigate the effect of data spar-sity on the performance of collaborative filtering in more de-tail. Fig. 4(a) and (b) compare the behavior of scheme SF1 to that obtained by simply averaging user-based and item-based approaches, when varying test user sparsity (Fig. 4(a)) and test item sparsity (4(b)). The results indicate that com-bining user-based and item-based approaches ( SF1 ) consis-tently improves the recommendation performance regardless neighborhood sparsity of test users or items.

Next, Fig. 4(c) plots the gain of SF2 over SF1 when vary-ing overall training user sparsity. The figure shows that SF2 improves SF1 more and more when the rating data be-comes more sparse. This can be explained as follows. When the user-item matrix is less dense, it contains insufficient test item ratings by similar users (for user-based recom-mendation), and insufficient similar item ratings by the test user (for item-based recommendation) as well. Therefore, smoothing using ratings by similar items made by similar users improves predictions.

We conclude from these experiments that the proposed fusion framework is effective at improving the quality of rec-ommendations, even when only sparse data are available.
We continue with a comparison to results obtained with other methods, setting  X  to 0 . 7and  X  to 0 for SF1 and using  X  =0 . 7and  X  =0 . 7 for SF2 . We first compare our results to the standard user-based vector similarity (UBVS) approach of [1] and the item-based adjusted cosine similarity (IBVS) of [15]. We report results for test user sparsity 5, 10, or 20, and test item sparsity  X  &lt; 5 X ,  X  &lt; 10 X ,  X  constrain X . Table 3 summarizes the results, showing how SF1 and SF2 outperform the other methods in all twelve resulting configurations.

Next, we adopt the subset of MovieLens (see [9, 19]), which consists of 500 users and 1000 items. We followed the exact evaluation procedure described in [19] to compare the performance of our SF2 scheme with the state-of-art re-sults listed in [19]. Table 4 presents our experimental results, as well as the four best methods according to their exper-iments, i.e., cluster-based Pearson Correlation Coefficient (SCBPCC) [19], the Aspect Model (AM) ([7]),  X  X ersonality Diagnosis X  (PD) ([12]) and the user-based Pearson Correla-tion Coefficient (PCC) ([1]). Our method outperforms these methods in all configurations.
We proposed a novel algorithm to unify the user-based and item-based collaborative filtering approaches to over-come limitations specific to either of them. We showed that user-based and item-based approaches are only two special cases in our probabilistic fusion framework. Furthermore, by using a linear interpolation smoothing, other ratings by similar users towards similar items can be treated as a back-ground model to smooth the rating predictions. The exper-iments showed that our new fusion framework is effective in improving the prediction accuracy of collaborative filter-ing and dealing with the data sparsity problem. In the fu-ture, we plan to conduct better formal analyses of the fusion model and more complete comparisons with previous meth-ods. [1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [2] J. Canny. Collaborative filtering with privacy via [3] M. Deshpande and G. Karypis. Item-based top-n [4] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [5] J.L.Herlocker,J.A.Konstan,A.Borchers,and [6] D. Hiemstra. Term-specific smoothing for the [7] T. Hofmann. Latent semantic models for collaborative [8] Z. Huang, H. Chen, and D. Zeng. Applying associative [9] R. Jin, J. Y. Chai, and L. Si. An automatic weighting [10] J. Kittler, M. Hatef, R. P. W. Duin, and J. Matas. On [11] G. Linden, B. Smith, and J. York. Amazon.com [12] D. M. Pennock, E. Horvitz, S. Lawrence, and C. Giles. [13] J. D. M. Rennie and N. Srebro. Fast maximum margin [14] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [15] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [16] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. T. [17] L. Si and R. Jin. Flexible mixture model for [18] J. Wang, A. P. de Vries, and M. J. Reinders. A [19] G.-R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu,
We first normalize the matrix by subtracting the average item ratings: where n ( x a,b ) I normalizes ratings by subtracting the mean item rating.  X  x b is the average rating of item b .
We normalize again by the average user rating: where n ( x a,b ) I,U is the normalization of both item and user aspects.  X  x a is the average rating from user a .  X  x average of all the ratings. From here, we see that the result does not depend on the order of normalization (whether to normalize first by user or by item).

Treating each normalized individual rating as individual predictor results in:
More specifically, replacing three conditional probabilities with Eq. 15, the following can be derived from Eq. 13: x = = where where A,B and C act as the weights to combine the pre-dictors from three different sources. Unifying them we can obtain Eq. 16.
