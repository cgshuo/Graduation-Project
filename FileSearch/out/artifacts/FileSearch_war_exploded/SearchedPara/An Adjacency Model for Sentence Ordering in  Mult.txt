 Information overload has created an acute need for multi-document summarization. There have been a lot of works on multi-document summarization [3][5][7][10][11] [12]. So far the issue of how to extract information from source documents is the main topic of summarization area. Being the last step of multi-document good summary must be fluent and readable to human being, sentence ordering which organizes texts into the final summary can not be ignored. 
Sentence ordering is much harder for multi-document summarization than for single-document summarization. The main reason is that unlike single document, multi-judgment. This is more obvious for sentence extraction based summarization systems. 
Chronological ordering [1][2][4] is a generally used method for sentence ordering in multi-document summarization. It orders sentences by published date of source documents or time information within texts. This method is suitable for event based documents. Sometimes it gets good results [4]. But on the one hand, it doesn X  X  work for all kinds of summarization tasks. On the other hand, the chronological information is not always available. Because of these limitations, chronological ordering can only solve part of sentence ordering problems. 
Majority ordering is another way of sentence ordering. This method groups sentences to be ordered into different themes or topics of texts in source documents, method is reasonable since the summary of multi-documents usually covers several topics in source documents to achieve representative, and the theme ordering can suggest sentence ordering somehow. However, there are two challenges for this sentences belonging to the same topic. Barzilay et al. [2] combined topic relatedness and chronological ordering together to order sentences. Besides chronological ordering, sentences were also grouped into different themes and ordered by the order of themes learned from source documents. The experiment results show that chronological ordering is not sufficient for sentence ordering, and the results could be improved combining with topic relatedness. 
Probabilistic model was also used to order sentences. Lapata [8] ordered sentences based on conditional probabilities of sentence pairs. The condition probabilities of sentence pairs were learned from a training corpus. With condition probability of each sentence pairs, the approximate optimal global ordering was achieved with a simple greedy algorithm. The condition probability of a pair of sentences was calculated by condition probability of feature pairs occurring in the two sentences. The experiment results show that it gets significant improvement compared with randomly sentence ranking. This suggests that without any linguistic knowledge, statistical information does help to improve performance of sentence ordering. 
Bollegala et al. [4] combined chronological ordering, probabilistic ordering and topic relatedness orderi ng together. He used a machine learning approach to learn the way of combination of the three ordering methods. The combined system got better results than any of the three methods. 
In this paper, we propose a new sentence ordering method named adjacency-based ordering. It orders sentences with sentence adjacency or connectivity. Sentence adjacency or connectivity between two sentences means how closely they should be put together in a set of summary sentences. Although there is no ordering information in sentence adjacency, an optimal ordering of summary sentences can be derived by use of such information of all sentence pairs with help of the first sentence selection. 
We also implemented majority ordering and probability based sentence ordering to make a comparison with our method. The probabilistic model we implemented in this paper is similar to the work of [8], but probabilities of feature pairs are learned from source documents instead of external corpus. 
We test our methods on DUC2004 data collection and evaluated our results against manually produced summaries provided by DUC as  X  X deal X  summaries. We also present manually evaluation results. 
The remainder of this paper is organized as follows. Section 2 introduces our adjacency-based ordering model, with a comparison with probabilistic model. Chapter 3 introduces our experiment results as well as evaluation metrics and results. In Chapter 4 we present the discussion and conclusion. Before we describe our newly proposed adjacency based ordering, the method of majority ordering and probabilistic ordering will be briefly introduced. All thiese three methods can order sentences without any external sources but with the source documents to be summarized. This makes them capable to most summarization tasks. 2.1 Majority Ordering Majority ordering assumes that sentences in the summary belong to different themes or topics, and the ordering of sentences in the summary can be determined by the occurring sequence of themes in source documents. To define the order of themes, nodes of the graph are themes and each edge from one node to another denotes the occurring of one theme before another theme in source documents. The weight of each edge is set to be the frequency of the pair occurring in the texts. Each theme is given a weight that equals to the difference between outgoing weights and incoming weights. By finding and removing a theme with the biggest weight in the graph recursively, an ordering of themes is defined. 2.2 Probabilistic Model The probabilistic model treats the ordering as a task of finding the sentence sequence assumption that the probability of any given sentence is determined only by its previous sentence, the probability of a sentence sequence can be generated given the the feature of S i-1 . 
By finding the sentence with the biggest condition probability with the previous sentence recursively, an ordering of sentences is defined. A null sentence can be introduced as the beginning of the ordering to get the first sentence found. For more details please refer to [8]. 2.3 Adjacency Model However, we notice that the learned probability might lose important information presented by the data. Consider examples below: Example 1: Source Document = ......ABA...... Example 2: Source Document 1 = ......AB...... Source Document 2 = ......BA...... Here A and B denote two sentences. Let X  X  assume that A and B are both selected as the summary sentences. 
With probabilistic model described in the previous section, since the times of A preceding B equal to the times of B preceding A in both examples, the system will learn that p(A|B) equals to p(B|A). Thus it will get confused when ordering sentences A and B. In other words, text structures in the two examples do not contribute to ordering in probabilistic model. But in fact we can understand intuitively that sentence A and B shall be put adjacently, despite the sequence between them. 
Understanding that the conditional probabilities learned from sequences of sentences or features in source documents only focus on feature sequence information but ignore feature adjacent information, we propose the adjacency model which focuses on sentence adjacency instead of feature sequence. Given a group of can be captured by their connectivity defined as below: connectivity function for feature pairs. ) ( f and S . In general the connectivity of a pair of sentence can be understood as the average connectivity of all feature pairs derived from the sentence pair. 
The connectivity of feature pair C f ( f i , f j ) is defined as below: frequency of f i and f j cooccurring in the source documents within a limited range (say, one or several sentences). documents. It can be reasonably inferred that sentences that are close to each other in source documents tend to remain close to each other in the summary produced from the source documents. Notice that with equation (1) and (2) we can get connectivity learned from source documents between any two sentences, not only for sentences occurring in source documents. This helps to implement this model to sentence ordering of any summarization task, not only sentence-extraction based summarization tasks. adjacently in the summary. Notice that connectivity doesn X  X  directly suggest the ordering between two sentences but only the information of how close they are. Given a sentence S i , the sentence S j which makes j i C , biggest is the most likely sentence to be put right before or after S i . To avoid the selection between the two possible positions while ordering, we could always find the next sentence after sentences at previous positions are all found already. Then the next selected sentence with the has been taken already. whole sentence set T, the task of finding the (i+1)th sentence can be described as: 
Now the sentence sequence become 1 S the whole sentence sequence could be derived, if given the first sentence. The method of finding the first sentence 1 S can be defined in the same way as above: Here j C , 0 denotes how close the sentence j and a null sentence are. By adding a null sentence to the beginning of each source document and assuming it contains one null feature, j C , 0 can be calculated with equation (2). Noises Elimination In experiments, we found that the majority amount of feature pairs were assigned with quite low connectivity values, and they produce noises for the models, especially for long sentences. Assume that there are K features in one sentence and L features in another sentence, there are K*L possible feature pairs. We observed that the relationship of the two sentences is mainly determined by distinguishable feature producing noises. Thus we don X  X  need to consider all K*L feature pairs. 
For this sake we modified equation (1) as: 
The biggest_top_n is number of feature pairs which will be considered while calculating the connectivity between a pair of sentences. Given a pair of sentences S i and only the biggest_top_n feature pairs with the biggest connectivity values are used to produce the connectivity of sentence pairs. Notice that if the biggest_top_n is set to sentence S j ., the modified equation is the same with original equation (1). In this section we describe the experiments made with majority ordering, probability-based ordering and adjacency-based orde ring. Lapata [8] tested probabilistic model with an external training corpus, he also extracted sentence features such as nouns, verbs and dependencies. In this paper we focus on the methodology itself with raw supporting semantics or grammar knowledge. We use single words except stop words as features to represent sentences. 3.1 Test Set and Evaluation Metrics DUC 04 provided 50 document sets and four manual summaries of each set for its task 2. Each document set consist of 10 documents. After excluding summaries containing more than 8 sentences for the sake of running efficiency, we chose 157 summaries. The average number of sentences in each summary is 5.92. Sentences of each summary are token as input to the ordering algorithm. Original sequential information of sentences is abandoned. This is to simulate the circumstance of sentence ordering step in summarization tasks. The ordering algorithm then produces orderings which are compared with those orderings in manually generated summaries. Here we assume that each manually generated summary has an  X  X deal X  ordering. With this assumption, given any produced ordering, we can compare it with the  X  X deal X  ordering by automatic evaluation. This assumption is reasonable. But at the same time, given a group of sentences, there might be not only one  X  X deal X  ordering. In experiments of Barzilay et al. [2], 10 human participants often get 10 unique readable orderings for the same sentence group with an average size of 8.8. While number of human participants increased to 50, number of unique orderings raised to 21. This suggests that automatic evaluation for sentence ordering is hard to represent the actual performance, and certainly will get worse evaluating result than human evaluation. But we believe that with a statistically big enough test set, automatic evaluation is not meaningless. Considering the shortcoming of automatic evaluation experiment results, we present automatic evaluation result on whole test set (157 summaries) and human evaluation on 10 randomly selected summaries. A number of metrics can be used to measure the difference between two orderings. In this paper we use Kendall X  X   X  [9], which is defined as: Here N is number of objects to be ordered (ie sentences). Number_of_inversions is the minimal number of interchanges of adjacent objects to transfer an ordering into another.  X  can be understood as how easy an ordering can be transfer to another. The orderings are the same, and -1 denotes the worst situation. Given an ordering, randomly produced orderings of same objects get an average  X  of 0. In examples in Table 1, the  X  values with natural sequences (123...n) are 0.67, 0.4, 0.33 respectively. 3.2 Results We use single words as features to calculate condition probabilities and connectivity values of sentence pairs. We did experiments with majority ordering (run_Mo), probabilistic model (run_Pr) and connectivity model (run_Cn). A run producing random sentence orderings (run_Rd) was also presented to make the comparison more illustrative. Automatic Evaluation For automatic evaluation, the Kendall X  X   X  is calculated between each output ordering and the ordering of the manual summary. This evaluation measures how similar the output orderings and orderings of manual summaries are. Since we believe that the orderings of manual summaries are ideal, hence the bigger Kendall X  X   X  got, the better is the ordering performance of our ordering applications. The evaluation was made on all 157 summaries. The value of  X  varies from -1 to 1. 
Table 2 describes automatic evaluation results of our experiments. We can see that Meanwhile the adjacency model got a  X  of 0.276, with an improvement of 91.7%. 
Table 3 gives out a further comparison between the four methods. The first data column describes how many output orderings put the 1st sentence of the 157 manual standard summaries at the  X  X orrect X  position (ie the first position in output orderings). The adjacency model run significantly outperforms the other three runs. 94 out of 157 output orderings got the same 1st sentences with manual summaries. The reason why adjacency model performs better than other two models for the first sentence selection may be that when determining the first sentence, not only the occurrences of features after the null feature but also their occurrences elsewhere are both considered, while other models only consider their occurrence after the null features. 
In Table 3, we use  X  X ositive ordering X  to denote the output ordering that gets a positive  X  , which means it can be considered as a better ordering than a random which means it can be considered as a worse ordering than a random ordering.  X  X edian ordering X  is the ordering get a  X  of 0. We can find from the last 3 columns of Table 3 that the adjacency based ordering significantly outperforms the other 3 runs on finding positive orderings and avoiding negative orderings. 82.1% (positive plus median ordrings) of its output orderings are not worse than random produced orderings. 
We compared the correction ratio of sentence inferrence from correctly ordered previous sentences in Table 4. The first data column describes the number and percentage of runs that the second sentence is correctly ordered compared with the manual summary, given the first sentence being correctly ordered. The second data column discribes that of correctly ordered third sentence, given the first two sentences are correctly ordered. Because the number of runs with first 3 sentences correctly orderred is too few, we didn X  X  make further comparison on inferrence of later sentences. Table 4 shows that given correctly ordered previous sentences, probabilistic model outperforms majority ordering and adjacency model outperforms both of them in inferring the next correct sentence. 
We also find that though majority ordering got close Kendall X  X   X  with probabilistic ordering, but it X  X  weaker than probabilistic ordering to correctly order the first sentence and infer the next correct sentence. This may be because that majority ordering select the next sentence based on relations among unordered sentences, ie. it X  X  dependent with ordered sentences. Meanwhile the probabilistic model and adjacency model depend on the previously ordered sentence to select the next sentence. This makes majority ordering weaker when a good previous ordering acquired, but stronger when a bad previous ordering acquired. 
Table 5 describes the experiment results of adjacency model with varing connectivity window ranges and noise elimination parameters. Cooccurrences of feature pairs are counted within the given window range in source documents. For example, range being set to 3 means that feature pairs co-occurring within adjacent 3 sentences are counted. Top-n is the noise elimilation parameter introduced in section 2.3. Table 5 shows that noise elimination does affect the performance, and the best performance was acquired with top-n being set to 3 or 4. The connectivity window size slightly affect the performance. The proper setting of connectivity window size might depend on the length of source documents. The longer the source documents, the bigger connectivity window size may be expected. Manual Evaluation As mentioned in previous sections, there are usually more than one acceptable orderings for a given group of sentences. This means that the automatic evaluation certainly underestimate the performance of ordering applications. To more accurately measure how efficient our ordering applications are, we randomly selected 10 manual summaries from the test set to manually evaluate output orderings. 
In manual evaluation, the number of inversions is defined as the minimal number of interchanges of adjacent objects to transfer the output ordering to an acceptable ordering judged by human. The Kendall X  X   X  of all 3 runs are listed in table 6. 
We can see from table 6 that all runs get bigger Kendall X  X   X  than in automatic evaluation. The result of connectivity model is quite good. In this paper we proposed an adjacency model for sentence ordering in multi-document summarization. It learns the adjacency information of sentences from the source documents and orders sentences accordingly. Unlike the conditional probability between two sentences which helps to decide the sequence of them, the adjacency between two sentences denotes only the information about how close they determined, an ordering can be acquired from adjacency information of sentence pairs. The experiment results show that this method significantly outperforms two other existing sentence ordering methods on dataset of DUC04. 
With the adjacency based sentence ordering, sentences are ordered based on only the input source documents without any extra sources. This means that it is capable to almost any text ordering task for document summarization. While multi-document summarization becomes more and more neccessary in varies domains and occasions, supporting knowledge is getting harder to be predicted and prepared. This makes the adjacency based sentence ordering even more meaningful. 
From the experiment results we found that adjacency based model outperforms probabilistic model in finding both the first sentence and the next sentence given previous ones. The reason might be that probabilistic model focuses on feature sequences, however, they might mutually contradict during learning, which will make the conditional probability useless. In contrast, adjacency model focuses on feature proximity, which will not contradict with each other. 
There are some aspects for future improvement. First, noise reduction is a key step Second, currently the connectivity between two features is based on counts of their superficial co-occurrence, how to disclose the latent co-occurrence is an interesting try some multi-word units as features in future. 
