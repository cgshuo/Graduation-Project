 With the growth of information technology, data accessible through the Internet has become increasingly voluminous and diverse. It is impossible for humans to check this much data by hand and identify important information. Thus, data mining, which systematically extracts useful information from data, has become essential. Outlier detection, a data min ing technique to detect rare events, de-viant objects, and exceptions from data, has been drawing increasing attention in recent years. Most existing outlier det ection algorithms focus on numerical data sets [1,2,3,4,5,6,7,8,9,10].

We target categorical r ecord databases and detect records in which many attribute values are not observed even though they should occur in association with other attribute values in the records. To detect such records as outliers, we provide an outlier degree based on associations among attribute value sets. We derive a set of association rules with high confidence from an input record database as information about such attribute associations. The outlier degree we propose demonstrates suffi cient detection performance in accuracy-evaluation experiments.

Beyond that, since a naive brute force algorithm for detect ing outlier records based on attribute associations takes much time, we propose a more efficient algorithm, which includes two, speed increasing devices as well as a fast path for finding cases in which no outliers exist in the data set.
 Experiments using real data sets have yielded three interesting results: (i) The outlier degree we derive presents s ufficient accuracy compared with the probabilistic approach of a related work [14]. (ii) Our method detects practically interesting records as outliers. (iii) Our proposed algorithm detects outliers at least ten times faster than a brute force algorithm.

The rest of the paper is organized as follows: Section 2 mentions related work, where we introduce a study used in our experiments as the baseline for the accuracy evaluation. Section 3 explains preliminaries for this paper and defines terms and statements. Section 4 introdu ces a formula of the outlier degree based on the association among attribute value sets. Section 5 presents an algorithm for outlier detection, which includes a fast path and two speed increasing devices. Section 6 shows experimental results fo r real data sets. Sect ion 7 summarizes the paper and introduces future work. Until now, much research on outlier detect ion has been proposed [1,2,3,4,5,6, 7, 8, 9, 10]. However, most research has targeted numerical data and differs from our research, which targets categorical record databases. [11,12,13,14] is a study of outlier or anomaly detection, which applies to categorical record databases.
Approaches proposed in [11,12] are based on a bayesian network. They build a probabilistic model and estimate the likelihood for each record. If the likelihood is unnaturally low, the corresponding record is regarded as an anomaly. Just as with our method, Chan and others propose an approach based on association rules. However, while our outlier degree is not based on statistics, they derive an anomaly score on the basis of the probabilistic concept [13]. The method [13] is used as the baseline for an accuracy co mparison in [14]. According to results presented in [14], the method of [14] significantly outperforms [13]. Therefore we use the method of [14] as the baseline for our accuracy comparison.

As far as we know, the work [14] is the hottest in this study field. They detect anomalous records in a categorical database using a probabilistic method. Their idea is that a given test record is interesting as an anomaly if it has unusual combinations for an attribute values set. For a training database, their method counts the number of records containing each attribute value set and keeps the counts. With these counts, they calculate the rareness degree of each test record. For each combination of attribute value sets A and B contained in a test record, regarded as the rareness degree of the record. If this degree is less than or equal to a user-specified threshold  X  , the record is regarded as an anomaly. Marginal probabilities are estimated with the counts of records that contain A , B and A  X  B respectively. The time and space costs for calculations are very large because the number of attribute value sets is huge, so they give parameter k as a maximum size of an attribute values set for the calculation. Here, we describe terms and statements u sed in this paper. A categorical record data DB is a set of records. | DB | is the number of all records on DB . A record t  X  DB is a tuple. t [ A t has. Assume n be the number of all attributes of DB .

Let A be an attribute and let a be a value of A . Then, a categorical record database can be regarded as a set of n -itemsets ,wherean item corresponds to a For a minimal support msup ,if sup ( X )  X  msup ,then X is called a frequent itemset (FI). A Maximal frequent itemset (MFI) is an FI having no super set in a set of all FIs. Let X and Y be itemsets such that X  X  Y =  X  ,theform X  X  Y is called an association rule . The left hand itemset of a rule is called an antecedent , while the right hand is called the consequent . The rule X  X  confidence is derived as conf ( X  X  Y )= sup ( X  X  Y ) sup ( X ) .Fora minimal confidence mconf ,if conf ( X  X  Y )  X  mconf then X  X  Y is called a high-confidence rule .
For an asymmetric attribute A, where a specific attribute value a occurs very frequently and the other values rarely o ccur, such a frequent value may hide re-ally meaningful associations among attribute values. To tackle such sparce data, we can consider the following option when mapping a record into an itemset. [ Mapping Option ] We ignore ( A , a ) in the mapping and consider only ( A , b ) where b = a . We want to detect records in which many attribute values are not observed even though they should occur in associat ion with other attribute values in the records. We use association rules with high confidence to determine the degree of associations among attribute values set included in a record. It is obvious that as conf ( X  X  Y ) is higher, the association between attribute values of X and those of Y is stronger. For a record t and a rule X  X  Y with high confidence, if t [ A ] is a for all pairs ( A, a )  X  X while t [ B ]isnot b for some pairs ( B, b )  X  Y ,itcan be thought to be rare. This is true because t [ B ] should be b for all ( B, b )  X  Y , which tends to occur with X stochastically. We call such a rule an unobserved association. Definition 1. Unobserved Association Let R be a set of association rules and let Z be an itemset, a rule X  X  Y  X  R is Z  X  X  unobserved association when Y Z although X  X  Z .
 To determine the degree of outlier for a record t , we first search how many attribute values are not observed in t even though t should have them. For a record t ,wefocuson t  X  X  associative cover , which covers all attribute values in association with attribute values occurring in t .
 Definition 2. Associative Cover
Let R be a set of association rules. An initial associative cover of t is derived values in t . t  X  X  associative cover C t + is derived as follows: If this cover expands larger, it means that more attribute values in t have stronger association with other attribute values not in t .Inotherwords,sucha t can be regarded as rare.
 Definition 3. Outlier Degree t  X  X  outlier degree is defined as od ( t )= | C t +  X  C t 0 | | C mod ,if od ( t )  X  mod then the record t is detected as an outlier. Table 1 lists the naive algorithm for detecting outlier records. It calls function getOutliers listed in Table 2. With this brute force algorithm, for each record t  X  DB , we have to check all association rules in a given R to make the associative cover according to Definition 2.

As Table 1 shows, our method requires three parameters: msup for mining frequent itemsets, mconf for generating high-confidence rules, and mod for out-lier detection. Experimental results show that the distribution of outlier degrees changes depending on msup and mconf . Given an inadequate mod for msup and mconf , there will be no outliers. We want to find such cases without spending time and resources in vain. Consequently, we provide a fast path for finding the case of no outliers existing in DB .

In addition, the naive algorithm obviously takes O ( | DB | X | R | 2 ), where both |
DB | and | R | are generally vast. Thus our algor ithm includes two, speed increas-ing devices, which decrease the numbe r of records and rules, which are needed to calculate the outlier degree. Below, we first explain about the fast path, then present two devices and introduce the proposed algorithm. 5.1 Fast Path for Inadequate Parameters We can find the case of no outliers existing in the data sets as soon as we obtain frequent itemsets, by focusing on the following property of outlier degree. Property 1. For a given record t , the outlier degree od ( t ) increases monotonically as | C t + | increases.
 Now, let us consider the case that | C t 0 | = n for all records t . This is the case in which we do not use the Mapping Option.
 Definition 4. Maximum Increment
Let F be a set of FIs for msup , the maximum increment is the itemset I  X  2 called a maximum increment value.
 Note that C t +  X  C t 0  X  I  X  2 for each t .
 Property 2. For a set F of FIs for msup , the outlier degree od ( t ) of a record t is always less than mod when max inc &lt; mod 1  X  mod n .

On the mining phase, we derive max inc as well as a set of FIs. If max inc &lt; mod n , we can say that there is no outlier.

In the case where we use the Mapping Option, we can use the minimal car-dinality n min = min t  X  DB | C t 0 | in place of n and check mix inc in a similar way. 5.2 Pruning Candidate Records of Outliers By deriving outlier degree upper bounds, we prune candidate records of outliers. Definition 5. Maximal Associative Cover Let M be a set of all MFIs for msup ,andlet MC t 0 = C t 0 . For a record t , t  X  X  maximal associative cover MC t + is derived as follows: Property 3. Let M be a set of all MFIs for msup ,andlet MC t + be the maximal associative cover of a record t for M . MC t + is equal to t  X  X  associative cover C t + with the same msup and mconf =0.
 Because C t + can grow most when mconf =0for msup , we derive an upper bound of an outlier degree as follows.
 Definition 6. Outlier Degree Upper Bound For msup and mconf ,let R be a set of high-confidence rules and let M be a complete set of MFIs. The outlier degree upper bound od max ( t ) of a record t is od Before outlier calculation, we check all records and prune such a record t that od max ( t ) &lt;mod ,since od ( t ) &lt;mod holds for t by Property 1. Increased speed can be expected, because | M | is generally much less than | R | .

Table 3 is an example record data set in which each record shows a habit of an individual animal. Table 4 represents its attributes. Given msup = 30%, we derive MFIs as shown in Table 5. Assuming the Mapping Option, the initial associative cover of record t 3 is generated to be C 0 t Therefore, od max ( t 3 ) = 0.43, on another front, od ( t 3 ) = 0.33 5.3 Redundant Rules Removal In R , which is a set of association rules for a given msup and mconf ,thereare redundant rules to make associative covers. Again we take Table 3 as an example. Given msup = 30% and mconf = 70%, we derive the set of high-confidence rules listed in Table 6, where rules with 100% confidence are ignored because they do not become unobserved associations nor do they contribute to the growth of associative covers.

In this case, rule 1 is redundant because the growth by rule 1 toward the asso-ciative cover is subsumed by rule 3 .Also, rule 2 is a redundant rule in the light of rule 3 .
 Definition 7. Redundant Rule
Let R be a set of association rules, a rule X  X  Y  X  R is a redundant rule on R when it has the other rule V  X  W  X  R , which satisfies at least one of following two conditions: (i) V  X  X  X  V  X  W = X  X  Y , or, (ii) V = X  X  W  X  Y . We remove such redundant rules on the rule generation phase, and check only remaining rules for making associative covers. A set of such remaining rules { rule 0 ,rule 3 ,rule 4 } .

Let C t + be t  X  X  associative cover generated by a set of association rules R and let C t,min + be the one generated by a minimal rule set R min for R .Notethat C 5.4 Outlier Records Detection Algorithm Table 7 shows our proposed algorithm, which includes a fast path and the two, speed increasing devices explained above.
 At line 1, the algorithm derives MFIs and max inc as well as FIs. To derive MFIs concurrently while getting FIs, we improve the FP-growth algorithm [15] for implementation in which the MFI-tree and subset-checking method proposed records of outliers are pruned. The manner to calculate outlier degree upper bounds is very similar to that of outlier degree calculation. The process for getting a minimal rule set corresponds to lines 10-15, which is based on the algorithm of [16].

While the function genMinRule listed in Table 8 is called recursively, we mark high-confidence rules, which are redundant for Condition (i) in Definition 7. The function apriori-gen called at line 3 in Table 8 is proposed in [16], which generates all possible ( m + 1)-itemsets from H m . When the process exits the recursion, we again mark no-marked high-confidence rul es, which are redundant for Condition (ii) in Definition 7 (line 13-14). Finally we remove all redundant rules marked so far and get a minimal rule set (line 15). At the last line, we call function getOutliers to calculate outlier degrees for only candidate records and derive a set of outlier records. We first introduce real data sets used i n experiments, and then show results of the outlier records validation, accuracy comparison against [14] and runtime comparison between proposed algorithms and the brute force algorithm in that order. 6.1 Data Sets We use three real data sets: Zoo, Mushroom and KDD Cup 99. All are derived from the UCI Machine Learning Repository [18].

Zoo is a simple database about the habits of animals; it contains 15 boolean-valued attributes and 2 non-binary attributes. It is almost binary and sparce. Each record corresponds to an individual animal classified into one of 7 classes: mammal, bird life, crawler, amphibia, fin, bug and arthropods other than bug. It has 101 records. We use 16 attributes excepting the animal name and classes. Moreover, to make runtime comparis on easier, we prepare a new data set Zoo10000, which has 10,000 copies of each record in Zoo. Note that support values of each itemset on Zoo10000 equals those on Zoo.

Mushroom is a record data set about the botany of mushrooms. All attributes are nominal-valued. Each record belongs to class edible or class poisonous. Orig-inally, the number of instances for the two classes is almost equal (4208 edible class records and 3916 poisonous class records). We call this original data set Original Mushroom. For the accuracy comparison, we regard poisonous class records as true outliers, delete the clas s attribute and decrease the number of poisonous records so that the ratio of poisonous class records is approximately 1%. We call this data set Mushroom.

KDD Cup 99 is a network connection data s et, which includes a wide variety of intrusions simulated in a military network environment. Each record is classified into the normal class or one of the intrusion Classes, such as guess password, warezmaster and so on. The existing work [14], which we use as the baseline method for comparison of our detectio n performance, uses this data set for a detection accuracy experiment. Most attr ibutes take continuous values, which are put into to 5 discrete levels. We sel ected records in the guess password class as the true outliers set and created a data set KDD Cup 99, which contains 97% normal records and 3% outlier records. 6.2 Distribution of Outlier Degrees First, to observe distributions of outlier degrees, we calculate the outlier degrees for three data sets. They are presented in Figs. 1(a) to 1(c). We fix msup as 10% for Zoo assuming the Mapping Option, 20% for Mushroom, and 95% for KDD Cup 99, and calculate outlier degrees for some values of mconf . The horizontal axis of these figures corresponds to records sorted in the descending order of their outlier degrees. The vertical axis presen ts an outlier degree. From these figures, we know that as mconf becomes larger, the variance becomes smaller, i.e., fewer records have a relatively large outlier degree value. In Fig. 1(b), outlier degrees for mconf = 0%, i.e., the upper bounds, are very high and similar to each other. We think the reason is that cardinalities of associative covers are nearly equal to the number of attributes. In Fig. 1(c), the line for mconf = 95% perfectly corresponds with that for mconf = 0% because association among attribute values is extremely strong in KDD Cup 99. 6.3 Validation of Outliers We apply our method (called the AA Method) to Zoo and validate whether detected records (an imals) can really be regarded as outliers.

Table 9 shows the top 3 outliers in Zoo assuming the Mapping Option with msup = 20% and mconf = 90%, where the first column denotes the correspond-ing animal name, the second column repr esents initial associative covers C t 0 and the third column lists typical unobserved associations of C t 0 . Because the Map-ping Option is assumed, false values are ignored here. Due to space limitations here, we denote an item for a boolean-valued attribute as just the attribute. Although the Crab fundamentally has 8 legs, it is thought that item (# of Legs, 4) is used to mean  X 4 pairs of legs. X  However, item (# of Legs, 4) normally means  X 4 legs. X  Usage to mean  X 4 pairs of legs X  is obviously an exception. The Housefly and Moth have the same outlier degrees because their initial associative covers is typical for mammals, other typical rules for mammals and bird life become unobserved associations. From the beginning, the bug class for the Housefly and Moth is a minor class having only 8 kinds of animals. Of them, bugs having item Hair are the Housefly, Moth and Wasp, which is the fourth outlier. Judging from the results, detected ou tliers are reasonable.

When we do not use the Mapping Option, we derive a record of Octopus with the highest outlier degree. A typ ical unobserved association is { (Feathers, F), (Fins, which is the largest class in this data, while the antecedent can be observed in any class other than bird life and fin. That is, this unobserved association is not quite meaningful and it is uncertain why the Octopus is detected as an outlier with the highest outlier degree. This suggests that the Mapping Option is useful for asymmetric attributes.

We also apply the AA Method to Original Mushroom with msup =6%and mconf = 90%. The top 112 records have the same outlier degree value (1.4% for all records). Among these outliers, 93 belong to class edible. None of these outliers includes the item (Odor, none) . There are only 10% edible mushrooms that have odor. Moreover, about half of all high-confidence rules have item (Odor, none) in either the antecedent or consequen t. In fact, initial associative antecedent are used for the growth. As a re sult, their associative covers expand more. The remaining 19 outliers ranked in number-one belong to the poisonous class. Their associative covers similar ily expand because they do not have items all high-confidence rules. We conclude, then, that our method can detect more rare records. 6.4 Accuracies Comparison We evaluate our method (AA Method) against the probabilistic method of [14]. Similar to accuracy experiments in [14 ], we take two accuracy measures: the detection rate that is the fraction of detected true outliers to all true ones, and the detection precision that is the f raction of detected tr ue outliers to all transactions detected as ou tliers. To see fair play, we provide a fixed parameters for each method, and get accuracy plot lines of top-l records ordered by the outlier degree which each method calculates, as changing the l value.
Fig. 2(a) presents the comparison for Mushroom, when msup = 20%, mconf = 95%, and mod = 0.25 are given for the AA Method and k =2and  X  = 0.003 for the probabilistic method. Both the AA Method and Probabilistic Method show very good accuracy. In the best case, the AA Method derives about 98% of the detection rate and 100% of the detection precision, where, in fact, it fails to detect only one true outlier. Although the Probabilistic Method achieves both 100% accuracies, the performance gap between the AA Method and Probabilistic Method is very small.

Fig. 2(b) shows the experimental result for KDD Cup 99. We have given msup = 95%, mconf = 95% and mod = 0.15 for the AA Method and have given k = 2and  X  = 0.15 for the Probabilistic Method. The reason that the plot line of the Probabilistic Method moves upwards partway is that a few records ranked top, which derive the highest outlier degree, are not true outliers, although true outlier records also derive higher outlier degree. As shown in this figure, our method obviously outperforms the method of [14].
 Although we give the other msup value and mconf for Mushroom and KDD Cup 99 respectively, the accuracy change s are not dramatic because attribute as-sociations in both data are strong and the set of generated rules does not change significantly. However, it is obvious that our algorithm is generally sensitive to parameters, so finding proper parameters is important. We regard this problem as future work. 6.5 Runtime Comparison Here, we verify that the proposed algor ithm delivers faste r detection. We com-pare 4 detecting methods. First is the brute force algorithm in Table 1 (BF). Second is an outlier detection that uses only a minimal rule set (MinR). Third is one that uses only a maximal associative cover (MaxC). Fourth is our com-plete algorithm utilizing both a minimal rule set and a maximal associative cover (MinR+MaxC). For Zoo, we use the Mapping Option. Here we omit the result for Mushroom due to space limitations.
 Fig. 3 shows the processing time (logarithmic scale) as msup changes. For Zoo10000 (Fig. 3a), we provide ( mconf , mod ) = (90%, 0.6). For KDD Cup 99 (Fig.3b),wegive( mconf , mod ) = (95%, 0.15).

BF takes much runtime and the availabilities of proposed algorithms increase as msup decreases. In both figures, Min R+MaxC runs fastset for some msup . Overall, MinR can decrease runt ime much more than can MaxC. In this paper, we target cate gorical record databases and detect records in which many attribute values are not observed even though they should occur in asso-ciation with other attribute values. We provide an outlier degree based on asso-ciations among attribute value sets, and present more efficient algorithms than a brute force algorithm to speed up detection. Experiments show that our out-lier degree has sufficient detection perfo rmance compared to the hottest related work, detected records are practically inte resting and convincing as outliers, and the proposed algorithms are much faster than a brute force algorithm. A future task is to derive the most proper parameter values such as msup , mconf and mod .
 Acknowledgement. This research was supported in part by the grant-in-aid for scientific research from JSPS (#19024006).

