 Mobile spam in an increasing thr eat that may be addressed using filtering systems like those employed against email spam. We believe that email filtering techni ques require some adaptation to reach good levels of performance on SMS spam, especially regarding message representation. In order to test this assumption, we have performed experime nts on SMS filtering using top performing email spam filters on mobile spam messages using a suitable feature representation, with results supporting our hypothesis. H.3.3 [ Information Storage and Retrieval ]: Information Search and retrieval  X  information filtering . H.3.4 [ Information Storage and Retrieval ]: Systems and Software  X  performance evaluation (efficiency and effectiveness) . Performance, Experimentation, Security, Standardization. Spam filtering, Mobile Spam , SMS, ROC Analysis, TREC. SMS spam is now prevalent in Singapore and Japan and will undoubtedly spread throughout the world. As mobile devices increase in computational power, and sophisticated and powerful systems can be connected to mob ile phone networks, it is wise to test which technical measures against email spam can be transferred to SMS spam. We report here our work on making current email spam filters effective on mobile spam. It is not clear that current spam filters should perform well on mobile spam. SMS messages are shorter then email; they lack structured fields, and their text is rife with abbreviations and idioms. We have performed a seri es of experiments on SMS spam filtering, using high performance email spam filters, following TREC-like procedures [2], and focusing on feature definition. The results of our experiments show th at feature engineering is more critical for mobile spam filtering than for email filtering. In order to test filters on SMS spam, a collection of spam and ham (not spam) messages must be coll ected. We use variations of the collections described in [3]: These spam filters 1 have performed consistently well on TREC spam filtering evaluations, OSBF-Lua being the top scoring method in TREC 2006. The filters were presented the messages in raw form, but Bogofilter and OSBF-L ua were also fed a textual representation of the feature vectors discussed above: Each feature is represented by a different dummy word, repeated as many times as the feature appears in the original message text. We evaluated each filter on each corpus using 10-fold cross validation. Following TREC, we plot the tradeoff between ham misclassification and spam misclassification as a receiver operating characteristic (ROC) curve. As a summary measure we report 1-AUC as a percentage where AUC is the area under the ROC curve (normalized so that each axis extends from 0 to 1). Figures 1 and 2 show the ROC curv es for the English and Spanish collections; (1-AUC)% statistics are presented in table 1, along with a 95% confidence interval (the smaller, the better). Bogofilter and OSBF-Lua perform poorly on the raw messages, but are competitive using our textualized features. DMC and PPM, which are not feature based, perform well without modification. Logistic Regre ssion and SVM perform well on our features. In absolute terms the performance of all filters (except the raw versions of Bogofilter a nd OSBF-Lua) is comparable to what one might expect for an email corpus of comparable size. We note that the differences in AUC among these six filters are not statistically significant  X  a larger corpus will be necessary to distinguish them. The effect of shorter and sparser text is also clear. Bogofilter and OSBF-Lua perform poorly on the raw messages and much better on the textualized feature vectors. OSBF-Lua reports the fewest mistakes, with only five false ne gatives and no false positives, for the English collection. As a final conclusion, the differences among all the filters are not clear, so more experiments with a larger dataset are required. Pointers to descriptions of these spam filters and Machine Learning methods can be found in e.g. [2]. 
