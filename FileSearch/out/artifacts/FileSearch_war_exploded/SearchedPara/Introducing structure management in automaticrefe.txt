 1. Introduction
XML is a well-established and successful document language. Among the characteristics that justify this success are that it is application-independent, which makes it the ideal format to exchange data, that it sep-arates document content from document layout, its extensibility (basic to providing semantic tagging), and the ability to explicitly represent document structure by means of the markup. This last characteristic, together with extensibility, make it an ideal format, with no rival at the moment, for structured documents . represent many different types of document structures, ranging from the most specific ones, restricted to one document, to wide-spread standards which provide the common rules for classes of documents in the form of
DTDs or XML Schemas. The domain fields of application are wide, and as examples we can cite the schemas defined for the math environment (MathML DTD, Carlisle, Ion, Miner, &amp; Poppelier, 2003 ), web documents (XHTML, W3C HTML Working Group, 2002 ), chemical (CML DTD, Murray-Rust &amp; Rzepa, 1999 ), liter-ature (the TEI DTD, Sperberg-McQueen et al., 2002 ), or the various schemas defined to be used in e-govern-ment applications and legislative digital libraries ( Arnold-Moore, 2000; Boer, van Engers, &amp; Winkels, 2002;
Bolioli, Dini, Mercatali, &amp; Romano, 2002; Finke, 1997; Marchetti, Megale, Seta, &amp; Vitali, 2002; Mart X   X  nez, de la Fuente, &amp; Derniame, 2003; Palmirani &amp; Brighi, 2002; Sjo  X  berg, 1997a, 1997b ).

Representing structure is not enough by itself and once the structure is available in electronic format, access to it, that is, to be able to access a document content, not as a whole, but in independent pieces (the ones it is structured in), is an immediate requirement. For this, XML provides a standard language, XPath ( Clark &amp;
DeRose, 1999 ). 2 XPath provides a standard syntax to access fragments of XML documents, by structure, describing the path from the document root to the desired element or set of elements. XPath is the basis of several other XML standards (XPointer, XLink, XSLT). It is also the basis of query languages that support queries based on conditions with respect to both structure and content from XML documents, as the ones presented in Fuhr and Grobjohann (2004), Amer-Yahia and Case, 2003, Buxton and Rys, 2003, Boag et al., 2002, Chamberlin, Robie, and Florescu, 2001 and Robie et al., 1999 .

Access and querying by structure are probably the best known situations in which the structure of docu-ments plays a significant role. However, the structure of documents is also exploited in other situations, not so popular but no less useful, as are the references to fragments of structured documents. For example, a reference 3 such as  X  the fourth article of chapter two  X , uses the structure of the document the (referenced) arti-cle belongs to, in order to identify it, by providing its position within this structure.

References, such as the one in the example, are to be extracted from the content of documents. The auto-matic tools analyze document content, searching the patterns that references follow and, when a match is found, a reference is recognized. This being a problem with a variable degree of difficulty, depending on the regularity of the patterns associated to references, it has been, and still is, the target of several efforts, mainly dedicated to the recognition of references to scientific literature ( Bergmark &amp; Lagoze, 2001; Councill, Giles, Han, &amp; Manavoglu, 2005; Day et al., 2005; Ding, Chowdhury, &amp; Foo, 1999; Dozier, Jackson, Guo,
Chaudhary, &amp; Arumainayagam, 2003; Lawrence, Giles, &amp; Bollacker, 1999; Lawson, Kemp, Lynch, &amp; Chow-dhury, 1996; Moens, Angheluta, &amp; Dumortier, 2005 ).

Related with reference extraction is reference resolution , the step in which the item (document or fragment) or items referenced are located and presented to the end user. The most common practice is to work at the doc-ument level, that is, the document target of each reference is identified and located, but without saying exactly what the fragment or fragments of interest are. This is called document-centric resolution ( Bergmark &amp; Lagoze, 2001 ).

However, together with the fact of knowing which documents are related by a reference, it can be interest-ing, in the case of structured documents, to know where (in what part) in the document the reference appears.
This may be useful information to keep, as it can be used in the case of large documents to quickly find a ref-erence in the document. Also, it would permit queries about  X  X here X  inside documents a given item is refer-enced to be answered.

Moreover, this ability is much more interesting from the user X  X  perspective if the  X  X here X  is expressed in a manner he/she can easily understand. For example, if we search  X  X here X  the last issue of this journal is refer-enced in an on-line article, it is clear that an answer such as  X  in the  X  X ourth X  paragraph of the second  X  X ivision X  element within the  X  X ody X   X  is not very meaningful for a human; however, an answer such as  X  in the fourth par-agraph of section 2  X  makes much more sense for us humans. This perspective could be part of automatic treat-ments if the structure of the electronic documents describe the structure of the abstract entity (document) whose content it stores  X  which is the one the users recognize  X  or some information is stored that permits the equivalences between them (the electronic document structure and the abstract entity structure) to be computed automatically. We did not find, in any of the works cited about reference extraction, anything that indicates that this feature is present in the existing reference extraction tools. However, this feature would fill a gap between automatic applications and their users: the results of these tools would be  X  X eaningful X  to their users.

Some works consider the possibility of working with document fragments during reference resolution. One of these approaches is the languages designed in the open hypermedia context to permit arbitrary selection of components of hypermedia documents ( Gr X nb X k, Sloth, &amp; Bouvin, 2000 ). As this specification is neither really related to structured documents or XML documents, and nor is it a widely accepted standard (in fact, there are very few implementations using it), we do not take up this option. Another approach to the man-agement of document fragments during reference resolution is the association of identifiers to fragments. In these approaches, at the moment of solving a reference, the fragment(s) is located by its identifier ( Arnold-
Moore, Anderson, &amp; Sacks-Davis, 1997 ) In this case there is no language at all that uses document structure to address fragments by their position within it.

A last approach is using some proprietary language (to address fragments by their position within the doc-ument structure), as in the examples shown in Dumitru, Colomitchi, Budulea, and Diaconescu (2005) . In this work the authors present a legislative digital library, whose documents are XML, in which references are stored as links. One of the attributes of such links is the one that stores the  X  path  X  of the legal text fragment referred to (e.g. the path article 1, paragraph 7 is represented as 1 * /7 ). The language used to address frag-ments is not described in this work and only the examples give some clue about the basis. However, this is enough to realize that this is a proprietary language (looking at the example it seems that article elements as XPath has.

In this paper we present a methodology, and application case, to automatically extract and solve references to fragments of structured documents. The automatic reference resolution is a process which considers both the structure of the documents referenced and of the document that contains the references. XPath is used as the base language to express paths to fragments of documents by means of paths in trees. Not all the expres-sions at this level would be XPath valid expressions, but they are similar. These  X  X Path-like X  paths are machine-processable, and transforming them automatically to equivalent XPath expressions that address XML document fragments, is simpler than it would be if we used a different language.

We distinguish two levels of abstraction in this work with references: the abstract document (or intellectual entity ) level, and the electronic document level. In the application case of this paper, the intellectual entities considered are legal texts. The first step of reference resolution, presented in Section 6 , works on these abstract documents. For each reference, if we are able to automatically build a path expression that locates the legal text fragment referred to, this step succeeds. The different renditions of these abstract documents in different formats are different electronic documents . In the case of XML documents, their markup represents their struc-ture. But this structure may or may not coincide with the structure of the abstract document whose content they hold. 5 The second step of reference resolution intends to solve references at this level, dealing with the schema heterogeneity that different XML markups introduce: If we are able to link the reference to some
XML document (or fragment) whose content is the legal text referenced, this phase succeeds. In the implemen-tation, we also benefit from the fact that the source documents to the reference extraction processes are XML to compute the document position where a reference was detected.

This proposal is inspired (and implemented) from our work with legislative texts
The legislative environment is one example in which XML is widely accepted as the most appropriate  X  X ormat X  for legal documents. Legislative texts are very well-structured documents and XML helps to manage structure.
References to legislative texts are in many cases references to internal fragments. The position of fragments with respect to the internal structure of the document is used to identify them. Several schemas have been developed in this domain, either in the form of DTDs or XML Schemas ( Arnold-Moore, 2000; Boer et al., 2002; Bolioli et al., 2002; Doggen, 1996; Finke, 1997; Haider, Sjo  X  berg, Quirchmay, &amp; Sebald, 1996; Heintz, 2002; Hemrich, 2002; Marchetti et al., 2002; Mets, 1996; Sjo  X  berg, 1997a, 1997b ), but few of them are based on mapping the internal structure of legislative texts to XML tags ( Marchetti et al., 2002; Mart X   X  nez et al., 2003 ).
However, one of the advantages of doing so would be to facilitate automatic reference resolution, as we show in this paper.

On the other hand, despite the fact that legal documents are, after scientific papers, one of the preferred examples to test reference extraction proposals (due to the regularity of the patterns reference chains present) ( Bolioli et al., 2002; Lawson et al., 1996; Nahm &amp; Mooney, 2001; Palmirani, Brighi, &amp; Massini, 2003 ), there are very few works which indicate how that reference resolution is considered. The only ones we know of are ( Bolioli et al., 2002; Dumitru et al., 2005 ). However, these works do not discuss if this process is somehow automated , nor how XML X  X  capabilities could facilitate this process, or how schema heterogeneity could be managed, which our work does cover.

The approach presented is original in the use of XPath for reference extraction and resolution. It contrib-utes to filling the gap between reference extraction applications and structured document manipulation. In addition, it introduces an original use of XML standards showing how this standard is useful over and above what it was originally intended for, and not just restricted to XML documents.

The remainder of the article is organized as follows. Section 2 offers a brief introduction to XPath. In Sec-tion 3 we present the methodology. The structure of legislative texts is briefly presented in Section 4 . Reference extraction is dealt with in Section 5 , while the automatic resolution of these references is the subject of Section 6 . Section 7 discusses the results obtained in some experiments with legislative texts. Section 8 presents the main conclusions from this work. 2. Addressing fragments with XPath
XPath, the XML Path Language ( Clark &amp; DeRose, 1999 ), permits fragments (parts of) of XML documents to be selected, based on conditions on those fragments. XPath conforms to the view of an XML document as a tree, whose nodes are the XML document pieces (elements, attributes, text, processing-instructions). Condi-tions with XPath are expressed by means of path expressions, which provide a means of hierarchic addressing nodes in an XML tree. With XPath, it is possible to select nodes by position, node kind, content, and several other criteria. Several useful XML languages are based on XPath. XSLT, the XML Stylesheet Transformation
Language, uses it to match and select particular elements in the input document for copying into the output document. XPointer, the language used in association with XLink to link fragments, is built on top of XPath. XQuery, the XML query language enforced by the W3C, was conceived as an extension of XPath (in fact, of
XPath 2.0). When using XML Schema, the W3C standard to describe schemas, XPath serves to define unique-ness and identity constraints.

The most important XPath expressions are location paths , which are built from location steps. A location path selects a set of nodes from an XML document. There are seven kinds of nodes in XML documents: the document node  X  root of the tree, element nodes, text nodes, attribute nodes, comment nodes, processing-instruction nodes, and namespace nodes. Each location step specifies a point in the targeted document, gen-erally relative to some other point, such as the start of the document, or the previous location step. This point is called the context node . In general, a location step has three parts, the axis, the node test, and an optional predicate, combined in the following form:
The axis indicates in what direction to search from the context node. The node-test selects the nodes to con-sider along the axis. The predicate is a boolean expression that tests each node in the node-set. It may be a single predicate, or a list of predicates. Only nodes that comply with the three conditions expressed by the axis, node-test, and predicate, simultaneously, are selected.

With XPath, there is a document order , defined on all the nodes in a document. The order of each node is the order in which the first character of the XML representation of each node occurs in the XML represen-tation of the document. If we consider only element nodes, the document order orders element nodes in order of the occurrence of their start-tag in the XML.

An example XPath expression appears in Fig. 1 . This location path addresses the first element articulo inside the first element disposicion inside the context node (e.g., the document root). There are two loca-tion steps in this example: (1) descendant::disposicion[1] (2) articulo[1]
The child and descendant axes are the most used. However, other axes ( following-sibling , preceding-sibling , following , preceding ancestor-or-self ) permit traversals of XML trees to be implemented in several different directions, providing flexibility. This permits the classical tree traversals to be implemented with XPath.
For example, the disposicion node selected by the first location step in the example above is the dispo-sicion element that would be listed first in a preorder traversal of the subtree whose root is the context node.
Besides the flexibility that axes provide, it is possible to combine subqueries to specify sophisticated conditions on XML elements. For example, the expression //articulo[position() &gt; = 1 and position() &lt; =5] refers to the first, second, third, fourth and fifth articulo elements in the document.

XPath is a powerful language, with which it is possible to express complex path expressions. What has been explained in this section is that part of XPath needed to understand how XPath is used in reference resolution in Section 6 . It is the subset of XPath with which we express paths in trees with typed (named) nodes. We assimilate a typed node in a legal text document tree with an XML element, so that the tag name of the
XML element is equivalent to the node type of the legal text node. 3. Methodology
This section presents the steps for reference resolution that are related with structure. This first step of ref-erence extraction and resolution consists of an analysis of the domain in which the documents that contain references are created. This study would permit the patterns that these references follow to be characterized, so that the tools that extract the strings matching these patterns from texts (that is, the reference anchors) and solve the references, can be created. Steps 1 and 2 make part of the domain analysis. They emerge as necessary when structure is considered. When reference manipulation works at the document level (document-centric resolution) these steps are not needed. Reference extraction and resolution follow. In the following, the four tasks are discussed in the same order they are performed: (1) To discover the structure rules exploited in references.
 (2) To identify how that structure is used in references.
 (3) To design a method to extract references from document content.
 (4) To design an algorithm to solve references.
 4. The structure of legislative texts
The rules of the Law are organized under the form of legislative texts, each of which groups rules governing a given subject-matter. These texts are intellectual entities. They have a title, source, content, date of promul-gation, etc., and they exist no matter what the format is their creators choose to render their content. They may be rendered in XML, pdf, or any other format, all of these texts are the same; two users accessing different renditions of the same legal text will find the same content.

Legal texts are very well-structured documents. They are always written as a sequence of divisions, such that each division governs a specific subject-matter within the general matter ruled in the document; each divi-sion can itself be subdivided in other divisions in the same way. In the legal community, this structure is called internal structure ( Grupo de Estudios de Te  X  cnica Legislativa, 1989 ). These divisions always have a  X  X  X ype X  X  (or  X  X  X ame X  X ) and are  X  X  X rdered X  X  inside a document; they can be distinguished during the reading of a document by their type and number. Moreover, this structure reflects the semantic structure of the document: the divisions are chosen by legislators because of semantic reasons (subject considered in each division) ( Grupo de Estudios de Te  X  cnica Legislativa, 1989 ).

This is the structure that helps normative document users to determine exactly where inside a document they can find information (rules) about a given subject (finding the rules governing a given subject is the main reason to use these documents). Fig. 3 shows a fragment of an EU normative document. is to recognize here the second chapter of the document, containing the first section , within which there are the articles number two and three of the document. Chapter two rules the jurisdiction of the Regula-tion, while articles two and three specify respectively how that jurisdiction applies to residents of a Member state, inside it, and outside it.

Documents made by composing well X  X elimited pieces of content (that can present an inclusion hierarchy between them) are said to have a logical structure , and called structured documents ( Andre  X  , Furuta, &amp; Quint, 1989 ). The logical structure of a document divides and subdivides it into items meaningful to the human author or reader. The logical structure can be represented with a tree model, where internal nodes represent the document fragments (divisions), and leaves represent the document content ( Furuta, 1989 ).

According to this definition, legal texts are structured documents . Therefore, it is possible to represent their structure in a tree manner, so that paths in the tree select pieces of these texts, which are their divisions. For example, in the tree associated to the document in Fig. 3 (see Fig. 6 ), there are: a root node representing the document, and descendants of this node, representing its divisions, within which there are several chapters .
One of these is the second chapter of the document. That is, the one that occupies the second position within the ordered set of chapters of the document; in the view of the document as a tree, the node representing this chapter occupies the second position in the ordered list of chapter nodes of the document, which can be obtained by selecting the chapter nodes from the ordered list of nodes that returns a preorder traversal of the document tree. That is, the position of a legal text X  X  division can be expressed, either relative to the starting point of the document, or in terms of the relative position of its associated node in the document tree.
Normative documents produced in the same legislation space (state, union of states, others) have similar structures; they constitute a class. The internal structure of the documents we deal with complies with the structuring rules we can find in the corresponding drafting manuals ( European Communities, 2003; Grupo de Estudios de Te  X  cnica Legislativa, 1989 ). These rules restrict the types of divisions allowed, and the inclusion hierarchy among them. For example, sections can contain chapters and articles ; chapters can contain articles but no sections , and articles can contain neither sections , nor chapters . This provides a general structure, which we reflect in a pivot schema for these documents. Its formalization under the format of a DTD appears in Fig. 2 . 10 5. Reference extraction
A reference implies a relationship between the origin of the reference and its target or targets, that is, the items referred to. The text in Fig. 4 is a fragment of an EU normative document and it contains two references: one to Article 41 of the 1968 Convention and the second one to Article 40 . Each of them establishes a relation-ship. For example, the first one relates the 20th article of the Convention of Accession of 9 October 1978 of the
Kingdom of Denmark , of Ireland and of the United Kingdom of Great Britain and Northern Ireland to the Con-vention on jurisdiction and enforcement of judgments in civil and commercial matters and to the Protocol on its interpretation by the Court of Justice , in which it appears, with article 41 of the 1968 Convention (which is a different document).

It is worth remarking here that both documents are legislative texts, that is, abstract entities, and that there is no need to know anything about the format of the available renditions of each document (or even if they are available) to confirm the existence of a relationship between these two abstract documents. Each relationship connects two document fragments and each of them can be described by providing a pair ( source , target ) with the locators of each of them. Fig. 5 shows the data that describe the example reference. These data are its anchor , which is the string extracted from document content; the source document , that is, the document in which it was found; and the target document , which is the document referred to. This is the minimal informa-tion to describe a reference, which is the classical perspective of reference extraction. Added to this work are the two location fields that permit the (source) document fragment where the reference has been found, and the (target) document fragment referenced to be located.

In fact, there are two levels of abstraction we have to differentiate when dealing with reference extraction and resolution. The first is the abstract document (or intellectual entity ) level. The second is the electronic doc-ument level. 5.1. Abstraction levels in reference resolution
The abstract document level is at a higher level of abstraction. The entities considered at this level are intel-lectual entities, which are the ones that domain users manipulate. Therefore, the references in document con-tent are created at this level: the structure exploited is that of these intellectual entities. The extraction of references from document content (the anchor detection explained in part 5.2 ) works at the level of abstract documents, legal texts in our example. The resolution is also started at this level: it computes the paths of the fragments of abstract documents. In the following, we will refer to paths in this level as  X  X evel-1 X  paths. We express these paths in an XPath-like manner. However, they are not XPath expressions. First, the documents considered are not XML documents. Second, the positions in these paths are not XPath valid positions. How-ever, they are meaningful positions in documents at this level.

The electronic document level is at a lower level of abstraction. This level is to the abstract document level the same as logical models in databases are to conceptual models. The different renditions of the abstract doc-uments of the first level, in different formats ( e.g. the XML , PDF , HTML , etc. versions of this paper ), are the entities considered at this level. In the case of XML documents, their markup represents their structure. Yet this structure may or may not coincide with the structure of the abstract document whose content they hold. If it coincides, it is said to be a descriptive markup , which  X  X  X ot just marks element boundaries, but carries the meaning X  X  ( Renear et al., 2002 ). However, this is not always the case: HTML (or XHTML) is a well-known example of presentation oriented markup, in which case the markup does not say what an element is, but how it should be presented.

Paths in this level are XPath expressions: they are paths in XML documents. In the following, we will refer to these paths as  X  X evel-2 X  paths.
 Fig. 6 (a) shows a piece of the structure of the abstract document to which the fragment in Fig. 3 belongs. This is the abstract document level. Fig. 6 (b) shows the structure of one rendition of this document in
XHTML. 11 Nodes in this tree are XML elements. A comparison of both trees reveals differences between them: besides the obvious differences in node names, there are also structural differences (that is, the divisions of the abstract document and its rendition do not map one-to-one); for example, there is no division in the
XHTML document that permits an XML processing tool to recognize the limits of a section . Another example of heterogeneous markup for the same abstract document is shown in Fig. 11 and discussed in Section 6.2 .
This distinction between resolution at the level of abstract documents and the level of digital documents is an aspect we have not found in any of the papers about reference extraction consulted. In those papers related with reference extraction the method seems to be implicitly assumed to work with intellectual entities, for example, in the extraction of scientific references ( Bergmark &amp; Lagoze, 2001; Day et al., 2005; Ding et al., 1999; Dozier et al., 2003; Lawrence et al., 1999; Lawson et al., 1996; Moens et al., 2005 ). As in these cases the resolution is restricted to the  X  X ocument level X  (no access to fragments is required) it is not important to pay attention to what the structure of the documents is or what the format and/or structure of their ren-ditions is. However, in a situation as the one we present, in which references to fragments play an important role, the structures play a very important role as well, and this distinction becomes an essential issue in the automation of both extraction and resolution processes. 5.2. Anchor detection Anchor detection consists in detecting the strings representing each reference in the document content.
This step is prior to the resolution. Anchor detection is a pattern matching problem. Briefly, what we do is to match the texts against a set of patterns, which are the patterns followed by references in the working domain (legal domain in the example of this paper). These patterns are built with the vocabulary used in references and the syntactic constructions that references follow. The vocabulary in references to fragments includes the names of divisions ( articles , chapters , others), the lexicon for position (ordinals, num-bers, etc.), and connecting particles (conjunctions, etc.). No more details about the pattern matching tech-niques used in this process are included in this paper, as it is not the problem considered in this discussion.
Anchor detection is a task dealt with by the pattern recognizer component of Fig. 7 . For each reference, the results of this anchor detection process is a record that contains the terms found, each of them annotated with the type of token it matched. That is, here are names of divisions and their identifiers (positions in most cases). Also, the inclusion relationships between these divisions are also available in these records, as they are represented by the nexus connecting these divisions in the anchors. These records are later used in the resolution.

It is this pattern matching task that will reflect changes in the manners of referencing (style, language) in different collections. Grammar description and lexical information would be different for each referencing style.

In general, the more documented task, when information extraction is applied to citation (reference) extrac-tion, corresponds to our anchor detection phase ( Bolioli et al., 2002; Day et al., 2005; Ding et al., 1999; Dozier et al., 2003; Palmirani et al., 2003; Zelenko, Aone, &amp; Richardella, 2003 )  X  which is not the task that receives the main attention of this paper. For this task several techniques can be used, distinguishing mainly between approaches that learn patterns from manual examination, and approaches that try to learn patterns automat-ically ( Moens, Logghe, &amp; Dumortier, 2002 ). In the first case, knowledge available in drafting manuals (if we consider legal documents drafting), or style guidelines as APA, IEEE, etc. (if we talk about scholarly biblio-graphy), is used to build the patterns that anchors would match. In the second case, the tools learn from a training set (see for example Lawrence et al., 1999 ). Our approach falls in the first case. 5.3. Anchor location One of the advantages of using XML is that it is possible to accurately address document fragments.
Anchor detection, a process for which the format of the analyzed document is initially indifferent, benefits from the fact of working with XML documents. It helps to automatically calculate the location of the string detected, that is, the location of the reference anchor in the XML document where it was found. In such a case, the pattern matching process operates on the content (text nodes) of XML elements. A document analyzer, built on top of an XML parser, receives the text of each element from the XML parser and passes it to the pattern matching application ( pattern recognizer in Fig. 7 ), from which it receives in turn the set of records (commented in part 5.2 ) that describe the references found in that portion of text. But the document analyzer also keeps track of the elements visited in the document, and the inclusion hierarchy between them. With this information, it is able to build a path to locate the anchor in the XML document. This path is a very precise
XPath expression, which always addresses the smallest XML element in which it is possible to locate the reference.

It is worth remarking that the path we consider is a path in an XML document, not in an abstract docu-ment. There is always an equivalent path in the abstract document represented by the XML document. The process to obtain an equivalent path in the abstract document is the inverse of the process commented for the second step of the resolution in part 6.2 . 6. Reference resolution
The resolution of a reference consists in computing locators, for each anchor detected during reference extraction, that address the reference X  X  targets. As advanced in Section 3 , reference resolution is organized in two steps. The first is to obtain a  X  X evel-1 X  path, that is, a locator in the target abstract document (legal text). The second is to calculate equivalent  X  X evel-2 X  paths, that locate XML elements in XML documents.
The algorithm in Fig. 8 deals with the first part of the resolution. This is the resolution step that receives the main attention in this paper. It performs the tasks that always have to be done. It is independent of the markup of the XML documents available in digital collections. However, its results,  X  X evel-1 X  paths, are expressions that automatic tools can process. This allows automatic methods to map them to equivalent paths in the XML documents available to be dealt with, no matter what their markups are. This  X  X evel-2 X  resolution is a schema mapping problem to be solved for each different (XML) schema present in the digital collections.
 6.1. Level-1 resolution: paths in abstract document trees
The resolution algorithm (in Fig. 8 ) builds  X  X evel-1 X  paths ( X  X Path-like X  expressions) for the anchors extracted from the content of documents. Its inputs are the output records of the anchor detection dealt with in Section 5.2 . For each input reference, it returns a set of paths. Each path in this set locates one of the ref-erence X  X  targets.

The algorithm starts by decomposing the input reference in a set of equivalent references. Each reference in this set has a single target, either document or document fragment. If the input reference to the algorithm is already a single reference, it is the only element of this set. If the input reference has several targets, the ref-erence set has two or more single references.

For each single reference r i , the algorithm executes the following actions: First, it builds a path for its con-text node, which can either be the root node of a document, or the node associated to some known division (e.g., the division in which r i is placed). Next, it calculates a set of  X  X ocation steps X , one for each division men-tioned in r i . Then, it builds a path connecting these location paths, starting from the lowest level division, either until it reaches a  X  X ocument-position X  type division (i.e., a division whose position is expressed relative to the root node of the document), or all location paths are connected. Finally, it concatenates this path with the path of r i  X  X  context node, which provides the locator for r
In the following, its operation is explained in a set of example references. They cover, in order of appear-ance: an internal reference with two target fragments; an external reference, with several target fragments; a reference with a range; a reference to a fragment with a human-understandable, but not machine processable, position; a direct, ambiguous reference; and a relative reference. Table 1 shows them and their paths. Example 1. Internal reference, with two target fragments.

Let us consider the reference articles 1.3 and 1.4 of this Law ( art X   X  culos 1.3 y 1.4 de esta Ley ). The record that the anchor detection returns contains each term of this anchor, annotated with the type of token it matched.
This record is the input to the algorithm. Below are shown the terms, and corresponding types, of this refer-ence. It is possible to recognize the element type article , of which there are two items with their respective num-bers (1.3,1.4) coordinated in the reference; both of them are connected by an inclusion particle ( of ) with the document they belong to ( X  this Law  X ). has multiple targets. As this is a multiple reference, it is decomposed in an equivalent set of single references, that is, a set of two single references:
In this example, there is an intermediate step to perform before proceeding with the algorithm in Fig. 8 . This is a particularity of a certain manner of citing legislative documents which we had to implement to cope with it:
The article X  X  numbers are in fact an abbreviation to indicate a paragraph contained inside the cited article. As this is a particular stylistic use of the legal domain, we do not extend more on this, and it is not considered by the algorithm, which covers general situations. Before advancing to compute the paths for each reference, we decompose both to provide the element type (paragraph) and position (3rd, 4th), so that everything is ready to enter the next step of the algorithm:
Now that each document fragment has its own element type and number, it is possible to proceed with the next step of the algorithm. The body of the external for loop calculates a path for each of these references.
In the example reference, the context node is the root node of a document ( X  this Law  X ), which is the document that contains the reference.

The construction of a location path for fragments is implemented by the repeat loop, which concatenates the location steps obtained in the preceding for loop. When the  X  X ocument-position X  type division is found (an article in the example) the path is complete, ready to be added to the context node X  X  path.

Fig. 9 synthetises the composition of a location path for the example reference with number (1). There are two location steps in this location path: one for the element article and another for the paragraph ele-ment. Both are identified by their position. Yet, while the position of the article is relative to the root node of the document (it is the 4th article of the document), the position of the paragraph is relative to the arti-cle that contains it, that is, it is the 4th paragraph inside article 3. In consequence, the article X  X  location step is built on the document X  X  descendants axis (//), which is the axis used for  X  X ocument-position X  divisions, while the paragraph X  X  location step indicates that it is a child of the article (/). The use of these two axes com-bined, descendant and child , has permitted the inclusion relationships between the two legislative text divisions that participate in this path to be expressed. 12 Example 2. External multiple reference.
 example of an external reference with multiple targets, for which we show the records obtained from the extraction, already decomposed in several single references:
The most evident way to solve such a reference would be to build a path in which the elements are nested in the inclusion order indicated by the inclusion particles of the references. Also, each of these elements would be  X  X dentified X  by its position, which would give, for the example reference (1), the path rdleg1-1994#// chapter[5]//article[24] . In fact this is in an incorrect path: it addresses the 24th article inside the 5th chapter (we should go into the 5th chapter , consider its article elements, and count up to 24 to get the arti-cle addressed). However, that is not the article referenced. It is the 24th article of the document. The correct path is shown in Table 1 .

These references illustrate the way in which the criteria used to number certain types of divisions in a domain determines the axis and context node that the resolution algorithm has to consider when building paths for them. To cope with this, the algorithm checks the criteria used to locate each type of division and it stops adding location steps to a fragment X  X  path when it finds a  X  X ocument-position X  fragment. This information is available in the pivot schema as an attribute of each type of division. If there were other pos-sibilities than the two mentioned, they would be reflected conveniently in the corresponding attribute in the pivot schema.
 Example 3. Direct reference, with a range.

References to portions of documents which are in fact a sequence of divisions of the same type are quite com-mon. In the reference  X  articles 181 to 185  X ( los art X   X  culos 181 a 185 ) we have such an example: the interval of articles ranging from position 181 to 185 are referred to simultaneously, by providing the extremes of the interval.

This manner of referencing usually appears when the divisions mentioned form together a piece of document with related content, which the reference X  X  author wants to present in a unitary manner, as a block.
These intervals of divisions of the same type can be expressed with a predicate ( position ()&gt;= 181 and position ()&lt;= 185 for the example interval).

Example 4. Direct, non-ambiguous reference, to a fragment with a human-understandable, but not machine processable, position.
 nica del Poder Judicial ) is a normal one, except for one thing: the  X  X umber X  used to index the position of the referenced article . This example shows the use of an ordered set, used to index the sequence of ordered ele-ments (in the example, the set of articles of the document named Ley Orga  X  nica del Poder Judicial ), distinct from the set of natural numbers, which is the most common one.

In the example, the index set is the one obtained by intermixing additional elements within the natural set of no problem for a human being to locate an element indexed with this set. In correspondence, when we work at the level of the abstract documents (legal texts) in the resolution, we use these indices for the  X  X osition X  of the elements. However, this could never be used when considering digital documents, that is, XML documents, because they are not valid positions in XPath.

With programming languages, the use of these  X  X ndex sets X  is well controlled: the programmer defines such a special data type and the compiler internally records the equivalence of each element in the new set with a natural number, so that in the end it uses the set of natural numbers to locate elements in any set indexed with such an index set (see Fig. 10 ). However, this is not the case with XPath, as it is not a programming language.
It permits elements to be located within a set (normally one of the axes child , descendant , ancestor , etc.) by its position, but it always uses the set of natural numbers as the index set.

In our application we compute the equivalence between the index set used to number the elements of the document referred to and the set of natural numbers. We use this equivalence when we translate the paths that locate fragments of legal texts to paths that locate fragments of XML documents ( X  X evel-2 X  resolution). Example 5. Direct, ambiguous reference.

We humans are imprecise and ambiguous when talking more frequently than we realize. References are in-cluded within the targets of this ambiguity and impreciseness. Even if, in many cases for us, this imprecision is not really problematic (in some cases it is), because we are able to use context information and knowledge to determine which items are being referred to in an ambiguous manner, such abilities are not easily transferable to automatic algorithms, which means that ambiguous references are difficult to solve automatically. The reference  X  articles 168 and following ones of the Law on Civil Judgments  X ( art X   X  culo 168 y siguientes de la
Ley de Enjuiciamiento Civil ) is an example of such a reference. For a human, depending on the context in which this reference appears, it may be possible to solve this reference to articles 168 and all those that follow it and treat the same subject-matter, or whatever other interpretation may be possible. However, for an automatic resolution, this reference is problematic. It is clear what the axis is ( article elements of the text Ley de Enjuiciamiento Civil ), and which is the first article of the sequence (168). Even if it is possible to recognize that here there is another interval, one of its limits is undefined and there is no information to determine it. Only heuristics can be used, in the hope that the election made is correct.

A heuristic we tried was to select all the  X  X ollowing X  articles that are part of the same division (share the parent). For our example reference, we solve for an interval starting in article 168, comprising all articles within the chapter containing article 168. However, its results are not really satisfactory: sometimes the range covers more articles than it should and other times it covers fewer than it should. In fact, this is logical. Legal text writers tend to manage structure in the most natural way in their references. That is, if it is possible to and the following ones  X , the first manner is preferred, which means that the probability of success for this heuristic is not as high as could be expected.

As a consequence of these considerations, in our implementation, we finally decided to avoid the range and just solve the element that can be solved precisely. That is, for the example reference, we solve article 168 and we let the user decide what the following articles should be. The path we obtain appears in the fourth row of Table 1 . Example 6. Relative reference.

Relative references are references that refer to some known item, which may be the document (or a fragment of it) in which the reference is.

The resolution of these references benefits from the fact that the documents parsed are XML documents: there is the possibility of tracing the position (XML element) in which a reference is found. The same information that the document analyzer uses to build a path for the XML element where each fragment was found, can be used to solve these references.

An example of relative reference is the one we show:  X  previous paragraphs of this article  X ( apartados ante-riores de este art X   X  culo ). The article referred to is the same as the one that contains the reference. Its path is available through the XML tool that analyses the document. However, the reference does not refer to the whole article, just to some of its paragraphs : the ones that preceed the paragraph that contains the reference. The XPath expression that addresses them appears in the fifth row of Table 1 .

A necessary condition for dealing with the resolution of internal relative references as we explain here is that the input documents are XML. Another condition, not necessary, but convenient, is that their markup (structure) matches the structure of the legal text they contain. Otherwise, this process would not be so direct. We consider it important to clarify this issue. The documents we use as input in the prototype that tests the resolution algorithm are all XML, and adapted to a pivot schema. If necessary (that is, if they are not originally tagged according to it) we transform them to an equivalent XML document, valid with respect to this schema. In this manner, we avoid calculating equivalences in trees to locate the origins of references, which allows us to concentrate the efforts on the resolution algorithm for the targets of references.

In addition, it simplifies the resolution of internal relative references. Moreover, we are ready to offer the domain users solutions that fit their interests (solutions in which they can access the content of the reference target) with reasonable implementation efforts. 6.2. Level-2 resolution: paths in XML document trees
Level-2 resolution provides extensibility, permitting heterogeneous schemas in XML collections. This step is necessary to complete an automatic resolution that permits the end user to be provided with the content of references X  targets automatically. At this step, the solver (see Fig. 7 ) uses the structure mapping information to achieve the resolution to XML documents.

Fig. 11 shows two fragments taken from two different XML documents. them shows that the content is the same, that is, they are two different renditions of the same legal text.
However, the markup is different. While the one in Fig. 11 is tagged according to the structure of the legal text it contains (descriptive markup), the one in Fig. 11 has a markup not related with that structure. The DTD the first one complies with is the pivot schema that reflects the general structure of legal texts (in
Fig. 2 ); the DTD of the second XML document is a proprietary DTD ( w3clex.dtd ). tive markup, as the first one, is preferred, the reality is heterogeneous. So, if we want the proposed frame-work to be extensible to more than one DTD (or XML schema), it is necessary to provide solutions to this heterogeneity.

The resolution of references to documents as the one in Fig. 11 is simpler: the paths obtained for the legal texts can be reused in their most part (the element names are reusable and the inclusions between them are also the same as those we will find in the XML document). However, in cases of documents such as the one in
Fig. 11 , paths in abstract documents have to be mapped to paths in the XML documents. This is, in fact, a schema mapping problem.

There are two possible solutions to deal with this schema mapping problem. One is to develop a method to calculate the equivalence between the paths in the legal text and the paths in the XML document and use it when completing the level-2 resolution. The difficulty of this work depends on the degree of dissimilarity between the general schema of legal texts and the schema (DTD or XML schema) of XML documents.

The second solution is to transform the collection of XML documents to the pivot schema. This is the solution we took for the prototype in which we evaluate the resolution algorithm. We implemented a (specific infor-mation extraction) tool that transformed XML documents coming from the legal text publisher to equivalent documents (same content, different markup) valid with respect to the DTD presented in Fig. 2 . To do so, we use XSLT stylesheets, which implement schema transformations. However, as this is not always possible, for example if we are not allowed to modify the collection of XML documents  X  this would be the case if working for external providers, the first solution is there for such cases. 7. Experiments
We tested the solutions provided in this paper for two collections of legal texts. The first collection,  X  Col-lection 1  X , is a set of 50 Spanish normative texts, from which we selected a subset of six documents. The doc-ument whose fragment appears in Fig. 11 is part of this collection. On this last set of documents, we applied a careful, manual revision of each document, which produces the set of references present in each document.
Thus, we have two types of data in this set, that we use for the validation: the reference data set, which is the normal output of the extraction process, and the set of references found manually, which has been gener-ated for validation purposes. This set of data extracted manually has been revised twice, which ensures that it contains all the references present in these documents. It is the fact that the generation of these data is a man-ual process that limits the number of documents on which we show results for the experiments to a small amount (otherwise, the application functioned correctly on the whole collection of 50 documents on which it ran). There are 175 relevant references in this collection.
 The second collection,  X  Collection 2  X , is a set of 14 normative texts provided by a legal text publisher  X  Lex-
Nova S.A. , in which references are already tagged. The documents in this collection are originally tagged with a markup similar to the document in Fig. 11 ; they were transformed as indicated in Section 6.2 to input them to the reference extraction tool. These marks have been mined automatically from the texts to obtain the vali-dation set against which the results of our extractor are compared; the set of references marked by the legal text publisher are the relevant references present in these documents. The number of relevant references (ref-erences marked by the publisher) in this collection is 352.
For the validation, we proposed two evaluation measures, defined in a similar way to the evaluation mea-sures used in Information Retrieval: Recall in reference resolution and Precision in reference resolution . Recall measures the proportion of relevant references that are correctly solved out of all relevant references present in the documents. Precision measures the proportion of relevant references that are correctly solved out of all references detected by the extractor. In this paper we provide results for the one most commonly used in Infor-mation Extraction experiments: recall (also called  X  X fficiency X  or  X  X ffectivity X ). Its definition is provided in Eq. (1) . Table 2 shows the results for  X  Collection 1 X  . Table 3 shows the results on the collection of 14 documents provided by the legal text publisher. Each row shows the results for each document in the collection. The left-most column shows the name of the XML document analyzed by the reference extractor. The second column shows the recall on that document, while the third and fourth columns show the data used to calculate them, that is, the number of relevant references present in the document, and the number of relevant references that were correctly solved by the automatic tool. The results of Table 3 produce an average recall of 51%, while for  X  Collection 1  X  the average recall is a proportion of 45%.

The main cause of failure related with the resolution of references is in fact a problem related with the use of context information in references. For example, a reference such as  X  X  X rticle 2 X  X , whose anchor is extracted cor-rectly, has the problem that the document to which  X  X rticle 2 X  belongs is not explicit in the reference. It can be the same document in which the reference is (internal reference), or another document that has been cited pre-viously (external reference). Humans can solve this ambiguity, as they know the context in which the refer-ences appear. However, management of context information with automatic tools is a hard problem. We used a heuristic to solve them (to the current document), which, logically, fails in some cases. Another problem was found with references in which long natural language explanations are intermixed (e.g., a reference as  X  articles 1, which establishes the context in which this rule should be applied, 2, and 3  X ). They are split by the anchor detector (it only recognizes as a reference the chain  X  articles 1  X  whereas it is one reference to the three articles with number 1, 2, and 3).
 8. Conclusions
The work presented in this article uses XPath, one of the most important XML standards, in an automatic process of reference resolution in structured documents as the base language to express paths. Two abstraction levels are considered during reference resolution. A pivot schema reflects the structure rules common to the abstract documents on which the first-level resolution (resolution to abstract entities) operates. It provides extensibility, as it facilitates the management of the schema heterogeneity that different markups in XML ren-ditions cause.

The algorithm that solves references at the abstract document level has been presented in this paper. We choose XPath as the language to address internal fragments of structured documents. There are other lan-guages, mentioned in the Introduction and Bibliography of this paper, some of which are more powerful than
XPath ( Murata, 2001 ). However, there are several reasons that justify our choice. First, XPath is the W3C standard language to address fragments of XML documents. As such, it is implemented in most XML tools, which support it and return paths expressed with XPath expressions. For example, our reference extractor tool, which is built on top of an XML parser, automatically returns the paths of the elements in which the references are found. If we did not use XPath, we should translate these XPath expressions to another lan-guage in all cases. Of course, the benefit obtained by simplifying the implementation could not supersede the limitations we may find to express paths equivalent to those expressed in natural language in the refer-ences. But our experience shows that these paths are not so elaborate that we cannot express them in an XPath manner. Indeed, XPath is able to express more elaborate paths than the ones we have found in references.
It is hard to infer from existing publications if the set of relevant references used in the evaluation includes the same types (that is, sets) of references in all cases (or if the results include anchor detection and resolution, or they only refer to anchor detection). For example, selecting only well-formed references that contain all the necessary information to solve a reference would produce much better results than testing automatic extrac-tors against a set of references that also include irregular, badly-formed, or incomplete references. As already suggested in Ding et al. (1999) in their work on bibliographic references (in general, more regular and complete than legislative references) this last type of references is not so uncommon as it could seem, greater challenge for information extraction researchers.

In our experiments, we did not exclude any reference present in the documents (that is, all the references that were manually found in the documents were computed as  X  X elevant references X ). This explains percentages in recall (efficacy) under 50%: for example, we knew that the heuristic used in the resolution of partial refer-ences (see the Experiments in Section 7 ), would fail in many cases and decrease success in results. However, if we had excluded relative references from our experiments, we would not have had a relevant idea about the frequence of these references, and in consequence, of the importance that future research to solve this problem could have.

As for what concerns the resolution step  X  which is the step of reference extraction that receives the main attention in this paper, we are not aware of any published work dedicated to reference resolution in structured documents. This makes it impossible to compare the resolution algorithm presented in Fig. 8 with other re-solution algorithms.

The Semantic Web effort searches for semantically enhanced information. This requires marking up Web resources with embedded semantic metadata. However, this cannot be done until the metadata values are dis-covered ( Passin, 2004 ). Information extraction processes provide the possibility to automate this discovery.
Besides, if  X  X he structure of a document can imply certain meta data X  ( Passin, 2004 ), this is without a doubt the case with normative documents, whose structure reflects the semantic divisions in the document. The work presented in this paper falls in the set of efforts that automate the extraction of semantic metadata related with document structure, thus contributing to the Semantic Web effort.

This work with references is part of a wider project, which includes building user applications to manipulate legislative texts. These applications (under development at the moment of writing) will soon be used as a sup-port for practical works in Law studies, 17 and by the Association of Attorneys of Valladolid. The reference extraction provides the reference data used to annotate normative texts X  divisions and in the automatic con-struction of the hypertext structure derived from cross-references between normative documents. The revision (and evaluation) of results from automatic reference extraction is supported by a tool (in Fig. 12 ), that permits the extracted references to be corrected before feeding them to the end user applications.

Future work and research should include considering advanced techniques (Natural Language Processing, others) that permit work with context knowledge, so that the heuristic used with relative references could be substituted by a more accurate method. In addition, these techniques could also help to solve the problems that cause references with long natural language explanations in between. Finally, XPath has shown itself to be a very valuable tool for work with automatic reference resolution in structured documents. Acknowledgements
The implementation of reference extraction was carried out by Sandra Mun  X  oz M X   X  nguez, Nuria Serrano, and Yoana Mart X   X  n. The reference revision interface was implemented by Jesu  X  s Requejo. All of them are stu-dents at the University of Valladolid (Spain). Dr. Da  X  maso Javier Vicente Blanco, teacher at the University of
Valladolid, guided the analysis of the legal domain and coordinates the jurist team involved in the end-user applications development. The legal publisher LexNova S.A. provided the 14 documents that compose the Collection 2 of our experiments. This work has been partially supported by the research project
VA010B06 18 and the Spanish I+D+I program (project TIC2003-09268 Appendix A. Appendix
Table 4 lists the example references of the paper in their Spanish version, which are the ones we work with, and the English translation we used for the examples of this paper in order to increase the readability of the paper.
 References
