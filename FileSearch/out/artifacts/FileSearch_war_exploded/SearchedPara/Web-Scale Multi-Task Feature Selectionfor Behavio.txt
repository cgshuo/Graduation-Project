 A typical behavioral targeting system optimizing purchase activities, called conversions , faces two main challenges: the web-scale amounts of user histories to process on a daily ba-sis, and the relative sparsity of conversions. In this paper, we try to address these challenges through feature selec-tion. We formulate a multi-task (or group) feature-selection problem among a set of related tasks (sharing a common set of features), namely advertising campaigns. We apply a group-sparse penalty consisting of a combination of an ` and ` 2 penalty and an associated fast optimization algo-rithm for distributed parameter estimation. Our algorithm relies on a variant of the well known Fast Iterative Thresh-olding Algorithm (FISTA), a closed-form solution for mixed norm programming and a distributed subgradient oracle. To efficiently handle web-scale user histories, we present a dis-tributed inference algorithm for the problem that scales to billions of instances and millions of attributes. We show the superiority of our algorithm in terms of both sparsity and ROC performance over baseline feature selection methods (both single-task L 1-regularization and multi-task mutual-information gain).
 G.3 [ Probability And Statistics ]: Statistical Comput-ing; I.2.6 [ ARTIFICIAL INTELLIGENCE ]: Learning Sparsity, Feature Selection, Large-scale Learning, Behav-ioral Targeting
The first three authors had equal contribution toward this work. 2 Contributed to this work while affiliated with Ya-hoo! Research.

A typical behavioral targeting platform optimizing for con-versions, e.g. [10 , 3], faces two core issues:1) the large vol-umes of user histories to be processed in a periodic fashion and 2) sparseness of conversions. Processing activities of bil-lions of users on a daily basis imposes many challenges such as how to build user profiles in an efficient way, and how to optimize multiple campaigns at the same time. Conver-sion rarity is another issue further complicating the task of the platform as it requires parsimoniously mining the user historical online behavior. Though Yahoo! X  X  novel platform presented in [ 3] develops a variety of engineering and ma-chine learning techniques to cope with these two issues, it is never enough. While an increased number of features is often beneficial, using the maximum number of features possible may not amount to the best engineering decision, especially because of consequently increased computational costs. An additional pain point for our platform is to optimize cam-paigns with very low conversion volumes (tens or hundreds). For these campaigns, conversion rarity represents a major bottleneck against achieving tangible advertising improve-ments.

In this paper, we resort to feature selection as a powerful technique to cope with both problems. There is ample liter-ature covering this subject both from an algorithmic [5 ] and a statistical [ 6] aspect. Feature selection clearly copes with the large volumes of user histories to be processed. To cope with conversion sparseness problem we consider the union of all (possibly sparse) attribute sets of all advertisers to decide which ad to choose (e.g. by means of a generalized second price auction).

Our problem is a variant of the multi-task learning prob-lem with the key difference that we are not necessarily inter-ested in the best function space but rather in the minimal subset of attributes required for good joint performance. We refer to this problem as multi-task feature selection. The key tool we use in this context is that of convex optimization for sparsity. To summarize, our contributions are the following:
Our behavioral targeting problem can be formalized as follows. To capture the interaction between covariates x , campaigns c and associated labels y (e.g. whether a partic-ular user converted on an ad in a particular campaign at a particular occasion) we consider the issue of estimating y | x,c for a large range of campaigns simultaneously. We assume that the input space of the covariates is R is, each covariate x c i for instance i of campaign c lies in a d -dimensional feature space. We also let n denote the total number of campaigns.

Formally we consider sets of covariates and labels indexed by a campaign c , as denoted by of covariates and labels respectively. Typically we choose Y = { X  1 } , in particular when dealing with a simple classi-fication problem. The prediction problem can be expressed either as one of risk minimization (we want to come up with a classifier which makes a small number of mistakes) or as one of maximizing the data likelihood. In the latter case we want to find a parameter w = { w 1 ,w 2 ,...w c } such that p ( Y | X,w ) = Y is large. Here, we can also view w as a n  X  d matrix such that each w c is a d -dimensional row vector.

For the purpose of the present paper we pick a rather spe-cific form of p ( Y c | X c ,w c ), namely a log-linear model where Rather than minimizing the negative log-likelihood, we cast the problem of finding w as risk minimization. Here we minimize a penalized version of the aggregate risk Here the function l ( x,y,w ) is a loss function, which is typ-ically convex in w . Note that by choosing the logistic loss l ( x,y,w ) = log 1 + e  X  y  X  w,x  X  (which is what we use in our experiments), logistic likelihood maximization and risk min-imization can be treated in the same framework.

The specific choice of a regularizer is the subject of Sec-tion 3. For the moment we abstractly define it as  X [ w ]. This means that the problem of Maximum a Posteriori (MAP) es-timation for w can be cast as convex minimization:
Recall that we denote by R c [ w ] the empirical risk terms incurred by the individual campaigns c and by R [ w ] the aggregate risk as defined in (4 ). For the purpose of fast estimation we want to ensure that only a small number of attributes are used in any of the campaigns  X  after all, if we were to use a feature in even just one campaign we would need to compute it beforehand regardless. This is achieved by combining a penalty per entry w ij of the parameter ma-trix, with one per group of parameters for each feature (i.e, per column k [ w ] j k ). We thus obtain the problem of mini-mizing The last term of the above expression also corresponds to the l 1 , 2 mixed-norm (see e.g. [ 9]) of the parameter matrix w . It is easy to see that L [ w ] enhances sparsity of the solution. For instance, provided that at optimality any subgradient |  X  w ic R [ w ] |  X   X  1 it follows immediately that w ic = 0. Fur-thermore, if k  X  w i R [ w ] k  X   X  2 then likewise the entire coeffi-cient vector satisfies [ w ] i = 0.

To solve the associated optimization problem we employ the Fast Iterative Shrinkage Algorithm (FISTA) of [5]. At its heart lies a proximal operator  X  ( c |  X  ) (see e.g. [ 7]), which solves a simplified version of the penalized risk minimiza-tion problem studied above, and a subgradient computation which we distribute for the benefit of scalability. For the sake of completeness we state the problem solved by the proximal operator explicitly (it is easier to derive it from scratch rather than specializing [4 ]).
 Lemma 1 The mixed norm optimization problem  X  ( c |  X  ) can be found by x =  X  ( c |  X  ) in the following algorithm Here  X  ( x, X  ) = x max(0 , 1  X  X  x k  X  1 2  X  ) is a shrinkage map.
Proof. Taking subgradients of the various norms in the optimization problem we see that  X  x k x k 2 = k x k  X  1 2 and  X  x k x k 2 = B 1 otherwise (i.e. it is an element of the unit ball). Hence it follows that x can be written as a sum of subgradients x  X  c  X  That is, x satisfies the first order optimality conditions and we established the result.

An analogous shrinkage result holds whenever we mini-mize R [ w ] rather than 1 2 k x  X  c k 2 2 . Moreover, the steps out-lined above constitute the inner loop of the fast iterated shrinkage algorithm (FISTA) of [5].
We now adapt FISTA to the problem at hand. The basic strategy is described in Algorithm 1. That is, the algorithm first computes the subgradient g :=  X  w R [ w ]. Subsequently the gradient and the current (and past) parameter vector are used in the prox operator to obtain a new iterate of the parameter vector.
 Algorithm 1 Optimization Using the FISTA Algorithm. input: Lipschitz constant L for R [ w ].
 for i = 1 to N do end for
In order to invoke Algorithm 1 we need a number of com-ponents: firstly we need a Lipschitz bound L on R [ w ]. In our experiments, we use the logistic loss, for which it is known that the corresponding Lipschitz constant is 1. If the in-stances are bounded in terms of their norm by some r  X k x k we can easily obtain an (admittedly) conservative bound of L  X  rm . Whenever R is already normalized in terms of the sample size this reduces to L  X  r . [ 5, Lemma 4.3] show that FISTA converges at rate O ( Lk  X  2 ) where k is the number of iterations. Moreover, whenever this estimate of L is too conservative we may use an alternative step size adaptive variant of FISTA.

In terms of practical constraints  X  we need to be able to compute g efficiently in a distributed fashion and to dis-tribute parts of g to different machines in order to invoke the prox operator  X  . These are the computationally expen-sive parts of the algorithm. Fortunately  X  (( w i  X  g L ) | composes into individual attributes , each of which can be computed individually. Likewise, computing g can be eas-ily parallelized over different campaigns, each of which have their own parameter vector w c . We discuss both parts in further detail in section 4.
 Figure 1: Work flow during the distributed opti-mization algorithm. The weight matrix is broken into a set of PxP blocks and stored in a distributed hash table. The instances are partitioned among the machines. Each machine is assigned all instances that belong to C/P campaigns, where C is the num-ber of campaigns and P are the number of machines. Invoking Algorithm 1 involves the following main steps: Figure 2: Storage of the weight matrix. C is the num-1. Compute partial subgradients of R [ w ] for all campaigns 2. Aggregate subgradients obtained from all instances. 3. Distribute coordinates (or subsets S  X  S thereof) of 4. Invoke the prox operator and redistribute the results. Naively this problem suggests the use of a MapReduce com-putation on Hadoop. Unfortunately, the latter is not well suited to computations that repeatedly use the same data as Hadoop mainly communicates via files which is undesirable since disk I/O overhead becomes comparable to the time to compute the results. Hence we resort to a method discussed in [ 1, 11 ], namely to allocate the machines using Hadoop and then the establish an overlay communication network.
Let P be the number of machines, D be the number of attributes, and C be the number of campaigns. Thus the weight matrix to be learnt is of size C  X  D . We first dis-tribute the instances across machines, where each machine is assigned the instances (examples) of a set of C/P camp-ings.These allocations do not change as the algorithm pro-ceeds, thus minimizing data movement. As shown in Fig-ure 2, the weight matrix is divided into P  X  P blocks each of which spans C/P campaigns and D/P attributes.This weight matrix divided into blocks can be stored across the Hadoop file system and these blocks can be exchanged be-tween machines via file disk I/O operation. However, in-stead of writing these to disk and synchronizing processes via file I/O we synchronize them by storing the blocks in memcached . The latter, when used in storage rather than caching mode, allows us to spread the data evenly and to retain it in memory since it uses consistent hashing [8].
Computing subgradients of R [ w ] requires the following op-eration In other words, the subgradient trivially decomposes into  X  w c R c [ w c ]. Hence it is advantageous to aggregate data from individual campaigns on each machine. This way most coor-dinates of the subgradient will vanish on each machine and only the composite g be largely nonzero. Consequently we only need to transmit smaller g c between the machines hold-ing individual blocks. More specifically, each machine, say i , computes the gradient of the C/P campaigns assigned to it. To do that, the machine first retrieves the current weight vector from the distributed hash table. This amounts to reading blocks A i, 1: P from the distributed hash table. As ev-idence, this step can be performed in parallel across all ma-chines. Once the machine obtains the current weight vector pertaining to its allocated campaigns, it does a single pass over the examples stored locally to compute the gradient and update the weight vector corresponding to its assigned campaigns. The next step now for machine i is to write back the new weight vector to the distributed hash table. To do so, it first breaks its assigned weight into P blocks and write them back to the hash table. Since each machine i reads blocks A i, 1: P and writes back blocks A i, 1: P , it is clear that these two steps can be executed in parallel across all the ma-chines. After this step, the machine reach a barrier before proceeding to the next step. Similar to [2], we implemented a reverse-sense barrier algorithm that scales logarithmically with the number of machines.
The final step required in addressing the distributed op-timization problem of minimizing L [ w ] is to solve the prox operator  X  . It decomposes along the set of attributes. Hence we simply need to solve each of the arising problems accord-ing to the algorithm described in Lemma 1 separately. Note that the latter can be done in linear time  X  we only require computing norms of vectors and rescaling them.

The data exchange is completely analogous to the gra-dient computation, except that we now work on attributes rather than campaigns. Each machine, say machine i , reads blocks A 1: P,i and solves the prox operator for a set of D/P attributes. Once performed, it then breaks each of these at-tributes vectors (each of which is of dimension C ) back into a set of P blocks and writes them back to the distributed hash table. Similar to the gradient computation phase, this read and write steps can be performed in parallel, and fol-lowed by a barrier to ensure consistency of the weight matrix before moving to the next iteration.
As a consequence the (key,value) pairs are distributed uni-formly over the p machines involved. Hence the data ex-change between any pair of machines is O (1 /p 2 )  X  a fixed amount of data is distributed between p machines. Each O (1 /p ) sized block is distributed over p machines. As long as all machines are located on the same switch this exhibits perfect scalability, i.e. it takes O (1 /p ) time to process and synchronize. Finally, we obtain the following theorem: Theorem 2 In order to process m instances with D dimen-sions from C campaigns on P processors we need O mD +  X CD time. Here  X  is the ratio between network transfer and data processing speed.

Proof. To process the gradients associated with mD data on P machines costs O ( mD/P ) time. Exchanging chunks costs O (  X CD/P ) time. Evaluating the prox operator costs O ( CD/P ) time. Since we may safely assume that the net-work is the limiting factor relative to processing the latter does not matter. We ignore log factors associated with net-work congestion and collision.
 Algorithm 2 Distributed Optimization 1: for all i = 1  X  X  X  P do parallel do 3: for all c = ( i  X  1)  X  C P + 1  X  X  X  i  X  C P do 4: compute subgradient g c :=  X  w c R [ w ]. 5: end for 6: Write back to the hash table blocks A i, 1: P . 7: end for 8: Reach a barrier. 9: for all i = 1  X  X  X  P do parallel do 10: Read blocks A 1: P,i 11: for all d = ( i  X  1)  X  D P + 1  X  X  X  i  X  D P do 12: solve the prox operator 13: end for 14: Write back to the hash table blocks A 1: P,i . 15: end for 16: Reach a barrier.

To model the performance of our algorithm, we build tar-geting models for display advertising campaigns based on the targeting system for conversion-optimization presented in [3 ]. Table 1 presents some statistics about our data set.
We study the performance of our techniques compared to the baseline system developed in [3 ]. We mainly com-pare modeling performance in terms of the area under the ROC curve (AUC). Unless otherwise specified, all metrics are measured as conversion-weighted average of AUC across all campaigns in the benchmark set.

To assess the performance of our proposed sparse multi-task feature selection technique (denoted as MTFS), we start by applying standard feature selection baseline techniques to our data set. The first baseline that we use to compare our performance is a per-campaign L1-regularized learning model. In addition, we also use as a second baseline, a cross-campaign greedy information gain heuristic. More specifi-cally, the set of baseline feature selection techniques that we compare against, are: Figure 3: Features histogram across campaigns. The X-axis represents the rank index of features under each method and the Y-axis gives the number of cmapigns having this feature in their model when trained using this method.
All Parameters for all models were tuned over a validation set. For our model we report two runs with conservative (  X  1 = 0 . 4 , X  2 = 10)and aggressive (  X  1 = 0 . 4 , X  2 = 25 )fea-ture selections to give more insight about its mechanics. All results are reported in terms of the weighted average ROC measure * 100 across all campaigns.

As can be seen from Table 3, our MTFS group feature selection models for both conservative and aggressive spar-sity levels, outperform the ROCs for not only the Cross-Campaign Information Gain Models, but also the Per-Campaign Information L1 Feature Selection Model.

In Figure 3, we show the histogram of feature counts in the trained model of different techniques. As evident, MTFS significantly reduces the total number of features which re-sults in compact models that can be loaded in memory as well as trained more frequently and thus reduces the latency to predict user conversions It is quite striking that perform-ing feature selection over each campaign independently re-sults in 500K global features yet performs poorly compared to the merely 17K global features discovered by our joint training algorithm. This is largely due to the heavy tail dis-tribution that occurs when features are not selected jointly (see Figure 3). Moreover, [3 ] showed that merely cutting features based on their frequency in the trained models, did NOT improve the accuracy of those models.

Table 2 shows the performance comparison of the differ-ent techniques for campaigns with less than 100 and 500 conversions, respectively. The numbers clearly show the su-periority of our algorithm in leveraging cross-campaign in-formation to improve the performance of campaigns with very few conversions, as opposed to the baseline techniques.
Finally, concerning the running time, the algorithm con-verges after only a few iterations ( &lt; 10) and the time con-sumed by the I/O was negligible to the time consumed by the gradient computation step. Finally, it should be noted that the gradient computation step just requires a single pass over the data, which is comparable to the amount of time required to train each model separately.
In this paper we addressed the problem of multi-task fea-ture selection for behavioral targeting across different adver-tising campaigns. We formulated the problem as a mixed-norm optimization problem and devised a novel and efficient distributed inference algorithm that scales to billions of in-stances and millions of attributes. We empirically showed that our algorithm not only reduces the number of over-all features needed for classifications but also improves per-formance, especially for campaigns with sparse conversions, Table 2: Modeling performance (ROC) comparison for campaigns with few conversions.
 Method ROC Size Global-MI: top 10K + L2 56.6 10,000 Global-MI: top 30K + L2 56.9 30,000 Global-MI: top 50K + L2 56.7 50,000 Per-Campaign L1 54.5 588,975 MTFS (conservative:  X  1 = 0 . 4 , X  2 = 10) 61.1 17,789 MTFS (aggressive:  X  1 = 0 . 4 , X  2 = 25) 59.3 3,992 Table 3: Modeling performance and resulting fea-ture set sizes for the different feature selection tech-niques. over models that perform individual task-level optimization. In future work, we intend to model the effect of hierarchical sparsity constraints for groups of features. [1] Amr Ahmed, Mohamed Aly, Joseph Gonzalez, Shravan [2] Amr Ahmed, Yucheng Low, Mohamed Aly, Vanja [3] M. Aly, A. Hatch, V. Josifovski, and V. K. Narayanan. [4] F. Bach, R. Jenatton, J. Mairal, and G. Obozinski. [5] Amir Beck and Marc Teboulle. A fast iterative [6] Emmanuel Candes and Terence Tao. Decoding by [7] S. Ji and J. Yi. An accelerated gradient method for [8] D. Karger, E. Lehman, T. Leighton, M. Levine, [9] Guillaume Obozinski, Martin Wainwright, and [10] S. Pandey, M. Aly, A. Bagherjeiran, A. Hatch, [11] A.J. Smola and S. Narayanamurthy. An architecture
