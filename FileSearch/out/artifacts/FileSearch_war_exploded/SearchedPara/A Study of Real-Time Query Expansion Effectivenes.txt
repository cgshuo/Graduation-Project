 In this poster, we describe the study of an interfa ce technique that provides a list of suggested additional query terms as a searcher types a search query, in effect offering interactiv e query expansion (IQE) options while the query is formulated. Analy sis of the results shows that offering IQE during query formul ation leads to better quality initial queries, and an increased up take of query expansion. These findings have implications for ho w IQE should be offered in retrieval interfaces. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  query formulation, relevance feedback Experimentation, Human Factors Real-time query expansion, query quality Improving the quality of queries has been of great interest in Information Retrieval (IR) research. Techniques li ke Relevance Feedback (RF) [6] have been proposed as a way in wh ich IR systems can support the iterative development of a search query using examples of relevant information. Interactiv e query expansion (IQE) uses RF to suggest additional terms for query modification [3]. However, studies of IQE effectiv eness have shown that it can be worthwhile but searchers may m ake poor term selections [5], or rarely use it in operationa l settings [1]. This could be related to how IQE is presented, and it is therefore important to investigate alternative ways of offeri ng IQE. Real-Time Query Expansion (RTQE) describes an inter face mechanism whereby candidate expansion terms are pre sented to the searcher as they enter their search query. Thi s approach integrates IQE directly into query formulation, giv ing help at a stage in the search when it can positively affect q uery quality, and possibly supporting the development of improved exp ansion strategies by searchers. Although similar techniqu es have already been implemented (e.g., Google Suggest), there exis ts to our knowledge no study of how effective such techniques are for real searchers. In this poster we describe a study of R TQE effectiveness based on the quality of queries it he lps generate. A laboratory-based within-subject user study was co nducted. Three experimental systems were developed: a search system with no query expansion ( Baseline ), and two systems that used Pseudo-Relevance Feedback (PRF) [4]. RealTime implements a variant of RTQE that uses the titles and abstracts of top-r anked results as sources for PRF, and presents query expansion optio ns as a searcher enters their query. Retrospective also uses the top ten titles and abstracts as PRF sources, but offers que ry expansion options after a retrieval operation has been perfor med. The difference between RealTime and Retrospective was when the expansion support was offered. On each of these tw o systems the top ten terms are displayed in a  X  X ecommended words  X  list situated between the query entry box and the search button. To append a term from the list of recommendations to t he current query, the searcher can double-click the term in th e list with the mouse pointer. Figure 1 illustrates the component in action. In RealTime the terms are presented as a list very shortly (le ss than two seconds depending on network latency) afte r the searcher finishes typing the first term of their qu ery, and updates after each term is typed. Searchers may either sel ect a term or ignore the suggestions, and complete their query. A total of 36 subjects were recruited between the c ampuses of the University of Maryland at College Park, and the Uni versity of North Carolina at Chapel Hill (18 subjects per camp us). Subjects were both undergraduate and graduate students from a range of nine different majors. Subjects were run independe ntly. For the study we developed six known-item retrieval type ta sks and six open-ended, exploratory type tasks. The explorator y tasks were phrased in the form of simulated work task situatio ns [2], i.e., short search scenarios that were designed to reflec t real-life search situations and allow subjects to develop personal a ssessments of relevance. Each experiment ran for up to two hours. Subjects attempted 12 tasks (two known-item and two explorat ory tasks on each system), and completed background, post-system , and exit questionnaires containing semantic differentials, L ikert scales, and open-ended questions. Their interaction with the s ystems was also logged for later analysis. We use the data derived from the study to assess th e quality of the queries generated for known-item and exploratory se arches. Query quality is a complex construct that is depend ent on many factors such as the searcher X  X  knowledge about the need, search experience, system experience, and the mapping betw een the need and the information source. As an estimate of quer y quality we employed a panel of two judges who independently as sessed the quality of every query expressed for all subjects u sing a 5-point scale. The judges met with one of the experimenter s and discussed ways to assign values. The basic agreeme nt was to examine the task, conduct a search, and then identi fy the key concepts in the task to use as basis for judging th e subject queries. The judges then coded queries for one task together to establish a common rating scheme. They then independently asse ssed the queries for each of the tasks. To minimize differe nces in quality estimates by the judges, the mean of the two judgme nts was taken as the overall query quality for each query. The m ean average query quality ratings for the initial query alone ( since it allowed us to isolate the RTQE) and all queries, are shown in Table 1. Measure Initial Known-item 2.14 1.88 1.86 1.86 2.07 1.82 Exploratory 2.01 1.75 1.70 1.72 1.99 1.65 Overall 2.07 1.81 1.78 1.77 2.03 1.73 We applied two-way ANOVA for the  X  X nitial Query X  an d for  X  X ll Queries X  separately. Statistical analysis is condu cted at p &lt; .05. Initial Query: There was a significant effect of system on initial query quality F (2,142) = 12.37, p &lt; .001. Post hoc comparisons using a Tukey Test reveal that RealTime led to significantly higher initial query quality than other systems for each of the task types. There were no statistically significant diff erences in initial query quality between the two task types F (1,71) = 3.26, ns . All Queries: Across all queries submitted to the three systems there were no statistically significant differences in query quality F (2,142) = .95, ns . However, there were statistically significant differences between the task types F (1,71) = 4.98, p = .029, with lower means on the known-item tasks. Across all qu eries, known-item searches, which have a more defined task descr iption, appear to result in higher query quality. One explanation is that the space of high quality queries for these tasks is more con strained, making it perhaps easier to generate good queries. We also analyzed the composition of queries in two further ways: query iterations, and unique query terms used per q uery and per search task. The analysis of iterations suggests t hat there were significantly more iterations for exploratory tasks F (1,71) = 12.53, p &lt; .001, but no difference between search systems F (2,142) = 1.06, ns . There was no significant effect of tasks F (1,1152) = .09, ns or systems F (2,1152) = 1.18, ns on the number of unique terms per query . However, per task , there are fewer unique terms for known-item tasks F (1,71) = 18.65, p &lt; .001, perhaps because the tasks were well-defined and fewer result sets were viewed. An analysis of query quality showed that RTQE impro ved the quality of initial queries for both known-item and exploratory tasks, making it potentially useful during the init iation of a search, when searchers may be in most need of support. If RTQE is capable of enhancing the quality of some queries, a nd does not having a detrimental effect on other aspects of sea rch performance, then there is a case for it to be impl emented as a feature of all search systems. A promising charact eristic of RTQE is that it does not force searchers to use it, or i ndeed do anything radically beyond the scope of their normal search a ctivities. Additional analysis of the findings, presented in [ 7], shows that compared to post-retrieval query expansion, RTQE lo wers task completion times, increases searcher engagement, an d increases the uptake of IQE ( RealTime : 44% of queries used expansion, Retrospective : 28% of queries used expansion). The nature of the query expansion support offered d id not appear to affect the number of query terms, or the number of query iterations. In fact, it was Retrospective that led on average to the highest query quality across all queries. This may be because the system provided two types of support: searchers wer e shown the ten query expansion terms, and they were shown the titles, abstracts, and URLs of the documents from which tho se terms were derived. The presence of this information may provide an additional source from which to choose terms, but p erhaps more importantly, give practiced, motivated searchers a sense of the type of documents that their query retrieved, and a sense for the context within which query modification terms occur in the collection. To this end, in future work we will im plement an alternate interface mechanism embedding query expan sion terms in the context they appear in their source document s. The future of IQE may well reside in techniques that couple ex pansion more closely with searchers X  normal information-seeking behaviors. [1] Anick, P. Using terminological feedback for web sea rch [2] Borlund, P. Experimental components for the evaluat ion of [3] Efthimiadis, E.N. Query expansion. Annual Review of [4] Jinxi, X. and Croft, W.B. Query expansion using loc al and [5] Ruthven, I. Re-examining the potential effectivenes s of [6] Salton, G. and Buckley, C. Improving retrieval perf ormance [7] White, R.W. and Marchionini, G. Examining the 
