 Recommender systems have been widely used in e-commerce websites to suggest items that meet users X  preferences. Col-laborative filtering, which is the most popular recommen-dation algorithm, is vulnerable to shilling attacks, where a group of spam users collaborate to manipulate the recom-mendations. Several attack detection algorithms have been developed to detect spam users and remove them from the system. However, the existing algorithms focus mostly on rating patterns of users. In this paper, we develop a proba-bilistic inference framework that further exploits the target items for attack detection. In addition, the user features can also be conveniently incorporated in this framework. We utilize the Belief Propagation (BP) algorithm to per-form inference efficiently. Experimental results verify that the proposed algorithm significantly improves detection per-formance as the number of target items increases.
 H.3.3 [ Information Search and Retrieval ]: Information filtering, Retrieval models.
 Collaborative Filtering, Shilling Attack, Belief Propagation
Recommender systems are increasingly employed by e-commerce websites, e.g., Amazon.com and Netflix.com, to provide personalized recommendations to users. Collabora-tive Filtering (CF) is so far the most popular recommen-dation algorithm, which relies on historic ratings given by users on items to make recommendations. Unfortunately, it is vulnerable to the so called  X  X hilling X  attacks [6], in which a group of spam users collaborate to influence the recommen-dations for their benefits, e.g., to recommend their products more often.

To protect the recommender systems against such attacks, one of the major approaches is to detect the spam users and remove them from the system. A number of detection algo-rithms have been proposed in the literature. Earlier work in [3] introduced several metrics for detecting the rating pat-terns of spam users. Then in [2], the authors improved the detection accuracy over [3] by including more model-specific features for classification. However, those feature-based al-gorithms suffer from low accuracy, as they only look at indi-vidual user rating patterns. In [7], the authors exploited the statistical properties of spam users, e.g., covariance, to per-form detection via variable selection using Principle Com-ponent Analysis (PCA-VarSel). PCA-VarSel is very effec-tive when spam users have low covariance, e.g., when they rate items randomly selected from all items, because gen-uine users have high covariance since they mostly rate only the popular items. However, it was shown in [4] that PCA-VarSel easily fails if spam users also selectively rate only those popular items.

All the existing works focused extensively on rating pat-terns of spam users, but they did not take into account the effect on the target items. In this work, we develop a prob-abilistic inference framework that further exploits the tar-get items for attack detection. In particular, we propose a factorized probabilistic model, and apply the efficient Belief Propagation (BP) algorithm [5] for inference. Previously, [8] applied BP to build a privacy-preserving CF system.
The shilling attack includes two general classes: push at-tacks and nuke attacks. In push attacks, the spam users col-laboratively promote the target items by rating them high, whereas in nuke attacks, the spam users demote the target items by rating them low. In addition, to effectively affect the recommendations made to the genuine users, each spam user also rates a set of filler items to increase similarity with those genuine users. Some well-known shilling attack models include Random attacks and Average attacks [6]. In Ran-dom attacks, the set of filler items are rated randomly on a distribution learnt from the ratings in the dataset, whereas in Average attacks, each filler item is rated around the av-erage rating of this individual item, making the spam users more similar to the genuine users. Hence, the Average at-tack is more effective than the Random attack. Moreover, in both attack models, the set of target items are given the highest allowed rating for push attacks and the lowest rating for nuke attacks.
W e assume there are a set of M users denoted by U = in the system. Let r ui denote user u  X  X  rating on item i , and R denote the set of all observed ratings in the system. The set of users who have rated item i is denoted by U i , and the set of items rated by user u is denoted by I u . For each user u , we assign a binary variable m u , where m u = 1 if user u is a spam user and m u = 0 otherwise. Similarly, for each item i , we assign a binary variable t i , where t i = 1 if item i is a tar-get and t i = 0 otherwise. Let M = { m u : 1  X  u  X  M } and T = { t i : 1  X  i  X  N } . We denote by P ( M , T |R ) the joint posterior probability distribution of M and T given the ob-served ratings in R . To identify spam users, we need to find the marginal distributions of P ( m u |R ),  X  u  X  U . P ( m can be directly computed from P ( M , T |R ) by summing over all variables in M and T except m u as follows However, the computational complexity is O 2 M + N , which is exponential in the total number of users and items. In the following, we propose a proper factorization of P ( M , T |R ), and employ the efficient Belief Propagation (BP) algorithm that operates in a factor graph to infer P ( m u |R ),  X  u  X  U .
We begin by describing the local functions that P ( M , T |R ) factorizes into. Since spam users collaboratively work to-gether to influence the ratings on target items, the local dependency among spam users is induced by their ratings on target items. Let M i = { m u : u  X  U i , r ui = r a } , where r denotes the maximum rating in cases of push attacks and the minimum rating in cases of nuke attacks. The reader may focus on push attacks, as the method and results hold for the nuke attacks as well. Hence, we introduce the lo-cal function f i ( M i , t i |R ) to model the local probabilistic dependency among variables in {M i , t i } . Given a config-uration of M i , we can compute the rating bias caused by spam users as  X  r i ( M i ) = where the first term in the absolute operator is the average rating on item i , including all ratings, and the second term is the unbiased average rating after removing ratings from spam users. Based on (2), we express f i ( M i , t i |R ) as f i ( M i , t i |R ) = where  X  t &lt; 0 and  X  r &gt; 0, and both are adjustable scalars. Given a configuration of M i , if the rating bias  X  r i ( M exceeds  X  r , this function assigns a larger value for t i than for t i = 0, and vice versa.

We also introduce a local factor function for each variable in M and T , so as to incorporate the local information ex-tracted from each individual user and item. Let g u ( m u be the local function for m u  X  M . g u ( m u |R ) can be de-signed to take into account the rating patterns of individual users, such as those user features introduced in [2]. Here, for the purpose of illustration, we consider the use of a single feature  X  u of user u . A simple probabilistic discriminative classifier [1] based solely on feature  X  u can be given in the
Figure 1: The factor graph for attack detection. f ollowing form where  X  1 and  X  1 are design parameters.

Likewise, we define a local factor function h i ( t i |R ) for each t  X  T . We notice that the ratings of target items are more likely to have large variances than those of normal items, due to the eccentric ratings from spam users. Let  X  i denote the variance in ratings of item i . Similar to g u ( m u |R ), we define h i ( t i |R ) as follows where  X  2 and  X  2 are design parameters.

Based on the local functions, we can express the factor-ization of P ( M , T |R ) as where Z is a normalization factor.
A factor graph is a bipartite graph that expresses the fac-torization structure of a function, where variable nodes and factor nodes represent variables and local functions, respec-tively, and an edge connects a variable node to a factor node if and only if the variable is an argument of the local func-tion associated with the factor node [5]. We illustrate the factor graph that expresses the factorization of P ( M , T |R ) by (6) in Fig. 1. Specifically, user variable m u is represented by node m u , and item variable t i is represented by node t in Fig. 1. Each factor function in (6) is represented by a fac-tor node. We connect each factor node g i to item variable node t i , and connect each factor node h u to user variable node m u . Also, we connect each factor node f i to the user variable nodes in M i and the item variable node t i .
To infer the marginal distributions P ( m u |R ),  X  u  X  U , we apply BP in the factor graph to exploit the factorization for efficient inference. Since the constructed factor graph has loops, we cannot apply the standard BP algorithm for exact inference. We thus resort to  X  X oopy X  BP, which performs iterative message passing between variable nodes and factor nodes along the edges in the factor graph [5].
While the BP algorithm can be much more efficient than direct computation using (1), the computational complexity for generating messages at the factor node is exponential in t he degree of the factor node. This computational burden can be quite significant at factor node f i , where the com-plexity in terms of multiplications is O |M i | 2 |M i | for gen-erating a message. Since in recommender systems an item can be rated by over hundreds of users, it renders the BP algorithm almost practically infeasible. Hence, we propose a complexity reduction technique by reducing the degree of factor node f i as follows.
 We randomly divide the user variable nodes in M i into G i =  X  X M i | /D  X  groups, where D is a small integer. Let M i denote the set of user variable nodes in group k , and M ik be the size of group k , where M ik = D for 1  X  k &lt; G and M ik = |M i | mod D for k = G i . Assuming independence among groups, we can approximate (6) using where we derive f ( k ) i M ( k ) i , t i |R from (3) by replacing  X  r i ( M i ) with  X  r where  X  U i = { u : u  X  U i , r ui 6 = r a } ,  X  R i = P u  X  w ik = M ik / |M i | . Note that we allocate  X  R i , the sum of rat-ings from  X  U i , to each group in proportion to the group size. Similarly as in Sec. 2.3, we construct a new factor graph for (7) and apply the BP algorithm. The computational com-plexity at factor node f ( k ) i is O D 2 D . The overall com-plexity of the BP algorithm with complexity reduction is O D 2 D |R a | , where R a is the subset of the observed rat-ings with value r a .
We evaluate the performance of the proposed BP-based attack detection algorithm using the 100K MovieLens dataset The dataset contains 100 , 000 ratings, all integers from 1 to 5, on 1682 items (movies) by 943 users. We treat the origi-nal users in the dataset as genuine users. To launch shilling attacks, a number of spam users are injected into the sys-tem. The ratio of spam users to genuine users is set as 1 E ach spam user randomly selects a set of filler items from the top 50% most popular items according to the number of ratings each item receives, similar to [4]. We refer to the ratio of filler items to all items as filler size . We consider the Average attack model described in Sec. 2.1, since it is more effective than the Random attack. The rating on each filler item follows a normal distribution with standard deviation  X  , and its mean is set as the average rating received by the filler item. Finally, a set of items are selected as targets in the attack. For the push attack, each target item has an av-erage rating between 1 and 3, whereas for the nuke attack,
A vailable at: http://www.grouplens.org/node/73. each target item has an average rating between 3 and 5. We assume all spam users have the same set of targets.
We evaluate the performance of the attack detection al-gorithms in terms of P recision = |D  X  S| / |D| and Recall = |D X  X | / |S| , where D and S denote the sets of detected spam users and true spam users, respectively. We compare the performance of various detection algorithms, including the proposed BP algorithm, the PCA-VarSel algorithm in [7], and the feature-based algorithm using (4).

To assess the detection performance, the PCA-VarSel al-gorithm described in [7] sorts the users in ascending order of their contribution to the principle components (PCs) ob-tained from PCA analysis, and selects the top-M d listed users as spam users. For easy comparison and fairness, in the proposed BP algorithm, we likewise sort users in de-scending order of P ( m u = 1 |R ), and also select the top-M users as spam users. Similarly, in the feature-based algo-rithm, we select the top-M d users ranked in descending or-der of g u ( m u = 1 |R ). In our experiments, we set M d number of true spam users injected into the system, so the Precision and Recall are equal.

In the proposed BP algorithm, we adopt the MeanVar feature introduced in [2] for  X  u in (4). The MeanVar  X  u user u is computed as w here  X  r i is the average rating of item i , and  X  I u r , i  X  I u } . The MeanVar feature is particularly effective for detecting spam users in Average attacks.
In Fig. 2, we present the results for detecting spam users in Push attacks, where we have set the parameters of the proposed BP algorithm as  X  t =  X  3 and  X  r = 0 . 35 in (3),  X  1 =  X  1 and  X  1 = 0 . 5 in (4),  X  2 = 1 and  X  2 = 1 . 5 in (5), and the group size D = 8 for complexity reduction de-scribed in Sec. 2.4. The results show that the performance of the proposed BP algorithm improves significantly as the number of targets increases, reaching almost 100% precision when there are enough number of targets, whereas the other algorithms do not exhibit such improvement. This verifies that the proposed algorithm can effectively exploit the tar-get items to detect spam users with high accuracy. Since the BP algorithm also incorporates the output g u ( m u |R ) of the feature-based algorithm as illustrated in Fig. 1, we would like to examine the case when the performance of the feature-based algorithm is very poor. In Fig. 2c, the detection preci-sion of the feature-based algorithm is only around 20% after we set  X  = 0 . 7. Interestingly, we observe a threshold phe-nomenon for the BP algorithm, that is the BP algorithm has 0% precision when the number of targets is small, but when the number of targets exceeds a certain number, the BP al-gorithm provides almost 100% precision. This is because as the number of targets increases, the information gained from target items becomes dominant and corrects the results of the feature-based algorithm. Note that in practical imple-mentations, we can incorporate into the BP algorithm more advanced feature-based algorithms for better performance. We have also performed experiments for Nuke attacks, and similar results can be observed, so we only present one set of those results in Fig. 3.

In Fig. 4, we investigate the impact of the filler size on the performance of the BP algorithm. We show the detec-
Figure 3: Detection precision v ersus number of targets in Nuke attacks. Filler size = 10% and  X  = 0 . 7 . tion results for both spam users and target items in Fig. 4a and Fig. 4b, respectively. Here, to evaluate the detection performance for the target items, we infer P ( t i |R ) from (6) and select the top-N t items ranked in descending order of P ( t i = 1 |R ), where N t is set as the number of true targets. Note that the existing algorithms only detect spam users. As the filler size increases, the BP algorithm suffers from per-formance loss for small numbers of targets. This is because the BP algorithm relies on information from target items, but the noise information from the filler items corrupts the useful information. Indeed, we can see in Fig. 4b that the detection precision for target items drops with increasing filler size. However, when there are enough target items to suppress the noise information, the BP algorithm still can achieve high detection precision. It is worth noting that in practice a higher cost is incurred for attackers to increase the filler size while decreasing the target number. Also, the BP algorithm can be enhanced with feature-based algorithms that deliver high detection accuracy for large filler sizes.
To protect the collaborative filtering systems against the shilling attacks, we proposed a BP-based algorithm for de-tecting spam users in a probabilistic inference framework. Different from the existing algorithms that rely solely on users X  rating patterns, the proposed algorithm further ex-ploits the target items. Considering the computational com-plexity for inference, we developed a factorized probabilistic model for attack detection and applied BP to perform in-ference efficiently. The proposed detection algorithm can also conveniently incorporate the existing algorithms for en-hanced performance. We showed through experiments that the proposed BP algorithm significantly improves detection accuracy as the number of target items increases. We also observed that its performance degrades with increasing filler sizes. In the future work, we will develop more robust algo-rithms to deal with more sophisticated attack scenarios. This material is based upon work supported by the National Science Foundation under Grant No. IIS-1115199. [1] C. M. Bishop. Pattern Recognition and Machine [2] R. Burke, B. Mobasher, C. Williams, and R. Bhaumik. [3] P.-A. Chirita, W. Nejdl, and C. Zamfir. Preventing [4] N. Hurley, Z. Cheng, and M. Zhang. Statistical attack [5] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger. [6] S. K. Lam and J. Riedl. Shilling recommender systems [7] B. Mehta, T. Hofmann, and P. Fankhauser. Lies and [8] J. Zou, A. Einolghozati, and F. Fekri.

