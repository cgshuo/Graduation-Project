
Constraint networks are among the most successful tech-nologies for the implementation of knowledge based sys-tems in numerous domains such as configuration and rec-ommender systems, planning, scheduling, etc. The major advantage of this technology is that it represents knowl-edge explicitly which can then be exploited for validation and explanation generation. However, the downside is the significant engineering effort required for knowledge base formulation and maintenance. In order to ease this problem, Bessi  X  ere et al [1] proposed C ONACQ a knowledge acqui-sition algorithm based on the version space paradigm [2]. C
ONACQ characterizes the version space (i.e. the set of all possible constraint networks for a given vocabulary) using a propositional theory following the approach suggested in [3], [4] and can learn constraint networks from training sets provided by an expert. However, in situations when only small or even no training sets are available, the learning can be done by using a membership query generation algorithm [5]. This algorithm uses the propositional theory maintained by C ONACQ to generate queries that, regardless of expert X  X  classification, reduce the size of the version space roughly by half with each learning step. While this is a major step towards efficient knowledge acquisition, the acquisition process can be further improved by exploiting additional knowledge. The domain expert can usually provide some pieces of knowledge for each training example (which we call arguments) that justify its classification.

In our solution we follow the approach presented in [1], but also introduce arguments for constraint acquisition. Note, arguments for learning classification rules were pioneered in [6]. We borrow the idea that additional knowledge about examples improves the learning process. However, since both the underlying learning method and the target lan-guage are different we follow another route for constraint acquisition. In particular, our novel contributions are as follows: First, we show the broad range of possible types of arguments a domain expert can formulate. Complete positive and negative examples in the sense of [1] are treated as special cases in this generalized view. Next, we show the consequences on the version space depending on the type of argument. Finally, we provide a constraint learning algorithm based on a generalized view of arguments that follows the ideas of C ONACQ . Similar to its predecessor, our algorithm can use training examples either given in a training set or generated by employing the method proposed in [5]. In addition the domain expert may provide a set of arguments which are exploited to reduce the version space thus reducing the number of examples required by C ONACQ to converge. E.g. our experimental study shows a reduction of roughly 50% to 75% for two arguments per example.

The paper is structured as follows: In Section II we provide an introduction to constraint learning. The types of possible arguments, their relation to examples, and their consequences for the version space are described in Sec-tion III. The implementation of our method is presented in Section IV followed by the results of our experiments in Section V.

In order to be able to learn a target problem description, an expert should define the underlying formal language of the learner. In the case of constraint network learning, an expert has to specify a vocabulary that includes a set of variables X : { x 1 ,...,x n } along with a (finite) set of domain values D and a set of allowable constraints L : { b 1 ,...,b m } constraint b  X  L with arity n can be defined on a set of variables X b  X  X where | X b | = n specifies a restriction on the allowable combination of domain values for the set of variables X b .

For simplicity we assume that every constraint considered by the learning algorithm is binary, that is | X b example, given a constraint library L : { X } and a set of variables X : { x 1 ,x 2 } one can define a constraint  X  1 , 2 specifies a  X  X reater than X  relation between variables x 1 x . Note, this assumption does not affect the generality of the proposed approach since every high-order finite-domain constraint can be reduced to a set of binary constraints.
Constraints from the library L together with the set of variables X define the inductive bias of the learning algo-rithm B . A bias B is a subset of { b i j,k } for all 1  X  j,k  X  n , 1  X  i  X  m . For instance, given the library L : { X  ,  X  , 6 = } together with the set X : { x 1 ,x 2 } an expert can construct the possible subsets.

A training set E f is the second input required by the constraint acquisition algorithm. Such a set should be formed by an expert and consists of a set of instances E (training examples) and a classification function f : E  X  { 0 , 1 } . The classification function partitions the given instances into positive e + and negative e  X  examples.

Each instance e  X  E is a mapping from the set of all variables X to the set of domain values e ( x j )  X  D . If a pair ( e ( x j ) ,e ( x k )) is an element of a binary constraint b then we say that the instance e satisfies the constraint b the opposite case the instance is rejected by the constraint. An instance e is called a solution for a set of constraints C  X  B if it satisfies all constraints in C and a non-solution otherwise.

Bessi  X  ere et al [1] define the constraint network acquisition problem as generating a constraint set C  X  B that correctly classifies all training examples in E f , i.e. every positive example e +  X  E f is a solution and every negative example e  X   X  E f is a non-solution of C . In this case C is termed to be consistent with the training set E f .

C ONACQ [1] is a SAT-based algorithm that uses version spaces [2] to acquire constraint networks. Here, the hypoth-esis space corresponds to the bias. Given a bias B and a set of training examples E f the version space V B ( E defined as the set of constraint networks C  X  B which are consistent with E f .

C ONACQ encodes the version space V B ( E f ) as a propo-sitional theory K . The propositional variables of K are symbols b  X  B representing constraints of the bias B . In an interpretation of K a propositional variable b with truth value 1 indicates that the constraint b is included in a constraint network. Truth value 0 represents the exclusion of constraint b . models ( K ) denotes the set of all models of K . A function  X  ( m ) transforms a model m of K into a constraint network by mapping propositional symbols with truth values of 1 to corresponding constraints. All constraints which correspond to symbols with truth value 0 are omitted. The negative facts  X  b in K should be understood not as the negation of constraint b itself, but as a description that b is absent in all constraint networks characterized by K . Thus, models ( K ) is used to represent all possible constraint networks consistent with E f .

C ONACQ takes the bias B and a set of examples as an input. For each example e the constraint acquisition algorithm finds a set  X  ( e ) of constraints b  X  B where b is unsatisfiable with example e . If e is a positive example then the unit clauses { X  b } are added to K for all b  X   X  ( e ) . In the case e is a negative example then the clause { W b  X   X  ( e ) is added. Each learning step finishes by applying unit propagation to simplify the propositional theory K and to check consistency.

Example 1: Assume that an expert provided a constraint library L = { X  ,  X  , 6 = } along with a set of variables X = { x 1 ,x 2 ,x 3 } and a domain D = { 1 , 2 , 3 } . The constraint bias B is defined as { X  i,j ,  X  i,j , 6 = i,j 1  X  i &lt; j  X  3 . Furthermore, the expert defined a training set E f T = { e + 1 ,e  X  2 } (see Table I) aiming to acquire a target constraint network C T that contains two constraints {6 = 1 , 2  X   X  2 , 3 } . After processing these examples C will output the propositional theory K presented in Table I.
Example 1 shows that due to incompleteness of the provided training set E f T multiple constraint networks are consistent with the examples. [5] subsequently suggest an algorithm to generate missing examples until all b  X  B are fixed , that is either b or  X  b is entailed by K . From the given propositional theory K and a set of constraints L the algorithm iteratively generates extensions of K such that: (a) K is satisfiable and (b) there exists m  X  models ( K ) such that constraint network  X  ( m ) has at least one solution. Such a solution is then presented as an example to an expert, who classifies it as positive or negative. Using the leading optimistic-in-expectation strategy, the algorithm iteratively generates such examples, which in the best case fix exactly one constraint b  X  L , thus reducing the version space by half, regardless of user classification.

Example 2: For the case given in Example 1 the algo-rithm generates examples that fix at least one constraint b i,j . The generated examples and the learned clauses are presented in Table II. Note, unit propagation will reduce clauses such that after removing the clause generated for e 2 from K after e
However, experts may give arguments to supplement examples. E.g. for e  X  2 the expert may give the constraint  X  e e e e e e as a reason why the example is negative. These arguments represent additional information and can be easily formu-lated by an expert in the validation step. In the following section we will provide a general definition of arguments and their impact on the version space.

The task of argumentation based learning is to generate a logical theory C based on a set of arguments ARG provided by an domain expert. In our case this logical theory is a set of constraints. Consequently, we define an argument arg as a set of constraints, thus allowing examples and arguments to be treated uniformly. In particular, an example is a set of constraints x i = v i where x i is a variable and v element of the domain D . Therefore, an argument is a subset of the bias and the set of all possible value assignments, i.e. arg  X  B  X  X  x i = v i | x i  X  X,v i  X  D } . In the following we require that arguments are satisfiable. Arguments and constraints are interpreted with respect to a vocabulary. An interpretation for a vocabulary is an assignment of a value from the domain to each variable of the vocabulary. The concepts of models, satisfiability, and entailment are defined as usual.

Definition 1: Given a set of arguments ARG and a logical theory C , C is valid with respect to ARG iff C is consistent and the following conditions hold for all arguments of ARG : 1) C  X  arg + satisfiable where arg + is called a positive 2) C  X  arg  X  unsatisfiable where arg  X  is called a negative 3) C | = arg N where arg N is called a necessary argu-4) C 6| = arg  X  N where arg  X  N is called too-strong for 5) arg S | = C where arg S is called a sufficient argument 6) arg  X  S 6| = C : arg  X  S is called too-weak for C . The The set of arguments ARG is ARG +  X  ARG  X   X  ARG N  X 
In the following we specify the clauses added to the propositional theory K for each argument type which char-acterize the version space. For this characterization we employ the concept of conflicts.

Definition 2: The set of constraints B 0 for a bias B is a conflict for argument arg (set of constraints) where B 0  X  B iff B 0  X  arg is unsatisfiable. A minimal conflict is a conflict which does not contain a proper subset which is a conflict.
Property 1: If arg + is a positive argument and B 0  X  B is a conflict for arg + then K contains the clause W b  X  B 0 It is sufficient to consider only minimal conflicts B 0 .
This property ensures that every set of conflicting con-straints are excluded by adding corresponding clauses to K since arg + can be empty.

Given the vocabulary defined in Example 1, if a user specifies a positive argument arg + to be { x 1 = 1 ,x 3 = 2 } then the minimal conflicts are { X  1 , 3 } , { X  1 , 2 ,  X  2 , 3 Consequently, clauses like { X  6 = 1 , 2  X   X   X  2 , 3  X   X  6 = are added to K .

Note, we can construct cases where the number of min-imal conflicts increase exponentially with the size of the bias. However, if some of existing minimal conflicts are not added to K then the domain expert should validate more examples, thus allowing computational costs to be traded for knowledge acquisition costs.
 Property 2: If arg  X  is a negative argument and CONF is the set of minimal conflicts for arg  X  then W
If a user specifies the argument given in the previous example as negative then the presented conflicts are in-terpreted as a conjunction and connected by a disjunction. However, Property 2 can be reformulated in order to avoid the disjunction of all minimal conflicts.

Property 3: If arg  X  is a negative argument and B 0  X  B s.t. arg  X   X  ( B  X  B 0 ) is satisfiable then the clause W is contained in K . It is sufficient to consider only sets B where for each B 00  X  B 0 , arg  X   X  ( B  X  B 00 ) is unsatisfiable.
If for the example given above a user specifies the negative argument { x 1 = 1 ,x 3 = 2 } then the clauses { X  1 , 3 } can be added to K . Note, each such clause corresponds to the minimal hitting set of the conflicts, i.e. the set that includes exactly one element from each minimal conflict set B 0  X  CONF (see Property 2). As previously stated not all clauses need to be added to K since query generation proceeds until all b in B are fixed.

As in [1] examples may be specified completely, i.e. every variable of X is assigned a value. In the case that arg  X  is a complete example then the previous property
ARG T Clauses added to K can be simplified since minimal conflicts are singletons. Consequently, the previous property corresponds to the case in [1] where the complete example is a negative one.

Property 4: If arg S is a sufficient argument and b  X  B and arg S 6| = b then the clause  X  b is contained in K .
Let us assume that the user knows that x 1 = 2 and x 2 = 1 together with the domain constraint on x 3 is a sufficient argument, i.e. in cases where x 1 = 2 and x 2 = 1 all values of x 3 are allowed. In this situation { X   X  1 , 2 } , { X   X 
Note, completely specified examples correspond to suffi-cient arguments. If e S is a completely specified example then e
S | = C . Consequently, the previous property corresponds to the case in [1] where the complete example is a positive one.

Property 5: If arg  X  S is a too-weak argument and B 0 the set of all b  X  B where arg  X  S 6| = b then add W b  X  B 0 K .

If a user specifies a too-weak argument arg  X  S to be { x 1 = 1 ,x 3 = 1 } then the following clause {6 = 1 , 2  X   X  argument is a too-weak argument. In cases where the too-weak argument is a completely specified example then this argument is also a negative argument. Because of this one-to-one relation for complete examples, these can be treated either as sufficient or too-weak arguments.

Cases with necessary arg N and too-strong arg  X  N ar-guments can be reduced using negation to the cases with negative arg  X  and positive arg + arguments respectively. The learning algorithm should verify if C  X   X  arg N is unsatisfiable for each arg N and if C  X  X  arg  X  N is satisfiable for each arg  X  N . However, in practice it is useful to allow experts to specify necessary and too-strong arguments since positive and negative can be hard to formulate as shown by the following example.

Example 3: Assume that the same constraint bias B was provided as in Example 1. Instances in training set E f are complete examples and are processed as sufficient and too-weak arguments. Moreover, for each example the expert provided two arguments, arg N and arg  X  N , defined in terms of bias constraints. Thus the necessary argument arg the first example specifies that  X  X onstraint 6 = 1 , 2 fulfilled X , and the too-strong argument arg  X  N 1 that  X  X on-straint  X  1 , 3 need not be fulfilled X . For the second example the arguments arg N 2 and arg  X  N 2 can be interpreted as  X   X  is violated therefore the example is negative X  and  X  X ven if 6 = 1 , 3 is satisfied the example is negative X  respectively. Paradigms of necessary and too-strong arguments may be more understandable for experts compared to those of posi-tive and negative arguments. For instance, one can formulate a positive argument for the first training example as  X  X he target constraint network must be satisfiable with 6 = which is more requirement for the target network and not an argument explaining why the first example is positive.
The learning algorithm exploits the arguments according to the properties given above. Clauses inserted into the propositional theory K by the learner for each argument are presented in Table III. For necessary arguments arg and too-strong arguments arg  X  N we depict only those clauses needed for fixing the constraints in the bias. Note, in practical settings, if K entails  X  b then the constraint b is removed from the bias, thus reducing the size of clauses. E.g. in the second line of Table III clause {6 = 1 , 2  X  X  X  1 , 3 is simplified to {6 = 1 , 2 } .

The resulting theory K obtained after unit propagation is  X  X  6 = 1 , 3 . The example generation algorithm will generate only one complete example for this theory, e.g. (1 , 2 , 2) which we assume to be classified as a positive argument. By processing this example the argumentation-based learning algorithm can fix the last missing constraint  X 6 = 2 , 3 and the method outputs the constraint network C T = {6 = 1 , 2 ,  X 
Note that the expert can also formulate arguments as value assignments. For instance, the argument arg N 1 in Table III can also be given as arg N 1 ( x 1 = 1 ,x 2 = 2) . In this particular case the same set of clauses can be added to K .

The argumentation-based constraint acquisition algorithm described in this section relies on two general algorithms: Q
UICK XP LAIN [7] and HS-T REE [8]. Given a set B of possibly unsatisfiable constraints and a set BK of con-straints considered to be correct, Q UICK XP LAIN (B,BK) returns either (a)  X  in cases when the set B  X  BK is consistent or BK is inconsistent, or (b) a minimal conflict B
C  X  B . On each call Q UICK XP LAIN computes only one minimal conflict by searching the space of possible subsets of B using the divide-and-conquer algorithm. Since a set of constraints B may contain more than one minimal conflict we can use the HS-T REE (B,BK) algorithm that uses a breadth-first search strategy to find: (a) the set of all minimal conflicts CONF , and (b) the set HS of all minimal hitting sets of conflicts. In Algorithms 1 and 2 we use functions C
ONFLICTS and H ITTING S ET to show which results are extracted from the search tree created by HS-T REE . Algorithm 1 : Iterative learning algorithm Input : set of constraints B , set of training examples E Output : set of constraints C
CONF  X  C ONFLICTS ( HS-T REE ( B,  X  )) if CONF 6 =  X  then else K  X  X  X 
K  X  S IMPLIFY ( K,B )
LS  X  X  B }
The computation of minimal conflicts within HS-T REE is done by Q UICK XP LAIN and therefore both algorithms take the same inputs [9]. Each minimal hitting set B HS  X  HS is a set of constraints such that ( B \ B HS )  X  BK is satisfiable. During computation the generation of conflicts and hitting sets can be limited to avoid combinatorial explosion. This strategy is sufficient because the constraint acquisition algo-rithm continues to generate solutions until all the constraints in the given bias are fixed.

The constraint acquisition algorithm (see Algorithm 1) takes the set of bias constraints B generated from the given vocabulary and a set of training examples E as input. In the first step the consistency of the bias is verified by applying HS-T REE . For an inconsistent bias HS-T REE outputs a set CONF of minimal conflicts. According to Prop. 1 for each conflict B C  X  CONF the algorithm adds corresponding clauses to the propositional theory K . Additional constraints are fixed in K by applying S IMPLIFY . This procedure exploits unit propagation, redundancy rules, and backbone detection as proposed by [1] in order to fix bias constraints and to reduce the size and number of clauses in K . Next, the algorithm initializes an ordered set of sets LS by inserting the bias into it. During the learning process LS is used to store sets of unfixed constraints, namely all constraint sets corresponding to non-unary disjunctions in K . Hence, the elements of LS are constraint sets.

The main loop (Line 7) of Algorithm 1 includes three stages: generation of an example (Line 8), validation of the solution by an expert (Line 10) and learning of the version space (Line 11). The algorithm stops when all bias constraints are fixed.
 Complete examples are returned by the G ET E XAMPLE Algorithm 2 : L EARN C ONSTRAINTS algorithm
Input : set of arguments ARG , set of clauses K , set of
Output : set of clauses K foreach argument a  X  ARG do
K  X  S IMPLIFY ( K,B ) return K method. In the case where E 6 =  X  the method takes the first example e  X  E , removes it from the training set and returns as a result. In the opposite case G ET E XAMPLE returns an example generated by the algorithm presented in [5] (see Section II for the basic idea). Note, G ET E XAMPLE outputs complete examples or  X  . If  X  is returned by G ET E XAMPLE then E =  X  and the arguments processed on previous learn-ing steps exclude all possible constraint networks. Hence Algorithm 1 returns inconsistency . On the validation step (V
ALIDATE ) the algorithm verifies if an example returned by G ET E XAMPLE is classified. Each unclassified example is presented to the expert, who decides if the example is a solution of the target network or not. Depending on the classification results the example is added either to ARG ARG  X  S . Furthermore, during this step the set of arguments ARG can be extended by the expert by specifying additional arguments justifying the classification.
 In the next step, Algorithm 1 calls the L
EARN C ONSTRAINTS ( ARG,K,B ) method which processes all given arguments one by one. For each argument, Algorithm 2 introduces changes to the propositional theory K as defined in Section III. Depending on processing requirements we invoke either HS-T REE or Q UICK XP LAIN to identify a minimal conflict or a minimal hitting set in the bias B given an argument as a background theory. If an argument provided by an expert is inconsistent then both Q UICK X PLAIN and HS-T REE return  X  . Hence, inconsistent arguments are ignored by the constraint acquisition algorithm. During the final step the algorithm calls S IMPLIFY ( K,B ) to validate and to simplify the generated propositional theory.

The last steps of the main loop update the set LS so that the new set includes all constraint sets that correspond to non-unary positive disjunctions of the propositional theory K . The bias is added in cases where LS is empty. Note, the actual implementation deletes those b from B where K entails  X  b . When all constraints b  X  B are fixed, the algorithm returns the target constraint network C T to the expert.

The main goal of the evaluation was to show the impact of argumentation-based constraint acquisition on the number of training examples required to learn the target constraint network. Therefore, in our experiments Algorithm 1 was provided with an empty set of training examples E . Hence we can compare the number of examples generated to learn a desired constraint network using the approach presented in this paper with that of [5]. Furthermore, we evaluated how the number of arguments influences the number of generated examples.

Similar to [5] the argumentation-based learner was applied to three problems: random binary problems, Sudoku puzzle and Schur X  X  lemma. In order to generate the random binary problem the system created a constraint bias given the library { X  ,&lt;, = , 6 = ,&gt;,  X } and a set of 14 integer variables with domain size | D | = 20 . Next the generator randomly selected a constraint and added it to the network. If the network had solutions the generator randomly added another constraint. The iterations continued until a given size of a soluble network was achieved. The resulting network was used as the target network for the learner. The second problem implements a standard 9  X  9 grid Sudoku puzzle as well as a reduced 4  X  4 version (employed in [5]). Both Sudoku problems were evaluated using a constraint library { X  ,  X  , 6 = } . The constraint library for Schur X  X  lemma was defined as a set of ternary constraints just as in [5]
For each problem we performed multiple tests in order to obtain average results that correspond to the expected per-formance. The generation of arguments as well as validation of examples was implemented using task-specific checkers which were aware of the target constraint network and thus were able to validate generated examples. Moreover, the checkers provided a given or maximum possible number of arguments for each example. The latter was done to simulate an expert X  X  actions during the argumentation process. We randomized the argumentation as follows: first the validation system generated a set of possible arguments for a given example using elements of the bias as necessary or too-strong arguments. Then the system randomly selected the required number of arguments and returned them to the learner. In order to compute a set of possible arguments for a positive example, the checker considered all unfixed constraints UC that accepted the example. If c  X  UC was included in the target constraint network then c was a candidate for ARG N otherwise c was considered as an element of ARG  X  N . For a negative example the algorithm generated the possible arguments as previously described with the exception that UC was the set of all unfixed constraints that reject the example.

Example 4: Consider the Sudoku learning problem, where a generated complete example includes the following constraints e i : { x 1 , 1 = 1 ,x 1 , 2 = 2 ,x 1 , 3 = 3 ,... } . The validation system evaluates this example as positive and randomly generates the arguments a N 1 : { x 1 , 1 6 = x a The implementation of the presented approach used the SAT4J and C HOCO CSP solver. The example generation parameters were set to values that correspond to the optimal-in-expectation strategy.

Figure 1 shows the performance of the argumentation-based approach in terms of the number of examples validated and arguments provided for the described problems. The case with zero arguments is equivalent to the approach presented in [5]. As can be seen in Figure 1, the number of examples to be classified by an expert decreases consid-erably depending on the number of provided arguments. The experiment shows, however, that increasing the number of arguments (cases with 4 or more arguments per example) does not guarantee a constant improvement in performance. Regarding the runtime performance we can report that the generation of an example (G ET E XAMPLE ) together with the processing of arguments (L EARN C ONSTRAINTS ) for our largest test problem (i.e. the 9  X  9 Sudoku) required on average 17 sec. for the 2 argument case. Other average runtimes were: 9 sec. for 0 arg., 12.4 sec. for 1 arg., 20.7 sec. for 3 arg., 24.9 sec. for 4 arg., and 29.6 sec. for 5 arg. These results indicate the applicability of the proposed approach in interactive settings.

As discussed above our approach extends the work of [1] in that it allows domain experts to provide arguments and thus to improve the results of the knowledge acquisition process. Arguments are also exploited in the area of learning classification rules introduced in [6]. In this approach the expert can provide  X  X ecause of X  and  X  X espite of X  arguments in addition to the usual attribute/classification vector. These arguments are exploited by an enhanced version of the CN2 rule generation algorithm. The main differences to our approach is the underlying learning approach and the language exploited to express a theory.

The work of [10] aims to acquire preferences over existing constraint networks from preferences defined over training examples. We regard this as important step for effective knowledge acquisition. However, learning preferences is beyond the scope of this paper. In particular, we leave it as an open problem to investigate argumentation techniques for enhancing the acquisition of preferences.

Our work was motivated by the fact that efficient knowl-edge acquisition is still an important problem and one which must be solved in order to make knowledge based systems competitive. Since constraint based systems are among the most successful problem solving approaches in many application domains, we focused on the acquisition of constraints. In particular, we built on the version space approach pioneered by [1]. We enhanced this method by giving the domain expert the ability to provide arguments, since specialists are not only able to classify examples but may also partially formulate the desired knowledge base. We investigated various types of arguments and discussed the consequences on the version space in cases where such arguments are given. Based on this analysis we have presented the implementation of a learning method where the expert can provide arguments in addition to classification information. We validated our method based on the test problems formulated in [5]. Our tests showed a significant reduction in the number of examples required to learn the target constraint network depending on the number of arguments provided.
 The research project is funded by grants of the Austrian Science Fund (Project V-Know, contract 19996) and the Austrian Research Promotion Agency (Project Kiras PL2: C2DSAS, Contract 813806) .

