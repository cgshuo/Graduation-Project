 This work presents RTTBurst, an end-to-end system for ingesting descriptions of user interest profiles and discovering new and rel-evant tweets based on those interest profiles using a simple model for identifying bursts in token usage. Our approach differs from standard retrieval-based techniques in that it primarily focuses on identifying noteworthy moments in the tweet stream, and  X  X umma-rizes X  those moments using selected tweets. We lay out the archi-tecture of RTTBurst, our participation in and performance at the TREC 2015 Microblog track, and a method for combining and po-tentially improving existing TREC systems. Official results and post hoc experiments show that our simple targeted burst detection technique is competitive with existing systems. Furthermore, we demonstrate that our burst detection mechanism can be used to im-prove the performance of other systems for the same task.  X  Information systems  X  Summarization; Social tagging sys-tems;  X  Human-centered computing  X  Social networking sites; burst detection, real-time tracking, twitter
A significant power of social media is the velocity with which new information is posted and shared. If a user is interested in re-cent posts about a particular item, event, or topic, she can search for a few relevant keywords in a social network and track the newest developments. For instance, one can track tweets mentioning  X  X oal X  on Twitter during the 2014 World Cup to identify when goals are scored [4]. If a user wants to track these interesting events on cur-rent social media platforms, however, she must remain online and manually filter through many duplicate posts. Many approaches have been proposed to address this need [3, 7, 8, 9], as explored at the 2015 Text Retrieval Conference (TREC) [6] organized by the National Institute of Standards and Technology (NIST).

This paper describes a simple scoring method that uses burst de-tection to address this social media tracking problem. By identi-fying rapid increases (i.e.,  X  X ursts X ) in relevant social media posts, one can theoretically rely on the social network to determine in-teresting data for a given set of interests. We describe this ap-proach, which we call RTTBurst, and its use of real-time burst detection on Twitter X  X  social media stream. Besides documenting our techniques, RTTBurst was one of the systems participating in the TREC 2015 Microblog track, and we discuss its performance relative to similarly purposed systems. Lastly, RTTBurst X  X  archi-tecture is quite different from the other TREC systems, allowing us to demonstrate its use as an additional filtering step to increase other systems X  performance.

This work makes the following contributions:
Identifying important events from the ever-growing body of dig-ital media has fascinated researchers for over twenty years, starting from digital newsprint to blogs and now social media [1]. Early event detection research followed the work of Kleinberg [5] by identifying bursty keywords from digital newspapers and clustering those keywords to identify bursty events. These works inspired our exploration of burst detection, but they often used complex mod-els, were not designed for big datasets, and were not designed for real-time use.

A recently published survey by Atefeh and Khreich [2] explores many of the avenues used for modern event detection in social me-dia. They laid out many of the issues in analyzing Twitter (e.g., high levels of noise, mixed language, spelling/grammar mistakes, etc.) and presented a classification of event detection techniques. The classes cover three dimensions: unspecified vs. specified event information, new vs. retrospective detection, and unsupervised vs. supervised learning methods. Our work falls in the new-event-detection, unsupervised learning classes but represents a hybrid in the unspecified vs. specified dimension. RTTBurst was originally developed on an open-domain model and was adapted to the in-terest tracking domain. It allows the user to pre-specify a topic of interest but leverages temporal signatures to identify new, unantic-ipated events related to that topic. This hybridization is well-suited for the TREC 2015 Microblog track, which focused on identifying new, topically relevant information on Twitter in real time.
As mentioned in the track X  X  2015 overview paper by Lin et al. [6], this filtering task X  X  goal was to identify new tweets relevant to a set of given interest profiles, each of which was comprised of an iden-tifier, title, a brief description, and a narrative describing the topic of interest. The evaluation occurred in July of 2015 over ten days and was broken across two tasks: a mobile notification task that en-forced a limit of 10 tweets per topic per day and penalized tweets based on the delay between posting and reporting (Scenario A), and a daily digest task with the relaxed constraint of 100 messages per day and no temporal penalty (Scenario B). For the evaluation, NIST created 225 topics, 51 of which were later assessed.
RTTBurst X  X  high-level pipeline is composed of several stages, from collecting the Twitter stream, to finding bursty tokens, to us-ing these tokens to extract the most interesting tweets. Each of these stages is described below.
 Processing the Twitter Stream. For input, RTTBurst used Twit-ter X  X  unfiltered public sample stream, corresponding to approxi-mately 1% of the full stream (though larger samples should also work), and the user X  X  interest profiles. After extracting search key-words k  X  P i from the set of interest profile titles P , RTTBurst leveraged Apache Spark X  X  1 Twitter receiver to collect all tweets from the public sample stream and tokenized them using CMU X  X  ARK TweetNLP tokenizer. 2 We then applied a series of filters to remove non-English tweets and low-quality tweets based on the number of hashtags, web links, token counts, and whether the tweet contained the string  X  X ollow X  (motivated by the large amount of  X  X ollow-me X  spam on Twitter).

After this first round of quality-based pruning, RTTBurst then calculated the intersection between each tweet X  X  token set and the set of all search keywords  X  i P i and kept only those tweets with a non-empty intersection (i.e., only those tweets that contained at least one keyword from at least one interest profile). These to-kenized tweets were then converted into a time-stamped inverted index matching tokens to the users who tweeted them.
 Identifying Bursty Tokens. This time-stamped inverted index al-lowed us to capture changes in a token X  X  usage over time. We main-tained a sliding window over all tweets generated by the Twitter streaming API within the past two minutes and incremented the window by 60-second time slices. Each window therefore over-lapped with the previous 60 seconds to smooth the input.
For each two-minute window, we calculated the number of users tweeting with each token and stored this frequency over the previ-ous N windows. We normalized these frequencies by the number of unique tokens in the past N windows and used add-one additive smoothing to correct for tokens with zero occurrences in a single window. Following the features set forth in the paper by Buntain et al. [3], we then used linear regression to fit a line to the natural logarithm of this frequency data. By transforming this frequency data to logarithmic space, exponential curves will appear linear, simplifying the linear regression step, and the steeper the slope of the best-fit line, the steeper the exponential growth of the token X  X  usage. Based on this fit, we then scored each token by the product of the slope of the best-fit line and its coefficient of determination R . Since R 2 coefficient is in the range [0 , 1] , this product reduced scores for highly deviant frequency curves. In this manner, tokens experiencing large bursts in usage, which we would expect to ex-hibit exponential growth, were scored highly. We then discarded all https://spark.apache.org http://www.cs.cmu.edu/~ark/TweetNLP/ tokens with scores below a burst threshold  X  and any token whose length is less than four characters.
 Moment Summarization. Every sixty seconds, RTTBurst iden-tified a new (possibly empty) set of bursty tokens, which corre-sponded to noteworthy moments in the relevant interest profile. For the TREC Microblog track, however, returning these bursty tokens was not sufficient for summarizing the moment, since the evalua-tion was based on judgments over individual tweets. Rather, our system used tweets to summarize these moments, similar to the ReDites system [7].

To this end, every sixty seconds, RTTBurst parsed all tweets in the previous N windows to create a subset of tweets containing these bursty tokens. We then calculated a Jaccard similarity score for each tweet in this subset by comparing the tweet to tweets re-turned to the user in previous windows. Any new tweet whose Jac-card similarity was above our threshold J t = 0 . 7 was discarded, and the remaining tweets were sorted by their similarity scores in decreasing order. Finally, the top M least similar tweets contain-ing bursty tokens from the past N windows were assigned to the relevant interest profiles and stored.

Before pushing a tweet to the user, however, RTTBurst performed one last pass through the tweets to select those that were most rel-evant to the given interest profile. For each candidate tweet stored up to this point, RTTBurst then selected only those tweets that con-tained at least X tokens from the relevant interest profile. All other tweets were then discarded.

In summary, for Scenario A of the TREC Microblog track, the top 10 most dissimilar tweets containing bursty tokens and at least two tokens from the relevant interest profile were returned to the user per day. Scenario B followed the same pipeline with the addi-tional relaxation of returning the top 100 most dissimilar tweets.
While analyzing results after the official TREC 2015 evaluation, we noticed a significant dissimilarity between the tweets returned by RTTBurst and those returned by the other systems. This obser-vation led to an interesting question: If we apply the burst detection approach of RTTBurst to the output of another more traditional information retrieval system, could we increase the system X  X  per-formance? To explore this question, we designed a simple gating mechanism that, given a set of tweets returned by system A , used RTTBurst to keep only those tweets that contained a bursty token.
Following from this question of using RTTBurst to filter other systems, we also investigated whether RTTBurst could be used to create ensembles of these information tracking and summarization systems. That is, given the output of two TREC systems A and B , would applying RTTBurst to their combined output yield higher scores? For this investigation, we constructed a simple system that takes the union of any two systems X  returned tweets and then ap-plies RTTBurst X  X  gating mechanism to filter the results. To ensure that RTTBurst did not benefit simply from combining multiple sys-tems, we also conducted an experiment that scored the outputs of each pair of systems, without any gating by RTTBurst. Duplicate tweets were removed from this paired output, the output was or-dered by delivery time, and only the first tweets within the scenario A daily limits were scored.
We divide our results into two sets: The first covers RTTBurst X  X  relative performance results from the real-time Microblog track tasks as scored by NIST (including some post hoc testing), and the second covers results from our ensemble experiments.
RTTBurst X  X  TREC evaluation version originally lacked several tweet quality metrics (i.e., it did not filter out tweets with many hashtags, many links, or few tokens) and did not include mecha-nisms for preventing duplicate tweet content from being reported to the user. This official run crystallized the need for these quality metrics as our system caught a significant amount of spam in this early run. For example, while the original RTTBurst implemen-tation did prevent the same tweet ID from being reported twice, two different tweets with the same content could still be reported, and many Twitter bots spammed the same tweet content with only slight differences (one token at the end of the tweet might differ from one spam tweet to the next).
 Following the TREC evaluation period and the release of the NIST-judged tweets, we implemented these quality metrics and performed a series of post hoc parameter optimization experiments. Parameter optimization used a randomized parameter search over window size N  X  [7 , 43] , maximum tweets delivered per minute N  X  [10 , 50] , and burst thresholds  X   X  [0 . 015 , 0 . 18] . For each pa-rameter set, we recorded the number of tweets RTTBurst flagged for delivery to the user (across all topics), the number of these tweets that did not have associated relevance judgments from NIST (unjudged tweets), and their scores. Table 1 shows the top-scoring sets for both scenarios from the official run (indicated by the  X  ) and our parameter optimization (see the track overview paper [6] for de-tails on the scoring methodology). Official scores placed RTTBurst 11th out of 32 automatic runs in Scenario A (ranked by ELG) and 4th out of 38 in Scenario B. After parameter optimization, RTT-Burst would move up one rank in Scenario A and would remain in fourth in Scenario B. Note that randomized parameter optimiza-tion produced more scored tweets than the official run, which was essentially silent. It is worthwhile to note that RTTBurst is exceed-ingly conservative in the emission of tweets, and that this approach occupies a completely different point in the tradeoff space com-pared to standard retrieval-based systems.
Applying RTTBurst X  X  gating mechanism to a single Scenario A system resulted in an average increase in ELG and nCG by 17% and 13% respectively but decreased the ELG of the best-performing system [10] by about 19%. A two-sided t-test on the original scores and the gated scores determined this increase in ELG was statisti-cally significant ( t (33) = 3 . 28 , p &lt; 0 . 01 ). In total, RTTBurst increased the performance of 22 systems and decreased the perfor-mance of 13 systems, as shown in Figure 1a. For Scenario B, gating with RTTBurst resulted in a 9% decrease in nDCG@10.

For system pairs, comparing an individual system with its high-est-scoring pair (that is, pairing it to all other systems and taking the one that achieves the highest ELG) yielded an 11% average ELG increase. Only three systems achieved higher scores with-out pairing. Using RTTBurst to gate these pairs yielded a 24% increase in ELG over the individual, ungated systems, and five sys-tems performed worse than their unpaired, ungated counterparts. Differences in single system ELG and paired, gated system scores are shown in Figure 1b.

For completeness, we also compared the best pairs X  ELG to a silent system (Figure 2a) and the best gated pairs of systems (Fig-ure 2b). Note that these figures show absolute scores as opposed to score differences. We see that the best pairs of systems did not perform as well as a silent system, but applying RTTBurst as an additional gating filter raised all pairs up to or above the score for a silent system.
Results from our experiments and the official Microblog track exhibited a correlation between higher scores and fewer reported tweets. This link was first apparent given the score for a system that returns no tweets at all: an ELG, nCG, and nDCG@10 of 0.2471, which placed in the upper third of rankings in both TREC scenar-ios. During our parameter optimization experiments, we saw more evidence of this trend in a strongly negative, nearly linear correla-tion ( R 2 = 0 . 8172 ) between the more tweets RTTBurst returned and the score produced by the TREC evaluations. This preference towards silence might explain why gating with RTTBurst increased the average score in Scenario A: Summed across all topics, gating reduced the average number of tweets delivered by two orders of magnitude (from 1,600 tweets to a mere 57).

Such a significant reduction in the number of delivered tweets suggested another issue regarding similarity of results returned by the original systems and their gated counterparts. From Figure 2, all systems X  scores tended to converge to the same value; this con-vergence would be easily explained if all systems were converging to the same set of tweets. To examine this potential issue, we cal-culated the Jaccard similarity among the returned tweets for each system and then among the gated systems: For the original sys-tems, the average similarity across all systems was 0.045, and for our gated systems, average similarity was 0.55. Therefore, gains made from gating with RTTBurst are not the result of reducing all output to a common set of tweets. This result suggests bursts pro-vide a valuable relevance signal.

While this convergence is a positive effect for many systems, we must address why RTTBurst decreases the top performing run [10] by 19% . One possibility is the absence of query expansion tech-niques. RTTBurst was originally designed as an open-domain sys-tem without tracking capabilities, and the modifications to track interest profiles did not include data-driven synonyms or identify related keywords that could expand the filtered data. RTTBurst therefore potentially discarded many relevant tweets, something that future versions of the system should address. Another possibil-ity, however, is an imbalance in the  X  X ursty-ness X  of some topics; thresholds for bursts about celebrities may be too high for more esoteric topics.
This work is also limited by unjudged tweets in the returned tweet sets, which makes a true performance comparison between official and post hoc runs difficult. That is, while the NIST asses-sors provided relevance judgments for approximately 94k tweets, the Twitter sample stream over the TREC evaluation period con-tains around 40 million tweets, so it is highly likely post hoc runs of RTTBurst may return tweets without these judgments. This lim-itation may be the driving force behind the connection between re-turned tweet set size and low scores. Going forward, we need to explore better methods for scoring these unjudged tweets or com-paring judged and unjudged tweets and scores via similarity prop-agation, self-learning, or a similar method.
RTTBurst is a hybrid end-to-end system that uses a simple burst-detection technique to identify tweets a user may find interesting. This paper laid out RTTBurst X  X  architecture, our participation in and performance at the TREC 2015 Microblog track, and a method for combining and potentially improving the performance of ex-isting TREC systems. While not as effective as the best systems, RTTBurst did perform well and shows potential in hybrid or com-bined approaches. Further steps could be taken to integrate mod-ern information retrieval techniques like query expansion and spam detection to increase RTTBurst X  X  performance. Given RTTBurst X  X  simple model and its stream-oriented processing, it is at least a use-ful tool that can be easily integrated into other approaches. Acknowledgments. This work was supported in part by the Na-tional Science Foundation under awards IIS-1218043 and CNS-1405688. Any opinions, findings, conclusions, or recommenda-tions expressed are those of the authors and do not necessarily re-flect the views of the sponsors. [1] J. Allan, R. Papka, and V. Lavrenko. On-line new event [2] F. Atefeh and W. Khreich. A survey of techniques for event [3] C. Buntain, J. Lin, and J. Golbeck. Discovering Key [4] L. Cipriani. Goal! Detecting the most important World Cup [5] J. Kleinberg. Bursty and hierarchical structure in streams. [6] J. Lin, M. Efron, Y. Wang, G. Sherman, and E. Voorhees. [7] M. Osborne, S. Moran, R. McCreadie, A. Von Lunen, [8] J. Rogstadius, M. Vukovic, C. A. Teixeira, V. Kostakos, [9] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes [10] L. Tan, A. Roegiest, and C. L. A. Clarke. University of
