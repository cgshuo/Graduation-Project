 1. Introduction
N -gram matching is one of the main techniques in probabilistic string matching. It has been used for a variety of information retrieval applications, including index term conflation, text searching and retrieval, text categorization, image-based text retrieval, degraded text recognition, and spoken-document retrieval.
Tauritz (2002) has pointed out 13 areas of application in which N -gram matching has been used during the last 50 years. The technique is described as being robust, complete, domain independent, efficient, and simple. It has been well established within the information retrieval (IR) research community that, in certain cases (such as generalized multilingual systems involving no customization for particular lan-guages), N -gram matching performs as good as, or even better than, word-based techniques. It has also been shown to be effective for many languages.

There are relatively few studies on the retrieval of Arabic documents in the literature. The lack of a realistically large test corpus has been a problem in past studies on Arabic retrieval (Xu, Fraser, &amp; We-ischedel, 2002). Furthermore, a claim is sometimes raised that some statistical NLP techniques for IR on
European languages do not transfer well to Arabic because of the complexities involved in the morpho-logical and orthographic structure of the language (Goweder &amp; De Roeck, 2001).

Over the last few years, a number of researchers have addressed this issue and investigated various statistical techniques and strategies for Arabic text retrieval and for some other applications, including speech recognition (Kirchhoff et al., 2002), OCR-degraded text recognition (Darwish, 2003), and document classification (Sawaf, Zaplos, &amp; Neyt, 2001).
 Besides, there has been some effort to initiate an Arabic corpus for experimental purposes such as the
TREC 2001 test suit, which included 383,872 newspaper articles (Larkey, AbulJaleel, &amp; Connell, 2002), and the corpus described by Goweder and De Roeck (2001), which included 42,591 newspaper articles. Apart from these cases, most researchers have constructed their own data sets.

Statistical language models offer a possible alternative to traditional morphology-based stemming techniques. Typically, Arabic stemming algorithms operate by  X  X  X rial and error X  X . Likewise, morpho-syn-tactic approaches have limited scope for deployment in IR. Even if substantial, their morpho-syntactic coverage remains limited and processing efficiency implications are often unclear (De Roeck &amp; Al-Fares, 2000).

Statistical methods can provide a more language-independent approach to conflation. Related words can be grouped based on various string similarity measures. Such approaches often involve N -grams (Larkey, Ballesteros, &amp; Connell, 2002). This paper examines the performance of N -gram matching as a basis for
Arabic term clustering. Given a text T, the paper addresses the problem of finding all occurrences of words sharing the same root in T.

Typically, one slices a string into a set of contiguous N -grams. However, the term N -gram as defined in the literature can include the notion of any co-occurring set of characters in a string such as an N -gram made of the first and third character of a word (Cavnar &amp; Trenkle, 1994). The main objective of the re-search, reported in this paper, was to test the impact of N -gram character contiguity on the overall per-formance as measured by clustering recall and precision.

The notion of using non-adjacent characters in N -gram computation is not new. The issue was raised earlier by Sawaf et al. (2001), who pointed out that:  X  X  X ap-n -grams X  X  should be investigated for Arabic, so that the more abstract level of morphological analysis can be reached. Pirkola, Keskustalo, Leppanen,
Kansala, and Jarvelin (2002) have also reported using this strategy in a cross-lingual study. In their technique (which they termed  X  X  X argeted S -gram X  X ), N -grams were classified into categories on the basis of character contiguity in words. The results indicated that the S -gram technique outperformed the conven-tional N -gram matching technique.

Arabic morphology involves a complex infix structure. Word infixes may occur in two places: after the first root radical, and before the last root radical. This might lead to an assumption that: adjacent N -grams might fail to capture the similarity between related infixed words. If this were the case, we would expect that non-contiguous N -grams should improve the overall performance of N -gram matching. 2. N -gram matching and Arabic
It has been sometimes assumed that some of the statistical techniques that have widely been applied to many languages cannot be expected to perform well on languages like Arabic in which suffixing is not the only inflectional aspect (Larkey et al., 2002). Given this assumption, a number of research studies have been carried out during the last three years or so. An overall look at the experimental results of these studies points out some differences. From an information retrieval perspective, these studies fall into two cate-gories: the first focuses on applying statistical techniques for string searching and term conflation, while the other focuses on document retrieval as a basis for N -gram matching. Mustafa and Al-Radaideh (in press) have examined the performance of N -matching techniques for
Arabic word-based string searching. They addressed the problem of finding morphologically related words in a text using two N -gram strategies: digrams and trigrams. The results showed that the digrams strategy offered a better overall performance, in terms of conflation recall and precision ratios, than the trigrams strategy. However, when their performance values were evaluated using the Sign test, the two methods were not found significantly different at the 0.5 level of significance.

Similarly, De Roeck and Al-Fares (2000) tested N -gram matching (or what they called  X  X  X damson X  X  algorithm X  X ) to assess its potential for clustering Arabic words sharing the same root. To do so, two strategies were tested: purely conventional N -gram matching and a refined two-stage approach in which potential affixes and weak letters were preprocessed to give relevance to root consonants only. The results gave a strong indication that the two-stage strategy involved improvement over Adamson X  algorithm.
However, the small size of data sets used in the experiment should be considered as a limiting factor in these results.

Mayfield, McNamee, Costello, Piakto, and Banerjee (2001) investigated the use of N -grams for Arabic retrieval in TREC 2001. They found that N -grams with N  X  4 were most effective. Using the same corpus, this work was continued in TREC 2002 by McNamee, Piatko, and Mayfield (2002) with some modifica-tions on the original research setup and tokenization. Plain 4-gram did quite well, but the hybrid scheme involving the combination of words plus N -grams of length 3, 4 and 5 was the best performing approach.
Using the TREC Arabic corpus as a test bed, Xu et al. (2002) evaluated a number of search strategies for the retrieval of Arabic documents. Experimental results showed that spelling normalization and stemming could significantly improve Arabic monolingual retrieval. The best results were obtained with trigrams, suggesting that bigrams carry too little contextual information while 4-gram and longer ones simply sim-ulate word or stem-based retrieval.
 In contrast, Darwish (2003) explored the effectiveness of OCR-based information retrieval using different
Arabic index terms including three categories: character N -grams, terms obtained through morphological analysis, and combination of both. The results indicated that N -grams of length 3 and 4, and combinations of N -grams with lightly stemmed words were well suited for OCR-degraded Arabic text retrieval. Proba-bilistic structured methods were shown to improve N -gram matching. The same conclusion, in respect to
N -grams of length 3 and 4, was pointed out earlier by Darwish and Oard (2002). 3. Experimental setup
In this research, a corpus consisting of about 160K of Arabic text with no diacritics was used as a test bed. It was extracted from a larger set of documents that were collected by the author. The corpus rep-resented different subject areas in humanities and social sciences and contained 24,750 textual words (including redundant words), with an average word size of 5.56 letters. No attempt was made to remove any characters or strings from the corpus. Basically, three experiments were carried out using three different strategies. Fig. 1 gives a flow diagram of the overall process.

In the first experiment, search was carried out for a textual word in the text to find all possible related word variants and their multiple occurrences. In the second experiment, the query word and textual tokens were preprocessed by first level (light) automatic stemming before N -gram matching was performed accordingly. Light stemming involved a limited number of suffixes and prefixes, including the definite article ( al ), connected pronouns, prepositions, conjunctions, interjection article ( X  X  waa  X  X ), postponement article ( X  X  sa  X  X ), and the interrogation article ( X  X  a  X  X ). In the third experiment a higher-order automatic stemming was performed, including all possible Arabic textual and morphological prefixes and suffixes.

As an example, consider the word  X  X  waliestifsaratihim  X  X  (for their inquiries). In the first experiment, no stemming is performed on this textual word. When light stemming is applied, the prefix  X  X  wali  X  X  and the suffix  X  X  ihim  X  X  will be removed, with the result being the stem  X  X  estifsarat  X  X . In contrast, when higher-order stemming is used, the prefix  X  X  waliesti  X  X  and the suffix  X  X  atihim  X  X  will be removed, with the result being the stem  X  X  fsar  X  X .

Each experiment was run twice using two different sets of digrams: conventional and hybrid, as ex-plained below. Digram matching was thought to be the most appropriate among other N -gram strategies for testing the main assumption stated earlier in the introduction of this paper. Arabic word infixes may occur in two places: after the first root radical, and before the last root radical. The majority of these infixes are formed of one letter (which is usually a long vowel). By forming non-contiguous digrams, we can have the ability to skip these one-letter infixes, which is not possible when using trigrams or other N -gram strategies.

The N -gram procedure starts with generating the set of digrams for the input query token. It then generates the set of digrams for each textual token. Given a token W (i.e., a string of letters
W  X  1 ; W  X  2 ; ... ; W  X  n over a given natural language alphabet), its set of diagrams D different ways as follows: 1. Conventional digrams (consecutive) 2. Hybrid digrams (consecutive plus non-consecutive)
Digram matching between the query set of diagrams and the set of diagrams for each textual word is carried out using a simple similarity measure, known as Dice X  X  coefficient (denoted S , as defined below) and different similarity threshold values, ranging from 0.4 to 1.0 (thus, making up six intervals). where A is the number unique digrams in a query word, B is the number of unique digrams in a textual word, and C is the number of unique digrams shared by A and B .

The list of possible related textual words are ordered according to threshold values. An example of the output for one of the query words is given in Fig. 2. 4. Results and discussion
The textual words retrieved from the corpus text using N -gram matching were compared against a list of relevant words that was compiled by hand. Table 1 presents the results of this analysis for the hybrid approach, including the total number retrieved and the total number relevant. The data represents the three strategies used in the experiment, including no stemming, light stemming and higher-order stemming. Similarly, Table 2 presents the corresponding results for the contiguous N -gram approach.

The term  X  X  X etrieved X  X  should be interpreted as being the set of word variants in the corpus text that are suggested by the N -gram matching procedure to be related to the query word. The term  X  X  X elevant X  X , on the other hand, should be taken to mean a subset of retrieved textual words that are judged by the user to be related to the query word on the basis of sharing the same Arabic root.

A general observation one can make about the results presented in the two tables is that: as the threshold value goes down the contiguous N -gram approach tends to provide higher values of  X  X  X etrieved X  X  textual words than the hybrid N -gram approach. While this might reflect positively on the overall recall perfor-mance, it might reflect negatively on the overall precision performance.

Table 3 presents the overall performance results of the hybrid N -gram approach. It shows the mean average recall and precision ratios for the three experiments, including no stemming, light stemming and higher-order stemming. Table 4, presents the results of the corresponding analysis for the contiguous
N -gram approach. The  X  X  X ecall X  X  ratio is used as a measure of clustering efficiency, relative to the target list of relevant words in the corpus text. The  X  X  X recision X  X  ratio, on the other hand, is intended to indicate the level of correctness of the judgements made by a given N -gram technique.

The results in both tables confirm the previous results that performance improvements are realized, as the level of stemming is increased. This observation seems to be consistent throughout the results of the hybrid approach as well as the conventional approach. One must indicate, in this respect, that the results are influenced by the performance of the stemmer used. Consequently, one would expect higher recall and precision values if infixes were also handled in some way, which provides the basic rationale underlying the present work.

Differences in the overall performance between the hybrid and conventional approaches are also apparent in the results presented in Tables 3 and 4. This is especially true, with respect to precision and with respect to the results of the two stemming forms. When the results of the no-stemming strategy are con-sidered, the two approaches show little or no difference in the recall behavior, but the hybrid N -gram approach provides higher ratios of precision, as the threshold value increases. As we move to the results of the light-stemming strategy, we start to see improvements in the overall performance of the hybrid ap-proach over the conventional approach. A more notable improvement is recognized in the corresponding results of higher-order stemming, especially in the case of smaller threshold values.

In view of the fact that recall trades off against precision, support to this general observation about the overall performance of the hybrid N -gram approach against the conventional N -gram approach can be sought in what is known as bivariate plots (i.e., plotting precision as a function of recall). Figs. 3 X 5 show how the performance of this approach compares to that of the conventional contiguous approach, using the given three stemming strategies: no stemming, light stemming, and higher-order stemming consecutively. In all cases, including no stemming, the hybrid approach can be seen to be better than the other approach.
As the precision X  X ecall graph in Fig. 3 indicates, the hybrid approach shows a better overall performance than the conventional approach in five cases out of the six values used. But, as the recall ratio goes down, the gap between the two approaches starts to narrow down until it reaches a point at which the two ap-proaches get intersected at the highest precision ratio.

A similar performance pattern can also be observed in the case of light stemming as shown in Fig. 4, but with less consistency. As we move from left to right on the recall axis, a larger gap in the overall perfor-mance (as indicated by the combined measure of precision and recall) is noticed between the hybrid and conventional N -gram approaches. Similarly, little difference is recognized between the two approaches as the recall values get smaller. This seems to indicate that light stemming has its main impact on the overall performance when the similarity threshold value is below 0.6. For higher threshold values, light stemming seems to have little impact on the results.

By contrast, as we examine Fig. 5 a significant improvement seems to be realized by the hybrid approach over the conventional approach. The fact that potential suffixes and prefixes are removed increases the capability of the N -gram matching procedure to determine the degree of similarity between a pair of words (i.e., a query word and a textual word). Add to that the fact that the hybrid approach takes care of the infixes as well, hence comes the difference in performance between the two approaches. But, as with the other two strategies, this difference appears to narrow down as we move up with the performance slopes.
A further observation that has to be made about the results shown in Figs. 3 X 5 concerns the point at which recall and precision performance values break even. This carries some significance, due to the fact that this balancing point of recall and precision is the point at which we make a decision to go for a higher or a lower similarity threshold value, with the consequent being lower or higher precision and recall values. For all cases, the hybrid approach seems to show higher break-even point values.

In the case of the hybrid approach, the performance break-even points occurred around the threshold values 0.43 (with no stemming), 0.51(with light stemming) and 0.56 (with higher-order stemming). In contrast, the corresponding break-even points for the conventional contiguous approach occurred around the values: 0.40, 0.42, and 0.46 consecutively. Given these results, it may be possible to assume that N -gram matching can offer a balanced combination of recall and precision performance that might exceed 40% of the searching results obtained. 5. Concluding remarks
The work, reported in this study, assessed the overall performance of two N -gram techniques using three different levels of word stemming: no stemming, light stemming, and higher-order stemming. The first N -gram technique was based on the conventional approach of generating adjacent digrams, while the other was based on a hybrid approach of mixing adjacent and non-adjacent digrams. Due to the highly inflected nature of Arabic, it was assumed that the contiguity of N -grams would have an effect on the performance of
N -gram matching. The fact that Arabic word morphology involves a complex infix structure might suggest that contiguous N -grams are not capable of capturing this structure.

Given the experimental conditions, under which this study was conducted as outlined above, the results demonstrated that considerable differences, in the overall performance, exist between the two techniques, especially when combined with stemming. These results and the findings of other previous studies, in re-spect to combining stemming with N -grams, raise questions about the most commonly stated feature of N -grams which is  X  X  X anguage independence X  X . While it is true, from the technical point of view, that N -gram matching is language independent, most of the attempts to improve its performance have been biased by morpho-syntactic features of the language under consideration.

The present results provide a strong indication that the hybrid approach of consecutive and non-con-secutive digrams outperforms the conventional approach which relies on contiguous digrams. Besides, the present findings indicate that N -gram matching, regardless of the technique used, seems to offer a combined balancing point of recall and precision over 40% of the results that can be obtained.
However, given the fact that the focus of the present research was on string matching using a word-oriented approach, the findings should not be taken further to conclude that text retrieval will necessarily exhibit the same pattern of behavior along the recall X  X recision performance dimension. This issue merits further investigation using a large document corpus such as the TREC 2001 test suit mentioned earlier. One can also suggest that the hybrid digram matching approach, presented in this paper, be extended to include Boolean text searching and to include phrase-based N -gram matching.
 References
