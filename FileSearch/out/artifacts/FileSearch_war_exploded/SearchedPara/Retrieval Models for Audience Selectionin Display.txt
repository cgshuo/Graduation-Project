 Web applications often rely on user profiles of observed user actions, such as queries issued, page views, etc. In audience selection for display advertising, the audience that is likely to be responsive to a given ad campaign is identified via such profiles. We formalize the audience selection problem as a ranked retrieval task over an index of known users. We focus on the common case of audience selection where a small seed set of users who have previously responded positively to the campaign is used to identify a broader target audience. The actions of the users in the seed set are aggregated to con-struct a query, the query is then executed against an index of other user profiles to retrieve the highest scoring profiles, validate our approach on a real-world dataset, demonstrat-ing the trade-offs of different user and query models and find that our approach is particularly robust for small cam-paigns. The proposed user modeling framework is applica-ble to many other applications requiring user profiles such as content suggestion and personalization.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing Algorithms, Experimentation Retrieval models, audience selection, ad targeting
Display advertising is the placement of graphical ads dis-played on web pages alongside the original content. In dis-play advertising, targeting is often performed by categoriz-ing users into standard segments (e.g., auto, health) based on their online activities. However, such pre-defined seg-ments might be too broad and poorly aligned with audience partitioning by the advertiser. This mismatch has led to the emergence of the current trend of advertiser-centric charac-terization of audiences. One popular approach for the adver-tisers is to characterize their desired audience by providing asmall seed set of existing customers as examples for iden-tifying additional prospective customers who are similar to those in the seed set, and are likely to  X  X espond X  to the ad-vertiser X  X  campaigns. This problem formulation is referred to as audience selection .

There are multiple ways to identify users similar to the seed set. One possible approach is K-Nearest Neighbors (KNN) modeling, however, KNN is less effective in very high dimensional spaces. Another possibility is to use Collabora-tive Filtering (CF) techniques, however, CF requires a suffi-ciently long history of user-item interactions. In our scenario we only have a few observations of users X  prior interactions with ads, and many fewer prior purchases or conversions. Furthermore, unlike CF, where user interests are mostly sta-tionary (e.g., a preference trend for action movies), in online advertising users X  interests and needs change over time.
We formulate the audience selection problem as a retrieval problem. We build rich user profiles using their entire on-line experience and explore two retrieval approaches inspired by language modeling and vector space models. Given the seed set of positive examples (users) for the advertiser, we construct a query , in a way that is reminiscent of relevance feedback in IR. This query is then executed against the index of all other users (potential customers), and used to identify users for targeting the advertiser X  X  campaign. This method allows for very efficient audience selection when searching over a large space of users.

Our setting differs from that of conventional ad-hoc IR in several interesting ways. First, natural language documents indexed by IR systems are usually fairly coherent around a single topic (or several related topics). On the other hand, users X  online history are composed from numerous, often un-related activities. Furthermore, the events we observe (e.g., Web searches, page views, ad clicks) are heterogeneous and contain varying amounts of information, hence reconciling them into a single user profile is an important research task. Additionally, users X  interests evolve over time. The change in their interests can be either personal (e.g., planning a va-cation), or can reflect a global trend (e.g., a popular movie). Finally, in contrast to conventional IR, which judges the rel-evance of retrieved documents, we focus on maximizing the conversion rate, namely, the fraction of (retrieved) users who purchase the product or service being advertised.
Given the seed set of users U = { s 1 ,s 2 , ...s 3 } who have previously converted on a given campaign, our goal is to rank other users by their conversion potential. We approach this problem within the information retrieval paradigm, develop-ing two alternative representations for indexing users. First, we consider language modeling (LM), a generative model where documents are generated by a multinomial distribu-tion estimated through maximal likelihood over a document collection. We represent users as sequences of their observed events, hence we can talk about the probability of  X  X enerat-ing X  a user by estimating the probability of observing a given event sequence. Our second approach is based on the vector space model (VSM), which maps documents and queries into a space defined by their features.
We represent a user by the set of events u = { e 1 ,e 2 ...e she has performed over a given history span. Each event is a type , int i is the time interval ,and c i is the event content .
An event type describes the nature of the event, such as a page view, ad click, etc. An event occurs at a specific time, and events are grouped in time intervals of varying length, ranging from 1 day to 1 month. Time intervals span non-overlapping continuous ranges of user activity, and to-gether cover the whole period of user activity. Different intervals can be assigned different weights, effectively  X  X e-caying X  the importance of older events. Finally, the event content contains the observed information about the event, usually in textual or numeric form, i.e., ids of ads viewed, the text of search queries issued, etc. We employ the bag of words method for modelling content strings, like queries, us-ing both unigrams and bigrams, as well as nodes of a topical taxonomy that represent more general text categories.
An important research question is how to reconcile differ-ent events (ie queries the user issued two weeks ago, with ad clicks from the last minute) in a single model. Each of these cues can provide a valuable signal, yet the heteroge-neous nature and large volume of user activity would make a very noisy representation if all combined in a single bin. To this end, we propose to represent users as a two-dimensional array of models, where we build a separate model (whether a language model or a vector space model) for each com-bination of a time interval and event type (see Figure 1). For example, if our time intervals are week-long, we have a separate model for the user X  X  page views each week, as well as an additional models for her search queries issued each week. Each entry of this two-dimensional array contains a single model built over the concatenation of the content of all the events of the same type observed in the given inter-val. We build a single user model by learning weights for the different cells of the two-dimensional array.
Language modeling (LM) has been successfully applied to representing documents and queries in textual information retrieval. LMs are often favored for their competitive perfor-mance, clean formalization and probabilistic interpretation.
Language models are generative models, where each user is assigned a probability of being generated. This probability is computed by estimating the probability of the sequence of events observed for this user. With a simplifying assump-tion of independence between events, we can transform this probability into a product of the probabilities of individual events. In this form, the model assumes a multinomial dis-tribution over the space of events: p ( u )= p ( e 1 ,e 2 p ( e 1 ) p ( e 2 | e 1 ) p ( e 3 | e 2 e 1 ) ...p ( e n |
A common strategy to alleviate the independence assump-tion in document retrieval models is to define composite fea-tures or n-grams. Similarly, here we can define composite events that are based on commonly performed actions, e.g., submitting a query followed by browsing the top search re-sults. While we do not present experiments with these type of features, they can be easily facilitated by our model.
We further develop this model by considering the struc-ture of events, namely, their time interval, type, and con-tent: p ( u )= p ( c i | int i ,type i ) } .

The probability of each event is estimated using three components: (1) the probability of observing an event in the given time interval ( p ( int i )), (2) the probability of observ-inginthatintervalaneventofthegiventype( p ( type i | int i and (3) the probability of observing a specific event content given the interval and the event type ( p ( c i | int i ,type
The model is simplified by assuming that the activity of the user proceeds with constant frequency. That is, p ( int proportional to the length of the interval, and 1, where T is the entire history span. A further simplifica-tion can be made by assuming that the mix of event types does not depend on the interval: p ( type | int )  X  p ( type ), that is, the ratio between the number of page views, queries and other event types stays constant. Although this assumption does not necessarily always hold, our intervals are usually fairly long (several days), hence the assumption is not vio-lated too much in practice.

To compute p ( c i | int i ,type i ), we use standard modeling techniques to generate the content of the events. The prob-ability of the textual content of the event is generated based on the probability of individual words: p ( c i | int i ,type event content and P w p ( w timated using the maximum-likelihood estimator over the aggregated content of all events of a given type in a given time interval. We used Laplace smoothing.

The query for audience selection is very different than in standard retrieval tasks. In the standard document re-trieval, the query is essentially a short fragment of text. In the audience selection task the query is created from a set of seed users, and contains more events than an in-dividual user might. To develop an adequate query rep-resentation, we build upon the work on language model-ing with relevance feedback [16]. There, the query is com-posed by merging several documents (users in our case). Conceptually, we treat the seed set of users as relevance Figure 1: Component models of the user and query. feedback from the advertiser. The query is thus calculated by finding a language model  X  q that is close to the mod-els of the users in the seed set, but far from the other users (the collection background model) [16]: p ( w | the models for the users in the seed set, C is the background model composed of all other users, and  X  is a parameter learned on a validation set. By subtracting the background model we are emphasizing those words/events in the query that discriminate positive users from the rest. Note that this approach is reminiscent of the Rocchio method [12].
We use two alternative LM scoring paradigms. First, as in standard language modeling, we score users based on the query likelihood  X  the probability of the query be-ing generated using the user X  X  language model: p ( q | u ) Q u . To compute  X  u , we separately analyze the content of events for each combination of interval and event type. More precisely, we manipulate an array of models,  X  u int,type user model is then computed as a combination of individ-ual models for different intervals and events types (in a way that is reminiscent of the mixture language models [2, 17]): p ( w |  X  u )= model simpler, we opted to reduce the number of parame-ters and to learn one parameter for each time interval and event type (  X  int and  X  type , respectively) from the held-out validation set, instead of learning one parameter for each possible combination (i.e.,  X  int,type ). Figure 1 illustrates how the query and user models are compared when each is represented as a two-dimensional array of language models.
In the second scoring paradigm we use the model compar-ison approach. Drawing on the language modeling work for relevance feedback, we use KL-Divergence to compare the query and the user sub-models: KL (  X  u , X  q )= divergence when the model does not use smoothing, but in our case these two represent different metrics. Here we also compare an array of models, as shown in Figure 1.
Users are represented in our framework as a set of events we observed for them, where each event is a triplet of its time interval, type, and content. In essence, we first con-struct a meta-document by concatenating the content of all theeventsofthesametypeinthesameinterval. Then,we represent this meta-document as a TFIDF vector of its bag of words. Each user profile is then represented as a weighted combination of such vectors, where the weights are learned on a validation set: to make the model simpler, we reduce the number of pa-rameters and learn one parameter for each time interval and event type (  X  int and  X  type , respectively). In order to com-pute VSM int,type , we experimented with several TF and IDF formulations (Table 1), and used dot product as the distance metric to compare query and user vectors.
We use the Rocchio approach to incorporate pseudo rele-vance feedback and compose the queries [12] for our vector space model. As a first approximation, we construct the query from two sets of users X  X he seed set of positive ex-amples ( U ) who converted on this campaign, and a set of negative examples ( V ) sampled from the rest of the users (who did not convert on this campaign): q =  X   X  1 | U |  X  P
Since conversion rates are usually very low, the set of con-verted users is small, which leads to extreme data sparsity over a rich feature set. To this end, we also experimented with augmenting the seed set of users who converted with an additional set ( U click )of pseudo-positive users, who clicked on the ad but did not convert (a similar approach was used in [1]). The assumption behind this approach is that the users who clicked on the ad found it relevant at least to some degree, and might still convert later: q =  X   X  1 | U |  X   X  where V  X  U
In both formulations, values of the free parameters  X  ,  X  and  X  are estimated on held-out validation data.
We randomly selected 34 different display ad campaigns, which were registered on the Yahoo Advertiser Network. All these campaigns are performance-based, i.e., advertis-ers only pay for actual conversions. Of the 34 campaigns, some had only 30-50 conversions per week on average, while others receive many thousands of conversions every week.
User who either viewed, clicked, or converted on the ads from the three week period from 02/04/2010 to 02/24/2010 were identified. Users who converted for campaign c in the first two weeks make up our (positive) seed user set U for c (Section 2.3). The first 2 days of the final week make up the validation set for parameter tuning, and the last 5 days for the test set. In total there were more than 150K validation and 450K test instances across the 34 campaigns.

Each user X  X  profile is constructed from four weeks online activity preceding the user X  X  ad view. Note that while pre-dicting a test instance, say on day t , we access user history up to day t  X  1. Hence, the method is not using any future information.
One way to evaluate the ranked list of users produced by the different audience selection methods is to use the Re-ceiver Operating Characteristic (ROC) curve. A ROC curve plots true positives versus false positives for different classifi-cation thresholds. The Area Under Curve (AUC) for a ROC curve is the probability that the audience selection method assigns a higher score to a random positive example than a random negative example (i.e., probability of concordance). So, a purely random selection method will have an area un-der the curve of exactly 0.5. An algorithm that achieves AUC of 0.6 can distinguish a positive user from a negative user with 60% accuracy.
We begin by evaluating Vector Space Modeling (VSM) and for Language Modeling (LM), and vary one parame-ter at a time to study its effect. In most cases, the effect of varying parameter values was similar for VSM and LM, suggesting that both approaches use the information in the data in a similar way; consequently, owing to lack of space we present parameter exploration results only for the VSM model.

While an AUC of 0.8 or more is common in many re-trieval tasks, note that the audience selection task is inher-ently much more difficult than standard textual query-based retrieval. This is due in part because conversions are ex-tremely rare and there are no true negative examples. Users who did not convert right away might still convert later. To put the sparsity into perspective, in the literature re-searchers have often found it to be difficult to predict clicks where the click-through rates are very small (e.g. 0.01 for certain applications) [3, 8, 11]. Conversions are usually two to three orders of magnitude rarer than clicks. Additionally, there are a multitude of activities in the user profiles that may not be relevant to the conversion. For the initial vector space model we set TF to n ( d,t ) (ratio), IDF to max { 0 ,log ( N  X  df t df malization. In this configuration all events were put into a single time interval and one event type (i.e., only one cell in the two-dimensional array of Figure 1). We study the ef-fect of these parameters later. The query from the seed set was constructed using the Rocchio algorithm with weights  X  =1,  X  =0,and  X  = 1 and dot product was used to score the users. Using this configuration, macro-averaged across all campaigns achieved an AUC of 0.65. Figure 2 shows the performance breakdown of the VSM model over individual campaigns. For some campaigns our approach does remark-ably well (and achieves 0.90 AUC), while for some others the model does not perform any better than random guess-ing. In Section 4.6 we analyze these results and attempt to understand the variation in performance across campaigns.
For the language modeling approach, we use the query construction method as described in Section 2.2. Again, we use a single time interval and merge all the events as if they were of the same type (i.e., effectively consider one event type for this experiment). Overall, we found that the lan-guage modeling approach performed on par with the vector space one. In our experiments log-likelihood had a AOC of 0.66, better than both KL-divergence which had a ROC score of 0.63 and VSM score of 0.65.
Recall from Section 2.3 that the query is constructed from the seed set of relevant users and a set of non-relevant users, with  X  and  X  representing their weights in the query compo-sition (we discuss the effect of using clicks to create pseudo-positive examples later). Figure 5 illustrates the effect of these two parameters.

Note that when  X  = 0, the query is being constructed us-ing only the relevant users. Even though many retrieval sys-tems use only positive feedback [10], in our experiments we found that negative examples can help significantly. For ex-ample, the performance goes up from 0.62 to 0.65 when the ratio  X   X  is increased from 0 to 1. However, further increasing the value of  X   X  causes the non-relevant users to overwhelm the relevant users, which in turn hurts the performance.
When compared on the per campaign basis, using non-relevant users leads to superior performance for most cam-paigns (over 80%). The increase in performance over the model from Section 2.3 is illustrated in Figure 3. Augment-ing the seed set of converted users with users who clicked on ads but did not convert (which we called pseudo-positive examples) resulted in only a negligible improvement in AUC.
We represent the user history with a two-dimensional ar-ray of time intervals and event types. In section 2.3 we used one bucket of time, yet user histories are four weeks long in our dataset. We divide them into equi-width inter-vals where each interval is w days long. We vary the value of w from 1 to 28. We learn the importance weights  X  int for each time interval using the validation set. When width w is small, it allows us to capture finer patterns in the user history. On the other hand, by making w smaller, we reduce the amount of content in each cell of this two-dimensional array. This leads to data sparsity and worsens the individual cell-based scores computed for a user. For example, while a user and query may match reasonably well when their ag-gregated representation is a whole week, when compared on a daily basis they may look much less similar.

The best performance comes from w = 28, i.e., when the entire user history is put into one interval (Figure 6). This shows that the performance loss due to sparsity when w is decreased, outweighs the benefit of capturing finer user patterns. When w&lt; 28, we found that the model learned higher weights for more recent intervals than the older ones. For example, with w = 10 we get the weight of 0 . 76 for the most recent interval, 0 . 19 for the second interval, and only 0 . 05 for the oldest one. This shows that recent activities are a better indicator of conversion likelihood, as expected. Figure 2: Performance of our VSM approach. Figure 5: The effect of using non-relevant users.
User history consists of different kinds of events (such as page views, ad clicks and the like). Instead of treating them collectively as was done in the previous experiments, each event is divided into four event types: page views, search queries, organic and sponsored result clicks, and ad views. As described in Section 2.3, we construct a separate rep-resentation for each event type, score them, and then take a weighted linear combination of these scores (where the weights for the different event types,  X  type , are learned us-ing the validation set). By doing so, we achieved a marginal improvement of 0.005 in AUC over the 0.65 AUC achieved by the baseline (Section 4.1). More interestingly, we found that some event types are much more indicative of user interests than others. In Figure 7, we show the weights learned for the different event types using the validation set. Browsed page views seem to help the most in predicting conversions. Even though one might expect page views to be less predic-tive than other event types such as queries and clicks, in our dataset they have higher density (i.e., much more events of this type) compared to other event types.
TFIDF weighting of features has been central to the vector space models. The success of the TFIDF weighting scheme is due to its capturing the importance of features both within the document (TF) and in the entire collection (IDF).
In traditional IR, the TF function is based on the number of occurrences of the term within the document, namely, the raw term frequency which we will denote by n u,t .Inuser modeling there are multiple ways of defining n u,t .Wecon-sidered (1) number of days on which feature t appeared in the (time interval, event type) cell for user u (ie #days) and (2) number of times feature t appeared in the (time inter-val, event type) cell for user u (ie #occurrences ). While both forms of n u,t perform fairly similar, the best perfor-mance comes from the #days definition of n u,t . A likely explanation is that it captures sustained user interest in an activity for a conversion to happen. Additionally, #days is more robust, e.g., some Web pages reload automatically and can dramatically bloat the number of the occurrences, while their adverse effect on #days is significantly limited.
We evaluate four different forms of TF defined in terms of n u,t : boolean, log, natural, and ratio and different forms of and IDF functions (see Table 1). The results are shown in Figure 4. First, we note that the rightmost bar corresponds to no TFIDF weighting, i.e., TF = n u,t (natural), IDF =1 (no). It achieves an AUC of 0.56 while our best setting achieves AUC = 0.65. This shows the significance of TFIDF weighting in the vector space model for users.

Among the various TF forms, TF = n u,t P consistently the best across all forms of IDF. This is re-markable because we normally expect more active users to be more likely to convert, and vice versa. However, this TF form, normalized with respect to the total amount of user activity, shows that it is not necessarily the case. Instead, it is the user activity in a specific topic relative to her overall activity that leads to the best prediction performance.
Among the IDF variants, we found max { 0 , log ( N  X  df t (prob idf) to perform the best, with log ( N df ing the second and third spot.
To investigate the variation in performance over individ-ual campaigns, we divided the campaigns into 3 sets, large , medium and small ,wherethe large group contains the top one-third of the campaigns with the highest number of con-versions, while the small group contains the bottom one-third. We found that our approach performs well in all three groups, in fact it does better on the medium (0.657) and small (0.673) campaigns compared to the large ones (0.624). Since most methods suffer when they are trained on fewer positive examples, this is a nice advantage of our approach, as it seems it can be applied to these tail/small campaigns, where other methods, especially discriminative ones, struggle to perform. This can also explain why our approach did not benefit much from using pseudo-positive examplesbasedonuserswhoclickedontheadsbutdidnot immediately convert. These pseudo-positive examples typi-cally prove helpful on small campaigns where there are few positive examples. However, our approach already performs well on those campaigns.

In further analysis of large campaigns we found that these campaigns are quite diverse and are thus associated with a variety of goals (ad groups, in computational advertising terminology), and thus different kinds of users convert on them. In other words, there is more heterogeneity among the seed users in these campaigns (compare to the smaller ones), and when these diverse users are combined together during the query construction process, they weaken the signal and hurt the performance of our approach.
Audience selection/segmentation is an important task in marketing. Since customers have diverse interests and needs, marketing strategies that target individual segments per-form better than a single global strategy for the entire pop-ulation [6]. In this paper we formulated the problem of audi-ence selection in display advertising within the IR paradigm.
Our approach has similarities to user profiling and behav-ioral targeting based on observed past events. A commonly used approach in behavioral targeting is to infer user inter-ests and use them to predict whether she will be interested in a product. Chen et al. [4] proposed a linear regression model to leverage user behavior for predicting ad clicks. However, learning regression models for conversions is difficult since conversions are typically several order of magnitude fewer than clicks. Another difficulty in modeling user behavior is that user interests are not always fixed, and some interests are transient, influenced by media and pop culture. Shmueli-Scheuer et al. [13] used a decay model to predict clicks to give recent features more emphasis. In their analysis of query in-terests, Wedig et al. [14] found that users tend to stabilize on a distribution of interests. In contrast, Liu et al. [9] found that user interests change from month to month based on their analysis of news topics and attributed this change to the task of browsing news (compare to the task of issuing queries studied by Wedig et al. [14]).

In their empirical study on understanding the potential of behavioral targeting for online advertising, Yan et al. [15] studied how ad click-through rates relate to the search queries and page views of the users who clicked on these ads. They found that users who clicked on the same ads tend to have more behavioral similarities than users who clicked on different ads. Our work builds on this hypothesis to perform audience selection, where we model user simi-larity using multiple sources of information, such as page views, clicks on search results, and the like, and not only ad clicks. We also focus on conversions rather than clicks. In particular, we first construct a query based on the seed set of users who converted in the past, and then execute this query against an index of user profiles. This allows us to retrieve more users who are similar to the seed set, and are therefore likely to convert in the future.
In this paper, we formulated the problem of audience se-lection as an information retrieval task, retrieving user pro-files instead of documents. These profiles are constructed based on users X  online actions such as browsing and search-ing. Unlike documents, which are often coherent units, user activity is composed of multiple events at distinct time points, each potentially having distinct intent. We then defined a formal retrieval model for the audience selection task based on language modeling and vector space modeling.

We found that both vector space and language models per-formed well for this task. We also found that using TFIDF feature weighting, as well as using a set of non-relevant users for Rocchio-style query expansion significantly improves per-formance. Although recent activity proved more important than past activity, bucketing based on time intervals de-graded performance, as it led to the sparsity of data.
We thank Fernando Diaz for his insightful comments.
