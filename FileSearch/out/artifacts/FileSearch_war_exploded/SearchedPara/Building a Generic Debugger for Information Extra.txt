 Complex information extraction (IE) pipelines are becom-ing an integral component of most text processing frame-works. We introduce a first system to help IE users ana-lyze extraction pipeline semantics and operator transforma-tions interactively while debugging. This allows the e ff ort to be proportional to the need, and to focus on the portions of the pipeline under the greatest suspicion. We present a generic debugger for running post-execution analysis of any IE pipeline consisting of arbitrary types of operators. For this, we propose an e ff ective provenance model for IE pipelines which captures a variety of operator types, ranging from those for which full to no specifications are available. We have evaluated our proposed algorithms and provenance model on large-scale real-world extraction pipelines. Categories and Subject Descriptors: H.4.0 Information Systems Applications: General General Terms: Algorithms Keywords: Information extraction, provenance
Information extraction (IE) systems identify structured information and, not surprisingly, IE systems are becom-ing a critical first-class operator in a large number of text-processing frameworks. As a concrete example, search en-gines are moving beyond a  X  X eyword in, document out X  paradigm to providing structured information relevant to users X  queries (e.g., providing contact information for busi-nesses when user queries involve business names). For this, search engines typically rely on having available large repos-itories of structured information generated from web pages or query logs using IE systems. With the increasing com-plexity of IE pipelines, a critical exercise for IE developers and even users is to debug , i.e., perform a thorough post-mortem analysis of the output generated by running an en-tire or partial extraction pipeline. Despite the popularity of IE pipelines, very little attention has been given to building e ff ective ways to trace the control or data flow through an extraction pipeline.

Prior work [14] recognizes the need for interactive debug-gers and proposes methods that use complete knowledge of how each operator functions. However, prior informa-tion regarding the specifications of the operators may not be available (e.g., o ff -the-shelf black-box operators). In the absence of full function specifications of an operator, the only (straightforward) approach to debugging is exploring all data in the pipeline. However, such an approach is clearly infeasible due to the sheer volume of data. For instance, de-bugging a simple pipeline involving 10 operators with 10,000 input records per operator would require 100K records to be manually examined; typical data sizes are even larger.
This paper presents PROBER (for Provenance-Based De-bugger), the first generic framework for debugging infor-mation extraction pipelines composed of arbitrary ( X  X lack-box X ) operators. A critical task towards building debuggers is that of tracing and linking output records from each op-erator and understanding their transformations across dif-ferent operators in the pipeline. To trace the lineage of any arbitrary record in the output, we propose a novel prove-nance model for IE pipelines. With debugging in mind, our provenance model tries to minimize the amount of user e ff ort necessary in resolving the fate of the records in the output. For example, provenance for (incorrect) output records only refer to input tuples that impacted this output record.
While IE pipelines may vary in their implementation logic [1, 11, 12, 13] several underlying common components can be abstracted from the implementation details. We characterize information extraction pipelines for the task of performing post-mortem analysis.

Definition 2.1. [Record] A record r is a basic unit of data (e.g., a tuple), consisting of a globally unique identifier I ( r ) ,andvalue V ( r ) .Weuse R to denote the set of all records.  X 
Definition 2.2. [Operator] An operator is defined by afunction O :( I 1 ,I 2 ,  X  X  X  ,I N )  X  R ,whereeach I i  X  R is a set of records. In practice, the function O may be unknown to us.  X  Intuitively, an operator takes as input an N -tuple of sets of records and outputs one set of records. Specifications on how an operator generates an output record may be available in Figure 1: Example of an IE pipeline to generate business names and their contact information. varying forms. Specifically, we consider the following four scenarios involving operator specifications.

An operator is said to be a black-box if we have no informa-tion about it. In this case, naturally, the only way to gain information about a black-box operator is by executing it on input sets of records. In contrast, we have exact informa-tion about an operator O if we know precisely which input records contributed to each output record, and how .We have Input-Output (IO) specifications when for each output record, we know which input records were used to construct it, however exactly how a record is generated is unknown to us. Finally, we may have integrity constraints ,e.g.,key-foreign key relationships, satisfied by the input and output records. For instance, an operator may support a  X  X ebug X  mode where each output record is assigned an id associated with the input records that generated it. E ff ectively, using key-foreign keys we have the same information as that in IO specifications, but this information is (indirectly) avail-able using dependencies on the values of fields in input and output records.

Next, we define various (standard) properties of an op-erator, that help design specialized algorithms for building provenance and debugging e ff ectively. As we will see later, these properties may be learned by sampling or the operator specifications (when available) described above.

Definition 2.3. [Properties]  X  (a) I = n i =1 I i (b)  X  i = j :( I i  X  I j )=  X  .
Definition 2.4. [Extraction Pipeline] An extraction pipeline P is defined by a DAG G ( V, E ) consisting of a set V of nodes and a set E of edges where each node v  X  V corresponds to an operator O in the pipeline. An edge a  X  b between nodes a and b indicates that the output from the op-erator represented by a is input to operator represented by b . We have a single special node s  X  V with no incoming edges representing the operator that takes input to the pipeline, and one special node t  X  V with no outgoing edges representing the operator that outputs the final set of records.  X 
Figure 1 shows a real-world extraction pipeline, Business , for building a large collection of businesses by extracting records of the form n, a, p , where business n is located at address a with contact number p . The first step is to build a set of web pages likely to contain information regarding businesses which is done using a variety of document re-trieval strategies. Specifically, we issue manually generated domain-dependent queries (e.g., X  X oyota car dealership loca-tions X ) as well as use form filling methods where entries such as model, make, and zipcode may be filled in order to fetch a list of car dealerships. This operator, denoted by wb is an example of a black-box operator with arbitrary properties.
Given a collection of web pages, operator sg parses the html page and identifies appropriate segments of text in this page, where ideally, each segment contains a complete tar-get record (see Figure 2 for a real-world example). These segments are then processed by operators, ad and pn , which respectively identify an occurrence of an address and a phone number. The annotation from one operator is used by the subsequent operator to identify regions of text that should not be processed. ad and pn are implemented using hand-crafted patterns based on a dictionary of address formats. The nm operator on the other hand needs to identify names of business which may be arbitrary strings and for this, we follow a wrapper-induction approach. In particular, using some training examples we learn a wrapper rule to identify candidate business names; these rules are based on the docu-ment structure of the html content. Of course, several other implementations for each of these operators are possible and the implementation details are orthogonal to our discussion since our goal is to build debuggers for pipelines with black-box operators where no implementation information may be available. The jn operator joins outupt from ad , pn , and nm to build candidate output records which are, in turn, pro-cessed by dp to eliminate duplicates. The final operator, assignes a confidence score sc to each output record.
We note that all our implementations of the above op-erators are monotonic. (Obviously, there may be non-monotonic implementations in other pipelines, but we pri-marily consider monotonic operators in this paper.) Al-though monotonic, the operators from the pipeline span a variety of properties, e.g., segmentation is a one-to-many operation, and by design one address is extracted from each segment, so address extraction is one-to-one , while de-duplication is many-to-one . Candidate webpage generation and wrapper training, on the other hand are arbitrary, i.e.  X  many-to-many  X .

Given unexpected output records, an IE developer may want to answer some natural questions about the out-put [14]. (Figure 2 shows an example where sg generates an incorrect segment that leads to missing one address and extracting one incorrect address.) Specifically, a developer may be interested in tracing all or part of the input records that contributed to a particular output record. For instance, given an incorrectly extracted record, we would like to know only the relevant subset of webpages and training data that impacted it, i.e., the minimal amount of input data neces-sary to identify the error. Motivated by the above observa-tions, we focus on the following problem in the PROBER system.

Problem 3.1. Given a pipeline P ,input I ,andpartial information about operators in P ,wewouldliketo(1)build provenance for the set of (intermediate and final) records in the pipeline; (2) expose provenance to developers through a query language and guide them in debugging the pipeline.
The notion of provenance is relatively well-understood for traditional relational databases (refer [6, 16]). A commonly advocated model [2] is to use a boolean-formula provenance, e.g., S 1  X  ( S 2  X   X  S 3 ). For the purpose of debugging extrac-tion pipelines, such provenance models are not appropriate for two main reasons. First, unlike relational queries where the exact specifications of each operator are known, we may have black-box operators in our extraction pipeline. Second, for debugging, ideally we would like to limit the number of records (and simplify their interdependencies typically rep-resented as boolean formulas for relational operators) a hu-man has to assess in order to understand the issue at hand. With these in mind, we define a provenance model based on minimal subsets of operator inputs that capture neces-sary information (Section 4.1) and extend this basic model to operators where multiple minimal subsets may exist (Sec-tion 4.2) .
To define the provenance of an IE pipeline P ,webegin by defining the provenance for each operator in P ;weomit details on how to construct the provenance for each opera-tor in P due to space constraints. We confine ourselves to extraction pipelines consisting of only monotonic operators (see Definition 2.3), which are a common case in practice (as in our motivating example from Section 2). We define the provenance of a monotonic extraction operator O based on the provenance for each output record r  X  R for O as in the definition below:
Ideally, we would like the provenance of r to represent precisely the set of records that contributed to r , however, as we will see, in practice it may not be possible to always determine the precise set of contributing records (e.g., in the absence of exact information about O ), and even if possible it may be computationally intractable. For our goal of build-ing a debugger, we observe that one of the main operations we expect users to perform is look at an (erroneous) output record r , and explore its provenance to determine the cause of this error. Therefore, a suitable provenance model is one that enables users to examine the fewest records required to decide the fate of an output record r . Formally, we define a basic unit of provenance, called MISet as follows:
Definition 4.1. [MISet] Given an operator O ,itsin-put I and output R ,wesaythat I s  X  I is a Minimal Subset (MISet) of r  X  R if and only if: (1) r  X  O ( I s ) ;and(2)  X  I  X  I s : r  X  O ( I ) .Weuse M a ll ( O, I, r  X  R ) to de-note the set of all MISets of O for input I and output record r  X  R .  X  Intuitively, an MISet gives the fewest input records required for a particular output record r to be present. Therefore, an MISet provides users with one possible reason for the oc-currence of r . This, in turn, reduces the burden of manual annotation on the users; in the absence of MISets, a user may have to explore the entire input to understand what caused an error in the output. The notion of MISets pri-marily focuses on debugging the presence of records in the output.

We note that the notion of MISets has been proposed in the past [4] in the context of relational operations (called minimal witnesses ). In practice, we may have more than one MISet possible for an output record as shown by the fol-lowing example. Therefore, in the context of debugging ex-traction operators, we study the handling of non-uniqueness of MISets, and propose provenance definitions and construc-tion algorithms based on combinations of MISets to facilitate debugging.

In practice, we may have more than one MISet possible for an output record as shown by the following example.
Example 4.1. Consider a (simple) record validation op-erator (e.g., sc in Figure 1) that computes the  X  X upport X  of each record and outputs only records with su ffi cient support. Suppose sc outputs a record r if there are atleast 50 input records supporting it. Given an input of 100 records that could support r ,theMISetfor r is any subset of the input records of exactly 50 records.  X  When multiple MISets are available, several ways of building provenance are possible, each di ff ering in the extent to which they impact information and execution speed.
Several formalisms for provenance model are possible when multiple MISets are available. We rigorously exam-ine compositions of MISets, while capturing the spectrum of complete (and potentially intractable) provenance, to more tractable (but approximate) provenance.

Consider an operator O which consumes input I and gen-erates output R ; for a record r  X  R , we denote the prove-nance of r as P ( O, I, r ). We use subscripts P  X  to capture various types of provenance and when clear from the con-text, we simply use P  X  ( r ) to denote P  X  ( O, I, r ). All-and Any-provenance: Ideally for any output record, we would like to provide all possible information using MIS-ets, i.e., capture all possible  X  X auses X  of an output record. Definition 4.2. [All-provenance] Given an operator O ,input I ,output R ,and r  X  R ,wedefine all-provenance as P a ll ( r )= M a ll ( O, I, r  X  R ) .  X  In many cases P a ll may be intractable to compute or store, and we may need to resort to  X  X pproximations X  of it, pre-sented shortly. Alternatively, we may want to find any one (or k ) MISets.

Definition 4.3. [Any-provenance] Given integer k&gt; 0 ,operator O ,input I ,output R ,and r  X  R ,wede-fine any-provenance as any P a ny ( r )  X  P a ll ( r ) of size min( k, | P a ll ( r ) | ) .  X  Impact-provenance: Given restricted amount of editorial resources, we may want to explore the most impactful ,i.e., top-l input records sorted by their impact instead of any-k MISets. Our next definition of provenance ranks tuples based on their expected impact on the output record, mea-sured by the number of MISets in which a tuple is present.
Definition 4.4. [Impact-provenance] Given an op-erator O ,input I ,output R ,and r  X  R ,wedefine impact-provenance as P i mp ( r )= { ( i, c i ) |  X  M  X  P a ll ,i  X  M, c Union-and Intersection-provenance: Our next goal is to summarize P a ll using two approximations: (1) We obtain an  X  X pper bound X  provenance that captures the set of all inputs possible for r , instead of exact combinations of in-puts. Therefore, we define the union-provenance of r to be the union of all its MISets. (2) We obtain a  X  X ower bound X  provenance that captures the set of all possible inputs nec-essary for r ; we define the intersection-provenance of r to be the common input records among all MISets.

Definition 4.5. [Union-Provenance] Given an oper-ator O ,input I ,output R ,and r  X  R ,wedefine union-provenance as P u ni ( o )= I
Definition 4.6. [Intersection-Provenance] Given an operator O ,input I ,output R ,and r  X  R ,wedefine intersection-provenance as P i nt ( o )= I  X  It can be seen easily that for operators with unique MISets, P
Recent work [7, 8, 9, 10, 15] has looked at providing explo-ration phases to determine if a text database is appropriate for an IE task, but little or no insight is provided into why unexpected results are produced, and how to debug them. There is a large body of work on provenance for relational data (refer [6, 16]), and more recently [3] on understanding provenance information, which not address the problem of building provenance for black-box operators to facilitate IE debugging with minimal editorial e ff ort, the primary goal of our work. Our recent work [14] considered debugging for iterative IE, and [5] looked at provenance for non-answers in results of extracted data. However, these papers assumed complete knowledge of each operator in some form. Also, in [14], we considered a specific type of extraction, namely iterative information extraction and studied how a simple  X  X rovenance structure X  helped debugging. In this paper, we provide a system for constructing provenance for ad-hoc de-bugging tasks for any extraction pipeline with black-box op-erators.
