 1. Introduction
The various types of engagement in digital libraries (DLs), such as funding developmental stages or devot-ing important shares in the acquisition of access has drawn considerable attention to the evaluation of these systems during the late period. The term digital library is vast, covers many and different applications and has been used interchangeably for systems, like digitized collections, e-journals platforms, network databases, library websites, etc. Moreover the current electronic publishing business models enrich the DL technology aiming to provide powerful information access options to the users. However despite the polymorphous nat-ure of DLs, one feature is stable: information provision through networked systems.

The advance of open access systems increases the complexity and diversity of DLs because the collection development requires the involvement of new actors; e.g. authors submit their own original material, system editors check and approve the corresponding metadata, etc. Although a significant amount of research is noted on the evaluation of commercial or research DLs, the equivalent work is not dedicated to the freely accessible DLs. However the evaluation of such systems is imperative, due to their worldwide acceptability and usage, but their special characteristics perplex the whole process of evaluation. Different types of evalu-ation are proposed and various approaches are followed. Their majority is concentrated on the intrusion of these systems to the scholar population and the effect of the social, economic and technologic environment on their embracement.

In the present paper the prime investigation aim is to define which content and system features most sig-nificantly affect the usefulness and usability levels of an Open Access (OA) repository. In particular a user-cen-tered evaluation approach is presented and applied to the subject repository E-LIS ( http://eprints.rclis.org ), which is an e-print archive in the field of library and information science. This investigation is done by apply-ing a DL evaluation framework  X  with a special interest on usability and usefulness  X  on important attributes and functionalities of E-LIS.

Section 2 resumes the scientific literature in regard to evaluation of DLs and OA systems. Section 3 presents the research setting in terms of problem, aims and models employed. Section 4 presents the methodology of the current study, while Section 5 presents the results. Section 6 is dedicated to the discussion of the main find-ings and Section 7 summarizes and suggests further research steps. 2. Literature review
There are various DL evaluation initiatives that use different protocols and models; some of them contin-uously tested, other created or adapted to fit to specific systems and needs. Among the various concepts under investigation, two have gained significant attention in user-centered evaluation, namely usefulness and usabil-ity. Originating from the fields of information behaviour and human X  X omputer interaction respectively, they both hold significant role in pursue of user satisfaction and system usage, as they study users X  interaction with representations of information systems and information objects. While the information behaviour domain concentrates on the dynamic expression of user activities in a given context and may identify areas in system usage that require improvement, human X  X omputer interaction aims  X  through user-centered approaches  X  at the development of systems that enhance user performance and satisfaction.

Ja  X  rvelin and Ingwersen (2004) have based the formation and analysis of user X  X  cognitive processes and information seeking behaviour on the interactivity between the user and information resources structural ele-ments (e.g. systems, items and interfaces). The effect of information sources structure have been acknowledged in the information behaviour literature as one of the many intervening variables in the information seeking process, that can be  X  X  supportive of information use, as well as preventive  X  X  ( Wilson, 1999 ).

The user interaction with content and system has been used in the area of information architecture for the purposes of effective DL design. Toms (2002) has used this tri-polar structure as a platform, where users X  infor-mation seeking behaviour takes place, and upon this platform proposes ways of extracting meaningful design suggestions. Several empirical studies have demonstrated that usability problems, i.e. design inefficiencies, can disrupt user X  X  information searching activity and affect information task accomplishment. Kim (2002) has employed DLISP model to match information searching expressions with usability problems, while Stel-maszewska and Blandford (2002) have demonstrated the need for effective usability design in DLs for assisting the creation of information searching strategies. Current studies in the DL area ( Chowdhury, Landoni, &amp; Gibb, 2006 ) show that there is a consensus in the research community for unified treatment of the two concepts.
Additionally, the interest on the concepts of DL usefulness and usability is reinforced by the opinions of the users themselves. Xie (2006) collected user identified DL evaluation criteria, analyzed and classified them in five categories, namely usability, collection quality, service quality, system performance efficiency and users opinions. The principal finding was that  X  X  users like to apply the least effort principle to finding useful informa-tion to solve their problems  X  X . Results of a similar study by Kani-Zabihi, Ghinea, and Chen (2006) designate that users prefer learnable and reliable DLs, than aesthetically pleasant and supportive ones. The authors of the study examined the users X  preferences on system functionalities, interface usability and content and found that learnability and reliability were prerequisites for DL satisfaction for all types of participants (from novices to experts).

Similarly the two concepts have been extendedly discussed in the field of information systems (IS) manage-ment. Technology Acceptance Model (TAM) is widely used in the field of IS success and it has been used in prior studies of predictive usage of digital libraries ( Hong, Thong, Hong, &amp; Tam, 2002; Thong, Hong, &amp; Tam, 2002 ), search engines ( Liaw &amp; Huang, 2003 ) and portals ( Yang, Cai, Zhou, &amp; Zhou, 2004 ). TAM exploits users X  perceptions of usefulness and ease of use of an information system, relates them with external variables of users X  profile and combines them to predict attitudes and actual usage. According to the Delone and
McLean (1992) , one of the eminent models in IS success, system and information quality affect seriously user satisfaction. Therefore the qualitative properties of the system and the information provided can improve sys-tem X  X  use and consequently affect the organizational performance.

Concerning the DL evaluation methodology Bertot, Snead, Jaeger, and McClure (2006) report an iterative campaign based on the system-driven concepts of functionality, usability and accessibility. One of the main suggestions by the authors is that evaluation activities  X  in order to assist the formation of a holistic picture for user interactivity and to extract easier a set of implications on system design  X  should be based on a num-ber of constructs (evaluation concepts), rather than to focus on one. Accordingly, DigiQUAL ( Kyrillidou &amp;
Giersch, 2005 ), which has its origins in the field of service quality in the library sector and aims to be extended to the digital space of service provision, covers areas such as design features, accessibility/navigability, inter-operability, DL as community for users, developers and reviewers, collection building, role of federations, copyright, resource use, evaluating collections and DL sustainability. It is quite evident that the level of focus depends on several parameters, such as the purpose of the research, the macroscopic view of the evaluation, the object of the evaluation, etc. Saracevic (2004) , in a meta-analysis study of the current evaluation practices, has classified the various parameters in four main categories, namely construct, context, criteria and method-ology. This classification supports any description endeavour and differentiates each evaluation initiative for the sake of meaningful comparison. The need for identification of such parameters is recognized by the DL evaluation community ( Fuhr, Hansen, Mabe, Micsik, &amp; S X lvberg, 2002; Fuhr et al., in press ), by finding inte-gral components of the DL operation (such as content, system and user) and matching them to criteria, met-rics and methods.

Since the present paper focuses on OA systems some representative studies in this particular field are pre-sented. Although open access DLs and electronic information services have undergone various evaluations of their impact, their technological infrastructure ( Wyles, Maxwell, &amp; Yamog, 2006 ) and integration with library resources ( Center for Research Libraries, 2006 ), there are a few studies concerning the interaction of the users with such systems. By the number of user studies it can be figured out that the acceptability of these systems and the corresponding services by the scientific community is an attractive research issue. Nicholas, Hunting-ton, and Rowlands (2005) gathered the opinions of a world wide sample of scientific authors to estimate the rate of adoption of OA publishing schemas and to compare it with the dominant publishing habitus. They showed that scholars from disciplines that have dominant subject repositories, like physicists, computer scien-tists and economists, relate OA with the notion of  X  X  X ood access X  X  to electronic resources. Kurata, Matsubay-ashi, Mine, Muranushi, and Ueda (2006) showed that the usage of e-prints servers in Japan is limited to specific disciplines, such as physicists, and that electronic journals remain the principle vehicle of scientific communication. Their results also show that the highest levels of preference for alternative publishing means, such as e-prints, are traced in disciplines that have strong backgrounds in subject-based repositories, such as physics (which is supported by the Arxiv repository, http://www.arxiv.org ). This is supported by several stud-ies supporting the argument that scholars in various disciplines are favourable to self-archiving, due to the existence of dominant subject repositories ( Swan &amp; Brown, 2005 ). However Andrew (2003) and Davis and
Connolly (2007) mention that, unlike scholars from other disciplines, physicists in their respective studies do not self-archive their research outcome in institutional repositories, because of the existence of Arxiv.
Despite all these conflicts, one definite outcome of the various studies is that scholars from disciplines that facilitate subject repositories are aware of the self-archiving processes, while as an explanation of this paradox can be proposed the type of OA vehicle (e.g. repository, journal) in which they self-archive and the associated rewards.

Digital repositories, either subject-based, or institutional, conjoin with two different types of usage: archiv-ing, or input activity according to Luce (2001) , and actual usage. While there are studies examining the use of digital repositories ( Correia &amp; Castro Neto, 2002 ), the major part of these studies show that the self-archiving aspect of these systems X  use is associated with publication aspects (e.g. visibility, preservation and durability of work), communication and self-related benefits (e.g. funding and curriculum strengthening) ( Kim, 2005; Kim, 2006; Rowlands &amp; Nicholas, 2005 ). The literature also shows that the interest in OA systems is concentrated on electronic journals and institutional repositories, presumably because of the association of these repository variations with the previously mentioned benefits. This makes easier the application of various means for the growth of collection and the improvement in quality terms of the repositories, such as mandating policies or peer-review processes, but it is not easy to apply in the cases of subject-oriented repositories. The above studies also suggest that the acceptability and the adoption of OA e-print systems (in their various formulations) is related to contextual factors, strongly linked with traditional structures and mechanisms of the scholar envi-ronment, and require the development of several synergies between scholars, libraries, funding agencies, gov-ernment and non-government organizations and other agents.

Hitchcock et al. (2002) evaluated the usefulness and usability of the open-access bibliographic service Cite-base. Although this formative evaluation campaign demonstrated a useful and usable system, problems with the coverage and the navigation ability were reported. Despite the fact that Citebase is not a DL, but a biblio-graphic service that in parallel provides access to full text, where available, the results showed problems concern-ing the features of content and system. Silva, Laender, and Gonc  X alves (2007) examined the various aspects of input activity in the BDBComp self-archiving system. In their usability study they recorded the average submis-sion time under different conditions, such as users X  experience, expertise and content types, and gathered their opinions on easiness to use the e-print archive, comfort and usefulness. On the other hand, Kim (2005) investi-gated several aspects of the usage activity of two digital repositories systems, namely DSpace and Eprints, in the context of Australian National University institutional repository. He went on to count the time demands of the systems, their error proneness and user satisfaction. Concluding the evaluation activities of OA systems, beyond issues commonly used in the evaluation of DLs (such as multi-constructness), involves also the examination of aspects related to their purpose and their typical user tasks X  supporting processes. 3. Research setting
As literature suggests, user-centered evaluation of a DL should be multi-constructed, capable to capture a panoramic view of users X  opinions, able to take into account their characteristics and grounded on their per-ceptions and goals. Thus for the aims of this research Interaction Triptych Framework was used (ITF) ( Fuhr et al., in press; Tsakonas, Kapidakis, &amp; Papatheodorou, 2004 ), which is a theoretical model that attempts to integrate knowledge and experience from the fields of information behaviour and human computer interac-tion. ITF is based on the concept of DL components interaction. Each DL is consisted by three main com-ponents, namely system, content and user. Each component interacts with the other two and each interaction defines an evaluation axis, which is considered as the resultant of a set of descriptive attributes of that interaction. In particular the interactions between the three components (i.e. the evaluation axes) are defined as usability, usefulness and performance and each of them is a resultant of a number of attributes, which are considered as evaluation variables ( Fig. 1 ). ITF complies with the requirements extracted by the previous experience as (a) it fulfils the multi-construct requirement since it has the ability to explore the two main categories of user-centered interest in DL evaluation, (b) it provides quick and convenient view of the users X  opinions on critical factors of the evaluated system, allowing further exploration with different methodologies, and (c) it takes into consideration important variables of the users X  profile and attitude.
The following subsections present analytically the evaluation axes and their components attributes. 3.1. Usefulness The concept of usefulness defines whether DLs constitute valuable tools for the completion of users X  tasks.
Usefulness answers the questions if DLs support users X  information needs and work completion. Users X  work tasks are formed by their social and organizational context and responds to needs like research, authorship, etc. Users seek in DLs the appropriate resources for their work tasks, both relevant, in terms of subject prox-imity, and  X  X  X ntegrateable X  X , in terms of content morphology. On the other hand information tasks include all actions related to need formulation, need expression, querying, relevance assessment, all combined and exe-cuted in an iterative manner. During all those phases of information seeking activity there are common attri-butes that are expressed either as requirements or criteria, depending on the stage of the information seeking procedure. ITF summarizes these attributes into relevance, reliability, level of the provided information, for-mat and temporal coverage.

Hong et al. (2002) report that system features have effect on both users X  perceptions of ease of use and use-fulness. However relevance, which is considered as a system feature, was related only to perceived usefulness.
The authors interpret this relation as the association of relevance to the content of the DL. Liu (2004) signifies the importance of information reliability and credibility for the selection of the appropriate resources, while
Vakkari and Hakala (2000) include in their relevance criteria the level of the provided information. Moreover users X  information searching behaviour has demonstrated that despite retrieval of full text resources is signif-icant, other levels of information, such as abstracts, are also preferred ( Wolfram &amp; Xie, 2002 ), probably due to the content overview they provide to users ( Krottmaier, 2002 ). Current evaluation practices involve recording and analysis of usage statistics based on users X  format preferences, such as .pdf and .html file formats ( Mercer, 2000 ). Xie (2004) includes content coverage among the important components of an information retrieval sys-tem and associates it with other attributes of the information resources, such as reliability and level, while the library community ( Brennan, Burkhardt, McMullen, &amp; Wallace, 1999 ) jointly assesses the ratio of coverage and level in pursue of collection quality. 3.2. Usability
Usability stands on the user-system axis, focuses on the effective, efficient and satisfactory task accomplish-ment and aims to support a normal and uninterrupted interaction between the user and the system. DL com-munity has shown an increasing interest in usability and through the research activities a set of attributes have been identified, such as ease of use, terminology, navigation, aesthetic appearance, learnability. Easiness of use is considered as a crucial attribute of DL interaction, especially in advanced systems, like aggregated search interfaces ( Park, 2000 ). Previous usability studies ( Ebenezer, 2003; McMullen, 2001 ) have shown that termi-nology raises important barriers in user X  X  understanding of principal functions and contribute to negative changes in their affective state. Navigation is considered as an important factor contributing to the improve-ment of users X  performance, as they are able to trace their place in the DL and to direct to previous or next destinations ( Hartson, Shivakumar, &amp; Pe  X  rez-Quin  X  ones, 2004; Theng, Duncker, Mohd-Nasir, Buchanan, &amp;
Thimbleby, 1999 ). Additionally the aesthetic appearance and layout has a crucial role to the overall satisfac-tion rate ( Jackson, 2001 ). Van House (1996) suggested a simplified interface that would reduce users X  efforts and recent usability studies have concentrated on the effect of inappropriate visual layout to user interaction ( Allen, 2002; Cockrell &amp; Jayne, 2002; Fuller &amp; Hinegardner, 2001 ). Finally some researchers have emphasized on the ability of a DL to be easy to learn in order to improve user familiarity and performance ( Ferreira &amp;
Pithan, 2005; Jeng, 2005; Sutcliffe, Ennis, &amp; Hu, 2000 ). 3.3. Performance
Performance evaluation is often a system-centered process, based on quantitative data and does not involve real users. Precision (the ratio of relevant items that were retrieved to a set of retrieved items) and recall (the ratio of relevant items retrieved to a set of relevant items of a collection) are the main metrics, which are trans-ferred from the field of Information Retrieval. With the advance of networked systems other metrics are intro-duced, such as response time ( Kobayashi &amp; Takeda, 2000 ). Response time is considered as a metric sensitive to the subjective judgement of users and is often reported by end users as a criterion for the adoption of a DL.
The proliferation of mechanisms for the retrieval from the internet and the empowerment of the users have initiated a discussion about the extension of IR metrics in order to cover new aspects, such as the search engine design and functionalities ( Landoni &amp; Bell, 2000 ). 4. Methodology 4.1. Aim of the research
The present study seeks to find which DL interaction attributes affect most significantly E-LIS usefulness and usability. This is obtained using two tools: (a) following an online questionnaire survey and inferential statistical analysis to define these attributes, and (b) using regression analysis to identify their predictive strength, as well as the impact of the system X  X  functionalities. 4.2. Evaluated system  X  E-LIS
According to the repositories typology proposed by Heery and Anderson (2005) , E-LIS is an international e-print archive that holds full text pre-print and post-print documents and their metadata and provides enhanced access to researchers in the domain of field of librarianship and information science. E-LIS X  func-tionalities provide: free access to content through simple and advanced search interfaces and various indices, personalized access for document submission or review and approval (according to user roles and rights), and several other tools and peripheral services, such as document interlinking or email-based awareness. E-LIS is an effort that covers more than 80 countries and hosts more than 6000 documents in many different languages (as of July 9, 2007). The main requirements for the inclusion of archives in E-LIS are domain relevance and document integrity for the promotion of scientific communication. E-LIS is grounded on a solid and vivid international community, which has structured communication channels and organized dissemination events for the achievement of internal consistency. In each country-member there are one or more editors who are responsible for the promotion of E-LIS, the support of native users and the control of the deposited archives. 4.3. Data collection procedure and instrument
Data for this survey were gathered by an online questionnaire. The selection of this procedure was sug-gested due to the geographical dispersion of the E-LIS community, the time saving aspect and the ability of the instrument to gather in a quantitative manner the users X  opinions and satisfaction ( Covey, 2002 ; Allen, 2005 ). A call for participation was distributed to several national and international mailing lists by the respec-tive national E-LIS editors. Editors were also invited to take part in the survey, as well as the administrative personnel. The call was also visible on the main E-LIS website and the Greek website for a period of one month (May to June 2006). A total of 131 of valid questionnaires were collected for analysis, after the removal of duplicate and test submissions.

The questionnaire ( http://dlib.ionio.gr/~gtsak/e-lis ) consisted of thirty four (34) questions, structured in three main parts.

The first part (six questions) consisted of questions that asked users about their familiarity with E-LIS, the perceived usage, the attributed significance of E-LIS in their information seeking activity and the potential dedication of time and effort to retrieve the desired information. The second and more important part (16 questions) investigated the role of the usefulness, usability and performance attributes on the evaluation of
E-LIS DL interaction. In detail, it consisted of three subsets of questions each one corresponding to the con-cept of usefulness, usability and performance respectively. Each subset included also a final question measur-ing the overall satisfaction with the related concept. The last part of the questionnaire (12 questions) examined the relative influence of the E-LIS functionalities on the concepts of usefulness and usability. In all question-naire parts, participants were invited to deposit their degree of agreement to a number of statements through a five-point Likert scale (from  X  X  X isagree X  X  to  X  X  X gree X  X ).

Reliability of the research instrument was measured. Cronbach alpha tests were conducted separately for each group of items and rates were high for every group and every separate item, respectively ( Table 1 ), super-seding the 0.70 threshold proposed by Nunnaly and Bernstein (1994) . There was an exception in the question 3.2 (Response Time), which scored higher than the value of its group, but the difference was not considered that affected drastically the group X  X  value. 5. Results 5.1. Characteristics of the participants
Table 2 presents the respondents X  relation with the archive, such as role, geographic area (continent-wide) and E-LIS X  introduction channel. The results show that almost half of the participants were unregistered users, indicating an equal readership degree of E-LIS compared to its active membership. The results also show that
E-LIS has a plenitude of dissemination channels, which introduce the service to the potential users. It is notice-able that almost half of the respondents learned about E-LIS by informal means, like their own searches in the Internet or personal communication with friends and peers.

Table 3 presents the results of the questions reflecting users X  characteristics. Participants reported their usage frequency, appointed significance and intention to spent time and effort to complete successfully their work tasks through E-LIS. Although the average usage of the DL is below the mean value of the users X  rates, there is a normal distribution recorded that indicates several types of usage, from very frequent to infrequent.
Accordingly, participants appoint mediocre importance to E-LIS in their regular information seeking activity, while they are more positive towards the statements of spending significant amounts of time and effort to com-plete their information tasks.

Cross-tabulation of the E-LIS role and the usage revealed that usage is consistently increased when the type of respondent indicates an active role, such as editor (Agree n = 10) or Registered User (Agree n = 11). Like-wise E-LIS significance and intention to spent the needed time and effort for the retrieval of the desired infor-mation increase as the participants report more intense usage (Agree n = 10 in all cases). Analysis of Variance reported that the factor of E-LIS X  role shows considerable differences at the questions of usage ( F = 9.016, p &gt; .001) and appointed significance ( F = 3.466, p &gt; .010). However there are non-significant differences at the questions for time ( F = 0.984, p &gt; .419) and effort spent ( F = 1.059, p &gt; .380). The same pattern was observed at the reverse cross-tabulation where the factor usage showed significant differences with role ( F = 13.913, p &gt; .001) and appointed significance ( F = 40.399, p &gt; .001), but did not show with time the results in terms of role and usage factors. This analysis is followed because (a) usage is considered a critical factor for creating and classifying user profiles, as it implies experience in effective and efficient use of DLs and (b) the role in the archive is introduced by the system X  X  nature and accordingly suggests some sort of experi-ence with the related processes (input/usage activities). 5.2. Results on axes and features
This section reports the findings of the second part of the questionnaire, which focused on the significance of usefulness, usability and performance attributes. Table 4 presents the participants X  answers, which demon-strates in general a positive attitude towards each attribute.
 5.2.1. Usefulness questions
All of the usefulness features (1.1 X 1.5) scored high rates, indicating a very positive attitude towards the use-fulness attributes. However, the only feature that failed to clearly satisfy users is Coverage. It seems that the participants were not satisfied entirely with the content coverage of E-LIS. The comparison of responses between different roles demonstrated that participants with more active role in the system are more favourable to E-LIS coverage (Editors x  X  3 : 88, SD = 1.11 and Registered Users x  X  3 : 75, SD = 0.94), while Unregis-tered Users are not completely satisfied by the content quantity found in it ( x  X  3 : 09, SD = 1.09). Those who reported very rare use disagreed with the statement of satisfaction of coverage ( x  X  2 : 67, SD = 1.17), while those who reported very often use stated also their agreement with the statement ( x  X  4 : 12,
SD = 1.05). ANOVA showed that the role and usage factors differentiate significantly the behaviour of the sub-samples ( p &lt; .001 for all features in the usefulness category). 5.2.2. Usability questions
In the usability category (2.1 X 2.5), Ease of Use and Learnability scored very high mean rates (4.06 and 4.08, respectively). Once again users with active presence in the archive consider E-LIS as very easy to use (Editors x  X  4 : 00, SD = 0.79 and Registered Users x  X  4 : 41, SD = 0.76), but those with little interference with formal roles do not share the same opinion to the same extend (Unregistered Users x  X  3 : 86, SD = 1.18). Similar were the results in the Learnability attribute, where Editors ( x  X  4 : 12, SD = 0.86) and Registered Users ( x  X  4 : 36, SD = 0.72) believe that E-LIS is a fairly learnable system, while the opinion of the Unregistered
Users was the same, but to a lesser degree ( x  X  3 : 89, SD = 1.10). Participants reporting very rare use do not consider E-LIS as an easy to use DL ( x  X  3 : 17, SD = 1.27) and they were in contrast with those who reported very often use ( x  X  4 : 44, SD = 0,65). Participants with very often use reported that E-LIS is an easy to learn DL as well ( x  X  4 : 32, SD = 0.75), but the participants with very rare use argued on its learnability ( x  X  3 : 08, SD = 1.28).
 A non-significant difference between the sub-groups representing different roles was traced in the case of
Learnability ( F = 2.314, p &gt; .05), while all other features showed significant differences at p &lt; .001 for Aes-thetic ( F = 7.410) and Terminology ( F = 5.558) and p &lt; .05 for Ease of Use ( F = 2.781) and Navigation ( F = 3.023). Significant differences were also found between the sub-groups based on usage at the levels of p &lt; .001 for Ease of Use ( F = 8.906), Aesthetic ( F = 7.806) and Navigation ( F = 5.820) and p &lt; .05 for Termi-nology ( F = 4.619) and Learnability ( F = 3.646). 5.2.3. Performance questions In the Performance category (3.1 X 3.3), the two dominating IR evaluation measures, Precision and
Recall, did not capture the preference of the participants. They did not supply a clear answer for their satisfaction with the Precision and the Recall of E-LIS. While Editors X  responses for Precision were above the mean value ( x  X  3 : 65, SD = 1.22) and were in accordance with the rates provided by Registered
Users ( x  X  3 : 61, SD = 0.92), Unregistered Users X  rates were below medium showing a disagreement about the ability of E-LIS to return precise results ( x  X  2 : 85, SD = 0.98). Similar were the results for Recall. Editors ( x  X  3 : 65, SD = 1.00) and Registered Users ( x  X  3 : 48, SD = 0.88) agreed that E-LIS could provide them the right number of results, but Unregistered Users demonstrated a negative attitude towards this feature ( x  X  2 : 94, SD = 0.96). Participants that reported very rare use believed that both Precision ( x  X  2 : 42, SD = 1.18) and Recall ( x  X  2 : 46, SD = 0.98) are not satisfactory. The participants with more frequent use of E-LIS declared their mediocre satisfaction with Precision ( x  X  3 : 76, SD = 1.05) and Recall ( x  X  3 : 84, SD = 0.90).

Significant differences were indicated at the level of p &lt; .001 for Precision ( F = 6.521) and Response Time ( F = 5.501), and p &lt; .05 for Recall ( F = 4.446). Participants with very low frequency of usage showed their disagreement with the statements of satisfaction in Precision ( x  X  2 : 42, SD = 1.18) and Recall ( x  X  2 : 46,
SD = 0.98). On contrast participants with high levels of usage agreed with the respective statements and pro-vided scores above medium ( x  X  3 : 76, SD = 1.05 for Precision and x  X  3 : 84, SD = 0.90 for Recall). Significant differences were reported for all types of reported usage ( p &lt; .001). 5.3. Inter-axes correlations
Although the presented results reflect participants X  opinions about the DLs features, the correlations that they assign to them and their categories were also investigated. Table 5 presents the inter-attribute Pearson correlations, all of which were found to be significant, ranging from r = 0.35 to r = 0.79. An overview of the table demonstrates significant correlations between Reliability and Format, Reliability and Level, and Coverage and Level for the usefulness category, Ease of Use and Navigation, Ease of Use and Learnability,
Navigation and Aesthetics and Terminology and Learnability for the usability category and Recall and Pre-cision for the performance category.

Similarly, Fig. 2 presents the inter-category correlation values. Participants correlate highly all categories between each other (all correlations are above 0.70), with most notable the correlation between usefulness and performance ( r = .839). In regard to the relation between usefulness and usability, the high correlation ( r = .798) verifies the assumption that the quality of user interaction depends strongly on both axes. 5.4. Predictive strength of factors
Stepwise multiple regression analysis was performed for each category of constructs in order to estimate their predictive strength. The attributes of each category were entered as independent variables and the regres-sion model was performed on a dependent variable that measured the overall quality of each category. Table 6 presents the results of stepwise multiple regressions for each category. The multicollinearity values of VIF and
Tolerance were calculated for each variable of the regression model. This check showed that all values were below 10 (min. = 1.496, max. = 3.369) and Tolerance were found more than .2, hence data multicollinearity was evaded.
 had a significant effect on the prediction for DL usefulness. The three attributes are responsible for the 65% of the observed variance. Four out of five usability attributes of the usability category produce the 63% of var-iance and have a significant effect at the p &lt; .01 level, while the fifth construct, Navigation, was excluded from the analysis ( t (126) = .534, p &gt; .05). The data in the Performance category reveal that Precision ( t (127) = 8.050, p &lt; .001) and Recall ( t (127) = 4.467, p &lt; .001) cause 66% of variance, when the remaining construct, Response Time ( t (127) = 1.713, p &gt; .05), has a non-significant effect. 5.5. E-LIS functionalities evaluation Table 7 presents the participants X  opinion on the questions of the third part of the questionnaire regarding
E-LIS functionalities and characteristics and how they affect the system X  X  overall usefulness and usability. The selected functionalities reflect adequately the E-LIS nature and its information management processes, which are the information discovery methods (e.g. search and browse), personalized delivery of services, peripheral services provision (e.g. e-mail alerts, cross-reference), its OA nature and finally the procedural phases (e.g. sub-mission, review, edit, delete of contributions, etc.). Participants exhibited a positive attitude towards all these functionalities (mean ranges from 3.31 to 4.08). In particular 50% of the participants strongly believe that E-
LIS is both useful and usable to them due to its open access (OA) nature, but they also believe in their majority that the personalized functionalities of E-LIS are not quite useful and usable.

Stepwise multiple regression analysis was repeated including as independent variables the system function-alities in investigation, to predict the overall usefulness and usability. Despite the fact that five of six function-alities (browsing, search, personal account, services and OA) are considered to cause the 55% of variance ( R 2 = 0.556, F = 31.312, p &lt; .001), only two of the functionalities possess significant strength to predict satis-faction on usefulness. In particular participants believe that the services provided by E-LIS ( t (125) = 3.227, p &lt; .05) and the fact that it is an OA system ( t (125) = 4.152, p &lt; .01) are enough to predict usefulness.
The OA nature of E-LIS was strengthened even more as it was conceived by the participants as a feature that the e-print archive provides ( t (125) = 2.317, p &lt; .05). Once again the above mentioned five functionalities are considered to capture 57% of usability variance ( R 2 5.6. Synopsis of results
In summary the results show that usefulness and usability are two related concepts that jointly affect user satisfaction. However the gravity of system performance was also exhibited and demanded adequate attention even in user-centered evaluations. Participants of the current study believe that usefulness can be predicted by the Open Access to relevant, levelled and widely covered information supported as well by peripheral services.
They also believe that E-LIS is considered as a usable system if it satisfies the conditions of Ease of Use, Aes-thetics, Terminology and Learnability. According to the participants, the level of usability is increased by the fact that E-LIS is an Open Access system and that provides certain personalized features. 6. Discussion
The present study reported differences in users X  opinions as their experience changes. Users X  experience, reflected in the reported usage and the role they have in the system, affects their perceptions about E-LIS use-fulness and usability. This conclusion validates prior studies X  findings ( Koohang &amp; Ondracek, 2005 )and makes them applicable in the field of digital repositories. Differences between experienced and novice users were also reported for performance of repositories usage ( Silva, Laender, &amp; Gonc  X alves, 2005 ). Whilst one can support that there are studies claiming no actual differences in the user performance between novice and experienced users of DLs ( Kengeri, Seals, Harley, Reddy, &amp; Fox, 1999 ), this does not infer a clear conflict among the various experimental findings, but indicates the need to exploit a wide range of methods and met-rics, especially in the usability field. The inclusion of editors and the administrative team aimed to strengthen the concept of experience and to provide a more detailed analysis, since the ANOVA test showed significance differences ( F = 9.016, p &gt; .01). Editors represent an important part of the mechanical process of self-archiving and possess knowledge of the system and content parameters. Despite argumentation on the bias that they may cause, the opinion of representative classes should be gathered as they typify different needs, requirements and behaviours. Therefore, the favourable attitude they expressed towards E-LIS X  usefulness and usability seems logical and explainable at the same time. In general, scholars from this discipline will apply some sort of bias on research studies, because of the high level of awareness on self-archiving processes. Swan and Brown (2005) have reported that 60% of the sample from this discipline, which was the highest among the various disciplines, knows what self-archiving encapsulates and that is a means towards OA publishing.

Concerning the other users X  characteristics, participants appoint mediocre importance to E-LIS when they execute their information seeking tasks. This low level of significance showed respectable differences only for the factor of usage ( F = 40.399, p = 0.001), which leads to the conclusion that system usage may affect the participants X  preference. Participants who frequently use E-LIS consider it as a regular channel for retrieving information and quite naturally assign to it high priority. Furthermore, users are committed to spend as much time and effort is needed in using E-LIS to find the information they want. Once again, users X  behaviour was significantly different between these two parameters (for Time F = 96.456, p = 0.001, while for Effort
F = 95.400, p = 0.001). Finally the introduction channels suggest an elaboration of the promotional and mar-keting means that the administration team employs. These results, which are in agreement with the results from other studies ( Allen, 2005; Hitchcock et al., 2002 ), request much more attention in the area of support and documentation, especially in cases of subject-oriented repositories, where spatial distribution restricts physical interaction with the served community.

Most of the usefulness attributes were highly appreciated by the users. However participants are not satis-fied by E-LIS Coverage. Apparently they prefer more uploaded content, ranging to many years, and their pref-erence is in accordance to the remarks of the Citebase subjects ( Hitchcock et al., 2002 ). As the authors of the
Citebase research note, the responsibility for content growth is transferred to the hands of the users them-selves. In addition raw statistic evidence, provided by the E-LIS administrative team, showed a steady increase in the collection size. Shearer (2003) also highlights the indissoluble connection between input activity and usage. This vice-versa relation explains the entrustment of depositing works in a repository of high usage and wide recognition, as well as the rate of usage according to the deposited material.

Users seem to prefer systems that provide them a structured and levelled presentation of information, which is relevant to their information tasks. However they do not appoint significance to the role of Format and Reliability. In the former attribute, this interesting exclusion can be credited to the deposit policy of the
DL, which allows only the PDF file format. The result for the latter attribute can be explained by the fact that the only prerequisite for the documents deposit in E-LIS is relevance and document integrity. Therefore it can be supported that users of such systems do not assign significance to reliability, due to their awareness that the content review and approval procedure does not employ reliability criteria. It is remarkable that both attri-butes are highly correlated ( r = 0.74).
 The five usability features scored high above the medium. Users reported their preference to Easiness of
Use and Learnability, while understandable Terminology and Aesthetics do not attain high levels of users X  preference. This allocation of preference is in accordance with conclusions by other studies, such as Kani-
Zabihi et al. (2006) . According to their findings, users give higher priority to the easy discovery of information and the high degree of familiarization with DL functionalities. Moreover, learnability remains one of the key factors for the acceptance of these systems and that is linked with the prospective benefits and the added value of the application ( Davis &amp; Connolly, 2007 ), while in the present study ANOVA demonstrates that learnabil-ity is the only widely preferred attribute, regardless the participants X  roles. In spite Navigation gained high scores by participants, it was not perceived as an important feature that affects overall opinion on DL usabil-ity. However literature reveals that navigation is considered an important factor that influences many of the traditional work tasks of librarians and information scientists ( Moyo, 2002 ). One possible explanation might be that the information scientists with the assistance of appropriate navigation tools and aids (such as indices, menu bars, etc.) have gained the experience needed and may overtake any obstacles in their navigation routes.
This experience is underlined by some DL development studies that highlight the role of experienced users, in the successful information discovery through navigation tools ( Xu, 2004 ).

Although not a primary aim of this study, following the theoretic foundations of ITF, the performance axis was also analyzed. Precision and Recall are considered the main factors that affect users X  opinion on system performance. Despite the dependence on factors that influence Response Time (e.g. traffic, webpage size, etc.) and the critical position in the evaluation of web-based systems, users expressed higher levels of preference to the  X  X  X raditional X  X  measurements of Precision and Recall.
It is very intriguing the fact that participants in this study believe that the open access nature of e-print archives makes them both useful and usable. This may be associated with the current trends of the scientific community to advocate open access. Participants in this study did not appreciate the provision of personalized services, but they were satisfied with the usefulness and usability of the browsing and searching features. These features allow users to retrieve documents in a wide number of methods, such as author, country or year indi-ces and advanced search interfaces. In the comparative usability study by Kim (2005) subjects using Eprints, upon which E-LIS is build, were more satisfied with the retrieval functionalities and made less time to con-clude their tasks, especially in tasks employing browsing and searching in simple search interfaces. Therefore, it can be concluded that the wealth and structure of retrieval tools outweighs the inefficiency of Eprints soft-ware to search on a full-text level, as reported by Goh et al. (2006) .

Furthermore participants in this study correlated very highly the Usefulness and Performance categories. A possible explanation is that participants are correlating particularly usefulness and performance due to their knowledge of the importance of these two concepts in the effective operation of a DL (also demonstrated in
Tsakonas &amp; Papatheodorou, 2006 ). As being information scientists that manage information objects and han-dle them under different criteria that are equivalent with the usefulness attributes of ITF (e.g. relevance and format), they know how these support users X  work tasks. At the same time they are aware of the significance of
IR evaluation criteria for the successful completion of their information searching activities. This high corre-lation value demonstrates that, despite the focus of the current study, user satisfaction is also dependent on the classic IR criteria and that content attributes are affecting system performance. 7. Conclusions
While commercial DLs have proved their degree of self-sustainability, e-print archives X  operation is depen-dent on many issues, either political, or economic. One of the major challenges that e-prints face is to become self-sustainable systems closely linked with users X  work tasks, instead of gradually transform into graveyards of invaluable documents. Although the issue of open access systems has gained significant attention and the consensus for their evaluation strengthens among the scientific community, there are not many studies con-centrating on usefulness and usability issues. In this study a theoretical model for DL evaluation was applied to assess the usefulness and usability of an OA digital library and it was attempted to demonstrate the signif-icant content and system attributes and how they affect user interaction and satisfaction. These attributes request research attention and in depth analysis on each one will reveal more details and contribute to the overall evaluation of DLs.
 Acknowledgements
The authors wish to thank Antonella DeRobbio, Imma Subirats, Zeno Tajoli, E-LIS administrators, and the national editors of E-LIS for their invaluable help and support during the realization of this study, Dim-itris Gavrilis, Department of Electrical Engineering, University of Patras, Patras, Greece, for his technical assistance, and Tasos Tsagkos for his constructive comments on the statistic analysis of this study. References
