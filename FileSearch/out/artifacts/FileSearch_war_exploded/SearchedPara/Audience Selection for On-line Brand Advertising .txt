 This paper describes and evaluates privacy-friendly methods for extracting quasi-social networks from browser behavior on user-generated content sites, for the purpose of finding good audiences for brand advertising (as opposed to click maximizing, for example). Targeting social-network neigh-bors resonates well with adver tisers, and on-line browsing behavior data counterintuitively can allow the identification of good audiences anonymously. Besides being one of the first papers to our knowledge on data mining for on-line brand advertising, this paper makes several important con-tributions. We introduce a framework for evaluating brand audiences, in analogy to predictive-modeling holdout evalu-ation. We introduce methods for extracting quasi-social net-works from data on visitations to social networking pages, without collecting any information on the identities of the browsers or the content of the social-network pages. We in-troduce measures of brand proximity in the network, and show that audiences with high brand proximity indeed show substantially higher brand affinity. Finally, we provide ev-idence that the quasi-social network embeds a true social network, which along with results from social theory offers one explanation for the increase in brand affinity of the se-lected audiences.
 Categories and Subject Descriptors: H.2.8 [ Database Management ]: Database Applications X  X ata mining; I.2.6 [ Artificial Intelligence ]: Learning X  X nduction; I.5.1 [ Pat-tern Recognition ]: Models X  X tatistics; J.4 [ Computer Applications ]: Social and Behavioral Sciences General Terms: Algorithms, Design, Experimentation Keywords: on-line advertising, predictive modeling, social networks, user-generated content, privacy This work was conducted while the authors were at Media6  X  Foster Provost thanks NEC for a Faculty Fellowship and Daniel P. Paduano for a Fellowship in Business Ethics.
This paper introduces a privacy-friendly method for tak-ing advantage of user-generated content on social network-ing sites (and beyond) to improve audience identification for on-line brand advertising. Unlike direct-marketing-style on-line advertising, the goal of on-line brand advertising is not only to generate clicks or near-term on-line purchases. On-line brand advertising focuses on getting a brand-oriented message to an audience of interest. This introduces oppor-tunities as well as challenges for developing a data mining solution. For example, one challenge is that there are no true  X  X egative examples X  with which to train classifiers. An opportunity is that advertisers tend to believe that brand affinity is likely to cluster in social networks [21], similar to product affinity [16]. Therefore, the social-network neigh-bors of those already exhibiting brand affinity are an at-tractive brand audience. The techniques we describe and evaluate attempt to take advantage of this clustering, in a privacy-friendly fashion. 1 On-line brand advertising has a huge opportunity for growth. Even though the majority of on-line ads are display ads, sponsored search advertising is responsible for the majority of advertising revenue and profit [8]. Well-designed brand advertising may be more appropriate for much display ad-vertising, since unlike for sponsored search the user has not come for the express purpose of clicking on a returned link. ComScore [7] recently reporte d a clear correlation between seeing on-line brand advertising and increasing both on-line and off-line purchases, well into the future (beyond the reach of current view-through conversion measurement 3 technol-ogy), which echoed prior industry results (e.g., [1]). Further-more, due in large part to the stabilization of the ad technol-ogy business landscape, with a few large ad exchanges auc-tioning massive numbers of non-premium display slots, in-dustry analysts forecast that the growth of the non-premium display market will significantly outpace the overall online ad market [8].
One contribution of this paper is to address the key ques-tion: How can on-line brand audiences be assessed? We present a framework for assessing on-line brand advertis-ing audiences. It is meant to complement rather than sup-plant traditional brand-advertising evaluations, and to offer an on-line alternative to click-maximizing. The key is that certain brand actions become visible and measurable on-line, which helps to circumvent the traditional difficulty of eval-uating brand advertising. In short, we adapt a predictive-modeling-style hold-out evaluation based on a selected au-dience X  X  density of brand actors  X  X hose browsers who take certain observable actions indicative of brand affinity, e.g., visiting a brand loyalty club page or a purchase thank-you page. More specifically, to evaluate whether a technique identifies a  X  X etter X  audience for a brand, we compare the density of brand actors in the identified (holdout) audience to the baseline density of brand actors in the population as a whole. The evaluation is based on an inference that res-onates well with advertisers and marketers: if the audience has a higher density of brand actors, then the non-actors in the audience (the vast majority) will be better candidates for brand advertising.

The second contribution of this work is the introduction of a method for identifying good brand audiences. We ex-tract a (quasi-)social network from browsing data, select the social-network neighbors of previous brand actors, and then calculate a measure of  X  X rand proximity X  to rank the social-network neighbors. A brand audience of a desired size can be chosen by selecting the top of the resultant ranking.
Existing on-line brand advertising usually follows an on-line adaptation of off-line brand advertising (the vertical television/magazine model): associate brand advertisements with top-notch, brand-relevant content. Unfortunately, con-sumers spend most of their time on-line away from such  X  X re-mium slots. X  Our technique is complementary: we identify an audience of browsers of interest and target them any-where on the web, e.g., through ad networks or via ad ex-change auctions of non-premium display slots.

For this study we use data on visits to social networking sites, which allows us to reach (potentially) up to 75% of Internet users [20], and also allows us to infer the structure of social networks among Internet users. One of the most influential results of social theory is the notion of homophily [21]: that social relationships tend to be made between peo-ple with similar characteristics. This has been shown to be directly useful for targeted direct marketing: Hill et al. [16] show that social-network neighbors of existing customers are substantially more likely to respond to an offer for a telecom-munications product than consumers who do not have an existing customer as a social-network neighbor. We evalu-ate this technique on brand-affinity data for more than a dozen well-known national and international brands, show-ing that the identified audiences indeed exhibit markedly higher brand affinity. We also show evidence that a robust measure of brand affinity can be learned.

The third main contribution of this paper is to provide suggestive evidence that the extracted quasi-social network actually embeds a true social network. Thus, more gener-ally, this paper offers an approximate method of identifying  X  X riends X  anonymously. An ad network implementing such a technique can engage in social-network targeting without collecting or saving any data on browsers X  identities or the content of the social-network pages they visit.
The method we introduce for creating brand audiences is based on two assumptions. First, micro-content affinity  X  co-visitation of the same user-g enerated micro-content X  X eads to brand affinity. By user-generated micro-content (UGC), we mean pages created by individuals outside the scope of a professional engagement, such as pages on social network-ing sites (the focus of this paper), photograph sites, non-professional blogs, etc. For social networking sites, this as-sumption is supported by the results presented below.
The second assumption is that micro-content affinity acts in important ways like true interpersonal relationships, and in fact may indicate actual interpersonal relationships de-pending on the UGC. For example, people who visit the same social-network pages may well be true friends or rela-tives. If so, such affinity networks embed actual social net-works. Network neighbors bein g true friends is not critical for the techniques to work, but provides an important mo-tivation for brand advertising, due to the wealth of results showing that people with social relationships are more likely to be similar along many different dimensions [21], including likelihood of purchasing a particular product [16]. To select the audience for a brand we first use visits to UGC to define an anonymous, quasi-social network among web browsers. A browser is an anonymous visitor to one or more web pages. Advertising networks serve massive num-bers of ads to massive numbers of browsers, and via cookies keep track of which browsers visit what content. Each time two browsers are observed to visit the same UGC page, an affinity-network link is placed between the browsers. Tech-nically, this network is induced from the bipartite affinity graph between users and UGC. Frequencies of visitation can become strengths for the individual links. This method for audience selection has the advantage that it can operate on doubly de-identified data: browsers are represented by ran-dom numbers, and content pages are represented by ran-dom numbers. Targeting the audience can be done through normal ad network procedures, which require only that the ad network tell the ad exchange to target the browsers in a given set based on their cookies X  X he ad network need transfer no data about the browser besides the (otherwise random) cookie id.

For brevity, clarity and emphasis, since there are two dif-ferent affinity graphs, we will refer to the network induced among browsers as the  X  X uasi-social X  network. We add the prefix  X  X uasi- X  here because technically at this point we do not know who are true friends and who just share a strong content affinity but don X  X  actually know each other. We re-turn to this in section 4.5. Keeping this in mind, we will drop the  X  X uasi X  except where necessary to distinguish from a real social network.

In order to assemble proposed high-quality brand audi-ences, we select the subset of the social network neighbors closest to a set of seed nodes . The seed nodes are browsers in the network identified (ex ante) or estimated to exhibit brand affinity. To instantiate the method, we must define (i) a precise sort of seed node to use, and (ii) what it means to be close to the set of seed nodes.
How to define seed nodes depends on the information available to the advertiser and to the ad network implement-ing the method. For example, seed nodes could represent ex-isting customers, or consumers who have exhibited interest in the company X  X  product, or consumers estimated to be-long to a desired demographic or psychographic group. 4 For this paper we will consider observable brand-associated ac-tions of interest. More specifically, define brand actors to be those browsers observed to have visited a particular brand-oriented page selected by the advertiser, e.g., a brand loyalty page, a customer login landing page, a purchase thank-you page, or simply the company X  X  home page. The seed nodes are browsers known at the time of audience selection to be brand actors (future brand actors will be used for evalua-tion). Specifically, let B be a set of M web browsers under consideration. We will consider the brand audience for each brand separately. Let the seed nodes compose a subset of the browser set B +  X  X  . Let all the other non-seed-node browsers ( candidate nodes )belongtotheset B 0 = B X  X  + . Our goal is to compose a brand audience of interest A X  B 0 based on browsers X  proximity to B + , such that a larger-than-baseline proportion of the browsers in A are likely to be as-of-yet unobserved brand actors. Brand proximity is a dis-tance/similarity measure between candidate nodes and the set of seed nodes. Brand proximity can be calculated as an aggregation over proximity measures for individual nodes, orbasedonthesetasawhole;weexperimentwithboth below. There are countless ways to define similarity or dis-tance between individual nodes in a network [19]; here we use straightforward measures for simplicity and efficiency. If more sophisticated techniques [14, 18, 19, 25, 26] can scale, they may provide the basis for improving the results we present below.

Assume that there are N user-generated micro-content pages in total that the browsers have visited. Browsers and content form a bipartite graph which can be represented by a M  X  N browser-content matrix as: where each browser b i  X  X  is represented by a row in  X  X  X  content vector representation, each  X  ij represents the weights of the links in the bipartite graph. In the simplest case,  X  ij is simply one or zero, a binary value indicating whether browser b i has visited content piece c j and  X  is the biadjacency matrix for the bipartite graph. Non-binary weights can be computed in various ways, e.g., as the frequency with which browser b has visited content piece c j (what we do for this paper), penalizing for popularity such as with tfidf, and/or damping older counts [9].

The network neighbor audience for a brand is N = { b i :  X  X  X   X   X   X   X   X  k =0forsome b k  X  X  + } . For this paper, the largest high-quality audience we will select is N , and every audi-ence we choose will be a subset of N (these will be the only
See for example http://www.mindset-media.com/ . browsers with non-zero brand proximity). This will allow ef-ficient computation of A over massive social networks, since the identification of N canbedoneveryefficiently. Our conjecture is that immediate network neighbors give sub-stantially more lift than neighbors further in the network, as with prior work on network-based marketing [16, 17]. Fur-thermore, for brand proximity measures that aggregate over individual node proximities, we will be most interested in the proximity of a browser to those in the set B + ,rather than arbitrary inter-browser proximities (although it may be useful to create a baseline for comparison).

Since we do not have a theoretically optimal brand prox-imity measure, we can represent brand proximity for b i by avector different proximity measures. We use lecting A . For our main results, we rank the candidate nodes b  X  X  0 based on some monotonic function of the projection of  X   X  where on its qth row, and f i is a monotonic function to map the single proximity measure selected by for b i . Alternatively, if desired, we can treat vector to learn a brand-specific proximity measure to rank the candidates. In either case, the brand audience would comprise the top-ranked browsers in B 0 .
For the results presented below, we use five brand proxim-ity measures. For clarity, we will use b 0 i to denote a candidate node b i  X  X  0 and b + k to denote a seed node b k  X  X  + .Fora browser b i (either a seed node or a candidate node), let be the set of content pieces to which the browser is linked in the bipartite graph; i.e., C b i corresponds to all nonzero entries in b i  X  X  content vector 1. POSCNT: the number of unique content pieces through 2. MATL: the maximum number of unique content pieces 3. maxCos: the maximum cosine similarity of the can-4. minEUD: the minimum Euclidean distance between 5. ATODD: the ratio of the number of a browser X  X  neigh-
One contribution of this paper is a framework for evalu-ating on-line brand audiences. It is an adaptation of predic-tive modeling holdout testing, but to our knowledge there has been no prior application to on-line brand advertising: Choose two non-overlappi ng, ordered time periods, t 1 and t . Consider a set of browsers B knownintime t 1 .The seed nodes B + are those elements of B for which a brand action is observed in t 1 . Let us call the seed node set clarify that the seed nodes are the brand actors in time t For evaluation, the candidate nodes B 0 are those elements of B that are observed in time t 2 .The future brand actors , 2 ,arethoseelementsof B 0 who are observed to take a brand action in t 2 . As with a predictive modeling holdout evaluation, information about action taking of the holdout set is not used in selecting the audience.

To evaluate any audience A , we can compute the future density of brand actors as:
Audiences can be compared based on their future brand actor densities. The important twist from standard response modeling is that this can be done either with or without ad-vertising. To advertisers, a larger proportion of an audience showing brand affinity  X  X rganically X  (i.e., without advertis-ing) is highly indicative that the audience is a good audience for brand advertising. Furthermore, unlike click-based eval-uations, it can be used to judge brand affinity separately from someone just being a  X  X licker X  [6].

Evaluation and comparison can be done based on any measure of density of a binary attribute over a set of data. We are interested in how well the different proximity mea-sures rank the candidates, and we presume that a particular campaign will target some upper portion of the ranking de-pending on the advertising budget and other considerations. Thus, we report the area under the ROC curve (AUC, equiv-alent to the Mann-Whitney-Wilcoxon statistic), which mea-sures how well a scoring system can rank members of one class above the other [13]. In this application, a higher AUC means that an audience selected from the top of the ranking will have a higher density of brand actors. Human brand actions are fundamentally difficult to predict, and as with targeted marketing reponse modeling we would expect low but hopefully better than random AUCs. 5 To illustrate the relative increase in brand-actor density over a baseline au-dience ( X  X ift X  in brand-actor density) we also report results for the top-10% of N for each ranking, which is reasonable for the application.
We now present results assessing the effectiveness of tar-geting close social network neighbors for identifying brand audiences on-line.
The results are based on anonymized browsing and action-taking data from a working ad network. Specifically,  X  is built from a sample of page visits to several of the largest so-cial networking sites over a 90-day period. The sampling be-gins with a quasi-random (convenience) sample of browsers from every server log file every 10 minutes across the server farm, resulting in about 10 million unique browsers who have visited social network (SN) content over a 90-day period. As far as the ad network experts can tell, there is no sys-tematic bias to this sampling. For each of these browsers we query for all the observed page visits over SN content over the time period. On average, a browser has about 25 visits recorded to unique SN pages. The resulting  X  has ap-proximate dimensionality 10 7  X  10 8 , with about 250 million non-zero entries.

A set of major brands is divided into two groups: (1) four brands for which in the experimental period no advertising was done by the ad network (Hotel A, Modeling Agency, Credit Report, Auto Insurance), plus a fifth  X  X rand X  that consists of a demographic group of intense interest to cer-tain large-scale adverisers, for which no amount of advertis-ing will change one X  X  membership status in the short term (Parenting); (2) ten brands for which some advertising was done (Apparel Hiphop, Apparel Athletic, Apparel Women X  X , Voip A, Voip B, Airline, Hotel B, Electronics A, Electronics B, Cell Phone). In group 2, advertising was done more or less uniformly across N , so being able to rank within N would be indicative of some combination of brand affinity and differ-ences in  X  X esponse X  to the advertisements. The latter plays more or less of a role for different brand actions. In no case does clicking on the ad lead directly to an observed brand action. However, browsing the site or purchasing may. For example, for Hotel B, the action is reserving a room. It may be that a browser is indeed influenced by the advertising to reserve a room in this particular hotel chain during the testing period, in which case brand affinity is exhibited, but it would not be purely organic.

In these data we have on average about 100,000  X  X eed X  action takers per brand, with the actual number varying be-tween 5000 and 1 million. In the experimental data, each seed action taker has on average 20-40 social-network neigh-bors, with the resultant network-neighbor audiences being up to 20-40 times the number of seeds. Choosing the  X  X los-est X  in brand proximity involves sub-selecting from these.
For example, good models for the KDDCUP 1998 targeted marketing data yield AUCs of around 0 . 6. for the best univariate measure.
 For example, in some experiments below we choose the top-10% of N . Technically, we would expect to see different future brand actor densities even for the same brand for dif-ferent brand actions; here for simplicity we just refer to each as  X  X he brand X . In one case (Voip A &amp; B), the two  X  X rands X  are two different actions for the same brand.
The left side of Table 1 shows AUC results for the various techniques over the entire candidate set ( B 0 ). The upper-most five rows correspond to brand group 1, and the bottom ten rows to brand group 2. Consider brand group 1. For all five brands, all five brand proximity measures give AUCs which show statistically significantly 6 better-than-random separation of future brand actors, indicating that the prox-imity measures indeed do rank audiences with respect to their brand affinity. Absolute AUC values are difficult to assess out of context, and as far as we know, this is the first attempt to evaluate brand audiences in this way. They compare favorably to the AUC values one typically gets for targeted marketing, even though here the audiences have not been advertised to. The results are even stronger for group 2; all are statistically significantly better than random, and one (Cell Phone) is remarkable (AUC=0.79).

As noted previously, ranking results for some group 2 brands may be affected by advertising. Column  X  X axCos( N ) X  provides an evaluation using maxCos on only N ,asetthat received uniform advertising during the experimental pe-riod. Note that this already is a set that we believe to have excellent brand affinity. Column  X  X axUNI( N ) X  shows the AUC for the best univariate measure on N .Notethat when maxCos is statistically significantly better than the others on B 0 ,it X  X alsothebeston N . These results show
All statistical significance results for AUCs are computed using the procedure described by [10], which is the proce-dure implemented by the commercial statistical packages SAS and Stata. Qualitatively similar results were obtained via t-tests over mean AUCs from randomly resampled test sets. one view of whether ranking among the network neighbors themselves provides additional gain over just identifying and advertising to it indiscriminately. Recall that for those brands where response might result in an observed brand action, this gain is a combination of pure brand affinity and response likelihood. The results here are solidly positive as well. The restriction of the data results in many fewer positive testing examples, and increases the variance in the AUCs substantially, so detecting statistical significance be-comes more difficult (and the seeming increases in AUC over the former setting may be illusory). Nonetheless, for group 2 for maxCos, 8 out of the 10 individual AUCs are statisti-cally significantly better than random (not Apparel Hiphop or Electronics B); 10 out of 10 are greater than 0.5 (strongly significant by a sign test), and the overall average AUC is 0 . 61, which is quite respectable, especially when considering that the baseline here ( N ) already is expected to be a high-performing group. The even stronger results for maxUNI suggest trying to select or combine measures.

An alternative evaluation is to assess the increase in brand actor density (hereafter, density ) directly on a selection of browsers from the top of the ranking. The results are qual-itatively similar to those presented in the next section (when comparing the univariate measures to the multivariate model), which are plotted there. We selected audiences comprising the most highly ranked 10% of N for each brand and prox-imity measure. Overall, the results echo the AUC results with the exception that ATODD is the dominant technique. For group 1 we see increases in density ranging from an 80% increase to a 500% increase ( X  X ifts X  of 1 . 8to6 . 0). In group 2 we see even larger increases. As with the AUC results, we also generally see lifts in density as compared to the den-sity of brand actors in N . The top-10% network neighbors clearly show an increase in density over N (increases in 13 of 15 cases when ranked by ATODD; highly statistically sig-nificant by a sign test); the average increase in density over the network neighbors is 100% (a lift of 2 . 0). Figure 1: Brand actor densities for the top-10% of N se-lected by the best and worst univariate proximity measure and the trained multivariate measure, compared to the den-sity over the entire candidate set B 0 ( X  X aseline X ; normalized to one).
No univariate measure is consistently the best, and in fact for each method that is statistically significantly best for some brand, there is another brand for which it is statisti-cally significantly beaten by another measure. As introduced briefly above, since we represent each candidate browser by avector them into a multivariate measure designed specifically to identify high-brand-affinity browsers. Ideally, such a mea-sure would be more robust across brands.

For this paper, the rank of a candidate browser b i  X  X  0 is calculated by a multivariate logistic function of the elements of  X   X  where w p are brand-specific weights. The weights are com-puted with standard MLE logistic regression, using an ex-tension of the holdout framework presented in section 3. Specifically, we extract from the set of candidate nodes an additional training set, comprising brand-actors and non-brand-actors in t 2 . Any evaluation, of course, will be con-ducted on a disjoint (hold-out) data set from t 2 . 7 In order for the comparison to be as fair as possible, for this compari-son we also added these training brand-actors to the seed set for the univariate measures. The technique that we report as MV chooses the best of the univariate and multivariate models, based on estimated AUC using cross-validation on the training set.

The results (not depicted) show that in terms of AUC, MV is always at least as good as the best UNI. For ranking all of B 0 MV posts a win-tie-loss record of 14 X 1 X 0, and for ranking N , a win-tie-loss record of 9 X 6 X 0; both are significant by a sign test and in both cases there are 5 individually significant wins. Thus, with training we can learn to do at least as well as the best univariate brand proximity measure, and often better.
Although we did not do so for this study, to match the use scenario most closely we would like to segment the evalua-tion data into three time periods. Figure 2: Brand actor densities as in Figure 1, except with the normalization baseline being the brand density of the network neighbor set ( N ), showing the additional lift (if any) over targeting all N .

Figures 1 and 2 show the brand actor densities of MV and the univariate measures with the best and worst per-formance for each brand, normalized so that each figure X  X  baseline ( B 0 and N , respectively) is one for each brand. For the top of the rankings, MV adds consistency but on average does not improve the top-of-the-list densities sig-nificantly over the best univariate measure. This may be showing that MV X  X  advantage is in rescoring the browsers below the top-10%; however, the logistic regression training does not specifically focus on the top of the ranking, so the comparison may not demonstrate the full power of MV. To-gether, the MV results provide strong evidence that better or more robust models can be learned. 8
It would have been nice to have shown lifts in purely or-ganic brand affinity for all brands. Of course, getting a working ad network to stop advertising to its largest cus-tomers is infeasible. As an alternative, we conducted an  X  X n vivo X  evaluation, by designing and running experiments in production. Specifically, for three selected group-2 brands, we identified a small audience of close network neighbors. To assess organic brand affinity, we targeted them only with a public service announcement (PSA) across the web, by bid-ding for them on a major ad exchange. These browsers do not get any brand advertising from the ad network. Simul-taneously, we issue a quasi-randomly targeted (RON 9 )cam-paign with the same PSA and campaign parameters. Since we X  X e targeted these browsers with  X  X ds X  (albeit PSAs), we now can obtain from the ad exchange statistics on  X  X iew through conversions X , specifically, the number of targeted browsers in each campaign who subsequently (e.g., within 7 days) take a predefined brand action (as described previ-ously). Of course the PSA ad should have no effect on a browser X  X  propensity to take the action.

Table 2 shows the number of PSAs shown to top-ranked neighbors and the number shown to RONs, and the  X  X r-
We have found that other learning-based methods can im-prove significantly both the rankings overall and the top-of-the-ranking performance.
The ad exchanges allow one to bid on every display slot, called  X  X un of network. X  Table 2: Organic action lifts for three group-2 brands.
Brand Impressions Impressions Organic Electronics A 67 53,347 5.89 Apparel: 26,161 266,661 6.06 Athletic Apparel: 5,757 223,509 64.65
Hiphop ganic conversion X  lift: the ratio of the percentage of the PSA-targeted neighbors who took the action to the percent-age of the PSA-targeted baseline who took the action. The results demonstrate remarkable organic lifts in brand ac-tor density for the audiences of close network neighbors for these three group-2 brands. Apparel: Hiphop is an inter-esting case. The brand previously had done the majority of its advertising through word of mouth, and here we in-deed see a tremendous lift in brand action density (65 times) for the close neighbors. This provides some initial evidence that the close quasi-social network neighbors are actual so-cial network neighbors. One caveat is that here we need to believe the statistics reported by the ad exchange, and to our knowledge there is no way to verify them directly.
The notion of targeting social network neighbors resonates with brand advertisers because they believe that the per-sonal networks of those already exhibiting brand affinity should be good targets for brand advertising. A long line of research in sociology supports this, as described by McPher-son et al. [21]. In particular, they note  X  X eople X  X  personal networks are homogeneous with regard to many sociodemo-graphic, behavioral, and intrapersonal characteristics. X 
Our quasi-social network being  X  X nly X  a content-affinity network may not matter to bottom-line-oriented advertis-ers, if indeed the networks are identifying audiences with high brand affinity. Nonetheless, if the quasi-social network is defined across visits to pages on social networking sites, it seems that it ought to embed a true social network. Users of social networking sites generally visit their own home pages and their friends X  pages (among others), and thus friends should be connected in our quasi-social network. Of course non-friends also will be connected, so one interesting ques-tion is whether strong brand proximity selects audiences comprising the actual friends of the brand actors.
One possibility is to map the explicit  X  X riends X  network from a social networking site to our network, and examine the overlap. However, this would require that we acquire personally identifying information, which we would prefer not to do. More importantly for drawing conclusions, the veracity of friend links is highly dubious [5].

Instead, based on the content visitation data, we estimate which piece of UGC is most likely to be authored by each browser, following ideas for identifying authors in citation networks [15]. Specifically, we estimate that the content piece a browser visits most, normalized by the overall popu-larity of the content, is owned by the browser (e.g., is her own social network page); let X  X  call this the browser X  X  home page. This is the average across all 15 brands.
 Table 3: F-AUCs showing that friends are very likely to be ranked (by maxCos) higher than those not known to be friends.
 Figure 3: Friends ROC curve for Airline, showing that friends are very likely to be ranked higher than those-not-known-to-be-friends. The top of the ranking is very dense with friends (steep initial rise) and the bottom of the ranking is almost devoid of friends (flat finish).
 We evaluated home-page identification accuracy on a sepa-rate data set of social-network browsing data which, while still completely anonymous as to user and content, indicated which page belonged to whom. The results showed high ac-curacy generally (65% correct at choosing a browser X  X  page) and very high (80% correct) for browsers where the method is confident in its prediction (about 60% of the browsers). Then we estimate that two browsers are  X  X riends X  only if one visits the other X  X  home page X  X ather than just having visited similar content.

Now, with this approximate notion of  X  X riends X  we can ask: does the audience comprising close neighbors of the seed brand actors in the quasi-social network (as measured by brand proximity) actually seem to include the friends of the brand actors? Of course, even if our estimation is accurate, the selection of friends that we observe in a data sample is only a small subset of all the friends. Therefore, we would like to measure whether brand proximity on average tends to rank brand actors X  friends higher than those-we-don X  X -know-are-friends. This is measured by the Mann-Whitney-Wilcoxon test statistic, which is equivalent to the area under theROCcurvewhentheclassistakentobe known-friend or not . Let X  X  call that F-AUC.

The results are striking. Table 3 shows the F-AUCs for each brand for maxCos, both over all candidate browsers (
B 0 )andjustover N .The B 0 results are striking but ulti-mately less interesting: In every case they are greater than 0 . 9, with a mean of 0 . 96. However, we know that with no connection to seed nodes, a browser will be ranked low. The N results are quite interesting and encouraging: even among the network neighbors, there is an 80% chance that a friend will be ranked higher than a browser who we don X  X  know is a friend. Figure 3 shows the ROC curve (over N ) for Airline: the top of the ranking is very dense with friends and the bottom almost devoid of friends.
In summary, our main results show unambiguously that we can build high brand-affinity audiences by selecting the social-network neighbors of existing brand actors identified via co-visitation of social-networking pages, without saving any information about the identities of the browsers or con-tent of the pages. These network neighbors tend to take brand actions at a higher rate organically, as well as after being targeted with ads. We also show that it is possible to learn better models, by using the individual univariate prox-imity measures as features in a higher-level model. And we provide evidence that the quasi-social network likely embeds a true social network (which makes sense if the visitations are over social networking pages).
 Table 4: Demographic profiles for CellPhone seeds and their social-network neighbors.

Among other things, brand advertisers would like their audiences to be similar along important dimensions of in-terest, which is why targeting social-network neighbors res-onates well [21]. As a final demonstration, for one brand (Cell Phone) we submitted a set of seed nodes and a set of close network neighbors to the internet analytics firm Quant-cast ( http://www.quantcast.com ), which gives statistically es-timated demographic profiles for sets of browsers. For the particular brand action selected by the advertiser, the seed nodes and the network neighbors returned with exactly the same profile along all dimensions (see Table 4).

We call this method  X  X rivacy friendly X  because here we offer no formal proof of the power of the anonymization scheme, but nonetheless assert that it has several attrac-tive properties from a privacy standpoint. First, it can be implemented without ever collecting direct PII (personally identifying information); thus it addresses a primary pri-vacy concern for firms dealing with personal information, i.e., that someone internally can directly look up informa-tion about particular individuals. Second, in contrast to other attempts at social-network-based on-line advertising, this method does not use user-posted personal (profile) infor-mation. This is important not only from a base-level privacy standpoint, but also as a deterrent to reidentification [27].
A secondary constellation of privacy issues revolves around vulnerability to data breaches and anonymization attacks. We believe that this anonymization is relatively robust to both active and passive attacks (see e.g., [27, 22]), especially as compared to existing practice which normally ignores the danger of reidentification. (1) The data contain no public information at all. (2) The data are sampled via a pro-cess opaque to the browser, and thus lack many true social network connections. (3) They contain a high degree of ad-ditional  X  X oise X  links with respect to the true social network, since they are based on content visitations. (4) It is difficult to envision how an attacker would  X  X eed X  a passive attack on the anonymized quasi-social network with knowledge of cer-tain members of the network (but see below), and (5) There is little information to  X  X eveal X  that would not be more eas-ily found elsewhere. One exception would be the data on brand activity of browsers, which also could be anonymized for storage (to minimize the risk of a data breach), but is necessary for targeting and is also a possible entry point for reidentification. If the advertising firm X  X  data security was breached, and a reidentification attack was successful, and the content and/or brand-action anonymization scheme were broken (which could begin with the homepage identification discussed above), it may be possible to discern who visited which social-network or brand pages. This is not trivial, but it is information that is collected routinely and widely now without any anonymization, by advertising networks, ad exchanges, search engines, and so on. In addition, the potential harm is arguably mild with respect to that associ-ated with much personal information that is used routinely (unanonymized) for data mining, personalization, and tar-geting. Thus our claim that this method is privacy friendly. Nonetheless, a privacy-sensitive firm using these techniques may want to consider not even saving anonymized data on certain content, engage only well-respected brands, and be-ware of saving potentially sensitive details of brand activity.
The greater question of privacy and on-line advertising involves where we as citizens and consumers, collectively, would want on-line businesses to operate on the spectrum between two unacceptable extremes: (a) doing absolutely anything with consumer data regardless of any ethical ques-tions, and (z) being unable to increase business and con-sumer welfare via data modeling. The answer obviously is beyond the scope of a paper like this. We hope we have illustrated that there are interesting and viable points be-tween the extremes (cf., [11]), that promise increased privacy as well as increased business and consumer welfare (here, better-targeted advertisements). It would be valuable to develop privacy-preserving techniques to augment this pri-vacy friendliness without reducing effectiveness too much, for example by introducing additional randomness into the content visitation network.

We are not aware of prior research on data mining for on-line brand advertising. Prior work tends to focus on spon-sored search advertising [4], contextual advertising [3], and display advertising optimized for some action in response to the ad X  X sually clicks and sometimes more sophisticated conversions. Provost et al. [24] describe in detail a broad set of different sorts of data that can be useful for on-line ad targeting. Unlike this prior work and most actual on-line advertising [4, 3] (especially when measured by current ad-vertising spending), the focus of our research is on finding and evaluating audiences for brand advertising. It makes sense that better brand audiences also will be more likely to click or convert, which would be a natural and attractive by-product (but we have not shown this).

Our problem has some similarity to collaborative filtering (CF), but differs in important ways. The scale of the data is different, which has implications for scalability. Just in our research data set, we have 100 million  X  X tems X , as compared to at least an order of magnitude fewer even for very large CF systems. More importantl y, rather than recommending from among the item set itself ( X  X atrix completion X ), our task more closely resembles traditional predictive modeling of a specific target variable, but with a massive number of variables, and technically only positive and unlabeled exam-ples [12]. Nonetheless, it may be that CF-style dimension-ality reduction [2] can further improve audience selection.
Although we have tried to design the experiments care-fully, there may be some residual bias in data collection. We have investigated this both by using regression analy-sis including variables that may indicate bias, as well as by trying to seemingly improve the audiences by using bias-related variables, but have not found anything to lead us to question the results. For example, including the number of pages a browser has visited does not reduce the significance of the proximity variables in a regression on brand affinity, and does not systematically increase accuracy.

Any technique operating in the framework we provide will be limited by browser cookie deletion. This is a well-known problem for brand advertisers, who often  X  X etarget X  ads to known brand actors (since they X  X e already displayed brand affinity). Over time, deletion of cookies will cause some of the chosen audience members never to present themselves (again) for advertising. Our methods are less sensitive to cookie deletion because in effect our techniques will natu-rally retarget lost brand actors, as long as they visit the same social networking pages. Moreover, our techniques will naturally, anonymously target brand actors on other com-puters, if they  X  X ct like their own best friends, X  which may account for some of the effect shown above.

The use of  X  X riends X  links from SN sites for direct mar-keting has received much criticism from the popular press due to privacy concerns [23], and from the academy [5]. In particular, Clemons et al. [5] provide a well-worth-reading argument that advertising on a SN site to SN neighbors is unlikely to be successful. However, they do not discuss brand advertising X  X hich may be successful on SN sites, as brand advertising is different from click-inducing advertis-ing. Nor do they consider that the value of SN sites for delivering ads and their value as a vehicle for collecting data are independent. This paper shows the substantial value of social networking sites as a mine for data on brand affinity (the advertising may take place elsewhere on the web). [1] Atlas Institute. Where can you find your customer? [2] R. Bell, Y. Koren, and C. Volinsky. Chasing [3] A. Broder, M. Fontoura, V. Josifovski, and L. Riedel. [4] M. Ciaramita, V. Murdock, and V. Plachouras. Online [5] E. K. Clemons, S. Barnett, and A. Appadurai. The [6] comScore. New study shows that heavy clickers dis-[7] comScore. Whither the Click? comScore brand metrix [8] R. Coolbrith. On-line advertising 2.0: The [9] C. Cortes, D. Pregibon, and C. Volinsky. Communities [10] E. R. DeLong, D. M. DeLong, and D. L.
 [11] G. T. Duncan, S. A. Keller-McNulty, and S. L. Stokes. [12] C. Elkan and K. Noto. Learning classifiers from only [13] T. Fawcett. ROC Graphs: Notes and Practical [14] F. Fouss, A. Pirotte, J. Renders, and M. Saerens. [15] S. Hill and F. Provost. The myth of the double-blind [16] S. Hill, F. Provost, and C. Volinsky. Network-based [17] S. Hill, F. Provost, and C. Volinsky. Learning and [18] G. Jeh and J. Widom. Simrank: a measure of [19] Y. Koren, S. C. North, and C. Volinsky. Measuring [20] Lotame. Moms in social media. Lotame I.D. Reports, [21] M. McPherson, L. Smith-Lovin, and J. M. Cook. [22] A. Narayanan and V. Shmatikov. De-anonymizing [23] J. C. Perez. Facebook X  X  beacon more intrusive than [24] F. Provost, P. Melville, and M. Saar-Tsechansky. Data [25] J. Sun, H. Qu, D. Chakrabarti, and C. Faloutsos. [26] S. White and P. Smyth. Algorithms for estimating [27] B. Zhou, J. Pei, and W.-S. Luk. A brief survey on
