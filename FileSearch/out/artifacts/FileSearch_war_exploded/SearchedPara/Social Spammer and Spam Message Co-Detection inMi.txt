 The popularity of microblogging platforms, such as Twitter, makes them important for information dissemination and sharing. Howev-er, they are also recognized as ideal places by spammers to conduct social spamming. Massive social spammers and spam messages heavily hurt the user experience and hinder the healthy develop-ment of microblogging systems. Thus, effectively detecting the social spammers and spam messages in microblogging is of great value. Existing studies mainly regard social spammer detection and spam message detection as two separate tasks. However, social s-pammers and spam messages have strong connections, since social spammers tend to post more spam messages and spam messages have high probabilities to be posted by social spammers. Combin-ing social spammer detection with spam message detection has the potential to boost the performance of each task. In this paper, we propose a unified framework for social spammer and spam mes-sage co-detection in microblogging. Our framework utilizes the posting relations between users and messages to combine social s-pammer detection with spam message detection. In addition, we extract the social relations between users as well as the connection-s between messages, and incorporate them into our framework as regularization terms over the prediction results. Besides, we intro-duce an efficient optimization method to solve our framework. Ex-tensive experiments on a real-world microblog dataset demonstrate that our framework can significantly and consistently improve the performance of both social spammer detection and spam message detection.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Classification ; I.2.7 [ Artificial Intelligence ]: Nat-ural Language Processing Spam Detection; Microblog; Social Context c  X 
Microbblogging websites, such as Twitter 1 and Sina Weibo have become very popular platforms for information dissemination and sharing [21]. Hundreds of millions of users frequently post short messages on these websites to release latest news and share their opinions on various topics, such as political events, compa-nies and daily life. However, microbblogging websites are also recognized as ideal places to conduct spamming due to their pop-ularity [34, 39, 21]. Massive fake microblogging accounts, which are known as social spammers [37], post masses of spam messages for various purposes, such as conducting social advertising, collect-ing users X  personal information, promoting affiliate websites and so on [5, 23]. These spam messages may contain dangerous content and URLs that are related to scams, malware, phishing [17, 23, 21]. Spam messages are also used to conduct political astroturfing [5, 32]. These massive social spammers and spam messages serious-ly hurt the user experience and hinder the healthy development of microblogging systems [23]. Thus, effectively detecting the social spammers and spam messages are beneficial to both microblogging websites and users.

Various methods have been proposed for social spammer detec-tion and spam message detection. For example, some researcher-s suggested to detect social spammers via social network analy-sis [30, 12]. The basic assumption behind these methods is that so-cial spammers cannot build enough social trust relations compared with legitimate users [21]. However, different from other online social networking platforms, such as Facebook and Youbute, in mi-croblogging websites, a user can follow anyone else without the followee X  X  permission, and it is not too hard for social spammers to gain sufficient social relations with legitimate users [38]. Thus these social network analysis based methods may not work well on social spammer detection in microblogging platforms [21]. Anoth-er line of research for social spammer detection is analyzing their attributes, online behaviours, and textual content of the microblog messages they post [4, 34, 36, 24, 20, 19]. These methods are based on the assumption that the online behaviours and textual content of social spammers are different from those of legitimate users. How-ever, social spammers may continue to change their posting be-haviours and try to behave like normal users [20]. In addition, be-sides spam messages, social spammers may also post some normal messages. These strategies may lead to the content and behaviour analysis based methods less accurate. As to spam message detec-tion, existing methods mainly focus on extracting effective features and building a classifier using machine learning techniques [33, 25, https://twitter.com/ http://www.weibo.com/ Figure 1: An illustrative example of the social contexts used in our framework. The red and green user figures represent social spammers and legitimate users respectively. The red and green rectangles stand for spam messages and normal messages re-spectively. The solid black lines with arrows connecting users represent the relations between users. The dashed purple line connecting a message with a user represents the posting rela-tion between the user and the message. The solid blue lines and orange lines represent the connections between messages intro-duced by hashtags and URLs respectively. 26]. For example, some researchers found that URLs, timestamps are informative features for identifying spam messages [14].
In general, in existing studies social spammer detection and s-pam message detection are mainly regarded as two separate tasks. However, in microblogging websites, a common phenomenon is that social spammers tend to post more spam messages, and spam messages have high probabilities to be posted by social spammer-s. Thus there are strong connections between social spammers and spam messages. Detecting social spammers and spam messages simultaneously may achieve better performance than conducting each task in isolation. In addition, the social connections between users and those between messages may also be helpful for social spammer detection and spam message detection. For example, so-cial spammers are often followed by other spammers, because they frequently collaborate in this way to build more social relations and pretend to be normal users. Many spam messages contain the same URLs because they belong to the same promoting campaigns [39]. Some spam messages contain the same hashtags for the purpose of advertising for a brand. An illustrative example of these social contexts is shown in Fig. 1.

Motivated by above observations, in this paper we propose a uni-fied framework for social spammer and spam message co-detection in microblogging with various social contexts. In our framework, social spammer detection and spam message detection are bridged by the posting relations between users and messages. The result-s of social spammer detection can help refine the results of spam message detection, and vice versa. Both the performance of so-cial spammer detection and that of spam message detection can be boosted. In addition, our framework can incorporate the social contexts of user-user relations and message-message relations by modeling them as regularizations over the prediction results.
The main contributions of this paper are summarized as follows:
The rest of this paper is organized as follows. In Section 2, we briefly introduce several representative works related to social s-pammer detection and spam text detection. In Section 3, we dis-cuss how to extract various social contexts for detecting social s-pammers and spam messages in microblogging. In Section 4, we describe our framework for social spammer and spam message co-detection, and the optimization method to solve this framework. In Section 5, we report the experimental results on a real-world mi-croblog dataset. In Section 6 we conclude this paper.
In this section, we briefly introduce several representative works related to social spammer detection and spam detection.
Social spammer detection is an important research topic and has been studied in various social networking websites, such as Twit-ter [4], Facebook [9], Youtube [29] and Sina Weibo [24]. Existing studies on social spammer detection can be roughly divided into two categories. The first category is using social network analy-sis to detect social spammers [30, 12, 15]. The assumption behind these methods is that social spammers cannot build a large number of social relations with legitimate users [21]. However, due to the special characteristics of microblogging websites, this assumption may not hold true [38] and these methods cannot be applied to mi-croblog spammer detection directly [21]. The second category of methods is to extract effective features from users X  attributes, on-line behaviours, and the textual contents of the messages they post, and build a classifier using machine learning techniques [4, 34, 24, 20, 19]. For example, McCord and Chuah proposed to extract two kinds of features, i.e., user-based features and content-based fea-tures, and use traditional classifiers, such as SVM and Naive Bayes, for detecting the social spammers in Twitter [27]. The user-based features they used include the numbers of friends and followers, and reputation score. The content-based features contain the num-bers of URLs, keywords and hashtags in a user X  X  messages. Hu et al. proposed to detect social spammers according to users X  textual content, and explored to utilize the resources from email, SMS, and Web spam detection fields to help train the classifier [19]. Howev-er, social spammers may continuously change their behaviours and attributes to pretend to be normal users. In addition, they may post some normal messages besides the spam messages. These strate-gies may make above methods less accurate.

Social contexts have also been explored for social spammer de-tection. In [21], the authors proposed to incorporate the following relations between users into the classifier learning stage by con-straining that the users with social relations are assigned similar scores by the learned classifier. When a new user comes, only the textual content of his/her messages is used to classify this user. Our method is different from their method in two aspects. First, our method models social spammer detection and spam message detec-tion in a unified framework, while their method only focuses on so-cial spammer detection. Second, in our method, the social contexts are used in the prediction stage, while in their method the the social contexts are incorporated into the model learning stage. Even with the help of social contexts, it is still difficult to train an accurate enough social spammer classifer, since spammers X  attributes, be-haviours and textual content are continuously evolving [20]. How-ever, the social contexts of the unseen users and messages can pro-vide some useful information for classifying them into spam or non-spam. Thus we believe that it is more appropriate to utilize social contexts in prediction stage than in model training stage.
Spam detection has been extensively studied on various kind-s of texts, such as email [6], webpage [18, 1, 28], SMS [16] and review [22]. There are two main kinds of methods for spam de-tection, i.e., link-based methods and content-based methods. Link-based methods are widely used for detecting spams in linked texts, such as webpages [18, 1]. These methods are based on the assump-tion that spam webpages have different link patterns compared with normal webpages and they are seldom linked by high-quality web-pages. For example, Becchetti et al. found that degree correlations, number of neighbors, and TrustRank score are effective metrics for Web spam detection [1]. However, since not all the microblog mes-sages contain URLs, and the URLs in microblogs usually point to webpages rather than other microblogs messages, these link-based methods cannot be directly used to detect spam microblog mes-sages.

Content-based methods are extensively studied and popularly used for spam detection [6, 28, 16, 22]. In these methods, effec-tive features are first extracted from the content. Then spam classi-fiers are trained on labeled data using machine learning techniques. These classifiers are used to classify unseen texts into spam or non-spam according to their content. For example, Ntoulas et al. de-signed various features for Web spam detection, such as number of words in the page, amount of anchor text, fraction of visible con-tent, and so on [28]. Then they used C4.5 algorithm to train the classifier.

Many microblog spam message detection methods also belong to content-based methods [33, 25, 26]. For example, in order to detect malicious tweets in trending topics, Martinez-Romo and A-raujo proposed to extract language model based features, e.g., the K-L Divergence between a tweet and the thread of tweets in this topic. They also incorporated other content-based features, such as the numbers of URL, hashtags, numeric characters and so on [26]. However, since microblog messages are very short and noisy [21], it is quite difficult to detect all the spam messages purely according to their textual content. Different from above methods, our method combines spam message detection with social spammer detection, and exploits various social contexts to refine the spam message de-tection results.

The benefit of combining spam detection and spammer detection on Web data has been observed by Chen et al. [10]. Given a set of labeled bookmarks and a set of labeled users, they trained a SVM classifier for spam detection and a SVM classifier for spammer de-tection simultaneously by utilizing the user-user relations and user-bookmark relations. The users with fans relation are constrained to have similar scores during training. Similarly, a user and a book-mark are constrained to be assigned similar scores by the classifiers if the bookmark is created by this user. Different from this method, our method utilizes the social context information in the prediction stage rather than the model learning stage. Since the behaviours and attributes of social spammers are continuously changing and the content of spam messages are evolving, the pre-trained spam-mer classifier and spam classifier cannot be accurate enough [20]. Meanwhile, social contexts of the messages and users can provide useful information to help make more accurate predictions. Thus we propose to utilize social contexts in the prediction stage.
In this section, we introduce the social contexts used in our frame-work for improving social spammer detection and spam message detection in microblogging platforms.
The first kind of social contexts used in our framework is the posting relations between users and messages, i.e., the user-message relations. It has been widely recognized in social spammer detec-tion and spam filtering fields that social spammers tend to post more spam messages than legitimate users, and spam messages have higher probabilities to be posted by social spammers rather than legitimate users [39, 21]. Thus social spammer detection and spam message detection are not independent tasks. In fact, they are closely connected by the social connections between users and messages. Detecting spam messages can help identify more poten-tial social spammers. In turn, if we find that some users are social spammers, we can obtain more candidate spam messages.

Denote U as the set of users and M as the set of messages. U = |U| and M = |M| are the numbers of all users and messages. We model the user-message relations using matrix P  X  R U  X  M message j is posted by user i , then P i,j = 1 . Otherwise, P For example, in Fig. 1, messages m 1 and m 3 are posted by u u respectively, then P u 1 ,m 1 = 1 and P u 2 ,m 3 = 1 .
Microblogging is one kind of Online Social Networks (OSN) and microblog users are networked. If a user wants to receive messages from some other users, he/she can just follow them. However, dif-ferent from other OSNs such as Facebook, a user in microblogging platforms can follow anyone without the followee X  X  prior permis-sion. Thus, the social relations among microblogging users are di-rected.

A common observation in social spammer detection is that social spammers usually follow each other, in order to gain more follow-ers and pretend to be normal users [21]. Legitimate users also fol-low each other frequently, partially because they know each other offline. Thus, if two users follow each other, then they have a high probability to be both social spammers or legitimate users. How-ever, it is also frequently observed in microblogging platforms that some social spammers follow a large number of legitimate users, in order to gain enough social relations with legitimate users and obtain high social influence [38]. Although social spammers can follow legitimate users, it is not very likely that legitimate users will follow them.

Motivated by above observations, in this paper we extract two kinds of user-user relations. The first kind is friend relation, which means that two users follow each other. We use matrix F  X  to denote friend relation. If users i and j follow each other, then F i,j = 1 and F j,i = 1 . Otherwise, F i,j = 0 and F j,i = 0 . The second kind of user-user relation is following relation. Different from friend relation, following relation is directed. We use D  X  R
U  X  U to denote this relation. If user i follows user j , but user j does not follow user i , then D i,j = 1 and D j,i = 0 . Otherwise, D
Normal messages may be related to various topics. However, masses of spam messages share the same targets. This is because spam messages are usually not used independently. In fact, many of them are used collectively to promote the same products, services or websites. For example, researchers have found that many spam accounts are manipulated by a small group of spammers. They use these accounts to post massive spam messages for some promoting campaigns by adding the same URLs into these messages [39]. In addition, some researchers have found that spam messages share highly similar content and the same hashtags [3, 24].

Motivated by these observations, we propose to extract social connections for microblog messages. We define that the message-message relations are undirected and if two messages are related to the same target, then they are connected. Denote T  X  R M  X  M the social connections between messages. If message i and mes-sage j share the same target, then T i,j = 1 and T j,i = 1 . Other-wise, T i,j = 0 and T j,i = 0 . In this paper, if two messages contain the same URL or hashtag, then we regard they are related to the same target and connected with each other. For example, in Fig. 1, since messages m 4 and m 5 have the same URL, and messages m and m 7 contain the same hastag, then T m 4 ,m 5 , T m 5 ,m T
In this section we study how to effectively and efficiently incor-porate all the three kinds of social contexts into a unified framework and detect social spammers and spam messages simultaneously.
First, we introduce several notations and formally formulize the problem of social spammer and spam message co-detection with various social contexts.

Denote the set of microblog users to be classified as U , and the size of U as U . Similarly, denote M as the set of microblog mes-sages to be classified, and the size of M is M . Following the nota-tions used in previous section, here we denote P  X  R U  X  M user-message relation matrix, F  X  R U  X  U as the friend relation be-tween users, D  X  R U  X  U as the following relation between users, T  X  R M  X  M as the message-message relation. Assuming that we already have a social spammer classifier f U (  X  ) and a spam message classifier f M (  X  ) which are trained on labeled datasets using ma-chine learning techniques. Denote u  X  R U  X  1 as the classification results of U using the social spammer classifier f U , where posi-tive values indicate social spammers and negative values indicate normal users. Similarly, denote m  X  R M  X  1 as the classification results of M using the spam message classifier f M , where positive values indicate spam messages and negative values indicate normal messages. Since the features of social spammers and spam mes-sages are continuously evolving, the social spammer classification results u and spam message classification results m may not be accurate enough. So we incorporate the social contexts to refine them. Denote x  X  R U  X  1 and y  X  R M  X  1 as the final classification scores of U and M outputted by our framework.

Based on above notations, the problem of social spammer and spam message co-detection in microblogging with various social contexts can be formally defined as follows: Given a set of microblog users U , a set of microblog messages M , and the initial classification results u and m generated by an existing social spammer classifier f U (  X  ) and a spam message clas-sifier f M (  X  ) , as well as three kinds of social contexts of these users and messages, i.e., user-message relations P , user-user relations F and D , and message-message relations T , we aim to refine the ini-tial social spammer and spam message classification results using these social contexts in a unified framework, and output more ac-curate social spammer classification results x and spam message classification results y simultaneously.
Our solution to the problem of social spammer and spam mes-sage co-detection in microblogging with various social contexts is a unified framework defined as follows: arg min where  X  ,  X  ,  X  and  X  are non-negative regularization parameters. hope the final prediction results do not differ too much from the original classification results. In other words, we take the clas-sification results generated by existing social spammer classifier and spam message classifier as the prior knowledge. The terms P tivated by graph-guided fused lasso [11], which can exploit the graph structure over the output variables for structured regression croblog users follow each other, then their spam scores should be similar, i.e., they tend to be both social spammers or legitimate two microblog messages contain the same hashtag, or refer to the same URL, then these messages tend to be both spam or non-spam and should be assigned similar spam scores. P U i =1 P j 6 = i x ) incorporates the directed following relations between users. The insight behind this term is that if user i follows user j while user j does not follow user i , then user i has a higher probabil-ity to be a social spammer than user j . Thus if the spam score of user j exceeds that of user i , a penalty will occur. The term P classification results with spam message classification results. This term constrains that if a message j is posted by user i , then they should have the same spam label, i.e., be both positive (spam) or negative (non-spam). This is motivated by the observation that so-cial spammers tend to post spam messages while legitimate users tend to post more normal messages. If message j is posted by user i , but they are assigned different spam labels, then a penalty will be triggered (note that there is a minus sign before this term in E-q. (1)). Thus our model defined in Eq. (1) can incorporate various social contexts into a unified framework for social spammers and spam messages co-detection.
Next, we discuss how to solve our framework in Eq. (1) efficient-ly. The optimization problem in Eq. (1) is convex with respect to x and y respectively. However, it is non-convex with respect to x
Figure 2: An illustrative example of constructing A from F . and y together, due to the term P U i =1 P M j =1 p i,j x be verified using the second-order condition [8]. Thus there is no analytical solution for the optimization problem in Eq. (1). Here we introduce an iterative optimization method to solve our framework.
First, we introduce several new notations. Assuming that there are n F non-zero elements in F , then we define A  X  R n F equivalent representation of F . If F i,j is the n th non-zero element in F , then A n,i = 1 and A n,j =  X  1 . Other elements in the n of A are all zeros. An illustrative example of constructing A from F is shown in Fig. 2. Similarly, we define B  X  R n D  X  U R
T  X  M as the equivalent representations of D and T respectively, where n D and n T are the numbers of non-zero elements in D and T . Then the optimization problem in Eq. (1) can be equivalently reformulated as follows: Inspired by [13], we propose to optimize x and y alternatively. When updating x , y will be fixed. Similarly, x will be fixed when updating y . The optimization problem in each step of the alterna-tive algorithm is convex and a unique optimal solution exists. The alternative algorithm continues until converges.

Next, we introduce how to update x and y respectively.
When updating x in the t th iteration, we fix y as y t , and opti-mizing the objective function in Eq. (2) is equivalent to following optimization problem: arg min
We can prove that the optimization problem in Eq. (3) is con-vex [8, 13]. However, the objective function in Eq. (3) is not s-mooth with respect to x , due to the term k Ax k 1 . Thus it cannot be solved using standard gradient descent method. Although we can solve Eq. (3) using subgradient descent method, the convergence rate of subgradient descent method is O (1 / number of iterations, which is unsatisfactory. In order to solve the optimization problem in Eq. (3) more efficiently, here we introduce an algorithm based on alternating direction method of multipliers (ADMM) [7], which has a convergence rate of O (1 /k ) .

First, we equivalently reformulate Eq. (3) as follows: arg min where v  X  R n F  X  1 is introduced as an auxiliary variable. Since ADMM is a method of multipliers, we further transform Eq. (4) into an augmented Lagrangian problem as follows: L ( x , v , X  ) = k x  X  u k 2 2 +  X  k v k 1  X   X  1 T Bx  X   X  x where  X  &gt; 0 is a penalty coefficient and  X   X  R n F  X  1 grangian multipliers vector.

Our ADMM-based method for Eq. (3) is an iterative optimiza-tion method. Different from other methods of multipliers, where in each iteration all the variables are updated simultaneously, in our method the variables x , v and  X  are updated in an alternating manner, which breaks the original problem into three easier sub-problems. Denote w =  X / X  as the scaled dual variable [7], then in the k th iteration of our method the variables x , v and w are updated sequentially as follows:
Updating x k +1 :
Updating v k +1 :
Updating w k +1 :
According to Eq. (6), x k +1 can be updated by solving a con-vex optimization problem. We can obtain the analytical solution of x k +1 by setting the first-order derivative of the objective function in Eq. (6) with respect to x to zero, which is shown in Eq. (9). x k +1 = (  X  A T A + 2 I )  X  1 (2 u +  X  B T 1 +  X  Py t +  X  A
Updating v k +1 also needs solving a convex optimization prob-lem (Eq. (7)), which is non-smooth due to the L 1 -norm of v . Luck-ily, we can have an analytical solution of v k +1 by applying the approximal algorithm [31]: where S is the soft thresholding operator which is defined as S ( a  X   X  ) +  X  (  X  a  X   X  ) + [31]. w k +1 can be updated directly according to Eq. (8). The com-plete ADMM-based algorithm for updating x in Eq. (3) is summa-rized in Algorithm 1.
 Algorithm 1 The optimization algorithm for updating x . 1: Input: x t , y t , u , A , B , P ,  X  ,  X  ,  X  ,  X  . 2: Output: x t +1 . 3: Initialize x 0 = x t , v 0 = Ax t , w 0 = 0 , k = 0 . 4: while the convergence condition is not satisfied do 5: x k +1 = (  X  A T A + 2 I )  X  1 (2 u +  X  B T 1 +  X  Py t 8: k = k + 1 . 9: end while
Next we discuss how to update y in Eq. (2). Since x is fixed to be x t +1 when updating y in the t th iteration, minimizing the objective function in Eq. (2) is equivalent to following optimization problem:
We can verify that this is a convex optimization problem. It is also non-smooth due to the term k Cy k 1 . Thus again we can apply ADMM to solve this optimization problem efficiently. We omit the detailed derivations here for the sake of concision since they are similar with those in previous section, and just illustrate the final algorithm for updating y in Algorithm 2. Interested readers can verify the conclusions in Algorithm 2 following the similar steps in previous section.
 Algorithm 2 The optimization algorithm for updating y . 1: Input: x t +1 , y t , m , P , C ,  X  ,  X  ,  X  . 2: Output: y t +1 . 3: Initialize y 0 = y t , n 0 = Cy t , w 0 = 0 , k = 0 . 4: while the convergence condition is not satisfied do 5: y k +1 = (  X  C T C +2 I )  X  1 (2 m +  X  P T x t +1 +  X  C 8: k = k + 1 . 9: end while
In this section we report the experimental results. We first intro-duce the real-world dataset used in our experiments. Then we vali-date the assumptions behind our social spammer and spam message co-detection framework by conducting hypothesis testing on this dataset. After that we evaluate the performance of our framework on both social spammer detection and spam message detection, and compare it with several state-of-the-art methods. We also explore the influence of parameter setting on the performance of our frame-work. Finally we analyze the time complexity of our framework empirically using experiments on the real-world dataset. In this section, we introduce the dataset used in our experiments. We first crawled a large microblog dataset using API from Sina Weibo 3 , which is the most popular microblogging website in Chi-na. The time period of this data crawling process is from January 1st, 2015 to February 1st, 2015. Then we randomly selected 200 users who frequently used some third-party APIs to automatically post microblog messages in our dataset. We found that these user-s tend to be social spammers. In addition, we randomly selected 200 verified users from our dataset, since verified users have a high probability to be legitimate users. We merged these 400 users to-gether and used them as seed users. Then we crawled followers and followees of these users. Finally we obtained 5,090 users in total including the seed users. Among these users, there are 433 friend relations and 4,748 following relations. We also crawled the profiles and recent microblog messages of these users from their microblogging homepages. We obtained 53,484 messages in to-tal. We used the URLs and hashtags contained in these messages http://www.weibo.com/ to build connections between them and obtained 234,375 message-message relations. We manually labeled each user and each mes-sage into spam or normal. We used +1 as the spam label and  X  1 as the normal label. The detailed statistics of this dataset is illustrated in Table 1.
 Table 1: The statistics of our dataset. #Friend , #Following and #Message-Message represent the numbers of friend relations, following relations and message-message relations respectively. #Message #Spam #Normal #Message-Message 53,484 25,681 27,803 234,375
In the preprocessing steps, we extracted feature vector for each user and each message. The features used for user classification include the total number of messages posted by the user, the num-ber of followers of the user, the number of followees, the ratio of followee number to follower number, the self-description of the us-er, the textual content of the messages posted by the user. As to message, we used the TFIDF vector as feature vector. Stop word-s as well as the rare words that appeared less than 10 times were removed.
Our framework defined in Eq. (1) is mainly based on four as-sumptions. First, microblog users who follow each other, i.e., users with friend relations, tend to be both social spammers or legitimate users. Second, if two users have directed following relation rather than friend relation, then the follower has a higher probability to be social spammer than the followee. Third, social spammers tend to post more spam messages and legitimate users tend to post more normal messages. In other words, users and their messages tend to share the same spam labels. Fourth, microblog messages connect-ed by the same URL or hashtag tend to be both normal or spam. We verified each of these assumptions by conducting hypothesis testing on our dataset.

In order to verify the first assumption, we built two vectors h and h 2 , each with a length of 100. Each element of h 1 is specified by randomly sampling two users with friend relation, and record-ing the absolute difference of the labels of these two users. Each element of h 2 is specified by randomly sampling two users without friend relation, and computing the absolute difference of the labels of these two users. We used two-sample t-test to compare h h . The null hypothesis is that there is no difference between these two vectors, i.e., H 0 : h 1 = h 2 . The alternative hypothesis is that the difference between users with friend relations is less than that without friend relation, , i.e., H 1 : h 1 &lt; h 2 . The t-test result rejects the null hypothesis with the significance level 0.01, and val-idates our assumption that users with friend relations tend to have the same spam labels.

We verified the second assumption using following steps. First we built two 1000-dimensional vectors h 1 and h 2 . Each element of h 1 is obtained by randomly sampling two users with follow-ing relation, and computing the value of the follower X  X  label mi-nus the followee X  X  label. Each element of h 2 is the difference of the labels of two randomly sampled users without following rela-tion. Two-sample t-test was used to compare h 1 with h 2 . The null hypothesis is that there is no difference between h 1 with h H 0 : h 1 = h 2 . The alternative hypothesis is H 1 : h 1 &gt; h followers are more likely to be spammers than followees compared with random user pairs. The t-test result shows that we can reject the null hypothesis with significance level 0.01, and validates the second assumption.

The experiments for validating the third assumption and the fourth assumption are similar with that for validating the first assumption. The difference is that when validating the third assumption, each element of h 1 is the absolute difference between the label of a ran-domly selected user and the label of a randomly selected message posted by this user. Each element of h 2 is the absolute difference between the label of a randomly selected user and the label of a randomly selected message posted by other users. When validating the fourth assumption, the elements of h 1 are the absolute differ-ences of the labels of randomly selected message pairs connected by URLs or hashtags, while the elements of h 2 are the absolute differences of the labels of message pairs without connection. The null hypotheses in these two experiments are both H 0 : h and the alternative hypotheses are H 1 : h 1 &lt; h 2 . The t-test results reject the null hypotheses with strong evidence (significance level 0.01), and validate our third and fourth assumptions.
In this section, we evaluate the performance of our framework on both social spammer classification and spam message classification by comparing it with several baseline methods. The methods to be compared are listed as follows:
The experimental results are shown in Table 2. In each exper-iment, five-fold cross-validation was used. The dataset was ran-domly partitioned into 5 subsets with equal size, where three for training, one for validation and one for testing. The parameters of our framework and all the baseline methods were tuned on the val-idation sets, and the results were recorded on the testing sets. Each experiment was repeated 10 times independently, and the average results are reported. In order to explore the influence of dataset size, we conducted another set of experiments. All the experiment settings are the same with previous experiments except that we ran-domly sampled half of the training data in each experiment. The experimental results are also summarized in Table 2.
 Table 2: Accuracies of different methods. Spammer represents the accuracy of social spammer detection and Spam stands for the accuracy of spam message detection.

By comparing the accuracies of different methods in Table 2, we have following observations:
First, our method achieves the best performance among all the methods compared here on both social spammer detection and s-pam message classification with difference sizes of training da-ta. We used two-sample one-tail t-tests to compare the results of our method with those of the baseline methods. The hypothesis testing results show that our method performs significantly better than all the baseline methods with the significance level 0.01. Our method can outperform traditional classification methods (such as SVM and Logistic Regression) and the method based on sparse learning (LS_Lasso) because the attributes and content of social s-pammers and spam messages are various and evolving, and it is quite difficult to build an accurate enough classifier for social s-pammer detection and spam message detection using traditional classification methods. Our method tries to alleviate this difficul-ty by exploiting the social contexts of users and messages to re-fine the classification results, which can provide additional infor-mation besides the attributes, behaviours and textual content infor-mation. The experimental results show that incorporating social contexts into our framework can improve the classification accu-racy significantly. These results validate the usefulness of social contexts in social spammer detection and spam message detection. SSDM and Co-Classify methods also incorporate social contexts for social spammer detection and/or spam message detection. The main difference between these methods and our method is the way of utilizing social contexts. In SSDM and Co-Classify, the social contexts are used in the model learning stage to constrain the user-user pair or user-message pair with social relations to have similar scores. However, in prediction stage, only the textual content and attributes are considered. Due to same reasons mentioned previous-ly, it is still difficult to train an accurate enough classifier even with the help of social contexts. Different from these methods, in our framework, the social contexts are used in the prediction stage. We exploit the graph structure over the output variables extracted from the various kinds of social connections between users and messages to make more accurate predictions. The superior performance of our method compared with those of SSDM and Co-Classify vali-dates the advantage of our framework in utilizing social contexts for social spammer detection and spam message detection.
Second, the accuracies of all the methods with half of the training data are not significantly different from those with all the training data. This result implies that our dataset is big enough for training social spammer classifier and spam message classifer. Thus further increasing the size of training data is not helpful for improving the classification accuracy significantly. The relatively low accuracy is mainly due to the inherent difficulties of these tasks rather than lack of training data. However, our method can improve the classifica-tion accuracy consistently and significantly without any additional Figure 3: Contributions of different kinds of social contexts to the performance improvement of our framework. None rep-resents the performance of the original Logistic Regression. Friend , Following , Post and M-M represent the performance of our framework with the friend relations between users, the fol-lowing relations between users, the user-message relations, and the message-message relations respectively. All represents the performance of our framework with all these social contexts. Figur e 4: The influences of parameters  X  and  X  on social spam-mer detection. training data. This is because our method can exploit and incorpo-rate another kind of information in the testing data, i.e., the social contexts, since in social media users and messages are networked.
We also conducted experiments to explore the contributions of different kinds of social contexts to the performance improvement of our framework. We examined the influence of a certain kind of social contexts by setting the coefficients of others to 0 in Eq. (1). The experimental results are shown in Fig. 3.

From the results in Fig. 3, we can draw three conclusions. First, all the user-related social contexts, such as the friend relations, the following relations, and the user-message relations, are helpful for improving the performance of social spammer detection. Similar-ly, the two kinds of message-related social contexts, i.e., the user-message relations and message-message relations, are both helpful for improving the performance of spam message detection. These results validate that all the social contexts introduced in Section 3 are useful under our framework. Second, among all the social con-texts compared here, the user-message relation is the most powerful one on both social spammer detection and spam message classifi-cation. This result validates our assumption in the Section 1, i.e., combining social spammer detection and spam message detection together can boost the performance of each task because social s-pammers and spam messages are closely connected. Third, our framework performs best when all the social contexts are incor-porated. This indicates that different kinds of social contexts can collaborate with each other under our framework. Thus our unified framework is effective in incorporating various social contexts. Figure 5: The influence of parameter  X  on social spammer de-tection and spam message detection. Figure 6: The influence of parameter  X  on spam message de-tection.
In this section we conducted experiments to explore the influ-ences of parameters on the performance of our framework. There are four important parameters to tune in our framework (Eq. (1)), i.e.,  X  ,  X  ,  X  and  X  . Parameters  X  and  X  are used to control the im-portance of friend relations and following relations between users respectively. Parameter  X  is used to control the penalty introduced by user-message relations. Parameter  X  represents the importance of message-message relations. We examined the influence of each parameter independently by setting other parameters to zeros. The experimental results are shown in Fig. 4, Fig. 5 and Fig. 6.
From these figures we can see that the influences of parameters  X  ,  X  ,  X  and  X  on the performance of our framework show similar patterns. When the values of these parameters increase from 0, the performance of our framework first increases quickly, then reaches the peak, and decreases afterwards. This is because when param-eter values are too small, the information in these social contexts is not fully used. Thus the performance improves as the param-eters increase from a small value. However, when the values of parameters are too large, the information in these social contexts is overemphasized. The prediction results will be overwhelmed by the social contexts. Since social contexts contain some noise inevitably, the performance will be harmed if parameters are too large. An interesting pattern observed in the experiments is that as long as the parameter values are in a moderate range, the perfor-mance of our framework is always better than that without social context. This implies that incorporating social contexts is always helpful under our framework, and it is not difficult to select ap-propriate values for these parameters either by cross validation or empirically.
In this section we conducted experiments to explore the time complexity of our framework and compare the efficiency of our ADMM based method with that of subgradient method in solving our framework. In each experiment, we randomly sampled N mes-sages. Then we extracted all the associated users and all the social relations of these messages and users. We varied N from 5,000 to 10,000. Each experiment was conducted 10 times independently and the average results were recorded. The algorithms ware imple-mented using Matlab R2011b. All the experiments were conducted on a laptop computer running Windows 7 with Core i5 CPU and 8GB RAM. The experimental results are shown in Fig. 7.

From Fig. 7 we can see that the running time of our framework with ADMM-based algorithms is approximately linear with the da-ta size when data size gets large, which is a promising property for analyzing large-scale microblog data. In addition, our framework with ADMM-based algorithms is much faster than that with sub-gradient algorithm, which validates the usefulness of Algorithm 1 and Algorithm 2 in improving time efficiency.
This paper presents a unified framework for social spammer and spam message co-detection in microblogging. Our framework can incorporate various social contexts of the microblog users and mes-sages, and refine the results of social spammer classification and spam message classification by exploiting their social connection-s. Three kinds of social contexts are extracted, i.e., the friend and following relations between users, the posting relations between users and messages, and the connections between messages. In our framework, the social spammer detection and spam message de-tection are combined using the posting relations between users and messages. The friend and following relations between users and the connections between messages are modeled as the regulariza-tion terms over the prediction results in our framework. In addition, we propose an accelerated algorithm based on ADMM to solve our framework efficiently. Extensive experiments on a real-world mi-croblog dataset show that our framework can outperform baseline methods significantly and consistently.
We would like to thank Dr. Yangqiu Song for his kind sugges-tions. We are grateful to the anonymous reviewers for their help-ful comments. This research is supported by the Key Program of National Natural Science Foundation of China under Grant No. U1405254, and the National Natural Science Foundation of Chi-na under Grant No. 61472092 and 61472092. [1] L. Becchetti, C. Castillo, D. Donato, S. Leonardi, and R. A. [2] A. Beck and M. Teboulle. A fast iterative [3] K. Beck. Analyzing tweets to identify malicious messages. [4] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. [5] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All your [6] E. Blanzieri and A. Bryl. A survey of learning-based [7] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. [8] S. Boyd and L. Vandenberghe. Convex optimization .
 [9] G. Brown, T. Howe, M. Ihbe, A. Prakash, and K. Borders. [10] F. Chen, P.-N. Tan, and A. K. Jain. A co-classification [11] X. Chen, S. Kim, Q. Lin, J. G. Carbonell, and E. P. Xing. [12] G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes [13] C. Ding, T. Li, and M. I. Jordan. Convex and [14] H. Gao, Y. Chen, K. Lee, D. Palsetia, and A. N. Choudhary. [15] S. Ghosh, B. Viswanath, F. Kooti, N. K. Sharma, G. Korlam, [16] J. M. G X mez Hidalgo, G. C. Bringas, E. P. S X nz, and F. C. [17] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @ spam: the [18] Z. Gy X ngyi, H. Garcia-Molina, and J. Pedersen. Combating [19] X. Hu, J. Tang, and H. Liu. Leveraging knowledge across [20] X. Hu, J. Tang, and H. Liu. Online social spammer detection. [21] X. Hu, J. Tang, Y. Zhang, and H. Liu. Social spammer [22] N. Jindal and B. Liu. Review spam detection. In WWW , [23] K. Lee, J. Caverlee, and S. Webb. Uncovering social [24] C. Lin, J. He, Y. Zhou, X. Yang, K. Chen, and L. Song. [25] L. Liu and K. Jia. Detecting spam in chinese microblogs-a [26] J. Martinez-Romo and L. Araujo. Detecting malicious tweets [27] M. McCord and M. Chuah. Spam detection on twitter using [28] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. [29] D. O X  X allaghan, M. Harrigan, J. Carthy, and P. Cunningham. [30] P. Oscar and V. Roychowdbury. Leveraging social networks [31] N. Parikh and S. Boyd. Proximal algorithms. Foundations [32] J. Ratkiewicz, M. Conover, M. Meiss, B. Gon X alves, S. Patil, [33] J. Song, S. Lee, and J. Kim. Spam filtering in twitter using [34] G. Stringhini, C. Kruegel, and G. Vigna. Detecting [35] R. Tibshirani. Regression shrinkage and selection via the [36] A. H. Wang. Don X  X  follow me: Spam detection in twitter. In [37] S. Webb, J. Caverlee, and C. Pu. Social honeypots: Making [38] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: finding [39] X. Zhang, S. Zhu, and W. Liang. Detecting spam and
