 FANG WU and BERNARDO A. HUBERMAN HP Labs, Palo Alto 1. INTRODUCTION
Since opinions play such an important role in trust building and the creation of consensus about many issues and products, there have been a number of recent studies focused on the design, evaluation and utilization of online opin-ion systems [Dellarocas 2000, 2006; Cosely et al. 2003; Gao et al. 2006; Hu cesses such as group polarization [Asch 1955; Myers 1982; Sunstein 2002] and information cascades [Banerjee 1992; Bikhchandani et al. 1992; Salganik ception of one study [Li and Hitt 2004], little research has been done on the dynamic aspects of online opinion formation. It remains unclear, for ex-ample, whether the opinions about books, movies, or societal views fluctu-ate a long time before reaching a final consensus or they undergo systematic changes as time goes on. Thus the need to understand how online opinions are created and evolve in time in order to draw accurate conclusions from that data.

On reflection, it is rather surprising that people contribute opinions and re-views of topics which have already been extensively covered by others. While posting views is easy to understand when it involves little effort, like clicking on a button of a Web site, it is more puzzling in situations where it is costly, such as composing a review. (e.g., when an Amazon user decides to review a simple star rating. The average word count of Amazon reviews is 181.5 words [Ketzan 2002], so the cost of opinion expression is indeed high.) If the oppor-tunity to affect the overall opinion or rating diminishes with the number of published ones, why does anyone bother to incur the cost of contributing yet another review? From a rational choice theory point-of-view, if the utility to be gained does not outweigh the cost, people would refrain from expressing their views. And yet they do not. This is reminiscent of the well analyzed voter X  X  paradox [Downs 1957; Riker and Ordeshook 1968] where a rational calculation of their success probability at determining the outcome of an election would make people stay home rather than vote, and yet they show up at the polls cept of winning in online opinion systems. Rather, by contributing her own opinion to an existing opinion pool, a person affects the average or the distri-bution of opinions by a marginal amount that diminishes with the size of that pool.

Recently, Schlosser [2005] has pointed out that posters (those who post opin-ions) tend to disagree with previous ones because they do not want to be per-ceived as indiscriminate, while lurkers (those who do not post opinions) are less affected by others X  negative opinions [Amabile 1983]. In an empirical study in-volving a few hundred students, she found out that posters presented more than one side when publicly explaining their attitudes despite their favorable product experiences and commitment to these attitudes. Interesting as these findings are, they have not been extended to very large scale (i.e., millions of opinions) in a real-world setting.

Within this context, we studied the dynamics of online opinion expres-ranging from online reviews of the best-selling books at movie reviews at the Internet Movie Database IMDB . On the massive scale that the web offers, we observed that later opinions in the course of time tend to show a large difference with previous ones, which moderates the average opinion to the less extreme. Furthermore, posters tend to dis-agree with previous ones when the cost of expression is higher. This is a robust and quantitative observation which conforms with Scholosser X  X  hypotheses.
 2. STUDY 1: AMAZON.COM 2.1 Data
We will use the following notations throughout this article: X quantified value of the n th opinion of one particular item; denotes the average value of the first n opinions of one particular item; EX denotes the sample mean of X n for all items in a dataset; E sample mean of  X  X n for all items in a dataset.

In order to perform our study on online opinions, we first analyzed book ratings posted on Amazon.com . Our sample consisted of 1,729,830 book ratings of the top 4,000 best-selling titles of Amazon in each of the following 12 categories, as of July 1, 2007: arts and photography, biographies and memoirs, history, literature and fiction, mystery and thrillers, reference, religion and spirituality, sports, travel, nonfiction, science, and entertainment. For each of the 48,000 books, a series of user ratings was collected in time order, where each rating is an integer between 1 and 5. Among the 48,000 books, 16,454 books have no less than 20 ratings, 7,385 books have no less than 50 ratings, and 3,495 books have no less than 100 ratings. 2.2 Results
We first checked the average rating of books ( EX n ) in each of these three sets of books as a function of the rating index ( n ). As can be seen from Figure 1(a), the ratings are generally favorable (the average of all 1,729,830 ratings is  X 
X to write different reviews from those of earlier users. This is consistent with the empirical finding of Ariely and Levav [2000] that when group members voice their opinions sequentially, an opinion shift may be induced. However, as opposed to the widely observed group-polarization effect, the overall opinion on Amazon tends to decrease away from the extreme ones.

Since the book ratings in our dataset are generally favorable, one might wonder whether the moderating effect in Figure 1(a) is merely an artifact of high initial ratings. It would be helpful if one could locate a set of books with low initial ratings and see if their ratings also exhibit a moderating effect over time. To this end, we divided the books into 6 tiers based on the average value of their first 3 ratings (  X  X 3 ) and plotted the average rating as a function of the rating index for each tier. As one can see in Figure 1(b), all 6 tiers tend to move closer to the overall mean  X  X all = 4 . 04 as opposed again to the divergent pattern commonly observed in group polarization experiments.

In order to better compare our results with existing studies of group po-larization, which usually measure the difference between the final and initial average opinion, we next measured the change of ratings at the level of each individual book. For each book with l  X  2 n ratings, we calculated the mean (  X 
X alternative hypothesis  X   X  X l  X  n + 1 , l &lt;  X  X 1 , 1 to 50. The results are listed in Table I (see also Figure 2). As can be seen, the conclusions drawn from Figure 1(b) are robust.

While these empirical findings reveal interesting trends in online opinion formation in contrast to group polarization, we stress that the convergence pattern shown in Figure 1(b) does not necessarily imply that people come to an agreement in the end. In fact, when we measured the standard deviation 2 n ratings, all 49 tests supported the alternative hypothesis  X  with p -value less than 0.001 for n = 2 ,..., 50, suggesting diversification of opinions over time. We also measured the fraction of each star rating as a among all the n th ratings in our dataset for r = 1 the growth of fractions for r = 1 , 2 , 3 , 4. As one can see, the fraction of 1-star ratings grows fastest, indicating that instead of ending with a group of people with moderate opinions, one observes a variety of diverse views. This shows that public discourse on Amazon typically intensifies over time and does not reach a consensus in the end in contrast to the imitative behavior seen in herding and information cascades.

In Figure 1(b), we could only compare the ratings of two groups of subjects (the first n and the last n ), for Amazon does not allow its users to leave multiple reviews. Hence our results do not necessarily imply that as time goes on the average opinion of the whole population changes for the late reviewers might come from a different group than the earlier ones and need not be representa-tive of the whole population. This is seen when plotting the average  X  X elpful ratio X  as a function of star rating in Figure 4 for users of seen, the whole population finds high ratings in general more helpful than low ratings. If one assumes that agreeing with a review is correlated with finding it useful, this implies that the majority of the population does not necessarily agree with the low ratings. This additional data then suggests that rather than indicating a real choice shift in the whole population, the observed dynamic trend on Amazon might be more of a selection bias . By this we mean that the more recent ratings are generated by a subgroup of users whose opinions devi-ate considerably from the average opinion of the whole group, a point that we will elaborate below.
 2.3 Discussion One possible explanation for these results is that in cases like will derive more utility the more they can influence the overall rating as in the voter X  X  paradox. To be precise, in cases where users X  opinions can be quantified and aggregated into an average value (when a user opens up a book page on title), the influence of an online opinion can be measured by how much its expression will change the average opinion [Osborne et al. 2000]. Suppose that n users have expressed their opinions, X 1 ,..., X n , on a given topic at a Web site. If the ( n + 1)th person expresses a new opinion X average rating to  X  X n + 1 = ( n  X  X n + X n + 1 ) / ( n average rating is given by |  X  X n + 1  X   X  X n |=| X n + more likely to express her opinion whenever | X n + 1  X   X  likely to be expressed if it deviates by a significant amount from those already stated. Indeed, what is the point of leaving another 5-star review after one hundred people have already done so? This point has similarities to Schlosser X  X  hypotheses [2005], and has also been made within the  X  X rag-and-moan X  model [Hu et al. 2006; Dellarocas and Narayan 2006], which assumes that consumers only choose to write reviews when they are very satisfied with the products they purchased (brag), or very disgruntled (moan). Note however, that the brag-and-moan model is static and thus predicts that  X  X in contradiction to the observed dynamical trends.

In order to test our hypothesis, we measured directly how much one X  X  rating deviates from the observed average rating. We plot the expected deviation
Ed seen, Ed n increases with n . Since the expected deviation Ed and identically distributed sequence normally decreases with n , this increasing trend is indeed significant.

It is known in the group polarization literature that exposure to the group average is sufficient to stimulate a more polarized response and that those polarized than those who merely witnessed the group average [Brown 1974; Myers 1978]. Because Amazon also shows its users a histogram of all the past ratings and a list of the most recent ratings near the bottom of the page, we also measured the deviation of each rating from its recent three predecessors.
Figure 5(b) plots Ed n = E | X n  X  ( X n  X  3 + X n  X  2 + X only the increasing trend remains but the deviation actually exceeds Ed 0.05 stars. This again supports our conjecture that those users who disagree with the existing average will be more willing to express themselves and thus soften the overall opinion of a given book. 3. STUDY 2: IMDB.COM 3.1 Data While our hypothesis seems to explain the softening of opinions observed in
Amazon , it would be more conclusive if one could conduct a test that directly compares people X  X  opinions expressed at different cost levels. In order to address this issue we conducted a study of IMDB.com (The Internet Movie Database).
Unlike users of Amazon who are required to write a review when rating a book, users of IMDB are free to choose the effort level when reviewing a movie.
Specifically, after observing the current average rating of a movie, a user can either submit a quick rating by clicking on a scale of 10 stars or make the extra effort involved in writing a comment between 10 and 1,000 words.

Our dataset consists of all 1,275 USA movie titles released after year 2000 which have no less than 5,000 ratings, as of August 1, 2008. The list of titles were obtained using IMDB X  X  Power Search engine. A constraint on the number of ratings is necessary because the proportion of commented rating among all ratings is very low (1 . 17% in our dataset). For each movie, we know its average rating (taken among all ratings with or without a comment) as well as the value and date-stamp of each of its commented ratings, but we do not have any specific information about each uncommented rating. There are 407,557 commented ratings in total. We divided the movies into 3 tiers based on their ratings: the top tier contains 545  X  X ood movies X  whose ratings are at least 7, the bottom tier contains 34  X  X ad movies X  whose ratings are at most 4, and the middle tier contains the rest. 3.2 Results
We observed a clear decreasing trend in the ratings associated with comments in the top tier, as shown in Figure 6. We did not observe any clear trend in the bottom tier. Similar to the Amazon study, we tested the alternative hypothesis  X   X 
X  X  n + 1 , l &gt;  X  X 1 , n  X  in each of the three tiers, for n the top tier and the middle tier all support the alternative with p -value less than 0.001. None of the 50 tests in the bottom tier yield statistically significant results (i.e., the alternative can neither be supported nor rejected), possibly due to its small size. While it is not reliable to say that bad movies tend to receive higher ratings, it is safer to conclude that good movies accumulate lower ratings as time goes on.

We also examined the difference between the overall average rating (with or without a comment) and the average rating associated with a comment for each movie, and the result is shown in Figure 7. Assuming as we do that the benefit of opinion expression diminishes as the number of opinions grows, it follows that it is those who are willing to incur a high cost that will continue to express opinions at very late times. Since the data in the figure shows that the latter deviate opposite from the population average, this offers a tenta-tive (but not conclusive) explanation for the moderating effect in the average opinion.

An alternative explanation is that people are reluctant to be the first one to dissent so after the first bad review appears, a series of bad reviews follow up.
To test the effect of pioneering bad reviews, we counted the number of 1-star ratings among the first n ratings of each Amazon title (denoted by Y performed the linear regression X n + 1  X  a + b  X  X n + cY fittings yield a statistically significant coefficient c between suggesting a weak herding effect. 4. CONCLUSION
In this article, we studied the dynamics of online opinion expression by ana-lyzing the temporal evolution of a very large set of user views, ranging from online reviews of the best selling books at Amazon.com , and movie reviews at the
Internet Movie Database IMDB . Our observations revealed that later opinions tend to show a large difference with previous ones, which in turn moderates the average opinion to the less extreme. When opinion expression is costly, we found that people tend to project a perception of being discriminate by disagreeing with previous ones. This is a robust and quantitative observation in conformity with Scholosser X  X  hypotheses [2005].

These results also show that in the process of articulating and expressing their views online, people tend to follow a different pattern from that observed in information cascades or group polarization. This might be due to the fact that both at Amazon and IMDB , the setting and measurements differ from the standard ones in group polarization experiments and information cascades.
We point out, however, that it is opinions like the ones we studied that are increasingly used by millions of people to navigate the sea of information they encounter every day. Thus these results might be of practical value. We close with a cautionary note on the interpretation of online public opinion.
This is because a simple change in the order or frequency of given sets of views can change the ongoing expression in the community and thus the perceived collective wisdom that new users will find when accessing that information.
