 Many classification tasks, such as spam filtering, intrusion detection, and terrorism detection, are complicated by an adversary who wishes to avoid detection. Previous work on adversarial classification has made the unrealistic assump -tion that the attacker has perfect knowledge of the classifie r [2]. In this paper, we introduce the adversarial classifier reverse engineering (ACRE) learning problem, the task of learning sufficient information about a classifier to constru ct adversarial attacks. We present efficient algorithms for re-verse engineering linear classifiers with either continuou s or Boolean features and demonstrate their effectiveness using real data from the domain of spam filtering.
 I.2.6 [ Artificial Intelligence ]: Learning X  Concept learn-ing ; F.2 [ Analysis of Algorithms and Problem Com-plexity ]: Miscellaneous Algorithms, Theory Adversarial classification, linear classifiers, spam
Systems using machine learning have been successfully de-ployed for fighting spam, fraud, and other malicious activ-ities. These systems typically consist of a classifier that flags certain instances as malicious based on a fixed set of features. For example, spam filters classify each incoming email message as spam or legitimate email by using a set of features such as which words are present.

Unfortunately, as classifiers become more widely deployed, the incentive for defeating them increases. In some domains , there is ample evidence that adversaries are actively modif y-ing their behavior to avoid detection. For instance, sender s of junk email often disguise their messages by adding unre-lated words, sentences, or even paragraphs more indicative of legitimate email than spam.

Dalvi et al. explore the possibility of anticipating such at -tacks by computing the adversary X  X  optimal strategy [2]. To do so, they make the unrealistic assumption that the adver-sary has perfect knowledge of the classifier. This is rarely true in practice: adversaries must learn about the classi-fier using some combination of prior knowledge, observation , and experimentation.

In this paper, we explore the role of active experimenta-tion in adversarial attacks. In particular, we consider cas es in which an adversary can send membership queries to the classifier to determine whether a specific instance is mali-cious or not. The adversary X  X  goal is not to perfectly model the classifier, but rather to identify high-quality instanc es that are not labeled malicious with a reasonable (polyno-mial) number of queries. We define the adversarial classifier reverse engineering (ACRE) learning problem to formalize this problem. The ACRE learning problem differs signifi-cantly from both the probably approximately correct (PAC) model of learning [6] and active learning [1] in that (1) the goal is not to learn the entire decision surface, (2) there is no assumed distribution governing the instances and (3) succe ss is measured relative to a cost model for the adversary.
While solving the problems of adversaries such as spam-mers may seem counterproductive, we believe that learning the vulnerabilities of current classifiers is the only way to fix them in the future.

The remainder of our paper is organized as follows. We first define when an ACRE problem is learnable in Section 2 and describe adversarial cost functions in Section 3. In Sec -tion 4, we present basic results regarding classifiers that a re Boolean formulae. In Section 5, we prove efficient reverse engineering algorithms against linear classifiers. In part icu-lar, we show that, for some adversary cost functions, these classifiers are ACRE learnable. We present empirical result s for the real-world domain of spam filtering in Section 5, and conclude in Section 6.
We define a reverse engineering problem for classifiers over a fixed instance space , X , consisting of n -dimensional feature vectors. Each feature X i may be real, integer, Boolean, etc. We refer to elements x  X  X as instances . We use x i to denote the value of the i th feature in instance x .
A classifier , c , is a function from instances x  X  X to values in the set { 0 , 1 } (i.e., a Boolean classifier). We refer to instances x for which c ( x ) = 1 as positive instances (i.e., those labeled as malicious), and those for which c ( x ) = 0 as negative instances .

We assume that the adversary can issue membership queries to the classifier for arbitrary instances and has access to an adversarial cost function a ( x ) that maps instances to non-negative real numbers. The adversary is also provided with one positive instance, x + , and one negative instance, x For most domains, this is not an onerous assumption.
The adversarial cost function represents the increased cos t (or decreased utility) of using some instances as compared t o others. In the spam domain, for example, some spam mes-sages are more effective at selling products. In credit card fraud, forgoing certain purchases may decrease the likeli-hood of detection, but it may also decreases the fraudster X  X  reward.

The assumptions that the adversary can issue queries in instance space and that the adversary has a cost function over instances is an idealization. In many domains, an ad-versary can make educated guesses about the features that define an instance. In others, the mapping from object to instance may be difficult to determine, preventing the adver-sary from constructing arbitrary instances or defining a cos t function over the instance space. Our goal is not to analyze this often domain specific problem of learning about feature representations but to focus on the ability for an adversary to reverse engineer a classifier assuming this knowledge.
The minimal adversarial cost (MAC) of a classifier c and cost function a is the minimum cost a ( x ) over all instances x classified negatively by c : We also define instances of minimal adversarial cost (IMAC) as the set of all instances x classified negatively by c and with minimal cost: IMAC( c, a ) = { x  X  X | a ( x ) = MAC( c, a ) and c ( x ) = 0 }
The adversarial classifier reverse engineering (ACRE) learn-ing problem for classifier c and adversarial cost function a is to find an instance x  X  IMAC( c, a ); that is, an instance that is classified as non-malicious and has a minimum cost of all instances classified as non-malicious.

We say that a set of classifiers C is ACRE learnable under a set of cost functions A if an algorithm exists that, for any c  X  C and any a  X  A , finds some x  X  IMAC( c, a ) using only polynomially many membership in: n , the number of features; size ( c ), the encoded size of c ; and size ( x encoded size of the positive and negative instances.
We assume that numerical parameters in c , x + , and x  X  are encoded as strings of digits in a known, fixed base, so that excessively large or small values require longer encod -ings. With minimal changes, we can also handle encodings in scientific notation, e.g. 1 . 234  X  10 5678 , in which the en-coding size may be doubly logarithmic in the magnitude of the value.

For situations where finding an IMAC is intractable, we define k -IMAC, the set of all negative instances whose costs are within a constant factor k of the MAC: k  X  IMAC( c, a ) = { x  X  X | a ( x )  X  k MAC( c, a ) and c ( x ) = 0 }
Finally, we say that a set of classifiers C is is ACRE k-learnable under a set of cost functions A if, for any c  X  C and any a  X  A , an algorithm exists that always finds x  X  k  X  IMAC( c, a ) using a polynomial number of queries as in ACRE learning.
The hardness of an ACRE learning problem depends not only on the classifier, but also on the adversarial cost func-tion. In the extreme case, in which the cost function is con-stant for all instances, the adversary need not issue a singl e membership query because the adversary is given a negative instance and every negative instance is optimal. While the hardness of an ACRE learning problem does depend on the adversarial cost function, the precise relationship betwe en the hardness of ACRE learnability and the complexity of the adversarial cost function is subtle. For instance, if th e adversary can efficiently learn the exact parameters of the classifier, then the problem would be ACRE learnable for any well-behaved adversarial cost functions because the ad -versary need not issue any membership queries to optimize the cost function. In this paper, we investigate a specific class of cost functions that is easy to analyze but still cap-tures interesting adversarial problems.

A linear cost function is the weighted absolute difference between feature values in the base instance, x a , and those in the target instance, x :
By representing the cost a ( x ) in terms of the base instance x , we capture the reasonable assumption that the instances most similar to x a are best. The scalars a i represent the relative cost of changing each feature, allowing that some features may be more important or more expensive than others. We assume that all a i are greater than zero.
In spam, for example, x a would be the email that makes the best sales pitch for the adversary X  X  product. Each chang e to this email reduces its effectiveness, but some changes cos t more than others. For instance, one might expect that the cost of removing the product X  X  name would be larger than the cost of removing most other words and thus the scalar associated with the product name would be larger than most other words.

We also consider the restricted subset of uniform linear cost functions , where every a i is one. In the spam domain, this could represent a spammer who simply wishes to add or obfuscate as few words as possible. While uniform linear cost functions are less expressive than linear cost functio ns, they make ACRE learning tractable for some problems.
In this section, we assume that instances have only Boolean features and that each classifier c expresses the set of posi-tive instances as a Boolean formula in terms of the literals X i (1  X  i  X  n ).

In general, this set of classifiers is not ACRE learnable under most interesting adversarial cost functions. Consid er the classifier that only classifies two instances as negative , x and x  X  X  . This can easily be expressed as a Boolean for-mula with size O ( n ). If x  X  is the unique IMAC according to the adversarial cost function a , but the provided negative instance x  X  = x  X  X  , then the adversary can only find x  X  lucky guess or an exponential brute-force search.

Certain classes of Boolean formulae, however, are ACRE learnable. In particular, any class of Boolean formulae tha t can be learned using only a polynomial number of member-ship queries is ACRE learnable due to the finiteness of the instance space. For example, consider disjunctions of con-junctions of k unnegated literals (monotone k -DNF). We can learn this concept class in O ( n k ) queries by exhaus-tively testing possible k -DNF clauses and find an IMAC by brute-force searching through the negative instances.
In addition, because the adversary is given a positive in-stance, they can efficiently learn arbitrary conjunctions, e .g. X 2  X  X  X 4  X  X 5 . This can be accomplished by starting from the positive instance x + and successively negating each fea-ture to find the features in the conjunction X  X  feature is listed in the conjunction if, after negating the feature, th e modified instance is classified as negative. We can therefore determine the exact conjunction in only n queries. Since the negation of a conjunction is a disjunction, we can anal-ogously learn disjunctions of Boolean literals starting fr om the negative instance, x  X  .

Proving the learnability of less restricted Boolean formu-las under different adversarial cost functions is a topic for future work.
In this section, we demonstrate the ACRE k -learnability of linear classifiers under the adversarial cost functions d e-scribed in Section 3. We consider the case in which all of the features are either real-valued or Boolean.

Linear classifiers are one of the most popular types of clas-sifier, due to their efficacy, simplicity and scalability. For example, many spam filters are naive Bayes models, a spe-cial class of linear classifiers. Support vector machines wi th linear kernels and maximum entropy models are other ex-amples of linear classifiers widely used for text classificat ion.
A linear classifier consists of a set of n weights (one for each feature X i ), which we represent as a vector w  X  R n and a threshold, T . Thus, x is a positive instance if w x &gt; T , and is otherwise a negative instance. We refer to | w x  X  T | as gap ( x ). The gap of a negative (positive) instance is the weight that would have to be added (subtracted) to make it a positive (negative) instance.

A pair of instances can indicate the sign of a feature weight. Given a linear classifier c , a sign witness to a fea-ture f is a pair of instances, s + and s  X  such that c ( s c ( s  X  ) = 0, and  X  i 6 = f, s +
From the classifier definition, w s + &gt; T and w s  X   X  T , so it follows that w s +  X  w s  X  &gt; 0. Since s + and s  X  differ in feature f , this reduces to w f ( s + f  X  s  X  f the sign of feature f .
We begin with the case in which all features are contin-uous. Our approach to demonstrate ACRE learnability is to first efficiently approximate feature weights and second to use these approximate weights to identify low cost instance s.
We begin by describing FindWitness , a subroutine for finding a sign witness for some feature f , given one positive and one negative instance (e.g., x + and x  X  ). This procedure starts with x + and changes feature values one at a time to match those of x  X  . At some point, the instance classifica-tion must change, and the most recently changed feature, f , must have non-zero weight. The previous value and the cur-rent value of the intermediate instance constitute the sign witness. This requires at most n membership queries.
Our algorithm FindContinuousWeights for learning the weights is provided in Algorithm 1. The algorithm proceeds by finding a single feature with non-zero weight, construct-ing an instance of known gap, and computing the relative weights of all other features using line searches along each feature dimension. We next describe the algorithm in detail .
The inputs to the algorithm are positive and negative in-stances x + and x  X  , an approximation threshold  X  , and a lower bound on the magnitude of the ratio of any two non-zero weights  X  . (Although the adversary may not know a good  X  a priori, the ACRE learning algorithm we later present provides a value that still guarantees a good approx -imation.) The first step (i.e., FindWitness ) is to find some feature f with non-zero weight and a sign witness ( s + , s for that feature. The instances in the sign witness have dif-ferent values for the feature f and the same values for all other features. Since scaling the weights and threshold by a positive number has no effect on the decision boundary, we may assume that the weight of w f is 1.0 or -1.0, depending on if its value is larger in the s + or s  X  . Since w f has unit magnitude and s + and s  X  differ only in feature f :
We refine the gap between our original sign witnesses using a binary search on the value of feature f to find a negative instance x with gap less than  X / 4. This requires O (log(1 / X  ) + size ( s + , s  X  )) queries. We increase or decrease x f by 1.0 to obtain instance with gap between 1 and 1+  X / 4.
Finally, we compute the relative weight of each other fea-ture using a line search. This consists of increasing or de-creasing each x i exponentially until the class of x changes, then bounding its exact value using a binary search. By finding feature values within (1 +  X / 4), our total error is at most (1+  X / 4) 2 &lt; 1+  X  , for  X  &lt; 8. We ensure termination by testing the addition or subtraction of 1 / X  first; if the class re-mains unchanged, we assume w i = 0. The number of queries per feature is logarithmic in 1 / X  and the ratio w f /w i our assumed encoding, log( w f /w i ) is O ( size ( c )), so the total number of queries is polynomial.

Note that very large and very small weights require length-ier encodings. In fact, if we know the encoding length of the original classifier, size ( c ), then no parameter can have mag-nitude greater than 2 size ( c ) and none can be less than 2 Thus, we can find exact weights when  X  =  X  = 2  X  2 size ( c )
Theorem 5.1. Let c be a continuous linear classifier with vector of weights w , such that the magnitude of the ratio between two non-zero weights is never less than  X  . Given positive and negative instances x + and x  X  , we can find each weight within a factor of 1+  X  using a polynomial number of queries.

Proof. Follows from the correctness of the algorithm and the fact that each step uses at most polynomially many membership queries. Algorithm 1 FindContinuousWeights ( x + , x  X  ,  X  ,  X  ) ( s + , s  X  , f )  X  FindWitness ( x + , x  X  ) w f  X  1 . 0 ( s + f  X  s  X  f ) / | s + f  X  s  X  f |
Use ( s + , s  X  ) to find negative instance x with gap ( x ) &lt;  X / 4 for each feature i 6 = f do end for
We now describe how to use approximately learned feature weights to identify low-cost instances.

Recall that linear cost functions define the cost of an in-stance as a weighted sum of feature differences, relative to some base instance x a . In a continuous linear classifier, we can arrive at an approximate IMAC instance by changing only one feature in x a : the feature f with highest weight-to-cost ratio, | w f | /a f . Were we to use any other feature, we could always achieve the same benefit for cheaper by changing f instead.

This property of linear cost functions and linear classifier s enables us to efficiently approximate instances of minimal cost with arbitrary precision. Our algorithm FindContin-uousIMAC for doing this is listed in Algorithm 2.

The inputs to our algorithm are a positive and a negative instance, x + and x  X  , and an approximation threshold,  X  .
The first step is to approximately learn all feature weights, within 1 +  X / 4. Algorithm 1 depends on knowing the mini-mum absolute weight ratio,  X  . Although the adversary may not know this value, we can use the minimum feature cost ratio, a i /a j , in its place. Since no feature with a smaller weight can have the largest cost ratio, we may safely ap-proximate those feature weights as zero.

We then select the feature f with highest weight-to-cost ratio. Since our weights are learned approximately, this ma y not be the optimal feature, but it X  X  close enough that our cost is within a fixed ratio of optimal. We find a (1 +  X  )-IMAC by doing a line search from x a along dimension f , to bound the change in x a f within a factor of 1+  X / 4. Our total error is therefore (1 +  X / 4) 2 &lt; 1 +  X  . The number of queries required for this line search is O (log(1 / X  ) + log( gap ( x a ))), but gap ( x a ) and 1 / X  are constants.
 Algorithm 2 FindContinuousIMAC ( x + , x  X  ,  X  )  X   X  min i a i
Run FindContinuousWeights ( x + , x  X  ,  X / 4 ,  X  ) f  X  argmax i | w i | /a i t  X  LineSearch ( x a , f,  X / 4)
Let  X  f be the unit vector along dimension f return x a + t  X  f
Theorem 5.2. Linear classifiers with continuous features are ACRE (1 +  X  ) -learnable under linear cost functions.
Proof. Follows from the correctness of the algorithm and the fact that each step uses at most polynomially many membership queries. We now consider the case in which all features are Boolean. In sharp contrast to the case in which all features are con-tinuous, we show that learning even the sign of all features is NP-hard. Despite this hardness result, we demonstrate that, for uniform linear cost functions, the problem is ACRE 2-learnable. Unlike the previous analysis, the adversary s uc-ceeds in this reverse engineering problem by obtaining only partial knowledge of the classifier while identifying near o p-timal instances.

Evidence regarding the sign of a feature weight is provided by a sign witness. If a feature has no sign witness then the feature is irrelevant to the adversary because changing the feature in any instance never changes the class. The fol-lowing theorem demonstrates that even determining which features are relevant can be very hard to do.

Theorem 5.3. In a linear classifier with Boolean features, determining if a sign witness exists for a given feature is NP -complete.

Proof. Clearly, the problem is in NP, because we can non-deterministically pick a witness, if one exists, and ve rify it with only 2 queries to the classifier.

We prove that the problem is NP-hard via a reduction from subset sum. In the subset sum problem, we are given a set of integers S = { s 1 , s 2 , . . . , s n } and an integer t and want to determine if there exists a subset S  X   X  S such that P
We convert an instance of subset sum into a linear classi-fier with n + 1 features where the i th feature weight w i for 1  X  i  X  n . The n + 1st feature weight is set to some  X  in the range (0 , 1). We further set the classifier X  X  threshold to t .

If there exists a sign-witness ( x + , x  X  ) for the n + 1st fea-ture, then x  X  must have a gap less than  X  , which is less than 1: From our construction of w and T , this is equivalent to: Because t and the s i  X  X  are all integers, and because x  X  the left-hand side reduces to a sum of integers. It must there -fore evaluate to a non-negative integer less than 1, namely, 0: By adding t to each side and letting S  X  = { s i | x  X  i = 1 } , this can be rewritten as: (  X  never appears because x  X  n +1 = 0.) Thus, the existence of a sign-witness implies a solution to the original subset sum problem.

In spite of this hardness result, Boolean linear classifiers are still ACRE 2-learnable under a uniform linear cost func-tion. We demonstrate this via an algorithm and a proof of its correctness and efficiency. Our algorithm FindBoolean-IMAC for finding a low-cost instance is listed in Algorithm 3.
Because we are using a uniform linear cost function we have an ideal minimum-cost instance x a . For a feature vec-tor v we use C v to denote the set of features that have different values in v and x a . Again, because we are using a uniform linear cost function, the cost of a feature vector v is c ( v ) = | C v | . The algorithm terminates due to the fact that we modify y to reduce the cost and terminate when y does not change.

The algorithm begins with the negative instance provided and repeatedly modifies it to find instances of lower and lower cost that are still classified as negative. The modifica -tions we allow are removing individual changes (relative to x ) from the instance or replacing any pair of changes with a single other change. Each modification reduces the instance cost by one. The algorithm terminates when no modification can be made without producing a positive instance. Algorithm 3 FindBooleanIMAC ( x a , x  X  ) y  X  x  X  repeat until y prev = y return y
Intuitively, this algorithm works for the following reason : if there exists another negative instance x  X  with fewer than half as many changes as y , then the most helpful change in x must be over twice as good as the two least helpful changes in y . Since the algorithm considers all possible replacements of two changes with one change, it cannot terminate as long as such an instance exists. Some additional complexity is introduced by the fact that we can only add changes that are not already present in the current instance. However, we can make a similar argument considering only the disjoint changes. Our proof fully formalizes this.
 We begin with a mathematical lemma.

Lemma 5.3.1. For two sequences of non-positive real num-hold then there exists j, k, l such that l 6 = k and s j  X  t k
Proof. Suppose that all conditions hold for the two se-quences of non-positive numbers.

Aiming for a contradiction, we assume that for all k, l we have t k + t l  X  u/m . From condition 2 we can write Using our assumption and Equation 4, we obtain Since there is at least one t i in the second sumation we have a contradiction with Condition 3. Thus, there must exist k, l such that t k + t l &gt; u/m . Using (1), we can upper bound the size of s min , the smallest number in the s sequence as follows s min  X  u/m . Thus, t k + t l &gt; u/m  X  s min which proves the claim.

Theorem 5.4. Boolean linear classifiers are ACRE 2-learn-able under uniform linear cost functions.

Proof. We demonstrate that Algorithm 3 finds an ap-propriate instance.
 Let x denote a minimum cost feature vector with c ( x ) = 0. We use Lemma 5.3.1 to show that the second inner loop of Algorithm 3 will find a change to reduce the cost of y whenever c ( y ) &gt; 2 c ( x ), that is, whenever y is not a feature vector satisfying the theorem.
 We assume that we have just completed the first loop of Algorithm 3 and assume that c ( y ) &gt; 2 c ( x ). We let y be our current feature vector with c ( y ) = 0.

With each feature f we associate a real-valued quantity  X  (defined below). We apply Lemma 5.3.1 to the sequences in which the s i  X  X  are the  X   X  X  associated with features in C and the t i  X  X  are the  X   X  X  assocated with features in C y
We use score ( v ) to denote the dot product of the feature vector v and the feature weights w of our linear classifier: score ( v ) = w v .

We define  X  f = w f (1  X  2 x a f ). Informally, this repre-sents the change in instance score from adding change f . If x a f = 0, then changing feature f to 1 adds w f to the score; otherwise, the change adds  X  w f to the score. The (1  X  2 x a f ) term captures this sign change.

We now rewrite the definition of score ( v ) in terms of x and C v using the  X  f values:
We say that a feature f is positive with respect to a linear classifier and ideal instance x a if changing the value of fea-ture f in instance x a makes the score of the instance larger; that is,  X  f &gt; 0.

There are no positive features in C y because we have just completed first loop in Algorithm 3 and if there were any such features they would have been changed. There are also no positive features in C x because x is the minimum cost feature vector and if there were any positive features they could be removed to create a feature vector with a lower cost and have the same classification. Therefore the sequences contain non-positive real numbers.
 From the fact that c ( x ) = 0 we know that score ( x ) &lt; T . Which, using Equation 5 yields satisfying Condition 1.

After the first loop of Algorithm 3 completes we know that there is no single change can be removed without changing the classification of y (i.e., c ( y ) = 0) which implies that satisfying Condition 3.

Finally, if c ( y ) &gt; 2 c ( x ) then | C y | &gt; 2 | C that | C y \ C x | + | C y  X  C x | &gt; 2 | C x \ C y | +2 | C and c ( x a ) = 1 it must be the case that C x 6 =  X  . Furthermore, C x 6 X  C y otherwise the first loop in Algorithm 3 would re-move all of the features in C y \ C x and y would be optimal. We have demonstrated that the sequences satisfy Condi-tion 2.

We have shown that all of the conditions of the lemma are satisfied which implies that the second loop will find a change if c ( y ) &gt; 2 c ( x ).
In the previous sections, we defined the ACRE learning problem and provided efficient algorithms against continu-ous and Boolean linear classifiers under linear and uniform linear cost functions. In this section, we apply our theoret i-cal results to the real-world domain of spam filtering.
In our experimental scenario, an adversary wishes to dis-guise some spam message to get it past a target spam filter. The adversary can explore the instance space by changing which words are present in an email. The adversary issues queries by sending messages to a test account protected by the target filter and observing which ones are blocked.
We simulate this scenario experimentally by training spam filters, reverse engineering them, and measuring the cost of disguising messages relative to the optimal cost (MAC). While basing our experimental methods on our theoretical framework, we also endeavor to keep the setup as realistic as possible. For example, we do not assume that the adversary knows the entire feature space, only an easily guessed subse t.
The training data used to configure our spam filters con-sisted of 500,000 Hotmail messages, voluntarily hand-labe led by the original recipients as  X  X pam X  or  X  X egitimate X . From these, we extracted almost 290,000 Boolean features. From this data, we trained two linear classifiers, a naive Bayes model and a maximum entropy (maxent) model. Naive Bayes was first suggested for spam filtering in [4] and has since become a widely popular choice due to its simplicity and scalability. Maxent is more popular in the text clas-sification community, but has also been applied to spam filtering [7].

In a linear spam filter, such as naive Bayes or maxent, we can lower the filter threshold to increase the number of spam messages that are caught, but this also increases the number of legitimate messages incorrectly classified as spam. We configured our spam filter thresholds so that each classified 10% of the legitimate email in our test set as spam. While this may seem like a lot, our error rates are somewhat overestimated due to inconsistencies in how volunteers lab el their email.
Because not all of the 290,000 features in the classifier are directly manipulable, and even fewer are easily guessed by adversaries, we restricted adversaries to a simple sub-set: 23,000 English words from the first ispell dictionary, english.0 that appear as features in our filter. We also ex-perimented with two smaller word lists: the 1,000 English words most common in our training data, and 1,000 random English words appearing as features in our filter. We refer to these feature lists as Dict, Freq, and Rand, respectively .
The one exception to these word lists is when the adver-sary is searching for the first feature witness. In this searc h, we allow the adversary to change any token found in the body of the positive or negative instance. Our justification is that, given a pair of messages, it X  X  easy to add or remove the few tokens present.

We used a single spam email from our test set to construct a uniform linear cost function. This corresponds to a unit cost per word obfuscated or added to the email.
The adversarial learning algorithm applied was an opti-mized version of Algorithm 3. Our modified version main-tains the theoretical guarantees of the simpler version, bu t uses many fewer queries than a naive implementation would.
Our first optimization is to skip unnecessary tests by re-membering which changes will never be helpful. For exam-ple, any change that yields a positive instance need never be considered again. Additionally, if a change f was unable to take the place of two other changes at one stage in the algo-rithm, then we need never consider it in the future, since the changes in our current instance only get better on average as the algorithm progresses.

Our second optimization is to consider only O ( n ) pairs of changes to remove, rather than all O ( n 2 ) combinations. As-sume an even number of changes and group all changes into pairs. At least one of these O ( n ) pairs must be average or worse. If there is an odd number of changes, then this might fail because one change remains unpaired. We compensate for this by constructing a second pairing in which a differ-ent change is left unpaired. If no pair of changes from either pairing is average or worse, then it X  X  easy to show that the two left-out changes must together be worse than average.
We ran our modified ACRE algorithm 1,000 times for each filter and word list combination. In each run, we started from a single legitimate email and a single spam email and compared the cost of the negative instance we found to the MAC, computed by greedily removing the largest-weight features and adding the smallest-weight features.

In 16.3% of the naive Bayes runs and 27.6% of the maxent runs, we never found a witness for a single non-zero feature. This happened because we only permitted the adversary to swap tokens in the body of the email; if other features deter-mine the class too strongly, then we may never see a witness. In practice, an adversary could probably still come up with a witness in these cases by adjusting words in the subject and a few other  X  X uessable X  properties. At worst, the adver-sary need only find a different spam/legitimate email pair to start from, and the process will likely succeed.
Table 1 shows the medians and maximums for the ad-versary X  X  instance cost, the adversary X  X  cost relative the the MAC, and the number of queries used. Tests in which we failed to find a witness were excluded from these calcula-tions.
Overall, our algorithm does quite well at finding low-cost instances: over half the time, it found instances within 17% of the optimal cost. Additionally, its instances only cost 50% more than optimal in the worst case, well below our theoretical bound of costing 100% more.

In terms of queries, our algorithms were reasonably ef-ficient in the average case. Not suprisingly, fewer queries were required to sort through the smaller feature sets, Freq and Rand. More interestingly, naive Bayes models were sig-nificantly more difficult, especially in the worst case. This can be attributed to differences in the weight distributions of the two models. Our maxent model featured more large-magnitude feature weights than our naive Bayes model, lead-ing to lower-cost negative instances and fewer changes to consider removing. This relationship is observable from th e differences in the median and maximum adversarial cost for each scenario.

Our algorithms were designed to be generic and easy to analyze, not to be efficient in the number of queries. In practice, especially with domain knowledge, one can signifi -cantly reduce the number of queries. See [3] for an in-depth demonstration of this on the same dataset, along with more detailed analysis.
ACRE learning is a theoretical framework for studying one X  X  enemy and oneself, attacker and the defender, ad-versary and classifier. Much as PAC learning determines whether concepts can be learned efficiently relative to the natural distribution, ACRE learning determines whether an adversary can efficiently learn enough about a classifier to minimize the cost of defeating it.

But ACRE learning is more than just theory: in the do-main of spam filtering, our ACRE learning algorithm per-formed quite well, easily exceeding the worst-case bounds. In practice, it may be possible to do much better using domain-specific heuristics.

Of course, the algorithms presented are not designed to be efficient in the number of queries but simple to analyze. In practice, especially with domain knowledge, one can sig-nificantly reduce the number of queries.

While our preliminary results only cover two types of lin-ear classifiers, we hope that future work will cover addition al types of classifiers, cost functions, and even learning scen ar-ios. We have proven certain scenarios to be relatively easy; what scenarios are provably hard?
A number of framework questions remain as well. Under what conditions is ACRE learning robust to noisy classifiers ? What can be learned from passive observation alone, for do-mains where issuing any test queries would be prohibitively expensive? If the adversary does not know which features make up the instance space, when can they be inferred? Can a similar framework be applied to relational problems, e.g. to reverse engineering collective classification? Mov -ing beyond classification, under what circumstances can ad-versaries reverse engineer regression functions, such as c ar insurance rates?
Finally, how do such techniques fare against a changing classifier, such as a frequently retrained spam filter? Will the knowledge to defeat a classifier today be of any use to-morrow? Years of research have led to good classification algorithms . Now that these classifiers have been deployed, adversaries are beginning to attack and defeat them. Common classi-fiers are fast becoming victims of their own success. One of our goals, although one not addressed in this paper, is to understand the susceptibility of different classifiers to ad-versarial attacks. Our adversarial learning framework mea -sures the vulnerabilities of different classifiers to differe nt adversaries, which is a first step. We hope that this line of research leads to classifiers that are provably difficult to re -verse engineer for any adversary. At the very least, we hope that this framework will lead to useful descriptions of the relative vulnerability of different classifiers against diff erent types of adversaries.
We thank Mausam for helpful comments on a draft of this paper. This work was partially done while the first author visited Microsoft Research, and was partiallly fund ed by an NSF Graduate Research Fellowship awarded to the first author. [1] D. Angluin. Queries and concept learning. Machine [2] N. Dalvi, P. Domingos, Mausam, S. Sanghai, and [3] D. Lowd and C. Meek. Good word attacks on statistical [4] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz. [5] S. Tzu. The art of war, 500bc. [6] L. G. Valiant. A theory of the learnable.
 [7] L. Zhang and T. Yao. Filtering junk mail with a
