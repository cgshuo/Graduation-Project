 The MEMOSE (Me dia Emo tion Se arch) system is a specialized search engine for fundamental emo tions in all kinds of emotional-laden documents. We apply a c ontrolled vocabulary for basic emotions, a slide control to adjust the intensities of the emotions and the approach of broad folks onomies. The paper describes the indexing and the retrieval tool of MEMOSE and results from its evaluation. H.3.1 [ Information storage and retrieval ]: Content Analysis and Indexing -indexing methods H.3.3 [ Information storage and retrieval ]: Information Search and Retrieval  X  Search process Design, Human Factors Emotion, Multimedia Resources, Collaborative Indexing, Slide control tagging, Emotional In formation Retrieval (EmIR) Some content in multimedia resources is able to display feelings or to provoke certain emotions in the users. The aim of our research is to identify these emotions and to make them searchable so that they can be used for information retrieval. Emotions are hidden in different document types. We can find emotional-laden documents in text ual objects like lyrics, poems or novels, music [3], images [5], vi deos [1] and blogs. Lee and Neal [3], Schmidt and Stock [5] and Knautz et al. [1] pointed out that users are able to index fundament al emotions consistently by means of tagging (in the context of a broad folksonomy). In our studies we worked with a controlled vocabulary for basic emotions (love, happiness, fun, su rprise, desire, sadness, anger, disgust and fear), a slide cont rol to adjust the emotions' intensities, and the approach of broad folksonomies [4]. We found two forms of distribution: the power law and the inverse logistic distribution [6]. In the first one users mostly assign only one emotion with a high intensity to a resource. An inverse logistic distribution is ava ilable if several emotions with a high average value are assigned to the multimedia documents. Knautz et al. [1] showed th at a relative stability of the distributions' shapes can be reached after some dozens of tagging users. Our next-generation retrieval system for emotions in multimedia documents is designed as a web a pplication and consists of the following components: a tool fo r emotional tagging for adding weighted emotional tags to the resources, some processing scripts that interact with the APIs of Web 2.0 services and our API and finally a retrieval tool needed to access the indexed data. For our experimental evaluation we selected about 500 pictures with animals on it from Flickr. The pictures were collected by a group of students studying informa tion science. We reduced the scope of this broad field by limiti ng the available animals to pets and farm animals in order to get several results for every type of animal. There were no restricti ons regarding the selection of images, the students were encour aged to choose pictures by random and not by means of felt emotions. The only demand was that these pictures were taken from Flickr. After the links were collected, they were checked fo r validity. Additional data (e.g, information about the author, asso ciated tags, license etc.) were collected by using the Flickr AP I. All the tools that will be described here were de veloped using PHP. The data were held in a MySQL database with an InnoDB engine. In order to get fast response times the emotional intensity was saved in a materialized view. The user interface was designed using strict XHTML and the jQuery library for dynamic el ements like the slide controls. For the purpose of emotional tagging we created a user interface consisting of one picture and 18 slide controls on one web page (figure 1). The 18 slide controls where split into two groups of 9 slide controls each. One group contained the emotions shown , i.e. the emotions that are displayed on the picture. The other group covered the emotions felt by the viewer when looking at the picture. The range of every scroll bar contains values from 0 to 10, so the viewers could differentiate the intensity of every emotion. A zero value means that the emotion is not shown on the image or not felt by the observer. As we had th is large number of pictures for every user to tag it was not practicable to force the students to tag all the pictures in one pass one af ter the other. We applied a user management by which the alread y tagged pictures were logged and with its help every user could make breaks whenever needed and go on later. Another benefit of this user management was that no user could tag a picture twice. The retrieval tool was designed to access the tagged pictures in a manner of a search engine. For this purpose we designed a clean user interface consisting of one input field and nine checkboxes where the emotions could be select ed. The user first had to choose the emotions to search for and th en got suggestions by typing in the search terms through an auto completion feature based on the tags we got from Flickr according to the pictures. After sending the request the results are show n in two distinct columns, differencing between shown and felt emotions (figure 2). Both columns are sorted in descending order regarding the selected emotions. For every hit a thum bnail of the corresponding picture and bars that show the intensity of the chosen emotions are displayed. The retrieval status value (RSV) of the documents (which satisfy both topic and emotion) was calculated through the arithmetic mean of the intensity of the emotion. If there were more than one emotional search argument, we took the sum of the means as RSV. By clicking on th e thumbnail the picture is opened in an overlay window filled with further information like associated tags, information about the author etc. From the tool box of evaluation methods [2] we took the SERVQUAL, the customer value discovery and the critical incident approach to evaluate the IT service dimension. To evaluate the IT system dimension we worked with success factors such as ease of use, perceived usef ulness, trust and fun, and with a usability test. In order to get a first idea of what people think of a search engine for emotions we took a number of people who were not involved in any part of deve lopment. They had to do several tasks (e.g., to search for pictures with dogs and happiness ) including filling out questionnaires and doing task-based thinking-aloud tests that were r ecorded. We concluded from the results of the evaluation that the search for emotions in multimedia documents is an exciting new task that people need to adapt to. Especially the separated display of shown and felt emotions in a two-column raster was at first hard to cope with. And  X  not unimportant for Web 2. 0 services  X  our test persons found MEMOSE an enjoyable system. [1] Knautz, K. et al. 2010. Indexieren von Emotionen bei [2] Knautz, K., Soubusta, S., and Stock, W.G. 2010. Tag [3] Lee, H.J. and Neal, D. 2007. Toward Web 2.0 Music [4] Peters, I. 2009. Folksonomies. Indexing and Retrieval in [5] Schmidt, S. and Stock, W.G. 2009. Collective Indexing of [6] Stock, W.G. 2006. On Relevan ce Distributions. J. Am. Soc. 
