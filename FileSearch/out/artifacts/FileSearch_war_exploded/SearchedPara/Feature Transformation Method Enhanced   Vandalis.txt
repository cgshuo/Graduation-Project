 Wikipedia 1 , the collaboratively edited encyclopedia, is among the most prominent websites on the Internet today. Every visitor of a Wikipedia Web site, even anonym-edited, or deleted without the need for authentication. Through this way, a large scale measured in June 2012 2 . According to a recent comparison conducted by Nature, the Britannica encyclopedia 3 . 
However, allowing anonymous edit destructive in its removal of content. Wiki-anti-vandal bots such as ClueBot and VoABot II are also used to detect vandalism in expression rules are created manually and are difficult to maintain. Since 2008, machine learning methods have been introduced to solve the problem. Various features are collected and used to tr ain a classifier to detect vandals including trained on only one group of these features, which means that there is still much room for improvement on vandalism detection task. 
The motivation of our research comes from the observation that most previous work tried to increase the number of features used for vandalism detection. However, bring possible burden for feature extraction. Another possible way to improve detec-amine in this paper is: Would it be better to make the best use of features we already have at hand and get almost the same result? ferent from the previous work, after obtaining enough effective features, our method focuses on transforming the available features to create a new feature space. We use the techniques of multivariate statistics for feature transformation. A binary classifier is then trained to detect vandalisms. Our experiment results show an improvement of approximately 2%~25% at different evaluation metrics over the baseline. The main contributions of this paper are listed below. 
It is a double-edged sword. Often times Wikipedia X  X  freedom of editing has been ticles that undermine the quality and veracity of the content. Vandalism is defined as any edit which is non-value adding, offensive, or destructive in its removal of content.  X 
Feature transformation methods are studied and applied to transform features be-fore training the classifiers for detection task. To ourknowledge, such an approach has not been used in the vandalism detection task.  X 
Principle Component Analysis is studied and different kinds of utilizations of transformation using PCA are tested with both the entire data and the partial data to find an optimal solution.  X  We combine feature selection methods with PCA to expand the feature set though PCA is often used to reduce the dimensions. The rest of the paper is organized as follows: Section 2 describes some previous work on vandalism detection in Wikipedia. In Section 3 we will give detailed description of some with analyses. Finally, we conclude our work in Section 5. Wikipedia vandalism detection is a novel res earch topic related to social media quali-The previous work done on Wikipedia articles X  information quality provides valuable references for our current research, such as featured article identification [3] and qual-ity flaws distribution in Wikipedia [4]. 
The early approach being applied in Wikipedia for automatic vandalism detection amount of uppercase letters and the frequency of vulgarisms detected via regular ex-need of creating lists of regular expressions and manually adjusting weights and thre-sholds, these earlier heuristics based systems are difficult to maintain. 
The Wikipedia vandalism detection research community begins to concentrate on machine learning approaches since 2008. Potthast et al. [7] are among the first to cast content in diff text into a bag of words, disregarding grammar and word order. They use Na X ve Bayes to detect vandalisms. 
Many researchers apply natural language processing techniques in their learning model. Their researches on vandalism detection have explored features based on text, such as stylometric analysis based text features [9], text stability-based approach [10]. Wang et al. [11] propose a Web-based shallow syntactic semantic modeling method, which utilizes Web search results as resource and trains topic-specific n-tag and syn-statistical language model. Similar to Chin, Mola-Velasco [13] proposes a topic-sensitive and language-independent method. With his method, given an edit, a set of related articles can be retrieved. These articles are used to build a language model. content, but now they are used in vandalism detection task to evaluate the reputations of both the article and the contributor [14]. Since different parts of an article are con-tributed by different users, the reputation degree computed from their previous beha-viors may affect the judgment whether their current edits are offensive or not. Adler et al. [15] analyze the reputation scores generated by a well-known Wikipedia reputation ture vectors. The classifier trained by repu tation features achieves a recall of 80% but a precision of only 40%. 
Revision metadata have been proved to be an effective feature for Wikipedia Wikipedia, including the time-of-day, time-of-week when edits happened, time-since time vandalism detection online. 
To our knowledge, among all the previous research mentioned above, none of them has used advanced feature processing techniques. These techniques are well studied in classification and pattern recognition. In this paper, we apply a feature transformation technique to vandalism detection. train a classifier in which vandalisms are considered as positive training examples and regular edits as negative training examples. 
In contrast to previous work, our approach adds a post processing stage before can be used to analyze the properties of the feature distribution. After the transforma-best performing features from the newly generated feature space which combines the classifier. 3.1 Original Feature Set Construction Wikipedia revision histories provide the Pagediff page 4 , which shows the differences between two versions of the article. On the Pagediff page, the numbered version and with different parts highlighted. Features are mostly extracted from this page. The two versions of content are also used for feature extraction like the language model com-puting and KL distance computing. 
Using all these data, 59 features are extracted to create the initial feature set in our system. Text features take the highest percentage. Many of them are used by Potthast and the PAN completion teams. Language features are computed based on the ma-nually constructed dictionary for bad and good words. Revision metadata features are model features because sometimes vandalism comes with some unexpected words so indicator of legitimate edits. Therefore we calculate Kullback X  X eibler distance (KLD) between two language models for both unigram and bigram. For a complete feature set, see Table 1. Class Features Descriptions 3.2 Feature Transformation Feature transformation is a process through which additional features can be generat-ed from the original feature set. There are two classes of features generated by feature transformation methods. The first kind of features can aggregate the information giv-en by the original set. For example, we have the feature of length and width of a rec-mensional reduction. 
Based on the idea of feature transformation, we propose a different solution for the problem of vandalism detection. Our model of training a detector is divided into three steps including feature construction (a), feat ure transformation (b) and classifier train-ing (c), which are illustrated in Figure 1. 
Notice that most previous work on Wikipedia vandalism detection focused on parts (a) and part (c). We try to introduce some feature transformation methods to enhance the performance of vandalism detector. Our feature transformation methods are based on Principle Component Analysis. 
Principle Component Analysis (PCA) is the best, in the mean-square error sense, linear feature transformation [17] that we can achieve. It is an unsupervised projection method that computes linear combinations of the original attributes that are con-structed to explain maximally the variance. The goal of PCA is to find such a group of mappings. that  X   X   X   X   X   X 1 and the variance of  X   X   X   X  is maximal. Assuming the covariance matrix of X is  X  X  X  X  X  X  X  and X has been normalized, the covariance matrix is shown in Equation (3). It has been proved that the principal components  X   X  are equal to eigenvectors of the ordered eigenvalues  X   X   X  X   X   X  X  X  X   X  , then the additional features are the corres-ponding eigenvectors of the m largest eigenvalues. Afterwards, the dimensionality of transformed space m could be determined. According to the normal procedure of ma-trix decomposition, we can get m eigenvalues where m=n. However, some of them do choose m by the threshold of cumulative contribution rate (85% ~ 95%) or the value and added to our feature set , which is then used in th e next classification step
If the additional features are all added to train the classifier, we can foresee the un-the final feature set. 
With the transformed features, we are read y to train a classifier. We are now faced 10% and of the data and there are many outliers. For this reason Random Forest and LogitBoost with Decision stump as base learner are preferred because of their parameters. Both methods have been implemented in Weka 5 which we use in our experiments. 4.1 Experiment Setup A large-scale corpus has been created in the PAN 2010 competition. This corpus makes the experiments easily reproducible. The corpus contains a week X  X  Wikipedia edits (PAN-WVC-10) 6 . It is generated by Crowdsourcing task, and every edit has been labeled by at least three annotators. 
We download the entire corpus of PAN-WVC-10 and use this public dataset to run the experiment. The corpus contains 32,452 edits on 28,468 Wikipedia articles, among which 2391 vandalism edits have been identified. An edit refers to a revision on a numbered article and reflects the differences between the two versions.
The classifier using only the original feature set listed in section 3.1 is our baseline method, which is a commonly used approach to detect vandalism. Another baseline two different kinds of PCA-based methods for feature transformation in the experi-ment which are listed below  X 
PCA-base method. Using the entire collection (training set + test set) as the input computed on the entire collection;  X 
Partial PCA-based method. Using only the test set as the input to PCA, so that a and test set into a feature space and generate new training set and new test set. The idea of proposing the Partial PCA-based method emanates from the real world online detection. If we can extract the prin ciple components from the real world data task of vandalism detection will be more realistic. 
Besides PCA which is introduced in section 3.2, we also attempt to use some other feature transformation methods including the Singular Value Decomposition (SVD), and Non-negative Matrix Factorization (NMF). The experiment with feature trans-formation method of SVD uses the vectors in matrix U (  X  X  X  X  X   X  ) as the additional features. Similarly, the experiment with NMF uses the vectors in matrix W (A=WH) as the additional features. Because the NMF method requires the non-negative matrix shown in Equation (4) and let the training data be in the range between 0 and 1. results of our classifiers X  performance. 4.2 Evaluation Metrics Vandalism detection can be considered as a binary classification problem, we want to determine whether the input instance is vandalism. The evaluation metrics of informa-tion retrieval including precision, recall and F-score are adopted here. Besides, AUC-ROC (The area under the receiver operating characteristic curve) is also reported here to compare the performance of different classifiers. The ROC curve is plotted with FP as the horizontal axis and TP as the vertical axis. In the case of vandalism detectors, and FP is the number of edits that are untruly identified as vandalism (false positives). 4.3 Results and Discussion classifier and iteration number in LogitBoost are set to 100. The results of baseline1 are calculated with the features used by Potthast [7], and the results of baseline2 are calculated with the feature set in section 3.2. Both of the baseline models are not ag-gregated with features transformation methods. 
As we can see from the results, the precisions of all the methods except baseline1 are higher using Random Forest classifier than LogitBoost. However, the latter F-score, the average F-score 0.587 of LogitBoost is higher than 0.567 of Random Forest. This shows that the LogitBoost classifiers have better overall performance. 
Among the feature transformation methods which are used in our experiments, Par-group of results by Random Forest, it improves the baseline1 method by 14% at pre-cision, 2% at recall, and 7% at F-score and improves the baseline2 method by 4% at The second best performed method is PCA-based which also makes an obviously improvement in comparison with baselines. Some of the other feature transformation methods improve the performance (SVD, PCA, Partial PCA) of the vandalism detector but some do not (NMF). This is due of not orthogonal, because of which there will be much noise in the vectors. On the other hand, all the feature transformation methods we used in this paper are unsupervised, samples. As a result, the additional features created by those methods are not selected has been proven to be effective and efficien t and it can be used to transform features in the vandalism detection on Wikipedia. The AUC-ROC results for our best perform-ing classifiers (LogitBoost) are also listed in Table 4 in comparison with the baseline models 
The Partial PCA-based method is proved to be the best performed solution through the normal PCA-based method because of the use of a subset for PCA computing (only one fifth of the original training time for 5-fold cross validation). The two PCA-based methods outperform others because the effective latent space can provide more discriminative features through our feature selection process which combine some features from our raw features according to their latent similar meaning. As a result, the new features can enhance the vandalism detectors. 4.4 Detailed Analysis We ask some questions in order to examine the properties of our proposed detection framework, and the answers to those questions are given in detail to help understand why the PCA based methods achieve the best results.  X  How can the additional PCA features are interpreted? tive induction. When generating new features, it can produce new (emerging) con-concepts. For example, we get the new feature generated by the features which share almost the same information of using bad words ( SexFrequency, Vandalism Frequen-duced features like the  X  X otal degree of users X  negative impact X  bring us new and use-improvements in the results.  X  Why the Partial-PCA more suitable for the task of vandalism detection? The difference between the Partial-PCA method and the PCA method is the different original feature set for transformation they use. When using test set for PCA, the pro-dalisms. For example, the styles of vandalisms perhaps have evolved with time. If we use the Partial-PCA to extract features based on the latest three months X  data, we can better catch the evolved habits of the vandals.  X  What is the computational complexity of the proposed methods? As described in section 3.2, we can see PCA is a linear method, which means that the large dataset like Wikipedia with only less than 100 features, it is appropriate to apply PCA. At the same time, the additional training time of PCA-based feature transforma-ratio of the two stages is almost 10:1(training classifier vs. PCA). We have proposed a new idea to help detect vandalism in Wikipedia more efficiently. The feature transformation approaches are expl ored in the vandalism detector in order proved to be a good choice among the others studied in this paper. With the limitation of our feature set, the performance of our proposed classifiers may not be as good as the best state-of-art approach, which involved a large number of features, but the idea vandalism detection on Wikipedia. 
In our future work, a more comprehensive feature set will be created. More feature transformation methods will be tested to extend the feature set such as the non-linear also be studied. Acknowledgement. This work is partially supported by grant from the Natural Science Foundation of China (No.60673039, 60973068, 61277370), the National High Tech Research and Development Plan of China (No.2006AA01Z151), Natural Science Foundation of Liaoning Province, China (No.201202031), State Education Ministry and The Research Fund for the Doctoral Program of Higher Education (No.20090041110002). 
