 Question recommendation that automatically recommends a new question to suitable users to answer is an appealing and challeng-ing problem in the research area of Community Question Answer-ing (CQA). Unlike in general r ecommender systems where a user has only a single role, each user in CQA can play two different roles (dual roles) simultaneously: as an asker and as an answerer. To the best of our knowledge, this paper is the first to systemati-cally investigate the distinctions between the two roles and their different influences on the performance of question recommenda-tion in CQA. Moreover, we propos e a Dual Role Model (DRM) to model the dual roles of users effectively. With different independ-ence assumptions, two variants of DRM are achieved. Finally, we present the DRM based approach to question recommendation which provides a mechanism for naturally integrating the user relation between the answerer and the asker with the content rele-vance between the answerer and the question into a uni-fied probabilistic framework. Expe riments using a real-world data crawled from Yahoo! Answers show that: (1) there are evident distinctions between the two roles of users in CQA. Additionally, the answerer role is more effective than the asker role for model-ing candidate users in question recommendation; (2) compared with baselines utilizing a single role or blended roles based meth-ods, our DRM based approach cons istently and significantly im-proves the performance of questi on recommendation, demonstrat-ing that our approach can model the user in CQA more reasonably and precisely. H.3.3 [ Information Search and Retrieval ]: Information Filtering Algorithms, Design, Experimentation Community Question Answering, Role Analysis, Question Reommendation, Dual Role Model, PLSA 
Community Question Aswering (C QA) is a web service where people can seek information (pos ting a question and getting the answer of it from others) and share knowledge (answering a ques-tion). Yahoo! Answers 1 and Baidu Zhidao 2 are two typical exam-ples of CQA system. Compared with the traditional information retrieval, CQA bases on the communi ty, which is a form of social network, so it can make best of user's collective wisdom to meet the information needs of users more easily and accurately. 
In CQA system, there are a large number of questions posted every day. Take Yahoo! Answers for example, there are about 207 thousands new questions asked dail y [1]. If we can automatically recommend the new question to appropriate users to answer, it will help the question be resolved as soon as possible, which will improve the CQA system X  X  performan ce. In addition, it will meet the answerers X  needs to answer questions. As we can see, question recommendation is a very important component in a CQA system. 
The core issue of question recommendation is how to represent the users X  interests (profile) and the questions, which is called the representation model. Based on that, we can assess the match between a question and each user, and then recommend the ques-tion to top N users who are the most consistent with it. Of course, we can solve question recommendation from another perspective, which is matching a user with each question and recommending the appropriate questions to him. Both of these types of recom-mendation tasks aim to make new questions answered as early as possible and satisfy the user better. Essentially, the key issues of both of them are the representati on models for users and questions. As our target is recommending a new question to the appropriate users to answer, this paper focuses on the first type of recommen-dation task. At present, a lot of representation models have been proposed. Dror et al [5] represen ted the user and question as vec-tors consisting of multi-channel f eatures and casted question rec-ommendation as a classification pr oblem. Other methods [2, 4, 6] utilized latent semantic models (PLSA, LDA, etc.) to model the user and question as the dist ribution of several topics. 
As we can see, each user in C QA plays two different roles (dual roles) simultaneously: the asker and the answerer. That is, swer someone else's questions. In tuitively, the profiles of the two roles of users are different from each other, which exist-ing methods have not paid attention to. For example, a piano teacher wants to learn some computer knowledge which he is not familiar with. Thus he is most likely to ask lots of questions relat-ed to computer, and answer many piano-related questions based on his specialty. As an asker, a user may post some questions in http://answers.yahoo.com/ http://zhidao.baidu.com/ the field that he is not familiar with. In contrast, as an answer, the user will solve the question which he is good at and interested in. 
Are there distinctions between users X  roles? How do different roles affect the performance of question recommendation? Whether we can legitimately combine the characteristics of differ-ent roles to improve the effectiveness of the recommendation system? All of these important issues are worthy of our concern. However, current recommendation methods have not in-depth studied the different characteristics of users X  roles and their differ-ent influences on question reco mmendation. All of previous methods only modeled the user us ing a single role, or simply mixed the two roles together to represent the user without consid-ering the distinctions between roles. 
This paper systematically investigates the distinctions between users X  dual roles and how they affect the performance of question recommendation differently. To the be st of our knowledge, this is the first work on studying these im portant issues. While Nam et al. [30] observed that users in CQA are divided into askers and an-swerers and only a few of them both ask and answer in the same category through statistics, they have not theoretically analyzed the distinctions between users X  different roles and their different influences on question recommendation. Moreover, we propose the Dual Role Model (DRM) to m odel the dual roles of users ef-fectively. Finally, we present the DRM based approach to ques-tion recommendation, which takes full advantage of users X  differ-ent roles to improve the effect of question recommendation. There are three primary contributions of our work. 
First, DRM which considers the two different roles of users separately provide s a more precise and appropriate user represen-tation model for question recommendation in CQA. Specifically, we utilize DRM to analyze the latent topic information of differ-ent roles for modeling the user. According to different independ-ence assumptions, two variants of DRM are achieved: (1) inde-pendent DRM that assu mes that users are independent of each other and models each user individually; (2) dependent DRM which considers the dependence between users. 
Next, we carried out systematic experiments on a real-world da-ta to explore the distinctions between users X  roles and compare the effects of recommendation methods that are based on asker role, answerer role or blending both of these roles. The results show that not only the two roles but al so their influences on question recommendation are different from each other distinctly. In addi-tion, simply mixing the roles together will impair the performance of recommender methods. 
Finally, our DRM based recommendation approach allows us to naturally integrate the user relation between the answerer and the asker with the content relevance between the answerer and the question into a unified probabilis tic framework, which is more interpretable. Most previous me thods only consider the content relevance. There have been severa l approaches that make use of the user relation [3, 5], however in these approaches, the user relation is either obtained through somewhat heuristic statistics outside of the model or combined with the content relevance by a linear interpolation. 
The remainder of this paper is organized as follows: Section 2 introduces some prior work related to our approach. Section 3 is the preliminary description of question recommendation in CQA. Section 4 discusses our dual role model and how to use it in ques-tion recommendation. Experimental results are presented in Sec-tion 5. At last, we conclude the paper and discuss about the future work in Section 6. 
In this part, we review previous work which is related to our approach: recommender system, question recommendation. 
Because question recommendation is a type of recommender system, we first review gene ral recommender systems. Recom-mender systems can be divided into three stages based on how recommendations are made: content-based recommendations, collaborative filtering and hybrid approaches [18]. In content-based recommendations, the user will be recommended items similar to the ones the user preferred in the past. In collaborative filtering, the user will be recommended items that people with the similar tastes and preferences liked in the past, that is, user will help each other find what they may like. In order to combine the advantage of both previous methods together, hybrid approaches are proposed. All these recommende r systems firstly attempt to profile user preferences based on his history logs, and then rec-ommend items according to the relevancy between him and items. Different kinds of methods are used to capture the model of users, such as classifying [24, 28], PLSA [13], matrix factorization [29], and ranking-oriented approach [17]. However, the user in these general recommender systems only pl ays one single role, which is significantly different from question recommendation. Therefore, we should pay close attention to this difference as we have men-tioned in the above section. 
With CQA system becoming popular in recent years, many people turn their attention to question recommendation in CQA, this problem in previous work. 
On one hand, question recommendatio n is consider as a classi-fier problem which is similar to [5]. In [5], Dror et al. proposed a representation model based on multi-channel vector space model, where the user and question are represented as the vector with multiple dimension features from multi-channel data. Then, the matching degree between a user and a question is learned from their respective features using a binary classifier. Although this model treats user attributes in the answered-channel and asked-channel as two groups of features respectively, all the features are the user X  X  dual roles without considering the distinctions between user X  X  different roles and their different influences on question recommendation. 
On the other hand, we can learn a ranking model to generate a recommendation list for question recommendation. In these earlier works, various extensions of Probabilistic Latent Semantic Analy-sis (PLSA) or other topic models are developed. Wu et al. [2] presented an incremental automatic question recommendation framework based on PLSA. Question recommendation in their work considered both the users X  interests and feedback. Guo et al. [4] developed a general generati ve model based on basic Latent Dirichlet Allocation (LDA) model for questions and answers in CQA. In this approach, they combined topic-level information about questions and users with wo rd-level information to improve question recommendation. In order to deal with the data sparsity, Qu et al. [6] used a user-word aspect model instead of direct as-pect model [9] to model user preferences. However, all of these methods have used a single role, or simply blended roles to repre-sent the user, which have not distinguished user X  X  different roles and considered how they affect the performance of question rec-ommendation differently. 
Given the question set  X  X  X  X  X   X   X ... | X  X   X  and the user set  X  X   X  X   X   X ... | X  X   X  , where | X | is the number of questions and | X | is the number of users. Each question in Q is denoted as a triple  X  X  X   X   X , X   X   X ,  X   X  . The  X  is the text content of the question. For instance, If we assume that words are independent,  X  can be denoted as a The  X   X  denotes the answerer of the question (it is also the an-swerer role of user  X  ). The  X   X  denotes the asker of the question (it is also the asker role of user  X  ). If there are multiple answerers in the question, all answerers will be separated. If the question is not answered,  X   X  is null. 
Based on the previous discussion in the section of related work, we choose the idea of ranking to solve the problem of question recommendation. For a new posted question, the question an-swerer recommendation task is to suggest a ranked list of users who are suitable to answer it. To tackle with this problem, we need to resolve the two sub-prob lems: question and user represen-tation, the method of ranking recommendation candidates. 
Since Probabilistic Latent Sema ntic Analysis (PLSA) [20] can effectively mines the latent semantic information of users and questions, it has been widely used to obtain the question and user representation in question recommendation, e.g., [2, 3, 4, 6]. PLSA assumes that users and questions are generated from a mix-ture of some latent topics. We can compute the consisten-cy between the distribution on topi cs of a user and a question to determine whether to recommend the question to the user. We summarized the previous PLSA based methods for question recommendation and discovered that they can be divided into two main categories: (1) methods that model the user i ndirectly. Simi-larly to [2], it takes a question as one document and use PLSA to the user can be represented as the average of topic distributions of all the questions that he accesse s; (2) methods that obtain the model of the user directly. In th ese methods, all the questions that a user accesses are treated as one document. Then PLSA is used directly to get the topic inform ation of the user. A typical ap-proach is the user-word aspect m odel applied by Qu et al. [6]. This model is proposed by Popesc ul et al. [7], which improves Hofmann X  X  aspect model [9] for collaborative filtering. 
However, when these PLSA based methods modeling the user, they did not pay attention to the user X  X  dual roles and their distinc-tions. In order to effectively analyze characteristics of different roles and make use of both of user roles to improve the perfor-mance of question recommendation, we propose a Du-al Role Model (DRM) based on PLSA to model the user in CQA precisely. According to different independence assumptions, we implement two variants of DRM. In the next section, we will de-tail generation processes of these variants and describe the DRM based method for question recommendation. 
With the assumption that all users are independent of each other in independent DRM (IDRM), we separately model the dual roles of each user. As Figure 1 il lustrates, the IDRM can be divid-ed into two steps. First, we employ the PLSA to analyze the topic information of all the questions, a nd then model the answerer role and asker role of each user ba sed on questions which he answers or asks. 
We introduce the latent variable  X  X  X  X  X  X  X   X   X  to indicate each topic under users and questions. The model of user X  X  answerer role can be represented as its topic distribution  X   X   X   X  |  X   X  information of the question is  X  X  X  X  X  X  . According to the first step of IDRM in the Figure 1, the generative model for question/word co-occurrences is defined as: a latent topic  X  is obtained with probability  X  X  X  X  X  , and then a question q is generated with probabil-Therefore, we can compute the joint probability  X   X   X , X   X  of ob-serving a question  X  together with a word  X  based on topic varia-ble  X  as follows: 
Then considering all question/word pairs  X   X , X  X  in question set  X  , the log likelihood  X  is where  X   X  q,w  X  is the frequency of word  X  in the question  X  . 
We use the Expectation Maximization (EM) method to learn the model parameters  X   X   X   X  ,  X   X   X  |  X   X  and  X   X   X  |  X   X  : E-Step , M-Step , 
After obtaining all questions X  representations, we perform the second step to get the representations of users X  different roles. The user X  X  answerer role is defined as the combination of topic distri-butions of all questions that he answers, and the modeling method is similar for the asker role. Intuitively, we can give an example to illustrate the feasibility of this approach. For example, if a user answers lots of questions related to using computer, so the profile of his answerer role is very likely to be related to this topic. Spe-cifically, the role models  X   X   X   X  |  X   X  and  X   X   X   X  |  X   X  where,  X  X  X  X  X  X   X   X   X  is the set of questions that the user  X  answers, and  X  X  X   X   X   X  is the set of question he asks. Different from the IDRM, the a ssumption made in dependent DRM (DDRM) is that there is dependence between users. As we can see in Figure 2, DDRM assumes that the answer and the asker are dependent on each other when not observing the latent varia-ble. The assumed generative model is as follows. We first pick a latent topic to some prior  X   X   X   X  . We then generate the answerer  X  the asker  X   X  , and the content  X  X   X   X   X   X  of question  X  with corre-sponding probability  X   X   X   X  |  X   X  ,  X   X   X   X  |  X   X  , and  X   X   X   X  |  X   X  Thus, the joint probability distribution of a triple  X , X  X  question  X  is defined as: 
In the above equation,  X   X   X , X   X  is the frequency of word  X  in the content  X  . 
Accordingly, the log likelihood  X  in DDRM is and we can also train the model using EM method as follows: E-step ,  X   X   X  |  X , X   X   X ,  X   X   X  M-step , 
The IDRM and the DDRM respectively model the user X  X  dual roles from different perspectives. Compared with previous models DRM provides a more precise and a ppropriate user representation model for question recommendation. Apart from different inde-pendence assumptions between users, we can see that the IDRM is a type of method modeling us er role indirectly while the DDRM is a method which learns the role model directly. Based on any one of the above DRM variants, we build the DRM based method for question r ecommendation that takes full advantage the characteristics of different user roles. When a new question  X  arriving, we compute posterior probability  X  X  X  each candidate user  X   X  , and then recommend this question to the top N users.  X  X  X   X   X  X  X  is obtained by: where, the first step uses the Bayesian formula for an equivalent transformation. In the second step, the question  X  is decomposed consider the candidate X  X  answerer role when we evaluate whether he is suitable to answer this question. Therefore, the  X  sented as his answerer role  X   X   X  . The third step and fourth step is based on the role models an d the question model obtained in DRM, where the generation probability  X   X   X  |  X   X  is normalized by the length of question content | X | .

In this recommendation approach,  X   X   X   X   X  |  X   X   X   X   X   X  |  X   X  denotes the consistency of the answerer an d the asker over topics, which models the user relation between the answerer and the asker. Cor-respondingly,  X   X   X   X   X  |  X   X  X  X   X  X  X  X  X  X   X  X  X  X , X  X  X   X  X  X  measures the con-sistency of the answerer and the question content over topics, which models the content relevance between the answerer and the question. As we can see, our DRM based method takes full ad-vantage of users X  dual roles to improve the performance of ques-tion recommendation. Moreover, this method utilizes a unified probabilistic framework to naturally associate the user relation with the content relevance together, which is more interpretable. 
Compared with the DRM, both the methods described in [2] and [6] employed a single role m odel to represent the user and ignored the user relation when recommending question to users. In the next section, these method s will be used as two groups of baselines in our experiments. 
We evaluate the proposed appro ach using a real-world data from Yahoo! Answers and conduct different experiments to ad-dress the following questions: (1) Are there any distinctions be-tween users X  dual roles and how they affect the result of question recommendation? (2) Does the proposed DRM improve the effec-tiveness of question recommendation compared with other base-line methods? (3) Which of the two variants of DRM for question recommendation, namely IDRM and DDRM, is more effective? In order to obtain the data sets for experiments, we used Yahoo! Answers API 3 to crawl 246490 resolved questions posted in 2011 from Yahoo! Answers. All the questions are lowercased and all stop words are removed from questions using a standard list of 418 common terms before further experiments. 
In our question set  X  , we divide the whole question set and user set  X  X , X  X  into three subsets according to the user participation degree. For each subset, we split it into the training set and the testing set based on the asked time of questions. The training set is used solely for parameter estimation and the test set is used for evaluation purposes. In each subs et, we take about 9/10 of ques-tions as training set, and the rest as testing set. The data set statis-tics of all subsets are listed in Table 1. Each dataset contains a question set and a user set. For in stance, the question set and user set of User-10 are  X   X  X  and  X   X  X  . We selected users who asked or answered more than 10 questions as the user set  X  collected questions which were as ked or answered by users in  X  as the question set  X   X  X  . Other subsets are similar to User-10. 
In traditional recommender syst ems, precision is a commonly used measure to evaluate the perf ormance. However, precision is not suitable in the CQA context. There are so many questions asked in a CQA community every day [1] that the user can only access a very small portion of al l questions. While the questions one accessed are those he is interested in, we can not guarantee that the remaining unaccessed questions are those he does not because he had no chance to see the question in CQA system. Therefore, we employ a new metric proposed in [6] to evaluate the effectiveness of question recommendation in CQA. 
For a question in testing set, th e user who provides the best an-swer (named the best answerer, Adamic et al. [27] have verified that answers selected as the best ones are mostly indeed the most suitable for the questions.) of this question is seemlier to answer it compared with other answerers, so it is more reasonable to rec-ommend this question to the best answerer than other answerers. Based on this intuition, we only recommend the question to the users who actually answered it instead of all possible users in the whole dataset. Then the recomme ndation accuracy for this ques-tion is defined according to the rank of the user who provides the best answer. (We only keep the que stions which have more than one answer and are already labele d with the best answers in the testing set.) Therefore, according to the evaluation metric applied http://developer.yahoo.com/answers in [6], we utilize the best answ erer X  X  rank as the ground truth of our evaluation metric: where |  X  | is the length of recommending list, which is equally the number of answers, and  X   X  X  X  X  X  is the rank of the best answerer. 
We first discuss an interesting subject: the distinction be-tween the user X  X  two roles. Based on latent topic an alysis of user roles in DRM, the distinction between the answer role and the asker role is defined as the diffe rence between their topic distribu-tions. The larger the difference between the topic distributions is, the greater the distinction between roles is. In information theory, the Kullback-Leibler divergence (KL divergence) is a commonly used non-symmetric measure of th e difference between two prob-ability distributions. We apply the KL divergence to assess the distinction between user roles. According to the modeling results of user roles in DRM, we obtain the latent topic distributions of each user role: 
Based on the above two equations , the distinction between an-swer role and asker role of the user  X  is 
In DRM, the number of topics is a parameter that has siginificant impact on the performance. We utilize cross-validation to estimate the parameters. Based on experiments of tuning parameter, we empirically set topic number to 70 to train our DRM. 
First, we analyze the average of KL divergence of all users in the user set of each subset to measure the overall distinction be-tween user roles. The results are summarized in Table 2. Across data subsets  X  the overall role distinction in ID RM is about 1.3 to 1.5, and that in DDRM is about 2.4. Compared with IDRM, the role distinction in DDRM is greater and relatively more stable over different data subsets. 
Furthermore, we take User-10 as an example to detail the dis-tribution of role distinction, which is illustrated in Figure 3. For the DDRM, role distinction of 65.5 % of users is more than 1.0, and most of them is in the range of [0.5, 3.5]. For the DDRM, role distinction of 74.3% of users is more than 2, most of which is in the range of [1.5, 4.5]. This shows that there are clear differences between different roles of most of users in CQA. Another important result to note is that the role distinction in DDRM is more obvious and relativel y more stable than that in IDRM, which can be observed in bot h of overall and detailed role analysis. This result may be due to that DDRM models the depen-Answerer Blended Table 4: All versions of baselines considering users X  different roles. dence between users which is more effective to capture the pecu-liarities of different user roles. 
After discussing the role analysis of all users, we take a typical user in DDRM as an illustrative example to show the modeling results of user roles. Table 3 lis ts the topic with maximum proba-bility and corresponding top words of the topic for both of user programmer (such as junior college students from school of com-puter science). He has some basi c knowledge of computer and is familiar with using computer, so he solved many questions about that topic. While he may be just getting started with computer programming, a lot of questions he asked are related to program-ming. 
In this section, we explored how different roles of users affect the result of question recommendation. Moreover, we compared our DRM-based question reco mmendation method with other methods. 
The models proposed in previous work are classified into two main categories. The first one is the word-level Vector Space Model (VSM) which is directly used to compute the similarity between users and questions. VSM only make use of word-level information to model users and que stions. For example, the user and question are represented as vectors with tf.idf word weights, and then cosine similarity between them is defined as: where  X  X  X . X  X   X   X , X   X  is the word  X   X  X  tf.idf weight in question  X  , and  X  X  X . X  X   X   X , X   X  is the sum of  X   X  X  tf.idf weights in questions that  X  asks or answers. 
The second one is PLSA based methods. As we have specified in section 3, these methods model the user either indirectly or directly. For the former, we took the model in [2] (PLSA1) as baseline. For the latter, we implemented the  X  X ser-word aspect model X  presented in [6] (PLSA2) as another baseline. The details of PLSA1 and PLSA2 have been described in section 3. 
In order to explore the impact of different user roles on ques-tion recommendation, we implemented the different ver-sions of the three groups of baseli nes. These versions are based on the answerer role, the asker role , or the blended roles. Table 4 shows the labels of all baseline methods. Each version of a base-line is trained on the question set that users access under the cor-responding role. Specifically, the blended roles mean all the ques-tion that each user answers or asks are simply mixed together as one set. 
Based on cross-validation, we se lected the best topic number for PLSA1 and PLSA2. The reco mmendation results of baselines and our DRM are summarized in Table 5, where the best result for each baseline group is underlined and the best result in each data subset is highlighted. 
We first compare the performances of different roles in each baseline group. From Table 5, we observe that the answerer role always wins the best result in all baseline groups across data sub-sets. Especially, the answerer ro le is obviously better than the asker role over all the recommendation results. When data sets become denser and denser from User-10 to User-20, the effect of the answerer role becomes better and better as we expect. On the contrary, the result of the asker role appears an unexpected de-crease in User-20. Furthermore, we examine the recommendation results of blended roles. As we can see, simply mixing the asker role into the answerer role not only fails to improve but worsens recommendation results of answerer role instead. According to above experiments, we conclude that different user roles re-flect the different aspects of the user, moreover, there are clear distinctions between their influences on question recommenda-tion. When modeling the user in CQA, we must distinguish the different user roles. When reco mmending new questions to users, it would be more appropriate to use the answerer role model to represent the candidate users. 
Since the recommendation methods based on blended roles do not work well, whether our DRM ba sed method can make full use of user X  X  dual roles to improve the recommendation result? Tested on each data subset, our model exhibits good performance, signif-icantly outperforming all baseline s. The relative improvement of DDRM over the best baseline result is 7.2% for User-10, 6% for User-15, and 3.4% for User-20. In addition, DDRM is significant-ly better than IDRM across data sets, which means considering the dependence between uses is more effective to model user roles. This result is also consiste nt with the above role analysis. 
Another interesting result to note is that the PLSA1 which models the user indirectly is a lmost equivalent to PLSA2 which models the user directly on three da ta subsets, suggesting that it is feasible to model the user indirectly by combining the topic in-formation questions that he accesses. Additionally, it is clear that all methods based on latent topic analysis (PLSA1, PLSA2, and DRM) always perform better than word-level VSM, which demonstrates that the latent topi c based model can be more effec-tive to represent the profile of user. And this result also verifies the conclusion drew in [6]. Moreover, it is part of the reason for that Guo et al. [4] introduced topic-level model to improve heuris-tic word-level methods. 
We note that the topic number K is an important parameter in our proposed DRM. Therefore, we are interested in analyzing the sensitivity of the recommendation performance of DRM with respect to the topic number. We tested these two DRM variants with 8 different values of K, which is illustrated in Figure 4. Like previous role analysis, we only pr esent the final results in data subset User-10. The results for other subsets are similar. As we can see from Figure 4, the recommendation accuracy gradually increases when the topic number varies from 10 to 40. Then we observe that the effectiveness of both DRM based recommenda-tion approaches begins to be relatively stable when topic number is more than 40. 
The user in CQA plays two different roles (dual roles) simulta-neously, which is different from the user in a general recommend-er system. In this paper, we have systematically investigated the distinctions between users X  dual roles and how they affect the performance of question recommendation differently. Moreover, in order to represent the user in CQA with dual roles more reason-ably and precisely, we proposed a Dual Role Model (DRM) to model the user X  X  different roles. With different independ-ence assumptions, two variants of DRM were achieved, which were independent DRM (IDRM) and dependent DRM (DDRM). Finally, we presented the DRM based approach to question rec-ommendation which can take full ad vantage of the particularities of users X  different roles. Based on a unified probabilistic frame-work, our DRM based method natu rally combines the user rela-tion between the answerer and the asker with the content rele-vance between the answerer and the question. 
Our experiments were carried ou t on a real-world data crawled from Yahoo! Answers. First, the re sults of user role analysis showed that there are evident differences between the answerer role and asker role of users in CQA. Comparing the effects of the two roles on question recommendation, we discovered that the answerer role model is more appropriate to represent the candi-date users when recommending new questions to users. Addition-ally, an interesting result was that simply mixing the asker role into the answerer role not only failed to improve but impaired recommendation results of answerer role instead. Furthermore, we compared our DRM based recommendation methods with base-line methods based on a single role or blended roles. Experiment results on three data subsets sh owed our DRM significantly out-performs all baselines, where the relative improvement of DRM over the best baseline result is 7. 2% for User-10, 6% for User-15, and 3.4% for User-20. In addition, DDRM is more effective than IDRM across data subsets, suggesting it is more effective to mod-el users X  dual roles. Finally, the parameter sensitivity analysis showed our DRM approach is robust. There are two interesting future research directions to explore. One of the most interesting directions is to further study how the roles of users will vary over time, and whether that will have in-fluence on question recommendation. The other interesting direc-tion is how to diversify the recommendation results to satisfy users better. We thank the anonymous reviewers for their useful comments. This work is supported by the National Science Foundation of China under Grant No. 61070111. [1] L. Rao. Yahoo mail and im us ers update their status 800 [2] Hu Wu, Yongji Wang and Xiang Cheng. Incremental Prob-[3] Damon Horowitz and Sepandar D. Kamvar. The anatomy of [4] Jinwen Guo, Shengliang Xu, Shenghua Bao, and Yong Yu. [5] Gideon Dror, Yehuda Koren, Yoelle Maarek and Idan [6] Mingcheng Qu, Guang Qiu, Xiao fei He, Cheng Zhang, Hao [7] Alexandrin Popescul, Lyle H. Ungar, David M. Pennock [8] Baichuan Li, Irwin King and Michael R. Lyu. Question [9] Thomas Hofmann and Jan Puzich a. Latent class models for [10] Thomas Hofmann. Proba bilistic latent sema ntic indexing. In [11] Luo Si and Rong Jin. Flexib le mixture model for collabora-[12] David M. Blei , Andrew Y. Ng and Michael I. Jordan. La-[13] Thomas Hofmann. Collaborative filtering via gaussian [14] Tom Chao Zhou, Chin-Yew Lin, IrwinKing, Michael R. [15] Qiaoling Liu and Eugene Agichtein. Modeling answerer [16] Ke Sun, Yunbo Cao, Xinying Song, Young-In Song, [17] Nathan N. Liu and Qiang Yang. EigenRank: A ranking-[18] Adomavicius G., and Tuzhilin A. Toward the next genera-[19] P. Kantor, F. Ricci, L. R okach, and B. Shapira. Recom-[20] Thomas Hofmann. Unsupervised learning by probabilistic [21] Jiwoon Jeon, W. Bruce Croft, Joon Ho Lee and Soyeon [22] Jiwoon Jeon, W. Bruce Crof t and Joon Ho Lee. Finding [23] G. Linden, B. Smith, and J. York. Amazon.com recommen-[24] Jiahui Liu, Peter Dolan, Elin R X nby Pedersen. Personalized [25] Y. Cao, H. Duan, Chin-Yew Lin, Y. Yu and Hsiao-Wuen [26] S. Deerwester, S. Dumais, T. Landauer, G. Furnas, and R. [27] J. Zhang, L. A. Adamic, E. Bakshy and Mark S. Ackerman. [28] M. Pazzani and D. Billsus. Learning and revising user pro-[29] Y. Koren, R. M. Bell, and C. Volinsky. Matrix factorization [30] Kevin K. Nam, Mark S. Ackerman, Lada A. Adamic. Ques-[31] Pawel Jurczyk, Eugene Agichtein. Discovering authorities 
