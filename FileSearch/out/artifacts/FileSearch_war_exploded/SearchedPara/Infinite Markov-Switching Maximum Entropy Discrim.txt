 Sotirios P. Chatzis soteri0s@icloud.com Cyprus University of Technology In this work, we focus on the problem of classifying data with temporal interdependencies by application of large-margin techniques. In the last years, sev-eral researchers, inspired from the literature of support vector machines (SVMs), have proposed large-margin methods capable of classifying sequential data under the large-margin paradigm. For example, in Sha &amp; Saul (2007), a large-margin generative model is pro-posed for sequential data classification; in Altun et al. (2004), an extension of SVMs suitable for structured output prediction is proposed, and is further applied to sequential data classification. The power and pop-ularity of such large-margin approaches stems in part from the fact that their inference and training reduce to convex optimization problems, thus not suffering from the possibility of getting stuck to spurious local optima, which is often the case with alternative ap-proaches. However, learning only a single large-margin model may often be less than sufficient to capture the underlying patterns (e.g., temporal clusters) in mod-eled data with rich and complex dynamics.
 To address this issue, recently, a mixture-of-experts (Collobert et al., 2002; Fu et al., 2010; Zhu et al., 2011) model was proposed that uses a set of SVM classifiers, each one trained to perform modeling in a coherent subregion of the observations space. As such, each one of these classifiers, and, hence, the derived model as a whole, can capture much more subtle underly-ing patterns than a single SVM expert. However, a drawback of this approach is its complete lack of an explicit mechanism for capturing temporal dynamics in sequential data, encapsulated in the context of an appropriate component switching mechanism.
 Inspired by these advances, in this paper we propose a Markov-switching mixture of large-margin classifiers for sequential data classification. A first basic con-cept underlying our approach is that, in data with temporal dynamics, one large-margin classifier is not enough for capturing rich underlying temporal struc-tures; therefore, use of a set of local experts is needed. A second key-concept of our approach that differenti-ates it from existing approaches consists in the intro-duction of an appropriate mechanism describing how subsequent observations may belong to different sub-regions in the considered observations space. Indeed, simply considering that the data are generated from these subregions as draws from independent distribu-tions is not expected to allow for effective modeling. Rather, one would expect that such subregions could be interpreted as temporal states or subpatterns in the modeled data; therefore, transition from one state to another should be described by an appropriate model of temporal dependencies. To account for these facts, in this work we employ a latent first-order Markov chain to capture the temporal dynamics of the alloca-tion of successive observations to the postulated model component large-margin classifiers.
 A challenge in the field of Markov-switching models consists in the data-driven determination of the num-ber of their latent states (model components) required to represent the modeled data (model order). The most common data-driven methodologies for model or-der selection are based on the popular Bayesian infor-mation criterion (BIC) or other related model size se-lection criteria (McLachlan &amp; Peel, 2000). However, such model selection methods require training of mul-tiple models (to select from), a procedure which can be applied only up to a limited extent, due to its com-putational demands. In addition, they are also well-known for their overfitting proneness, hence often lead-ing to models much larger than necessary (McLachlan &amp; Peel, 2000).
 Nonparametric Bayesian modeling techniques, espe-cially Dirichlet process (DP) prior-based models, have become very popular in statistics over the last few years, for performing nonparametric density estima-tion (Walker et al., 1999; Neal, 2000; Muller &amp; Quin-tana, 2004). Briefly, a realization of a DP prior-based model can be seen as an infinite mixture of distri-butions with given parametric shape (e.g., Gaussian, HMM, etc.). Indeed, although theoretically a DP prior gives rise to an infinite number of parameters for the model, it turns out that inference for the model is pos-sible, since only the parameters of a finite number of model components need to be represented explicitly (Neal, 2000; Antoniak, 1974).
 Motivated by these results, formulation of our model is based on the introduction of appropriate nonparamet-ric priors over the employed large-margin component classifiers of our model. Specifically, we utilize ap-propriate stick-breaking priors under a truncated non-parametric Bayesian inference scheme (Sethuraman, 1994). This way, our model combines the advantages of Bayesian nonparametrics to allow for automatic, data-driven determination of the appropriate number of model components (states), and large-margin clas-sifiers to capture local nonlinearity in the context of a convex optimization scheme, not suffering from getting trapped into spurious local optima.
 To perform inference, we employ the maximum en-tropy discrimination (MED) framework (Jaakkola et al., 1999), which integrates the large-margin princi-ple with Bayesian posterior inference in an elegant and computationally efficient fashion, allowing to leverage existing high-performance techniques for DP and SVM models. We dub our approach the infinite Markov-switching maximum entropy discrimination machine (iM 2 EDM) for sequential data classification. The remainder of this work is organized as follows: In Section 2, we briefly review the theoretical back-ground of our method, namely DP priors and the MED framework. In Section 3, we introduce the iM 2 EDM approach, and derive its training and inference algo-rithms. In Section 4, we perform experimental eval-uations, considering several applications dealing with semantic classification in real-world video sequences. In the final section of this paper, we summarize and discuss our results. 2.1. Dirichlet process models DP models were first introduced in Ferguson (1973). A DP is characterized by a base distribution G 0 and a positive scalar  X  , usually referred to as the innovation parameter, and is denoted as DP( G 0 , X  ) . Essentially, a DP is a distribution placed over a distribution. Let us suppose we randomly draw a sample distribution G from a DP, and, subsequently, we independently draw N random variables {  X   X  n } N n =1 from G : Integrating out G , the joint distribution of the vari-ables {  X   X  n } N n =1 can be shown to exhibit a clustering effect. Specifically, given the first N  X  1 samples of G , {  X   X  n } N  X  1 n =1 , it can be shown that a new sample  X  either (a) drawn from the base distribution G 0 with probability  X   X  + N  X  1 , or (b) is selected from the exist-ing draws, according to a multinomial allocation, with probabilities proportional to the number of the previ-ous draws with the same allocation (Blackwell &amp; Mac-Queen, 1973).
 A characterization of the (unconditional) distribution of the random distribution G drawn from a Dirichlet process DP( G 0 , X  ) is provided by the stick-breaking construction of Sethuraman (1994). Consider two infinite collections of independent random variables the Beta distribution Beta(1 , X  ) , and the  X  c are inde-pendently drawn from the base distribution G 0 . The stick-breaking representation of G is then given by (Sethuraman, 1994) where and Note that, typically, due to the significant effect of the innovation parameter  X  on the internal data allo-cation mechanism of the DP, an appropriate prior is also imposed over  X  in the context of model inference. Usually, a conjugate Gamma prior is imposed, s.t. 2.2. Maximum entropy discrimination Let us denote as x  X  R d an observation vector from a modeled input space, and as y the classification la-bel assigned to it, taking values from the finite set { 1 ,...,L } . Let us also consider a large-margin clas-sifier for this problem, and denote as F ( y, x ; w ) its discriminant function with parameter vector w . In conventional large-margin classifiers, such as SVMs, a point-estimate is obtained for the parameter vector w by resolving a (typically convex) constrained opti-mization problem. A major drawback of such point-estimates is their lack of a direct probabilistic inter-pretation. As a consequence, such approaches prove to underperform, and be vulnerable to input noise, since point-estimates cannot account for the uncertainty in the modeled datasets.
 MED is a method that allows for resolving these issues of conventional large-margin classifiers, by learning a distribution q ( w ) obtained as the solution of the fol-lowing entropic regularized risk minimization problem (Jaakkola et al., 1999) where p ( w ) is a prior imposed over the parameter vector w ,  X  is a positive regularization constant, and KL ( q || p )) stands for the Kullback-Leibler divergence between q ( w ) and p ( w ) . R ( q ( w )) is the hinge-loss function; it encodes the large-margin principle under-lying the considered classifier, and is defined as R ( q ( w )) ,
X where { x n ,y n } N n =1 is the set of available training ex-amples (input/output pairs),  X  n ( y ) is usually defined as a binary function equal to one if the computed out-put y and the true (training) label y n are different, and  X  X  X  q (  X  ) is the expectation of a quantity with respect to the posterior distribution q (  X  ) .
 Finally, under the MED framework, the prediction rule of the derived large-margin classifier becomes essentially utilizing the expectation of the employed discriminant function with respect to the parameters posterior q ( w ) to obtain predictions in a way similar to conventional large-margin approaches.
 The Bayesian-style formulation of MED renders it an elegant means of integrating the ideas of large-margin learning and Bayesian generative modeling, and in-cludes SVM-type models as a special case. In addition, MED allows for incorporating latent variables in the derived models (Lewis et al., 2006), which comprise a key-tool in machine learning, as well as for performing structured output prediction (Zhu &amp; Xing, 2009). 3.1. Model Formulation As we have already discussed, using a single global MED/large-margin classifier to model the complex un-derlying patterns in sequential observations is rather unlikely to yield models with satisfactory recognition performance. In addition, existing mixture-of-expert approaches (e.g., Fu et al., 2010; Zhu et al., 2011) are not designed for handling sequential data with under-lying temporal patterns and dynamics. Apparently, in such a setting, the temporally dependent observations cannot be accurately modeled as draws from indepen-dent distributions.
 Under these considerations, we introduce the iM 2 EDM method; it comprises a set of large-margin classifiers, each one fitted to capture complex structure in a sub-part of the observations space (model state). The pat-tern under which successive observations are generated from different model states is captured by means of a latent first-order Markov chain that interconnects the component large-margin classifiers of the model (states).
 Let us consider an L -class classification problem, with class variables y  X  { 1 ,...,L } , and M -dimensional in-put observations x  X  R M . Derivation of our model commences by introducing a latent Markov chain com-prising infinite (latent) states, and considering that each modeled observation is associated with one la-tent model state. Let s t  X  X  1 ,...,  X  X  be a latent vari-able denoting the model state that generates the t th pair of input/output observations { x t ,y t } . To obtain an appropriate prior construction, we impose suitable stick-breaking priors over the latent state variables s t following the discussions of Section 2.1. Specifically, we impose stick-breaking priors over the latent state transitions in the Markov chain, of the form where the $ ij ( v $ ) are the probabilities generated by a stick-breaking process with stick-variables v $ , such and Similar, we impose a stick-breaking prior for the initial state prior probabilities  X  i of the latent Markov chain, such that v  X  = ( v  X  i )  X  i =1 and Subsequently, on the basis of this construction, and conditional on the latent Markov chain states gener-ating each observation, we employ a set of conditional discriminant functions for our model of the form where we let W = { w c }  X  c =1 , and denote as f ( y, x ) an ML -dimensional vector comprising L subvectors, with the y th one being equal to x , and all the others equal to 0 . Each one of the used discriminant functions F ( y t , x t | s t = c ; W ) captures complex non-linearities in a subpart of the observations space, related to an underlying subpattern in the modeled data, and asso-ciated with the corresponding ( c th) latent model state. Regarding the model parameters w c , we choose to im-pose a standard Gaussian prior over them, of the form The above prescribed prior construction, given by Eqs. (11)-(22), defines the proposed iM 2 EDM model. Then, if we consider a pair of input/output observation se-quences { X,Y } , with X = { x t } T t =1 and Y = { y t } T the overall discriminant function of iM 2 EDM yields
F ( Y,X ) = Finally, similar to the discussions of Section 2.2, the prediction rule for our iM 2 EDM model, with discrim-inant function (23), eventually yields 3.2. Model Training To learn the optimal (approximate) posterior distribu-tions over the model parameters, i.e., W , v  X  , v $ , and  X  = {{  X  $ i } i , X   X  } , as well as over the latent variables of state allocation S = { s t } T t =1 , we resort to the MED framework. For this purpose, we need to introduce an appropriate loss function for the prediction rule (24) of our model. Following the discussions of Section 2.2, we introduce a hinge-loss function, yielding R ( q ( S,W )) , max where P T t =1  X  t ( y  X  t ) is equivalent to the Hamming dis-tance between the estimated labels sequence Y  X  and the correct one Y . Then, based on the principles of the MED framework, our learning problem reduces to solving the following entropic regularized risk mini-mization problem where we denote  X  , { W,S, v $ , v  X  ,  X  } . To solve (26), we further assume that the sought (ap-proximate) posterior factorizes similar to the consid-ered prior p ( X ) : q ( X ) = q ( W ) q ( S ) q ( v $ ) q ( v Under this assumption, usually referred to as the mean-field approximation (Chandler, 1987; Winn &amp; Bishop, 2005), our learning problem eventually be-comes Apparently, under the infinite dimensional setting of our model, optimization of the risk function (27) is in-tractable, as it entails an infinite number of optimized factors. To resolve this issue, and render our model training algorithm computationally feasible, we trun-cate the imposed stick-breaking priors (Blei &amp; Jordan, 2006): we fix a value C and let the posteriors over the v ij and the v and q ( v  X  C = 1) = 1 . In other words, we set  X  c ( v  X  $ ic ( v $ ) equal to zero for c &gt; C . Note that, under this setting, our iM 2 EDM model still involves a full stick-breaking prior; truncation is not imposed on the model itself, but only on its (approximate) posterior distri-bution to allow for a tractable inference procedure. Hence, the truncation level C is a free parameter, and not part of the prior model specification.
 Posteriors over the model parameters. Solving problem (27), the posterior over w c yields where where the multipliers  X  y t are computed by resolving the dual quadratic programming problem Similar, regarding the stick-breaking variables, we have where  X  and where Finally, the innovation parameters yield where and where Posteriors over the latent variables. Minimizing the criterion (27) w.r.t. q ( S ) , we obtain where p ( y t , x t | s t = c ) , exp X and Q is a normalizing constant. From (46), it follows that the expression of q ( S ) for our model is analogous to the expression of q ( S ) pertaining to a first-order hid-den Markov model (HMM) (McLachlan &amp; Peel, 2000), with initial state prior probabilities equal to  X   X  c , state-transition priors equal to $  X  ij , and state-conditional putation of both the state-transition posteriors q ( s t = assignment posteriors q ( s t = c ) ,  X  c,t , of the iM 2 can be performed by considering the analogous (proxy) HMM described previously, and running the forward-backward algorithm (Rabiner, 1989) for that HMM. This way, we obtain the sought latent variable poste-riors for our model in an elegant and computationally efficient manner. 3.3. Prediction Generation Given a trained iM 2 EDM, when a new test sequence X = { x t } T t =1 is provided, the prediction task consists in computing the optimal corresponding class labels sequence Y = { y t } T t =1 , by application of the prediction rule (24).
 For this to happen, we need to compute the initial state posteriors q ( s 1 = i ) and the state-transition pos-teriors q ( s t = j | s t  X  1 = i ) for the test sequence X This can be conducted in a fashion similar to the MED training algorithm of our model: specifically, to obtain the sought posteriors, we consider the regularized risk minimization problem which is clearly analogous to the approach we used for model training, and yields exactly the same posterior expressions for q ( S ) as those obtained in Section 3.2.2. However, a careful inspection of Eqs. (43) and (46) shows that computation of these posteriors, q ( S ) , re-quires knowledge of the class labels Y , which are the unknown sought quantities of our prediction al-gorithm. Therefore, application of the prediction rule (24) of the iM 2 EDM yields a computationally cumber-some dynamic programing optimization procedure. To ameliorate these drawbacks, we devise an alter-native approximate algorithm for prediction gener-ation under the proposed iM 2 EDM method. Our approximation, inspired by the mean-field principle (Winn &amp; Bishop, 2005; Chandler, 1987), and the point-pseudo-likelihood technique of Qian &amp; Titterington (1991a;b), is an iterative algorithm comprising the fol-lowing steps: 1. Initially, an approximate estimate of Y is ob-2. Using the so-obtained estimates Y , we compute 3. We run the optimization process (24), with the 4. We repeat steps 2 and 3 until convergence. 3.4. Relation to existing approaches Our method follows the MED paradigm, which com-bines the ideas of large-margin classification and Bayesian inference techniques. It also exploits the mer-its of Bayesian nonparametrics, to allow for automatic model order determination. In that sense, our ap-proach is related to the iSVM approach (Zhu et al., 2011); iSVM is an infinite mixture model of large-margin (SVM) classifiers. The inference algorithm of our model shares several common steps with the vari-ational algorithm of iSVM. On the other hand, iSVM employs a likelihood model, while the proposed model strictly follows the MED framework, without a data likelihood model. In this latter aspect, our method shares similar concept with the nonparametric MED model for matrix factorization of Xu et al. (2012). In the following, we experimentally evaluate our ap-proach using real-world datasets. We compare the per-formance of our approach to large-margin HMMs (LM) (Sha &amp; Saul, 2007), moderate-order CRFs of 5th order (5-CRF) (Ye et al., 2009), the hidden Markov support vector machine (HMSVM) approach of Altun et al. (2004), and the iSVM approach of Zhu et al. (2011) with RBF kernels. Our source codes were developed in MATLAB R2012a.
 4.1. Sports Video Mining In this experiment, we consider the problem of sports video mining in football videos. We follow the exper-imental setup of (Ding &amp; Fan, 2009). We detect four camera view classes, namely central, left, right, and end-zone, and four play types, namely long play, short play, kick, and field goal play.
 Feature Extraction. To capture camera view infor-mation, we use the color distribution and the yard line angle (Dingand &amp; Fan, 2007). For this purpose, we es-timate the spatial color distribution, and perform edge detection using the Canny algorithm, which we com-bine with the Hough transform to detect the yard lines and to compute their angles. Regarding play type in-formation extraction, we utilize for this purpose cam-era motion information (panning and tilting), as this information is sufficient to characterize different play types: strong panning is usually associated with a long play, while a weak panning effect is usually associated with short plays (Ding &amp; Fan, 2009). To compute the two kinds of camera motion, we choose the optical flow-based method of Srinivasan et al. (1997). Experimental Setup and Results. We evalu-ate the efficacy of the proposed approach by using a database comprising twelve 30-min NFL American football games. The videos are of 720  X  576 resolution, and were preprocessed so as to remove commercials and replays. As such, from each video, a series of play shots was obtained, with each video being typically segmented into 138 X 189 shots, and each shot compris-ing 600 X 900 frames. We provide few example frames of the used videos in Fig. 1.
 From this raw data, we extract the feature descriptors presented previously, and use them to train and eval-uate the considered models. We use cross-validation in the following fashion: in each cycle, we use 75% of the available shots for training, and the rest for testing. We run the same experiment 10 times, using each time different splits of the available video shots into train-ing and test sets, to account for the effect of random selection of samples.
 In Table 1, we provide the obtained performances of the evaluated algorithms (average results per detected class over the conducted 10 repetitions of our experi-ments). As we observe, our method works clearly bet-ter than all the considered approaches. Further, ex-ploiting the availability of multiple performance mea-surements for the evaluated algorithms (over 10 exper-iment repetitions), we evaluate the statistical signifi-cance of the obtained average performance differences using the Student X  X -t test. Generated p -values of the Student X  X -t test below 0.05 strongly indicate that the average performance statistics of two compared meth-ods provide a very good assessment of their actual performance difference. Running the Student X  X -t test, we obtained p -values ranging from 10  X  4 in the case of the 5-CRF method (compared against our method) to 10  X  9 in the case of the iSVM; thus, the Student X  X -t test found that the obtained performance differences between our method and its competitors are strongly statistically significant in all cases.
 4.2. Activity recognition in depth image In this experiment, we evaluate our method in seg-menting and classifying depth image sequences, which depict humans performing actions in an assistive liv-ing environment. More specifically, our experiments are based on the dataset described in Ni et al. (2011). This dataset includes several actions from which we have selected the following: (1) get up from bed, (2) go to bed, (3) sit down, (4) eat meal, and (5) drink water. Some example frames from the considered dataset are depicted in Fig. 2. We seek to recognize these actions (1)-(5), using as our observable input the sequence of vectors x extracted as described next.
 From this dataset, we extract features similar to Ni et al. (2011), by computing motion history images along the depth change directions. To calculate depth change, we use depth maps computed by a Kinect TM device. Kinect depth maps, however, contain a sig-nificant amount of noise. After frame differencing and thresholding, we noticed that motion was encoded even in areas with only still objects. To tackle this problem, we use median filtering. In the temporal do-main, each pixel value is replaced by the minimum of its neighbors. Eventually, from these motion his-tory images, we extract the first 12 complex Zernike coefficients (both norm and angle) (Kosmopoulos &amp; Chatzis, 2010), and use them as our feature vectors. In our experiments, each action is contained in 35 video sequences. Each one of these sequences, de-rived from the dataset of Ni et al. (2011), contains at least two of the considered actions (sequentially ap-pearing). This setting enables us to assess the capacity of the evaluated algorithms to recognize these actions in real-world activities (in an assistive living environ-ment). We subsample these video sequences by a fac-tor of 2, similar to Ni et al. (2011). We use cross-validation in the following fashion: in each cycle, we use 15 randomly selected video sequences to perform training, and keep the rest 20 for testing. We run the same experiment 50 times to account for the effect of random selection of samples. Recognition consists in assigning each feature vector to a corresponding action class. We provide the obtained average performance results (mean obtained error) over the conducted ex-periment repetitions in Table 2, where we also illus-trate the obtained p -values of the Student X  X -t test. As we observe, our method obtains competitive re-sults, yielding statistically-significant performance dif-ferences over the considered alternative methods. 4.3. Discussion on Computational Complexity The computational costs of both the training and pre-diction algorithms of our model are comparable to those of iSVM. This is due to the very efficient na-ture of the forward-backward algorithm used in model training, and the approximation of the original pre-dictive functional of our model by treating q ( S ) as a known, iteratively updated quantity. Note also that, in all our experiments, the iterative prediction algorithm of our model converged in less than 10 repetitions. In this paper, we presented a Markov switching model comprising an infinite set of component large-margin classifiers for sequential data. Our model is capa-ble of capturing subtle temporal patterns underlying sequential data observations; further, by leveraging the strengths of Bayesian nonparametrics, specifically stick-breaking priors, it allows for data-driven determi-nation of the appropriate number of component large-margin classifiers. Model training and inference was made possible by utilizing the MED framework in the context of an efficient truncated representation of the stick-breaking process. We illustrated the efficacy of our approach using two real-wold datasets, and com-paring its performance to state-of-the-art alternatives. Future goals in this line of research comprise imposing kernel functions on the input observations x , instead of the linear construction of the component-wise dis-criminant functions F ( y, x | s ) , implied by the way we have defined the auxiliary functions f ( y, x ) in Section 3.1. This development will allow for our method to handle cases where the nature of the modeled sequen-tial observations is not vectorial (feature vectors), but graphs, trees, or other types of structured input. We shall provide demos of our method at: http://www.cut.ac.cy/eecei/staff//sotirios.chatzis. Altun, Yasemin, Tsochantaridis, Ioannis, and Hof-mann, Thomas. Hidden Markov support vector ma-chines. In Proc. ICML , 2004.
 Antoniak, C. Mixtures of Dirichlet processes with ap-plications to Bayesian nonparametric problems. The Annals of Statistics , 2(6):1152 X 1174, 1974. Blackwell, D. and MacQueen, J. Ferguson distribu-tions via P X lya urn schemes. The Annals of Statis-tics , 1(2):353 X 355, 1973.
 Blei, David M. and Jordan, Michael I. Variational inference for Dirichlet process mixtures. Bayesian Analysis , 1(1):121 X 144, 2006.
 Chandler, D. Introduction to Modern Statistical Me-chanics . Oxford University Press, New York, 1987. Collobert, R., Bengio, S., and Bengio, Y. A parallel mixture of SVMs for very large scale problems. In Proc. NIPS , 2002.
 Ding, Y. and Fan, G. Sports video mining via multi-channel segmental hidden markov models. IEEE Trans. on Multimedia , 11(7):1301 X 1309, 2009. Dingand, Y. and Fan, G. Segmental hidden Markov models for view-based sport video analysis. In
Proc. IEEE Int. Conf. Computer Vision and Pat-tern Recognition , 2007.
 Ferguson, T. A Bayesian analysis of some nonparamet-ric problems. The Annals of Statistics , 1:209 X 230, 1973.
 Fu, Z., Robles-Kelly, A., and Zhou, J. Mixing linear SVMs for nonlinear classification. IEEE Trans. on Nueral Networks , 21(12):1963  X  1975, 2010.
 Jaakkola, T., Meila, M., and Jebara, T. Maximum entropy discrimination. In Proc. NIPS , 1999. Kosmopoulos, D. and Chatzis, S.P. Robust visual behavior recognition. Signal Processing Magazine, IEEE , 27(5):34  X 45, sept. 2010.
 Lewis, D., Jebara, T., and Noble, W. Nonstationary kernel combination. In Proc. ICML , 2006.
 McLachlan, G. and Peel, D. Finite Mixture Mod-els . Wiley Series in Probability and Statistics, New York, 2000.
 Muller, P. and Quintana, F. Nonparametric Bayesian data analysis. Statist. Sci. , 19(1):95 X 110, 2004. Neal, R. Markov chain sampling methods for Dirichlet process mixture models. J. Comput. Graph. Statist. , 9:249 X 265, 2000.
 Ni, Bingbing, Wang, Gang, and Moulin, Pierre.
RGBD-HuDaAct: A color-depth video database for human daily activity recognition. In ICCV Work-shops , pp. 1147 X 1153, 2011.
 Qian, W. and Titterington, D.M. Estimation of pa-rameters in hidden Markov models. Philos. Trans. R. Soc. London Ser. A , 337:407 X 428, 1991a.
 Qian, W. and Titterington, D.M. Stochastic relax-ations and EM algorithms for Markov random fields. J. Statist. Comput. Simul. , 40:55 X 69, 1991b. Rabiner, L.R. A tutorial on hidden Markov models and selected applications in speech recognition. Proceed-ings of the IEEE , 77:245 X 255, 1989.
 Sethuraman, J. A constructive definition of the Dirich-let prior. Statistica Sinica , 2:639 X 650, 1994. Sha, Fei and Saul, Lawrence K. Comparison of large margin training to other discriminative methods for phonetic recognition by hidden Markov models. In Proceedings of IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP 2007) , pp. 313 X 316, 2007.
 Srinivasan, M., Venkatesh, S., and Hosie, R. Qualita-tive estimation of camera motion parameters from video sequences. Pattern Recognit. , 30:593 X 606, 1997.
 Walker, S., Damien, P., Laud, P., and Smith, A.
Bayesian nonparametric inference for random distri-butions and related functions. J. Roy. Statist. Soc. B , 61(3):485 X 527, 1999.
 Winn, J. and Bishop, C.M. Variational message pass-ing. J. Machine Learning Research , 6:661 X 694, 2005. Xu, Minjie, Zhu, Jun, and Zhang, Bo. Nonparamet-ric max-margin matrix factorization for collabora-tive prediction. In NIPS , 2012.
 Ye, Nan, Lee, Wee Sun, Chieu, Hai Leong, and Wu,
Dan. Conditional random fields with high-order fea-tures for sequence labeling. In Proc. NIPS , 2009. Zhu, J. and Xing, E. Maximum entropy discrimination
Markov networks. J. Machine Learning Research , 10:2531 X 2569, 2009.
 Zhu, Jun, Chen, Ning, and Xing, Eric P. Infinite SVM: a Dirichlet process mixture of large-margin kernel
