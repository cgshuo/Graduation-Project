 according to the final document score which linearly combines the query rele-vance information score and the diversity information (i.e., topic coverage infor-mation and redundancy reduction information) score of the document. However, the original Affinity ranking model uses a predefined heuristic ranking func-tion which can only integrate limited features and has many free parameters to be tuned manually. A direct idea to solve this problem is to borrow machine learning methods to train the Affinity ranking model. Intuitively, the Affinity ranking model is similar to the traditional retrieval ranking model (e.g., query likelihood Language Model) which ranks documents in descending order accord-ing to document scores. Therefore, improving the Affinity ranking model with learning-to-rank technique is reasonable and feasible. To do this, in this paper, we addressed three pivotal problems, i.e., (i) how to redefine the ranking func-tion which can incorporate both relevance information and diversity information within an unified framework; (ii) how to learn the ranking model by optimizing the diversity evaluation metric directly; (iii) how to extract diversity features (i.e., topic coverage features and redundancy reduction features) inspired by the Affinity ranking model. Particularly, we propose a learning based Affinity ranking model by extending a well-known Learning-to-Rank method (i.e., Lamb-daMART). Extensive comparative experiments are conducted on diversity tracks of TREC 2009-2011, which show the effectiveness of our method. 2.1 Overview of Affinity Ranking Method This subsection gives a brief description of the Affinity Ranking model [ 8 ]which maximizes the topic coverage and reduces the information redundancy. At first, they introduce a directed link graph named Affinity Graph to compute the information richness score which represents how many the query subtopics have been covered for each document. Similar to the PageRank, the information rich-ness score for each document is obtained through running the random walk algorithm. The documents with largest information richness score (subtopic cov-erage information) will be returned to users. Meanwhile, in order to reduce the information redundancy, they compute the Affinity ranking score by deducting a diversity penalty score for each document as described in the Algorithm 1 . However, improving the diversity may bring harm to the relevance quality. In order to balance the diversity ranking and relevance ranking, their final rank-ing function linearly combines both original relevance score and Affinity ranking score, and then they sorts the documents in descending order according to the final combination score.
 uation measures) and incorporate more features, we propose a learning approach which is illustrated in the following parts.
 However, the evaluation metric needs to satisfy the property that if irrelevant document ranks before the relevant document after swapping (that is, wrong swapping), the metric should decrease (i.e.,  X Z ij &lt; 0). So if we extend derivative  X  ij by using the current diversity metric (e.g.,  X  -NDCG [ 3 ]or ERR -IA [ 2 ]), some adjustments should be made. The relevance label of a document is one value in original LambdaMART to decide the relevant-irrelevant document pair used in the Eq. 2 , while our label should a multiple values (in which each value represents whether the document is relevant to the each query subtopic) in order to compute the change value of diversity metric. So we assume that the document covering at least one query subtopic is more relevant than document covering no any query subtopics. Thus the label of the document covering at least one query subtopic is bigger than the document covering no any query subtopics. Therefore, the document label used in the training procedure contains two part. And then after defining the relevant-irrelevant document pair, we should show diversity metrics satisfy the above property. We choose the  X  -NDCG as the representative because ERR -IA is same in rewarding the relevant document ranking before the irrelevant document. In the top k results of a return list for query q ,for example, there are m documents which covers at least one query subtopic where four documents among the m is relevant to the query subtopic t . We denote the p 3 &lt;p 4 &lt;k . If one relevant document (we use d p 2 in the following proof case, which means the document at the position p 2 ) swaps with another irrelevant document which ranking position is beyond k, we have proved that  X Z &lt; 0. Let Z is the  X  -NDCG @ k before the swapping while  X  Z is the  X  -NDCG @ k after the swapping (the value of  X  is between 0 and 1). When only considering the log(1+ P 4 ) &lt; 0. The same is true for every subtopics. Thus, the diversity metric satisfies the above property. Through above adjustments, it is suitable for using the diversity metric as part of objective function to guide the training process. Feature Extraction. At first, we formalize the diversity features (which aim at maximizing the topic coverage and reducing the information redundancy) inspired by the Affinity ranking. For topic coverage maximization features, we use the information richness score used in the Affinity ranking model. For infor-mation redundancy reduction features, we formalize it according to Algorithm 1 : where document set D q is the already selected document set, t ( q, d i ) mea-sures how many query topics has been covered by the document d i , p ( d j ,d i ) denotes the penalty score that the document d j deploy to d i for the information baselines to show the diversity ability of Affinity ranking model. From Table 2 , we find AR model has better performance than other baselines. Moreover, we find that the result list does not achieve good diversity ability in term of diver-sity evaluation  X  -NDCG and ERR -IA for two approaches [ 1 , 9 ] which only reduce the redundancy. The experiment result shows that a group of document with low redundancy can not achieve large subtopic coverage. For RankScoreDiff approach [ 4 ], one only considers the subtopic coverage maximization, also out-perform MMR and QPRP [ 1 , 9 ]. The experiment results illustrate that query subtopic coverage maximization is more important than low information redun-dancy for diversity search. Secondly, we compare our model with AR model to prove that our model (both LAR(  X  -NDCG )andLAR( ERR -IA ) model) improve the diversity ability of AR model significantly. For using  X  -NDCG as evaluation metric, the improvement percentages of our model compared with the AR model is 26.96 % for LAR(  X  -NDCG ) and 31.31 % for LAR( ERR -IA ) respec-tively. When using ERR -IA as evaluation metric, the improvement percentage is 43.68 % for LAR(  X  -NDCG ) and 50.42 % for LAR( ERR -IA ) respectively. In this paper, we build a learning diversity model within the framework of learning-to-rank to improve the diversity ability of Affinity Ranking model. Our motivation comes from that the Affinity Ranking model can reduce the redun-dancy and make topic coverage maximization. Beyond that, the ranking principle of Affinity Ranking model makes it possible to build learning model with help of learning-to-rank approach. The final comparative experiments have shown that our approach is effective. In the future, we will propose better topic coverage representation technique to formalize the better diversity features.
