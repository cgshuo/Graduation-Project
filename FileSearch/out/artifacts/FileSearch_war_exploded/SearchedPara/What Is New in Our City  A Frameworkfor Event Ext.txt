 With the growing popularity of mobile devices and applications, more and more people are sharing their moments with their friends and the public through mainstream social media platforms such as Facebook (Instagram) and Twitter. A recent report 1 shows that Instagram now has more than 200 Million monthly-active-users (MAU) and these users upload more than 1 . 5 billion photos and videos per month. Twitter has even larger traffic and popularity, 255 Million MAUs and 15 billion tweets per month.
 Although a dominating proportion of posts from such social media platforms are about users X  personal life [ 19 ], such as emotional feeling, opinions, food, travel and even self-portraits, there are still considerable amount of posts recording what are happening in our city. A user may upload photos of a fashion show to her Instagram account, or talk about emergency or crime on Twitter. These valuable social media posts have made it possible for researchers and developers to accurately detect and present local events in real time. Such techniques will benefit various users, ranging from government officers, journalists, to tourists and residents, etc. For example, a system quickly reporting fire or car accidents can help the local police to make a timely response to the emergency; detecting entertaining events in real time and representing them to nearby tourists or residents can provide opportunities in social engagement.
 from social media data streams remains challenging. First, event-related social media data are sparse, although the volume of posts from any popular social media platform is large. Second, most current research focuses on Twitter [ 2 ], while there are various types of social media platforms which can potentially contribute to the detection problem. However, the problem to choose or combine multiple data sources to detect events is challenging due to the heterogeneity of posts from different data sources. Third, after detecting events, to represent events with the most relevant posts is still challenging due to the noisy posts stream with heterogeneous content including image, text and geolocation. framework first detects candidate event signals from Instagram and Twitter post streams, and then extract features to classify whether an event signal is a true event or noise. Finally, it summarizes the detected event by retrieving relevant photos and topics and then estimating the occurrence time and location. Besides the proposed framework, our contributions also include that we analyze different methods to integrate Instagram and Twitter post streams, and experimentally show that they improve the detection accuracy. To our best knowledge, we are the first to integrate Instagram and Twitter posts to detect events in real time. For event summarization, we propose a method to retrieve relevant photos, which utilizes image content, text and geolocation information. Finally, we conduct case studies to show that our framework has low spatial and temporal deviation for detected events.
 works. In Section 3, we formally define the local event detection problem. We introduce the detailed methodology and our system framework in Section 4. We analyze and discuss our experiment results in Section 5, and conclude our work in Section 6. There have been plenty of research regarding detecting events or news. They can be categorized according to several aspects, including types of events, data sources and methods [ 2 ].
 events from traditional media data. As a seminar work to this problem, [ 16 ] uses an infinite-state automaton to model the term frequency in documents, and considers the burst, for example, the significant change in term frequency, as potential events. [ 13 ][ 14 ] detect events by modeling feature burst with spectral analysis and Gaussian mixture respectively. [ 12 ] heuristically identifies bursty terms and then groups these terms to discover potential events. Since all of them use information which has been existing for long time as data sources, their systems can hardly produce events in real time.
 The introduction of social media platform brings new opportunities and chal-lenges to the problem of event detection, and plenty of methods have been pro-posed. Inspired by the idea of detecting bursty feature, EDCoW [ 33 ] uses wavelet theory to model the signal of words and capture their bursts to detect events. [ 28 ] monitors bursty topics instead of unigram or tweet-segments [ 21 ]. Simi-larly, [ 7 ] detects events by discovering trending topics. Modeling trending topics can produce real-time detection, however, it is not applicable to our scenario of detecting and locating events since trending topics are usually weak signals for small scale event, and it has large error to estimate the location of trending topics [ 1 ][ 15 ][ 17 ]. Other than detecting the trending topics, based on influential theories of emotions, [ 32 ] automatically assigns a single tweet with an emotional label which is neutral or comes from one of the 6 Ekman X  X  emotions. Then they monitor the sudden change of tweets X  emotions in countries as the signals to detect events. All of the above works consider burst of certain features as sig-nals of potential events. They model different bursty features including n-gram, terms, topics and emotions, and the common idea behind is absorbed into our framework.
 Some detection frameworks are specific-event driven, that is, assigning a spe-cific event type to each detection task. TEDAS [ 22 ] was proposed to detect crime and disaster related events from twitter stream. Earthquake center and typhoon trajectory have been successfully estimated in [ 30 ]. Besides disasters, [ 11 ][ 20 ]use twitter posts to detect local festivals by monitoring the movements of crowds. Twitterstand [ 31 ] classifies tweets as news and non-news to detect news events. Different from these methods, our proposed framework is not restricted to any event type.
 Considering the data source, most of the previous works collect data from Twitter posts [ 11 ][ 20 ][ 22 ]. We put two data collectors in Instagram and Twitter monitoring and collecting useful information from the live post streams from these two social media platforms. Our previous work [ 35 ] uses Instagram posts to detect events with high accuracy. Unlike them, in this paper we use the posts from both of the two popular OSNs together to detect events.
 After detecting events, retrieving relevant content to represent existing events is a challenging problem. Focusing on Twitter content, [ 3 ][ 5 ] extracts tweets and topics for known events. [ 25 ] generates a journalistic summary of a sport event using status updates from Twitter. Including Twitter, [ 4 ] retrieves social media content across YouTube and Flickr for existing events. In [ 9 ], photo tags are used to detect events and then retrieve photos based on tags to represent an event. It does not use the rich image content but heavily rely on user generated tags that are not always reliable [ 27 ]. Although the work in [ 27 ] combines photo content and tags to detect events, it needs to discover landmarks first and then detect events around the landmarks. To be different, our work does not rely on land-mark discovery, thus we can detect more general events. As to retrieving images, most existing methods rank images based on certain similarity measurements to a specific query, a keyword or image. In large scale applications, approximate nearest neighbor algorithms and hashing method [ 18 ][ 24 ] are widely explored. However, these methods are not directly applicable to our problem since we do not have a specific query. Instead, our query is an entire event that consists of noisy photos, text and geolocations. In our system, we observe that for a true event, the images that are relevant to it usually share common patterns. While other irrelevant images are considered as noise, which are usually independent and randomly distributed. Following [ 32 ][ 35 ], we define an event as a real world activity that occurs during time period T within a geographical area L . To detect such events in real time, we define a framework as follows. The framework takes the real-time streams of posts from Instagram and Twitter as the input. The system is expected to output detected events in sequence. For each detected event, we extract its related con-tent namely the set of related images, topics (a set of keywords), the estimated occurrence location, and the estimated occurrence time. In this section we introduce our architecture, each component and methods. The system framework is shown in Figure 1 . Given a fixed geographical region L from which we want to detect events in real time, first we distribute event sensors over the entire region. Each event sensor is designed to be independently responsible for discovering events in a single sub-region l . In other words, we divide the entire region, i.e. New York City in this paper, into k sub-regions, L = each sub-region l , we allocate an event sensor, which has three components, Event Signal Discovery, Event Signal Classification and Event Summarization. Although more advanced methods that divide an entire region to sub-regions according to topic distribution [ 1 ][ 17 ] or population density [ 20 ] might improve the overall performance, in this paper we do not focus on this problem, and we divide the entire New York City into N  X  M grids of equal size.
 covery component takes the input of Instagram and Twitter data streams in real time and outputs candidate event signals. The Event Signal Classification com-ponent takes candidate event signals as input, extracts various features for them, and finally outputs event signals which are classified as true events. The Event Summarization component selects the most relevant content, including photos and text to represent the event. Besides, it produces the estimated occurrence location and time of the event. 4.1 Event Signal Discovery The Event Signal Discovery component contains 3 sub-components, data stream collector, time series estimator and bursty detector. The motivation behind fol-lows the general idea of modeling bursts [ 16 ] of certain features as potential events. Unlike other papers which model the sudden change of emotions [ 32 ], the movements of crowds [ 20 ] or the trending topics/terms/n-grams [ 21 ][ 33 ][ 7 ], we adopt the method in [ 34 ][ 35 ] which considers the abnormal increase of social media posts as the potential signal of events. This is because we observe that the change in the number of posts is sensitive to event occurrence, especially to the occurrence of small-scale local events.
 The data stream collectors keep collecting posts from Twitter and Instagram in real time. We only collect posts containing geo-location information. In order to find bursty signals, an event sensor monitors the change in the number of posts in a sub-region l . A time series of the post number is constructed for l .We use t to denote the time, and v l ( t ) denotes the post number at l and within t . In practice, t stands for a time period and its window length in our experiments is 15 minutes.
 The time series estimator is implemented by Gaussian Process Regressor (GPR) [ 29 ]. We use GPR due to its great performance in modeling various time series data such as stock prices [ 29 ]. Due to limited space, the detail of GPR is available in our previous work [ 35 ].
 Once the GPR model is built on the historical data, it is able to predict the number of posts at l during t ,as X  v l ( t ) for any given t . When the data stream collector gathers the true number of posts in a sub-region l at t , we compare the actual number of posts, i.e. v l ( t ), with the predicted number of posts, i.e.  X  v If there is a large deviation between these two numbers, this signal is marked as a potential event signal. Following bursty detection, we are only interested in when the predicted number of posts is larger than the actual number of posts. Typically, we define an abnormality score as [ X  v l predictive standard deviation given by GPR. It indicates the confidence of the prediction and a smaller  X   X  ( t ) indicates stronger confidence. If the abnormality score in sub-region l during time t exceeds a given threshold, the Event Signal Discovery component outputs a candidate event e ( l, t ) that stands for the set of all the Instagram and Twitter posts that are posted during time t and within location l . 4.2 Event Signal Classification Once Event Signal Discovery component produces a candidate event signal e ( l, t ), the Event Signal Classification component first extracts features from e ( l, t )and classifies it as true or false by a supervised learning model. Since a candidate event signal (shortened as candidate event) e ( l, t ) is a set of Instagram and Twitter posts bounded by location l and time t , we can extract various types of features from them. Based on these features, the classifier determines whether e ( l, t ) represents a true event or not. Note that, even if there is an event at location l and time t , not all the posts in e ( l, t ) is related to that event. Thus we will choose relevant posts to represent the event which is discussed in Section 4.3 . At this step, we focus on extracting robust features from the Instagram and Twitter post streams.
 Feature Fusion. Before design specific features for candidate events, we first model the fusion of Instagram and Twitter posts. We previously assume when the number of total posts (including Instagram and Twitter) bounded by location l and time t suddenly increases, some event e ( l, t ) may happen. However, we do not know which data source, Instagram or Twitter, records this event, or both. This is caused by the heterogeneity of Instagram and Twitter posts and users. Although they are both popular social media, their users have different habits and interests. Instagram is more about recording personal life and daily activity while Twitter is considered as an influential news media [ 19 ]. Thus, it is expected that some events are recorded by only one data source while some are recorded by both. We can either extract features from Instagram posts or Twitter posts only, or from both of them. In this paper, we consider two methods to fuse two data sources for feature extraction and classification.
 level, i.e. before feature extraction. In this way, we need to consider a Twitter post and a Instagram post as homogeneous. For each event signal e ( l, t ), we extract its features vector x e from all the posts during time period t within location l . This method mitigates the sparsity problem of geo-tagged posts, and it is expected to benefit the classification of small-scale events with a few of posts in total.
 level, i.e. after separate feature extraction. We extract feature vector x Instagram posts and extract feature vector x T e from Twitter posts respectively, and then concatenate them to form the final feature vector x this method, the size of feature vector x e is nearly doubled compared to the first method. The benefit of this method is that, we can extract different features from Twitter and Instagram, and further incorporate other inhomogeneous data sources.
 Feature Extraction. To represent an event signal e ( l, t ), we extract four types of features from all the posts bounded by l and t , namely topic features, emo-tional features, spatial features and social features. Formally, we use P { p , ..., p n } to denote the set of posts associated with the event e ( l, t )and n = |
P e | . Note that, here we do not extract feature from a single post, instead, we extract features from the set of posts P e associated to event signal e ( l, t ). First we extract five topic features from posts X  text, i.e. photo captions and/or tweets. We first build a background topic distribution  X  B word unigram language model to represent the topic distribution of the back-ground posts, i.e. all the posts during last 24 hours within l . We also build the event topic distribution  X  E for all the posts in P e in the same way. We calculate (1) the total number of words that are in  X  E but missing in  X  which has never appeared before, may indicate something new. We calculate (2) the average KL-divergence [ KL (  X  B ||  X  E )+ KL (  X  the topic distribution changes when there are true events. We also compute (3) average number of hashtags in p i , (4) the average text length of p average frequency of the 3 most frequent words in P e .
 The second type is emotional features. Inspired by [ 32 ] in which the authors experimentally prove when there are large event occurring, user emotions on Twitter change. In order to capture emotional changes, we compute the num-ber of emotion-related punctuations and words from P e : (1-2) the number of exclamations and question marks respectively and (3-8) the total number of words from P e categorized to each of the six Ekman X  X  emotions [ 32 ] respectively. Similar to topic features, we construct a background emotion-related word and punctuation count vector E B , and take the deviation between E features as the (9-16) features, indicating the change of emotion with location l and time t .
 The third type is geolocation features. They are (1) mean and (2) standard deviation of pairwise post geo-distance, i.e. dist ( p i ,p entropy [ 35 ] of the spatial distribution of all posts in P these features is that we observe that when there is an event, the event-related posts tend to form a cluster. Similarly, we also compute these features from the background posts, and take the corresponding difference from (1-3) features as (4-6) features.
 The fourth class includes a social feature. We compute the average number of mentioned users, i.e. @Alex of all posts in P e . We finally extract 28 features of four categories in total. We also normalize the topic and emotional features by text length.
 4.3 Event Summarization In this section, we introduce our methods to summarize a detected event. A candidate event signal that consists of a number of Instagram and Twitter posts bounded by time period t and location l is classified as a true event or not. Provided that the classifier in Section 4.2 judges an event signal is a true event, we still do not know what the event is, a concert or a car crash, because the event classifier in this framework is designed to be general, i.e. independent of event type or scale.
 location and occurrence time. Extracting topics from user generated posts is well studied [ 3 ][ 4 ][ 5 ][ 8 ]. Thus it is not our focus in this paper, and we use existing methods to select keywords from tweets and photo captions as the topics of an event. Besides, it is straightforward to estimate the occurrence location and time of an event in our framework. Due to their simplicity, the methods are discussed together with performance in the experiments, Section 5.4 . Here we only cover the method we proposed to retrieve relevant photos for a detected event. Since tweets are seldom associated with photos, we only retrieve photos from Instagram posts to represent an event.
 time period t and Location l are related to that event. For example, an Instagram photo was uploaded near a fire accident event, but the image content is about beers. Besides, we observe that users frequently upload self-portraits or food in events, which are not helpful for other users to understand the event. Moreover, some photos involve user privacy issue as shown in Figure 2 . Therefore, we need to select relevant and representative photos to visually summarize an event. For simplicity, we name them event-related photos.
 event-related photos usually share similar image content. For example, photos related to a fire accident usually record smoke, fire or the police. We also observe similarity of text associated to event-related photos. For example, users are likely to use  X  X ire X  or  X  X moke X  to describe the photo related to a fire. Besides image content and text, most events occur in a fixed place, such as NBA matches, thus event-related photos tend to geographically form a cluster in the event center. Different from event-related photos, we observe that, for most noisy photos, their image content and text share very limited similarity to each other, and they are not necessarily close to the geographic center. However, we also observe outliers. For example, a user uploads a photo of her food during a NBA game and write a caption  X  X  wonderful NBA game! # Knicks! X  to the photo. In this example, when we compute the relevance score of the photo by only considering its geolocation and/or text, we find many popular text algorithms consider this photo highly relevant to the event. But when we compute its relevance score based on image content, the relevance diminishes.
 Inspired by the above observations, for each photo x in an event e , we indi-vidually compute the image content relevance score (to the event e ) given the image content of x only, as s c ( x, e ), the text relevance score given the text of x only, as s t ( x, e ), and the geolocation relevance score given the geolocation of x only, as s l ( x, e ). Note that, here P e denotes the set of photos associated to event e , and thus x  X  P e . After that, we linearly combine the three individual relevance scores into the finalized relevance score s ( x, e )inEq( 1 ) that denotes how the photo x is overall relevant to the event e . a , a t and a l are the weights for the three independent relevance scores. Conventionally, we specify a c + a t + a l =1and a t ,a c marginal effects of individual relevance score contributed to the overall relevance score. Intuitively, the larger a weight is, the larger positive impact that the corresponding single relevance score has on selecting event-related photos. Since we model retrieving event-related photos as an unsupervised ranking problem, the choices of a c , a t and a l are discussed through experiments. We introduce the models to compute the three individual relevance scores as follows.
 Image Content Relevance Model. To compute the image relevance score function s c ( x, e ), we use color histogram and GIST features [ 26 ] as image descrip-tor. These two image features are known for effectively describing discriminative scene characteristics. Our image relevance ranking method is adapted from an unsupervised image outlier removal method [ 23 ].
 For a detected event e , its corresponding posts set is denoted as P { x x i  X  R d ,i =1 , 2 , ..., n } . Since each post is always associated with an image, here we use the same notation for a post ( x ) and its image ( x in vector space). For each image x i , we learn a scoring function s ( x i ) to manifest its relevance to the event: Note that, the value of s ( x i ) is exactly the image relevance score s Eq ( 1 ). n  X  is the number of posts which is considered as irrelevant to the events, L is the graph Laplacian matrix, computed from the k nearest neighbor graph. We construct the neighborhood graph G by defining the affinity matrix W as: of x i ,and  X  is the bandwidth parameter. L in Eq ( 2 ) is the graph Laplacian matrix of G , computed as L = D  X  W , where D is a diagonal matrix with diagonal elements defined as D ii = n j =1 W ij .  X  and  X  are two model parameters balancing the regularization of graph Laplacian term and the effect of pushing the average positive example away from the margin.
 image is event-related or not, therefore we are essentially solving an unsuper-vised learning problem: y i is unknown in our optimization problem. As suggested by Eq ( 2 ), we treat y i as a variable which is softly labeled as t mization. Following the experiment results in [ 23 ], we dynamically set ( t by alternating optimization: iterating between fixing y to minimize s and fixing s to minimize y , until convergence. The first subproblem, fixing y to minimize s is achieved by solving a constrained eigenvalue problem with a closed form solution. The other subproblem, fixing s to minimize y , is achieved via sorting and sweeping cut to find an optimal threshold. Throughout our experiment, the similarity between any two posts is measured in Gaussian kernel space. Finally, we use the score s ( x i ) as the image content relevance score for images x s ( x, e ).
 Text and Relevance Model. We directly use the method in [ 3 ][ 5 ] to compute the relevance score of a photo X  X  text to the event. For each photo X  X  text, we represent it by a character n -gram language model where each photo X  X  text is converted to a large and sparse vector. Then we compute the textual centroid c t of these photos as c t = 1 n vector space) of the event. According to [ 3 ][ 5 ], the text relevance of a photo x to the event e could be computed by the closeness of x to the centroid c we compute s t ( x ,e ) as the cosine similarity between x and c Geolocation Relevance Model. Each photo is associated with a coordinate ( u, v ) which denotes its latitude and longitude respectively. Similarly, we com-pute the geographical centroid c l of the event as ( 1 n n u i and v i respectively denote the latitude and longitude of the i -th photo of the event. Thus, the geolocation relevance score s l ( x, e ) can be computed by the earth surface distance between x and c l .
 Interpretations and Advantages. In the above method, we extract image, text and geolocation features from a photo and the event to compute the three relevance scores separately, and finally linearly combine them into the overall rel-evance score. An alternative method is not to compute the individual relevance scores separately. Instead, it extracts the same image, text and geolocation fea-tures but concatenates all the three feature vectors into a longer feature vector, and then apply a unified model to assign relevance score to the photo given its event. However, such a unified model has problems caused by the heterogeneous characteristics of image, text and geolocation information. First, the dimensions of the three feature vectors are largely different. An efficient text representation is n -gram model which transfers a piece of text to a large and sparse feature vec-tor. However, the geolocation information is efficiently represented as a feature vector in two dimensions only. Thus, if we just simply concatenate them with-out robust feature selection, the geolocation information is easily overwhelmed in such feature space. Second, the hypotheses of relevance (or similarity or close-ness) are semantically different in the three aspects. In modeling the relevance of image content, many previous researches find the similarity between photos defined in Gaussian kernel space is proper. While in modeling geolocation close-ness, the earth surface distance is naturally the best. Thus, it is not ideal to model all the three types of information in a unified distance space. In this section, we first introduce the dataset and parameter setting. Then we evaluate event detection accuracy by Instagram and Twitter post streams. We also evaluate the event-related photo retrieval. Finally, we sample detected true events to evaluate the temporal latency and spatial accuracy by case studies. 5.1 Dataset and Setting We use Twitter APIs and Instagram APIs to crawl geo-tagged posts in New York City. Each crawled Instagram post (shortened as photo) is associated with an image, a text, a pair of coordinates, created time and other information. Each crawled tweet is associated with a non-empty text, a pair of coordinates, created time and other information. From 2012-12 to 2014-06, we collected 12 , 453 , 448 geo-tagged tweets and 31 , 188 , 195 geo-tagged photos.
 Event Classification Annotation. We use crowdsourcing to accomplish this labeling task: given an event signal e =( l e ,t e ) and its associated posts, it is labeled based on whether there is a true event during time period t location l e . We first used Amazon Mechanical Turk to label the discovered event signals and then invited three journalists from a local newsroom in New York city to calibrate the labeling to guarantee our dataset is as correct as possible. We sampled 1945 events signals with associated posts to label. As a result, we get 1084 events signals with valid and confident labeling. Among them, 477 events signals are labeled as true events while the other 607 are labeled as false events (noise).
 ImageRelevanceAnnotation. To evaluate our proposed relevant photo retriev-ing method, we randomly select 153 true events which contain at least 8 photos For each event, we label all its photos (if the number of photos in an event exceeds 35, we sample 35 photos). We tried to use a third-party crowdsourcing to label, but find out their correctness is largely below our expectation. Therefore we trained an inde-pendent user, and ask the user to label whether a photo is relevant to a given event based on these criteria, 1 for relevant, 0.5 for partially relevant and 0 for irrelevant. For example, we consider self-portraits and food as irrelevant. We also give the user the location and time information and topics of the event to facilitate labeling. On average, an event has 24 . 7 photos, and 39 . 4% of its photos are labeled as relevant, 5 . 8% are partially relevant and the rest, i.e. 54 . 8% are irrelevant. Parameter Setting. To monitor the entire New York City, we divide NYC into 25  X  25 sub-regions (0.45 square kilometers for each geo-region). We also turned the window size t in Gaussian Process Regressor to be 15 minutes. A reasonably long time interval will lead to large detecting latency while a tiny interval will cause the decrease of the detection accuracy since there may be very few posts during a tiny time interval. The experiments on the choice of these parameters are in our previous work [ 35 ]. 5.2 Detection Accuracy In this section, we evaluate the performance of Event Signal Classification. Before extract text-related features, we preprocess posts X  text by NLTK [ 6 ]. We remove stopwords, non-English characters and urls. We also separate capitalized and concatenated words, such as from  X  X LoveThisGame X  to  X  X  X ,  X  X ove X ,  X  X his X  and  X  X ame X . Then we use 10-fold cross-validation to evaluate the effectiveness of feature extraction and fusion with standard classifiers. To avoid the variance caused by different classifiers, we run all the experiments with three popular and representative supervised classifiers, Support Vector Machine (SVM), Logistic Regression (LR) and Random Forest (RF).
 different settings in Table 1 . In the setting of the Instagram-only method, we discard all Twitter posts. We only extract features from Instagram posts and train all the three classifiers with Instagram data. Then we discard all Instagram posts but extract features and train the classifiers from Twitter data only, as the Twitter-only method. From Table 1 , we can find that if we just use a single data source to classify the candidate events, Instagram data outperforms Twitter data. Furthermore, we evaluate the event classifiers on integrated data with two fusion methods. We find that the classifiers trained with the two fusion methods, no matter in data-level or feature-level, both outperform the classifiers trained on a single data source. We investigate results in detail and conclude this improvement is caused by the following reasons. First, although we have plenty of geo-tagged posts, in certain sub-regions, we still encounter severe data sparsity problem. Either fusion method brings us more valuable data to mitigate this problem. Second, small-scale events whose weak signals are easily overwhelmed in noisy content. But when we find the weak signals in both data sources, our system are more confident to detect them. Due to the limited length, the evaluation of feature importance is not included. In short, by investigating the weights in Logistic Regression, topic and spatial features are far more discriminative than the emotional and social features. 5.3 Relevant Photo Retrieval To evaluate the efficiency of the relevant photo retreiving method in Eq ( 1 ), we use Normalized Discounted Cumulative Gain (NDCG@k) in Eq ( 4 ) as the metric. For each event, we rank its photos decreasingly by overall relevance scores in Eq ( 1 ), and then compute NDCG@k for the ranking.
 z n is a normalization factor. r i is the actual relevance score of the ranked i -th photo, and it is given by our labeler, 1, 0.5 or 0. k is a free parameter to control the number of ranked photos to compute NDCG@k. To reduce the vari-ance caused by k , we compute the NDCG@k for k from 1 to 10. We compare the combined relevance model in Eq ( 1 ) with three baselines, image content rel-evance model, text relevance model and geolocation relevance model introduced in Section 4.3 . As shown in Table 2 , we have the following observations. First, among all the three baselines, the relevance model based on text information works the best. Second, the combination of all the three single relevance models constantly performance better than any of the three single relevance models. Third, by grid search, we empirically find that around ( a the combined relevance score reaches the maximal on our labeled dataset. This implies the importance of each factor X  X  contribution to the overall relevance. 5.4 Spatial and Temporal Deviation In this paper we focus on local event detection in real time, thus we also evaluate the detecting deviation of spatial and temporal factors of events. The detecting deviation of the spatial factor of an event is the geographical distance between the coordinates where the event actually occurred and the coordinates our framework estimated for the event. Similarly, the detecting deviation of the temporal factor of an event is the time period between when the event actually occurred and the time our framework estimated for the event. However, since it is expensive to manually collect accurate spatial and temporal information of an event, we choose 20 events to evaluate their spatial deviation, and 5 events to evaluate their temporal deviation as case study.
 dynamically in a wide region, e.g. New Year parade in China town and marathon, thus we are unable to track all the areas associated with that event. Therefore we only consider events that take place in a fixed area, such as fire accident and basketball games. For each event, we find the name of the associated place, and then take the coordinates of the associated place from Google Maps as the actual event coordinates, in a pair of longitude and latitude. On the other hand, our system calculates the geographic center of of all Instagram and Twitter posts related to that event, as the estimated coordinates of the event. More specifically, the estimated longitude is the arithmetic mean of the longitudes of all related posts, the same for estimated latitude. Then a spatial deviation, i.e. spherical distance, is calculated between the estimated coordinates and the actual coordinates of an event. On average the estimated coordinates of these 20 events are 104 . 46 meters far from their actual coordinates with a standard deviation of 37 . 75. Table 3 shows the results for 5 example events. acquire the exact knowledge of when events occurred, we manually check with websites, the police or news reports for their actual occurrence time. Meanwhile, we take the time of the earliest post among all posts related to that event as the estimated time. We report the time interval between actual time and estimated time of an event as its temporal deviation. Table 4 shows the results of 5 detected events as examples. We can find that  X  X BA Knick Game X  and  X  X oxing: Cotto vs Trout X , which are two planned events, are detected prior to the actual event time. This is because as more people arrived to the stadium in advance and started to post about the coming events, our system detected the local unusual increasing trends before the game actually started. For  X  X ire in West Village X ,  X  X ire in 34 St X , which are two emergencies, our event responded 14 minutes and 9 minutes after the events happened respectively. Notice that for the  X  X ar Crash X  event, our system responded 3 hours later. This failure is probably because it happened at 5:45AM, when most of local residents were still sleeping. In this case, few related posts can be detected at the early stage of this event. In this paper, we proposed a general framework for real-time event detection from Instagram and Twitter post streams. Our proposed system uses three compo-nents to discover and classify the events. Then we can extract high-level knowl-edge from detected events. Extensive experiments on NYC social media data show the promising results. Based on our general framework, a lot of future work can be investigated to potentially boost the performance. For example, we plan to further study how to adaptivity divide sub-regions in the city based on their topic distributions [ 10 ]. Also, more sophisticated feature fusion approaches for event knowledge extraction can be investigated.

