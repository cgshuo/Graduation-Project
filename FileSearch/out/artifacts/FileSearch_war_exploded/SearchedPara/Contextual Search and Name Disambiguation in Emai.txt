 Similaritymeasuresfortexthavehistoricallybeenanimpor-tanttoolforsolvinginformationretrievalproblems. Inmany interesting settings, however, documents are often closely connected to other documents, as well as other non-textual objects: forinstance,emailmessagesareconnectedtoother messages via header information. In this paper we consider extendedsimilaritymetricsfordocumentsandotherobjects embedded in graphs, facilitated via a lazy graph walk. We provide a detailed instantiation of this framework for email data, where content, social networks and a timeline are in-tegrated in a structural graph. The suggested framework isevaluatedfortwoemail-relatedproblems: disambiguating names in email documents, and threading. We show that reranking schemes based on the graph-walk similarity mea-sures often outperform baseline methods, and that further improvements can be obtained by use of appropriate learn-ing methods.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models, Search process Algorithms, Experimentation graph-based retrieval, email, name disambiguation, thread-ing
Many tasks in information retrieval can be performed by clever application of textual similarity metrics: in addition to the canonical IR problem of ad hoc retrieval, which is often formulated as the task of finding documents  X  X imilar to X  a query, textual similarity plays a prominent role in the Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00. literature for diverse tasks such as text categorization [32], data integration [6], summarization [28] and document seg-mentation [16].

In modern IR settings, however, documents are usually not isolated objects: instead, they are frequently connected to other objects, via hyperlinks or meta-data. (An email message, for instance, is connected via header information to other emails and also to the recipient X  X  social network.) Thus it is important to understand how text-based doc-ument similarity measures can be extended to documents embedded in complex structural settings.

Oursimilaritymetricisbasedonalazygraphwalk,andis closely related to the well-known PageRank algorithm [25]. PageRank and its variants (e.g., [14]) are based on a graph walk of infinite length with random resets. In a lazy graph walk, thereisafixedprobabilityofhaltingthewalkateach step. Inpreviouswork[30],lazywalksovergraphswereused for estimating word dependency distributions: in this case, the graph was one constructed especially for this task, and the edges in the graph represented different flavors of word-to-wordsimilarity. Otherrecentpapershavealsousedwalks overgraphsforqueryexpansion[31, 11]. Inthesetasks, the walk propagates similarity to a start node through edges in the graph X  X ncidentally accumulating evidence of similarity over multiple connecting paths.

Incontrasttothispreviouswork,weconsiderschemesfor propogatingsimilarityacrossagraphthatnaturallymodels a structured dataset like an email corpus: entities corre-spond to objects including email addresses and dates, (as well as the usual types of documents and terms), and edges correspond to relations like sent-by . We view the similarity metricasa tool for performing search acrossthisstructured dataset,inwhichrelatedentitiesthatarenotdirectlysimilar to a query can be reached via a multi-step graph walk.
In this paper, we formulate and evaluate this extended similarity metric. The principal problem we consider is disambiguating personal names in email , which we formu-late as the task of retrieving the person most related to a particular name mention. We show that for this task, the graph-based approach improves substantially over plausible baselines. After retrieval, learning can be used to adjust the ranking of retrieved names based on the edges in the paths traversed to find these names, which leads to an ad-ditional performance improvement. As a demonstration of generality,wealsoshowperformanceimprovementsonasec-ond email-related task X  X ecovering messages from the same emailthread. Namedisambiguationandemailthreadingare particular applications of the suggested general framework, which is also applicable to any real-world setting in which structural data is available as well as text.

This paper proceeds as follows. Sections 2 and 3 formal-ize the general framework and its instantiation for email. Section 4 gives a short summary of the learning approach. Section 5 includes experimental evaluation, describing the corpora and results for the person name disambiguation as well as threading tasks. The paper concludes with a review of related work, summary and future directions.
Agraph G consists of a set of nodes, and a set of labeled directed edges. Nodes will be denoted by letters such as x y ,or z , and we will denote an edge from x to y with label as x  X  X  X  y . Every node x has a type, denoted T ( x ), and we will assume that there is a fixed set of possible types. We will assume for convenience that there are no edges from a node to itself (this assumption can be easily relaxed). We will use these graphs to represent real-world data. Each node represents some real-world entity, and each edge x  X  X  X  y asserts that some binary relation ( x, y )holds. The entity types used here to represent an email corpus are shown in the leftmost column of Table 1. They in-clude the traditional types in information retrieval sys-tems, namely file and term . In addition, however, they include the types person , email-address and date .These entities are constructed from a collection of email mes-sagesintheobviousway X  X orexample,arecipientof X  X inat Minkov &lt; einat@cs.cmu.edu &gt;  X  indicates the existence of a person node  X  X inat Minkov X  and an email-address node  X  X inat@cs.cmu.edu X . (We assume here that person names are unique identifiers.)
The graph edges are directed. We will assume that edge labels determine the source and target node types: i.e., if x  X  X  X  z and w  X  X  X  y then T ( w )= T ( x )and T ( y )= T ( z However,multiplerelationscanholdbetweenanyparticular pair of nodes types: for instance, it could be that x  X  X  X  y or x  X  X  X  y ,where = . (For instance, an email message x could be sent-from y ,or sent-to y .) Note also that edges need not denote functional relations: for a given x and , there may be many distinct nodes y such that x  X  X  X  y .For instance, for a file x , there are many distinct terms y such that x has-term  X  X  X  y holds.

In representing email, we also create an inverse label  X  1 for each edge label (relation) . Note that this means that the graph will definitely be cyclic. Table 1 gives the full set of relations used in our email represention scheme.
Similarity between two nodes is defined by a lazy walk process, and a walk on the graph is controlled by a small set of parameters  X . To walk away from a node x , one first picks an edge label ; then, given , one picks a node y such that x  X  X  X  y . Weassumethattheprobabilityofpickingthe label depends only on the type T ( x ) of the node x , i.e., that the outgoing probability from node x of following an edge type is: Table 1: Graph structure: Node and relation types Let S T i be the set of possible labels for an edge leaving a nodeoftype T i . Werequirethattheweightsoveralloutgo-ingedgetypesgiventhesourcenodetypeformaprobability distribution, i.e., that X
In this paper, we will assume that once is picked, y is chosen uniformly from the set of all y such that x  X  X  X  y . That is, the weight of an edge of type l connecting source node x to node y is: 1 This assumption could easily be generalized, however: for instance, for the type T ( x )= file and = has-term , weights forterms y suchthat x  X  X  X  y mightbedistributedaccording to an appropriate language model [12].
Conceptually,theedgeweightsabovedefinetheprobabil-ity of moving from a node x to some other node y . At each stepinalazygraphwalk,thereisalsosomeprobability  X  of staying at x . Putting these together, and denoting by M xy the probability of being at node y at time t +1giventhat one is at x at time t in the walk, we define M If we associate nodes with integers, and make M a matrix indexed by nodes, then a walk of k steps can then be de-fined by matrix multiplication: specifically, if V 0 is some initial probability distribution over nodes, then the distri-bution after a k -step walk is proportional to V k = V 0 M Largervaluesof  X  increasetheweightgiventoshorterpaths between x and y . Intheexperimentsreportedhere,wecon-sider small values of k , and this computation is carried out
Ifnosuch y exists,thentheoutgoingprobabilitymass  X  ,T i associated with node x is absorbed into a  X  X ull X  state. directly using sparse-matrix multiplication methods. 2 If gives probability 1 to some node x 0 and probability 0 to all other nodes, then the value given to y in V k can be inter-preted as a similarity measure between x and y .
Inourframework,a query isaninitialdistribution V q over nodes, plus a desired output type T out , and the answer is a list of nodes y of type T out , ranked by their score in the distribution V k . For instance, for an ordinary ad hoc doc-ument retrieval query (like  X  X conomic impact of recycling tires X ) would be an appropriate distribution V q over query terms, with T out = file .Replacing T out with person would find the person most related to the query X  X .g., an email contact heavily associated with the retread economics. Re-placing V q with a point distribution over a particular docu-mentwouldfindthepeoplemostcloselyassociatedwiththe given document.
Itisinterestingtoviewthisframeworkincomparisontoa moretraditionalIRsetting,whichcanbeviewedasaspecial case. Supposewerestrictourselvestoonlytwotypes,terms and files, and allow only in-file edges. Now consider an initial query distribution V q which is uniform over the two terms X  X heaardvark X . Aone-stepmatrixmultiplicationwill result in a distribution V 1 , which includes file nodes. The common term  X  X he X  will spread its probability mass into smallfractionsovermanyfilenodes,whiletheunusualterm  X  X ardvark X  X illspreaditsweightoveronlyafewfiles: hence theeffectwillbesimilartouseofanIDFweightingscheme.
Assuggestedbythecommentsabove,thedescribedgraph framework could be used for many types of tasks, and it is unlikely that a single set of parameter values  X  will be best for all tasks. It is thus important to consider the problem of learning how to better rank graph nodes.

Previous researchers have described schemes for adjust-ing the parameters  X  using gradient descent-like methods [14, 24]. In this paper, we suggest an alternative approach oflearningtore-orderaninitialranking. Thisrerankingap-proachhasbeenusedinthepastformeta-search[8]andalso several natural-language related tasks [10, 9]. The advan-tage of reranking over parameter tuning is that the learned classifier can take advantage of  X  X lobal X  features that are not easily used in a walk.

Note however that node reranking, while can be used as analternativetoweightmanipulation,itisbetterviewedas a complementary approach, as the techniques can be natu-rally combined by first tuning the parameters  X  ,andthen reranking the result using a classifier which exploits non-local features. This hybrid approach has been used success-fully in the past on tasks like parsing [10].

We here give a short overview of the reranking approach, whichisdescribedinmoredetailelsewhere[10]. Thererank-ing algorithm is provided with a training set containing n examples. Example i (for 1  X  i  X  n ) includes a ranked list of l i nodes. Let w ij be the j th node for example i ,andlet p ( w ij )betheprobabilityassignedto w ij bythegraphwalk.
We have also explored an alternative approach based on sampling; this method scales better but introduces some additionalvarianceintotheprocedure, whichisundesirable for experimentation.

A candidate node w ij is represented through m features, which are computed by m feature functions f 1 ,...,f m .We will require that the features be binary; this restriction al-lowsaclosedformparameterupdate[10]. The ranking func-tion for node x is defined as: where L ( x )=log( p ( x )) and  X   X  is a vector of real-valued parameters. Given a new test example, the output of the model is the given node list re-ranked by F ( x,  X   X  ).
To learn the parameter weights  X   X  , we use a boosting method[10], whichminimizes thefollowinglossfunctionon the training data: where x i, 1 is, without loss of generality, the correct tar-get node. 3 The weights for the function are learned with a boosting-like method, where in each iteration the feature f k that has the most impact on the loss function is chosen, and  X  k ismodified. Closedformformulasexist forcalculat-ing the optimal additive parameter updates [10, 29].
There are currently no available annotated email corpora forevaluationofemail-relatedqueries. Inthispaperweeval-uatethesystemontwotasks: personnamedisambiguation, andemailthreading. Thekeypropertyofthesetasksisthat a non-subjective correct answer set can be constructed per query. Each task was evaluated on three corpora.
Eachcorpusisofmoderatesize X  X epresentative,wehope, of an ordinary user X  X  collection of saved mail.
The Cspace corpuscontainsemailmessagescollectedfrom amanagementcourseconductedatCarnegieMellonUniver-sity in 1997 [23]. In this course, MBA students, organized inteamsoffourtosixmembers,ransimulatedcompaniesin differentmarketscenarios. Thecorpusweusedhereincludes the emails of all teams over a period of four days, plus all messages that were replied to in the four-day period. This subcorpusisconvenientforthetaskofnamedisambiguation for several reasons, which are outlined below.

The Enron corpus is a collection of mail from the Enron corpus that has been made available to the research com-munity [19]. This corpus can be easily segmented by user: here, we used the saved email of four different users. 4 To eliminate spam and news postings we removed email files sent from email addresses with suffix  X .com X  that are not Enron X  X ; widely distributed email files sent from addresses suchas X  X nron.announcement X  X r X  X nron.chairman X  X t X  X n-ron.com X ; and emails sent to  X  X ll.employees@enron.com X  etc. Text from forwarded messages, or replied-to messages
If there are k&gt; 1 target nodes in a ranking, we split the ranking into k examples. Note also that it is possible to incorporate weights into this formula, e.g., to assign higher weighttonodesearlierintheranking;howeverweassignall nodes equal importance.
Specifially, we used the  X  X ll documents X  folder, including both incoming and outgoing files. were also removed from the corpus. In deriving terms for thegraph,termswerePorter-stemmedandstopwordswere removed.

Table2(leftmostcolumns)givesthesizeofeachprocessed corpus,andthenumberofnodesinthegraphrepresentation of it. The processed Enron-derived corpora are available from the first author X  X  home page. 5
Consider an email message containing a common name like  X  X ndrew X . Ideally an intelligent mailer would, like the user, understand which person  X  X ndrew X  refers to, and would rapidly perform tasks like retrieving Andrew X  X  pre-ferred email address or home page. Resolving the referent of a person name is also an important complement to the ability to perform named entity extraction for tasks like so-cialnetworkanalysisorstudiesofsocialinteractioninemail.
However, while the referent of the name is usually unam-biguous to the recipient of the email, it can be non-trivial for an automated system to find out which  X  X ndrew X  is in-dicated. Automatically determining that  X  X ndrew X  refers to  X  X ndrew Y. Ng X  and not  X  X ndrew McCallum X  (for in-stance) is especially difficult when an informal nickname is used, or when the mentioned person does not appear in the email header. As noted above, we model this problem as a search task: based on a name-mention in an email message m , we formulate query distribution V q , and then retrieve a ranked list of person nodes.
Unfortunately, building a corpus for evaluating this task isnon-trivial, because(iftrivialcasesareeliminated)deter-mining a name X  X  referent is often non-trivial for a human other than the intended recipient. We evaluated this task using three labeled datasets, as detailed in Table 2.
TheCspacecorpushasbeenmanuallyannotatedwithper-sonal names [23]. Additionally, with the corpus, there is a greatdealofinformationavailableaboutthecompositionof the individual teams, the way the teams interact, and the full names of the team members. Using this extra informa-tion it is possible to manually resolve name mentions. We collected 106 cases in which single-token names were men-tioned in the the body of a message but did not match any name from the header. Instances for which there was not sufficient information to determine a unique person entity were excluded from the example set. In addition to names that refer to people that are simply not in the header, the names in this corpus include people that are in the email header, but cannot be matched because they are referred
Unfortunately, due to privacy issues, the CSpace corpus can not be distributed in this way. to using: initials  X  X his is commonly done in the sign-off to an email; nicknames , including common nicknames (e.g.,  X  X ave X  X or X  X avid X ),andunusualnicknames(e.g., X  X ai X  X or  X  X eiko X );orAmericannamesthatwereadoptedbypersons with foreign-language names (e.g.,  X  X enny X  for  X  X ing X ). For Enron, two datasets were generated automatically. We collected name mentions which correspond uniquely to namesthatareintheemail X  X c X  X eaderline;then,tosimu-late a non-trivial matching task, we eliminate the collected person name from the email header. We also used a small dictionary of 16 common American nicknames to identify nicknames that mapped uniquely to full person names on the  X  X c X  header line.

Table 3 gives the distribution of name mention types for all datasets. For each dataset, some examples were picked randomlyandsetasideforlearningandevaluationpurposes (see Table 2).
Table 3: Person Name Disambiguation Datasets
All of the methods applied generate a ranked list of per-son nodes, where there is exactly one correct answer per example. 6 Figure 1 gives results 7 for two of the datasets as a function of recall at rank k , up to rank 10. Table 4 showsthemeanaverageprecision(MAP)oftherankedlists as well as accuracy , which we define as the percentage of correct answers at rank 1 (i.e., precision at rank 1).
Toourknowledge,therearenopreviouslyreportedexper-imentsforthistaskonemaildata. Asabaseline,weapplya reasonably sophisticated string matching method [7]. Each name mention in question is matched against all of the per-son names in the corpus. The similarity score between the name term and a person name is calculated as the maximal Jaro similarity score [7] between the term and any single token of the personal name (ranging between 0 to 1). In addition, we incorporate a nickname dictionary, 8 such that if the name term is a known nickname of the person name, the similarity score of that pair is set to 1.

TheresultsareshowninFigure1andTable4. Ascanbe seen, the baseline approach is substantially less effective for the more informal Cspace dataset. Recall that the Cspace corpus includes many cases such as initials, and also nick-namesthathavenoliteralresemblancetotheperson X  X name (section5.2.2),whicharenothandledwellbythestringsim-ilarity approach. For the Enron datasets, the baseline ap-proachperfomsgenerallybetter(Table4). Inallthecorpora there are many ambiguous instances, e.g., common names like  X  X ave X  or  X  X ndy X  that match many people with equal strength.
If a ranking contains a block of items with the same score, anode X  X rankiscountedastheaveragerankofthe X  X lock X .
Results refer to test examples only.
The same dictionary that was used for dataset generation.
We perform two variants of graph walk, corresponding to different methods of forming the query distribution V q Unless otherwise stated, we will use a uniform weighting of labels X  X .e.,  X  ,T =1 /S T ;  X  =1 / 2; and a walk of length 2.
In the first variant, we concentrate all the probability in the query distribution on the name term. The column la-beled term gives the results of the graph walk from this probability vector. Intuitively, using this variant, the name term propagates its weight to the files in which it appears. Then, weight is propagated to person nodes which co-occur frequently with these files. Note that in our graph scheme there is a direct path between terms to person names, so that person nodes may recieve weight vis this path as well.
As can be seen in the results, this leads to very effective performance: e.g., it leads to 61.3% vs. 41.3% accuracy for the baseline approach on the CSpace dataset. However, it does not handle ambiguous terms as well as one would like, asthequerydoesnotincludeanyinformationofthe context inwhichthenameoccurred: thetop-rankedanswerforam-biguous name terms (e.g.,  X  X ave X ) will always be the same person. To solve this problem, we also used a file+term walk, in which the query V q gives equal weight to the name term node and the file in which it appears.

We found that adding the file node to V q provides useful context for ambiguous instances X  X .g., the correct  X  X avid X  would in general be ranked higher than other persons with this same name. On the other hand, though, adding the file node reduces the the contribution of the term node. Al-thoughtheMAPandaccuracyaredecreased,file+termhas better performance than term at higher recall levels, as can be seen in Figure 1.
We now examine reranking as a technique for improving theresults. Weformedthefollowingtypesoffeatures f fora node x . Edge unigram features indicate, for each edge label ,whether was used in reaching x from V q . Edge bigram features indicate, foreachpairofedgelabels 1 , 2 ,whether and 2 were used (in that order) in reaching x from V q . Top edge bigram features are similar but indicate if 1 were used in one of the two highest-scoring paths between V q and x (where the  X  X core X  of a path is the product of Pr( y  X  X  X  z ) for all edges in the path).

We believe that these features could all be computed us-ingdynamicprogrammingmethods. Currently,however,we compute features by using a method we call path unfolding , which is similar to the back-propagation through time algo-rithm [15, 14] used in training recurrent neural networks. Graph unfolding is based on a backward breadth-first visit ofthegraph,startingatthetargetnodeattimestep k ,and expanding the unfolded paths by one layer per each time step. This procedure is more expensive, but offers more flexibilityinchoosingalternativefeatures,andwasusefulin determining an optimal feature set.

Inaddition,weusedforthistasksomeadditionalproblem-specific features. One new feature indicates whether the set of paths leading to a node originate from one or two nodes in
V q . (We conjecture that in the file+term walk, nodes that are connected to both the source term and file nodes aremorerelevantthannodesthatareconnectedtoonlythe filenodeoronlythetermnode.) Wealsoformfeaturesthat indicatewhetherthegiventermisanicknameoftheperson Figure 1: Person name disambiguation results: Re-call at rank k name, per the nicknames dictionary; and whether the Jaro similarity score between the term and the person name is above 0.8. This information is similar to that used by the baseline ranking system.

The results (for the test set, after training on the train set) are shown in Table 4 and (for two representative cases) Figure 1. In each case the top 10 nodes were reranked. Reranking substantially improves performance, especially for the file+term walk. The accuracy rate is higher than 75% across all datasets. The features that were assigned thehighestweightsbythere-rankerweretheliteralsimilar-ity features and the source count feature.
As a test of the generality of our approach, we also con-sidered a second task. Threading is the problem of retriev-ing other messages in an email thread given a single mes-sage from the thread. Threading is a well known task for email, although there are only few relevant works published [21, 27]. As has been pointed out before [21], users make inconsistent use of the  X  X eply X  mechanism, and there are
Table 4: Person Name Disambiguation Results frequent irregularities in the structural information that in-dicates threads; thus, thread discourse arguably should be captured using an intelligent approach. It has also been suggested [19] that once obtained, thread information can improve message categorization into topical folders.
Our primary interest in this task is that threading is an easily-evaluated proxy for the task of finding similar mes-sages in a corpus. Finding related messages would be both a useful operation for users, and is also important for auto-matic email processing at the corpus level. As threads (and more generally, similar messages) are indicated by multiple typesofrelationsincludingtext,socialnetworkinformation, and timing information, we expect this task to benefit from the graph framework.

More precisely, we formulate threading as follows: given an email file as a query, produce a ranked list of related email files, where the immediate parent and child of the given file are considered to be  X  X orrect X  answers. We limit the answer set to the adjacent files because of our more general interest in finding related messages: while consecu-tive thread messages can be assumed to be related to each other, this assumption is weaker if applied on the entire thread. This definition does, however, make the task some-what more challenging.
We created three datasets for task evaluation, again from the Cspace and Enron corpora. The number of queries for eachdatasetaregiveninTable2. Foreachrelevantmessage, its parent was identified by using the subject line and time stamp. About 10-20% of the messages have both parent and child messages available, otherwise only one file in the thread is a correct answer.

We used a series of variants of this data, in which we varied the amount of message information that is available. Specifically, several information types are available in these corpora: the email header ,including sender, recipients and date;the body ,i.e.,thetextualcontentofanemail,excluding any quoted reply lines or attachements from previous mes-sages; reply lines , i.e., quoted lines from previous messages; and the subject , i.e., the content of the subject line.
We compared several combinations of these components, as detailed in Table 5. Of particular interest is the task which considers header and body information alone, since it best reflects the situation for the more general task of finding  X  X elated X  messages.
The baseline approach generates a list of files, ranked by similarity scores using the vector space model, in which a documentisrepresentedasaweightedvectorinatermspace and a document similarity score is the cosine similarity of theirvectors. TF-IDFtermweightingiscommonlyusedfor documentrepresentation;toapplytheTF-IDFschemehere, we simply consider all available information as text.
The results (Table 5) show that this approach performs reasonably well. Due to space limitations full results are givenasMAPscores;inaddition,Figure2showstherecall-at-k curve for the Cspace dataset, using header and text. Recall of about 55% at rank 5 is reached using header and text information for Cspace using the baseline approach. As one might expect, adding information, in particular the subjectandreplylines,improvesperformancesubstantially.
To formulate this as a problem in the graph model, we let V q assign probability 1 to the file node corresponding to the original message, and let T out = file . In addition to using uniform graph weights, we also use an extremely simple weight-tuning method: specifically, we evaluated 10 randomly-chosen sets of weights and pick the one that per-forms best (in terms of MAP) on the CSpace training data. Werepeatedthisprocedureseparatelyforeveryexperiment setting, so a total of four  X  X andom X  weight vectors were used. Performance for this weight set is shown as  X  X raph-Random X  in the table.

The results show that the graph walk and the TF-IDF are comparable when identical chunks of text, such as sub-ject lines, are present in both the query message and the  X  X arget X . However, the graph walk performs better using only header and body text information, with an absolute improvementof4.1%to24.7%inMAPacrosscorpora. Note thatthe X  X andom X  X eightsoutperformuniformweightsand TF-IDF substantially on CSpace, and often also on other corpora. This is especially true when reply and subject lines are not available. This suggests that even very simple weight-tuning methods are likely to improve performance.
Weappliedrerankingontopoftherandom-weightedgraph walk results. The top 50 file nodes were given to the re-ranker. The features applied are edge unigram , edge bigram and top edge bigram (described in section 5.3.4). We found that the edge bigram features are most informative, leading to large improvement rates. Overall, reranking the graph walk almost always yields the best results. 9 For example, recall of 75% at rank 5 is achieved for the CSpace dataset, withonlyheaderandtextavailable,comparedto58%using theTF-IDFbasedmethodand54%priortoreranking. Most features that were assigned high weight by the learner were bigrams: some examples are: sent from  X  sent to  X  1 , date Performance degraded in only one of the ten cases, for Farmer-D dataset using header only. This is probably due to over-fitting; performance improved slightly on the train set. of  X  date of  X  1 ,and has term  X  has term  X  1 . These paths are indeed characteristic of a thread: e.g., the sender of a message is likely to be a recipient of a reply message, there is high temporal proximity between messages in a thread, and some textual overlap.

Note that while such sequences of relations can be read-ily identified as important in our framework, they cannot be even modeled easily in a flat representation. Sequential aspects of a corpora have been shown to be important for otheremail-relatedtasks, e.g., workflowsandsocialinterac-tion [5].
Asnotedabove,thesimilaritymeasureweuseisbasedon graph-walk techniques which have been adopted by many other researchers for several different tasks. In the infor-mation retrieval community, infinite graph walks are preva-lent for determining document centrality (e.g., [25, 14, 20]). Another related line of research is of spreading activation over semantic or association networks: here the underly-ing idea is to propagate  X  X ctivation X  from source nodes via weighted links through the network (e.g., [4, 26]). Spread-ing activation methods are parameterized by user-provided threshold functions for node activation, limits on node dis-tance, preferences over paths, and other constraints. The framework presented here is similar, but operates through unconstrained lazy graph walks, where path preferences are learned from data.

The idea of representing structured data as a graph is widespread in the data mining community, which is mostly concernedwithrelationalorsemi-structureddata. Recently, the idea of PageRank has been applied to keyword search in structured databases [2]. Analysis of inter-object rela-tionships has been suggested for entity disambiguation for entities in a graph [18], where the graph edges are undi-rected and edge weights represent confidence in having a connectingpathbetweentheentities. Ithasbeensuggested to model similarity between objects in relational data in terms of structural-context similarity [17], where the simi-larity measure corresponds to the expected number of steps requiredforarandomsurfertocrossthegraphfromoneob-ject to the other. The latter did not consider edge weights.
In this paper we propose the use of learned re-ranking schemes to improve performance of a lazy graph walk. Ear-lier authors have considered instead using hill-climbing ap-proaches to adjust the parameters of a graph-walk [14]. We have not compared directly with such approaches; it may be that the performance gain of such methods is limited, due to their inability to exploit the global features we used forthesetasks. Inpreliminaryexperiments,rerankingusing a set of simple locally-computable features only modestly improved performance of the  X  X andom X  weight set for the CSpace threading task. Another related line of research ex-plores random walks for semi supervised learning [34, 33].
As mentioned earlier, not much work has been done that integrates meta-data and text in email. One example ex-amines clustering using multiple types of interactions in co-occurence data [3]. Another recent paper [1] proposes a graph-based approach for email classification. They repre-sent an individual email message as a structured graph rep-resenting both content and header, and find a graph profile for each folder; incoming messages are classified into folders using graph matching techniques.

The task of person disambiguation has been studied in the field of social networks and applied also to email data (e.g., [22, 13]). In particular, it has been recently suggested to perform name disambiguation in email using traffic in-formation, as derived from the email headers [13]. Our ap-proach differs in that it allows integration of email content and a timeline in addition to social network information in a unified framework. In addition, we use learning to tune the system parameters automatically.
We have presented a scheme for representing a corpus of email messages with a graph of typed entities, and an ex-tension of the traditional notions of document similarity to documentsembeddedinagraph. Thisschemeprovidesgood performance on two representative email-related tasks: dis-ambiguating person names, and email threading. Using a boosting-based learning scheme to rerank outputs based on graph-walk related features provides an additional perfor-mance improvement. The final results are quite strong: for namedisambiguation,themethodyieldsMAPscoresinthe mid-to-upper80 X  X ;andforthreading,itproducessubstantial gains over a TF-IDF baseline. The person name identifica-tion task illustrates a key advantage of our approach X  X hat contextcanbeeasilyincorporatedinentitydisambiguation.
In future work, we plan to further explore the scalability of the approach, and also ways of integrating this approach with language-modeling approaches for document represen-tation and document retrieval. A newer version of this sys-tem (not the one used in the experiments) uses a sampling-based approximation to iterative matrix multiplication. In preliminary timing experiments, the new system can very accurately approximate walks of the sort considered here in around 0.5 seconds, and can approximate 10-step walks on a million-node corpus (from a different domain) in around 10-15 seconds.

Thereareseveralstrongmotivationsforusingthisframe-work for search-related tasks in email. First, preserving entity type allows one to formulate a broad range of prob-lemsastypedsearchqueries X  X ncluding,inthispaper,name disambiguation and threading. Secondly, structural rela-tion modeling provides a unified framework for integration of multiple types of information, including social networks, text,timelines, 10 andotherinformationsuchasorganization charts. With such additional information, many interesting information management tasks can be formulated as (or fa-cilitated by) typed retrieval: for instance, retrieval of email addressesrelatedtocalendarentriescouldfacilitatemeeting rescheduling.
This material is based upon work supported by the De-fense Advanced Research Projects Agency (DARPA) under Contract No. NBCHD030010. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA), or the Department of Interior-National Business Center (DOI-NBC).
In future work we plan to incorporate additional time in-formation by adding edges between dates nodes.
