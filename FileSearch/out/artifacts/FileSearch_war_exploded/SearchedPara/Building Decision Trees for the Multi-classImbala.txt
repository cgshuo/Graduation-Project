 One of the fundamental problems in data mining classification problems is that of class imbalance. In the typical binary class imbalance problem one class (negative class) vastly outnumbers the other (positive class). The difficulty of learning under such conditions lies in the induction bias of most learning algorithms. That is, most learning algorithms, when presented with a dataset in which there is a severely underrepresented class, ignore the minority class. This is due to the fact that one can achieve very high accura cy by always predicting the majority class, especially if the majority class represent 95+% of the dataset [3].
The multi-class classification problem is an extension of the traditional binary class problem where a dataset consists k classes instead of two. While imbalance is said to exist in the binary class imbal ance problem when one class severely outnumbers the other class, extended to multiple classes the effects of imbalance are even more problematic. That is, given k classes, there are multiple ways for class imbalance to manifest itself in the dataset. One typical way is there is one  X  X uper majority X  class which contains most of the instances in the dataset. Another typical example of class imbalance in multi-class datasets is the result of a single minority class. In such instances k  X  1 instances each make up roughly 1 / ( k  X  1) of the dataset, and the  X  X inority X  class makes up the rest.
The multi-class imbalance problem is therefore interesting for two important reasons. First, as before, most learning algorithms do not deal with the wide vari-ety of challenges multi-class imbalance presents. Secondly, a number of classifiers do not easily extend to the multi-class domain.

As a result, researchers have sought to e xploit theoretical a nd empirical per-formance benefits of binary approaches for the multi-class problem. One common techniquetodosoistodecomposethemulti-classproblemsintoasetofbinary class problems. This enables users to learn binary class classifiers on each of the subproblems which can then be combined into an ensemble in order to solve the multi-class problem. Such examples include  X  X ne-Versus-All X  (OVA) and  X  X rror Correcting Output Codes X  (ECOC) [7].

One important distinction between an en semble created using a decomposition technique, and a traditional ensemble in the binary class literature, is no single classifier in the decomposition ensembl e can classify an instance in the multi-class domain. Thus while we use the word ensemble in this paper, we do not compare against traditional ensemble techniques (e.g., bagging [1], and AdaBoost [9]) as they are outside the scope of this paper. In order to avoid confusion, ensembles built using decomposition techniques will be known as  X  X ecomposition ensembles X .
 Contributions. While the multi-class imbalance problem is a serious problem in data mining, there has been little study on the effectiveness of decision trees on the multi-class imbalanced learning problem. Recently Hellinger distance deci-sion trees (HDDTs) have been proposed as a way of solving the class imbalance problem for decision trees without sampling. Building upon this method, we propose a modified HDDT algorithm which improve its performance on multi-class datasets, along with an analytic result to explain the relative weaknesses of HDDT in the multi-class domain. We t hen demonstrate the effectiveness of various decomposition techniques on impr oving the performance of decision trees (both C4.4 and HDDT). We then specifically demonstrate how these techniques exploit the nature of HDDT on binary imbalanced datasets to build decom-position ensembles of HDDT classifiers which outperform other decision tree methods on two widely used metrics. Finally, we provide recommendations for building decision trees for the multi-class imbalance problem. We apply a variety of methods to better understand the performance of decision trees in the class imbalance problem. Due to space restrictions, we limit the study to two popular decomposition techniques (OVA and ECOC), as well as building single trees. 2.1 Decomposition Techniques As previously discussed, decomposition techniques have become a powerful tool in the data mining community to transfer (less studied) multi-class problems into (more studied) binary class problems. When considering decomposition tech-niques, an important factor is the size o f the generated decomposition ensemble. Since one of the criteria when selecting decomposition methods to consider was the amount of computation time required, we selected two techniques which (generally) generate vastl y different sized decompos ition ensembles (and thus require vastly different computation time).
 One-Versus-All Decomposition. The OVA technique is one of the simplest and most natural techniques for decomposing the multi-class problem into mul-tiple binary class problems. In OVA, given c classes, c classifiers are built such that each one considers one of the classes to be the  X  X ositive X  class while the remainder are combined into a  X  X egativ e X  class. When a new instance is seen, each classifier returns a probability estimate for the instance. An overall proba-bility estimate is then obtained by combining each of the individual probability estimates into a vector of length c , and normalizing.

One of the main advantages of the OVA technique is that it is conceptually simple. Rifkin and Klautau [16] argue that this simplicity, combined with its superior performance, make OVA a very desirable technique which should be considered over its more com plicated alternatives.
 Error Correcting Output Codes Decomposition. ECOC is another pop-ular method developed by Dietterich and Bakiri [7], which uses the concept of error correcting codes to learn a decompos ition ensemble of classifiers. The choice of error correcting codes is a natural one as, assuming the codewords have ham-ming distance d ,amaximumof d  X  1 2 errors can be made by the decomposition ensemble before misclassification occurs. This is a strong guarantee, and allows users to customize the size of the decomposition ensemble based on how many errors they expect versus the size of the codewords which they will allow.
More specifically, in ECOC each class is given an n -bit binary string called a  X  X odeword X . These codewords are gen erated such that the hamming distance between all codewords is maximized. Let c be an m  X  n matrix (where m is the number of classes), such that c ij denote the j th bit for the codeword of class i . Giventhis,wecannowlearna decomposition ensemble of n classifiers. For each classifier, the positive and negative classes are determined by the j th column of c .Thatis,if c ij =1,thenclass i is considered part of the positive class in classifier j .Otherwise,if c ij =0,class i is considered part of the negative class.
One of the most important considerations when building an ECOC decompo-sition ensemble is the length of the codewords. The maximum codeword length is 2 m  X  1  X  1. While building decomposition ensembles of this size results in the one most robust to errors, it also requires the most training time. Specifically, for 11 classes this method requires building a decomposition ensemble of size 1024. While given the computing power available today this is of reasonable size, as the number of classes grows the problem quic kly becomes intractable. Since having so many classes is rare in practice, and does not in fact occur for any datasets in this paper, we build codewords of maximum size for all datasets. 2.2 Decision Trees Decision trees are one of the fundamental learning algorithms in the data mining community. The most popular of decision tree learning algorithm is C4.5 [14]. Recently Hellinger distance decision trees (HDDTs) [4] have been proposed as an alternative method for building decision trees for binary class datasets which exhibit class imbalance.
 Provost and Domingos [13] recommend a modification to C4.5 known as C4.4. In C4.4 decision trees are constructed by building unpruned and uncollapsed C4.5 decision trees which use Laplace s moothing at the leaves. These choices are due to empirical results [13] demonstrating that a fully built unpruned, uncollapsed tree with Laplace smoothing outperforms all other configurations, and thus are used in all experiments in this paper.

The important function to consider wh en building a decision tree is known as the splitting criterion . This function defines how data should be split in order to maximize performance. In C4.4 this function is gain ratio, which is a measure of purity based on entropy [14], while in HDDT this function is Hellinger distance. In the next section we motivate Hellinger distance as a splitting criterion, and then subsequently devise a strategy for improving its performance on multi-class datasets.
 Hellinger Distance Splitting Criterion. Hellinger distance is a distance met-ric between probability distributions used by Cieslak and Chawla [4] to create Hellinger distance decision trees (HDDTs). It was chosen as a splitting criterion for the binary class imbalance problem due to its property of skew insensitivity. Hellinger distance is defined as a splitting criterion as [4]: where X + is the set of all positive examples, X  X  is the set of all negative examples and X + j ( X  X  j ) is the set of positive (negative) examples with the j th value (of p distinct values) of the relevant feature.

Since Hellinger distance defines the distance between probability distributions, it does not naturally extend to the multi-class problem. This is in contrast to gain ratio  X  which is based on entropy  X  which is easily extensible to any number of classes. Specifically, since Hellinger distance is a distance metric, any natural extension would be attempting to determine the distance between c probability distributions, where c is the number of classes. Since this is not a well defined problem, we propose an extension to the HDDT algorithm for the multi-class problem. Algorithm 1. Calc Multi Class Hellinger Multi-Class HDDT. In order to overcome the shortcomings of Hellinger dis-tance as a splitting criterion for the multi-class problem, we employ techniques similar to the decomposition algorithms described in Section 2.1. That is, given the set of classes C , we consider each unique pair of subsets: C 1  X  C , C 2 = C \ C 1 and consider all classes in C 1 as the positive class, and all classes in C 2 as the negative class 1
Algorithm 1 outlines the approach to incorporating Hellinger distance in learn-ing multi-class decision trees. Let T C indicate the subset of training set T which has its class in set C ,and T k,j,C identifies the subset which has its class in set C and has value j for feature k .

The important aspect of this version of the Hellinger distance splitting crite-rion is the reduction of the multiple classes into all relevant binary class possi-bilities. This choice enables Hellinger distance to try find the best split between all possible choices of positive and negative class, and thus any meaningful split available to it in the multi-class domain.

This distance calculator can then be use d as the splitting criterion in a decision tree algorithm in order to build multi-class HDDTs (MC-HDDTs). Comparing MC-HDDTs further to HDDT shows us that for the binary class problem, exactly the same tree will be learned as the original version. Our algorithm can therefore be recommended in lieu of HDDT, as it returns the same tree for the binary case while offering better performance on the multi-class problem. One of the major research questions in this paper is why the performance of HDDT suffers in the multi-class case when compared to C4.4, especially in light of their performances on binary class i mbalanced datasets. In this section we present an analytic example which dem onstrates how HDDT and C4.4 behave when a binary class problem is transformed into a multi-class problem and then back again. Due to space limitations we limit ourselves to a single example which demonstrates an example of Hellinger distance performing poorly in the multi-class case.

For our analytic example we created a simulated dataset with 4 classes, with centers on the corners of a square, such that their means were separated by 2  X  . In the upper left and lower right corners, we simulated 10,000 examples, while in the lower left and upper right corners we simulated only 100 examples. This gives us a class imbalance ratio of 10,000:100:10,000:100 ( C.V.: 0.98). We then decomposed the 4 class problem into a b inary class problem by removing the lower half of the square (as depicted in Figure 3). In order to determine their performance, each of the experiments was run 100 times, and the (W)AUROC (defined in Section 4) computed.

Figures 1(a) and 1(d) are representative examples of the effects of gain ratio and Hellinger distance (respectively) on the binary class problem. From the splits, we see that Hellinger distance is much more aggressive when splitting into the majority class. When considering their performance, we see that, based on AUROC, HDDT wins 85 out of the 100 runs. This increase in performance is therefore an effect of Hellinger distanc e aggressively attempting to capture as much of the minority class as possible, while gain ratio remains very conservative.
In the multi-class case (Figures 1(b) and 1(e)) Hellinger distance once again is very aggressive in attempting to capture as much of the minority class as possible, while C4.4 is much more conservative. Due to the nature of this prob-lem, however, the more conservative approach is better able to capture the multi-distributional aspect of the problem. This is demonstrated by the fact that, based on WAUROCs, C4.4 wins 82 of the 100 runs. Thus, for multi-class, Hellinger distance is not able to adequately separate the two classes, instead being overwhelmed by the spurious information from the extra classes.
In order to better understand this phenomena, consider the right-most hor-izontal split Hellinger makes in the multi-class case. For this split, Hellinger distance considers the  X  X op X  points to be the positive class and the  X  X ottom X  points to be the negative class. As evidenced by the inaccuracy of the top left points, Hellinger distance is not able to accurately partition the space. Gain ratio, on the other hand is able to arrive at a better split point which more accurately represents the boundary for this problem.

Finally we consider the case of OVA decomposition on the dataset. Figure 1(f) shows Hellinger distance is very good at capturing the minority class. This favorable splitting is exactly what would be expected from such a binary class imbalanced dataset, and thus explains the performance increase HDDT sees over C4.4 when used in conjunction with OVA. This hypothesis is further confirmed when we note that HDDT obtains a higher AUROC in 80 of the 100 runs, thus confirming that it is the preferred classifier to use.

Given these results, we now better understand the dynamics of Hellinger dis-tance in the binary class problem which result in inferior performance in the multi-class domain. Further research into overcoming these challenges might prove useful in developing a single decision tree approach which, without sam-pling, is able to outperform the others in the case of multi-class imbalance. We implemented MC-HDDT in WEKA [10], and used WEKA X  X  built-in OVA and ECOC to train each of the classifiers. In order to make fair comparisons, we split the experiments into three separate categories, namely: single trees, OVA decomposition, and ECOC decomposition. This separation is done to highlight the difference in performance of HDDT and C4.4 under different decomposi-tion techniques. That is, by comparing each method within a category, we are providing a fair comparison of the d ifferent decision tree techniques.
Table 1 gives the relevant simple statistics about the datasets used in this paper. One of the main goals when choosing the datasets to consider was ensuring that they were imbalanced. To measure imbalance in multi-class datasets, we use the  X  X oefficient of variation X  (C.V.) as recommended by Cieslak and Chawla [5]. Specifically, C.V. is the proportion of the deviation in the observed number of examples for each class versus the exp ected number of examples in each class. In this paper we consider datasets with a C.V. above 0.35  X  a class ratio of 2:1 on a binary dataset  X  imbalanced. This leaves us with the 17 datasets listed. 4.1 Configuration In order to ensure a fair comparison of the methods, we ran 50 iterations [15] of 2-fold cross-validation. We chose 2-fold cross-validation due to the small number of instances of some classes in the datase ts. Due to space restrictions, we only consider weighted area under the receiver operating characteristic (WAUROC) [19]. We chjse this metrics as it is a commonly used criterion when comparing classifiers in the multi-class imbalance case.
 4.2 Statistical Tests While many different techniques have been applied to attempt to compare clas-sifier performance across multiple datasets, Dem X  sar suggests comparisons based on ranks. We follow this recommendation and rank the performance of each classifier by its average performance, with 1 being the best. Since we seek to determine whether or the HDDT methods are statistically significantly better than the existing methods, we use the Friedman and Bonferroni-Dunn tests as was recommended by Dem X  sar [6].

The Friedman test is first applied to det ermine if there is a statistically sig-nificant difference between the rankings of the classifiers. That is, it tests to see if the rankings are not merely randomly distributed. Next, as recommended by Dem X  sar, we preform the Bonferroni-Dunn test to compare each classifier against the control classifier. 4.3 Results As stated previously we break the experi ment into three different categories. Each of the categories corresponds to a different level of computational effort required to construct the classifier, with single trees requiring the least amount of work, and ECOC requiring the most. For the sake of space, however, the WAUROC values for each of the methods is presented in Table 2.

Table 2 also contains the results of the statistical test described in Section 4.2. A classifier receives a check mark if it is c onsidered statistically significantly worse than the best classifier (i.e., the classifier with the lowest average rank) in its category (e.g., single tree, OVA, ECOC) at the noted confidence level. Single Tree Performance. When considering the sing le tree performances, C4 . 4 and MC-HDDT perform equivalently. This is an interesting result for multi-class imbalanced data sets, and further corroborates the intuition established with the illustrations in Section 3. As dis cussed, this is mainly due to the aggres-sive nature of the splits which Hellinger distance tries to create. The consequence of this analysis is further evidenced in the OVA performance.

Hellinger distance, as a criterion, is limited in capturing the multi-class diver-gences. Nevertheless, we recommend MC -HDDT as a decision tree classifier, as it reduces to HDDT for binary class datasets (achieving statistically significantly superior performance over C4.4 [4]), and is a competitive alternative to C4.4 for multi-class datasets (no statistically significant variation in performance). OVA Performance. When considering OVA perfor mance, HDDT significantly outperforms C4.4. This result confirms our understanding of the binary class performances of each of the classifiers . That is, when decomposing the multi-class problem into multiple binary problems, the binary class problems obtained are (often) extremely imbalanced. This f act is further exacerbated by the fact that the multi-class dataset itself is highly imbalanced.

Thus in the OVA approach, each binary classifier in the decomposition ensem-ble must deal with the class imbalance problem. Since HDDT has been shown to perform statistically significantly better than C4.4 in this scenario, we expect to see HDDT outperforming C4.4 when using the OVA approach. Based on the observations obtained, we can conclude that our intuition is correct and, further-more, that when using OVA decomposition for multi-class imbalance, HDDT are the appropriate decision tree learning to choose.
 ECOC Performance. When comparing the relative performance of the clas-sifiers, we see that HDDT outperforms C4.4 almost as well as in the OVA ap-proach. While the statistical significance is only  X  =0 . 10, we see that it is not statistically significant at the  X  =0 . 05 threshold by one dataset. As Table 2 shows, some of the performance differen ces were quite small. Thus it seems rea-sonable to believe that with more datasets we might see the same statistical significance with this method as was shown in OVA, as we would expect the same performance gains of using HDDT over C4.4 in this case as well.
This expectations of better performance of HDDT over C4.4 is due to similar reasoning as the OVA case. That is, by decomposing the problems into multi-ple binary problems, the class imbalance will still be a major concern. However, the ECOC approach will result in 2 m  X  1  X  1 binary datasets. Some of these will be highly imbalanced, while others may be balanced depending on the respec-tive class distributions. Nevertheless, HDDT is able to capitalize with ECOC. It is able to achieve stronger separability on highly imbalanced combinations, and achieves comparable performance to C4.4 on the relatively balanced class combinations, and thus, as a collective, it is able to outperform C4.4. Overall Performance. When considering the over all performance of each method as given in Table 2, we see that, in general, the more computational power used, the better the performance. That is, the ECOC methods outper-form the OVA methods which outperform the single tree methods.

This is an unsurprising result, as a wealth of data mining literature demon-strates that combining a large number of classifiers into an ensemble is a powerful technique for increasing performance. The decomposition ensemble techniques employed in this paper are also of particular interest, as the diversity of the clas-sifiers created in the decomposition ensembles is quite high. That is, since the class values under consideration are changing between datasets, the classifiers are not merely learning on different permutations of the underlying instances, instead having the decision boundaries themselves change. It is well known that diversity is important to creating good ensembles [11]. A number of methods have been proposed to counter the class imbalance is-sue, however a large portion has focused on the binary class problem. Sampling methods have emerged as a de facto standard, but present numerous challenges when being extended to multiple classes. This is due to the complexity aris-ing from the combination of multiple class imbalance types, different amounts of sampling, different sampling methods, and different cost matrices. Thus to apply any reasonable optimization criteria to discovering the optimal sampling amount is computationally prohibitive.

Rescaling [8] is a general method for cost-sensitive and class-imbalance prob-lems which changes the distribution of the original data [20]. As there are many methods that can change the distribution, rescaling can be realized in numerous ways (e.g., by sampling, instance-weighting, threshold moving, etc.). Sampling is a widely used rescaling method to deal w ith the class-imbalance problem. The method balances the distribution modifying the training set to either increase the presence of the minority class (e.g., random oversampling, SMOTE [2]), or reduce the majority class (e.g., undersampling). Another popular rescaling method is instance-weighting. In this method, instead of removing or adding in-stances, a weight is generated for each instance according to its misclassification cost, which is passed to a cost-blind classifier which uses instance weights [17]. A final common approach is threshold moving, wherein the decision threshold is modified in order to achieve the minimal cost in cost-sensitive learning [8,21].
Cost sensitive learning methods have been developed to deal with the differ-ent costs of misclassification [18]. For example, the cost of misclassifying a can-cer patient as healthy is much higher than the cost of misclassifying a healthy patient as having cancer. Given this, cost sensitive problems require the min-imization of the misclassification cost rather than misclassification errors. The class-imbalance problem can thus be considered a cost-sensitive problem where the costs are unequal and unknown [12]. Most cost-sensitive learning methods are actually based on rescaling [20], and therefore it is natural that by assigning the appropriate misclassification cost for each class, cost-sensitive approaches can be used to deal with the class-imbalance problems. In this paper we compared different methods of building C4.4 and Hellinger distance decision trees for multi-class im balanced datasets. G iven the different amounts of computation time required by each method, we investigated the problem in three separate categories: single tree, OVA, and ECOC.
 In the single tree case we found that MC-HDDT performs comparably to C4.4. While MC-HDDT does not statistically significantly outperform C4.4, it is a reasonable alternative to C4.4 for all classification problems. This is an important result as it gives practitioners another viable tool to use when confronted with a new dataset.

Alternatively, when the analysis was extended to build decomposition ensem-bles of binary classifiers HDDT became the clear choice. Given the skew insen-sitivity of Hellinger distance as a splitting criterion, coupled with the nature of skew in the resulting problems, the gains in performance become significant. With this in mind, we recommend HDDT for all multi-class imbalanced learning when used in a decomposition method.

Another important observation stems from the overall performance. Specifi-cally we see that the more complex (and thus more computationally intensive) algorithms give real gains in performance. We can therefore revise our recom-mendation, this time recommending the use of HDDT in an ECOC decomposi-tion ensemble if the user has enough com putational power. Otherwise, the user should consider an OVA decomposition ensemble with HDDT, and, finally, if not enough computational power exists for such a decomposition, building MC-HDDTs. We recommend MC-HDDTs over C 4.4, as even though the difference between them is not statistically significant for multi-class datasets, MC-HDDT reduces to HDDT for binary class datasets, where it has been demonstrated to be strongly skew insensitive and statistically significantly over C4.4. As a result, MC-HDDT may be considered the recommended decision tree algorithm.

Finally, Section 3 illustrated the challenges Hellinger distance faces in the multi-class domain. With this understanding further research can now explore the problem of multi-class Hellinger distance and attempt to overcome the demonstrated difficulties to provide a robust classifiers for multi-class problems. Acknowledgements. Work is supported in part by the NSF Grant ECCS-0926170, NSFC (60903103, 61021062) and the Notebaert Premier Fellowship.
