 1. Introduction
In a cognitive approach to information interaction ( Ingwersen, 1996 ), the different actors in the interaction processes con-tribute interpretations of their situations and pre-suppositions of the world as well as of the information structures and objects involved. Such manifestations of human cognition, reflection and ideas take the form of different representations, for instance, author X  X  text, pictures, music tunes in documents, or as database designers X  indexing schemes and retrieval algorithms, see information objects and information technology (IT) components of model, Fig. 1 . They might also consist of a searcher X  X  request formulation(s) and corresponding perceived work task description(s) representing his/her informa-tion requirement and problem state originating from the socio-organizational context ( Ingwersen &amp; J X rvelin, 2005 ). Implicit or explicit patterns and evidence of seeking behaviour are similarly seen as such representations of the interaction processes ( Larsen, Kek X l X inen, &amp; Ingwersen, 2006 ).

In this perspective the interpretations (and thus representations) found in each of the components of the model, Fig. 1 , including the information interaction process itself, are seen as contextual and complementary to one another and interplay over time. This complementarity constitutes the idea behind the polyrepresentation principle.
According to Ingwersen (1992, 1996), Ingwersen and J X rvelin (2005) the principle of polyrepresentation is based on the following main hypothesis:  X  X  ... the more interpretations of different cognitive and functional nature, based on an IS&amp;R (infor-the higher the probability that such objects are relevant (pertinent, useful) to a perceived work task/interest to be solved, the of objects created by the divergent cognitive (and functional) representations we name  X  X ognitive overlaps X   X  Fig. 2 .
Polyrepresentation distinguishes between two kinds of representations: cognitively different ones deriving from the inter-pretations by different actors; and functionally different representations that derive from the same actor, such as, author gen-erated document structures, title, image features, diagram captions, and references or out-links (anchors), e.g. the information objects component (dark shading), Fig. 1 , and the  X  X uthor X  part of the Venn-diagram, Fig. 2 . With respect to an-chor text one might argue that they inform both about the cited item ( Brin &amp; Page, 1998 ) and about the citing item ( Schnei-der, 2004 ). Owing to their contextual properties, references are thus functionally quite different from, say, title words and other content-bearing tokens. The  X  X  X elector category X , Fig. 2 , signifies special actors responsible for the existence and avail-ability of the information objects, such as editors or publishers. According to the principle, good retrieval results are expected when cognitively unlike representations are used for retrieving the documents, e.g. the same search key found in the docu-ment title (made by the author) and retrieved from the intellectually assigned descriptors made by indexers, and found in citing documents (or in-links) made by other authors over time.

In other words, polyrepresentation is a particularly structured way of carrying out a kind of classic triangulation in the information and IT spaces and, simultaneously, allows making use of redundancy in the cognitive space of searchers. The diversification of all components in Fig. 1 including the searcher X  X  space, information objects and IT-components and their application are founded in a theoretical IR framework and constitutes the real novelty of polyrepresentation. A more detailed analysis of the scientific background underlying the principle and its applicability is provided by Ingwersen and J X rvelin (2005, pp. 206 X 214 and pp. 342 X 346), Larsen et al. (2006) .

Several machine learning studies have examined the use of document structure weights to learn the best combination of document structures resulting in increased retrieval performance. This work has resulted in the field-weighted BM25 rank-ing function by Robertson, Saragoza, and Taylor (2004) . In the mentioned studies the optimal combination of document structure weights are learned by examining retrieval performance. In the present study, however, the representations are chosen and grouped based on the principle of polypresentation. The present study is the first of its kind to examine IR by focusing on polyrepresentation of information objects in order to explore the best combinations of document representations, measured according to retrieval performance. The paper investigates the intersection of search keys as found in Title/Ab-stract terms and phrases (made by authors), and as identical or similar MeSH major and minor index terms (from indexers), and as title words in documents being cited (as references) by the documents retrieved, as illustrated below in Fig. 3 , e.g. OL 1. The references thus play the role of additional document features (context) useful to IR, as originally proposed by Garfield with respect to the creation of the citation indexes ( Garfield, 1979, 1993 ). The present article elaborates on the results of Skov, Pedersen, Larsen, and Ingwersen (2004, 2006) .

Three kinds of experiments are executed. First we test restricted best match polyrepresentation of the four search fields mentioned above in all their combinations. Secondly, we investigate the retrieval performance in restricted best match poly-representative IR of structured queries expanded by thesaurus structures (synonyms) according to Kek X l X inen and J X rvelin (1998, 2000) against unstructured (bag-of-words) queries. And thirdly, we do two re-ranking tests according to (a) obtained precision in overlaps between different representations or (b) based on citation impact. The three experiments are further explained in Section 3.1 .

The paper is structured as follows: Section 2 discusses briefly previous empirical studies that are central to the under-standing of polyrepresentation and associate to the present investigation. Section 3 outlines the experimental setting and places the five document representations included in the experiment in a polyrepresentation framework. Section 4 presents and discusses the results of the investigations. Section 5 concludes the article by suggesting future possible applications and research on polyrepresentation. 2. Previous empirical studies of polyrepresentative nature 2.1. Polyrepresentation of information space The first observations of retrieval performance improvements made by polyrepresentative means were carried out by
McCain (1989) and Pao (1994) . However, these studies did not apply that concept. The experiments demonstrated that re-trieval of documents by search keys found in titles and abstracts and by involving documents identified by a citation search strategy produces much higher odds for finding relevant documents in the constructed overlap than in each of the retrieved sets independently ( Pao, 1994 ). The overlaps turned out to be small. In a slightly different experimental setting Christoffer-sen recently tried out the effectiveness of retrieval overlaps constituted by combining several databases ( Christoffersen, 2004 ). He searched Medline, Embase and SCI in order to test the relevance proportions in any of the overlaps created online between indexers of MeSH (Medical Subject Headings in Medline), author text (Embase) and citing authors X  X  texts (Science
Citation Index). Expert relevance assessments were used. He found that  X  X  X t]he degree of overlap strongly correlates with the percentage of relevant items in a set X  (p. 391). The results were statistically significant ( Ingwersen &amp; J X rvelin, 2005 ).
Also in recent investigations Larsen (2004) tested the retrieval performances of a variety of inter and intra-document fea-tures in the information space, the focus component, Fig. 1 . He used different document representations from the INEX test collection 1 , as well as added thesaurus and uncontrolled terms assigned by INSPEC indexers. Finally, citation cycling strategies, i.e. backward chaining followed by forward citation chaining were used, named the Boomerang effect ( Larsen et al., 2006 ). The purpose of the Boomerang effect was to exploit the potentially high performance offered by incorporating link or citation infor-mation, and at the same time allow for queries formulated in natural language.

The best precision result was achieved by functionally different document representations, such as article titles, section headings and the cited titles in the references. Reasonable effectiveness was obtained by combining those representations and intersecting them with indexer descriptors and the citation cycling based Boomerang effect ( Larsen, 2004 ). Unstructured queries were used, and the frequency of documents cited was part of the weighting in the citation search. The Boomerang effect was compared (1) to best match bag-of-words used for each representation separately and fused in a relaxed polyrep-resentative modus and (2) to a common bag-of-words based baseline. The results showed that the Boomerang effect on aver-age did not decrease performance, but relaxed polyrepresentation was slightly better. However, the common bag-of-words baseline obtained the best overall performance ( Larsen et al., 2006, p. 155 ). 2.2. Polyrepresentation of users X  cognitive space
As noted above the entire principle of polyrepresentation does not rely on one request formulation from a searcher. It assumes that functionally different representations of the searcher X  X  cognitive space come into play too, such as current knowledge state of domain, request formulation or work task perception (see Ingwersen, 1996 ). Again, one may regard such polyrepresentations as restricted when using each representation separately to query the retrieval engine and isolating the output to be measured for performance to the inner overlap by intersection; or as more relaxed if loosely combined by a union of the representations with term weights, as in recent investigations by Kelly, Dollu, and Xin (2005) , relating back to Belkin et al. X  X  multi-query version experiments ( Belkin, Kantor, Fox, &amp; Shaw, 1995 ).

Kelly et al. (2005) combined different searcher statements of a single information need with statements captured from each user via a structured interface: current knowledge state of the request; reason for the request; and additional known concepts. The experiments were carried out within the TREC HARD track using the Lemur IR Toolkit. A baseline was con-structed from the TREC topic title and description elements combined into a single query. The investigation X  X  experimental (single) runs consisted of the baseline query terms + different combinations of relevance feedback modes + the polyrepre-sentative combination from the searcher X  X  space. Whereas the baseline alone yielded on average 9.3 words, the polyrepre-sentation captured from the searchers yielded more than 25 different words on average. This result stresses the usefulness of attempting the extractions of searcher statements, in particular if initial requests (the TREC topic title) are very short state-ments. When combining the polyrepresentative searcher statements, Kelly and colleagues did not retrieve documents by each statement separately later to be intersected in order to define overlaps of documents. Instead, they applied the state-ments in union with weights for term repetition (term overlap). This is thus a relaxed approach to polyrepresentation. Their retrieval performance results are highly promising from a polyrepresentation point of view, since all polyrepresentation combinations yielded statistical significant performance improvements over the baseline ( Kelly et al., 2005 ). Also, they found a significant correlation between query length and performance. 2.3. Polyrepresentation of retrieval engines and the interaction process
Lund, Schneider, and Ingwersen (2006) carried out polyrepresentation studies of the IT system component (lower left model component, Fig. 1 ). They examined the retrieval results from the 12 most effective TREC 5 search engines. In Lund et al. X  X  study the involved search engines illustrate cognitively different representations of IR system settings when they fol-low different retrieval principles, and functional difference when they are versions of the same principle. Their initial results demonstrate that when combining the search engines according to restricted polyrepresentation principles, the performance in terms of recall and precision depends on how many relevant documents potentially exist in the search task. The more relevant documents in the topics over the engines in all combinations the higher the precision ( Lund et al., 2006 ). This result implies that in data fusion based on polyrepresentation principles search topics should contain  X  X ubstantial numbers X  of rel-evant documents in order to function properly. According to Larsen et al. (2006, p. 154) , Lund et al. X  X  results indicate that a combination of 3 X 5 systems may perform better than combinations of, for instance, 12 different IR engines, owing to the involvement of too many functionally alike and/or badly performing IR systems in the fusion.

Secondly, for the restricted combinations of the four best performing but logically different engines, for all performance indicators, the combined fusion outperformed the single systems. In support of the polyrepresentation principle Lund et al. X  X  results demonstrate with statistical significance that when cognitively different systems are combined the precision is higher than when only functionally different systems are fused  X  provided that they are of equal performance. These results coincide with automatic IR data fusion experimental findings that smaller retrieval overlaps commonly imply better performance of the fusion over the single systems involved ( Kwong &amp; Kantor, 2000; Wu &amp; McClean, 2006 ). Further exper-imental results on data fusion following  X  X elaxed X  polyrepresentative principles are underway at present.

Looking into the interaction process itself (the horizontal line, Fig. 1 ) White has recently investigated empirically the prin-ciple of polyrepresentation applied to interface functionality (2006) and implicit relevance feedback algorithms for interactive
IR ( White, Ruthven, Jose, &amp; van Rijsbergen, 2005 ). White proposes to apply  X  X  X ontent-rich search interfaces that implement an aspect of polyrepresentation theory, and are capable of displaying multiple representations of the retrieved documents simultaneously in the results interface X  ( White, 2006, p. 1 ). Three  X  X imulated search X  scenarios ( Borlund, 2003 ) were tested for retrieval performance by means of searcher simulations of all possible combinations of representations and paths avail-able. The best performing combination of representations consisted of document title, its query-biased summary and sum-mary sentence in context. 3. Testing inter-and intra-document features in polyrepresentation  X  the experimental setting
The present project and experimental setting was inspired by and elaborated on the Larsen observations (2002, 2004), and the Pao experiments (1994) discussed above. The setting included selected elements of polyrepresentation of the infor-mation space in a best match setting. The Cystic Fibrosis test collection ( Shaw, Wood, Wood, &amp; Tibbo, 1991 ) and the InQuery retrieval system (version 3.1) were used in the experiment. The Cystic Fibrosis test collection contains 1239 document surro-gates of documents published in 1974 X 1979. The surrogates consist of title, abstract, major and minor Medical Subject Headings (MeSH) from Medline, 3 as well the reference list and subsequently citing documents in condensed form. TheCystic Fibrosis col-lection originally contains 100 topics from which we randomly selected 29 for our test purpose. We chose to reduce the number of topics because the processing of each topic in the experiment was quite demanding. The topic processing was demanding primarily due to two manual elements of the process (the query expansion of search keys in MeSH thesaurus and the chosen approach to include bibliographic references as a representation) further described in Section 3.1 . The relevance assessments in the test collection are given on a graded scale (retrieved documents were judged highly relevant, marginally relevant or not relevant) by four assessors. The four assessors include three medical subject experts and one medical bibliographer. Assess-ments provided by the three medical subject experts were used as a conglomeration. In the experiments a document is graded highly relevant if just one of three medical expert assessors have judged the document highly relevant. Likewise with docu-ments assessed marginally relevant. Assessments by the medical bibliographer were not included since less agreement was found between relevance evaluations made by the medical bibliographer and the subject experts than between the three sub-ject experts ( Shaw et al., 1991, p. 354 ). Table 1 shows summary figures for the 29 topics from the Cystic Fibrosis test collection we used in the present study.
 The Cystic Fibrosis test collection is small compared to common TREC news test collections or even the INEX collection of
IEEE CS journal papers. However, it is ideally suited for testing inter and intra-document features in polyrepresentation as it contains both cognitively and functionally different features. Functionally different features were applied in the form of titles (TI) combined with abstracts (AB) and references (RF), all representing the author, combined with Medical Subject Headings (MeSH) representing the indexer as a cognitively different actor. MeSH is a controlled vocabulary used for indexing, and both major (MJ) and minor (MN) subjects of the document are represented. The TREC and INEX test collections do not contain descriptors or citations to the indexed documents and are hence less suitable for polyrepresentation experiments. Although the Cystic Fibrosis collection contains all the bibliographic references given to previous work, they are unfortunately pre-sented in a very short form that makes searching their titles impossible, e.g. as  X  X  X rvine WJ Lancet 2 163 970 X . This form also pertains to the citations given to the articles from their publication year (1974 X 1979) until 1987. There exists a definitive need for a large-scale journal article test collection with full text, human indexing and references as well as citations for an extensive time period. Elsevier X  X  SCOPUS 4 might be used as a basis for creating such a collection. 3.1. The experimental setting and operations
Three kinds of experiments are executed based on the principle of polyrepresentation: (1) In the first experiment, we test restricted best match polyrepresentation of the four search fields mentioned above in (2) Secondly, the study investigates the retrieval performance in restricted best match polyrepresentative IR of structured (3) Third, we want to test if re-ranking of retrieved documents according to obtained precision in overlaps between dif-
Before we conducted the experiments we merged two representations and decided how to include the reference representation. First, the representations TI and AB were merged and searched as one representation (TI/AB), owing to the very large overlap (80%) the two fields in between. Combining the four representations (TI/AB, MJ, MN and RF) resulted in 15 overlaps 6 ( Table 2 ). The restricted polyrepresentation search principle used in the project with respect to over-laps is shown in Fig. 3 and demonstrated below in terms of a search string from InQuery applying the quorum principles.

Secondly, a straightforward way to include references (RF) as a document representation in a polyrepresentation search is to perform a topic search in the natural language title included in the bibliographic reference in the reference list of the documents. As stated above, this option was not possible in the test collection. Therefore, an alternative contextual ap-proach was used in order to include references as a document representation despite the missing title. Inspired by an ear-lier study of polyrepresentation ( Larsen, 2002 ) references were included by means of a subject search executed for each request in science citation index (SCI). The aim of this subject search was to locate seed documents in the citation data-base. 7 The references in the retrieved documents were ranked using the Dialog RANK command on the cited reference field. This command ranks the cited references in the retrieved documents by frequency. For each request the top-three cited references were selected as seed documents. 8 The three seed documents were then used as input in a (RF) search in the test collection and provided the substitute retrieval of the title words of the references. This way of deriving at polyrep-resentation overlaps by keys found in RF from context and the three other fields signifies a conservative means of polyrepresentation.

Twenty nine topics and two types of queries were tested in InQuery: unstructured, natural language queries and highly structured queries. The 29 requests were used without modification as direct bag-of-words input for the natural language queries searched in TI/AB, MJ and MN, respectively, and combined with Boolean logic. The same 29 requests were searched as highly structured queries, modified in a number of ways inspired by Kek X l X inen and J X rvelin X  X  ap-proach to query structuring ( Kek X l X inen &amp; J X rvelin, 1998, 2000 ): first, queries were parsed for noun-phrases, shown in the example below in double quotes, e.g.  X  X  X epatic complications X . Secondly, stop words were removed, and finally the remaining search keys were expanded manually using the MeSH thesaurus to increase recall. In the manual query expansion narrower terms and synonym terms were added from the MeSH thesaurus. The process of query expansion could be automated in future larger scale experiments. In accordance with Kek X l X inen and J X rvelin (1998) InQuery X  X 
Boolean operators were used to express relations between search terms in the highly structured queries. Using highly structured queries tend to ensure that documents identified in an overlap have identical or synonym search terms pres-ent from all the representation searched agreeing with the principle of polyrepresention (see also Section 4.2 ). The fol-lowing example of a highly structured query is based on the test request: What are the hepatic complications of cystic fibrosis? In the query example below the query terms in italics are expanded terms from MeSH. It illustrates a quorum
OL 2 search where the unique overlap between TI/AB, MJ, MN is identified ( Fig. 3 and Table 2 ) by isolating it from the documents that also contain the search keys in their RF (by quorum NOT-logic excluding the documents already retrieved in OL 1): TI/AB = (hepatic OR liver OR hepatectomy OR  X  X  X epatic complications X ).
 AND MJ = (hepatic OR liver OR hepatectomy OR  X  X  X epatic complications  X  ).
 AND MN = (hepatic OR liver OR hepatectomy OR  X  X  X epatic complications  X  ).
 NOT RF = (Bowman T Lancet 1 183 962, Weber A Pediatrics 4 53 949).

The same sample expressed in the query language of InQuery: #q = #bandnot (#band (#field (TI/AB #syn (hepatic liver hepatectomy #1 ( X  X  X epatic complications))), #field (MJ #syn (he-patic liver hepatectomy #1 ( X  X  X epatic complications))), #field (MN #syn (hepatic liver hepatectomy #1 ( X  X  X epatic complica-tions)))), (#field (RF #1 (Bowman T Lancet 1 183 962) #1 (Weber A Pediatrics 4 53 949))).

Using query structure as an independent test variable provides information on the impact of query structure when apply-ing polyrepresentation in a best match setting.

In the last two re-ranking experiments the following approach was used. For both experiments, the search results from the 15 overlaps (all the retrieved documents) were merged into one ranked list of documents (run 1, Table 3 ). Since each document only appears once in an originally retrieved overlap (because of the restricted polyrepresentation), the original
InQuery RSV decided this run X  X  final ranking, including documents from less well performing overlaps (like OL 2 and OL 6 X 9). This final ranking thus signifies a moderately restricted kind of polyrepresentation.

The first and primary re-ranking test (runs 2 X 4) was based on the precision obtained in the structured queries in the 15 overlaps (the right-hand side, Table 2 ) by assigning weights to the documents according to (a) precision obtained in those queries and (b) precision obtained retrieving highly relevant documents (column 7, Table 2 ). The following weights were applied (in run 1 no weights were applied). In run 2 weight 100 was assigned the documents in the four overlaps with the highest precision in structured retrieval (OL 1, 3, 4, and 5). In run 2 no weights were assigned to documents in OL 2, as precision obtained in this overlap is considerably lower than in the before mentioned overlaps with three and four rep-resentations (column 7, Table 2 ). This weighting is intended to reduce the impact of the documents placed in the less well performing overlaps when all the overlaps are merged into one ranked list of documents. It boosts the best polyrepresenta-tive combinations as if the selected overlap documents are repeatedly retrieved 100 times. In addition, run 2 illustrates weights assigned to cognitively and functionally different fields. In run 3 weight 100 was applied as in run 2 plus that weight 50 was applied to overlaps with medium precision (OL 2, 6, 8, and 10, Table 2 ). This run also introduces documents from the inner overlaps retrieved simultaneously by structured queries from only two fields, regardless types of overlaps. In run 4 weight 100 was applied to overlap 1 (consisting of four different representations), weight 66 was applied to OL 2 X 5 (consist-ing of three different representations), and weight 33 was applied to OL 6 X 11 (consisting of two different representations).
This modus of weighting illustrates an automatic assignment of weights according to number of overlapping fields. The scal-ing of the weights is not learned from the experiments. Instead, the weight 100 is an absolute weight and the other weights are decided proportionally. However, more tests could reveal a more optimal assignment of weights.

The second re-ranking test (runs 5 and 6) was based on citation impact , i.e. applying the number of received citations as an indication of quality. Citations (in-links) represent the citing author X  X  cognitive structures and their interpretations of the work cited. In runs 5 and 6 all documents included in the search result had received at least one or three citations, respectively.

We measured the performance of individual overlaps using straight recall and precision. The performance of the re-rank-ing runs were evaluated by cumulative gain (CG) ( J X rvelin &amp; Kek X l X inen, 2002 ). 4. Results and discussion
The tripartite relevance assessments provided in the test collection made it possible to investigate the retrieval perfor-mance for (a) all relevant documents (marginally relevant and highly relevant documents) and (b) highly relevant docu-ments across unstructured and structured queries, respectively. 4.1. Retrieval performance of number and types of representations
The results show that, with a few exceptions, overlaps generated by three or four representations have higher precision than those generated from two overlaps, or from the lists of unique remaining documents retrieved by the individual search fields, as a result of the quorum searching. This observation concerns both the structured and the unstructured natural lan-guage search mode ( Table 2 ). These findings support the overall principle of polyrepresentation suggesting that a high num-ber of different representations pointing towards a document are likely to be an indicator it being highly relevant ( Ingwersen, 1996 ).

However, the results also clearly demonstrate that the types of representations producing the best performing overlaps are central in polyrepresentation of information space. Observe, for instance, OL 3 in natural language querying ( P = 48%) and in structured querying for all relevant ( P = 79%)  X  the highest performance achieved. These results are due to the cognitive dif-ference between fields. The combinations of TI/AB, MJ and RF seem the most powerful ones, in particular those including RF (OL 1; OL 3 X 5; OL 10). On the other hand, precision drops when MN terms contribute to an overlap (OL 7, 11, and 14). The latter observation probably derives from the higher specificity of the MN terms, compared to the small size of the test col-lection, and hence its low performance. The same phenomenon of precision drop can be observed with respect to the com-binations of TI/AB terms. For both MN and TI/AB their individual retrieval results (and their combination; OL 7) are very poor, Table 2 . These findings stress the importance of using representations that are both cognitively dissimilar (e.g. RF vs. MJ
MeSH-headings: OL 1, 3, 10) and (strongly) functionally different (e.g. TI/AB vs. RF). Exactly because of their different func-tionality, owing to their temporal nature and serving as additional contextual  X  X  X escriptors X  of the article contents, the ref-erences become central to improving IR performance, as originally intended by Garfield (1979) when devising the citation indexes.
 One should also note that MJ combined with TI/AB provide better precision results than each field separately (OL 1 X 3 and
OL 6). Table 2 further shows the impossibility of applying mean average precision (MAP) performance measures owing to the diversity of number of retrieved documents.

These observations are valid across precision for  X  X ll relevant X  as well as  X  X ighly relevant X  P -measures. 4.2. Impact of query structure
For all 15 overlaps highly structured queries result in higher precision for  X  X ll relevant X  documents when comparing to queries in natural language ( Table 2 , column 3 and 4). This supports the findings of Kek X l X inen &amp; J X rvelin (1998) . From a polyrepresentative point of view this can be explained by looking at the two different query structures. The highly structured queries tend to ensure that documents identified in an overlap have identical or synonym search terms present from all the representations searched. In contrast, the natural language queries only require one search term from the query as such to be present. This is because the NL queries are treated as best match queries by InQuery. As a consequence the retrieved sets and overlaps between them include document representations with no or little relation to the information need. Therefore, it seems that polyrepresentation in the true sense of the concept is less likely to be achieved with weakly structured queries in natural language. 4.3. The re-ranking experiments in restricted polyrepresentation
In large scale databases ranking of highly relevant documents at the top of the search result is important to end users. For this reason we measure performance using cumulative gain (CG) rather than mean average precision as more emphasis is placed on the top-ranks in CG ( J X rvelin &amp; Kek X l X inen, 2002 ). Table 3 demonstrates CG performance with document cut-off value (DCV) = 30.

To decide whether differences in the CG figures are statistically significant we ran the non-parametric Friedman test, which is based on ranks. The test was based on normalised average CG vectors as suggested by J X rvelin &amp; Kek X l X inen (2002) . The Friedman test showed that search performance for baseline bag-of-words and runs 2 X 4 (weights applied to high precision overlaps) was significantly better than run 1 where no weights are applied (df = 4, p &lt; 0.05). In run 1 only the RSV given each document by InQuery determined the ranking. Documents from overlaps other than the inner one might thus be ranked high on the final output list. Results in Table 3 also indicate that run 2 , boosting the high-precision inner overlap doc-uments retrieved by 3 X 4 representation fields, constantly performs better than runs 3 X 6 over all DCV points. However, the differences are not statistical significant (probably partly caused by the small test collection). Comparing weighting accord-ing to polyrepresentation (runs 2 X 4) and InQuery X  X  own weighting of natural language queries (bag-of-words) shows no sta-tistically significant difference. Again run 2, however, performs better than the InQuery baseline from DCV = 5 documents over all 29 requests. This suggests that weighting according to the principle of polyrepresentation performs at least as well as InQuery X  X  standard bag-of-words weighting with respect to pushing relevant documents up the ranking list. 4.3.1. Ranking by citations
Results in Table 3 indicate a slight decrease in retrieval performance when applying citations (runs 5 X 6) as an indication of quality compared to the best run of weighted overlaps (run 2). However, the Friedman test showed no statistical signif-icance between the bag-of-words baseline and the two runs including citations. Table 3 further demonstrates that InQuery X  X  baseline results in top 15 outperform runs 1 and 3 X 6. The Cystic Fibrosis test collection does not include citation titles, but like references only a very short form is presented, and therefore citations are not used according to the principle of poly-representation ( Ingwersen, 1996 ) in the present study. In addition, because the volume of citations is small, re-ranking based on these is problematic and should be tested with much larger test collections in citation rich domains. 5. Discussion of future work and conclusions
With very few exceptions the presented experiments support the principle of polyrepresentation suggesting that a sub-stantial number of cognitively and functionally different document representations that simultaneously point towards a document is likely to be an indicator of it being (highly) relevant, thus providing improved performance in terms of preci-sion. The main finding suggests that successful polyrepresentative IR by combining document search fields seems to depend on (a) applying document representations as cognitively different as possible and (b) excluding poorly performing fields in the combinations, as observed in data fusion of retrieval engines ( Kwong &amp; Kantor, 2000; Wu &amp; McClean, 2006 ). Such a field, as the MN MeSH field in the present tests, decreases the combined performance in natural language as well as highly struc-tured query mode. It also seems to degrade the ability of the fusion to rank relevant documents high on the output lists.
Because of the Boolean nature of polyrepresentation, a strongly structured query language appears to be necessary when implementing the principle of polyrepresentation in a best match IR system. The results indicate that scientific references are an important type of representation in order to obtain high precision. Finally, re-ranking tests showed statistically significant improvements when weights were applied to high precision overlapping fields with respect to alternative re-ranking weighting methods. Polyrepresentation equals ranking performance confronting InQuery X  X  bag-of-words weighting scores.
Results from re-ranking test based on citation impact indicate a slight decrease in performance. But the citation volume ap-plied to the test bed was quite small.

The present experiments test the polyrepresentation principle in a conservative manner, i.e. in its restricted form. Future research could include work on combining the representations using semi-structured best match queries. Such an approach could retain some of the structure of the Boolean queries, while softening the rigidity of them. An alternative polyrepresen-tation approach is following a more relaxed mode. This implies to allow documents to appear (be repeated) in the overlaps and to include the sub-overlaps in the final rank list, as done in common data fusion of retrieval engines. The advantage is that the repetition allows for aggregating their RSV scores in a variety of ways that can be tested. One kind of aggregation corresponds to the CombSUM weighting scheme in data fusion ( Fox &amp; Shaw, 1994 ) and can be illustrated by Fig. 3 . The inner cognitive retrieval overlap of the four fields (OL 1) contains (few) documents for which their four assigned RSV will be aggre-gated. The documents found in the next level of overlaps (OL 2 X 5) then become mixed with the OL 1 list of documents according to their CombSUM scores, and so on until a DCV has been reached.

The Cystic Fibrosis collection mirrors scientific open access repositories that include  X  X on-author X  derived representations, such as index keywords, citation networks, the possibility of ontology and other added metadata. In more general and often heterogeneous collections, such as Web 2.0, enriched OPACs (Library 2.0), the semantic Web, several alternative sources of  X  X  X on-author X -based representations can be acquired and used. Among such are anchor texts or the entire text and other symbols or signs in Web pages linking to a specific web page, various forms of added context like peer-to-peer structures, social tags, reviews and recommendations of a web page or site. With an increased inter-(con)textuality of produced docu-ments the amount and weight of non-author representations will increase and become feasible from a polyrepresentative perspective. An important issue is that the principle of polyrepresentation should be tested on larger data sets. One possi-bility is the large collection of Medline records used by the TREC genomics track or the IEEE INEX collection. Also the test collection from the TREC web track would potentially be a possibility. This opens new ways of exploring polyrepresentation as anchor text and URL text can represent intra-document context and hyperlinks can represent inter-document context. In
Google Scholar tests of the citation-based ranking might likewise yield knowledge of how to explore polyrepresentation principles in IR.
 References
