 SPECIAL ISSUE PAPER Changsong Liu  X  Yu Zhang  X  Baokang Wang  X  Xiaoqing Ding Abstract This article discusses restoration of camera-captured distorted document images. Without the assistance of 3D data or model, our algorithm estimates and rectifies document warping just from 2D image based on line seg-mentation. Warping shape of each text line is acquired by estimating baselines X  shape and characters X  slant angles after line segmentation. In order to get fluent recovery result, thin-plate splines are exploited whose key points are determined through the result of warping estimation. Such process can effectively depict document warping and successfully restore warped document images to be flat. Comparison of OCR recognition rate between original camera-captured images and restored images shows the effectiveness of the algorithm proposed. We also demonstrate evaluation on DFKI dewarp-ing contest dataset with some related algorithms. Besides desirable restoration result, processing speed of the whole procedure is satisfactory as well. In conclusion, it is applica-ble to be performed in OCR application to achieve better understanding of camera-captured document images.
 Keywords Baseline fitting  X  Distorted document images  X  Line segmentation  X  Thin-plate splines 1 Introduction Document images are traditionally acquired by flat-bed scan-ners for optical character recognition (OCR) processing. The prevalence of digital cameras in recent years makes it much more common to shoot document images rather than to scan them.
 Such trend brings about big challenges to traditional OCR techniques. Unlike scanned document images that are acquired in flat-bed style with good lighting, camera-captured document images are usually distorted due to non-planar page shape or perspective distortion with uneven light-ing. Generally, traditional OCR applications cannot handle such deterioration.

A document image will firstly be binarized and segmented by OCR applications in order to extract text regions; then characters will be separated for recognition. Uneven lighting often brings about difficulties for image binarization because multiple binarization thresholds need to be identified for dif-ferent image pixels to adapt different luminance on the page; otherwise, noise might arise on the binarized image. There are several approaches [ 1  X  3 ] that solve binarization problem with uneven lighting.
 Distortion reduces accuracy of the segmentation process. In traditional cases, texts in flat documents are well aligned horizontally or vertically. Therefore, it is reasonable to use methods based on projection to perform segmentation because the projection X  X  peak-and-valley shape can effec-tively reflect the distribution of text lines and characters in certain direction. In distorted cases, however, text lines are usually slant or curved. As a result, horizontal or vertical projection would no longer provide effective evidence and the traditional segmentation methods may result in wrongly segmented lines and characters. Figure 1 shows such a com-parison of horizontal projection between flat and distorted document images. Since the segmentation may be incorrect, character recognition would not probably have high accu-racy.

This article mainly focuses on the problem of distortion in camera-captured document images. The approach in this article tries to recover the distorted image to be flat. There-fore, the restored image can be segmented and recognized by traditional applications. It is worthwhile to highlight two contributions of this paper: (1) The proposed algorithm esti-mates document warping just from 2D image and achieves recovery in the absence of 3D data and model limitations or other information. (2) In addition to good restoring perfor-mance, the running speed has reached the available magni-tude, so that it can be effectively applied to OCR applications to accommodate camera-captured documents images. 2 Related work 2.1 General procedure A great many methods that are focused on document image dewarping have been proposed in recent years. Most of them perform shape estimation first and then restore the image through the estimation result.

Generally, it is natural to divide the whole procedure into estimation step and restoration step. Different approaches could show difference in either one or both of the two steps. 2.2 Shape estimation Shape estimation aims to estimate or describe document image X  X  distortion in an effective way. Existing approaches can be classified into two categories according to their esti-mation type: 3D method and 2D method.

Three-dimensional method could be further divided into two kinds. One tries to acquire 3D shape of the page, whether using a model or directly getting it. Cao X  X  method [ 4 ] defines a cylindrical surface model on the assumption that warping is cylindrical. The page X  X  shape is then estimated by analyzing text line direction and applying the model into the original 2D image. Zhang et al. define a luminance model [ 5 ]ofthe page X  X  surface, which is called shape-from-shading model. Such model analyzes the luminance in different position of a page under the assumption of parallel lighting. Using shape-from-shading model, we can estimate each pixel X  X  3D posi-tion in a curved document image based on its gray level. In some special cases [ 6 ] such as ancient manuscript restoration, 3D camera is used and 3D shape of a page can be acquired directly.

All above 3D methods have restrictions in their applica-tion. Cylindrical surface model assumes the page is warped in a shape of generalized cylinder and requires the curved document X  X  generatrix parallel to the image plane.
The other 3D method calculates the mapping from the surface to the 2D projection. Similarly, luminance model defined by Zhang et al. needs the page to be placed in a cylindrical shape and the parallel light X  X  direction should be known. Although method of 3D camera does not confine any distortion shape or need certain parameters, the specific pho-tographic device itself is a big restriction. In recent work, Liang et al. [ 7 ] use neighborhood projection and directional filtertoestimateeachpixel X  X horizontalandverticaldirection. Meng et al. [ 8 ] propose a metric rectification method to con-struct an isometric image mesh by exploiting the geometry of page surface and camera. They use a general cylindrical surface (GCS) to model the curved page shape. It derives a global image transformation by constructing an isometric imagemesh.Heetal.[ 9 ] propose a book boundary-based model that first extracts book boundary; then a 3D book sur-face is reconstructed. Finally the horizontal and vertical met-rics of each column are restored from it.

Unlike 3D method, 2D method does not tend to get real 3D surface shape of a document. It just estimates the text X  X  distribution on the 2D image for restoration. The most impor-tant information which is used in 2D method is the text line flow and character erection direction. Therefore, most 2D method tries to estimate such two kinds of information and presents them in different ways. Lu X  X  method [ 10 ] estimates page X  X  warping by fitting baselines and extracting vertical strokes of text and represents the warping by dividing the image into small grids through the estimation result. Gatos X  method [ 11 ] first performs a word and line segmentation on the binary image and estimates each word X  X  slant. The overall warping is represented by the neighborhood relationship of each line. Masalovitch et al. [ 12 ] first approximates defor-mation of interlinear spaces of image based on elements of image X  X  skeleton; then the whole image deformation is acquired by combining single interlinear spaces deformation represented in the form of 2D cubic Bezier patch. Bukhari et al. [ 13 ] proposed a novel dewarping approach based on curled text lines information, which has been extracted using ridge-based modified active contour model (coupled snakes). The same author explained curled text line segmentation method in detail in [ 14 ]. Bin Fu et al. [ 15 ] proposed a book dewarping model based on cylinder assumption. The main idea of the model is to build up the correspondence between a rectangle region on a flat surface and its curved region on the distorted book image, and the dewarping task is to flatten the curved region to its original rectangle shape. Recently, Hsia et al. [ 16 ] proposed a method based on text rectangle area segmentation which is a fast method. Stamatopoulos et al. [ 17 ] address the projection of a curved surface into a 2D rectangular area. The projection of the curved surface to the plane is guided only by the textual content X  X  appearance.
Because no model or parameter is needed, these 2D meth-ods can process arbitrary types of warped images. 2.3 Image restoration The restoration is quite different between 3D method and 2D method.

Since 3D data are acquired in 3D method, the mapping between original flat page and the warped projection can be decided. Then the image is naturally restored to be flat. Dif-ferent types of 3D data representation or model will make different ways to decide the mapping. Whereas the key of 3D method is how to define a model and acquire 3D clues in an image, which makes different method X  X  mathematical expression in various forms. Essentially, different 3D meth-ods [ 4  X  6 ] are the same in restoration.

There are several different types of restoration in 2D meth-ods. Because there is only warping information about text distribution in 2D image such as the baselines X  shape and characters X  slant, the goal is to make such clues to seem like arranged in a flat page after restoration. In other words, the restoration of 2D method does not tend to restore the dis-torted image as it originally is, but aims at restoration result that can be processed by traditional OCR application.
In Lu X  X  method [ 10 ], each grid is transformed and reg-ularized into a square with uniform size and then pieced together to form the full page. This method seems to seg-ment the page into too many pieces, which makes it diffi-cult to be mosaicked. Similarly, Gatos X  method [ 11 ] rectifies each word X  X  slant with an affine transformation and pieces all words together line by line to guarantee each word and line is horizontal. This method segments the image in a reasonable way, whereas the segmentation and restoration is so rough that it can only process some simple slight warping cases. Liang X  X  work [ 7 ] calculates rulings of a page on the image based on text flow estimation result and then restores the full image by stripes divided from the rulings. It is the best in arbi-trary shape cases; however, it seems to be too complicated and no data about the algorithm speed are reported. Hsia X  X  work [ 16 ] uses the DLT method to compute the mapping relations between the warped document and the non-warped document. These methods all divide the whole image into small parts and restore each part with a projective transfor-mation. The difference between them is the ways to divide image and decide parameters in transformation matrix.
Compared with 3D methods, 2D methods are obviously more flexible to use, at the same time much easier in estima-tion and restoration. As a result, a 2D method is adopted in this article. Present model-free dewarping methods mainly focus on shape estimation stage, and various curled text line segmentation methods have been put forward. Parts of approaches directly estimate distorted shape of text block or paragraph by either rectangle area or other geometric model [ 15 , 16 ], but information inside text lines and characters is thus ignored which leads to estimation error when text block borders are not so clear. Some proposed methods combining curled line segmentation and baseline estimation, for exam-ple, by coupled snakes [ 14 ]. The information of every con-nected components along with its neighboring elements is exploited, and text line shape estimation is free of any curve model, but its computational cost is too high to be applied in real OCR applications, while digging into local connected components structure could bring about inconsistent distor-tion estimation due to shape variations in local area. To make a tradeoff, we carry out text line segmentation by specialized connected components clustering, and baseline is estimated by piecewise linear regression, achieving a good balance between restoration effect and running speed. Experiments show that our method reached state-of-the-art performance. 3 Approach 3.1 Overview This article presents a segmentation-based approach. Similar to Gatos X  work, this approach performs text line segmenta-tion first. Text lines X  curve is the most obvious evidence to estimate a document image X  X  warping shape. Therefore, line segmentation step is useful for shape estimation step. In order to be capable of processing more complex cases than Gatos X  approach, a cluster algorithm is performed in order to classify connected components into text lines correctly.

After line segmentation, we can simply regard the restora-tion problem as estimating baselines of all text lines and straightening them. Besides baselines, this approach also estimates and rectifies slant of characters.
A global interpolation method is adopted in restoration step. Such method avoids the problem of grid piecing in oth-ers X  work. The restoration result is then naturally smooth and continual. 3.2 Warped line segmentation It is mentioned that traditional projection method is not suit-able for segmentation of warping documents. Restoration approaches concerning line segmentation [ 11 ] usually ana-lyze centroids and bounding boxes of neighbor connected components from left to right to form text lines. However, there might be errors when distortion is violent.

Intheproblemofhandwritingdocumentprocessingwhere text may not be orderly distributed on a page, cluster method is applied. Similarly, a directional connected components cluster method is presented in this article.

First of all, a preprocessing step should be taken to support efficient clustering and segmentation. The whole procedure is illustrated in Fig. 2 . Erosion is first performed to input binary image to smooth the borders of connected compo-nents and eliminate small noise. In general, the structuring element is set to be a square of side length 3px. Then the image will be filtered to eliminate tiny connected compo-nents such as punctuations, small strokes and noise. Such tiny connected components may bring ambiguities to seg-mentation; therefore, it is better to filter them out and assign them to segmented text lines later. To handle documents with different character sizes, we first calculate the average den-sity and average height/width of all the connected compo-nents, denoted as Avg_D and Avg_H/Avg_W , respectively, and the filter parameters are then determined by these statis-tics. Based on the experimental results, we remove connected components with both density less than Avg_D/4 and height less than Avg_H/2 . Finally, for most English text that con-tains many characters in a page and has the unit of word, successive characters can be first blurred to make characters in a word attached together into a single connected compo-nents. For Chinese documents, as there are no spaces between words, we perform simple neighborhood connected compo-nents merging instead of blurring. Therefore, computation of cluster will be greatly reduced. The kernel size of blur operation is set to be Avg_W/2. A sample of preprocessing is shown in Fig. 3 . Such preprocessing to the connected compo-nents will enhance accuracy of the algorithm and accelerate the clustering procedure.

Cluster is then performed to make connected components nearby clustered into a same text line, and those far away are classified into different text lines. In warped document images, however, connected components in different text lines might be very close in 2D geometric position because of page distortion. Therefore, we should not just use simple Euclidean distance as cluster distance. Instead, a new type of distance is defined to reflect neighborhood relationship of connected components directionally. Such definition of dis-tance tries to shorten the distance between nearby connected components in the same text line and enlarge the distance between connected components in different text lines. A sim-ple example is shown in Fig. 4 : the distance of (a) to (b) and (c) to (d) should be small while the distances between any other two connected components should be large according to the aim of the definition.

Lines over each connected components in Fig. 4 represent directions of connected components, which are determined by the minimum bounding rectangle (MBR) of each con-nected component. Main direction of the MBR can better describe the direction of a connected component here than the principle component direction obtained by principle com-ponent analysis (PCA) because characters containing holes, ascenders or descenders make the connected components not uniform in density, whereas their outer edges X  shape reveals the directions. The MBR of connected component can be acquired by Cheng X  X  algorithm [ 18 ], and then the direction of the connected component is decided.

A vector connecting two connected components repre-sents their relationship in location. Since neighboring char-acters are blurred to form a wide connected components, only part of each connected components is used to form these vectors. For two connected components, centroids of horizontally nearest sections with a width of one character are determined as vertices of the vector between them (as Fig. 5 shows). The vector X  X  length and direction can totally indicate the location relationship between the two connected components.

Given two connected components X  direction and the vec-tor between them, the distance is then defined as: d = l where l is the length of the vector between the two con-nected components, and  X  L is the direction of the vector;  X  and  X  2 are directions of the two connected components, respectively;  X  is a small value to avoid the denominators being zero.

Such a definition guarantees small clustering distance for neighboring connected components arranged in the same line with uniform direction and large clustering distance vice versa.

Cluster is then performed. A minimum spanning tree (MST) [ 19 ] is built for the cluster. By breaking first n -1 largest edges of the tree, n clusters are naturally formed with one cluster representing a segmented text line. When build-ing the MST, we can use Prim algorithm [ 20 ] to accelerate the process.

Partial projection is utilized to decide the number of clus-ters. As Fig. 6 shows, we perform partial horizontal projec-tion to different part of the document image and then select the largest number of the projection peak as the line number. Therefore, the cluster number of the sample shown by Fig. 6 is 17. When counting text lines in a document, human beings usually select the densest vertical stripe and count from top to bottom instead of analyzing global shape of the text lines. So it is reasonable to use partial projection to determine the number of text lines.

After blurred connected components are clustered, origi-nal connected components can be divided into different text lines according to the cluster result. Tiny connected compo-nents that were filtered out in the first step are allocated to text lines nearest to them. 3.3 Distortion shape estimation The following process tries to extract useful information about distortion from line segmentation result. Baselines are the most obvious clues that reflect the text lines X  flow. As a result, baselines are fitted here. In addition, characters X  ver-tical slant is also estimated to describe local character distor-tion. 3.3.1 Baseline fitting Baseline is the line upon which most letters  X  X it X  and below which descenders extend [ 21 ]. Baselines can be explicit or implicit in a document, and characters in a text line are arranged along a same baseline. Also there is a mean line corresponding to a baseline: It indicates the upper boundary of non-ascending lowercase characters. In this article, only baselines are fitted and mean lines are acquired by adding a distance of one character X  X  height on corresponding base-lines.

Baselines are straight lines if the document image is flat, and they can be easily estimated by projection method. However, when the document is warped, baselines become curves and the projection method does not work as mentioned before. Therefore, envelope analysis and curve fitting should be performed to estimate baselines.
 Figure 7 a shows part of a text line X  X  lower envelope. Because the bottom shape of each character is not flat and fixed, lower envelope of a text line is not smooth locally. However, it can reflect text line X  X  flow globally by its rough shape.

It is important to extract useful information from lower envelopes to fit baselines. Because characters are  X  X itting X  on baselines, lowest pixels of characters are usually located on baselines except for possible descenders. Therefore, neigh-borhood lowest peaks, which correspond to lowest pixels of characters, are extracted as clues for baselines. Dots in Fig. 7 a are such points extracted from the lower envelope.
Then baselines are fitted through these points (as Fig. 7 b shows). Fitting should reflect arbitrary shape of baselines and eliminate the influence of outliers that are brought about by descenders.

Since it requires that the fitted baselines should be valid in arbitrary warping situations, polynomial fitting is not very suitable because we cannot decide the degree of the polyno-mial. As Fig. 8 shows, the warping shape is abnormal and the polynomial degree is hard to estimate. Too little degree leads to wrong or inaccurate estimation, while too large degree leads to overfitting. In conclusion, polynomial fitting lacks flexibility, sometimes it is hard to estimate correct fitting results, and it is relatively time-consuming. Approximately, baselines canberegardedas straight inlocal areas evenif they are curved, and that is always true in all cases. A neighbor-hood linear fitting is therefore more reasonable, and in addi-tion, it is simpler and faster. Figure 9 shows the process of the neighborhood linear fitting. A text line is divided into several sections, and each of them is fitted by a straight line. There are overlaps between neighboring sections, and therefore, we can get a curve by smoothing fitting results in neighboring sections. Width of the divided section reflects precision of the fitting; it should not be too large, and in practice, it should not be too small either. In a warped document, most text lines go relatively smoothly with mild curvature variation. As Fig. 6 shows, all the text lines are equally segmented into nine fragments, and each fragment shows approximate linearity. In this approach, the segmentation width is set to be 1/10 of page X  X  width according to the analysis above to ensure piece-wise linearity. To make a trade-off between smooth-ness of the whole text line and segmentation number (e.g., the computational complexity), half width of each fragment overlaps with neighboring fragments. As the overlap areas of two adjacent fragments are composed of same points, we simply take the average estimation result as the final result for the overlap area.

In order to eliminate the influence of outlier points such as noise and character descenders, the fitting method should be robust. Commonly, RANSAC algorithm is used to deal with outliers, yet least median square (LMS) algorithm [ 22 ] is reported to have slightly better performance in [ 23 ]. So we adopt LMS for neighborhood linear baseline fitting. By randomly selecting two points iteratively, many line para-meter candidates are formed; the goal of LMS is to achieve minimum median error, and thus, single or small amount of outliers would not affect the final estimation of line.
Mean lines are acquired as a byproduct of baselines by adding a neighborhood average character height to baselines. Mean lines may not be parallel to corresponding baselines because of distortion, and they should be restored as parallel straight lines.

All in all, the overall process of baseline fitting is listed in the following: 1. For each segmented text line, extract the bottom enve-2. Initialize baseline and mean line as: 3. Collect a set of successive peak points on bottom enve-4. Perform LMS algorithm to fit a straight line using peak 5. Set value to baseline f ( x ) in [ x 1 , x 2 ] , which can be 6. Calculate average height of characters in [ x 1 , x 2 ] 7. Start from the middle point from the point set and collect 8. Smooth the fitted baseline and mean line in order to
Figure 10 is the result of a sample of baseline and mean line fitting. There is a text line that has no fitting result due to segmentation error. Besides this, all other text lines X  baselines and mean lines are correctly fitted. It is acceptable that few text lines are wrongly segmented or missing fitting results if most text lines X  baselines and mean lines are acquired as this case because the fitted baselines are able to provide enough clues to reflect the page X  X  shape. 3.3.2 Vertical direction estimate Except for curve of text lines as a whole, character itself may be slanted. Restoring text lines to be straight eliminates hor-izontal slant of characters naturally. However, vertical direc-tions of characters still need to be estimated and rectified.
Vertical directions can be estimated by extract vertical boundaries of characters [ 24 ]. Previous work [ 25 ]ofthis project also adopts a similar method. However, extracted vertical boundaries may not be uniformly distributed on the image and there might be extraction errors in practice. There-fore, sometimes such vertical boundaries could not describe characters X  vertical slant well.

It is observed that the arrangement of neighboring charac-ters in a text line can also reflect slant of characters because gaps between characters have the same direction as vertical strokes. In other words, by performing projection to a series of successive characters, we can get a most obvious peak-and-valley shape projection on their vertical direction. Such projection shape can be scaled by its variance. Taking Fig. 11 , for example, vertical projection of words with direction (a) has the most evident peak-and-valley shape and largest vari-ance as a result.

The process of vertical direction estimation is sketched in Fig. 12 . Groups of successive characters in a text line are analyzed in different angles. A character group is rotated and vertically projected, and the angle with largest projection variance is decided as the slant angle of characters in the group. The division of character groups is similar to that of baseline neighborhood linear fitting to get a smooth result. Figure 13 shows a result of vertical direction estimation. Each straight line represents a vertical direction of the char-acter below it. The estimation is correct and easy to perform.
It should be mentioned that for Chinese documents, strokes contain less curves and that most strokes lie in hor-izontal or vertical directions linearly, which provides even more clues for baseline fitting and vertical direction estima-tion. As a result, the proposed algorithm of distortion shape estimation can achieve even better results on Chinese docu-ment images. 3.4 Image restoration through thin-plate splines After distortion shape is estimated, we should then restore the image. A thin-plate spline (TPS) method is used to perform interpolation.

Thin-plate splines [ 26 ] is an interpolation method to cal-culate coordinate mappings from R 2 to R 2 . Given several key points X  mapping from original image to final image, TPS algorithm can give all points X  new coordinate in final image in the same time keeping the given key points X  mapping rela-tionship. TPS interpolation assumes that the image is a soft  X  X hin plate, X  which means the moving of a point will bend all the plate as one pulls a point of a piece of cloth. There-fore, TPS algorithm is suitable to deal with warped images if enough key points X  new and original coordinates are con-firmed. In addition, because it is an interpolation algorithm on the whole image, TPS can keep the neighborhood rela-tionship of the original image in the new image.
It is important to determine key points and their mapping for TPS. Once they are determined, we can calculate a pixel mapping relationship between the original image and the new image, and then we know each pixel X  X  gray level in the new image to get an interpolation result. Such key points are on baselines and mean lines in distorted document images. Their mapping are the position where they should been in if the document were flat.

In detail, as shown in Fig. 14 , key points are evenly located on the baseline and mean line of each text line. Red curves in Fig. 14 represent baseline and mean line, and dots over them are key points. As to their mapping points, they are marked as crosses in Fig. 14 and in a same horizontal straight line if they are from a same baseline or mean line originally. The mapping also considers vertical slant. Red short lines in Fig. 14 represent characters X  vertical directions, and each key point onthemeanlinewill begivenahorizontal displacement decided by its nearest character X  X  vertical slant.
Mathematically, if there are n key points in both base-line and mean line of a text line, and they are denoted as ( xb baseline and ( xt 1 , yt 1 ), ( xt 2 , yt 2 ),...,( xt n , on the mean line, the expressions of these key points X  coor-dinates are as follows: where left is the leftmost horizontal coordinate of the baseline and mean line, and W is the width of the baseline and mean line.

The key points X  mapping points ( xb 1 , yb 1 ), ( xb 2 , yb ...,( xb denoted as: xb i = xb i yb i = yb 1 xt i = tan (  X   X  i )  X  xheight + xt i yt i = yb i  X  xheight where xheight is the average distance between the baseline and mean line, and  X  i is the slant angle of the character nearest to the key point ( xt i , yt i ) .

Such selection of key points and their mapping guarantees that baselines and mean lines in the restored document image are straight and that characters are rectified for their vertical slant.Therefore,theimageseemstobeflatafterinterpolation.
As for the interpolation speed, the TPS algorithm mainly consists of two steps: The first is to solve the parameters for interpolation, and the second is to calculate the mapping for each pixel using these parameters. The first step solves a linear system of equations of ( n + 3 ) division if there are n key points, and the second step interpolates each pixel as f ( x , y ) = a where a 1 , a x , a y and  X  i are the parameters to be solved, and ( x , yi ) is the i th key point X  X  coordinate. U is the basis func-tion of the interpolation. The solving of the linear system has a time complexity of O (( n + 3 ) 3 ) , and the interpolation of all m pixels requires m  X  n times of multiply-add operation.
To speed up the algorithm without decreasing the num-ber of key points, approach in the article divides the image into pieces and perform TPS interpolation separately. If an image is separated into m parts and each part contain n / key points, the whole time to solve the linear system reduces from O ( N 3 ) to O ( N 3 / m 2 ) .

Figure 15 sketches process of the interpolation. Line seg-mentation in previous step divides an image into parts. Natu-rally, we interpolate the whole image line by line separately and then piece them up by sequence in the end to get a full restoration result. Such a division is easy to perform and keeps fluency of connected components in the same text line. The result is then ready to be recognized by traditional OCR applications. 4 Experiments 4.1 Evaluation method After a distorted document image is restored by approach mentioned above, experiment and evaluation about the approach will be given.

First, we autonomously selected a set of real camera-captured distorted images for the experiment. As most approaches in others X  work do, this article compares recog-nition rate before and after the restoration. The more the recognition rate enhances, the better the restoration is. Eng-lish samples are adopted here, and we use OmniPage v17.0 to perform recognition. What X  X  more, we evaluated our algo-rithm along with some state-of-the-art document dewarping methods on DFKI dewarping contest dataset that consists of 102 warped document images. Running time is also evalu-ated. The results show that our approach reached a relatively effective and efficient level, which can be adopted to camera-OCR applications (Figs. 16 , 17 ). 4.2 Experimental results For the basic evaluation, 23 English document images are selected and classified into different categories according to the degree they are distorted. Seven images are greatly dis-torted, while six images just have slight distortion on page borders. There are also five images with planar perspective distortion and five images that are basically flat for compar-ison. Figure 18 shows four typical images of the different categories, and their restoration results are shown in Fig. 19 . Table 1 shows the statistical results of the recognition rate. For samples that are greatly distorted or with planar distor-tion, the algorithm acquires large enhancement on recogni-tion rate; for those just distorted slightly, the algorithm can rectify distortions on the edge and because characters there are just small part of a whole page, the enhancement is not that big; and for flat document images that can be processed well by traditional OCR applications, the algorithm will not bring about too much influence. As a whole, the restoration will bring positive effect to camera-based OCR.

We also performed evaluation on a DFKI dewarping con-test dataset that consists of 102 warped document images. This dataset is freely available with ASCII text ground-truth. The images are somehow more complicated as many of the images contain figures, tables or shadows of page border. Considering the mechanism of our approach, we first removed all unrelated parts of the document to fit our algorithm. As rectification results of some other methods have been published, to be fair, we use a unified eval-uation measure-recognition rate to judge all the involved approaches. Methods for comparison are SEG [ 11 ], SKEL [ 12 ], CTM [ 15 ], CTM2 [ 15 ] and Snakes [ 13 ].
The rectified documents of all methods are processed through OmniPage v17.0. Then recognition rates of all rec-tified images are evaluated. Table 2 shows the results of all involved approaches with respect to overall recognition rate, median recognition rate and the number of documents for each method on which it has the best recognition rate. The number in bold indicates that our algorithm shows the best overall recognition performance.

As the table shows, with respect to overall recognition rate, our algorithm outperforms all the other methods, which instructs that our algorithm achieves the best restoration per-formance on all images in DFKI dataset as a whole. But for median rectification rate and number of best-performance documents, our approach gives slightly less effective results than CTM \ CTM2 does, meaning that it shows greater robust-ness on various documents but may not provide the most accurate restoration. Figure 16 shows an recognition results summary which indicates that our algorithm reached state-of-the-art performance:
For every algorithm, three dots represents the recognition rate of one quarter position, median position and three quar-terspositionofalldatasets,respectively.Itisobservedthatthe one quarter position of proposed method and CTM \ CTM2 are all around 95%, indicating that for most warped docu-ments, our algorithm could give a reasonable and appropriate solutions.

Estimation and interpolation algorithm speed are related to image size. Sizes of images in this experiment vary from 400,000 pixels to 6,000,000 pixels, and the average size is 2,200,000 pixels. There are also image size and processing time labeled in Fig. 19 . Images are processed by a computer with CPU of Pentium IV 2.8GHz and 1GB memory. It costs 138s to process all 23 images with about 6s per image. Such speed is acceptable in a common PC. We also evaluated run-ning time on all images in DFKI dewarping contest dataset, the time distribution can be figured in Fig. 17 .

Most images can be processed in 2 X 5s, and the average running time of the proposed algorithm is 3.395s. 5 Conclusion In this paper, a segmentation-based approach and TPS algo-rithm are introduced in order to restore distorted document image. In order to be applicable in arbitrary warping cases, local shape of different positions on an image must be esti-mated with least constraint. Therefore, baselines and vertical directions are estimated locally to reflect local shape. TPS interpolation method is used in order to keep neighborhood relationships. The experimental results above prove its effec-tiveness on arbitrary warping cases, and the processing speed is acceptable.

The process this article uses is a framework to restore distorted document images using 2D method. The process can be divided into three parts: segmentation, estimation and restoration. Each part can be improved separately in order to get more accurate restoration result.

In addition, the process itself can be changed by combin-ing the approach with traditional OCR applications. It can be added into the traditional OCR process of segmentation and recognition. That is to say, we can perform line segmenta-tion, make restoration and recognize a single text line without piecing then together and performing segmentation again. References
