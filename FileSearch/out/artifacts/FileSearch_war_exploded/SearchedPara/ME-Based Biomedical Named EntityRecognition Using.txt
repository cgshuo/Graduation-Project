 KYUNG-MI PARK, SEON-HO KIM, and HAE-CHANG RIM
Korea University and YOUNG-SOOK HWANG Advanced Telecommunications Research Institute (ATR) 1. INTRODUCTION
Biomedical named entity (NE)-recognition task can be divided into two phases: the term-recognition phase, which identifies the boundaries of terms for a given sentence, and the semantic-classification phase, which determines semantic classes of terms. By adopting the two-phase method, we can alleviate the unbalanced class distribution problem in a multiclass classification task, be-cause we can decrease the number of classes [Lee et al. 2003]. To identify the boundary of a term in the term-recognition phase, we assign only one of two ( TERM , O ) or three ( B TERM , I TERM , O ) classes to words, and classify only the recognized terms into a proper semantic class in the semantic-classification phase. We can also construct different feature sets relevant to each phase.
Since features for recognizing terms are different from features for classifying a semantic class, we can consider different feature sets appropriate for each task.

In this paper, we present a two-phase biomedical NE-recognition method based on a maximum-entropy (ME) model. In the two-phase NE-recognition method, the performance of term recognition is critical to the overall perfor-mance of the system because term-recognition errors can be propagated to the semantic-classification phase. In this paper, we propose a lexical knowledge-incorporated method to improve the performance of term recognition. We uti-lize domain-salient words and collocations as lexical knowledge extracted from raw corpora. In addition, we use morphological patterns extracted from train-ing data. In order to extract lexical knowledge for biomedical NE-recognition, we use external resources such as the WSJ and Medline corpora.

As shown in Figure 1, the proposed NE-recognition method consists of three-step term-recognition and a semantic-classification phase. In the preprocess-ing step, input sentences are part-of-speech (POS)-tagged and noun phrase (NP)-chunked, and then the noun phrases called salient NPs that include biomedically salient words are detected. In the boundary-identification step, one of B TERM , I TERM ,or O class is assigned to words in the salient NPs.
In the postprocessing step, in order to reduce term-recognition errors, we ex-tend a term boundary by using collocation information. Finally, we classify the identified terms into protein , DNA , RNA , cell line ,or cell type in the semantic-classification phase.
 We use different feature sets for the recognition and the classification phase.
In the term-recognition phase, we focus on orthographical features to distin-guish term words 1 from nonterm words, 2 because most of the biomedical term words have characteristics of including capital letters, digits, symbols, greek letters, gene sequences, or specific prefixes/suffixes. For semantic classification, we focus on lexical features to determine whether the recognized term is pro-tein , DNA , RNA , cell line ,or cell type , because the clues for NE class tagging are words themselves constituting a term rather than the words located in the left or the right context of terms.

The remaining part of this paper is organized as follows: In Section 2, we explain the maximum-entropy model. In Section 3, we describe the proposed method of two-phase biomedical NE recognition. In Section 4, we explain an automatic extraction method of lexical and morphological knowledge. We show some experimental results in Section 5, and analyze errors from our recognition results in Section 6. Finally, we discuss previous approaches in biomedical NE recognition in Section 7, and conclude the paper in Section 8. 2. MAXIMUM-ENTROPY MODEL
In the maximum-entropy framework, the conditional probability of predicting an outcome o given a history h is defined as follows: where f i ( h , o ) is a binary-valued feature function,  X  p ( o | h ) = 1 [Berger et al. 1996].

In this study, the probability P ( o | h ) is calculated by the weighted sums of active features (i.e. f i ( h , o ) = 1). For instance, a feature for our task can be represented by an indicating feature function, as follows:
It means that a target word is likely to be the beginning of a biomedical term, when the word includes a Greek letter, such as kappa .

The maximum-entropy classifier for the term recognition phase classifies each word into one of the following classes: B TERM class representing the beginning of a biomedical term, I TERM class representing a part of a biomed-ical term, or O class indicating that the word does not belong to the biomedical term. The maximum-entropy classifier for the semantic-classification phase classifies the recognized term into one of the following classes: protein , DNA ,
RNA , cell line , cell type . The set of feature functions for each task is described in the Section 3. 3. TWO-PHASE BIOMEDICAL NE RECOGNITION
The proposed two-phase NE-recognition system is outlined in Figure 2. 3.1 Preprocessing
Most biomedical terms exist in noun phrases and the words constituting biomedical terms scarcely occur in a general text. Therefore, for recognizing biomedical terms, we do not need to examine all words in a sentence. In this study, we restrict the search space only as noun phrases, which include at least one biomedically salient word.

If some words occurred more frequently in a domain-specific corpus than in a general corpus, we regard the words as domain-salient words. Most term words in the biomedical domain, such as NF-kappa , scarcely occur in a general text. Therefore, salient words can provide useful information for spotting the probable noun phrases, which include domain-specific terms. In Figure 1, the italicized words such as leukemia , cell , continuous , GR , assay , correlated , sen-sitivity , cell , glucocorticoid , steroids , and vitro are regarded as salient words. These salient words can be retrieved through corpus comparison.
 We call the noun phrases that include biomedically salient words salient NPs .
In order to find salient NPs, we first identify noun phrases by using POS tagger [Brants 2000] and NP chunker [Kudoh and Matsumoto 2000], and then per-form salient NP spotting by using salient word lists extracted through corpus comparison. By filtering the salient NPs, which may contain term words, we can decrease the number of irrelevant target instances and reduce the training cost.
 3.2 Boundary Identification
In this step, the boundaries of biomedical terms in salient NPs are identified. In order to train the ME model for the identification task, we consider the following features. word : we use five words: the target word, left adjacent two words, and right adjacent two words.

POS : we use POS of the above five words. prefix/suffix : we use morphological patterns of the above five words. Mor-phological patterns reflect orthographical characteristics of words, as prefix and suffix. In case a target word infrequently occurs in the training data, mor-phological patterns can alleviate the data sparseness problem of the word.
Especially, when a target word is constituted by only lower letters, a mor-phological pattern such as -ase can become a useful information to indicate whether the word is a term word or not. gene sequence : this binary feature indicates whether a target word repre-sents a gene sequence or not. If the length of a word is larger than three, and the word is only constructed with A , C , G ,or T , we regard the word as a gene sequence.

Greek : this feature indicates whether a target word includes a Greek letter such as alpha , beta ,or kappa , or not. beginning word : this binary feature indicates whether the target word is the beginning word in a sentence or not. capital start : this binary feature indicates whether the target word starts with capital letter. With the beginning word and capital start features, we try to determine whether the target word that starts with capital letter is the beginning word in a sentence or not.

We train the ME model with these features. In Figure 1, the italicized words such as leukemia , cell , lines , GR , and lines correspond to B or I TERM . 3.3 Postprocessing
In order to reduce term-recognition errors, we use collocation information. If the words occur outside the boundary and have a collocation relation with words inside the boundary, we assume that the words outside the boundary are term words. In general, since words such as binding , class , receptor , response , and signaling are frequently used as both a term and a nonterm word, it is difficult to determine whether the words become a term word or not. The collocation information can be useful to identify whether the words frequently used as both a term and a nonterm word are term words or not. We recursively extend a term boundary only when the word inside the term boundary and the word outside the term boundary have a collocation relation (i.e., the word outside the boundary is merged into the term). In Figure 1, a bigram cell lines is identified as a collocation and cell is merged into the term. 3.4 Semantic Classification
In this phase, a proper semantic class is assigned to the recognized term. order to train the ME model for the classification task, we use the following features. word : only four words from the rightmost of the recognized term are used as features. The words themselves constituting the recognized term play a significant role in classifying the term into protein , DNA , RNA , cell line ,or cell type . Specially, the functional term words play a key role in classification.
For example, the functional term words, such as factor , receptor , and protein , are very helpful for classifying a given term into protein . Functional term words, such as gene , promoter , and motif are very useful clues for classifying
DNA [Lee et al. 2003]. In general, functional term words are often located in the rightmost of a term. Thus, we use only words on the rightmost of the term as features. prefix/suffix : we use morphological patterns of the above four words. word variation : we also use four word variations like word features. To make a word variation, we alter all capital letters to lower letters and sub-stitute  X  #  X  for numbers. Also, for segmenting words into two parts, we regard a symbol like a hyphen as blank. Among the parts of the target words, we select the longest part as a word variation, which may contain more useful information. For example, ( IL-2 ) changes to ( il # ) using the above-mentioned rules and ( il ) is extracted as a word variation.

In Figure 1, the recognized terms leukemia cell lines , GR , and cell lines are classified into cell line , protein , and cell line class, respectively. 4. AUTOMATED EXTRACTION OF LEXICAL KNOWLEDGE
In this section, we describe an automatic lexical knowledge extraction method for biomedical NE-recognition. First, in order to perform salient NP spotting, we extract salient words through corpus comparison between a domain-specific and a general corpus. We use the WSJ corpus as a general corpus. In order to obtain features for ME learning, we next extract morphological patterns based on relative entropy. Finally, in order to perform the term boundary extension, we extract collocations by applying the chi-square test from a very large Medline corpus. 4.1 Salient Word Extraction
In order to extract salient words occurring more frequently in the training than in a general corpus, we compute each word X  X  probabilities both in the training and in a general corpus, respectively. The WSJ corpus is not likely to contain biomedical term words, such as NF-kappa , because it is constituted by
Wall Street Journal articles. From the estimated probabilities, we compute the relative frequency ratio of a word w by Eq. (2).

We regard the word as a salient word when its relative frequency ratio is more than the predetermined threshold value. 5 The words that do not occur in the WSJ corpus are also regarded as salient words. Table I shows the relative frequency ratio of the words in the example sentence of Figure 1. 4.2 Morphological Pattern Extraction
In order to extract internal morphological patterns of words, which are useful for detecting biomedical term words, we select every possible prefix or suffix of words when they consist of more than three characters. We then compute the relative entropy of each substring in order to discriminate informative prefixes and suffixes. 6 The relative entropy of a substring str is computed by Eq. (3) from the training data.

If the words, including the substring, are more frequently used in term words tw than in nonterm words  X  tw , the substring can be an informative pattern to recognize a term word. Morphological patterns are sorted in the descending order of the amount of relative entropy of each pattern. When a word is given, we find the most highly ranked morphological pattern that matches one of the word X  X  substrings [Kim and Tsujii 2004]. Table II shows the relative entropy of words in the example sentence of Figure 1. 4.3 Collocation Extraction
To extract reliable collocations, we use a large subset of the Medline corpus. Be-cause the training data is not enough to extract collocations, with Medline text. We use MeSH terms such as human , blood cell , and tran-scription factor to retrieve the same-topic abstracts analogous with the training data. The total number of retrieved abstracts is 8954. From the abstracts, we extract bigram collocations by applying the chi-square test as Eq. (4).
In the equation,  X  denotes C ( w 1 , w 2 ),  X  denotes C ( two words, and N denotes the number of the total bigrams. We regard the bi-gram as a collocation when it occurs more than twice and its chi-square value is more than a threshold. Table III shows the example collocations extracted for term boundary extension. 5. EXPERIMENTS
To test the proposed method, we have experimented with JNLPBA-2004 datasets 8 [Kim et al. 2004]. The training data came from the Genia version 3.02 corpus. This was constructed by a controlled search on Medline using the MeSH terms human , blood cells , and transcription factors . From this search, 2000 ab-stracts were selected and hand-annotated according to a small taxonomy of 48 classes based on a chemical classification. Among the classes, 36 terminal classes were used to annotate the Genia corpus. In order to simplify the data for the shared task, only five classes ( protein , DNA , RNA , cell line , and cell type ) are considered.
 The test data was a newly annotated collection of Medline abstracts from the Genia project. For the same classes of entities 404 abstracts were annotated.
One-half of them was from the same domain as the training data and the other one-half of was from the superdomain of blood cells and transcription factors .
The term-recognition phase generally finds the boundary of all terms in a given sentence. However, in the given training data, biomedical terms corre-sponding to only five specific classes were tagged. We assumed that it is better to identify all terms and to assign appropriate semantic classes to the identified terms. In this experiment, we also annotated the words corresponding to other
NE classes 9 as B other or I other using Genia 3.02 version. Thus, in the term-recognition phase, we find all the biomedical terms represented in sentences, and classify only the biomedical NEs corresponding to five specific classes among the identified terms in the semantic-classification phase. Because other class is not the one we want to find, the class is changed to O class. The total number of biomedical NEs that belong to other class turned out to be 25,987. For preprocessing, we reimplemented a POS tagger based on the trigram HMM model by using Penn II corpus and Genia corpus as training corpora.
As a chunker, we used the Taku Kudoh X  X  YamCha 10 based on support vector machines. As a result, about 96.3% of terms in the training data and about 94.5% of terms in the test data can be found in the salient NPs. The percentages correspond to the upper bound on recall.

For building classifiers, we utilized the Zhang le X  X  MaxEnt toolkit,
L-BFGS parameter estimation algorithm with Gaussian Prior smoothing [Chen and Rosenfeld 1999]. 5.1 Experimental Results
Table IV shows the overall performance on the test data. Fully correct means that the boundaries of the system and those of the gold standard match on both sides. Left boundary correct also means that the boundary of the system and that of the gold standard match on the left side; right boundary correct means that the boundary of the system and that of the gold standard match on the right side. Our system obtains an F score of 66.91% on both sides, 71.64% on the left side, and 74.23% on the right side.

Table V shows the performance of each phase on the test data. Our system obtains an F score of 54.43% in the term-recognition task and an accuracy of 87.07% in the semantic-classification task. In the term-recognition task, we obtain low precision due to other class: 15,211 terms were found by the system, while only 8662 terms were annotated in test data.
Table VI shows the performance of the experiment when other NE classes are considered. It shows that including the other NE classes except five classes can improve the overall performance.

Table VII shows the performance of biomedical NE recognition using the one-phase and the two-phase method, respectively. The one-phase method is implemented by incorporating the term-recognition phase into the semantic-classification phase. In order to improve the performance of the one-phase method, we experimented with several feature sets. For example, one-phase shows the performance of the experiment when only features for the term-recognition of the two-phase method are used. One-phase with word variation (2, 4) also shows the performance of the experiment when we use word vari-ation features in addition and use left adjacent two words and right adjacent four words. Experimental results show that the two-phase is better than the one-phase method in our evaluation.

Table VIII shows the effects of using lexical knowledge. We take the sys-tem without using any lexical knowledge as a baseline. The baseline baseline + MP, and baseline + Co indicate the cases when salient words, mor-phological patterns, and collocations are all used on the baseline system, respec-tively. Usage of salient words decreases the performance. However, we obtain the performance improvement of about 1.8% by using morphological patterns and collocations. Addition of prefix/suffix features is most effective; collocations are also effective.

In analyzing the performance of the system, it is useful to estimate the rel-ative contribution of the various feature sets used. Table IX shows the per-formance of various feature combinations on the term-recognition task. In
Table IX, we notice that the performance is deteriorated by leaving out one feature at a time. Removing the word feature has the most effect on the perfor-mance, while removing the Greek feature has the least effect on performance.
The upper part of Table X shows the performance of various feature com-binations on the semantic-classification task. Like the term-recognition task, we also notice that the performance is deteriorated by leaving out one feature at a time. Removing the word feature has the most effect on the performance, while removing prefix/suffix feature has the least effect on the performance.
The lower part of Table X shows the performance of the experiment when the words located in the left and the right contexts of terms are used, in addition.
According to the experimental results, the use of the left and the right contexts are not effective on the improvement of performance, because the NE class tagging mainly depends on words themselves constituting a term.

Table XI shows the performance according to the number of term words used as features on the semantic-classification task. For example, 3word-left2right1 represents the performance of using two words from the leftmost and one word from the rightmost of the recognized term. A 4word-right4 rep-resents the performance of using only four words from the rightmost of the recognized term. A 4word-right4 is most effective on the performance except 4word-left3right1 .

Table XII shows the percentage of the cases when the number of term-word candidates are reduced. No restriction means the case when all words are con-sidered, NP means the case when the terms are found in NP; salient NP means the case when the terms are found in salient NPs. The second and third columns indicate the number of words and the percentage of words that satisfy each re-striction. The 4th and 5th columns indicate the number of term words tw and the percentage of term words tw that satisfy each restriction. According to
Table XII, we notice that only 19,392 of the 101,039 words are actually served to term words. By applying the salient NP restriction, we can remove about 46.3% of total words, as shown in the third column. Thus, we can reduce the training cost by applying the salient NP restriction. 6. ERROR ANALYSIS
In the preprocessing step, we find the terms only in salient NPs. However, there are terms that do not satisfy the restriction such as human osteosar-coma (Saos-2) cells , transforming growth factor-beta , leucine zipperlike , and transcription factor nuclear factor of activated T cells . These terms include symbols, verbs, adjectives, and prepositions. Thus, in order to include the biomedical terms as many as possible, NP boundaries are extended by using rules. As shown in Table XIII, by applying simple 3 rules, most biomedical terms, although we use the salient NP restriction.
 Tables XIV and XV show the examples of collocations extracted from the
Medline corpus for the term boundary extension. Table XIV shows the example of collocations that can correct term-recognition errors; Table XV shows an example of collocations that make false corrections. The left column of Table III represents the chi-square value of collocations applied in Table XIV; the right column of Table III represents the chi-square value of collocations applied in
Table XV. If the word inside the boundary and the word outside the boundary have a collocation relation, we assumed that the word outside the boundary is a term word. However, as shown in Table XIV and XV, although the word outside the boundary has a collocation relation with the word inside the boundary, the word outside the boundary does not always constitute a term. For example, cell and signaling are shown in both Tables XIV and XV. Therefore, usage of collocation information does not significantly improve the performance.
Among 8662 terms annotated in the test data, 2165 terms were not correctly identified in the term-recognition phase. In order to show the distribution of error types on the term-recognition task, we analyzed 2165 terms as shown in
Table XVI. gold1, system0 means the case when one term of the gold standard does not overlaps with any terms of the system, gold1, system1 means the case when one term of the gold standard overlaps with only one term of the system, and gold1, system2 means the case when one term of the gold standard overlaps with more than two terms of the system. In Table XVI, about 50.8% (1100/2165) of errors corresponds to the gold1, system1 .

The gold1, system1 can be subdivided into several error types. Each of the left boundary and the right boundary can be classified into one of the following classes: M means the case when the boundary of the system and that of the gold standard match, I means the case when the boundary of the system is inside that of the gold standard, and O means the case when the boundary of the system is outside that of the gold standard. Thus, the gold1, system1 can be subdivided into 3  X  3 = 9 types, and 8 types except MM correspond to the error.
In Table XVI, about 63.6% (700/1,100) of the gold1, system1 errors correspond to the case when the left boundary of the system is outside that of the gold standard or when the right boundary of the system is outside that of the gold standard.

Table XVII shows the confusion matrix between the output of gold stan-dard and the proposed system on the semantic-classification task. Among the correctly identified 6497 terms in the term-recognition task, we analyzed 714 terms in which the semantic classes of the system and the semantic classes of the gold standard do not match. The first column represents NE classes of gold standard . Among terms that our system classifies into other class, there are a lot of terms that actually belong to five NE classes. protein / DNA and cell line / cell type confusion are also noticeable. 7. RELATED WORK
There are several related works performing postprocessing in order to improve the performance of a system. Zhou et al. [2004] suggested a pattern-based post-processing to resolve the cascaded entity names. All patterns are automatically extracted from the cascaded entity names in Genia corpus. Lee et al. [2003] suggested a dictionary-based postprocessing to extend the term boundaries.
The dictionary is constructed by the term words in GENIA corpus. The method extends the term boundaries with adjacent words of recognized terms through simple dictionary lookup. If the adjacent word exists in the dictionary and be-longs to one of the groups, such as noun or adjective, it is merged into the term.
Table XVIII shows the official results of the top four participating systems in the JNLPBA 2004 shared task and experimental performance of our system on the same training and test data. Our system is ranked 4th for F score. The reason that the top three systems outperform our system seems to be due to the use of precompiled resources. Zhou and Su [2004] explored an open dictio-nary from the database term list SwissProt and the alias list LocusLink. The open dictionary contained about 700,000 entries. Finkel et al. [2004] explored a gazetteer compiled from lists from biomedical websites (such as LocusLink), as well as from the Gene Ontology and the data provided for the BioCreative 2004 tasks. The final gazetteer contained 1,731,496 entries. Settles [2004] ex-plored the sort of semantic domain knowledge provided in the form of lexicons.
He prepared a total of 17 such lexicons, which include seven that were entered by hand (Greek letters, amino acids, chemical elements, known viruses, plus abbreviations of all these), and four corresponding to genes, chromosome lo-cations, proteins, and cell lines, drawn from online public databases (Cancer GeneticsWeb, BRID, SwissProt, and the Cell Line Database).
 8. CONCLUSION
We have presented a two-phase biomedical NE-recognition method based on a ME model. In the two-phase NE-recognition method, in order to improve the performance of term recognition that dominate the overall performance of our system, we have performed preprocessing and postprocessing using lexi-cal knowledge. In the preprocessing step, in order to decrease the number of instances from nonterm words and the training cost, we have performed NP spotting by using salient word lists extracted through a corpus comparison. In the postprocessing step, we have performed term boundary extension by us-ing collocation information extracted from Medline text. If the word inside the boundary and the word outside the boundary have a collocation relation, the word outside the boundary is merged into the term. In addition, for the ME learning, we have added morphological patterns extracted from the training data to a feature set. Experimental results show that our system obtains an
F score of 66.91% and that the introduction of lexical knowledge improves the performance of our system as compared with a baseline performance. The ad-dition of morphological patterns are the most effective on the improvement of performance.

The contribution of our work lies on the trial of a lexical knowledge-incorporated method to improve the performance of term recognition. According to the experimental results, the use of salient words are not effective on the im-provement of performance. However, by filtering the salient NPs, which may contain term words, we can decrease the number of irrelevant target instances and reduce the training cost. We also assumed that the collocation information can be useful to identify whether the words frequently used as both a term word and a nonterm word are term words or not. However, we found that the collocation information is not enough to identify a term word.

As a future work, we will devise a more elaborate method of extracting salient words for term recognition. Furthermore, we will also explore a more reliable method of identifying whether the words frequently used as both a term word and a nonterm word are term words or not.

