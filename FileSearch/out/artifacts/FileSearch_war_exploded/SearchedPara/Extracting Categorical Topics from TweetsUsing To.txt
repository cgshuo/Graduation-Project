 Twitter, as a microblogging website, is beco ming more and more popular. The number of Twitter users has exceeded 500 million sin ce July, 2012. The number of active users is over 200 million per month. The structure of Twitter contents is strictly constrained and it differs from the traditional medias in many aspects.

One tweet is much shorter than a traditional document and its length is strictly con-strained to 140 words. So, only a little information is conveyed in a tweet and much of the content in a tweet is noisy. Because of these characteristics of Twitter data, tradi-tional topic models, such as LDA, can not yield interpretable experiment results. From our observations of real tweets, users tend to discuss some public issues of the whole society or share their personal lives with their friends. Previous studies are unable to dis-cover interests of each user and hot issues of the whole community since they usually treat all tweets as a whole to discover interests of all users.

To filter out noisy words, we introduce a background word distribution into our model. Moreover, we divide topics into two main types in semantics: personal top-ics and public topics. Personal topics are usually interested by several users and could strongly depict one user X  X  personal interests, such as autos and weight loss , while public topics, such as Boston marathon bombing , are usually interested by the whole commu-nity and could strongly depict hot issues of the society.

Hashtag which is a word or phrase prefixed with the symbol # indicates the tweet is discussing a public topic. In the Twitter community, users are inclined to use a hash-tag as a public topic label. So, in order to analyze these two categories of topics, the presence of hashtags is taken into account while selecting topic of one tweet in our model.

A novel topic model is proposed in this paper. Using a background word distribution, the proposed model can clearly extract public topics and personal topics separately. The potential useage of these two kinds of topic distributions is very great. For example, we can extract the hottest public topic using the public topic distribution. And we can also recommend the users of same interests to each other. Many algorithms for topic mining in text exist. An early solution for this problem is to transfer the text data into vectors and cluster with some traditional methods like K-means[1]. In the popular td-idf scheme[2], each document in the corpus is reduced to a fixed-length list of numbers, roughly corresponding to the frequency of appearance for a basic set of words within that document.

Later, the LSI model[3] uses the singul ar value decomposition (SVD) of the word-by-document matrix from td-idf to identify a subset of the feature space that captures the most variance. Probabilistic latent semantic indexing (pLSI)[4], which allows each document to contain multiple topics , has been introduce naturally.
 Blei &amp; Jordan proposed Latent Dirichlet Allocation (LDA) topic model in 2003 [5]. This is an unsupervised, statistical approach proposed for modeling text corpora by dis-covering latent semantic topics in large collections of text documents. LDA has become a standard tool in topic modeling. A number of extensions of LDA has been proposed. Because tweets are much shorter than the traditional text and with a lot of noisy words, traditional topic models do not work well with the Twitter data.

Few works has presented a systematic analysis of content on Twitter. [6] character-izes content on Twitter and other  X  X ocial Awareness Streams X  via a manual coding of tweets into categories of varying specificity , from  X  X nformation Sharing X  to  X  X elf Pro-motion X . Some have focused on modeling conversations on Twitter[7]. [8] has studied features of Twitter social network, such as t opological and geographical properties, pat-terns of growth, and user behaviors. Ramag e et al. applied Labeled Latent Dirichlet Allocation (Labeled LDA) model to Twitter context [9,10]. But, this method relies on hashtags and may lose topics without hashtags. In order to overcome the difficulty of short text in Twitter context, unlike traditional LDA model, [11] associated one tweet, rather than one word, with only one topic. Nevertheless, previous works equally analyze all topics as one type and can not discover personal interests of each user and public issues from the given corpus, the problem we approach here. 3.1 Preliminaries A vocabulary consists of a set of V unique words in a set of tweets.
 A userlist consists of a set of U unique users.

A word is the basic unit of data, which is an item from a vocabulary indexed by { 1 , ..., V } .The v th word can be represented by a V-vector such that the v th element is one and other elements are zero.
 A corpus C is a collection of M tweets C = { w 1 ,w 2 , ..., w M } .

A tweet is divided into three parts:  X  Text w m = { w m 1 ,w m 2 , ..., w mN } is a sequence of N words, where w mn is the  X  Hashtag flag h is a Boolean variable denoting whether the tweet contains hashtags.  X  User u is a user number indexed by the userlist of the tweet. This variable indicates
A topic is a random variable z n on { 1 , ..., K } where n indicates the n th word in the tweet and K is the number of topics.
 Personal topic: topics focusing on personal life strongly depicts one user X  X  interests.
Public topic: topics focusing on hot issues depicts the public X  X  interests. 3.2 Categorical Topic Model In our model, denoted as  X  and  X  , two latent variables representing personal topic dis-tribution and public topic distribution are introduced. Besides, a background word dis-tribution, denoted as  X  , is introduced to filter background words for all topics. Bayesian network of the proposed Categorical Topic Model is shown in Figure 1. Here, we intro-duce the following model parameters:  X  is a symmetric Dirichlet hyperparameter for personal topic mixtures and public topic mixtures.  X  is a symmetric Dirichlet hyperparameter for words distribution.  X  are symmetric Dirichlet hyperparameter for word distribution selection.  X  is a Muiltnomial parameter to gove rn the process of selecting users.

And, seven latent variables of our model are introduced:  X  k is the Multinomial words distribution over topic k . It remains the same meaning with original LDA.  X  is the Multinomial background words distribution.
  X  stands for public topic distribution of all users.  X  = {  X  z is the topic indicator of a word in the tweets of one user.

 X  is U  X  K multinomial parameters matrix in w hich each column represents topic multinomial distribution of one user. y is a binary parameter governing the selection of word distributions.  X  is a Bernoulli parameter which represents the probability of generating a word from the background word distribution.

We also introduce: n k u is the number of words of user u under topic k in tweets without hashtags. n k M is the number of words under topic k in tweets with hashtags. n v k is the times that word v appears under topic k in all tweets. n v M is the times that word v appears as a background word. n c M is the number of background words(c=1) or the number of non-background words(c=0).

In the generating process, the topics of tw eets are selected according to its presence of hashtags. When a tweet with hashtags is generated, its topic is selected from the pub-lic topic distribution. Otherwise, if one tweet without hashtags is generated, its topic is selected from the user X  X  personal topic distribution. Variable y mn is acted as a back-ground word indicator. When it equals one, word w mn is selected from  X  k ,otherwise  X  . Formal generating process of our model is in Algorithm 1. 3.3 Deriving a Gibbs Sampler for Our Model According to Figure 1, when the corpus is given, h and u can be observed, prior  X  and prior  X  are d-separated from the rest of the model. Given h , u and hyperparame-ters:  X  ,  X  ,  X  , the joint probability of w , z , y can be computed with Equation 1.With the joint distribution of w , z , y , full conditional distribution for the current word can be Algorithm 1. The Generation Process of Tweets derived as Equation 2 by using Euler integration and one property of Gamma function  X  ( x +1)= x X  ( x ) . If one further manipulates the above formula , one can turn them into separated update equations for the topic and the background word indicator of each token. With the Gibbs updating rule, topic distribution and word distribution can be derived as Equation 3, Equation 4 , Equation 5 and Equation 6. Algorithm 2. Sampling Algorithm
Because the exact inference of LDA is intr actable, Heinrich introduced Gibbs sam-pling for approximate inference [12]. Gibbs sampling is a special case of Markov-chain Monte Carlo (MCMC) simulation. It often yields relatively simple algorithms for ap-proximate inference in high-dimensional models such as LDA. Therefore it is also uti-lized for the proposed model.

The procedure of Gibbs sampling for our model is shown in Figure 2. All words in the corpus are set with an initial topic and a background word indi cator randomly. Then, for each topic and its background wo rd indicator are calculated. z ( m,n ) and z  X  ( m,n ) indicate topic assignments for the current word and the rest of words in the corpus respectively. When the probabilities of each topic and its background word indicator are calculated, a topic and its background word indicator for the current word is sampled based on the probability distribution. The s ame procedure is done to the other words in the corpus. The procedure runs iteratively until all distributions have been converged. The algorithm is shown in Algorithm 2.
 4.1 Data Set and Preprocessing In order to test and illustrate our model, we use the data set provided officially by the Micro-blog Track at Text Retrieval Conference (TREC) 2011. The data set contains ap-proximately 16 million tweets, posted ove r a period of 2 weeks from January 23, 2011 to February 8, 2011. In this corpus, each tweet record has five attributes: tweet remark, user remark, status codes, posted time and tweet content. Five types of status code are included in the corpus: 200, 302, 403, 404 and null, which means ok, found, forbid-den, not found and nothing respectively. The statistic result of the dataset is showed in Ta b l e 1 .

Because only records with status code 200 and 302 are useful, tweets with status code 403 and 404 are cleared. We also have conducted Stemming operation for all the left tweets. And, URLs, stop words, punctuation, RT labels, words not in the dictio-nary (Alan Beales Core Vocabulary is used here) are also filtered. Eventually, the users who posted less than 50 tweets and their corresponding tweets are removed. After pre-procession, tweet number, user number and vocabulary size are 87292, 1210 and 4840 respectively.
 4.2 Parameter Settings Referring to [13], our hyper-parameters are set as  X  =1 . 0 , k =1 . 0 ,  X  =0 . 1 .The topic number is set as 50 (Numbered from 0 to 49) at the beginning of the experiment. 4.3 Evaluation Metrics In order to evaluate the results, perplexity is employed here. It is a criterion of clustering quality that does not require priori categorisations and it is a measure of the ability of a model to generalize the unseen data. Perplexity is defined as reciprocal geometric mean of per-word likelihood of a test corpus. A lower perplexity indicates a better generalization performance. The perplexity is shown in Equation 7, where C is the corpus, w d is the observed words in d th tweet.
 Perplexity 4.4 Performance Comparison The comparison bewteen LDA, ATM and our model on perplexity are illustrated in Figure 3. When the iteration number is set less than 150, the perplexity of the proposed method is better than LDA. When the iteration number is over 150, our model can yield the best performance of the three. Figure 4 shows an example of top 10 words for 4 top-ics and background words. Clearly, Topic4, Topic8, Topic20, Topic39 can be interpreted as  X  X eight loss X  ,  X  X ornography X  ,  X  X errorist attack X  and  X  X olitics X  respectively. In the background words column, common words have been listed and filtered out from topic words. As we can see, background words usually do not convey definite meanings and are not helpful to illustrate a topic.
Public topic distribution and personal topic distribution are illustrated in Figure 5 and Figure 6. From these two types of distributions, we could see that the two types of topics have different probability distribution. As shown in Figure 5, Topic 20 and Topic 39, related to  X  X errorist attack X  and  X  X olitics X  , have relatively high ratio of all the topics. Both of the two topics are hot issues of the society at that time. Figure 6 illustrates an example of personal topic distribution for two users. Clearly, these two users have different interests. User23 and User119 are strongly interested in  X  X eight loss X  and  X  X ornography X  separately. Obviously, both topics mainly focus on personal lives. In this paper, the Categorical Topic Model is presented for extracting topics from tweets. By introducing a background word distribution, common words have been effectively filtered and topics extracted by our model are more interpretable. According to the presence of hashtags, we divide topics into two types in semantics: personal topics and public topics. Thus, personal interests and hot issues can be clearly analyzed in the same model. The derivation of approximated inference via Gibbs sampling is illustrated for the model. Compared with the previous research, our model could discover per-sonal interests and hot issues and achieve comprehensive and interpretable experimental results.

