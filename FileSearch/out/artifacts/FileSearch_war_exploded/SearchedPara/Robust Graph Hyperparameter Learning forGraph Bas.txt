 Graph-based semi-supervised learning techniques have attracted much attention in recent years. The general idea of the se methods is based on building a graph whose nodes are data points connected with edges that encode similarities be-tween them. The labels of unlabeled da ta are learned on this graph in such a way that nearby data points will have similar labels. Examples of graph-based semi-supervised algorithms include label propagation [1], graph mincuts [2], ran-domized mincuts [3], and regularization on graphs [4,5].

Although the graph structure is shown to have much influence in graph-based semi-supervised learning [5], few methods are proposed to deal with its con-struction problem. In [6] the hyperparameters of the graph are learned using the evidence maximization. Ca rriera-Perpinan and Zemel [7] propose to construct an ensemble of graphs by combining multiple minimum spanning trees, formed from perturbed version of the data. Wang and Zhange [8] propose a method that is similar to locally linear embedding(LLE) to learn the graph weights by minimizing the reconstruction error of the data points from its neighbors. The most influencial works are the algorithms introduced in [9] and [10]. In [9], the authors optimize the hyperparameters using average label entropy on unlabeled data points as a criterion, i.e., they sel ect hyperparameters which yield the most confident labeling on unlabeled data. It is shown by experimental results in [10] that minimizing the entropy on unlabeled data is insufficient. Zhang and Lee instead find the parameters by minimizing leave-one-out prediction error on labeled data.

While there are several strategies to learn graph structure, propagation al-gorithms on the graph are quite similar. Indeed, most of graph-based semi-supervised techniques rely on an object ive function which is a tradeoff between prediction error on labeled data and smoothness of label transition. In [5], the authors have shown that the smoothness term makes the label assignment a  X  X table X  algorithm, thus bounds over the generalization error can be computed. This suggests that a good hyperparameter should not only minimize the leave-one-out prediction error as in [10], but also maximize the stability of the labeling function on the resulting graph.

In this work, we extend the techniques proposed in [9] and [10] by directly incorporating a regularization term which measures the stability of the labeling function on graphs. Involving this regularizer, the hyperparameters of a graph are learned using the gradient-based optimization technique. Using the stability measure, we can achieve a stable labeling function as a consequent of this graph learning method. Given a data set X consisting of l labeled examples x i  X  L = { x 1 ,x 2 , ..., x l } and u unlabeled examples x i  X  U = { x l +1 ,x l +2 , ..., x n } ,where L and U denote sets of labeled and unlabeled examples, respectively. Let n = l + u be the total number of examples and m be the dimensionality of the input data. Associated with each labeled example is labels y i  X  Y . In this work, we consider only a binary classification problem in which Y = { 0 , 1 } . 2.1 Graph-Based Semi-supervised Classification A general task in graph-base d semi-supervised classification is to assign labels to unlabeled nodes x i  X  U through a graph G . The nodes represent both labeled and unlabeled data points. The symmetric weight matrix W which encodes the similarities between nodes is typically computed as follow: where x i,d is the d -th component of x i  X  R m and  X  d is the bandwidth hyper-parameters for the dimension d . The transition probability matrix between two nodes can be computed by P = D  X  1 W .Thematrix D is a diagonal matrix whose D ii = n j =1 w ij is a degree of node i .

A general strategy is to find a real-valued function f on graph and then assign labels based on f .Wewant f to take values y i on labeled data points and varies smoothly on unlabeled data points according to the weight matrix W .This criterion leads to the followi ng choice of consistency of f on graphs [9]: where f ( i )and f ( j ) are the function values at node i and j , respectively. To find the solution of the above equation, it is convenient to split the matrices W and P into four parts, starting with labeled data points followed by unlabeled data points: It is not difficult to show that the function that yields a minimum value of (2) is given by: This function is called the soft-label function since its value does not directly specify the class to which the example belongs, but it gives a possibility of being in each class. The most obvious method to transform soft-label to hard-label otherwise. This method generally works well when the classes are well-separated. However, this is not the case in many practical applications. In such cases, using simple thresholding may result in an unbalanced classification.
 Another method to transform the soft-label to hard-label is Class Mass Normalization (CMN) introduced in [9]. The class distribution of the data is adjusted to match the class priors, that can be obtained from the labeled exam-ples. For example, if the prior cl ass proportion of class 1 and 0 is p and 1  X  p , (1  X  p )((1  X  f ( x )) / ficient labeled examples to determine the class prior that accurately represents the true class distribution.

As mentioned previously, graph structures do influence the results of clas-sification. Figure 1 illustrates examples of such a situation, which shows two-dimensional data set called twomoon . In Fig.1(a) two labeled examples, circle and triangle, are drawn along with unlabeled examples depicted as solid dots. As we can see in Fig.1(b) and (c), a small change in the value of  X  used to con-struct graphs results in significantly different classification results. Moreover the optimal  X  , which yields a correct result as shown in Fig.1(d), is difficult to find in practice. Consequently, we need an effici ent graph learning algorithm to solve this problem as it plays vital role in graph-based semi-supervised classification. 2.2 Graph Learning Algorithms As mentioned previously, this work extends two previous works namely Minimum Entropy(MinEnt) [9] and Leave-one-out Hyperparameter Learning(LOOHL) [10]. This section gives a brief review of these two techniques successively.
In MinEnt, the weight matrix is obtained by learning all  X  d in (1) from both labeled and unlabeled data. An average label entropy , H ( f ), is used as a heuristic criterion for parameter learning, which is defined as soft-label at the individual unlabeled data point i . The concept of this algorithm is that a good weight W should result in a confident labeling, i.e., the average label entropy is low when soft-label at each unlabeled data point is close to the boundary of the labeling function.
Instead of considering label entropy at unlabeled data, the LOOHL learns the hyperparameters  X  d of the graph by minimizing the leave-one-out prediction error on all labeled examples. The objective function is: where h t ( x ) is the cost function for labeled example x that penalizes the dif-ference between the predicted soft-lab el and the true label of the instance. An efficient algorithm to gradient computation is proposed based on matrix inver-sion lemma and careful precomputation. Both MinEnt and LOOHL also mention a case of degenerative graphs in which  X  d grow either too large or too small. Thus a simple regularizer is used to pr event this problem. Moreover, P is replaced by  X  P =  X  U +(1  X   X  ) P ,where U ij =1 /n , to prevent the numerical problem. In this work, we propose a hyperparame ter learning method which considers the leave-one-out prediction error on labeled examples and the stability cost of the labeling function on unlabeled examples. Using the result of (3), at each iteration t =1 , .., l of leave-one-out, the soft-label function can be determined transition matrix is then defined as: The first row and column in P t UU and the missing column in P t UL correspond to a labeled example x t used to evaluate prediction cost h t ( x t ). Let e k be a vector whose element is 1 at k -th position and 0 elsewhere. The soft label of the soft-label of x t together with other unlabeled examples. Then the objective function to be minimized can be written as: where  X  balances accuracy and stability of the soft-label function. The f U,k = ( f function can be x, x a , and a x t  X  1 , for example.

In the second term of (6), the cost function s ( f U,k ) measures the variation of the soft-label over elements of f U,k . Thus the sum of this quantity over all unlabeled examples can be used to determine how stable the labeling function is. A possible choice of s ( f U,k ) is the variance function. Although this function captures the variation of soft-label, it does not take into account the confidence of labeling function. For example, if most of soft-label values lies near 0.5, we assign labels to unlabeled data with low confidence. Instead, the stability cost function used in this work is: which is the entropy of an average of all elements of f U,k . This function is chosen because it penalizes the high variation as well as the deviation from the function boundary. By minimizing this cost, labels are assigned with high confidence using the stable function.

To minimize R , we use the gradient-based optimization technique. The gra-dient is: that  X  P =  X  U +(1  X   X  ) P . With careful re-arrangement and substitution, the gradient can be written as where  X  =  X  (1  X   X  )and  X  =(1  X   X  )(1  X   X  ). From the relation that P ( i, j )= be computed by lowed from [10], the computational complexity of the algorithm is very expen-sive. A possible way to reduce the cost is by applying matrix inversion lemma in computation of ( I  X   X  P t UU )  X  1 for each iteration t . Moreover, the computational cost can be further reduced by using an efficient precomputation. Spliting the gradient computation into two parts,  X  X / X  X  d =  X   X   X  X / X  X  d +  X   X   X  X / X  X  d and substituting (10) into (9), each gradient term can be derived separately as: Let  X  (  X  )be Kronecker delta. The  X  k ij can be computed by the following formula:
To compute  X  ij , substitute  X  t k,p by  X  t p without subscript k . Since computing the gradient of stability term requires much computation, a possible method to reduce this computational cost is to use only a subset of unlabeled examples to compute the gradient. We call this algorithm Robust Graph Hyperparame-ter Learning (RobustHL) . The graph constructed by this technique is called robust graph . Algorithm 1 shows the efficient gradient computation of RobustHL. In the experiment, we comp are the prediction accuracy of four model selec-tion methods, namely 5-fold Cross Validation, MinEnt, LOOHL, and RobustHL. Algorithm 1. An efficient gradient update algorithm for RobustHL These techniques are used to learn the h yperparameters of the graph. Then the accuracy of label assignment is computed. Instead of comparing the performance of our technique with other semi-supervi sed techniques, we pay more attention to the comparison of different model sel ection techniques. Fur thermore, charac-teristics of the robust graph learned using the proposed stability measure are investigated. The benchmark used in the experiment consists of six data sets as shown in Table 1. The benchmark is well-known and is widely used to assess the power of various semi-supervised learn ing techniques. They can be categorized into two groups. The first group includes g241c , g241d ,and Digit1 which are artificially created in ord er for certain assumptions to hold. The data sets in second group are derived from real data to indicate the performance of algo-rithms in real world applications. It includes USPS , COIL 2 ,and BCI . The detailed explanation of each data set can be found in [11].

In the first experiment, we assess the performance of algorithms when there are 10 labeled examples for each data set. To see the effect of soft-label transfor-mation, both thresholding and CMN are applied in each algorithm. To make the results from the experiment robust and independent of properties of the chosen data points, the algorithms are tested on randomly selected 12 subsets of labeled examples and report the average accuracy as well as its confidence interval.
Throughout the experiment, the smoothing factor  X  is fixed at 0.001 for all same for all dimensions. The final objective function of other three methods is: where Loss is the original cost function of MinEnt, LOOHL, and RobustHL. The second term in the above equation is introduced to regularize the value of  X  d by preventing the value from approaching either 0 or  X  .Foreachratio C 1 : C 2 in { 10  X  2 , 10  X  1 , 1 , 10 , 100 } ,the  X   X  avoid the local minima. All input vectors are normalized to have length 1. The result of this experiment is shown in Table 2.
 In the second experiment, the data set i s split into traning set and test set. In traning set, the number of labeled examples varies across 10%, 30%, 50%, 70%, and 90% of this set. Then the labels are assigned to unlabeled examples in both traning set and test set. For each particular set of labeled examples, the classification error and stability on test set are calculated. In this experiment, the same model selection methods as previous experiment are used. Figure 2 shows the plot of classification error and stability of four model selection methods when the number of labeled examples in each data set increases.

From the result in Table 2, we can make the following conclusions. 1. MinEnt, LOOHL, and RobustHL graph learning methods perform better 2. LOOHL and RobustHL in general achi eve higher accuracy than MinEnt in 3. For LOOHL and RobustHL, both methods have competitive results. The 4. As a result of stability measure introduced in RobustHL, the confidence in-
It is interesting to mention the following points about the stability of each model selection technique shown in Fig. 2. 1. In some data sets, the MinEnt method has lower stability than CV, which 2. In general, LOOHL method has higher stability than CV and MinEnt. Men-3. For RobustHL, introducing explicit regularized term of stability in addition In general, the labels of unlabeled exam ples can be predicted with higher confi-dence when more label information is avaliable. The predicted label of unlabeled examples are determined by their soft-label using simple thresholding or CMN. However, this soft-label may dramatically change and result in a different pre-diction when we add more labeled examples.

The stability of the soft-label on unlabeled examples can be used as a crite-rion to determine the sufficient number of labeled examples. As can be seen in Fig. 2, the stability of soft-label on unlabeled examples increases as more labeled examples are added. However, at particular point, it will increase very slowly, i.e., adding more labeled examples will no longer affect the soft-label of the un-labeled examples. In other words, the prediction result is unlikely to change. At this point, we can stop providing label information since doing so will no longer improve the accuracy of the classification.

According to the experimental result s, RobustHL generally achieves higher stability and lower classification error than other three techniques. This means that the stability of the labeling function of RobustHL can be used as the criteria to determine the sufficient number of labeled examples very effectively. In this work, the new hyperparameter learning in graph-based semi-supervised classification is proposed. The paramet ers is learned by minimizing leave-one-out prediction error on labeled examples while retaining high stability on un-labeled examples. The problem can be solved efficiently using gradient-based optimization. Encouraging results show that the proposed technique has high performance compared to existing model selection techniques in graph-based semi-supervised learning.
 Acknowledgments. This work is supported in part by the Young Scientist and Technologist Programme or YSTP (SIIT-NSTDA:S1Y48/F-002) of the National Science and Technology Development Agency, Thailand. Special thank to Xinhua Zhang for providing the useful codes for testing.

