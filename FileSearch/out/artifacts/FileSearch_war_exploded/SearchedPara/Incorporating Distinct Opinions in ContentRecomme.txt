 With the advancement of technology, the media content industry has been growing continuously, and an enormous amount of content is now generated on a daily basis. Various strategies such as advertising and Word-of-Mouth (WOM) have been imple-mented to draw people  X  s attention [ 1 ]. Indeed, it has become very common that content providers hire celebrities or well-known bloggers to promote their content and strive to shape mainstream opinions because most users simply follow the majority opinions [ 2 ]. In recent years, these promotion strategies have become more unnoticeable and have been used to maneuver more people into biased choices for their purchases without their awareness [ 3 , 4 ].
 simple yet novel measure, called Distinctness , to estimate how unique a certain rating of a user is from the major trend of ratings. In the fi eld of recommender systems, there have been some prior attempts to exclude the effects of possible biases in systems by detecting users  X  biased opinions [ 5 , 6 ]. To the best of our knowledge, however, none of those studies have explored distinct opinions when biases exist, nor did they utilize such opinions for recommender systems.
 For instance, The Matrix, a well-known blockbuster movie, has 133, 229 ratings from individual users in our dataset (obtained from MovieLens ratings for the movie is (52, 32, 10, 3, 1) in percentages; the numbers correspond to a rating scale of (5, 4, 3, 2, 1). It should be noted that the rating 5, representing like  X  , accounts for more than half of the total ratings and that the majority of ratings, 94 %, are positive ratings (above 3 out of 5). Let us assume that there are user A and user B, each of which rated the movie 5, and user C and user D, each of which rated the movie 1. In accordance with the rating distribution for the movie, it seems that the identical opinions made by users C and D are more distinct than the opinions made by users A and B: they are strongly against the movie while most users liked it. In other words, the two people who gave the movie a rating of 1 express distinct opinions (rating the movie  X  strongly dislike  X  ), in contrast to the majority of users, who gave positive ratings. These unique ratings are powerful evidence to explain the character-istics of users. In spite of the potential usefulness of this type of distinctness feature, common CF approaches overlook the feature by assigning the same similarity value for the two user groups because the relations within groups are treated equally [ 7 ]. Unlike the aforementioned CF approaches, we measure the relations of users while considering the degree of their differences from the majority. By doing so, we are able to identify distinct opinions that can be potentially highlighted to generate more accurate recommendation results. In our experiment, it is shown that, compared with the existing CF approaches, an approach that exploits the Distinctness feature can improve the accuracy for recommender systems. In addition, we introduce three hybrid collaborative fi ltering methods combined with Distinctness ; the results show unani-mous increases compared to the baselines. The experiment was conducted on a real-life movie dataset, MovieLens, which is well-known for containing reliable data that can verify the performance of recommender systems [ 8  X  10 ]. By choosing the common dataset, we expect that our work can be easily reproducible.
 The remainder of the paper is followed by related work on bias in recommender systems in Sect. 2 . We then present the details of the proposed measure, Distinctness , and four variations of the CF methods utilizing Distinctness in Sect. 3 . In Sect. 4 ,we describe experiments and results. Finally, the conclusion and future work are given in Sect. 5 . In this section, we discuss some of the state-of-the-art recommendation models dealing with possible in fl uences within interactions between users and recommender systems, and examine the limitations of these systems. biases are involved in the interaction. User tendencies for rating and item selection are identi fi ed as biases in [ 11 ] and one work [ 12 ] pointed out user background and personal interest as potential sources of biases. In addition to the biases from individual users, context information in fl uences opinions and responses. Regarding context information, many approaches have been studied. Context information such as weather, time, and companions does matter in recommender systems that have a multidimensional per-spective since it affects the way users react [ 14 ] and thus its in biases. The interactive methods that are used to detect context information and adapt to changes of information are able to reduce possible biases [ 15 ].
 example, different kinds of interfaces of recommender systems are able to intentionally instruct users in certain ways of expressing opinions and lead users their perceptions [ 9 , 16 ]. Visually effective readability drives presentation and temporal biases in online reviews and comments [ 9 ]. Different types of rating scales also guide users toward certain ways of interacting with recommender systems and a 1-to-5 star scale allows users to express extreme feelings with great ease [ 16 ].
 recommender systems. In terms of popularity biases, several models are suggested for improvement of recommendations. A recent work [ 10 ] analyzed the causes and effects of popularity bias and proposed an algorithm to weaken the phenomenon in which only popular items are frequently recommended to users regardless of users In [ 17 ], it was found that a function to penalize popular items in item-based collaborative fi ltering was able to decrease the chances of popular items appearing as recommendations. purchases, and opinions. By continuously appearing on a front page, early written online reviews lead to sequential biases and fi nally in fl a greater volume of WOM results in a higher box of fi ce performance in the movie industry and directly connects to revenue in the fi eld [ 2 ].
 to exclude the effects of biases in the system. However, in this paper we explore implicit and unbiased opinions and propose an ef fi cient measure to build sophisticated relationships among users. To the best of our knowledge, unbiased and distinct opinions have never been exploited in recommender systems, though use of such opinions can potentially be effective in bolstering relations among users. In this section, we will fi rst introduce the concepts of popularity and entropy. Based on those concepts, we fi rst describe a new measure called Distinctness to estimate distinct similarities between users and then move on to explain four CF methods based upon Distinctness .
 Popularity. In content industries including movies and books, opinions about content are highly susceptible to advertising and WOM [ 1 , 2 ]. This situation eventually leads to the Matthew Effect:  X  the rich get richer and the poor get poorer items become widespread and establish certain reputations, their images are accumu-lative and fossilized [ 5 ]. Therefore, when a major trend of opinion for an item is formed by the public, Distinctness of unique opinions increases. The total number of ratings can indicate the Popularity of a certain movie. The advantage of Popularity is that it is straightforward and easy to compute, but the possibility of pre having enough ratings usually defeat unpopular items  X  is a disadvantage [ 18 ]. However, in this study, to lessen the in fl uence of possible weakness, we take advantage of a property of the logarithm function, which can transform an exponential-like curve to a linear-like curve by compressing large values.
 Entropy. Entropy of an item  X  s ratings indicates the distribution of ratings. For instance, when ratings are evenly distributed on a 1-to-5 star rating scale, the value of Entropy is greater. In contrast, when the majority of ratings are positive ratings, 4 or 5, the Entropy value is smaller. As the Entropy value decreases, the meanings of distinct ratings increase in terms of Distinctness . Entropy , however, does not imply the total number of ratings for items. Two rating distributions, (1, 0, 0, 0, 5) and (100, 0, 0, 0, 500), have the same Entropy values, although the former distribution has fewer ratings. In other words, Entropy alone never enables us to completely represent the concept of Distinctness of ratings due to the total number of ratings. Entropy of item p distribution is calculated as follows: where P  X  i j p  X  denotes the relative frequency of rating i in an item p . In a 1-to-5 star rating scale, i can be 1, 2, 3, 4, or 5.
 Distinctness. Both Popularity and Entropy are correlated with Distinctness . We esti-mate Distinctness , D pi for each rating i in an item p , using Bayes follows: where N p is the total number of given ratings to item p and N i in an item p .
 D pi . N p is the total number of given ratings to item p and N an item p . In order to apply Bayes  X  theorem in Distinctness , Popularity and Entropy have less correlation [ 8 , 18 ]. Unlike the previous studies applying the concepts of Popularity and Entropy [ 8 , 10 , 18 ], this research exploits the idea of Entropy in reverse. Skewed distributions of ratings represented in smaller values of Entropy play a crucial role in Distinctness .
 Distinctness-Based Collaborative Filtering (DISTINCT). All the ratings i of every item p can be represented by Distinctness values, D pi . We use the Distinctness values to calculate Distinctness -based user-user similarity, S D as follows: where P is a set of items rated by both users, u and v , and p is each item included in S , the predicted rating of an unknown item i for the target user u is computed as follows: where r v ; i is user v  X  s rating for item i , r u and r K is a set of u  X  s neighbors who rated the target item i , and at the same time satis with a parameter k from 0.1 to 1.0 which is detailed in Sect. 4.3 .
 ventional rating-based collaborative fi ltering in recommender systems. Generally, in the conventional collaborative fi ltering, which directly uses ratings, user-user similarity using Pearson Correlation Coef fi cient is derived as follows: replaces S D . In the fi rst two hybrid algorithms, the Distinctness -based CF (DISTINCT) and the conventional CF are linearly combined together.
 Linearly Combined Similarities CF (LCS). The two similarities from each CF method are joined together in the fi rst hybrid CF as follows: where S D  X  u ; v  X  and S R  X  u ; v  X  are similarity values from Eqs. 4 and 6 , and as 0.5 to balance the two similarity scores. The new combined similarity value S used to compute the predicted rating, c r u ; i as follows: Linearly Combined Ratings CF (LCR). The second hybrid method linearly com-bines two predicted ratings coming from the different CF strategies based on Eqs. 4 and 6 . The combination of two predicted ratings of an unknown item i for the target user u is then calculated as: where r 0 u ; i is the fi nal predicted rating as a result of the second hybrid CF. Distinctness Weighted CF (DWCF). In the last hybrid CF method, the Distinctness values are applied to S R as weighting parameters to control the contributions of rating-based relationships as follows: In DWCF, S 0  X  u ; v  X  from Eq. 10 is used to compute the Eq. 8 . 4.1 Experiment Setup To evaluate our approach, we carry out experiments on the MovieLens dataset, which consists of more than 10 million ratings given by 70,250 active users for approximately 10,000 movies. This dataset is commonly used to evaluate recommendation tasks, and thus, we expect that our work can be easily reproducible. The ratings are on a 1-to-5 star scale. In order to focus on the users having common rating behaviors, we randomly chose 1,000 users who rated individual movies between 1,000 and 5,000 times. For users having given a myriad of ratings, the rating behaviors show stricter standards in rating [ 12 ], and in the case of users who have rated movies only a few rating times, the cold start problem occurs [ 8 ], so such types of users are excluded from this study. We then follow 5-fold cross validation by categorizing 80 % of the data as training data which generates recommendations and the rest of the data as test data to evaluate the recommendation results. cient CF (PEARSON) and Cosine Similarity CF (COSINE) are used as baseline models. All experiments are evaluated for two types of accuracies. Mean Absolute Error (MAE) and Root-Mean-Square Error (RMSE) are used to evaluate the prediction accu-racy and Normalized Discounted Cumulative Gain (NDCG) is used to assess the ranking accuracy. Due to the limits of space, details of the measures are referred to [ 7 , 19 ]. 4.2 Experiment Results In this section, we analyze the performances of our approaches, which adopt Distinctness : DISTINCT, LCS, LCR, and DWCF compared with the baselines. Figure 1 (a) shows MAE values from the different methods; and Fig. 1 (b) displays RMSE values. Note that lower values indicate better performances for those metrics and all the improvements are signi fi cant with a con fi dence level of 0.01. From the two graphs, the baselines show lower performances than the methods using the Distinctness feature. DISTINCT using the Distinctness feature alone outperforms the COSINE and PEARSON in 5.5 and 4.56 %, respectively. This is due to the fact that the method contains not only the Distinctness feature that detects the unique characteristics of the users, but also the popularity feature that re fl ects the major trend of ratings. Further-more, we can see that adopting the hybrid approaches boosts the overall performance. DWCF especially presents the highest performance among our approaches, as it indeed outperforms the baselines in 9.32 and 9.28 %, respectively.
 performs well in the higher ranking predicted accuracy. In detail, Fig. 2 (a) represents NDCG score at N while N varies from 1 to 10; and it shows that distinctness methods including DWCF return higher NDCG score at every N compared to the baselines. Figure 2 (b) shows that this tendency still resides while N increases from 10 to 40. A cursory look at the results is that utilizing the Distinctness feature reaps bene recommendations as the algorithms including the feature show better performances than the baselines. Especially, in both graphs, DWCF presents the highest performances in most cases of N compared to all the methods, implying that using the Distinctness feature as a weighting parameter mixed with the conventional CF methods promises the best recommendation results. Our proposed method DWCF outperforms baselines by approximately 1.48 % and 1.64 % on average for NDCG at 5 and 10, respectively. Note that the improvements are signi fi cant with a con fi dence level of 0.01. Our assumption for Distinctness is that the relationship exhibited in a unique trend is stronger than the relationship in major trend. By focusing on the information on the minor rating on users, Distinctness enables us to successfully predict the minor ratings of users, although they have been hardly exploited for rating the movies. To verify the assumption and understand why the performance of the certain algorithm surpasses the other methods, we looked into how accurate the predicted ratings are in each rating scale. Let us denote HIT (is a counting measure) if an error value, the difference between a predicted rating and a target rating, lies in the range from zero to the MAE. HIT can be regarded as the number of correct predictions since the predicted rating values are quite close to the target answers within the setup error range; HIT Ratio is calculated that the number of the ratings is divided by the number of HITs. The higher the HIT Ratio is, the more precise prediction the method generates.
 Table 1 shows a partial rating distribution for randomly chosen 40 users and HIT and HIT Ratio performances. In this random set, users frequently used 3 and 4 when rating the movies compared to 1, 2, and 5. The common ratings such as 3 and 4 have more opportunities to be predicted and obtain higher HITs. Nevertheless, if a method has higher HIT Ratio values for minor ratings like 1, 2, and 5, the method incorporates the information buried in ratings data including the distinct feature in ef recommender systems.
 Table 1 demonstrates HIT and HIT Ratio of the methods for each rating scale as well as the rating distribution. In Table 1 ,a a indicate that the value is signi higher within each method. From the table we can see that PEARSON has noticeable HIT accuracy when the target ratings to predict are 3 and 4 rather than 1 and 5. On the contrary, when the answer ratings are 1 and 5, the algorithm DISTINCT which uses only the Distinctness values has far higher HIT numbers than the baseline models (the HIT for 5 is reasonably better than PEARSON and COSINE).
 SON, since it exploits the Distinctness feature as weights on the conventional CF method. The performances of DWCF for 1 and 5 are as good as DISTINCT and for 2, 3, and 4 are more superb than PEARSON. This implies that DWCF mutually adopts both strengths from DISTINCT and PEARSON. A clear summarization of the above statements is given in Fig. 3 as it indicates how much each method generates HIT prediction for target ratings. In Fig. 3 , the methods COSINE and PEARSON fail to predict the target rating 1 and 2, while DWCF yields the much better predictions in the target ratings. Again, as DWCF is the hybrid technique based upon PEARSON, it also shows a robust performance in predicting the major ratings such as 3 and 4 like PEARSON does.
 4.3 Impact of Parameter for Selecting Neighbors Previously we introduced a parameter k in order to choose the size of similar neighbors for a certain user. It has been believed that the parameter plays a vital role to generate precise recommendations [ 11 ]. If the value of k is too small, some of the neighbors ratings that match with the current user might be completely overlooked. On the other hand, if the value of k is too large, the ratings of users who have strongly the opposite tendency against the user might be potentially regarded for prediction. To evaluate the impact of the parameter, we observe the MAE, RMSE, NDCG at 5 and NDCG at 10 results by slowly increasing the parameter from 0.1 to 1.0. Note that the value of 1.0 indicates that all users are used as neighbors. Meanwhile, the value of 0.1 indicates that, after sorting all users in a descending order of each similarity method: COSINE, PEARSON, and DWCF, top 10 % of the users are chosen to be a set of neighbors with the target user.
 Figures 4 and 5 present the effect of varying the parameter k . In speci performance for each k is shown in Fig. 4 (a), the RMSE performance is given in Fig. 4 (b), and the NDCG performance is given in Fig. 5 . In terms of DWCF, we observe that the overall performance for each metric peaks approximately between 0.4 and 0.5, gradually decreasing afterwards. On the other hand, PEARSON and COSINE show lower performances than DWCF except for few cases. Although the performance varies depending on the value of k , we still can observe that the best value for DWCF presents the best performance compared to the best cases of the compared methods. Another observation is that each method peaks at different k and thus, we set the parameter to its best performing value in accordance with the method chosen for our experiment. The goal of this paper is to suggest a new collaborative fi recommender systems. To achieve this goal, we have presented a novel measure, Distinctness , to estimate unique and distinct ratings that do not follow major trends. Using Distinctness , we have developed four CF approaches: DISTINCT, LCS, LCR, and DWCF. Following the proposed approaches, similarity and predicted ratings have been computed while considering the degree of Distinctness . Throughout our experi-ment, we have showed that our models effectively utilize data and clearly outperform comparable models. Especially, by exploiting the concept of HIT and HIT Ratio, we have detailed an investigation of superior results from DWCF.
 basis of analyzing rating patterns. We assume that there might be different types of users in terms of ways of reacting to external in fl uences according to rating times and experiences. In our experiment, we have chosen only common users who have a certain range of rating times, to avoid cases of the cold-start problem and unusual rating behaviors. Additionally, in order to focus on discovering the distinctness information and validating this new feature for the fi rst time, we have used easily computable algorithms as the baselines. Based on improvements from the distinctness feature proposed in this study, we believe that it is also worthwhile to incorporate sophisticated algorithms like Matrix Factorization approach into this feature in future. Despite the need for the further work, the proposed methods show the promising potential of Distinctness to improve the overall performance of recommendation results.
