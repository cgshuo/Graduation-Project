 Kihyuk Sohn kihyuks@umich.edu Guanyu Zhou guanyuz@umich.edu Chansoo Lee chansool@umich.edu Honglak Lee honglak@umich.edu One fundamental difficulty in building algorithms that can robustly learn from complex real-world data is to deal with significant noise and irrelevant patterns. In particular, let X  X  consider a problem of learning from scratch , assuming the lack of useful raw features. Here, the challenge is how to learn a robust representation that can distinguish important (e.g., task-relevant) patterns from significant amounts of distracting (e.g., task-irrelevant) patterns.
 For constructing useful features, unsupervised feature learning ( Hinton et al. , 2006 ; Bengio et al. , 2007 ; Ran-zato et al. , 2007 ; Bengio , 2009 ) has emerged as a pow-erful tool in learning representations from unlabeled data. In many real-world problems, however, the data is not cleaned up and contains significant amounts of irrelevant sensory patterns. In other words, not all patterns are equally important . In this case, the unsu-pervised learning methods may blindly represent the irrelevant patterns using the majority of the learned high-level features, and it becomes even more diffi-cult to learn task-relevant higher-layer features (e.g., by stacking). Although there are ways to incorporate supervision (e.g., supervised fine-tuning), learning is still challenging when the data contains lots of irrele-vant patterns, as shown in ( Larochelle et al. , 2007 ). To deal with such complex data, one may envision us-ing feature selection. Indeed, feature selection ( Jain &amp; Zongker , 1997 ; Yang &amp; Pedersen , 1997 ; Weston et al. , 2001 ; Guyon &amp; Elisseeff , 2003 ) is an effective method for distinguishing useful raw features from irrelevant raw features. However, feature selection may fail if there are no good raw features to start with. To address this issue, we propose to combine feature learning and feature selection coherently in a unified framework. Intuitively speaking, given that unsuper-vised feature learning can find partially useful high-level abstractions, it may be easier to apply feature selection on learned high-level features to distinguish the task-relevant ones from the task-irrelevant ones. Then, the task-relevant high-level features can be used to trace back where such important patterns occur. This information can help the learning algorithm to focus on these task-relevant raw features (i.e., visible units corresponding to task-relevant patterns), while ignoring the rest.
 In this paper, we formulate a generative feature learn-ing algorithm called the point-wise gated Boltzmann machine ( PGBM ). Our model performs feature selec-tion not only on learned high-level features (i.e., hid-den units), but also on raw features (i.e., visible units) through a gating mechanism using stochastic  X  X witch units. X  The switch units allow our model to estimate where the task-relevant patterns occur, and make only those visible units to contribute to the final prediction through multiplicative interaction. The model ignores the task-irrelevant portion of the raw features, thus it performs dynamic feature selection (i.e., choosing a variable subset of raw features depending on semantic interpretation of the individual example).
 We evaluate our models in two ways: 1) recognizing handwritten digits in the irrelevant background, and 2) localizing and classifying objects in the natural scenes. In the first experiment, our method shows strong per-formance in learning features and distinguishing task-relevant features from task-irrelevant features. In the second experiment, our model shows promising results in distinguishing foreground objects from background scenes and localizing the object bounding boxes in a weakly-supervised way, which leads to an improved ob-ject recognition performance.
 We summarize our main contributions as follows:  X  We propose the PGBMs that jointly perform fea- X  We propose the semi-supervised PGBM and show  X  We show that the PGBM is an effective building  X  We propose a convolutional extension of the  X  We achieve a significant improvement over state-Our model can be viewed as a high-order extension of the restricted Boltzmann machine (RBM), and we briefly review it in this section. The RBM is an undi-rected graphical model that defines the distribution of visible units using binary hidden units. The joint distribution of binary visible units and binary hidden units is written as follows:
P ( v , h ) = E ( v , h ) =  X  where v  X  X  0 , 1 } D are the visible (i.e., input) units, and h  X  X  0 , 1 } K are the hidden (i.e., latent) units. Z is the normalizing constant, and W  X  R D  X  K , b  X  R
K , c  X  R D are the weight matrix, hidden and visible bias vectors, respectively. Since there are no connec-tions between the units in the same layer, visible units are conditionally independent given the hidden units, and vice versa. The conditional probabilities of the RBM can be written as follows: where  X  ( x ) = 1 1+exp(  X  x ) . Training the RBM corre-sponds to maximizing the log-likelihood of the data with respect to parameters { W , b , c } . Although the gradient is intractable to compute, contrastive diver-gence ( Hinton , 2002 ) can be used to approximate it. In this section, we propose the point-wise gated Boltz-mann machine and its extensions. In Section 3.1 , we describe the basic unsupervised PGBM that learns and groups features into semantically distinct components. In Section 3.2 , we propose the supervised PGBM that uses class labels as a top-down feedback to partition the hidden units into the task-relevant and the task-irrelevant components. In Section 3.3 , we propose the semi-supervised PGBM that uses unlabeled data as a regularizer when there are only a small number of labeled training examples. Furthermore, we con-struct a deep network using the PGBM as a building block, where we stack neural network layer(s) on top of the PGBM X  X  task-relevant hidden units. Finally, we present the convolutional extension of the PGBM that can efficiently handle spatially correlated high-dimensional data. 3.1. Point-wise Gated Boltzmann machines When we deal with complex data, it is desirable for a learning algorithm to distinguish semantically dis-tinct patterns. For example, an object recognition al-gorithm may improve its performance if it can separate the foreground object patterns from the background clutters. To model this, we propose to represent each visible unit as a mixture model when conditioned on the hidden units, where each group of hidden units can generate the corresponding mixture component. Before going into details, we describe the generative process of the PGBM as follows: (1) The hidden units are partitioned into components , each of which defines a distinct distribution over the visible units. (2) Con-ditioning on the hidden units, we sample the switch units . (3) The switch units determine which com-ponent generates the corresponding visible units. A schematic diagram is shown in Figure 1(a) as an undi-rected graphical model.
 The PGBM with R mixture components has a multi-nomial switch unit, denoted z i  X  X  1 ,  X  X  X  , R } , 1 for each visible unit v i . The PGBM imposes element-wise mul-tiplicative interaction between the paired switch and visible units, as shown in Figure 1(a) . Now, we define the energy function of the PGBM as follows: Here, v , z r and h are the visible, switch and hidden unit binary vectors, respectively, and the model pa-rameters W r ik , b r k , c r i are the weights, hidden biases, and the visible biases of r -th component. The binary-valued switch unit z r i is activated (i.e. takes value 1) if and only if its paired visible unit v i is assigned to the r -th component, and its conditional probability given hidden units follows a multinomial distribution over R categories. The energy function can be written in matrix form as follows: where the operator denotes element-wise multipli-cation, i.e., ( z r v ) i = z r i v i .
 The visible, hidden, and switch units are conditionally independent given the other two types of units, and the conditional probabilities can be written as follows: where we use W r i to denote i -th row, and W r k to denote k -th column of the matrix W r .
 It is important to note that, while inferring the hid-den units, our model gates (or re-weighs) each visible unit v i according to the corresponding switch units z r i (Equation 2 ). In other words, the point-wise multi-plicative interaction between the switch and the vis-ible units allows the hidden units in each component to focus on a specific part of the data, and this makes the hidden units in one component to be robust to the patterns learned by other components. Moreover, the top-down signal from the hidden units encourages as-signing the same mixture component to semantically-related visible units during the switch unit inference, and therefore we can prune out the irrelevant raw fea-tures dynamically for each example.
 It is worth noting that, when we tie all switch units (i.e., z i = z for all i ), the PGBM becomes equiva-lent to the implicit mixture of restricted Boltzmann machine ( Nair &amp; Hinton , 2008 ). Furthermore, given that there is a multiplicative interaction between three types of variables, the PGBM can be understood in the context of higher-order Boltzmann machines ( Se-jnowski , 1987 ; Memisevic &amp; Hinton , 2010 ). We train the PGBM with stochastic gradient descent using contrastive divergence. Since the exact inference is intractable due to the three-way interaction, we use mean-field or alternating Gibbs sampling (i.e., sample one type of variables given the other two types using Equations ( 2 ),( 3 ), and ( 4 )) for approximate inference. 3.2. Generative feature selection with Although the PGBM can learn to group distinct fea-tures for each mixture component, it doesn X  X  neces-sarily learn discriminative features automatically since the generative training is done in an unsupervised way. One way to make the PGBM implicitly perform fea-ture selection (i.e., distinguish features into different groups based on their relevance to the task) is to pro-vide a good initialization of the model parameters. For example, we can pre-train the regular RBM and di-vide the hidden units into two groups based on the score from the simple feature selection algorithms such as the t-test 2 to initialize the weight matrices of the PGBM. As we will discuss in Section 5 , this approach improves classification performance of the PGBMs. Furthermore, to make use of class labels during the generative training, we propose a supervised PGBM that only connects the hidden units in the task-relevant component(s) to the label units. The graphi-cal model representation is shown in Figure 1(b) . By transferring the label information to the raw features through the task-relevant hidden units, the supervised PGBM can perform generative feature selection both at the high-level (i.e., using only a subset of hidden units for classification) and the low-level (e.g., dynam-ically blocking the influence of the task-irrelevant vis-ible units) in a unified way.
 For simplicity, we present the supervised PGBM with two mixture components, where we assign the first component to be task-relevant. The energy function is defined as follows: subject to z 1 i + z 2 i = 1 , i = 1 ,  X  X  X  , D . The label vector y  X  X  0 , 1 } L is in the 1-of-L representation. relevant hidden units and the label units, and d is the label bias vector. The conditional probabilities can be written as follows: The conditional probabilities of the visible and switch units are the same as Equations ( 3 ) and ( 4 ). As we can see in Equation ( 6 ), the label information, together with the switch units, modulates the hidden unit ac-tivations in the first (task-relevant) component, and this in turn encourages the switch units z 1 i to activate at the task-relevant visible units 3 during the iterative approximate inference.
 We can train the supervised PGBM in generative cri-teria whose objective is to maximize the joint log-likelihood of the visible and the label units ( Larochelle &amp; Bengio , 2008 ). Similarly to that of PGBM, the in-ference can be done with alternating Gibbs sampling between Equations ( 3 ),( 4 ),( 6 ), and ( 7 ). 3.3. Variations of the model 3.3.1. Semi-supervised PGBMs There are many classification tasks where we are given a large number of unlabeled examples in addition to only a small number of labeled training examples. For this scenario, it is important to include unlabeled ex-amples during the training to generalize well to the un-seen data. The supervised PGBM can be adapted to the semi-supervised learning framework. For example, we can regularize the joint log-likelihood log P S ( v , y ) with the data log-likelihood log P S ( v ) defined on the unlabeled data ( Larochelle &amp; Bengio , 2008 ). We pro-vide more details in Section 5 and the supplementary material. 3.3.2. Deep networks The PGBM can be used as a building block of deep networks. For example, we can use it as a first layer block and stack neural networks on the hidden units of task-relevant components. Since the PGBM can select the task-relevant hidden units with supervision, the higher-layer networks can focus on the task-relevant information. In Section 5.1 , we show that the two-layer model, where we stack a single-layer neural net-work on top of a PGBM X  X  task-relevant component, was sufficient to outperform existing state-of-the-art classification performance on the variations of MNIST dataset with irrelevant backgrounds. 3.3.3. Convolutional PGBM Convolutional models can be useful in representing spatially or temporally correlated data. The PGBM can be extended to a convolutional setting ( Lee et al. , 2011 ), where we share the filter weights over different locations in large images. In Section 5.2 , we present the convolutional PGBM with an application to the weakly supervised foreground object localization prob-lem. Furthermore, by locating the bounding box at the foreground object accurately, we achieved state-of-the-art recognition performance in Caltech 101. For more details, see the supplementary material. As mentioned in Section 3.1 , the PGBM can be viewed as an extension of the implicit mixture of RBM (im-RBM) ( Nair &amp; Hinton , 2008 ) that allows per-visible-unit switching. Although these two models look sim-ilar, the per-visible-unit switching property of the PGBM brings an important benefit over the imRBM because it allows the PGBM to represent data with multiple components, each of which focusing on dif-ferent part of the raw features. In particular, the su-pervised PGBM represents the data with two groups of hidden units (one containing task-relevant hidden units and the other containing task-irrelevant hidden units). In contrast, the imRBM uses a single com-ponent to represent the data, and thus cannot dis-tinguish between the relevant and irrelevant patterns when the data contains significant amounts of irrele-vant patterns.
 The discriminative RBM (discRBM) ( Larochelle &amp; Bengio , 2008 ) is another model that can learn dis-criminative features using class labels. We argue that, however, the PGBM can be more robust to noisy data since it can prune out (or re-weigh) the irrelevant fea-tures dynamically for each data instance using switch unit activations, whereas the discRBM accumulates the contribution from noisy visible units with the fixed weights applied to all data instances. In Section 5.1 , we empirically show that the PGBM significantly out-performs both the imRBM and the discRBM in clas-sifying handwritten digits in the presence of irrelevant background patterns.
 Rifai et al. ( 2012 ) proposed the contractive discrim-inative analysis (CDA). Similarly to the PGBM, the CDA has two groups of hidden units, one of which is connected to labels. The difference is that the CDA is a feed-forward neural network which can learn dis-tinct features for each group with a contractive penalty term, while the PGBM is a probabilistic model that performs generative feature selection through a mul-tiplicative interaction between visible, hidden, and switch units.
 The robust Boltzmann machine (RoBM) ( Tang et al. , 2012 ) shares its motivation with our work, though there are several technical differences. First, the RoBM models each background noise unit with a unimodal Gaussian distribution, whereas the PGBM models the background visible units with more com-plicated multimodal distribution with a group of hid-den units. Furthermore, the PGBM can directly learn from the noisy data with class labels, but the RoBM requires clean data to pre-train the GRBM.
 In terms of energy function, the unsupervised PGBM can be viewed as having a similar formulation to the masked RBM ( Le Roux et al. , 2011 ; Heess et al. , 2011 ). However, our main motivation is to perform joint fea-ture selection at both low-level and high-level. Specifi-cally, the difference becomes clearer when we use class labels in supervised PGBM that performs generative feature selection, as discussed in Section 3.2 . 5.1. Recognizing handwritten digits in the We evaluated the capability of the proposed models in learning task-relevant features from noisy data. We tested the single-layer PGBMs and their extensions on the variations of MNIST dataset: mnist-back-rand , mnist-back-image , mnist-rot-back-image , and mnist-rot-back-rand . 4 The first two datasets use uniform noise or natural images as background patterns. The other two have rotated digits in front of the corre-sponding background patterns. We used the PGBM with two components of 500 hidden units, and initial-ized with the pre-trained RBM using the feature selec-tion as described in Section 3.2 . We used mean-field for approximate inference for all our experiments. 5 In Figure 2 , we visualize the filters and the switch unit activations for mnist-back-image . The foreground filters capture the task-relevant patterns resembling pen strokes (Figure 2(a) ), while the background fil-ters (Figure 2(b) ) capture task-irrelevant patterns in the natural images. Further, the switch unit activa-tions (the posterior probabilities that the input pixel belongs to the foreground component , Figure 2(c) ) are high (colored in white) for the foreground digit pixels, and low (colored in gray) for the background pixels. This suggests that our model can dynamically separate the task-relevant raw features from the task-irrelevant raw features for each example.
 For quantitative evaluation, we show test classification errors in Table 1 . For all experiments with our single-layer models, we used the  X  X ask-relevant X  hidden unit activations as the input for the linear SVM ( Fan et al. , 2008 ). The single-layer PGBM significantly outper-formed the baseline RBM, imRBM, and discRBM. 6 We did a careful model selection to choose the best hy-perparameters for each of the compared models. These results suggest that the point-wise mixture hypothesis is effective in learning task-relevant features from com-plex data containing irrelevant patterns. 5.1.1. Generative feature selection As a control experiment, we compared our model to the two-step model which we call  X  X BM-FS, X  where we first trained the RBM and selected a subset of hid-den units using feature selection. As we see in Table 1 , the RBM-FS is only marginally better (or sometimes worse) than the baseline RBM. However, the PGBM significantly outperforms the RBM-FS, which demon-strates the benefit of the joint training. 5.1.2. Semi-supervised learning The supervised PGBM can be trained in a semi-supervised way as described in Section 3.3.1 . We used the same experimental setting as ( Larochelle &amp; Ben-gio , 2008 ), and provided labels for only 10 percent of training examples (100 labeled examples for each digit category). We summarize the classification errors of semi-supervised PGBM, supervised PGBM, RBM and RBM-FS in Table 2 . The semi-supervised PGBM con-sistently performed the best for all datasets, showing that semi-supervised training is effective in utilizing a large number of unlabeled examples. 5.1.3. Deep networks Finally, we constructed a two-layer deep network by stacking one layer of neural network with 1,000 hidden units on the task-relevant component of the PGBM. We used softmax classifier for fine-tuning of the second layer neural network. Table 1 shows that our deep net-work (referred to as  X  X GBM+DN-1 X ) outperforms the DBN-3 and the stacked contractive autoencoder by a large margin. In particular, the result of the DBN-3 on mnist-back-image implies that adding more layers to the DBN does not necessarily improve the performance when there are significant amounts of irrelevant pat-terns in the data. In contrast, the PGBM can block the task-irrelevant information from propagating to the higher layers, and hence it is an effective building block for deep networks. Finally, we note that, to the best of our knowledge, the PGBM+DN-1 achieved state-of-the-art classification performance on all datasets ex-cept mnist-rot-back-image , where the transformation-invariant RBM ( Sohn &amp; Lee , 2012 ) achieved 35.5% error by incorporating the rotational invariance. 5.2. Weakly supervised object segmentation In this section, we extend our model to learn groups of task-relevant features (i.e., foreground patterns) from the images with higher resolution, and apply it to weakly supervised object segmentation. 5.2.1. Weakly supervised object segmentation Lee et al. ( 2011 ) showed that the convolutional deep belief network (CDBN) composed of multiple layers of convolutional RBM (CRBM) can learn hierarchical feature representations from large images. In particu-lar, the first layer of the CDBN mostly learns generic edge filters, and the higher layers learn not only com-plex generic patterns, such as corners or contours, but also semantically meaningful features, such as object parts (e.g., eyes, nose, or wheels) in the second layer or whole objects (e.g., human face or car) in the third layer. To learn and group related features from large images, we propose the point-wise gated convolutional deep network (CPGDN), where we use the convolu-tional extension of the PGBM (CPGBM) as a building block.
 Specifically, we construct the two-layer CPGDN by stacking the CPGBM on the first layer CRBM. This construction makes sense because the first layer fea-tures are mostly generic, and the class-specific features emerge in higher layers ( Lee et al. , 2011 ). We train the CPGDN using greedy layer-wise training method, and perform feedforward inference in the first layer. We use mean-field in the second layer for approximate infer-ence of switch and hidden units. Due to the space con-straint, we put more technical details of the CPGDN in the supplementary material.
 We first trained a CPGDN with two mixture com-ponents only on the single class of images from Cal-tech 101 dataset ( Fei-Fei et al. , 2004 ). For this ex-periment, we randomly initialized the weights without pre-training. We visualize the second layer features trained on  X  X aces X  and  X  X ar side X  classes in Figure 3 . The CPGDN made a good distinction between the task-relevant patterns such as face parts and wheels, and the generic patterns. In Figure 4 , we visualize the switch unit activation map, which shows that the switch units are selectively activated at the most infor-mative region in each image. Interestingly, using this activation map, we can segment the object region from the background reasonably well, though our model is not specifically designed for image segmentation. 5.2.2. Object recognition Inspired by the CPGDN X  X  ability to distinguish the foreground object from the background scene, we pro-pose a novel object recognition pipeline on Caltech 101 dataset, where we first  X  X rop X  each image at the bounding box predicted using the switch unit activa-tions of the CPGDN and perform classification us-ing those cropped images. Specifically, we used the CPGDN with two mixture components, each of which is composed of 100 hidden units. To train the model ef-ficiently from many different classes of images, we pre-train a set of second layer CRBMs with a small num-ber of hidden units (e.g., 30) for each class to capture more diverse and class-specific patterns, and perform feature selection on those CRBM features from all ob-ject categories to initialize the weights of the second layer CPGBM. Once we train the model, we compute the posterior of switch units arranged in 2d. To pre-dict the bounding box, we compute the row-wise and column-wise cumulative sum of switch unit activations and select the region containing (5,95) percentiles of the total activations as a bounding box. For classifi-cation, we followed the pipeline used in ( Sohn et al. , 2011 ), which uses the Gaussian (convolutional) RBMs with dense SIFT as input.
 We first evaluated the bounding box detection accu-racy. We declare that the bounding box prediction is correct when the average overlap ratio (the area of in-tersection divided by the union between the predicted and the ground truth bounding boxes) is greater than 0.5 ( Everingham et al. , 2010 ). We achieved average overlap ratio of 0 . 702 and detection accuracy of 88 . 3%. Finally, we evaluated the classification accuracy using the cropped Caltech 101 dataset with CPGDN and summarize the results in Table 3 . The object centered cropped images brought improvement in classification accuracies, such as 74.9% to 76.8% with RBM, and 77.8% to 78.9% with CRBM using 30 training images per class, respectively. 7 As a baseline, we also report the classification accuracy on the augmented dataset where we uniformly crop the center region across all the images with a fixed ratio. After cross-validating with different ratios, we obtain a worse classification accuracy of 75.8% with RBM using 30 training images per class. This suggests that the classification perfor-mance can be improved by localizing the object better than simply cropping the center region. In this paper, we proposed a point-wise gated Boltz-mann machine that can effectively learn useful fea-ture representations from data containing irrelevant patterns. Our methods achieve state-of-the-art clas-sification performance on several datasets that con-tain irrelevant patterns. We believe our method holds promise in building a robust algorithm that can learn from large-scale, complex, sensory input data. Acknowledgments This work was supported in part by NSF IIS 1247414 and a Google Faculty Research Award.
