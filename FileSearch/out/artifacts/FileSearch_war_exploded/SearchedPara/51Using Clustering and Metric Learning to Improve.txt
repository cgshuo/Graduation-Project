 DAVID S. HAYDEN, STEVE CHIEN, DAVID R. THOMPSON, and REBECCA CASTA  X  NO, In general, data from spacecraft can be c ollected at a much higher rate than can be transmitted to Earth. Bandwidth bottlenecks due to distance, power, visibility, and competing mission downlinks can significantly limit the lifetime science return of a mission. As a result, scientists must exercise great care in deciding which data to collect and transmit to Earth for analysis. For previously observed or static environments, such as most planetary surfaces imaged from orbit, data collection may be scripted so that specific targets are imaged at prearranged times. For unknown or dynamic environments, scripted data collection strategies may include sampling at random or periodic intervals. In both case s, relatively little is known about collected data until it has been downlinked. Returned images may exhibit substantial redun-dancy, be marred by artifacts, or may not be relevant to current science objectives [Thompson et al. 2008]. Additionally, scripted observations leave the collection of remarkable or unexpected data to chance and could miss key features.

These bandwidth constraints motivate onboard data analysis that could recognize key image content and prioritize the most informative observations for downlink. Previous work in onboard data understanding has been practiced on rover, satellite, and submersible platforms, and is well underway for UAVs [Clough 2002]. The Mars Exploration Rovers can autonomously search for science targets, including clouds and dust devils [Castano et al. 2008], as well as for rocks of specific size, albedo, and shape [Estlin et al. 2010]. For the Earth Observing 1 Satellite, hazardous events such as fires, floods, and volcanic activities are detected and pertinent data downlinked [Chien et al. 2005]. Terrestrial autonomy includes underwater exploration [Kinsey et al. 2006], mine and cave mapping [Thrun et al. 2005], and also exploration of Mars-like environments, such as the Atacama [Wettergreen et al. 2008] and Mojave [Calderon et al. 2008] deserts.

In many cases, it would be useful to complement target detection with represen-tative sampling [Casta  X  no et al. 2003; Gilmore et al. 2000]. Representative sampling characterizes the entire dataset by selecting archetypal exemplars from its principal classes, where these classes are not known or specified in advance. Representative sampling is formally equivalent to a vector quantization strategy for data compression [Gersho and Gray 1992]. In practice, one can treat it as a clustering problem in which a spacecraft groups images according to con tent and downlinks characteristic exam-ples of each cluster [Casta  X  no et al. 2007; Hayden et al. 2010]. Figure 1 demonstrates a graphical example.

Several factors complicate automatic clus tering. First, effective performance re-quires describing the data with numerical features that can be correlated well with its science content. These features should be invariant to irrelevant differences from changing imaging conditions or noise. Finding such features and implementing them in flight software is a difficult process that may need to be repeated for changing mission objectives. Moreover, interfeature redundancy and correlation can adversely affect clustering performance. Previous work shows that clustering with different feature subspaces can dramatically alter selective data-return performance [Hayden et al. 2010].

We desire a general method for learning an optimal image representation based on training data. Specifically, we generate many features and then learn a distance metric that places similar images close together and dissimilar images far apart. As mission objectives evolve and additional training data becomes available, new metrics can be trained on Earth. Then, oper ators can transmit this information to the spacecraft in the form of relatively compact parameters, such as linear transformation matrices. Computing distances with the learned metric is equivalent to projecting the original feature space and subsequently taking Euclidean distances. The resulting clusters should better reflect the distinctions in science content most relevant to mission objectives.

Onboard remote science analysis presents an additional complication. Traditional metric learning and feature selection require an internally consistent and authorita-tive set of training data. But in remote exploration, such ground truth standards may not exist. It will almost certainly not be possible to find a single partitioning of the data that satisfies all mission science goals simultaneously. It will probably be the case that there are many scientists, each with their own separate science goals, key distinctions, and clusterings. Relaxing the consistency assumption lets the learning process fully utilize a training set from multiple scientists and balance any competing objectives that they have assumed in their training labels.

In this article, we explore efficient metric-learning approaches to selective data re-turn. We demonstrate that clustering based on metric learning outperforms random or periodic collection strategies at producing partitions to match those made by sci-entists. We especially focus on the problem of satisfying multiple, competing mission objectives. In particular, we extend Linear Discriminant Analysis [Duda et al. 2000] to handle multi-class data with several inconsistent labelings and show that it out-performs modern metric-learning approaches in satisfying multiple competing science objectives. Throughout, we address practical and logistical constraints of implement-ing a clustering framework for selective data return.

Central to our work is the assumption that the utility of an automatic clustering is determined by how closely it matches clusterings made manually by scientists. While intuitive, this is not formally justified, and in this article, it is only demonstrated on a small terrestrial dataset.

In Section 2, we discuss clustering and metric-learning algorithms in the context of selective data return. We also introduce Multi-domain Multiclass Linear Discrim-inant Analysis (MDMC-LDA), a new metric-learning algorithm for handling multiple competing science objectives. In Section 3, we discuss our terrestrial dataset, labeling strategy, image features, and clustering performance evaluation strategy. Sections 4 and 5 detail our findings.
 Clustering provides scientists with considerable control over how downlink bandwidth is used. If scientists desire a summary of observed data, they can downlink repre-sentatives from each cluster. Alternatively, they can reallocate bandwidth to favor particular clusters that prove consistently interesting. Clustering in a metric space af-fords additional flexibility by allowing data to be rank-ordered by representativeness. Data closest to the centroid can be considered more representative, while an image far from any centroid may be an interesting outlier. Geolocating cluster representatives and outliers into a terrain map can facilitate subsequent mission planning.
Of the many clustering techniques available [Xu and Wunsch 2005], we focus on k-means [MacQueen et al. 1967] because it is fast, simple, and well understood. For R recomputes each centroid as c i = 1 | C of the sum-of-squares error of each x and its closest centroid c i when no c i change value and no x are assigned to a different cluster.

By perturbing each x to avoid degenerate cases, Arthur et al. [2009] have shown that k-means has polynomial runtime in n . In practice, the typical implementation [Lloyd 1982] often has linear or sublinear runtime [Duda et al. 2000]. If a suboptimal solution is sufficient, one can alter the algorithm to guarantee such performance. Im-provements of several orders of magnitude have also been demonstrated: Elkan [2003] exploits the triangle inequality, while Saegusa and Maruyama [2007] demonstrate an FPGA implementation running 30 times per second with d =3 , n = 512 2 ,and k = 256.
K-means requires that the number of clusters be determined in advance. This can be seeded by initial tests on the ground then adjusted throughout the course of a mission to determine if other values seem more useful. K-means also requires that careful consideration be given to the image descriptors used to represent each image. In exploration scenarios, an ideal clustering partitions the images into groups that reflect current objectives (fo r example, each cluster could contain images dominated by a particular topography). Constructin g an optimal feature space is a more subtle challenge that we will investigate further in Section 2.2. Metric learning can tune clustering behavior towards current or dynamic mission objectives without requiring modifications to flight software. Scientists would man-ually cluster data returned from the spacecraft. One can use these clusterings to construct a linear or nonlinear feature transformation that emphasizes their preferred distinctions. The scientists would transmit the parameters of this transformation back to the spacecraft 1 , which would then use it to form a mission-relevant feature space for cluster analysis of future observations.

Following Xing et al. [2002], we formulate the metric-learning task as follows. Given two sets of constraints in the form of pairs of similar and dissimilar data, metric-learning methods seek a projection in which similar data are close together and dis-similar data are far apart. We describe proximity with the L 2 -norm: for d -dimensional the d  X  d identity matrix. With metric learning, the identity matrix is replaced with a positive semidefinite or positive definite transformation matrix A that parameterizes a family of Mahalanobis distances in R d . A diagonal matrix A simply weights each dimension. Otherwise, the transformation is equivalent to a rescaling and rotation of the data. Computing the transformation for each distance computation is equiva-lent to projecting the feature space and subsequently measuring all distances with the standard Euclidean metric.

Yang [2007] provides an overview of metric-learning approaches. The foundational work of Xing et al. [2002] describes metric learning as a convex optimization problem which minimizes the sums of squared distances between similar data and pushes sums of squared distances between dissimilar data beyond a threshold. Other more recent approaches include Neighborhood Components Analysis [Goldberger et al. 2005] which minimizes the leave-one-out k-nearest-neighbor classification error. Largest-Margin Nearest Neighbor [Weinberger et al. 2006] also minimizes nearest-neighbor error but utilizes a largest margin framework that results in a convex optimization problem. Other metric-learning methods explore nonlinear transformations [Chen et al. 2007], active learning and Bayesian frameworks [Yang and Jin 2007], and online methods [Jain et al. 2009]. To establish a baseline, we restrict our attention to linear methods. Classical multiclass linear discriminant analysis (LDA or MDA) projects a d -dimensional data X = { x 1 ,... x N } with labels 1  X  l i  X  C : i =1 ,..., N into a ( C  X  1)-dimensional subspace that better separates each of the C classes. The Bayes classifi-cation error is optimally minimized when t he classes are Gaussian and homoscedastic (having equal covariance matrices). Mo re thorough coverage of MDA can be found in Friedman [1989] and Duda et al. [2000].

Our notation reflects the fact that the set of training data consists of just one self-consistent labeling. Let X 1 j be the subset of X corresponding to the single labeling X  X  j th class. Let n 1 j be the number of vectors in the j th class. We define the within-class scatter matrix as where co v ( X 1 j ) is the covariance matrix of the matrix whose columns are the vectors x  X  X be the mean of the j th class. Then, we define the between-class scatter matrix as
MDA simultaneously minimizes the projected within-class scatter and maximizes the between-class scatter. This is equivalent to finding a (non-unique) W that maximizes
The columns of the optimal projection W are the top eigenvectors of S  X  1 W S B [Duda et al. 2000]. Note that if dimensionality is high or there are few training samples, then S W may be singular. We avoid this condition with a simple regularization scheme where the columns of W are generated from ( S  X  1 W +  X  I ) S B . Designers can set  X  to a small value or optimize it with cross validation.

Many variations on MDA exist. Duin and Loog [2004], Hamsici and Martinez [2007], and Qin et al. [2005] relax the homoscedastic requirement. Ye [2006], Chen et al. [2000], and Howland et al. [2004] do not require nonsingularity. Friedman [1989] and Guo et al. [2007] provide regularization strategies. Space exploration scenarios will often involve multiple teams of scientists with inde-pendent and possibly competing objectives. This may make MDA impractical since it requires a single fixed number of classes and a single set of labels. Finding a con-sensus labeling among all teams might require a challenging negotiation. At worst, the basic task may be ill-posed if the labelers consider different aspects of the data. A more reasonable strategy would be to prompt each team to label relevant training data according to its individual objectives, and then learn a projection which mediated between them. Our algorithm, Multi-Domain, Multiclass Linear Discriminant Anal-ysis (MDMC-LDA) extends MDA to account for multiple, possibly inconsistant labels on multiple, possibly overlapping datasets.

We define a domain as a single independent labeling of the training data. The i th domain is characterized by a set of d -dimensional vectors with integer labels ranging from [1 , C i ]. We take X i to be the set of its vectors, with n i = | X i | . The labels of all domains are represented by L = { L 1 ,..., L D } , where L i = { l i 1 ,..., l in represents the total number of data points, each counted as many times as there are labels supplied for it (alternatively, we could simply say this is the total number of labels).

Our modification of MDA does not directly compare images across domains, since these semantic relationships are undefined. Two classes in different domains might represent the same semantic category, despite having different labels, in which case it would not be desirable to separate them. However, taken independently, the domains supply additional training data that can improve performance. Specifically, we treat each domain as an independent sample of the between-class and within-class sam-ple matrices. The expectation of these matrices, taken over all domains, provides a semantically-consistent solution. We define the within-class scatter as
Here C i =max L i and co v ( X ij ) is the covariance matrix of the matrix whose columns are the vectors x  X  X ij . We define the mean of the i th domain and also the mean of the j th class in the i th domain as
Similarly, we find a separate between-class scatter matrix for independent domains and average them to produce a final point estimate. This ignores proximity relation-ships across different domains.

As in Equation (4), we take the solution to be a W that maximizes the ratio of between-class and within-class scatter.

We again generate the columns of W by the top eigenvectors of ( S  X  1 W +  X  I ) S B ,where the regularization parameter  X  is determined through cross validation. If D =1, then MDMC-LDA degenerates to MDA. Notationally, the i subscripts in MDMC-LDA can be replaced with 1, and the solution W will be optimal if data are Gaussian and homoscedastic. For D &gt; 1, we do not expect these conditions will ever be satisfied in the case of overlapping labels. Informally, though, overlapping labels should push data with corresponding labels into proximity so that clusters can more naturally form that better satisfy all objectives. We thus hypothesize that the projected space will improve overall agreement between multiple labelers, although agreement with any one might be lower than if MDA were trained on that particular labeling. To demonstrate our clustering approach to onboard data analysis, we use 19 image descriptors that can be collected in subpolynomial time and use these to cluster im-ages from an aerial dataset. We investigate correspondence between these automatic clusterings and manual clusterings created by planetary geologists. We also consider clusterings that would result from nonadaptive or uninformed data return strategies, such as random sampling or periodic sampling at regular time intervals. We explore various alternative metric-learning approaches to improve performance, including the new MDMC-LDA algorithm. Most studies in onboard data understanding have focused on rover and satellite plat-forms. Here, we investigate aerial exploration scenarios, such as those proposed for Titan, by a blimp, or for Venus, by a fixed-wing craft [NASA 2006]. In the case of Titan, an autonomous blimp would likely travel for many kilometers X  X ometimes for more than a week X  X etween downlink opportunities and collect a vast number of tra-verse images over previously unseen and diverse terrain [Elfes et al. 2008]. Selec-tive data return could help discriminate between its morphological and atmospheric features, which are known to include hydrocarbon lakes, dried riverbeds, shorelines, mountainous and smooth desert-like terrain, sand dunes, clouds, and the occasional crater. Figure 2 shows some examples.

Rather than utilizing terrestrial or Martian satellite imagery, which may not cor-respond well with expected Titan imagery in color, resolution, or feature diversity, we simulated an aerial imaging sequence on Titan using 162 terrestrial scenes collected with a consumer camera at two megapixels during a commercial flight from New York to Los Angeles. Figure 1 demonstrates that the dataset primarily contains images dominated by sky, horizon, or undeveloped land. Some contain clouds, water bodies, patches of desert, or patches of vegetation.

To construct ground truth data for a disco very-oriented mission objective, we prompted four planetary geologists to manually group the dataset. All had some back-ground in remote sensing, but their areas of emphasis differed (e.g., volcanology, pale-obiology, geology). Images were presented in a graphical interface simultaneously and in random order. Scientists were allowed t o name, rename, create, and delete groups throughout the session. Directions were provided in the form of the following prompt. Fixing the number of groups to five controlled for strong variations that may have resulted from scientists pursuing objectives of radically varying complexity. We strive to automatically group images in a way that simultaneously agrees well with all scientist clustering strategies. P erfect correspondence is unlikely, but band-width utilization X  X nd thus science return X  X s still improved if autonomous strategies can group data more effectively t han nonadaptive strategies.

Two uninformed strategies for downlinking images are random sampling ,wherea random subset of an image sequence is returned, and periodic sampling , where every i th image of a sequence is returned. The former strategy amounts to a random clus-tering, while the latter is equivalent to clustering based on collection order. 2 We will subsequently refer to these strategies as random clustering and periodic or time-based clustering.

To compare correspondence between clusterings, we use the information-theoretic adjusted mutual information, which we briefly derive here. Given dataset S = { s ,..., s similarly for V ). Then, the probability that a random data s  X  S is also contained in some cluster U i or in cluster V j is given by the respective equations The probability that s is found in both clusters is given by The mutual information between the two labelings is defined as
Mutual information quantifies how much knowing about one clustering tells us about the other. Though it is symmetric and nonnegative, it is not upper-bounded by a constant, and so is of limited utility as a general metric for comparing cluster-ings. Furthermore, Vinh et al. [2009] demonstrate that mutual information does not take a constant value when comparing random clusterings and tends to grow with the number of clusters. They use a hypergeometric model of randomness to derive an expected value for two random clusterings. This permits a correction similar to the ad-justed rand index [Hubert and Arabie 1985] that ensures random clusterings produce a constant value. This correction yields the adjusted mutual information (AMI).
The entropies of clusterings U , V denote the uncertainty in a data point X  X  cluster membership.

The denominator in Equation (10) corrects for randomness and serves as a normal-ization, as otherwise MI ( U , V )  X  min( H ( U ) , H ( V )). Furthermore, AMI ( U , V )=0only when equal to its expected value (e.g., that expected by comparing two random cluster-ings), and AMI ( U , V ) = 1 when clusterings U , V are identical. In the experiments that follow, we use the AMI as a general measure of correspondence between clusterings.
Figure 3 demonstrates the advantages of both our metric-learning approach and our evaluation metric. Each figure shows two-class clusterings of synthetic data. On the left, (a) and (c) show four gaussians arranged into two classes such that k-means is unable to correctly cluster them. On the right, metric-learning algorithms bring all points of each class into proximity, enabling the desired clusterings. Note that the two classes in (a) are equal in size while the two classes in (b) are not. This affects the entropy of each class, which causes mutual information to give different values for (b) and (d), despite both being clustered perfectly. AMI permits a fair comparison between the two cases. Our primary concern is that image descriptors be fast enough for operation onboard power-restricted spacecraft computers (di scussed in Section 5). To that end, we do not examine the more common but computationally expensive and higher-dimensional ap-proaches, such as those based on SIFT features [Lowe 1999], Gabor filters [Grigorescu et al. 2002], or correlograms [Huang et al. 1997]. Instead, we present 19 low-level, computationally efficient features that summarize texture, color, and the temporal or-dering of each image. Except where noted, all features can be computed in linear time with respect to image size and can be trivially parallelized. Each feature is defined in Table I; relevant notation and definitions are established in subsections that corre-spond to the Feature Type column. 3.3.1. Texture. Let I be an m  X  d  X  3imageand I be its m  X  d grayscale. Let I be the resulting binary image from performing convolution with a Sobel operator on image I .Let G y , G x be the m  X  d matrices representing vertical and horizontal gra-dient responses, respectively. Let  X  L = G 2 y + G 2 x be the m  X  d matrix representing gradient magnitudes, and  X  =atan2( G y , G x )bethe m  X  d matrix representing gradi-ent orientations. Then, edge density and magnitude can help distinguish smooth from rough terrain, while gradient magnitude and orientation can provide information on texture regularity, which can help distinguish periodic textures (e.g., sand dunes, large expanses of sediment). Figure 4 shows a visualization of the edge densities between images with smooth and rough terrain.
 Let f be the resulting m  X  d matrix after the 2D Fourier transform on I ,andlet G ( f )= | f | 2 be the m  X  d power spectrum of f . Let the normalized power spectrum be N = G ( f ) / G ( f ). Then, taking the energy in the first and second quadrants (which are symmetric to the fourth and third) can provide good texture discrimination.
The frequency energy statistics were motivated by Liu and Jernigan [1990], which were found by a survey of 28 low-level frequency space statistics to best discriminate a subset of the Brodatz textures. The frequency features are an exception to the linear-time constraint since they require a fast Fourier transform. This is an n log n oper-ation, though there are many efficient hardware and software implementations (we also touch on this in Section 5). 3.3.2. Color. Let P j be the m  X  d matrix of pixels in band j of I .Thenhistogramsum-marization statistics taken on each band can help distinguish verdant from mountain-ous terrain, clouded from cloudless skies, and dried river basins from rivers. Figure 5 show an example. 3.3.3. Temporal. For a sequence of images collected in serial, let the acquisition order I be an integer that represents the temporal ordering of each image.
 We begin by examining the clusterings performed by each scientist. Figure 6 depicts class distributions and names for each scientist.

Priorities differed among the scientists. For instance, Scientists 3 and 4 made four distinctions in atmospheric qualities of the imagery, while Scientist 1 made two dis-tinctions, and Scientist 2 placed them into a single group. Roughly 40% of labels from Scientists 1 and 4 focused on atmospheric distinctions, compared to 68% for Scientist 3 and 14% for Scientist 2. All scientists, except for the third, created a group based on the presence of water, but these comprised only 6% of Scientist 4 X  X  labels, compared to at least 30% for Scientists 1 and 2.

Many of the scientists X  clusters corresponded for at least some images. For example, scientists consistently ascribed similar labels to images, such as (a) and (b), where the horizon was roughly centered and cloud cover was evident. Images, such as (c) and (d), that contained water bodies were often labeled consistently but only when there was no horizon or clouds present. The labeling consensus was weaker in the presence of sky or clouds. While Scientist 2 typically labeled an image as  X  X ydrology X  if it contained even a very small lake, Scientists 3 and 4 would often favor horizon and cloud labels as they began to become more prevalent, as can be seen with images (g) and (h). Unsurprisingly, Scientist 1 X  X   X  Desert X  label sometimes corresponded with Scientist 2 X  X   X  X ountain X  label, and both were often contained within the  X  X and X  labels of Scientists 3 and 4 (as in images (e) and (f)).

These differences imply that scientists were pursuing different objectives. In follow-up discussions, some suggested distinctions in atmospherics had been most important, while others preferred to disambiguate fea tures of the terrain. Table II quantifies the agreements between scientists by showing the adjusted mutual information between scientists X  clusterings. Scientists 1 and 3 had the highest agreement, at 0 . 4232. Scien-tist 2 appears as an outlier, with the lowest mean agreement among other scientists of 0 . 184, as compared to agreements of around 0 . 3 among the remaining scientists. The overall mean agreement of 0 . 285 is the expected mean AMI of any human strategy against the rest; it establishes a milestone for how well autonomous clusterings might simultaneously correspond to scientists X  clusterings.

We compared the correspondence of manual clusterings with various automated ap-proaches, including static data return strategies like random or periodic sampling. We also considered clustering approaches using the entire feature set, as well as feature spaces learned by metric-learning strategies based on scientist-labeled training data. We trained the metric-learning strategies on a uniformly sampled 25% training set, starting four times at image indices 1 to 4 for multifold cross validation. For each trial, we performed an automated k-means clustering on the remaining 75% of the data and evaluated the result using the AMI score. Because k-means results can be sensitive to initialization, we performed 1,000 randomized runs for each cross-validation subset.
Figure 7 compares mean clustering agreement between all scientists and strate-gies based on uninformed and autonomous methods. The red uninformed approaches represent random and periodic sampling. The unsupervised approaches in green rep-resent strategies that do not benefit from training data. The baseline approach is simple clustering with all 19 features from Section 3.3. The PCA approach uses prin-cipal components analysis to reduce dimensionality. The metric-learning strategies compare neighborhood components analysis (NCA), largest-margin nearest neighbor (LMNN), multiclass discriminant analysis (MDA), and multi-domain multiclass linear discriminant analysis (MDMC-LDA). MDMC-LDA used training labels from all scien-tists. The remaining metric-learning approaches were restricted to learning from a single set of labels. Experiments validated our intuition that learning would be most productive on the labels of the first scientist, who had the highest overall agreement with others. Dimensionality was reduced to d = 2 for PCA, NCA, LMNN, MDA, and MDMC-LDA. Comparisons were averaged over 1 , 000 trials.

Periodic sampling produ ced a mean agreement of 0 . 1648. Unsupervised methods marginally outperforms it at 0 . 1898 for clustering in 19 dimensions, and 0 . 1816 for clustering with PCA. Metric-learning strategies show obvious benefit over periodic sampling, with correspondence i mproving from 23% for NCA to 73 . 5% for MDMC-LDA. It is interesting to note that the more cla ssical MDA shows marked improvement over contemporary approaches.

Figure 8 compares mean clustering agreement relative to the first scientist. The same trends are evident: metric learning significantly outperforms unsupervised strategies, and both outperform uninformed strategies. All methods show improved correspondence. Remarkably and counterin tuitively, MDMC-LDA significantly out-performs all other approaches despite having to balance competing objectives. With AMI =0 . 3662, MDMC-LDA produces a clustering that more closely matches this sci-entists than do the clusterings of all but one other scientist.

Ideal clustering agreement would approach 1 . 0, particularly when autonomous clus-terings are attempting to match a single objective. The relatively low scientist agree-ment in our results suggests that such high correspondence will not be possible in the face of multiple mission objectives. Even so, with correspondence nearly double that of alternative strategies, clustering informed by metric learning could provide substan-tial gains in science return over a mission X  X  lifetime. Figure 9 provides some intuition on what clusters look like in a learned space. Figure 9 (a) displays a 2D projection of the test set using an unsupervised strategy (PCA) based only on the intrinsic structure of the data. Figure 9 (b) displays the same data projected with MDMC-LDA. Colors correspond to labels provided by the first scientist. Except in the case of the sparse  X  X esert X  cluster (comprising 3 . 7% of the data), cluster compactness and consistency is substantially improved when data is projected into a space that accounts for the scien-tist X  X  preferences. If a cluster representative were downlinked from each cluster (the image closest to each centroid), then three classes would be accurately identified. And even in the case of the red  X  X iver X  cluster, we would see reasonable behavior in that a  X  X and X  image would be downlinked. In other words, the learned feature space empha-sizes distinctions in science content that is not obvious from the distribution of base feature vectors. Many current space-based missions, such as the exploration of Mars by the Spirit and Opportunity rovers, or the imaging of Ear th or Mars by orbiters, involve research groups from around the world, each competing over limited bandwidth. Orbiter tar-gets are scheduled a year or more in advance. Rover actions and downlink priorities are debated by teleconference on a daily or weekly basis. In these static and largely observable environments, competing requests can be individually serviced. In essence, bandwidth can be distributed among different groups, even if it X  X  not to the satisfaction of all involved.

This would not be so easy in a dynamic or previously unobserved environment, such as Titan. While groups could influence the trajectory of an aerobot, it seems unlikely that downlink bandwidth could be precisely allocated without target detection capabil-ities that catered to the needs of individual groups. These objectives would be difficult to anticipate before launch, but they would almost certainly be in competition in the same way that scientists X  labels on our terrestrial dataset were competing. Supporting the changing objectives of each group with target detectors or other custom autonomy code would be hugely expensive, if not completely impractical, in large part due to the complexities involved in coding flight software [Dvorak et al. 2009].

Metric learning and clustering provide a mechanism for supporting changing mis-sion objectives by allowing scientists on the ground to further inform downlink deci-sions through small uplinks to the spacecraft that do not require modification to flight software. Although onboard feature extraction will not undergo many changes over a mission, scientists on the ground are free to experiment with training data and metric-learning techniques without concern for computational or flight hardware complexity. Our MDMC-LDA approach shows particular promise because it can balance multiple, competing objectives, perhaps without making great concessions to any individual ob-jective. Future work will investigate this behavior X  X mpirically on different datasets and theoretically on how objectives are balanced.

Our approach (feature extraction, cluste ring, metric learnin g) has been carefully chosen so that it is feasible on current spacecraft hardware (notably, BAE Systems X  RAD750 3 , in use on dozens of spacecraft). We accomplished this by keeping to fast, subpolynomial runtime. Future spaceflight processors will have greater computational power, with parallelism playing an increasing role. Potential architectures include OPERA 4 , the Xilinx Virtex 5 Pro 5 , and Coherent Logix X  X  Hyper X. 6 For our current approach, all feature extractors are trivially parallelized except for the frequency-domain texture descriptors, which rely on a Fourier transform. Work on ever-faster, even parallel implementations of the fast Fourier transform remains active, how-ever. The MIMD (multiple instruction, multiple data) parallelization of the FFT in Averbuch et al. [1990] would be appropriate for the OPERA platform. In addition to the optimizations we previously cited, k-means can also be parallelized (see for in-stance, Stoffel and Belkoniene [1999]).

With our current approach being amenable to parallelization, there may be head-room for more sophisticated clustering and feature extraction approaches as spacecraft hardware advances. The scientist labeling strategies that we saw for our terrestrial imagery demonstrated that a single image might be considered interesting based on different criterion, such as dominant terrain type (e.g., sky, desert, mountain), or pres-ence of a specific, possibly small feature (e.g., clouds, water). Our approach would likely be more flexible to these objectives if higher -granularity summarization statistics were employed, such as textons [Julesz 1981], wavelets [Manjunath and Ma 2002], or color-based features [Burghouts and Geusebroek 2009]. These descriptors often require al-ternative similarity measures (e.g., earth-movers distance [Rubner et al. 2000]), which are not readily implementable with k-means but could be with kernel-based methods. Additional spatial resolution can be obtained by taking statistics in the neighborhoods of interest points detected based on saliency, or more expensively, within individually detected regions or segments [Tuytelaars and Mikolajczyk 2008]. Future work will explore these methods on additional datasets and with larger numbers of scientists. The disparity between the amount of data that can be collected during the course of future space exploration missions and the amount that can be downlinked back to Earth is likely only going to increase. Onboard clustering provides scientists and mission planners with improved control over downlink bandwidth through selective data-return strategies, including representative sampling. Metric learning can tune clusterings for specific, even changing mission objectives through small uploads that do not require changes to flight software. Our new MDMC-LDA algorithm extends metric learning so that multiple, possibly competing objectives can be simultaneously accounted for. Using an aerial dataset and algorithms and features that could be im-plemented on current spaceflight hardware (and parallelized for future hardware), we show that autonomous clustering more closely corresponds with the way that four planetary geologists grouped images than do nonadaptive random or periodic sam-pling strategies. Metric-learning approaches further improved correspondence, with MDMC-LDA substantially outperforming contemporary methods.

