 Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran School of Computer Engineering, Iran University of Science and Technology, Tehran, Iran 1. Introduction
Organizations and companies share their data with others for a variety of purposes. They can use various methods and algorithms like statistical algorithms, machine learning algorithms and modeling algorithms to analyze data [1]. Data publishing causes considerable challenges on the security and pri-vacy of data [2]. Therefore, we need to find methods for data publishing, which not only preserve the privacy of data but also provide proper usage of data by others. There are several methods for privacy preserving data publishing (PPDP) [3,4]. The PPDP algorithms use transformation methods to disguise the original data. Randomization [5], k -anonymity [6,7] and l -diversity [8] are some well-known PPDP algorithms. These algorithms perturb the original data and then make available the resulting data to users. Users look for their particular information by applying proprietary data mining algorithms over the published data. It is clear that every action has a reaction. Although the data have been modified to the users, however, there are people who look for the methods to use them for restoring the original data from the perturbed data. Most of these methods are based on the users X  background knowledge.
The aim of this paper is to publish data for privacy preserving clustering (PPC), in which the objects are clustered without compromising their privacy. In clustering analysis, each object (i.e. data) is as-signed to a group (i.e. cluster) based on a defined similarity measure. Objects in a group will have high similarity to each other whereas they will be different from the objects of other groups [9]. For exam-ple, clustering customers according to their interests or clustering documents based on their subjects are examples of the clustering analysis [10]. The person X  X  sensitive data can be used in clustering analysis. For example, there is sensitive information of individuals in the records of a bank X  X  financial transac-tions. The owner of data (i.e. the bank) should not make available the individuals sensitive data for the public, because it is possible to involve untrusted party in clustering analysis. For example, suppose that national security agency (with a legal authority) needs to check the financial records of individuals in a financial institution. Therefore, the institution should release its records so that not only the national security agency can achieve its desired goal but also the sensitive information of the individuals is not disclosed. In most PPDP algorithms, it is assumed that an adversary has a little background informa-tion about the published data [3]. This assumption is incorrect. Record linkage, attribute linkage, table linkage and probabilistic attack are four types of attacks based on users X  background knowledge, which are discussed in details in [3]. In general, it is hard to estimate the degree of users X  background knowl-edge about the published data so the detection of all privacy breach methods will be actually impossible. Then, we must look for ways in which the concepts of background information and privacy are consid-ered independently. In other words, the ways in which the degree of adversary X  X  background knowledge does not matter in the privacy breach of particular data. Also, most existing algorithms are based on heuristic notions without provable security. Therefore, the concept of epsilon differential ( -differential) privacy is introduced to overcome these problems [11]. The main purpose of differential privacy is that the small changes in the input cause small changes in the output of the algorithm applied to the pub-lished data. It means that the output of the algorithm must be independent from inputs. From differential privacy viewpoint, it does not matter how much information an adversary may have about a particular data. Therefore, it is one of the strongest definitions about the privacy concept, which also has a strong mathematical basis. Unfortunately, most differential-based algorithms are suffering from poor utility. Also, another issue in the clustering analysis is high dimensionality of data, which reduces the efficiency of the clustering algorithms [4].

The intuition of this research has been to propose a PPDP algorithm for PPC pur pose. Our motivations are as follows: 1. First, it is to separate the concept of privacy and the users X  background knowledge. Therefore, in 2. Second, it is to reduce the dimensionality of data. High dimensional data causes extremely difficult
To achieve these goals, we have used the following properties:  X  Guarantee -differential privacy . There are many methods to guarantee -differential privacy. The  X  Achieve an appropriate level of utility and lower dimension . There are several techniques for data
We have proven that the differential privacy of the proposed algorithm. To evaluate both the privacy and the quality of clustering, the proposed algorithm has been implemented and experimented using several appropriate datasets. We have also compared the proposed algorithm with recently introduced PrivateProjection algorithm [14] based on the utility and privacy guarantees. Like several other studies, the Euclidean distance is used to measure the similarity between two objects for clustering. Also, the utility of the publis hed data is considered to be the quality of clustering (QOC) measure corresponding to clustering algorithm applied over the published data.

The rest of this paper is organized as follows. In Section 2, basic concepts of the proposed technique are briefly reviewed. Related works are introduced in Section 3. In Section 4, the proposed technique is presented. In Section 5, the privacy of the proposed technique has been proved. The experimental are given in Section 6. In Section 7, the proposed technique is compared with the PrivateProjection algorithm. Finally, some concluding remarks are mentioned in Section 8. 2. Background
In this section, some basic concepts, which are used in this paper, are presented. Clustering, the privacy measures in data mining, Haar wavelet transform (HWT), and the concept of differential privacy are briefly explained in this section. 2.1. Clustering
In recent years, due to the massive volume of data collected by organizations, new methods have been developed, which are different from the traditional analysis methods. These new methods are known as data mining methods where clustering is one of them. In general, data mining methods are divided into prediction methods [15] and description methods [16]. The prediction methods are the most common type of data mining methods in which a labeled input/output pairs is delivered to the system as training sets. The goal of the system is to learn a function, which can be used to determine the label of new entries. In description methods, the label of data is not available and the system tries to find the hidden structure of the unlabeled inputs in order to assign them to the meaningful groups. The clustering is a description method, which assigns a number to each object. This number shows the group in which the object is fallen. There are many algorithms, which are introduced for clustering purpose. k -means clustering [17] is the most popular of them. The work in [18] is the latest extension of the k -means algorithm. One of the most important tasks in the clustering technique is to determine the similarity measure between the shows the similarity (distance) between the two data objects x and y : 1. d ( x, y ) &gt; 0, for all data objects x and y and d ( x, y )= 0 only if x = y .( Positivity ) 2. d ( x, y )= d ( y,x ) , for all data objects x and y .( Symmetry ) 3. d ( x, y ) d ( x, z )+ d ( z,y ) , for all data objects x, y and z .( Triangle inequality )
In clustering techniques, different measures are used to evaluate the similarity between objects. One can find the latest of them in the work introduced in [20], which is based on the distance metric learn-ing. In other words, distance-based similarity is the most popular measure for evaluating the similarity between two objects. It is up to the researcher to select the right distance measure for her/his specific algorithm. The following are some of the distance-based measures, which can be applied on two data objects x and y , where each of them has n attributes: 1. Euclidean distance [16]: The Euclidean distance between two data objects x and y, is calculated as 2. Squared Euclidean distance [21]: In this measure, the distance between two objects is computed 3. City block (Manhattan, taxicab, L 1 norm) distance [16]: This measure is calculated by distance ( x, 4. Chebychev distance [21]: This measure is calculated by distance ( x, y )= maximum | x k  X  y k | . 5. Power distance [21]: This measure is calculated by distance ( x, y )=( n k =1 | x k  X  y k | p ) 1 /r ,where The Euclidean distance is the popular similarity measure, which is used in many existing techniques. In this paper, we will use the Euclidean distance due to the following reasons: 1. The Euclidean distance is one of the most widely used concepts in geometry from ancient times to 2. This measure not only satisfies positivity , symmetry and triangle inequality conditions but also is 3. According to the Parsevel X  X  theorem [12], the Euclidean distance between two objects is preserved 4. In most existing PPC algorithms, the Euclidean distance is selected to measure the similarity of 5. There exist many algorithms, such as the algorithm introduced in [22] that maps the Euclidean dis-2.2. The privacy measures in data mining
In general, the privacy measures can be classified into three types [4]: statistical methods, probabilis-tic methods, and computational methods. In statistical methods, the privacy is measured based on the variance of the perturbed data. The higher the variance, the higher the privacy will be. Query restric-tion [23], anonymity via variance [5] and anonymity via multiplicity [7] are the measures that fall in this category. There is no possibility to measure the adversary X  X  background knowledge in the statis-tical methods. Therefore, the probabilistic methods were developed. In these methods, the tools such as  X  X nformation theory X  and  X  X ayesian analysis X  are used to measure the degree of privacy. In [24,25], probabilistic methods are used to evaluate the privacy. In parallel with the development of probabilistic methods, the measuring of privacy based on the resource (computationally)-bounded adversary has been developed [4]. This method measures the privacy in terms of the amount of information accessible to an adversary. The algorithm presented in [11] is an example in which the privacy is measured based on computational methods. From mathematical viewpoint, computational methods are attractive rather than other approaches. Differential privacy is one of them in which there is no assumption about the adversary X  X  background knowledge. 2.3. Haar wavelet transform (HWT)
Wavelet transforms are useful computational tools, which are used in various areas, such as noise reduction, compression and so on. A signal (dataset) can be converted into wavelet domain using wavelet transforms. There are well-known properties and theorems in the wavelet domain such as the Parsevel X  X  theorem and the multi-resolution analysis (MRA) property, which can be used to solve some problems like data dimensionality reduction. HWT is the easiest of all discrete transformations, which has the simplest orthogonal basis. Based on MRA, Haar wavelet decomposes the original signal (dataset) from the high scale (level) to the scale (level) 0 recursively. It is necessary to mention that we will use the terms scale and level interchangeably. In this research, it is considered that the original data is located in the highest scale and there are two types of coefficients in each scale: the approximation coefficients and the wavelet coefficients. An example of a HWT is given below.

Consider the original data (9, 7, 3, 5), which is located in the scale 2 [26]. In HWT, the length of data must be the power of 2; otherwise, the data is padded with enough zero. We first average the array values, (scale) 1. As you can see, some information (wavelet coefficients or detail coefficients) in the averaging process (decomposition process) has been lost. To restore the original data, it is essential to have both the approximation coefficients and the wavelet coefficients. Therefore, we need to save the wavelet within the scale 1. Applying the averaging process on the scale 1, the approximation coefficient of the scale 0, namely the value ( 8+4 2 ) = (6) will be gained. The decomposition process will be stopped when the scale index reaches to 0. Table 1 shows Haar wavelet decomposition process on the values (9, 7, 3, 5). As you can see, the information is neither gained nor lost in the decomposition process. A pictorial view of HWT can be showed using  X  X rror tree X  (ET) structure [27]. ET is a complete binary tree with an additional node that is attached to its root. It has 2 m leaves where m is the scale of the original data.
In the above simple example, the value of m is 2 (2 2 = 4). Each leaf V i is associated with a value in the original data, and each internal node C i is associated with a wavelet coefficient value (Fig. 1). The formula C = Av l  X  Av r 2 will be used to determine the value of each internal node C (except the value of C 0 )where Av l ( Av r ) shows the average value of the all leaf nodes on the left (right) side of the node C [28]. The value of node C 0 , which is called the base coefficient, is the average value of all leaf nodes [28]. In the above example, the value of C 0 is 6. Also, the value of C 1 is 2 because the average value of all leaf nodes on the left (right) side of C 1 is Av l = 9+7 2 =8 ( Av r = 3+5 2 =4 ). Hence, C 1 = 8  X  4 2 =2 . The rest of the coefficients are calculated in the same way. The data ( C 0 ,C 1 ,C 2 ,C 3 )= (6, 2, 1,  X  1) is the wavelet transformation of the example data.

To restore the original data, the formula v = c 0 + l i =1 ( g i .c i ) can be used [28] where C i shows the ancestor node value of v in the level i and the value of g i equals 1 (  X  1) if the node v is located on the left (right) side of sub-tree C i . For example, the value of V 2 is equal to C 0 + C 1  X  C 2 =6+2  X  1= 7. 2.4. Differential privacy Differential privacy is one of the strongest notions of privacy, which was introduced by Dwork [29]. As we explained in Section 2.2, differential privacy falls in the computational methods category [30]. In differential privacy, we can be sure that changing a single attribute value in the original dataset will not affect the output of the algorithms. Let T and  X  T be two datasets differing in at most one user X  X  one attribute value and f be a function such that f ( T )= x and f  X  T =  X  x .Ifthevalue x be approximately equal to the value  X  x , it is said that the system has differential privacy property. Hence, we need a mech-anism such as A to fill the gap between the output (real data) of function f and the users. The output of f must be delivered to the mechanism A .Next, A perturbs them and finally makes the result available to the users. In differential privacy, the background knowledge of the users is not considered. In other words, the background knowledge is not important. Differential privacy is defined as follows. Like the work in [14], we adopt a slight variant of the definition introduced in [29]: Definition 1. The mechanism A is -differential if for all datasets T and  X  T , which differ in only one entry X  X  one attribute value, the following condition is satisfied: where S  X  Range ( A ) .

L1-sensitivity is a key concept to generate the data with epsilon differential privacy property. If we model the dataset as a vector of m entries from some domain D of the form R n [31] (we can consider each dataset T  X  D m as a matrix with m rows and n columns where each row represents the information contributed by one individual), the definition of L1-sensitivity is as follows (we adopt a slight variant of the definition introduced in [31]): Definition 2. [31] The L1-sensitivity of a function f : D m  X  R k is the smallest number S ( f ) such that for all datasets T  X  D m and  X  T  X  D m , which differ in a single attribute of one entry, the following condition is satisfied:
The symbol || . || 1 shows the L1 distance (or L1 norm) between the two objects. 3. Related work
For data mining, the data are published by data provider. Also, the privacy breach is one of the major problems in data publishing. Privacy preserving data publishing (PPDP) concept is developed to resolve the privacy problem of the published data [3,30]. Many algorithms have been introduced for PPDP, which some of those are related to privacy preserving clustering (PPC) purpose. The goal of PPC is to cluster the objects without revealing their private information. The introduced algorithms for PPC are divided into two general categories [32]: 1. The algorithms in which only the privacy is preserved. 2. The algorithms in which not only the privacy is preserved but also the dimension of data is reduced.
The PPC was first introduced by Oliveira et al. [33]. Oliveira and Za X ane [33] proposed an algorithm to resolve PPC problems based on the first category in horizontally distributed data. In [33], geometric transformations, which include shift, scaling and rotation, are used to perturb the original data. The Euclidian distance will be preserved using these transformations (except scaling). The algorithm in [33] has a low degree of privacy. It also does not reduce data dimension. The random projection (RP) is another algorithm for PPC [34], which is based on the second category. In RP algorithm, the data matrix is multiplied by a random matrix. The elements of th e random matrix are random variables, which are drawn from the normal distribution with mean of 0 and variance of 1. Multiplying the data matrix by random matrix will cause reduction in the dimension of data from m to k ( k m ) where m and k are respectively the original data and the perturbed data dimensions.

In [35], a generalized matrix-theoretic framework, abbreviated by FRAPP, has been presented to facil-itate a systematic approach to the design of random perturbation schemes for privacy preserving mining. Using FRAPP, it is possible to construct new perturbation mechanisms for minimizing the model re-construction error while ensuring amplification-based privacy [36] guarantees. The main drawback of FRAPP is that the degree of a particular individual privacy leakage is not considered.

In [37], the algorithm, abbreviated by DCT-H, is proposed for PPC, which belongs to the second category. The important feature of Fourier transform is the backbone of DCT-H algorithm. In the Fourier transform, the Euclidean distance is preserved in the transform domain. DCT-H algorithm preserves the privacy of data not only in centralized environments but also in distributed systems. In [37], the discrete cosine transform is first applied on the dataset. Then, the highest coefficients within each perturbed record coefficients are selected and their indices are stored in a matrix, DL . Next, the algorithm counts for each coefficient with the index j , which is the number of rows in DL that contains it. Finally, the k coefficient with highest frequency in DL will be selected and permuted in a random order and then, the permuted selected coefficients are sent to the third party. HWT-S is another algorithm for PPC, which is introduced in [32,38,39]. This algorithm belongs to the second category. HWT-S algorithm uses HWT to reduce the dimension of data. In HWT-S algorithm, HWT is first applied on each row of a specific dataset to decompose them. This process is called decomposition process, which will cause each row of dataset to be divided into two parts: approximation coefficients and wavelet coefficients . Applying decomposition process recursively on the approximation coefficients of the previous step will cause each row of the dataset to be decomposed from high level to the level 0. Decomposition process is automatically stopped at the level u if the condition m E ( D u ) &lt; m E ( D u  X  1 ) is satisfied where m E ( D u the dataset records.

The above algorithms not only have been proposed based on heuristic notions without provable privacy guarantees but also are vulnerable based on the adversary X  X  background knowledge. Therefore, it may be applied on four general background knowledge-based attacks (i.e., record linkage, attribute linkage, table linkage and probabilistic attack) against the above algorithms, which are discussed in details in [3]. The -differential privacy concept is a way to resolve the adversary X  X  background knowledge. This concept was proposed by Dwork [11], which is described in Section 2.4. Based on differential privacy, little change in the input will cause little change in the output. Therefore, an adversary will not be able to determine, which entry within the original dataset has been changed.

Several algorithms have been introduced based on differential privacy area for clustering purpose. The works in [40,41] introduced algorithms for obtaining k -means cluster centers. In [40], sub-linear queries output perturbation framework is used, which was introduced by Dwork and Nissim [41], whereas [42], a generic sampling-based procedure is introduced, which allows one to release a function f ( x ) accurately on many databases x , in order to release k -means cluster centers privately. In [43], privacy integrated queries (PINQ) is introduced, which is an extensible data analysis platform, to provide unconditional privacy guarantees for the records of the underlying datasets. The work in [43] has applied the PINQ platform to write an easy adaptations of k -means algorithm, introduced by [40]. Feldman et al. [44] consider the problem of constructing differentially private geometric data structures known as core sets. In [44], after applying the private core set scheme on the input set P and obtaining a core set C ,any clustering algorithm/heuristic for k -median can be applied on C privately.

Our approach differs from the above differential-based clustering algorithms. Especially, when our proposed algorithm is trying to generate an -differential-based perturbed data with lower dimension (than the original data) in order to publish the resulting data for public. Also, the resulting data of our proposed algorithm can be used by other distance-based data mining algorithms. Recently, the work in [14] introduced a Euclidean distance-based algorithm to publish data privately. It is proved that the introduced algorithm in [14] guarantees ( ,  X  )-differential privacy. First, it applies a random Johnson-Lindenstrauss transform to the original data (to obtain much lower dimension data than the original data) and then adds random variables (noise) drawn from a normal distribution to each entry of the resulting data. Also, in [14] a recovery algorithm for applying over the published data to estimate the squared distance between two users is introduced. Our -differential-based method is similar to the work introduced in [14], except we apply wavelet transform instead of Johnson-Lindenstrauss transform. The intuition of using wavelet transform is twofold: 1. In [38], it is showed that wavelet transform preserves the Euclidean distance of perturbed version of 2. To obtain the perturbed dataset with much lower dimension than the original data using the well-
Also, we apply the Laplace distribution noise instead of normal distribution noise to guarantee -differential privacy. The Laplace distribution noise provides the worst case of privacy guarantee (( , 0)-differential or the more stringent privacy guarantee) whereas normal distribution noise has more le-nient guarantee of privacy (( ,  X  )-differential privacy, where  X  =0 ). The proposed algorithm has been implemented and experimented using several datasets. The results show that the proposed algorithm has an appropriate level of utility corre sponding to quality of clustering me asure. Also, we have compared the proposed algorithm with the algorithm introduced in [14]. This comparison is based on privacy and the amount of noise added to the elements of published data. 4. The proposed technique
As mentioned earlier, the users X  background knowledge plays an important role in breaching the pri-vacy of published data. Differential privacy is a strong notion of privacy [11,29], introduced to solve this problem. In differential privacy definition, tracing of input X  X  change based on the output X  X  change is not possible. Also, no matter how much prior knowledge is owned by adversaries. Therefore, we will use this definition for proposin g a new algorithm for PPC. There are ma ny ways to guarantee differential privacy. As mentioned in Section 2.4, Laplace mechanism is one of them, which guarantees the worst case privacy. Therefore, to resolve the users X  background knowledge, we will propose an algorithm for PPC based on the Laplace mechanism to guarantee differential privacy. There are two main problems associated with most of the existing differential-based PPC algorithms: (1) the nature of differential pri-vacy definition, which adds noise to the published data, and (2) the high dimensionality of published data. These two problems cause the utility of algorithms to be decreased. We will use HWT properties to overcome the above problems.

In this section, we present the proposed algorithm for PPC. Having an appropriate degree of both privacy and utility are t he most important goals of the proposed al gorithm. It is worth to mention that by utility, we mean the quality of clustering concept, which will be described in detail later in this paper. The proposed algorithm tries to establish a good trade-off between privacy and utility. The data with high utility and low privacy will result in t he privacy breach of individuals. Also, the data with high privacy and low utility is not applicable by the users. 4.1. Assumptions
In the proposed technique, the following assumptions have been made: 1. Each dataset T is considered as a matrix with m rows and n columns where each row represents the 2. There is a positive value T Max , associated with the dataset T , so that the absolute value of each 4.2. Details of the proposed algorithm
In this section, we present the details of the proposed algorithm for differential privacy preserving clustering based on HWT, abbreviated by DiffHWT , for centralized datasets. As mentioned earlier, using the Parsevel X  X  theorem [12], a combination of the condition expressed in [13] with our heuristic method and the Laplace mechanism [31] are three important components, which construct the main structure of the proposed algorithm.
 The proposed algorithm is presented in Fig. 2. Let T m  X  n be the original dataset. For applying HWT, the length of each record must be power of 2; otherwise, the record should be padded with enough zeros. Also, the input dataset is normalized by dividing all coordinates by the value T max , associated with the dataset T m  X  n (Section 4.1). Therefore, all values within the original dataset T m  X  n have been transferred to the new intervals [  X  1, 1] (if we suppose that the dataset T contains both positive and negative values) or [0, 1] (if we suppose that the dataset T contains only positive values) (lines 1 and 2). Suppose that R m  X   X  n denotes the resulting data generated by two above processes where n is the smallest power of 2, greater than or equal to n , obtained in line 1. In lines 4 and 5, HWT has been applied over R m  X   X  n . As described in Section 2.3, the records of the dataset R m  X   X  n have been located in initial level (scale) log (  X  n ) . Applying HWT over the records of the dataset R m  X   X  n will cause each record to be decomposed into approximation and wavelet coefficients. These coefficients will be located within the lower level. This process is also known as decomposition process.

Algorithm 1 (Fig. 2) receives the value s as input parameter, which determines the stop level of the decomposition process. Therefore, the decomposition process will be stopped in the level s. On one hand, the size of the approximation coefficients of each record (within R m  X   X  n )inthelevel s is 2 s .On the other hand, if the approximation coefficients of each record in the level s have been indexed from 1 to 2 s ,thevalueoflast 2 s  X  (  X  n  X  n ) n coefficients will be zero. The reason is as follows.
As mentioned earlier, for applying HWT, the size of each record must be power of 2; otherwise, each record should be padded by enough zeros. Let  X  n be the smallest power of 2, which is greater than or equal to n . Then, we must add  X  n  X  n zero value to the end of each record. Whenever the decomposition process is applied over the approximation coefficients (of each record) in a particular level l , those coefficients have been decomposed into approximation and wavelet coefficients in the level l  X  1 so that the length of the approximation coefficients in the level l  X  1 is half of the length of the approximation coefficients in the level l . Therefore, if the records have been decomposed until the level s ,  X  n 2 s is the value that each coordinate of the original dataset has been divided by that (based on Haar wavelet decomposition process). Hence, the number of zeros in the end of the approximation coefficients (of each record) in d =2 s  X  2 s  X  (  X  n  X  n )  X  n first approximation coefficients within the level s (line 6).
The remaining pseudo-codes of Algorithm 1 (Fig. 2) are straightforward. In line 7, matrix Y m  X  d shows the approximation coeffients of records in the level s. In other words, the i th row of Y m  X  d represents which the coordinates of original dataset have been transferred, has been computed ( IntervalLength ). If we consider that the original dataset only contains the positive values ( hasnegativevalues = false ), the coordinates will be transferred to the interval [0, 1], whose length is IntervalLength = 1; otherwise, if we consider that the original dataset contains both positive and negative values (( hasnegativevalues = true ), the coordinates will be transferred to the interval [  X  1, 1], which its length is IntervalLength = 2. In line 9, the magnitude of a Laplace distribution (  X  ) has been computed based on s , IntervalLength , and  X  n . In line 10, a random m  X  d noise matrix has been constructed, in which each element is drawn independently at random from a Laplace distribution with mean 0 and magnitude  X  . In line 11, Laplace random noises are added to the matrix Y m  X  d . Finally, the final resulting data, i.e P m  X  d ,has been published by data provider. It is worth to mention that the dimension of matrix P is much lower compared to the dimension of original dataset T ,i.e. d n . We will prove later in this paper that the proposed algorithm guarantees -differential privacy.
 is as follows: Also, suppose that the input parameters of Algorithm 1 (Fig. 2) are as follows: T Max = 10, s = 2, =1 and hasnegativevalues = false . First, each element of matrix T is divided by T Max . As you can see, n =8 is the smallest power of 2, which is greater than or equal to n = 5. Therefore, each record of th e resulting data is padded with enough zero values to generate the 5  X  8 matrix R .Thematrix R is as follows: The length of each record in R is 8 so the initial level of decomposition process will be log(8) = 3. Table 2 shows the decomposition process over R .
 first approximation coefficients (in the level 2) of each record be collected in the matrix Y .Hence,the In this example, the value of hasnegativevalues is false . In other words, it is supposed that the matrix T only contains positive values. Hence, the value of IntervalLength will be 1. Next, a random noise matrix has been constructed so that whose entry is drawn independently at random from a Laplace be as follows: 5. Epsilon differential privacy of the proposed algorithm
In this section, we prove the -differential privacy of the proposed algorithm. Differential privacy is the strong notion of privacy, which we introduced in Section 2.4. In this definition, the users X  background knowledge will lose its vital role in the privacy breach. In other words, the degree of background knowl-edge is not important for the system privacy. In the proposed algorithm, line 11 (Fig. 2) adds Laplace random variable with a particular magnitude to the dataset, which we want to release it. In other words, by adding the Laplace random variable, we can be su re that little change with in the inputs w ill cause lit-tle change within the outputs. Hence, we will have the published data with differential privacy property. The above addition process is called Laplace mechanism. In [31], it is proven that the data generated using Laplace mechanism has differential privacy property. L1-sensitivity is a concept, which plays a vital role in differential privacy notion. This concept was defined earlier in Section 2.4 (Definition 2) for a single function. For a subset of functions we have the following definition (we adopt a slight variant of the definition introduced in [28]): Definition 3. [28] Let F show the subset of real-valued functions like f . The L1-sensitivity of F is the smallest number S ( F ) such that for all datasets T and  X  T , which differ in only one entry X  X  one attribute value, the following condition is satisfied:
Also, the following theorem explains that the Laplace mechanism satisfies the differential privacy property.
 Theorem 1. [28,31] Let F be a set of real-valued functions with L1-sensitivity S ( F ) . Suppose that M is an algorithm, which adds Laplace noise (with magnitude  X  ) to the output of each function f  X  F . Then, M satisfies -differential privacy, where = S ( F )  X  .

Now, we are ready to prove the -differential privacy of the proposed algorithm. Therefore, we have the following theorem. Theorem 2. The proposed algorithm satisfies -differential privacy.
 Proof Let Y m  X  d be the resulting matrix constructed by applying lines 1 through 7 of Algorithm 1 (Fig. 2) over the original dataset T . Suppose that we increase or decrease only one element of the original dataset T m  X  n by a constant value  X  . Without the loss of generality, let the element t  X  X  ( 1  X  m, 1  X  n ) be changed to t  X  X  +  X  . Please note that, if we apply lines 1 through 7 of Algorithm 1 over the modified version of T m  X  n , only one element of matrix Y m  X  d will be changed, namely the element, which its location is the crossing of row  X  and column  X  = 2 s  X   X  n +1 , namely y  X  X  (because of apply HWT). The amount of change within the coordinate y  X  X  can be computed as follows. In line 1 of Algorithm 1 (Fig. 1),  X  is divided by T Max .Let  X  =  X  T (decomposition process) over the resulting dataset until level s . Haar wavelet decomposition process has been described in Section 2.3. Hence, in the level s , each value of the original dataset has been divided by . Therefore,  X  will be changed to  X  (  X  n process is applied independently over each row. Therefore, the elements (the approximation coefficients of matrix R records) of matrix Y (in the line 7 of Fig. 2) will not be changed except the element y  X  X   X  Y that dataset T contains both negative and positive values, the maximum absolute value of  X  will be 2 (The reason is that in the worst case, if we suppose that t  X  X  = T Max (  X  T Max ) , the maximum value of  X  can be  X  2  X  T Max (2  X  T Max ) in order to satisfy the relation | t  X  X  +  X  | T Max (based on Section 4.1). Therefore, |  X  | 2  X  T Max  X   X  =  X  T are only positive values ( T do not include negative values), the maximum value of  X  will be 1 (similar to above description). Therefore, the amount of change within the coordinate y  X  X  is 2 s  X   X   X  n where the value of  X  is 2 (if dataset T contains both negative and positive values) or 1 (if dataset T contains only positive values).

Also, each element y ij (1 i m, 1 j d ) within the dataset Y m  X  d can be regarded as the output of a real-valued function f ij so that f ij maps the original dataset T to y ij .Inotherwords, f ij ( T )= y ij (1 i m, 1 j d ) . Hence, we can consider F as the set of real-valued functions { f pose that, we change the value of only one coordinate of table T ,say t  X  X  , by a constant value  X  ,for generating the dataset T . Applying the functions of set F over the dataset T and  X  T , respectively, will construct the same dataset Y m  X  d except in the value of element y  X  X  where  X  = 2 s  X   X   X  n +1 .Basedonthe relation: According to Eq. (5), we have:
Therefore, according to Definition 3, L1 -sensitivity of F will be S ( F )= 2 s  X   X   X  n . Hence, according to Theorem 1, if we add the random variables drawn from a Laplace distribution with mean 0 and magnitude  X  to the output of each function f  X  F , the proposed algorithm will satisfy -differential privacy where the value of  X  will be computed as follows:
It is worth to mention that the value of  X  and the value of IntervalLength ( line8ofFig.2)arethe same. Hence, in Eq. (7), we replace IntervalLength instead of  X  . Therefore, we have:
In line 10 of Fig. 2, the proposed algorithm construct a random m  X  d noise matrix , in which each element is drawn independently at random from a Laplace distribution with mean 0 and magnitude  X  = generate the matrix P m  X  d for publishing. Therefore, the proposed algorithm guarantees -differential privacy. 5.1. How can we choose the value of s in order to achieve an appropriate degree of both utility and
As mentioned earlier, our goal is to publish a dataset with appropriate degree of both privacy and utility. By utility, we mean the quality of clustering. As you can see, Eq. (8) determines the value of  X  , which is the magnitude of Laplace noise addition. The lower value of  X  will cause the amount of random variable drawn from a Laplace distribution to be close to zero. Therefore, we expect that adding these random variables to the elements of a particular dataset Y , will cause only a slight change of the Euclidean distance between two objects of Y , which in turns cause the resulting data to generate an appropriate quality of clustering.
 According to Eq. (8), the value of  X  is related to the values of s , IntervalLength ,  X  n and . Interval-Length , n are the out of our control variables. In [45], the value of is also considered as the public value and it is assumed that may select the values such as 0.01, 0.1 or even in some cases Ln (2) or Ln (3). Although in most studies, it is assumed that the value of is 2 but it seems that it is better that the value of not to be greater than 1. Therefore, the value of can be considered as a constant value. Hence, the only variable that we can select is s. According to Eq. (8), two variables  X  and s are directly proportional. The lower the value of s , the lower the value of  X  . The condition expressed in [13] can be used in order to obtain an upper bound value for s . First, we have some definitions: Definition 4. [13] Let X  X  R  X  n and  X  X  X  R  X  n (  X  n is the power of 2) are considered as two datasets. Definition 5. [13] The energy of a dataset X  X  R  X  n is calculated using E ( X )=  X  n i =1 x 2 i formula. Definition 6. [13] Suppose that the wavelet transformation is applied on the dataset X .Let A j  X  R m and D j respectively represent the approximation and the wavelet coefficients of the dataset X in the level j . The energy difference between X and A j is ED ( X,A j )= E ( X )  X  E ( A j )=  X  n i =1 x 2 i  X 
Suppose that j  X  [0 ,...,L  X  1] represents the current level of a dataset based on the wavelet trans-form. The transformed version of X in the level j can be shown as H j ( X )= { A j ,D j ,...,D L  X  1 } where L =log(  X  n ) is the level that the original dataset X is located, A j represents the approxima-tion coefficients of X within level j and D l ( j l L ) shows the wavelet coefficients of X within have H j  X  X = { A j , 0 ,..., 0 } . If we calculate the energy difference between X and  X  X ,thevalue SSE X,  X  X = ED ( X,A j ) can be achieved. In other words, the energy difference between X and  X  X is the total energy of all removed wavelet coefficients within the level j and higher levels.

In [13], it is shown that if we decompose all records of a particular original dataset X from the highest level to the level zero and we can be able to find the level u in which the Eq. (9) is satisfied, the approximation coefficients within the level u can be used instead of the original data where m E ( D u ) represents the sum of all wavelet coefficients of all records within the dataset X in the level u :
As you can see, in the initial level log(  X  n ) , where the original dataset is located, there are no wavelet coefficients. Therefore, the condition expressed in Eq. (9) is not true for the initial level. Therefore, decomposition process will be run at least one time. Hence, u log (  X  n )  X  1 . Using the Eq. (9), we can obtain an upper bound value for s . The experimental results show that the value u +1 may generate the better result compared with the value u . Hence, suppose that the following equation has been considered: ( log (  X  n ) is the maximum level, where the records of original dataset have been located): Therefore, we consider the upper bound value ub for s , namely s ub ,whichinturns s log (  X  n )  X  1 . Therefore, the Eq. (9) will give us an upper bound value in order to obtain an appropriate value for s .To do so, we use following heuristic method:
After obtaining the level u, we repeat the decomposition process until the level 0. Next, we start from the level 0 to the level ub in order to obtain the smallest level s (0 s ub ) , where the amount of quality of clustering (for grouping the objects into 2 cluster) obtained by applying k -means algorithm over the approximation coefficients within the level s will be greater than or equal to a determinate constant value q ;otherwise, s should be considered to be u. In this paper, the quality of clustering has been computed based on F-measure and its maximum value is 1. In other words, if all objects within dataset have been grouped correctly, the value of F-measure will be 1. In this paper the value of q is considered to be 0.80. After applying the above process, the resulting dataset Y will be the approximation coefficients within the level s . It is worth to mention that our proposed algorithm generates the better quality of clustering if it be able to transform a dataset T with higher dimension to a much lower dimension dataset. The experimental results show that the above heuristic method generates a dataset with appropriate quality of clustering.
 6. Experiments
In this section, we show the efficiency of the proposed algorithm based on the quality of clustering concept. We have used a prototype implementation of the proposed algorithm in Microsoft C#.NET. Then, we have run the implemented program over some datasets, which are used in most similar works. The results show that the proposed algorithm has a good quality of clustering (along with preserving differential privacy). 6.1. Clustering quality measure
To measure the utility or th e quality of clustering (QOC) of the proposed algorithm, we accomplish the following three steps in sequence. In the first step, we determine the clusters in which each record falls. In the second step, we determine the clusters in which each sanitized record falls. Finally, in the third within the original data and the cluster of its corresponding perturbed record within the transformed data. Therefore, the QOC measure can be calculated.

F-measure is a well-known measure in the field of information retrieval. In this research, we use F-measure concept in order to measure QOC. This measure determines how and to what degree a cluster in the perturbed data is similar or close to its corresponding cluster in the original data [32,39]. To do so, we first create a k  X  k clustering membership matrix (CMM), where k is the number of clusters provided by the user (as shown in Table 3).

Each row of CMM shows the clusters in the original data and each column shows the clusters in the perturbed data. Each element of CMM is represented with the symbol freq i,j . Each value freq i,j shows the number of records of cluster c i in the original data, which fall into the cluster  X  c j in the perturbed data. After calculating the elements of CMM, we can use the following formulas to obtain the values of Precision ( P ij ), Recall ( R ij )and F-measure ( F ij ) [37]:
Let F ( c i ) be the highest value within all values of a row with the index i , which is related to cluster c . The overall F-measure ( OF ) will be calculated as follows: The higher the value of OF , the higher the efficiency of algorithm will be. The maximum value of OF is 1. 6.2. The selected datasets for the experiments
In this section, we introduce the selected datasets to evaluate the proposed algorithm. These datasets have been used in many similar works. Three real-life datasets and two synthetic dataset are used in our experiments. These datasets are downloaded from two different sites.  X  Synthetic Control Chart Time Series  X  (SCCTS), Pendigits , X  Breast Cancer Wisconsin  X  X nd Ionosphere are downloaded from UCI Ma-chine Learning Repository [48]. Also, the synthetic dataset is generated using a batch file program downloaded from [49]. The above datasets contain numerical attribute values without missing values and with various distributions. For example, the 14 th attribute of Pendigits dataset have a skewed dis-tribution whereas its 13 th attribute follows a uniform distribution. Table 4 shows the properties of the selected datasets. 6.3. The degree of data dimension reduction
Before applying the data mining algorithm over a particular data, reducing the dimension of data is one of the most important issues, which has been attracted the attention of many researchers in recent years. There is an inverse relationship between the efficiency of data mining algorithm and the dimen-sion of the input data. That is, as dimension of the input data increases, the efficiency of data mining algorithm decreases and vice versa. Feature extraction and feature selection are two general methods for the reduction of data dimension [50]. In feature extraction, new features are generated using the exist-ing features whereas in feature selection, a number of features are selected within the existing features. Our proposed algorithm fall into the feature extraction methods. It uses both HWT and The Parsvel X  X  theorem to reduce the dimension of data in order to increase the efficiency of data mining algorithms on one hand and the much less noise addition to the resulting data in order to have an appropriate degree of utility on the other hand. In the proposed algorithm, we apply our heuristic method (Section 5.1) in order to achieve the level s in which there is a good trade-off between the degree of privacy and the degree of utility. Whenever the decomposition process is applied over the data, half of the data (wavelet coef-ficients) will be removed. Therefore, we will have a significant reduction in data dimension. It is worth to mention that in the initial level, which the original data is located, there are no wavelet coefficients. Therefore, the condition expressed in Eq. (9) is not true for the initial level. Then, the decomposition process will be run at least one time and in the worst case, the dimension of the perturbed data will be half of the dimension of the original data. Table 5 shows the decomposition process number, the original data dimension X  X  number and the perturbed data dimension X  X  number in the DiffHWT algorithm, which is running over the datasets described in Section 6.2. For example, the dimension of the original dataset Breast Cancer Wisconsin is 31. Then, the decomposition process is run over this dataset five times. Therefore, the dimension of the corresponding perturbed dataset of Breast Cancer Wisconsin will be 1. 6.4. The quality of clustering
In this section, we present the quality of clustering (QOC) of the published data, generated by the proposed algorithm, evaluated based on the measures we described in Section 6.1. To do so, we first have applied our algorithm over the original dataset to obtain the perturbed version of it. Then, k -means algorithm is applied over the records of both the perturbed dataset and the original dataset to cluster them. Finally, overall F-measure Eq. (10) is calculated to determine how and to what degree a cluster in the perturbed dataset is similar or close to its corresponding cluster in the original dataset.
In this research, the QOC measure in the clusters 2, 3 and 4 have been studied. In line 11 of the proposed algorithm (Fig. 2), the Laplace random variables are added to the elements of the matrix Y in order to disguise Y, based on differential privacy property. Therefore, if we run the proposed algorithm for multiple times over a particular original dataset, in each time, not only the different perturbed data but also the different amounts of the QOC measure will be obtained. Suppose that we want to group the records of the original (or the perturbed) dataset into k clusters where k is 2 or 3 or 4. To do so, we will run the proposed algorithm 100 times over the particular original dataset, T, in order to generate 100 different perturbed dataset. Each time that proposed algorithm runs over T , we will obtain the perturbed dataset P i as the output of the algorithm where 1 i 100 ( i is an integer value). Next, we apply the k -means algorithm over the original dataset, T , and the perturbed dataset, P i (1 i 100) ,inorderto group their records into k clusters separately ( k is an integer value). We are now able to calculate the QOC between T and its perturbed version, P i (1 i 100) , using the formula expressed in Eq. (10). Therefore, we will have 100 different values for the QOC between T and its perturbed version, P i ,fora particular cluster k where 1 i 100 and 2 k 4 . Finally, we will find the maximum value within those 100 values as the QOC between an original dataset and its perturbed version dataset.

As mentioned earlier, Laplace random variables are added to the data in order to guarantee the dif-ferential privacy property. The magnitude  X  of Laplace random variables has a key role in the degree of data privacy. In Theorem 2 (Section 5), it is proved that our algorithm guarantees -differential privacy words, the value of identifies the degree of the noise, which must be added to the original data. Smaller values of give more privacy and = 0 shows that no information will be obtained from the published data. In [45], the value of is considered as the public value and it is assumed that may select the values such as 0.01, 0.1 or even in some cases Ln (2) or Ln (3). Although in most studies, it is assumed that the value of is 2 but it seems that it is better that the value of not to be greater than 1. In this research, the value of is considered to be 1. Therefore, the values of  X  along with s should be chosen so that the condition =1 is satisfied. For example, let X  X  consider Breast Cancer Wisconsin dataset. According to Table 4 (Section 6.2), its dimension is n =31 ,whichinturns  X  n =32 . Also, we consider that all the values within Breast Cancer Wisconsin dataset are positive. Therefore, IntervalLength = 1 . Based on our heuristic method (Section 5.1), the value of s is zero. Therefore, if the value of has been Laplace random variables with mean 0 and magnitude  X  = 0.03 are generated and added to the elements of dataset Y . For the rest of the datasets, the above process will be done.

Tables 6 through 10 represent the results of executing the proposed algorithm over each dataset, de-scribed in Table 5, for 100 times (100 trials) in the clusters 2, 3 and 4 independently where d o , d r , Max-OF, Min-Of, Avg-OF , Std-OF and K are respectively the dimension of the original dataset, the dimension of the final (published) dataset, the maximum value of OF within 100 trials, the minimum value of OF within 100 trials, the standard deviation of the 100 trials and the number of clusters. The value  X  shows the magnitude of Laplace random variables, which is drawn for each particular dataset independently. Also, shows the differential privacy parameter value. IntervalLength (i.e., the length of level where decomposition process has been stopped),  X  n (i.e., the smallest power 2 value greater than or equal to the length of each record of original dataset) and T Max (i.e., the maximum value associated to each table T , which each elements of T could not exceed from that) have been discussed in Section 5. As mentioned earlier, by appropriate choosing of the value  X  ,thevalueof will be 1 for all experimented datasets. The results of the experiments show that the generated published dataset, which are the outputs of the proposed algorithm, has a good QOC along with an appropriate privacy guarantee, namely =1 . 7. Comparison of DiffHWT with PrivateProjection
In this section, we compare the proposed algorithm with recently proposed PrivateProjection algo-rithm [14] based on the degree of both privacy and utility (or quality of clustering (QOC) measure). In order to compute QOC, we need to find the Euclidean distance between the objects. If we add high amount of noise to each element of a particular dataset, the Euclidean distance between two objects will be changed in higher degree compared with less noise addition. Therefore, less noise addition will cause higher QOC compared with high degree of noise addition. As mentioned earlier, in [38], it is shown that wavelet transform preserves the Euclidean distance of the perturbed version of two objects better than Johnson-Lindenstrauss transform so the data quality of clustering generated using wavelet transform will be superior compared with the data quality of clustering based on Johnson-Lindenstrauss transform. The results of comparison between a wavelet-based algorithm (i.e., HWT-S) and a Johnson-Lindenstrauss-based algorithm, random projection (RP) obtained from [38], confirm the above claim. Hence, we compare the above two algorithms based on (1) the degree of privacy and (2) the amount of noise, which are added to the elements of a particular dataset in order to satisfy differential privacy preserving property. First of all, we discuss PrivateProjection algorithm as follows: PrivateProjection algorithm is based on Johnson-Lindenstrauss transform [51]. First, it constructs a random n  X  d projec-tion matrix R . Then, a Boolean (values in [0, 1] can be used instead of Boolean values) m  X  n original dataset T is multiplied by R in order to project T to obtain a much lower dimension dataset Y m  X  d .Next, a random noise matrix m  X  d , which its elements have been drawn from a normal distribution is added satisfies ( ,  X  )-differential privacy. The definition of ( ,  X  )-differential privacy is as follows: Definition 7. [14] A randomized algorithm A satisfies ( ,  X  )-differential privacy, if for all inputs T and  X  T differing in at most one user X  X  one attribute value, and for all sets of possible outputs D : where the probability is computed over the random coin tosses of the algorithm.

The following Lemma has been proved in [14] and it gives the conditions in which the PrivateProjec-tion guarantees ( ,  X  )-differential privacy.
 Lemma 1. [14] Let the projection matrix R be n  X  d matrix whose entries are i.i.d. N (0, 1 /d ) (normal distribution with mean 0 and variance 1 /d ) random variables. PrivateProjection using the noise matrix whose entries are sampled from N (0,  X  2 )satisfies( ,  X  )-differential privacy if: and
In [14], a recovery algorithm, abbreviated by RecoverDistancePP, has also been introduced, which can be used in order to estimate the Euclidean distance between two users. By using the recovery algo-rithm, an adversary may apply a sophisticated attack to infer the sensitive information of a particular user (the ability to identify that two users are similar constitutes a privacy violation). Therefore, to fair com-parison, only the published matrix P m  X  d is compared with the output matrix of our proposed algorithm, namely DiffHWT . 7.1. Comparison based on the privacy degree
According to line 11 of the proposed algorithm (Fig. 2), we add random Laplace noise to each element of matrix Y to obtain the matrix P for publishing. Random Laplace noise addition guarantees the worst case of privacy [14] compared to the normal noise. In Theorem 2 (Section 5), it is proved that the proposed algorithm guarantees -differential privacy. Based on Definition 7, ( , 0)-differential privacy is equal to -differential privacy. In other words, the value of  X  is zero (0) in our proposed algorithm. On the other hand, in PrivateProjection ,if  X   X  0 ,thevalueof d  X  X  X  (based on d&gt; 2(ln( n )+ln(2 / X  )) , expressed in Lemma 1), which is not true, because in PrivateProjection it is supposed that the value of d is much less than the value of the original dataset dimension. Also, it is considered that the original dataset dimension is limit. Therefore, in PrivateProjection ,thevalueof  X  could not be zero. Hence, in a fixed value of , the privacy of our proposed algorithm is superior compared with the privacy of PrivateProjection. 7.2. Comparison based on the amount of noise added to the published dataset To do so, we prove the following lemma first: Lemma 2. Suppose that matrix P m  X  d = Y m  X  d + m  X  d has been constructed by applying the proposed algorithm DiffHWT (Fig. 2) over the original dataset T m  X  n , where the matrix m  X  d is a random matrix whose elements are drawn from a Laplace distribution with mean 0, magnitude  X  = 2 s  X  IntervalLength  X  n  X  where the parameters s , IntervalLength ,  X  n and have been described in Sec-tion 5. The variance of Laplace noise added to the matrix Y m  X  d satisfies the following condition: Proof The proof of this lemma is straightforward. As mentioned earlier, there are no wavelet coef-ficients in the initial level, where the original datas et is located. Therefore, the condition expressed in Eq. (9) is not true for the initial level. Then, the decomposition process will be run at least one time and in the worst case, the dimension of the perturbed data will be half of the dimension of the original data. Therefore, u log (  X  n )  X  1 where n is the smallest power 2 value, which is greater than or equal to n the maximum value of IntervalLength is 2 so tervalLength 2 . Therefore, using the above conditions, we will have the inequality  X  1 . Also, The variance of a Laplace distribution with mean zero and magnitude  X  is  X  2 =2  X  2 . Therefore,  X  =  X 
Now, we are ready to compare the proposed algorithm with the PrivateProjection algorithm based on the amount of noise, which is added to the published data. In the DiffHWT algorithm, the amount of  X  is zero and in the case that the value of is fixed, the value of  X  is less than or equal to  X  in the PrivateProjection algorithm dependents on the value of  X  . According to Lemma 1, the inequality  X  4 ln (1 / X  ) is satisfied for PrivateProjection. Then, for a fixed value of ,when  X   X  0 ,thevalue of  X   X  X  X  . For example, if the values of and  X  have been considered to be 1 and 0.1 respectively, the maximum value of  X  in DiffHWT will be will be 6.06. Also, 0.75 percent of a specific distribution values lie within two standard deviations of the mean, based on Chebychev X  X  inequality [52]. The mean of random variables within the above two algorithms is zero. Therefore, our proposed algorithm adds much less amount of noise compared to the PrivateProjection algorithm. The lower the value of noise, the better the Euclidean distance will be, which in turns cause the higher QOC. Therefore, our proposed algorithm has better QOC measure compared to PrivateProjection .

Also, we have implemented PrivateProjection algorithm based on the conditions expressed in Lemma 1 without using the RecoverDistancePP algorithm. First, we apply the PrivateProjection algorithm to the rescaled version (into interval [0, 1]) of datasets  X  BreastCancer Wisconsin  X ,  X  Pendigits  X  X nd X  Synthetic  X , as the PrivateProjection algorithm considers only values within the interval [0, 1]. Next, we compute the overall F-measure (OF) between the original dataset and its corresponding perturbed dataset by applying the k -means clustering algorithm to them.

Tables 11 X 13 show the experimental results of PrivateProjection algorithm in the clusters 2, 3 and 4 independently where d o , d r , Max-OF, Min-Of, Avg-OF, Std-OF,  X  , T Max and K are respectively the dimension of the original dataset, the dimension of the final (published) dataset, the maximum value of OF within 100 trials, the minimum value of OF within 100 trials, the standard deviation of OF within 100 trials, the standard deviation of the noise needed according to Lemma 1, the maximum value associated with the original table T (Section 4.1) and the number of clusters. Also, and  X  show the privacy parameters according to Lemma 1. As you can see, by comparing Tables 11 and 6, we can conclude that in a fixed value of =1 , the QOC of the proposed algorithm is superior compared to the QOC of the PrivateProjection algorithm in the  X  Breast Cancer Wisconsin X  dataset. Also, the comparison of Table 12 and Table 8 shows that in the  X  Pendigits X  dataset, the proposed algorithm has also better QOC compared to the PrivateProjection algorithm. The same results can be obtained for  X  Synthetic  X  dataset whenever we compare two Tables 10 and 13. It is worth to mention that the symbol d , used in Tables 11 X 13, represents the parameter d , expressed in Lemma 1. In other words, the symbols d and d r are the same. Also, according to Lemma 1, the values of  X  and d r satisfy the inequalities  X  4 ln (1 / X  ) and d&gt; 2(ln( n )+ln(2 / X  )) respectively. For example, in  X  Breast Cancer Wisconsin  X  dataset, if =1 and  X  =0 . 1 ,thenwewillhave  X  6 . 069 and d r &gt; 12 . In other words, in Tables 11 X 13, we show the minimum values of  X  and d r . On the other hand, the lower the value of  X  , the higher values of  X  and d r will be, as  X  4 ln (1 / X  ) and d&gt; 2(ln( n )+ln(2 / X  ) . Therefore, we can conclude that if  X  be less than 0.1 (  X &lt; 0 . 1 ), we will obtain the lower QOC compared to  X  =0 . 1 , as the amount of noise addition will be increased. To better compa rison of the proposed algor ithm (DiffHWT) and the PrivateProjection algorithm, we gather the maximum values (within 100 trials in the clusters 2, 3 and 4) of both algorithms X  OF in Table 14. As you can see, the proposed algorithm (DiffHWT) has superior QOC compared to the PrivateProjection algorithm. 8. Conclusions Privacy preserving data publishing (PPDP) is a sub-branch of the privacy preserving data mining. The aim of PPDP is to design the transforming methods for disguising dataset. Randomization [5], k -anonymity [6,7] and l -diversity [8] are the algorithms designed for PPDP. In these algorithms, the data will be published to the users after changing them and the users can use the data mining algorithms over the published data to get information for his/her own use for any purpose. But there is a problem. The users can breach the privacy of the published data using their background knowledge. Record linkage, attribute linkage, table linkage and probabilistic attack are important attacks, which can be applied over the published data. The basis of the above attacks is the users X  background knowledge. The differential privacy is the strong notion of privacy to overcome this threat. The main important goal of differential privacy is to change the original data so that littl e change in the input data causes little change in the output. There are many ways to guarantee the differential privacy property in the published data. Adding Laplace random variables to the values of the original data is one of them, which is called Laplace mechanism.

In this paper, the privacy of the published data in clustering algorithms is studied. The most existing al-gorithms for privacy preserving clustering (PPC), do not take into account users X  background knowledge. Therefore, breaching of data privacy by using background knowledge may be possible. To overcome this privacy threat, we introduced a PPC algorithm based on the differential privacy concept, abbreviated by DiffHWT.

Most existing algorithms in differential privacy area suffer from poor utility. The proposed algorithm provides an appropriate degree of utility. In the proposed algorithm, Haar wavelet transform (HWT) is used to reduce the dimensionality of the original dataset in order to (1) increase the efficiency of the data mining algorithm, and (2) add much less noise to the published data because of the perturbation nature of Haar wavelet X  X  decomposition process. In addition, the Laplace mechanism is used to guarantee the differential privacy of the published data.

We have proven that the proposed algorithm guarantees the differential privacy preservation. Also, the proposed algorithm has an appropriate level of utility or quality of clustering, comparing to the existing differential privacy algorithms, which mostly suffer from poor utility. In addition, by appropriate mapping, the non-Euclidean distance-based algorithms will also be able to use the output of the proposed algorithm. The proposed algorithm is implemented and experimented with real-life datasets, which are used in most similar researches. The results represent that the proposed algorithm generates the perturbed dataset from a specific original dataset such that not only the privacy of the perturbed dataset is preserved but also it has a good quality of clustering when the clustering algor ithms are applied on it.
In future, we intend to use other wavelet transformations, such as Daubechies wavelet transform, in order to compare the results with the results of this research. Also, we intend to extend the proposed algorithm for horizontally and/or vertically distributed datasets.
 References
