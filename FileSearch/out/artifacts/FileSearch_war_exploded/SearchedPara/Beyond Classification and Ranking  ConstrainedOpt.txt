 Classification has been commonly used in many data mining projects in the financial service industry. For instance, to predict collectability of accounts receivable, a binary class la-bel is created based on whether a payment is received within a certain period. However, optimization of the classifier does not necessarily lead to maximization of return on investment (ROI), since maximization of the true positive rate is often different from maximization of the collectable amount which determines the ROI under a fixed budget constraint. The typical cost sensitive learning does not solve this problem either since it involves an unknown opportunity cost due to the budget constraint. Learning the ranks of collectable amount would ultimately solve the problem, but it tries to tackle an unnecessarily difficult problem and often results in poorer results for our specific target. We propose a new al-gorithm that uses gradient descent to directly optimize the related monetary measure under the budget constraint and thus maximizes the ROI. By comparison with several classi-fication, regression, and ranking algorithms, we demonstrate the new algorithm X  X  substantial improvement of the financial impact on our clients in the financial service industry. H.4 [ Database Management ]: Database Applications -Data Mining; I.2.6 [ Artificial Intelligence ]: Learning; I.5.2 [ Pattern Recognition ]: Design Methodology -classifier design and evaluation Algorithms return on investment, neural networks, constrained opti-mization Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00.
Classification has been commonly used in many data min-ing projects in the financial service industry. We have used a classifier to predict defection of mutual fund accounts for a major US mutual fund company [9], where the positive samples are defined as those accounts with a net redemp-tion amount (redemption minus purchase) of 35% or more of the account balance within a two-month window. We set up a control group for the project to evaluate the model X  X  accuracy. Table 1 shows the real-world evaluation results for the control group over a four-month window, which consists of two levels of defection risk and three segments based on account values.
 Table 1: Defection rate and average net redemption amount for the control group for a US mutual fund company.

We can see that the model was successful at predicting defecting accounts as evidenced by the higher defection rate in the higher risk groups for all the three segments. How-ever, the average net redemption amounts in the higher risk groups were not significantly higher than those in the lower risk groups. Especially, for Segment 1, even though the higher risk group had a much higher defection rate than the lower risk group, the negative net redemption amount in the higher risk group indicates a positive net purchase. This model can be used to reduce defection rate, but it would not be the best model used to prevent the highest redemp-tion amount. For a fixed budget, the return on investment (ROI) of the project is determined by the amount of redemp-tions prevented (rather than by the reduction of defection rate). There are many significant factors other than the model affecting the retained amount, but simply classifying the accounts as defection or non-defection does not enable the mutual fund company to reach out to those accounts with the highest redemption amount.

As another example, a classifier can be used to predict col-lectability of delinquent accounts receivable for credit card issuers using credit, demographic, and account data, where a binary class label is created based on whether a payment foranaccountisreceivedwithinacertainperiodsincethe account was placed into the collection process. Typically, the budget restricts how many accounts can be placed into a specific collection process. While the true positive rate among those accounts in the collection process is a mean-ingful measure of classification accuracy, maximization of the true positive rate is often different from maximization of the collectable amount for the specific collection process. It is the collection amount rather than the true positive rate that determines the ROI under the fixed budget.

Note that we are always addressing a budget constraint, which determines, among other things, how many mutual fund accounts the customer service team can reach out ev-ery month and how many accounts receivable can be placed into a specific collection process. In our applications we represent the budget constraint by the pull rate r which is the percentage of accounts to pull out for a specific inter-vention/collection process. Let us denote x as the target monetary measure, e.g., collection amount, which directly determines the ROI. Then the goal is to find a function y ( e ), where e is the independent variables such as credit, demographic, and account data, so that the accounts in the top r %by y correspond to those in the top r %bythetarget x . Thus the problem of maximizing the ROI can be formally defined as where i =0 , 1 ,...,n  X  1, and n is the total number of ac-counts.
One might immediately suggest cost-sensitive learning, e.g., [4], and ranking, e.g., [2], [3], would solve the above problem. For cost-sensitive learning, we have the cost ma-trix in Table 2. Assuming c 00 =0and c 11 =0,atypical sensitive learning algorithm tries to minimize the cost over the training set, where P , N are the sets of positive and negative samples, respectively, and q i , q j are both posterior probabilities of belonging to the positive class. In our appli-cation, the actual positives are those accounts which are in the top r %of x , and predicted positives are those accounts which have a score y in the top r %. It is straightforward that c 01 = x , since if an actual positive is placed out of the top r % (a predicted negative), the company will not be able to collect $ x or retain the net redemption of $ x .Ifanactual negative is placed among the top r %, the company will lose the opportunity to reach out to one of the accounts with a larger x in the top r %, since the number of accounts to be contacted is pre-determined by the pull rate r .Thus, c 10 is an opportunity cost that is not a constant and unknown. One might still try to train a classifier with sample weights intuitively based on x . In Sections 3 and 4, we compare our algorithm X  X  results with such a classifier X  X .

If we can learn a regression model so that y ( e i )= x i 0 ,...,n  X  1, or a ranking model so that y ( e i ) &gt;y ( e
Table 2: A cost matrix for cost-sensitive learning. ( i, j )  X  X  ( i, j ) | x i &gt;x j ,i,j =0 ,...,n  X  1 } , would be optimized for each r . However, both regression and ranking try to solve an unnecessarily difficult problem, and often lead to poorer results for our specific target at pull rate r . Maximization of y ( e i )  X  Top r% x i requires only the correct ranking between the Top r % and the others. The ranking within the Top r % or the others is not necessary, neither is the estimate of x itself by regression. In Sections 3 and 4, we compare our model with a regression and a ranking model, which uses the algorithm in [2].

We present the new algorithm in the next section, where we also describe the several classification, regression, and ranking algorithms which we compare with in our projects. In Section 3, we use the proposed algorithm to predict col-lectibility of accounts receivable for delinquent consumer loan accounts from several US financial institutions. In Sec-tion 4, the new algorithm is applied to predicting defection of mutual fund accounts for a major US mutual fund com-pany. Finally, we discuss several algorithmic and applied extensions of the proposed algorithm in Section 5.
For a mo del with 0  X  y  X  1 1 , assume that the specified pull rate r canbeachievedatadecisionthreshold  X  (0 &lt;  X &lt; 1), i.e., the accounts in the pull are those with an output larger than  X  . In this case, maximization of y i  X  Top r% can be solved by the following constrained optimization over y , i =0 ,...,n  X  1, and  X  : subject to where When the constraint ber of accounts with the model output y i &gt; X  will be ex-actly r %of n . The difficulty here is that I ( y i , X  )isnon-differentiable, and gradient based optimization cannot be used to optimize Eq. 7.

In [8], [9], we demonstrate that the sigmoid function  X  ( y entiable approximation to I ( y i , X  )when  X  1  X  y i  X   X   X  Instead, we have proposed the following differentiable ap-proximation
For simplicity, we X  X l omit the independent variable e and use y i for y ( e i ).
 where p&gt; 1and0  X   X &lt; 1. A small but positive  X  is often helpful for a better generalization performance over the test set. Now Eq. 3 becomes However, [9], rather than trying to use a differentiable approximation to r , we approximate a related ratio r 1  X  r by the following differentiable function: where with p&gt; 1. g ( y i , X  ) is a differentiable approximation to the following step function Since the optimization often moves most y i close to  X  in the end, we will see that Eq. 8 can provide a close approximation
Now we convert the constrained optimization into an un-constrained optimization problem by minimizing the follow-ing Lagrangian: L =  X  1 During the train ing iterations,  X  is gradually decreased un-til convergence of the constraint ( achieved. In practice, we have found that mapping x i in cally obtains improved results.

This algorithm can be applied to any parametric model, for which one can optimize the differentiable objective func-tion with respect to the para meters using gradient based methods. 2 In our projects, we use a typical multilayer per-ceptron (MLP) network with softmax outputs between 0 and 1, and with a single hidden layer and direct connection be-tween the input and output layers.  X  can also be optimized with the model parameters, but we have found that fixing  X  at 0.5 achieves almost the same results over our data sets.
In Sections 3 and 4, we apply the new algorithm to pre-dicting collectibility of accounts receivable and predicting defection of mutual fund accounts, and compare the re-sults of the proposed algorithm with the following four al-gorithms X .
 Classification An ensemble of MLP classifiers is trained by mean squared error based on the defined class label. Since the class prior is typically low, each individual classifier in the ensemble has a modified prior to compensate for the imbalanced data sets [10]. We use the limited memory BFGS method in [6].
 Weighted classification An MLP classifier is trained by mean squared error based on either the defined class label, e.g., whether the net redemption amount is above or below 35% of the account balance, or the ranks of the training samples. Using the ranks to determine the class label is an intuitive idea: labeling those samples in the top r %of x as positive and the others as negative. When r isthesameas the prior of the defined class, these two approaches are the same. During training, the samples are weighted by x or a function of x . To avoid the dominance of those samples with an extreme value of x , we typically use the sigmoid function of x to smooth out the weights.
 Ranking Burges et al. propose a ranking algorithm using gradient descent [2]. We apply this algorithm to train an MLP model which ranks x in our applications. The algo-rithm tries to minimize the cross entropy function where S = { ( i, j ) | x i  X  x j ,i,j =0 ,...,n  X  1 } ,and target probability of x i &gt;x j . P ij is the model X  X  estimate of  X  becomes In our experiments, we choose  X  P ij =1if x i &gt;x j and 0 . 5if x i = x j .
 Regression An MLP regressor is trained by mean squared error against x .Wemap x toavaluebetween0and1using the sigmoid function.
Accounts receivable are unpaid customer invoices, and any other money owed to a company by its customers. From credit card issuers to banks, from local retail stores and service businesses, to the federal, state and local govern-ments, if the business or government unit extends credit, offers payment installment plans, or makes assessments, it has accounts receivable. The collection industry serves an important role in the U.S. economy by recovering billions in revenue from charged-off or delinquent accounts receiv-able for U.S. companies. By returning this money to U.S. companies, the collection indus try saves American families on average $331 a year in money they otherwise would have spent if businesses raised their prices to cover losses to bad debt [1].

The portfolio of accounts receivable we worked on consists of consumer loan accounts from several US financial service institutions. The portfolio includes several types of accounts in terms of account history. For example, some are the so-called Prime accounts which are newly charged off accounts, and some are Seconds which had already gone through a col-lection process. Our goal is to develop a generic predictive model which can be used to guide the agents X  collection ef-forts. In particular, we would like to identify a high value segment which consists of 11% of the whole portfolio. The 11% is chosen since the payer rate (percentage of paid ac-counts in the first six months) is 11%. It is clear that the return on investment is determined by the collection amount from the identified 11% accounts in the segment.
 Figure 1: This figure shows convergence of pull rates achieved by the threshold  X  during the optimization. Line 1 is for the training set, and Line 2 shows the pull rate change over the test set.

The data set includes 684,600 accounts. We randomly split the data set into a training set and a test set of equal size. In addition to the account history and general de-mographic information, several hundred data fields from a credit score provider about the account owner are also avail-able. The domain experts guided the feature selection, and 30 data fields are used in the final model. 3 Missing values for continuous variables are simply imputed by the mean with an added binary column indicating missingness for this vari-able. Most of the data fields are categorical. For categorical variables with missing values, the sets of distinct values are augmented by another value  X  X issing X . We encode the cat-egorical variable C = { c 1 ,c 2 ,...,c k } by replacing c the conditional mean E ( x | c i ) and conditional standard de-viation  X  ( x | c i ), i =1 , 2 ,...,k .

We set r = 11% and fix  X  at 0.5 for the new algorithm, trying to maximize the average collection amount among the top 11% accounts. We choose  X  and p in Eq. 11 so that the number of training samples with the model output y&gt; X  is close to r % and the average collection amount among the top r % in the training set is the largest. Here we chose  X  =0 . 01 and p =2 4 , and the number of hidden units is 5. 5 In Figures 1 and 2, we show the optimization process along with iterations of  X  , which is initialized at 100, and is updated by  X  t +1 =0 . 75  X  t during the optimization, where t is the iteration index. Figure 1 shows that the optimization converged when the number of training samples with y&gt; X  reached 12%, which is quite close to the target pull rate 11%. We can see that the pull rate over the test set, achieved by the same threshold  X  , is also very close to the target 11%. This demonstrates that Eq. 8 provides a good approximation 1  X  r . In Figure 2, with the iterations, a steadily improving
While we are still working on several feature selection al-gorithms trying to reveal more useful data features, up to now we have only achieved marginal improvement by adding more data fields. In some cases, by choosing different p values in Eq. 7 and Eq. 8, better results over the training set can be achieved.
We have observed that the number of hidden units, varying from 0 to 10, does not have a significant effect on the results over our large data sets. Therefore all the MLP structures in the paper have 5 hidden units. Figure 2: This figure shows the improving average collection amount among the top 11% accounts dur-ing the optimization. Line 1 is for the training set, and Line 2 is over the test set. average collection amount among the top 11% is observed for both the training and test sets. We rarely observe obvious overfitting, and this justifies the use of the training set to choose  X  and p .

Table 3 presents the average collection amount in the top 11% accounts over the test set for five different models. The classification model is an ensemble of 25 MLP networks with a modified class prior between 0.02 and 0.5 [10]. For the model of weighted classification, during training the samples are weighted by  X  ( x )= 1 1+ e  X  x , which is also the target vari-able for the regression model. For ranking, most accounts (89%) have a tied collection amount of zero. We can see that the new algorithm is clearly exceeding all other algo-rithms. Comparing with the classification model, the ROI is improved by 25%. Note that the average collection amount over the whole portfolio is $36 only. new model class. weighted class. ranking regress. Table 3: The average collection amount in the top 11% accounts over the test set for five different mod-els.
Today, the US mutual fund industry holds about 18% of all households X  financial assets and about 22% of all out-standing US corporate stock [5]. However, in the end of 2003 the industry w ide redemption rat e stood at 24.2%, implying that the investor base completely turns over in 4 (1/0.242) years. To illustrate the magnitude of redemp-tions in the mutual fund industry, the Investment Company Institute estimated that in 2003 1.086 trillion new dollars flowed into equity funds but, over the exact same measure-ment interval, 934 billion (86%) flowed back out [5]. The costs associated with keeping track of this flowing river of money, adding and deleting client information to databases, filing required tax forms with federal, state and local taxing authorities as well as simply cutting checks to redeeming clients is an enormous drain on any funds X  expense ratio, not mentioning the revenue drop of fund companies because of the decreased assets under management (AUM) due to redemption. In recent years, more and more mutual fund companies have recognized the importance of early identi-fication of investors at risk of redeeming their assets (i.e., defectors), so that proactive client service and educational programs could be initiated to  X  X lug X  the outflow of assets.
We have developed a model to predict account defection for a major US mutual fund company. In order to pro-vide early identification of defectors, there is a two month gap between the end of the independent variable (IV) win-dow and the beginning of the two-month dependent vari-able (DV) window. For example, at the end of February, we would like to predict which accounts will defect in the time period of May and June. The two-month leading time allows the mutual fund company to act on the predicted potential defectors in March and April. For classification purpose, a defector is defined by the domain experts as an account which had a net redemption amount (redemption minus purchase) of at least 35% of the account balance in a two month window. As the training set, we received about 184,000 accounts, each of which had an account balance of at least $100,000. For training, the IV window is a one-year period ending on May 31, and the DV window is a two-month period of August and September. Based on the definition of defection, the defection rate is below 1% in the two month window. Regardless of the defection definition, the average net redemption amount in the two months over the whole training set was about -$3,000, where the nega-tive sign means that, on average, the account balance had a net increase. We used a forward time-shifted test set of around 434,000 accounts, which had the one-year IV win-dow ending on September 30 and the DV window consisting of December and January.

The data for each account is a mixture of continuous and categorical variables, including basic account information, asset data, transactions, demographic information, bench-mark performance data, and customer service records. There are about 2,000 raw data fields, but the final model uses 123 data fields after conducting feature selection and time series transformation [9]. The mutual fund company set r = 10% based on the predetermined budget. We will discuss the savability issue in the next section. Until then let us assume that the return on investment is primarily dependent on the net redemption amount identified among the top 10%.
Again we fix  X  at 0.5 for the new algorithm and try to maximize the average net redemption amount in the top 10%. We chose  X  =0and p = 2 since, with these param-eters, the number of training samples with y&gt; X  is close to 10% and the average collection amount among the top 10% in the training set is the largest. We have seen that these two goals are often quite consistent, i.e., when a set of parameters results in the larg est average collection amount, it also brings the number of training samples with y&gt; X  close to the target pull rate. We show the optimization pro-cess along with iterations of  X  in Figures 3 and 4. Again we can see that the optimization converged when the num-ber of training samples with y&gt; X  reached 11%, which is quite close to the target pull rate 10%. Over the test set, the number of samples with y&gt; X  reached 12%, 2% higher than the target rate. Figure 4 shows a quite large difference of the average net redemption amount between the training Figure 3: This figure shows convergence of pull rates achieved by the threshold  X  during the optimization. Line 1 is for the training set, and Line 2 shows the pull rate change over the test set. Figure 4: This figure shows the average net redemp-tion amount change among the top 10% accounts during the optimization. Line 1 is for the training set, and Line 2 is over the test set. and test sets. This is due to the overall net redemption is changed in the test set X  X  DV window, which is four months apart from the training set DV window. The average net re-demption amount over all the accounts is now about -$3,400, comparing with -$670 over the training set.
 In Table 4, the classification model is an ensemble of 25 MLP networks trained with modified priors based on the defection definition of 35% or more redemption. However, the weighted classification model is trained by class labels based on the ranking, i.e., the samples with the top 10% of net redemption amount are positives and the others are negatives. The training samples are weighted by 1 1+ e  X  X  x | which gives larger weights to samples with a larger (posi-tive or negative) net redemption amount. The regression model is trained against  X  ( x )= 1 1+ e  X  x . Note that in Table 4 a negative net redemption amount means a positive net purchase. Though the classification model achieves a 39% true positive rate (the new model has a true positive rate of 14%), it cannot effectively identify those accounts with the highest redemption amount.
 new model class. weighted class. ranking regress. Table 4: The average net redemption amount in the top 10% accounts over the test set for five different models.
We have proposed a new learning algorithm which focuses on maximizing the monetary measure under a fixed budget constraint. The two applications demonstrate the substan-tial improvement of financial impact by the new algorithm. In this section, we discuss several related practical issues and some algorithmic and application extensions.
 Savability There is no doubt that maximizing the collection amount for the top r % accounts also maximizes the ROI of the collection efforts which reach out to a predetermined r %. However, it is arguable that maximizing the net redemption amount in the top r % accounts would maximize the retained redemption amount and thus the ROI. Another important factor determining the ROI is the savability of the predicted net redemption amount. It is reasonable to assume that it might be more difficult to retain a substantial redemption amount of a large account, since the redemption rate against the balance might be insignificant and the redemption is just some normal cash flow activity. To model  X  X avability X  directly appears not feasible since  X  X eing savable X  is not ob-servable and cannot be defined correctly. However, we have tried to model savability from the other aspect  X   X  X eing un-savable X , which can be partially defined, i.e., if an account was predicted to defect and was contacted for retention but still became defected, this account was unsavable. Here we implicitly assume retention efforts do not cause originally non-defecting accounts to defect. We have developed such a savability model for a US mutual fund company. However, we have not been able to combine the savability model with scores from the model by the new algorithm in a principled way, since the score is only a ranking indicator rather than a probabilistic estimate of x . An empirical way to consider savability is to increase the predetermined r by a certain percentage, and to exclude those accounts with a savability score below an empirically determined threshold.
 Valuable false positives The model trained using the new algorithm does not classify accounts into positive and nega-tive samples defined separately, e.g., by the redemption rate of 35%. We have observed that the model achieving the highest average net redemption amount can have a very low true positive rate based on the defection definition. Some companies will not feel comfortable to see a low true pos-itive rate based on the defection definition given by their domain experts. It would be most desirable to achieve both a high true positive rate and a higher average redemption amount among the false positives. We call these false posi-tives valuable false positives since they may have substantial net redemption too. We have tried to simply add an item, which approximates the true positive rate in [9], into Eq. 11 and to minimize the corresponding Lagrangian. However, this intuitive approach does not appear to work well. No budget constraint In some cases, there is no fixed bud-get constraint and r is not predetermined. For example, for the collection industry, th e goal might be loosely stated as collecting as much as possible by contacting as less ac-counts as possible. In this case, the maximum profit or ROI is achieved when the marginal collection cost equals to marginal revenue (collection amount). Typically, we can assume the marginal collection cost is a constant. By search-ing over different r values, for each of which a model needs to be trained by minimizing Eq. 11, the optimum r can be found so that the marginal collection cost is equal to the marginal revenue and the ROI is maximized.
 Other applications The new algorithm can also be applied to several other areas. For example, maximizing average re-turns of stock selection, identifying tax auditing targets of highest values, and identifying fundraising targets with the highest contributions  X  all these tasks involve a predeter-mined budget and only concern the related average mone-tary value in the top r % determined by the budget. Even in the typical customer relationship management area, e.g., churn prediction for wireless service providers [10], since the ultimate concern is the loss of revenue due to service dis-connection, we can apply this algorithm to identify those accounts with the highest revenue losses. It would be inter-esting to compare this approach to another approach which combines an estimate of customer value with a predicted churn probability [7]. [1] Association of Credit and Collection Professionals. [2] C. Burges, T. Shaked, et al. Learning to rank using [3] R. Caruana, S. Baluja, and T. Mitchell. Using the [4] C. Elkan. The foundations of cost-sensitive learning. [5] Investment Company Institute. 2004 Mutual Fund [6] D. C. Liu and J. Nocedal. On the limited memory [7] L. Yan and P. Baldasare. Optimizing customer value [8] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. [9] L. Yan, M. Fassion, P. Baldasare. Enhancing the lift [10] L. Yan, R. Wolniewicz, and R. Dodier. Customer
