 CMLA, UMR CNRS 8536, ENS Cachan, France LPMA, Universit  X  e Paris Diderot, France CMLA, UMR CNRS 8536, ENS Cachan, France Stochastic optimization problems are encountered in nu-merous real world domains including engineering design (Wang &amp; Shan, 2007), finance (Ziemba &amp; Vickson, 2006), natural sciences (Floudas &amp; Pardalos, 2000), or in machine learning for selecting models by tuning the parameters of learning algorithms (Snoek et al., 2012). We aim at find-ing the input of a given system which optimizes the out-put (or reward). In this view, an iterative procedure uses the previously acquired measures to choose the next query predicted to be the most useful. The goal is to maximize the sum of the rewards received at each iteration, that is to minimize the cumulative regret by balancing exploration (gathering information by favoring locations with high un-certainty) and exploitation (focusing on the optimum by favoring locations with high predicted reward). This op-timization task becomes challenging when the dimension of the search space is high and the evaluations are noisy and expensive. Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit (Auer et al., 2002; Kleinberg, 2004; Bubeck et al., 2011; Audibert et al., 2011), active learning (Carpentier et al., 2011; Chen &amp; Krause, 2013) or Bayesian optimization (Mockus, 1989; Grunewalder et al., 2010; Srinivas et al., 2012; de Freitas et al., 2012). The theoretical analysis of such optimiza-tion procedures requires some prior assumptions on the un-derlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP (Rasmussen &amp; Williams, 2006). Our main contribution is twofold: we propose a generic algo-rithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm (Srinivas et al., 2012) such as (Krause &amp; Ong, 2011; Desautels et al., 2012; Contal et al., 2013). We suggest an alternative policy which achieves an exponential speed up with respect to the cumulative re-gret. We also introduce a novel algorithm, the Gaussian Process Mutual Information algorithm ( GP-MI ), which im-proves furthermore upper bounds for the cumulative regret from O ( a T (log T ) d +1 ) for GP-UCB , the current state of the art, to the spectacular O ( a (log T ) d +1 ) , where T is the number of iterations, d is the dimension of the input space and the kernel function is Gaussian. The remainder of this article is organized as follows. We first introduce the setup and notations. We define the GP-MI algorithm in Section 2. Main results on the cumulative regret bounds are pre-sented in Section 3. We then provide technical details in Section 4. We finally confirm the performances of GP-MI on real and synthetic tasks compared to the state of the art of GP optimization and some heuristics used in practice. 2.1. Sequential optimization and cumulative regret Let f : X  X  R , where X  X  R d is a compact and convex set, be the unknown function modeling the system we want to be optimized. We consider the problem of finding the maximum of f denoted by: via successive queries x 1 ,x 2 ,...  X  X . At iteration T + 1 , the choice of the next query x T +1 depends on the previous noisy observations, Y T = { y 1 ,...,y T } at locations X { x 1 ,...,x T } where y t = f ( x t ) + t for all t  X  T , and the noise variables 1 ,..., T are independently distributed as a Gaussian random variable N (0 , X  2 ) with zero mean and variance  X  2 . The efficiency of a policy and its ability to address the exploration/exploitation trade-off is measured via the cumulative regret R T , defined as the sum of the instantaneous regret r t , the gaps between the value of the maximum and the values at the sample locations, Our aim is to obtain upper bounds on the cumulative regret R
T with high probability. 2.2. The Gaussian process framework Prior assumption on f . In order to control the smooth-ness of the underlying function, we assume that f is sam-pled from a Gaussian process GP ( m,k ) with mean func-tion m : X  X  R and kernel function k : X  X X  X  R + . We formalize in this manner the prior assumption that high local variations of f have low probability. The prior mean function is considered without loss of generality to be zero, as the kernel k can completely define the GP (Rasmussen &amp; Williams, 2006). We consider the normal-ized and dimensionless framework introduced by (Srinivas et al., 2010) where the variance is assumed to be bounded, that is k ( x,x )  X  1 for all x  X  X  .
 Bayesian inference. At iteration T + 1 , given the previ-ously observed noisy values Y T at locations X T , we use Bayesian inference to compute the current posterior distri-bution (Rasmussen &amp; Williams, 2006), which is a GP of mean  X  T +1 and variance  X  2 T +1 given at any x  X  X  by, ances between x and the query points at time T , and C nel matrix,  X  2 is the variance of the noise and I stands for the identity matrix. The Bayesian inference is illustrated on Figure 1 in a sample problem in dimension one, where the posteriors are based on four observations of a Gaussian Process with squared exponential kernel. The height of the gray area represents two posterior standard deviations at each point. 2.3. The Gaussian Process Mutual Information The Gaussian Process Mutual Information algorithm ( GP-MI ) is presented as Algorithm 1. The key statement is the choice of the query, x t = argmax x  X  X   X  t ( x ) +  X  t ( x ) . The exploitation ability of the procedure is driven by  X  t , while the exploration is governed by  X  t : X  X  R , which is an increasing function of  X  2 t ( x ) . The novelty in the GP-MI algorithm is that  X  t is empirically controlled by the amount of exploration that has been already done, that is, the more the algorithm has gathered information on f , the more it will focus on the optimum. In the GP-UCB algorithm from (Srinivas et al., 2012) the exploration coefficient is a O (log t ) and therefore tends to infinity. The parameter  X  in Algorithm 1 governs the trade-off between precision and confidence, as shown in Theorem 2. The efficiency of the algorithm is robust to the choice of its value. We confirm empirically this property and provide further discussion on the calibration of  X  in Section 5.
 Algorithm 1 GP-MI p  X  0  X  0 for t = 1 , 2 ,... do end for Mutual information. The quantity p  X  T controlling the exploration in our algorithm forms a lower bound on the information acquired on f by the query points X The information on f is formally defined by I T ( X T the mutual information between f and the noisy obser-vations Y T at X T , hence the name of the GP-MI algo-rithm. For a Gaussian process distribution I T ( X log det( I +  X   X  2 K T ) where K T is the kernel matrix [ k ( x i ,x j )] x for further reading on mutual information. We denote by  X  formation obtainable by a sequence of T query points. In the case of Gaussian processes with bounded variance, the following inequality is satisfied (Lemma 5.4 in (Srinivas et al., 2012)): upper bounds on the cumulative regret we derive in the next section depend mainly on this key quantity. 3.1. Generic Optimization Scheme We first consider the generic optimization scheme defined in Algorithm 2, where we let  X  t as a generic function viewed as a parameter of the algorithm. We only require  X  to be measurable with respect to Y t  X  1 , the observations available at iteration t  X  1 . The theoretical analysis of Algo-rithm 2 can be used as a plug-in theorem for existing algo-rithms. For example the GP-UCB algorithm with parame-ter  X  t = O (log t ) is obtained with  X  t ( x ) = a  X  t  X  2 generic analysis of Algorithm 2 leads to the following up-per bounds on the cumulative regret with high probability. Algorithm 2 Generic Optimization Scheme (  X  t ) for t = 1 , 2 ,... do end for Theorem 1 (Regret bounds for the generic algorithm) . For all  X  &gt; 0 and T &gt; 0 , the regret R T incurred by Algo-rithm 2 on f distributed as a GP perturbed by indepen-dent Gaussian noise with variance  X  2 satisfies the follow- X  = log 2  X  :
Pr The proof of Theorem 1, relies on concentration guaran-tees for Gaussian processes (see Section 4.1). Theorem 1 provides an intermediate result used for the calibration of  X  to face the exploration/exploitation trade-off. For exam-ple by choosing  X  t ( x ) = constant is hidden), Algorithm 2 becomes a variant of the GP-UCB algorithm where in particular the exploration pa-rameter function of t . The upper bounds on the cumulative regret with this definition of  X  t are of the form R T = O (  X  T as stated in Corollary 1. We then also consider the case where the kernel k of the Gaussian process is under the form of a squared exponential (RBF) kernel, k ( x 1 ,x 2 ) = l  X  R . In this setting, the maximum mutual information  X  satisfies the upper bound  X  T = O p (log T ) d +1 q , where the dimension of the input space (Srinivas et al., 2012). Corollary 1. Consider the Algorithm 2 where we set  X  ( x ) = we have that the cumulative regret for Algorithm 2 satisfies the following upper bounds with high probability:  X  For f sampled from a GP with general kernel:  X  For f sampled from a GP with RBF kernel: To prove Corollary 1 we apply Theorem 1 with the given definition of  X  t and then Equation 3, which leads to Pr r R T  X  previously known upper bounds on the cumulative re-gret for the GP-UCB algorithm are of the form R T = O p of the generic Algorithm 2 with  X  t ( x ) = the GP-UCB algorithm with respect to the cumulative re-gret is then exponential in the case of Gaussian processes with RBF kernel. For f sampled from a GP with linear ker-nel, corresponding to f ( x ) = w T x with w  X  N (0 , I ) , we obtain R T = O p d log T q . We remark that the GP assump-bandit framework, as it implies a Gaussian prior over the linear coefficients w . Hence there is no contradiction with the lower bounds stated for linear bandit like those of (Dani et al., 2008). We refer to (Srinivas et al., 2012) for the anal-ysis of  X  T with other kernels widely used in practice. 3.2. Regret bounds for the GP-MI algorithm We present here the main result of the paper, the upper bound on the cumulative regret for the GP-MI algorithm. Theorem 2 (Regret bounds for the GP-MI algorithm) . For all  X  &gt; 0 and T &gt; 1 , the regret R T incurred by Algorithm 1 on f distributed as a GP perturbed by independent Gaus-sian noise with variance  X  2 satisfies the following bound The proof for Theorem 2 is provided in Section 4.2, where we analyze the properties of the exploration functions  X  t Corollary 2 describes the case with RBF kernel for the GP-MI algorithm.
 Corollary 2 (RBF kernels) . The cumulative regret R T in-curred by Algorithm 1 on f sampled from a GP with RBF kernel satisfies with high probability, The GP-MI algorithm significantly improves the upper bounds for the cumulative regret over the GP-UCB algo-rithm and the alternative policy of Corollary 1. In this section, we provide the proofs for Theorem 1 and Theorem 2. The approach presented here to study the cu-mulative regret incurred by Gaussian process optimization strategies is general and can be used further for other algo-rithms. 4.1. Analysis of the general algorithm The theoretical analysis of Theorem 1 uses a similar ap-proach to the Azuma-Hoeffding inequality adapted for Gaussian processes. Let r t = f ( x ? )  X  f ( x t ) for all t  X  T . We define M T , which is shown later to be a martingale with respect to Y T  X  1 , for T  X  1 and M 0 = 0 . Let Y t be defined as the mar-tingale difference sequence with respect to M T , that is the difference between the instantaneous regret and the gap be-tween the posterior mean for the optimum and the one for the point queried, Lemma 1. The sequence M T is a martingale with respect to Y T  X  1 and for all t  X  T , given Y t  X  1 , the random vari-able Y t is distributed as a Gaussian N (0 ,` 2 t ) with zero mean and variance ` 2 t , where: Proof. From the GP assumption, we know that given Y t  X  1 , the distribution of f ( x ) is Gaussian N Gaussian random vector, that is r t is distributed as a Gaus-sian N (0 ,` 2 t ) , with ` 2 t =  X  2 t ( x ? ) +  X  2 t ( x hence M T is a Gaussian martingale.
 We now give a concentration result for M T using inequali-ties for self-normalized martingales.
 Lemma 2. For all  X  &gt; 0 and T &gt; 1 , the martingale M normalized by the predictable quadratic variation P T t =1 satisfies the following concentration inequality with  X  = log 2  X  and y = 8( C 1  X  T + 1) : Proof. Let y = 8( C 1  X  T + 1) . We introduce the notation Pr &gt; [ A ] for Pr[ A  X  P P using Theorem 4.2 and Remark 4.2 from (Bercu &amp; Touati, 2008) with  X  M  X  T = P T t =1 ` 2 t and a = 0 and b = 1 we obtain for all x &gt; 0 : With x = b 2  X  y where  X  = log 2  X  , we have: By definition of ` t in Eq. 5 and with k ( x ? ,x t )  X  0 , we have we have p  X  T  X  y 8 , we finally get: Now, using Theorem 4.1 and Remark 4.2 from (Bercu &amp; Touati, 2008) the following inequality is satisfied for all x &gt; 0 : With x = Combining Equations 6 and 7 leads to, proving Lemma 2.
 The following lemma concludes the proof of Theorem 1 using the previous concentration result and the properties of the generic Algorithm 2.
 Lemma 3. The cumulative regret for Algorithm 2 on f sampled from a GP satisfies the following bound for all  X  &gt; 0 and  X  and y defined in Lemma 2: Proof. By construction of the generic Algorithm 2, we have x t = argmax x  X  X   X  t ( x ) +  X  t ( x ) , which guarantees for all t  X  1 that  X  t ( x ? )  X   X  t ( x t )  X   X  t ( x t )  X   X  placing M T by its definition in Eq. 4 and using the previous property in Lemma 2 proves Lemma 3. 4.2. Analysis of the GP-MI algorithm In order to bound the cumulative regret for the GP-MI al-gorithm, we focus on an alternative definition of the explo-ration functions  X  t where the last term is modified induc-Being a constant term for a fixed t &gt; 0 , Algorithm 1 re-mains unchanged. Let  X  t be defined as, where x t is the point selected by Algorithm 1 at iteration t . We have for all T &gt; 1 , We can now derive upper bounds for P T t =1 p  X  t ( x  X  ( x ? ) q which will be plugged in Theorem 1 in order to cancel out the terms involving x ? . In this manner we can calibrate sharply the exploration/exploitation trade-off by optimizing the remaining terms.
 Lemma 4. For the GP-MI algorithm, the exploration term in the equation of Theorem 1 satisfies the following in-equality:
X Proof. Using our alternative definition of  X  t which gives the equality stated in Equation 8, we know that,
X By concavity of the square root, we have for all a  X   X  b that p  X  Moreover, with 0  X   X  2 t ( x )  X  1 for all x  X  X , we have a  X  leading to the inequality of Lemma 4.
 The following lemma combines the results from Theorem 1 and Lemma 4 to derive upper bounds on the cumulative regret for the GP-MI algorithm with high probability. Lemma 5. The cumulative regret for Algorithm 1 on f sam-pled from a GP satisfies the following bound for all  X  &gt; 0 and  X  defined in Lemma 2, Proof. Considering Theorem 1 in the case of the GP-MI algorithm and bounding P T t =1 p  X  t ( x t )  X   X  t ( x Lemma 4, we obtain the following bound on the cumulative regret incurred by GP-MI :
Pr which simplifies to the inequality of Lemma 5 using Equa-tion 3, and thus proves Theorem 2. 5.1. Numerical experiments Protocol. We compare the empirical performances of our algorithm against the state-of-the-art of GP optimization, the GP-UCB algorithm (Srinivas et al., 2012), and a com-monly used heuristic, the Expected Improvement ( EI ) al-gorithm with GP (Jones et al., 1998). The tasks used for assessment come from two real applications and five syn-thetic problems described here. For all data sets and algo-rithms the learners were initialized with a random subset of of the underlying function was not known, the Bayesian in-ference was made using a squared exponential kernel. We first picked the half of the data set to estimate the hyper-parameters of the kernel via cross validation in this subset. In this way, each algorithm was running with the same prior information. The value of the parameter  X  for the GP-MI and the GP-UCB algorithms was fixed to  X  = 10  X  6 for all these experimental tasks. Modifying this value by several orders of magnitude is insignificant with respect to the em-pirical mean cumulative regret incurred by the algorithms, as discussed in Section 5.2. The results are provided in Fig-ure 3. The curves show the evolution of the average regret
T in term of iteration T . We report the mean value with the confidence interval over a hundred experiments. Description of the data sets. We describe briefly all the data sets used for assessment.  X  Generated GP. The generated Gaussian process func- X  Gaussian Mixture. This synthetic function comes  X  Himmelblau. This task is another synthetic function in  X  Branin. The Branin or Branin-Hoo function is a  X  Goldstein-Price. The Goldstein &amp; Price function is  X  Tsunamis. Recent post-tsunami survey data as well  X  Mackey-Glass function. The Mackey-Glass delay-Empirical comparison of the algorithms. Figure 3 compares the empirical mean average regret R T T for the three algorithms. On the easy optimization assessments like the Branin data set (Fig. 3(e)) the three strategies be-have in a comparable manner, but the GP-UCB algorithm incurs a larger cumulative regret. For more difficult assess-ments the GP-UCB algorithm performs poorly and our al-gorithm always surpasses the EI heuristic. The improve-ment of the GP-MI algorithm against the two competitors is the most significant for exceptionally challenging op-timization tasks as illustrated in Figures 3(a) to 3(d) and 3(h), where the underlying functions present several local optima. The ability of our algorithm to deal with the ex-ploration/exploitation trade-off is emphasized by these ex-perimental results as its average regret decreases directly after the first iterations, avoiding unwanted exploration like GP-UCB on Figures 3(a) to 3(d), or getting stuck in some local optimum like EI on Figures 3(c), 3(g) and 3(h). We further mention that the GP-MI algorithm is empirically robust against the number of dimensions of the data set (Fig. 3(b), 3(g), 3(h)). 5.2. Practical aspects Calibration of  X  . The value of the parameter  X  is chosen following Theorem 2 as  X  = log 2  X  with 0 &lt;  X  &lt; 1 being a confidence parameter. The guarantees we prove in Section 4.2 on the cumulative regret for the GP-MI algorithm holds with probability at least 1  X   X  . With  X  increasing linearly for  X  decreasing exponentially toward 0 , the algorithm is R /T robust to the choice of  X  . We present on Figure 4 the small impact of  X  on the average regret for four different values selected on a wide range.
 Numerical Complexity. Even if the numerical cost of GP-MI is insignificant in practice compared to the cost of the evaluation of f , the complexity of the sequential Bayesian update (Osborne, 2010) is O ( T 2 ) and might be prohibitive for large T . One can reduce drastically the computational time by means of Lazy Variance Calculation (Desautels et al., 2012), built on the fact that  X  2 T ( x ) always decreases for increasing T and for all x  X  X . We fur-ther mention that approximated inference algorithms such as the EP approximation and MCMC sampling (Kuss et al., 2005) can be used as an alternative if the computational time is a restrictive factor. We introduced the GP-MI algorithm for GP optimization and prove upper bounds on its cumulative regret which improve exponentially the state-of-the-art in common set-tings. The theoretical analysis was presented in a generic framework in order to expand its impact to other similar al-gorithms. The experiments we performed on real and syn-thetic assessments confirmed empirically the efficiency of our algorithm against both the theoretical state-of-the-art of GP optimization, the GP-UCB algorithm, and the com-monly used EI heuristic.
 A The authors would like to thank David Buffoni and Rapha  X  el Bonaque for fruitful discussions. The author also thank the anonymous reviewers for their detailed feedback.
 Audibert, J-Y., Bubeck, S., and Munos, R. Bandit view on noisy optimization. In Optimization for Machine Learn-ing , pp. 431 X 454. MIT Press, 2011.
 Auer, P., Cesa-Bianchi, N., and Fischer, P. Finite-time anal-ysis of the multiarmed bandit problem. Machine Learn-ing , 47(2-3):235 X 256, 2002.
 Bercu, B. and Touati, A. Exponential inequalities for self-normalized martingales with applications. The Annals of Applied Probability , 18(5):1848 X 1869, 2008.
 Bubeck, S., Munos, R., Stoltz, G., and Szepesv  X  ari, C. X-armed bandits. Journal of Machine Learning Research , 12:1655 X 1695, 2011.
 Carpentier, A., Lazaric, A., Ghavamzadeh, M., Munos, R., and Auer, P. Upper-confidence-bound algorithms for ac-tive learning in multi-armed bandits. In Proceedings of the International Conference on Algorithmic Learning Theory , pp. 189 X 203. Springer-Verlag, 2011.
 Chen, Y. and Krause, A. Near-optimal batch mode ac-tive learning and adaptive submodular optimization. In Proceedings of the International Conference on Machine Learning . icml.cc / Omnipress, 2013.
 Contal, E., Buffoni, D., Robicquet, A., and Vayatis, N.
Parallel Gaussian process optimization with upper confi-dence bound and pure exploration. In Machine Learning and Knowledge Discovery in Databases , volume 8188, pp. 225 X 240. Springer Berlin Heidelberg, 2013.
 Cover, T. M. and Thomas, J. A. Elements of Information Theory . Wiley-Interscience, 1991.
 Dani, V., Hayes, T. P., and Kakade, S. M. Stochastic lin-ear optimization under bandit feedback. In Proceedings of the 21st Annual Conference on Learning Theory , pp. 355 X 366, 2008. de Freitas, N., Smola, A. J., and Zoghi, M. Exponential regret bounds for Gaussian process bandits with deter-ministic observations. In Proceedings of the 29th In-ternational Conference on Machine Learning . icml.cc / Omnipress, 2012.
 Desautels, T., Krause, A., and Burdick, J.W. Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization. In Proceedings of the 29th Interna-tional Conference on Machine Learning , pp. 1191 X 1198. icml.cc / Omnipress, 2012.
 Dutykh, D., Poncet, R, and Dias, F. The VOLNA code for the numerical modelling of tsunami waves: generation, propagation and inundation. European Journal of Me-chanics B/Fluids , 30:598 X 615, 2011.
 Flake, G. W. and Lawrence, S. Efficient SVM regression training with SMO. Machine Learning , 46(1-3):271 X  290, 2002.
 Floudas, C.A. and Pardalos, P.M. Optimization in Compu-tational Chemistry and Molecular Biology: Local and Global Approaches . Nonconvex Optimization and Its Applications. Springer, 2000.
 Grunewalder, S., Audibert, J-Y., Opper, M., and Shawe-
Taylor, J. Regret bounds for Gaussian process bandit problems. In Proceedings of the International Confer-ence on Artificial Intelligence and Statistics , pp. 273 X  280. MIT Press, 2010.
 Hill, E. M., Borrero, J. C., Huang, Z., Qiu, Q., Banerjee,
P., Natawidjaja, D. H., Elosegui, P., Fritz, H. M., Suwar-gadi, B. W., Pranantyo, I. R., Li, L., Macpherson, K. A., Skanavis, V., Synolakis, C. E., and Sieh, K. The 2010
Mw 7.8 Mentawai earthquake: Very shallow source of a rare tsunami earthquake determined from tsunami field survey and near-field GPS data. J. Geophys. Res. , 117: B06402 X , 2012.
 Jones, D. R., Schonlau, M., and Welch, W. J. Efficient global optimization of expensive black-box functions.
Journal of Global Optimization , 13(4):455 X 492, Decem-ber 1998.
 Kleinberg, R. Nearly tight bounds for the continuum-armed bandit problem. In Advances in Neural Information Pro-cessing Systems 17 , pp. 697 X 704. MIT Press, 2004. Krause, A. and Ong, C.S. Contextual Gaussian process bandit optimization. In Advances in Neural Information Processing Systems 24 , pp. 2447 X 2455, 2011.
 Kuss, M., Pfingsten, T., Csat  X  o, L., and Rasmussen, C.E.
Approximate inference for robust Gaussian process re-gression. Max Planck Inst. Biological Cybern., Tubin-gen, GermanyTech. Rep , 136, 2005.
 Mockus, J. Bayesian approach to global optimization .
Mathematics and its applications. Kluwer Academic, 1989.
 Osborne, Michael. Bayesian Gaussian processes for se-quential prediction, optimisation and quadrature . PhD thesis, Oxford University New College, 2010.
 Rasmussen, C. E. and Williams, C. Gaussian Processes for Machine Learning . MIT Press, 2006.
 Snoek, J., Larochelle, H., and Adams, R. P. Practical bayesian optimization of machine learning algorithms.
In Advances in Neural Information Processing Systems 25 , pp. 2960 X 2968, 2012.
 Srinivas, N., Krause, A., Kakade, S., and Seeger, M. Gaus-sian process optimization in the bandit setting: No regret and experimental design. In Proceedings of the Interna-tional Conference on Machine Learning , pp. 1015 X 1022. icml.cc / Omnipress, 2010.
 Srinivas, N., Krause, A., Kakade, S., and Seeger, M.
Information-theoretic regret bounds for Gaussian pro-cess optimization in the bandit setting. IEEE Transac-tions on Information Theory , 58(5):3250 X 3265, 2012. Stefanakis, T. S., Dias, F., Vayatis, N., and Guillas, S.
Long-wave runup on a plane beach behind a conical is-land. In Proceedings of the World Conference on Earth-quake Engineering , 2012.
 Stefanakis, T. S., Contal, E., Vayatis, N., Dias, F., and Syn-olakis, C. E. Can small islands protect nearby coasts from tsunamis ? An active experimental design ap-proach. arXiv preprint arXiv:1305.7385 , 2013.
 Wang, G. and Shan, S. Review of metamodeling techniques in support of engineering design optimization. Journal of Mechanical Design , 129(4):370 X 380, 2007.
 Ziemba, W. T. and Vickson, R. G. Stochastic optimization
