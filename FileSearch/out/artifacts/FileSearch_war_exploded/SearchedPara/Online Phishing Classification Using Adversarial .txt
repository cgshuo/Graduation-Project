 In adversarial systems, the performance of a classifier de-creases after it is deployed, as the adversary learns to defeat it. Recently, adversarial data mining was introduced, where the classification problem is viewed as a game mechanism between an adversary and an intelligent and adaptive clas-sifier. Over the last years, phishing fraud through malicious email messages has been a serious threat that affects global security and economy, where traditional spam filtering tech-niques have shown to be ineffective. In this domain, us-ing dynamic games of incomplete information, a game theo-retic data mining framework is proposed in order to build an adversary-aware classifier for phishing fraud detection. To build the classifier, an online version of the Weighted Margin Support Vector Machines with a game theoretic prior knowl-edge function is proposed. In this paper, a new content-based feature extraction technique for phishing filtering is described. Experiments show that the proposed classifier is highly competitive compared with previously proposed online classification algorithms in this adversarial environ-ment, and promising results were obtained using traditional machine learning techniques over extracted features. H.2.8 [ Database Management ]: Database Applications X  Data Mining ; I.5.1 [ Pattern Recognition ]: Design Method-ology X  classifier design and evaluation ; K.4.4 [ Computers and Society ]: Electronic Commerce X  Security Email Filtering, Game Theory, Data Mining Spam and Phishing Detection, Adversarial Classification, Games of Incomplete Information
In security applications, modern threats are becoming more effective as adversaries are adapting and evolving over cur-rent security systems. In many domains, such as fraud, phishing, spam, intrusion detection, and other malicious ac-tivities, a permanent race between adversaries and classi-fiers. The evolution of the initial problem is driven by a ra-tional change of the adversaries X  behavior. In this context, one of the major problems of a classifier is to consider the drift concept and incremental properties of security systems. Recent studies on this topic [32], focus on the incremental characteristic of these applications, leaving the adversarial behavior as an open question in most of the previously men-tioned domains.

In Cyber-Crime , one of the most common social engineer-ing threats is phishing fraud. This malicious activity consists of email scams, where attackers ask for personal information to break into any site where victims store useful private in-formation, such as financial institutions, e-commerce or mas-sive services. The phishing filtering problem is not an easy task. While client side phishing filtering techniques have been developed by large software companies, server side fil-tering techniques have been a large research focus [1, 3, 5, 10]. Most of this work is based on machine learning ap-proaches to determine the relevant features to extract from phishing emails, and data mining techniques to determine hidden patterns associated to the relationship between the extracted features.

There is an important issue when using data mining to build a classifier for the phishing detection task, and many other adversarial classification tasks: it must deal with the uncertainty of classifying malicious or regular activities, with-out information about the real intention of the message. This interaction can be modeled as a Bayesian game (or in-complete information game), where the classifier must choose a strategy without knowing the adversaries X  real type, whether it was malicious or just happened to be a X  X alicious like X  X eg-ular message. All this, using just the revealed set of features to decide.

The aim of this work is to present a game-theoretic data mining framework using dynamic games of incomplete infor-mation for the adversarial classification problem. A mecha-nism is proposed to model a signaling game between an ad-versary and a classifier, where equilibrium strategies and the classifier beliefs are used to build an online machine learning classifier to detect phishing emails.

Section 2 of this paper introduces previous work on adver-sarial data mining and latest research on phishing classifica-tion. Problem definition and game properties are introduced in section 3. The adversary strategies definition, the clas-sifier, and main contribution of this paper are presented in section 4, followed by the experimental settings and results in section 5. Finally, main conclusions and future work are presented in section 6.
As described by Dalvi et al. [9], an adversarial game can be represented as a game between two players: A malicious agent whose adversarial activity reports its benefits, and a classifier whose main objective is to identify as many ma-licious activities as possible, maximizing its expected util-ity. The malicious agent tries to avoid detection by chang-ing its behaviour (hence its features), inducing a high false-negative rate to the classifier. The adversary is aware that changing features to a non-adversarial behavior might not increase its benefit. Considering this, the adversary might try to maximize its benefit minimizing the cost of chang-ing features. This framework, based on a single shot game of complete information, was initially tested in a spam de-tection domain [9] where the adversary-aware na  X   X ve Bayes classifier had significantly less false positives and false neg-atives than the classifier X  X  plain version. Then a repeated version of the game was tested [9], where results showed that the adversary-aware classifier outperformed consistently the adversary-unaware na  X   X ve Bayes classifier.

Some extensions of the adversarial classification frame-work were recently developed. M. Kantarcioglu et al. [16], consider an adversarial stackelberg game model to define the interaction between the classifier and the adversary. They determine the subgame perfect equilibrium, reporting promis-ing results.

Recently, several studies about the possibility that a clas-sifier is intentionally mis-trained by the adversary or that its optimal strategies could be revealed in adaptive adver-sarial environments have been developed. Open questions such as  X  X an machine learning be secure? X  are extensively discussed in [2]. More specifically, Nelson et al. present in [21] how to exploit a spam classifier to render it useless us-ing a very specific attack framework, using indiscriminate, focused attacking and an optimal attacking function, all of them assuming that the training model used for the spam filter is based on na  X   X ve Bayes classifier.

Furthermore, Lowd and Meek proposed as the adversarial learning theory [18], which enables the adversary to recon-struct the classifier based on reasonable assumptions and re-verse engineering algorithms. However, Biggio et al. present a promising alternative to randomize the classifier decision function using multi-classifier systems, in order to hide the classifier X  X  strategy observed by the adversary, diminishing the adversarial learning and the possibilities to mis-train or learn from the classifier [6].
Spam filtering has been discussed over the last years, and many filtering techniques have been described [14]. Never-theless, phishing classification is different in many aspects from the spam case, where most of the spam email just want to inform about some product. In phishing there is a more complex interaction between the message and the receiver, like following malicious links, filling in deceptive forms, or replying with useful information which is relevant for the message to succeed. Also, there is a clear difference among many phishing techniques, where the two main cat-egories are known as deceptive phishing and malware phish-ing . While malware phishing has been used to spread mali-cious software to be installed on victim X  X  machines, deceptive phishing , according to [4], can be categorized into the follow-ing six categories: Social engineering, Mimicry, Email spoof-ing, URL hiding, Invisible content and Image content . For each one of these subcategories, specific feature extraction techniques have been proposed [4] to help phishing classifiers to use the right characterization of their respective messages.
Among the countermeasures used against phishing, three main alternatives have been used [4]: Black listing and white listing, network and encryption based countermeasures and content based filtering. The first alternative, consists in us-ing public lists of malicious phishing websites (the black list) and lists of legitimate non-malicious websites (white list), where each link in a message must be checked in both lists. The main problem of this countermeasure is that phishing websites do not persist long enough to be updated on-time in the black list, making difficult to keep an up-to-date list of malicious websites. The second alternative is based on email authentication methods, where the transaction time in encryption based methods could be a considerable com-putational cost. Besides, it is likely that a special techno-logical infrastructure is needed for this countermeasure [4]. Previous work on content-based phishing filtering [1, 3, 4, 5, 10] focused on the extraction of a large number of fea-tures and the usage of popular machine learning techniques for classification. These approaches for automatic phishing filtering have shown promising results regarding the relative importance of features.
Consider a message arriving at time t represented by the feature vector x t = ( x t, 1 , ..., x t,i , ..., x t,a ) , where x i th feature of message x t . Each message can belong to two classes: positive (or malicious) messages, and negative (or regular) messages. We define the adversarial classification under a dynamic game of incomplete information as a signal-ing game between an Adversary , which attempts to defeat a Classifier by not revealing information about his real type, modifying x i (a message of type i ) into x j (a message of type j ) by using the transformation function  X  ( x i ) = x Consider the incomplete information game, as defined by J. Harsanyi in [15], as the tuple where N = { 1 , ..., N } is the set of players, A n is the set of possible actions for player n ,  X  n  X  N . T n is the n th possible types set  X  n  X  N . p n is a probability function p n : T n  X  [0 , 1] which assigns a probability distribution over  X  j  X  X  T j to each possible player type ( T n ),  X  n  X  N . Finally, the utility function of player n is denoted by U ( payoff of player n as a function over the actions of all players ( A n ) and their types ( t n ).

Based on the previous scheme, as described in [11, 13], dynamic games of incomplete information can be modeled as a signaling game. The model of incomplete information for the adversarial classification between an Adversary ( A ) On the figure, x ij is defined by  X  ( x i ) = x j and I j information set where the classifier has to decide for the adversary, where  X  ( x i ) = x j is decided. and a Classifier ( C ), i.e. N = {A , C} , behaves as the following sequence of events.
 Firstly, Nature draws a type t i for the Adversary from versary is Regular (R) or Malicious (M), and defines the initial optional message of type i , x i . Nature draws accord-ing to the probability distribution p ( t i ) , where p ( t and his type t i , which can be either t R,x i or t M,x i , and chooses a message x j from his set of actions A A = {  X  ( x i ) = x where x i is defined from the type t R,x i or t M,x i . The func-tion  X  : R a  X  R a transforms a feature vector x i into x , the message which the Classifier has to decide its class. A non malicious adversary does not have incentives to modify its behavior, so  X  ( x i ) = x i , when its type is t
R,x i ,  X  i = { 1 , ..., k } . Thirdly, The Classifier observes x j (but not t i ) and chooses an action C ( x j ) from its set of actions A C = { +1 ,  X  1 } . It is important to notice that the Classifier is a single type player, so its type is common knowledge and there is no need to be mentioned further. Finally, payoffs are revealed by U A ( t i ,  X  ( x i ) , C (  X  ( x U ( t i ,  X  ( x i ) , C (  X  ( x i ))) .

The extensive form game that represents the signaling game between the Adversary and Classifier is presented in figure 1.

In order to analyze the optimal strategies for the Classi-fier in the proposed mechanism, special requirements and assumptions over the traditional Bayesian Nash equilibrium must be considered [13, 17].

Definition 1. Signaling requirement 1 (S1) After ob-serving any message x j , from A A , the Classifier must have a belief about which types could have sent x j . De-note this belief by the probability distribution  X  ( t i | x  X  ( t i | x j )  X  0 ,  X  t i  X  T and
Definition 2. Signaling requirement 2 (S2C) For each x j  X  A A , the Classifier  X  X  optimal strategy defined as the probability distribution  X   X  C over the Classifier  X  X  actions C ( x j )  X  A C , must maximize the Classifier  X  X  expected util-ity, given the beliefs  X  ( t i | x j ) about which types could have sent x j . That is, where U C ( t i , x j ,  X  (  X | x j )) =
Definition 3. Signaling requirement 3 (S2A) For each t  X  T , the Adversary  X  X  optimal message x j =  X  ( x i ) , defined by the probability distribution  X   X  A over the Adver-sary  X  X  actions x j  X  A A , must maximize the Adversary  X  X  utility function, given the Classifier  X  X  strategy  X   X  C . That is, where and U A ( t i , x j ,  X  C (  X | x j )) =
Definition 4. Signaling requirement 4 (S3) For each x  X  A A , if there exists t i  X  T such that  X   X  A , then the Clas-sifier  X  X  belief at the information set I j corresponding to x must follow from Bayes X  rule and the Adversary  X  X  strategy If
P probability distribution.

Sequential equilibria, a subset of perfect Bayesian equilib-rium (PBE) in the adversarial signaling game is a pair of mixed strategies  X   X  A and  X   X  C and a belief  X  ( t i | x signaling requirements S1, S2C, S2A , and S3 . It is clear, by construction of the mechanism, that requirements S1 and S3 are satisfied by the adversarial classification game. How-ever, signaling requirement S2A will be considered satisfied as a first approach and a strong assumption on the game development. Whether adversarial behavior strategies, as described by [9], could represent a more reliable interaction will be considered as an open question to be treated as future work.

Recently, numerical approximation on the sequential equi-libria refinement have been proposed by Turocy in [25], using a transformation of the logit quantal response equilibrium (QRE) correspondence, parameterized by a scalar precision parameter, which as tends to infinity, a numerical approx-imation for the sequential equilibria is obtained. This nu-merical algorithm has been implemented in Gambit [19], an open-source project for estimating equilibrium results in fi-nite games.
In this section the main characterization of the signal-ing game proposed and contribution of this work is pre-sented. Firstly, the Adversary  X  X  strategies and types are determined by the usage of unsupervised learning tecniques. Then, the classifier strategy represented by a novel data min-ing algorithm which includes game-theoretic parameters is extensively developed.
The previously defined classifier was tested over an En-glish language phishing and Ham email corpus built us-ing Jose Nazario X  X  phishing corpus [20] and the Spamassas-sin Ham collection. The phishing corpus 1 consists of 4450 emails manually retrieved from November 27, 2004 to Au-gust 7, 2007. The Spamassassin collection, from the Apache SpamAssassin Project 2 , is based on a collection of 6951 Ham email messages. The email collection was saved in a unix mbox email format, and was processed using Perl scripts.
As initially described in [10] and then in [3, 4, 5], the extraction of basic content-based features is needed for a minimum representation of phishing emails. These features, considered as binary variables for this study, are associated to structural properties of the email, link analysis, program-ming elements and the output of the spam filters. It is im-portant to notice that basic features (a total of 15 features) are directly extracted from content-based properties of an email message, and each one can be considered as a strategy for the Adversary to defeat the Classifier .
Previously mentioned features are not sufficient for the ap-propriate characterization of a phishing message, and clearly not the complete representation of adversarial strategies. Following the content-based extraction techniques, a new list of features is proposed to characterize phishing emails, which is related to the Adversary  X  X  strategy A A .
In the following, word-based features will be described as an approach to fulfill the needed phishing strategies X  rep-resentation. These features will be presented as a binary variable for each word in a list of keywords, whose value is 1 if the word is used in the document, and 0 otherwise. The main idea is that phishing strategies are defined as a list of words used in a message. So, for each keyword cluster ( Adversary type), a list of relevant words will be associ-ated, representing a phishing strategy.

First, a stop-words removal and stemming pre-processing is necessary to setup the email database. Let R be the to-tal number of different words in the complete collection of phishing emails, and Q the total number of emails. A vec-torial representation of a the phishing corpus is given by M = ( m ij ) , i = 1 , ..., R and j = 1 , ..., Q , where m weight word i in a document. The weights m ij considered in this research are an improvement of the basic tf-idf term [27, 28] ( Term Frequency times inverse document frequency ), and are defined by where f ij is the frequency of the i th word in the j th docu-ment, sw ( i ) is a factor of relevance associated to word i in a set of words and n i is the number of documents containing word i . On this case, sw ( i ) = w i email TE , where w i frequency of word i over all documents, and TE is the total amount of emails.

The tf-idf term is a weighted representation of the im-portance of a given word, in a document that belongs to a collection of documents. The term frequency indicates the weight of each word in a document, while the inverse document frequency states whether the word is frequent or uncommon in the document, setting a lower or higher weight respectively.

Based on the previous tf-idf representation, a clustering technique must be considered for the segmentation of the whole collection of phishing emails. k -Means clustering with the cosine between documents, as the distance function was used. Furthermore, the optimal number of clusters was de-termined using as stopping rules the minimization of the distance within every cluster and the maximization of the distance between clusters. Then, for each cluster the most relevant words are determined by for i  X  1 , .., R , where Cw is a vector containing the geometric mean of each word X  X  weights within the messages contained in a given cluster. Here,  X  is the set of documents in each cluster and m ip as defined in equation 5. Finally, the most important words for each cluster can be determined ordering the weights of vector Cw . This procedure is based on previ-ous work described in [29]. Results on this method showed that the optimal number of clusters is 13, where the 30 most relevant words of each cluster were considered as features (a Table 1: Five most relevant words for each of the 13 clusters of the phishing corpus.
 total of 390). The first five relevant words of each cluster are presented in table 1.
Based on previously mentioned features (a total of 405 features), a feature selection algorithm is used to improve the performance of the classification algorithms, eliminating noisy features that do not represent the target value, and do not provide enough information about the underlying phe-nomenon observed by the game agents. This is a key step for eliminating word features considered arbitrarily as the 30 most relevant words for each cluster, giving a final list of attributes for the phishing/ham classification problem. These attributes represent the strategy profile for a given Adversary . An information-theoretic feature selection al-gorithm was implemented, where the information gain for each feature was calculated over the whole database, elimi-nating those features that did not report a minimum thresh-old. 153 features where eliminated, obtaining the final set of 252 features.
 The Adversary  X  X  types t i  X  T are extracted using k -Means clustering over the collection of emails (phishing and ham). Therefore, the number of clusters over the whole set of features ( K features ) will represent the total number of types for the Adversary player. For each message x j , represented by a vector of 252 variables, the type will be determined by where C i is the centroid of cluster i , and function d : R a  X  R a  X  R represents the distance between two vectors of dimension a . The distance function used in this research is the Hamming distance, represented by the number of bits needed to change one vector into another.
As mentioned before, the Classifier  X  X  optimal strategies are defined by the set A C = { +1 ,  X  1 } . From the signal-ing requirement S2C , it can be shown that the Classifier  X  X  optimal strategy C  X  ( x j ) can be solved by the following con-ditional statement, defined by equation 4, and In the following, these expressions will be considered as and where  X  M .  X  R ,  X  M and  X  R must be defined based on mi-croeconomic assumptions on the primitives of the game, and e is a vector of ones, whose dimension is a . The modeling intuition and the final analytical expression of the utility functions are intentionally omitted in this paper.
The previous game-theoretic result (condition 9), can be considered as a prior knowledge constraint in a classification problem, associated with the regularized risk minimization from the statistical learning theory proposed by Vapnik in [26]. All this, is formulated as the following quadratic prob-lem, Where, and  X  ( x i ) =
The online algorithm to solve the proposed minimization problem, is based on solving its dual formulation using the Sequential Minimal Optimization (SMO) described by Platt in [22]. The SMO algorithm is used to train SVMs breaking up the large Quadratic Programming (QP) representation of the dual into small series of QP problems, which are solved analytically by the algorithm. Small changes in the SMO algorithm, such as explained in previous prior knowledge inclusion in SVMs [31] were considered. Based on previ-ous work on Online Support Vector Machines algorithms described by Gentile in [12] and later by Sculley in [23], the proposed adversary-aware classifier is stated as follows, Algorithm 4.1 : Bayesian Adversary-Aware Online SVM Data : ( x 1 , y 1 ) , ..., ( x n , y n ) ,  X  M ,  X  R ,  X  Result : f ( x t ) = w T  X  x t + b t
Initialize w 0 := 0 , b 0 := 0 , seenData := {} ; foreach x t , y t do return 1 ;
Previous algorithm 4.1 presents the online learning al-gorithm, Bayesian Adversary-Aware Online SVM (BAAO-SVM). Based on the Classifier  X  X  beliefs and sequential equilibrium strategies, the hyperplane parameters are up-dated, incorporating as prior knowledge constraints the game theoretic results. The main idea of the algorithm, is that given an incoming message x t , a label is assign using the classification function f ( x t ) = w T t  X  1  X  x t + b t  X  1 sifier  X  X  optimal strategy is not satisfied (equation 9), the hyperplane parameters are updated using a modified version of the SMO algorithm over the seen messages (seenData set). A memory parameter m is used to set the number of mes-sages in seenData. Then, every Gp periods, the sequential equilibrium strategies are updated using logit QRE. Finally, x is added to seenData and the type X  X  probabilities are up-dated, hence beliefs and  X ( x i )  X  i  X  seenData. At t = 0 , with no prior information, all outcomes can be considered equally likelly to happen. It is important to notice that the algorithm evolves dynamically as messages are presented to the Classifier .
In this section, the experimental settings for batch and online learning performance evaluation, as well as the eval-uation criteria is presented.
The classification of phishing emails is a natural extension of text mining, where the most promising classification algo-rithms are Support Vector Machines, na  X   X ve Bayes, Random Forest, among other text categorization algorithms [24]. In the online setting, the problem associated to the email in-box nature, where messages arrive from an undetermined set of messages. In this context, the following experiments will be determined to give the right benchmark results for the proposed feature extraction between previous results and batch learning SVMs. Likewise, the main objective of the experimental setting is to show the accuracy and effective-ness between different online classification algorithms and BAAO-SVM, the proposed online adversary aware classifier.
Firstly, a 10 times 10 cross validation learning schema using SVM on the complete database characterized with 265 features was developed, using the libSVM-library [7], and the same learning schema was used to train a na  X   X ve Bayes model implemented in Weka [30]. Then, for the on-line setting, the Relaxed Online SVM (ROSVM) proposed by Sculley in [23] was used, as well as an incremental eval-uation of na  X   X ve Bayes, and BAAO-SVM were evaluated in this schema.

The adversary aware classifier was developed using the 265 features as possible Adversary  X  X  strategies, and the { +1 ,  X  1 } set as the Classifier  X  X  strategies. Types where considered as previously described type extraction method, where a total of 7 clusters were obtained. Approximation on the sequential equilibria was determined using logit QRE, implemented in Gambit [19] software command-line tool ( gambit-logit ). The Classifier  X  X  strategy (adversary-aware classifier) described in section was implemented in C++, ex-tending D. Sculley X  X  Online SVM implementation [23], with a modified version of SMO for prior knowledge described in [31]. BAAO-SVM parameters tunning were estimated over a 20% subset from the overall dataset, setting m = 100 for the time window,  X  = 0 . 6 for the threshold, G p = 250 for the game period, and C = 100 for the SVM objective function.
The values of  X  M .  X  R ,  X  R and  X  M where defined as an initial estimation over the primitives of the game. More details on this model parameters finding where intentionally omitted by the authors.
The resulting confusion matrix can be described using four possible outcomes: Correctly classified phishing messages or True Positives (TP), correctly classified ham messages or True Negative (TN), wrong classified ham messages as phishing or False Positive (FP) and wrong classified phish-ing messages as ham or False Negative (TN). The evaluation criteria considered are: The False Positive Rate (FP-Rate) and the False Negative Rate (FN-Rate) as the proportion of wrongly classified ham and phishing email messages respec-tively. Precision, as the classifier X  X  safety, states the degree in which messages identified as phishing are indeed malicious. Recall, as the classifier X  X  effectiveness, states the percentage of phishing messages that the classifier manages to classify correctly. F-measure, the harmonic mean between the Pre-cision and Recall, and Accuracy, the overall percentage of correct classified email messages.
As shown in Table 2, the F-measure obtained for a 10 times 10 fold cross-validation SVM is 99.32% and for the na  X   X ve Bayes algorithm under the same learning schema the F-measure obtained is 94.84%. Previous results for the same email corpus reported an F-measure of 99.89% obtained by Bergholz et al. in [5]. In some evaluating measures, these results are slightly worst than previously obtained results, Table 2: Experimental results for the benchmark machine learning algorithms in the Batch Learning context.
 Table 3: Experimental results for the benchmark machine learning algorithms in the online learning context.
 but are highly competitive. This points out an interesting open question: as a future work, a combined feature extrac-tion technique could achieve better results. However, results for the False Positive Rate is considerable better than pre-viously obtained with a value of 0.33%, compared to 1.11% respectively.
To identify the online property of learning algorithms is not an easy task. In this work, a first approach using previ-ously mentioned classification performance measures in sec-tion 5.1.1, the applicability and accuracy of the overall pro-posed algorithm were tested. Here, as shown in table 3, ROSVM obtained an F-measure of 86.01% with an accu-racy of 85.20%, for an online version of na  X   X ve Bayes the F-measure is 85.20% whose accuracy is 81.18% and for the proposed adversary aware classifier (BAAO-SVM) the F-measure is 87.69% whose accuracy is 86.63%, with a better performance than previously used online classification algo-rithms on these evaluating criteria.
An extension of the Adversarial Classification framework for Adversarial Data Mining was presented, considering dy-namic games of incomplete information as a new approach to make classifiers improve their performance in adversar-ial environments. This work considered strong assumptions on the Adversary strategies, the utility function modeling for the Classifier , and experimental setups related to the database processing.

The proposed adversary-aware classifier, BAAO-SVM, whose core is mainly the Support Vector Machines model, considers a signaling game where beliefs, mixed strategies and proba-bilities for the messages X  types are updated and incorporated as prior knowledge, as new email messages arrives. This en-ables the classifier to change the margin error parameter dynamically as the game evolves, considering an embedded awareness of the adversarial environment. More specifically, this is considered in the miss-classification constraint in the optimization problem for the SVM algorithm. As a first ap-proach, the experimental settings showed promising results over previous online text categorization algorithms used for email filtering.

Feature extraction is a key component for the game strate-gies and types for the game proposed. Results showed that the proposed strategies used as features are highly competi-tive in comparison with previous feature extraction work in phishing filtering. Future work could be oriented to con-sider a mixture of former and present feature extraction techniques. This could estimate a better strategy space for the Adversary , therefore improving the Adversary types. This is an important topic that affects directly the definition of the signaling game, hence the Classifier  X  X  performance.
Determining the actual drift concept of the game, e.g. Ad-versary learning new phishing strategies, is an important open question. An experimental setup to show the impact on the classifier X  X  performance related to the inclusion of new Adversary strategies within an already defined set of strategies (features) might help to answer this question in future work.

In game modeling, adversaries must be considered as strate-gic agents. For this, their strategies could be estimated using linear programming, as previous authors recommended in the original Adversarial Classification framework [9]. How-ever, this first approach in adversarial classification with dy-namic games of incomplete information showed interesting empirical and theoretical results. An extension on theoret-ical aspects of the game theoretical framework, such as re-finements on these equilibria, using for example the intuitive criteria proposed by Cho and Kreps [8], among other special refinements for the perfect Bayesian [11] equilibria could be considered.
Support from the Millennium Science Institute on Com-plex Engineering Systems (www.sistemasdeingenieria.cl) and the Center for Analysis and Modeling for Security (www.ceamos.cl) is greatly acknowledged. [1] S. Abu-Nimeh, D. Nappa, X. Wang, and S. Nair. A [2] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and [3] R. Basne, S. Mukkamala, and A. H. Sung. Detection [4] A. Bergholz, J. D. Beer, S. Glahn, M.-F. Moens, [5] A. Bergholz, J.-H. Chang, G. Paass, F. Reichartz, and [6] B. Biggio, G. Fumera, and F. Roli. Multiple classifier [7] C.-C. Chang and C.-J. Lin. LIBSVM: a library for [8] I.-K. Cho and D. M. Kreps. Signaling games and [9] N. Dalvi, P. Domingos, M. Sumit, and [10] I. Fette, N. Sadeh, and A. Tomasic. Learning to detect [11] D. Fudenberg and J. Tirole. Game Theory . MIT Press, [12] C. Gentile. A new approximate maximal margin [13] R. Gibbons. Game Theory for Applied Economists . [14] J. Goodman, G. V. Cormack, and D. Heckerman. [15] J. C. Harsanyi. Games with incomplete information [16] M. Kantarcioglu, B. Xi, and C. Clifton. A game [17] D. M. Kreps and R. Wilson. Sequential equilibria. [18] D. Lowd and C. Meek. Adversarial learning. In KDD [19] R. D. McKelvey, A. M. McLennan, and T. L. Turocy. [20] J. Nazario. Phishing corpus, 2004-2007. [21] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, [22] J. Platt. Sequential minimal optimization: A fast [23] D. Sculley and G. M. Wachman. Relaxed online svms [24] F. Sebastiani. Text categorization. In A. Zanasi, [25] T. L. Turocy. Using quantal reponse to compute nash [26] V. N. Vapnik. The Nature of Statistical Learning [27] J. Velasquez, H. Yasuda, T. Aoki, and R. Weber. A [28] J. D. Velasquez and V. Palade. Adaptive Web Sites: A [29] J. D. Velasquez, S. A. Rios, A. Bassi, H. Yasuda, and [30] I. H. Witten and E. Frank. Data Mining: Practical [31] X. Wu and R. Srihari. Incorporating prior knowledge [32] P. Zhang, X. Zhu, and Y. Shi. Categorizing and
