 Information systems have traditionally been developed for groups of people or stake-holder roles. However, there are several a pplication areas where the user as an indi-vidual is the focus of the application. For example, recommender systems deliver personal advice services [1], while many games and learning support systems are customized for the individual user. Adaptive systems have modeled user goals and contexts, although personal needs were not specified in a systematic manner [20] Mobile, context-aware and self-adaptive systems frequently need to be tailored to individual preferences and context. Here, requirements may not only vary by individuals but may also change over space and time [3-4]; athough systems based on personas have been developed [5], little guidance exists about what constitutes user-centric-data modeling for such systems. To address this shortcoming, this paper proposes a framework for person-centric conceptual modeling. Our motivation is to extend scenario-based persona  X  X ser stereotypes X  used in human-computer interaction by providing a model-based framework for personal and contextual modeling. 
We argue that a framework for individual-level requirements is necessary as tech-nology products become personalized and individual users become embedded in the loop of self-adaptive systems. In this paper we propose a framework for personalized and contextual modeling with guidelines for eliciting user-centric information and deciding how personal requirements should be implemented. The following section reviews related work, then section 3 describes our proposed conceptual framework and preliminary taxonomy of models for personalized adaptive, context-aware sys-tems. Section 4 applies the framework and method in a healthcare technology case study. The paper concludes with a discussion and road map towards future research. Models and requirements matched to different stakeholder roles has been established in the viewpoint tradition of requirements analysis, e.g. PREview [6] and [7]. Variability and specialization of generic requirements to fit more specialized usage domains has also been investigated in the product line literature [8] as variation points that specify where generic requirements may be tailored. In human-computer interaction, requirements are seen as an individual concern for customizing the user interface and matching the mix of functional requirements to individuals [9]. Personas [10] are an established approach to modeling typical users as stereotypes describing typical behaviors with scenarios, as well as recording user objectives, motivations and beliefs. Personas were extended with dime nsions for attention and reactivity for purposes of modeling requirements for adaptive mobile applications [5]; however, they have not been extended beyond simple, scenario-based formats. 
System models of environmental phenomena have been described in many disciplines, for instance problem-solving methods in knowledge engineering [11], user models in human-computer interaction [12], and user/context models for adap-tive user interfaces. In recommender systems, models of users preferences are either inferred from choices or entered as a user profile, augmented by semantic networks of preferences and make wider-ranging suggestions [1]. 
Appropriate consideration of personal values, social and political views has been recognized as a key aspect of successful system development [13], while socio-political issues are key factors in many system failures [14-15]. In their review of power and political issues, [16] pointed out that requirements are socially constructed in a political context, and argued for development of techniques for social power modeling. Stakeholder conflicts often arise from users X  values where adverse emotional responses can lead to system rejection; for example, stakeholder values of ownership and control can lead to frustr ation and rejection of ERP (Enterprise Resource Plan) systems. User values have been analyzed at a high level of cultural attributes such as power distance and individualism [17], while [18] argued that cultural values should have an important influence on requirements definition. Values and affective responses have been investigated by [19] in worth maps, which attempt to document stakeholders X  views about products or prototypes, expressed as feelings, values and attitudes. 
In psychology, values are beliefs and attitudes held by people about other people, organizations or artifacts; for instance, in Small Group Theory [20], values, beliefs and attitudes are held by group members and influence the group operation, collabora-tion and performance. Rescher X  X  Value Theory [21] provides a classification of the benefits of values, e.g. economic, moral, social; objects they apply to: things, the environment, people, groups and whole societies; and potential benefit of applying values such as economic, moral, social, political, aesthetic and religious. Modeling context at the requirements level has been recently addressed by REAssuRE [22], and [23]. A common thread for much of this work is that goal models are extended to include an explic it representation of context, defined as a partial state of the world that is relevant to an actor X  X  goals [23]. Spatial and temporal data modeling has also received mu ch attention for context-aware, mobile systems. For example, [24] identifies and tracks objects in a topographical space for functional adaptations. The PC-RE method [25] proposed goals for individual people and monitors to track attainment of such goals in assistive technology applications, although it did not address context-sensitive self-adaptive applications specifically. 
In conclusion, many of the components of context-aware conceptual modeling ex-ist; however, person-centric modeling is less mature, and furthermore, personal and contextual modeling is ad hoc with few gene ric models to guide elicitation of such knowledge. We argue that new models focusing on individual people are necessary to enable development of personalized, cust omized and context-aware systems. The aim of the framework is to describe individual users X  needs, goals, and attributes, which may be important for systems that adap t at runtime to user context. Personal information has two interpretations in our framework: information describing people, i.e. their characteristics; and information held by people, i.e. their beliefs, values and goals. The framework accommodates the matching of requirements to individual needs, how individual needs change over time, how requirements evolve as people learn and their ambitions grow, and finally the needs for universal accessibility and the ageing user population [26]. 
We propose a two-layer framework for personal and contextual requirements, placed in the perspectives of location and time, which act on both layers. The User Characteristics while the Personal Goals layer models mental states held by a person. User characteristics time. In contrast, personal goals/values may vary from motivations and values, which are stable over a person X  X  lifetime, to short-term goals. The perspectives of space and time that form cross-cutting  X  X spects X  at each layer are intended to encourage analysis of the evolution and change in contextual models. 3.1 The User Characteristics Layer The user characteristics layer (see Table 1) models the needs of individual users and generic user characteristics. The main pur pose of this layer is adapting designs to individual users in assistive technology, learning systems and other personalized sys-tems involving physical or mental parameters of individual users. Individual user ability profiles may be needed to cope with change over time as, for example, people learn system functions and need new styles of dialogue as they become more skilled; necessitate change in the form of, for example, magnified visual displays and slower response times. Location may also affect user characteristics as people X  X  abilities change with place, such as the need fo r adapting communication modalities in noisy environments. 
The focus of the user characteristics layer is the individual user, who is modeled with attributes describing physical and me ntal characteristics. Individual user attributes are taken from inventories of modality abilities, knowledge and capabilities [27], and general cognitive abilities [28]. User characteristics can be assessed by psy-chology-based questionnaires and tests to measure cognitive, physical and perceptual abilities (e.g. [28]) or by interviewing users to gather information on general abilities, experience and skills. Assessing the user X  X  characteristics also produces an inventory of specific skills that we assume the user possesses to successfully operate the system. Physical characteristics are applied in assi stive technology applications or any socio-technical system involving physical action by the user, e.g. operating machinery or moving in augmented reality applications. A checklist of height, weight, physical movement abilities, fitness, etc. is used to test obstacles to human operation. Mental characteristics are applied in similar circumst ances to check requirements for assistive technology and potential barriers to safe system operation. Skill, knowledge and learning abilities will be pertinent to training and educational technology, while cognitive abilities such as short-term memory, attention span, motor control, and reasoning need to be checked with impairments such as dyslexia and dyspraxia for healthcare applications. These lists are illustrative rather than exhaustive, since the level of detail will be determined by the application. 3.2 The Personal Goals Layer At this layer, which includes attitudes and preferences, personal goals are held by individuals and become important in appli cations where customization of individual services is the prime objective, e.g. ente rtainment and games, personal knowledge management and assistive technology. Values are important since they may influence human behavior and responses to adaptive systems, especially in persuasive technolo-gy [29], decision support and recommender systems, which attempt to influence hu-man behavior. Change over time in this layer depends on the stability of people X  X  wishes, while the contextual interaction may be influenced by how their goals are affected by location and the social setting (e.g. social settings may influence privacy and hence the display of personal information). 
Personal goals can be assigned attainment levels on a 1 to 5 scale so the user X  X  progress towards achieving each goal can be monitored and assessed. The attainment levels also specify the assumptions associated with each goal, such as the necessary customization of the software, modification to requirements (i.e. re-design) and user training. Personal goals may require monitors to be specified to capture user behavior, so goal attainment can be assessed. Other personal goals may be implemented as pre-ference settings under user control, e.g. aesthetic details such as screen savers and ring tones on mobile phones Values are a key component of this layer. A taxonomy of user values is given in Table 2. Nine upper-level value categories are proposed based on Rescher X  X  theory [21], card sorting experiments and expert interviews [30]. Six categories are common-ly recognized concepts across most taxo nomies: trust, morals, aesthetics, priva-cy/security, sociability and creativity/innovation. Synonyms which express variations on the core value are given in the related terms column. Personal characteristics val-ues are taken directly from the  X  X ig five X  framework, which is the accepted standard of personality theory [27]: openness (inventive/curious vs. consistent/cautious), con-scientiousness (efficient/organized vs. easy-going/careless), extroversion (out-going/energetic vs. solitary/reserved), agreeableness (friendly/compassionate vs. cold/unkind) and neuroticism (sensitive/nervous vs. secure/confident). 
Trust, sociability and moral/ethical values are all properties of relationships with others or within groups, whereas creativity is closely linked to curiosity, experimenta-attitudes are a diverse category including socio-political, cultural and religious beliefs. These values change more rapidly, driven by social, cultural and political issues as well as events, so this category is an open-ended set that varies across time and cul-tures, whereas the other values are general time-invariant conceptual structures or belief systems, independent of culture. Motivations [31] for achievement and self-esteem are related to incentives for personal goal achievement, whereas power and ambition have connotations for how authority and responsibility is distributed among individuals in the system. Emotions are responses to events and situations [32], which may have important effects on personal goal achievement, either as positive rewards in pleasure in system operation, or frustration when usability problems are encoun-tered. Emotional responses are important in human-in-the-loop adaptive systems when the potential emotional response of users to system advice and decisions needs to be considered. The potentia l sources in column three suggest questions and inter-view topics for eliciting particular values. Each value has design implications. For example, the achievement of trust may be accomplished by making actions visible and using components or services with established reputations. 
Values are uncertain concepts so they may need to be modeled as a probabilistic influence on a person X  X  goals or behavior. A suitable representation for reasoning in both personal user layers is to construct causal models as Bayesian networks (BNs), enabling the influences of values on goal achievement to be explored in different scenarios. The BN predicts how an indivi dual may achieve a personal goal according to a combination of values and motivations set against possible negative influences from the constraints of time and access to resources. 
Obstacle analysis [33] can be used to enquire how and when dissonance between design assumptions and the system environment may occur, raising questions such as: what barriers prevent the system monitoring its world, does the rate of change in the world become too fast, or even too slow with interval-based monitoring? Inconsisten-cies may exist between models of different types and obstacles might hinder or pre-vent the acquisition of models by software systems. These concepts can be applied to models where the systems need to adapt to individual people as well as specifications used as a checklist of potential obstacles, which could hinder achievement of personal goals, e.g. does the user have the necessary skills and training to achieve a performance goal? In the personal goals layer, values suggest  X  X eak obstacles X  or probabilities that th e user X  X  behavior in an adaptive system may be uncooperative and hence hinder the attainment of personal and system goals. This section illustrates experience of applying the initial forms of the framework in an Ambient Assisted Living (AAL) system [34]. In the AAL, there are two users: the occupant of the house, Mary, and a carer who monitors Mary X  X  condition. Our appli-cation of the framework employs goal modeling to explore the goals of the system. We use KAOS [35] because of its support for obstacle analysis. Mary X  X  personal characteristics are used to identify obstacles to goal achievement, prompting the iden-tification of new obstacle-mitigating goals. Mary X  X  personal goals are then applied to amplify the analysis, by developing weak obstacles. Like obstacl es, weak obstacles are barriers to achievement of the overall system goal to maintain Mary X  X  health but are treated in a probabilistic way. This analysis stimulated exploration of different options to incentivize Mary to make her compliance with her health regime more probable. Her medical condition is treated with medi cine that she is able to administer herself. Figure 1 shows a subset of the goal model using a slight variant of KAOS. This subset comprises the primary goal ( Maintain[IsHealthy] ), the sub-goal Achieve[CorrectMedicineDose] and its two sub-goals Achieve[MedicineTaken] and Achieve[ReleaseDose] . Strictly speaking, these last two are (respectively) an expectation because responsibility for Achieve[MedicineTaken] is assigned to a human actor (Mary), and a requirement since Achieve[ReleaseDose] is assigned to a system component (an automatic medicine dispenser). This represents a model of the AAL X  X  maintenance of Mary X  X  health in which a dose of Mary X  X  medication is period-ically delivered by an automatic dispenser. Mary is then expected to act by taking the dispensed medication. 4.1 Personal Characteristics Mary has mild cognitive impairment (MCI), which effects her attention and short-term memory; she tends not to perform routine tasks reliably, presenting an obstacle to maintaining her health. The obstacle is represented as the bottom of the Achieve[MedicineTaken]. Obstacle analysis is developed bottom-up and two plausibly consequent obstacles are identified that may have a negative affect on Mary X  X  health: Underdose (in which the dose is missed completely) and Overdose (in which the dose is initially overlooked but then taken with the next dose). Achieve[PromptToTakeMedicine]. The goal Achieve[PromptToTakeMedicine] derives three sub-goals; Achieve[Remind MedicineUntaken], Achieve[DetectUntaken Medicine] and Maintain[MonitorDispenserTray]. Thus, to determine if Mary has forgotten to take her medicine, a means of sensing the dispenser is planned so that the system can detect whether medicine remains uncollected. If this remains so after some given time, an advisor system will remind Mary to take her medicine. Finally, notwithstanding Mary X  X  poor health, a domain assumption is identified; that Mary wants to maintain her health. 4.2 Personal Goals Although an advisor system is planned to remind Mary to take her medicine, her cognitive impairment suggests obstacles to her compliance with system recommenda-investigate options for improving the probability of her cooperating with the system and achieving her personal goals. From this analysis, particularly with respect to her Motivation and her Emotional Responses (Table 2), two personal goals are elicited from Mary; to Avoid intervention representing a desire to maintain her independence, and to Minimize intrusion representing not to be overtly managed. Both goals are represented as soft goals since they necessarily express desired qualities to be experienced by Mary rather than functional properties of the AAL. Soft goals can be used to evaluate the impact of the goals already identified or the ways in which the goals are operationalized. Thus, in Figure 1, the arc connecting Achieve[MedicineTaken] to Avoid intervention (a contri-bution link ) is annotated with a  X + X  indicating that by taking her medicine Mary can have a positive effect on maintaining her independence. However, Achieve[Prompt ToTakeMedicine] has a negative ( X - X ) effect on Minimize intrusion since such prompts not only remind Mary to take her medicine, they also remind her that she is being managed. Mary X  X  personal goals are derived from her values and preferences, but the contributions these make to her personal goals need to be understood since they may have either negative as well as positive effects on goal achievement and may be sensi-tive to features of the AAL design. We thus treat them as weak obstacles to attain-ment of Mary X  X  personal goals. 
Values and preferences can be somewhat uncertain conceptually, so it is beneficial to develop them beyond depicting the personal goals they derive in the goal model. In Mary X  X  case, modeling her motivations and values may suggest further interventions to change her behavior towards a more productive response. Consider her Avoid intervention goal. As well as Mary X  X  MCI, her behavior could be influenced by a variety of factors which alter her intent to follow the system X  X  advice. This is Conscientiousness ) are inputs to the model and represent values or related terms sug-gested by Table 2. The nodes on the second level are internal to the model and simply serve to aggregate the inputs in a way that makes it feasible to combine them using Bayes X  theorem (see below). An exception on the second level is the node Attention , which represents the manifestation Mary X  X  MCI. Thus in the example, the model combines personal goals, values and preferences that apply to Mary as elicited by the characteristic of Mary X  X  MCI on achieving Mary X  X  Avoid intervention goal. 
At the top left of the model, the effect of Mary X  X  value of Trust in the system and wil-lingness to Cooperate with it and her carer (that we have aggregated under Relation-sentment , the consequences of the technology being imposed on her life will be to in-crease her tendency to ignore or subvert the system. The Concerns branch combines her desire for Privacy with a personality attribute, Conscientiousness . In this case, therefore, being more conscientious will counteract a high desire for privacy in influencing her intent. The final node represents her MCI condition, the chance of her failing to remem-ber to take her medicine or notice reminders issued by the advisor system. The BN combines the input nodes X  influences using Conditional Probability Tables (CPTs) with prior probability distributions in Bayes X  theorem to predict the probability that Mary will achieve her Avoid intervention goal with a high/medium or low. This is illustrated in the conditional probability table in Table 3, which deals with the Relationship branch from Figure 2. 
The BN model is implemented by configuring CPTs for each set of parent-child nodes where the input nodes are the parents. The settings of High/Medium/Low of the parent input variables determine the output probability of child variable Relationship . When the network and CPTs have been completed, Bayes X  theorem is used to calcu-late the probability of each state of each node in the net, as shown in equation 1: Where, P(a/b) = posterior (unknown) probability of a being true given b is true P(b/a) = prediction term for b given a is true (from CPT) P(a) = prior (input) probability of a P(b) = input probability of b The BN network can be used at design time by setting the input (parent) nodes to High/Medium/Low values to investigate the weak obstacles influencing Mary X  X  intent and probable response to the system. Input values may be estimated by experts and other stakeholders such as Mary X  X  carer, or measured directly, e.g. personality attributes: conscientiousness. Different scen arios are run to assess which combination will result in an acceptable probability that Mary will achieve her Avoid intervention goal. For instance if Mary has a good relationship with her carer and the system (both the prompts ( Frustration and Resentment are high), with a medium level of Privacy and low Conscientiousness , what is the probability that she will achieve her goal; that is Avoid intervention = high, with a probability &gt;0.9? The answer will depend on the algorithm implementing Bayes formula plus the assumptions about the causal influence embedded in the CPTs. 
Once the BN is set up it can be reused for many personal analyses. The model could be treated as a general representation of trade-offs between user values, adverse emotional response to the system and trust in the technology. Furthermore, it can be personalized by changing the biases in the CPT tables to reflect, for instance, a lower propensity to trust technology. Personalization could also be achieved by running responses? Alternatively, the BN and CPT could be reconfigured to change the com-binations of motivations, emotions and values. A similar BN would be implemented for her Minimize intrusion goal, although in this case runtime feedback could be incorporated by detecting ignored remind ers which would increase the chances of (self-esteem), trust, and emotional responses, etc. 
The personal goals, values and preferences analysis exposes the conditions under which Mary X  X  goals may or may not be achieved. Mitigations can then be planned in the social system to ensure that Mary is well motivated and has good trust in the sys-tem, while the technology design might need to be improved to reduce the chance of adverse emotional responses. Some examples of possible mitigations are to monitor Mary X  X  compliance and reward her with encouraging messages for good behavior; system trust could be improved by using avatars and empathetic characters to present and explain the prompts to Mary; while precautions to prevent adverse emotional response might be implemented as a graded series of messages starting with a gentle tone and only becoming more assertive if Mary has missed more than three reminders. 
So far, we have not discussed the time or location dimensions of the AAL. Howev-er, these should be consider ed to understand how they might affect attainment of Mary X  X  Avoid intervention and Avoid intrusion goals. These should be considered at design time; for example to avoid dispensing medicine at night when Mary is ex-pected to be asleep. Howeve r, an adaptive system such as the AAL also offers the opportunity to monitor goal attainment, to collect data to try to better understand Mary X  X  behavior in terms of her user characteristics and personal goals, values and preferences, and to adapt the system to better tailor the system to Mary. Notice that in a self-adaptive, human(carer)-in-the-loop, socio-technical system such as the AAL, adaptation need not be fully autonomic. Rather, causality between what is observed by monitoring and goal attainment may need human interpretation and enactment of adaptations may affect the social elements of the system. 
For example, interventions could be monitored to detect trends, such as the incidence of Mary failing to take her medicine which could be recorded to look for trends perhaps indicating distractions arising from Mary X  X  mealtime or television habits, or the presence of visitors. These would need to be interpreted by Mary X  X  carer but interpretation may be better informed if other elements in the AAL could be mo-nitored to infer coincidence of untaken medicine with phenomena such as background noise from the television, Mary X  X  location, recent family visits, etc. Mitigating actions taken might then be possible, such as synchronizing the dispensing of medicine with Mary X  X  TV habits, or tuning reminders if family visits appear to correlate with changes in Mary X  X  motivations or emotions. This capability to monitor and adapt represents a form of requirements awareness [36]. 
For future work, we will investigate the integration of models of location and tem-poral context. Spatial data modeling [37] and Geographic Information Systems [38] have produced techniques for representing location, coordinate systems, special form and proximity, orientation and direction. Spatial and temporal modeling for mobile systems [24] identify objects in a topographi cal space, while formal temporal logics have been applied to requirements [35] and personal goals. Finding a way to syste-matize analysis of the impact that location and time have on personal goals and their fulfilment would significantly extend the utility of our approach, particularly for prob-lem domains in which user mobility was a major feature [39]. Implementation path-ways will be based on BN toolkits [40-41] and our existing BN modeling tools [42] which will be integrated with goal-oriented model checkers adapted for KAOS obstacle analysis. This paper has proposed a new conceptual modeling approach which has implications for theory as well as practical applications in system development techniques and methods. Our approach leverages the established KAOS goal-modeling approach, using obstacle analysis to reason about how a user X  X  personal characteristics may inhibit achievement of the system X  X  goals. Furthermore, we introduce a Bayesian model and reasoning for scenario analysis of weak obstacles, predicting the probabili-ties that human agents would behave in a way that would enable them to achieve their personal goals. Although we did not implement the BN tool for the Ambient Assisted Living case, such tools are a mature techno logy and could easily be adapted to per-sonal and contextual requirements. Automated BN scenario analysis enables a range of  X  X hat if X  scenarios to be processed to identify potential causes of weak obstacles and plan mitigations [43]. BNs have been applied to a wide variety of domains as decision-support and modeling tools [44]; however, construction of the networks and configuration of the CPTs does require expertise and considerable resources from domain experts. 
In the AAL case study, the framework supports walkthroughs to stimulate obstacle analysis questions. The identification of obstacles to goal fulfilment helps pose trade-off questions about the domain assumptions that may underlie the requirements derived for a system. For instance, there is an economic cost in monitoring Mary X  X  actions, so requirements are closely related to assumptions about what the system does, and is assumed not to know. In self-adaptive context-aware systems we argue that the boundary is fluid and changes as the machine gathers more knowledge about the world. Furthermore, as Mary X  X  perspective in the AAL example demonstrates, we need to model human behavior since it may change the boundaries and domain as-sumptions as well. In this sense our approach is related to satisficing solutions to meet requirements according to assump tions and preference trade-offs. 
Further development and testing are necessary to improve the validity of our pro-posal, which will be fully implemented and tested on further case studies followed by application to projects in industry. The approach will have limitations in the resources and access to domain experts necessary to configure BNs as well as the goal models; however, once developed such models could be re-used, so our approach may have better payback in product lines and domains where personal adaptation is at a premium, such as education, healthcare and assistive technology.

