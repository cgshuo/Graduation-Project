 In this paper we investigate what sorts of information hu-mans request about geographical objects of the same type. For example, Edinburgh Castle and the Bodiam Castle are two objects of the same type  X  castle . The question is whether specific information is requested for the object type castle and how this information differs for objects of other types, e.g. church , museum or lake . We aim to answer this question using an online survey. In the survey we showed 184 participants 200 images pertaining to urban and rural ob-jects and asked them to write questions for which they would like to know the answers when seeing those objects. Our analysis of 7644 questions collected in the survey shows that humans have shared ideas of what to ask about geographi-cal objects. When the object types resemble each other (e.g. church, temple ) the requested information is similar for the objects of these types. Otherwise, the information is specific to an object type. Our results can guide tasks involving au-tomatic generation of templates for image descriptions, and their assessment, as well as image indexing and organization. IR [ Language technologies for IR ]: [NLP, IE, Summa-rization, QA]; IR [ Evaluation, Test collections, Crowd-sourcing for IR ]: [Mechanical Turk] NLP, Summarization, Image Description Generation Geographical object description
In every day life we see and categorize things in our built or natural environment. For instance, if we look at different churches, we see that each of them has different style, dif-ferent look, different size, some of them are newer than the others, etc., but still we are able to categorize all of them as churches. For categorization purposes visual attributes such as the style and the size of a church might be enough; how-ever, to report about each church separately we need more attributes whose values make each church distinguishable from others.

Knowing what sets of attributes people use to describe geographical objects has several applications. Text sum-marization employed to automatically generate descriptions of geographical objects can be improved by incorporating human preferences into the output summaries. Template based summarization methods, for example, have been used successfully for news event summarization [2, 3]. The same strategy can be applied to the task of generation of descrip-tions for geographical objects, e.g. for purposes of generat-ing descriptions for images of these objects. Templates can be derived from the set of attributes relevant to humans to bias the summarization system towards the text units con-taining the values for these attributes. Furthermore, the attributes could be used in a guided summarization task as organized by the Document Understanding Conferences (DUC) 1 and the Text Analysis Conference (TAC). 2 Addi-tionally, the attributes can be used to evaluate the output of an automatic summarization system by testing whether highly relevant attributes are covered in the output sum-mary. Furthermore, the attributes supply a guide for what to index for images pertaining to locations. If information highly relevant for humans is used for indexing, this could lead to better retrieval and organization of those images.
For such applications it is relevant to know whether there is a general set of attributes that people use to describe any geographical object. Or, given that humans categorize objects into types (e.g. church, museum, etc.), are the sets of attributes specific to single object types, or perhaps shared between types that are subtypes of a common higher level type (e.g. church and temple are both religious buildings)?
In this paper we aim to address these questions. Specif-ically, we ask: For what attributes related to geographic objects would people like to know the values when seeing such an object? And: Is this set of attributes specific to a particular object type (e.g. church) or shared between different object types?
We aim to answer these questions using an online survey conducted on Mechanical Turk. In the experiment we show the participants different images of objects from around the world. Our set of images contains only images of static fea-http://duc.nist.gov/ http://www.nist.gov/tac/ tures of the built or natural landscape, i.e. objects with persistent geo-coordinates, such as buildings and mountains, and not images of objects which move about in such land-scapes, e.g. people, cars, etc. We ask the participants to write questions for which they would like to know the an-swers when seeing each image. We collected 7644 questions from 184 participants. The results of our analysis reveal that people share ideas as to what to ask about geographi-cal objects in general. When the object types resemble each other, the requested information is similar. Otherwise, this information is specific to a specific type.

In this paper we first present the experimental setting of our survey and outline the preprocessing process of the data (Section 2). In Section 3 we present our analysis and report and discuss the results. We conclude the paper in Section 4.
In the experiment we showed the participants an image pertaining to a particular object or place. We also pre-sented the participants with the name of the place (e.g. Eiffel Tower ) and its object type (e.g. tower ). The par-ticipants were asked to take the role of a tourist and provide ten questions for which they would like to know the answers when they see the place shown in the image. We showed im-ages picturing places of 40 different object types randomly chosen from our entire set of 107 object types. From these 40 object types 25 are urban and 15 rural types (see Table 1). For each object type five different places were shown. For example, for the object type tower the images of Eiffel Tower, Flag Tower of Hanoi, BT Tower, Munttoren, Betti-sons Folly were shown. These places (towers) were manually selected from Wikipedia. Each image was shown to five dif-ferent participants. We ran the experiment for four weeks. In total we collected 7644 questions for 187 different places. The questions came from 184 different participants. The ex-pected number of questions was 10.000 (40 types  X  5 objects  X  5 participants  X  10 questions). However, there are some objects for which we only have questions from two or three workers. Most objects have 40 questions. The number of questions for the urban types is 4815 and for the rural ones 2829. We used Mechanical Turk for our experiment.
We manually analyzed all questions in order to assess quality. Approximately 2% of the questions were empty be-cause not all the workers wrote 10 questions for each object. Moreover, some questions are only related to the image itself rather than to the place shown in the image (e.g.  X  X hen the picture is taken? X ,  X  X ow many flowers you found in the im-age? X ,  X  X s there a bus in the picture? X  ). In addition to these, some questions present non-resolved references so it is im-possible to know what object they refer to (e.g.  X  X hat lan-guage do they speak? X  ). Finally, there are questions which bear no relation at all with the object in the image (e.g.  X  X ow is the manager? X  ). These questions do not address the task, which is to ask questions about the object shown in the image, not about the image itself or related information. Therefore, we categorized all these questions as noise which makes up 19% (1479 out of 7644) of the entire question set.
We categorized the remaining 81% of the questions (6169 out of 7644) by the attribute the worker was seeking the value for with his/her question. An attribute is an abstract grouping of similar questions. We regard two or more ques-tions as similar if their answers refer to the same information type. For instance, we regard the questions  X  X here is gar-wood glacier? and  X  X here exactly is edmonton? X  as similar because both aim for answers related to the information type location . We name the attribute according to the informa-tion type it refers to (e.g. location ). Table 2 shows examples attributes with questions.

In total we identified 146 attributes, however, 95 of them contain less than five questions, so we ignore these attributes in further analysis. We analyse the remaining set of 51 at-tributes (see Table 3), each of which has at least five ques-tions related to.
In Table 3 the 51 attributes are given. The left column of the table shows the very frequent addressed attributes ( top ten ). More than 65% of the questions can be categorized by these ten attributes. This means that people do share ideas as to what types of information are required about a place, and the set of top ten attributes captures the majority of these information types. However, although these attributes occur for many object types, their popularity is not the same for all the object types with which they are associated.
We define the popularity of an attribute for an object type as the number of questions categorized under this attribute for that particular object type. Attribute popularity indi-cates how important the type of information represented by the attribute is for the particular object type.

For instance, the attribute visiting is the most popular attribute (has the maximum number of 52 questions) in the object type museum (see Table 4). This indicates that it is most important for people to know how much the entry to the museum costs or when the museum opens. This informa-tion is more relevant than, e.g. knowing when the museum was built. However, if we look at the object type house , we can see that the same attribute visiting is not the most popular one. It occurs at position five with only 11 ques-tions. For this object type people seem to be interested most in knowing the design of the house and less in information related to visiting.

The remaining 35% of the questions are spread over the remaining 41 attributes as shown in the right column ( below top ten ) of Table 3. From this list we can observe that there are some specific attributes which are likely to be present only in a specific object type or in very few object types. For instance, as shown in Table 4 the attribute erruption-info is associated only with the object type volcano . This attribute contains questions related to the eruption of dif-ferent volcanos. From Table 4 we can see that this attribute is also the most popular for the volcano object type, while information related to visiting , location , etc., which is gen-erally most frequently asked for, comes after erruptioninfo . From this we can conclude that even though object types share the top ten attributes, the differences in attribute pop-ularity indicate that these are not equally important for all object types. Therefore, the question arises as to whether each object type has an associated specific set of attributes, or whether the attributes relevant to it are shared between several object types. This is our second research question.
To address this question we compare different object types and investigate the degree of similarity between them. We assume, if two object types are similar, then they will not only share a set of attributes, but the attributes within this set will also have similar popularity ranking.

We use Kendall X  X  Tau rank correlation coefficient as a met-ric which indicates similarity between object types, while considering the attribute popularity ranking in their attribute sets. Kendall X  X  Tau correlation coefficient is equal or close to 1 if two events are highly correlated in rankings and close to 0 if there exists little or no correlation between the ranks of the two events.

The attributes are ranked according to their popularity, i.e. the number of questions contained under each attribute. If attributes of two different object types have similar rank-ings, this is an indication that these attributes are of similar importance for both object types. Kendall X  X  Tau for these object types will return a high correlation for the pair, and we will refer to such object types as similar. A difference in attribute rankings between different object types indicates that these attribute sets are more specific to the one object type and not shared by the other(s). In this case Kendall X  X  Tau will return a low correlation, and we will refer to such object types as dissimilar.

In our analysis we report comparisons based on three dif-ferent sets of attributes: all , top ten and below top ten . All is the entire set of attributes shown in Table 3 (attributes from columns top ten and below top ten ). The top ten attributes include the top ten attributes which are shared between most of the object types and thus more likely to render similar-ity. The below top ten set contains all remaining attributes which are as we assume above rather object type specific.
If all attributes are taken, there is in general a correlation between object types in both urban and rural categories. On average the urban object types correlate with 0.55 (median 0.57 ) and the rural types with 0.53 (median 0.53 ). The mean and median correlation coefficient lie close to each other, which indicates that the distribution of highly corre-lating object types is similar to that of object types with low correlation. To analyse this result further, we aim to identify the object types whose correlation coefficient is higher than the mean correlation and those which are correlated with a coefficient lower than the mean. We also aim to understand whether there are object types which are only highly corre-lated when top ten most frequent attributes are considered and whose correlation potentially drops for the remaining set of attributes.

Table 5 shows three groups of object type pairs in rural and urban areas. In the first column the object type pairs whose correlation coefficient is higher than the mean for all attributes are shown. The second column shows the object type pairs whose correlation is higher than the mean in the top ten attributes, but drops below the mean for the below top ten attributes. Finally, in the third column the pairs which are correlated with the coefficient lower than the mean for all attributes are presented.

From Table 5 we can see that high correlation in attributes is always present when the object types have e.g., the same look, design or the same purpose. For the urban areas we have object types such as church, basilica, abbey, cathedral and temple which correlate with a coefficient higher than the mean of 0.55 when all attributes are considered. A similar picture can be drawn for other urban object types such as house-residence , building-residence or museum-operahouse . In rural areas, object types related to mountainous areas (e.g. glacier, mountain, peak, volcano, ski resort etc.) are correlated above the mean of 0.53 . The same is valid for water bodies like canal, lake, river , etc.

All these object types clearly share features like look, de-sign, purpose, etc. The correlation coefficient is always low for object types which do not share these aspects such as the ones shown in the third column of Table 5. This indicates that aspects used for categorizing objects into object types also play a role in deciding which object types are similar for purposes of describing them.

However, the second column of the tables also highlights the importance of shared ideas of what information is rele-vant for describing geographic objects for object type simi-larity (Section 3.1). The object types shown in the second column of the tables are correlated above the mean for top ten attributes and their correlation drops below the mean when below top ten attributes are used.
Our analyses have shown that people taking the role of a tourist do share ideas as to what information is relevant for describing geographic objects, and we identified a set of in-formation types that reflects these ideas. However, although we could say that there are clearly several information types which people like to know when seeing any geographic ob-ject, it was also clear that not every type of information is equally relevant for each object type. These findings prompted the question, whether each object type has a spe-cific set of information associated with it, or whether object types can be grouped according to how they are described by people.

We found that some object types are similar and not only share the information types associated with them, but also the importance ranking of these types. Such similar objects were mostly objects of similar purpose, look or design (e.g. churches and temples, rivers and lakes, etc.). This indicates that sets of features which people use to categorize objects also plays a role in deciding which information should be used to describe these objects. However, some object types which do not share these features are still similar in terms of which information is required to describe them. In these cases people will refer to the shared set of frequently re-quested attributes we identified.
In this paper we investigated which information types (at-tributes) humans associate with geographic objects from ur-ban and rural landscapes. We identified a set of attributes which were relevant for any geographic object type, but also found that an appreciable proportion of attributes is object type specific. Even in the set of shared information types, not all information types were equally important for each ob-ject type. Based on the importance ranking of information types for each object type, we were able to identify similar object types.

In our earlier work we extracted the information types which humans associate with geographic objects from ex-isting text resources describing locations around the world and used them to automatically generate image descriptions [1]. One of our future works will be to compare the informa-tion types we identified in this paper with the ones extracted from these existing text resources. If these correlate with the set of attributes obtained through our user survey, we could regard the text descriptions containing these attributes as conceptual models of geographic objects of the same type. [1] A. Aker and R. Gaizauskas. Generating image [2] K. McKeown and D. Radev. Generating summaries of [3] D. Radev and K. McKeown. Generating natural
