 1. Introduction available ontologies continues increasing. For example, an ontology search engine, S more than 10,000 ontologies on the Web so far.
 processing.
 matching. ment Evaluation Initiative 2007 (OAEI) [15] , 17 ontology matching tools joined the campaign, but only four tools (including the one described in this paper) accomplished all the three matching tasks with large ontologies ( and Library ). But, the other three tools, namely DSS IM [43] ,R ogy matching problem. DSS IM manually partitions large ontologies into several smaller pieces, while R simple string comparison techniques as alternatives.
 ment, large book classification categories, such as Brinkman dant books. For another example, in the medicine and biology domains, large life-science ontologies, e.g., demands on matching large ontologies bring a new challenge to the state of the art ontology matching technology. ( Phase 2 ) to be further matched by two powerful matchers, V-D in which 3258 (nearly 82%) are expressed in RDFS or OWL.
 cution time with pretty good quality. For example, two large ontologies are provided in the each one contains about 3000 entities. DSS IM ,R I MOM and P tively, while our approach merely takes 12 min. More importantly, as compared to DSS achieves better (or at least comparable) precision and recall.
 ontologies 2007 and compared our approach with other participants.
 and real world data sets. Finally, Section 8 concludes the paper with future work. 2. Problem formulation ontologies.
 thousand entities as a large ontology.

Ontology matching (also called mapping or aligning) aims at discovering alignments (also named mappings, correspon-spired by the definitions in [54] , we define ontology matching as follows. Definition 2. (ontology matching) Let O ; O 0 be two ontologies. Matching O with O 0 finds a set of alignments
A  X f a 1 ; a 2 ; ... ; a n g . Each a i ( i  X  1 ; 2 ; ... ; n ) is a 5-tuple: h id d ; and v is a similarity between d and d 0 in the  X  0 ; 1 range.
 lence relationship between entities.
 RDF graph can be decomposed into a unique set of RDF Sentences.
 structure. We define it as an RDF Sentence .
 connected RDF triples. 3 conditions: (1) s O ; (2) 8 t i ; t j 2 s , i 6  X  j , t i ; t j are b-connected; (3) 8 t i 2 s ; t j 6 2 s , t i ; t j are not b-connected. subject of its main RDF triple.
 Now, we give the definition of blocks by using RDF Sentences as basic units instead of RDF triples. to the entire set of the entities.
 clusters f g 1 ; g 2 ; ... ; g n g , which satisfies: (1) 8 g the block corresponding to a cluster g i ( i  X  1 ; 2 ; ... ; n ). b ( k  X  1 ; 2 ; ... ; m ) satisfies subject  X  s k  X 2 g i . 8 b relationship of two blocks within a block mapping.

B with B 0 finds a set of block mappings BM  X f bm 1 ; bm 2 id is a unique identifier; b ; b 0 are two blocks in B ; B 0 not depicted in the figure). The ontology O in the left part includes six classes graph , Person and Author ; and one property hasAuthor . We can generate three blocks b from three clusters g 1  X f Reference ; Book ; Inproceedings ; Monograph g ; g
Note that the triples among b 1 , b 2 and b 3 are disjoint, not the entities. For example, but the RDF triple t 8 only belongs to b 3 . The ontology O 0 in the right part has five entities:
Author and hasAuthor . We may also generate three blocks b
Reference ; Entry ;  X  ; 1 : 0 i . 3. Related work 3.1. Large ontology matching divide-and-conquer strategy.
 ontologies and makes extensive use of medical background knowledge. For the if there is proper background knowledge, they can find some complex and interesting alignments.
In OAEI 2007, three generic ontology matching tools, DSS IM ogies to be matched to a query fragment in terms of WordNet. seven different ontology matching strategies, each one aims at a specific ontological information. P manually divides large ontologies into small blocks, while R 3.2. Ontology partitioning titioning approach.
 provide any mechanism to preserve the triples that contain blank nodes. 3.3. Block matching decomposition, when the number of entities in any block exceeds a pre-defined value, a compaction function would be problem is that it ignores the different features of classes and properties. So, the partitioning quality of C some matched fragments may be skipped.

In schema matching (see [14,48] ), IM AP [10] semi-automatically finds both 1:1 and very complex alignments (e.g., room price  X  room rate  X  1  X  tax rate  X  ). It embeds two kinds of domain knowledge (overlapped data and external the 1:1 alignments between two schemas by using WordNet and generates block mappings from the 1:1 alignments via a clustering algorithm. This is similar to the framework of B for finding the 1:1 alignments. 4. Partitioning ontologies
Finally, we will describe the construction of blocks by assigning RDF Sentences to the clusters ( Phase 1.3 ). 4.1. Computing structural proximities principle, which categorizes and specifies concepts (e.g., in acterize their structural proximities.

ClassOf relationships. Let c i ; c j be two classes in a given ontology O , the structural proximity between c where c ij is the common superclass of c i and c j , and depth  X  c there exists any cycle, we break up the cycle by arbitrarily removing an edge) rather than trees, so the depth of c ique. In this paper, we choose the maximum one as the depth of c and c j .
 Object , Human , Animal , Woman and Man . Woman and Man are two subclasses of subclasses of Object . Hence, Woman and Man are closer than is 1, then prox  X  Man ; Woman  X  X  2 2 =  X  3  X  3  X  &gt; 2 1 =  X  2  X  2  X  X  prox  X  of the rdfs:subClassOf relationships is considerably dominant as compared to others. For instance, rdfs:subClassOf . Moreover, for thesauri such as Brinkman p is: where p ij is the common super-property of p i and p j , depth  X  p dom  X  p k  X  gets the domain(s) of p k .
 i.e., only computing the structural proximities of entities satisfying j depth  X  d approximation is often used in structure-based partitioning approaches (e.g., in [42] ). ture proximities between the entities are depicted in the right part of the figure. 4.2. Partitioning
The objective of a partitioning algorithm is to partition a set of vertices V into a set of disjoint clusters g by certain measure, the cohesiveness among the vertices in a cluster g union of all the clusters equals to the complete set of the entities.
 of binary values.
 tance of two clusters by considering the aggregate inter-connectivity of them. Let g tural proximity matrix between entities, the cut  X  X  between g when g i and g j are the same, it computes the cohesiveness of the cluster, i.e., cohesive  X  g ferent, it computes the coupling between them, i.e., coupling  X  g similarity [47] ). In our experiment, we also evaluate two popular variations j g form function to calculate both cohesiveness and coupling is also proposed in [51] , called silhouette coefficient. for merging. During an iteration, it selects the cluster g ter g t that has the maximum coupling with g s (Line 10). After merging g the cohesiveness of g p as well as its coupling with other ones (Lines 17 X 20). If g arated). In practice, is determined based on the memory requirements of the following matchers such as G necessary to re-sum the structural proximities between the entities in the new cluster. For instance, let g merged from g s and g t , the sum of the structural proximities in g
Recall Formula (3) , the sum of the structural proximities in g (or g t )to  X j g s jj g s j X  (or  X j g t jj g t j X  ). Also, the sum of the structural proximities between g algorithm shown in Fig. 4 , we use u to represent this optimization (Line 17 and Line 19). we do not sort clusters by the cohesiveness (or coupling), thus selecting g to running environment. However, partitional clustering approaches such as K-rithms is out of the scope of this paper.
 trated in Fig. 4 ( Phase 1.2 ), the seven entities in Fig. 5 are partitioned into three different clusters g grouped into g 1 , while classes and properties are separated into disjoint clusters. 4.3. Constructing blocks 1 ).
 stance, let us see the cluster g 1  X f Reference ; Book ; Inproceedings ; Monograph g in Fig. 2 , three triples t 4 : h Inproceedings ; rdfs : subClassOf ; Reference i . t 5 : h Book ; rdfs : subClassOf ; Reference i . t 6 : h Monograph ; rdfs : subClassOf ; Book i . erence at least has one Author . In fact, this restriction is useful for many ontology matching approaches [16] . of blocks is much less than the number of entities.
 (encircled by dashed lines). s 1 is composed of three RDF triples, and its subject is _ :genid , the RDF triple h : genid ; owl : minCardinality ; also illustrates the process of constructing a block from a cluster ( Phase 1.3 ): b the left part of the figure), since the subjects of s 1 ; s tances between RDF Sentences is even harder. 5. Matching blocks then the blocks from the two ontologies are matched based on the distribution of the anchors ( Phase 2.2 ). 5.1. Finding anchors chors between large ontologies. (1) Use I-S UB [55] to automatically generate a set of candidate anchors. (2) Manually remove incorrect ones from the candidate anchors (optional). (3) Manually add some omissions to the candidate anchors (optional).
 during anchor generation.
 follows: improvement of the result by using a correction coefficient introduced in [62] . If the similarity between two descriptions is greater than a pre-defined value l ( l 2 X  0 ; 1  X  ), then I-S two entities containing those two descriptions as a candidate anchor. In [55] , it suggests l P 0 : 75. provides evidence to support the use of I-S UB . In addition, as compared to other matching techniques [16] , I-S cient and scalable. 5.2. Generating block mappings is that the more anchors can be found between two blocks, the more similar the two blocks are.
Let B ; B 0 be two sets of blocks from two ontologies O ; O returns the number of the anchors in Q between two blocks b and b as follows: see that, in our experiment, the number of block mappings is much less than  X j B jj B alignment discovery would be largely decreased.
 Let us see the example in Fig. 2 . Some anchors like h 3 ; be easily discovered, because the entities in each anchor have the same local names. Next, some block mappings like h 1 ; b 1 ; b 0 1 ; 1 : 0 i can be detected. 6. Discovering alignments other methods [16,19] can also be freely chosen as alternatives. Due to the technical details of V-D published in [46,27] , in this section we only generally summarize their distinguishing features. 6.1. Linguistic matching positions in RDF triples. 6.2. Structural matching lation of similarities from the involved entities as the same role in these two triples being compared. G of G
MO improves with the accuracy of external alignments increases. 6.3. Similarity combination strategy structural comparability, which makes the combination robust in a variety of ontology matching scenarios. unnecessary to execute G MO any more. Then, we determine the threshold of V-D order to select the strong (i.e., more reliable) alignments.
 is measured by the cosine similarity, which compares which built-in properties are used between two ontologies, and how often. It is used to determine the threshold of G MO to obtain the weak (i.e., less reliable) alignments. comparability and the structural comparability are both low, our approach would combine less alignments from V-D G
MO to the final result but make the alignments from V-D OC are assumed to be more reliable than the ones from G MO .
 include d would be deleted.) The process terminates until no candidate is left. Please consider the example in Fig. 2 again. Although by using I-S contains the entities having the same names. The alignment between
Inproceedings and ConferencePaper cannot be directly found, because they do not have similar names. However, a hu-man may still recognize that they should be alignments because of the similar contexts of the ontologies. V-D neighboring information, hence, regarding Reference for instance, it imports the names of ceedings . By using the neighboring information, V-D OC detects alignment between Inproceedings and ConferencePaper can be discovered.

Supposing that V-D OC can also find the three alignments containing the entities with the same names, the number of alignments found by V-D OC is 4, and the minimum number of the entities in O ; O inality and owl:onProperty . As an example, the number of rdfs:subClassOf in O ; O other built-in properties is 1, respectively. The cosine similarity between those built-in properties is 19 = where 19  X  5 3  X  1  X  1  X  1  X  1 ; 29  X  5 2  X  1  X  1  X  1  X  1 ; 13  X  3 bined as the final result for output. 7. Evaluation We have implemented the proposed approach in Java, called P synthetic and real world data sets. The test cases and experimental results are all available at our web site. [15] . 7.1. Synthetic test
We will measure the performance of P BM on partitioning ontologies as well as on finding block mappings. 7.1.1. Data sets
In our evaluation, we choose two pairs of ontologies: Russia12 ontologies are given below.
 about Russia. Russia1 contains 151 classes and 76 properties.
 erence alignment file contains 85 alignments.
 klenburg X  X orpommern (a federal state in the northeast of Germany).

TourismB contains 474 classes and 100 properties. The reference alignment file contains 226 alignments. 7.1.2. Experimental methodology and evaluation metrics alignments further. In order to measure these two kinds of quality, three experiments are designed for evaluation. Russia1 , 22 ones for Russia2 , 18 ones for TourismA and 23 ones for widely adopted in data clustering [23] .

We use a well-known metric entropy to compare the automatically generated blocks with the manually established ref-( j R j X  m ). b i denotes a block in B , while r j denotes a block in R . j b ogously. b i T r j calculates the common entities in both b follows: as follows: tions about the denominator. So, we also compare two other popular choices, j g function.

In the second experiment, we evaluate the mapping quality of computed block mappings by measuring the correctness the upper bound if only matching the blocks in block mappings. Let O ; O block mappings ( j BM j X  l ). bm k denotes a block mapping in BM. bm
Let A be a set of alignments in a reference alignment file ( j A j X  n ). a from O ; O 0 , respectively. The correctness of BM is defined as follows: reference alignments as anchors to determine the best g , and then test various l to find whether P best l and g here and apply them to the real world cases further.
 We choose two other block matching approaches for the above two tests. The first one is B pletely contrary process as compared to P BM . The second one is based on C see Section 3 for more details.
 In the third experiment, we make a comparison between the alignments from P F ALCON -AO without partitioning. Because the sizes of the ontologies in I-S This metric serves as the truly cost of partitioning and block matching in F computed alignments and A 0 be a set of reference alignments, the precision and recall of A referring to A follows: 7.1.3. Experimental results Firstly, the experimental results of the partitioning quality ( entropy )ofP cate that P BM is dominant in all the four test cases (i.e., the blocks constructed by P standing), and B MO performs better than C OMA .
 Secondly, we evaluate the mapping quality ( correctness )ofP ments as anchors, with the variation of g , the correctness of P because the correctness is fairly large, while the number of block mappings is fairly small. P BM is robust with slight changes on g (e.g., g  X  0 : 05 ; 0 : 1).
 By adopting l  X  0 : 85, g  X  0 : 075, we compare the correctness of P in Fig. 13 . It shows that the mapping quality of the two approaches is good, and B the two parameters are not the best ones (e.g., l  X  0 : 8 ; 0 : 9 and g  X  0 : 05 ; 0 : 1), the correctness of P Fig. 11 ).

More specifically, P BM exploits 39 block mappings for Russia12 block mappings for Russia12 and 26 ones for TourismAB . Therefore, the potential computational cost of P number of two sets of blocks (22 22  X  484 for Russia12 and 18 23  X  414 for block mappings, 15% alignments for Russia12 and 9% ones for If we go further to observe the run time spent by P BM and B would immediately find that P BM is more efficient than B and 8 seconds to complete the Russia12 and TourismAB cases respectively (including the parsing time), while B ontologies firstly. Therefore, B MO is not feasible for large ontologies. Thirdly, we directly apply F ALCON -AO without partitioning to the whole ontologies in ments would be lost because of partitioning. For example, in in recall , which means that 6% alignments are not found by P G also involves some wrong alignments, thus the precision of P
However, the experimental results demonstrate that P BM does not lose too much precision or recall . Based on the experimental results above, we conclude that P good mapping quality. 7.2. Real world test We will report the results of P BM on discovering alignments in two large real world ontology matching tasks: book integration [61] and query rewriting for art thesauri [26] . 7.2.1. Data sets In OAEI 2007, the organizers provided three large ontology matching tracks: present any results on this test, we ignore it here. Short descriptions of the Anatomy . The ontologies of the Anatomy track are the NCI Thesaurus describing the human anatomy (denoted by published by the National Cancer Institute (NCI), and the Adult Mouse Anatomical Dictionary (denoted by is developed as part of the Mouse Gene Expression Database project.
 2743 entities. The two ontologies are represented as complex graphs.
 It includes two ontologies: AGROVOC , which is developed by Agriculture Organization (FAO), and by United Nations Food Organization. AGROVOC contains 28,439 entities, while ontologies are represented as simple tree structures. 7.2.2. Experimental methodology and evaluation metrics We compare the alignments generated by P BM to the ones found by the other three ontology matching tools, DSS R MOM [58] and P RIOR+ [39] , which also participated in OAEI 2007. Besides, C which is exactly the same as the one in OAEI 2007, and A OAS life-science ontologies and achieved the best performance in the and A OAS with P BM . For more details, please see Section 3 .
 In OAEI 2007, the organizers also provided several matching tasks with small ontologies, such as Directory , and many ontology matching tools participated in these tracks. Although our tool, F matching tools, there exist several tools that performed slightly better than ours in these tracks. For instance, O P [15] .

The performance of P BM , DSS IM ,R I MOM, P RIOR+ ,C OMA tion time is evaluated.
 less than 500. This value is set based on the memory requirements of V-D are gained from the synthetic test. 7.2.3. Experimental results
The comparison results of the precision and recall of P BM effectiveness of using domain knowledge in ontology matching. In fact, A 2007. P BM outperforms the other four generic tools, DSS IM also proves that, even without using domain knowledge, P BM coverage.
 The execution time of P BM , DSS IM ,R I MOM, P RIOR+ and A cution time yet.) It shows that P BM is the most efficient one. Please note that, in the that, because of using domain knowledge, A OAS takes more time to achieve better precision and recall.
Based upon the experimental results, we conclude that P BM of run time.
 It is also interesting to analyze the portions of the alignments found by each matcher (i.e., I-S guaranteed. Besides, we could also observe that more alignments come from I-S portion of the alignments only generated by I-S UB indicates the number of alignments P missing alignments due to block matching. 8. Conclusion In summary, the main contributions of this paper are listed as follows: problem, but it also achieves good precision and recall with significant reduction of execution time. technology.
 block matching.

We have integrated two powerful matchers, V-D OC and G MO matchers discover alignments from different perspectives, and our combination strategy is flexible. our approach can achieve good precision and recall in short time.

In the future work, we look forward to implementing a public Web interface to make the technology widely accessible integration between different data models.
 Acknowledgements 2003CB317004. We appreciate Christian Meilicke and Willem van Hage for providing the respectively. We also thank Miklos Nagy, Jie Tang and Ming Mao for useful discussion on DSS their valuable comments.

References
