 Recently, as an attractive alternative to probabili stic parsing, deterministic parsing (Yamada and Matsumot o, 2003; Nivre and Scholz, 2004) has drawn great atten tion with its high efficiency, simplicity and good accur acy comparable to the state-of-the-art generative proba bilis-tic models. The basic idea of deterministic parsing is using a greedy parsing algorithm that approximates a globally optimal solution by making a sequence of l o-cally optimal choices (Hall et al., 2006). This gre edy idea guarantees the simplicity and efficiency, but at the same time it also suffers from the error propagatio n from the previous parsing choices to the left decis ions. For example, given a Chinese sentence, which means Paternity test is a test that gets personal identit y through DNA analysis, and it brings proof for findi ng lost children , the correct dependency tree is shown by solid line (see Figure 1). But, if word  X  X  X  (through) is incorrectly parsed as depending on word  X  (is) (shown by dotted line), this error will result in the inco rrect parse of word  X  X  X  (a test) as depending on word  X  X  X  (brings) (shown by dotted line). 
This problem exists not only in Chinese, but also i n other languages. Some efforts have been done to sol ve this problem. Cheng et al. (2005) used a root finde r to divide one sentence into two parts by the root word and parsed them separately. But the two-part division i s not enough when a sentence is composed of several coord i-nating sub-sentences. Chang et al. (2006) applied a pipeline framework in their dependency parser to ma ke the local predictions more robust. While it did not show great help for stopping the error propagation betwe en different parsing stages. 
This paper focuses on resolving this issue for Chi-nese. After analyzing the dependency structure of s en-tences in Penn Chinese Treebank 5.1 (Xue et al., 20 02), we found an interesting phenomenon: if we define a main-root as the head of a sentence , and define a sub-sentence as a sequence of words separated by punctua-tions, and the head 1 of these words is the child of main-root or main-root itself , then the punctuations that de-pend on main-root can be a separator of sub-sentenc es.
For example, in the example sentence there are thre e punctuations marked as PU_A, PU_B and PU_C, in which PU_B and PU_C depends on main-root but PU_A depends on word  X  X  X  (gets). According to our observation, PU_B and PU_C can be used for segment-ing this sentence into two sub-sentences A and B (c ir-cled by dotted line in Figure 2), where the sub-roo t of A is main-root and the sub-root of B depends on main-root. 
This phenomenon gives us a useful clue: if we divide a sentence by the punctuations whose head is main-r oot, then the divided sub-sentences are basically indepe nd-ent of each other, which means we can parse them se pa-rately . The shortening of sentence length and the recog-nition of sentence structure guarantee the robustne ss of deterministic parsing. The independent parsing of e ach sub-sentence also prevents the error-propagation. I n addition, because the sub-root depends on main-root or is main-root itself, it is easy to combine the depe ndency structure of each sub-sentence to create the final de-pendency tree. 
Based on above analyses, this paper proposes a thre e-step deterministic dependency parser for Chinese, w hich works as: 
Step1(Sentence Segmentation) : Segmenting a sen-tence into sub-sentences by punctuations (sub-sente nces do not contain the punctuations for segmentation); 
Step2(Sub-sentence Parsing) : Parsing each sub-sentence deterministically; 
Step3(Parsing Combination) : Finding main-root among all the sub-roots, then combining the depende ncy structure of sub-sentences by making main-root as t he head of both the left sub-roots and the punctuation s for sentence segmentation . As mentioned in section 1, the punctuations dependi ng on main-root can be used to segment a sentence into several sub-sentences, whose sub-root depends on ma in-root or is main-root. But by analysis, we found onl y several punctuations were used as separator commonl y. To ensure the accuracy of sentence segmentation, we first define the punctuations which are possible fo r seg-mentation as valid punctuation , which includes comma, period, colon, semicolon, question mark, exclamator y mark and ellipsis . Then the task in step 1 is to find punctuations which are able to segment a sentence f rom all the valid punctuations in a sentence, and use t hem to divide the sentence into two or more sub-sentences.
We define a classifier (called as sentence seg-menter ) to classify the valid punctuations in a sentence to be good or bad for sentence segmentation. SVM (S e-bastiani, 2002) is selected as classification model for its robustness to over-fitting and high performance. 
Table 1 shows the binary features defined for sen-tence segmentation. We use a lexicon consisting of all the words in Penn Chinese Treebank 5.1 to lexicaliz e word features. For example, if word  X  (for) is the 27150 th word in the lexicon, then feature Word 1 PU_B (see Figure 2) is  X 27150:1 X . The pos-tag featu res are got in the same way by a pos-tag list containin g 33 pos-tags, which follow the definition in Penn Chine se Treebank. Such method is also used to get word and pos-tag features in other modules. The parsing algorithm in step 2 is a shift-reduce p arser based on (Yamada and Matsumoto, 2003). We call it a s sub-sentence parser . 
Two stacks P and U are defined, where stack P keeps the words under consideration and stack U remains all the unparsed words. All the dependency relations cr e-ated by the parser are stored in queue A . 
At start, stack P and queue A are empty and stack U contains all the words. Then word on the top of sta ck U is pushed into stack P , and a trained classifier finds two stacks. After that, according to different acti ons, dependency relations are created and pushed into qu eue A , and the elements in the two stacks move at the sa me time. Parser stops when stack U is empty and the de-pendency tree can be drawn according to the relatio ns stored in queue A . Four actions are defined for word pair &lt; p , u &gt;: 
LEFT : if word p modifies word u , then push p u into A and push u into P . 
RIGHT : if word u modifies word p , then push u p into A and pop p . 
REDUCE : if there is no word u X  ( u X   X  U and u X  which modifies p , and word next to p in stack P is p  X  X  head, then pop p . 
SHIFT : if there is no dependency relation between p and u , and word next to p in stack P is not p  X  X  head, then push u into stack P . 
We construct a classifier for each action separatel y, and classify each word pair by all the classifiers. Then the action with the highest classification score is se-lected. SVM is used as the classifier, and One vs. All strategy (Berger, 1999) is applied for its good eff iciency to extend binary classifier to multi-class classifi er. Features are crucial to this step. First, we define some features based on local context (see F local in Table 2), which are often used in other deterministic parsers (Yamada and Matsumoto, 2003; Nivre et al., 2006). Then, to get top-down information, we add some glob al features (see F global in Table 2). All the features are bi-nary features, except that Distance is normalized be-tween 0-1 by the length of sub-sentence. 
Before parsing, we use a root finder (i.e. the sub-sentence root finder introduced in Section 4) to ge t Root n feature, and develop a baseNP chunker to get BaseNP n feature. In the baseNP chunker, IOB represen-tation is applied for each word, where B means the word is the beginning of a baseNP, I means the word is inside of a baseNP, and O means the word is outside of a baseNP. Tagging is performed by SVM with One vs. All strategy. Features used in baseNP chunking are curr ent word, surrounding words and their corresponding pos -tags. Window size is 5. A root finder is developed to find main-root for pa rsing combination. We call it as sentence root finder . We also retrain the same module to find the sub-root i n step 2, and call it as sub-sentence root finder . 
We define the root finding problem as a classificat ion problem. A classifier, where we still select SVM, i s trained to classify each word to be root or not. Th en the word with the highest classification score is chose n as root. All the binary features for root finding are listed in Table 3. Here the baseNP chunker introduced in sect ion 3.2 is used to get the BaseNP n feature . We use Penn Chinese Treebank 5.1 as data set. To transfer the phrase structure into dependency struc ture, head rules are defined based on Xia X  X  head percolat ion table (Xia and Palmer, 2001). 16,984 sentences and 1,292 sentences are used for training and testing. The same training data is also used to train the senten ce segmenter, the baseNP chunker, the sub-sentence roo t finder, and the sentence root finder. During both t rain-ing and testing, the gold-standard word segmentatio n and pos-tag are applied. 
TinySVM is selected as a SVM toolkit. We use a polynomial kernel and set the degree as 2 in all th e ex-periments. First, we evaluated the dependency accuracy and roo t accuracy of both three-step parsing and one-step pa rsing. Three-step parsing is the proposed parser and one-s tep parsing means parsing a sentence in sequence (i.e. only using step 2). Local and global features are used i n both of them. 
Results (see Table 4) showed that because of the shortening of sentence length and the prevention of er-ror propagation three-step parsing got 2.14% increa se on dependency accuracy compared with one-step pars-ing. Based on McNemar X  X  test (Gillick and Cox, 1989 ), this improvement was considered extremely statistic ally significant (p&lt;0.0001). In addition, the proposed parser got 1.01% increase on root accuracy. 
Then we tested the average parsing time for each se n-tence to verify the efficiency of proposed parser. The average sentence length is 21.68 words. Results (se e Table 4) showed that compared with one-step parsing , the proposed parser only used 2.14 more seconds ave r-agely when parsing one sentence, which did not affe ct efficiency greatly. 
To verify the effectiveness of proposed parser on complex sentences, which contain two or more sub-sentences according to our definition, we selected 665 such sentences from testing data set and did evalua tion again. Results (see Table 5) proved that our parser outperformed one-step parsing successfully. At last, we compare the proposed parser with Nivre X  s parser (Hall et al., 2006). We use the same head ru les for dependency transformation as what were used in Nivre X  X  work. We also used the same training (secti on 1-9) and testing (section 0) data and retrained all the modules. Results showed that the proposed parser achieved 84.50% dependency accuracy, which was 0.20% higher than Nivre X  X  parser (84.30%). In the proposed parser, we used five modules: sente nce segmenter (step1); sub-sentence root finder (step2) ; baseNP chunker (step2&amp;3); sub-sentence parser (step 2); and sentence root finder (step3). 
The robustness of the modules will affect parsing a c-curacy. Thus we evaluated each module separately. R e-sults (see Table 6) showed that all the modules got rea-sonable accuracy except for the sentence root finde r. Considering about this, in step 3 we found main-roo t only from the sub-roots created by step 2. Because the sub-sentence parser used in step 2 had good accurac y, it could provide relatively correct candidates for mai n-root finding. Therefore it helped decrease the influence of the poor sentence root finding to the proposed pars er. 
Then we evaluated the proposed parser assuming us-ing gold-standard modules (except for sub-sentence parser) to check the contribution of each module to parsing. Results (see Table 7) showed that (1) the accu-racy of current sentence segmenter was acceptable b e-cause only small increase on dependency accuracy an d root accuracy was got by using gold-standard senten ce segmentation; (2) the correct recognition of baseNP could help improve dependency accuracy but gave a little contribution to root accuracy; (3) the accur acy of both sub-sentence root finder and sentence root fin der was most crucial to parsing. Therefore improving th e two root finders is an important task in our future work. We propose a three-step deterministic dependency parser for parsing Chinese. It aims to solve the er ror propagation problem by dividing a sentence into ind e-pendent parts and parsing them separately. Results based on Penn Chinese Treebank 5.1 showed that com-pared with the deterministic parser which parsed a sen-tence in sequence, the proposed parser achieved ex-tremely significant increase on dependency accuracy . Currently, the proposed parser is designed only for Chinese. But we believe it can be easily adapted to other languages because no language-limited information i s used. We will try this work in the future. In addit ion, improving sub-sentence root finder and sentence roo t finder will also be considered in the future. 
