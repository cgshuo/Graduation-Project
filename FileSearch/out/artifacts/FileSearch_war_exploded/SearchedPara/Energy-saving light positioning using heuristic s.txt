 1. Aims and scope
Inverse problems in lighting consist in deciding the set of lighting settings (number of lights, emission power, light position, light shape, etc.) that allows to obtain the desired lighting in a given environment. Such problems have application to interior design, urban modeling, etc. In many cases, the importance of indirect illumination (light interreflections between objects) in such problems makes it necessary to use a global illumination model which considers both direct and indirect illumination, in order not to miss realism.

This work focuses on the problem of light positioning in real environments. Given a set of lighting requirements introduced by the user, the problem consists in finding the lighting settings (position and power for the light sources, basically) that fulfills the requirements while taking into account the saving of energy. Since finding the optimal solution can be extremely costly even for problems of a moderate size, the goal is to obtain a good enough solution (close to the optimum) at a reasonable cost. It must be noticed that a reduction of a few Watts in the total emitted power can be valuable for long-term energy saving, so it is worth to devote computational efforts even to such a small reduction.

The resulting combinatorial optimization problem involves exploring a generally huge search space in which each state corresponds to a given subset of positions from a wide set of authorized light locations. In order to avoid extremely costly brute-force algorithms, which would scan all the possible states in the search space, the problem is tackled via several heuristic-search-based approaches.

This paper presents a novel formulation of the problem, in which lighting requirements take the form of a set of constraints on the maximal and/or minimal irradiance allowed to each surface in the scene. Heuristic search is performed only over the set of lights and positions, and once a particular set of lights and positions has been selected, linear programming is used to compute the optimal emission power for each light in the set, that is, the values producing an illumination of the scene which respects all the constraints while minimizing the total irradiated power. In order to perform the big amount of lighting simulations required by the search process, a radiosity shooting random walk technique is used. Radiosity random walk techniques are appro-priate to simulate the lighting including direct illumination and diffuse interreflections. Since the lighting has to be computed for many different light positions, reuse of random paths allows to drastically reduce the cost of computing the radiosity solutions corresponding to each of the positions.

The article extends the work presented in Castro et al. (2009) by defining the problem more accurately, elaborating on the heuristics applied on hill climbing, and applying other heuristic algorithms such as genetic algorithms, discrete particle swarm optimization, and hybrid algorithms, which have noticeably improved the performance of the searches. The article is struc-tured as follows. Section 2 introduces previous work in reuse of shooting paths and light positioning using heuristic search. The optimization problem is defined in Section 3 . Section 4 describes the simple hill climbing algorithm, while Section 5 introduces the use of genetic algorithms, Section 6 deals with the use of jumping particle swarm optimization, and Section 7 describes hybrid algorithms that combine local and global approaches. Section 8 explains how a priori knowledge could be incorporated to our framework. Section 9 describes the test framework involved in our experiments. Section 10 refers to the experiments devoted to the parameter study. Section 11 describes the results, involving the comparison between the methods. Finally, Section 12 pro-vides the conclusions of our work, together with several possible directions for future research. There is an appendix which, for the sake of clarity, presents a list of all the abbreviations, variables, and constants used along this article. 2. Previous work 2.1. Reuse of paths for several light-source positions in radiosity technique that simulates the multiple reflections of light in a scene. Radiosity algorithms assume that the exiting radiance of a point is direction independent, and given a discretization of the scene in patches (small polygons), compute their irradiance . The irradiance of a patch is defined as its incoming light power divided by its area. Monte Carlo shooting random walk ( Bekaert, 1999 ) can be used to estimate the irradiances: this algorithm uses shooting paths generated from the light sources, carrying each of the paths an equal amount of light power which is distributed to the patches visited by the path.
 solution of linear equation systems ( Halton, 1994 ), the reuse of shooting paths in radiosity was introduced for moving lights in
Sbert et al. (2004) : shooting paths generated in a light position could be used for the rest of positions, in a sort of each-for-all strategy. Let F be the emission power, and let N s be the number of shooting paths generated at each position. The multisample esti-mator ( Veach and Guibas, 1995; Veach, 1997 ) allows to combine samples from different probability density functions (pdfs). Thus, instead of distributing F = N s power from position j by means of just one path, q paths can be effectively combined, starting at points ( Cohen and Wallace, 1993 ) between points x and y ).
 the irradiances for each patch due to a power unit emitted at several locations, allowing to economically obtain and store the irradiances matrix that will be referred to in Section 3 . More details about how path reuse in shooting random walk works can be found in Castro et al. (2008) , where it was applied to light positioning by simply allowing the user to visually decide which was the best location for a light. 2.2. Heuristic search different solution to the same given problem. Suppose that the best solution in S has to be found. Looking for such an optimal solution is equivalent to looking for some extreme (maximum or minimum) in S , which is known as a search space. Brute force algorithms which involve visiting all the states in S guarantee to find the best of the solutions. However, such approaches, due to the size of the search space, are usually infeasible in a reasonable time.

Heuristic algorithms ( Newell and Ernst, 1965 ) avoid visiting the whole search space by defining rules designed to facilitate moving towards states that are most likely to lead to the optimal solution. However, heuristics are fallible: since they rely on limited information, they may lead to a suboptimal solution or to a dead end. Despite of this, such algorithms usually work well in many search problems, meaning they are likely to obtain a good enough solution (either the optimal solution or a solution close enough to the optimal solution) in an acceptable computational time.

There exist a large amount of heuristic search algorithms, described in the literature, which can be applied to a wide range of problems. Hill climbing ( Goldfeld et al., 1966 ), beam search ( Rusell and Norvig, 2009 ), simulated annealing ( Kirkpatrick et al., 1983 ), A n ( Dechter and Pearl, 1985 ), tabu search ( Glover, 1997 ), genetic algorithms ( Goldberg and Holland, 1988 ), and particle swarm optimization ( Kennedy and Eberhart, 1995 ) are some of the most popular of them. 2.3. Light positioning and inverse lighting approaches
Next, some of the main approaches to the problem of inverse lighting for real or virtual environments considering light posi-tions will be summarized.

Schoeneman et al. (1993) developed an approach to lighting design for image synthesis. From a desired solution, their method determined light intensities in order to achieve a desired effect in a computer simulation. Given a set of lights with fixed positions, they computed the light intensities and colors matching the most closely the target image. The computation was done using a constrained least squares approach.

Kawai et al. (1993) presented a framework for designing the illumination in an environment using optimization techniques applied to a radiosity-based system. Their algorithm was flexible and fast, and considered light-source emission, reflectivities, and light direction as optimization variables, but not light positions, which had to be fixed. The user was allowed to modify the constraints and objective function at each iteration of the algo-rithm. Inequality constraints setting lower and upper bounds for the radiosity of a patch were allowed.

Elorza and Rudomin (1997) used standard genetic algorithms to search for the best combination of number, position, and intensities of lights. Objective function, which took into account the minimization of energy, was defined with respect to the difference between the proposed solution and a desired user-defined illumination. A radiosity-based image synthesis system was used.

Marks et al. (1997) dealt with light selection and placement for image rendering, using image-based techniques. They allowed the user to intuitively browse through the space of solutions in order to select light positions and test the results.

Jolivet et al. (2002) applied a Monte Carlo approach to the inverse lighting problem, considering only direct lighting. Once defined the lighting wishes of the designer with declarative modeling, they estimated using ray tracing the most appropriate light positions in order to illuminate the desired areas.
Contensin (2002) proposed a method allowing the user to define a target effect in a scene discretized in patches, using a radiosity approach for computing the lighting. Such a method allowed the light sources to be placed at any patch in the scene, unless some patches forbidden by the user. The inverse problem was formulated in a system of equations and solved using a pseudo-inverse. The obtained solution was taken as a starting point to a second stage in which negative values of emission power were removed and the number of light sources was reduced.

Gumhold (2002) tackled the problem of light positioning in the context of visualization, aiming at maximizing the information introduced by the illumination. He used histogram Shannon entropy together with global maximization algorithms to compute the optimal light locations, considering only direct illumination. Vazquez and Sbert (2003) dealt with the problem of automatic selection of light positions in order to adequately illuminate an object. They also used Shannon entropy, defining a metric in order to calculate the amount of information relative to an object that was communicated to the user given a fixed camera position.
Ha and Olivier (2006) created a tool which allowed the design of objective functions and the application of several optimization techniques, including stochastic optimization. The same authors presented ( Ha and Olivier, 2007 ) an example-based design system for local illumination lighting. Such a system allowed both declarative and natural specification of lighting. Users were allowed to choose a desired lighting from exemplar 2D images.
Some of the most recent work on light positioning has been applied to agronomy and botany. Ferentinos and Albright (2005) used genetic algorithms for lighting design applied to green-houses. They took into account only direct illumination. Optimi-zation was done considering number of point lights and power consumption, and looking for a uniform distribution of the light. Delepoulle et al. (2008) also used genetic algorithms for light positioning, taking into account direct and indirect illumination and including the coordinates of the light positions in the solution codification. They aimed at obtaining uniform incoming light over the plants in a grown chamber.

Finally, Pellacini et al. (2007) presented an interactive system, with applications to computer cinematography, that allowed the desired lighting effects to be easily painted in the scene. The system computed the parameters to achieve the desired lighting with nonlinear user-guided optimization. 3. Problem definition
This section describes the light positioning problem that will be dealt along with this article. The problem definition here extends the definition recently presented in Castro et al. (2009) .Sucha definition involves some novelties regarding the approaches men-tioned in the previous work. 3.1. The proposal
Most of the approaches to the inverse lighting problem listed in Section 2.3 share a common trait: they use heuristic search methods in order to try to find the illumination which minimizes some distance function to a desired final illumination. In our opinion, these approaches present several shortcomings:
The search space includes both light positions and light intensities, being very costly to do an effective search in such a huge search space.

The use of a simple distance function like, for example, the mean quadratic error between the illumination obtained for each surface and the desired illumination, raises problems like the impossibility of specifying maximal or minimal illumina-tion for a patch or set of patches, the difficulty of minimizing the total cost of the illumination, or even the obtention of negative values of emission power for one or more lights.
The attempt to fix these problems by modifying the distance function and introducing constraints produces complex search spaces with plenty of local minima.

The heuristic search processes need continuous illumination simulations to evaluate the goodness of the successive pro-posed solutions. These simulations are very costly if the illumination has to be computed from scratch, and very inexact if only direct illumination is taken into account.
Fig. 1 shows the importance of considering indirect illumina-tion in light positioning. Given an environment in which a minimum irradiance  X  20 W = m 2  X  is required for the top of the desks, and four lights are allowed placed at any of 144 authorized positions on the ceiling, the top image corresponds to the optimal solution obtained using a model which takes into account both direct and indirect illumination, while the bottom image corresponds to the optimal solution obtained from a model which only considers direct illumination. It is worth to notice the differences between the optimal locations for the four lights in both images: in the image considering only direct illumination, lights are placed closer to the walls than in the image considering also indirect illumination. To tackle these problems, our proposal presents two novelties:
A new formulation of the problem substitutes the distance function to be minimized by a set of constraints on the 3.2. Mathematical definition instance of the light positioning problem is given by the following:
Given the sets P , L , X and C , the 3D-array F , and given a positive integer K (the maximum number of active lights allowed), find a subset L K  X f l u 1 , ... , l u K g L of lights, with positions x and emission powers w u 1 , ... , w u K in such a way that all the constraints in C are satisfied and the total illumination cost T (objective function) (2) is minimized: T  X  practice, the best solution could have less than K active lights. set of locations (in the sense that the total light emission power needed to satisfy the illumination constraints is minimal) where a set of light sources must be located in order to assure that, for example: Every desk in an office receives a minimum of light.
 All the pictures in a museum are conveniently illuminated. There are no dark zones in an alley.

The plants in a greenhouse receive a uniform quantity of light. 3.3. Simplifications to the problem Some simplifications have been done to the problem stated in Section 3.2 . First, undistinguished light sources have been con-sidered, namely the same maximum emission power d , the same minimum emission power, which has been set to 0, and the same cost per Watt, which has been set to 1, have been taken for each of the light sources. Thus, since the contribution of the light sources does not depend now on which light source in l 1 , ... , l is considered, F loses one dimension. So, for each authorized position x k in X and for each patch p i in P , F ik is the contribution to the irradiance of patch p i of each unit of light power emitted by a source at location x k . Coefficients F ik are obtained with radiosity random walk taking advantage of the reuse of the paths (see Section 2.1 ).

Given the simplifications above, irradiance I i of patch p expressed as: I  X  where w v j stands for the emission power of a light located at point x v j . The total illumination cost T to be minimized is now the sum of such emission powers. 3.4. The proposal The problem defined has been split into two subproblems: Exploring the search space.
 For a given state, computing optimal emission powers.
 Exploring the search space, choosing subsets of light positions : The search space is defined as the set of all the combinations of K light positions from a set of q authorized positions  X  q 4 K  X  ,regard-less of whether or not a feasible solution (i.e. a solution that fulfills the constraints) for these combinations does exist. This gives a by means of a brute force algorithm, of such a search space is unfeasible even for moderate values of q and K . Different heuristic-search algorithms have to be applied in order to explore the search space in a reasonable amount of time.

Computing optimal emission powers : Given a state, i.e. a subset s of K light positions, the irradiance matrix F and the constraints set C , a linear inequality system with an objective function to be minimized can be stated. Linear programming can be used to evaluate s (using for instance the simplex algorithm), allowing to find out if its associated linear system has a solution, that is, if the corresponding light configuration permits to observe the con-straints (i.e. it is a valid state), and obtaining in this case the optimal emission powers for each light position.

Since the problem has always  X  X  X reater or equal X  X  inequalities, given by minimum irradiance bounds, the states in which the irradiances corresponding to the maximum emission power allowed for each light source do not reach the minimum bound for some of the patches can be discarded as non-valid, avoiding running the simplex algorithm and thus resulting in a reduction of the cost.
 3.4.1. The complete pipeline
Once the irradiances for each patch and light position have been computed and stored on external memory in a pre-process using radiosity random walk with reuse of paths (see Section 2.1 ), an being each state a valid solution. From such initial states, which are chosen at random, the search stage intelligently explores the search space by combining heuristic sear ch algorithms and linear program-ming. Different search algorithms are taken into account in the next sections. Fig. 2 illustrates the whole process. It must be noticed that the storage of irradiances could be done on RAM instead of on external memory, resulting in a red uction of the cost of writing and reading such irradiances. However, the small significance of such a cost with regard to the cost of computing the irradiances and especially of running heuristic search algorithms makes the storage place to be irrelevant.

It is worth to notice that if, for a given instance of the problem, no valid solutions are obtained in the initial stage once a reasonable number of states have been explored, it will be considered that it probably does not exist any light configuration fulfilling the con-straints. In this case, the proces s will be forced to abort, meaning that the problem should be reformulated, for example by relaxing irradiance constraints or by inc reasing maximum emission power allowed for each light source. It is also worth to remark that states are stored in a hash map in order to avoid evaluating the same state more than once, involving a noticeable reduction of the cost. 4. Hill climbing
Hill climbing (HC) algorithms are a relatively simple kind of heuristic search algorithms valid for problems formulated in terms of maximizing (or minimizing) a given criterion (objective function). They are a family of greedy algor ithms whose common treat is to depart from an initial state (seed) in the space of possible solutions and move through this space by means of slightly mutating the current state to a better one (i.e. one with a better value of the objective function). The process stops when no mutation of the current state improves the objective function. Hill climbing always finds a local maximum (or minimum), but such a value can be far from the optimum. Algorithm 1 outlines the basic HC algorithm for a given initial state.
 Algorithm 1. Basic hill climbing 1: function HILL C LIMBING (State seed): returns State best 2: best  X  s  X  seed 3: Compute set Succ ( s ) 4: while Succ ( s ) includes some state better than s do 5: s  X  best in Succ ( s ) 6: best  X  s 7: Compute Succ ( s ) 8: end while 9: return best 10: end function The seed can be naively obtained by generating combinations of K light positions at random and taking the first valid solution found.
Given a valid state s , that is, a set of K possible light source placements, its best successor is chosen between the set of its successors Succ ( s ). Such successors are generated by applying mutations to s . A mutation of s is added to Succ ( s ) if it is a valid state with an objective function lower than s . A state s is mutated by replacing a light source position by a new one. Three issues have to be taken into account: Which light position x i in s is to be replaced.

Which light positions are to be considered to replace x i Which state in Succ ( s ) is to be chosen.

Regarding the first issue, several heuristics have been consid-ered, such as replacing the position with the highest value of optimal emission power, the one with the lowest optimal emis-sion power, and a position at random. The results obtained for test scenes 1 and 2 (see Section 9 ) show the best results when replacing the position with highest emission power. Thus, this is the heuristic that will be applied in further experiments.
Regarding the second issue, a radius r , expressed in grid cell units (assuming that the authorized light positions are placed in a grid on the ceiling and/or on the walls), is established as input parameter. All the positions within distance r are selected to replace the outgoing position. Experiments have shown that a value of r  X  2 gives a good balance between performance and cost. Thus, this is the value used in all our tests.

Regarding the third issue, once the set Succ ( s ) has been deter-mined, one of its elements has to be chosen as successor of s .Two different ways of choosing such a successor have been considered:
Choosing the state with the lowest value of the objective function. This deterministic strategy is known as steepest ascent hill climbing (SAHC) or just hill climbing (HC). Choosing the successor using a probability distribution on Succ ( s ).
Reasonably, the probability of a state to be chosen is established proportionally to the inverse of it s objective function value. This strategy is referred to as stochastic hill climbing (StHC).
From several experiments performed for both scenes 1 and 2, the first way (SAHC) has been observed to be better than the
StHC. Thus, we will use SAHC in further experiments. 4.1. Random restart hill climbing
An important issue for hill climbing and, in general, for local search algorithms, is that they are strongly affected by local extremes (foothills), and also for regions in the search space with no significant variation of the objective function (plateaus).
Such problems can be reduced mainly in two different ways: by applying random jumps to the current solutions in the search process, and by running the algorithm a number n of independent times, each from a different randomly chosen seed, and taking the best of the obtained solutions. In this second approach, known as random restart hill climbing (RRHC), it can be proved that, if there is a finite number of local minima, the probability of finding the optimal solution tends to 1 as n tends to infinity. 5. Genetic algorithms solutions (states) in sets or multi-sets, referred to as populations, swarms, etc. Such algorithms are based on generating a succession of populations in which each of them should be better than the previous one, that is, should have better individuals. It is worth to notice that such algorithms clearly differ from local-search-based algorithms such as hill climbing (see Section 4 ), which are based in successions of individuals rather than populations.
 family of computational models inspired by evolution. They have been proved to suitably work on a wide range of optimization problems from different fields. In the usual implementation of genetic algorithms, the solutions to each problem have to be codified.
The codification of a solution is called a chromosome .Thus,GAare based on the evolution of sets of chromosomes, each of these sets called a population .
 which represents its suitability. The process begins with a population of typically random initial chromosomes. Populations evolve by means of three different mechanisms: summarized.

Algorithm 2. Basic genetic algorithm with elitism established as an input to the algorithm. The end condition has also to be set in a way: sometimes, a given number of iterations is set a priori; in other cases, the process ends when no improve-ment is obtained from one iteration to the following one.
Elitism is one of the most usual strategies in GA. It consists in taking the best (or the k best) individuals in a population to the following population. By applying elitism one guarantees not to lose the best solution(s) found in the search process. 5.1. Genetic algorithms applied to the light positioning problem
We have applied genetic algorithms to the light positioning problem defined in Section 3 . Next, the main features of such an application will be described. 5.1.1. Encoding
Each chromosome is codified as a list of K sorted light position identifiers (values in 1 :: q ), K being the number of active lights allowed. According to GA terminology, each of the light positions corresponds to a gen . 5.1.2. Populations: generating initial population
Populations are sets of valid solutions (chromosomes), a valid solution being a combination of K authorized light positions with their emission powers able to light the environment according to the lighting constraints. Let n be the population size , that is, the number of chromosomes in each population. The initial popula-tion is formed by n chromosomes chosen at random. 5.1.3. Objective function and fitness function
Let d be the maximum amount of power allowed for each light source, the product K d is the maximum total emission power allowed. As the total emission power has to be minimized, the objective function F ( s ) for a given valid solution (chromosome) s is defined (4) as the difference between K d and the total emission power of s , which will be referred to as T ( s ): F  X  s  X  X  K d where w u j stands for the emission power corresponding to the light in the position u j . Moreover, each chromosome s has to be assigned a fitness value, which represents the quality of the solution associated to s regarding the rest of the chromosomes in the population. In this case, the fitness function has been defined in the following way: f  X  s  X  X  F  X  s  X  where F  X  P  X  is the average value of the objective function for the chromosomes in population P . 5.1.4. Crossover
Pairs of chromosomes (parents) are chosen at random from a previously done selection. The crossover operator is run on each couple of parents, according t o a given crossover probability p implementation of the crossover operator used in our experiments consists in sorting the light positions from both parents, and assign-ing each of the positions to either of the two resulting offspring, at random, until K positions have been assign ed to each of the offspring. Positions common to both parents are assigned to both offspring. Fig. 3 illustrates the crossover procedu re.Suchaprocessisiterated until the new population is complete (until it has n individuals). We have used a crossover variant called elitist crossover in which, if crossover is done, the 2 resulting offspring are added to the new population only if they improve the parents. Otherwise, the parents are added to the new population.
 5.1.5. Mutation
Each of the light positions (gen) in the new offspring is submitted to mutation with probability p m . The mutation of a light position consists in replacing it by a new one. In our implementation, the new position is selected by sampling positions at random and picking up the first of them that gives a valid solution when replacing the position to be mutated. If no replacement (in a previously established number of attempts) is able to give a valid solution, the mutation is not carried out. In general, the mutation mechanism is intended to be a tool to permit random jumps in the search space, in order to avoid the process getting stuck in local maxima. For such a purpose, the result of the mutation is not r equired to improve the original chromosome, and all the authorized positions (and not only the ones in a neighborhood of t he mutated positions) are allowed for the replacement. Fig. 4 illustrates the mutation procedure 5.1.6. End condition
The process carries on if either the best individual in the new population improves the best individual in the previous popula-tion, or the average value of the objective function for the new population improves the same value for the previous population.
Otherwise it stops. 6. Jumping particle swarm optimization
Particle Swarm Optimization (PSO) ( Kennedy and Eberhart, 1995 ) is a family of search algorithms based on groups of states (popula-tions). They are inspired by the social behavior of individuals inside swarms in nature. Solutions of the problem are modeled as members of the swarm which fly in the solution space. We will use a modality of discrete particle swarm optimization called Jumping Particle
Swarm Optimization (JPSO) ( Consoli et al., 2010 ). At each iteration, all particles in the swarm evolve by jumping from one state (solution) to another. Some attractors are considered that guide in a way the movement of the particles and thus of the whole swarm.
A random component is also involved in such a movement. For each particle P i , 3 attractors are considered: The best position to date of the particle ( b i ).

The best position obtained by the swarm in the current iteration (neighborhood best position g i ).

The best position to date obtained by all the particles (global best position g n ).

Particle jumps will be done approaching one of the attractors, consisting in changing a feature of the current solution by a feature of the attractor. In the application to our light positioning problem, we have used the same encoding as in genetic algo-rithms (see Section 5.1 ), and the feature change referred above corresponds to the replacement of one of the light positions of the current solution by a light position of the chosen attractor. The decision about which of the three attractors b i , g i , g n will be chosen at each case will be taken by considering pre-established probabilities prob b , prob n , prob g , respectively, with prob 1 prob b prob n prob g as the probability of keeping the particle unchanged. Fig. 5 (left) illustrates the election of the attractor, while Fig. 5 (right) illustrates the replacement. In Algorithm 3 we present a pseudo-code for the JPSO algorithm applied to our problem, while in Algorithm 4 the pseudo-code for the combine function is shown.

Algorithm 3. Jumping particle swarm optimization
Algorithm 4. Combine function based on the number of iterations without improvement in g n .
From a given number of such iterations (five in the experiments done), the process is forced to terminate with probability 1 1 = 2 j , j being the number of iterations over that given number. However, other heuristics could obviously have been applied. 6.1. Parameters in JPSO
Next we will summarize the main parameters involved in JPSO algorithm: Swarm size n .

Probability prob b of taking b i (best position of P i to date) as attractor.

Probability prob n of taking g i (best position of the social neighborhood) as attractor.

Probability prob g of taking g n (best global position to date) as attractor.

Probability prob k  X  1 prob b prob n prob g of keeping P i out combination.
 We will experiment with different values of n in Section 10 . The most appropriate values for the probabilities will be also discussed in the same section. 7. Hybrid algorithms: combining global and local approaches
Algorithms based in sets of individuals, such as GA and JPSO, involve a global approach, since all the individuals in each popula-tion/swarm interact and contrib ute to the obtention of the final solution. It is possible to combine them with algorithms which involve a local approach, such as hill climbing (see Section 4 ). 7.1. Hill-climbing-based genetic algorithm
Genetic algorithms usually improve their performance when combined with other optimization methods. From another point of view, traditional methods such as local search (hill climbing) do not get worse when combined with a genetic algorithm.
Some authors ( M  X  uhlenbein, 1990 ) state that applying local hill climbing to each individual in each population usually improves the performance of genetic algorithms. Such a strategy obviously increases the cost of the search, but it is expected to produce better results than bare genetic algorithms.

The standard genetic algorithm described in Algorithm 2 can be slightly modified by adding a hill climbing step to the chromosomes in each population, including the initial one. Such a hill climbing step will correspond to Algorithm 1 , the initial states being the chromosomes in the considered population.

The hill climbing stages aim at improving the quality of the current population by making each of its individuals mutate in order to climb in the search space. Such a hybrid algorithm will be referred to in this paper as hill-climbing-based genetic algorithm (HCBGA). 7.2. Hill-climbing-based jumping particle swarm optimization We have also experimented with the combination of JPSO and HC, in order to obtain a better performance. Thus, the standard JPSO described in Algorithm 3 can be modified in the same way as GA (see Section 7.1 ) by adding a hill climbing step to the particles in each swarm, including the initial one. Such a hill climbing step will also be applied according to Algorithm 1 , the initial states being the particles in the considered swarm. Such a hybrid algorithm will be referred to in this paper as hill-climbing-based JPSO (HCBJPSO). 8. Incorporating a priori knowledge
A possible criticism to be made to the framework presented in this paper is that it does not make any use of the a priori knowledge about the general illumination problem that designers, decorators, and architects have and which is mainly based upon common sense and past experience. In fact, our framework is intended to be a tool to back the work of such professionals. Such a priori knowledge will depend on the scene complexity and on the irradiance constraints applied to the patches. We refer to pieces of knowledge or design patterns as, fo r example  X  X  X egular dispositions are generally preferable X  X  or  X  X  X ry not to locate a weak light source side by side to a strong one X  X . Now, the ways in which such a priori knowledge can be combined to the heuristic search methods will be described.

Suppose we can express those design patterns in the form of a set R of rules, we can incorporate this knowledge to the frame-work in several ways:
It can be used to build the initial population (both in the GA and in the JPSO) following the desired design patterns. Indivi-duals constructed according to the rules will tend to have proportionally better values of the objective function and to be in better areas of the search space, too (that is why people uses design patterns, after all), so they will tend to remain in successive generations. Thus, the initial populations of rule-respecting individuals could be provided by design experts.
It is possible to modify the objective function by adding a penalty term which takes into account the number (or the importance) of the design rules broken by each possible solution, penalizing those individuals representing light source distributions which do not adjust themselves to the design patterns codified in the set of rules R .

It is also possible to define a function f R : S - X  0 ... 1 , where S is the set of all the possible solutions to the inverse illumina-tion problem at hand, representing the degree to which each possible solution adjusts itself to the design rule set R . Once defined f R , it can be used as a probability of survival. In the case of GA, after crossover, the function can be applied to the offspring in order to obtain its probability to be incorporated to the new population. In the case of JPSO, 1 f R can be used, for example, at each iteration, as the probability of the worst particle in the population to be  X  X  X illed X  X  and substituted by a fresh one.

The function f R can also be used to specify a threshold below which newly created individuals (after crossover in GA X  X , after jumps in JPSO) are not allowed to survive. This threshold can be dynamic, in the sense that it can be very low in the first iterations of the algorithms, permitting the existence of individuals with very low values of the f R function (that is, light source distributions breaking many design patterns), and can increase steadily in such a form that at the final iterations of the algorithms only light source distributions respecting the design patterns could be contemplated.

We have incorporated the third of the ways above to our framework. However, regardless the way used to incorporate the  X  X  X  priori X  X  knowledge to our framework, it seems clear that the prior indications of the designers, etc. reduce the size of the search space by discarding many of the possible configurations. Nevertheless, in many cases such a reduced search space keeps being huge enough to need an efficient exploration via heuristic search algorithms as we propose. Note that the size of the space grows very quickly with both the number q of authorized positions of the light sources and the maximum number K of lights allowed. Furthermore, note that not only position but also orientation of the light sources could be considered, resulting in a noticeable increase of the search space size (for a given position, each orientation can be considered as a new position), and finally note that variable light conditions (sunlight entering a room, etc.) can also result in an increase of the search space size. 9. Test framework
Three problem instances corresponding to three different environments have been used in order to make a wide analysis of the performance of the algorithms previously discussed. As a reference comparison, we have taken a brute-force algorithm which simply generates valid solutions and gives the best of them as result. Moreover, parameters for the different studied algo-rithms have been tuned up for each of the environments.
Next we describe the indicators taken into account in our analysis:
T , the sum of emission powers (T) for the best solution found. t , the total running time for the search process.

It is worth to mention that, for the sake of statistic significance, for each of the experiments 10 independent runs have been carried out, and the mean and the standard deviation of the obtained results have been considered. All the runs have been done on a Pentium IV at 3 GHz with 2 GB of RAM. 9.1. Scenes considered 9.1.1. Scene 1
Scene 1 , the simple environment shown in Fig. 1 , is used in a series of experiments. For this problem instance, a minimum irradiance of 20 W = m 2 on the top of the desks is required, resulting in 256 constraints. Lights of 300 W at most have been taken into account, and 144 authorized positions for the lights have been considered, placed in a regular grid on the ceiling. The maximum number of active lights allowed has been fixed to 5, giving a total of  X  144 5  X  481 M states.

The computation of the irradiances for each patch and position in the scene has been done via shooting random walk with reuse of paths (see Section 2.1 ). The reuse allows to obtain an accep-table irradiance estimation with only 20 000 shooting paths per authorized light position, resulting in a total cost of about 500 s (the cost could be reduced by using GPU computation). Irra-diances are stored on external memory in order to be read over and over for each run of the search process. 9.1.2. Scene 2
Scene 2 consists of a space which is subdivided by partition walls in a kind of small rooms. Maximum and minimum irra-diance requirements have been established for different zones of the rooms, giving a total of 574 constraints. A maximum of seven light sources will be observed, having each of them 300 Watts at most. Authorized positions for the light sources are placed, similarly to scene 1, in a grid on the ceiling, resulting in a total of 384 positions, which, taken in groups of 7, gives a huge search space sized  X  384 7  X  2 : 3 10 14 .

In particular, three of the rooms require an interval of max-imum and minimum irradiances  X  40 W = m 2 , 3W = m 2  X  arriving to the center part of their partition walls, while the fourth room has a maximum irradiance  X  40 W = m 2  X  to arrive to the center part of one of its walls. These constraints make it clear the requirement of one light source (at least) over each of these three rooms plus, as a designer X  X  desire, an additional light source over the corridor.
Such a priori knowledge will be incorporated to our application by immediately discarding all the states that do not fulfill such a requirement, resulting in a noticeable reduction of the search space size. Thus, scene 2 serves as an example of how to apply a priori features that a human (designer, architect, etc.) can decide to incorporate to the light positioning process.
 such a scene has been done, as in scene 1, using shooting random walk with reuse of paths, obtaining an acceptable irradiance estimation with 50 000 paths per authorized position, with a cost of about 1 h. Again, irradiances are stored on external memory. 9.1.3. Scene 3 containing several partition walls and a table. Six hundred and twenty four authorized light positions are considered, corre-sponding to a regular grid on the ceiling and the upper part of the four walls. Incoming irradiances are limited on the central part of the partition walls (where the pictures to exhibit are supposed to be placed) in the interval  X  3 ; 15 W = m 2 , while they have been given a lower bound equal to 5 W = m 2 on the top of the table. This sums up to 416 constraints (the scene has been subdivided in 4992 patches). A maximum number K  X  6 of active lights up to 200 W is allowed. This problem instance involves a huge search space with a total of  X  624 6  X  8 10 13 states. such a scene has been done using radiosity shooting random walk with reuse of paths (see Section 2.1 ). The reuse allows to obtain an acceptable irradiance estimation with only 100 000 shooting paths per authorized light position, resulting in a total cost of about 3.5 h.
Note that irradiances have been computed just once and stored on external memory (about 36.5 M) as with the other two scenes. 10. Parameter study methods previously described to scenes 1 and 2 in order to tune the parameters involved in the computations. 10.1. Use of random restart hill climbing (RRHC) of RRHC in which the successor of a given solution is chosen as the best of the set of successors obtained by replacing the light position with the highest power by any light position in a radius of two grid units. Thus, the only parameter taken into account is the number of seeds considered in the random restart procedure. 10.1.1. Experiment 1: on the number n of random restarts (seeds) considered restarts the better the solution obtained, although in scene 1 there is an increase of the variability for the higher experimented values of n .
In these tables it is also possible to see a comparison between RRHC and a brute force procedure in which a number of random solutions is generated and, simply, the best of them is chosen. Such tables make it clear the advantage of hill climbing in front of the brute force procedure, which empirically confirms what was totally expectable: even a naive searching strategy such as hill climbing explores the search space more efficiently than just taking solutions at random. 10.2. Use of genetic algorithms (GA)
The parameters considered in the experiments with GA will be described next: n , the number of chromosomes in each population. p c , the crossover probability. p m , the mutation probability (probability of mutating a given gen in a given chromosome).

Now we describe the carried out experiments. It has to be remarked that the same initial populations have been used when comparing performances for different parameter values and the same population size, in order to abstract the results away from the specific initial population. 10.2.1. Experiment 2: on the crossover probability
This experiment evaluates the performance of GA for different values of the crossover probability p c . GA has been run for different values of p c , taking population size n  X  50 and mutation probability p  X  0.01. Graphs in Fig. 6 show the average values of T b together with their standard deviation for different values of the crossover probability in the range [0.6,1). These results show that the best performance is achieved, for scene 1 (left) using p c  X  0.95, while for we will use in the remaining GA experiments with these problem instances. On the one hand, these empirical facts concur with the heuristics indicated in the literature on GA (see Reeves and Rowe, 2002 ), which recommend using high values of the crossover prob-ability. On the other hand, these results show that the most appropriate values of the crossover probability depend on the problem instance that is being dealt with; thus, such a values should be tuned for each problem instance. 10.2.2. Experiment 3: on the mutation probability
This experiment makes an evaluation of the performance of GA for different values of the mutation probability p m . GA has been run for different values of p m , taking population size n  X  50 and crossover probability p m  X  0.95 for scene 1 and 0.8 for scene 2. Since the literature on GA ( Reeves and Rowe, 2002 ) recommends using low values of p m ,graphsin Fig. 7 show the average values of T with their standard deviation for such low values of the mutation probability. These results show that the best performance is achieved, for scene 1, using p m  X  0.01, while for scene 2 the value of p has been chosen as the most appropriate of the tested values (note that a slightly lower average T b has been obtained using p scene 2, but at a higher standard deviation). Thus, these are the values used in further experiments with these problem instances. It has to be mentioned that, as in the case of the best value for the crossover probability, such  X  X  X ptimal X  X  values are tied in a way to the problem instance, so they should be reconsidered for other problem instances. 10.2.3. Experiment 4: on the population size
This experiment elaborates on the performance of GA for different values of the population size n .Taking p c  X  0.95, p for scene 1, and p c  X  0.8, p m  X  0.0025 for scene 2, the algorithm has been tested for several population sizes. Graphs in Fig. 8 represent, for both scenes 1 (left) and 2 (right), the average values of T together with their standard deviation for different values of n .For scene 1, graph on the left shows a tendency to reduce T b so that the best performance is achieved using n  X  200, but higher values of n present a slight increase of the average T b and even of the standard deviation, in a kind of erratic behavior. Regarding scene 2, graph on the right also shows a tendency to reduce T b as n grows, obtaining the best results for n  X  300, but the behavior is also irregular for some values of n . Thus, one can conclude that it is not easy to find the value of n which offers the best performance, although high values of the population size seem to work better than low values.
 10.3. Use of jumping particle swarm optimization (JPSO) attractor, and second, we elaborate on the number of particles of the swarms involved in the search. 10.3.1. Experiment 5: on the probabilities of choosing the attractors both scenes 1 and 2. Basically, we have compared an equiprobable situations in which one of the four probabilities is clearly higher than the rest. Results obtained for a 200 particles swarm with scene 1 and for a 50 particles swarm with scene 2 are presented in Table 3 ,where we can see that the best results regarding low objective function and low variability are obtained, for scene 1, taking prob that the best results have been obtained taking prob g  X  0.7, and the rest 0.01. Thus, these are the values used for the remaining experi-ments with JPSO and HCJPSO. 10.3.2. Experiment 6: on the swarm number of particles
This experiment is intended, in the same line as experiment 4 for genetic algorithms, to study the evolution of the perfor-mance of JPSO as the swarm number of particles grows. Graphs in Fig. 9 show, as expected, how the average value of T b and even its standard deviation tend to decrease as n grows for both scenes 1 (left) and 2 (right). Such a decreasing is more clear than the one shown in experiment 4 with genetic algorithms, which had a more erratic behavior. 10.4. Use of hybrid approaches 10.4.1. Experiment 7: hill-climbing-based genetic algorithm
Graphs in Fig. 10 show the behavior of HCBGA (see Section 7.1 ) by representing the evolution of the average T b when the population size grows for both scenes 1 (left) and 2 (right). In both cases, it is possible to see the tendency of obtaining a lower T when n grows. However, an irregular behavior is observed, espe-cially regarding the variability (s tandard deviation) in scene 1, but also with respect to the value of T b , which in some specific cases grows when the population size grows. Note that in scene 1 the last value has standard deviation 0, meaning that the 10 independent experiments have produced the same best solution, which happens to be the optimal one (it has been found by an extremely long brute force run which has taken about 64 days on a Pentium IV at 3 GHz with 2 GB of RAM).
 10.4.2. Experiment 8: hill-climbing-based jumping particle swarm optimization
Graphs in Fig. 11 show the behavior of HCBJPSO (see Section 7.2 ) by representing the evolution of the average T b when the population size grows for both scenes 1 (left) and 2 (right). In both cases, it is possible to see the tendency of obtaining a lower T b when n grows. There also exists an irregular behavior, like the one observed in experiment 7, but less noticeable in this case. Note also that, like in the previous experiment, in scene 1 the last value has standard deviation 0, meaning that the 10 independent experiments have produced the same best solution. 11. Results In this section we first intend t o compare the performance of RRHC, GA, and JPSO using scenes 1 and 2. Next we compare the performance of hybrid and non-hybrid approaches, using the same pair of scenes. Next, we elaborate on the number of explored states. Finally, scene 3, due to the huge search space associated to it, has been used as a touchstone for our methods in solving a problem instance using the most appropriate techniques according to the results obtained in the experiments done with scenes 1 and 2. 11.1. Comparing the performance of RRHC, GA, and JPSO Graphs in Fig. 12 show a comparison of the behavior of RRHC, GA, and JPSO when applied to scenes 1 and 2. Running time appears on x -axis, while y -axis corresponds to objective function T b .

For scene 1 (top), we note that for low running times RRHC offers lower values of the objective function than GA and JPSO at similar times. However, as n grows, JPSO seems to be more competitive than the other 2 methods. Note the erratic behavior of GA, for which the average value of T b even grows a bit for the highest tested values of n . If we consider the variability (not reflected in this graph), we note that the standard deviation of T is lower in RRHC than using JPSO and especially than using GA, which is an advantage of the first method in front of the remaining two. In sum, for scene 1, the results obtained using JPSO are better regarding T b than the ones using GA and RRHC, and are more stable (have less variability) that the ones using GA.
For scene 2 (bottom) the behavior is quite different, especially in the fact that the performance of RRHC is clearly worse than the ones of GA and JPSO. GA have, as in scene 1, an erratic behavior that allows us to state that JPSO is superior to RRHC and seems to be less irregular than GA. With respect to the variability, there is no significative difference, in this scene 2, between the 3 methods.

We can conjecture that RRHC is more or less competitive regarding GA and JPSO for regular search spaces involving few local minima, like the corresponding to scene 1, since in this case it is more probable to reach the global minimum, but not when the search space presents many local minima due to the scene and constraints complexities and to the human-established a priori requirements, like in scene 2.
 11.2. Comparing the performance of hybrid and non-hybrid approaches of non-hybrid approaches GA and JPSO against hybrid approaches HCBGA and HCBJPSO for both scenes 1 (top) and 2 (bottom).
Average T b (W) has been represented on y -axis, while running time (s) has been displayed on x -axis. Points on each curve correspond to increasing values of the population/swarm size n .
For scene 1, graph on the top shows the superiority of hybrid methods in front of non-hybrid approaches. On the contrary, for scene 2, non-hybrid methods GA and JPSO have a clearly better performance than the respective hybrid approaches, obtaining lower values of T b in the solution at similar running times.
Although non-represented on these graphs, the variability in the results (standard deviation of T b ) is lower, for scene 1, using the hybrid approaches, while in scene 2 the lower variability has been obtained using the non-hybrid approaches (see graphs in experi-ments 4, 6 X 8). In both scenes, and for a given population/swarm size, hybrid methods reduce the average T b regarding the corre-sponding non-hybrid method, but in scene 2, at a high increase similar running time, lower values of T b and less variability than the hybrid approach. Tables 4 and 5 illustrates such a behavior for genetic algorithms and jumping swarm particle optimization, respectively.

Hill-climbing based search techniques tend to show a poorer performance in complex search spaces with a lot of local minima, due to their tendency to get stuck in them. This fact can provide an explanation to the difference in the performance of hybrid and non-hybrid algorithms in the two scenes. Scene 1 is a simple one, with few local minima, so it benefits more for the incorporation of the hill climbing step. Scene 2 is more complex due to the existence of walls which cause discontinuities in the objective function and the gain produced by the local search step do not justify the increase in computational cost. Note that (see Section 11.1 ) while in scene 1 RRHC is competitive regarding GA and JPSO, in scene 2 RRHC performs clearly worse than GA and JPSO.

Summing it up, it will be preferable to use hybrid methods in problems with large and relatively simple search spaces and use the direct approaches in problems with complex search spaces. In practice, we purpose to do a previous test on the given problem instance, using on the one hand RRHC, and on the other hand JPSO (or GA) involving a similar running time. If the performance of RRHC is similar to the one obtained using JPSO (which is going to happen when the search space contains few local minima), then it will be valuable to combine the advantages of both approaches using the hybrid algorithm (HCBJPSO). On the contrary, the poorer the performance of RRHC with respect to the one of JPSO, the less profitable and thus the less convenient will be the use of the hybrid approach. 11.3. On the number of explored states
We have also counted the number of explored states at each experiment. Avoiding to include such results in order not to unnecessarily enlarge this article, some comments are worth to be mentioned here. First, we have to remark that only a very small part of the search space is explored with our heuristic search techniques. As an example, for scene 1, only an average of about 1700 states have been explored using HCBGA with n  X  20 over a search space size of about 481 millions. However, the solution obtained in such experiments has been shown (by a brute force extremely long run) to be the optimal one; this fact emphasizes the effectiveness of the search algorithm. Second, it is also worth to mention that, for a similar number of explored states, hybrid algorithms obtain better results than bare GA and JPSO. For instance, in scene 2, considering JPSO and HCBJPSO with n  X  75 in both cases, the number of explored states has been similar, but the hybrid algorithm has obtained a solution with a significatively lower value of the objective function. 11.4. Practical application to a problem instance
In this section we will describe the results obtained with scene 3, which has been used as a touchstone for our methods in solving a problem instance using the most appropriate techni-ques according to the results obtained in the experiments with scenes 1 and 2.

Since JPSO and HCBJPSO seem, from the previous experiments, to have a slightly better performance than GA and HCBGA, respectively, we have decided to use that first pair of methods based on discrete swarm particle movement. In a first test we have tried to compare the performance of JPSO against the performance of HCBJPSO, in order to decide which of both approaches can drive us to a best result when applied with a higher value of n . 11.4.1. Comparing the performance of JPSO and HCBJPSO
We have run both methods with the same number of particles n  X  100, taking prob g  X  0 : 7 , prob n  X  0 : 2, and prob Results can be seen in Table 6 , in which a reduction of the average T and of the standard deviation is observed, as expected, using HCBJPSO, but a much higher cost. In order to compare both approaches taking a similar cost, JPSO has been run using a higher value of n  X  1700. Results obtained show a slight advantage of HCBJPSO. 11.4.2. Several runs of HCBJPSO with a higher swarm size
In order to cover as much of the search space as possible in a reasonable running time, five runs of HCBJPSO with prob g prob n  X  0 : 2, prob b  X  prob k  X  0 : 05, and n  X  200 have been done taking each time a totally different initial population. The best of the five results corresponding to each of the five runs has been taken as final result. Table 7 compares such a result with the ones previously obtained using HCBJPSO with n  X  100. Note that, on the one hand, the average value of T b and its standard deviation have not been reduced using a higher n (conversely, they have slightly increased). On the other hand, the best solution obtained in the independent runs happens to be thesameinbothexperiments.
Thus, although it is not sure that such a solution is the optimal one, it can be considered an acceptable solution obtained in a reasonable cost.

Two views (top and side) of t he best solution found are represented in Fig. 14 . In the image on the top, corresponding to the top view, the six light positions are represented (three of them on the right wall, 1 on the left wall, and the two remaining on the ceiling). In the bottom image, corresponding to the side view, only 3 of the light sources are visible. Lights are represented in a size proportional to their corresponding emission power. 12. Conclusions and future research
This article describes a formulation of the problem of light positioning for real environments in the form of a combinatorial optimization problem. The goal of this new formulation is to minimize the total emission power spent to illuminate a scene, given a set of constraints in the form of irradiance intervals over the surfaces defining the scene, and given the maximum number and authorized positions of the light sources.

The framework presented in this paper has proved itself able to obtain a valid solution for the problem with a reasonable computational cost. It makes use of radiosity techniques with path reuse for the precomputation of the illumination. Path reuse allows to drastically reduce the precomputation cost. Although our framework does not guarantee the obtention of the optimal solution, we can obtain, thanks to the use of intelligent heuristic search algorithms, much better solutions for the same computa-tional cost than a brute force approach: such an approach, in which the best of a number of valid solutions taken at random is selected, would take several orders of magnitude more to obtain a similar solution. Our framework also allows to easily incorporate a priori human design decisions such as invalid light combina-tions or forced light positions.
 framework, including hill climbing (HC), genetic algorithms (GA), jumping particle swarm optimization (JPSO), and hybrid algo-rithms which combine GA and JPSO with HC. Some conclusions have to be remarked from our experiments. First, that population based algorithms, such as GA and especially JPSO, have performed better than HC, although the superiority degree of GA and JPSO regarding HC has been shown to be very related to the problem instance, appearing, from the experiments done, to be higher in more complex search spaces. Second, that the use of hybrid algorithms HCBGA and HCBJPSO, for a given population size, improves on the result obtained with the respective non-hybrid approaches GA and JPSO. However, depending on the problem instance, the increase in cost of the hybrid approach makes it preferable to use the non-hybrid one with a larger population size. Thus, it is convenient to use hybrid approaches when the performance of RRHC is similar to the performance of JPSO (or
GA) (it can be checked in a small previous test), corresponding to simple search spaces involving not many local minima. On the contrary, it is more convenient to use non-hybrid approaches when JPSO (or GA) clearly outperforms RRHC, which basically occurs with more complex search spaces involving many local minima.
 search space in a more effective way than short ones, but up to a point, since the decreasing of the function to be minimized has been shown to be irregular when n grows in all the tested algorithms. And fourth, that the most appropriate value for the parameters involved in the search depends on the problem instance, and thus such a value should be tuned in each case.
However, from our experiments it seems to be clear that, in GA, high values of the crossover probability and low values of the mutation probability are appropriate, while in JPSO it seems to be worth taking a high value of the probability of using the global best position in the combinations.
 the human intuition and knowledge of designers, architects, etc. to find the more appropriate positions and emission powers for the light sources to be placed in order to illuminate an environ-ment according to some lighting requirements.
 mentioned. First of all, experiments with other heuristic search algorithms, such as genitor, GHC, and A n , can be done in order to eventually incorporate them to t he framework. Second, variable lighting conditions as sun movement along the day can be taken into account, involving change on the fly of the artificial illumination in order to adapt it to the natural lighting. Third, a parallel programming approach, using for instance the modern graphic cards (GPU), can be investigated in order to reduce the total cost of the search. Fourth, a new problem formulation involving a finite set of possible emission powers for the light sources will be considered. Such a new formulation would involve new strategies to tackle the problem, in which constraint-based logic programming would play an important role. Finally, future work will include the study of the applications of our framework to other types of radiation than light, such as heat radiation, microwaves, etc. Acknowledgments This project has been funded in part with grant number TIN2010-21089-C03-01 from Spanish Government, and with grant number 2009 SGR 643 from Catalan Government.
 Terminology table: Abbreviations HC hill climbing RRHC random restart hill climbing SAHC steepest ascent hill climbing StHC stochastic hill climbing GA genetic algorithms PSO particle swarm optimization JPSO jumping particle swarm optimization HCBGA hill climbing-based genetic algorithms HCBJPSO hill climbing-based jumping particle swarm optimization Symbols F total emission power N s number of shooting paths to be generated at each X set of authorized light positions q number of authorized light source positions x i an authorized light position F xy form-factor between points x and y G i light path generated at position i S set of states (search space) s a state P set of patches p number of patches in the scene p i a patch A i area of patch i I i irradiance arriving on patch i L set of lights m number of lights l i a light w i emission power for light i or for light placed at position i F 3D-array of irradiances F ijk contribution to the irradiance of patch p i of 1 unit of K maximum number of lights allowed C set of constraints c number of constraints i lower irradiance bound for patch i b i upper irradiance bound for patch i i lower emission bound for light i d i upper emission bound for light i T total emission power Succ ( s ) set of successors of state s r radius expressed in grid cell units n population/swarm si ze in GA/JPSO, and number of restarts f ( s ) fitness function in GA F ( s ) objective function in GA P a population (GA) F  X  P  X  average value of the objective function for population p c crossover probability (GA) p m mutation probability (GA) S a swarm y i position of particle i in a swarm v i velocity of particle i in a swarm b i best position to date of particle i in a swarm g i best position in the neighborhood of particle i in prob b probability of taking attractor b i prob n probability of taking attractor g i prob k probability of keeping a particle unchanged T b sum of emission powers for the best solution found s b standard deviation for T b t running time for the heuristic search process x random value from a uniform distribution in  X  0 ; 1  X  R set of rules S set of all the possible solutions to the inverse illumina-f
R function representing the degree of adjustment of a References
