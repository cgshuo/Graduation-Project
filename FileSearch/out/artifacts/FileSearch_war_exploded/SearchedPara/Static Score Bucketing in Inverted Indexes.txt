 Maintaining strict static score order of inverted lists is a heuristic used by search engines to improve the quality of query results when the entire inverted lists cannot be pro-cessed. This heuristic, however, increases the cost of index generation and requires complex index build algorithms. In this paper, we study a new index organization based on static score bucketing. We show that this new technique sig-nificantly improves in index build performance while having minimal impact on the quality of search results.
 Categories and Subject Descriptors H.3[Information Systems]: Information Storage and Retrieval; E.1[Data]: Data Structures General Terms: Algorithms, Performance Keywords: Indexing, Search engines, Static scoring
In previous work, Long and Suel [6] have proposed an in-verted lists organization that is based on a static rank order of the postings. Such an organization improves the result quality when the entire index cannot be scanned. However, it degrades index build performance and increases the com-plexity of index build algorithms [3]. This issue stems from the fact that a change in the score of a single document may translate to many updates to postings lists.

In this work, we propose relaxing the total static score order to a partial order. The partial order groups postings with similar static scores into buckets. Thus, we only need to maintain order across buckets and we allow the docu-ment order inside of a bucket to be arbitrary. For example, postings inside a bucket can be stored in an increasing do-cid (document identifier) order, which need not be the same as the static score order. This allows for an efficient query evaluation, since posting lists can be joined, and for efficient indexing algorithms, since a full sort on the static scores can be avoided. Although this approach can lead to slight degradation in the quality of the returned results, we experi-mentally show that the degradation in quality is controllable and can be made negligible.
Our indexing algorithm is based on a re-merge index-update strategy, which Lester et al. [5] found to have good performance. In the re-merge strategy, new documents are added to a delta index, which can be an in-memory index. When the delta index gets to a certain size it is merged with the main index to produce the a new main index and the delta index is reset. The challenge is that using static rank to dictate inverted list order presents problems when merg-ing indexes, especially when the docid order is the same as the static score order [3]. Since docids need to be changed to reflect new static scores, a full sort of the output posting lists is required to reflect the new scores in new main index. For instance, when a single document with a high score is added to the system, most of the docids become invalid.
We now present the re-merge algorithm based on static score bucketing. The algorithm has a time complexity that is linear in the combined size of the main and delta indexes. Our algorithm uses the following in-memory structures: (i) remList : the list of documents that need to be removed, and (ii) changeTable : a mapping from the docid of docu-ments that changed their bucket to their new bucket num-ber. These structures can be readily stored in memory.
The algorithm merges, for each term t , the corresponding postings lists from the delta and the main indexes: delta[] and main[] arrays respectively. The size of these arrays is the number of buckets and delta[] and main[] contain one posting list per bucket for the given term t . These posting lists are sorted by docid. Each iteration of the main loop processes the posting with the minimum docid (line 6). If its document has been deleted, that posting entry is not added to the merged index (line 7). The output postings are parti-tioned into several output streams (the bucketPages array) based on the static score bucket of the posting document. These output stream are represented by buffer pages, which are flushed to disk whenever the they fill up. If the docu-ment in question is in the changeTable , it is redirected to the output stream corresponding to the new static score bucket (line 8). Otherwise, it remains on the output stream that corresponds to its old bucket (line 11).
We performed two main sets of experiments. The first set tested the index build performance. The second set of exper-iments tested the change in quality of the results when using inverted lists bucketing. For both sets of experiments, re-sults were compared to the baseline system with documents completely ordered by their static scores.

Experimental setup. Our scheme introduces several tunable parameters that potentially influence performance. The bucket type parameter specifies the function used for bucketing. We follow Haveliwala [4] who describes static score quantization methods in the related problem of find-ing efficient encodings of static scores. For our experiments, we used the following non-linear quantizations: logarith-mic G ( x )  X  log x , square root G ( x )  X  G ( x )  X  x b and equi-depth where each bucket contains ap-proximately the same number of documents. We also experi-mented with an additional bucketing scheme, which we refer to as adaptive. It groups documents so that the maximum difference of the static scores within a bucket does not exceed a fixed value. A second parameter that we tested is the num-ber of buckets per inverted list. Finally, we experimented with two types of static score methods: in-degree (the num-ber of hosts referring to the document) [3] and PageRank (a measure of the popularity based on the random walk model [1]).

We performed our experiments with a real-world query load from the IBM intranet: a sample of 277 unique queries out of 116,313 total queries. All the experiments were exe-cuted using the Trevi intranet search engine [3].
Experiments on indexing performance. For these experiments, we implemented the index re-merge algorithm described in Section 2. We compared the proposed algo-rithm with a re-merge algorithm based on strict static score ordering. We built an index with four buckets using all the bucket types previously described. The results for all the bucketing methods we tested were similar.

We fixed a main index for 500K documents and varied the delta index size, from 64,000 documents to 128,000 doc-uments. The results indicated that using static score buck-eting we can achieve more than 20% increase in index build performance to an already highly-optimized indexing algo-rithm. Furthermore, the results are independent of the size of the delta index being merged. Thus, a search engine us-ing static score bucketing can have an increased indexing throughput. Therefore, the search engine can update its in-dex more frequently, resulting in more up-to-date content provided to the users.

Experiments on query-results quality. These experi-ments illustrate how the query results change when we apply static score bucketing to the inverted lists. We tested how the number of inversion between the result rankings (the Figure 1: Static score = in-degree, Number of buck-ets = 64 Kendal Tau similarity measure [2]) varies with the number of scanned documents. The ground truth for our experi-ments were the results returned by the search engine using its standard total ordering of t he inverted lists based on the static score, and scanning the entire inverted lists (i.e. no  X  X arly-termination X ).

Figure 1 presents the experiments using in-degree static score and 64 buckets. The experiment compares the differ-ent bucketing types when the number of scanned postings increases. As a reference, we have also included the results with early termination when no bucketing is applied (the  X  X o-buckets X  series).

As it can be expected, the difference to the ground truth quickly decreases when the engine scans larger potions. The comparison to the reference  X  X o-buckets X  series shows that most of this difference can be attributed to the early ter-mination and not to the bucketing type. Furthermore, the figure shows that the differences between the various bucket-ing types are small. Experiments with larger values for the number of documents scanned (not presented due to lack of space) show that the differences get even smaller when larger potions of the posting lists are scanned.

The experiments with PageRank show similar trends and we do not present them due to lack of space. The differences between the tested bucketing schemes were even smaller due to the higher precision of the PageRank scores, which allows better clustering of the postings into buckets.
