 The Minimum Description Length (MDL) princi-ple is a method for model selection that provides a generic solution to the overfitting problem (Barron et al., 1998). A formalization of Ockham X  X  Razor, it says that the parameters are to be chosen that minimize the description length of the data given the model plus the description length of the model itself.

It has been successfully shown that minimizing the model size in a Hidden Markov Model (HMM) for part-of-speech (POS) tagging leads to higher accuracies than simply running the Expectation-Maximization (EM) algorithm (Dempster et al., 1977). Goldwater and Gri ffi ths (2007) employ a Bayesian approach to POS tagging and use sparse Dirichlet priors to minimize model size. More re-cently, Ravi and Knight (2009) alternately mini-mize the model using an integer linear program and maximize likelihood using EM to achieve the highest accuracies on the task so far. However, in the latter approach, because there is no single ob-jective function to optimize, it is not entirely clear how to generalize this technique to other prob-lems. In this paper, inspired by the MDL princi-ple, we develop an objective function for genera-tive models that captures both the description of the data by the model (log-likelihood) and the de-scription of the model (model size). By using a simple prior that encourages sparsity, we cast our problem as a search for the maximum a poste-riori (MAP) hypothesis and present a variant of EM to approximately search for the minimum-description-length model. Applying our approach to the POS tagging problem, we obtain higher ac-curacies than both EM and Bayesian inference as reported by Goldwater and Gri ffi ths (2007). On a Italian POS tagging task, we obtain even larger improvements. We find that our objective function correlates well with accuracy, suggesting that this technique might be useful for other problems. 2.1 Objective function In the unsupervised POS tagging task, we are given a word sequence w = w 1 ,..., w N and want to find the best tagging t = t 1 ,..., t N , where t  X  T , the tag vocabulary. We adopt the problem formulation of Merialdo (1994), in which we are given a dictionary of possible tags for each word type.
 We define a bigram HMM In maximum likelihood estimation, the goal is to find parameter estimates The EM algorithm can be used to find a solution. However, we would like to maximize likelihood and minimize the size of the model simultane-ously. We define the size of a model as the number of non-zero probabilities in its parameter vector. Let  X  1 ,..., X  n be the components of  X  . We would like to find where k  X  k 0 , called the L0 norm of  X  , simply counts the number of non-zero parameters in  X  . The hyperparameter  X  controls the tradeo ff between likelihood maximization and model minimization. Note the similarity of this objective function with MDL X  X , where  X  would be the space (measured in nats) needed to describe one parameter of the model.

Unfortunately, minimization of the L0 norm is known to be NP-hard (Hyder and Mahata, 2009). It is not smooth, making it unamenable to gradient-based optimization algorithms. There-fore, we use a smoothed approximation, where 0 &lt;  X   X  1 (Mohimani et al., 2007). For smaller values of  X  , this closely approximates the desired function (Figure 1). Inverting signs and ig-noring constant terms, our objective function is now:
We can think of the approximate model size as a kind of prior: where Z = R constant. Then our goal is to find the maximum Figure 1: Ideal model-size term and its approxima-tions. a posterior parameter estimate, which we find us-ing MAP-EM (Bishop, 2006): Substituting (8) into (10) and ignoring the constant term log Z , we get our objective function (6) again.
We can exercise finer control over the sparsity of the tag-bigram and channel probability distri-butions by using a di ff erent  X  for each: arg max In our experiments, we set  X  c = 0 since previ-ous work has shown that minimizing the number of tag n -gram parameters is more important (Ravi and Knight, 2009; Goldwater and Gri ffi ths, 2007).
A common method for preferring smaller mod-els is minimizing the L1 norm, P i |  X  i | . However, for a model which is a product of multinomial dis-tributions, the L1 norm is a constant.

Therefore, we cannot use the L1 norm as part of the size term as the result will be the same as the EM algorithm. 2.2 Parameter optimization To optimize (11), we use MAP EM, which is an it-erative search procedure. The E step is the same as in standard EM, which is to calculate P ( t | w , X  t ), where the  X  t are the parameters in the current iter-ation t . The M step in iteration ( t + 1) looks like Let C ( t , w ; t , w ) count the number of times the word w is tagged as t in t , and C ( t , t 0 ; t ) the number of times the tag bigram ( t , t 0 ) appears in t . We can rewrite the M step as
X subject to the constraints P w P ( w | t ) = 1 and P term of both summations over t separately. For each t , the term is easily optimized as in EM: just let P ( w | t )  X  E [ C ( t , w )]. But the term is trickier. This is a non-convex optimization prob-lem for which we invoke a publicly available constrained optimization tool, ALGENCAN (An-dreani et al., 2007). To carry out its optimization, ALGENCAN requires computation of the follow-ing in every iteration:  X  Objective function , defined in equation (15).  X  Constraints : g t = P t 0 P ( t 0 | t )  X  1 = 0 for  X  Gradient of objective function :  X  Gradient of equality constraints :  X  Hessian of objective function , which is not We perform this optimization for each instance of (15). These optimizations could easily be per-formed in parallel for greater scalability. We carried out POS tagging experiments on En-glish and Italian. 3.1 English POS tagging To set the hyperparameters  X  t and  X  , we prepared three held-out sets H 1 , H 2 , and H 3 from the Penn Treebank. Each H i comprised about 24 , 000 words annotated with POS tags. We ran MAP-EM for 100 iterations, with uniform probability initializa-tion, for a suite of hyperparameters and averaged their tagging accuracies over the three held-out sets. The results are presented in Table 2. We then picked the hyperparameter setting with the highest average accuracy. These were  X  t = 80 , X  = 0 . 05. We then ran MAP-EM again on the test data with these hyperparameters and achieved a tagging ac-curacy of 87 . 4% (see Table 1). This is higher than the 85 . 2% that Goldwater and Gri ffi ths (2007) ob-tain using Bayesian methods for inferring both POS tags and hyperparameters. It is much higher than the 82 . 4% that standard EM achieves on the test set when run for 100 iterations.

Using  X  t = 80 , X  = 0 . 05, we ran multiple ran-dom restarts on the test set (see Figure 2). We find that the objective function correlates well with ac-curacy, and picking the point with the highest ob-jective function value achieves 87 . 1% accuracy. system accuracy (%)
Standard EM 82.4 (Goldwater and Gri ffi ths, 2007) 85.2 our approach 87.4 Table 1: MAP-EM with a L0 norm achieves higher tagging accuracy on English than (2007) and much higher than standard EM. Table 3: MAP-EM with a smoothed L0 norm yields much smaller models than standard EM. We also carried out the same experiment with stan-dard EM (Figure 3), where picking the point with the highest corpus probability achieves 84 . 5% ac-curacy.

We also measured the minimization e ff ect of the sparse prior against that of standard EM. Since our method lower-bounds all the parameters by , we consider a parameter  X  i as a zero if  X  i  X  . We also measured the number of unique tag bigram types in the Viterbi tagging of the word sequence. Table 3 shows that our method produces much smaller models than EM, and produces Viterbi taggings with many fewer tag-bigram types. 3.2 Italian POS tagging We also carried out POS tagging experiments on an Italian corpus from the Italian Turin Univer-Figure 2: Tagging accuracy vs. objective func-tion for 1152 random restarts of MAP-EM with smoothed L0 norm. sity Treebank (Bos et al., 2009). This test set com-prises 21 , 878 words annotated with POS tags and a dictionary for each word type. Since this is all the available data, we could not tune the hyperpa-rameters on a held-out data set. Using the hyper-parameters tuned on English (  X  t = 80 , X  = 0 . 05), we obtained 89 . 7% tagging accuracy (see Table 4), which was a large improvement over 81 . 2% that standard EM achieved. When we tuned the hyper-parameters on the test set, the best setting (  X  t = 120,  X  = 0 . 05 gave an accuracy of 90 . 28%. A variety of other techniques in the literature have been applied to this unsupervised POS tagging task. Smith and Eisner (2005) use conditional ran-dom fields with contrastive estimation to achieve Figure 3: Tagging accuracy vs. likelihood for 1152 random restarts of standard EM. 88 . 6% accuracy. Goldberg et al. (2008) provide a linguistically-informed starting point for EM to achieve 91 . 4% accuracy. More recently, Chiang et al. (2010) use GIbbs sampling for Bayesian in-ference along with automatic run selection and achieve 90 . 7%.

In this paper, our goal has been to investi-gate whether EM can be extended in a generic way to use an MDL-like objective function that simultaneously maximizes likelihood and mini-mizes model size. We have presented an e ffi cient search procedure that optimizes this function for generative models and demonstrated that maxi-mizing this function leads to improvement in tag-ging accuracy over standard EM. We infer the hy-perparameters of our model using held out data and achieve better accuracies than (Goldwater and Gri ffi ths, 2007). We have also shown that the ob-jective function correlates well with tagging accu-racy supporting the MDL principle. Our approach performs quite well on POS tagging for both En-glish and Italian. We believe that, like EM, our method can benefit from more unlabeled data, and there is reason to hope that the success of these experiments will carry over to other tasks as well. We would like to thank Sujith Ravi, Kevin Knight and Steve DeNeefe for their valuable input, and Jason Baldridge for directing us to the Italian POS data. This research was supported in part by DARPA contract HR0011-06-C-0022 under sub-contract to BBN Technologies and DARPA con-tract HR0011-09-1-0028.

