 An outlier is an object that is considerably dissimilar with the re-mainder of the dataset. In this paper, we first propose the notion of centrality and center-proximity as novel outlierness measures which can be considered to represent the characteristics of all of the objects in the dataset. We th en propose a graph-based outlier detection method which can solve the problems of local density , micro-cluster ,and fringe objects . Finally, through extensive exper-iments, we show the effectiveness of the proposed method. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Clustering Graph-based outlier detection, centrality, center-proximity
An outlier is an object that is relatively dissimilar to other objects in the dataset [1]. Figure 1 shows a 2-dimensional dataset. An and thus o 1 could be considered as a normal object . The collection of these normal objects is called a cluster [2]. An object o 2 has different characteristics from normal objects, and because of this, it is positioned far away from normal objects. Such an object is considered as an outlier that is to be detected in this paper. An object o 3 has characteristics similar to a few objects neighboring it, However, the cluster is relatively far away from the majority objects in the dataset and has a very small size. In this paper, we consider o 3 and its neighbor objects as outliers, and define a micro-cluster as are positioned at the fringe of the cluster are called fringe objects . Such fringe objects need to be differentiated from outliers [3].
There are several previous methods for outlier detection such as distance-based and density-based methods [1][2][3][4][5]. These methods use their own outlierness measures for detecting outliers. They first calculate a measure score of each object in the dataset, andthenassignan outlierness score to each object based on the calculated measure score. Here, an outlierness score of an object i means how much different i is compared to other objects in the dataset. Finally, they consider the top m objects having the highest outlierness score as outliers.

The existing methods have a probl em that their outlierness mea-sures only consider the characteristics of one object , and do not consider the characteristics of the neighbor objects nor all of the objects in the dataset. Therefore, the measure score of each ob-ject is dedicated to the parameters given by users. Due to this, the problems such as the local density problem [3], inability to detect micro-clusters as outliers (micro-cluster problem) [3] arise.
In this paper, (1) we first propose the notion of centrality and center-proximity as novel outlierness measures that consider the characteristics of all the objects in the dataset. (2) We then propose a graph-based outlier detection method that calculates the outlier-ness score using two outlierness measures. Finally, (3) we verify the effectiveness of our method through extensive experiments.
The distance-based outlier detection method uses the distance among objects as the outlierness measure, and detects as outliers the objects that are distant from other objects over a specific thresh-old [5]. Here, the threshold is a user-defined parameter.
A simple but representative method for distance-based outlier detection is the DB-outlier method [4]. The DB-outlier method uses the number of other objects existing within a specific distance d as an outlierness measure. In the DB-outlier method, an object o is detected as an outlier if there are less than p objects within the distance d around o .

The outlierness measures used by distance-based outlier detec-tion methods only consider the characteristics of the object itself . This causes the local density problem [2]. Figure 2 shows a 2-dimensional dataset. Assume that we use the DB-outlier method to detect the outlier from the given dataset. For the purpose of de-tecting the object o 1 as an outlier, we may set d to d 1 . In this case, On the other hand, if we set d to d 2 in order to consider the objects
The density-based method detects an object as an outlier if the density of the object is much lower than that of its neighbor objects [2]. Here, the density of an object is generally defined as the num-ber of objects existing within a specific distance from the object.
The outlierness measure used by density-based methods only considers the characteristics of the object itself. However, during the calculation of the outlierness score of the object, the density-based methods try to consider the measure scores of its neighbor objects . Therefore, the local density problem does not occur in the density-based outlier detection m ethod. However, it still suffers from the micro-cluster problem [3].

Figure 3 shows a 2-dimensional dataset. The density of an object objects included in the same micro-cluster. Therefore, the density-based outlier detection methods ca nnot detect thos e objects in the micro-cluster as outliers.

This is due to the fact that only the neighbor objects are consid-ered when determining if an object is an outlier in the density-based outlier detection. Therefore, we may be able to solve the problem if we consider the characteristics of all the objects in the dataset when deciding whether or not an object is an outlier.
In this section, we discuss the goals of our outlier detection method along with the strategies to achieve each of the goals. The follow-ing is our list of goals in detecting outliers.
In this paper, in order to fulfill all of our goals, we propose two novel outlierness measures called centrality and center-proximity , which can consider the characteristics of all the objects in the dataset (Goal 1). This makes the measure score of an individual object is not seriously affected by parameter values given by the user. There-fore, the precision of the outlier detection less affected by parame-ter values (Goal 2).

The proposed method is composed of the following three steps. 1. Model the given dataset as a k -NN graph. Each object in 2. Calculate the centrality and center-proximity scores of each 3. Detect the top m objects having the highest outlierness score
Normally, an object that is positioned closer to the cluster cen-ter has many neighbor objects, and the distances to its neighbor objects are very small. On the other hand, in case of an outlier, there are very few objects that are close to it. In this paper, in order to measure such characteristics of objects, we propose two novel outlerness measures called centrality and center-proximity .
In this paper, we model a dataset as an integrated graph . Thanks to the integrated graph, the characteristics of an object can be trans-ferred to those of other objects. The given dataset can be mod-eled with various graph forms. However, we recommend the k -NN graph for modeling the dataset. In Section 5, we discuss different graph modeling schemes on the outlier detection.

The centrality score of an object p indicates how much other ob-jects recognize p as the center of their cluster. The center-proximity score of an object p indicates how much close p is to objects located in the cluster center. The centrality score of an object p increases when (1) the number of the objects that recognize p as their neigh-bor increases, (2) the center-proximity scores of the objects that recognize p as their neighbor increase, and (3) the distances from p to the objects that recognize p as their neighbor decrease. The center-proximity score of an object p increases when (1) the num-ber of the objects that p recognizes as its neighbor increases, (2) the centrality scores of the objects that p recognizes as its neighbor in-crease, and (3) the distances from p to the objects that p recognizes as its neighbor decrease.

The two scores are computed by referring to each other in an iterative way as shown below. Center _ P roximity i ( p )= where, In ( p ) is the set of objects that point to p ,and Out edge from p to q . Z Out ( q ) and Z In ( q ) are normalization factors; Z
Out ( q ) is the sum of all weights assigned to the edges from q to out-link objects, while Z In ( q ) is the sum of all weights assigned to the edges from in-link objects to q .

The centrality and center-proximity scores have the following properties. First, the two scores have a mutual reinforcement rela-tionship . The centrality score of an object increases if it is pointed to by many other objects having high center-proximity scores. Sim-ilarly, the center-proximity score of an object increases if it points to many objects having high centra lity scores. Second, the central-ity and center-proximity scores of an object have influence on its neighboring objects in the amount proportion to the weights on the edges. This means that an object has a larger effect on a closer object to itself than a remote object.

The detailed procedure for calculating the two scores is as fol-lows. As the number of iterations (MAX_ITERATIONS) increases, the mutual reinforcement relationship between the two scores en-ables them to more clearly differentiate normal objects and outliers. Therefore, we recommend to compute the centrality and center-proximity scores of all objects repetitively until they converge. DO Assign initial value  X 1 X  to the two scores for all objects FOR i from 0 to MAX_ITERATIONS by 1 { FOR j from 1 to NUM_OF_TOTAL_OBJECTS by 1 { } } DO Normalize the sum of centrality scores of all objects to 1 DO Normalize the sum of center-proximity scores of all objects to 1 Figure 4: Procedure of calculating the centrality and center-proximity scores.

The centrality and center-proximity scores of an object p is af-fected by those of the neighbor objects of p . Also, the centrality and center-proximity scores of neighbor objects of p will be affected by those of their neighbor objects. This relationship is defined recur-sively, and finally, the centrality and center-proximity scores of p can be affected by all the objects in the dataset. Therefore, the pro-posed outlier detection method can solve the problems of existing outlier detection methods such as the local density problem and micro-clusters problem.

The proposed method uses the inverse number of the converged center-proximity score of each object as the final outlierness score. This is due to the fact that fringe objects and outlier objects can be clearly differentiated by the center-proximity score instead of the centrality score. Both fringe objects and outliers are located at the outside boundary of the cluster, and thus, are not frequently recognized by the cluster center. Therefore, they finally have low centrality scores. However, fringe objects are located closer to the cluster center compared to outliers, and thus, tend to have a higher center-proximity score than outlier objects.

Figure 5 shows the centrality and center-proximity scores as-signed to each object on the 2-NN graph where edge x  X  y in-dicates x thinks y is its neighbor and the thickness of each edge indicates how much close the two nodes are located. The object c has the highest centrality and center-proximity scores because it is close to the cluster center. As the fringe object d and the outlier object a do not have any objects that recognize them as the cluster center, their centrality scores are 0. However, d has a higher center-proximity score than a because it is closer to the cluster center. Figure 5: Centrality and center-proximity scores assigned to objects in a 2-NN graph.
The edges in the graph indicate the neighbor relationships among nodes which directly affect the centrality and center-proximity scores of their incident nodes. We considered and analyzed the effect of three graph modeling schemes of (1) a complete graph, (2) an e -NN graph, and (3) a k -NN graph on our outlier detection method. Through our extensive analysis, we chose the k -NN graph for our method.

In the k -NN graph, the out-degree of every object is identical but the in-degree of each object could be different depending on the distribution of its neighbor objects. The objects that exist near the cluster center tend to have higher in-degrees, and thus have higher centrality and center-proximity scores. On the other hand, the objects existing near the outside or the outlier objects tend to have smaller in-degrees, and thus have low centrality and center-proximity scores.

In case of fringe objects, they point to more objects near the cluster center than outliers do, and therefore, they have a higher center-proximity score than outliers. This makes it possible to dif-ferentiate fringe objects from outliers in the k -NN graph. Through experiments, we verified that the k -NN graph modeling scheme has a higher precision compared to other graph modeling schemes (in Section 6.3).
For experiments, we used four 2-dimensional synthetic datasets used in Chameleon [6]. The Chameleon datasets are composed of 8,000, 8,000, 8,000, and 10,000 objects, respectively. We used pre-cision as our evaluation metric. The ground truth for the precision was constructed by five human experts. Objects chosen to be out-liers by the majority of five human experts were decided as outliers.
We conducted a simple toy experiment first to show that the pro-posed method can solve all of the problems occurring in existing outlier detection methods. For th is, we generated a synthetic 2-dimensional dataset composed of 266 objects and 29 outliers.
The result of detecting 29 outliers with the highest outlierness scores using our method are shown in Figure 6. Here, the dataset was modeled as a 10-NN graph.
 Figure 6: Result of the proposed outlier detection method.
In Figure 6, the objects marked with the cross (green color) are normal objects, and marked with the square (red color) are the out-liers detected by the proposed method. The results show that the proposed method (a) does not suffer from the local density prob-lem and (b) the micro-cluster problem, and (c) can differentiate between fringe objects and outliers.
In this experiment, we first modeled four Chameleon datasets as (1) a complete graph, (2) an e -NN graph, and (3) a k -NN graph. Then, we measured the average precision of our method with a varying parameter e of the e -NN graph from 0.5% to 10% by 0.5% of the longest distance between two objects in the dataset, and with a varying parameter k of the k -NN graph from 0.5% to 10% by 0.5% of the number of total objects in the dataset, respectively.
Figure 7 shows the results. The x -axis indicates the parameter value of each modeling scheme and the y -axis does the precision. The k -NN graph shows the highest precision in all cases, and shows less fluctuation of the precision occurred by the parameter change compared to the e -NN graph. The complete graph shows the lowest precision. In case of the e -NN graph, the fluctuation of the preci-sion is very large occurred by the change in e .

Figure 7: Precision with varying graph modeling schemes.
In this experiment, we measured the average precision of three different outlier detection methods, k -Dist [5] (distance-based), LOF [2] (density-based), and the proposed method. For this, we used four Chameleon datasets. The parameters for previous methods were set to the same values as their papers that showed the best precision for each dataset [2][5].

Table 1 shows the results. The proposed method which considers the distribution of all objects in the dataset provided the best aver-age precision. The density-based outlier detection method (LOF) which considers the influence of the neighbor objects showed a higher precision than the distance-based outlier detection method ( k -Dist) which only considers the influence of the object itself. The contributions of the paper are summarized as follows: (1) We have proposed the notion of cen trality and center-proximity as novel outlierness measures that consider the characteristics of all the objects in the dataset. (2) We have proposed a graph-based outlier detection method that solves the local density problem and the micro-cluster problem, and differentiates the fringe objects and outlier objects. (3) We have analyzed the effect of graph modeling schemes on outlier detection. (4) We have verified the effectiveness of the proposed method by conducting extensive experiments.
This research was supported by (1) Semiconductor Industry Col-laborative Project between Hanyang University and Samsung Elec-tronics Co. Ltd., (2) the MKE (The Ministry of Knowledge Econ-omy), Korea, under the Convergence-ITRC (Convergence Informa-tion Technology Research Center) support program (NIPA-2012-H0401-12-1001) supervised by the NIPA (National IT Industry Pro-motion Agency), and (3) the MKE, Korea and Samsung Electronics Co., Ltd., under IT/SW Creative research program (NIPA-2010-C1810-1003-0007) supervised by the NIPA. [1] C. Bohm et al.,  X  X oCo: Coding Cost for Parameter-Free [2] M. Breunig et al.,  X  X OF: Identifying Density-based Local [3] S. Papadimitriou et al.,  X  X OCI: Fast Outlier Detection using [4] E. Knorr, R. Ng, and V. Tucakov,  X  X istance-based Outliers: [5] S. Ramaswamy, R. Rastogi, and K. Shim,  X  X fficient [6] G. Karypis, E. Han, and V. Kumar,  X  X hameleon:
