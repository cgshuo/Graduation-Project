 1. Introduction
Millions of people use Web search engines everyday to find information. Therefore, the performance capa-ing and the overlap among results for the same queries. Research by Ding and Marchionini (1998) first ries. Lawrence and Giles (1998) also showed that any single Web search engines indexes no more than 16% of acteristics of Web search engines and how their content collections are not the same.
In what ways do Web search engines differ from each other? Currently, we know that Web search engines differ from one another in three primary ways X  X rawling reach, frequency of updates, and relevancy analysis.
The Web is very large and millions of new pages are added every single day. Fig. 1 shows the number of tex-tual documents indexed from December 1995 to September 2003 ( Search Engine Watch, 2005 ).
Today, there are many Web search engine available to Web searchers. comScore Meta Metrix (in press) reported over 166 search engines online in May 2005. Today the indices continue to grow and Table 1 shows where the indices stood as of November 2004 ( Search Engine Watch, 2004 ).
 one time.

To further extend our knowledge of Web search engine differences, this paper reports the results of a major study examining the overlap among four major Web search engine for results retrieved for the same queries. Dogpile.com. Metasearch engines query multiple Web search engines concurrently for the same query, com-
Ask Jeeves, Google, MSN Search, and Yahoo! Together, these Web search engines comprise 89.3% of all Web searches conducted in the United States ( comScore qSearch Data, April 2005 ).

Why is the study of Web search engine overlap important? Recent studies by the Pew Internet and Amer-ican Life Project (2005) show that many people do not understand the capabilities of Web search engines. Some 84.1% of people online use a Web search engine every month to find information ( comScore Media
Metrix, May 2005 ). Web searching is also the second most popular online activity, behind email, according to Pew Internet study of Web search engine users ( Pew Internet and American Life Project, 2005 ). Further large-scale studies, such as the one we report, are essential in helping users, Web search companies and researchers understand more about what Web search engines actually accomplish, including the differences commercial Web search engines allow for robust and scalable results often lacking in previous studies.
The next section of the paper situates our study within the previous research investigating Web search engine results overlap. 2. Related studies 2.1. Overlap studies Web research is now a major interdisciplinary area of study, including the modeling of user behavior and have evolved as an important area of Web research since the mid-1990s. In their 1998 study, Ding and Mar-chionini first identified aspects of the low overlap among the results from the Web search engines InfoSeek,
Lycos and Open Text. Gauch, Wang, and Gomez (1996) also found that a metasearch engine returned the highest number of links judged relevant.

Bharat and Broder (1998) had measured the size of the Web and overlap between the Websites indexed by the HotBot, Alta Vista, Excite and InfoSeek search engines. They estimated the size of the Web in November 1998, Lawrence and Giles found that Web search engine coverage of the Web was low and any single Web search engines indexed no more than 16% of all Websites.

In 1999, Chignell, Gwizdka and Bodner found little overlap in the results returned by various Web search ferent means of matching queries to relevant items and have different indexing coverage. Subsequently, the design and performance of metasearch engines became an ongoing area of study ( Buzikashvili, 2002; Chignell, relevant results. Gordon and Pathak (1999) studied five search engines and measured overlap at document cut-Web search engine.

Nicholson (2000) replicated the 1998 Ding and Marchionini study and found similar results and low Web search engine overlap. Hood and Wilson (2001) also found a low overlap amongst bibliographic databases.
Ferreira, da Silva, and Delgado (2004) stated that studies have shown that documents retrieved by multiple information retrieval (IR) systems in relation to the same query are more likely to be relevant. Mowshowitz and Kawaguchi (2005) examined the difference between Web search engine results from an expected distribu-tion. Egghe and Rousseau (2005) analyze IR system overlap from a mathematical perspective and Bar-Ilan (2004) discusses a statistical comparison of overlap in Web search engines.
 While search engine performance studies show little overlap in retrieval, user research has shown that most engine overlap should focus initially on the first page of results retrieved.

In summary, previous studies have produced some consistencies in relation to Web search engine perfor-indexed and algorithms applied to queries. However, most Web search engine overlap studies were performed results from large and current study of Web search engine overlap using four major Web search engines X  X sk
Jeeves, Google, MSN Search, Yahoo! and in comparison to the metasearch engine Dogpile.com using a large set of queries. The study is a collaboration research project between the Web search industry company Info-space, Inc who provides the meta-search Web search engine Dogpile.com, and academic researchers.
The next section of the paper outlines the study X  X  research design, including the data collection and data analysis. 3. Research goals
The goal of our research was to measure the overlap across major Web search engines. The specific research objectives of the study were to: (1) Measure the degree to which the search results on the first results page overlap (i.e., share the same (3) Measure the degree to which a metasearch Web engine, such as Dogpile.com, provides searchers with the (4) Measure any overlap change for the three Web search engines Yahoo!, Google and Ask Jeeves between
The next section of this paper discusses the methodology utilized in this study. 4. Research design 4.1. Search result overlap methodology 4.1.1. Rationale for measuring the first result page This study set out to measure the first result page of various Web search engines for the following reasons: query. Therefore, measuring the first result page captures the majority of activity on search engines.
Additionally, the first result page represents the top results that an engine found for a given query and therefore is a barometer for the most relevant results an engine has to offer. 4.1.2. How the query sample was generated
To ensure a random and representative sample, the following steps were taken to generate the query list:
Infospace powered search sites. These key phrases were picked from one weekday and one weekend day of the log files to ensure a diverse set of users. 2. Removed all duplicate queries to ensure a unique list. 3. Removed terms that are typically not processed by search engines. 4.1.3. How search result data was collected (A) Compiled the two sets of random user-entered queries from the Infospace powered network of search (B) Built a tool that automatically queried various search engines, captured the result links from the first (D) Captured the results (non-sponsored and sponsored) from the first result page and stored the following 4.1.4. How overlap was calculated
After collecting all of the data for the queries, we ran an overlap algorithm based on the URL for each 1. When the URL on one engine exactly matched the URL from one or more engines of the other engines a duplicate match was recorded for that query. up with the overall overlap metrics. 4.1.5. Explanation of the overlap algorithm
For a given query, the URL of each result for each engine was retrieved from the database. A COMPLETE result set is compiled for that query in the following fashion: Begin with an empty result-set as the COMPLETE result set.
 is contained in engine X.
 added (it is not unique), so flag the result in the COMPLETE set as also being contained by engine X (this assumes that it was already added to the COMPLETE set by some other preceding engine). the URL of the current result and the rest of the results in the COMPLETE set.

What we have after going through all results for all engines is a COMPLETE set of results, where each result in the COMPLETE set are marked by at least one engine and up to the maximum number of engines (in this case, 4). The different combinations (in engine X only, in engine Y only, in engine Z only, in both engine X and engine Y but not engine Z, etc.) are then counted up and added to the metric counts being col-lected for overlap.

The next section of the paper provides the results of our study. 5. Results 5.1. First results page 5.1.1. Mean number of results on first results page Table 2 shows the mean number of results that are similar across the first page results for the four major Web search engines for the 12,570 query set.

The mean number of search results returned on the first result page by the four Web search engines is sim-are sponsored while 73 X 82% are non-sponsored. It is important to note that these numbers are averages across the 12,570 queries. The number and distribution of sponsored and non-sponsored results on the first page of results is where the similarity of these engines ends. 5.1.2. Search result overlap on the first results page Table 3 shows that across the 12,570 queries run on the four engines returned 485,460 unduplicated results.
Of these results: 84.9% were unique to one of the four search engines (412,246), 11.4% were shared by two of the three search engines (55,515), 2.6% were shared by all three search engines (12,398), 1.1% were shared by all four search engines (5301).

These metrics are calculated at the query level and then aggregated. A result like www.ebay.com may appear of the engines for a particular query.
 5.1.3. Missed first page Web search results
Table 4 shows the number and percentage of the possible top results a searcher would have missed had they only used one Web search engine.

Using a single Web search engine only for a query means that a user misses exposure to a range of highly ranked Websites that are provided on the first page of results retrieved to any query. Table 5 below further 5.1.4. Majority of all first results page results are unique to one Web search engine Table 5 shows the first page results unique to one Web search engine.
 and ranking methodologies materially impacts the results a Web searcher will receive when searching on their first result page. 5.1.5. Majority of all first results page non-sponsored results are unique to one engine Table 6 shows the percent of first results page non-sponsored results.

Isolating just non-sponsored search results further supports the conclusion that each Web search engine has a different view of the Web. Searching only one Web search engine can limit a searcher from finding the best result for their query. 5.1.6. Yahoo! and google have a low sponsored link overlap
When looking at sponsored link overlap it makes sense to focus on Yahoo! and Google as they supply sponsored links to the majority of search engines on the Web, including MSN Search (i.e., Yahoo!) and Ask Jeeves (i.e., Google).
 Table 7 shows the sponsored overlap between Yahoo! and Google.

Yahoo! returned 34,306 sponsored links across the 12,570 queries while Google returned 30,194 sponsored tionships between Google and Ask Jeeves and Yahoo! and MSN Search. Through partnerships, Google sup-plies Ask Jeeves with a feed of their advertisers that Ask Jeeves incorporates into its results page. Yahoo! ves, and Yahoo! and MSN Search.
 The sponsored link overlap for these partnerships is: Google and Ask Jeeves sponsored link overlap: 14,816 links or 20.6% [I got 25.9%].
 Yahoo! and MSN Search sponsored link overlap: 10,166 links or 17.2% [I got 20.8%].

Analyzing the sponsored links for Yahoo! and Google, the top sponsored link aggregators on the Web, this study found that the number of sponsored links returned was about the only thing these search engines had in common. Yahoo! returned one or more sponsored links for 1889 queries, which Google did not return any for 1,827 queries that Yahoo! did not return any sponsored links. This represents 14.5% of the total 12,570 queries. Almost one third (29.6%) of searches lacked a sponsored result from one of the top sponsored link aggregators.
 5.1.7. Search result ranking differs across the four search engines Table 8 shows how the search results ranking differences across the four Web search engines.
The percentage of the 12,570 queries where the following ranking scenarios were true. Note that non-spon-sored and sponsored results were measured separately because they are separated on the search results pages.
Ranking matches across all four engines (Ask Jeeves, Google, MSN Search, and Yahoo!). 5.1.8. Overlap comparison over time
The comparison of overlap among three of the Web search engines over time (April to July 2005) was examined. Table 9 shows that over time the content on search engines is unique for both sampling periods.
The overlap between Google, Yahoo! and Ask Jeeves fluctuated from April to July 2005 as the percentage of unique results on each of the Web search engines increased slightly.
 The percent of total results unique to one Web search engine grew slightly to 87.7% in July from 84.9% in April.
 The percent of total results duplicated by two Web search engines declined to 9.9% in July from 11.9% in April.

The percent of total results duplicated by all three Web search engines declined to 2.3%% in July from 3.2% in April.

Table 9 shows that across Google, Yahoo!, and Ask Jeeves the percentage change in first page search results slightly more unique in July than April. Both Yahoo! and Google conducted index updates in-between these data suggests that index updates may affect the content of a search engine and overtime this trend may continue.
 5.1.9. Dogpile.com results results for the 12,570 queries were 231,625.

Table 11 shows that the Dogpile.com total first page non-sponsored results for the 12,570 queries were 145,529.
 Table 12 shows that the Dogpile.com total first page sponsored results for the 12,570 queries were 40,786.
Results matched by two or more engines highlight the consensus that the results are of value to the query, however these only account for 15.1% of the total 485,460 links returned on the first results page. Unique have over another ( Introna &amp; Nissenbaum, 2000 ). 6. Discussion
This study has produced key findings that are important for all Web search engine users and researchers, which results to return on the first results page for any given search query. This finding confirms previous sored links between the major paid search providers.

Web search engine X  X  first page results are primarily unique, meaning the other engines did not return the same result on the first result page for a given query. The fact that no one Web search engine covers every page on the Internet and the majority of page one results are unique may contribute to the fact that almost highlight that among Google, Yahoo!, and Ask Jeeves the percentage change in first page search results chan-acteristics, such as overlap, number of queries entered, etc. are not dramatically changing over time and The results of this study also highlight the fact that the top Web search engines (Ask Jeeves, Google, MSN
Search, and Yahoo!), have built and developed proprietary methods for indexing the Web and their ranking of searchers a more comprehensive result set containing potentially relevant results from the top Web search search power of the top Web search engines may reduce the time spent searching multiple Web search engines while providing the top ranked results from the single Web search engines.

The explosion of information on the Web has created a need for online businesses to continually evolve and remain competitive. To remain competitive, online business, whether an extension of a brick-and-mortar busi-them online. Additionally, Web search engines must continually improve their technology to sort through the growing number of pages in order to return quality results to Web searchers. With 29.6% of the queries not returning a sponsored link from either Yahoo! or Google, search engine marketers should be aware of the potential missed audience by not leveraging the distribution power of both Google and Yahoo!. Those mar-keters who only optimize for, or purchase on, one Web search engine may be missing valuable audience expo-sure by not running on both networks.

The results suggest that a Web metasearch engine that uses a large number of single Web search engines gives coverage of those sites that each engine has ranked most relevant to the query. According to comScore
Media Metrix in a study commissioned by Infospace, 30.5% of Yahoo! searchers, or 19.3 million people, only searched on Yahoo! in January 2005. Similarly, 29.0% of Google searchers, or 18.7 million people only searched on Google in January 2005. Therefore, by only running ads on one of these engines a marketer would miss millions of potential customers each month. Metasearch technology that leverages the content of both
Google and Yahoo! sponsored listings can effectively bridge this gap. Since sponsored links are relevant for
A major practical implication for users is X  X now your Web search engine and know its capabilities, cov-erage and limitations. Single Web search engines have obvious strengths and weaknesses. In some circum-stances, the uniqueness of a Web search engine X  X  coverage may be useful for engine users. If they know that metasearch engines are more effective at accessing the top ranked Websites from multiple engine or that a particular search engine focuses on retrieving certain types of Websites (e.g., business, news, homepages, and requires access to good quality information and research about Web search engine capabilities. 7. Conclusion and further research
After 15 years of work, Web search is still in its infancy and technology around Web search will continue to evolve. Our study shows that different Web search engines have different capabilities and the overlap among
Web search engine results is very low. The study validates previous studies and adds new dimensions to our understanding of Web searching. Our research conducted to date has uncovered five different voices for Web search based on unique ways of capturing and ranking search results. Google is different than Yahoo! Yahoo! results of the Web. A metasearch engine also provides a unique voice that combines and filters other voices.
Further research is needed to determine additional dimensions of the overlap, across subsequent results pages and rankings of different Web search engines. Additional studies are also necessary to access the strengths and limitations of Web metasearch engines.
 Appendix A. Examples of random queries Keyword Google sponsored links Yahoo! sponsored links Sunnyside Washington death notices for June 26, 2002 10 0 Kazaa 10 0 Native American wedding decorations 10 0 Kennel fencing California southern 10 0 Outer banks realtors 10 0 Berlin flats 10 0 Retail fasterns tags 10 0 Car graffix 10 0 Apartment agencies in Berlin 10 0 Bulk mail services for real estate 10 0 Coleman solar shower 10 0 Movers south Chicago suburbs 10 0 Inexpensive good quality watches 10 0 Printing maps for wedding directions 10 0 Aluminum ceiling tiles in new jersey 10 0
Washington State University 0 11 peoplepc.com 0 11 Knockoff handbags 0 11 Replica watches 0 11 Fresno wedding services 0 10 Land cruiser gx 0 10 Mcallaster Oklahoma 0 10 Carpet cleaning saltash 0 10 Louisiana State University 0 10 Jacquelina olive oil 0 10 Port and Maine 0 10 Star wars fan site 0 10 Tylenol 0 10 Bank of America 0 10 Era productions 0 10 References
