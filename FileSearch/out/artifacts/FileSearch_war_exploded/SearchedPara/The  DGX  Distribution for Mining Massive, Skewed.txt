
Skewed distributions appear very often in practice. Unfortu-nately, the traditional Zipf distribution often fails to model them well. In this paper, we propose a new probability distribution, the Discrete Gaussian Exponential (DGX), to achieve excellent fits in a wide variety of settings; our new distribution includes the Zipf distribution as a special case. We present a statistically sound method for estimating the 
DGX parameters based on maximum likelihood estimation (MLE). We applied DGX to a wide variety of real world data sets, such as sales data from a large retailer chain, us-age data from AT&amp;T, and Internet clickstream data; in all cases, DGX fits these distributions very well, with almost a 99% correlation coefficient in quantile-quantile plots. Our algorithm also scales very well because it requires only a single pass over the data. Finally, we illustrate the power of DGX as a new tool for data mining tasks, such as outlier detection. DGX, gipf's law, rank-frequency plot, frequency-count plot, maximum likelihood estimation, lognormal distribution, out-ller detection *This author thanks the Department of Physics and the Center for Automated Learning and Discovery (CALD) at Carnegie Mellon University for their support which makes this work possible. ['This author thanks the support by the National Science Foundation under Grants No. DMS-9873442, IIS-9817496, IIS-9910606, IIS-9988876, LIS 9720374, IIS-0083148, IIS-0113089, and by the Defense Advanced Research Projects Agency under Contracts No. N66001-97-C-8517 and N66001-00-1-8936. Additional funding was provided by do-nations from Intel. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, DARPA, or other funding parties. requires prior specific permission and/or a fcc. KDD 01 San l:rancisco CA USA 
Copyright ACM 2001 1-58113-391-x/01/08...$5.00 
In countless cases we encounter skewed distributions, where a few products (or vocabulary words, or customers) are re-sponsible for most of the revenue (or occurrences, or sales), while the rest have very little individual contributions. Zipf, in his milestone book [20], proposed the distribution in which the frequency is inversely proportional to the rank of vocab-ulary words (and city populations, length of articles, income distributions and so on). Although a significant step to the correct direction, the gipf distribution often fails to model real data sets well. For example, in Figure 1, we make the "frequency-rank plot" and the "count-frequency plot" of words in the Bible. As explained in the survey section, the Zipf (or generalized-Zipf) distribution would expect the plots to be straight lines in logarithmic-logarithmic scales. 
However, we observe a clear tilting in Figure 1. Zipf him-self had observed this deviation and even had a name for it ("top concavity"), and he devoted several paragraphs in his book to justify it, whenever it appeared in a data set. 
Similar deviations are observed in many other cases, as we shall see in section 4. 
Our goal in this paper is to find a more general model. We want a distribution that would have the following attractive properties: 
The rest of the paper is organized as follows: Section 2 describes the Zipf distribution and gives the literature sur-vey. Section 3 presents our proposed method, along with the proofs and the algorithms. Section 4 gives the experiments on our real data sets, in Section 5 we give some discussion of our results and significance of our methods and Section 6 lists the conclusions and future research directions. 
First, we start with the description of the Zipf distribu-tion, and then we describe related work. 
We describe the Zipf distribution and the two Zipf "laws": the rank-frequency one and the frequency-count one. The laws are best described with an example, such as words in a book (or the Bible, as we show in Figure 1) Let V be the vocabulary size, fl the occurrence frequency of the most frequent vocabulary word, and/2 the second most frequent, and so on. 
DEFINITION 1. The rank-frequency plot is the plot of the occurrence frequency f~ versus the rank r, in logarithmic-logarithmic scales 
The rank-frequency version of Zipf's law states that 
This is typically referred to as the Zipf's law or the Zip/ distribution. In log-log scales, the Zipf distribution gives a straight line with slope -1. 
The generalized Zipf distribution (or "Zipf-like" distribu-tion) is defined as where the log-log plot can be linear with any slope. 
The second 'law', also known as the discrete Pareto dis-tribution[16], involves the "count-frequency" plot: let c s be the count of vocabulary words that appear f times in the document. The second Zipf's law states that 
There are three observations:  X  The count-frequency plot actually corresponds to the  X  It is a mathematical consequence of the first law. It can  X  In log-log scales, the count-frequency plot of a Zipf 
Despite the success and fame of the Zipf distribution, we note that, eg. in Figure 1, the words in the Bible do not follow the Zipf distribution exactly, but instead they have the "top concavity". 
For the rest of this work, we only report the 'count-frequency' (: PDF) plots for all the upcoming data sets, since the PDF is a more familiar concept than the "rank-frequency" plot, and since the two "laws" are in fact sides of the same coin. 
There are significant past attempts to model skewed dis-tributions. They form two classes of distributions: discrete and continuous. 2.2.1 Discrete distributions 
This is the class that we are most interested in, since most of the data of interest are either inherently integer-valued, or rounded-off to integers: salaries and dollar amounts are down to pennies, products sell integer counts ("1 loaf of bread"), and so on: Distribution in this class include Zipf and its variations, the Yule distribution [19], and the Pareto distribution [16]. Among these distributions, Zipf's law is most widely used because of its simple form. Zipf's law has been observed in many fields. For example, the popula-tion of cities and the rank of the population[2], the number of articles in rth largest journal versus the rank of the jour-nal[17], the surnames of 4794 people in an area in England[6] are all reported to 'follow Zipf's law. Recently, Zipf's law has been applied to research on web caching. Studies[8, 4, 18, 3] show that the number of requests the server of rank r receives versus r also has the Zipf-like behavior. 2.2.2 Continuous distributions 
Although not directly applicable, we mention them, mainly because of the "lognormal" distribution, which is extremely successful in modeling continuous data sets. The lognormal distribution [7] takes positive values, and can be generated as e x where X is a Gaussian variable. It has been used to model particle sizes in natural aggregates, dust concen-tration in industrial atmospheres, in geological applications, concentration of minerals in deposits, flood flows, weights 18 of children, automobile insurance claims, the weight dis-tribution of U.S. adult males and females (Page 238-239, [15]). Gibrat found the distribution useful to represent the distribution of size for varied kinds of "natural" economic units.(Page 238-239, [15]) 
In several cases, there are even theoretical arguments sup-porting the lognormal distribution[9, 10, 15] : For example, if we break a stick into two at a random point, and continue recursively, the length of the resulting pieces will follow a lognormal distribution. It is also considered a competitor to the Weibul distribution for lifetime distributions of man-ufactured products. In fact, it can also approximate the Gaussian distribution. (Page 238-239, [15]) 
There have been some attempts to fit this kind of skewed data with other probability distributions, such as parabolic fractal[13] and stretched exponentials[14]. These works, how-ever, are based on continuous probability distribution func-tions which are not appropriate for a lot of real world data which can only take discrete values, such as the visits to web sites, number of certain products sold in a supermarket, etc. Secondly, they estimated the parameters by fitting a curve on the rank-frequency plot in log-log scale, which we believe is statistically ad hoc. Our goal is to find a discrete distribution that will fit the PDF (a.k.a. frequency-count plot) of many, real data sets. 
However, it is unclear where we should start from: Should we try to fit a parabola in the rank-frequency plot? Or, maybe, a third degree polynomial? or a Gaussian, a sinu-soid, a spline? or something else? Or should we try all these functions on the frequency-count plot? 
A deeper question is: even if one of these functions fits in a few cases, do we have "a-priori" reasons to believe that it will fit well, in multiple settings? 
The answer to all this questions is our proposed DGX dis-tribution. Judging from the success of the lognormal (also referred to as "anti-lognormal") distribution for continuous data, we propose the following thought experiment: Con-sider a random variable, say, the duration of a web-surfing session. This is a continuous variable, and, most likely, might follow a lognormal distribution. However, we need to store it with finite accuracy, and thus turn it into an integer (number of minutes, or seconds, or hours). This is exactly the motivation behind DGX. Consider a lognormal random variable (by creating a Gaussian variable, and exponentiat-ing it); then, digitize it to the nearest integer. The same is true for everything else: salaries (digitized to penny ac-curacy), duration of hospital stays (rounded to days), body height (inches), body weight (pounds) and so on. 
There is a subtle, but important point: If the lognormal random variable becomes zero after the rounding, we omit it. This is necessary, since, e.g., we don't know how many vocabulary words have not appeared in our document. No-tice that this omission leads to the so-called "truncated" or "veiled" random variables, which are notoriously difficult with respect to their parameter estimations, in the continu-We are now ready to present our proposed discrete PDF. 
We propose a distribution with the following PDF: 
P(x = k) --A(/z, 0.) exp k = 1,2,... (4) k 20. 2 J where is a normalization constant depending on/~ and 0.. 
Proof: We first rewrite Eq.(4) as Assume that Ink &lt;&lt; Jill, the PDF becomes which reduces to generalized Zipf distribution (See Eq.(3)) with slope  X  = 1 -~/0.2. QED 
DGX works well on real data sets both when their PDF has a clear curvature and when the PDF is straight in log-log plot. with proposed models. One is to fit the frequency-rank plot the PDF with maximum likelihood estimation (MLE). We believe the second method is statistically sound, therefore we choose to use MLE to estimate parameters,/~ and 0., for DGX. If the data are xl,... , x,, the likelihood is and its logarithm, the log-likelihood is 19 
We then maximize l(/z, or) numerically to estimate parame-ters,/~ and a. For clarity, we describe DGX on the count-frequency of words in documents, but, of course, the same algorithm applies to any setting. The full algorithm is as follows, Algorithm DGX_Estimator 
Input: A sequence ("multiset') of N words w(i), i = 1,... , N 
Output: Estimated parameters,/~ and cr 1. Create an associative array word_count (as in Perl) to 2. Create another associative array y to store distinct word 3. for i &lt;-1 to N 4. wad +--w(i) 6. (* V is vocabulary size, i.e., the number of distinct 7. V &lt;--size(wcrd_ccunt) 8. for i +-1 to V 9. key +-word_count(i) 10. y(key) &lt;--y(key)+l 11. (* pare is used to pass parameters to loglikelihood 12. (*/t0 and ~0 are initial values for/z and ~ ,) 13. (* y is the count-frequency data *) 14. (* tclerance is used to set the stopping criterion *) 15. para &lt;---(/z0, ~r0, y, tolerance) 16. (* Call a maximization routine to find the optimal pa-17. [#, ~] = Maximization(loglikelihood_func, para) 18. Output [p, ~r] and exit. 
Note that we only need to go over the data set once (step 3 to 5) to obtain the frequency vector, word_cotmt, and go over the frequency vector once to obtain the count vector, y. The estimation is then carried out only on the count vector. This computation can be clone fast. 
In Step 17, we called an optimization function, e.g. frnin-search[12] in Matlab, to which we pass the function loglike-
The DGX is designed to fit a wide variety of data sets. We thus applied it to three data sets from completely different fields:  X  Text: the English Bible. There are totally about 800000  X  Sales data from a large retailer chain, in which there 
All these data sets show extremely skewed behavior, i.e., we expect to see that very few products, or web sites are re-ally popular, while most products have low sales, and most web sites have low traffic. Therefore, it is meaningless to talk about the mean, median or variance of these data. To characterize these data, we need to use some skewed distri-bution. We also observe that Zipf's Law often fails, i.e., the PDF in log-log scale shows a clear curving trend. However, DGX gives excellent fits in all cases we tested, including when the data set is very Zipf-like as well as when it devi-ates from Zipf's law very much. 
The technique we used to test the goodness-of-fit is the traditional quantile-quantile plot (qqplot). The qqplot com-pares the quantiles of two data sets. If the two data sets are from the same distribution, the qqplot should be linear and the slope should be one. We first use the original data to estimate the parameters of DGX. We then use DGX and the estimated parameters to generate a synthetic data set. Next, we make a qqplot between the real and the synthetic data sets. Then, we fit the qqplot with a straight line and compute the slope and correlation coefficient. If both are close to one, we can claim that the real data and the syn-thetic data are from the same distribution. 
We first apply DGX to text data from the Bible. The results are shown in Figure 2. We notice that the real data and the synthetic data are in agreement. The slope and the correlation coefficient of the qqplot are both very close to one, which indicates we obtain an excellent fit. 
We also apply DGX to the clickstream data. We study the count-frequency relation of the web sites and the users. The count-frequency plot of website traffic, as shown in Fig-ure 3-(a) shows a clear Zipf-like behavior, while the count-frequency plot 3-(b) of users deviates significantly from Zipf's law. However, both distributions can be fit well with DGX. 20 (a) Count-frequency plot of words in Bible. (a) Count-frequency plot of website visits. Estimated pa-rameters are (/~ = -60.35,~r = 7.68). We observe that this distribution is very Zipf-like and it has a large neg-ative p. This seems to agree with Lemma 1. but both can be modeled well with DGX 
We then applied DGX to sales data from the three largest branches of a retail chain. For each store, we use the sales data to estimate parameters p and a in our distribution. With the estimated parameters we generate a set of syn-thetic data. Then, for each branch, we make the count-frequency plot and the qqplot as in Figure 4. We notice that they have similar count-frequency plots. Their param-eters, # and ~, have similar values. As we will see later, some other stores have very different parameters and their count-frequency plots have different shapes. 
From Figure 4, we observe an excellent fit between the synthetic data and the real data. In the count-frequency plot which is clearly not a straight line, DGX gives a nice fit. We also observe that the slope and correlation coefficient of the qqplot are very close to one, which also indicates the data is expressed with DGX very well. service of monthly usage volumes, broken down by customer. 
We used three instances of this data, each from a different geographic region, which we refer to as Region A, Region 
B, and Region C. Following the same procedures, we obtain well with DGX. described above, exist in many fields of natural and social sciences. They are not represented well using standard sta-tistical aggregates such as mean, median, or extrema. For example, most words appear only once in Bible while a few common words appear very often. The mean is 63.0, the median is 3, the maximum is 63924, and the minimum is 21 i to' qqplot of real and synthetic data for store no. 96 qqplot of real and synthetic data for store no. 82 qqplot of real and synthetic data for store no. 101. Count-frequency plot of real and synthetic data for Re-gion A./~ = -0.712 and ~ = 1.450. Count-frequency plot of real and synthetic data for Re-gion B./~ = -0.420 and ~ = 1.387. Count-frequency plot of real and synthetic data for Ke-gion C./~ ---0.64 and o" -: 1.418. excellent fit. 23 
Figure 6: Scatter plot of/~ and a of all branches of a retail chain. We clear see stored No. 4 and No. 31 are outliers compared to the majority. 1. These aggregates do not give a sense of the distribution; for example, they do not indicate how the i-th frequency is related to the (i+l)-th frequency. We therefore propose a new discrete distribution, DGX, which seems to be an ex-cellent tool to model skewed data. The features we obtain with DGX are p and a, which can be used for data mining, such as clustering or outlier detection. 
To illustrate the data mining power of DGX, we apply it to the sales data of all branches of the retail chain and obtain a (p, a) pair for every store. In Figure 6, we make a scatter plot of (/~, a) pairs and mark a few outlier stores according to the parameters. Notice that store No. 4 and No. 31 are outliers in (/~, a) plane. 
Figure 7 gives the count-frequency plots for these two as well as some other "mainstream" stores. It is clear that No. 4 and No. 31 have more linear plots while the others have curving plots. Moreover, closer inspection shows that these two have smaller sales volume. This shows that the outlier detection in (p, a) indeed successfully discovered some stores with "abnormal" distribute sales data. 
Skewed distributions appear very often in practice. They are often modeled well by "power" laws such as the (gen-eralized) Zipf distribution. However, they often suffer from deviations, like 'top-concavity'. 
The main contribution of this work is an alternative dis-crete distribution called DGX, which has the following fea-tures:  X  It includes the Zipf and generalized Zipf distributions  X  It is related to the "lognormal" distribution, which  X  It models several discrete, real-life distributions, from 
We provided a statistically sound method to estimate the parameters, using the Maximum Likelihood Estimation, and we showed how to use DGX to find patterns and outliers in a collection of many skewed distributions, like branches that have clearly different patterns than the rest. 
The /~ and ~ parameters of DGX are valuable for clus-tering and detecting outliers, because they constitute con-cise, but accurate "features" of a discrete distribution X  In contrast, for skewed distributions, the obvious 'features' of mean, median, minimum, maximum, and variance are prac-tically useless: The minimum value is almost always '1'; the maximum value (eg., the salary of the Queen of England in a data set with salaries) is so large and so unrelated to is 'high-jacked' by the few outliers; the standard deviation tends to infinity, because of the so-called "heavy-tail" prop-erty of the Pareto-like distributions; and the median is low, but it still fails to convey much information about the rest of the distribution X  
Given the success of DGX in modeling 1-dimensional PDFs, future work could focus on extensions of it for higher dimen-sionalities. 
The authors would like to thank the anonymous retailer chain, the anonymous Internet Service Provider and AT&amp;T for providing us their properly anonymized data. We also like to thank Dr. Bill Eddy and Dr. Alan Montgomery for some useful discussions and suggestions. [1] L. Adamic. Zipf, power-laws, and pareto -a ranking [2] B. Berry and W. Garrison X  Alternate explanations of [3] L. Breslau, P. Cao, L. Fan, G. Phillips, and [4] A. B. C. Cunha and M. CroveUa. Characteristics of [5] C. Faloutsos and H. Jagadish. On B-tree indices for [6] W. Fox and W. Lasker. The distribution of surname [7] Galton. The geometric mean in vital and social 24 25 
