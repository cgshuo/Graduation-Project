 We propose a two-stage lossless compression approach on large scale RDF data. Our approach exploits both Repre-sentation Compression and Component Compression tech-niques to support query and dynamic operations directly on the compressed data.
 H.3.2 [ Information Systems Applications ]: Information Storage and Retrieval X  Information Storage ;E.2[ Data ]: Data Storage Representations RDF Graph, Semantic Web, Compression The movement of Linked Open Data aims at providing Web data in a standard format (i.e., Resource Description Framework) which can be accessed, manipulated and un-derstood automatically by machines. With increase of data providers taking actions on publishing their data in RDF format, the volume of RDF data is booming. As a result, efficiently managing scalable RDF datasets becomes a crit-ical challenge. Reducing the size of RDF datasets is one approach to achieve scalability. Most current RDF storage systems (i.e., triple-stores) are developed based on relational database (e.g., [4]). Recently, graph-based RDF systems are proposed (e.g., [6]). However, few efforts have been devoted to compressing RDF datasets. Current RDF compresssion approaches can be classified into two groups: i) Representa-tion Compression (e.g., [1]), which focuses on reducing the size of RDF datasets by modifying their representations; and ii) Component Compression (e.g., [2]), which concentrates on eliminating redundant triples.

We propose a two-stage lossless compression approach that exploits both compression techniques. Our method supports querying and dynamic operations directly on the compressed datasets. To the best of our knowledge, there is no exist-ing solution that achieves both compression and dynamic operations on very large RDF datasets.

In the first stage, we compress the representations of RDF triples. Inspired by [1], we leverage Dictionary Encoding principles and decompose an RDF dataset into two com-ponents: Dictionary and Triples. We propose to use Dy-namic FM-Index [5] to represent the dictionary and choose the graph-based representation of the RDF dataset for the triple part. Two-level adjacency lists will be used to repre-sent triples. Specifically, subject representation is omitted by ordering its corresponding predicates list and objects list sequentially. A succinct data structure, wavelet tree [3], can be used to represent the predicates and objects sequences, as this data structure can achieve nH 0 ( S )+ O ( n )bitsstor-age and O (1 + lg |  X  | /lglgn ) query time, where H 0 ( S )isthe zero-order empirical entropy of sequence S , n and  X  are the length and alphabet of S respectively. The output of the first stage is a collection of numerical values, which serves as the input of the component compression stage. We pro-pose to use rule-based inference methods to find the redun-dant triples. Specifically, we will leverage the frequent item-set mining technique: FP-Growth algorithm to find frequent triple items. Thus the association rules are generated and re-dundant triples can be eliminated according to the rules. De-compression process simply uses rules and remaining triples to recover the eliminated ones. By leveraging the charac-teristics of self-index and succinct data structure, querying can be efficiently performed directly on the compressed rep-resentation of RDF dataset without decompressing it first. [1] M. A. Mart  X   X nez-Prieto et al. Exchange and [2] A.K.Joshi,P.Hitzler,andG.Dong.LogicalLinked [3] G. Navarro. Wavelet trees for all. Journal of Discrete [4] T. Neumann and G. Weikum. The RDF-3X Engine for [5] M. Salson et al. Dynamic extended suffix arrays. [6] K. Zeng, J. Yang, H. Wang, B. Shao, and Z. Wang. A
