 This paper introduces a family of link-based ranking algorithms that propagate page importance through links. In these algorithms there is a damping function that decreases with distance, so a direct link implies more endorsement than a link through a long path. PageRank is the most widely known ranking function of this family.
The main objective of this paper is to determine whether this family of ranking techniques has some interest per se , and how dif-ferent choices for the damping function impact on rank quality and on convergence speed. Even though our results suggest that Page-Rank can be approximated with other simpler forms of rankings that may be computed more efficiently, our focus is of more spec-ulative nature, in that it aims at separating the kernel of PageRank, that is, link-based importance propagation, from the way propaga-tion decays over paths.

We focus on three damping functions, having linear, exponential, and hyperbolic decay on the lengths of the paths. The exponential decay corresponds to PageRank, and the other functions are new. Our presentation includes algorithms, analysis, comparisons and experiments that study their behavior under different parameters in real Web graph data.

Among other results, we show how to calculate a linear approxi-mation that induces a page ordering that is almost identical to Page-Rank X  X  using a fixed small number of iterations; comparisons were performed using Kendall X  X   X  on large domain datasets.
 Categories and Subject Descriptors: H.4.m [Information Sys-tems Applications]: Miscellaneous General Terms: Algorithms.
 Keywords: Link analysis, Link-based ranking, Web graphs.
While traditional Information Retrieval (IR) methods are used by web search engines to some extent, the web is much more mas-sive, dynamic and less coherent than traditional text collections [2].  X 
Partially supported by MIUR COFIN Project  X  X inguaggi formali e automi X .
 Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00.
 While for any given topic there might be thousands or even millions of pages available, the problem of ranking those pages to generate a short list is probably one of the key problems of Web IR, and this requires some kind of relevance estimation.

One of the measures of importance of a scientific paper is the number of citations that the article receives. Following this idea, several authors proposed to use links for ranking web pages [28, 21, 25]; however, it quickly became clear that just counting the links was not a very reliable measure of authoritativeness (it was not in scientific citations either), because it is very easy to manipulate in the context of the web, where creating a page costs nearly nothing.
The PageRank technique, introduced by Page et al. [31], actu-ally tries to mend this problem by looking at the importance of a page in a recursive manner:  X  X  page with high PageRank is a page referenced by many pages with high PageRank X . The algorithm not only counts the direct links to a page, but also includes indirect links. The same is valid for scientific and bibliographic citations in general.

PageRank is a simple, robust and reliable way to measure the importance of web pages, has a clear interpretation as a Markovian process, and can be computed in a very efficient way. For these reasons, most of today X  X  commercial search engines are believed to use it as a part of their ranking function. In this paper we:
The rest of this paper is organized as follows: Section 2 intro-duces the notion of functional ranking, Section 3 describes three damping functions, Section 4 compares them analytically, and Sec-tion 5 experiments with different parameters for each function. Fi-nally, the last section presents our conclusions.
In this section, we introduce the notion of functional ranking , a general family of ranking functions that includes PageRank. To describe PageRank formally, we consider a web graph of N pages. Let A N  X  N be the adjacency matrix in this graph, a i , j is a link from page i to page j . This link matrix is seldom used as it is, mainly for two reasons:
Normalization. In the Web, creating an out-link is free, so there is an incentive for web page authors to create pages with many out-links; this is the reason why a metaphor of  X  X oting X  is enforced [26] in which each page has only one  X  X ote X  that has to be split among its linked pages. This is typically done in link-based ranking by normalizing A row-wise: the normalization process means that every web page can only decide how to divide its own score among the pages it leads to, but it cannot assign more score than it has. Another way to look at normalization is that the matrix is turned into the transition matrix of a stochastic process.

The normalization does not need to give each out-link the same value, as there is evidence that web links have different purposes such as navigating in a multi-page set, expanding the contents of the current page, pointing to another resource, etc. [17]. Also, links within the same site can be considered self-links and as such do not confer as much authority as a link between different sites; indeed, there are ranking methods like BHITS [6] that treat them differ-ently. Other characteristics of links, such as the exploration level at which they appear in Web sites [27], or if they are at the begin-ning or the bottom of individual pages, or inside a certain HTML element, can also be used for non-uniform normalization [3].
To simplify our treatment, we will assume uniform normaliza-tion, so if a page has d out-links, each of those links has a weight of 1 / d , but the results of this paper can be applied to other forms of normalization.

Dangling nodes. Special attention should be paid to the possible presence of nodes with no outgoing arcs (known as  X  X inks X  in graph theory): in fact, dangling nodes fail to produce a row-stochastic matrix, because the rows of dangling nodes are filled with zeroes. Dangling nodes can be dealt with by adding an extra node that is linked to and from all other nodes, or by introducing new arcs from each dangling node to every node in the graph [14]. In our analy-sis, we shall assume that all dangling nodes have been eliminated already in some way, so that we do not have to worry about their presence. All the algorithms we will present can be modified so that dangling nodes can be dealt with explicitly and with virtually no additional cost.

Let P be the row-normalized link matrix of the graph with N nodes. PageRank r (  X  ) is defined as the stationary distribution of the Markov chain with state transitions given by the matrix where  X   X  [ 0 , 1 ) is a parameter called damping factor (sometimes also called a dampening factor), and v is a fixed preference vec-tor that may represent the interests of a particular user, or another ranking vector that is used for weighting pages. Note that the above matrix is ergodic (at least, if every entry of v is strictly positive), so it has exactly one stationary distribution. Even though most of our results can be easily restated with a non-uniform preference vector v , for the sake of clarity we shall only consider the uniform prefer-ence 1 / N in the rest of the paper.

As observed in [15, 8], the PageRank vector r (  X  ) can be written as: or in matricial form:
There is an equivalent, and actually very intriguing way of rewrit-ing this formula, mentioned in [30] that leads to a conclusion simi-lar to those of [10]: given a path, that is, a sequence of edges in the graph p = x 1 , x 2 ,..., x k , such that node x i is connected to node x 1 , we define its branching contribution as follows where d j is the outdegree, this is, the number of outgoing arcs, of node x j .

Then, the ranking of node i according to PageRank is where Path (  X  , i ) is the set of all paths into node i and branching contributions of all paths of length t from i to j , as one can easily show by induction on t (a path of length 0 and branching 1 is also included in the summation). This way of expressing the PageRank of a node is interesting, because it highlights the fact that the rank of a node is essentially obtained as a weighted sum of contributions coming from every path entering into the node, with weights that decay exponentially in the length of the path.
A natural generalization of this idea consists in taking into con-sideration a ranking R of the general form: or equivalently where the damping function is a suitable choice of weights.
We call this form of ranking a functional ranking as it is para-metrized by a damping function. This generalizes Lifantsev X  X  [26] model in which the damping factor is a matrix of voting trust that is fixed during the computation, while in our case, this depends ex-plicitly on the iterations. Our damping function could be even more general by using D ( t ) , a damping matrix instead of damping in this paper we analyze only the latter form. Fogaras [15] pro-posed using decreasing link weights depending on path lengths in the reverse link graph, and used exponentially decreasing weights as in PageRank for finding good Web browsing  X  X tarting points X  in the Web graph. Another, yet unexplored, possible direction would be to consider damping functions that depend on other properties of the paths (e.g., whether the path passes through some node out of a certain set) rather than on their length.

As we have seen, generic PageRank is a functional ranking where the damping function decays exponentially fast (something similar was first considered in citation analysis back in 1953! [22]). The next section shows several functional rankings by describing their damping functions.
Formula (1) defines a form of ranking that is parametrized by a damping function; the latter describes how rapidly the importance of paths decays as the path length increases. A first, if only formal, problem is establishing which class of damping functions generates well-defined functional rankings.

T HEOREM 1. Every damping function such that the sum of damp-ings is 1 yields a well-defined normalized functional ranking. Proof. As shown in [10, Corollary 2.4], for every pair of nodes i and j , and for every length t In other words, the sum of branching contributions of all paths of a certain length between two specific nodes does never exceed 1. A more general property holds (the proof is an easy induction on the path length): for every node i and every length t As a consequence, to guarantee that the functional ranking is well-defined and normalized (i.e., that rank values sum to 1) we need: or equivalently alent to
Of course, not all choices are equivalent, so we have to find out which functions generate better rankings. Since a direct link should be more valuable as a source of evidence than a distant link, we focus on damping functions that are decreasing on t , the length of the paths.

Computation. For calculating functional rankings, we use the general algorithm shown in Figure 1; the next sections provide de-tails on the initialization, stop condition and iteration steps for each calculation.
 Require: N: number of nodes, v : preference vector 1: for i:1 ... N do { Initialization } 2: S[i]  X  R[i]  X  START 3: end for 4: for k:1 ...  X  do { Iteration step } 5: if STOP then 6: break 7: end if 8: Aux  X  0 9: for i:1 ... N do { Follow links in the graph } 10: for all j such that there is a link from i to j do 11: Aux[j]  X  Aux[j] + R[i]/outdegree ( i ) 12: end for 13: end for 14: for i:1 ... N do { Add to ranking value } 15: R[i]  X  Aux[i]  X  DAMP(k) 16: S[i]  X  S[i] + R[i] 17: end for 18: end for 19: return S Figure 1: Template algorithm for computing a functional damping. START, STOP and DAMP(k) differ for each func-tional ranking.
As we already noted, PageRank can be seen as a functional rank-ing where the damping function decays exponentially: Since longer paths have less importance in the calculation of PageRank, it could be approximated by using only a few levels of links. In [11], it is shown that by using only the nodes at distance 1 from a target node (equivalent to linear damping with L = Rank values can be approximated with 30% of average error. Using nodes at distance 2, the average error drops to 20% and at distance 3, to 10%. After that, there are no significant improvements by adding a few more levels, and the cost (the number of nodes to be explored) is much higher.

Computation. Since PageRank is the principal eigenvector of the modified graph matrix, it can be easily approximated by the iter-ative Power Method algorithm, as suggested by Page et al. in their original paper [31]; this iterative algorithm gives good approxima-tions (both in norm and with respect to the induced node order) in few iterations, even though convergence speed and numerical sta-bility decay when  X  gets close to 1 [19, 18].
As an (extreme) alternative to PageRank, let us consider a simple damping function such as: that is, a damping function that decreases linearly with distance, and reaches zero at distance L . The trivial case L = 1 gives a uni-form ranking, and L = 2 is ranking by indegree, as in the latter case all paths of length  X  2 are not considered.
 From the definition, provided that ( I  X  P ) 2 is not singular.

An advantage of this type of ranking is that only the first few levels are considered, so the number of iterations is fixed. The ra-tionale for this is that after a certain distance the information given by links can be disregarded.

Computation. For computing this functional ranking, we can define the following sequence:
The functional ranking with linear damping is  X  L  X  1 k = computing this ranking, the generic algorithm shown in Figure 1 can be used, with:
Recently, a ranking method called TotalRank [7] has been pro-posed. The method aims at eliminating the necessity for an arbi-trary parameter by integrating PageRank over the entire range of If r (  X  ) is the vector of PageRank, then TotalRank is defined as: T can be written as: where the first equality is obtained applying Theorem 1.27 of [33].
Provided that P is not singular and P = I , we can write TotalRank using the definition of the logarithm of a matrix:
TotalRank is a weighted sum of the scores associated with paths of varying lengths, in which the weights are hyperbolically decreas-functional ranking with damping function: which is well defined since  X   X  t = 0 damping ( t )= 1.
 Computation. It is known that the cost of calculating Total-Rank is the same as the cost of calculating PageRank via the Power Method [8], even though some more iterations are required to ob-tain the same precision.
TotalRank is part of a more general family of weighting schemes for paths of different lengths that can be approximated using:
Again, this way of ranking follows the general scheme, with damping function chosen as
Here, we are using Riemann X  X  zeta function,  X  (  X  )=  X   X  t normalization, and we need  X  &gt; 1 for it to converge. Note that when  X  = 2 we get weights similar to those of TotalRank, in which the t -th coefficient is 1 / ( t + 1 )( t + 2 ) whereas here it is 1
A meaningful choice for  X  should be done considering the dis-tribution of paths of different lengths in a scale-free graph. A large  X  in PageRank, or a small  X  in HyperRank, means increasing the effect of longer paths in the score.
 Computation. Let us define a vector sequence R ( t ) as follows:
It is easy to see that  X   X  t = 0 R ( k ) = s (  X  ) , because R algorithm of Figure 1 with the following parameters: Note that convergence speed is much slower than ordinary Page-Rank, especially when  X  is close to 1, the norm of the k -th sum-mand being bound by 1 / ( 1 + 1 / k )  X  . Interestingly enough, though, convergence speed is reasonable if  X  is sufficiently large.
An empirical damping function would consider how much the value of an endorsement decreases by following longer paths in the real web graph. This cannot be known exactly, but we can attempt similar than pages chosen at random [13]; evidence from topical crawlers [34] shows that when doing breadth-first exploring, the topic  X  X rifts X  as the distance increases. On the same line of thought, we propose to use the decrease of text similarity as an approxima-tion to an  X  X mpirical X  damping function. In [29] it is shown that text similarity and link distance are anticorrelated up to 4-5 links.
To find out which is the correlation between link-distance and similarity, we performed the following experiment: we considered a web graph corresponding to a partial snapshot of the .uk domain with 18 million pages, and sampled 200 nodes at random. For each sampled node, we followed links backwards to obtain nodes at a minimum distance of 1, 2, 3, 4, or 5 links. Then, we sampled 12,000 pairs at each minimum distance at random, and computed their similarities with the original nodes. Similarity was measured using the normalization of TF.IDF [4], without stemming or stop-word removal.

The resulting averages are shown in Figure 2, with standard de-viation error bars. Text similarity clearly decreases with distance, and in some applications the empirical distribution of text similar-ity versus distance could be used as an  X  X mpirical X  damping func-tion. Different measures of text similarity can yield different dis-tributions; for instance [36] uses the number of repeated words and phrases between pages and obtains a faster decrease in similarity. Our results show that a linear damping with L = 8or L = 9ap-proximates better text similarity than an exponential damping as suggested in [29]; also, for different communities the link structure Figure 2: Link distance vs. average text similarity. A link dis-tance of one means a direct link exists. Text similarity appears to decrease linearly in the first few levels of links. could be different (e.g. academic vs. commercial Web subsets), so we should measure first which is the correlation of link distance to text similarity in the specific collection we want to rank.
A comparison of the damping functions described in the previous section is shown in Figure 3: of course, hyperbolic damping func-tions decay asymptotically more slowly than exponential damping, but notice that for short paths the latter may dominate the former in many cases. Figure 3: Weights given by the different damping functions, for some values of  X  and  X  .

In this section, we aim at analyzing how similar are these func-tional rankings, and how we could use one of the damping functions to approximate another with a suitable choice of parameters.
Now we want to approximate the weights of: using the weights of: and we proceed again by considering paths up to a certain length:
The minimum can be zero, and it is attained at:
The  X  that minimizes the difference of weights for different val-ues of  X  and of the maximum path lengths is shown in Figure 4. In the case of  X  = 2, for instance, for path lengths up to 10 to 20, the best  X  is between 0 . 75 and 0 . 85.
For approximating the damping function of PageRank with the damping function of LinearRank, we consider the summation of the differences up to a certain path length. If  X  L : Figure 4: Best  X  for minimizing the difference of the sum of weights between PageRank and HyperRank, for various pa-rameter combinations.
 And if &gt; L :
We will assume that  X  L , so the evaluation of the difference between the two rankings is done in an area in which both rankings have non-zero values. The L that minimizes the difference for a given combination of  X  and is L (  X  , )= + and we have plotted it for different values of  X  and in Figure 5.
For our experiments, we used several snapshots from the Web, including the .uk , .it and .eu.int domains. For comparison, we also considered a synthetic scale-free network produced according to the evolving model described by Kumar et al. [24] (a combina-tion of preferential attachment and random links) with the param-eters suggested by Pandurangan et al. [32]. As far as the latter is concerned, in the generated graph the exponents for the power-law in the center part of the distributions are -2.1 for in-degree and PageRank, and -2.7 for out-degree; we generated a 100,000-nodes graph without disconnected nodes.

In this section, we study the behavior of the ranking functions for different values of their parameters. Figure 5: Best L for minimizing the difference of the sum of weights between LinearRank and PageRank, for various pa-rameter combinations.
In scale-free networks, the distances between pairs of nodes follow a Gaussian distribution [1] (the average is not given in their paper). Analytic estimations for the average distance of a graph of scale-free network of n nodes include: O [35]; O ( log ( n ) / log ( np )) in sparse graphs with p links [12]; 1 z 2 is the average number of nodes at distance 2 [30]; and O ( log ( n ) / log ( log ( n ))) [9].

We did the following experiment: starting from a node picked at random, we followed the links backwards and counted the number of nodes at different distances. The average distances found, appear to be growing (sub)logarithmically with the size of the graph. Fig-ure 6 shows the distribution obtained in each sample (the synthetic graph has less variance due to its small size). For this experiment, we are not counting the pages without in-links.

The act of linking a page represents human endorsement and of following a link, in terms of a random surfer, should be affected. However, an algorithm for propagating this endorsement through links for computing a ranking function needs to account for the typical distances involved; this need is typical in a situation where local properties have a global impact: for example, the addition of a single arc may reduce drastically the diameter of a graph. In most cases, researchers have used exponential damping with base 0.85 or 0.90 in graphs that are much smaller than the full Web (concept graphs, social networks, e-mail graphs, etc.), meaning that a po-tentially much larger fraction of the nodes contributed towards link ranking. We consider that in a smaller graph, the damping function should decay faster.

Let X  X  suppose that for a graph with N 1 nodes it is found, by ex-perimental or analytic means, that a good parameter for PageRank is 40 mill nodes; avg. dist. 14.9 18 mill. nodes; avg. dist. 14.8 .eu.int Web graph Synthetic graph 800,000 nodes; avg. dist. 10.0 100,000 nodes; avg. dist. 4.2 Figure 6: Distribution of the average number of nodes at a cer-tain distance from a given node in three Web samples and a synthetic scale-free network. with the same properties, except that the size of the new graph is N 2 &lt; N 1 . One possible approach, consistent with what we have done so far, is to consider that the sum of the weights up to the av-erage path lengths of the graphs ( L 1 , L 2 ) have to be similar for both rankings to behave in a similar way. If we take this approach: An example that can be used in practice is the following: let X  X  con-sider a web graph with N 1 = 11 . 5  X  10 9 pages (the size of the full Web estimated by [16]), and another graph with only N 2 = pages (the size of the Web of a large country); the second graph is roughly 3 orders of magnitude smaller.
 If it is shown empirically that  X   X  1 = 0 . 85 is a good value for the PageRank parameter for the whole Web, then  X   X  2 = 0 have a similar behavior in the 50-million page set, which is natural as the path lengths are shorter. If the subset of web pages were even smaller, for instance, N 2 = 10 6 pages (the size of the web of a large organization), then  X   X  2 = 0 . 76, and for smaller graphs of N nodes,  X   X  2 = 0 . 72. We recommend using these values for graphs that are not comparable in size to the full Web graph.
In this section, we present experimental results about the similar-ity between the ranking orders induced by some of the functional rankings discussed in the previous sections. To perform the ex-periments, we used data from the U.K. Web graph. To compare ranking orders, we used Kendall X  X   X  : a correlation measure related to the number of inversions in the rank order of one variable when the data is ordered according to the other variable ( perfect agreement,  X  =  X  1 means reverse ordering).

We tested the correlation of in-degree with these damping func-tions. In general the correlation drops as more levels of links are considered (we omit the details here for lack of space, they will appear in the full version of this paper). Figure 7 (a) shows how  X  PageRank compares with HyperRank for various pairs of  X  . In the limit  X  ,  X   X  1 both rankings are equivalent, and they remain similar in a large region of the parameter space. We can see that the rankings obtained with HyperRank and PageRank can be almost equivalent (Kendall X  X   X   X  0 . 95). Moreover, the analysis shown in section 4.1 considering only paths of lengths less than 5, provides a very good approximation for the optimal combination of parameters. This means that in fact, the difference in the damping functions in the first few levels is crucial.
 The exponents  X  required for giving a good approximation of PageRank are small when  X   X  0 . 7, limiting the practical applicabil-ity of HyperRank, as it does not converge more quickly than Page-Rank. As far as LinearRank and PageRank with  X  = 0 . 8 ... concerned, paths of roughly 10 to 20 links should be considered to obtain rankings that are almost equivalent, as shown in Figure 7 (b).
The predicted optimum given in section 4.2 with = 5 (i.e., con-sidering only the summation of the differences between both damp-ing functions up to paths of length 5) is very close to what was ob-tained in practice. For  X  = 0 . 8, calculating LinearRank with L (which means the same number of iterations) gives  X   X  0 .  X  = 0 . 9, calculating LinearRank with L = 15 also gives  X   X  In both cases, the ranking order of PageRank is approximated by the ranking order of LinearRank with very high precision. Precision Finally, we focused our attention on the Linear-Rank ranking that uses linear damping, to see if LinearRank with a small number of iterations can provide a ranking that is compet-itive with PageRank. With this aim in mind, we used the Web-TREC Gov2 collection (available from the University of Glas-gow for research purposes, see http://ir.dcs.gla.ac.uk/-test collections/ ). This collection consists of about 25 million documents obtained in 2004 from the .gov domain. We picked at random 50 tasks and manually created keyword queries for this evaluation, following the policy used in the standard ad hoc TREC tasks. We then used the Managing Gigabytes for Java ( mg4j ) framework to select from the collection 1000 pages matching each query according and re-ordered the query results according to the scores resulting from different link-based ranking strategies.
On this graph, the PageRank calculation took 39 iterations to converge on the L1-norm of the difference between two iterations to less than 10  X  6 . We computed the standard precision and recall measures [4] and averaged them across all queries. Precision at result number N is the fraction of correct results in the first N results returned by the system; the  X  X orrect X  results in our case are taken from the quality assessments included in this reference collection. This is shown in Figure 8.

Of course using link ranking improves the precision over no ranking at all, and PageRank and LinearRank behave very simi-larly. For instance, if we compare the PageRank (that requires 39 iterations) with LinearRank at distance 5 (that requires 5 iterations only) we observe that the precision of the first element is 8% better for PageRank, of the first five elements is 17% better for PageRank, but for the first ten elements is 2% better for LinearRank. From that point over, both rankings are roughly equivalent.

This means that LinearRank at distance 5 can provide a level of precision for information retrieval tasks that is quite similar to that of PageRank. This is applicable in contexts where link-based Figure 8: Evaluation of the precision of LinearRank and Page-Rank in the WebTREC Gov2 collection. ranking cannot be computed in advance, but a computation at query time is necessary. For instance, this occurs if we need to analyze links over a sub-graph that is generated at query time.
In this paper we have defined a broad class of link-based rank-ing algorithms based on the contribution of damping factors along all the different paths reaching a page. We found that functional rankings using different damping functions can provide similar or-derings, if the parameters are chosen carefully. LinearRank can be used for calculating a ranking that is as good as PageRank, but with a fixed, and smaller, number of iterations. Also, the parameters for the damping functions depend on the characteristic path lengths in the graph, which are known to grow sub-logarithmically on the size of the graph.

More work is needed to find other damping functions that com-pute rankings similar to PageRank but are easier and faster to com-pute. We use a global ranking similarity, but another measure could be the ranking similarity in the top 20 results of real queries. In this setting our results can change, so future work will include this variation. Our results show that the exponential damping used by PageRank is not that special.

Because of their high cost, link-based ranking methods that in-volve iterative calculations at query time are probably not used by large-scale search engines at this moment, but the functional rank-ing with linear damping we have presented can provide a good ap-proximation with few iterations. Moreover, the approach we have presented could be also applied to multivalued ranking functions such as HITS [23] and topic-sensitive PageRank [20] to obtain, for instance, a method for approximating the hubs and authority scores using less iterations and a linear damping function.

Our approach also helps to understand how easy or difficult it is to collude many pages to modify the ranking of a given page. Clearly there are many different factors: path lengths, damping function, branching degrees, and number of colluded pages. The graph structure of the collusion will affect those factors and we plan to analyze them. In particular, under the assumption that is easier to  X  X pam X  closer links, PageRank damping is more affected by collusion than the rest of the damping functions presented here. In [5] a truncated exponential damping, combined with other link-analysis techniques, is used for spam detection.

Acknowledgements : we would like to thank D  X  aniel Fogaras for a valuable discussion about TotalRank that motivated part of this research. The authors also thank the support from ICREA and the C  X  atedra Telef  X  onica at Universitat Pompeu Fabra.
