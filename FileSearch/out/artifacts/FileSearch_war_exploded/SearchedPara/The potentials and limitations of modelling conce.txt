 Oi Yee Kwong Abstract This paper explores the feasibility of modelling concept concreteness perceived by humans and representing it in computational semantic lexicons, addressing an issue at the crossroads of computational linguistics, lexicography, and psycholinguistics. The inherent distinction between concrete words and abstract words in psychology has relied mostly on subjective human ratings. This practice is hardly scalable and does not consider the effect of polysemy. In view of this, we attempt to obtain a measure of concreteness from dictionary definitions comparable to human judgement, capitalising on conventional lexicographic assumptions and the regularities exhibited in the surface structures of sense definitions. The structural pattern of a definition is analysed and scored on a 7-point scale of concreteness ratings. The definition scores turned out to be quite effective for a dichotomous distinction between concrete and abstract concepts and more consistent with human ratings for the former. Beyond the two-way distinction, however, the results were more variable. The study has thus revealed the potentials and limitations of our approach, suggesting that different defining styles probably reflect the describability of concepts, and describability alone may not be sufficient for differentiating the degree of concreteness. The range of definition patterns has to be reconsidered, in combination with other inseparable factors constituting our perception of con-creteness, for better modelling on a finer scale of concreteness distinction to enrich semantic lexicons for natural language processing.
 Keywords Concept concreteness Dictionary definitions Semantic lexicons Polysemy Computational lexicography 1 Introduction Evidence from lexical decision tasks (e.g., Bleasdale 1987 ; Kroll and Merves 1986 ) and studies on children X  X  spoken and reading vocabulary (e.g., Yore and Ollila 1985 ), amongst others, tends to suggest that concrete concepts are often easier to learn and process than abstract concepts. Psychologists have also put forth various plausible explanations, such as the dual-coding theory (Paivio 1986 ) and the context availability theory (Schwanenflugel 1991 ). The distinction between concrete and abstract concepts is apparently natural and inherent, and plays an important role in human lexical processing.

By analogy, if this common-sense phenomenon can be properly modelled in computational semantic lexicons, it should benefit natural language processing, especially those sub-tasks which draw heavily on lexico-semantic information. For example, coupled with the availability of characteristic linguistic context, concreteness may partially account for the lexical sensitivity issue observed in word sense disambiguation (Kwong 2012 ).

One major obstacle to further studying the impact of concreteness in computational linguistics is, ironically, that concreteness can hardly be understood and defined in any concrete way. Physical existence and visibility might be critical factors influencing our judgement on whether something is concrete or abstract. Other factors like familiarity, imageability, and frequency of occurrence may all have an impact too, but the effect of polysemy often escapes our attention. In reality, concreteness is often a matter of degree and our judgement is largely and inevitably subjective.

In psychology studies, concreteness (or abstractness) has often been measured by averaging human ratings (from 1 for highly abstract to 7 for highly concrete) on a sample of words (e.g., Paivio et al. 1968 ). While this practice results in first-hand data from human subjects, it is inadequate to rely on human ratings in two regards. First, it is not scalable. One can hardly ask enough human subjects to rate all words in our vocabulary. Second, the ratings do not address polysemy, and the raters may not be thinking of the same sense for a word. A word deemed concrete may possess abstract senses, and vice versa. Only if we can have a way to measure concreteness for words and senses consistent with human judgement in large scale will it be possible for us to pursue further studies on its role in natural language processing. In the current study, we investigate the feasibility of obtaining such a measure from dictionary definitions.

In addition to contact with family, peers, school, and mass media, dictionary definitions constitute a major source of lexical knowledge based on which we form our own perception and understanding of words, including whether they are concrete or abstract by various criteria. There are conventional assumptions in lexicography that concepts corresponding to tangible objects and intangible things are more appropriately defined by different styles. Based on such assumptions, in the current study we attempt to utilise the regularities exhibited in various defining styles and their corresponding surface structures for automatically inducing concreteness scores.

While this study explores a new usage of definitions, many computational lexicographic projects have used sense definitions for semi-automatically acquiring 2.3 Recognizing definition patterns from dependency relations We focus on a major kind of noun definitions in the form of  X  X  is Y X , where X is the word being defined and Y is the definition in the form of a noun phrase (NP). In many conventional dictionaries, the verb  X  X s X  might be implicit, where Y is just listed after the headword X. 3
We used the dependency parser from Lund University (Johansson and Nugues 2008 ) to analyse the structure of the definitions and detect the various definition patterns by means of the presence or absence of certain dependency relations obtained from the parse results. Figure 1 shows the dependency parse for the definition  X  X  bag is a flexible container with a single opening X . Only those parses consisting of a root (ROOT) and a predicative complement (PRD) in the form of a noun, thus corresponding to the  X  X  is Y X  form, will be of interest to us. Results with no PRD will not be further analysed.

The automatic scoring steps are shown in Fig. 2 and implemented in Java. Given the dependency parse of a definition, we first look for the ROOT (usually  X  X s X ) and its dependent PRD. If a PRD as a noun is found, it is treated as the genus and an NP definition is assumed to be identified and further processed. Subsequent analysis of an NP definition includes detecting genitives like  X  X  of Y X , checking for differentiae in the form of dependent Apposition (APPO), Location (LOC), Modifier of nominal (NMOD), Object complement (OPRD), or Temporal (TMP) to the PRD, and prototypes if such dependencies are marked by words like  X  X sually X  or  X  X ypically X . If considered a synonymous phrase. The genus is also checked if it is possibly an abstract or mass noun, which is approximated by the absence of any indefinite articles and plural marker. Hence, for the example in Fig. 1 , the PRD to the ROOT is container/NN. It is neither embedded in an  X  X  of Y X  structure nor other empty kernels like  X  X omeone X  or  X  X omething X . Therefore it is assumed to be a true kernel, corresponding to the genus. The parse result is then checked for the presence of prototype, and there is none. Nevertheless, there is a post-nominal modifier found in the form of a prepositional phrase  X  X ith a single opening X , and a pre-nominal modifier with the word  X  X lexible X . Both will add one point to the basic score, and consequently the final score would be 6 for this definition. Other kinds of PRD (such as those in the form of a verb) would simply be assigned the basic score, assuming they are mostly similar to empty kernels like  X  X omething X  or  X  X omewhere X . 3 Experiment 3.1 Resources and materials Kroll and Merves ( 1986 ) used 100 abstract and 100 concrete nouns in their lexical study. The words were rated by human subjects for concreteness on a 7-point scale. The abstract and concrete words were matched on the basis of word frequency and word length. The word frequency data were taken from Kucera and Francis ( 1967 ). For the current study, a total of 100 word samples (50 concrete and 50 abstract) with frequency greater than 20 were selected from Kroll and Merves X  list. Sense definitions were collected from WordNet, LDOCE, and COBUILD. The WordNet senses were taken as the base, and senses from the other two dictionaries were manually mapped to them.

Word senses are grouped in hierarchically organised synsets in WordNet, and each synset is associated with a simple gloss like conventional dictionary definitions (Fellbaum 1998 ). Our concrete word samples have 1 X 17 senses and the abstract ones have 1 X 9 senses, with 4.36 and 3.44 senses on average respectively. LDOCE is one of the most typical monolingual learner X  X  dictionary where words used in definitions have been confined to the 2,000-word Longman Defining Vocabulary. We only selected the senses or sub-senses which explain our word samples in isolation (not in collocation or fixed phrases). The concrete word samples have 1 X 13 senses and the abstract ones have 1 X 9 senses, with 3.9 and 3 senses on average respectively. The COBUILD series of dictionary are known for being the pioneer of corpus-based lexicography, and are distinct from others with their full-sentence definitions as mentioned earlier. Our concrete word samples thus have 1 X 13 senses and the abstract words have 1 X 10 senses, with 2.84 and 3.08 senses on average respectively.

Assuming that lexicographers would consistently apply the various defining styles as appropriate for senses of different degrees of concreteness, we hypothesise that in general the scores obtained from the definitions should follow closely human ratings on concreteness. 3.2 Method Since the ratings in Kroll and Merves ( 1986 ) are only for word-level concreteness, in this study four human raters were additionally asked to rate the selected samples on a 7-point scale (7 = highly concrete, 1 = highly abstract), first giving a score to each word as a whole, and then to the individual WordNet senses.

To automatically obtain concreteness scores from the dictionary definitions, the definitions were first parsed by the Lund University Parser and the results were analysed by the scoring method presented in Sect. 2.3 above. 4 For sense concreteness, the definition scores for individual senses were compared to the human ratings we obtained for this study. For the overall concreteness of a word, we tried two ways for estimating it from the individual senses. One is to take the average of the scores from all senses, assuming all component senses of a word contribute equally to its overall concreteness; and the other is to take the score for the first sense, assuming the most frequent or familiar sense dominates one X  X  perception of the word in general. These two measures were compared with the human ratings. 4 Results and discussion 4.1 Word-level concreteness Table 2 shows the mean and standard deviation of the concreteness ratings for the 100 word samples (and for the 50 abstract and 50 concrete samples separately). The column K&amp;M refers to the original ratings from Kroll and Merves ( 1986 ), and AvgR the average of the four human raters in this study. The columns W, L and C refer to the scores from definitions in WordNet, LDOCE and COBUILD respectively. The overall lexical concreteness estimated from the average scores of all senses and that from the score of the first sense are shown separately. LDOCE and COBUILD. This may be a consequence of the different sense orderings in the dictionaries. WordNet lists the most frequent sense first, whereas LDOCE and COBUILD are learner X  X  dictionaries and may give a more generic meaning first.
The different sets of ratings were compared with respect to the Spearman rank correlation ( q ) and the Kendall X  X  coefficient of concordance ( W ). The former measures the interdependence between two sets of scores and the latter is used for assessing the agreement among different rating sources. The human ratings (K&amp;M and AvgR) are quite strongly correlated ( q = 0.848), and the overall ranking is very much similar ( W = 0.924). The correlation between each pair of human raters in this study ranges from 0.685 to 0.802, suggesting that people do share some general idea not only on the crude distinction between concrete and abstract words, but also on the degree of concreteness. As for the definition scores, it turns out that the first sense in WordNet is relatively a better indicator of the overall word concreteness as compared to the others. It shows the best correlation with human ratings (0.301 with K&amp;M and 0.415 with AvgR, both are statistically significant), suggesting that sense frequency might play a very important if not predominant role in one X  X  perception of the concreteness of a word in general. However, in the case of polysemy, the overall concreteness of a word is not entirely determined by sense frequency. As seen in Fig. 3 , compared to human ratings, scores from first senses in dictionaries spanned a wider range across the scale with more even spread of scores, especially for abstract words. Hence, words deemed concrete may be polysemous and have abstract senses, but the first one listed is likely to be concrete; whereas words deemed abstract may also have concrete senses. While Kendall X  X  W shows at least medium agreement in the general rankings, what we can say is that many abstract words (and their first senses) are unexpectedly describable in the lexicographers X  minds. 4.2 Sense-level concreteness For the sense level ratings, we compared only the 176 senses shared by all the three dictionaries (79 from the abstract words and 97 from the concrete words). Table 3 shows the mean and standard deviation of the concreteness ratings from various sources for all senses, and separately for senses deemed concrete and abstract respectively by human raters. The mean of human ratings on the concreteness of individual senses is obviously higher than those obtained from definitions. Among the dictionaries, WordNet and LDOCE tend to result in higher concreteness ratings, while COBUILD gives a much lower mean score. Examining the distribution of scores, it is apparent that our categorisation of the surface structures of the definitions has not been able to realistically distinguish concrete concepts on a finer scale (e.g., highly concrete vs mildly concrete) and has produced many false alarms for highly abstract concepts. It is possible that the human raters are lenient on their scores, preferring concrete to abstract, but the limitation of the definition scores is also responsible for the weak association with human perception.

Unlike the word level, human ratings for individual senses show much less agreement. The correlation between each pair of human raters ranges from 0.455 to 4.3 Implications The results of the current study thus reveal the following issues which are worth further investigation. 4.3.1 Range of definition patterns Our current framework for analysing the definition patterns cannot really make full use of the whole range of scores, which is partly responsible for the lack of distinguishability between concrete and abstract concepts on a finer scale. Few definitions in our samples have both differentiae and prototype and many highly concrete meanings, mostly rated 7 by humans, may only have scored 6 from the definitions. Also, we only considered definitions in the form of  X  X  is Y X  and may have missed variant forms like  X  X ou can refer to Y as X X , which is essentially genus and differentiae expressed in a different way. Thus further work is needed for more fine-grained mapping between defining styles and surface patterns. 4.3.2 Implicit information in definitions Although the surface structure of definitions can sufficiently reveal the defining style, the precise wordings in the definitions might contain implicit information on the concreteness of a sense. For instance, the word  X  X oncept X , defined as  X  X n abstract or general idea inferred or derived from specific instances X  in WordNet has a surface form mapped to score 6, but it should probably be adjusted given that the word  X  X bstract X  explicitly appears in the definition. Hence obviously abstract meanings can also be defined by means of genus and differentiae, but the modifiers to the genus, and even the genus itself (comparing  X  X un X  as  X  X  disposition X  and  X  X ibrary X  as  X  X  depository X ), might suggest a subtle difference. While the surface structures may be related to some aspect of concreteness depending on how describable a meaning is, they are inseparable from the semantics of the definitions which reflects other aspects constituting the judgement of concreteness. On the one hand, how much one may draw from the precise wordings for differentiating between concrete and abstract concepts, to a certain extent, depends on the quality of the definitions written by lexicographers for individual dictionaries. On the other hand, it might even be too simplistic to view concreteness on a simple one-dimensional scale. For instance, attitude or cognition are apparently intangible and much more abstract than physical entities, but some concepts falling under attitude may still be more describable than others, and some concepts, though with physical existence, might be less describable than others. Hence, while it is probably inadequate for just a dichotomous concrete/abstract distinction as in some existing resources, such a two-way distinction may provide a good starting point for further study. More detailed analysis and comparison could be done on the sense definitions extracted from the branches under  X  X hysical entity X  and  X  X bstract entity X  respectively in the WordNet taxonomy. Describability can be superimposed on the dichotomous distinction between concrete and abstract senses, together with measures on other factors, to form a multi-dimensional scale of concreteness, which better models human cognition. 4.3.3 Concreteness and polysemy As mentioned, most studies had only dealt with word concreteness, but seldom sense concreteness. It is still not clear how individual senses contribute to the overall concreteness perceived for a word in general. For example, it is easy to imagine most people will predominantly think of the first sense of  X  X ar X  ( X  a motor vehicle with four wheels  X ) rather than the others, thus  X  X ar X  is often highly concrete to many people. However, it is less clear whether people tend to think of  X  X etter X  as  X  the written message addressed to someone  X  X r X  the characters of an alphabet  X  when they decide on the word concreteness. To the psycholinguistic end, it is important to further investigate the relation between word concreteness and sense concreteness. Moreover, how does the interaction between polysemy and concreteness affect the demand of word sense disambiguation? How should we encode such information in computational lexical resources to facilitate the task? These are critical and practical issues for computational linguists. 5 Conclusions In this study, we have investigated the feasibility of systematically estimating concreteness from the surface structure of dictionary definitions. The hypothesis was based on the conventional assumptions in lexicography that concepts of various degrees of concreteness are most appropriately defined by means of different defining styles. The concreteness scores thus obtained from definitions were found to mildly correlate with human concreteness ratings. It turned out that abstract concepts were more variably defined. Many abstract senses happened to be more describable than expected. Despite the somewhat inconclusive findings, the current study can be usefully taken as a feasibility study which enables us to uncover the potentials and limitations of the proposed approach. The potentials come from the regularities exhibited in definition syntax allowing effective dichotomous concrete/ abstract distinction in general, and the limitations are due to the inseparability of definition syntax and semantics (and other psychological factors) resulting in the underperformance for distinguishing concreteness on a finer scale. Whether a concept can be defined effectively with genus and differentiae depends on the describability of the concept to a certain extent. Some concrete concepts may be less describable than others, while some abstract concepts may be exceptionally describable. We therefore need to expand and refine the range of definition patterns and incorporate other implicit information encoded in the precise wordings. In addition to scoring the definitions based on heuristics as in this study, we could also try machine learning approaches like decision trees for the purpose. Moreover, we need to further consider exploiting clues from existing lexical resources as well as other dimensions contributing to the concreteness judgement so as to distinguish between concrete and abstract concepts on a finer scale. This is essential for enriching computational lexical resources with such psychologically valid proper-ties to benefit language processing tasks.
 References
