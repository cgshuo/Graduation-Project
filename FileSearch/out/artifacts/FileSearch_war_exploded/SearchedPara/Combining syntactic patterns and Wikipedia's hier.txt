 The attempt to discover automatically semantic relat ions ( SR ) between words, or word pairs has attracted a number of researchers during the last decade which is understandable given the number of applications needing this kind of information. Question Answering, Information Retrieval and Te xt Summarization being examples in case (Turney and Littman, 2005; Girju et al., 2005). 
SRs extraction approaches can be categorized on the basi s of the kind of information used. For example, one can rely on syntactic patterns or semantic features of the constituent words. One may as well combine these two approaches.

The method using only syntactic information relies on the extraction of word -level, phrase -level, or sentence -level syntactic information . Th is approach has been introduced by Hearst (1992) who showed that by using a small set of lexico -syntactic pattern s ( LSP ) one could e xtract with high precision hypernym noun pairs . Similar methods have been used since then by (Auger and Barriere, 2008; Marshman and L X  X omme, 2006). These authors reported results of high precision for some relations, for example hyponymy, noting poor recall which was lo w. Furthermore, the performance of this approach var ies considerably depending on the type of relation considered (Ravichand ran and Hovy, 2002, Girju et al., 2005 . 
An alternative to the syntactic approach is a method relying on the semantics features of a pair of words. Most researcher s using this approach (Alicia, 2007; Hendrickx et.al, 2007) rely on i n-formation extracted from lexical resources like W N (Fellbaum, 1998). Alas, this method works o n ly for languages hav ing a resource equivalent to WN . Yet, even WN may pose a proble becaus e of its low coverage across domains (tennis problem) .
Hybrid approaches consist in the combin ation of syntactic patterns with the semantic features of the constituent words (Claudio, 2007; Girju et.al 2005). They tend to yield better results. However, their reliance on WN make them amenable to the same criticism as the ones just mentioned concerning WN . More r ecently Wikipedia based simil arity measures have been proposed (Strube, et.al, 2006; Gabrilovich, and Markovitch, 2007). While this strategy produce s excellent results, few attempts have been made to extract SRs (Nakayama et. al, 2007; Yulan et, al , 2007 ).
In this paper we propos e two approaches to extract meronymic relation s . In the first case we rely on the patterns learned from LSPs . Previous syntactic approach es aimed at finding stand -alone , unambiguous LSPs , for instance X such as Y , in order to extract a s e mantic relation like hyponymy. Yet, such una m biguous, stand -alone LSPs are very rare and yield l o w perfo r mance. Instead of using LSPs individ u ally, which are often ambiguous, we try to co m bine th em in such a way that they co m-plete each ot h er. For instance, the ambiguity of the pattern  X  NN 1 make of NN 2  X  can be reduced via the pattern  X  NN 2 to make NN 1  X  in order to extract m e-r onymy. NN 1 and NN 2 can stand for any pair of words. The s e cond a p proach consists in disamb i-guat ing the word pairs extracted by LSPs via the information ident i fied from the Wikipedia pages of the respective words .

Ou r contributions are twofold. First, we propose a novel technique for extracting and combining LSPs in order to extract SRs. Second, we propose an approach for disambiguating the syntactic patterns (say m eronymic patterns like NN 1 -ha s -NN 2 ) by building a hyperlink -hierarchy based on Wikipedia pages. Previous work relies on unambiguous , stand alone LSPs to extract SRs. While this ap proach allows for high precision, it has been criticized for its low accuracy and its variability in terms of the SRs to be extracted. Not all SRs are equally well 'identified'. On e of the main challenges and motivations for LSP mining lies in the disambiguat ion of LSP to allow for the extracti on of SRs. T o achieve this, we propose two methods :  X  Determine an opti mal combination of LSPs to  X  Combining LSPs with the semantic features The use of individual LSP for the extraction of word pairs linked via a given SR tends to produce poor results (Girju et al., 2005; Hearst, 1998). One reason for this lies in the fact that the majority of word pairs are linked via pol ysemous LSPs (Girju et.al , 2005). Hence, these patterns can not be used alone, as they are ambiguous. At the same time they cannot be ignored as they have the potential to provide good clues concerning certain SRs . This being so w e suggest to ass ign weights to t he LSPs according to their relevance for a specific SR , and to optimally combine such weighted patterns for extracting word pairs linked via the S R at hand.
In order to determine the optimal combination of LSPs likely to extrac t SRs , we have harvested all LSPs encoding the relation at hand. We assigned weights to the patterns according to their relevance for the given SRs , and finally filtered the best combination of LSPs . 
In order to extract such patterns linking word pairs vi a a certain SR , w e s elect ed seed -word pairs representative of the relation at hand. In order to balance the word pairs we followed standard taxonomies to group the relations and selected samples from each group (see Section 3.1.1). S entences containing the word pairs were e xtracted and then identified their dependency structure. We identified d ependency structure linking the word pairs using the shortest path ( ex. nsubj(have , air craft ) and dobj(have, en gines ) from the sentence aircrafts have engine) . Having r e placed the word s by NN 1 (whole) and NN 2 (part) we o b tained pa t-terns like NN 1 have NN 2 . We finally c ounted the frequency of the LSPs and ord ered them according to their frequency and considering the top 50 . Determin ation of the optimal combination of LSPs encoding a given SR . To determine the optimal combination of LSPs, we identyfied th e discrimination value ( DV ) for each pattern. The DV is a numerical value signaling the relevancy of a given LSP with respect to a given SR. We applied the following steps in order to identify the DV and to determine the optimal combination of the LSPs : 
Step 1: For each extracted LSP , we extracted more connecte d word pairs from Wikipedia . We defined regular expression matching sentences linking word pair s via the LSPs and built then word pairs in a LSPs matrix (Matrix 1) . Table 1 b e-low shows sample word pairs connected by the pa t terns NN 1 has NN 2 and NN 2 of NN 1 . Next, we labeled the extracted word pairs with the SR type and built a matrix of word pairs by a specific SR type (Matrix 2). In Table 2 the word pairs from matrix 1 are l abeled with their respective type of SR . W e relied on WN to automatically label the word pairs . Starting with the first sense of the words occurring in WN , we traverse the hierarchies and identify the SRs encoded by the word pairs. Us ing the information from Matrix 1 and 2, we built a matrix of SRs to LSPs (Matrix 3). Table 3 shows sample M atrix 3. The rows of the matrix represent the SR type , while columns represent the LSPs ' encoding . The cells are populated by the number of word pairs linked by the LSP encoding the SR . The DV of LSP for a given SR is given by the following formula: DV log ( 1 )
FP represents the total number of word pairs connected by the LSP (from Matrix 1). FPR stands for the number of word pairs connected by the given SR (from Matrix 2), while TNR and TRE represent respectively the total number of SRs ( from Matrix 3) and the total number o f SRs encoded by the pattern (from Matrix 3). 
Step 2: Identify the optimal combination of LSP to represent a given relation . First , we build a matrix combining LSPs e ncoding the respective SRs (Matrix 4) from matrix 3. The LSP s in Matrix 3 are combined un til no other combination is possible. The cell s of the M a trix 4 are populated by the number of word pairs linked via the r e spe c tive comb i nation of LSPs . Next w e calculated the discrimination value ( DV -g ) for the combined LSP s , t he DV -g being calculated for each combination of LSP corresponding to a given SR. We then selected the combination of LSPs with maximum DV -g for each SR. The DV -g for the combined LSPs corresponding to a given SR is given by the following formula: FP -g expresses the total number of word pairs connected by the group of patterns. It is determined by taking the intersection of word pairs connected via the combined LSPs (from Matrix 4 ), w here FPR -g represent s the number of word pairs connected by the combined LSPs for a given SR . This value is determined by taking the intersection of positive word pairs connected by the combined LSP for a given SR (from Matrix 4). Finally, T NR and TRE represent respectively the total number of SRs (from Matrix 4) and the total number of SRs encoded by the combination of the LSP .
 As can be seen from table 3, the pattern  X  NN 1 has NN 2  X  when used independently encode s both a m e-ronymic and a non -meronymic word pair. From t a-ble 4 above t here are two m e r o nymic word pairs linked by the co m bination of pa t terns  X  NN 1 has NN 2 + NN 2 of NN 1  X  while there are no non -meronymic word pairs . Hence the non -meronymic word pair r e trieved via the pattern  X  NN 1 has NN 2  X  is fi l tered out as a result of having combin ed it with the pattern  X  NN 2 of NN 1  X . We used here the hyperlink -hierarchies built on the basis of a selected se t of sentences of Wikipedia pages containing the respective word pairs in order to disambiguate LSPs encoding them. The basic motivations behind this approach are as follows: 1. Words linked to the Wikipedia page title ( WPT ) via LSP encoding SR are more re liable than word pairs linked in arbitrary sentences. 2. Word pairs encoding a given SR are not always directly connected via LSPs . SRs encoded by a given word pair can also be encoded by their respective higher/lower order conceptual terms. 
For instance , th e following two sentences " germ is an embryo of seed " and " grain is a seed " yield relations like hyponymy ( germ, embryo , and grain, seed ), meronymy ( embryo, seed , and germ, grain ) , t he latter ( germ, grain ) being i nferred via the relation of their higher order terms ( embryo and seed ) . 
The candidate meronymic word pairs extracted via meronymic LSPs are further refined by using the patterns learned from their conceptual hierarchies built on the basis of semantic links , namely, ' hypernymic -link ' ( HL ), and the  X  meronymic -link  X  ( ML ). W e extracted the hyperlinks connected to the Wikipedia pages of the respective meronymic candidates by using hypernymic and meronymic LSP . The hyperlink hierarchies were built by considering only important sentences (1 and 2 below) from the Wikipedia pages of the pair of terms: (1) definition sentences and (2) sentences linking hyperlinks to the WPT using meronymic LSP s . Since the meronymic LSP vary according to the nature of the arguments , the patterns used to extract hyperlinks for building the hierarchies were learned by taking the nature of the meronymic relations in to account (se ction 2.1). The definition sentences are used to extract hypernymic -hyperlink 1 , and the sentences linking hyperlinks to the WPT using meronymic LSPs are used to extract meronymic -hyperlink 2 . Using the hierarchy constructed for the candidate word pairs, t his approach determines whether the pairs are meronyms or not b ased on the following assumptions: Extracti on of the hyperlinks. To extract the hyperlinks , we performed the following operations : Step 1: For s i mple meronymic pairs we identified the respective Wikipedia pages align ing the word pairs with the WPT based on the overlap of the surface word form . The word pairs were selected based on standard categories used for describing meronymic taxonomy ( Winston et al. 198 7, see also section 3.1.1). We first cleaned Wikipedia articles and extracted Wikipedia definitions and sentences linking WPT with hyperlinks using meronymic LSPs . Step 2: Annotations. We manually annotated both kinds of sentences using two kinds of infor mation: WPT and the hyperlinks. The hyperlink either links the term to its meronyms or hypernyms.
 Step 3: Extract LSPs linking the WPT with the hyperlinks. We assigned DV (section 2.1) for the patterns and considered the most frequent LSPs . The hyperli nks broadly fall in either of two categories: (a) hypernymic -hyperlink . They are extracted by the patterns linking the tuple (hyperlink, wpt), for instance , is -a (hyperlink, Wikipedia page title) as in the example (b,c); (b) meronymic -hyperlinks . They are extracted via LSPs linking the tuple (hyperlink, wpt) , for instance , made -from (hyperlink, wpt) .

Constructing the hierarchy. For a given pair of terms, we identified the respective Wikipedia pages, by aligning the pairs with the wpt and by using word form overlap to extract their associated initial hypernymic and meronymic hyperlinks (hl i ) based on the patterns learned in step 2.2.1. We further identified the respective Wikipedia pages for the hypernymic and meronymic -hyperlink (hl i ) identified before and extracted the associated hypernymic and meronymic hyperlinks (hl i+1 ). Next we connected ( hl i ) with (hl i+1 ) to form a hierarchy (hypernyms are connected to each other and to meronyms and vice versa). The hyperlinks are extracted until the hierarchies converge, or until the hypernymic -hierarchy reaches seven layers ( m ost word pairs converg e earlier than that ) . Decide on the meronym ic status of words . T he hypernymic or meronymic -hyperlink of one of the words of the pair is searched in the hierarchy of the other, and if this link occurs we consider the word pairs as meronyms. Figure 2 shows th at th e meronymic word pair  X  germ grain  X  converg es at  X  seed X  in th e hierarch ies built from their respective Wikipedia pages. To show the validity of our line of reasoning w e carried out three experiments:
I. Extract the optimal combination of LSPs enco d-ing meron y mic relation only.
 II. Ev aluate CoSP -FRe for meronymy extraction . 
III. Evaluate WHH -Fre for extracting meronymy.
Training data set. Two sets of data are required: (a) the initial meronymic word pairs used to train our system (b) the corpus from which the LSPs were selected. T o select the representative list of meronymic pairs, we used a standard taxonomy. Indeed, several scholars have proposed taxonomies of meronyms (Winston et al., 1987; Pribbenow, 1995; Keet &amp; Artale, 2008). We followed Winston X  X  classical proposal: For the training w e used the part -whole training set of SemEval -2007 task 4 (Girju et al. 2007 ) . Experimental setup. T o determine the optimal combination of LSPs encoding meronyms we identified LSPs encoding meronymy according to the procedures described in section 2.1. Since most of these patterns are rare we considered only those with a frequency of 100 and above. For individual LSP extra ct ion , we identified the DVs associated with the meronymic relation by using the formula 1 followed by the DV -gs for every combination of LSPs by using the second formula . The combined LSPs are sorted based on their DV . Finally we selected the LSP with the highest DV as representatives of the respective meronymic types. As can be seen from Table 5 t he DV -g of staff object meronymic relations patterns is 83.6. The discrimination values for the LSP in the group when used individually is bel ow 50%. Evaluation . The goal is to evaluate the degree of correspond a nce between the meronyms extracted by CoSP -FRe and WHH -FRe on one hand and the one by human annotators on the other . Test data set. We used two data sets: (a) the part -whole te st set of the SemEval -2007 task 4 (Girju et al. 2007) which contains 72 examples (26 positive and 46 negative) and some meronymic word pairs gleaned from WN .
 Comparison with other systems. We have compared our work against three approaches that a chieved the best performance on SemEval -2007 task 4, and two other approaches. We categorized the se approaches as (a) WN -based: CMU -AT (Alicia, 2007) &amp; ILK (Hendrickx et.al, 2007), (b) syntactic and (c) hybrid approaches: FBK -IRST (Claudio, 2007) &amp; Girjus et.al (2005). We used the individual LSPs ( ILSP ) extracted in Sections 2.1 &amp; the LSPs extracted by Girju, et.al (2005) as syntactic approach. The LSPs extracted by Girju, et.al (2005) are the subset of the LSPs extracted in Sections 2.1 . Results. We com puted precision, recall and F -measures as the performance metric. Precision is defined as the ratio of the number of correct meronyms extracted and by the total number of extracted word pairs . Recall is defined as the r a tio between the number of correct meronyms extracted a nd the total number of meronyms in the test set. We have also ext racted meronymic word pairs from random W ikipedia pages of 100 articles and added 85% of the word pairs e n coded in WN .
Discussions . T he results for both approaches are discussed here below : CoSP -FRe . The pre cision of CoSP -FRe is improved o ver syntactic approach as the ambiguity of the indivi d ual LSP  X  X  is reduced when patterns are co m bined . R ecall is improved as a result of using ambiguou s LSPs for extracting word pairs . This contrasts with all the other syntactic approaches which relied only on unambiguous LSPs . In o ur approach, ambiguous LSPs are also used in comb i nation with other LSPs . H ence the coverage is si g nificantly i m proved .
 WHH -FRe . S everal kinds of hierarchies were formed. Some of the m are made of hypernymic or meronymic links , while others are a combination of both links . WHH -FRe outperform s s ignificantly previous a p proaches both with respect to recall and precision as it combines two important features . First LSPs are used to ex tract list s of candidate pairs . Second semantic features of the constituent words extracted from Wikipedia hyperlink -hierarchy is used to further refine . Precision is improved for several reasons: relation s encoding LSPs which link hyperlink s and WPT are more reliable than word pairs connected via arbitrary sentences. The featur es learned from the Wikipedia hyperlink -hierarchy further cleaned the word pairs extracted by LSPs . Recall is also improved since word pairs indirectly linked via their respective higher/lower order hierarchy were also extracted. The work of ( Turney, 2005, 2006; Turney and Lit t man, 2005 ; Chklovski and Pantel, 2004) is closely related to our work (CoSP -Fre) as it also relies on the use of the distribution of sy n tactic pa t-terns. However, the ir goal s , alg o ri thms and tasks are different. The work of (Turney, 2005, 2006; and Turney and Littma, 2005) is aimed at measu r-ing relational similarity and is a p plied to the class i-fication of word pairs (ex. quart: volume vs mile: distance ) while we are aimed at extracting SRs . The work of Girju et.al (2005) is more related to our WHH -FRe in that they combined LSPs with the semantic analysis of the constituent words to di s-ambiguate the LSPs . They used WN to get the semantics of the constituent words . Alicia (2007) converts word pairs of the positive examples into a semantic graph mapping the pairs to the WN hypernym hierarchy. Claudio (2007) combines information from syntactic processing and semantic information of the constituent words from W N . Wikipedia -b ased approaches mainly f o cused on the identif ication of similarity (Nakayama et. al, 2007; Yulan et, al , 2007) . Also, there is hardly any recent work concerning the extraction of meronyms. Many research ers are worki ng on the identification of semantic similarity achieving excellent result by using standard datasets (Camacho -Collados, Taher and Navigli, 2015; T a-her and Navigli , 2015 ) . Yet, most of this work date s back to 2010 a nd before . We presented here two novel approaches for e x-tracting SRs : CoSP -FRe and WHH -FRe . The strength of CoSP -FRe is its capacity to determine an optimal combination of LSPs in order to extract SRs . The approach yielded high precision and r e-call compared to other syntactic approaches. WHH -FRe perform significantly better than pr e-v i ous approaches both with respect to recall and pr e cision as our approach combines LSP and the lex i cal semantics of the constituted words g leaned from their respective Wi k ipedia pages.
