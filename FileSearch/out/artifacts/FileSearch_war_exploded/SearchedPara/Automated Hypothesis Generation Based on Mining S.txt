 Keeping up with the ever -expanding flow of data and publications is untenable and poses a fundamental bottleneck to scientific progress. Current search technologies typically find many relevant documents, but they do not extract and organize the information content of these documents or suggest new scientific hypotheses based on this organized content . We present an initial case study on KnIT, a prototype system that mine s the information contained in the scientific literature, represent s it explicitly in a queriable network, and then further reason s upon these data to generate novel and experimentally testable hypotheses. KnIT combine s entity detection with neighbor -text feature analysis and with graph-based diffusion of information to identify potential ne w properties of entities that are strongly implied by existing relationships . We discuss a successful application of our approach that mines the published literature to identify new protein kinases that phosphorylate the protein tumor suppressor p53. Retro spective analysis demonstrates the accuracy of this approach and ongoing laboratory experiments suggest that kinases identified by our system may indeed phosphorylate p53. These results establish proof of principle for automated hypothesis generation and discovery based on text mining of the scientific literature. I.2.6 [ Learning ]: Concept Learning and Knowledge Acquisition Algorithms, Experimentatio n. Text Mining ; Scientific Discovery ; Hypothesis Generation . The pace of scientific publications is growing at an exponential rate [18] with over 50 million papers published so far [16], and over a million additional articles published annually [4]. This means on average a new article being published every 30 seconds . Within specific field s there may be tens of thousands of papers published every year  X  far more than any individual scientist can keep up with. In biomedical research, papers on specialized topics often run in the tens of thousands and topic areas contain orders of magnitude more. For example, over 70,000 papers have been published on a single protein, the tumor suppressor p53 [13]. Proteins are the fundamental machinery of the cell; understanding them is critical to ad vances in biology and medicine, and yet no scientist can possibly assimilate, recall and accurately process all of the known facts and relationships that could be relevant to discovering unknown protein functions, identifying relationships between proteins , or elucidating the role a particular protein may play in disease. Even recogniz ing new questions that should be asked can be a challenge. Instead , only a sliver of the relevant knowledge guides hypotheses: an approach that is deeply wasteful. This funda mental bottleneck is pervasive in biology and representative of every area of human endeavor in which there is a mushrooming mismatch between raw information and our analytic abilities. Our goal is to accelerate scientific progress by combining mining, visualization, and analytics , with the hope to integrate all available content , identify the facts that are relevant to a given query, and from these fact s suggest hypotheses that are new, interesting, testable and likely to be true. Baylor College of Medi cine and IBM Research have engaged in a long -term partnership to define scientific goals, build the necessary infrastructure, software, and algorithms and test the strengths and limitations of our discovery capabilities through direct experiments. We see this as a multi -year effort, but in the process of designing our approach and applying some very basic algorithms to the data, we made some early and surprising discoveries: even relatively simple approaches, when applied across enough data and with the be nefit of expert domain knowledge, may quickly lead to significant discoveries in a complex domain. This paper describes our initial approach for this Knowledge Integration Toolkit ( KnIT ) for discovery and the early findings it has already led to so far.
 KnIT embodies a three -phase process of Exploration, Interpretation, and Analysis. The Exploration phase surveys the relevant unstructured information, designs text queries, and extracts relevant documents for entities of interest. The entities of interest in this paper are a particular set of human proteins called kinases , detailed in Section 3. In general, each entit y is modeled as a point in an abstract feature space , where the features of an entity correspond to its aggregate  X  X ext signature  X  in a corpus . Next, the Interpretation phase builds a connected graph that represents the similarity relationship among entities. This helps domain experts visualize hidden connections between entities based on most of the known features and properties discussed in the literature. Coloring overlaid on top of this graph may reveal sub -graphs that correspond to clusters, typically with respect to some important property of interest . Critically, a sub-graph may contain a few  X  X eviant X  entities not known to possess the property of interest ; because these entities are surrounded by others with a specific property, it is plausible to hypothesize that the deviant entities share it as well.
 Finally , the Analysis phase globally diffuses annotation information among entities to rank order the best entity candidates for further experimentation of novel annotation predictions. In doing this we may compare the candidates derived analytically and rank -order the best candidates for further experimentation. The graph from the Interpretation phase can be used as a sanity check to ensure that the results correspond to common sense. Ultimately the domain expert can choose to verify only those annotation candidates that are the most analytically probable, exper imentally testable, and of direct interest to the problem at hand, such as those suggesting a novel component of a disease X  X  mechanism or a potential drug target.
 Some past approaches have inferred formulas from experimental data [17]. Others have ded uced direct connections based on a set of indirect associations that are obtained from highly structured, manual annotations of a corpus, such as MeSH annotations of MEDLINE data [30], hypothesis generation from unstructured text has been a hit -or-miss manual process [31] tha t is heavily dependent upon serendipity. Our approach leverages mining techniques for unstructured text to automatically discover hidden similarities between entities based on a corpus of scientific articles. The hope is that this approach will be robust a nd scalable even as entities and their multi -dimensional features create complex network relationships far beyond what human scientists can reason over , generating hypotheses that would otherwise elude domain experts.
 In the rest of the paper we describe our proof of concept case study: a particular application of this methodology to a protein of singular importance across biology, the tumor suppressor p53. After discussing its role in cancer research, we describe our representation of the p53 literature and related proteins of interest. Next, we explain our knowledge visualization strategy for these proteins using a similarity graph, followed by a presentation of the analytical reasoning approach based on information diffusion . We then show in a series of retrospective validation studies that we are indeed able to create meaningful and accurate predictions. Finally, in a bona fide example of discovery, we present describe laboratory experiments that confirm several new p53 interactions predicted by KnIT, pr oviding a proof of concept that will help direct future biological research . In the spirit of this year X  X  KDD emphasis on Social Good, we briefly place our work in a broader societal context. Humanity is facing a fundamental information bottleneck that overwhelms cognitive capabilities inherited from 160 million years of mammalian evolution. For most of this time , brains only had to cope with the perils posed by the physical world and by social competition. But as human language emerged, and with it the ability to pass complex abstract information across generations, a new evolutionary demand took form that was different from past constraints : n ow the recording, teaching and learning of facts and knowledge yielded advantages . Even so, as long as education remained oral, the body of knowledge was bounded by and matched to the cognitive abilities of each generation. Once written language emerged, however, a mere 4000 years ago, this constraint broke. Now facts and knowledge could accumulate ex vivo regardless of whether we could absorb them intellectually: by antiquity the library of Alexandria may have held as many as 100,000 scrolls , and by 2010 Google estimated that 130 million books were in existence. With the automated large -scale produc tion of industrial, social, and scientific data upon us, the exponential divergence between information collection s and human understanding is now as brutally vexing to all as it doubtless already was to the Alexandrian scholars.
 Of course, humans overcome biological shortcomings by inventing tools , and a lready, many such computational aids exist . However, as empowering as they are compared to just a decade ago, their first -generation limitations are also inescapable. How often do we examine the fourth Google page, or even the third one for that matter? How deep into the literature do we read when a Medline search returns 200 papers, from the last 18 months? How much network traffic must we track to detect a lethal cancer cell, nascent electrical grid instability, or a terror target amidst anarchist chatter? In this study, we tackle these questions. Starting from an immense corpus of knowledge , some in text and some in Big Data, we aim to extract relevant facts, represent them, and reason over them in order to generate new hypotheses that we can then test experimentally to arrive at a validated discovery. The tools and the computational framework that we develop for this purpose are entirely general, but in order to demonstrate that it may lead to immediate practical discoveries , we are focusing here on biology. All human cells throu ghout an individual X  X  body contain roughly the same genome, that is, the DNA molecules which represent the blueprints of biology inherited from one X  X  parents. These blueprints contain the information necessary to create tens of thousands of different prote ins, which are the molecular machines that are fundamental to all of cellular biology, performing a wide range actions such as metabolizing nutrients, allowing a cell to respond to its environment , and even controlling the quantities , or  X  X xpress ion levels  X , of other proteins. In this paper we investigate a particularly important protein, p53, which is often referred to as  X  X he guardian of the genome  X  and is implicated in many biological processes and diseases including cancer [7; 9; 19; 22; 24; 25; 29] . As an individual grows and ages, cells must repeatedly make copies of their own genome s, which eventually results in degradation of the information contained therein. When enough errors accumulate, it is possible for a cell to enter a broken, cancerous state in which it grows continuously, damaging nearby tissue and causing harm to the orga nism. The p53 protein is a major player in the cell X  s natural defense against entering such a state: p53 responds to the detection of genomic problems by increasing the expression of hundreds of other proteins to try to destroy itself, saving the neighboring cells and the life of the individual. One way that p53 is able to react to such problems is due to signals from a set of proteins that chemically modify p53 in response to different conditions. Each p53 modification, of which there are over 50, acts as a n on/off switch, causing p53 to have one response or another [12]. The most common type of modification among all proteins , including p53 in particular, is phosphorylation, in which a phosphate molecule (PO 4 3-to a specific at om in a protein molecule . The class of protein s that carr ies out th e addition of phosphate molecules are known as kinases , which are increasingly the target of promising cancer treatments for use in these signaling mechanisms [27]. Drugs can affect the behavior of specific kinases, which can produce specific reactions in the proteins they phosphorylate, with the goal being to activate the cell  X  X  innate cancer -fighting abilities. Knowing which proteins are k inases is a well-solved problem [21]; however, knowing which proteins are modified by each kinase, and therefore which kinases would make good drug targets, is a difficult and unsolved problem . There are over 500 known human kinases and tens of thousands of possible proteins they can target . Biochemical experiments require months to establish a single novel kinase -protein relationship, and then years to fully elucidate the relationship's biological impact . Only 33 of the 500+ kinases are currently known to modify p53 [8; 12; 15; 23] , but it is likely that there are many such relationships that remain unknown . In this paper , we asked as a proof of principle whether KnIT can discover novel p53 kinase s. To approach this problem, we first note that there are over 240,000 papers that mention one or more of 500+ known human kinases in their Medline abstract . An avid reader capable of absorbing 10 papers per day would need 70 years to go through this relevant literature  X  a co mpletely unrealistic feat. Instead , however, we mine text so as to create a model for each kinase that specifically mention that kinase. In aggregate, and ignoring issues of errors and uncertainty, the words in these abstract s are assumed to be a useful signature of kinase features, such as details about biological process, molecular function, cellular component and specific interact ions. KnIT collect s and label s the abstracts to be mined using quer ies against a text index of all Medline abstracts. There is one OR query for each kinase that includes the kinases canonical name along with its synonyms taken from [6; 11; 32] . KnIT submit s the queries and download s all abstracts that match each kinase up to query size. (A few kinases have well over 10,000 abstracts, which is far more than is needed to develop an accurate model. ) In order to explore KnIT X  X  predictive properties , we used several different Medline searches. In our initia l exploration, we search ed all kinases but remove d abstracts that ma ke any reference either to p53 or to a second kinase. We thus excluded data that would trivialize the predictions . This left us with 259 kinases in all. Of these, 23 we re known to be p53 kinases. Next we create a numeric representation that encapsulates all we know about each kinase relative to ever y other kinase. To facilitate this process we represent the documents in a vector space model. That is, each document is a vector of weight ed frequencies of its features (words and phrases) [26]. We emphasize words with high frequency in a document, and normalize each document vector to have unit Euclidean norm. The words and phrases that make up the document feature space are determined by counting the number of documents in which each word appears and identifying the words with the highest counts. A standard  X  X top word X  list is used to eliminate words such as  X  X nd X ,  X  X ut X , and  X  X he X  . The top N words are retained in the first pass, where the value of N may vary depending on the length of th e documents, the number of d ocuments and the number of categories to be created. In our experiments we found that N=20000 is sufficient for the categories and documents used in this domain. After selecting the words in the first pass, we make a second pass to count the frequency o f the phrases that occur using these words. A phrase is considered to be a sequence of two words occurring in order without intervening non -stop words. We again prune to keep only the N most frequent words and phrases. This becomes the feature space. A third pass through the data indexes the documents by their feature occurrences. We experimented with various methods of weighting term occurrences in this matrix and eventually determined that a Term Frequency  X  X nverse Document F requency weighting (TF-ID F) [26] yielded the best overall prediction accuracy. Once we have a feature space we create a representation of each kinase by averaging the feature vectors of all documents that contain the kinase. This is the kinase centroid. Next we calculate a distance matrix that measures the distance between each kinase and every other kinase in the space. Such matrices are fine for computers to read and calculate properties over, but notoriously difficult for a domain expert to interpret in order to get a sense of the data X  X  underlying validity and meaning. Interpretability is important, because an expert must be confiden t and insightful when proposing new hypotheses . Thus some way must be found to convert the numbers into a meaningful picture of kinase -kinase relationships.
 A network graph is one approach that is often tried [10] but this requires determining when two nodes should be considered connected, when in fact all nodes are connected at some level of similarity th reshold. We could pick an arbitrary similarity cutoff and draw lines whenever similarity was greater than the sp ecified limit, but that assigns more meaning to the absolute value of the distance metric employed here than is strictly warranted. Relative distance is the more important concept to convey here. To design the graph used in KnIT, we switch the goal around. What does a maximally communicative graph look like? First of all it should be minimally connected, in other words containing one less arc than the number of nodes. Secondly it should be a tree because trees are easy to navigate and communicate information based on distance from the root , which is often helpful. Third, the tree should spread connections out fairly evenly among the nodes to avoid extreme situations where one node is connected to all the others, a very uninteresting graph. This leads us to the conclusion that a binary tree (or at least low n -ary ) would be highly advantageous if it can be drawn so as to accurately represent th e distance matrix. To create a binary tree we must choose a meaningful root node. Does any particular entity stand out for this honor? In fact, there is one property unique and important in the text vector space  X  namely typicality. There is one entity whose vector is closest to the average of all the vectors. This will be the root. Now as we move down the tree we will naturally go towards less typical (more unusual nodes). This turns out to be a very intuitive concept to grasp, visually.
 Algorithm 1 is used to create an n -ary similarity tree from the set of entities, where each entity is represented as a feature vector. The root of the tree is the "most typical" entity, and typicality decreases with increasing distance from the root, so that the leave s of the tree are the "least typical", i.e., unique outliers. The algorithm first computes the "most typical" feature vector as the average of the entities, and then calls the closestToFV function to select the entity closest to this typical feature vector as the root of the similarity tree. The algorithm also initializes candidates as a singleton set comprising the root node; here candidates are the set of nodes currently in the tree at which to potentially attach new child nodes. The algorithm next uses t he closestPair function to find the pair (e,c) such that e belongs to entities , c belongs to candidates , and distance(e,c) is minimized over all such pairs. (Thus e is the closest entity to the current set of candidates and c is the candidate closest to e.) Then e is added to the tree as a child of c. Moreover, e is removed from entities , the set of entities that have not yet been added to the tree, and added to candidates . If adding e as a child to c increases the numbe r of c's children to the limit n, then c is removed from candidates to ensure that its n -ary property will not be violated in the future. The algorithm continues to add elements of entities to the tree in a similar manner, until there are no more entities to add. The functions closestToFV and closestPair use Euclidean distance and break ties randomly. In Figure 1, we show an example of this kinase network diagram with n=2. G reen nodes are p53 kinases, red/orange/yellow nodes are hypothesized new p53 kinases based on their similarity to known p53 kinases. What is remarkabl e about this visual representation is that the green  X  X inase X  nodes tend to be clumped together, even though the algorithm knows nothing about p53 kinases. This tends to lend credence to the supposition that those nodes in the midst of the green clumps ar e also likely to be p53 kinases. Algorithm 1 Create an n -ary similarity tree from a set of entities Input : entities , n Output : n -ary similarity tree mostTypicalFV = average(entities) root = closestTo FV(entities, mostTypical FV) entities.remove(root) candidates = {root} while not entities.isEmpty() (e, c) = closestPair(entities, candidates) c.addChild(e) candidates.remove(c) candidates.add(e) entities.re move(e) end while Return : root The visualization tool provides a set of kinases that may phosphorylate p53 . However, some sort of principled ranking also phosphorylate p53. scheme is needed in order to prioritize the kinases for further experimentation. To provide such a scheme, our initial prototype uses graph diffusion [34]. Graph diffusion is a semi -supervised learning approach for classification based on labeled and unlabeled data. It takes known information (initial labels) and then constrains the new labels to be smooth in respect to a defined structure (e.g. a network). In our case, we know which kinases phosphorylate p53 (initial labels); we would like to know which other proteins phosphorylate p53 (final labels). The distance matrix based on the literature gives us the structure of our kinase network. The initial labels are extracted from current knowled ge found in review articles [8; 12; 15; 23] . Graph diffusion propagates information among network nodes following the edges between them (Figure 2A) . Here, human kinases are the nodes and the distance matrix of literature similarity between each kinase provides the edges. To formulate the kinase network, we defined edges between each kinase and the top ten most closely related kinases . This cutoff was determined empirically by cross -validation performance. We can represent our knowledge of protein function as y , a fixed binary vector of labels with y i representing whether protein i phosphorylat es p53. We seek to identify a new set of continuous labels , f ( i.e . how likely a kinase is to phosphorylate p53) by diffusing the known information in a network. We can solve for f by minimizing the sum of the loss and smoothing functions [3]: The first term , the loss function , represents the difference between initial y and final labels f . During diffusion, this function regulates and prevents the loss of the initial labels. The second term , the smooth ing function, represents the smoothness of the new label s f in the context of the Laplacian matrix L . The Laplacian matrix [5] is the matrix representation of the kinase network and defined 
L = D  X  A . The adjacency matrix, denoted A , specifies if kinase i is connected to kinase j where A ( i , j ) = 1 if the entities are connected and A ( i , j ) = 0 otherwise. The degree matrix, D , is a diagonal matrix given by The diffusion coefficient  X  balances the loss of the initial labels against the smoothness. The previous equation has a closed form solution [3]: where I is the Identity matrix. We set the diffusion coefficient  X  to the inverse of the Laplacian X  X  norm This value insures that the Hessian is positive definite and the above function is convex [20]. In order to identify new kinases, we then look at the new labels f where the labels with the largest increase will be our t argets. Leave -one -out cross -validation eliminates an observation from the original data set, and then tests whether predictions based on the remaining information can recover the observation that was removed. Each on e of the known p53 kinases was relabeled as an unknown and the performance of the prediction method was evaluated by whether it could recover the information . Due to the limited availability of negative information in biology, those with no known p53 activ ity were treated as negatives for the purposes of computational validation. now known to be true positives but were not known in 2003. We often used Receiver Operating Characteristic (ROC) curve s to measure performance. In more detail, the diffusion scores in f , together with a threshold t , can be used to cla ssify each protein as a  X  X ositive X  (i.e., it phosphorylates p53) or a  X  X egative X  (no phosphorylation). Protein i is predicted to be positive if f negative otherwise. Recall that the True Positive Rate (T PR ) is the fraction of the True Positives found over the total possible Positives. Similarly, the False Positive Rate ( FPR ) is a fraction of the False Positives found over the total possible Negatives. Thus in our setting the ROC is the cumulative plot constructed by calculating TPR and FPR at all possible binary classification thresholds t . The area under this curve (AUC) summarizes prediction performance: an AUC of 1.0 represents a perfect predictor while a random prediction would lead a diagonal line and an AUC of 0.5. In order to test the algorithm, we first applied it in a retrospective analysis to show whether recent annotations of new p53 kinases occurring after a certain date could be predicted from a model that only took into account papers written before that date, at a time when these discoveries of p53 kinases were still unknown . Next we asked whether some variations in the algorithm could improve p53 kinase prediction as we compared its performance to the common approach used most typically to identify functionally similar prote ins in biology . Finally , we expanded our analysis to a larger set of proteins to test scalability. The positive results in these retrospective controls led to a prospective stud y of bona fide prediction s, discussed in section 6. If KnIT is effective, it should predict from papers published prior to a given date events that were only discovered after that date . To test this hypothesis, we mined the literature up to 2003, when only half of the 33 currently known p53 kinases had been discovered . Because we filtered out confusing abstracts that mentioned multiple different kinases and p53 , the kinase search space became small: only 74 kinases . But a mong these 74, ten were known to phosphorylate p53 in 2003, nine were found at a later date, and the remaining 55 are for simplicity assumed to not phosphorylate p53 . A kinase distance matrix and a literature vector model was developed for the se 74 kinases , the ten p53 kinases that were known prior to 2003 were labeled as such, and these label s were propagated to the other 64 kinases by global graph diffusion from which we could now rank the 64 kinases by the likelihood they targeted p53. Strikingly, an ROC curve shows that seven of the nine true positives are readily predicted with this algorithm (Precision= 0.54 at Recall=0.77 , with an AUC of 0.8 40); see Figure 2B. Th is time -stamped study shows that back in 2003, we could have automatically predicted many of the p53 kinases that were discovered in the subsequ ent decade by combining text mining with feature analysis and graph -based diffusion as KnIT does. This result is remarkable considering that for simplicity we only used a limited subset of the least ambiguous abstract s, which restricted us to studying only 74 rather than about 500 kinases. In order to test KnIT on a larger scale, we next sought to include more abstract s, regard less of their date or mention of multiple kinases and p53 information . This time to mitigate the most obvious problems related to incomplete or noisy information, we only filtered out those kinases having fewer than 20 abstracts. This allowed us to model 401 kinases , rather than the previous 74 kinases . Instead of a time -stamped retrospe ctive analysis, we performed leave -one -out cross -validation of all 33 currently known p53 kinases. Specifically, a literature vector model and then a kinase distance matrix we re built and we then performed 33 separate experiments. I n each, one of the 33 p53 kinases was relabeled  X  X  nknown X  rather than  X  X 53 kinase,  X  then the remaining 32 p53 kinases were diffused globally to yield a ranking for the 
Figure 3 Graph diffusion was performed with leave -one -out -cross validation to assign scores to 33 kinases known to target p53 as well as 368 kinases not known to target p53. 
Of the 509 kinases included in analysis, we only included the 401 kinases reaching a minimum document count threshold. (Black) represents the average perf ormance of a random algorithm with no predictive value. (Green) is the original algorithm X  X  performance. (Blue) shows the improvement due to dictionary synonym refinement. (Red) is with the inclusion of the TFIDF weighting scheme.

Figure 4 Comparison to sequence -based method. (Red) is predictive power of the literature vector model in a leave -one -out cross -validation analysis of known p53 kinases. (Black) is the performance of a method that uses biological sequence information to do the same task. (Black -dotted) represents the performance of a random model.  X  X nknown X  p53 kinase . We th en diffuse d the label information of all 33 kinases to obtain scores for all non -p53 kinase (401 -33=368 ). Once each kinase has a label score, w e can then calculate the ROC curve treating the known p53 kinases as positives. The area under ROC curve was shown to be sig nificant at 0.691 (Figure 3 , green curve ). We first constructed a list of gene synonyms extracted form from NCBI [2; 33] , UniProt KnowledgeBase [32], and Hugo Gene Nomenclature Committee [11]. We noted that some kinases have ambiguous synonyms that are likely to return more incorrect abstracts than correct ones when querying Medline: BTK has "AT" as a s ynonym TYRO3 has "TIF" as a synonym ARUKA has "AURA" as a synonym RIPK1 has "RIP" as a synonym (confused with "repeat induced point mutation") ITK has "EMT" as a synonym (confused with "epithelial -mesenchymal transition") MOK has "RAGE" as a synonym BMP2K has "BIKE" as a synonym KIT has a problematic main gene name FYN has  X  X YN X  as a synonym (common acronym for synthetic) To improve on results , we removed these vague terms. A second issue we considered was that m any of the kinases shared synonyms names (i.e. PAK1 is a synonym for PKN1, but PAK1 is a distinctly different kinase). We removed redundant gene names within the protein kinase, unless the gene name was the Hugo Approved Gene Name (As is the case of PAK1). Removing these ambiguous synonyms yields a more accurate representation of each kinase X  X  content. After removing problematic synonyms, we resubmitted our queries and perform ed the analysis again with the new set of abstracts for each kinase. This improved kinase dictionary now increased the AU(R OC) from 0.691 to 0.751 (Figure 3 , blue curve ). Next, we experimented with different weighting schemes for term frequencies when creating the distance matrix. We determined that a TFIDF [26] weighting , which gives a stronger weight to shared words that occur less, dramatic ally improve s the AUC=0.8 00 (Figure 3, red curve). In contrast, increasing the max query size from 1600 to 3200 abstracts had virtually no impact on performance (data not shown ). We also compared KnIT to a common approach for predicting biological function: protein sequence alignment. Every protein exists as a sequence of amino acid molecules , which can be represented by a series of letters using a 20-character alphabet, one letter for each type of building block in the sequence. It is well known that similar sequence often, though not always, suggests similar function of two proteins. The amino acid sequence of e ach kinase was aligned with the set of positives, and those with low e -value as reported by BLAST [1] were predicted to be more likely to target p53. (Roughly speaking, the BLAST e -value indicates the probability that sequences align purely by chance.) A comparison of the leave -one -out performance of these methods is shown in Figure 4. These leave -one -out control studies show over a nearly fully representative set of kinases that that KnIT is superior to a sequence -based approach with respect recover ing knowledge of a true p53 kinase when this knowledge is erased . Although leave -one -out studies should not be over -interpreted, this positive result is consistent with the possibility that KnIT is predictive. 
Figure 5 Summary of 45 different AU(ROC) performance measures for predictions on each of 45 different kinase targets, each with a unique set of labels for the search space of 500+ known kinases. 
Figure 6 Experimental validation of candidate p53 kinases as bona fide p53 kinases. (A) In vitro kinase assay demonstrates phosphorylation of p53 by top ranked candidate kinases PKN1 and NEK2. Relative levels of p53 phosphorylation are indicated for each kinase normalized to positive control CHK1. Though the signal is weak for PNK1, subsequent exper iments lend further support. (B) 
PKN1 and NEK2 shown to interact with p53 in vivo . A p53 antibody isolates p53 and any proteins bound to it. 
Antibodies detect the presence of candidate kinases in this isolate . As a further test of scalability we next asked if KnIT could also predict kinase activity for targeted proteins other than p53 . In previous experiment we exploited review articles from p53 experts. In order to extend to the larger scale analysis, we exploited the kinase -to-target knowledge base built for human kinases by PhosphoSitePlus [14]. Th ese data are manually curated for the modifying protein, the type of modification, and the subject of the modification. So far, the curators of PhosphoSitePlus have reliably identified over 14,000 relationshi ps between kinases and target protein s by reading the available literature . Among these, we narrowed this study to 45 unique human proteins , each modified by at least eight unique kinases belonging to our kinase network . It is likely that some sets of kinases may be easier to predict than others, for example if some have simpler biological mechanisms , therefore rather than normalizing and plotting all predictions onto a single ROC curve, each protein was evaluated independently, and the AUC was calculated for each one separately. Figure 5 shows a histogram summarizing the performance of these 45 ROC curves. We found that in all cases that the predictions were significant (AU(ROC)&gt; 0.65) and the average AUC was 0.8 35. These data show that KnI T does not uniquely apply to p53, but that it can extend to make predictions in many other human proteins. Retrospective analyse s are suggestive but never proof of discovery. For the latter it is critical to predict an observation that has never been made and then assess its truth in the laboratory. The algorithms described above were used to rank 252 kinases (those with at least 20 publications) by likelihood of being p53 kinases. As expected, most kinases known to phosphorylate p53 were near the top of the rankings list. Five kinases on the list not known to phosphorylate p53 were then tested by biochemical and molecular biology experiments for their ability to interact with and phosphorylate p53. Two kinases (PKN1 and NEK2) we re chosen from near the top of the list and three kinases were chosen from the bottom half of the list (TNK2, INSRR, and PDGFRA). Two validation assays are shown here : an in vitro kinase assay and a cellular co -immunoprecipitation (IP) assay. In Figure 6A, the in vitro kinase assay, p53 is combined with a kinase and a radioactive source of phosphate, gamma -Then a technique known as electrophoresis is used to separate the components of the mixture by weight to different positions in a gel. Because the weight of p53 is known (53 kilodaltons), we can check for radioactivity of anything that weights exactly that amount. If the predicted relationship is real, the kinase will add the radioactive phosphate to p53, and electrophoresis will m ove that radioactivity to a specific position in the gel, which is detectable by standard instruments . Note that in Figure 6A top ranked kinase candidates NEK2 and PKN1 exhibit a labeled p53 band, as does a known p53 kinase CHK1 [28] (used here as a positiv e control). The PKN1 band is faint relative to the others, but in subsequent experiments, the interaction was found to be robust. In contrast, low ranked p53 kinase candidates PDGFRA, TNK2, and INSRR exhibit no 53 kilodalton band, indicating they are unlikely to be p53 kinases. Figure 6B shows a different approach for validating the predictions. The goal of this assay is to show that there is a physical protein -protein interaction between p53 and the predicted kinase s. This is considered a strong indica tion that the kinase is likely to target p53. Human cells containing p53 and a candidate kinase are generated and analyzed . Proteins from the cell are isolated and a p53-specific antibody is then added ; an antibody is a substance that will bind to and iso late a specific protein, in this case p53, along with any protein that is bound to it, in this case -if the prediction is correct -the kinase being tested . This isolate is then separat ed by size, and an additional antibody is used to test for the presence of each candidate kinase. In Figure 6B, each column, or  X  X ane X , represents a different set of experimental conditions. Lane 1 shows that p53 was indeed bound to NEK2, with lanes 2 and 3 as controls that show both NEK2 and the p53 antibody must be present to achieve this result . Lane 2 shows that p53 was bound to PKN1 . These two sets of experiments argue strongly that computationally predicted top p53 kinase candidates PKN1 and NEK1 are ind eed true p53 kinases. This early study tackles a basic problem that is challenging progress in every field of human intellectual activity: we have become much better at generati on of information than at its integrative analysis. This leads to deep inefficiencies in translating research into progress for humanity. No scientist can keep up with the unrelenting flow of new studies and results , even within specialized fields . While intuit ion and selective reading in a highly narrowed field of work are essential and can certainly lead to breakthroughs, they are also likely to lead most scientists at one time or another towards deeply unproductive hypotheses that might have benefitted from m ore comprehensive insights into the data that was available but which we could not find an opportunity to learn about. Specialization also inherently limits the opportunities to find common grounds at the interface between fields, even though these interfa ces are often are among the deepest areas of scientific synthesis. Baylor College of Medicine and IBM Research have joined forces for the purpose of combining talents and technologies in many diverse fields to accelerate scientific discoveries that lead t o improved patient outcomes. This research represents the first stage in this collaborative effort and as such it proves the principle that mining past literature is a viable strategy for predicting previously unknown biological events. We have shown th at p53 kinases predicted with our text mining methods are supported by laboratory findings. In the future, it should be possible to make many other kinds of predictions on a much larger scale as our infrastructure and capabilities ramp up.
 In the future o ur team will focus on a wider area of proteins and functions, building up comprehensive networks of interactions and predicting where new connections ought to exist based on everything else that is known. We believe this will ultimate ly accelerate the pace of cancer discoveries by an order of magnitude and allow scientists to come to a much more complete understanding of the mechanisms behind this disease. We also feel that the general approach of mining literature to identify hidden relationships between entities is not confined to cancer or even to biology, but is a general tool that can be applied in almost any science. The potential for dramatic acceleration of discovery in all sciences holds out the possibility of tremendous benefits for human health and for societal progress in the coming years. Given the enormous challenges facing science today on a global scale, with ever more complex systems of entities and networks of relationships, the acceleration of discovery is not only desirable, but also indispensable for human flourishing. This work was supported by the Robert and Janice McNair Foundation , DARPA ( N66001 -14-1-4027) , National Science Foundation (NSF CCF -0905536, NSF DBI -1062455) , National Institutes of Health (NIH -GM079656) , and was supported in part by the IBM Accelerated Discovery Lab. [1] ALTSCHUL, S.F., GISH, W., MILLER, W., MYERS, [2] ASHBURNER, M., BALL, C.A., BLAKE, J.A., [3] BELKIN, M., MATVEEVA, I., and NIYOGI, P., 2004. [4] BJ X RK, B. -C., ROOSR, A., and LAURI, M., Global [5] CHUNG, F.R.K., 1997. Spectral Graph Theory [6] COORDINATORS, N.R., 2014. Database resources of [7] DA COSTA, C.A., SUNYACH, C., GIAIME, E., [8] DAI, C. and GU, W., 2010. p53 post -translational [9] DERDAK, Z., VILLEGAS, K.A., HARB, R., WU, [10] GOH, K.I., CUSICK, M.E., VALLE, D., CHILDS, B., [11] GRAY, K.A., DAUGHERTY, L.C., GORDON, S.M., [12] GU, B. and ZHU, W.G., 2012. Surf the post -[13] HAGER, K.M. and GU, W., 2014. Understanding the [14] HORNBECK, P.V., KORNHAUSER, J.M., [15] JENKINS, L.M., DURELL, S.R., MAZUR, S.J., and [16] JINHA, A.E., 2010. Article 50 million: an estimate of [17] LANGLEY, P., BRADSHAW, G., and SIMON, H., [18] LARSEN, P.O. and VON INS, M., 2010. The rate of [19] LI, M., HE, Y., DUBOIS, W., WU, X., SHI, J., and [20] LISEWSKI, A.M. and LICHTARGE, O., 2010. [21] MANNING, G., WHYTE, D.B., MARTINEZ, R., [22] MAY, P. and MAY, E., 1999. Twenty years of p53 [23] MEEK, D.W. and ANDERSON, C.W., 20 09. [24] MULLER, P.A. and VOUSDEN, K.H., 2013. p53 [25] NATHANSON, J.W., YADRON, N.E., FARNAN, J., [26] SALTON, G. and MCGILL, M.J., 1986. Introduction to [27] SHAWVER, L.K., SLAMON, D., and ULLRICH, A., [28] SHIEH, S.Y., AHN, J., TAMAI, K., TAYA, Y., and [29] SIGANAKI, M., KOUTSOPOULOS, A.V., [30] SRINIVASAN, P., 2004. Text mining: generating [31] SWANSON, D.R., 1986. Fish oil, Raynaud's syndrome, [32] UNIPROT, C., 2013. Update on activities at the [33] WHEELER, D.L., CHURCH, D.M., FEDERHEN, S., [34] ZHOU, D., BOUSQUET, O., WESTON, J., and 
