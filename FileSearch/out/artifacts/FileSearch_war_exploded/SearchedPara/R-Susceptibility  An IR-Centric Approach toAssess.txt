 Privacy of Internet users is at stake because they expose personal information in posts created in online communities, in search queries, and other activities. An adversary that monitors a community may identify the users with the most sensitive properties and utilize this knowledge against them (e.g., by adjusting the pricing of goods or targeting ads of sensitive nature). Existing privacy models for structured data are inadequate to capture privacy risks from user posts.
This paper presents a ranking-based approach to the as-sessment of privacy risks emerging from textual contents in online communities, focusing on sensitive topics, such as be-ing depressed. We propose ranking as a means of modeling a rational adversary who targets the most afflicted users. To capture the adversary X  X  background knowledge regard-ing vocabulary and correlations, we use latent topic mod-els. We cast these considerations into the new model of R-Susceptibility, which can inform and alert users about their potential for being targeted, and devise measures for quan-titative risk assessment. Experiments with real-world data show the feasibility of our approach.
 Privacy Risk Assessment, Online Communities
The goal of this paper is to provide privacy risk assess-ments for users in online communities. An online post may directly or indirectly disclose personal information, such as gender, age, political affiliation, or interests. An adver-sary can combine such observations with his background knowledge of correlations between different attributes to in-fer privacy-sensitive information and discriminate against users. We argue that existing privacy models for struc-tured data, such as k-anonymity [33], l-diversity [24], t-closeness [22], membership privacy [23] and differential pri-vacy [10], are inherently inappropriate to capture these sit-uations. One reason is that user posts in social media are mostly of textual form, inducing a high-dimensional data space of word-level or phrase-level features. A second reason is that users might not want to be prevented from posting contents, but instead be selectively warned about emerging privacy risks. In our setting, certain assumptions also differ from the assumptions of prior work on privacy-preserving data publishing [13]: users do want to post information, but they should be aware of possible exposure and targeting risks. For these reasons, this paper pursues an IR-centric approach to privacy, making novel use of topic models and ranking.

Scenario: To understand why adversaries and user risks are different from the privacy concerns for structured databa-ses, consider the following scenario. An unscrupulous drug company wishes to advertise its new anxiety-reducing drug to Facebook users. It decides to target ads at a million users that are most susceptible to be afflicted by depression within the 1 billion population of Facebook. The company plans to infer users X  demographics by text mining their posts and combine it with the background knowledge correlating de-mographics and certain vocabulary usage with depression, obtained from text mining an archive of medical journals. In such a scenario, how can a Facebook user estimate her risk of being targeted? Similar issues arise also within spe-cialized online communities such as healthboards.com or patient.co.uk . Although these have a much smaller scale, a smart adversary would still target only a subset of highly susceptible users to avoid the impression of mass spamming.
Targeted ads of sensitive nature constitute one kind of risk, but there are even more severe threats with real cases reported: scoring users for financial credit worthiness or in-surance payments, factoring a user X  X  social-media posts in assessing her job application, and more (e.g., [7, 12]). De-spite these being big trends, most users do not need hard guarantees regarding privacy (e.g., preventing de-anonymiza-tion by all means), and perfect anonymity cannot be guar-anteed without severely diminishing the utility of social me-dia. For example, someone who always posts using a one-off anonymous identity cannot build up a reputation as a cred-ible information source. Conversely, even making all posts under a pseudonym is insufficient to prevent tracking-and-rating companies (e.g., www.spokeo.com ) from linking user accounts across different social platforms. Therefore, we fo-cus on the assessment of privacy risks and on alerting users to support their awareness, rather than pursuing the elusive goal of enforcing privacy.

Existing privacy models fail to capture theses issues, along the following dimensions:  X  Data model : Privacy models like k-anonymity or differ- X  Adversary X  X  background knowledge: Prior work on pri- X  Disclosure vs. discrimination risk: Existing privacy mod-
This paper introduces R-Susceptibility : a ranking-based privacy risk model for assessing users X  privacy risks in on-line communities, accompanied by IR-style risk measures for quantifying risks from textual contents. The model is very versatile: in this paper we demonstrate how it can capture user posts or search queries, but it can also be used with click streams, and other online activities. Semantic dependencies and statistical correlations among words and sensitive top-ics are represented using latent topic models, such as LDA [5] or Skip-grams [25]. This way, we anticipate adversaries with rich background knowledge. Adversaries are assumed to be rational: they target only a fraction of  X  X romising X  users. Therefore, we model the risk of a user as the ranking position in the community when all the users are ordered by the relevance of their contents to sensitive topics, such as pregnancy, depression, financial debts, etc. This ranking-based model is meant to alert the users whenever critical situations arise. We posit that users might be then guided to selectively post anonymously.

Our model addresses several technical challenges:  X  Sensitive vs. general topics: A trained latent topic model  X  Personal vs. professional interest: A user who posts  X  Personal interest vs. curiosity: A user may become in-
The paper X  X  salient contributions are:  X  a novel approach to privacy risks focusing on exposure  X  a framework for quantifying privacy risks from textual  X  measures for computing risk scores with regard to sensi-
We assess the risk of a user being perceived as afflicted by a sensitive state , such as depression, pregnancy, or financial debts. An adversary in our model attempts to find the most susceptible users, that is, the users who are most exposed with regard to a sensitive state. For instance, an adversarial insurance company might want to identify the users who are likely afflicted by certain diseases, an adversarial HR department of a company might want to screen for the users with likely drug or alcohol problems, while a seller of illegal anti-depressants might want to find the users most likely to be depressed, and thus prospective customers.

We therefore propose ranking as a means of modeling a rational adversary trying to identify the most susceptible users. To rank the users with respect to a given sensitive state, an adversary needs to choose a measure of quantitative risk assessment based on the contents of user profiles. We discuss several such measures in Section 3.
We associate sensitive states with a vocabulary distribu-tion, i.e., distributional vectors of related words. For ex-ample, the topic financial debts , could be captured by re-lated words and phrases like loan, mortgage, money, prob-lem, sorrows , or sleepless night . Such salient phrases re-lated to a sensitive state can be obtained by unsupervised or semi-supervised training of latent topic models over exter-nal datasets such as news archives, digital libraries or large crawls of social media. This way we capture the adversaries X  background knowledge about the vocabulary for a topic and about semantic dependencies and correlations.

Sensitive states might manifest themselves in the online contents of users. User posts can also be characterized as distributional vectors of salient words. Then, the similarity between the distributional vectors of the user X  X  posts and a sensitive topic can be used to assess the user X  X  susceptibility to being exposed with regard to that topic.
An adversary in our model is assumed to be interested in a sensitive state and aims to target a fraction of the most afflicted users. The adversary has background knowledge , characterized by statistical language and topic models. This is a natural form of useful knowledge for a rational adversary who wants rank the users based on the textual contents, and to bound the cost of his targeting efforts.

In this paper, we consider three versions of adversary X  X  background knowledge. The basic version is the knowledge of the most salient words for different topics, which is as-sumed in all the solutions we explore. The more advanced version assumes that the adversary is able to compute simi-larities between words, in the sense of semantic relatedness. Finally, in some of the solutions, we assume an adversary is able to assign latent topics to broader thematic domains, e.g., the topic of depression to the domain of psychiatry.
We believe that this model reflects a wide class of ad-versaries whose goal is to discriminate and target the most susceptible users in online communities.
We propose R-Susceptibility (Rank-Susceptibility) as a measure of a user X  X  privacy risk. To measure R-Susceptibility with respect to a sensitive topic, we first rank all users within an online community based on their decreasing susceptibil-ity of being exposed with regard to a sensitive topic (as described above) and then compute the position where the user is ranked.

Intuitively, the R-Susceptibility model could also have the following IR interpretation: we rank the users according to the relevance of their posts to a query containing the words of a sensitive topic, and choose the top-ranked, who should be the most likely to be personally afflicted.
Risk measures are plug-in components in the framework and orthogonal to the idea of R-Susceptibility. In this paper, we begin by investigating three kinds of risk scores, leaving an extended risk-measure study as future work.

The first two of the risk scores are baselines, inspired by standard measures in privacy research, namely, the entropy of attribute value distributions (as used in the t-closeness model) and the changes in the global probability distribu-tions of attribute values incurred by the inclusion of an indi-vidual user X  X  data (as used in the differential privacy model). The third measure is a novel IR-centric score based on topic models, capturing lexical correlations and three different characteristics of user interest in a topic: the strength of interest, the breadth of interest, and the temporal variation of interest.
 Desired properties. By considering the community and interpreting risk with respect to a user X  X  rank in the com-munity, our framework does not impose any restrictions on the absolute values or the value domains of valid risk mea-sures. Intuitively, for the framework to function, we expect a good measure to correlate with human assessments on the sensitivity of user profiles: the more human observers agree that a user might be in a senitive state, the higher the value of the risk score should be.
The entropy baseline measure is inspired by comparing a global probability distribution (for an entire community) against a local distribution (for an individual user) using relative entropy (aka KL divergence). We apply this measure to textual data as follows.

Let X be a sensitive topic, and { x 1 ,...,x j } be the salient words and phrases of X . The knowledge of this vocabulary for different topics is assumed to be a part of the adversarial background knowledge (e.g., derived from latent topic mod-els). We treat x 1 ,...,x j as database attributes and represent users as database records where the value of an attribute x equals to 1 if the word appears in the user X  X  contents, and to 0 otherwise.

Let U 0 be the user for whom we wish to compute the risk score with respect to X , and U = { U 1 ,..,U k } be the set of other users in the community. Let further be U  X  = { U 0 } X  U , and let P U ,P U  X  denote the distributions of attribute values for U and U  X  , respectively.

We compute the risk score by averaging the relative en-tropy of the univariate distributions P U ,P U  X  for the individ-ual attributes { x 1 ,...,x j } . Note that measuring the relative entropy over the multivariate joint distributions of attributes could be an alternative, but we do not pursue this here be-cause of the data sparseness that we would face.
 Definition 1 (Entropy baseline risk score of topic X for U The entropy baseline risk score of the user U 0 with respect to a topic X is: risk ENT ( U 0 ,X ) = 1
The ranking method based on this definition is being re-ferred to as ENT .
 Measure properties. It holds that risk ENT ( U 0 ,X )  X  0. The lowest value of 0 is reached when the user does not have any of the topic X  X  salient attributes in her observable contents. Otherwise, the risk score is lowest when half of the community X  X  users exhibit an attribute in their contents and highest when all or none of the users have the attribute.
The differential-privacy-based measure is inspired by the definition of differential privacy, that is calculating the chan-ges of attribute probabilities incurred by the inclusion of a user X  X  data. Let X , { x 1 ,...,x j } , U 0 , U , U  X  , P defined as in the previous section. The differential privacy principle requires that
P U [ x i ]  X  2 P U  X  [ x i ] and P U  X  [ x i ]  X  2 P U [ x for some small &gt; 0. To give an -differential-privacy guar-antee, existing methods would perturb the data by Lapla-cian noise if the inequalities are not already satisfied. How-ever, our  X  X ttributes X  are words in user posts that the user intentionally chose and our goal is to quantify risk rather than perturb the data. We thus aim to determine the best possible value of for which the guarantee holds without perturbation. This is the minimum for each x i , but the guarantee is only as strong as the weakest x i , leading to the following formulation: Definition 2 (Differential-privacy baseline risk score of topic X for U 0 ) . The differential-privacy baseline risk score of the user U 0 with respect to a topic X is: risk D-P ( U 0 ,X ) = max
The ranking method based on this definition is being re-ferred to as DIFF-PRIV . Measure properties. It holds that risk D-P ( U 0 ,X )  X  0. The risk value is lowest for a user who does not have any of the sensitive topic X  X  salient attributes in her contents and highest for a user who has a critical attribute that is not present in the contents of any other user.
The third measure we consider is IR-style and based on topic models. To this end, we construct a distributional representation of each of the sensitive topics X (e.g., finan-cial debts), user contents U (e.g., from an online community such as quora.com ), and each post P the user authors in the online community. We model X , P and U as vectors in a distributional vector space. Topic vectors. Topics are represented as vocabulary dis-tributions found by collecting word statistics over suitably chosen corpora.
 Definition 3 (Sensitive Topic Vector) . For sensitive topic X , the topic vector is a distributional vector ~ X constructed using words or bigrams weighted by topic relevance.
For example, hiv and positive are salient for the topic of hiv infection. Such topics and their salient phrases can be automatically extracted by applying latent topic analysis to large, thematically broad text corpora.
 User vectors. To be able to relate posts and users to topics, we map each user U and post P created by the user in an online community to a vector.
 Definition 4 (User Post and User Vectors) . The content of a post P of a user U is modeled as a distributional vector ~ P . User U in the context of a topic X is modeled as a distributional vector ~ U defined as: Vector construction. The exact mapping of topics and posts to vectors depends on the vector space in which we are operating. We use three different configurations in our experiments: i) a bag-of-words model ( bow ), ii) an LDA model ( lda ), and iii) a Skip-gram model ( w2v ).

Note that the use of LDA here is to construct a lower-dimensional vector space; this is orthogonal to using LDA for obtaining topics with their salient phrases, which we dis-cussed above.

In the bow vector space, we create topic vectors directly over the characteristic topic words with binary scoring; we also use these words as features with tf-scoring for user and post vectors.

In the lda model, topic vectors are indicator vectors of for the latent dimensions. Users and posts are treated as documents that LDA maps into its low-dimensional latent space.

The third technique that we consider, w2v , is a model based on learning word relatedness, which can be trained over large text corpora [25]. To create the topic vectors in this word-centric vector space, we compute a weighted sum of words from the previously computed sensitive topic dis-tributions. Since there is no natural mapping of documents to vectors in this setting, the procedure for posts is similar. However, to discount the impact of words unrelated to the topics at hand, we introduce a topic-dependent weighting scheme for user vectors. Namely, for a topic X and a post containing the set of words { v 1 ,v 2 ,... } , the post vector is ~ P = P j cos ( ~v j , ~ X )  X  ~v j .
 Risk scoring. Given these vectors, we can now compare a user posting history against a sensitive topic by vector-based similarity measures, like the cosine similarity. An advantage of this risk measure is that, unlike the entropy or diff-priv measures, it does not require any community-level data, as the risk score of a user is independent of other users X  data. Thus, each user can compute her score locally and privately, and send the value to a server to obtain an R-Susceptibility rank.

In addition to quantifying the strength of user interest in a sensitive topic, we also capture the breadth and temporal variation of that interest. This is crucial to avoid erroneously ranking higher those users who have a professional interest in a topic without being personally afflicted, or are temporarily interested out of curiosity. In our previous preliminary work in this area, we identified these two components to be crucial for reducing classification error in a similar setup [4].
Having a vector representation of a user U , we can now compute the similarity between U and a topic vector X . Definition 5 (Topic-aware risk score) . The strength-of-inte-rest risk score for a user U with respect to a topic X is:
We further refer to methods based on this definition as bow , lda , and w2v .
 Measure properties. It holds that  X  1  X  risk ( U,X )  X  1. A high value of this measure means the user has at least one post with vocabulary related to the topic. Thus, the strength of interest is reflected by the presence of the topic X  X  salient vocabulary in user posts.
When ranking users, an adversary might want to distin-guish between users who show a focused interest in a topic and users who show a broad interest in many topics within a domain, ranking the former higher than the latter. Applying this strategy could help, for instance, to capture users who are not personally afflicted but rather showing educational, hobbyist or professional interest in a topic. For example, for the topic of financial debts, a bank agent or finance hobbyist could offer advice in Q&amp;A communities; similarly, a medical doctor or student could engage herself in health forums.
The posts of a user with a broad interest should exhibit a diversity of topics within their respective domain. We aim to capture this behavior, by means of distributional vectors, assigning each topic X to a broader domain, like finance, medicine, psychology, etc.
 Definition 6 (Domain Vectors) . A domain D is a set of topics X 1 ,...,X | D | and its vector representation is a set of corresponding topic vectors ( ~ X 1 ,..., ~ X | D | ) .
To assess the risk taking into account whether a user U has a focused or a broad interest in a topic X , we compute: 1. how similar ~ U is to ~ X and 2. how dissimilar ~ U is to the domain D by computing the If both of these measures are high, then we conclude that U is personally afflicted by topic X .
 Definition 7 (Domain-aware risk score) . The domain-aware risk score for a user U with respect to a topic X from the domain D is: risk D ( U,X ) = cos ~ U, ~ X  X  max d k  X  X  D |e { cos ~ U,
We further refer to methods based on this definition as bow-d , lda-d , and w2v-d .
 Measure properties. It holds that  X  2  X  risk D ( U,X )  X  2. The value would be high for a user who has a post contain-ing topic X  X  salient vocabulary, but whose contents do not exhibit any vocabulary from other topics in the respective domain. A low value occurs in a situation where the user has not written any posts related to the topic at hand, but has contents related to other topics in the domain. Studying the relative importance of the two components in different online communities is an interesting topic of future work.
The intuition for parameter k is that a personally afflicted user would not have high posting activities in k -fraction of different topics within the same domain. The value of the parameter controls how large the domain coverage should be for the users to be considered broadly interested. In practice, setting this parameter requires the knowledge of the breadth of topics discussed in a particular community.
Being interested in users most likely afflicted by a given state, we would like to rank the users who exhibit recurring activity regarding a topic X higher than the non-afflicted (possibly curious or exploratory) users exhibiting a short-term interest in the topic. Such a bursty activity might be prompted by prominent news related to X , be it sex scandals in the press, or social campaigns about depression.
To capture this issue, rather than computing a user vec-tor ~ U over the entire user history, we divide the history into time buckets and compute a sequence of vectors ~ U the contents from each bucket i separately. In our model, bucketization may be realized at different granularity levels depending on the user observation period and the charac-teristics of the community.

We then identify the top-m time buckets with the highest risk level, representing m different time periods (such as days or weeks). Let us denote these buckets of the user model as U  X  1 ,...,U  X  m . A user whose interest in X is clearly above the level of a bursty interest (signifying occasional curiosity) would consistently have high risk scores in all of the top-m buckets. This leads us to our next definition of a user X  X  privacy risk regarding topic X .
 Definition 8 (Time-aware risk score) . The time-aware risk score for a user U in time period i with respect to a topic X is:
We further refer to methods based on this definition as bow-t , lda-t , and w2v-t .
 Measure properties. It holds that  X  1  X  risk T ( U,X )  X  1. The value would be high for a user whose posts contain relevant topic vocabulary in at least m observation buckets, and low for a user who does not exhibit topic X  X  vocabulary in their contents.

The choice of a particular value of the m parameter de-pends on the available observation timeline and the charac-teristics of a given community. The parameter controls how often the activity regarding a topic should occur in order to not be considered occasional.
The final measure we introduce combines all the aforemen-tioned dimensions of interest. Note that we use bucketized user contents for computing the temporal variation com-ponent, but the breadth-of-interest component is computed over the full contents.
 Definition 9 (Domain-and time-aware risk score) . The risk of user U in time period i for topic X in domain D is: risk DT ( U,X ) = avg i =1 ..m n cos ~ U  X  i , ~ X o  X  cos
We further refer to methods based on this definition as bow-dt , lda-dt , and w2v-dt .
To complete our framework, we need to train a back-ground knowledge model and answer the remaining question of how to identify sensitive topics. Although our model is ap-plicable to any topic irrespective of its sensitivity, in practice users would only be interested in their R-Susceptibility ranks for truly sensitive topics. There is indeed a systematic way of gathering such information in a reasonably inter-subjective manner: training a latent topic model on a background cor-pus and crowdsourcing sensitivity judgments for each topic. This section presents our results along these lines. Datasets. We trained 3 LDA models, using the Mallet topic modeling toolkit: i) with 500 topics, on 600K Quora posts we crawled ii) with 200 topics, on 3M posts from health Q&amp;A online forums, and iii) with 500 topics, on a sample of 700K articles from the New York Times (NYT) news archive. Crowdsourcing sensitivity and domain judgements.
 We collected human judgements regarding the sensitivity and the domains of topics using Amazon Mechanical Turk (AMT), employing only master workers from the USA, and collecting 7 judgements per topic. For each of the topics, the workers were shown the 20 most salient words computed by LDA, and asked whether they would consider a post in social media containing these words privacy-sensitive. We explained that by privacy-sensitive we mean that a person uses these words because he/she is in a privacy-sensitive sit-uation (e.g, alcohol addicted), or that the usage of these words might lead to a privacy-sensitive situation (e.g., po-litical extremism). The first condition can capture, for in-stance, words related to diseases, the second can capture words related to political or religious positions.

We computed Fleiss X  Kappa to measure the inter-annotator agreement for this task, obtaining 0 . 241 for the Quora top-ics, 0 . 294 for the HF topics, and 0 . 157 for the NYT topics. These low values confirm that sensitivity is rather subjec-tive. However, there is a considerable number of topics in all of these corpora, which were unanimously or almost unan-imously rated as sensitive. These were mostly related to Table 1: #topics with #judges agreeing on being sensitive topics. Table 2: Examples: vocabulary of sensitive topics.
Topic Vocabulary pregnancy baby birth pregnancy pregnant mother woman born child financial debts debt loan pay student interest payment money owe health, private relationships, political and religious convic-tions, personal finance, legal problems and others. Table 1 shows the numbers of topics on which certain numbers of judges agree on their sensitivity.

The judges were also asked to assign a topic to one of seven high-level categories. Six of these, potentially con-taining some sensitive topics, were chosen based on the top-level Microsoft Academic Search categories. The annotators could also choose a generic category other .
 Topics for evaluation in Section 5. For our further experiments, to make the much more laborious and costly evaluation of user profiles feasible, we leverage the above study to restrict the evaluation to 5 topics from the group of the most sensitive topics. The choice of particular topics is guided by the reported cases of social media screening by insurance companies, employers, and credit companies mentioned in Section 1. These are: clinical depression , drug addiction , hiv , pregnancy , and financial debts , assigned to the domains of psychology , medicine , and finance&amp;economy . Table 2 shows the most prominent words for each of the chosen topics from the Quora topic model.
To test our methods in a variety of scenarios, we con-structed three datasets using online communitites of differ-ent nature. As a first data source, we used the AOL query log collected between March and May 2006. The resulting data source amounts to around 107 K users and more than 13 M queries. The second data source consisted of over 5M posts spanning 13 years (2000-2013) from healthboards and ehealthforum Q&amp;A health communities. We also collected data from the Quora Q&amp;A community over a period of three months, between February and May 2015. The crawl fo-cused on Quora users who were active in categories related to the considered sensitive topics and their domains, and comprised more than 200K users and 1.3M posts.
 Ethics. To adhere to ethical standards concerning incorpo-ration of user data into research, we decided to only use data that is publicly available  X  either as online profiles (Quora, Health Q&amp;A), or as datasets used in numerous other stud-ies (AOL). We never attempted to identify the individuals whose profiles we analyzed.
We created our datasets by sampling the users from the data sources described above. However, we encounter a tech-nical challenge, as the number of sensitive users for a given topic is very small when compared to the size of the whole community. Sampling users uniformly would not constitute a good benchmark for risk scoring methods. For example, we could achieve high accuracy, in a misleading way, by the simplistic prediction that all users are non-sensitive.
What we want, though, is ranking evaluation  X  our goal is to see how sensitive the users are in different ranking re-gions. Therefore, our sampling method is non-uniform and proceeds as follows. We first rank all users for each of the datasets using our basic strength-of-interest method from Section 3.3.2, and then sample users from this ranking. To pick a user, the sampling procedure orders users by their score, then computes prefix sums  X  i for all users up to user i , with  X  n being the score sum for all users. Then we draw a random number between 0 and  X  n . If the number falls between  X  i and  X  i +1 , we choose user i + 1 (with users num-bered from 1 to n . However, given that risk scores are ex-tremely skewed, this sampling does still not yield good cov-erage of all the ranking regions. Therefore, we transform the original risk score q into a q , where constant a needs to be determined based on the score skew in a data source. The intuition is to give a higher probability of being sampled to users with higher scores, so that the final sample set has good coverage of users with both high and low scores. Fig-ure 1 depicts the depression risk scores of our 100 samples from the AOL data vs. the scores of the original dataset of 170K users.

In our case, a value of a = 10 2 for the Health Q&amp;A, and a value of a = 10 3 for the AOL were reasonable to compensate the skew. For each of these datasets, we sampled 100 users for each sensitive topic. We did not perform this kind of sam-pling for Quora, as our dataset was based on a focused crawl in the first place with focus on sensitive discussion threads. Since evaluating sizeable Quora profiles requires much more effort, for this data source we constructed smaller datasets with 40 users per topic. In total, our datasets comprised 1100 user profiles: personal histories of posts or queries.
To assign sensitivity labels for user-topic pairs as ground truth, we used crowdsourcing and asked human judges to examine user profiles with chronologically ordered textual posts. Specifically, we asked whether based on the content Figure 1: Example comparison of risk scores of sam-ple vs. full data.
 Table 3: Number of sensitive users according to judges X  assessments ( x/y means x sensitive users out of y in total).
 of the profile, the judge suspects that the user (or a family member) is in a given sensitive state.

To evaluate the AOL and Health Q&amp;A datasets, we em-ployed AMT master workers from the USA and collected 5 judgements for each of the profiles. Since the majority of Quora profiles contain hundreds of posts, to ensure that proper care is given to evaluating them, we collected the judgements employing 19 students from our institutions.
We computed Fleiss X  Kappa to quantify the global inter-annotator agreement across all the topics. The respective values for the AOL, Health Forums and Quora datasets were 0.442, 0.444, and 0.468 respectively, all corresponding to a moderate agreement. Table 3 shows the number of users who were marked by the human judges as sensitive by a majority vote.
To evaluate the topic-model-based method, we used three different distributional vector spaces: a bag-of-word vector space, as well as two 500-dimensional vector spaces trained with (i) the LDA implementation from the Mallet toolkit and (ii) word2vec 1 tool [25]. The latter two models were trained on NYT and Quora corpora described in Section 4.
In the breadth-of-interest model from Section 3.3.3, we set the parameter k to 0 . 3, i.e. we want a user of a broad interest in a domain to have at least a 30% coverage of topics from the domain. https://code.google.com/p/word2vec/ In the temporal-variance-of-interest models described in Section 3.3.4, we compute the results using weekly time buckets and set the number of buckets parameter m to 3.
We later analyze the robustness of the ranking methods with respect to these parameters.  X  R-Precision. For a given sensitive topic, where r users  X  Mean Average Precision (MAP). For a given sen- X  Normalized Discounted Cumulative Gain (NDCG).

The number of topics in our experiments is too small to perform significance tests over macro-averaged metrics. We thus resort to performing a paired t-test over r-precision dif-ferences on individual test samples within a dataset, marking the significance in the micro-averaged r-precision columns in the result tables. The  X  symbols denote the case when the gain of a given ranking method over the baseline ( ent and diff-priv in Table 4, strength-of-interest baselines within a block of results for a given vector space in Table 5) is statisti-cally significant with a p-value &lt; 0 . 05. This lets us conclude that a good r-precision score of a ranking method does not likely depend on the particular choice of user profiles.
The remainder of the experimental section seeks to answer the following research questions.
 RQ 1: Do the proposed topical risk measures perform bet-RQ 2: Does the topical risk scoring measure perform bet-RQ 3: How robust is the proposed method against changes
We begin the risk scoring methods analysis by comparing the effectiveness of the baseline ( entropy , diff-priv ) and Table 4: Average metrics over all sensitive topics for different risk assessment measures entropy 0.495 0.496 0.760 0.524 0.819 diff-priv 0.475 0.465 0.480 0.492 0.789 w2v 0.556  X  0.533 0.720 0.589 0.836 entropy 0.560 0.537 0.750 0.613 0.870 diff-priv 0.560 0.559 0.500 0.542 0.794 w2v 0.664  X  0.634 0.750 0.696 0.894 entropy 0.239 0.205 0.240 0.317 0.632 diff-priv 0.239 0.223 0.200 0.310 0.623 w2v 0.343  X  0.341 0.280 0.352 0.637 the strength-of-interest topical risk scoring methods. Here, we choose the baseline IR-based methods for comparison, while exteding the measures with dimensions of interest will be addressed in the sections to follow.

Table 4 shows that the lda risk scoring outperforms the alternatives (similar observation holds for w2v ), which con-firms that these methods are not naturally applicable to tex-tual data in the context of risk scoring. The relatively good Precision@5 of these measures indicates that the most sensi-tive users tend to use highly salient words. However, operat-ing on explicitly given salient attributes for each topic, the baseline measures do not capture any lexical correlations, an important prerequisite to capture users manifesting their sensitivity in a less direct way. This result validates the need to design new privacy risk measures better tuned to textual contents.
We posited that extending the topical risk measures with the breadth and the temporal-variation dimensions of inter-est can help to predict sensitivity judgements better. Table 5 shows the evaluation results averaged over all topics, con-firming that incorporating breadth and temporal variation into the risk score indeed improves the ranking performance.
We observe that breadth-of-interest is especially impor-tant for Quora, which is a Q&amp;A community with a very wide variety of topics. Many Quora users seem to frequently post replies prompted by others rather than by their personal sit-uation; hence the lower impact of the temporal component. Contrary, in AOL the temporal component takes over. With merely implicit cues in the form of queries, the temporal di-mension is an important indicator of user sensitivity (also for the annotators). The breadth-of-interest component per-forms worse for AOL, possibly due to the short time span of the query log (3 months).

Note that in case of the proposed breadth-of-interest score, an underlying assumption is that an adversary is able to assign latent topics to broader thematic domains. Thus the best performing -DT methods imply a stronger background knowledge of an adversary.

Table 6 shows the values of r-precisions split by the topic, for different variants of lda -based risk scoring. The trends observed in the results averaged over all topics can be seen here as well -there are consistent improvements across topics when incorporating the temporal and breadth dimensions. These results constitute anecdotal evidence that the pro-posed methods are general enough to be potentially applied to a variety of topics. Model changes. The BOW vector space models only an adversarial knowledge of salient words for different topics, whereas the latent vector spaces additionally enable an ad-versary to compute similarities between arbitrary words. The results presented in Table 5 show that this has a direct consequence in the risk ranking performance. The methods with the latent models as the background knowledge outper-form the methods with the BOW background knowledge, while being comparable with each other. Thus the model seems resilient to rational background knowledge model chan-ges, capturing a wide class of adversaries -the rational, cost-aware adversaries adopting latent models.
 Training corpus changes. The results presented in the experimental section were obtained using the Quora topic model as the background knowledge model. We ran addi-tional experiments using the NYT topic model described in section 4.1, and noticed that for the topics which were cap-tured in the other latent model as well, we observe similar trends and dependencies in the results. This would suggest that an adversary has the freedom to choose among the in-puts where his topics of interest are well captured. Parameter changes in risk measures. The topical risk measures introduce two parameters: k for coverage of do-main topics, and m for the number of (weekly) time buck-ets. Observing the values of r-precision and NDCG obtained when varying these parameters between k = { 0 . 1 , 0 . 2 ,..., 1 . 0 } , and m = { 1 , 2 ,..., 12 } , yields the following observations. First, when the parameters are set to values from the lower half of the ranges, we still observe improvements over the baseline strength-of-interest measure. Second, when the pa-rameters are set to higher values, the results tend to dete-riorate, possibly due to the incompleteness of user profiles in our datasets. Third, we observe higher sensitivity to pa-rameters when a given dimension of interest is important for a given community (e.g. temporal for AOL, breadth for Quora). This result suggests that there is room for im-provement within the framework of R-Susceptibility in that community-specific risk measures could be employed.
The presented experimental results suggest that R-Suscep-tibility with appropriate risk measures is able to identify sensitive users with reasonable accuracy. The topical risk measures that quantify a user X  X  exposure with respect to different topics work well, especially when the domain-and time-awareness components are included.

The R-Susceptibility framework allows the plugging of different risk measures, and in the future more advanced measures could be studied to address some of the limita-tions of this work. These could, for instance, model semi-experts, subtle vocabulary correlations, user contexts, or specific characteristics of a community. bow-d 0.364 0.358 0.394 0.700 0.612 0.580 0.610 0.832 0.418 bow-dt 0.374 0.372 0.441 0.758 0.612 0.597 0.667 0.894 0.463 w2v-d 0.414 0.395 0.427 0.738 0.642 0.600 0.647 0.874 0.493 w2v-dt 0.545 0.530 0.601 0.860 0.687 0.678 0.768 0.939 0.463 lda-d 0.566 0.563 0.557 0.803 0.716  X  0.703 0.772 0.921 0.493 , lda-t and lda-dt for different topics.
 debts 0.542 0.542 0.583 0.542 n/a n/a n/a n/a 0.300 0.500 0.100 0.200
The R-susceptibility model and risk measures can work on a user history in a streaming manner, considering all contents up to a given point and periodically or continuously repeating the risk assessment. These methods could also be embedded in a privacy advisor tool that would help users assess their privacy risk, raising an alert when they become too exposed with regard to a sensitive topic. Data-centric privacy. Methods for privacy-preserving data publising [13] aim at preventing the disclosure of individu-als X  sensitive attribute values, while maintaining data utility, e.g., for data mining [3], using concepts like k-anonymity [33], l-diversity [24], t-closeness [22], and membership pri-vacy [23]. All these models are geared for and limited to dealing with structured data, and this holds also for the most powerful and versatile privacy model, differential pri-vacy [10]. In the field of Private Information Retrieval the goal of retrieving data from a database without revealing the query is mainly addressed by query encryption/obfuscation [36]. Generating dummy queries to obscure user activity is another intensively studied technique (e.g., [29]). Sensitivity prediction. There is little research on charac-terizing what consitutes a sensitive topic. The recent work of [30] analyzed features of posts and user behavior in Quora, and developed a classifier that can predict the sensitivity of individual posts. However, the solution is largely based on explicit categories (rather than latent embeddings) and the  X  X o anonymous X  posting option that users may choose. In contrast, our work aims to understand the sensitivity of any latently represented topic, and provide assessment for risk understood as topical exposure in a community.
 Query log sanitization. This line of work tackles the chal-lenge of an adversary using session information to infer user identities from queries [2]. A variety of techniques have been proposed for anonymizing query logs, e.g., hashing tokens, removing identifiers, deleting infrequent queries, shortening sessions, and more [8, 11, 16, 20, 21]. [15] compared differ-ent methods for publishing frequent keywords, queries and clicks, and showed that most methods are vulnerable to in-formation leakage.
 User-centric privacy. Stochastic privacy [32] is one of the few works that focus on users rather than data. This model introduces a user-defined threshold for sharing data to be obeyed by the platform provider. Closest in spirit to our approach is [4], which uses probabilistic graphical models to infer sensitive user properties, but is very limited in scope. Linkability and de-anonymization. Privacy research for social networks has demonstrated the feasibility of link-ing user profiles across different communities [14] and de-anonymizing users [26, 27, 37]. To prevent such attacks, a family of methods (e.g., [34]) eliminates joinable attributes from published datasets.
 User behavior modeling. It has been shown that search queries can often be used to predict identity of users, as well as their gender, location, and other demographic attributes [18, 17, 35]. Such information can be harnessed for person-alization but may also incur privacy threats. [31] analyzed Twitter profiles and network information to predict the po-litical affiliation and race of users. Expertise identification and trust analysis. Expert and trustworthy users can be identified based on their ques-tions/answers contents and community votes [1] or by an-alyzing user interaction graphs [19, 38]. Unlike in these works, our aim is not to identify experts, but to push the users who have a broad interest in a domain down the pri-vacy risk ranking.
This paper proposes a framework for quantifying privacy risks from textual contents of user profiles in online com-munities. By employing IR techniques such as ranking and latent topic models, it specifically addresses the risk of ex-posure with respect to sensitive topics and targeting by a rational adversary with rich background knowledge about topic vocabulary and word correlations.

Although more large scale studies of adversarial risk scor-ing strategies are needed, our experiments constitute a proof of concept that the approach is a viable basis for privacy risk assessment for users who want to post about sensitive topics but would like to be warned when the risk of being targeted becomes high.

In the future, R-Susceptibility can be extended to incor-porate other forms of online activities, and be integrated in a framework for risk mitigation through appropriately guided user actions. Our vision is a trusted personal privacy advisor which assesses risks, alerts the user when critical situations arise, and guides her in appropriate countermeasures. [1] L. A. Adamic et al. Knowledge sharing and yahoo [2] E. Adar. User 4xxxxx9: anonymizing query logs. [3] E. Bertino, D. Lin, W. Jiang: A Survey of [4] J. Biega, I. Mele, G. Weikum. Probabilistic Prediction [5] D. Blei, A. Ng, M. Jordan. Latent Dirichlet [6] C. Carpineto, G. Romano. K  X  -affinity privacy: [7] Chicago Tribune Online: Social media activity might [8] A. Cooper. A survey of query log privacy-enhancing [9] W. Day, N. Li. Differentially Private Publishing of [10] C. Dwork. Differential Privacy: A Survey of Results. [11] L. Fan et al. Monitoring Web Browsing Behavior with [12] Forbes Online: How Social Media Can Help (or Hurt) [13] B. Fung et al. Privacy-preserving data publishing: A [14] O. Goga et al. Exploiting Innocuous Activity for [15] M. Gotz et al. Publishing search logs  X  a comparative [16] Y. Hong et al. Differentially Private Search Log [17] J. Hu et al. Demographic prediction based on user X  X  [18] R. Jones et al.  X  X  know what you did last summer X : [19] P. Jurczyk, E. Agichtein. Discovering authorities in [20] A. Korolova et al. Releasing search queries and clicks [21] R. Kumar et al. On anonymizing query logs via [22] N. Li, T. Li, S. Venkatasubramanian. t-Closeness: [23] N. Li et al. Membership privacy: a unifying framework [24] A. Machanavajjhala et al. L-diversity: Privacy beyond [25] T. Mikolov et al. Distributed Representations of [26] A. Narayanan et al. On the Feasibility of [27] A. Narayanan, V. Shmatikov. De-anonymizing Social [28] G. Navarro-Arribas et al. User k-anonymity for [29] H. Pang, X. Xiao, J. Shen. Obfuscating the Topical [30] S. T. Peddinti et al. Cloak and swagger: [31] M. Pennacchiotti, A.-M. Popescu. A machine learning [32] A. Singla et al. Stochastic Privacy. AAAI X 14. [33] L. Sweeney. k-Anonymity: A Model for Protecting [34] D. Vatsalan, P. Christen, V. Verykios. A taxonomy of [35] I. Weber, C. Castillo. The demographics of web [36] S. Yekhanin. Private Information Retrieval. CACM X 10. [37] A. Zhang et al. Privacy Risk in Anonymized [38] J. Zhang, M. S. Ackerman, L. Adamic. Expertise
