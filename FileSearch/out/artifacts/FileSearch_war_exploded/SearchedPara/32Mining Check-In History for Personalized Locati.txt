 With the increasing number of mobile devices with positioning capabilities and the diversification of positioning technologies, people can obtain their locations almost anywhere. Therefore, when taking a photo or posting a tweet, they can attach geo-locations; when visiting a Point Of Interest (POI), they can check in and thus show that they have been there; when going out, they can take GPS recorders with them to record their daily trajectories. These locations or trajectories, on the one hand, can help people review their historical trajectories, and on the other hand, can be shared with their friends on online social networks (e.g., photo sharing on Flickr, check-in sharing on Foursquare, Facebook, Twitter, or Sina Weibo, and trajectory sharing on GeoLife [Zheng et al. 2010c]). These locations or trajectories can be exploited for mining popular spots [Zheng et al. 2009; Ashbrook and Starner 2003], constructing and recommending popular routes [Arase et al. 2010; Wei et al. 2012; Zheng and Xie 2011], mobility modeling [Rhee et al. 2011], activity recognition and recommendation [Liao et al. 2007a; Zheng et al. 2010b, 2010a], location recommendation and prediction [Cho et al. 2011; Sadilek et al. 2012; Ye et al. 2011b; Zheng et al. 2011], and so on.

However, raw data from GPS devices only include physical locations without seman-tic names. Attaching physical locations with semantic names usually requires human effort and thus cannot be finished automatically. Take check-ins on Foursquare as an example, Foursquare provides check-in functionality that either lets users input a new location name or selects an existing nearby name (POI) from a location name database for naming users X  current physical locations. Naming a physical location with nearby semantic names (POI) generates a check-in, which can then be posted on Foursquare or synchronized to other social networks for interaction with friends. Such human effort in naming physical locations with semantic names (checking in) gives rise to a natural question: is it possible to do this automatically? If so, it would not only save human effort but also benefit mobile recommendations and advertisement, since the semantic information of locations provides important context for them. For example, if we infer a user is in a shopping mall, we could recommend clothing shops that are offering great discounts.

In this article, we are interested in a location naming problem which aims to au-tomatically map from user X  X  current physical locations to semantic names. Location naming is different from location annotation, which labels previously visited physical locations with activities or categories. Additionally, it is also different from location rec-ommendation, which helps people find potentially interesting but previously unvisited locations, and is different from location prediction, which hopes to predict user X  X  next location instead of the current one. When studying the location naming problem in terms of check-ins, the question is how to automatically map from physical locations to POIs. In particular, when a user performs a query with her physical location, she will receive a ranked list of POIs, the topmost of which is the most appropriate for query location. If the topmost POI in the returned list is the perfect one with respect to the query location, the proposed problem is perfectly answered. Therefore, this question can be boiled down to a POI ranking problem given query location. Since POI ranking for location naming around the same location may be different from person to person and different from time to time, it needs to take into account, a user X  X  history and time, and thus reach a personalized POI ranking problem given location and time. This characteristic of location naming also shows another difference from local search in addition to the keywords requirement of local search.

However, the personalized POI ranking problem given the query location and time is challenging in two ways. First, the number of candidate POIs for ranking is usually large. One reason is that we need to include many farther POIs, since most check-ins take place indoors, which is a place with poor positioning accuracy. When doing in-door localization, GPS easily becomes invalid or has poor positioning accuracy due to the lack of a clear view of the sky. Although this problem can be greatly eliminated by resorting to the GSM positioning techniques, the resulting loss of positioning ac-curacy prevents it from being a good alternative. In addition to the GSM positioning techniques, this problem can also be alleviated by many other approaches. The most promising one is WiFi-based positioning techniques, because its accuracy has improved with the increasing number of WiFi devices, in particular around downtown districts. In spite of this, its usage is still limited in practice, since it only usually works well in areas with lots of WiFi devices and is still not as accurate as GPS positioning with a clear view of the sky. In addition, there is another reason which lies in the high POI density around a user X  X  frequented check-in locations, as these locations are often lo-cated around downtown districts. Based on the statistics in Table I from a Beijing POI database that indicates the number of POIs within specific-sized regions, we can see that in the worst case, users need to make a choice among 490 POIs within 200  X  200 square meters, corresponding to a positioning error of 200 meters. The second challenge is that each user only has a limited number of check-ins (80 X 100 on average according to our later statistical result in Table II) though the total number of check-ins is large. Therefore, how to leverage these limited check-ins to train a personalized model is not easy to achieve.

To address the aforementioned problems, in our approach, we draw an analogy be-tween location naming and local search, and then design a local search framework. Under this framework, we propose a spatio-temporal and user preference (STUP) model for location naming. STUP consists of three preference components: user pref-erence (UP), spatial preference (SP), and temporal preference (TP), which all output a preference score for each POI. We then take these preference scores as features for learning-to-rank algorithms [Liu 2009] to get a final score for each POI.

The UP component is a learning-to-rank model with two features. The first feature is the user X  X  check-in frequency at the POIs, which is pretty important for the UP model. We have calculated the dependence between the possibility of users X  checking in POIs and their individual check-in frequency at these POIs and found that it is more likely for users to check in those POIs with larger individual check in frequency. In other words, users frequently follow their past routines and check-in at their fre-quented locations. Not only does it agree with the well-studied phenomenon that users return to a few highly frequented locations with a significant probability [Gonzalez et al. 2008; Cheng et al. 2011; Gao et al. 2012a], but it is also consistent with one of the evaluation results: user X  X  check-in frequency is surely an important factor for location naming. However, due to the limited check-in history of each user, a user X  X  check-in frequency at most POIs is zero, and thus this feature is pretty sparse. In order to address this problem, we resort to matrix factorization, a means of collabo-rative filtering techniques that make use of similar users X  behaviors. We take a user X  X  interest in POIs in terms of the dot product between the user and POI latent vec-tors obtained from matrix factorization as the second feature of the UP model. Since the dimension of the user and POI latent vectors is much smaller than the minimum between the number of users and of POIs, we model the check-in patterns in a low-dimension latent space. Therefore, UP can help solve the cold-start problem, for exam-ple, naming a novel location. We learn the user and POI latent vectors via maximization with respect to Bayesian personalized ranking optimization (BPR-OPT) [Rendle et al. 2009] criterion. We also plug social relationships into BPR-OPT to study the effect of friendship.

The SP component tries to understand how to perform location naming given only the query location. It is a learning-to-rank model that depends on not only the distance between query location and the locations of POIs but also the popularity of POIs, for example, all users X  check-in frequencies at the POIs and the review score of POIs from review websites, such as Dianping and Yelp.

Similar to SP and UP, the TP component is also a learning-to-rank model that combines all users X  check-in frequency conditioning on the hour of the week and the hour of the day with the temporal interest in terms of the dot product of the time and POI latent vectors. The reason for using matrix factorization to obtain the temporal interest is that temporal behavior is often daily periodic and thus is inherently in a low-dimension space. Similar to learning the user and POI latent vectors in user X  X  interests, we also learn the time and POI latent vectors by means of maximization with respect to BPR-OPT. However instead of constraining the proximity of the latent vectors of friends, we constrain the proximity of the latent vectors of neighbor time since there exists a natural proximity between them. For example, the temporal patterns at 8 a.m. and 9 a.m. of the same day are more similar than that at 8 a.m. and 8 p.m. of the same day.

Since this article extends our previous work [Lian and Xie 2011b], we summarize the contributions (including that of the previous paper) as follows. (1) In the previous paper [Lian and Xie 2011b], we proposed a local search framework (2) This extended work includes the following. The location naming system would like to identify users X  current semantic names, for example, POIs in the case of check-ins, of their physical locations. It is similar to high-resolution indoor localization, which incorporated existing outdoor localization systems, such as GPS, with sensors such as accelerometers, microphones, and cameras [Ofstad et al. 2008; Azizyan et al. 2009; Zhang et al. 2012]. These sensors were used for capturing ambiance and human movement to distinguish different types of locations. Therefore, they aimed to differentiate the POIs of different types around the same physical location. This goal is different from ours, which distinguishes all POIs around the same physical location, whether they are different types or not. Another difference lies in that they identified semantic names by resorting to the context information obtained from sensors, while we achieve it by learning from their location history. In spite of these differences, their methods can be combined with our location naming approach to get not only a high-performing but also energy-efficient naming model. This is because the category can be another important context for location naming according to our experimental analysis. Similar to that, recognizing the type (category) of locations can benefit location naming, learning location naming preferences also has benefits. Lin et al. [2010] studied how people referred to places when sharing locations. They derived taxonomy of different naming methods and identified factors, such as a person X  X  perceived familiarity with a place, and the entropy of that place strongly influenced the way people referred to it. However, they simply predicted the naming preference which decided which of the following three naming approaches, that is, geographical, semantic, and hybrid, was used to describe locations. In addition to these two kinds of research, location naming is also closely related to location annotation, local search, and location recommendation and prediction, and it could benefit from these research. Thus we review these methods from these three viewpoints. A great deal of research into location annotation starts with location extraction and then performs annotation on the extracted significant locations. As for location extrac-tion, Ashbrook and Starner [2002, 2003] extracted significant locations by clustering GPS-measured places where a user spent more than ten minutes and then modeled the transition between consecutive places using a second-order Markov model. Hariharan and Toyama [2004] inferred potential locations in a similar way, but explicitly took into account variations in the scale of a location X  X  size and duration of stay, and built a time-dependent hidden Markov model on these locations. Liao et al. [2007b] and Patterson et al. [2003] proposed a hierarchical hidden Markov model on raw GPS data to extract significant locations, then based on extracted significant locations, Liao et al. [2005] proposed a relational Markov network (RMN) to label locations with the activi-ties that occurred in those places. In another paper, Liao et al. [2007a], simultaneously performed significant location extraction by constructing hierarchical conditional ran-dom fields (hCRF). Although these works also labeled locations with semantic names, there were only a few location names (e.g., work, home, friend, parking) included in the labeling set. It may not be appropriate for them to include tens of thousands of location names (labels), since it would result in a data sparsity problem. Moreover, they cannot handle the cold-start problem, that is, naming a new location and naming with a new name. In our algorithm, since we considered all POIs as labels and leveraged matrix factorization simultaneously, we can easily handle these two problems, that is, the sparsity and cold-start problems. Similarly, Liu et al. [2006] proposed a method that takes reverse geocoding 1 as an intermediate step to derive semantic names for significant locations extracted from a user X  X  trace. Reverse geocoding, which translates geo-coordinates into street addresses, neighborhoods, postal codes, and countries, is not appropriate for location naming. One reason is that people rarely use geographical names to describe their locations based on the user studies of Lin et al. [2010]. Another reason is that the granularity of geographical names is comparatively coarse, and thus these names can still not fully describe the exact places where users are located. Location annotation can focus on not only significant physical locations but also POIs. Ye et al. [2011a] annotated POIs with user-generated tags according to their visiting patterns. Local search takes physical location and keywords as input for finding nearby matched POIs. Most research into local search focuses on improving its performance. One method was to incorporate richer contextual information, such as time, weather, and the activity of users [Lane et al. 2010]. They considered that the dependence of POIs ranking on the context varies with the category of POIs and thus built category-specific models. They then used keywords as the category description to determine the corre-sponding model. Another method was to improve the ranking of POIs leveraging other information. Venetis et al. [2011], ranked POIs by resorting to logged direction queries. They assumed a query asking for the direction from origin to destination implied that the destination was interesting and important. From these two methods, we can see that location naming and local search have similar inputs and outputs, but they are different in at least three aspects. First, location naming does not require users to in-put any query keywords. Second, the application scenarios of our system are different from that of local search; our system automatically infers where users are now, while local search infers their future location. Last but not least, location naming needs more personalized results. For example, a physical location named as a home place by some people can be named as a working place by other people. Therefore, user X  X  check-in history is important for location naming. Location recommendation takes all users X  location history as input and produces for each user a list of potentially interesting but previously unvisited locations. Since location naming mainly targets the points of interest, we only review the methods concerning location recommendation in terms of POIs, that is, POI recommendation. Ye et al. [2011b, 2010] employed a user-based collaborative filtering model for POI recommendation based on the check-in data. In addition to the standard rating-based user similarity measures, they also exploited social and geographical influence as the similarity measures in collaborative filtering. As for geographical influence, they pre-ferred to rank higher those POIs that were near all users X  previous check-in locations. However, according to Cheng et al. [2012], their geographical influence modeling ap-proach may ignore the multimodal nature of users X  locations. Therefore, Cheng et al. addressed this problem by means of explicitly modeling the multimodal characteristic. In addition, they exploited matrix factorization for collaborative filtering instead of the user-based model, since the user-based models don X  X  usually perform as well as matrix factorization [Adomavicius and Tuzhilin 2005]. Similar to matrix factorization, a topic model can also be considered as one of the model-based approaches for location rec-ommendation. Kurashima et al. [2013], built a geo-topic model that considered user X  X  activity area for location recommendation. These recommendation methods focused on users of the same city who shared common interests with higher probability. When considering recommendation across users of different cities, these approaches may not be appropriate any more. Bao et al. [2012] proposed recommending locations according to the local experts they found. According to these works, we can easily observe that the major difference between POI recommendation and traditional recommendation sys-tem lies in the existence of the location attribute of the POI. In addition to the location attribute, there are also a category and tips associated with each POI. Thus this textual information was also utilized to improve location recommendation [Yang et al. 2013; Liu and Xiong 2013]. After reviewing these existing works on POI recommendation, we have found that location naming and location recommendation share some common goal in POI ranking. However, they are different in many ways. One of is that location recommendation aims to rank those potentially interesting but previously unvisited locations higher, while location naming does not follow this principle, since it prefers to rank the frequented POIs higher. Because of this difference, it serves as one feature of location naming in the hope of finding potential POIs that users may check-in at in the future.

Similar to location recommendation, location prediction in terms of POIs intrinsically ranks POIs that users will visit next. Due to this kind of analogy, some researchers have even made use of the techniques of location recommendation for location predic-tion [Noulas et al. 2012b; Gao et al. 2012b; Lian et al. 2013]. However, similar to location naming but different from recommendation, location prediction includes previously vis-ited locations and puts those more frequented check-in locations in the upper position, since it is generally observed that users often return to previously visited locations. Most of the existing research into location prediction makes use of this phenomenon. Chang and Sun [2011], Noulas et al. [2012a] built a prediction model using feature engineering and proposed making use of many features, including check-in frequency from all users, from individuals, and from friends, and check-in frequency at some hour of the day and at some day of the week, and so on. They concluded that check-in frequency from individual and friends are the two most significant features. Gao et al. [2012a] leveraged a fantastic model, that is, Hierarchical Pitman-Yor (HPY) process for location prediction which took into account not only a user X  X  individual check-in frequency but also the transition between locations. In addition to leveraging HPY process, they also modeled the temporal dependence of location prediction [Gao et al. 2012c]. According to their conclusions, the observation that users often return to pre-viously visited location has great effect on predictions. The effect of this phenomenon on location prediction is consistent with its effect on location naming according to our later experimental analysis. However, although location naming and prediction share this insight, they are different at least in two ways. First, location naming already knows users X  physical locations, while location prediction does not, and thus the dis-tance between a user X  X  location and the location of POIs can be considered as a feature of location naming. Second, location naming actually recognizes where users are, while location prediction predicts user X  X  next location. In this section, we first clarify some terms used in this article, including point of interest (POI), check-in, and check-in history. Then, we formally define the location naming problem.

Definition 3.1 ( Point of Interest ). A point of interest p , indexed by a unique identifi-cation p . id , is a specific point location that someone may find useful or interesting. The specific location of a POI p is denoted as p . l , which is generally described by its coordi-nate ( lat , lon ). Each POI also has a special name p . name and has a category attribute p . category , describing its functionality such as  X  X estaurant X ,  X  X arenting X ,  X  X ourist X , etc. For the sake of simplicity, in addition to p , we also reserve letters i and j for indexing a POI. All the POIs constitute a POI Database P . P u and P  X  u denote the check-in POIs of user u and those POIs that the user has never checked in before, respec-tively. Similarly, P t and P  X  t denote the check-in POIs that have been checked in at time t by any user and the POIs that have never be checked in at time t , respectively. P where dist ( p , l ) is the distance function between POI p and location l . An example of POI is a famous scenic spot in Shanghai, represented as (name = Oriental Pearl Tower, id = 1795417, l = (31 . 2398 , 121 . 4997), category = tourist).
Definition 3.2 ( Check-In ). A check-in c is usually a quadruple ( u , l , t , p ), indicating auser c . u claims she visited a POI c . p at a particular time c . t around location c . l .In some LBSNs (e.g., Foursquare), location c . l would be omitted, since it can be implied by the locations of check-in POIs. However, since c . p and c . l are usually not the same due to the positioning error, and moreover, since we consider distance between them as a feature for location naming, we put query location c . l into the check-in definition. Taking an example of check-in: one user checked in Oriental Pearl Tower on 2/12/2011 at 13:53:37, when her actual location was (31.2372, 121.5016).

Definition 3.3 ( Check-In History ). A check-in history C t e t of multiple users between start time t s and end time t e ( t s  X  t e ). C t e t t } . Given a single user u , his check-in histories C u  X  C t e t total number of check-ins of user u . The check-in history of POI p is C p ={ c  X  C t e t p } .

Definition 3.4 ( Location Naming ). Location Naming names a physical location around GPS reading l for user u at time t ( t &gt; t e ) with a Point of Interest p  X  P d l , which is the topmost of a ranked list of candidate POIs returned by ranking algo-rithms. After assuming the scoring function f u , l , t ( p ) of a ranking algorithm, location naming names l with p , which satisfied
To better illustrate the location naming problem, consider the following scenario shown in Figure 1(a). Imagine that three users A, B, C are at the same location around  X 39.976 North, 116.331 East X  at 3 p.m. on some Saturday. By observing that user A often checked in a nearby office building, we infer she comes here to work overtime. User B often checked in hotels and attractions in many cities and thus would like to find accommodation here because there are no attractions nearby. User C often came around this place for entertainment since he often checked in the entertainment spots during this period. Therefore, based on their distinct check-in histories, given the GPS reading and the time, A, B, and C name this location as A X  X  office, a hotel tailored for B X  X  preference, and an entertainment spot that C often visited, respectively. Due to the analogy between location naming and local search, we design a local search framework, shown in Figure 1(b), based on which we propose spatiotemporal and user preference (STUP) for location naming. STUP is decomposed into three components: user preference (UP) X  f u ( i ), spatial preference (SP) X  f l ( i ), and temporal preference (TP) X  f ( i ), which all output a preference score for each POI. These scores are taken as the features for learning-to-rank algorithms so as to get a final score for each POI. in POIs by means of learning-to-rank techniques to score POI i for each user u . The check-in frequency of user u at POI i is represented as c ( u , i ), which is calculated on the training check-in history. 2 User X  X  interest f UI u ( i )inPOI i is represented by where p u  X  R K UP is the latent vector of user u of length K UP , which can be explained as the interest of user u in some intrinsic categories and q i  X  R K UP is the latent vector of POI i of length K UP , which could be the possibility belonging to corresponding categories.  X  ,  X  denotes the dot product of two vectors. Therefore, the dot product between user latent vectors and POI latent vectors is considered as user X  X  interest in POIs in terms of those intrinsic categories. If we assume there are M users and N POIs in total, there are ( M + N )  X  K UP parameters, far fewer than the number of entries ( M  X  N ) in the user-POI matrix. The original high dimension space (min( M , N )) is reduced as a low-dimension latent space ( K UP ), which is related to the intrinsic categories. And all users X  check-in patterns are represented in that low-dimension latent space. Therefore, user X  X  interest in POIs in terms of those intrinsic categories can resort to similar users to fill the value at the potentially interesting but previous unchecked-in locations ( c ( u , i ) = 0) and thus alleviates the sparsity problem of user check-in frequency. In other words, it could help to cope with the cold-start problem (e.g., naming a novel location and naming with a new name). The SP ( f l ( i )) model tries to understand how to do location naming given only query locations. In other words the SP model generally learns location naming without dis-between query location l and the location of POI, i , but also the popularity f ( i )ofPOI i . Intuitively, SP prefers both nearer and more popular POIs for naming locations. As for the popularity of POI i , we first consider all users check-in frequency c ( i )atthePOI i that is calculated on training check-in history. Then we consider its number of reviews and the review score acquired from the review websites, such as Dianping and Yelp. Since these review websites provide a platform for people to review local businesses and to share the review information with others, POIs with higher review scores and (or) a larger number of reviews are usually more popular and attractive. After obtain-ing the distance and three popularity measures of POIs, they are taken as features for learning-to-rank algorithms to get a SP model. Since user behaviors are different from time to time, we would like to know how users generally name locations at different times. As we know that users generally behave weekly-periodically, we consider modeling weekly-periodic patterns. For exam-ple, users work on weekdays and rest or hang out on weekends. Since their behaviors also show some daily-periodic patterns, there exists a low-dimension structure in the weekly-periodic pattern space. However, there are a few differences between patterns on different days of the week. For example, patterns on weekdays are usually different from those on weekends. Moreover, it is possible that patterns on the first and last day of the weekday may be subtly different from that on other days of the weekday. Thus we should distinguish patterns on different days of week. Therefore, it is difficult to accurately define such periodic patterns, that is, the low-dimension structure, in a heuristic way. We resort to matrix factorization to automatically discover such a struc-ture and denote it as temporal interest (TI). Temporal interest f TI t ( i )attime t in POI i is represented by where r t  X  R K TP is the latent vector of hour t  X  X  0 ,..., T = 167(7  X  24  X  1) } of week, which can be explained as the interest at hour t of the week to intrinsic categories and w distinguish w i from q i , since their dimensions are usually different ( K UP = K TP )and their parameters are learned within a different procedure (in the learning section). In addition to temporal interest being one feature of temporal preference ( f t ( i )), we also the hour of the week h w ( t ) and the hour of the day h d ( t ), respectively, where h w ( t )and h ( t ) are the time mapping functions from time t to the hour of the week and the hour of the day. These three values are taken as features for learning-to-rank algorithms to get a TP model. The learning algorithm consists of two parts. One part is the matrix factorization with respect to BPR-OPT, that is, to learn these parameters p u , q i , w i ,and r t . The other part is to apply learning-to-rank techniques for combining features. We learn the four latent vectors by means of maximization with respect to BPR-OPT [Rendle et al. 2009] on the training check-in history. The reason why we consider BPR-OPT as the optimization criterion for matrix factorization is that it models person-alized pairwise preference between check-in POIs and unchecked-in POIs, which agrees with the ultimate goal (POI ranking) of location naming. This scenario is pretty similar to implicit feedback information in One Class Collaborative Filtering (OCCF) [Hu et al. 2008; Pan et al. 2008]. In these two works, the authors used rating approximation to reach the goal of finding potentially interesting items. They defined the rating of items with implicit feedback information as 1 and the rating of random samples of other items as 0. Rendle et al. [2009] also studied this problem and proposed an optimization procedure with respect to BPR-OPT to learn the user and item latent vectors. They concluded that optimization with respect to BRP-OPT outperformed the approaches based on rating approximation. This is another reason for considering BPR-OPT as an optimization criterion. However, BPR-OPT has a disadvantage because it ignores the check-in frequency, similar to POI recommendation in Ye et al. [2011b]. We believe that ignoring check-in frequency incurs performance loss, but we leave exploiting check-in frequency for POI recommendation for future study. Next, we will discuss how to define this criterion in terms of user X  X  interest and temporal interest, and then extend it to take into account the proximal constraint of neighbor parameters.

First, we place parameters , representing the corresponding parameters, into scor-ing function f a ( i ) given the context a ,thatis, f a ( i ; ), where a  X  X  u , t } . According to Rendle et al. [2009], BPR-OPT in our case is formalized as follows: where  X  ( x ) = 1 1 + e  X  x is a logistic function mapping any real value into (0,1). One differ-ence from the original BPR-OPT is that we sample POI j from those POIs P  X  a  X  P d l , which are not only previously unchecked-in at context a but also near a user X  X  physical location l , since our items (POIs) have location attributes. P ( ) is the prior density. In Rendle et al. [2009], it was a spherical Gaussian distribution. In our case, in addition to spherical Gaussian prior, we also place a Gaussian Markov random field (MRF) prior, as proposed in Lu et al. [2009], to constrain the proximity of neighbor parameters. For example, friendship on an online social network is a kind of neighborhood, and thus if two users are friends online, their latent vectors should be proximal; 3 p.m. and 4 p.m. on the same day are also considered as neighbors, and thus their corresponding latent vectors also should be proximal. The reason why we use MRF prior to take into account proximity constraints, such as the social relationship is that this approach is compara-tively better according to the comparison in Ma et al. [2011b] among more approaches [Lu et al. 2009; Ma et al. 2011a, 2011b; Jamali and Ester 2010]. Then these two priors can be combined in a  X  X roduct of experts X  fashion, as pointed out in Lu et al. [2009]. Finally, BPR-OPT becomes where r and s aretheindexofuserortime,and  X  r and  X  s are their corresponding latent vectors. The prior knowledge of the similarity between r and s is sim ( r , s ), while the similarity between them in terms of their latent vectors is the square of the Euclidean norm of their difference, that is, ||  X  r  X   X  s || 2 . Thus the maximization of the last term in Eq. (5), including the minus symbol, results in higher proximity between the latent vectors of more similar users or time, where  X  &gt; 0 is a coefficient controlling this constraint. 2 F is the square of the Frobenius norm to prevent overfitting, and  X  is the coefficient to control its degree.
 As for optimization, we resort to stochastic gradient descent (SGD), as proposed in Rendle et al. [2009]. The utilization of SGD, in particular in the case of matrix factoriza-tion, requires a time-consuming search for regularization values that is usually done by techniques, such as grid search, and requires training the model parameters several times. Thus we leverage an adaptive regularization method, proposed in Rendle [2012], and extend it from the classification and regression scenario to the ranking scenario. We will elaborate the full procedure to learn p u and q i in user interest. In this case, the we assume the regularization coefficients of the user and POI latent vectors are differ-ent while different users share the same coefficient  X  U and different POIs also share  X 
U is a coefficient to control the effect of social relationships, and sim ( u u and user v equals 1 if they are friends and 0 otherwise.

We show the complete procedure learning the parameters, including the model pa-rameters and regularization values by means of SGD in Algorithm 1. During the procedure, we first initialize the latent vectors with nonzero values, that is, random values from normal distribution with zero means and one standard deviation, in step 1, otherwise the parameters cannot be updated. P old and Q old keep the old values after each update and are initialized as zero. We shuffle the training and validation check-in history C T and C V in step 4 to avoid the influence of the iteration order of samples on the optimization. We perform optimization and update the parameters round by round until convergence from step 5 to step 23. In each round, we perform the iteration on the training check-in history C T from step 6 to step 23. For each check-in ( u , l , t , i ) from the training check-in history, we sample another POI j from P d l  X  P  X  u , which has been not checked in before by user u and simultaneously is within distance d from query location l , and then construct the pairwise preference of POI i to POI j . The sampling of POI j is shown in step 7 and subsequently updates p u , q i ,and q j from step 12 to step 14. After the first round of iteration, which we use a boolean variable first for judgment in step 15, while iterating the training check-in history for updating latent vectors, the regularization values are also updated from step 16 to step 21. The first step of updating the regularization values is to obtain the pairwise preference, that is, ( u , l , t , i )and j , similar to step 6 X 7. We then update  X  step 21.

As for the learning of r t and w i in temporal interest, it follows similar steps, and thus its procedure is omitted here. However, instead of getting the similarity between users (social relationships) from an online social network, we define the similarity between hours of the week according to common knowledge. That is to say, each hour of the week is directly adjacent to its neighbors. For example, the neighbors of 3 p.m. include 2 p.m. and 4 p.m. on the same day. In addition, the 0 th hour of the week (i.e., the first hour of Monday) and the 167 th hour of the week (i.e., the last hour of Sunday) are also directly adjacent to each other. Therefore, the similarity between hours of the week is defined as follows. For each check-in c from training check-in history, we know user c . u checks in at POI c . i , which is labeled as relevant. During the procedure of this check-in, nearby POIs moment and are thus labeled as irrelevant. Therefore, we can boil the learning of com-bining features down to the learning-to-ranking problem with two levels of relevance. Then these L =| P d c . l  X  P  X  c . u |+ 1 POIs are considered as inputs for extracting features and labels. In particular, for each POI i among these L POIs, we can extract its features from the training check-in history and auxiliary data source to get a feature column vector f i a  X  R F  X  1 , where a is a context that we have mentioned before and F is the number of extracted features. If we take getting the STUP model as an example, f i a we use [ ] in Matlab as a vector and matrix composing operator. Stack these L feature is the transpose of matrix X . Thus each row of the feature matrix is the feature vector of the corresponding POI. Then we assign these L POIs with relevance labels according to the previous method and form a label vector y  X  R L  X  1 in the same order forming X , the POI i j among L POIs. By means of extracting the features and labels, the training check-in history is represented by a collection of feature-label pairs ( X , y ), where each pair corresponds to each check-in. Then three types of learning-to-rank algorithms X  pointwise, pairwise, and listwise X  X re applied to learn mapping from feature matrix variable X to label vector variable y . Pointwise approaches, which only consider the relationship between single feature vector and corresponding label, are similar to con-ventional supervised learning, taking f i a as an input and outputting the relevance label y i so that most classification and regression algorithms can be employed. Pairwise order between these two labels. In other words, pairwise approaches take a pair of feature vectors ( f i a , f j a ) as input and produce the relative order preference of this pair with respect to context a . Listwise methods take ( X , y ) as a whole to consider the overall relative order of POIs with respect to context a . For a further introduction of learning-to-rank algorithms and their categorization, please refer to Liu [2009]. In the experimental section, we will use ListNet [Cao et al. 2007] as the learning-to-rank algorithm for combining features, since we compared different types of algorithms in our previous paper [Lian and Xie 2011b] and found ListNet was more appropriate. In this section, we first describe the data and then frame the evaluation and present evaluation metrics. Finally, we provide the evaluation results and discussion. We evaluated the location naming system on a check-in dataset. We collected 1,826,856 check-ins from March 29th, 2011 to Oct 14th, 2012 from Dianping, a leading Chinese platform for reviewing local businesses. It allows users to perform check-ins and to synchronize them with other social networks (e.g., Weibo) for further social interaction. When shared on Weibo, each check-in includes time, a GPS coordinate, a short URL linking to the check-in POI, and optionally a text status message. The reason we choose the check-in history from Dianping rather than other location-based social networks is that only Dianping provides a user X  X  physical location for check-in, and thus the GPS coordinates of check-ins are different from those of the POIs. Therefore, we can consider the distance between them as a feature, which is a rather important factor for naming locations.

However, when going through the check-in dataset, we found that the physical loca-tions of some check-ins were extremely distant from the locations of the POIs (up to several thousands of kilometers). One of the reasons may be that users do check-ins by first searching POIs and then checking in, when there is not any spatial constraint. These check-ins, without reflecting any real physical visit to locations, were assumed to be unreasonable in practice and thus should not be included for evaluation. Addi-tionally, for the sake of a more reasonable evaluation, we also removed POIs with fewer than three check-ins and filtered users who have less than ten days of check-in history. Moreover, we found that most check-ins were located in Shanghai and Beijing and thus we were mainly concerned with check-ins in these two cities. After this preprocessing, 549,983 check-ins remained. We made basic statistics on the remaining check-ins and showed the result in Table II. The table showed that the standard deviations of the statistics were pretty large. The reason is that there was tremendous diversity of pat-terns among users. Some users often performed check-ins regularly while others did not; some often checked in several POIs each time while others only checked in a few or only one POI. The location distribution of check-ins was plotted in Figure 2 separately for Shanghai and Beijing. Since there may be some differences among the check-in patterns of different cities, we evaluated the location naming separately for these two cities.

After obtaining the 549,983 check-ins, for the sake of evaluation, we split them into three parts. The first step of splitting was to arrange the check-ins in chronological order for each user. Then we took the first 60% of the check-in history days from each user and merged them together as the training check-in history C T . The subsequent 10% of days of check-ins from each user were grouped as the validation check-in history C V . The remaining 30% of check-in history constituted the testing check-in history C Test .
During the evaluation of location naming, we also studied the impact of social rela-tionships on location naming. Since each user on Dianping has an account on Weibo, we crawled their social relationships from Weibo. The relationship between individuals on Weibo is one-way (called parasocial) friendship, similar to Twitter, represented by fol-lowers and followees. After crawling the social relationships of the users in our check-in dataset, we made basic statistics and found these users were sparsely connected. In Shanghai, only 59% of users had 3.7 followees on average and in Beijing, 45% of users had 3.3 followees on average. When incorporating social relationships on Weibo into STUP, we turned them into undirected social relationship, which meant that the simi-larity was 1 as long as there was a social link (follower or following) between two users, and 0 otherwise. We evaluated the location naming system from the following two perspectives. (1) Component Study . (a) As for the user preference (UP) model, we compared it with (2) Comparison with Baselines . As pointed out previously, location naming was not We considered the performance of the topmost POI and the entire list of candidate POIs. The performance of the topmost POI is termed as Accuracy (Acc), which means that what percentage of testing cases return the most accurate location name at the top position. As for the performance of the entire list of candidate POIs, since we grasped the analogy between location naming and local search, we adopt MAP which is widely used in information retrieval. The MAP averages the average precision (AP) of all testing cases. AP is formally defined as P@k, cut-of precision at cut k , is considered as the ratio of the number of check-in indicates whether the POI at position k is checked in or not. 6.4.1. The Study of User Preference Model. From Table III, we made the following seven observations. First, both Acc and MAP improved on all check-ins with the increase of the dimension of latent space in either Shanghai or Beijing and the performance increase from UI(16) to UI(32) was more than that from UI(32) to UI(64). This was because UI with a higher dimension can capture more information about user X  X  check-in patterns while to some extent, it cannot capture more behaviors due to the limit in user X  X  patterns. Second, in contrast to the results of all check-ins, both Acc and MAP on novel check-ins declined with the increase of dimension of latent space. This was because UI of higher dimension tended to overfit more easily and didn X  X  generalize well to find potentially interesting but previously unchecked-in POIs. Based on the previous discussion, we chose UI(32) for later experiments. Third, although the performance of UI on novel check-ins became worse with increasing dimension, UI in all three dimensions outperformed UMF on novel check-ins. This observation illustrated the ability of UI, that is, matrix factorization, to find previously unchecked-in POIs for each user and thus to solve the aforementioned cold start problem. Fourth, in Shanghai, UMF was better than the highest dimension of UI on both MAP and Acc; in Beijing, they were comparable with respect to MAP and UMF outperformed UI slightly on Acc. Since UI performed location naming according to the inherent common behaviors of users according to our previous analysis, the observation that UMF performed better than UI illustrated that users frequently preferred to follow their past routines and checked in their frequented check-in POIs. However, due to their different perspectives of behavior modeling, UI and UMF could benefit from each other. This was validated with the fifth observation that UP(32), the combination of UI(32) and UMF, outperformed UMF and UI(32). Sixth, the combination of UI(32) and UMF reduced the performance of novel check-ins by comparing the performance of novel check-ins of UP(32) and UI(32). This observation indicated these two models were not perfectly combined. Thus in the future, we will explore how to better combine them.

Finally, by comparing UI(32) with UI(32+f), we found that the introduction of social relationships into UI can improve the performance of all check-ins. This was because the friendships on Weibo can be associated with some underlying common interests so that constraining their latent vectors proximal encoded their underlying common in-terests. However, the improvement of introducing social relationships was only slight. One reason may result from the sparse social relationships, which were over two times sparser than that used in Cho et al. [2011] and Sadilek et al. [2012]. Another reason may lie in that the common interest forming a friendship on Weibo was greatly differ-ent from what the user latent vectors stood for. This moment of proximity constraint of latent vectors of neighbor users could be misleading. However, we believe social relationships were not fully exploited in this way, (although [Cho et al. 2011; Sadilek et al. 2012] pointed out a small part of the influence from social relationships on user X  X  behaviors). As for the performance of novel check-ins, from this table, we can see that the introduction of social relationships could also bring advantages. This observation manifested the effects of social relationships on finding interesting but unchecked-in POIs. 6.4.2. The Study of Spatial Preference Model. The results of the study on the effectiveness of SP, and its features were shown in Table IV. The first surprising result from this table was that the review score and the number of reviews from Dianping were not as effective as other features and was actually comparable to the Random method. One reason was that users didn X  X  always go to those POIs with high review scores or a large number of reviews to check in. POIs with high review scores or a large number of reviews usually had other properties (e.g., long waiting time or high expense or distant from users X  home and working place). What X  X  more, some business owners can look for customers to help them review so that these scores were not fully trusted. Another reason was that the popularity of POIs in terms of review scores and the number of reviews may be not appropriate for learning location naming from check-in history. This was because users X  check-ins didn X  X  necessarily reflect a real visit to a POI, so that frequently checked-in POIs were not necessarily popular POIs. However, due to learning the location names from the check-in history, the popularity of POIs from the check-in history should play a more important role than the popularity obtained from review information. This was validated by the superior performance of MostFreq over ReviewScore and NumReview. Another observation from Table IV was that among those features used in SP, distance was the most effective feature and the gap between them was pretty large. This was consistent with our previous assumption: users always checked in nearby POIs since the physical location of users constrained them from checking in a distant POI. Finally, we observed that SP was the best method. It indicated that distance between query location and popularity features of POIs complemented each other. In other words, SP preferred both nearer and more popular POIs for naming locations. 6.4.3. The Study of Temporal Preference Model. We studied the effectiveness of temporal features, and the results were presented in Table V. Since we made use of a similar probability representation and optimization procedure in TI to that in UI, they shared similar trends (i.e., the performance improved with the increase of latent space dimen-sion). The principles behind this were also similar. One difference from UI was that the benefit of increasing dimension was more limited both in Shanghai and Beijing. The reason behind this was that the effect on location naming from temporal patterns was limited. In other words, TI with low dimension already encoded most of the temporal patterns, and thus an increasing latent space dimension did not improve performance a lot. However, the goal of learning TI was to automatically discover the intrinsic periodi-cal patterns. Therefore, the comparison between TI and heuristic methods of periodical patterns discovery, that is, HourOfDay, which did not distinguish which days of the week were more important. Additionally, TI was also compared with HourOfWeek in order to check the effectiveness of learning temporal interest. From the results in Table V, we can see that in Beijing TI outperformed HourOfWeek and was comparable to HourOfDay and in Shanghai when the dimension reached a threshold it performed better than HourOfWeek but a little worse than HourOfDay. The superior performance of TI over HourOfWeek illustrated the effectiveness of periodic patterns discovery. How-ever, the two sides of its comparison with HourOfDay may lie in the difference about the average number of days in the user histories. According to the statistics of this quantity, the users X  histories from Shanghai were about 1.2 times longer than those from Beijing. Thus, check-in histories from Shanghai were more sufficient so that the HourOfWeek was more accurately estimated. However, similar to the analysis of the UP model study, TI and HourOfDay, as well as HourOfWeek, performed pattern model-ing from different perspectives and should complement each other. This was verified by the observation that TP outperformed any of the methods demonstrated in this table. Finally, we studied the effectiveness of proximity constraint between latent vectors of neighbor hours of the week by comparing TI(16+proximity) with TI(16). The reason for placing a proximity constraint in TI was a little different from that of social relation-ships. In the case of TI, we would like to guarantee that the patterns between neighbor hours should be similar. The results from this table actually showed the effectiveness of such a proximity constraint though the improvement was not large.
 6.4.4. The Comparison with Baselines. Finally, we compared the proposed model STUP with the three components and their combination as well as the Random method. The results of the comparison were shown in Table VI. As shown in this table, we first observed that each component significantly outperformed the Random method. This indicated that all the introduced features were useful and effective for location naming. Second, the performance of SP was highest among these three components and TP was the worst of all. This was because SP already covered a great deal of useful informa-tion for ranking, while patterns captured by TP were not so discriminative. However, without understanding personalized user behavior patterns and without acquiring the overall general temporal patterns, there was still a great deal of improvment space for SP. This was verified by the fact that both SP+UP and SP+TP outperformed SP. Since SP+UP was better than SP+TP, UP complemented SP more than TP. From the per-spective of UP, accurately acquiring user X  X  locations was pretty important for location naming and other applications related to mobility, such as location recommendation and prediction. Moreover, integrating user X  X  preferences with temporal patterns to achieve the user dynamic preference can also improve UP. We can validate these two assumptions by the fact that the performance of both UP+TP and UP+SP were better than that of UP. Similarly, since UP+SP was better than UP+TP, SP complemented UP more than TP. Despite the smaller impact of TP on UP and SP, the introduction of TP into SP+UP was still beneficial, since STUP outperformed SP+UP. However, the benefit was quite limited. One possible reason was that the temporal patterns may be different from person to person so that aggregating all user temporal patterns masked individ-ual temporal patterns. From this point of view, higher interaction between them may bring more benefits. However, the problem of higher-order interaction between users and time as well as POIs is that it suffers from a more severe sparsity problem than the interaction between users and POIs, which has been mentioned before. There is some research that considers this problem, but we have experimented with a few of them and have not found a large advantage. Thus we leave it as a future work.
After presenting these experimental result, we discussed the potential performance difference of STUP under different time, different percentages of training data, and different check-in categories in the following three sections. 6.4.5. Impact of Hour of Day on Weekend and Weekday. A user X  X  decision on location nam-ing is usually different from weekday to weekend and from hour to hour. Thus we plotted the performance of three components and STUP with respect to the hour of the weekend and the hour of the weekday in Figure 3. Since there were both similar-ities and differences in the impact of time on the performance between Beijing and Shanghai, we first discussed the similarities. First, UP on the weekend generally did not perform as well as UP on the weekday, in particular in the morning, at noon, and in the evening. In the morning (7 a.m. X 9 a.m.) on weekdays, UP performed well; at noon (12 p.m. X 14 p.m.) and in the evening (6 p.m. X 8 p.m.) it was a little more difficult for UP on the weekend than on the weekday. This, on the one hand, showed the high regularity of users on the weekday, in particular in the morning. On the other hand, it showed that on the weekend, in particular in the afternoon, users had more choices to make: decisions for dining, shopping, entertainment, and so on. Actually from this figure on the same day, whether it was a weekend or not, performance in the morning was usually higher than other periods, since in the morning, other than the frequently checked in POIs, there were not a large number of other options to choose from, and moreover people also did not have enough time to change their frequented choices. Of course, comparatively, in the morning on the weekend it was easier for them to change, which was also reflected in the figure. In contrast to UP, SP showed the opposite trend. Performance of SP on the weekend was higher than that on the weekday. The principle behind this was similar. On the weekend, users had more choices and thus tried to visit and checked in at novel POIs. At this moment, at user cannot leverage UP to make decisions due to the lack of history but depend on the general popularity of these POIs and the distance between users X  locations and the locations of POIs, that is, SP. Thus SP on the weekend performed better than on the weekday. Such a contrast between SP and UP resulted in a larger gap between them on weekends than on weekdays, which we observed in the figure.

Next we discussed the differences between two cities. The first difference was that the performance of UP, SP, and STUP in Shanghai was better than the performance of its counterpart in Beijing. One reason was that the three components complemented each other more in Shanghai than in Beijing. Second, from 10 a.m. to 11 p.m., whether it was the weekend or not, SP performed better than UP, and the gap between SP and UP in Shanghai was larger than that in Beijing. This observation showed that users in Shanghai were more likely to explore new locations and POIs during these periods, since we explained that gap between UP and SP reflects the extent of freedom to make a decision. 6.4.6. Impact of Different Percentage of Training Data. The results of the experiments on the impact of percentages of training data on performance were shown in Figure 4. From this figure, we see that STUP, SP, and TP were not influenced much by the volume of training data. In SP, the distance feature was not changed all the time and the relative popularity of POIs from check-in history was not changed much either. Moreover, compared to popularity, distance played a more important part in SP, and learning the weights for these two features just required some check-in history. Therefore, SP was not influenced much. Similarly, for TP, since the relative popularity of the number of check-ins at POIs conditioned on time did not change much, and since the dimension of time was not high, these features were not sparse. The change in the volume of training data didn X  X  have a large impact on its performance. As for STUP, as shown in Table VI, SP was the most effective component among the three components, and their performance gap was pretty large. Thus, similar to SP, STUP was also not influenced much. In other words, our proposed algorithm was robust for the volume of training data. In contrast to the aforementioned features, user check-in frequency became more and more sparse, that is, more of this feature became zero, while reducing the volume of training data. Thus the performance of UMF decreased as the volume of training data was reduced, as shown in Figure 4. UI and UP, which was the combination of UMF and UI, shared a similar trend to UMF. 6.4.7. Impact of Different POI Category. The results of the performance difference with respect to the POI category were shown in Figure 5. We can see that the naming with respect to the dining category was comparatively difficult, while naming with respect to the services category, which includes gas station, school, hospital, etc., was easier. The former phenomenon may lie in the fact that users preferred to discover delicious food and thus often went to different restaurants; the latter may lie in the fact that most users had similar and more stable tastes, since the three components performed well. It is interesting that among sports, beauty, parenting, and services categories, UP outper-formed SP and TP. In other words, among these categories, user interest did not easily change. Taking sports as an example, users didn X  X  often alter their location for exercis-ing, since the alternating of locations may bring a great deal of inconvenience. From these differences, we found that there were some biases of performance between dif-ferent check-in categories and that the different components of STUP showed different performances in the check-ins of different categories. And because of these differences, we can see some promising future directions for our research. One is to leverage the prediction of categories for location naming, since we can follow Lane et al. [2010] in building category-specific models for location naming. Category prediction can be achieved by location-based activity recognition [Lian and Xie 2011a; Liao et al. 2005] and by the approaches to high-resolution outdoor localization mentioned in the related work section. Semantic names of locations are important context for mobile recommendations and advertisements. In this article, we proposed a novel location naming approach which can automatically provide points of interest for users given their locations and time. In our approach, we drew an analogy between location naming and local search and designed a local search framework to propose a spatiotemporal and user preference (STUP) model for location naming. STUP combined three components, user preference (UP), spatial preference (SP), and temporal preference (TP) by leveraging learning-to-rank techniques. We evaluated STUP on 466k check-ins of 5k users from Shanghai, and 135k check-ins of 1k users from Beijing. According to the evaluation results, STUP outperformed the proposed baselines and returned accurate semantic names for 23.6% and 26.6% of testing queries in Beijing and Shanghai, respectively. Based on the results, the performance of SP among three components was highest. Among the features utilized in SP, distance was most effective. Although UP did not perform as well as SP, it was a necessity for STUP to provide personalized semantic location names for users. In UP, UMF outperformed UI, but both can benefit from each other. TI did not improve TP much, but by means of its exploitation on periodic patterns, we found that some heuristic approaches, for example, hour of the day, performed well. In other words, we can simply consider the check-in frequency at the hour of the weekday and the weekend as a temporal feature.

Although we observed that the performance contribution of TP in STUP was quite limited, its effect on location naming was not fully exploited. We mentioned that we can consider three-order interaction between the user, time, and location. The challenge introduced by this feature was that it had a more severe sparsity problem than the in-teraction between the user and the location. When evaluating the interaction between user and location (i.e., user X  X  interest), we observed that the increase in the latent space dimension can improve overall naming performance, but it decreased the ability of discovering potentially interesting but previously unchecked-in locations. Therefore, their combination should be explored more precisely. When modeling user X  X  interest for location exploration, we did not take into account the user check-in frequency, but we combined it with user interest as the user preference model. Therefore, the effect of user check-in frequency on location exploration needs further study. The last interest-ing result from the experiment was the naming performance with respect to different POI categories. We found that three components, in particular UP and SP, in STUP behaved differently in different categories. Thus if we can accurately recognize the user X  X  activity (category), it can be used in the combination of these three components. In other words, location-based activity recognition can benefit location naming.
