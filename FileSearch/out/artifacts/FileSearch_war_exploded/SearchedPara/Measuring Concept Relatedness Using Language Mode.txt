 Over the years, the notion of concept relatedness has at-tracted considerable attention. A variety of approaches, based on ontology structure, information content, associ-ation, or context have been proposed to indicate the re-latedness of abstract ideas. We propose a method based on the cross entropy reduction between language models of concepts which are estimated based on document-concept assignments. The approach shows improved or competitive results compared to state-of-the-art methods on two test sets in the biomedical domain.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Abstracting methods Algorithms, Theory, Experimentation, Measurement Language Models, Semantic Relatedness
Humans prefer to think and reason in terms of concepts rather than words. For computer-aided reasoning the rela-tionships between concepts are often explicitly modeled in an ontology. In this context it is important to have a mea-sure which indicates the semantic relatedness of concepts. In IR this measure can, for instance, be used for expanding a query with related concepts.

In this work we assume to have an ontology consisting of concepts and relationships as well as a document collection in which to each document one or more concepts have been assigned. In the literature, four categories of concept relat-edness measures can be distinguished: based on structure, information content, association, or context.

Firstly, concept relatedness can be based on ontology struc-ture. Concepts close to each other in the structure are as-sumed to be strongly related. Path length is a typical in-dicator of this kind of relatedness [ 1 ]. More sophisticated methods take into account the depth of the concepts in the structure or look at the lowest common subsumer [ 5 ].
Secondly, methods based on information theory have been proposed. These methods take into account the Information Content (IC) of the concepts. The IC indicates the speci-ficity of a concept and can be related to the ratio of docu-ments assigned to a concept. Resnik [ 7 ] proposed to measure the relatedness of concepts by looking at the IC of the lowest common subsumer. Lin [ 3 ] extended this by also taking into account the IC of individual concepts.

Thirdly, different association-based methods can be used to determine the relatedness of concepts, such as Dice, Jac-card and Overlap coefficients [ 8 ]. The co-occurrence of in-stances of two concepts X  X hich in our current case means concepts assigned to the same document(s) X  X erves as an re-latedness indicator. Other, collocation-based measures such as Pointwise Mutual Information (PMI) and Log Likelihood Ratio (LLR) can be used for this purpose as well [ 4 ].
Finally, relatedness of concepts has been estimated by con-sidering the context of concepts, where the context of a con-cept consists of text discussing it. Pedersen et al. [ 6 ] present an approach in which the relatedness of concepts is defined as the cosine of the angle between two context vectors .
In this paper we present a novel context based measure of concept relatedness, based on cross entropy reduction. After introducing our method, we compare it to the methods introduced earlier, by comparing the results with relatedness judgments provided by human assessors.
As a concept distance measure we propose to use a sym-metrical version of the Cross Entropy Reduction (CER) be-tween two concept language models. A concept language model  X  c is defined as a distribution over words based on a concatenation of all documents annotated with concept c . The concept language models are smoothed with a back-ground language model, based on the collection (Jelinek-Mercer smoothing,  X  = 0 . 7 background).

The rationale behind our CER-based notion of concept re-latedness is that related concepts are surrounded by similar language. The CER quantifies how much better a certain language model is in modeling a certain observed text in comparison with modeling by a collection model. CER has already been successfully applied to ad hoc retrieval and topic detection and tracking [ 2 ]. The CER is defined as follows: where  X  c is the language model of a concept c , M is a background language model and H (  X  1 , X  2 ) is the cross en-tropy between two language models. The incorporation of H (  X  c 0 ,M ) is essential since it makes the resulting scores comparable across different concept pairs. The relation-ship with KL divergence is as follows: CER(  X  c ; M, X  c 0 KL(  X  c || M )  X  KL(  X  c ||  X  c 0 ). A symmetrical version of CER is used as a concept distance [ 9 ]:
To assess the quality of our relation estimation method, we look at correlations with semantic relatedness as indicated by human assessors. Performance is measured by looking at the level of agreement between the two gold standard sets and each method, using both Kendall X  X  tau rank correlation coefficient and Pearson X  X  correlation coefficient. As ontology we use the Medical Subject Headings (MeSH) controlled vo-cabulary thesaurus maintained by the National Library of Medicine (NLM). The 2007 PubMed baseline distribution X  consisting of around 16 million biomedical abstracts X  is used for the creation of the concept language models. This bibliographic database has been manually indexed using MeSH concepts by curators from the NLM.

Caviedes and Cimino [ 1 ] kindly provided us with a test set of 55 MeSH concept pairs (11 unique concepts), judged on relatedness by three physicians on a 1 to 10 scale. As a second test set we use a set of 24 concept pairs (47 unique concepts) derived from Pedersen et al. [ 6 ], judged by experts on a 1 to 4 scale. This test set was developed for evaluating relatedness measures on the SNOMED-CT ontology.

We compare our approach to two structure-based methods ( path and Nguyen [ 5 ]), one information content approach ( Lin [ 3 ]), three association-based approaches ( Dice , LLR and PMI ), and one context-based approach ( context [ 6 ]).
Table 1 shows the correlation between the different meth-ods and the humanly assessed concept pairs. Several things are worth noting. First, our CER-based measure of concept relatedness performs best on test set 1 and second best on test set 2. Indeed, our CER-based measure shows a very strong correlation with the judgments of test set 1; the cor-relation with the judgments of set 2 is much smaller, but compared to other methods CER still performs very well. It is remarkable that a simple association-based method such as PMI performs well on both test sets. The context-based approach proposed by Pedersen et al. performs poor in this setting; it seems that the terms describing MeSH concepts do not lead to effective context vectors.

Next, it seems that test set 2 is  X  X ore difficult X  than test set 1, since all measures show a drop in correlation. The structure-based measures show an especially sharp drop in performance, perhaps because the MeSH structure does not describe the concept relations as completely as the SNOMED CT ontology.

Our method can be interpreted as a contextual extension to association-based measures: it intrinsically biases concept pairs which have been assigned to the same documents, but it is not limited to this co-occurrence information. Moreover, the lack of dependence on structure shows to be beneficial, especially on the second test set.
 Table 1: Absolute correlation (K = Kendall  X  coef-ficient, P = Pearson X  X  correlation) between metrics and ground truth (best scores are marked in bold-face).  X  /  X  : significant correlation at 0.05/0.01 level.
We have described a novel concept relatedness measure based on the cross entropy reduction between concept lan-guage models. We have shown that the measure performs well on an ontology and document collection from the biomed-ical domain and is able to outperform other relatedness mea-sures. Future work should point out whether the approach is also useful in more general domains and how robust the method is with respect to the ontology and document col-lection used.
This work was carried out in the context of the BioRange programme of the Netherlands Bioinformatics Centre, sup-ported by a BSIK grant through the Netherlands Genomics Initiative. Edgar Meij was supported by the Virtual Lab-oratory for e-Science project. Maarten de Rijke was sup-ported by the Netherlands Organisation for Scientific Re-search (NWO) under project numbers 220-80-001, 017.001.-190, 640.001.501, 640.002.501, STE-07-012 and by the E.U. IST programme of the 6th FP for RTD under project Mul-tiMATCH contract IST-033104.
