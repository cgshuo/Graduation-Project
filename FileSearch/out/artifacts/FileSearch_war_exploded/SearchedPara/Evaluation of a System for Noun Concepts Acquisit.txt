 There are several other studies about language ac-quisition systems. Rogers et al. (1997) proposed  X  X abbette X , which learns language rules from pro-vided examples. Levinson et al. (2005) describe their research with a robot which acquires language from interaction with the real world. Kobayashi et al. (2002) proposed a model for child vocabulary ac-quisition based on an inductive logic programming framework. Thompson (1995) presented a lexical acquisition system that learns a mapping of words to their semantic representation from training exam-ples consisting of sentences paired with their seman-tic representations.

As mentioned above, researchers are interested in making a robot learn language. Most studies seem to be lacking in the ability to adapt to the real world. In addition, they should be more independent from language rules. We believe that it is necessary to simulate human language ability in order to create a complete natural language understanding system.
As the first step in our research, we devel-oped a System for Noun Concepts Acquisition from utterances about Images, called SINCA in short (which means  X  X volution X  in Japanese) (Uchida et al., 2007). It is a language acquisition system with-out knowledge of grammar and vocabulary, which learns noun concepts from a user X  X  input. SINCA uses images as a meaning representation in order to eliminate ambiguity of language. SINCA can only acquire concrete nouns.

Currently, SINCA is for Japanese only. The lan-guage acquisition method of this system is very gen-eral and it is independent of language rules. SINCA is expected to work successfully using any language. In this paper, we describe the algorithms of SINCA and an experiment to test what kind of input would be appropriate for our system. We would em-phasize that we prepared a large video data of daily life of a family with young children. Figure 1 shows the SINCA user interface. The situ-ation shown in Fig.1 is that the affection of SINCA is directed to an eraser by the user, and after the recognition process, SINCA asks  X  KESHIGOMU? (Eraser?). X 
We describe SINCA X  X  process in detail in the fol-lowing subsections. 2.1 Input A user input consists of an image paired with a spo-ken utterance.

First, a user chooses an object O which he or she likes and captures an image of it with a web camera with 300,000 pixels effective sensor resolution. The user has to try to capture the whole object O in the image.

Next, a user imagines an utterance that an infant might be exposed to when listening to caregivers while gazing at the object O in the environment. The user enters the utterance on the keyboard as a linguistic input. The linguistic input is written in Hiragana , which are Japanese phonetic characters, to avoid the linguistic input containing some direct meanings as in the case of Chinese Kanji ideograms. This is also intended to standardize the transcrip-tion. SINCA does not carry out morphological anal-ysis of the linguistic input, because we believe that infant capability for word segmentation is not per-fect (Jusczyk et al., 1999).
 2.2 Image Processing cutting edge technologies for vision, navigation, and system development. ERSP Vision included in the ERSP enables a robot or device to recognize 2D and 3D objects in real world settings where lighting and placement are not controlled. We use the ERSP vi-sion for image processing. ERSP Vision informs the system whether the object in the present input image appears in the previously input images or not. 2.3 Common Parts When a user inputs an image of an object O and an utterance, the system extracts all sections of the string matching section of previously input utter-ances accompanied by the image of the same object O . We call these strings common parts. After this process, the system deals with them as candidates for a label for the object O .

The system provides every common part with a  X  X asic score X . The basic score is based on frequency of appearance and the number of characters, and in-dicates how appropriate as a label the common part is. The higher the score, the more appropriate the common part is. The basic score is defined as fol-lows: where,  X  is a coefficient which reduces the basic score if the common part has appeared with other objects than O , F is frequency of appearance of the common part with the images of O , PN is the num-ber of use inputs with images of O , and L is the num-ber of characters of the common part. 2.4 Output If the system finds a common part whose basic score exceeds a threshold, it outputs it as text. The reason for doing this is the assumption that there is a high possibility that such common parts are appropriate as labels.

A user evaluates an output by choosing one of the following keywords:  X  Good : It is appropriate as a label.  X  Almost : It makes some sense but is not  X  Bad : It makes no sense.
 Infants cannot understand these keywords com-pletely, but they can get a sense of some meanings from the tone of an adult X  X  voice or facial expres-sions. In our research, we use the keywords as a substitute for such information. The system recalcu-lates the basic score based on the keyword chosen by the user. Specifically, the system multiplies the basic score by the coefficient  X  dependent on the keyword. 2.5 Acquisition of the Noun Concepts After repeating these processes, if there is a com-mon part whose score is more than 30.0 and which has been rated as  X  X ood X , the system acquires the common part as the label for O . 2.6 Label Acquisition Rules Humans can use their newfound knowledge to learn their native language effectively. This system imi-tates humans X  way with  X  X abel acquisition rules X .
A label acquisition rule is like a template, which enables recursive learning for acquisition of noun concepts. The system generates label acquisition rules after acquisition of a label. When the system acquires a string S as a label for an object, the system picks up the previous linguistic inputs with the im-ages of the object which contain the string S. Then, the system replaces the string S in the linguistic in-puts with a variable  X   X   X . These abstracted sentences are called label acquisition rules. An example of the label acquisition rules is shown in Fig.3.

If the rules match other parts of previoiusly input strings, the parts corresponding to the  X   X   X  variable are extracted. The scores of these extracted strings are then increased.
 We carried out an experiment to test what kinds of input would be appropriate for SINCA. This section describes the experiment. 3.1 Experimental Procedure Two types of linguistic input data were collected in two different ways: a questionnaire and a video recording. We had SINCA acquire labels for 10 im-ages using the linguistic input data. The following are the details about the data collection methods. 3.1.1 Questionnaire 10 images were printed on the questionnaire, and it asked  X  X hat would you say to a young child if he or she pays attention to these objects? X . The re-spondents are allowed to answer with whatever they come up with. 31 people responded to this question-naire, and 13 of them have children of their own. We collected 324 sentences, and the average mora length of them was 11.0. 3.1.2 Video recording
We recorded a video of a child X  X  daily life to col-lect dialogue data that was spoken to and around him. The child is a member of a family consisting of his parents and his sister.

The recordings are intended to collect daily con-versation, therefore we did not set any tasks. The total recording period comprised 125 days and we recorded about 82 hours of video data. The first au-thor watched about 26 hours of the video data, and wrote parents X  dictation in Hiragana . We selected 353 sentences for linguistic input data that were spo-ken when joint attention interactions between a par-ent and a child were recognized. On average, their mora length was 9.8. 3.2 Experimental Result We input sentences from the collected inputs one at a time until SINCA acquired a noun concept for an image. SINCA was able to acquire labels for 10 im-ages, with each type of linguistic input. When we used the questionnaire data, SINCA needed on aver-age 6.2 inputs to acquire one label, and SINCA ac-quired 52 rules through the experiment. They cover 83.8% of the total number of inputs. When we used the video data, SINCA needed on average 5.3 inputs to acquire one label, and SINCA acquired 44 rules through the experiment. They cover 83.0% of the total number of inputs. 3.3 Considerations The experimental results indicate that using video data makes the acquisition of labels more efficient. There are 3 factors that contribute to this.
The first factor is the number of one-word sen-tences. There are 66 one-word sentences in the video data (18.6% of the total). Therefore, the length of the sentences from the video data tends to be short.

The second factor is the lack of particles. The re-spondents of the questionnaire hardly ever omit par-ticles. By contrast, of the 53 sentences which were input, 23 sentences lack particles (42.6% of the to-tal) in video data. Spoken language is more likely to have omitted particles compared with written lan-guage.

The third factor is the variety of words. We ran-domly selected 100 sentences from both sets of lin-guistic input data and checked the words adjacent to a label. Table 1 shows the number of different words that occur adjacent to a label. Because the respon-dents of the questionnaire all try to explain some-thing in an image, they use similar expressions.
When SINCA uses the video data, it can extract labels more easily than using the questionnaire data because of the factors listed above. This means that SINCA is well suited for spoken language. If we assume one application of SINCA is for communi-cation robots, this result is promising. In this paper, we described the algorithms of SINCA. SINCA can acquire labels for images with-out ready-made linguistic resources, lexical infor-mation, or syntactic rules. Additionally, it targets images of real world objects.
 We collected linguistic input data in two ways. One method is videos of a family X  X  daily life. The other method is a questionnaire. We had SINCA ac-quire noun concepts using both video and question-naire data. As a result, we have showed that spoken language is well suited to SINCA X  X  algorithm for ac-quiring noun concepts.

In the next step, we will focus on acquisition of adjectives.

