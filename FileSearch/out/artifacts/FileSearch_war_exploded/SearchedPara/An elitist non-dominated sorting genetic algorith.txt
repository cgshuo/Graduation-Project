 1. Introduction 1.1. Multi-objective optimization approaches
Process optimization and control can have a significant stra-tegic impact on production cost reduction and quality enhance-ment in polymer production facilities. The optimization of a polymerization process often involves a series of objectives non-commensurable and competing with each other, which must be satisfied at the same time. Consequently, in the last several years, some research has been reported in the literature on the optimi-zation of polymerization processes using multiple objective functions and constraints.

Many optimization techniques traditionally involved single (scalar) objective functions which used a weighted average combination of several individual objectives ( Ahn et al., 1998; Garg et al., 1999; He et al., 2008a, Osyczka, 2002 ). This approach was applied to a complex polymerization process in one of our previous studies ( Curteanu and Cazacu, 2008a ). The optimization method was found to be simple to use, but depending on the user X  X  decision to specify weights to the different objectives based on good knowledge of the process. This can be a drawback when the objectives to inter-relate are of different nature. A simple genetic algorithm has been used to generate optimal weights and eliminate the user X  X  implication at this step of the optimization process, but the risk of losing some optimal solutions remained ( Curteanu and Cazacu, 2008a; Curteanu and Leon, 2008 ).
Multi-objective optimization problems usually lead to a set of non-dominated solutions, known as Pareto optimal solutions , where each objective corresponding to any point along the Pareto optimal front can be improved only by degradation of at least one of the other objectives. The Pareto optimal front is the curve that connects all the points of the Pareto optimal set.

In the case of scalar objective functions, the Pareto optimal set can only be obtained after performing a series of separate runs of the optimization procedure, using different combinations of weights. A much better approach was reported to be the multi-objective optimization with vectorial objective functions ( Bhaskar et al., 2001; Mitra et al., 2004; Silva and Biscaia, 2003 ).
Extensive research has been related in recent literature on the algorithms used for generating non-dominated Pareto optimal solutions. Evolutionary algorithms (EA) have been recognized to be particularly suitable to solve multi-objective optimization problems ( Coello, 2005 ). Using vectorial objective functions, they simultaneously deal with a series of possible solutions, which allows an entire Pareto optimal set to be evolved in a single run of the algorithm. Although only one solution must be chosen at the end of the optimization exercise and this often must be per-formed with the guidance of a decision-maker, it is a better practice to first find a set of Pareto optimal solutions, to have an idea of the extent of possible trade-offs among the underlying objectives, before focusing on a particular solution ( Majumdar et al., 2005 ). Thus, many evolutionary multi-objective optimiza-tion algorithms were developed, among which Non-dominated
Sorting Genetic Algorithm II (NSGA-II) ( Deb et al., 2002 ) has been found effective in solving a wide variety of problems. Multi-objective optimization of polymerization processes is an example of its applications ( Deb et al., 2004; Sarkar and Modak, 2005; Tarafder et al., 2005 ).
 the solutions developed by the NSGA-II algorithm was success-fully approached in a previous study on the optimization of the siloxane X  X iloxane copolymers synthesis ( Furtuna et al., 2009 ). and its superiority over other multi-objective optimization algo-rithms was demonstrated by Nawaz Ripon et al. (2007) who compared NSGA-II with NPGA ( Horn et al., 1994 ), MOGA ( Fonseca and Fleming, 1993 ), SPEA ( Zitzler and Thiele, 1999 ), VEGA ( Schaffer, 1985 ), HLGA ( Hajela and Lin, 1992 ), and PAES ( Knowles and Corne, 2000 ). The algorithms were compared based on five benchmark test problems ( Zitzler et al., 2000 ) and NSGA-II proved, in most of the cases, to be able to find better non-dominated solutions with greater diversity and convergence. like particle swarm optimization (PSO) or differential evolution (DE), NSGA-II demonstrated a greater performance on solving multi-objective optimization problems. Kukkonen and Lampinen (2004) compared NSGA-II with DE on the five multi-objective benchmark functions described in Zitzler et al. (2000) . Two versions of DE (GDE (generalized differential evolution) and
GDE2) adapted for handling constraints and multiple objectives were used and NSGA-II outperformed them, in terms of extent and diversity of the solutions, on four of the five benchmark functions. The same state-of-the-art benchmark problems ( Zitzler et al., 2000 ) were used by Meng et al. (2005) to compare two versions of PSO adapted for multi-objective optimization pro-blems  X  MOPSO (multi-objective particle swarm optimization) and IPSO (Intelligent PSO)  X  with NSGA-II. It was observed that
NSGA-II provided the best spread of the solution in all the studied cases and it outperformed the other two algorithms in terms of finding the Pareto optimal set, on three test problems. 1.2. Approaches for modeling nonlinear systems neural networks (NN) represent the best approach in modeling nonlinear systems and solving problems that do not have an algorithmic solution.
 makes artificial neural networks a very popular tool in such diverse fields as modeling, time series analysis, pattern recognition, signal processing, and control. Using n eural networks offers important properties and possibilities: non-linearity, input X  X utput transforma-tion, adaptability, unambiguous response, contextual information, fault tolerance, uniformity of analysis and design, and neurobiolo-gical analogy. Neural networks do not need to be provided with the physical and chemical laws that govern the process for NSGA-II non-dominated sorting genetic algorithm II P 0 initial population of parents chromosomes
P t population of parents chromosomes at iteration/gen-
P t +1 population of parents chromosomes at iteration/gen-perf_index quantifier of NN performance
PF solutions vector (Pareto front) popSize number of chromosomes in a population Q 0 initial population of children chromosomes
Q t population of children chromosomes at iteration/ r linear correlation coefficient at NN testing
R t temporary population of parents and children chro-
S spacing metric sol_perf quantifier of NSGA-II performance t reaction time T reaction temperature
TournamentSize number of chromosomes that are candidates upper bound upper bound of the normalization interval x monomer conversion
X 0 , X 00 sets of solutions vectors y min minimum value for variable y y max maximum value for variable y y norm normalized value for variable y algorithmically converting an input to an output, but rather need a collection of representative examples of the desired translation, after which they adapt themselves to reproduce the desired output.
The open literature reports different approaches in using neural networks to model polymerization processes: direct and inverse modeling using feed-forward neural networks ( Curteanu, 2004; Curteanu and Cazacu, 2008b; Gosden et al., 2001 ), recur-rent neural networks ( Tian et al., 2002; Xiong and Zhang, 2005 ), and stacked neural networks ( Mukherjee and Zhang, 2008; Zhang, 2008 ). These problems were reviewed in a previous work ( Curteanu and Popa, 2004 ). 1.3. The proposed approach for multi-objective optimization and modeling of a complex polymerization process
The present paper proposes an original software implementa-tion of NSGA-II applied and adapted to the optimization of a complex polymerization process  X  the heterogeneous cationic polymerization of octamethylcyclotetrasiloxane. The process for polysiloxane synthesis is very complex, with many reactions concomitantly occurring. The decision variables optimized with NSGA-II represented the reaction conditions: temperature, reac-tion time, amount of catalyst, and amount of co-catalyst. The optimized conflicting objectives were the maximization of the reaction conversion and the achievement of a desired value for the molecular weight. The variation in time of the main para-meters of the process (conversion and molecular weight) was modeled with a feed-forward neural network, which was then used to compute the fitness functions of the genetic algorithm, at every new iteration.

Using artificial neural networks for computing the objective functions of NSGA-II represents a new enhancement to the multi-objective optimization technique, leading to a faster convergence of the algorithm. Another novelty brought by this study is the creation and utilization of a new operator for choosing only the unique solutions (chromosomes) to be included in the new population, which conducted to the increase in the solutions diversity. NSGA-II was adapted to the multi-objective optimiza-tion of the polysiloxane synthesis process through the real coding of the solutions to be evolved and through the use of the genetic operators suited to this kind of coding.

In order to evaluate the performance of the algorithm, a combination of three standard performance metrics was used, in an authentic technique for determining the optimum values for the parameters of NSGA-II, which led to the best Pareto optimal front.

The multi-objective optimization of a polysiloxane synthesis process using NSGA-II and a neural model for the calculation of the fitness functions represents itself a novel application in the field of chemical engineering. The resulting optimization proce-dure is easy to manipulate and provides satisfactory results.
The case study investigated in this paper is a complex poly-merization process, with nonlinear kinetics, for which the phe-nomenology and reaction mechanism are not yet elucidated. The purpose was to prove that the AI-based techniques using neural networks and genetic algorithms can overcome the difficulties of the classical approaches, carrying out the tasks of modeling and process optimization with accurate results. A good benefit is represented by the opportunity to make predictions and to obtain optimal working conditions, which lead to the final imposed objectives, instead of performing highly expensive experiments. Furthermore, the proposed methodology is general and can be easily adapted to other data sets (processes). 2. Case study
Two general methods are well known and widely used for polysiloxane synthesis: polycondensation of bifunctional silox-anes and ring-opening polymerization of cyclic oligosiloxanes. Ring-opening polymerization is the most traditional and signifi-cant way to obtain high molar mass linear polysiloxanes. This polymerization may be carried out either anionically or cationi-cally, and can be thermodynamically or kinetically controlled. There is a wide variety of compounds that can initiate the ring-opening polymerization of cyclosiloxanes, including strong organic and inorganic acids or bases ( Vadala et al., 2004 ).
It is well known that, in the presence of the strong acids or bases, the Si X  X  bonds in both unstrained cyclosiloxanes and linear macro-molecule (which have comparable energy) can be broken, and a mixture of cyclic and linear polysiloxanes will be obtained, accord-ing to Scheme 1 . The siloxane bonds are continuously broken and reformed until the reaction reaches a thermodynamic equilibrium. Thus, the process leading to the polysiloxanes is a complex one, where many concurrent reactions (r ing-opening, condensation, back-biting, redistribution, etc.) occur.

The synthesis of polydimethylsiloxane-a , o -diols was per-formed by ring-opening polymerization of octamethylcyclotetra-siloxane, D 4 , in the presence of a solid acid as catalyst and in absence of solvent. Water is used as a co-catalyst ( Cazacu and Marcu, 1995 ). D 4 was chosen as monomer because this is of higher industrial importance towards cyclotrisiloxanes and repre-sents the major component in the cyclosiloxanes mixture result-ing from the synthesis. The obtained polymer was weighted to calculate yield and analyzed for determining the molecular weight. Consequently, a series of experimental data was obtained, taking into account different reaction conditions (reaction time and temperature, amounts of catalyst and co-catalyst) ( Curteanu and Cazacu, 2008a ).

Accurate computational methods are an alternative to experi-ments, since they are less costly and time-consuming and provide greater flexibility in terms of conditions and/or components explored ( Makrodimitri et al., 2007 ). 3. Modeling with feed-forward neural networks
It is of high importance for the neural network that models the polymerization process to offer best performance in order to enhance the multi-objective optimization procedure in which it is included. Therefore, a methodology of choosing the most suitable network must be used.
 been proposed and used by researchers in this domain, starting with trial and error method and continuing with different other techni-ques. Two general directions can be outlined: (1) automatically constructing the optimal topology based on constructive or destruc-tive algorithms ( Ma and Khorasani, 2004; Narasimha et al., 2008 )or on hybrid methods which use genetic algorithms ( Benardos and
Vosniakos, 2007; Curteanu and Leon, 2008 ) or fuzzy systems ( Engin et al., 2004; He et al., 2008b ); (2) optimizing the internal parameters of the network in orde r to obtain the best generali-zation performance ( Balestrassi et al., 2009; Kim and Yum, 2004; Packianather et al., 2000; Sukthomya and Tannock, 2005; Sureerattanan and Sureerattanan, 2005; Zeng et al., 2003 ). enunciated in a previous study ( Furtuna et al., 2011 ). In the approach to optimize the neural network parameters, the starting point was a neural network with multilayer perceptron (MLP) architecture having some default values for parameters, trained with the backpropagation algorithm. Data from the input file for the neural network were normalized, randomized and divided into training set, cross-validation set, and test set. activation functions of the hidden and output layers of the neural network. The following formula was used for normalizing the data: where y norm is the normalized value for y , y min and y max minimum and maximum values for y ,and lower bound and upper bound are the lower and upper bounds of the normalization interval. The actual values used for normalization will be detailed in Section 5.
 mum number of training epochs being determined by this way.
The training was stopped when the mean squared error for the cross-validation data set started to rise.
 was used in the optimization procedure in order to determine the optimum values for the internal parameters of the network considered as having a significant influence over its performance: the number of hidden layers, activation function, number of neurons in the hidden layers, training epochs, learning rate, and momentum term. In this approach, the fact that an insufficient number of weights leads to  X  X  X nder-fitting X  X , while too many weights lead to  X  X  X ver-fitting X  X  was taken into account. begin with a small network, with one hidden layer and few intermediate neurons, which can solve well the problem. For many applications, the optimum number of hidden layers has been found to be less than the number of inputs. In most cases, one hidden layer is sufficient to compute arbitrary decision boundaries for the outputs. A two-hidden-layers network archi-tecture may be necessary for more complicated applications ( Furtuna et al., 2011 ). Fernandes and Lona (2005) noted that, although in most cases a single layer neural network is sufficient for modeling purposes, additional hidden layers are required for complex nonlinear processes, not only from the point of view of a good fit, but also due to the fact that additional layers provide an improved capacity to generalize. Considering these statements, the optimization procedure of the neural network topology started with a single hidden layer network and continued with a two hidden layer network.
 ( MinMSECV ), the normalized mean squared error at testing ( NMSEtest ), and the linear correlation coefficient at testing ( r ) were considered as performance indices. Thus, for the quantification of the network performance, the following formula was constructed: perf _ index  X  r  X  MinMSECV  X  NMSEtest  X  :  X  2  X  mance of the network.
 used for assessing the performance of the neural network, because it is measured in the same units as the original data. 4. Optimization with non-dominated sorting genetic algorithm II (NSGA-II) 4.1. The multi-objective optimization problem siloxane synthesis process included, besides the neural model used for computing the fitness functions of NSGA-II, a multi-objective vectorial function and a series of decision variables. fitness functions: f  X  T , t , c cat , c water  X  X  X  x , 9 1 M vd = M v 9  X  ,  X  3  X  where T is reaction temperature, t the reaction time, c cat amount of catalyst, c water the amount of water (co-catalyst), x the monomer conversion, M v the viscometric molecular weight, and M vd the desired viscometric molecular weight.
 conversion while obtaining a desired viscometric molecular weight, by minimizing the difference between the desired visco-metric molecular weight and the viscometric molecular weight obtained through the synthesis process.
 catalyst, and amount of co-catalyst) determined the reaction conditions and therefore, were optimized through the optimiza-tion procedure, aiming to achieve a maximum monomer conver-sion and a desired viscometric molecular weight. The bounds for the decision variables, derived from the experimental data set ( Cazacu and Marcu, 1995 ), were:
T : 50 110 3 C , t : 10 180min , c cat : 0 : 5 3 : 5 % , c water : 0 : 1 0 : 8 % , x : 0 100 % , M v : 31 900 91 600 :  X  4  X  4.2. The NSGA-II algorithm non-dominated sorting genetic algorithm NSGA-II, which was used to obtain the set of Pareto optimal solutions and the corresponding decision variables. NSGA-II is a multi-objective, fast, elitist (the best individuals are kept through the evolution process, from one generation to another) genetic algorithm, which preserves the diversity of the solutions.
 chromosomes (solutions), P 0 of size N . The population is sorted based on non-domination. Each solution is assigned a fitness (or rank) equal to its non-domination level (1 is the best level), the minimization of the fitness being assumed. A children population ( Q 0 ) of size N is then created by applying the genetic operators: binary tournament selection, recombination, and mutation. From this point forward the regular iteration of the
NSGA-II, described in Fig. 1 , is applied for a number of times equal with the predefined number of maximum generations.
 ( Q t ) are reunited forming a temporary population, R t of size 2 N . The number of the current generation is denoted by t . The population R t is then sorted on non-dominated Pareto fronts, F being the best non-dominated front, F 2 the second one, and so on. The new population of chromosomes ( P t+ 1 ) of size N is created by selecting the non-dominated fronts based on rank order (first F then F 2 , and so on). This procedure is followed until no more fronts can be accommodated. The last added front which led to the exceeding of the population size is then sorted based on crowding distance, in descending order, and the remaining population slots are filled with the best solutions. The new obtained population is then used for generating a new population of children and the procedure described above is continued.
The crowding distance is a criterion based on comparison of the congestion around a solution and is used in the selection of parents for a new individual and the selection of a new popula-tion. A greater crowding distance is preferred in order to maintain the diversity of the solutions. 4.3. The multi-objective optimization procedure
In the proposed software implementation of NSGA-II algo-rithm, chromosomes (solutions) with four real-coded genes, corresponding to the four decision variables, were used. The constrains of the decision variables were included in their encoding.

The real coding was used because it is more suited for solving real-life problems with continuous large search spaces than the binary coding, which causes difficulties in achieving any arbitrary precision in the optimal solution. Besides, the coding and decod-ing processes are avoided by the use of real values, leading thus to an increased convergence speed. The advantages of using real coding have been revised by Herrera et al. (1998) .

The selection of a new population was based on ranking method, the selection of parents for a new individual was performed through tournament, mutation was done by resetting, and arithmetic crossover with a single point, different for each gene was used. A new operator for choosing only the unique solutions (chromosomes) to be included in the new population was created and used for the increase of the solutions diversity. The stop condition of the evolutionary iterations was the achieve-ment of a preset maximum number of generations.

The operator for choosing only the unique solutions (chromo-somes) to be included in the new population was applied to the children chromosomes resulted after crossover and mutation, in the creation process of the temporary population. The chromo-some to be included in the new temporary population was compared with the ones already chosen and if it was unique, it was added to the new population.

The steps describing the working principle of the proposed software implementation for the NSGA-II algorithm, adapted for the studied multi-objective optimization problem, are listed in the flow chart presented in Fig. 2 .

In the flow chart, popSize represents the number of chromo-somes in a population and noGen is the maximum number of generations (iterations).

The optimization procedure was implemented in the C# programming language, and specific functions were programmed for each phase of the non-dominated sorting genetic algorithm (NSGA-II) leading to an original software program.

In order to evaluate the performance of a multi-objective evolutionary algorithm, the following indices are taken into account: the time taken to converge to the Pareto optimal solutions set in the objective space, the proximity to the true Pareto optimal solutions set, and the diversity and even disper-sion of the obtained non-dominated solutions along the Pareto optimal front ( Coello et al., 2007 ).

In this study, the convergence time was measured by calculat-ing the time taken by the algorithm to reach the preset maximum number of iterations (generations). The proximity to the true Pareto optimal solutions set was appreciated by using the set coverage metric ( Coello et al., 2007 ) and the distribution of non-dominated solutions throughout the Pareto front was evaluated with the spacing metric ( Coello et al., 2007 ) where, as distance measure, the Euclidean distance was used.

Set Coverage (relative coverage comparison of two sets) was calculated with the following formula: CS  X  X 0 , X 00  X  X  f a 00 A X 00 ; ( a 0 A X 0 : a 0 Z a 00 g jj where X 0 , X 00 are two sets of solutions vectors. CS (see Eq. (5)) maps all points in X 00 are weakly dominated by the solutions in X 0 .The opposite, CS ( X 0 , X 00 )  X  0, represents the situation when none of the solutions in X 00 are covered by the set X 0 . Since the domination operator is not symmetric, CS ( X 0 , X 00 ) is not necessarily equal to considered.
 The spacing metric was calculated as S  X  where PF is the solutions vector (Pareto front), d i is the Euclidean distance (measured in objecti ve space) between solution i next consecutive solution in PF ,and d m is the mean value of the above measured distances. S (see Eq. (6)) numerically describes the spread of solutions in the Pareto front. When S  X  0, all solutions are spaced evenly apart. Thus, an algorithm having a smaller S is better. spacing metric, and the set coverage metric. Taking into account that a better solution has a lower convergence time and a lower spacing metric, the following formula was created for evaluating the obtained set of optimal solutions: sol _ perf  X  0 : 001 C t  X  0 : 999 S ,  X  7  X  where C t is the convergence time and S is the metric defined above (see Eq. (6)). sol_perf represents a weighted sum, where the weight for the convergence time was chosen to be 0.001 in order to scale its values (expressed in seconds) in the same range as were the values obtained for the spacing metric. Consequently, the weight for the spacing metric was 0.999, because it was considered more important to have a good spread of the solutions in the Pareto optimal set, than to have a very fast convergence time. The more sol_perf is close to 0, the better are the convergence time and the spread of the solutions along the optimal Pareto front.
 mance index, the best parameters for NSGA-II were found, in an original manner.
 5. Results and discussion 5.1. Modeling with NN
The feed-forward neural network used to model the polysilox-ane synthesis process had four inputs (temperature  X  T , reaction time  X  t , amount of catalyst  X  c cat , and amount of water  X  c corresponding to the neurons in the fist (input) layer and two outputs (monomer conversion, x , and viscometric molecular weight, M v ) corresponding to the neurons in the output layer. The initial values for the internal parameters of the neural network were: one hidden layer, hyperbolic tangent  X  the activa-tion function for the hidden and for the output layer, 4 neurons in the hidden layer, 1000 training epochs, 1  X  the learning rate for the hidden layer, 0.1  X  the learning rate for the output layer, and 0.7  X  the momentum term for the hidden and the output layers.

The input data from the experimental database were scaled in the interval [ 0.9, 0.9] for the activation function of the hidden layer (the hyperbolic tangent), using formula (1). When optimiz-ing the activation function of the output layer, the desired output data from the experimental database were scaled in the interval [0.05, 0.95], for the logistic function and in the interval [ 0.9, 0.9], for the hyperbolic tangent function, respectively, also using the normalization formula (1).

Data from the input file for the neural network were then randomized and divided in 60%  X  training data set, 15%  X  cross-validation data set, and 25%  X  testing data set. Thereby, for a data set of 86 exemplars, 52 exemplars were for training, 13 for cross-validation, and 21 for testing.

A sensitivity analysis was performed experimentally. The experiments were conducted so as to be able to observe the influence of each input variable upon the output parameters. More specifically, one input parameter was varied, the others being kept constant. The conclusion was that all four parameters considered in the sensitivity analysis have an important influence on the network outputs (conversion and molecular weight, respectively).
 There were performed a series of simulations using the  X  X  Vary A Parameter  X  X  training process, which provided the best network with an optimized number of neurons in the hidden layer(s) ( Furtuna et al., 2011 ). The other parameters of the neural network remained to their initial values because the optimization meth-odology did not provide any better options.

Every network was tested using the test data set. Finally, the neural network with the best performance at training and testing has been chosen to be used in the multi-objective optimization technique.

The data for the M v output of the network, representing the viscometric molecular weight, were scaled by division with 1000 because the neural network did not generalize properly when values at different scales were used for the two outputs.
The results of the simulations with scaled values for the M output of the network are shown in Table 1 . Simulations 13 and 17 gave the best results, as can be observed in the table. The neural network with optimum performance (1.596  X  total perfor-mance index) had one hidden layer with 19 neurons (4:19:2). The mean absolute errors (MAE) obtained by this neural network at testing were 4.805 for the conversion values and 6.203 for the molecular weight values.

The results obtained after testing the neural network with data not seen at training can be observed in Fig. 3 , for conversion, and Fig. 4 , for molecular weight.

After obtaining the neural network, the optimization proce-dure continued by including the neural model in the genetic algorithm for calculation of the fitness functions. At this point, the results obtained after the multi-objective optimization indicated that it is important not only to use an optimum neural network, but also one with balanced performance for the two parameters modeled. Thereby, the network with global performance close to the optimum one, MLP(4:9:2) (1.585  X  total performance index, MAE  X  5.234 for conversion values, MAE  X  5.615 for molecular weight values) (see Table 1 ), but with more balanced performance for the two outputs was included in the NSGA-II and tested.
The results were very satisfying and the optimization proce-dure continued using the network having one hidden layer with 9 neurons (4:9:2). The performance obtained at testing the neural network with data not seen at training can be observed in Fig. 5 , for conversion, and Fig. 6 , for molecular weight. 5.2. Optimizing using the multi-objective optimization procedure for the parameters of NSGA-II in order to find the optimum values of the parameters which best optimize the polymerization pro-cess. The imposed value for M vd was 80 000, thus the objective of the optimization was to obtain a greater conversion and M .
 probability of 0.03, the number of individuals in a population ( popSize ) was varied from 10 to 500 and the number of maximum generation ( noGen ) was varied from 50 to 1000. Then, with the number of individuals in a population and the number of max-imum generations set at the previously obtained optimum values, the crossover probability was varied from 0.1 to 0.9 and the mutation probability from 0.01 to 0.8.
 of generations (see Table 2 ). It has also been observed that the solutions tended to be spaced evenly apart when the population size increased, but only until a certain point ( popSize  X  300).
Further increase in the population size did not lead to a decrease in the spacing metric. The best five values obtained for sol_perf and the corresponding values for the population size and the maximum number of generations used by the genetic algorithm are marked with bold in Table 2 (simulation nos. 12, 16, 17, and 21).

For the calculation of the set coverage metric, an original technique was constructed based on the comparison between the obtained solutions vectors. The comparison procedure started with the pair of solution vectors obtained after the simulations with a population size of 10 and 50 maximum generations and with a population size of 10 and 100 maximum generations, respectively. The dominant solutions vector was chosen for further comparisons. By continuing this procedure for the solu-tions vectors obtained with the other combinations of values for the genetic algorithm parameters, the best solutions vector has been found to be the one obtained using a population size of 500 and 500 maximum generations, as can be observed in Table 3 . This comparison technique was implemented in a separate authentic software program using C# programming language.
Each combination of parameter values from the lines in the  X  X  X urrent NSGA-II parameters X  X  column, in Table 3 , was compared with the one from the same line in the  X  X  X est NSGA-II parameters X  X  column. The result of the comparison was the combination of parameter values from the line below in the  X  X  X est NSGA-II parameters X  X  column. In this way, the column  X  X  X est NSGA-II parameters X  X  contains the best combinations of parameters values in ascending order.

Three of the Pareto fronts (solutions vectors) obtained through the search for the optimum combination of parameter values for population size and number of maximum generations are illu-strated in Fig. 7 .

As a confirmation of the results presented in Table 3 , it can be observed that the Pareto front obtained for a population size of 500 and a number of maximum generation of 50 dominates the Pareto front obtained for a population size of 50 and a number of maximum generation of 500 which, in turn, dominates the Pareto front obtained for a population size of 50 and a number of maximum generation of 50.

Correlating the best values for NSGA-II parameters indicated by the set coverage metric with the optimum values denoted by the solutions performance index ( sol_perf ), the best pair of parameter values were proven to be popSize  X  500 and noGen  X  50.
The best six values obtained for sol_perf and the corresponding values for the crossover probability and mutation probability used by the genetic algorithm are marked with bold in Table 4 (simulation nos. 3, 4, 9, 12, 19, and 21). The simulations revealed that a mutation probability greater than 0.5 leads to a decrease in the number of various solutions in the optimal Pareto set, mean-ing that the diversity of the solutions is decreased. The results listed in Table 4 do not indicate an explicit dependence between the crossover or mutation probability and the convergence time or the spread of the solutions.

The best combination of crossover and mutation probabilities which offers the solutions most close to the true Pareto optimal solutions set was determined using the same technique described above. The results are listed in Table 5 . It can be observed that the best combination of crossover and mutation probabilities resulted to be 0.1 and 0.2, respectively. These values for the NSGA-II parameters also gave the best convergence time and the best spread of the solutions.
 proposed optimization problem were: a population of 500 indi-viduals, a maximum number of 50 generations, a crossover probability of 0.1, and a mutation probability of 0.2. The Pareto optimal solutions set obtained using NSGA-II with optimum parameters values is shown in Fig. 8 .
 that both conflicting objectives were satisfied in different pairs of solutions (monomer conversion reached 100% and viscometric molecular weight got to 80, in its scaled value), as a compromise between the two goals. As a main characteristic of the Pareto optimal front it can be observed that an objective is optimized in the detriment of the other: as the molecular weight reaches the desired value, the reaction conversion starts to decrease and vise versa. When monomer conversion was 100%, the viscometric molecular weight was 67 690 and when viscometric molecular weight was 80 000, the monomer conversion was 89.3%.

Since different Pareto optimal solutions have different proper-ties, the inspection of the entire Pareto front makes the task of the user much easier in deciding which specifications of the objec-tives can be achieved and which not and what compromises can be done in order to achieve optimal operating conditions for the studied process.

Figs. 9 and 10 illustrate the influence of the reaction conditions on monomer conversion and viscometric molecular weight, respectively. These decision variables correspond to each point in the Pareto front presented in Fig. 8 .

Fig. 9 shows the optimum values for the reaction time, temperature, amount of catalyst, and amount of co-catalyst, which maximize the monomer conversion. Likewise, Fig. 10 dis-plays the optimum reaction conditions, which lead to the desired viscometric molecular weight.

A series of simulations were carried out with different values for the desired viscometric molecular weight and two of the obtained Pareto optimal solutions sets are displayed in Fig. 11 for M vd  X  70 000 and 90 000, respectively.

Being able to deal with a set of possible solutions at the same time, which allows it to find the entire Pareto optimal set in a single run, the NSGA-II algorithm proved to be superior to the traditional mathematical programming techniques. For example, the scalar multi-objective function approach needs to be per-formed for a series of separate runs in order to find a set of non-dominant solutions ( Curteanu and Cazacu, 2008a ). Furthermore, the mathematical programming techniques have real issues in dealing with discontinuous and concave Pareto fronts because they cannot find the unstable minima. NSGA-II is less susceptible to the shape or continuity of the Pareto front, being able to find the stable minima as well as the unstable minima.

The results of the multi-objective optimization procedure based on NSGA-II combined with a MLP neural network highlight once again the efficacy of this method, proving its generality. The association of the elitist multi-objective evolutionary algorithm with the neural model also gave satisfactory results in the optimization of the siloxane X  X iloxane copolymers synthesis ( Furtuna et al., 2009 ). The multi-objective optimization method provided the best reaction conditions, which led to the obtaining of a maximum reaction conversion and a desired copolymer composition.
 Although new methods for improving the performance of NSGA-II are emerging ( D X  X ouza et al., 2010 ; Nawaz Ripon et al., 2007), the real-coded NSGA-II with tournament selection of the parents, mutation through resetting, arithmetic crossover, and the ranking method used for the selection of a new population stands out as a powerful tool in solving multi-objective optimization problems. Our enhancements, consisting in the new operator used for choosing only the unique solutions (chromosomes) to be included in the new population and the original technique for determining the optimum values for the parameters of the algorithm, create a more efficient and faster NSGA-II. The inclu-sion of a neural network for modeling the fitness functions of the solutions makes the improved NSGA-II very suitable for optimizing processes for which the governing rules are not well known.

In a consecutive study, we compared the multi-objective optimization method based on the real-coded NSGA-II, proposed in this study, with an improved version of NSGA-II, the
NSGA-II-RJG algorithm. A new genetic operator, the jumping genes transposition, was added to the real-coded NSGA-II in order to increase the diversity of the solutions. The performance of the two algorithms, NSGA-II and NSGA-II-RJG, were compared on a new case study  X  the multi-objective optimization of the poly-meric nanoparticles synthesis with silicone surfactants. The metrics and the technique used for the comparison of the two algorithms were the ones proposed in this paper. It was observed that the solutions vector achieved by NSGA-II dominated the solutions vector obtained by NSGA-II-RJG and the convergence time and the spacing metric attained with NSGA-II-RJG ( C t  X  13.8125 s, S  X  0.0041) were insignificantly higher than the ones obtained with NSGA-II ( C t  X  13.2031 s, S  X  0.0040). Therefore, it was concluded that the efficiency of the new jumping gene operator, in its real-coded version, depends on the problem to which it is applied. This statement also emerges from the theoretical comparative study done by Nawaz Ripon et al. (2007). 6. Conclusions for solving multi-objective optimization problems, this study proposed an original software implementation of the elitist non-dominated sorting genetic algorithm (NSGA-II), which was used and adapted for the optimization of a polysiloxane synthesis process.
 parameters of the process was used to calculate the fitness functions of NSGA-II, leading by this way to a faster convergence of the algorithm and enhancing the multi-objective optimization technique.
 mined by an original technique. The simulations revealed that the new operator used for choosing only the unique solutions (chromosomes) to be included in the new population induced a slight increase in the solutions diversity.
 study, were very useful in improving the performance of the neural network and the multi-objective algorithm by finding the best suited values for their parameters.
 forward neural model, is easy to manipulate and provides satisfactory results. The efficiency of the proposed method in finding the entire non-dominated Pareto front is illustrated by the obtained results, which show that the algorithm can quickly evolve optimal solutions as an acceptable compromise between objectives competing with each other.

Although the proposed method has been applied for an optimization problem with only two objective functions, it can also be directly used for problems with more than two objective functions and for other processes, for which the amount of knowledge is limited, the use of neural networks being a powerful tool in this sort of situations.

A further improvement to the NSGA-II algorithm would con-cern the selection of one or several solutions from the optimal Pareto front depending on the user X  X  priorities. This could be done by including the user X  X  preferences in the algorithm so as to narrow the search space.

Another major challenge in NSGA-II would be the automation of the process for finding the best algorithm parameters. The fuzzy logic techniques could be used for the dynamic control of the algorithm parameters and for monitoring the NSGA-II behavior.
 Acknowledgments
This research was conducted with the support of BRAIN  X  X  X octoral scholarships as an investment in intelligence X  X  project, financed by the European Social Found and Romanian Govern-ment and the financial support provided by Romanian Ministry of Education and Research through National Program for Research, Development, and Innovation II, project Id_592, no. 59/2007. References
