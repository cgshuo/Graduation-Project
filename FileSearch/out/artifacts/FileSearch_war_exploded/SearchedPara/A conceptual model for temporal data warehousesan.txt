 1. Introduction
Decision-making users increasingly rely on data warehouses to access historical data for supporting the strategic decisions of organizations. A data warehouse is  X  X  X  collection of subject-oriented, integrated, non-vol-atile, and time-variant data to support management X  X  decisions X  X  [25] . Subject orientation means that the development of data warehouses is done according to the analytical necessities of managers at different levels of the decision-making process. Integration represents the complex effort to join data from different opera-tional and external systems. Non-volatility ensures data durability while time-variation indicates the possibil-ity to keep different values of the same information according to its changes in time. Therefore, the last two features indicate that data warehouses should allow changes to data values without overwriting existing values.
 The structure of a data warehouse is usually represented at a logical level using a star or snowflake schema.
These schemas provide a multidimensional view of data where measures (e.g., quantity of products sold) are analyzed from different perspectives or dimensions (e.g., by product) and at different levels of detail with the help of hierarchies . On-line analytical processing (OLAP) systems allow users to perform automatic aggrega-tions of measures while traversing hierarchies: the roll-up operation transforms detailed measures into aggre-gated values (e.g., daily into monthly or yearly sales) while the drill-down operation does the contrary.
Current data warehouse and OLAP models include a time dimension that, as the other dimensions, is used for grouping purposes (using the roll-up operation). The time dimension also indicates the timeframe for mea-sures, e.g., 100 units of a product were sold in March 2007; however, it cannot be used to keep track of changes in other dimensions, e.g., when a product changes its ingredients. Therefore, usual multidimensional models are not symmetric in the way of representing changes for measures and dimensions. Consequently, the features of  X  X  X ime-variant X  X  and  X  X  X on-volatility X  X  only apply for measures leaving to applications the represen-tation of changes occurring in dimensions.

Since in many cases the changes of dimension data and the time when they have occurred are important for analysis purposes, in [29] are proposed several implementation solutions for this problem in the context of relational databases, the so-called slowly changing dimensions . Nevertheless, these solutions are not satisfac-tory since either they do not preserve the entire history of data or are difficult to implement. Further, they do not consider the research realized in the field of temporal databases.

Temporal databases have been extensively investigated over the last decades (e.g., [53] ). They provide struc-tures and mechanisms for representing and managing information that vary over time. Two different tempo-rality types. 1 are usually considered: valid time (VT) and transaction time (TT) that allow representing, respectively, when the data is true in the modeled reality and when it is current in the database. If both tem-porality types are used, they define bitemporal time (BT). In addition, the lifespan (LS) is used to record changes in time for an object as a whole.

These temporality types are used for representing either events , i.e., something that happens at a particular time point, or states , i.e., something that has extent over time. For the former an instant is used, i.e., a time point on an underlying time axis; the specific value of an instant is called timestamp . An instant may have assigned a particular value now [64] indicating current time. An instant is defined according to a non-decom-indicating the time between two instants using, respectively, non-anchored (e.g., 2 weeks) or anchored lengths of time (e.g., [02/11/2004,05/01/2005]). Sets of instants and sets of intervals can also be used for representing events and states.

Temporal data warehouses join the research achievements of temporal databases and data warehouses in order to manage time-varying multidimensional data. Temporal data warehouses raise many issues including consistent aggregation in presence of time-varying data, temporal queries, storage methods, temporal view materialization, etc. Nevertheless, very little attention from the research community has been drawn to con-ceptual and logical modeling for temporal data warehouses and to the analysis of which temporal support should be included in temporal data warehouses.

In this paper, we propose a temporal extension for the MultiDim model [33] , a conceptual model used for representing data requirements of data warehouse and OLAP applications. We refer to different temporality types supported by the model, i.e., valid time, transaction time, lifespan, and loading time. Then, we present the inclusion of temporal support in different elements of the model, i.e., in levels, hierarchies, and measures.
For levels, we discuss temporal support for attributes and for a level as a whole. For hierarchies, we present different cases considering whether temporal changes to levels, to the links between them, or to both levels and links are important to be kept.

Since source systems and data warehouses may have different time granularities, (e.g., source data may be introduced on a daily basis yet data warehouse data is aggregated by month), we consider two different situ-ations: when measures are not aggregated before loading them into a temporal data warehouse and when these aggregations are realized. For the former, by means of real-world examples we show the usefulness of having different temporality types. For the latter, we discuss issues related to different time and data granularities and propose the inclusion of temporality types meaningful for aggregated measures.

Finally, we present a mapping of the conceptual model for time-varying multidimensional data into a clas-sical (i.e., non-temporal) entity-relationship (ER) and an object-relational (OR) models. In this paper, we do not consider operations in temporal data warehouses. There are not easy to cope with since (1) different time granularities between dimension data and measures should be considered, and (2) as demonstrated by, e.g., [17] , solutions for managing different schema versions should also be included that currently does not form part of our model.

Parts of this paper have been already presented in [32,34,35] . However, this paper not only collects sparse information in an unified manner but also refers to several new aspects. We extend our model by including role-playing dimensions, and different types of measures. We provide a mapping of our model into the ER model, thus allowing designers to transform MultiDim schemas into ER schemas. Afterwards, based on well-known rules, e.g., [18] , they are able to represent the ER schemas in different logical and physical models according to the target implementation platform. We also provide additional implementation solutions for temporal hierarchies, include the OR representation for temporal levels and temporal hierarchies, and present examples of implementation using a commercial DBMS (Oracle 10g). We also mention different physical aspects that should be considered during the implementation of temporal data warehouses.

This paper is organized as follows: In Section 2 we present the definition of the MultiDim model. Section 3 refers to different temporality types supported by the model and presents a general overview of the proposed temporal extension. Section 4 refers to temporal support for levels, hierarchies, and measures. Section 5 pro-vides the mapping of the constructs of the MultiDim model to the ER and OR models. Section 6 surveys works related to temporal data warehouses. The conclusions are given in Section 7 . 2. Overview of the multidim model
It has been acknowledged for several decades that conceptual models are essential for designing applica-tions. In particular, conceptual models allow describing the requirements of an application in terms that are as close as possible to users X  perception. Thus, they facilitate the communication between users and design-ers since they do not require the knowledge of technical features of the underlying implementation platform. We proposed in [33] the MultiDim model  X  a conceptual multidimensional model for data warehouse and
OLAP applications. The MultiDim model uses graphical notations similar to those of the entity-relationship (ER) model; they are shown in Fig. 1 . In order to explain the different elements of the model, we will use the example shown in Fig. 2 , which illustrates the conceptual schema of a Sales data warehouse.
 A schema is composed of set of levels organized into dimensions as well as a set of fact relationships.
A level corresponds to an entity type in the ER model. It describes a set of real-world concepts that, from the application X  X  perspective, have similar characteristics. For example, Product , Category , and Department are some of the levels of Fig. 2 . Instances of a level are called members . As shown in Fig. 1 a, a level has a set of attributes describing the characteristics of their members. In addition, a level has one or several keys (underlined in Fig. 1 ), identifying uniquely the members of a level, each key being composed of one or several attributes. Each attribute of a level has a type, i.e., a domain for its values. Typical value domains are integer, real, or string. For brevity, in the graphical representation of our conceptual schemas we do not include type information for attributes. This can be done if necessary, and it is included in the textual representation of our model.

A fact relationship ( Fig. 1 c) expresses the focus of analysis and represents an n -ary relationship between levels. For example, the fact relationship between the Product , Time , Client , and Store levels in Fig. 2 is used participating in a fact relationship is (0, n ), we omit such cardinalities to simplify the model. Further, as shown identified by a name and is represented by a separate link between the level and the fact relationship, as can be seen for the roles Payment date and Order date relating the Time level to the Sales fact relationship.
A fact relationship may contain attributes commonly called measures . They contain data (usually numer-ical) that are analyzed using the different perspectives represented by the dimensions. For example, the Sales fact relationship in Fig. 2 includes the measures Quantity , Price , and Amount . Key attributes of the levels involved in a fact relationship indicate the granularity of measures, i.e., the level of detail at which measures are represented.

Measures can be classified as additive , semi-additive ,or non -additive [29,31] . As shown in Fig. 1 d, we sup-pose by default that measures are additive, i.e., they can be summarized along all dimensions. For semi-addi-tive and non-additive measures we include the symbols +! and F[x], respectively, next to the measure X  X  name.
Further, both measures and level attributes can be derived , i.e., calculated based on other measures or attri-butes. We use the symbol/for indicating derived attributes and measures.

A dimension is an abstract concept grouping data that shares a common semantic meaning within the domain being modeled. A dimension is composed of one level or one or more hierarchies. Hierarchies are used for establishing meaningful aggregation paths. A hierarchy comprises several related levels, e.g., the Product ,
Category ,and Department levels. Given two related levels, the lower level is called child , the higher level is called parent , and the relationship between them is called child X  X arent relationship . Since these relationships are only used for traversing from one level to the next one, they are simply represented with a line to simplify the notation.

Child X  X arent relationships are characterized by cardinalities , shown in Fig. 1 e, indicating the minimum and the maximum number of members in one level that can be related to a member in another level. For example, in Fig. 2 the child level Product is related to the parent level Category with a many-to-one cardinality, which means that every product belongs to only one category and that each category can have many products.
The levels in a hierarchy allow analyzing data at different granularities , i.e., at different levels of detail. For example, the Product level contains specific information about products while the Category level allows con-sidering these products from a more general perspective of the categories to which they belong. The level in a hierarchy that contains the most detailed data is called leaf level ; it must be the same for all hierarchies included in a dimension. The leaf level name is used for defining the dimension X  X  name. The last level in a hier-archy representing the most general data is called the root level . If several hierarchies are included in a dimen-sion, their root levels may be different. For example, both hierarchies in Product dimension in Fig. 2 comprise the same leaf level Product , while they have different root levels, the Department and the Distributor levels.
In some works the root of a hierarchy is represented using a level called All . We leave to designers the deci-sion of including it in multidimensional schemas. In this paper we do not present the All level for the different hierarchies since we consider that it is meaningless in conceptual schemas and in addition it adds unnecessary complexity to them.
 Key attributes of a parent level define how child members are grouped. For example, in Fig. 2 the
Department name in the Department level is a key attribute; it is used for grouping different category members during the roll-up operation from the Category to the Department levels. However, in the case of many-to-many child X  X arent relationships it is necessary to determine how to distribute the measures from child to parent members. For example, in Fig. 2 the relationship between Product and Category is many-to-many, i.e., the same product can be included in several categories. The notation in Fig. 1 f is used indicating that a distributing factor is used to allocate the measures associated to a product among all its categories.

Moreover, it is sometimes the case that two or more child X  X arent relationships are exclusive. This is rep-resented using the symbol of Fig. 1 g. An example is given in Fig. 2 , where clients can be either persons or orga-nizations. Thus, according to their type, clients participate in only one of the relationships departing from the Client level: persons are related to the Profession level, while organizations are related to the Sector level.
The hierarchies in a dimension may express different conceptual structures used for analysis purposes; these are differentiated with an analysis criterion ( Fig. 1 h). For example, the Product dimension in Fig. 2 includes two hierarchies: Product groups and Distribution . The former hierarchy comprises the levels Product , Category , and Department , while the latter hierarchy includes the levels Product and Distributor .

Single-level dimensions, such as Time and Store in Fig. 2 , indicate that even though these levels contain attributes that may form a hierarchy, such as City name and State name in the Store dimension, the user is not interested in using them for aggregation purposes.

As can be seen in Fig. 2 , our model allows users to clearly indicate their analysis requirements related to both the focus of analysis and the summarization levels described by the hierarchies. It also preserves the char-acteristics of logical schemas, i.e., star or snowflake schemas, providing at the same time a more abstract con-ceptual representation. Our model allows distinguishing different kinds of hierarchies existing in real-world applications [33] , which is not the case when they are represented in traditional logical schemas. 3. General description of the temporally extended MultiDim model
In this section we briefly describe the temporal extension of the MultiDim model. First, we present tempo-rality types supported in the model. Then, we show a small application example, which is used to introduce some features of the model. For brevity, and to simplify the understanding of the model, we do not refer to all features of the model presented in Section 2 , such as many-to-many and exclusive child X  X arent relationships or role-playing dimensions. 3.1. Temporality types
The MultiDim model allows designers to include valid time, transaction time, and lifespan support. How-ever, these temporality types are not introduced by users (valid time and lifespan) or generated by the tempo-ral data warehouse (transaction time) as is done in temporal databases; on the contrary, they are brought from source systems (if they exist). For example, logged systems [26] , which register all actions in log files, contain transaction time; they may also include valid time represented in user-defined attributes.
 To the best of our knowledge, no other work includes the different types of temporal support proposed in the
MultiDim model. However, these temporality types are important in the data warehouse context for several rea-sons. First, having valid time and lifespan support, users can analyze measures taking into account changes in dimension data. Second, these temporality types help implementers to develop procedures for correct measure aggregation during roll-up operations in the presence of changes in dimension data [9,17,40,62] . Finally, trans-action time is important for traceability applications, for example, for fraud detection, when the changes to data in operational databases and the time when they occurred are required for investigation processes.
In addition, considering that data in data warehouses is neither modified nor deleted, we do not include transaction time generated in a data warehouses as is done in most works related to temporal data ware-houses. Instead, we propose the so-called loading time that indicates when data was loaded into a data ware-house. This time can differ from transaction time or valid time from source systems due to the delay between the time when changes have occurred in source systems and the time when these changes are integrated into a temporal data warehouse. Loading time can help users to know since when data was available in a data ware-house for analysis purposes.

In this work we do not refer to different clocks used in source systems and in a data warehouse, such as when an international company has a headquarter in one country and receives data form stores located in countries with different time zones. Although this is an important topic, it goes out of scope of this paper since it should consider the integration processes between different source systems.

Since the different temporality types can be used for representing events or states, we include in our model denotes a set of successive instants between two instants, an instant set is used for representing the same event vals of time.

As for attributes, for brevity we do not include temporal data types in the graphical representation of our conceptual schemas. This can be done in the textual representation of our model. 3.2. Model description
In this section we shortly present the temporal extension of the MultiDim model based on the example shown in Fig. 3 . The metamodel of the MultiDim model is included in Section 4.4 , while its formal definition can be found at http://cs.ulb.ac.be/research/dw/MultiDimFormalization.pdf .
Even though most of real-world phenomena vary over time, keeping the history of their evolution may be not necessary for an application. Therefore, determining which data evolve in time depends on application requirements and the availability of temporal support in source systems. The MultiDim model allows users to determine which historical data they need by including in the schema the symbols of the corresponding tem-porality types. For example, in the schema of Fig. 3 users are not interested in keeping track of changes to clients X  data. Therefore, this dimension does not include any temporal support. On the other hand, changes in measures values and in data related to products and stores are important for the application.
The schema in Fig. 3 includes four temporal levels, i.e., levels for which the application needs to keep the lifespan of their members (noted by the LS symbol next to the level X  X  name). This support allows users to track changes of a member as a whole, e.g., inserting or deleting a product, splitting a category, etc. A level may be temporal independently of the fact that it has temporal attributes. For instance, the Product level in the figure has two temporal attributes (i.e., Size and Distributor with valid time (VT) support); this indicates that the changes to these attribute values and the time when they occur will be kept. On the other hand, the Store level includes only lifespan support without any temporal attribute.

Child X  X arent relationships may also include temporal support. For example, in Fig. 3 the LS symbol in the relationship linking the Product and Category levels indicates that the evolution on time of assignments of products to categories will be kept. Temporal support for relationships leads to two interpretations of cardi-nalities. The snapshot cardinality is valid at every time instant whereas the lifespan cardinality is valid over the entire member X  X  lifespan. The former cardinality is represented using the symbol indicating temporality type next to the child X  X arent relationship while the lifespan cardinality includes the LS symbol surrounded by an ellipse. In Fig. 3 , the snapshot cardinality between Store and Sales district levels is many-to-one while the life-span cardinality is many-to-many. They indicate that a store belongs to only one sales district at every time instant but belongs to many sales districts over its lifespan, i.e., its assignment to sales districts may change.
In a temporal multidimensional model it is important to provide a uniform temporal support for the dif-ferent elements of the model, i.e., for levels, hierarchies, and measures. We would like to avoid mixing two different approaches where dimensions include explicit temporal support (as described above) while measures require the presence of the traditional time dimension to keep track of changes. Therefore, considering that measures are attributes of fact relationships, we provide temporal support for them in the same way as is done for levels X  attributes as can be seen in Fig. 3 . In this example, changes in measure values for both measures Quantity and Amount are represented using valid time.

An important question is thus whether it is necessary to have a time dimension in the schema when includ-ing temporality types for measures. If all attributes of the time dimension can be obtained by applying time manipulation functions, such as the corresponding week, month, or quarter, this dimension is not required anymore. However, in some temporal data warehouse applications this calculation can be very time-consum-ing, or the time dimension contains data that cannot be derived, e.g., events such as promotional seasons.
Thus, the time dimension is included in a schema depending on users X  requirements and the capabilities pro-vided by the underlying DBMS. 4. Temporal extension of the multidim model
In this section we present in detail the temporal extension of the MultiDim model. Although for levels and hierarchies we only give examples using valid time, the results may be straightforwardly generalized for trans-action time. 4.1. Temporal levels
As was said before, changes in a level can occur either for a member as a whole (e.g., inserting or deleting a product) or for attribute values (e.g., changing the size of a product). Representing these changes in temporal data warehouses is important for analysis purposes, e.g., to discover how the exclusion of some products or the changes to the product X  X  size influence sales.

Lifespan support is used to keep changes of levels X  members; this is represented by putting the LS symbol next to the level X  X  name. Lifespan can be combined with transaction time and loading time which indicate, respectively, when the level member is current in a source system and in a temporal data warehouse.
On the other hand, temporal support to attributes allow keeping changes in their values and the time when they have occurred. This is represented by including the symbol of the corresponding temporality type next to the attribute name. For attributes we allow valid time, transaction time, loading time, or a combination of them. We group temporal attributes firstly, to ensure that both kinds of attributes (temporal and non-tempo-ral) can be clearly represented and secondly, to reduce the number of symbols in schemas.
 Levels can have lifespan support and can have temporal and non-temporal attributes. For example, the
Product level in Fig. 2 keeps the lifespan of its members; it also keeps one value per attribute for non-temporal attributes (e.g., Name ) and the history of value changes for temporal attributes (e.g., Size ).
Many existing temporal models impose constraints on temporal attributes and the lifespan of their corre-sponding entity types. A typical constraint is that the valid time of attribute values must be included in the lifespan of their entity. As it is done in [48] , in our model we do not impose such constraints a priori. In this way, different situations can be modeled, e.g., a product that does not belong to a store inventory (it is not included in the master file), but it is on sales for defining its acceptance level. For this product, the valid time of temporal attributes may not be within the product X  X  lifespan. On the other hand, temporal integrity con-straints may be explicitly defined, if required. using a calculus that includes Allen X  X  operators [2] . 4.2. Temporal hierarchies
Hierarchies in the MultiDim model contain several related levels. Given two related levels in a hierarchy, the levels, the relationship between them, or both may have temporal support. We examine next these different situations. 4.2.1. Non-temporal relationships between temporal levels Levels with temporal support can be associated with non-temporal relationships. An example is given in
Fig. 4 . However, incorrect analysis scenarios may occur if the child X  X arent relationships change. For example, consider the situation depicted in Fig. 5 a where at time t time t 2 category C ceases to exist. In order to have meaningful roll-up operations, product P must be assigned to another category at instant t 2 . However, non-temporal relationships indicate that either these relationships never change or if they do, only the last modification is kept. Therefore, if for a product P the relationship
P  X  C1 replaces a previous version P  X  C , there is no link that leads from product P to a category that this prod-uct was assigned to before instant t 2 . Consequently, two incorrect aggregation scenarios may occur: (1) either measures cannot be aggregated before this time instant if category C1 have not existed before instant t ( Fig. 5 b) or (2) incorrect assignment of product P to category C1 will be considered before instant t
C1 have existed before this instant.
Therefore, users and designers must be aware of the consequences of having non-temporal child X  X arent relationships between temporal levels and to allow these kind of relationships if they do not change over time.
Moreover, incorrect analysis scenario may occur when key attributes include valid time support. Recall that key attributes of levels are used for the roll-up and the drill-down operations and their values are displayed for the users, e.g. Category name . For example, suppose now that valid time support is added to the Category name in the Category level in Fig. 4 and that at time t 2 category C is renamed as category C1 as shown in Fig. 5 b. In our model we use time-invariant identifiers for members to represent links between child and parent levels, therefore, product P will always reference the same category member. However, since we have temporal sup-port for key attributes, two names for the category will exist: C before instant t fore, in order to display adequate values of key attributes (e.g., category name) for different periods of time, special aggregation procedures must be developed for the roll-up operation. 4.2.2. Temporal relationships between non-temporal levels Temporal relationships allow keeping track of the evolution of links between child and parent members.
This is represented by placing the corresponding temporal symbol, e.g., LS, on the link between hierarchy lev-els as can be seen in Fig. 6 . The MultiDim model allows designers to include lifespan, transaction time, loading time, or a combination of these temporality types for representing temporal relationships between levels.
Nevertheless, temporal relationships between non-temporal levels can lead to the problem of dangling ref-erences if level members cease to exist. For example, consider the situation depicted in Fig. 7 a where an employee E is assigned to a section S at instant t 1 , and later on, at instant t meaningful roll-up operations, the employee E must be assigned to another section at instant t levels are non-temporal there is no more information about the existence of the section S . On the other hand, the relationship is temporal, thus, both assignments will be kept with their corresponding validity interval as can be seen in Fig. 7 b. However, during the roll-up operations before the instant t ing section S will be made.

Therefore, to avoid dangling references and inconsistency during roll-up and drill-down operations, the temporal relationships between levels should be allowed only if the level members do not change.
Notice since we use time-invariant identifiers for members to represent links between child and parent lev-els, these links do not change if we modify the key attributes, e.g., change the section name. However, since levels are non-temporal, only the last modification is kept. Therefore, during the roll-up operation users can only display the last value of the key attribute, loosing history of its changes. Thus, it is users and designers decision whether to keep this history by including temporal support for key attributes. 4.2.3. Temporal relationships between temporal levels
Temporal relationships may link levels having lifespan support and/or temporal attributes. This helps to avoid incorrect analysis scenarios and dangling references as described in Sections 4.2.1 and 4.2.2 .
The example of Fig. 8 models a sales company that is in an active development: changes to sales districts may occur to improve the organizational structure. The application needs to keep the lifespan of districts in order to analyze how the organizational changes affect sales. Similarly, new stores may be created or existing ones may be closed; thus the lifespan of stores is kept. Finally, the application needs to keep track of the evo-lution of assignments of stores to sales districts.

Some temporal models impose a constraint on temporal relationships between temporal levels indicating that the valid time of a relationship instance must be included in the intersection of the valid times of partic-ipating objects. In order to ensure correctness of the roll-up and drill-down operations, in multidimensional hierarchies it is further required the following:
Notice that when levels have included valid time support for key attributes, special aggregation procedures may be required if these key attributes change their values as was explained in Section 4.2.1 . 4.2.4. Snapshot and lifespan cardinalities
Cardinalities in a non-temporal model indicate the number of members in one level that can be related to member(s) in another level. In our temporal model this cardinality may be considered at every time instant ferent from the snapshot cardinality.

In the MultiDim model the snapshot cardinality is by default equal to the lifespan cardinality; however, if these cardinalities are different, the lifespan cardinality is represented as an additional line with the LS symbol surrounded by a ellipse as shown in Fig. 9 . In the example the snapshot and lifespan cardinalities for the Work hierarchy are many-to-many indicating that an employee can work in more than one section at the same time instant and over his lifespan. On the other hand, the snapshot cardinality for the Affiliation hierarchy is one-to-many, and the lifespan cardinality is many-to-many indicating that at every time instant an employee can be affiliated to only one section, but over his lifespan he can be affiliated to many sections.

Further, it is necessary to impose a constraint such that the minimum and the maximum values of the life-span cardinality are equal to or greater than the minimum and maximum values of the snapshot cardinalities, respectively. 4.3. Temporal measures
Current multidimensional models only provide valid time support for measures. Nevertheless, as we will see in this section, providing transaction time or loading time support for measures allows expanding the analysis possibilities. We consider two situations (1) when the time granularity of measures are the same in source sys-tems and in a temporal data warehouse (TDW), i.e., measures are not aggregated with respect to time during the loading process, and (2) when this granularity is finer in source systems, i.e., measures are aggregated with respect to time during the loading process. The case when the time granularity of measures in source systems is coarser than in a temporal data warehouse is meaningless since detailed data cannot be obtained from aggre-gated data without loss of information. 4.3.1. Temporal support for non-aggregated measures
Temporal support in data warehouses depends on both the availability of temporality types in source sys-tems and the kind of required analysis. We present next different situations that refer to these two aspects in order to show the usefulness of different types of temporal support for measures. For simplicity, we use non-temporal dimensions; the inclusion of temporal dimensions is straightforward.

Case 1 . Sources : non -temporal , TDW : LT In real-world situations, sources may be non-temporal or tempo-ral support is implemented in an ad-hoc manner that can be both inefficient and difficult to obtain. Even though the sources have temporal support, their integration into the data warehouse can be too costly, e.g., for checking the time consistency between different source systems. Nevertheless, decision-making users may require the history of how source data has evolved [63] . Thus, measure values can be timestamped with loading time indicating the time when this data is loaded into the warehouse.

In the example in Fig. 10 users require the history of product inventory considering different suppliers and warehouses. The LT abbreviation next to the measures indicates that measure values will be timestamped when loaded into the temporal data warehouse.

Case 2 . Sources and TDW : VT In some situations source systems can provide valid time and this valid time is required in a temporal data warehouse. Fig. 11 gives an example used for the analysis of banking transac-tions. Different types of queries can be formulated for this schema. For example, we can analyze clients X  behavior related to the time between operations, a maximum or minimum withdrawal, total amount for with-draw operations, total number of transactions during lunch hours, frequency of using a specific ATM, etc.
Case 3 . Sources : TT , TDW : VT In this case, users require to know the time when data is valid in reality while source systems can only provide the time when data was modified in a source system, i.e., transaction time. Thus, it is necessary to analyze whether transaction time can be used for approximating valid time. For example, if a measure represents clients X  account balance, the valid time for this measure can be calculated considering the transaction time of two consecutive operations.

Nevertheless, transaction time cannot always be used for calculating valid time, since data can be inserted in source systems (registering transaction time) when they are not valid in the modeled reality, e.g., recording an employee X  X  previous or future salary. Since in many applications only the user can determine the valid time, it is incorrect to assume that if valid time is not given, the data is considered valid when it is current in source systems [36] . The transformation from transaction time to approximate valid time must be a careful decision and the designer must make aware decision-making users about the imprecision that this may introduce.
Case 4 . Sources : VT , TDW : VT and LT The most common practice is to include valid time in a temporal data warehouse. However, the addition of loading time for measures can give the information since when the data has been available for the decision-making process.

The inclusion of loading time can help to better understand decisions made in the past and to adjust loading frequencies. For the example in Fig. 12 , suppose that it was decided to increase the inventory of a product based on the increasing trend of its sales during weeks 10, 11 and 12. However, a sudden decrease of sales was revealed in the next data warehouse load occurred 8 weeks later. Thus, an additional analysis can be per-formed to understand the causes of these changes in sales behavior. Further, the decision of more frequent loads may be taken.

Case 5 . Sources : TT , TDW : TT ( LT , VT ) When a data warehouse is used for traceability applications (e.g., for fraud detection), the changes to data and the time when they have occurred should be available. That is possible if the source systems include transaction time, since in this case past states of a database are kept.
The example given in Fig. 13 is used for an insurance company having as analysis focus the amount of insurance payments. If there is suspicion of an internal fraud that modifies the amount of insurance paid to clients, it is necessary to obtain the detailed information indicating when changes in measure values have occurred. Notice that including in addition loading time would give the information since when data has been available for the investigation process. Further, the inclusion of valid time would allow to know when the pay-ment was received by client. In many real systems, the combination of both transaction time and valid time, i.e., bitemporal time, will be included.

Case 6 . Sources : BT , TDW : BT and LT Data in temporal data warehouses should provide a timely consis-tent representation of information [10] . Since some delay may occur between the time when the data is valid in the reality, when it is known in the source systems, and when it is stored in the data warehouse, it is sometimes necessary to include valid time, transaction time as well as loading time.

Fig. 14 shows an example inspired from [10] of the usefulness of having these three temporality types. In this example a salary 100 with valid time from month 2 to 5 was stored at month 3 (TT
Afterwards, at month 8 (TT 2 ) a new salary was inserted with value 200 and valid time from the month 6 until now. Data was loaded into the temporal data warehouse at time LT values of salary can be retrieved depending on which instant of time users want to analyze, e.g., the salary at month 1 is unknown, but at month 4 the value 100 is retrieved since this is the last value available in a tem-poral data warehouse even though a new salary is already stored in a source system. For more details and analysis, readers can refer to [10] ; they specify additional conditions to ensure timely correct states during ana-lytical processing.
 4.3.2. Temporal support for aggregated measures
As already said in Section 4.3.1 , if source systems are non-temporal only loading time can be included for measures. On the other hand, even if transaction time is provided by source systems, it will not be included in a temporal data warehouse when measures are aggregated. Indeed, the purpose of having transaction time is to analyze changes occurred to individual data, and transaction time for aggregated data will not give useful information for decision-making users. Therefore, in this section we will only consider measure aggregation with respect to valid time.

We consider different time granularities between source systems and a temporal data warehouse. We ana-lyze how to match these time granularities and also how to aggregate measures with different granularities.
Notice that loading frequencies in temporal data warehouses may be different from the time granularity used for measures, e.g., data may be stored using as a granule month but the loading is performed every quarter.
We suppose that data can be kept in source systems before loading it into a temporal data warehouse. 4.3.2.1. Mapping between different time granularities. Since measures from source systems can be aggregated with respect to time before loading them into temporal data warehouses, an adequate mapping between multi-ple time granularities should be considered. Two mappings may be distinguished: regular and irregular [15] .
In regular mappings some conversion constant exists, i.e., one granule is a partitioning of another granule, so if one granule is represented by an integer it can be converted to another one by a simple multiply or divide strategy. Typical examples are converting between minutes and hours or between days and weeks.
In irregular mappings, granules cannot be converted by a simple multiply or divide strategy, e.g., when con-verting between months and days, since each month is composed by a different number of days. Other exam-ples include granularities that include gaps [5] , e.g., business weeks that contain 5 days separated with a 2-day gap. Thus, mapping between different time granules must be specified explicitly. For example, Dyreson [15] requires customized functions with a detailed specification to obtain the desired conversion.

Some mappings between different granularities are not allowed in temporal databases [13,15] , e.g., between weeks and months since a week can belong to two months. Nevertheless, this situation can be found in data warehouse applications, e.g., the analysis of employees X  salaries for each month where some employees receive a salary on a weekly basis. We call the mapping of such granularities forced . It requires special handling during measure aggregations, to which we refer in the next section. 4.3.2.2. Aggregation of measures with different granularities. Measure aggregation must be realized taking into account the type of measures. As already said before, three different types of measures can be distinguished [29,31] . Additive measures , e.g., monthly income, can be summarized during different periods of time; for example, if the time granularity in a temporal data warehouse is quarter, three monthly incomes should be added before being loaded into a temporal data warehouse. Semi -additive measures , e.g., inventory quantities, cannot be summarized along the time dimension, although then can be summarized along other dimensions.
Therefore, it is necessary to determine what kinds of functions can be applied to them, e.g., average. Finally, non -additive measures , e.g., item price, cannot be summarized along any dimension.

In some cases the procedures for measure aggregation could be complex due to the different granularities between source systems and the data warehouse. A simplifying example is given in Fig. 15 where sources have a month granularity and the data warehouse has a quarter granularity. This example includes different cases: (1) a period of time with a constant salary that overlaps several quarters (salary 20 and 40), (2) a quarter with different salaries (quarter 2), and (3) a quarter when the salary is not paid during several months (quarter 3).
Suppose that a user requires the measure average salary per quarter. For the first quarter, the average value is easily calculated. For the second quarter, the simple average does not work, thus the weighted mean value may be given instead. However, for the third quarter, a user should indicate how the value must be specified. In the example, we opt for giving an undefined value. Nevertheless, if instead of using average salary we use the sum (total salary earned during a quarter), the measure value for the quarter 3 can be defined.

Real-world situations could be more complicated demanding the specification of coercion functions or semantic assumptions [5,41,57] , which include rules of how to calculate values attached to multiple time gran-ularities. In the previous example in Fig. 15 , we use a user-defined coercion function [41] stating that if a tem-poral data warehouse granule is not totally covered by the valid time of one or several salaries, the average salary is undefined. The idea of coercion functions or semantic assumptions is not new in the temporal data-base community. The proposed solutions are important to consider in the temporal data warehouse context since they are needed to develop aggregation procedures.

It should be noted that coercion functions are always required for forced mappings of granularities since a finer time granule can map to more than one coarser time granule, e.g., a week spanning over two months.
Therefore, measure values to which a finer granule is attached must be distributed. For example, suppose that a salary is paid on weekly basis and that this measure is stored into a temporal data warehouse at a month granularity. If a week belongs to two months, a user may specify that the percentage of salary that is assigned for a month is obtained from the percentage of the week contained in the month, e.g., 2 days from 7. 4.4. Metamodel of the temporally extended multidim model
In this section, in order to provide a more general description of the temporally extended MultiDim model, we present its metamodel using the UML notation as shown in Fig. 16 .

As shown in the figure, a dimension is composed of either one level or one or more hierarchies, while each hierarchy belongs to only one dimension. A hierarchy contains two or more related levels that can be shared between different hierarchies. A criterion name identifies a hierarchy and each level has a unique name. The leaf level name is used for deriving a dimension X  X  name: this is represented by the derived attribute Name in
Dimension . Levels include attributes, some of which are key attributes used for aggregation purposes while others are descriptive attributes. Attributes have a name and a type, which must be a data type, i.e., integer, real, string, etc. Further, an attribute may be derived.
 Temporal support for levels and for attributes is captured by the TempSup multivalued attribute of type
Temp . The latter is a composite attribute with two components. The first one ( tempType ) is of an enumerated type containing the literals VT, TT, BT, LS, LTS, and LT that are used for representing different kinds of temporal support, respectively, valid time, transaction time, bitemporal time, lifespan, lifespan with transac-tion time, and loading time. The second component ( tdType ) is of an enumerated type containing different temporal data types defined in the model, i.e., instant, interval, set of instants, and set of intervals.
The levels forming hierarchies are related through the Connects association class. These relationships may also be temporal independently of whether the levels are temporal or not. This is indicated by the attribute
TempSup of the Connects association class. Additionally, the relationship between two levels is characterized by snapshot and lifespan cardinalities. Both kinds of cardinalities include their minimum and maximum values expressed in the child and in the parent roles. The Connects association class includes also the distributing fac-tor, if any. A constraint not shown in the diagram specifies that a child X  X arent relationship has a distributing factor only if the maximum cardinalities of the child and the parent are equal to many.

A fact relationship represents an n -ary association between leaf levels with n &gt; 1. Since leaf levels can play different roles in this association, the role name is included in the Related association class A fact relationship may contain attributes, which are commonly called measures. They are temporal and they may be additive, semi-additive, or non-additive.

A dimension is temporal if it has at least one temporal hierarchy. A hierarchy is temporal if it has at least one temporal level or one temporal relationship between levels. This is represented by the derived attribute Temporal in Dimension and in Hierarchy .

Table 1 summarizes the temporality types that are allowed in the MultiDim model. 5. Mapping to the ER and the OR models
The MultiDim model can be implemented by mapping its specifications into those of operational data mod-els, e.g., relational, object-relational, or object-oriented models. In this paper we use a two-phase approach where a MultiDim schema is first transformed into a classical entity-relationship (ER) schema and then, into an object-relational schema (OR). We choose the ER model since it is a well-known and widely used concep-tual model. As a consequence, the ER representation of the MultiDim constructs allows a better understand-ing of their semantics. Further, the transformation of the ER model into operational data models is well understood (e.g., [18] ) and this translation can be done using usual CASE tools. Therefore, in a second step we propose mappings that allow a translation of the intermediate ER schemas into OR schemas.

We chose a mapping instead of normalization for several reasons. First, there are no well-accepted normal forms for temporal databases even though some formal approaches exist, e.g., [27,57 X 59] . Further, the pur-pose of normalization is to avoid the problems of redundancy, inconsistency, and update anomalies. However, the usual practice in data warehouses is to de-normalize relations to improve performance and to avoid the costly process of joining tables in the presence of high volumes of data. This de-normalization can be done safely because data in temporal data warehouses is integrated from operational databases, which are usually normalized, and thus, there is no danger in incurring the mentioned problems. Finally, using a normalization approach may introduce a number of artificial relations that do not correspond to real-world entities, making the system more complex for designing, implementing, and querying.

We decided to use an OR model as an example of implementation model since it extends the relational model by allowing attributes to have complex types. The OR model inherently groups related facts into a sin-gle row [12] , thus allowing to keep together changes to data and the time when they have occurred. These facil-ities are not provided within the relational model, which imposes to users the responsibility to know and to maintain the groupings of tuples representing the same real-world fact in all their interactions with the database. 5.1. Mapping of temporality types
Temporal support in the MultiDim model is added in an implicit manner, i.e., using pictograms. Therefore, the transformation of temporal support into the ER model requires additional attributes for timestamps, which are manipulated as usual attributes. The mapping also depends on whether temporal support is used for representing events or states. The former require an instant or a set of instants and the latter need a period or a set of periods.

As already said, the MultiDim model provides several temporality types: valid time, transaction time, life-span, and loading time. Valid time and lifespan are used for indicating the validity of both events and states.
When valid time is represented as a set of instants or a set of periods it allows specifying that an attribute has the same value in discontinuous time spans, e.g., an employee working in the same section during different periods of time. Similarly, representing lifespan as a set of periods allows considering discontinuous lifespans, e.g., a professor leaving for sabbatical during some period of time. For representing transaction time, the usual practice in temporal databases is to use a period or a set of periods. Since loading time indicates the time when data was loaded into a temporal data warehouse, an instant is used for representing this temporality type. The rules for mapping the temporality types from the MultiDim model to the ER model are as follows: Rule 1: A temporality type representing an instant is mapped to a monovalued attribute.
 Rule 2: A temporality type representing a set of instants is mapped to a multivalued attribute.
Rule 3: A temporality type representing an interval is mapped to a composite attribute having two attributes
Rule 4: A temporality type representing a set of intervals is mapped to a multivalued composite attribute
We use the SQL:2003 standard to specify the mapping to the OR model. SQL:2003 represents collections using array and multiset types. The array type allows storing in a column variable-sized vectors of values of the same type while the multiset type allows storing unordered collections of values. Unlike arrays, multisets have no declared maximum cardinality. Composite types can be combined allowing nested collections, although this is considered an  X  X  X dvanced feature X  X  in the standard.

SQL:2003 also supports structured user-defined types , which are analogous to class declarations in object languages. Structured types may have attributes, which can be of any SQL type including other structured types at any nesting. Structured types can be used as domain of a column of a table, as domain of an attribute of another type, or as a domain of a table. These structured types allow to group semantically related attributes.

Therefore, in the mapping to the OR model (1) a multivalued attribute in the ER model is represented as a multiset (or array) attribute, and (2) a composite attribute in the ER model is represented as an attribute of a structured type. In this way, an instant, a set of instants, a period, and a set of periods can be represented in
SQL:2003 as follows: create type InstantType as date ; create type InstantSetType as InstantType multiset ; create type PeriodType as ( FromTime date , ToTime date ); create type PeriodSetType as PeriodType multiset ;
As example of a commercial object-relational DBMS we use Oracle 10g [47] . Oracle includes constructs that allow representing collections. A varying array stores an ordered set of elements in a single row while a table type allows having unordered sets and creating nested tables, i.e., a table within a table. The former corre-sponds to the array type of SQL:2003 and the latter to the multiset type. Further, Oracle provides object types that are similar to structured user-defined types in SQL:2003. Thus, the above-specified declarations using
SQL:2003 can be expressed in Oracle 10g as follows: create type InstantType as object ( Instant date ); create type InstantSetType as table of Instant ; create type PeriodType as object ( FromTime date , ToTime date ); create type PeriodSetType as table of PeriodType ; 5.2. Mapping of temporal levels 5.2.1. Temporal attributes of a level
The transformation of the Product level from Fig. 4 (not considering for now lifespan support) to the ER model is shown in Fig. 17 a and it is done according to the following rules: Rule 5: A level corresponds to an entity type in the ER model.
 Rule 6: A non-temporal attribute is represented in the ER model as a monovalued attribute.

Rule 7: A temporal attribute is represented in the ER model as a multivalued composite attribute, including
Notice that the multivalued attribute included in the last rule above allows keeping different values of the attribute at different periods of time. In the example of Fig. 17 a, the validity of attribute values is represented by a period, which is a typical practice for dimension data in temporal data warehouses [7,17] .
As can be seen by comparing the Product level in Figs. 4 and 17 a, the MultiDim model provides a better conceptual representation of time-varying attributes than the ER model. It contains less elements, it allows clearly distinguishing which data changes should be kept, and it leaves outside of users X  concern technical aspects such as multivalued or composite attributes.

Applying to the Product level in 17 a the traditional mapping to the relational model (e.g., [18] ), gives three tables: one with all monovalued attributes and one for each multivalued attribute. All tables include the key separate tables. It also has well-known performance problems due to the required join operations, especially if levels belong to hierarchies.

An OR representation allows overcoming these drawbacks, keeping together in a single table a level and its temporal attributes. Fig. 17 b shows the corresponding OR schema using a tabular representation. In the figure we use the symbol * for denoting collections. For simplicity we do not include in the figure the Dis-tributor attribute, which can be mapped similarly to the Size attribute. The OR representation corresponds to a temporally grouped data model [12] , which is considered as more expressive for modeling complex data [59] .

The temporal attribute in the OR model is represented as a multiset attribute of a structured type composed of two attributes: one for representing the value and another one for the associated temporality type. For example, given the declarations for the temporality types in Section 5.1 , the types for the Size attribute are defined as follows: create type SizeType as ( Value real , VT PeriodType ); create type SizeCollType as SizeType multiset ;
Since Size is a multivalued attribute, we represent it above as a multiset, but an array could also be used instead.

As a level corresponds to an entity type in the ER model (Rule 5), it is represented in the OR model as a table containing all its attributes and an additional attribute for its key. Two kinds of tables can be defined in
SQL:2003. Relational tables are usual tables, although the domains for attributes are all predefined or user-defined types. Typed tables are tables that use structured types for their definition. In addition, typed tables contain a self-referencing column keeping the value that uniquely identifies each row. Such column may be the primary key of the table, it could be derived from one or more attributes, or it could be a column whose values are automatically generated by the DBMS, i.e., surrogates.

Surrogates are important in data warehouses since they ensure both better performance during join oper-ations and independency from transactional systems. Further, surrogates do not vary over time, so two enti-ties having identical surrogates represent the same entity, thus allowing to include historical data in an unambiguous way. For this reason, we use a typed table for representing the Product level. declaration of a typed table requires the previous definition of a type for the elements of the table: create type ProductType as ( Number integer , Name character varying (25), create table Product of ProductType ( constraint prodPK primary key ( Number ),
The clause ref is Sid system generated indicates that Sid is a surrogate attribute automatically generated by the system.

To define the Product table in Oracle 10g we use the specification of temporality types from Section 5.1 as follows: create type SizeType as object ( Value number , VT PeriodType ); create type SizeTabType as table of SizeType ; create type ProductType as object ( Number number (10), Name varchar 2(25), create table Product of ProductType ( constraint prodPK primary key ( Number ))
The definitions in Oracle slightly differ from those in SQL:2003. As specified in Section 5.1 two different types of collections can be used, i.e., varying array and table types. Further, typed tables in SQL:2003 corre-spond to object tables in Oracle and they either include automatically generated surrogates (as in the previous example, the default option) or alternatively can use the primary key for that purpose.

However, it is important to consider the differences at the physical level between the two options that Ora-cle provides for representing collections. Varying arrays are in general stored  X  X  X nline X  X  in a row indexed. On the other hand, rows in a nested table can have identifiers, can be indexed, and are not necessarily brought to memory when accessing the main table (if the field defined as a nested table is not specified in the query). Nested tables require to specify their physical locations. For example, as shown in the previous dec-laration, the physical location for the nested table Size must be explicitly defined when the Product table is created. Therefore, the choice between nested tables and varying arrays must be done according to application specificities, e.g., which data is accessed, which operations are required, as well as taking into account perfor-mance issues. 5.2.2. Level lifespan The ER representation for a level that includes lifespan support, e.g., the Product level in Fig. 3 , is shown in Fig. 18 a. Recall that in Section 5.1 we explained the mapping of the lifespan temporality type to the ER model.
In the example we represented the lifespan by a set of periods, thus allowing products to have discontinuous lifespans.

Rule 8: The lifespan of a level is represented in the ER schema by an additional attribute mapped according
Fig. 18 b shows the OR representation where the surrogate attribute, the lifespan, and all level X  X  attributes are kept together in the same table. On the contrary, representing the lifespan in the relational model would introduce an additional table with a foreign key referring to the surrogate attribute and with two attributes FromTime and ToTime representing the begin and the end instants of the lifespan.

The SQL:2003 declaration for the Product type includes an additional attribute representing the temporal element of the lifespan as follows: create type ProductType as ( LS PeriodSetType , Number integer , 5.3. Mapping of child X  X arent relationships
In the MultiDim model child X  X arent relationships can be temporal or not, and they may relate levels that are temporal or non-temporal. In Section 5.2 we already discussed the mapping procedures for temporal lev-els; non-temporal levels are mapped in the similar way ignoring all aspects related to temporal support [33] .In this section we present the mapping of child X  X arent relationships considering two cases: when these relation-ships are temporal or not. 5.3.1. Mapping of non-temporal relationships
The transformation of the non-temporal relationship between Product and Category in Fig. 4 model is shown in Fig. 19 a. This transformation is based on the following rule: Rule 9: Non-temporal relationships are represented as usual binary relationships in the ER model.
For obtaining the corresponding OR schema, we first represent each level as explained in Section 5.2 . Then, we use the traditional mapping for binary many-to-one relationships and include a reference to the parent level time-invariant, this mapping does not depend on whether the levels are temporal or not. For example, the mapping of the Product level and the Product  X  Category relationship gives the relation shown in Fig. 19 b.
To define the Product table in SQL:2003, we need to create first a typed table Category with the surrogate in the Sid attribute. This is shown next: create type CategoryType as ( Name character varying (25), ... ) create table Category of CategoryType (/ * additional constraints create type ProductType as ( Number integer , ... , Sizes SizeCollType , create table Product of ProductType ( constraint prodPK primary key ( Number ), Notice the CategoryRef attribute in ProductType , which is a reference type pointing to the Category table.
This attribute can be used for the roll-up operation from the Product to the Category level. However, there is no such direct access in the opposite direction for the drill-down operation, i.e., from the Category to the Prod-uct level. If the application requires such link, it can be represented in an additional attribute of the Category-
Type as follows: ProductRef ref(ProductType) multiset . It allows representing a set of product surrogates that belongs to a specific category.
 The Oracle declarations for representing the Product groups hierarchy are very similar to those of
SQL:2003: create type CategoryType as object ( Name varchar (25), ... ); create table Category of CategoryType (/ * additional constraints create type ProductType as object ( Number number (10), ... , Sizes SizeTabType , create table Product of ProductType ( constraint prodPK primary key ( Number ), constraint prodFK foreign key CategoryRef references Category ) 5.3.2. Mapping of temporal relationships Temporal relationships can link either non-temporal levels an in Figs. 6 and 9 , or temporal levels as in Fig. 8 . Further, the maximum cardinality of the child level can be equal to 1 or to n . Notice that in order to have meaningful hierarchies, we suppose that the maximum cardinality of the parent level is always equal to n .

Fig. 20 a shows a schema where the maximum child cardinality is equal to 1. In the figure the snapshot and lifespan cardinalities are the same (i.e., many-to-one) allowing a child member to belong to at most one parent member during its entire lifespan; they indicate that an employee may work only in one section and if he returns after a leave, he must be assigned to the same section.

There are two different cases when the maximum child cardinality is equal to n. In Fig. 20 b the snapshot and lifespan cardinalities are different, i.e., a child member is related to one parent member at every time instant and to many parent members over its lifespan. On the other hand, in Fig. 20 c the snapshot and lifespan cardinalities are the same, i.e., a child member is related to many parent members at every time instant. mapping of both cases are handled in the same way since for the first case when the cardinalities are different, we must keep the different links according to the lifespan cardinality. The snapshot cardinality is then repre-sented as a constraint stating that among all links of a member only one is current.
 The following rule is used for mapping temporal relationships.

Rule 10: Temporal relationships are mapped into the ER model as usual binary relationships taking into
An example of applying this rule for the schema in Fig. 20 a is shown in Fig. 21 . The valid time of the rela-tionship is represented as a multivalued composite attribute since an employee can be hired several times in the same section, i.e., it corresponds to a set of periods. The mapping to the ER model of the schema in Fig. 20 b and c is straightforward. It can be represented in the same way as in Fig. 21 excepted that the cardinalities of relationships are both (1, n ).

There are several options for representing temporal relationships in the OR model. The first option consists in creating a separate table for the temporal relationship; this is shown in Fig. 22 a for the ER schema in Fig. 21 . The Work table is composed of the surrogates of the Employee and the Section levels, as well as the temporality of the relationship. For defining the Work table in SQL:2003, the
Employee and Section tables must have been previously declared as typed tables. We do not use a typed table for representing the Work relationship since the relationship does not exist without their related levels. create type WorkType as ( SectionRef ref ( SectionType ) scope Section create table Work ( EmployeeRef ref ( EmployeeType ) scope Employee
Notice that when the cardinalities between the child and the parent levels are many-to-many ( Figs. 20 band c), it suffices to define the InSection attribute above as multivalued (i.e., of type WorkType multiset ), since an employee can work in many sections over his lifespan.

The second option consists in representing a temporal relationship as a composite attribute in one of the the InSection attribute keeping the Section surrogates with its associated temporal span. The corresponding
SQL:2003 declaration is as follows: create type EmployeeType as ( EmplID integer , ... , InSection WorkType );
If the cardinalities between the Employee and Section levels are many-to-many ( Fig. 20 b and c), the InSec-tion attribute should be defined as WorkType multiset allowing an employee to work in many sections; this is shown in Fig. 22 c.

Similar to the mapping of non-temporal relationships (Section 5.3.1 ) in order to facilitate the access to members of the Employee level during the drill-down operations from the Section level, we could include in the Section table an additional multivalued attribute that keeps for a section member the references to the related employee members and their temporal characteristics.

The second solution above, i.e., the inclusion of an additional attribute in a level table, allows keeping all attributes and relationships of a level in a single table. This table expresses thus the whole semantics of a level.
However, the choice among the alternative OR representations may depend on query performance require-ments and physical-level considerations for the particular DBMS, such as join algorithms, indexing capabil-tables, thus not offering any advantage with respect to the solution of a separate table for the Work relationship.

The ER and the OR representations for temporal levels linked with temporal relationships are the same as the ones described for non-temporal levels and temporal relationships since the surrogates of child and parent members are time-invariant. An example of a MultiDim schema and its OR representation corresponding to this case is given in Fig. 23 . 5.4. Mapping of fact relationships with temporal measures
Temporal measures may represent either events or states. In this section we only refer to measures whose valid time is represented as an instant with granularity month. Nevertheless, the results may be straightfor-wardly generalized for other granularities or if valid time is represented by a period.
 The following rule is used for mapping fact relationships.

Rule 11: A fact relationship corresponds to an n -ary relationship in the ER model. Measures of the relation-Fig. 24 a shows the mapping to the ER model of the fact relationship with temporal measures from Fig. 3 .
Mapping this fact relationship to the relational model in first normal form (1FN) gives two tables. In Fig. 24 b we only show the table for the Amount measure since the other table for the Quantity measure has similar structure. However, this schema can be simplified if additional information is available. For example, if all measures are temporally correlated they can be represented in one table and tuple timestamping can be applied. In our example this means to add the Quantity attribute to the table in Fig. 24 b.

The OR model also creates a separate table that includes as attributes the references to the surrogate keys of the participating levels. In addition, every measure is mapped into a new attribute in the same way as was done for the temporal attribute of a level. An example of the tabular OR representation is given in Fig. 24 c.
However, even though the OR model allows for representing the changes in measure values for the same combination of foreign keys, in practice it may be not well suited for aggregations with respect to time. The objects created for measures contain a two-level nesting: one for representing different measure values for the same combination of foreign keys and another for representing temporal elements. Therefore, it is difficult to express aggregation statements related to time when accessing the second-level nesting.
 For choosing the OR representation, it is important to consider physical-level features of the particular OR
DBMS. For example, when using nested varying arrays in Oracle 10g, timestamps cannot be indexed and comparisons for valid time must be done by programming. On the other hand, if two nested tables are used, indexing and comparisons are allowed improving query formulation and execution. However, for accessing a measure and its corresponding valid time two nested tables must be joined in addition to a join with the main table containing the foreign keys. Therefore, depending on the specific features of the target OR DBMS, the relational representation may be more adequate in order to represent in a more  X  X  X alanced X  X  manner all attri-butes that may be used for aggregation purposes. 6. Related work
The necessity to manage time-varying data in databases has been acknowledged for several decades, e.g., [19,28] . However, no such consensus has been reached for representing time-varying multidimensional data.
Works related to temporal data warehouses raise many issues, for example, the inclusion of temporality types in temporal data warehouses (e.g., [1,10] ), temporal querying of multidimensional data (e.g., [40,49] ), correct aggregation in presence of data and structural changes (e.g., [17,24,40] ), temporal view materialization from non-temporal sources (e.g., [63] ), evolution of a multidimensional structure (e.g., [9,17,40] ), or implementation considerations for a temporal star schema (e.g., [7] ). Nevertheless, very little attention has been drawn to con-ceptual modeling for temporal data warehouses and its subsequent logical mapping.

The works reviewed next fall into four categories. First, the works describing different temporality types that may be included in temporal data warehouses; second, proposals of conceptual models for temporal data warehouses; third, works referring to a logical-level representation; and finally, works related to different granularities. 6.1. Types of temporal support
The inclusion of different temporality types in temporal data warehouses is briefly mentioned in several works. While most of them consider valid time [4,7,9,11,16,17,36,46,50,63] , they do no distinguish between constraints when levels form hierarchies.

With respect to transaction time several approaches are taken. Some approaches ignore transaction time [9,39] . As we already mentioned, the lack of transaction time precludes traceability applications. In [49] the possibility of including transaction time is briefly mentioned, but there is no analysis of the usefulness of hav-ing this temporality type in the data warehouse context. Other approaches transform transaction time from source systems to represent valid time [1,36] . This is semantically incorrect because data may be included in databases independently of their period of validity, for example, adding data about future employees. Finally, other approaches consider transaction time generated in a temporal data warehouse in the same way as trans-action time is used in temporal databases [30,36,52] , i.e., allowing to know when data was inserted, updated, or deleted from data warehouses. Since data in temporal data warehouses is neither modified nor deleted, trans-action time generated in a temporal data warehouse represents indeed the time when data was loaded into a data warehouse.

Our proposal differs from the works mentioned above in several respects: (1) we distinguish lifespan sup-port for levels and valid time support for attributes and measures, (2) we include valid time, lifespan, and transaction time support coming from source systems (if available), and (3) we include a new temporality type, i.e., loading time, that is generated in a temporal data warehouse. We showed by means of examples the use-fulness of these temporality types. To the best of our knowledge, only [10] discusses the inclusion of valid time, transaction time, and loading time. However, unlike our approach, they limit the use of these temporality types for active data warehouses and do not provide a conceptual model that includes these types. 6.2. Conceptual modeling and data manipulation
Several authors provide solutions for handling changes in multidimensional models [9,61] . These solutions can fit into two groups [9] : schema evolution [6,23,24,61] and historical models [8,9,11,16,17,20,39,49] . In the former approach, a unique data warehouse schema is maintained and data is mapped to the most recent schema version. The authors usually propose a set of operations that allow schema (and instance) modifica-tions. However, since only the last version of the schema is included, the history of data evolution is lost.
Historical models keep track of the evolution of schema and/or instances [9] , allowing the coexistence of different schema and/or instance versions. In general, the proposed model includes temporal support for levels and links between them. Very few models only timestamp instances. For example, [11] timestamps hierarchical assignments between level instances. At the implementation level, the assignments are represented as a matrix whose rows and columns correspond to the level instances and cells store the validity times of hierarchical assignments between level instances. A similar approach that timestamps level instances and their hierarchical assignments is presented in [16] . However, in their matrix the rows and columns represent the old and new version of instances while cells include the value that is used for transforming measures from one version to another one.

Most models are able to represent changes at the schema level; the changes at the instance level are man-aged as a consequence of schema modifications. These models mainly focus on the problem of data aggrega-tion in the presence of different schema/instance versions.

Different mechanisms are used for creating a new schema version. For example, [51] defines a multiversion multidimensional model that consists of a set of star versions. Each star version is associated to a temporal interval that includes one version for a fact and one version for each dimension associated to a fact. Whatever changes occur at the schema level (to dimensions or facts), a new star version is created. A similar approach is taken by [61] where each change at the schema or instance levels results in the creation of a new schema ver-sion, even though it remains the same as the original one in the case of changes at the instance level. On the other hand, in the approach of [20,21] a schema is first transformed into a graph of functional dependencies and then, a new schema is created using schema modification operators.

Several models refer to the aggregation of measures in the presence of time-varying dimensional data, i.e., when the issued queries refer to data included in several schema versions. Some works require transformation functions between different schema/instance versions. For example, [20,21] created the so-called augmented schema that contains elements in which the old and new schema versions differ. Then, users should specify transformation actions between different versions. A set of mapping functions is also required in the solutions proposed by [8,9,16,17,50,51] . The model of [39,40] extends the approach of [23,24] by including timestamps for schema and instance versions. It also defines a specific language, called TOLAP (Temporal OLAP) that allows users to aggregate measures according to the dimension structures when the corresponding measures were introduced. Another query language for temporal data is presented in [61] , which integrates several pre-vious works of [4,45,46] . This language first decomposes a query into partial queries executed on a unique ver-sion, and then, present these partial results to the users together with version and metadata information. In the second phase, the integration of partial results (if possible) into a common set of data is realized.
Other works relate to specific problems, such as maintaining changes for measures representing late regis-tration events (i.e., events needing some confirmation to be valid) [52] . Even though, the authors consider valid time and transaction time, they include them only for measures. Therefore, changes to dimension data are not considered.

Summarizing we can say that the above-mentioned models formally describe the temporal support for mul-tidimensional models, allowing to express changes in dimension members, hierarchy links, and in fact relation-ships. Further, several works provide a query mechanism for the specific models proposed by the authors.
However, none of the models propose a graphical representation based on a multidimensional view of tem-poral data that can be used for communication between users and designers. Further, they do not consider different aspects as proposed in this paper, for example, a hierarchy that may have temporal and non-temporal levels linked with either temporal or non-temporal relationships, the inclusion of different temporality types for measures, and the problem of different time granularities between source systems and temporal data ware-houses. In addition, these models do not provide an associated logical representation.

With respect to query and aggregation mechanisms, all solutions proposed require customized implemen-tations. On the contrary, we showed that temporal data warehouses can be implemented in current DBMSs. In this way we provided a more general approach that does not require a specific software for manipulating mul-tidimensional data that vary over time. Since at the moment we do not consider schema versioning, our approach is closer to the solutions proposed for temporal databases, in particular for temporal aggregations [44,55,56] . However, it is possible to extend our model with schema versioning. This extension can be done in a similar way as proposed by [4,45,46,61] when after realizing temporal aggregation for each version of the schema/instances (corresponding to temporal aggregations based on instant grouping [55] ), users must decide whether the results can be integrated. 6.3. Logical representation
Regarding logical representation for temporal data warehouses, [7] introduce a temporal star schema that differs from the classical one by the fact that the time dimension does not exist; instead the rows in all tables of the schema are timestamped. The authors compare this model with the classical star schema taking into account database size and performance. They conclude that the temporal star schema facilitates expressing and executing queries, it is smaller in size, and it does not keep redundant information.

In [24,40] are proposed two logical representation for their conceptual model, called fixed and non-fixed schemas, that are similar to snowflake and star schemas, respectively, with the difference that each row is time-stamped. Since their approach also refers to the schema versioning, additional tables that contain information about schemas and their validity are required. On the other hand, [9] implements their model using star schema changing some model characteristics and incurring into data repetition for those instances that do not change in different versions.

Given the lack of a satisfactory solution for a logical representation of temporal data warehouses, we briefly review logical models for temporal databases with the goal to adapt some of these ideas for the logical rep-resentation of temporal data warehouses.

One approach for logical-level design of temporal databases is to use normalization. Temporal functional dependencies have been defined, e.g., in [27,57 X 59] . Most of these approaches rely on the first normal form (1NF), However, the non-first normal form (NF2), e.g., [3] , was proposed for solving the well-known limita-tions of the first normal form for modeling complex data. The NF2 allows structured domains, collection domains, and relation-valued domains, and these are also included in the SQL:2003 standard under the name of object-relational model [37,38] . In addition, leading DBMS vendors (for example, Oracle, IBM DB2) have also included object-relational features. [12] distinguish temporally grouped and temporally ungrouped historical data models. The former cor-responds to attribute-timestamping models using complex domains in NF2, the latter to tuple-timestam-ping models represented in 1NF. Although these two approaches model the same information, they are not equivalent: while a grouped relation can be ungrouped, for an ungrouped relation there is not a unique grouped relation. [59] considers that the approach given in [12] has difficulties in managing time-varying data due to the absence of an explicit group identifier. Further, [12,59] consider that tempo-rally grouped models are more expressive. Based on this conclusion, we have chosen a mapping to object-relational databases that are able to represent temporally grouped model with an explicit group identifier (i.e., a surrogate).
 Another approach for logical-level design of temporal databases is based on mapping conceptual models.
While this is the usual practice for conventional (i.e., non-temporal) database design, to the best of our knowl-edge only [14,22,54] propose such an approach for obtaining a logical schema from a temporal conceptual model. In general, the approach for mapping timestamped elements is to create a table for each entity type that includes lifespan, a separate table for each timestamped monovalued attribute, and one additional table for each multivalued attribute, whether timestamped or not. This approach produces a significant number of tables since entities and their time-varying attributes are represented separately. It is not intuitive for express-ing the semantics of the modeled reality. 6.4. Temporal granularity
There are many works in temporal databases related to transformations for different granularities, e.g., [5,13,60] . In this section we only mention some of them; more detailed references can be found, for example, in [5,13] . For example, [15] defines mappings between different granularities as explained in Section 4.3.2.1 , while [5,41] refer to the problem of conversion of different time granularities as well as handling data attached to these granules. [5] propose calendar operations that allow to capture the relationships existing between time granularities. The authors define point-and interval-based assumptions that can be used, respectively, for data conversion between the same or different time granularities. [41] consider the transformation of time-varying data for the is-a relationship in a temporal object-oriented data model. To ensure the adequate transformation between a type and its subtypes having different time granularities, they introduce and classify coercion functions.

Even though the aspect of managing data with multiple time granularities is widely investigated in temporal databases, this is still an open research in temporal data warehouses. In this paper, we only consider different time granularities between source systems and a temporal data warehouse. 7. Conclusions
Bringing together two research areas, data warehouses and temporal databases, allows combining the achievements of each of them leading to the emerging field of temporal data warehouses. Nevertheless, neither data warehouses nor temporal databases have a well-accepted conceptual model that can be used for captur-ing users X  requirements. To establish a better communication between designers and users, we presented a tem-poral extension of the MultiDim model. We included temporal support for levels, attributes, child X  X arent relationships forming hierarchies, and measures giving their conceptual and logical representations.
First, we discussed the inclusion of valid and transaction time coming from source systems and the loading time generated in a temporal data warehouse. Next, we referred to levels that include temporal attributes and lifespan support. We also discussed three different cases for temporal hierarchies: (1) non-temporal relation-ships between temporal levels, (2) temporal relationships between non-temporal levels, and (3) temporal rela-tionships between temporal levels. For temporal measures we analyzed two different situations depending on whether the time granularity for representing measures in temporal data warehouses is either the same or coar-ser than the one in source systems.

For each element of our multidimensional model we included its conceptual representation and its trans-formation to the entity-relationship (ER) and the object-relational (OR) models. We also showed examples of implementation using Oracle, indicating physical features that should be considered during the implemen-tation of a temporal data warehouse.

Providing temporality types in a conceptual model allows including temporal semantics as an integral part of temporal data warehouses. In this way, the temporal extension provides symmetry to multidimensional models allowing to represent changes and the time when they occur for all data warehouse elements. After-wards, logical and physical models can be derived from such a conceptual representation.

The translation of the constructs of the MultiDim model to the ER model allows a better understanding of their semantics. However, the ER model provides a less convenient conceptual representation of time-varying attributes, levels, and relationships than the MultiDim model. The latter contains less elements, it clearly allows to distinguish which data changes should be kept, and it leaves outside of user X  X  concerns more tech-nical aspects.

On the other hand, the proposed mapping to the OR model helps implementers who use the MultiDim model for conceptual design of temporal data warehouses. The mapping also shows the feasibility of imple-menting our model in current DBMSs. Further, the mapping considers the particularities of the different ele-ments of a multidimensional model as well as the specificities of current DBMSs.

The object-relational model allows a better representation of temporal levels and hierarchies than the rela-tional model. In the former model a level and its corresponding temporal attributes are kept together while the relational model produces a significant number of tables with well-known disadvantages for modeling and implementation. Unlike the relational model, there are several alternatives for representing in the OR model a child X  X arent relationship. The choice among them must be made considering both application semantics and the physical level features of the particular OR DBMS. On the other hand, the relational model is more ade-quate for representing temporal measures. It considers in the same manner all attributes including the ones that represent time, thus facilitating aggregation procedures.

The proposed mapping may vary according to the expected usage patterns, e.g., data mining algorithms, and specific features of the target implementation system. For example, users may choose a tool-specific mul-tidimensional storage (e.g., using Analytic Workspace in Oracle 10g) instead of relying on more general solu-tions as the ones proposed in this paper.
References
