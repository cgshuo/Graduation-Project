 We report on an automated runtime anomaly detection method at the application layer of multi-node computer systems. Al-though several network management systems are available in the market, none of them have sufficient capabilities to detect faults in multi-tier Web-based systems with redun-dancy. We model a Web-based system as a weighted graph, where each node represents a  X  X ervice X  and each edge repre-sents a dependency between services. Since the edge weights vary greatly over time, the problem we address is that of anomaly detection from a time sequence of graphs.
In our method, we first extract a feature vector from the adjacency matrix that represents the activities of all of the services. The heart of our method is to use the principal eigenvector of the eigenclusters of the graph. Then we derive a probability distribution for an anomaly measure defined for a time-series of directional data derived from the graph sequence. Given a critical probability, the threshold value is adaptively updated using a novel online algorithm.
We demonstrate that a fault in a Web application can be automatically detected and the faulty services are identi-fied without using detailed knowledge of the behavior of the system.
 I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database applications -Data Mining; K.6.4 [ Management of Computing and Information Sys-tems ]: System Management Algorithms, Management  X  The authors address: 1623-14, Shimotsuruma, Yamato, Kanagawa 242-8502, Japan.
 Copyright 2004 ACM 1-58113-888-1/04/0008 ... $ 5.00. time sequence of graphs, principal eigenvector, Perron-Frobenius theorem, von Mises-Fisher distribution, singular value de-composition
Network systems having various connections and corre-lations between vertices have attracted much attention in several research fields such as ecology, economics, and solid-state physics. In the data mining community, growing atten-tion is being paid to graphs as a new data structure. Recent studies include: an extension of the a-priori algorithm to graphs [13], clustering graph vertices based on graph spec-tra [5, 4], and anomaly detection from a graph set based on the maximum description length principle [16]. Refer-ence [22] extensively reviews the state of the art of graph-based data mining. Most of those works today, however, assume that the attributes of graphs are static.

On an abstract level, computer systems are also repre-sented as graphs. What is profound here is that, first, it is possible to define various kinds of network structures. For example, one can consider several structures at each layer of the OSI (Open Systems Interconnection) reference model. Second, interactions between vertices or edge weights are not clearly defined at each layer.

In this paper, we address online anomaly detection for computer systems. We model a Web-based system as a weighted graph, where each node represents a  X  X ervice X  and each edge represents a dependency between services. Since edge weights may vary over time, the problem we address is that of anomaly detection from a time sequence of graphs, namely from a time-dependent adjacency matrix. The de-pendency matrix will exhibit some change when a monitored system experiences a fault. This change, however, will be difficult to detect by monitoring an individual dependency, i.e., each matrix element. This is especially true in Web-based systems, where the number of service calls fluctuates strongly over time. Even if a detector observes a sudden change in a single service, there is no evidence to conclude whether or not it is due to a fault. It may just be a fluctu-ation in traffic.

This is a new challenge for graph mining, where one needs to discover an unknown structure hidden deep inside of de-pendency graphs, and detect faults from their anomalous changes. In this paper, we discuss the dynamics of graphs in the context of data mining. We first extract a feature vector from an adjacency matrix that represents the activities of the services. The heart of our method is to use the principal eigenvector of the eigenclusters of the graph. To a time-series of directional data derived from the graph sequence, we next apply a pattern extraction technique based on a variational principle. Then we introduce a new online algo-rithm to update a probability distribution for an anomaly measure based on the von Mises-Fisher theory. Using this technique, anomalies can be detected by comparing with given critical probability that is independent of the details of the system.
The more the importance of information technology in society increases, the more serious the impact of major faults of computer systems becomes. In recent distributed complex systems, some autonomic system management model [6] is needed rather than the traditional model, where a human administrator constantly monitors the system. It is clear that, as the first step, one needs a tool to sense the whole system in a comprehensive manner and to detect any sign of faults in an automated manner. However, there is no practical method for this because of the intrinsic complexity of phenomena in computer networks.
 For instance, network node management systems (NN-MSs) today have poor fault detection capabilities although they can gather and visualize information distributed in the system, typically through the Simple Network Management Protocol (SNMP). In fact, because SNMP trap events are thrown too frequently in a default configuration and the in-dividual trap events are not necessarily related to actual faults, some administrators often neglect the trap events. As a result, monitoring a console by a human administrator is practically the only solution to detect the sign of faults.
These problems in existing NNMSs are summarized as follows: These problems are crucial, especially in high volume Web systems. For instance, consider a three-tier system including an HTTP (Hyper Text Transfer Protocol) server, a Web application server (WAS), and a database (DB) server. An appropriate description of the interaction between servers at the application layer is essential because the servers are connected at this layer as well as at the Transport layer. However, it is known to be difficult to monitor such higher-level correlations with the use of existing NNMSs.
To be more concrete, consider an anomalous situation in a doubly-redundant system with two HTTP servers and two WASs: The activity of one of the WASs suddenly decreases due to some external load. While this trouble clearly breaks the symmetry between the two WASs, there is no fault at layers below the TCP (transport layer protocol) layer and no change will be detected in response time at relatively low traffic levels. A heartbeat monitoring service may show that all of the processes work well. However, this situation is potentially dangerous because an increase in traffic may cause serious problems far before the traffic volume exceeds the rated capacity of the system.

Faults of this kind are difficult to find by monitoring in-dividual servers using the existing NNMSs. What we will propose in this paper is a novel method to detect such faults. To the best of the authors X  knowledge, this is the first re-port that succeeds in automated detection of faults at the application layer.

The rest of this paper is organized as follows: In the next section, we briefly refer to related work. In Section 3, we define the dependency matrix at the application layer and formally state the problem. In Section 4, we describe a new method of feature extraction and show that graph time sequences are reduced to time-series of directional data. In Section 5, we discuss probabilistic properties of the anomaly measure. In Section 6, we report on experimental results in a benchmark system. In the final section, we summarize the major results in this paper.
Most recent studies on graph mining address issues that are transplanted from traditional problems in data mining. Frequent pattern search [14, 10] and graph classification [12] are such examples. One of the properties that is inherent in graphs is the presence of graph spectra. References [5, 4] address the problem of graph partitioning. There are also studies that discuss time development of graphs for citation graphs [15] or for the World Wide Web [9], both of which employ the concept of graph spectra. In the field of image processing, incident matrices and their eigenvectors are used to characterize the time development of images [17]. While our approach has a part in common with the eigencluster concept in Ref. [17], we address the dynamics of graphs where edge weights are explicitly time-dependent, rather than gradual changes of incident matrices. To the best of the authors X  knowledge, there is little research that focuses on highly dynamic systems such as computer networks in the context of graph mining.

In a subsequent section, we will show that a sequence of dependency graphs at the application layer can be trans-formed into a sequence of directional data items (a time series of normalized vectors). For vector series without nor-malization, unsupervised anomaly detection techniques are extensively discussed in Refs. [24, 23] based on the normal mixture model (Note that traditional rule-based approaches are not appropriate in this case since the signs of faults are hidden deep inside the systems). However, the normal mix-tures are not appropriate to handle directional data. Refer-ence [1] employs a mixture of the von Mises-Fisher distribu-tion, and discusses the connection to the cosine measure. We also consider the von Mises-Fisher distribution. Our contri-bution is to derive a probability distribution of the anomaly measure itself and to give its online update procedure.
Recent studies on signal processing have demonstrated the utility of change-detection techniques to characterize anomalies of network traffic [2, 21]. However, most of those studies address highly aggregated data at the lower layers. We focus on the problem at the application layer in Web-based systems, where traditional autoregressive models with white noise are not appropriate because of the strong fluc-Figure 1: Configuration of benchmark system. IP addresses and port numbers are denoted by i k ( k = 1 , .., 4 ) and p j ( j = 1 , 2 , 3 ), respectively. tuation and the heavy tail nature of data. Reference [8] applied the approach of Refs. [24, 23] to a fault detection task in a local-area network. However, it only uses infor-mation from a single observation point, and considers only lower layer quantities. Reference [20] proposes an interesting method to correlate multiple observation points. However, it is based on the autoregressive model and its thresholding policy is not probabilistically consistent. Overall, our con-tribution is to discuss the problem of graph mining in terms of a vector space model, and to give a probabilistically con-sistent anomaly detection method.
As discussed, we focus on faults occurring in the applica-tion layer of Web-based systems. We define a service as a quartet of where I s and I d represent source and destination IP (In-ternet Protocol) addresses, respectively, and P denotes the port number of the destination application. We also use an attribute called the transaction type Q . Figure 1 illus-trates a benchmark system. There are four server boxes in this system, and two server processes with port numbers p 1 and p 2 are installed on each of the boxes at i 2 and i On each of the server processes, multiple applications can be running, and they are distinguished by the value of Q . For example, a service may be defined by ( i 1 , i 3 , p 1 i =192.168.0.19, i 2 =192.168.0.53, p =80, and q 1 = X  X rade X . This corresponds to a request to the HTTP server for a transaction type  X  X rade X . Figure 2 shows a subgraph of the dependency graph expected in the system depicted in Fig. 1. We drew links if I s = I d holds between two services, and ser-vices involving only q 1 and q 2 are shown there. The service type q 1 may be  X  X rade X , and q 2 may be a DB-related service. Generally, the dependency graph of a Web-based system is quite complicated even if the corresponding IP network is simple.

Consider a system with N different services. For the de-pendencies between services, it is natural to consider the quantity d i,j , the number of i  X  X  requests for j within a pre-determined time interval, as a measure of the dependency. Figure 2: A part of the dependency graph for the system in Fig. 1. Only services which have Q = q 1 or q 2 are shown. Graph edges are drawn if I s = I d holds between two vertices.
 Considering the bursty nature of Web traffic, it is reason-able to use its logarithmically transformed quantity,  X  d ln(1 + d i,j ). Since most transactions in Web-based systems are processed synchronously, a callee returns the control to-ken to its caller after processing a request. Thus, the sim-plest assumption is that the dependency of a service i on another service j is symmetric: where  X  i,j is Kroneker X  X  delta function and the  X  i s are con-stants introduced to stabilize the numerical calculations. By definition, D is a square non-negative matrix. Hereafter, we use a sans serif font to indicate matrices and use bold italic to indicate vectors. The norm of vectors is defined as the L -norm.

In principle, the quantity d i,j can be measured through server logs, typically using an API (application program in-terface) called ARM (application response measurement) [19]. In commercial systems, however, it is more practical to es-timate d i,j from some indirect information, since capturing server logs causes additional load. Recently, Gupta et al. [7] proposed an algorithm where d i,j is defined as the proba-bility that the duration of a transaction (an instance of a service i ) contains the duration of another transaction (an instance of a service j ). In such algorithms, D i,j  X  X  are not integer but real numbers including error. In this paper, how-ever, we do not discuss the details of such a method to eval-uate the dependency, and concentrate our attention on the online anomaly detection algorithm, given the dependency matrix.
We consider that the overall behavior of a computer sys-tem can be basically characterized by the dependency ma-trix D . Its dimension N and the definition of each element are assumed to be fixed, but the value of each matrix element strongly varies over time. Considering D as the adjacency matrix of a graph with a fixed structure, the problem we address is described as follows: Given a graph with time-dependent edge weights on a fixed structure, detect anoma-lies online and identify faulty vertices of the graph without using detailed knowledge on the system behavior.

The main considerations here are that, first, N is so large (on the order of 10 2 ) that monitoring each matrix element independently is not practical. Second, the behavior of each matrix element strongly fluctuates, and the fluctuation it-self does not necessarily indicate any anomalies. Anomalous situations are implied by phase transitions in the overall re-lation between the edge weights. Third, the rule to define the anomalies must be described without ad hoc knowledge specific to the system. Let us assume that the data for the dependency matrix D is sequentially obtained at each time t =1,2,... each a fixed interval, and that the dependency graph has a single connected component. We define the feature vector u of D as subject to  X  u T  X  u = 1, where T denotes transpose. Since D is a non-negative matrix, one can see that the maximum value is attained if the weight of u ( t ) is larger for services where D ij ( t ) is larger. If a service i actively calls other services, ( t ) has a large weight for the i -th element. Following this interpretation, we call this feature vector an activity vector .
By introducing a Lagrange multiplier  X  , Eq. (2) can be rewritten as so that While this equation holds for any of the eigenvectors of D ( t ), the feature vector corresponding to Eq. (2) is defined as the principal eigenvector (the eigenvector whose eigenvalue is the largest). Since Eq. (3) is homogeneous in  X  u , the follow-ing property holds for the activity vector:
Property 1. The direction of u is invariant with respect to the transformation D ( t )  X  k D ( t ) for any nonzero real number k .
 Thereby we can exclude overall traffic changes from analysis. It is the eigenvalue that is proportional to the global traffic volume. This is important to abstract a hidden structure from D .

To understand the meaning of u further, one can relate u with a stationary state of a discrete-time linear dynamical system whose equation of motion is given by where  X  denotes a virtual time being independent of the actual time t , and x is associated with u by u = x / || x Since D ( t ) is symmetric and of full-rank at least for  X  &gt; 0, all eigenvalues are real. Using the eigenvalues, x (0) can be expressed as a linear combination of the eigenvectors, so that x (  X  ) = lim where the eigenvalues and the normalized eigenvectors are and c i ( t ) X  X  are coefficients of the linear combination. Evi-dently, the term of the maximum eigenvalue becomes dom-inant as n  X  X  X  . Thus, we have Namely, the state vector approaches u after an infinite num-ber of transitions. For computer systems, the stationary state can be interpreted as the distribution of the probabil-ity amplitude that a service is holding the control token of the system at a virtual time point of  X  .
In real computer systems, the dependency graph is often disconnected. For such systems, a permutation matrix P exists such that where D 1 , D 2 , ... are square submatrices. To be concrete, consider the system shown in Fig. 3. Using the whole dependency matrix is decomposed into two square submatrices: Evidently, each submatrix corresponds to a connected sub-graph. Since the eigenvalue equation is invariant with re-spect to orthogonal transformations, the whole eigenvalue equation is written as where E ( n ) represents the n -dimensional identity matrix. Consequently, the solution of the whole system can be ob-tained as the union of the solutions of each connected com-ponent. This fact allows us to analyze each subgraph sepa-rately.

For each connected component, the Perron-Frobenius the-orem [3], which holds for non-negative irreducible matrices, guarantees a useful property of the activity vector:
Property 2. In each connected component, the principal eigenvector is positive, where an eigenvector is said to be positive if all the components of u or  X  u are positive and the corresponding eigenvalue is positive.
 This naturally supports the interpretation of the principal eigenvector as the activity vector, since the magnitude of the activities should be positive. For the principal (i.e. maxi-mum) eigenvalue, the following property holds:
Property 3. In each connected component, the principal eigenvalue is real 1 and has no degeneracy.
 From this, we understand that the activity vector is free from subtle problems due to level crossings of the eigenstates within a single connected component in the normal state of In this case, all of eigenvalues are real since Eq. (1) makes D real and symmetric. the system. If a level crossing easily occurs due to small fluctuations, the transition from one eigenstate to another eigenstate may be recognized as an outlier, resulting in a false alert.

For example, we show all of the eigenvectors in Table. 1 for the system shown in Fig. 3, setting a 13 , a 15 , a 36 , a to 4, 10, 3, 3, and 1, respectively. As shown, the principal eigenvectors, u 1 and u 3 , are positive, and the collections of nonzero elements correspond to the connected components, call the collections eigenclusters . An eigencluster is said to be principal if it has the largest principal eigenvalue.
The eigencluster concept provides us with a natural way to cluster services. When the set of all services is unknown, it is practically possible to find the activity vectors by choosing positive vectors from a set of eigenvectors [17]. Specifically, for the eigenvectors of the whole system, we understand the following fact:
Property 4. In disconnected systems where the princi-pal eigenvalue is not degenerate, the activity vector of the whole system is that of the principal eigencluster. We define the activity vector of the whole system by that of the principal cluster.
Although the Perron-Frobenius theorem guarantees that the principal eigenvalue is not degenerate within each single component, it says nothing about inter-component degener-acy. To explore the conditions of no degeneracy stated in Property 4, consider the following situation: A weak per-turbation F is applied to a system, and it couples an N 1 dimensional eigencluster D 1 with the other N 2 -dimensional eigencluster D 2 . Namely, at t and t + 1, the dependency matrices are given as Here F is an N 1  X  N 2 nonnegative matrix. Let  X  s 1 and  X  activity vectors of D 1 and D 1 , and let  X  1 and  X  2 be cor-responding eigenvalues, respectively. In the unperturbed system, N -dimensional vectors s 1 =(  X  s 1 , 0 ) T and s are eigenvectors with eigenvalues of  X  1 and  X  2 , respectively, where the 0 s are the zero vectors with appropriate dimen-sions. To find the activity vector of the perturbed system, let us limit ourselves to the space spanned by s 1 and s 2  X  be an eigenvector in this space. Since  X  u is mapped back onto the original space as K  X  u , where is the projection matrix, the eigenequation in the contracted space is expressed as Note that KK T = E (2) holds. Explicitly, the perturbed ma-trix is transformed into close to each other, any linear combination between s 1 and 2 can be an eigenvector. Thus, the activity vector of the whole system may make a transition from, e.g., s 1 to s 2 to a small perturbation. The activity vector is unstable in this case.

On the other hand, consider the case where  X  1  X   X  2 and  X  1  X  f holds. Solving the eigenvalue equation correspond-ing to Eq. (6), we have where we neglect higher order terms with respect to f/ X  1 and  X  2 / X  1 . The eigenvector corresponding to  X  + is given by Naturally, this is a positve vector. Equation (7) shows that the perturbation increased the difference of the two levels. The eigenvector of Eq. (8) indicates that s 1 is dominant in the whole activity vector as long as f is small. By defini-tion, f is small when the number of edges between the two subsystems is small and/or their edge weights are small. Fortunately, in Web-based systems, important services such as the HTTP server X  X  requests for a WAS are concentrated within the principal eigencluster, and therefore, the condi-tion of  X  1  X   X  2 , f is clearly satisfied. Hereafter, we will pay our attention only to the principal eigencluster which is stable against perturbations.
 Table 1: Eigenvectors and eigenvalues for the graph shown in Fig. 3. For parameters, see the text. 1 0.663 0.245 0. 0. 0.245 0.663 2 0. 0. 0.707  X  0.707 0. 0. 3 0.295  X  0.642 0. 0. 0.642  X  0.295 4 0. 0. 0.707 0.707 0. 0. 5 0.642 0.295 0. 0.  X  0.295  X  0.642 6 0.245  X  0.663 0. 0.  X  0.663 0.245  X  11.469 1.570 1.000  X  1.000  X  1.570  X  11.469
Our feature extraction technique provides a natural way to summarize the information contained in D . The eigen-cluster decomposition allows us to analyze each single eigen-cluster separately, and the activity vector extraction tech-nique allows us to further reduce the degrees of freedom. Thus, we expect that the degrees of freedom of each of sub-problems are still moderate even when the whole degrees of freedom are very large. In addition, the feature vector has a clear interpretation that is comprehensible to system admin-istrators. Understanding what is happening is as essential as detection itself in practical situations. These are advan-tages over naive approaches such as defining a feature vector simply by connecting all of the column vectors, where the scalability cannot be achieved and interpretation of results is often unclear.

For the numerical calculations, an extremely fast and sim-ple algorithm called the power method [18] is known to find the principal eigenvector. While the activity vector must be calculated online whenever D is updated in the given time interval  X  t , typically on the order of a few tens of seconds, our experience shows that the time to convergence is far less than  X  t even for N on the order of 10 3 .
Now we consider how to detect anomalous changes from ( t ) is normalized, this is a time sequence of directional data . The basic procedure is to extract a typical pattern from the past activity vectors, and to calculate the dissimilarity of the present activity vector from this typical one. We define a matrix U ( t ) by where W is a window size. Clearly, U ( t ) is an N  X  W matrix. It is natural to suppose that the typical pattern is a linear combination of the column vectors: where c is the normalization constant to satisfy r T r = 1. If the v i s are independent of i , r ( t ) is parallel to the mean vector. In order to further optimize the coefficients v T ( v 1 , v 2 , ..., v W ), we again consider the following extremum principle: subject to  X  v T  X  v = 1. This equation implies that the optimal v s are those that produce the strongest constructive inter-ference between u s. Notice that Eq. (9) can be expressed as Then the extremum equation reads where we set the Lagrange multiplier to be c 2  X  . Hence, we have an eigenequation While each eigenvector of U ( t ) T U ( t ) satisfies this equation, we define the typical pattern as the principal eigenvector. Using Eq. (12) and the normalization conditions, it is easy to show that Equations (11), (12), and (13) suggest that r ( t ) is the prin-cipal left singular vector of U ( t ), where a singular vector is said to be principal if it corresponds to the largest singu-lar value. Again, the power method [18] is a good way to perform the singular value decomposition (SVD). Figure 4: Summary of our anomaly detection pro-cedure.
To evaluate the dissimilarity, we introduce the quantity z ( t ), defined as The value of z ( t ) is unity if the present activity vector is orthogonal to the typical pattern at t  X  1, and zero if the present activity vector is identical to the typical pattern. In the present context, if z ( t ) is greater than a given threshold, we infer that an anomalous situation is occurring in the system. We summarize our anomaly detection procedure in Fig. 4.
 For directional data, the major distribution is the von Mises-Fisher (vMF) distribution [1], where || u || = 1. The angular variable  X   X  [0 ,  X  ] is defined as the arccosine of the inner product between u and a mean direction. Here, we take r ( t  X  1) as the mean direction at t : The value  X  &gt; 0 is a constant parameter called the angular variance. Intuitively, the vMF distribution describes fluctu-ations of u around the mean direction. The vMF distribu-tion is the most natural distribution for directional data in that it can be derived using the maximum entropy principle under a general condition. While Ref. [1] discusses the util-ity of a mixture model of the vMF distribution, the single vMF model is sufficient in the present application.
To derive the marginalized distribution with respect to  X  from Eq. (15), we perform a transformation of the vari-ables from u to angular variables {  X ,  X  2 , ...,  X  N  X  1 dimensional spherical coordinates. By using d where d N  X  1  X  is the area element on the unit sphere in an N -dimensional Euclidean space, the marginalized distribution for  X  is written as Since hold for |  X  |  X  1, we see that the distribution for z is given by where we used  X d X  = dz and reset  X  / 2 to be  X . We see that the distribution of z  X  [0 , 1] can be approximated by the  X  2 -distribution with N  X  1 degrees of freedom. Since the probability density function (pdf) of the  X  2 -distribution rapidly decreases as  X  2  X   X  for a moderate value of the degrees of freedom, the normalization constant can be eval-uated by integrating over [0 ,  X  ). Hence, q ( z ) = 1 where  X  represents the gamma function. In the above equa-tion, we replaced N with a real number n . As discussed in the next section, the actual degrees of freedom is consider-ably smaller than N . One reason is that some of services are inactive and have small activities in the activity vector, being almost independent of t . In the derivation of the vMF distribution, an implicit assumption is that all of the degrees of freedom are equally active. We regard n as a measure of the effective size of each eigencluster. We call n the effective dimension.
Using Eq. (16), the first and the second moments are cal-culated as These relations provide a way to evaluate n and  X  experi-mentally: The moments are easily calculated online. Using an identity and setting 1 /t as  X  , we have Similarly for the second moment, we have Naturally,  X  satisfies 0 &lt;  X  &lt; 1 and is called the discount-ing factor. Note that Eqs. (17)-(19) give an online version of maximum likelihood estimation algorithm for the vMF distribution in an approximated manner.

Since 1 / X  can be associated with the number of data points, a rough estimate of  X  may be  X   X   X  t/L , where L denotes the time scale we are interested in. Similarly, W can be estimated as W  X  L/  X  t . In our benchmark system, we empirically take L on the order of 10 minutes.
Based on the above discussion, we have an online algo-rithm to calculate a threshold value to judge whether it is anomalous or not: Table 2: Services appearing in the principal eigen-cluster 1. Give a critical boundary 0 &lt; p c &lt; 1. 2. Calculate  X  z  X  and  X  z 2  X  at t using Eqs. (18) and (19). 3. Calculate n  X  1 and  X  using Eq. (17). 4. Find z th numerically such that 5. Emit an alert if z ( t ) &gt; z th .
 The above algorithm includes three parameters, p c ,  X  , and W . Since  X  and W can be easily estimated with L and  X  t , the only parameter we must specify is substantially p which is totally independent of the details of the system.
The configuration of our benchmark system is illustrated in Fig. 1. As shown, the HTTP servers and WASs are dou-bly redundant. On the WASs, two applications,  X  X rade X  and  X  X lants X , are running. Trade is a standard benchmark application called Trade 3 [11], and Plants is a sample ap-plication bundled with IBM WebSphere Application Server V5.0 and simulates an online store dealing with plants and gardening tools. For both, the number of clients was fixed to be 16 and the think time was randomly chosen from 0 to 4 seconds.

We generated a matrix D every 20 seconds using a method that evaluates d i,j from captured IP packets. Loopback packets were ignored in the experiments, so that the services s x and s y in Fig. 2 are not observed for i 1 = 192 . 168 . 0 . 53 and i 2 = 192 . 168 . 0 . 54. The principal eigencluster is defined in Table 2, and small perturbations affecting it were ignored. In Table 2, the zeroth service was introduced to describe the situation where an optimal pair between callee and caller could not be identified. For example, services triggered by those outside the intranet will be associated with the zeroth service.

Apart from these, there are other service types,  X  X B2 X  and  X  X MS X , in Table 2. DB2 denotes a request for the DB server, and JMS is for communications related to the Java Messaging Service.
We calculated u and z online over a period when the sys-tem exhibited no failures. The dependency matrix was gen-erated over 52.7 minutes, so we had 158 matrices. The  X  i Figure 6: Statistics of z in the normal state. (a) Comparison of the experimental frequency and the  X  2 pdf. (b) The quantile-quantile plot. values were taken as small random numbers on the order of 0.01. To see the fluctuation in D , we show in Fig. 5 the time dependence of d 9 , 11 as an example. We see that there are approximately 500 calls within 20 seconds under these ex-perimental conditions and that the amplitude of fluctuation of d 9 , 11 is almost of the same order as the average. Hence, it makes little sense to place a threshold value on an isolated d
To experimentally validate the pdf of z , we plotted the frequency distribution of z in Fig. 6 (a), where the  X  2 pdf is also shown. The parameters of the  X  2 pdf were calcu-lated using all of the 158 data points with no discounting. The result was n = 4 . 62 and  X  = 6 . 79  X  10  X  5 . In spite of the limitation of the number of data points, the frequency distribution is a good fit to the  X  2 pdf. We also drew a quantile-quantile plot in Fig. 6 (b). As shown, the exper-imental data is well placed on the 45 degree line. These results clearly support our formulation in Sec. 5.2. 2
To demonstrate the anomaly detection capability, we in-duced an artificial change to the normal state data under the rule
We rounded the n  X  1 value to be 4 to fit the  X  2 pdf because of the limitation of the numerical library we used. This is the main reason the deviation of the  X  2 pdf from the experimental frequency. z Figure 7: Detection of an artificially applied change in D . for all i when t &gt; 39 . 0 [min]. The system has two paths to call the DB server. This rule indicates that one of them is artificially enhanced. The results for z are shown in Fig. 7 for  X  = 1 , 2, and 3, where the p c = 0 . 5% lines calculated using the n and  X  values above are also shown for reference. The corresponding z th value is 0.00093. To make them visible, the curves for  X  = 2 and 3 are shifted vertically. Since the fluctuation of the d i,j s is extremely large, the values of  X  = 2 and 3 are still reasonable values (Note that we did not directly modify D or  X  d i,j , but only d i,j ). Despite this fact, the figure shows that our method clearly detected the change.
Next, we performed a more realistic experiment: A bug in one of the applications ( X  X lants X ) only on 192.168.0.54 causes a malfunction of the service of 11 at a time point. The server process itself continues running, so the network communication is normal at the IP layer or below. Since two Web servers are working on the system, a client may feel no change in response time as long as the overall traffic is sufficiently small. Although this defect occurs within a single service, it can cause a massive change in D . In fact, the dependencies of the services directly related with the service 11 will be considerably changed. What we would like to detect is a transition of this kind.

Figure 8 shows the generated time-series of the activity vector. We see that a sudden change in activities is ob-served at t A and t B , which correspond to the malfunction of the service 11 and its recovery. From the figure, the activi-ties of the services 2, 6, and 11 are clearly decreased during this period. This result demonstrates that the service ac-tivity vector actually expresses the activity of services, and suggests a way to visualize the whole system.

To detect this fault automatically, we calculated z and its threshold value, following the algorithm explained in Sub-section 5.3. In Fig. 9, we depicted the z values with vertical bars and the threshold values with thick gray curves for W =5, 25, and 50. The discounting factor and the crit-ical boundary were taken as  X  = 0 . 005 and p c = 0 . 5%, respectively. While the result is considerably affected by the choice of W , we observe clear features at t =35.0 and 45.7 minutes, which correspond to t A &lt; t B in Fig. 8, re-spectively. These time points are highlighted with dashed vertical lines in Fig. 9. Note that the feature at t B (recov-index Figure 8: Time dependence of the activity vector. The failure duration starts at t A and ends at t B , as shown by arrows. The definition of the service indices are shown in Table 2 z z Figure 9: The dependence of z for W = (a) 5, (b) 25, and (c) 50. The 0.5% threshold is denoted by gray curves. Figure 10: Change ratio of the activity vector for W = 25 at a time point marked with a small triangle in Fig. 9 (b). ery from the malfunction) demonstrates the learnability for gradual changes of the environment. The dependence on W is an inevitable consequence of the choice of the appli-cations. Since the benchmark applications simulate human behavior, they must have a characteristic time scale. Com-paring Fig. 8 with Fig. 9, we conclude that an appropriate value of W is about 25 (8.3 minutes). We see that this value of W allows us to pinpoint the time points t A and t B .
The curves plotted with thin lines ( X  X ot SVD X ) in Fig. 9 represent the result using another pattern extraction method, where the v i s are set to be constant in Eq. (9). Specifically, we simply took the mean vector instead of r . The trend of z is similar to that of the SVD-based method, but is blurred out by the noise. This result demonstrates the effectiveness of the SVD-based pattern extraction technique.

To identify faulty services, we calculated the change rate of activities as compared to r for W = 25 at a time point with the peak of the feature around t A . The result is shown in Fig. 10. We recognize that the high z value is ascribed to the changes of services 6, 2, and 11. This result is under-stood as follows. Because of the sudden decrease of service 11, the activity of its caller 6 also decreases. Since loop-back packets are not observable, the change of the service 11 should affect the activity of service 2, which is a direct caller of the Plants service from 192.168.0.54 to 192.168.0.54 at P = 9081. Considering the consistency between IP ad-dresses, it is easy to perform an inference like this. The result in Figs. 8, 9, and 10 demonstrate the utility of our anomaly detection method.

For the limitations of our approach, first, the probabil-ity of false alarms will be finite even if W is set to be the optimal value. As understood from Fig. 9, there is small fi-nite probability of having outliers beyond a threshold value. Second, since the basic assumption of our approach is the stability of the direction of the activity vector, our approach is not appropriate for anomaly detection of rarely invoked services. Finally, there is much room for improvement in the calculations of the threshold values since the numerical library we used handles only integer degrees of freedom in the  X  2 pdf.
We have proposed a new approach to anomaly detection in computer systems. First, we discussed why the princi-pal eigenvector of the dependency matrix is a good feature vector which has a clear interpretation related to the activ-ities of services. Second, we described a method to extract a typical pattern from a time-sequence of the feature vec-tors, based on an extremum principle. We showed that the optimal choice of the typical pattern is the principal left singular vector of a matrix which contains activity vectors as column vectors. Third, we defined an anomaly measure z , and derived its probability distribution as an approxima-tion of the von Mises-Fisher distribution. Our theoretical analysis showed that z obeys the  X  2 distribution with n  X  1 degrees of freedom, where n is the effective size of the prin-cipal eigencluster. Based on this result, we derived an online algorithm to calculate threshold values of z . Only a value of the critical probability p c is needed to determine the thresh-old. Finally, we demonstrated that our method is capable of detecting a class of faults in a benchmark system.
We are grateful to T. Fukuda, J. Sakuma, A. Inokuchi, and H. Takeuchi for stimulating discussions. We also thank H. Etoh for assisting with the experiment and K. Yoda for help in implementing the anomaly detector. T.I. acknowl-edges fruitful discussions with K. Inoue. [1] A. Banerjee, I. Dhillon, J. Ghosh, and S. Sra. [2] P. Barford, J. Kline, D. Plonka, and A. Ron. A signal [3] A. Berman and R. J. Plemmons. Nonnegative [4] I. S. Dhillon. Co-clustering documents and words [5] C. H. Q. Ding, X. He, and H. Zha. A spectral method [6] A. G. Ganek and T. A. Corbi. The dawning of the [7] M. Gupta, A. Neogi, M. K. Agarwal, and G. Kar. [8] H. Hajji. Baselining network traffic and online faults [9] J. Hopcroft, O. Khan, B. Kulis, and B. Selman. [10] J. Huan, W. Wang, and J. Prins. Efficient mining of [11] IBM. Trade3; http://www-306.ibm.com/software/ [12] A. Inokuchi and H. Kashima. Mining significant pairs [13] A. Inokuchi, T. Washio, and H. Motoda. Complete [14] M. Kuramochi and G. Karypis. Discovering frequent [15] A. Y. Ng, A. X. Zheng, and M. I. Jordan. Link [16] C. Noble and D. Cook. Graph-based anomaly [17] S. Sarkar and K. Boyer. Quantitative measures for [18] G. Strang. Linear Algebra and its Applications . [19] The Open Group. Application response measurement [20] M. Thottan and C. Ji. Anomaly detection in IP [21] H. Wang, D. Zhang, and K. G.Shin. Detecting SYN [22] T. Washio and H. Motoda. State of the art of [23] K. Yamanishi and J. Takeuchi. A unifying framework [24] K. Yamanishi, J. Takeuchi, G. Williams, and P. Milne.
