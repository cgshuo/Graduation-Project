 The state-of-the-art in Named Entity Recognition relies on a com-bination of local features of the text and global knowledge to de-termine the types of the recognized entities. This is problematic in some cases, resulting in entities being classified as belonging to the wrong type . We show that using global information about the corpus improves the accuracy of type identification. We ex-plore the notion of a global domain frequency that relates relation-identifying terms with pairs of entity types which are used in that relation. We use this to identify entities whose types are not com-patible with the terms they co-occur in the text. Our results on a large corpus of social media content allows the identification of mistyped entities with 70% accuracy.
 I.2.7 [ Natural Language Processing ]: Text analysis Experimentation, Performance Named Entity Recognition (NER) is an important task for many Information Retrieval applications. One sub-task of particular im-portance is type identification : assigning meaningful types (e.g., Person, Organization, Location, etc.) to the extracted entities. The state-of-the-art NER systems rely on a mix of local information (statistics and results of lexical analysis) about small portions of the corpora and external knowledge (usually obtained through learn-ing on training data) to perform type identification. For example, LBJ [3] analyzes the corpus in fixed-sized text windows ignoring document boundaries and relies on two sources of external infor-mation: high-precision lists of named entities (gazetteers) and clus-ters of commonly used words in different contexts. While the use of external information has been shown to improve accuracy over purely local methods, they are limited to the knowledge contained in a small collection of documents or tokens for every entity type assignment decision they make. Inevitably, these methods eventu-ally assign incorrect types to the entities they extract. As an exam-ple, consider the snippet  X  X MISC Jewish] by birth, [ORG Alamo] married [PER Edith Opal] who was also [MISC Jewish] X  which is tagged with LBJ. As one can see, Alamo is correctly identified as an entity, but assigned type ORG (for Organization) instead of PER (for Person). As Alamo appears in LBJ X  X  gazetteers as an or-ganization, it is likely that this is the reason LBJ labeled Alamo incorrectly.

To overcome the limitation, we propose a scoring feature based on global information (extracted from the entire corpus) for im-proving the assignment accuracy of entity types. The feature is designed to be used as a supplement in different NER systems and other tasks. This work is motivated by our social network extractor system SONEX [2], that extracts latent social networks from so-cial media text (in [2] we report results on the ICWSM X 09 Spinn3r Blog dataset with 44 millions posts [1]). SONEX works by extract-ing named entities with LBJ, and individual sentences with Ling-Pipe 1 . Then it identifies relations that associate pairs of entities (e.g., Alamo and Edith Opal) by clustering those sentences using a variety of features. In the example above, SONEX identifies that Alamo and Edith are married to each other, and thus assigns this term to the pair. In this work, we show how to automatically use the results of this relation extraction in SONEX to identify entities which are incorrectly typed (Alamo in the example).
It is natural to expect that the relations extracted in SONEX are strongly correlated with a given context. For instance, marriage is a relation between Persons, and thus, belongs to the domain PER  X  PER . We exploit this observation to identify mistyped enti-ties. Starting from the social network extracted by SONEX, which we call the dataset in the sequel, we proceed as follows. For each relation-identifying term in the dataset (excluding stop words), we compute its relative frequency in every possible domain. We re-fer to the frequency of a term t in a given domain i as the term X  X  Domain Frequency (DF) score, and refer to it as df i ( t ) .
We normalize the domain frequency of every term across all do-mains associated with the term. More precisely, let t be a term and let i 1 , . . . , i n be all possible domains of pairs of entity types; let f ( t ) , . . . , f n ( t ) be the frequencies in which that term identifies a relation of a pair of entities in each of the domains. Then,
The number of possible domains is the square of the number of types the NER system identifies. LBJ offers the following types: PER (Person), ORG (Organization), LOC (Location), and MISC http://alias-i.com/lingpipe Table 1: Top-3 Domain Frequencies for  X  X arried X  in the Spinn3r social network extracted with SONEX. (miscellaneous) 2 . Table 1 shows the most significant relative DF scores for the term married across different domains. As expected, the DF score for the PER to PER domain is significantly larger than all other domains. If a term does not appear in a certain domain, its DF score for the domain is zero (e.g.,  X  X arried X  does not appear in the LOC to LOC domain, and hence, it does not appear in Table 1). The entire list of terms associated with their DF scores is available by request. This list can be used as an external knowledge source in different NER systems, in various dataset domains.
Our premise is that a pair of entities ( E 1 , E 2 ) from a given do-main d 1 = T 1  X  T 2 contains at least one mistyped entity if there is a relationship-identifying term t that connects them in the dataset, and the term X  X  domain frequency for d 1 is  X  X ignificantly X  lower than that of another different domain d 2 . Our hypothesis is that we can detect mistyped entities by comparing such domain frequen-cies. We validate it as follows.
 Setup. Since the ICWSM X 09 dataset does not include labels for named entities, we identify all type errors through manual evalua-tion. The complete evaluation we performed is available by request. We compute the list of terms in the dataset and their associated DF scores. Then, we obtain two random entity sets for our evalua-tion. The first, RANDOM contains 70 entity pairs (thus 140 typed entities) randomly chosen from the dataset. The second, SUSPI-CIOUS, consists of 326 entity pairs for which the gap in domain frequencies (highest to lowest) is higher a threshold.

More precisely, SUSPICIOUS is obtained as follows. For each term t in the dataset, we compute the difference between its high-est and the lowest DF scores. We keep those terms for which this difference is larger than 0.5 (empirically tested to produce high pre-cision with reasonable recall), resulting in 482 unique terms (i.e., relations). From these, we randomly chose 30 to obtain the entity pairs in our tests. For each term, we gathered up to 15 entity pairs, resulting in a total of 326 unique entity pairs (some terms were associated with less than 15 pairs), that generated 375 entities for the SUSPICIOUS evaluation (for most of the entity pairs, only one entity out of the two in a domain is identified as a mistake). Hypothesis. Our hypothesis is that pairs in the SUSPICIOUS set are more likely to contain at least one mistyped entity. This is justified by the following observation: out of the 375 entities, 269 (or 72%) are of type ORG, 83 (22%) are of type LOC, and 23 (6%) are of type PER. This distribution is very different than the one that takes into account all entities in the dataset: 12% for ORG, 43% for LOC, and 45% for PER. The type ORG, which appears in only 12% of all entities, appears in 72% of the entities in the SUSPICIOUS set, implying a higher error rate for organizations compared to other entity types.

Table 2 validates this hypothesis. In the table, precision is the number of entities with correct types (we did not consider the cor-
We do not consider the MISC type in our experiments. They are too generic, making it hard to evaluate whether the entities assigned to this type are misclassified by LBJ.
 Table 2: Correctness of the entity types in the 2 evaluation sets rectness of the entity boundary) divided by the total number of en-tities in each set. Weighted is the weighted average of the precision for the three types. Observe that in the RANDOM set entities are correctly typed 62% of the times, whereas in the SUSPICIOUS set this happens only 30% of the time. This 30% reflects the entities we incorrectly identified as mis-typed. Also, observe that LBJ is much more accurate in correctly identifying persons and locations compared to organizations.
 Method. The significant observation from our experiment is that the difference in domain frequency scores may be an effective way of identifying mis-typed entities. It effectively yields a very simple and automatic procedure for detecting incorrect type assignments which has 70% precision. Given the much lower rate mistyping rate of just 38% for the RANDOM set, these results are promising.
We proposed the use of Domain Frequency scores to predict en-tities which are erroneously typed by NER systems. This measure can be readily incorporated into existing NER systems with ease. DF exploits terms between pairs of entities to estimate the likeli-hood of a term to appear between given entity types. DF relies on global (corpus-wide) information as is thus sensitive to the domain at hand. We showed experimentally that the difference in DF scores for a given term serves as a good indicator that the entities associ-ated through that term are incorrectly typed, and that this simple rule was able to detect an entity with incorrect type in 70% of the cases, and that this rate is much higher than that of a random sample of the dataset.

We are investigating ways in which to use the DF scores to fur-ther improve not only entity type identification but also the extrac-tion of the relations among the entities. We envision a mutual re-finement scheme in which both tasks go hand-in-hand. This work was supported in part by the Natural Sciences and Engineering Research Council of Canada and the Alberta Ingenuity Fund. [1] K. Burton, A. Java, and I. Soboroff. The icwsm 2009 spinn3r [2] F. Mesquita, Y. Merhav, and D. Barbosa. Extracting [3] L. Ratinov and D. Roth. Design challenges and
