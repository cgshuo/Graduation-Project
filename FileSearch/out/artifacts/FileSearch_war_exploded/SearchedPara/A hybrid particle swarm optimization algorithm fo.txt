 1. Introduction
Several biological and natural processes have been influencing the methodologies in science and technology in an increasing manner in the past years. Nature inspired intelligence becomes increasingly popular through the development and utilization of intelligent paradigms in advanced information systems design.
The methods contribute to technological advances driven by concepts from nature/biology including advances in structural genomics, mapping of genes to proteins and proteins to genes, modeling of complete cell structures, functional genomics, self-organization of natural systems, etc. 1 Among the most popular nature inspired approaches, when the task is optimization within complex domains of data or information, are those methods representing successful animal and micro-organism team beha-viour, such as swarm or flocking intelligence (birds flocks or fish schools inspired particle swarm optimization Kennedy and
Eberhart, 1995; Kennedy et al., 2001 ), artificial immune systems (that mimic the biological one Dasgupta, 1998; De Castro and
Timmis, 2002 ), optimized performance of bees, or ant colonies (ants foraging behaviours gave rise to ant colony optimization Dorigo and Stutzle, 2004 ), etc. A number of nature inspired tools have been used to solve very diverse operations and supply chain management problems, like scheduling, organization of produc-tion and vehicle routing problems ( Rennard, 2006 ).

Particle swarm optimization (PSO) is a population-based swarm intelligence algorithm that was originally proposed by Kennedy and Eberhart (1995). PSO simulates the social behaviour of social organisms by using the physical movements of the individuals in the swarm. Its mechanism enhances and adapts to the global and local exploration. Most applications of PSO have concentrated on the optimization in continuous space while some work has been done to the discrete optimization ( Kennedy and Eberhart, 1997; Shi and Eberhart, 1998 ). Recent complete surveys for the particle swarm optimization can be found in Banks et al. (2007, 2008) and Poli et al. (2007) . The particle swarm optimization (PSO) is a very popular optimization method and its wide use, mainly during the last years, is due to the number of advantages that this method has, compared to other optimization methods. Some of the key advantages are that this method does not need the calculation of derivatives, that the knowledge of good solutions is retained by all particles and that particles in the swarm share information between them. PSO is less sensitive to the nature of the objective function, can be used for stochastic objective functions and can easily escape from local minima. Concerning its implementation, PSO can easily be programmed, has few parameters to regulate and the assessment of the optimum is independent of the initial solution.

As there are not any competitive nature inspired methods based to particle swarm optimization, at least to our knowledge, for the solution of the vehicle routing problem we would like to develop such an algorithm and to test its efficiency compared to other nature inspired and classic metaheuristic algorithms. Thus, in this paper, we demonstrate how a nature inspired intelligent technique, the particle swarm optimization (PSO) ( Kennedy and
Eberhart, 1995) and three metaheuristic techniques the multiple phase neighborhood search X  X reedy randomized adaptive search procedure (MPNS X  X RASP), the expanding neighborhood search (ENS) ( Marinakis et al., 2005a ) and the path relinking (PR) ( Glover et al., 2003 ) can be incorporated in a hybrid scheme, in order to give very good results in the vehicle routing problem (VRP).
Particle swarm optimization algorithms, due to their simplicity in coding and their global and local exploration abilities, are usually applied, with remarkable results, in continuous optimization problems. In this paper, we focused in the way a PSO algorithm can easily and efficiently be applied in a classic combinatorial optimization problem, like the vehicle routing problem. The main advantage of the application of a PSO algorithm in the VRP is that, in contrary to others metaheuristics, there are only two variables for each member of the population that will have to be calculated in each iteration, the position and the velocity. As we would like to increase more the efficiency of the particle swarm optimization we incorporated the three previously mentioned algorithms. More precisely:
In order to obtain more efficient initial solutions we applied the multiple phase neighborhood search X  X reedy randomized adaptive search procedure (MPNS X  X RASP) instead of a random creation of the initial population ( Marinakis et al., 2009 ).
In order to improve the solutions of each particle in the swarm and to reduce the computational time of the algorithm the expanding neighborhood search strategy ( Marinakis et al., 2005a, 2005b ) is utilized.

The path relinking strategy ( Glover et al., 2003 ) is used in order to give a more efficient way to move the particles either to their local optimum or to the global optimum of the whole swarm.

The rest of the paper is organized as follows: In the next section a description of the vehicle routing problem is presented. In the third section the proposed algorithm, the hybrid particle swarm optimization (HybPSO) is presented and analyzed in detail.
Computational results are presented and analyzed in the fourth section while in the last section conclusions and future research are given. 2. The vehicle routing problem
The vehicle routing problem (VRP) or the capacitated vehicle routing problem ( CVRP ) is often described as the problem in which vehicles based on a central depot are required to visit geographi-cally dispersed customers in order to fulfill known customer demands. Let G =( V , E ) be a graph where V  X f j 0 ; j 1 vertex set ( j i = j 0 refers to the depot and the customers are indexed j  X  j customer must be assigned to exactly one of the k vehicles and the total size of deliveries for customers assigned to each vehicle must not exceed the vehicle capacity ( Q k ). If the vehicles are homogeneous, the capacity for all vehicles is equal and denoted by Q . A demand q j l and a service time st j l are associated with each customer node j l . The travel cost between customers j of routes  X  one for each vehicle. A route is a sequence of locations that a vehicle must visit along with the indication of the service it provides. The vehicle must start and finish its tour at the depot. The most important variants of the vehicle routing problem can be found in the following: Bodin et al. (1983) , Golden and Assad (1988), Marinakis and Migdalas (2002) , and Toth and Vigo (2002) .

The vehicle routing problem was first introduced by Dantzig and Ramser (1959). As it is an NP-hard problem, the instances with a large number of customers cannot be solved in optimality within reasonable time. For this reason a large number of approximation techniques were proposed. These techniques are classified into two main categories: Classical heuristics that were developed mostly between 1960 and 1990 and metaheuristics that were developed in the last fifteen years. In the 1960s and 1970s the first attempts to solve the vehicle routing problem focused on route building, route improvement and two-phase heuristics. In the route building heuristics, the arcs are selected sequentially until a feasible solution has been created. Arcs are chosen based on some minimization cost criterion. In the route improvement heuristics, starting from one feasible solution, one more efficient solution is found by an interchange of a set of arcs. The most known of these algorithms is the Clarke and Wright method ( Bodin and Golden, 1981 ). The 2-opt, 3-opt and
Lin X  X ernigham heuristics are the most known heuristics that belong in the category of route improvement heuristics. In the two phase heuristics, known as cluster first and route second heuristics, the customers are first assigned in vehicles and then a route is constructed from every cluster, like Gillet X  X iller algo-rithm ( Bodin and Golden, 1981 ). In this category they, also, belong the methods called route first cluster second in which first a giant traveling salesman problem (TSP) tour is constructed and then this route is decomposed into feasible vehicle routes. In the 1980s a number of mathematical programming procedures are proposed for the solution of the problem. One of these procedures is the algorithm proposed by Fisher and Jaikumar (1981) .

In the 1990s, a number of algorithms, known as metaheur-istics, that simulate physical phenomena, were applied for the solution of the vehicle routing problem. Simulated annealing, genetic algorithms, neural nets, tabu search, ant algorithms, together with a number of hybrid techniques are the main categories of the metaheuristic procedures. These algorithms have the ability to find their way out of local optima. In simulated annealing, this is achieved by allowing the length of the tour even to increase with a certain probability. Gradually the probability allowing the objective function value to increase is lowered until no more transformations are possible ( Osman, 1993 ). Tabu search uses a different technique to get out of local optima. The algorithm keeps a list of forbidden transformations. In this way, it may be necessary to use a transformation that deteriorates the objective function value in the next step ( Gendreau et al., 1994;
Osman, 1993; Taillard, 1993; Toth and Vigo, 2003; Xu and Kelly, 1996). A neural network consists of a network of elementary nodes (neurons) that are linked through weighted connections.
The nodes represent computational units, which are capable of performing a simple computation, consisting of a summation of the weighted inputs. The result of the computation of a unit constitutes its output. This output is used as an input for the nodes to which it is linked through an ongoing connection. Very interesting and efficient algorithms based on the concept of adaptive memory, according to which a set of high quality VRP solutions (elite solutions) is stored and, then, replaced from better solutions through the solution process, have been proposed in Rochat and Taillard (1995), Tarantilis (2005) , and Tarantilis and Kiranoudis (2002) .

In the last 10 years, a number of nature inspired metaheuristic methods have been applied for the solution of the vehicle routing problem. The most common used nature inspired methods for the solution of this problem are genetic algorithms and ant colony optimization. Genetic algorithms mimic the evolution process in nature. Their basic operation is the mating of two tours in order to form a new tour. Moreover, they use algorithmic analogs to mutation and selection ( Baker and Ayechew, 2003; Berger and
Barkaoui, 2003; Marinakis et al., 2007; Prins, 2004 ). In the ant system artificial ants searching the solution space simulate real ants searching their environment, the objective values correspond to the quality of the food sources and an adaptive memory corresponds to the pheromone trails. In addition, the artificial ants are equipped with a local search function to guide their search through the set of feasible solutions ( Bullnheimer et al., 1999; Reimann et al., 2002, 2004 ). The reader can find more detailed descriptions of all the previously mentioned algorithms in the survey papers ( Bodin and Golden, 1981; Bodin et al., 1983; Fisher, 1995; Gendreau et al., 1997, 2002; Laporte et al., 2000; Laporte and Semet, 2002; Marinakis and Migdalas, 2002;
Tarantilis, 2005 ). 3. Hybrid particle swarm optimization for the vehicle routing problem 3.1. General description of hybrid particle swarm optimization (HybPSO)
The proposed algorithm for the solution of the vehicle routing problem, hybrid particle swarm optimization (HybPSO), combines a particle swarm optimization algorithm, the MPNS X  X RASP algorithm, the expanding neighborhood search strategy and a path relinking strategy. In this algorithm, the initial population of particles is calculated by using the MPNS X  X RASP algorithm (see
Section 3.2). One of the key issues in designing a successful PSO for vehicle routing problem is to find a suitable mapping between vehicle routing problem solutions and particles in PSO. Each particle is recorded via the path representation of the tour, that is, via the specific sequence of the nodes. The position of each individual (called particle) is represented by a d -dimensional vector in problem space s i  X  X  s i 1 ; s i 2 ; ... ; s id population size), and its performance is evaluated on the predefined fitness function. Concerning the fitness function, it should be noted that in VRP, the fitness of each particle is related to the route length of each circle and since the problem that we deal with is a minimization problem, if a feasible solution has a high objective function value then it is characterized as an unpromising solution candidate.

More precisely, initially all the solutions (particles) are represented with the path representation of the tour. For example if we have a particle with five nodes a possible path representa-tion is the following: 13524
As the calculation of the velocity of each particle is performed by the Eq. (1) (see below), the above mentioned representation should be transformed appropriately. We transform each element of the solution into a floating point interval [0,1], calculate the velocities of all particles and then convert back into the integer domain using relative position indexing ( Lichtblau, 2002 ). Thus, initially we divided each element of the solution by the vector X  X  largest element, and for the previous example the particle becomes: 0 : 20 : 610 : 40 : 8
The velocity of the i -th particle v i  X  X  v i 1 ; v i 2 ; ... ; v as the change of its position. The flying direction of each particle is the dynamical interaction of individual and social flying experience. The algorithm completes the optimization through following the personal best solution of each particle and the global best value of the whole swarm. Each particle adjusts its trajectory toward its own previous best position and the previous best position attained by any particle of the swarm, namely p and p g . The basic PSO and its variants have successfully operated for continuous optimization functions. In order to extend the application to discrete space, Kennedy and Eberhart (1997) proposed a discrete binary version of PSO. In our implementation instead of the formula proposed in Kennedy and Eberhart (1997) a path relinking strategy (see Section 3.4) is used. Path relinking is an intensification strategy that is used as a way of exploring trajectories between elite solutions. The velocities of the particles are updated using the following formula Kennedy and Eberhart (1995, 1997) and Shi and Eberhart (1998): v  X  t  X  1  X  X  wv i  X  t  X  X  c 1 rand 1  X  p i s i  X  t  X  X  X  c 2 rand 2  X  p where t is the iteration counter; c 1 and c 2 are the acceleration coefficients, rand 1, rand 2 are two random numbers in [0, 1]. The acceleration coefficients c 1 and c 2 control how far a particle will move in a single iteration. Low values allow particles to roam far from target regions before being tugged back, while high values result in abrupt movement towards, or past, target regions (Kennedy and Eberhart, 1995 ). Typically, these are both set equal to a value of 2.0, although assigning different values to c sometimes leads to improved performance. The proposed algo-rithm is established based on standard PSO, namely basic PSO with inertia weight developed by Shi and Eberhart (1998), where w is the inertia weight. The inertia weight controls the impact of previous histories of velocities on current velocity, which is often used as a parameter to control the trade-off between exploration and exploitation. The particle adjusts its trajectory based on information about its previous best performance and the best performance of its neighbors. The inertia weight w is also used to control the convergence behaviour of the PSO. In order to reduce this weight over the iterations, allowing the algorithm to exploit some specific areas, the inertia weight w is updated according to the following equation: where w max , w min are the maximum and minimum values that the inertia weight can take, and t is the current iteration (generation) of the algorithm while the t max is the maximum number of iterations (generations).

After the calculation of the velocities, the elements of the velocities X  vector are transformed back into the integer domain by assigning the smallest floating value to the smallest integer, the next highest floating value to the next integer and so on. Thus, if the velocities X  vector of a particle is 0 : 37 0 : 42 0 : 17 0 : 58 0 : 28 the backward transformation gives 34152
Afterwards, we use the path relinking strategy to calculate the new position of each particle. The expanding neighborhood search strategy is utilized in order to improve the solutions of each particle in the swarm (see Section 3.3) and to reduce the compu-tational time of the algorithm. In each iteration of the algorithm the optimal solution of the whole swarm and the optimal solution of each particle are kept. A pseudocode of the proposed hybrid particle swarm optimization algorithm is presented in Table 1 .

In the following sections, an analytical presentation of the main steps of the HybPSO is given. 3.2. Initial population
Instead of using a randomly generated initial population which may or may not necessarily contain good candidate solutions a modified version of the well known greedy randomized adaptive search procedure (grasp), the multiple phase neighborhood search X  X RASP (MPNS X  X RASP) is used to initialize the population. GRASP ( Feo and Resende, 1995; Marinakis et al., 2005a;
Resende and Ribeiro, 2003 ) is an iterative two phase search method which has gained considerable popularity in combinator-ial optimization. Each iteration consists of two phases, a construction phase and a local search procedure. In the construc-tion phase, a randomized greedy function is used to build up an initial solution. This randomized technique provides a feasible solution within each iteration. This solution is then exposed for improvement attempts in the local search phase. The final result is simply the best solution found over all iterations.
That is, in the first phase, a randomized greedy technique provides feasible solutions incorporating both greedy and random characteristics. This phase can be described as a process which stepwise adds one element at a time to a partial (incomplete) solution. The choice of the next element to be added is determined by ordering all elements in a candidate list with respect to a greedy function. The heuristic is adaptive because the benefits associated with every element are updated during each iteration of the construction phase to reflect the changes brought on by the selection of the previous element. The probabilistic component of a GRASP is characterized by randomly choosing one of the best candidates in the list but not necessarily the top candidate. The greedy algorithm is a simple, one pass, procedure for solving the vehicle routing problem. In the second phase, a local search is initialized from these points, and the final result is simply the best solution found over all searches.

In most GRASP implementations, some type of value based restricted candidate list (RCL) has been used. In such a scheme, a
RCL parameter determines the level of greediness or randomness in the construction. In MPNS X  X RASP, this parameter is not used and the best promising candidate edges are selected to create the
RCL. Subsequently, one of them is chosen randomly to be the next candidate for inclusion to the tour. This type of RCL is called a cardinality based RCL construction scheme . The restricted candidate list (RCL) of all the edges of a given graph G =( V , E ) is created by ordering all the edges from the smallest to the largest cost using a heap data structure. From this list, the first D edges are selected in order to form the final restricted candidate list. The candidate edge for inclusion in the tour is selected randomly from the RCL using a random number generator. Finally, the RCL is readjusted in every iteration by replacing the edge which has been included in the tour by another edge that does not belong to the RCL, namely the ( D + m )th edge where m is the number of the current iteration.

MPNS  X  GRASP introduces the flexibility of applying alternative greedy functions in each iteration instead of only one simple greedy function as in the classical approach. Moreover, a combination of greedy functions is also possible. The algorithm starts with one greedy function and if the results are not improving, an alternative greedy function is used instead. In these greedy functions, initially a traveling salesman problem is solved ( Marinakis et al., 2005a ), disregarding the side constraints (capacity constraints and maximum route duration constraints) of the vehicle routing problem. Subsequently, the solution of the TSP is converted to a solution of the VRP by adding the side constraints ( Bodin et al., 1983). More precisely, the first vehicle route begins from the node that corresponds to the depot and moves to the next node (customer) based on the solution of the
TSP, checking if the capacity of the vehicle or if the maximum route length of the vehicle are not violated. If any of these two constraints are violated, then the vehicle returns to the depot and a new route begins.

The utilization of a simple local search in the second phase of the classical algorithm limits the chances of obtained better solutions as the problem is NP-hard and more sophisticated local search algorithm are needed to improve a solution. Thus, MPNS X  GRASP uses instead the expanding neighborhood search (see
Section 3.3), which is a very flexible local search strategy. Almost all GRASP implementations use a termination criterion based on the maximum allowed number of iterations. Consequently, the algorithm wastes time in iterations that only add small, if any, improvements. MPNS X  X RASP, on the other hand, utilizes a termination criterion based on bounds obtained through Lagran-gean relaxation and subgradient optimization ( Marinakis et al., 2005b ). That is, first, a lower bound (LBD) is calculated and an upper bound (UBD) is estimated. Then, the parameter e  X  X  UBD LBD  X  = UBD % is computed and if its value is less than a threshold value, the algorithm stops with the current solution of
MPNS X  X RASP ( Marinakis et al., 2005b ). 3.3. Expanding neighborhood search (ENS) strategy 3.3.1. General description of ENS
Expanding neighborhood search (ENS) has been proven very efficient for the solution of the traveling salesman problem (Marinakis et al., 2005a ) and of the vehicle routing problem. ENS is based on a method called circle restricted local search moves and, in addition, it has a number of local search phases.

In the circle restricted local search moves  X  CRLSM strategy, the computational time is decreased significantly compared to other heuristic and metaheuristic algorithms because all the edges that are not going to improve the solution are excluded from the search procedure. This happens by restricting the search into circles around the candidate for deletion edges.

In the following, a description of the circle restricted local search moves strategy for a 2-opt trial move is presented. In this case, there are three possibilities based on the costs of the candidates for deletion and inclusion edges:
If both new edges increase in cost, a 2-opt trial move cannot reduce the cost of the tour (e.g., in Fig. 1 , for both new edges the costs C 2 and C 4 are greater than the costs B 2 and A of both old edges).

If one of the two new edges has cost greater than the sum of the costs of the two old edges, a 2-opt trial move, again, cannot reduce the cost of the tour (e.g. in Fig. 1 , the cost of the new edge C 3 is greater than the sum of the costs A + B 3 of the old edges).

The only case for which a 2-opt trial move can reduce the cost of the tour is when at least one new edge has cost less than the cost of one of the two old edges (e.g., in Fig. 1 , the cost C 1 of the new edge is less than the cost of the old edge A ) and the other edge has cost less than the sum of the costs of the two old edges (e.g., C 5 o A  X  B 1in Fig. 1 ).

Taking these observations into account, the circle restricted local search moves strategy restricts the search to edges where one of their end-nodes is inside a circle with radius length at most equal to the sum of the costs (lengths) of the two candidates for deletion edges.

The algorithm has the ability to change between different local search strategies. The idea of using a larger neighborhood to escape from a local minimum to a better one, had been proposed initially by Garfinkel and Nemhauser (1972) and recently by
Hansen and Mladenovic (2001) . Garfinkel and Nemhauser proposed a very simple way to use a larger neighborhood. In general, if with the use of one neighborhood a local optimum was found, then a larger neighborhood is used in an attempt to escape from the local optimum. On the other hand, Hansen and
Mladenovic proposed a more systematical method to change between different neighborhoods, called variable neighborhood search.

On the other hand, the expanding neighborhood search method starts with one prespecified length of the radius of the circle of the CRLSM strategy. Inside this circle a number of different local search strategies are applied until all the possible trial moves have been explored and the solution cannot further be improved in this neighborhood. Subsequently, the length of the radius of the circle is increased and, again, the same procedure is repeated until the stopping criterion is activated.

The idea of searching inside a radius of the circle of the neighborhood search, the circle restricted local search moves strategy, is the most innovative feature of the ENS strategy. In expanding neighborhood search strategy, another innovative feature is the fact that the size of the neighborhood is expanded in each external iteration. Each different length of the neighbor-hood constitutes an external iteration. Initially, the size of the neighborhood, s , is defined based on the circle restricted local search moves strategy, for example s = A /2, where A is the cost (length) of one of the candidates for deletion edges. For the selected size of the neighborhood, a number of different local search strategies are applied until all the possible trial moves have been explored and the solution can not further be improved in this neighborhood. The local search strategies are changed based on two conditions, first if the current local search strategy finds a local optimum and second if the quality of the current solution remains greater than the threshold number b 1 for a number of internal iterations. Subsequently, the quality of the current solution is compared with the current Lagrangian lower bound. If the quality of the solution is less than the threshold number e the algorithm stops, otherwise the neighborhood is expanded by increasing the length of the radius of the CRLSM strategy s by a percentage y (e.g. y  X  10 % ), the Lagrangian lower bound is updated and the algorithm continues. When the length of the radius of the CRLSM strategy is equal to A , the length continues to increase until the length becomes equal to A + B , where B is the length of the other candidate for deletion edge. If the length of the radius of the CRLSM strategy is equal to A + B , and no stopping criterion has been, already, activated, then the algorithm terminates with the current solution. In Fig. 2 , the expanding neighborhood search strategy is presented. A feature that has to be mentioned is that with this method if two routes are in opposite directions around the depot there is no possibility to be checked for a possible exchange between them in order to have an improvement in the cost, because the search for better solutions is restricted in neighborhood routes.

The local search strategies in the expanding neighborhood search for the vehicle routing problem are distinguished between local search strategies for a single route and local search strategies for multiple routes. The local search strategies that are chosen and belong to the category of the single route interchange are the well known methods for the TSP, the 2-opt and the 3-opt ( Lin, 1965). In the single route interchange all the routes have been created in the initial phase of the algorithm. The local search strategies for single route interchange try to improve the routing decisions.
The local search strategies for multiple route interchange try to improve the assignment decisions. This, of course, increases the complexity of the algorithms but gives the possibility to improve even more the solution. The multiple route interchange local search strategies that are used are the 1 X 0 relocate, 2 X 0 relocate, 1 X 1 exchange, 2 X 2 exchange and crossing ( Gendreau et al., 1997 ). 3.4. Path relinking
This approach generates new solutions by exploring trajec-tories that connect high-quality solutions  X  by starting from one of these solutions, called the starting solution and generating a path in the neighborhood space that leads towards the other solution, called the target solution (Glover et al., 2003 ). The roles of starting and target solutions can be interchangeable. In the first one, the worst among the two solutions plays the role of the starting solution and the other plays the role of the target solution. In the second one, the roles are changing. There is the possibility the two paths to simultaneously explored. A particle in particle swarm optimization can either follow its own way, or go back to its previous optimal solution, or go towards to the global optimal solution (to the best particle in the swarm). Thus, in the
HybPSO when the particle decides to follow either the path to its previous optimal solution or the path to the global optimal solution, a path relinking strategy is applied where the current solution plays the role of the starting solution and the best particle of the swarm or the current best solution of the particle plays the role of the target solution. The trajectories between the two solutions are explored by simple swapping of two nodes of the starting solution until the starting solution becomes equal to the target solution. If in some step of the Path Relinking strategy a new best solution, either of the particle or of the whole swarm, is found then the current best (particle or swarm) solution is replaced with the new one and the algorithm continues. 4. Computational results for the vehicle routing problem
The whole algorithmic approach was implemented in Fortran 90 and was compiled using the Lahey f95 compiler on a Centrino Mobile Intel Pentium M 750 at 1.86GHz, running Suse Linux 9.1.
The parameters of the proposed algorithm are selected after thorough testing. A number of different alternative values were tested and the ones selected are those that gave the best computational results concerning both the quality of the solution and the computational time needed to achieve this solution. Thus, the selected parameters are given in Table 2 .

The algorithms were tested on a set of benchmark problems, the 14 benchmark problems proposed by Christofides et al. (1979). Each instance of the set contains between 51 and 200 nodes including the depot. The location of the nodes is defined by their Cartesian co-ordinates and the travel cost from node i to j is assumed to be the respective Euclidean distance. Each problem includes capacity constraints while the problems 6 X 10, 13 and 14 have, also, maximum route length restrictions and non-zero service times. For the first 10 problems, nodes are randomly located over a square, while for the remaining ones, nodes are distributed in clusters and the depot is not centered.
The efficiency of the HybPSO algorithm is measured by the quality of the produced solutions. The quality is given in terms of the relative deviation from the best known solution, that is  X  X  c HybPSO c opt  X  = c opt % , where c HybPSO denotes the cost of the solution found by HybPSO and c opt is the cost of the best known solution. It can be seen from Table 3 , that the HybPSO algorithm, in half of the instances proposed by Christofides has reached the best known solution. For the rest instances proposed by Christofides the quality of the solutions is between 0.02% and 0.29% with average quality 0.084%. Also, in this Table the computational time needed (in minutes) for finding the best solution by HybPSO is presented. The CPU time needed is significantly low and only for one instance (instance 10) is somehow increased but still is very efficient. These results denote the efficiency of the proposed algorithm.

In order to give the significance of each of the characteristics (metaheuristics used) of the HybPSO, we implement a number of different versions of a particle swarm optimization algorithm for VRP. In these implementations the basic characteristics of the
HybPSO are not included in order to prove the contribution of each of the characteristics of the proposed algorithm. More precisely, initially a particle swarm optimization algorithm is tested without the MPNS X  X RASP, the expanding neighborhood search strategy and the path relinking strategy (columns 2 and 3 of Table 4 ), afterwards the MPNS X  X RASP strategy (columns 4 and 5of Table 4 ), and the ENS strategy (columns 6 and 7 of Table 4 ) are added , finally in the last two columns of the Table the results of the HybPSO are presented since the path relinking strategy is added. In the implementations where the path relinking strategy is not included the equation proposed by Kennedy and Eberhart (1997) is used in order the particle to decide if it will follows its own way or go back to its previous optimal solution, or go towards to the global optimal solution (to the best particle in the swarm). In all implementations, the parameters were set equal to the parameters of HybPSO and the local search strategies were the same as in HybPSO. In Table 4 and Fig. 3 the cost and the computational time of all implementations are presented. From this Table and this figure it can be observed that the use of each of the characteristics in the HybPSO improves significantly either the quality of the solution or the computational time or both of them.
More precisely, the addition of the MPNS X  X RASP in the initial PSO algorithm gave much better results regarding the quality of the solution but the computational time was not improved at all. The computational time was improved significantly with the addition of the expanding neighborhood search strategy, but the results were almost the same as in the previous case. The significant improvement in the quality of the solutions was achieved with the addition of the path relinking strategy. The reason is that, now, the particles moved in more fast and efficient way to their local optimum or to the global optimum solution (to the best particle in the swarm). It can, also, be observed that in some instances namely for instances 1 and 6, all four implementations found the same solutions but the significant difference is the time that they needed to find this solution. More precisely, while in the first implementation the computational time to find the optimum is equal to 1.07min and in the second implementation is equal to 1.05min, the addition of the ENS reduce the computational time (third implementation) to 0.08min and the addition of the path relinking (HybPSO) algorithm reduced even more the computational time to find the optimum to 0.05min.

The results obtained by the proposed algorithm are also compared to the results of the most efficient algorithms that have ever been presented for the vehicle routing problem. The VRP belongs to the class of NP-hard optimization problems. This means that no polynomial time algorithm is known for its solution.
Algorithms for solving the VRP may be divided in two classes, the exact algorithms and the approximation algorithms. The approx-imation algorithms for the VRP are classified into two main categories, heuristics and metaheu ristics algorithms. From these two categories, the most known an d the most efficient were chosen for the comparisons. The most class ical heuristics algorithms are not competitive with the metaheuristic algorithms but they are included in the comparisons for reasons of completeness.

The heuristic algorithms that are used in the comparisons with the proposed algorithm are the Clarke and Wright (1964) algorithm, the 1-petal and the 2-petal algorithms ( Foster and
Ryan, 1976), the Fisher and Jaikumar (1981) algorithm, the Wark and Holt (1994) algorithm, the B-SL Gavish algorithm ( Altinkemer and Gavish, 1991), the Christofides et al. (1979) algorithm, the
Desrochers and Verhoog (1989) algorithm , the sweep algorithm (Gillett and Miller, 1974 ) and, finally, the Mole and Jameson (1976) algorithm.

Metaheuristic algorithms are classified in categories based on the used strategy. In these comparis ons, algorithms that are based on
Neural Networks are not included, because their results are not competitive with the other metaheuristic algorithms. Tabu search strategy is the most widely used technique for this problem and a number of researchers have proposed very efficient variants of the standard Tabu Search algorithm (Taillard, TABUROUTE, Osman Tabu Search, Xu Kelly, Granular Tabu Search, UTSA, Barbarosoglu, PTC,
SEC). Very interesting and efficien t algorithms based on the concept of Adaptive Memory, according to which a set of high quality VRP solutions (elite solutions) is stored and, then, replaced from better solutions through the solution process, have been proposed (RT,
BoneRoute, SEPAS). Simulated annealing (Osman Simulated Anneal-ing) and threshold accepting algorithms (BATA, LBTA) are also applied efficiently in the VRP. Ant colony optimization for VRP have been proved to be very efficient and competitive with the other metaheuristics (RSD, D-Ants, BHS) just as genetic algorithms (Prins,
BAGA, HGA). In Table 5 , the ranking of all algorithms used for the comparisons and of the proposed algorithm is presented. The average quality of the solutions of all instances obtained by the HybPSO algorithm for the set of classic benchmark instances of
Christofides is equal to 0.084%. The proposed algorithm is ranked among 39 algorithms in the fifth place. Table 6 presents only the ranking of the Nature Inspired methods used for the solution of the vehicle routing problem. From this Table it can be seen that the proposed nature inspired method (HybPSO) is ranked in the first place among all algorithms of this kind.

Although a fair comparison in terms of computational efficiency is difficult as the computational sp eed is affected, mainly, from the compiler and the hardware that are used, in Table 7 the average CPU time (in minutes) of the metaheuristic algorithms of the previous comparisons is presented. It can be observed from this Table that
HybPSO is ranked in the second place among all metaheuristic algorithms. 5. Conclusions and future work
In this paper, a nature inspired approach was introduced for the effective handling of network analysis and optimization of logistics management problems. Specifically, a hybrid algorithmic nature inspired methodology was proposed, namely the HybPSO algorithm, for the effective handling of the vehicle routing problem.

One of the main contributions of this paper is to show that the particle swarm optimization can be used in hybrid synthesis with other metaheuristics for the solution of the vehicle routing problem with remarkable results both to quality and computa-tional efficiency.A second contribution is the utilization of the MPNS X  X RASP procedure for the generation of the initial particles. One of the main problems that one has to deal with is how the particles will move from their current solution to the global optimum (optimal solution of the whole swarm) or to the local optimum (optimal solution of each particle). HybPSO uses the path relinking strategy instead of the classic way that usually the particles move from their current solution to the local optimum or to the global optimum. Finally, the expanding neighborhood search strategy is utilized in order to improve the solutions of each particle in the swarm and to reduce the computational time of the algorithm. The algorithm was applied in a set of benchmark instances and gave very satisfactory results. More specifically in the set with the classic benchmark instances, proposed by Christofides, the average quality is 0.084% and, thus, the algorithm is ranked in the fifth place among the thirty nine most known algorithms and in the first place among the nature inspired methods used for the solution of the VRP in the literature. In the future we will apply this algorithm in other variants of the classic vehicle routing problem, like the open vehicle routing problem, the vehicle routing problem with time windows and the stochastic vehicle routing problem.
 References
