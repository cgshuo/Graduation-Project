 In any competitive business, success is based on the abili-ty to make an item more appealing to customers than the competition. A number of questions arise in the context of this task: how do we formalize and quantify the competi-tiveness relationship between two items? Who are the true competitors of a given item? What are the features of an item that most affect its competitiveness? Despite the im-pact and relevance of this problem to many domains, only a limited amount of work has been devoted toward an effec-tive solution. In this paper, we present a formal definition of the competitiveness between two items. We present efficien-t methods for evaluating competitiveness in large datasets and address the natural problem of finding the top-k com-petitors of a given item. Our methodology is evaluated a-gainst strong baselines via a user study and experiments on multiple datasets from different domains.
 H.2.8 [ Database Management ]: Database application-s X  Data Mining ; H.4.m [ Information Systems Applica-tions ]: Miscellaneous competitor mining, competitors, domain-invariant
Competitiveness is a challenge that every product or ser-vice provider has to face, regardless of the application do-main. A significant amount of relevant work has demon-strated the strategic importance of identifying and moni-toring an entity X  X  competitors [19]. In fact, a long line of research from the marketing and management community has been devoted to empirical managerial methods for com-petitor identification [8, 7, 10, 3, 18], as well as to methods for analyzing competitors [5], defending against competitive incursions, and devising appropriate response strategies [11, 6]. Our own work focuses on competitor identification, a key step for any competitiveness-driven study or application. Contrary to the significant amount of available work by the marketing community, the problem has been largely over-looked by computer scientists. For the latter, the challenge is to propose formalizations and competitor-identification al-gorithms that can utilize the vast amounts of rich data that is nowadays available on the web and other digital sources. Some progress toward this direction has been made by the information systems community [14, 15, 13, 1, 16, 27]. While the proposed approaches help motivate the problem, they present significant shortcomings. These include the lack of a formal definition of competitiveness, as well as the exis-tence of assumptions that limit the applicability of these ap-proaches. Specifically, these techniques are based on mining comparative expressions (e.g.  X  X tem A is better than Item B X ) from the web or other textual sources. Even though such expressions can be indicators of competitiveness, they are absent in many domains. For example, consider the domain of vacation packages (e.g flight-hotel-car combinations). In this case, the items have no assigned name by which they can be queried or compared with each other. Further, the frequency of textual comparative evidence can vary greatly across domains. For example, when comparing brand names from the domain of technology (e.g.  X  X oogle Vs Yahoo X  or  X  X ony Vs Panasonic X ), it is indeed likely that comparative patterns can be found by simply querying the web. However, it is trivial to consider other mainstream domains where such findings are extremely scarce, if not non-existent(e.g. shoes, jewelery, hotels, restaurants, furniture). Finally, even in do-mains where such approaches are applicable, they cannot actually evaluate the competitiveness relationship between any two items. Instead, they can only identify a subset of the competitors, based on the available evidence. Our own work overcomes these drawbacks, by providing a formal def-inition of competitiveness that is applicable across domains. On a high-level, the fundamental problem we address in our work is the following: Problem 1. We are given a set of items I , defined within the feature space F of a particular domain. Then, given any pair of items I, I  X  from I we want to define a function C
F ( I, I  X  ) that computes the competitiveness between the two in the context of the domain.

As mentioned in the statement of the problem, our no-tion of competitiveness is based on the feature-space F of the corresponding domain. Our competitiveness paradigm is based on the following observation: the competitiveness between two items is based on whether they compete for the attention and business of the same group of users (i.e. the s ame market share), and to what extent . For example, two restaurants that exist in different countries are obviously not competitive to each other, since there is no overlap between their target groups. In the ideal scenario, we would have access to the complete set of users that could be interested in a given item. Then, given any two items, we could triv-ially compute their competitiveness based on the overlap of their respective sets. In practice, however, this is clearly not an option. Taking this into consideration, we formalize the competitiveness between two items based on their re-spective features . For example, if the considered items are MP3 Players, F could consist of the features price, sound quality, battery life, connectivity, capacity and design . Our motivation is that, regardless of the domain, users compare and evaluate items based on their features. Therefore, by at-taching our formalization to the feature space, we ensure the availability of a consistent and informative resource for com-petitiveness evaluation. We provide a (simplified) overview of our approach in Figure 1.
 Figure 1: A (simplified) example of our competitiveness p aradigm
The figure illustrates the competitiveness between three different items I 1 , I 2 and I 3 . Each item is mapped to the set of features that it can offer to the users. Three distinct features are considered in this example: A, B and C . Note that, for this simple example, we only consider binary fea-tures (i.e. available/not available). Our actual formalization accounts for a much richer space of binary, categorical and numerical features. The left side of the figure shows three groups of users ( g 1 , g 2 , g 3 ). The example assumes that these are the only groups in existence. Users are grouped based on their preferences with respect to the features. For example, the users in group g 2 are only interested in features A and B . As can be seen by the figure, items I 1 and I 3 are not competitive to each other, since they simply do not appeal to the same groups of users. On the other hand, I 2 is in com-petition with both I 1 (for groups g 1 and g 2 ) and I 3 (for g Finally, another interesting observation is that I 2 competes with I 1 for a total of 4 users, and with I 3 for a total of 9 user-s. In other words, I 3 is a stronger competitor for I 2 , since it claims a much larger portion of I 2  X  X  market-share than I In our work, we propose ways to deduce these user-groups from sources such as query logs and customer reviews, and describe methods to estimate the size of the market share that they represent. Our work is the first to utilize the opin-ions expressed in customer reviews as a resource for mining competitiveness.

The formal definition of the competitiveness C F ( I i , I tween two items I i and I j , in the context of their domain X  X  feature-space F , is the first contribution of our work. As we demonstrate in our experiments, the evaluation of com-petitiveness can be a major computational challenge when dealing with real datasets of hundreds or even thousands of items. Motivated by this, we propose an algorithm for the natural problem of finding the top-k competitors of a given item. The proposed framework is geared toward scalability and efficiency, which makes it applicable to domains with large populations of items.
 Roadmap In Section 2 we introduce our competitiveness paradigm. In Sections 3 and 4 we present an efficient framework for finding the top-k competitors of a given item. The experimental evaluation of our work is presented in Section 5. In Section 6 we discuss previous related work. Finally, we conclude the paper in Section 7.
In this section, we describe how we can formalize and measure the competitiveness between any two items within a given domain. This formalization serves as the building block of our framework. Note that our definition can be easily extended to handle more than two items at a time.
In order to synthesize a competitor-mining method that works across domains, we need a formalization of compet-itiveness that is both accurate and flexible. Motivated by this, we build upon a crucial factor that remains consistent across domains: user preferences . In every market, the ulti-mate goal is to convert users into customers by meeting their individual requirements. Consider a single user u , interested in a specific domain (e.g. restaurants). While the domain may contain numerous items, the user will ultimately choose only one to spend his money on. In a typical scenario, the user follows the following steps: 1. Encode requirements and preferences in a query. 2. Submit the query to a search engine and retrieve the 3. Process matching items and make the final choice. We observe that the items that do not match the user X  X  crite-ria are never considered. In other words, they never get the chance to compete for his attention. As far this single user is concerned, the set of competitors consists of the matching items retrieved by the search engine. Consider the following motivating example: Example: A user is trying to pick a restaurant for din-ner. He has a very limited budget and is only interest-ed in Italian restaurants in the Boston Area. Only the restaurants that satisfy these criteria will compete for the user X  X  attention. On the other hand, Chinese restaurants, restaurants from New York, and expensive establishments are not truly competitors with respect to this particular user, since they are outside the boundaries of his personal requirements and thus never had a chance to be chosen. In this example, the user is interested in the features { price range, location, food type } . The respective values that en-code the user X  X  requirements are { Cheap, Boston, Italian } . Clearly, any other assignment of values could be specified for t he same query (e.g. { Cheap, Chicago, Chinese } ). In fact, each possible value-assignment represents the preferences of a different user. Formally, given a subset of features F  X  V
F  X  be the complete space of all possible value assignments over the features in F  X  . We observe that every item cover-s a portion of the entire space V F  X  , and, hence, covers the corresponding population of users. For example, a cheap restaurant in Boston that serves both Italian and American food covers a user who is interesting in cheap Italian food in Boston, as well as a user who is interested in cheap American food in the same city.
 In order to evaluate the competitiveness of two given items I , I j in the context of a subset of features F  X  , we need to compute the number of possible value assignments over F  X  that are satisfied by both items. Formally, we define pairwise coverage as follows: Definition 1. [Pairwise Coverage] Given the complete set of features F in a given domain of interest, let V F  X  complete space of all possible value-assignments over the fea-tures in a subset F  X   X  F . Then, the coverage cov ( V F  X  of a pair of items I i and I j with respect to V F  X  is defined as the portion of V F  X  that is covered by both items. Considering the above definition, we observe that the cov-erage of each dimension (i.e. each feature F  X  F  X  ) is in-dependent of the others. Therefore, we first compute the percentage of each dimension that is covered by the pair. We can then optimally compute the coverage of the entire space V F  X  as the product of the respective coverage values V { F } for every F  X  F  X  . Formally: This computation has a clear geometric interpretation: The portion of the space V F  X  that is covered by a pair of items can be represented as a hyper-rectangle in |F  X  | -dimensional space. For each dimension F , cov ( V { F } , I i , I j ) gives us the portion of the dimension that is covered by the two items. Finally, by multiplying the individual coverage values, we are essentially computing the volume of the hyper-rectangle that represents the entire space V F  X  .

Definition 1 allows us to evaluate the coverage provided by a pair of items to (the value space of) any subset of features F . Conceptually, F  X  captures the fraction of the population that is interested in the features included in F  X  . In practice, the size of the corresponding population varies across sub-sets. For example, in the domain of restaurants, the subset { food quality, price range } is arguably of interest to more users than the subset { Wi-Fi availability, delivery options } . To account for this in our definition of competitiveness, we attach a popularity weight w ( F  X  ) to each feature subset. We revisit the computation of these weights in Section 4, where we discuss practical methods for learning the weights from sources such as query logs and customer reviews . For the remaining of our analysis, we assume that the weights are provided as part of the input. Further, we define Q to be the collection of subsets with a non-zero weight. Formally: Q = {F  X   X  2 F : w ( F  X  ) &gt; 0 } . Taking the above into consid-eration, we formally define the competitiveness of two items I , I i as follows: Definition 2. [Competitiveness] Given the complete set of features F of a domain of interest, let Q be the set of all subsets of F that have a non-zero popularity weight. Then, the competitiveness of two given items I i and I i is defined as: both I i and I j .
Our definition of competitiveness between two given items is based on the pairwise coverage that they provide to the value space of the different subsets of features. We observe that the value space is complex, since it can contain differ-ent types of features. By supporting virtually every reason-able feature-type (numeric, ordinal, boolean, categorical), our framework guarantees the flexibility required to encode the requirements of virtually any potential customer. Next, we discuss the different types of features that we consider in our work, and show how coverage is defined for each of them.
 Categorical Features: In our work, we identify two sub-types of categorical features: single-value and multi-value. For a single-value feature F , each item assumes exactly one value from the respective value-space V { F } , e.g. the brand of a digital camera. Clearly, boolean features are simply a special case of this group, assuming values from { YES, NO } . The pairwise coverage of two items I i , I j , given a single-value feature F , is defined as follows:
For a multi-value feature F , each item can be mapped to any subset of values from the respective value-space V { F } Assume, for example, the feature parking from Table 1, re-ferring to the parking facilities of a restaurant. Since a restaurant can in fact provide any number of these options (even all of them), parking is a multi-value categorical fea-ture. We define the pairwise coverage of two items I i , I a multi-value feature F , as follows:
Conceptually, the covered portion is defined as the overlap between the sets of values that are mapped to each item, di-vided by the total number of possible values for F . Clearly, the dividend is always a value in [0 , 1]. [Ordinal Features]: The value space V { F } of an ordinal feature F assumes values from a finite ordered list: V { F } { v 1 , v 2 , v 3 , ... } . Depending on the nature of the feature, high-er or lower states may be preferable. For example, for the feature price range , lower values are preferable. On the other hand, for the feature stars rating , higher values are better.
First, let us introduce two functions that will aid us in our definition of coverage in the context of ordinal features. Given an ordinal feature F and two values v 1 , v 2  X  V { F } loser ( F, v 1 , v 2 ) return the least preferable between the two values. In addition, let weq ( F, v 1 ) return the set of values that are worse or equal to v 1 . For example, for the price range feature discussed above, weq ( F, $$$) = { $$$ , $$$$ } . Then, the pairwise coverage of two given items to the value space is defined as follows:
As in the case of categorical features, cov ( V { F } , I takes values in [0 , 1]. [Numeric Features]: A numeric feature F takes values from a continuous pre-defined range. Without loss of gener-ality, we assume that all numeric features are normalized to take values in [0 , 1]. Higher or lower values may be prefer-able, depending on the nature of the feature. As in the case of ordinal features, we define loser ( F, v 1 , v 2 ) to return the least preferable of two given values for a feature F . Then, given two items I i , I j , the pairwise coverage of the value space V { F } is defined as: Conceptually, the value space that is commonly covered by the two items is bounded by the one with the least preferable value. Consider the following example.
 Example: Consider the subset of features F  X  shown in Ta-ble 1. The respective representations for two items I i , I { $$$ , Boston , { Street, Valet } , 0 . 8 } and { $$ , Boston , { Street, Priv. Lot } , 0 . 6 } . Then, following Eq. 1, the pairwise coverage of the two items of is computed as follows: Table 1: Feature-subsets and their respective value-spaces.
I n the previous section we presented a formal definition of the competitiveness between any two items. Given this definition, we study the natural problem of finding the top-k competitors of a given item. Formally, the problem is defined as follows: Problem 2. We are given a set of items I , defined within the feature space F of a domain. Then, given a single item I  X  I , we want to identify the k items from I \ { I } , that maximize the pairwise competitiveness with I : A naive algorithm for this problem would iterate over all items in I  X   X  I\{ I } . For each such item I  X  , it would compute w ( F  X  )  X  cov ( V F  X  , I, I  X  ) for every subset F  X   X  Q , where Q is the collection subsets with a non-zero weight. It would then be trivial to obtain the top-k competitors for the given item. However, considering that I can contain thousands of items, the computational cost can be overwhelming. We demonstrate this in our experiments, where we compare our own CMiner technique with the naive approach.
Motivated by the inefficiency of the naive approach, we present CMiner, a new algorithm for Problem 2. Our ap-proach combines scalability with the ability to handle the online arrival of new items. The latter is crucial in many mainstream domains. As an example, consider the case when items are vacation packages. In such a domain, an arbitrary number of new packages can be introduced at any point in time. Hence, we would like to preprocess the data in a way that allows us to compute the competitors of a new package without having to repeat the entire computation effort.

First, we define the concept of item dominance , which will aid us in our further analysis: Definition 3. [Item Dominance]: Given two items I i , I j from a set I defined within a feature-space F , we say that an item I i dominates an item I j if both of the following conditions are true: 1. I j [ F ]  X  I i [ F ] , for every multi-value categorical feature 2. I i [ F ]  X  I j [ F ] , for every ordinal, numerical, or single-
Conceptually, an item dominates another if it has better values for all features of the considered space F . Clearly, if I dominates I j , then it is also more competitive with respect to any other item from I (since it covers at least as much coverage to any possible sub-space as I j ). This observation motivates us to utilize the skyline of the entire set of items I . The skyline is a well-studied concept that represents the subset of points in a set that are not dominated by any other point in the set [4]. We refer to the skyline of a set of items I as Sky ( I ). The concept of the skyline leads to the following lemma: Lemma 1. Given the skyline Sky ( I ) of a set of items I and an item I i  X  I , let Y contain the k items with the highest C (  X  , I i ) values from Sky ( I ) . Then, an item I j  X  I can only be in the top-k competitors of I i , if I j  X  Y or I j is dominated by one of the items in Y .

The proof is by contradiction, given the definition of item dominance and the skyline concept. We omit it for lack of space.

By applying Lemma 1, we do not need to consider the entire set of items in order to find the top-k competitors of a given item I  X  . Instead, it is sufficient to recursive-ly check for the items that are dominated by the current top-k items from the upper levels. In order to fully utilize this observation, we construct a structure that greatly re-duces the number of items that need to be considered for the computation of the top-k competitors set. We refer to this structure as the skyline pyramid . This structure is sim-ilar to the dominant graph , presented by Zou and Chen [29], except that it does not allow multiple parents for each item. The pyramid can be constructed by recursively computing the skyline and removing the skyline points from the current set, until the entire collection of items has been exhausted. Standard techniques can be used for computing the skyline on each iteration [17], as well as for updating the pyramid in case new items are introduced [12]. Each item from the i th layer of the skyline is assigned an inlink from the item from i t h level that dominates it. If multiple such domina-tors exist, we simply choose one randomly. This is simply done to avoid re-checking the dominated item during the competitor-finding process, and does not affect the optimal-ity of the result. A formal proof is trivial and omitted for lack of space.An example of the skyline pyramid is shown in Figure 2.
 Figure 2: T he left side of the figure shows the complete domi-The CMiner Algorithm : Next, we present CMiner, an optimal algorithm for finding the top-k competitors of any given item. Our algorithm makes use of the skyline pyramid described earlier in this section, in order to reduce the num-ber of items that need to be considered and minimize the number of required coverage computation. The intuition is that, since we only care about the top-k competitors, we can incrementally compute the score of each candidate and stop when it is guaranteed that the top-k have emerged. The pseudocode is given in Algorithm 1.
 Discussion of CMiner : The input to the algorithm in-cludes the set of items I , the set of features F , the item of interest I  X  , the number k of top competitors to retrieve, the collection Q of feature-subsets with non-zero weights, and the skyline pyramid D I .
 In lines 1-4, the algorithm uses masters ( I  X  ) to retrieve the set of items that dominate I  X  . Note that this set can be easily pre-computed for all the items during the pyramid-construction phase. These items are guaranteed to have the maximum possible competitiveness with I  X  . If at least k such items exist, we can just report them and conclude. Otherwise, we append them to the final result and decrement our budget of k accordingly. The LB variable maintains the lowest lower bound from the current top-k set. This is used as pruning threshold for the candidates. In lines 6-7 we initialize the upper and lower bounds for each candidate. In line 8 we initialize the set of candidates X as the union of the items in the first layer of the pyramid and the items dominated by those in the TopK . The latter is returned via calling getSlaves ( T opK, D I ).

In every iteration of lines 9-15, the algorithm does the fol-lowing: (i) it feeds the set of candidates X routine, which prunes items based on the LB threshold, (ii) updates the TopK set via the merge (  X  ) function, (iii) updates the prun-ing threshold LB , (iv) expands the set of items by including the items that they dominate.
 Discussion of UpdateTopK() : This routine processes the items in X and finds at most k with the highest competi-tiveness scores among X , subject to the condition that this score is higher than the global pruning threshold LB . The approach uses two bounds low and up , for every I  X  X . Algorithm 1 C Miner 10: X  X  updateTopK ( k, LB, X ) 12: T opK  X  merge ( T opK, X ) 14: LB  X  T opK [ k ] 16: return T opK low ( I ) maintains the competitiveness score of item I , as new feature subsets are considered. up ( I ) is an optimistic upper bound on I  X  X  competitiveness score. Therefore, up begins with the maximum possible competitiveness score, C ( I  X  , I  X  ).

For every feature subset, we examine all items in X and update their up value. If at any point up ( I ) &lt; LB (line 24), item I can be safely removed from the X . If, at any point, |X| becomes less or equal to k , the loop over the subsets comes to a halt. In lines 33-36 we update the lower bounds of the remaining items in X . We do this outside the loop, in order to avoid unnecessary bound checking and improve performance. Observe that the routine processes subsets in sorted order . In Section 4, we elaborate on the impact of the ordering on the performance of CMiner.
 Complexity: The complexity of CMiner depends on the number of points in each layer of D I . According to Bent-ley et al. [2], for n uniformly-distributed d-dimensional data Since we need to examine at most k skyline layers to find the top-k result, this value is upper-bounded by  X ( k  X  ln d  X  1 This bound naively assumes that each layer should be con-sidered entirely. In practice, however, we only need to check a small fraction of items that are dominated by the items c onsidered in the previous layer. For instance, for a uniform distribution with consecutive skyline layers of similar sizes, the number of points to be considered will be in the order of k , since links will be evenly distributed among the skyline points. As we only expand the top-k items in each step, at most k new items will be introduced. Therefore, for small values of k , the complexity of CMiner is O ( |I| * |Q| * k where Q is the set of feature subsets with non-zero weights.
Our analysis has assumed that the weight w ( F  X  ) of each subset of features F  X  is provided as input. In this section, we discuss methods for computing these weights.

The motivation of assigning a different weight to each sub-set stems from the observation that not all features are e-qually important to users. Based on this, a straightforward approach is to consider the weight of each individual feature separately, and then aggregate to the subset level. This ag-gregation could be achieved by selecting the sum, average, median, maximum or minimum over all the individual fea-tures in a set. This approach assumes independence among the features of an item. This assumption, however, is not always valid. For example, it may be the case that people who are interested in the screen resolution of a laptop com-puter are also more likely to be interested in the included graphics card. This motivates an approach that considers the popularity of feature-subsets instead of individual fea-tures. We identify two sources from which we can learn the popularity of a subset: query logs and customer reviews . Query logs: The first source is the query logs of the search engine on the website where the items are hosted. Re-gardless of the interface through which the user encodes his preferences in a query, the set of selected feature is always recorded in a dedicated log. Assuming the existence of a large enough user-base, we can simply estimate the popu-larity of a feature-subset based on the number of times that it was queried upon by the users.
 Customer reviews: In cases when query logs are unavail-able or inadequate, the weights of the subsets can be esti-mated by considering the reviews that are available for the items in the domain. As an example of such a dataset, con-sider the union of the review sets that are available for all the digital cameras offered on amazon.com. Each of these reviews comments on a particular subset of attributes from the digital-camera domain. Hence, the review corpus serves as an intuitive way to access user preferences. For example, a user who is greatly interested in the wheelchair-accessibility of a restaurant is more likely to discuss this feature in his re-view. We implement and employ review mining as a means for estimating the weights of feature-subsets in our exper-iments. In practice, one can choose to ignore subsets that appear less frequently than a set threshold. In our own ex-periments, we consider all subsets that appear at least once.
Given an item of interest I  X  , CMiner iterates over the giv-en set of subsets and computes the coverage provided by I and each candidate item to the value-space that corresponds to each subset. Given our definition of competitiveness, we next consider IC , an ordering scheme that processes subsets in descending order by w ( F  X  )  X  cov ( V  X  F  X  , I  X  , I the item of interest. As stated in the following lemma, IC achieves the optimal convergence rate (i.e. there exists no ordering that leads to a faster convergence).
 Lemma 2. [IC Convergence Rate]: Given two items I i , I j the ordering imposed by the IC scheme results in the fastest possible convergence to the target-value C F ( I i , I j ) (i.e. the true competitiveness between the two items)
Proof. Assume that we want to compute the competi-tiveness between the target item I  X  and a candidate I  X  . Let l and u i be the lower and upper competitiveness bounds, after checking F  X  i , the i -th feature subset imposed by the IC scheme. For ease of notation, we use C F  X  w ( F  X  i )  X  cov ( V F  X  new subset is considered, l i and u i are updated, until final-ly all the subsets have been evaluated and both variables converge to the actual competitiveness score C F ( I  X  , I now define T i = u i  X  l i . Since both l i and u i ultimately converge to C F ( I  X  , I  X  ), T i converges to 0. Also, T The convergence rate of T i is:
By immediate replacement in Eq. 8, the convergence rate becomes:
As it can be seen by Eq. 9, the convergence rate depends only on the score of the target item I  X  . The IC ordering scheme processes subsets in decreasing order of C F  X  which is the maximum possible coverage that any item can jointly achieve with I  X  . Thus, the numerator is equal to the i th maximum possible value among all feature-subsets. Similarly, the difference in the denominator is minimized, s-ince the subtracted sum maintains the highest possible value (and C F ( I  X  , I  X  ) is constant). F or our evaluation, we compiled the following datasets: Digital Cameras from Amazon.com : The features of this do-main include the objective attributes of each camera (e.g. price, number of megapixels ), as well as numeric attributes representing the opinions of the users on the item X  X  differ-ent characteristics (e.g. photo quality, video quality ). These were extracted via the method by Ding et al. [9], which as-signs a numeric opinion-value to each feature of an item, given the corpus of reviews. All scores were normalized to be in [0 , 1], with higher scores being preferable. The same method was also used for the datasets from Booking.com and TripAdvisor.com .
 Hotels from Booking.com : The feature-set for this domain consists of objective features (e.g. price, location ) and the opinion values extracted from the relevant reviews on differ-ent attributes (e.g. cleanliness, service quality ). Restaurants in New York from TripAdvisor.com : The feature-set for this domain consists of objective features (e.g. type of food served ) and the opinion values extracted from the relevant reviews on different attributes (e.g. food quali-ty,service quality ).
 Recipes from Sparkrecipes.com : The feature-set for each recipe consists of the different nutritional values (e.g. grams of protein and carbohydrates ), as listed on the website. The datasets were selected from different domains to por-tray the cross-domain applicability of our approach. Table 5 summarizes some basic statistics for each dataset.
The second, third, fourth and fifth columns include the n umber of items, the number of features, the number of distinct feature-subsets, and the number of layers in the re-spective (complete) skyline pyramid, respectively. The fea-ture subsets were extracted from the set of reviews that is available for each dataset; the frequency of each subset of features is equal to the number of times they were included together in a review. For all four datasets, nearly 99% of the items can be found within the first 4 layers of the pyramid, with the majority of those falling within the first 2 layer-s. This is due to the large dimensionality of the datasets, which makes domination unlikely. As we show in our evalu-ation, the skyline pyramid helps CMiner clearly outperform the baselines with respect to the computational cost. This is despite the high concentration of items within the first lay-ers, since CMiner can effectively traverse the pyramid and consider only a small fraction of the included items. Baselines : We compare our CMiner algorithm with two baselines. The first is the Naive approach described in Sec-tion 3. The second is a clustering-based approach that works as follows. First, it iterates over the considered feature-subsets. For each subset F  X  , it identifies the set of items that have the same value assignment for the features in F  X  , and places them in the same group. Thus, F  X  is mapped to dif-ferent groups of items with the save value-assignments over its features. The algorithm then iterates over the reported groups. For each group, it updates the pairwise coverage provided to V  X  F by the target item I  X  and an arbitrary item from the group (it can be any item, since they all have the same values with respect to F  X  ). The computed coverage is then used to update the competitiveness of all the items in the group. The process continues until the optimal compet-itiveness scores for all items have been computed. Assuming there are at most M groups per feature-subset, the algorith-m X  X  complexity is O( |I| * M * |Q| ). Obviously, when each group is a singleton, the algorithm degrades to the Naive case. We refer to this technique as GMiner .

Unless otherwise stated, we use the IC ordering scheme in our experiments, as described in Section 4.1. All exper-iments were run on a desktop with a Quad-Core 3.5GHz Processor and 2GB RAM.
In this experiment we compare CMiner with the two base-lines (Naive and GMiner), in terms of computational time. First, we use each of the three algorithms to compute the set of top-k competitors for each item in the four datasets. The process is repeated for k  X  { 3 , 10 , 50 , 150 , 300 } . The re-sults for the four datasets are shown in Figures. 3(a-d). The x-axis holds the different values of k . The y-axis holds the respective computational times (in seconds). We report the average time for each item.

The figures motivate some interesting observations. First, the Naive algorithm consistently reports the same compu-tational time regardless of k , since it naively computes the competitiveness of every single item in the corpus with re-spect to the target item. Thus, any trivial variations in the required time are due to the process of maintaining the top-k set. In general, Naive is outperformed by the two other algorithms, and is only competitive for very large values of k for the Hotels Dataset .

For the Cameras dataset, CMiner and GMiner exhibit al-most identical running times. This is due to the very large number of distinct feature-subsets for this dataset, which fa-vors GMiner. In particular, this dataset has 14779 different subsets and GMiner identifies, on average, 443.63 groups per subset. This means that the algorithm saves roughly a total of (579  X  443)  X  14779 = 2009944 coverage computation-s per item, allowing it to be competitive to the otherwise superior CMiner. In fact, for the other datasets, CMiner displays a clear advantage. This advantage is maximized for the Recipes dataset, which is the most populous of the four, in terms of included items. The experiment on this dataset also illustrates the scalability of the approach with respect to k . For the Hotels and Restaurants datasets, even though the computational time of CMiner appears to rise as k increases for the other three datasets, it never goes above 0 . 035 seconds.
I n Section 4.1, we described the IC ordering scheme, which determines the order in which subsets are processed by CMin-er. Two alternatives to this scheme are processing the sub-sets in descending ( W-DSC ) and ascending ( W-ASC ) or-der by weight. Next, we evaluate the impact of the three schemes on the efficiency of CMiner. We only show the re-sults for the Recipes dataset, which was by far the largest in terms of both size and dimensionality. The findings for the other corpora were identical and are omitted for lack of s-pace. Figure 4 shows the total number of subset-processings Figure 4: Number of subset processings that required under d ifferent ordering schemes. (i.e. the total number of times the for-loop in line 19 of Algo-rithm 1 is executed) required by each ordering scheme until CMiner converges to the top-k competitors, for different val-ues of k . We report the average over all items in the corpus. The results demonstrate that IC clearly outperforms the t-wo baselines, consistently requiring far less subsets for all values of k . We also obeserve that no more than 110 sub-sets had to be processed, for all considered values of k . This allows CMiner to quickly converge to the optimal top-k set.
In order to validate our competitiveness paradigm, we con-duct a user study as follows. First, we select 10 random item-s from the Cameras corpus. We refer to these 10 items as the seed . For each item I  X  in the seed, we compute its compet-itiveness with every other item in the corpus, according to our definition. In addition to our own CMiner approach, we also rank all the items in the corpus based on their distance to I  X  in the feature-space. The L 1 distance was used for numeric and ordinal features, and the Jaccard distance was used for categorical attributes. We refer to this as the NN ap-proach (i.e. Nearest Neighbor). We then chose the two items with the highest score, the two items with the lowest score, and two items from the middle of the ranked list. This was repeated for both approaches, for a total of 12 candidates per item in the seed (6 per approach). We then created a user study on the online survey-site kwiksurveys.com . The survey was taken by 20 different human annotators. Each of the 10 seed-items was paired with each of its 12 corre-sponding candidates, for a total of 120 different pairs. The pairs were shown in a randomized order to the annotators, who were also given access to a table including the values Figure 5: R esults of the user study comparing our competitive-of each item for every feature. For each pair, the annotator was asked whether he would consider buying the candidate instead of the seed item. The possible answers were  X  X ES X ,  X  X O X  and  X  X OT SURE X . The results are shown in Figure 5. The y-axis holds the percentage covered by each approach. The figure shows 3 pairs of bars. The left bar of each pair corresponds to our CMiner approach, while the right bar to the NN approach. The first two bars from the left represen-t the responses of the users to the top-ranked candidates for each approach. The two bars in the middle represent the responses to the candidates ranked in the middle, and, final-ly, the two bars on the right represent the responses to the bottom-ranked candidates. Each bar captures the fraction of each of the three possible responses. The lower, middle, and upper part of the bar represent the  X  X ES X ,  X  X O X  and  X  X OT SURE X  responses, respectively. For example, the first bar on the left, reveals that about 90% of the annotators would consider our top-ranked candidates as a replacement for the seed item. The remaining 10% was evenly divided between the  X  X O X  and  X  X OT SURE X  responses.

The figure motivates some interesting observations. First, we observe that the vast majority of the top-ranked items by our method were identified by the annotators as possible replacements for the seed item. These are thus verified as strong competitors that could deprive the seed item from potential customers. On the other hand, the top-ranked candidates of the NN approach were often rejected by the users, who did not consider these items to be competitive.
The middle-ranked candidates of our approach attracted mixed responses from the annotators, indicating that it was not straightforward to determine whether the item is indeed competitive or not. An interesting observation is that the middle-ranked candidates of the NN approach were more popular than its top-ranked ones. The interpretation is that this approach fails to emulate the way the users perceive the competitiveness between two items.

Finally, the bottom-ranked candidates of our approach were consistently rejected by the annotators, verifying their lack of competitiveness. The bottom-ranked items by the NN approach were also frequently rejected, indicating that it is easier to identify items that are not competitive to the target. In conclusion, the survey demonstrated the ability of our paradigm to capture the competitiveness between two items. Further, our approach consistently outperformed an intuitive baseline, indicating that the task is non-trivial.
W hile our work is the first to consider domain-invariant competitor mining, it has ties to existing relevant literature. Competitor Mining: Previous work [14, 13, 1, 26] focus-es on mining competitors based on comparative expressions found in web results and other textual corpora. The intu-ition is that the occurrence of expressions like  X  X tem A is better than Item B X   X  X r item A Vs. Item B X  is indicative of the competitiveness relationship between the two item-s. However, as we have already discussed in the introduc-tion, such comparative evidence are typically scarce, or even non-existent in many mainstream domains. As a result, the applicability of such approaches is greatly limited. Finding Competitive Products: Recent work [22, 23, 28] explored competitiveness in the context of product de-sign . The first step in these approaches is the definition of a dominance function that represents the value of a produc-t. This can measure domination of other items or potential customers. The goal is then to use this function to create non-dominated items, or items with the maximum possible dominance value. A similar line of work [25, 24] represents items as points in a multidimensional space and looks for subspaces where the appeal of the item is maximized. While relevant, the above projects have a completely different fo-cus from our own, and hence the proposed approaches are not applicable in our setting (and vice versa).
 Skyline computation: Our work leverages concepts and techniques from the extensive literature on skyline computa-tion [4, 12, 17]. These include the dominance concept among items, as well as the construction of the skyline pyramid used by our CMiner algorithm. Our work also has ties to the re-cent publications in reverse skyline queries [20, 21]. Even though the focus of our work is different, we intend to s-tudy the advances in this field and evaluate their potential to improve the efficiency of our framework in future work.
In this work, we presented a formal definition of the com-petitiveness between two items. Our formalization is appli-cable across domains, overcoming the shortcomings of pre-vious approaches. We consider a number of factors that have been overlooked by previous approaches, such as the position of the items in the multi-dimensional feature space, and the preferences and opinions of the users. A user study was conducted to verify the validity of our notion of com-petitiveness. Based on our competitiveness paradigm, we addressed the problem of finding the top-k competitors of a given item. Our framework is designed to be efficient and scalable, in order to be applicable to large populations of items. Our methodology was evaluated via an experimental evaluation on real datasets from different domains. This work was supported by the MODAP and DISFER projects.
