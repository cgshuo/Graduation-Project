
Recognizing and analyzing change is an important hu-man virtue because it enables us to anticipate future sce-narios and thus allows us to act pro-actively. One approach to understand change within a domain is to analyze how models and patterns evolve. Knowing how a model changes over time is suggesting to ask: Can we use this knowledge to learn a model in anticipation, such that it better reflects the near-future characteristics of an evolving domain? In this paper we provide an answer to this question by pre-senting an algorithm which predicts future decision trees based on a model of change. In particular, this algorithm encompasses a novel approach to change mining which is based on analyzing the changes of the decisions made dur-ing model learning. The proposed approach can also be ap-plied to other types of classifiers and thus provides a basis for future research. We present our first experimental resul ts which show that anticipated decision trees have the poten-tial to outperform trees learned on the most recent data.
In many application fields almost every data collected is time stamped, or, as Kimball [14] noted:  X  X he time dimen-sion is the one dimension virtually guaranteed to be present in every data warehouse, because virtually every data ware-house is a time series X . Due to its temporal nature such data not only captures influences, like management deci-sions or the start of marketing campaigns, but also reflects the changes of the underlying domain. Often, change can mean a risk (like a shrinking subgroup of target customers) or an opportunity (like an evolving market niche). In either case, it is in many domains not only imperative to detect change in order to survive or to win but inevitable for suc-cessful decision making. In fact, recognizing, analyzing, and acting upon change is a virtue which is somewhat nat-ural to us humans and a necessity in order to cope with ev-eryday life, from driving a car to stock investments. For thi s reason it may seem surprising that in the area of data min-ing change has been regarded more a burden than a fortune. While research in overcoming typical problems imposed by evolving domains, like decreasing classifier performance, has been prospering, studies in methods how to effectively utilize change are still rather rare.

Recently, there has been an increasing research interest in methods which aim at analyzing the changes within a do-main by describing and modelling how the results of data mining X  X odels and patterns X  X hange over time. Change Mining has been coined as an umbrella term for this rela-tively novel research area. So far, research on change min-ing has solely focused on patterns such as association rules and clusters where it has been successfully used to solve a variety of problems, for instance interestingness assessm ent [16] and the detection of tiny clusters in noisy domains [10] . Nevertheless, the application of change mining to classifi-cation models still is a rather unexplored field.

Similar to how it is used for patterns, change mining can be applied to models with the goal of describing change, for example by analyzing how the relevancy or sensitivity of at-tributes changes. However, for models it is more insightful to ask: If we do know how a model, for instance a decision tree, changes over time, can we use this knowledge to learn it in anticipation, such that it better reflects the near-fut ure characteristics of an evolving domain? Predicting a future model provides at least two advantages: Firstly, the pre-dicted model provides insight into a domain X  X  future char-acteristics. Secondly, it can be expected that a predicted, future model will perform better than one learned on past or even the most recent data, particularly in cases where the underlying domain evolves at a fast pace.

Our goal in this paper is twofold: first of all, we want to show the potential of change mining for classifiers by pre-senting an algorithm that uses a model of change to learn decision trees in anticipation. More precisely, it models h ow the change within a domain affects those measures that con-trol the process of decision tree induction. It then predict s the future values of the measures and induces a decision tree from the prediction. We start the discussion with related work in Section 2, a brief Section 3 on notation and a short introduction of decision trees in Section 4. Our approach for predicting decision trees is presented in Section 5, fol -lowed by experimental results in Section 6 and a discussion of the computational complexity in Section 7.

Secondly, we want to provide a more theoretic frame-work for this kind of predictive change mining by general-izing the approach taken for decision trees. In Section 8 we are discussing typical difficulties connected to change min -ing of classifiers in general and their prediction in particu lar. Thus motivated we propose a framework for what we call process-centric change mining in Section 9. It circumvents the discussed difficulties and also provides a basis for futu re research due to its genericness.
To our knowledge, the area of change mining for clas-sifiers in general and the prediction of future decision tree s based on change information in particular has not been dealt with in the literature.

In the broader context of pro-actively retrieving a future model the RePro system [22] is the only approach known to us. However, the RePro system does not predict a com-pletely novel future model but searches for the best match out of a repository of past models. It strongly assumes that models repeat in time following a predictable repetition pa t-tern. This in turn is only likely to occur if the change trigge r-ing events repeat in time too X  X n the same order and each time with the same impact on the domain. This assump-tion, furthermore, has to hold for a rather long duration be-cause unless data is collected very frequently and the do-main changes often it will take a considerable amount of time to derive the huge number of models necessary to reli-ably learn transition patterns.

As already noted in the Introduction analyzing the change of patterns and models has been studied in the field of change mining. While conventional data mining takes one dataset and produces models or patterns upon it, change mining goes one step further in that it analyzes how mod-els and patterns evolve over time. So far, research on change mining has primarily focused on describing how association rules and clusters are changing (cf. [1, 16, 4, 20]). Change mining approaches for patterns typically first derive a se-quence of patterns which are then related and compared for changes. In Section 8 we will show that the application of such an approach to classifiers has some serious practical problems.
Throughout the paper we will make use of the follow-ing notation. We assume that a dataset S of sample cases is described by a set of nominal input attributes A := { A (1) ,...,A ( m ) } and a class attribute C . We assume that the domain of an attribute A has n A values, i.e. dom( A ) = { a 1 ,...,a n A } , and that the domain of attribute C has n values, i.e. dom( C ) = { c 1 ,...,c n C } .

Since we are interested in how data changes over time, let S be a time-stamped data set and [ t 0 , t r ] the min-imum time span that covers all its samples. The inter-val [ t 0 , t r ] is divided into r &gt; 1 non-overlapping peri-ods [ t i  X  1 ,t i [ , such that the corresponding subsets S i  X  S each have a size |S i |  X  1 . Without loss of generality, let  X  T := { 1 ,...,r, ( r + 1) ,... } be the set of all past ( i  X  r ) and future ( i &gt; r ) period indices.
Almost all algorithms for decision tree induction (cf. [18] and [6]) grow the tree top-down using a greedy strat-egy. The induction process is controlled by two different types of decisions: Firstly, starting at the root node an at-tribute A is selected that yields the highest score regarding an attribute evaluation measure I . The dataset is then split into n A subsets each corresponding to one attribute value a  X  dom( A ) and a child node for each of them is created. Secondly, if all its cases have the same class label or a stop-criterion is reached, a subset is not split further and hence no children are created. The current node then becomes a leaf and is assigned the majority class c  X  dom ( C ) of its associated subset.

An attribute evaluation measure I ( C,A ) rates the value of an attribute A for predicting the class attribute C . The most well-known measures are probably information gain [19] and information gain ratio [18]. The information gain I gain ( C,A ) measures the information gained, on av-erage, about the class attribute C when the value of the at-tribute A becomes known. A disadvantage of the informa-tion gain is its bias towards attributes with many values. To overcome this problem the information gain ratio I gr ( C,A ) was proposed which penalises many-valued attributes by di-viding the information gain I gain ( C,A ) by the entropy of the attribute itself [19, 18].
As an example for our approach to change mining we present the PreDeT algorithm that anticipates future de-cision trees. It models how the measures which control the decisions during the tree induction process change over time, predicts their future values and derives a decision tr ee from the prediction.
Figure 1 illustrates the change in a data set and the result-ing change in information gain. It shows the distribution of samples over the attribute space at four consecutive time pe -riods. Each sample belongs to one of two classes, squares and bullets, each described by two attributes A and B with domains { a 1 ,a 2 } and { b 1 ,b 2 } , respectively. Lets assume that we learn a decision tree at the end of each period which predicts the samples in the next period. In period 1 , shown in Figure 1(a), the information gain of A is much higher than that of B and it therefore would have been chosen as the split attribute. However, the distribution of sample s shifts over time which is indicated by arrows in Figure 1(a) to Figure 1(c). In period 3 the information gain of A is still higher than the one of B and therefore A would be the split attribute. This would lead to a classification error of 8 using the samples from period 4 for testing. However, in period 4 attribute B would have been the superior split attribute. The choice solely based on the samples from period 3 was sub-optimal. If we look at how the information gain developed between periods 1 and 3 we can see that it has a downward trend for A and an upward trend for B . Using an appropri-ate model for both time series it would have been possible to anticipate the change in the split attribute and to choose B . This choice leads to a much smaller classification error of 5 .

Figure 2(a) shows an example obtained from the same real world dataset which we also use for our experimental evaluation in Section 6. The information gain history of the attribute A (1) is stable apart from noise whereas the infor-mation gain history of A (2) shows an upward trend. Fur-thermore, it can be seen that for the vast majority of time periods T = 1 ,..., 15 attribute A (1) has more predictive power and would therefore be chosen as the split attribute. However, due to the observed upward trend in the informa-tion gain of A (2) both histories will intersect and A (2) become the split attribute in the near future.

Figure 2(b) shows the two histories from Figure 2(a) each modeled by a quadratic regression polynomial. In pe-riod 16 the  X  at the time of modeling unknown  X  informa-tion gain values of both attributes are marked. As it can be seen, the predictions made by the regression models antic-ipate the change in the ranking of candidate split attribute s which happens between period 15 and 16 .

In summary, the basic idea of PreDeT is to learn mod-els which describe evaluation measure histories and class label distribution histories in each step of the decision tr ee induction. The models are then used to predict the value of the respective quantity for the next, future time period. Subsequently, the predictions are used to decide whether to grow a subtree and which class label to assign to a leaf node. As we already pointed out in Section 4 these two decisions are the main building blocks of the vast majority of decision tree learners. Because our algorithm leverages prediction s for both it is finally capable to predict how a decision tree may look like in the future. In the presence of a changing domain this means that we should be able to provide clas-sifiers with a higher accuracy than those which are solely reflecting the characteristics of historic data.
Assume that we have a sequence of time-dependent data sets ( S 1 ,..., S r ) each described by the same attributes A ( i ) ,i = 1 ,...,m having the same domains in each time period. Quantities crucial for decision tree induction lik e at-tribute selection measure and the distribution of class lab els are now related to a specific data set S i and thus to a certain time period T i . Therefore they form sequences of values which we will denote by I := ( I ( S 1 ,A ) ,...,I ( S r ,A )) for attribute evaluation measures and P := ( P 1 ,...,P r ) for the sequence of class label distributions. Thereby P k := the relative frequency of class attribute value i in time pe-riod k . We will refer to these sequences as attribute eval-uation measure history and class label distribution histor y, respectively.

A model  X  for attribute evaluation measures is a function  X  :  X  T  X  X  X  R . In general, it will be determined based on a history I := ( I ( S 1 ,A ) ,...,I ( S r ,A )) of attribute evalu-ation measures which will be denoted by  X  [ I ] . A model  X  is then used in each inner node to obtain a prediction  X  [ I ]( r + 1) for attribute evaluation measure X  X  value in the next time period T r +1 .

As the set of potential candidate models we chose the set of polynomials  X  ( T ) = P q i =0 a i T i fitted to I using least squares regression. Linear regression in contrast to other possible model classes, like neural networks [11], offers t he advantage that no large sample sizes (long histories) are re -b b I gain ( A ) = 0 . 118
I gain ( B ) = 0 . 066 quired and that the underlying algorithms are fast. The first aspect is helpful when the domain changes rather fast. The latter aspect is important because models for a large number of histories need to be learned. The advantage of polyno-mial linear regression is, specifically, that it offers a sim ple way to obtain a set of candidate models by varying the de-gree q of the polynomial.

Having a set of fitted regression polynomials the best polynomial needs to be selected. In this case  X  X est X  means that polynomial which provides the best trade-off between goodness of fit and complexity and is, for this reason, less prone to overfit the data. This can be measured using the Akaike information criterion (AIC) [2]. Let r be the num-ber of observations, i.e. the length of the history, q + 1 the number of parameters of the polynomial and RSS the resid-ual sum of squares of the fitted regression polynomial. Then AIC is defined as:
Commonly, the number of time periods for which data is available can be rather small. For example, the data we use for our experiments in Section 6 consists of 25 data sets obtained weekly. The original Akaike information criterio n, however, should only be applied to data sets with large sam-ple sizes [7], i.e. if r/ ( q + 1) &gt; 40 . To overcome this lim-itation a number of corrections of the Akaike criterion for small sample sizes have been developed. In our PreDeT algorithm we use the following known as AIC C [13]:
For large sample sizes r AIC C converges to AIC , there-fore it can be always used regardless of sample size [7].
A model  X  for histories of class label distributions is a tory of class label distributions P := ( P 1 ,...,P r ) . The dependency of  X  on P will be denoted by  X  [ P ] . Within our PreDeT algorithm a model  X  is used in each leaf node to predict the class label distribution at time point T r +1
The prediction model  X  is a vector of functions  X  tween the time period and the relative frequency (estimated probability) of a class label. Because the relative frequen -cies must sum up to one P n C i =1  X  i ( T ) = 1 must hold, i.e. To model each  X  i we also use polynomials of degree q , similar to Section 5.2, determined using the Akaike infor-mation criterion.

Because values  X  i ( T ) are relative frequencies additional constraints have to be imposed on the choice of the function  X  . In particular, the following should always hold.  X  T  X  { 0 ,...,r + 1 } X  i  X  { 1 ,...,n C } : 0  X   X  i ( T )  X  1 In our experience this constraint can be too strict. For ex-ample, in the case p k i = p k +1 i = 1 and p j i 6 = 1 for j 6 = k and j 6 = k + 1 it is rather difficult to find a continuous, low-complexity model class for  X  i . For this reason and because we only aim to predict values for the period r + 1 we use the weaker constraint Applying this constraint the model  X  i cannot be derived us-ing standard regression analysis anymore. Instead, we ob-tain the coefficients a := ( a 0 ,...,a q ) T of the polynomial  X  i = P squares problem There exist several methods from the field of optimisation for solving constrained linear least-squares problems. Th ey will not be discussed here in greater detail. For further rea d-ing see [9].
Having explained the main building blocks of how to predict future decision trees in the previous two sections we will now go ahead and explain how they can be used in combination with a decision tree learner to anticipate fu -ture decision trees. This will finally lead us to the PreDeT algorithm.

Figure 3 shows the PreDeT algorithm. Similar to the vast majority of decision tree learners it consists of two co n-secutive stages. In the first stage (lines 1 X 8) the split at-tribute for the current node is searched. In the second stage (lines 9 X 18) it is decided whether the current node is a leaf (line 9) or inner node (line 15). Respectively, either a clas s label is assigned to the leaf node based on the majority class in this node, or the data sets are split according to the split attribute and the PreDeT algorithm continues recursively (line 17). It should be clear that the basic ideas laid out in Section 5.2 and Section 5.3 can be used in connection with any decision tree learner that uses attribute evaluation me a-sures to determine splits.

In contrast to other decision tree learners PreDeT takes as input a sequence of data sets ( S 1 ,..., S r ) representing time periods 1 ,...,r . It uses these data sets to estimate the value of the attribute evaluation measure in the next time period r + 1 using a learned model  X  (lines 4 X 5). The class label distribution within each data set is used to predict th e likely class label distribution in time period r + 1 using a learned model  X  (lines 11 X 13). Note that every decision about the structure of the tree  X  the choice of the split at-tribute in inner and of the class label in leaf nodes  X  is solel y based on estimated future values of the used metrics. For this reason the tree learned by PreDeT can be seen as a prediction of the decision tree in period r + 1 .
The PreDeT algorithm does primarily depend on two parameters: first of all, the length r of the sequence of data sets ( S 1 ,..., S r ) , and secondly, the attribute evalua-tion measure I . In our experiments we evaluated how these factors influence the accuracy of the anticipated decision trees and how this accuracy compares to the one of con-ventionally induced decision trees.

For our experiments we chose a representative real-life dataset from the domain of Customer Relationship Manage-ment (CRM). The dataset contains answers of customers to a survey conducted by a telecommunications company over a period of 25 weeks. Each sample is described by 13 nom-inal attributes with a domain size between 2 and 9 . Goal of the classification task is to predict whether a customer will be satisfied or dissatisfied with a certain service using the remaining 12 attributes, i.e. the data set has two classes to predict. In order to have an equal class distribution we did balance the original data set by removing samples of satis-fied customers.

We split the original data set into 25 subsets S i , each corresponding to a time period of one week. The sub-sets contain between 243 and 399 samples. For each ex-periment we chose a sequence of r consecutive data sets ( S i ,..., S i + r  X  1 ) within the available 25 ones. For each i, i = 0 ,..., 25  X  r we then learned a decision tree using the PreDeT algorithm and obtained classifications for the samples in the data set S i + r that chronologically follows the sequence. For instance, for r = 5 we have 20 sequences, learn 20 decision trees and thus obtain the classification ac-curacy for 20 data sets.

We did compare the accuracy of anticipated decision trees with those of conventionally induced ones 1 . In order to make a fair and realistic comparison two arguments need to be considered in the choice of the training data set for the induced decision trees. Firstly, when learning decisio n trees in the presence of concept drift it is common prac-tise to use only the most recent data available because their characteristics are very likely to be best reflecting those o f (unknown) near future data. It has been demonstrated by several authors that such a temporal moving window ap-proach almost always outperforms trees which have been learned from all of the available data [21, 12, 15]. Secondly , from an abstract perspective PreDeT (implicitly) learns a sequence of r decision trees each corresponding to a data set S j ,j = i,...,i + r  X  1 and then anticipates the tree in the future period i + r using a prediction model (cf. Section 9). As with any prediction model, the obtained prediction cannot have a better quality than its inputs. The quality of a decision tree, in particular its generalisation ability, does strongly depend on the size of the data set used for training. From this it follows that the trees anticipated by PreDeT do have a similar quality to trees that would have been learned directly on a data set with a size similar to those of each S j ,j = i,...,i + r  X  1 . For these two reasons, we chose to compare anticipated decision trees with decision trees i n-duced from the most recent data set of each sequence.
Using the experimental setup above we carried out ex-periments using the information gain ratio I gr and infor-mation gain I gain and varied in each case the length of the sequence by using r = 5 , 10 , 15 . Figure 4 shows the results of our experiments. For each combination of I and r the figure contains a chart whose abscissa axis shows the time period. The ordinate axis shows the classification accuracy of the anticipated decision tree (solid line) and the induce d decision tree (dotted line) on each test data set.
For the information gain ratio I gr we can see in Fig-ures 4(a) X 4(c) that for r = 5 the anticipated decision tree has a higher accuracy in 12 periods, equal accuracy in 2 periods, and a lower accuracy in 6 periods. For r = 10 the anticipated tree performs better in 9 , equally in 1 , and worse in 5 periods. For r = 15 it performs better in 7 , and worse in 3 periods. This shows that anticipated decision trees outperform the induced ones on a considerably larger number of data sets. To show that the observed gain in accu-racy is statistically significant we carried out a (one-tail ed) Wilcoxon X  X  signed ranks test which is the recommended test for comparing two models [8]. The test yields p-values of 0 . 033 for r = 5 , of 0 . 0502 for r = 10 , and of 0 . 0704 for r = 15 . This means, for each r the null-hypothesis that the difference (accuracy(anticipated tree)  X  accuracy(induc ed tree)) has a median value lower than or equal to zero is re-jected using a significance level of  X  = 0 . 05 for r = 5 , and of  X  = 0 . 1 for r = 10 and r = 15 , respectively.
For the information gain I gain we obtain a similar result shown in Figures 4(d) X 4(f). For r = 5 the anticipated tree outperforms the induced tree in 14 periods, has an equal ac-curacy in 1 period and performs worse in 5 periods. For r = 10 the anticipated tree has a greater accuracy in 10 pe-riods and and a lower one in 5 periods. For r = 15 the antic-ipated tree has a greater, equal, and lower accuracy than the induced tree in 6 , 1 and 3 periods, respectively. To assess the statistical signicance of the observed gain in accuracy we once more used a (one-tailed) Wilcoxon signed ranks test. The test yields for r = 5 , r = 10 and r = 15 p-values of 0 . 0856 , 0 . 03515 and 0 . 082 , respectively, implying that anticipated trees performs statistically better than conv en-mance of a conventionally induced decision tree is shown. tionally induced decision trees in these three settings.
In terms of statistical significance the attribute evalua-tion measures I gr and I gain yield the best classification out-comes for different settings of the sequence length r , i.e. r = 5 for I gr and r = 10 for I gain . This gives rise to the assumption that the attribute evaluation measure is one factor the optimal choice of r depends on. Generally, the exploitation of this and other dependencies between param-eters leaves space for further optimisations of the PreDeT algorithm and is part of our future research agenda.
As already pointed out in Section 5 PreDeT follows the same greedy algorithm structure which is also employed by the vast majority of decision tree learners. Here, we will discuss the additional computational effort needed by Pre-DeT and compare it with the one of a conventional deci-sion tree learner. In the following discussion we will as-sume that PreDeT receives a sequence of (sub-)datasets ( S 1 ,..., S r ) as its input while the conventional decision tree learner receives the data set S r . Further we assume that each dataset is of size n and that the number of attributes in each dataset is m .

In each step of the tree-growing process of a conven-tional decision tree learner each candidate attribute is ex -amined and the one with the highest attribute evaluation measure is selected as the splitting attribute. The most tim e-consuming part is the calculation of the attribute evaluati on measure. The algorithm must pass through each instance in a subset S r , for each of which it iterates through each can-didate attribute. Because the union of the subsets of each level of the tree is S r the time complexity for each level thus is O ( m n ) . Because a tree can have no more than m levels the overall complexity of a conventional decision tr ee learning algorithm thus is O ( m 2 n ) .

Obviously, while the conventional decision tree learner has to calculate the attribute evaluation measure values an d the class label distributions in leaf nodes for only one data set, PreDeT needs to calculate it for r data sets. The same holds for splitting datasets: a conventional learner h as to split one while PreDeT has to split r . Additionally, PreDeT learns a regression polynomial for each sequence of attribute evaluation measure values (line 4 in Figure 3)) . This step involves solving a system of linear equations of size ( q + 1)  X  ( q + 1) whereby q denotes the degree of the regression polynomial. A solution can be obtained in O (( q + 1) 3 ) . Further, a constraint linear least square prob-lem needs to be solved by PreDeT to decide upon the class label of a leaf node (line 12 in Figure 3). The problem can be formulated by a r  X  ( q + 1) matrix and a solution ob-tained by a quadratic programming approach in O ( q 4 ) . The degree q of the employed polynomial functions is almost al-ways significantly small, typically values of q = 1 , q = 2 or q = 3 are employed. For this reason, the effort for these two computations is very small compared to the effort needed to calculate the attribute evaluation measure and to split the data set such that it does not significantly contribute to the overall runtime of the algorithm.

Therefore, the computational effort of PreDeT is ap-proximately r -times higher than those of a conventional de-cision tree algorithm that uses S r as its input leading to a time complexity of O ( r m 2 n ) . Mostly, however, the length of the sequence r will be rather low, for example in our experiments we did obtain good results for r = 5 and r = 10 , so that the additional effort is still manageable.
The memory space complexity of PreDeT is the same as for a conventional decision tree learner apart from the fact that it operates on more data. In particular, PreDeT does not store the time series of statistics needed to antici -pate decision trees, they are calculated on-the-fly during t he run of the algorithm (cf. lines 3 and 13 in Figure 3).
Having introduced an approach to predicting decision trees in previous sections, we will now discuss possible al-ternatives in more detail and finally generalize the chosen approach in Section 9 with a framework for process-centric change mining . Formally, the problem of predicting a clas-sification model can be described as follows. Using a data mining approach a model M i is derived for each time pe-riod [ t i  X  1 ,t i [ ,i &gt; 0 based on the data S i . Hence, we have two sequences: a sequence of data sets ( S 1 ,..., S r ) and a sequence of data mining models ( M 1 ,..., M r ) .
Given a a sequence of data sets ( S 1 ,..., S r ) we are in-terested in a data mining model M r +1 that represents the data S r +1 of the future time period [ t r ,t r +1 [ . Since S r is unknown the model M r +1 cannot be derived in the usual way. To solve the problem two basic approaches are appar-ent: 1. to predict the data set S r +1 from the sequence 2. to predict the model M r +1 directly from the sequence
For the first approach, directly using the history of data sets for prediction is not promising, because the relations hip between data points in different time periods is almost al-ways unknown. Instead, one could try to derive models for data generation, predict a data generator for [ t r ,t r +1 erate S r +1 and learn M r +1 . This, in turn, is an instance of the second approach because it involves the prediction of a model based on a sequence of past models. One may object that there is a conceptual difference between data generat-ing models and prediction models. Nevertheless, the diffi-culties linked to the prediction of a model based on a history of models are the same in both cases.

In fact the degree of difficulty depends on the type of model. Simple models based on parameterized probability distributions, for instance, can easily be predicted. How-ever, models with a manageable number of parameters are only available for numeric data and even then usually too simple. Predicting complex models based on a history of past models, on the other hand, proves to be extremely prob-lematic. Since a general discussion would be outside the scope of this paper, we will discuss the difficulties using decision trees as an example. Although they have a rather simple structure it turns out that the task of directly compa r-ing them for changes is more than challenging. Three major difficulties can be identified:  X  Complexity : To identify changes between two or more  X  Instability: In particular decision trees are known to be  X  Utility: Imagine that a satisfying solution for the first
In Section 8 we discussed that analyzing changes for de-cision trees and models in general is rather difficult, if the common change mining approach of direct model compar-ison is employed. As a solution we propose a generic ap-proach that is based on a decomposition of the model induc-tion process. Consider the induction process of a decision tree as an example. It can be described as a sequence of de-cisions comprising which attribute to take for the next spli t, when to stop growing the tree and which class label to as-sign to a leaf node. Decisions are driven by an attribute selection measure I like the information gain and the class label distribution P . Following the algorithm of tree induc-tion, the sequence of decisions then uniquely determines th e model. In other words, if we know all possible values  X  the image  X  of the information gain and the class label distribu-tion, we can directly compute the model without going back to the data. In this respect, the image of I and P together form an intermediate representation of a decision tree that is sufficient for tree induction. An example for such an in-termediate representation is the well known concept of suf-ficient statistics in probability theory. For instance, statistics can be sufficient to uniquely determine a probability distri -bution being the equivalent of our model.

More formally, when deciding on the attribute for the next split, we evaluate I on the data subset S  X   X  S of the current branch of the tree for all attributes A in the set of attributes A . We then pick the attribute that maximizes (or minimizes) I . In other words, if we know the image I := I ( A , 2 S ) of all possible combinations of attributes and subsets of S , we have all the information required to pick the best attribute for a split at any stage of growing the tree . Adding the image P := P (2 S ) of the class label distribu-tion P forms the intermediate representation IR = ( I , P ) .
In order to predict a future model we propose to look at how the intermediate representation changes over time, predict their future values and then follow the usual model induction process to derive the future model. Having a se-quence of data sets ( S 1 ,..., S r ) a sequence of intermediate representations ( IR 1 ,..., IR r ) can be generated. Almost al-ways, the values in IR i will change over time, so do the decisions based on them and, finally, so does the resulting model. This means, by analyzing how the values of IR i and thus the corresponding decisions change over time in each step of the induction process information about how the model will change can be retrieved. Figure 5 illustrates the proposed decomposition with predicted intermediate repre -sentation IR r +1 and induced future model M r +1 . In fact, as we have seen in Section 5 in case of decision Intermediate Representation IR
Figure 5. Process-centric change mining an-alyzes the sequences of intermediate repre-sentations IR i trees we do not necessarily need to compute and store the complete intermediate representation which can be compu-tationally expensive. Instead we generate the required par ts of the IR i on the fly, when they are needed.

It is obvious that such an approach needs to be embedded into the learning process itself rather than being a subse-quent analysis step as with the model-based approach. Be-cause our approach to change mining is tightly coupled with the learning process we will call it process-centric .
The approach is useful only, if the intermediate represen-tation is sufficient to derive the model, i.e. if the decompo-sition is well defined, and if the intermediate representati on is of such a form that it can easily be predicted. As we have shown in Section 5 both requirements are met for decision trees. The second requirement shows that decision trees are indeed well suited as an example. Since the measures I and P form real-valued time series for every attribute-data subset combination, we can apply standard time series pre-diction to determine IR r +1 .

The described approach does not only apply to decision tree learners. It is suitable for other algorithms, for inst ance in the area of Bayesian networks. An example is the K2 algorithm. In general, every algorithm that builds upon a greedy strategy can be described as such a sequence of mea-sure dependent decisions. More generally, the approach works wherever the mapping of data onto models can be decomposed into more or less complex sequences of map-pings with intermediate representations. The basic mecha-nism remains the same, as long as we can find intermediate representations that can easily be predicted and that fully determine the model. A general proof that the diagram in Figure 5 commutes for a particular mining model like deci-sion trees is difficult. Section 5.1 showed with an example at hand how a predicted intermediate representation reflect s data of the following time period.
In this paper we provided a first research step into the field of change mining for classifiers. We presented the PreDeT algorithm which predicts decision trees for future time periods by modelling how attribute evaluation measure and class label distribution evolve over time. First experi -mental results we obtained are very promising because they show that our approach is able to learn decision trees with a higher classification accuracy than approaches which only use the most recent data available. In particular, we only used a rather simple polynomial regression function for the prediction of the attribute evaluation measure in each step of PreDeT . It is likely that the results can be improved to a significant extent if more sophisticated prediction model s are used.

We also showed that the approach of learning a sequence of models is unsuitable for both providing a basis for change mining and for future model prediction due to the com-plexity of direct model comparison. As an alternative we proposed process-centric change mining which is a novel approach to change mining that focuses on the analysis of changes in the decisions made during model induction.
We are currently working on the application of process-centric change mining to other types of models, in particu-lar Bayesian networks. As part of this work we also look into proving that Figure 5 commutes under certain condi-tions. We are also working on several enhancements of the PreDeT algorithm. In the first place, we investigate the advantages of using more sophisticated and more robust re-gression methods. A rather challenging research question to answer here is which type of model can best reflect the changes in the attribute selection measure. Secondly, as th e algorithm stands a new decision tree has to be predicted ev-ery time a new batch of data arrives. For this reason it would be advantageous w.r.t. computational costs if PreDeT sup-ported incremental learning.

