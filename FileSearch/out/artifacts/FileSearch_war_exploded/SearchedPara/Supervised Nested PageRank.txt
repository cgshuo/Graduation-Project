 Graph-based ranking plays a key role in many applications, such as web search and social computing. Pioneering meth-ods of ranking on graphs (e.g., PageRank and HITS) com-puted ranking scores relying only on the graph structure. Recently proposed methods, such as Semi-Supervised Page-Rank, take into account both the graph structure and the metadata associated with nodes and edges in a unified opti-mization framework. Such approaches are based on initial-izing the underlying random walk models with prior weights of nodes and edges that in turn depend on their individual properties. While in those models the prior weights of nodes and edges depend only on their own features, one can also assume that such weights may also depend or be related to the prior weights of their neighbors. This paper addresses the problem of weighting nodes and edges according to this intuition by realizing it in a general ranking model and an efficient algorithm of tuning the parameters of that model. Categories and Subject Descriptions: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Algorithms, Experimentation, Performance Keywords: page authority, PageRank, random walks, fresh-ness, content features, web search, learning
Nowadays, various graphs such as web graph, user brows-ing graphs [14], query-flow graphs, social networks, and other graphs with a large amount of information on nodes are available to large-scale web information systems. For some of them, such as web search engines or online social net-working services, graph-based ranking has always been one of the key technologies. The most acknowledged of these methods are based on random walk models: PageRank [17], HITS [11], and their variants (see, e.g., [9, 18]). Accord-ing to PageRank algorithm, the score of node p equals to its probability in the stationary distribution of a Markov process, which models a random walk on the graph (origi-nally, the algorithm was applied to a web graph). A certain random walk can be defined by its transition and restart probabilities. For instance, in the original PageRank algo-rithm these probabilities are equal for all nodes in the case of a restart and are equal for all destination nodes in the case of a transition. In contrast, in more recent approaches these probabilities may essentially depend on the properties of nodes and edges between them. For instance, if the nodes are documents in a web graph [17] or a browsing graph [14], its nodes and edges may be supplied with some metadata in-cluding the statistics about users interactions with the nodes (e.g., the number or average duration of visits of documents by users or the number of transitions between them), doc-ument language models or histories of document changes. Such information defines certain properties of nodes and edges and can be used for a more accurate evaluation of nodes X  authorities as compared to the methods solely based on the geometric graph structure.

There is a number of studies addressing the problem of appropriate accounting for the above mentioned important properties of nodes and edges for graph ranking. The models described in early studies [5, 13, 18] utilize nodes X  and edges X  properties in a rigid way not allowing for their adjustment to particular use cases. The authors of more recent works [5, 6, 8, 9] propose more flexible ranking systems capable of accounting for the same properties in various ways within some parametric model. In other words, the weights of nodes (corresponding to restart probabilities) and the weights of edges (corresponding to transition probabilities) are defined as some parameterized functions of their features, and the values of these parameters thereby control the character of the random walk.

A crucial challenge is to adjust the parameters of above approaches in a supervised setting. Previous optimization methods [7] considered only the case of linear PageRank models, where the weights of nodes and edges are linear combinations of their features with coefficients as parame-ters of the model. In this way, the weight of a given node (or an edge) depends only on the features of this node (edge) and does not depend on the properties of its neighbors. This constraint makes the model suffer from a number of limita-tions.

First, in many applications, some node features are dis-tributed irregularly, which may occasionally lead to dispro-portional differences in weights and, consequently, in rank-ing scores of neighboring nodes. This effect does not agree well with the intuition that graph-based ranking methods are driven by: a neighbor of an authoritative node is likely to b e also authoritative. For instance, an old document can have a lot of recently created neighbors. Then the age of that old document is significantly greater than the age of its neighbors, though, if we want its authority to depend on its freshness and the freshness of its neighbors, we could smooth its age with the age of its neighbors.

Second, some metadata on nodes and edges may be sparse resulting in features whose values are not defined for many nodes and edges or very imprecise to be trusted. For in-stance, we may miss any click information for some pages, even if they are shown on SERPs, but not ranked highly enough to be seen by users. Such situations are also not foreseen by previous optimization methods of graph-based ranking.

Third, if feature values are noisy, then it may cause un-realistic fluctuation of ranking scores, when following from a node to its neighbor. For instance, there is no sense to compute the average dwell-time of a page that was visited only a few times by only one user, because it would re-sult in a very imprecise estimate. Other examples of noisy feature values are the creation times (and, hence, ages) of non-timestamped web documents, which are very hard to be inferred precisely [10].
 In this paper, we propose a new method called Supervised Nested PageRank (SNP) for learning a model of nodes X  au-thorities, which obviates the above-mentioned shortcomings. Similar to linear PageRank models, our method is based on learning parameters of a principal random walk model that is conducted by weights of nodes and edges. How-ever, the weight of an item (a node or an edge) is no longer defined only by the features of this item. Alternatively, this weight is also defined by the features of its neighbor-ing items, and this dependency allows smoothing of weights along the graph. Specifically, the weights of nodes and edges are defined by the stationary distributions of two respective different Markov processes. These two subordinate Markov processes are defined on the considered graph by two sim-ilar equations with two independent collections of parame-ters. The weights of nodes that define the restart probabil-ities of the principal Markov process are equal to the corre-sponding stationary node probabilities obtained for the first of the two subordinate Markov processes. The weights of edges that define the transition probabilities of the princi-pal Markov process are equal to the stationary node prob-abilities of their corresponding destination nodes obtained for the second of the two subordinate Markov processes. In this way, the subordinate random walks spread nodes X  and edges X  feature values along the graph, thus helping to avoid the above-described undesirable effects. We call processes of such type nested processes .

The ranking system of SNP approach depends on a vec-tor of parameters. We develop a new gradient optimization method for adjusting the model parameters in a supervised setting. It is based on calculation of derivatives of the model stationary probabilities with respect to the model parame-ters. Our optimization technique is efficient enough: its complexity is the number of steps of the gradient descent multiplied by the complexity of PageRank algorithm (up to a constant factor). It can be applied to a wider class of opti-mization tasks with smooth objective functions of stationary probabilities. To the best of our knowledge, we are the first to present an algorithm of obtaining optimal parameters for the nested processes used for nodes ranking.

The contributions of this paper are the following.  X  We introduce a new SNP algorithm, which is based  X  We introduce an algorithm of optimizing the parame- X  We evaluate our algorithm by considering a hyper-
The remainder of the paper is organized as follows. Sec-tion 2 contains a review of ranking algorithms on graphs based on random walks, whose transition matrix depends on features of nodes and edges of the considered graph. In Section 3 we define our Supervised Nested PageRank algo-rithm. In Section 4 we introduce the optimization method that we employ for tuning the parameters of our algorithm. Section 5 contains the descriptions of the graphs we experi-ment with, features of their nodes and edges and the objec-tive functions that we consider to compare the approaches. The experimental results are reported in Section 6. In Sec-tion 7 we summarize the outcomes of our study, discuss its potential applications and directions of future work.
Graph-based ranking methods relying on the principles of spreading activation, such as PageRank, can be param-eterized in different ways [15]. The problem of appropriate weighting of nodes and edges for better ranking of nodes on graphs appears in the scope of a variety of its applications: web page ranking [5, 7, 9, 13, 17, 18], ad-hoc retrieval of scientific articles and named entity recognition [12], finding similar entities (e.g., in an email corpus [15]), link prediction in social networks [1]. In the scope of each such application, there is some specific information on nodes or edges, which the original PageRank algorithm [17] does not account for.
Several methods that extend the PageRank model [7, 9, 18, 21] have been developed. In these works authors define parameterized models, where a surfer X  X  choice of transition to a node directly or through an edge depends on nodes X  and edges X  weights. However, the authors of the first such mod-els (e.g., [9, 18]) do not introduce any theoretically sound method of optimizing parameters of such random walks. In [1] Backstrom et al. designed the variant of PageRank called Supervised Random Walk for the link prediction task. In this work, only edges X  weights depend on metadata. Gao et al . [7] generalized the aboved-mentioned methods by in-troducing the framework called Semi-Supervised PageRank (SSP) . It should be mentioned here that a lot of clas-sical graph-based ranking methods (besides those listed), LiftHITS [4], NetRank [3], Laplacian Rank [22]), can be also considered as special cases of Semi-Supervised PageRank.
Roughly speaking, the weights of nodes and edges that all the above mentioned algorithms deal with are linear combi-nations of some nodes X  and edges X  features. It is also always considered that the weight of a node (or an edge) depends only on the properties of this node (edge). Such approach has limitations described in Section 1. In contrast to pre-vious approaches, our method is based on the idea that the weights of nodes and edges should be influenced by the fea-tures of neighboring items, and this dependency allows for smoothing weights along the graph.

A special case of nested PageRank model, which is in-vestigated in the current paper, was previously considered by Dai et al. [5] and later extended in [26]. These papers were devoted to the problem of recency-sensitive ranking of vertices in the web graph. For that purpose, authors de-signed random walks conducted by weights of nodes that represent their  X  X reshness X  in the web graph. In these ap-proaches, the weight of a node depends on both its features and features of its neighbors as well. However, these mod-els were not supplemented with any optimization technique for tuning numerous parameters of the model, and even the benefit of their complicated structure have not been evalu-ated. In contrast, our framework is an attempt to generalize nested models, study their advantage over the simpler yet effective SSP approach, and support them with a method of optimization of the underlying random walks parameters.
BrowseRank [13] is an effective method of page ranking, which utilizes user browsing graph. Based on Continuous-Time Markov Processes, BrowseRank can be still regarded as a special case of SSP with its inherited weaknesses (if we reduce it to a discrete case, as suggested in the paper). In [27], the authors propose Fresh BrowseRank exploiting nested processes on the browsing graph with recency data on nodes. Unfortunately, this short paper does not describe a general model, which could be applied to a broad range of similar problems, neither it provides any theoretical foun-dation of their own model. In contrast to that, SNP, pro-posed in this paper, is a general and theoretically grounded model, which can be applied to the case of Continuous-Time Markov Processes as well. What X  X  more, the authors of [27], do not describe any method of parameters X  optimization, which would make their model practically feasible (i.e, do not introduce any algorithm of computation of derivatives), while such a method is one of the major contributions of our paper.
In this section we introduce the method of ranking nodes of the graph. Let there be R ranking tasks, and in each task q  X  { 1 , . . . , R } we need to produce ranking scores for the nodes. For instance, if we consider the problem of query-dependent web page ranking, then a query submitted by a user can be considered as such a task. A random walk-based ranking algorithm takes as input nodes and edges features, which can be task-dependent. Besides these features, the output ranking depends also on the algorithm parameters, which are used for the adjustment of the algorithm itself, thus, are not task-dependent. We propose an algorithm that finds the values of a nested random walk X  X  parameters that optimize graph ranking for all the tasks on average, as fol-lows below.
Let q  X  { 1 , . . . , R } be a ranking task. We define a graph as a tuple G ( V, E, V q , E q ), where V is a set of n vertices, E is a set of edges, V q = ( V q i , i  X  V ) is an ordered set of vec-tors representing features of vertices ( V q i is an l -dimensional vector of features of node i ), E q = ( E q ij , i, j  X  V ) is a ma-trix of vectors representing features of edges ( E q ij is an h -dimensional vector of features of edge i  X  j ). We assume E ij = 0, if i  X  j is not represented in E . For instance, in web search, the property of a link to be an internal link of a site can be a valuable edge feature. Similarly, a ranking score of a web page produced by some external algorithm that measures the page X  X  importance, relevance of freshness can be a valuable node feature.

Let X, Y be some sets of parameters and f q : X  X  V  X  R , g q : Y  X  E  X  R be some positive real-valued functions, which define weights within task q in the following way. For fixed values of parameters  X   X  X ,  X   X  Y , the weights of node i from V and edge i  X  j from E are defined as f q (  X , i ) and g q (  X , i  X  j ) respectively. We assume that the values of function f (and function g ) are defined by nodes X  and edges X  features V q , E q as well. Note also that the value of function f (or function g ) at node i (edge i  X  j ) may essentially depend not only on the i -th element of V q (on the element of E q for edge i  X  j ).

Semi-Supervised PageRank (SSP, [7]) is the stationary distribution obtained over vertices of a graph for a Markov random walk that is defined for the considered task q in the following way. A surfer moves from one node to another at each step. Being at node i , he decides either to jump to any node at random with probability  X  , or to walk along a random outgoing edge with probability 1  X   X  . If the surfer walks by an outgoing edge, then edge i  X  j is chosen with transition probability If the surfer chooses a random node, then node j is chosen with reset probability
The n -dimensional vector  X  q is the stationary distribu-tion in the described Markov process (see [16]). That is, this distribution is the solution of the following system of equations:  X  q ( i ) =  X  f Note that this equation defines the stationary distribution, if there are no vertices with outgoing degree 0 (see [8]). If this property is not satisfied, one should supply graph G with an additional (virtual) node, which is adjacent to all the other nodes of the graph, as it was proposed in [6]. The components of the stationary distribution can be considered as the scores of the nodes of G , and these scores define a solution of task q (see, e.g., [17, 7]). Let us assume that, for each task q  X  { 1 , . . . , R } , we have a v q -dimensional vector of labels r q assigned by assessors to some v q nodes in ac-cordance to the degree of relevance to task q , forming some representative subset  X  V q  X  V . Particularly, if nodes of the graph are web pages, then R can be considered as a set of queries. Let H (  X  q , r q ) be a function, which measures the dissimilarity of two vectors  X  q and r q (e.g., a rank distance or a retrieval quality measure if these vectors represent a subjective and an ideal ranking respectively). We consider the average dissimilarity to be the objective to minimize, as it was done in [15]. The optimization problem can be solved by a gradient-based optimization method (see Section 5.1).

The type of the tasks q depends on the nature of the considered graph and on the ranking problem. For instance, a particular task of the link-prediction problem [1] is to rank nodes by their probability to be linked to a given node in the future. In this setting, an exemplary task-dependent feature is the binary feature that identifies the node q . A task in the document ranking problem is a user query and an exemplary nodes X  feature is its BM25 relevance score. When the outcome of an algorithm does not depend on task q (in this case we use task-independent notation  X  instead of  X  a linear combination with task-dependent ranking b q can be considered [7, 26, 27] (see Section 5.1):
While SSP method [7] takes the properties of individual nodes and edges into account to tune the probabilities to walk through them, their weights are not  X  X ontext-aware X , so they do not take into account the fact that the node X  X  (edge X  X ) properties could be to a certain extent determined by the properties of the surrounding nodes (edges). In the next section we describe how to take that evidence into ac-count, when tuning a random walk model used for ranking.
Here we discuss possible methods of introducing weights f (  X , i ), g (  X , i  X  j ) used in Equations 1, 2 that define the reset and transition probabilities respectively. We first con-tinue describing SSP [1, 2, 9] and then introduce our new method, an improvement of SSP.

In SSP, parameter spaces X = ( R l )  X  , Y = ( R h )  X  are dual to the spaces of vertices X  and edges X  features respectively. In other words, the weights are defined by the equations: These equations thereby define a narrow class of linear de-pendency of the weight of a node (edge) on its feature vector. It is also worth mentioning that the weight defined in such a way depends only on the features of the considered node (the considered edge). Note that this approach can be gen-eralized, as it was done in [1], by considering the weights where  X  f ,  X  g : R  X  R are some monotone functions (note that we obtain Equation 6 in the particular case  X  f ( x ) = x ,  X  ( x ) = x ).
 In contrast, our method is based on the following intuition. In most tasks, including those we consider in Section 5, the purpose of weights is to assign initial values that measure some quality of a node or the strength of an edge between nodes. It seems to be a reasonable assumption that these initial weight values of a node (an edge) may as well depend on the feature values of its neighbors. Specifically, an item can receive X  X  part of neighbors X  weights X  X ith respect to the idea that neighbors of a more valuable item may also be more valuable and vice versa. The smoothing of the initial weight of a node (an edge) by the initial weights of its neighbors can be performed by a random walk as well. Thereby, we define the final context-aware weights of a node (an edge) as the stationary distribution in a Markov random walk, initialized by the context-agnostic initial weights that depend only on the features of a node (an edge). Thus we obtain a two-stage random walk, where the stationary distributions of the first-stage subordinate walks represent the initial weights of the second stage principal walk. Special cases of such nested Markov processes are recently introduced in [5, 26, 27]. In the current paper, we present the general framework for such processes and their applications.

More specifically, we propose to define the vertices X  and edges X  weights, which participate in Equation 3, used to ob-tain the stationary distribution  X  , by the equations: where G 1 , G 2 are themselves the stationary distributions of other Markov random processes, which propagate the initial weights of vertices (of edges). Note that the sec-ond equation expresses dependency only on the target node of the edge i  X  j . It corresponds to the standard ap-proach to weight edges by the values of their target vertices. Within our framework, one can exploit, say, linear combi-nation g (  X , i  X  j ) =  X  1 G 2 ( i ) +  X  2 G 2 ( j ). We consider the case  X  1 = 0,  X  2 = 1 by the following two reasons. First, this case is the generalization of models from [5, 18, 26, 27], and means that a random surfer moves in the direction of more valuable nodes, so the value of edges can be measured by the merit of vertices they point to. Besides, we try to avoid increasing the complexity of the algorithm without a realistic need for introducing additional parameters.
The stationary distributions G k , k = 1 , 2, are defined by an equation analogous to Equation 3. This time we pro-pose to use weighting introduced in SSP, where vertices and edges are weighted as defined by Equation 6. However, the purposes of G 1 and G 2 are different, since they define weight-ings f and g that play different roles in Equations 3, 7 (they define weights of nodes and edges respectively). Therefore, the optimal values of the parameters  X ,  X  may be differ-ent, as we use them for defining G 1 and G 2 . Note that finding the optimal values of those parameters is non-trival: these parameters conduct random walks, whose stationary distributions define weights f, g , which in turn conduct the principal Markov random process, and the stationary distri-but ion of this process should minimize the objective func-tion F . Specifically, we describe each of the subordinate Markov random processes by the following equation: where  X  k  X  [0 , 1], k = 1 , 2, are the damping factors of the Markov random walks, and F k i are initial weights of vertices and edges respectively. It means that the reset probabilities of these Markov processes are proportional to F k 1 ( i ), and the transitional probabilities are proportional to F k 2 ( i, j ). As we already said, the weights F k i are defined by the equations analogous to Equation 6:
F 1 1 ( i ) =  X   X  1 , V i  X  , F 1 2 ( i, j ) =  X   X  2 , E ij
Unlike SSP, we thus introduced f and g that depend on both vertices X  and edges X  features, each according to Equa-tions 7 X 9, what seems reasonable, since those weights are the outcome of a random walk process and hence can be defined by its complete set of parameters. Thereby, in our weighting method, the parameter vector  X  (vector  X  ) that defines weight function f (function g ), consists of two parts  X  ,  X  2 (  X  1 ,  X  2 ) of dimensions l and h , where the first part is dual to node features and the second part is dual to edge features, and includes additional parameters  X  k , k = 1 , 2 (damping factors): Note that the components of these vectors and the compo-nents of vectors V i , E ij must be non-negative in order to obtain non-negative weights F k i defining transition and reset probabilities in the Markov random walks. In Section 4 we introduce the method of training parameters  X  and  X  . We also assume that, for each node i  X  V , the sum
P transpose of the matrix A k = ( a k  X  ii ), where is stochastic. Therefore, there exists [20] the stationary dis-tribution G k which is equal to the only solution of Equa-tion 8 satisfying the condition P i  X  V G k ( i ) = 1.
In this section we investigate theoretical basis for opti-mization parameters of SNP method that we introduced in Section 3.2. First, we describe linear equations that define derivatives of the stationary distribution  X  . Then we provide an algorithm that solves these equations.
Let us consider any graph G and tasks 1 , . . . , R that fall within the definition given in Section 3.1. Recall that  X  is the stationary distribution of Markov process introduced in Section 3.2, whose components define a solution of task q (in some cases nodes X  and edges X  features are task-independent, and then we consider  X  q =  X  +  X b q , where  X  is the station-ary distribution and b q is a default task-dependent scoring function). Note that  X  q ( p ) =  X  q ( p,  X  ) depends on the vector of parameters  X  = (  X  1 , . . . ,  X  t ), where, according to Section 3.2,  X  is the vector which consists of the components of  X  , the components of  X  , and  X  ,  X  1 ,  X  2 . We minimize objective function F defined in Section 3.1 by a gradient-based opti-mization method. According to Equation 4, function F is a composition of H and  X  q , and thus We assume that derivatives of H with respect to all its ar-guments are computed easily, as in the case of the mean squared error measure H (  X  q , r q ) = P i  X   X  V q (  X  q So the main difficulty is to find derivatives  X  X   X  X 
In SSP, derivatives  X  X   X  X  { 1 , . . . , h } , exist and can be found according to the following systems of equations. + X  X  X  +
In order to find derivatives of  X  in our approach introduced in Section 3.2, we rewrite Equation 3 in the following matrix form: b one equation on  X  ( i ) from Equation 3, which corresponds to the case i = n . In fact, Equation 3 is equivalent to system B X  =  X  f , since the sum of the first equations of System 3 over i = 1 , 2 , . . . , n equals the last equation P n i =1 of that system.

In the following statement we introduce systems of linear equations for derivatives  X  X   X  X  ,  X  X   X  X  1 . Syst ems for the other derivatives are obtained in the same way.

Lemma 1. Functions  X  ( i ) are differentiable with respect to  X  h , h  X  { 1 , . . . , t } . Moreover, derivatives  X  X  s olutions of the following systems of linear equations:  X  X   X  X  Finally, derivative  X  X   X  X  1 can be found according to the follow-ing system: mials of  X  of degree 1, the elements of the solution  X  =  X  ( B (  X  ))  X  1 f of Equation 11 are rational functions of  X  . Thus  X  ( i ) is differentiable with respect to  X  at any point of (0 , 1). Let us consider the left-hand side and the right-hand side of Equation 3 as two functions of  X  , which are implicitly de-fined by Equation 3. If  X  is the solution of the system, the values of these two functions are equal for any  X  in (0 , 1). Therefore, the derivatives of these functions with respect to  X  are also equal. As functions f (  X , i ) and g (  X ,  X  i  X  i ) do not depend on  X  , we get Equation 13.

In the same way it can be proved that function f (  X , i ) is a rational function of  X  1 . Therefore, it is differentiable with respect to  X  1 at each point of (0 , 1) and we get Equation 15. Moreover, the elements of vector  X  are rational functions of f (  X , i ) and, in turn, rational functions of  X  1 . Thus  X  ( i ) is differentiable with respect to  X  1 at each point of (0 , 1).
At this moment, we consider the left-hand side and the right-hand side of Equation 3 as two functions of  X  1 . Equa-tion 3 implies that the derivatives of these functions with respect to  X  1 are equal. As functions g (  X ,  X  i  X  i ) do not depend on  X  1 , we get Equation 14. In the same way, the existence of derivatives  X  X   X  X 
Lemma 1 provides equations that define derivatives of  X  with respect to parameters  X ,  X  1 . Note that all the other derivatives  X  X   X  X  to similar systems obtained in an analogous way, and we do not provide them explicitly due to space constraints.
In Section 4.2 we introduce an algorithm that numerically solves systems introduced in the statement of Lemma 1 and thereby finds derivatives  X  X   X  X  ,  X  X   X  X  1 . To the best of our knowl-edge, we are the first to obtain the gradients of station-ary distributions of nested Markov processes with respect to their parameters.
In this section we introduce our algorithm of computing the gradients of stationary distributions of nested Markov processes with respect to their parameters. Those gradients are used for finding the optimal values of these parameters. This algorithm is based on the systems of linear equations from the previous section (see Lemma 1). For the illustration of how this method proceeds, we only consider the case of derivatives due to space constraints.
 Let us write Equation 3 in the following form:  X  = A X  { 1 , . . . , n } ,
By the ergodic theorem [16], for any initial distribution  X  0 on the set of vertices V , the stationary distribution  X  defined by Equation 3 equals to lim by  X  j . Obviously, Let k  X  { 1 , . . . , t } . Due to Lemma 1, there exists derivative both sides of Equation 17 with respect to  X  k :
Consider also Equation 8 and rewrite it in the following
Ergodic theorem implies that, for any k  X  { 1 , 2 } and any distribution G k 0 , equality lim A G k 0 by G k j . We have Let us find the derivatives of both parts of Equation 19 in case k = 1 with respect to  X  1 :
Theorem 1. For any  X ,  X  1  X  (0 , 1) , we have
See t he proof of this theorem in Appendix A. This result implies that Equality 18 enables to find approximate values of  X  X   X  X  1 and  X   X   X  X  . In fact, we can proceed by the following way. First, we iteratively evaluate the values of G 1 j , G by u sing Equations 19 X 21. Then we find the components of the matrices  X  X   X  X  1 ,  X  X   X  by u sing equalities  X  X  At last, after we obtain the values of  X  X   X  X  1 ,  X  X   X  X  , we apply Equation 17 X 18 recursively and thus evaluate  X  j ,  X  X  j  X  X  At l ast, Theorem 1 guarantees that these values are approx-imations of  X ,  X  X   X  X  ,  X  X   X  X  1 . The above approach is summarized in Table 1.
In this section we describe two practical cases of the graph ranking problem that we consider in our experiments. We define objectives, all the parameters of the Markov processes and introduce the learning settings.
The data which is used for tuning parameters  X  1 , . . . ,  X  (see Section 4 for their definition) contains a collection of queries made by users of Yandex 1 . For each query q , there is a set of pages manually judged and grouped by rele-vance labels. We denote these groups by V 1 q , V 2 q , . . . , V in the decreasing order of relevance grades corresponding to these groups. For any two pages p 1  X  V i q , p 2  X  V j position of page p 2 according to our scoring function d q higher then the position of page p 1 , and i &lt; j . We consider loss h with margins b ij &gt; 0, where 1 6 i &lt; j 6 k , that is, aim is minimization of F (  X  ) = X where we have d q =  X  q ,  X  = (  X ,  X ,  X  ), yan dex.com Input: graph G ( V , E, V , E ),  X  ,  X  ,  X  ,  X  .

Algorithm: 1. Calculate F 1 1 ( i ), F 1 2 (  X  i, i ), F 2 1 ( i ), F for  X  i, i  X  { 1 , . . . , n } . 2. Calculate A 1 , A 2 ,  X  X  1  X  X  1 by u sing Equation 10, 21. 3. Set  X  s = 0, initialize G 1 0 ( i ) = G 2 0 ( i ) = 1 /n , 7. Calculate A ,  X  X   X  X  1 ,  X  X   X  X  by u sing Equations 16, 22. 8. Set s = 0, initialize  X  0 ( i ) = 1 /n for i  X  { 1 , . . . , n } . 9. Update  X  s +1 = A X  s , 10. If |  X  s +1  X   X  s | &lt;  X  , Table 1: Iterative alg orithm for evaluating derivatives We perform it by using the gradient based optimization method described in [25]. We use the algorithm described in Section 4.2 for evaluating derivatives. Our optimization technique is efficient enough: its complexity is the number of steps of the gradient descent multiplied by the complexity of PageRank algorithm (up to a constant factor).

In the next two sections we describe the features that define weights of nodes in subordinate Markov processes (scalar products  X   X , V i  X  ,  X   X , E ij  X  ). All these features and the resulting authority scores are not query-dependent. Thus, in order to compare the performance of the algorithms un-der study for a task of query-dependent ranking, as in [7], we combined their resulting authority scores  X  linearly with query-dependent BM25 scores b q of pages (see Equation 5) and evaluated them by Normalized Discounted Cumulative Gain (NDCG) metric. The parameter  X  of linear combina-tion with BM25 is chosen on the first iteration of gradient descent by maximizing NDCG on the training set. On the subsequent iterations we use the gradient descent method to define new values of the parameter:  X  s +1 =  X  s  X   X   X  X  with constant value of step size  X  of the gradient descent, where s  X  Z + is the iteration number.

Note that in [7] authors consider another objective func-tion, R (  X ,  X  ) = k  X   X   X   X  k 2 , where  X   X  ( i ) equals  X  f (  X , i ) P j  X  V f (  X , j ) + (1  X   X  ) As t his function is not query-dependent and a solution of the optimization problem is not consistent with the doc-ument relevance labels, the authors introduce constraints in t heir framework. Note that, for any positive  X  , we can find vector  X  such that k  X   X   X   X  k 2 &lt;  X  exploiting our itera-tive algorithm from Table 1. Therefore, any local minimum of our objective function is a local constrained minimum of the function R (  X ,  X  ) with the constraints F (  X  ) 6 C for some positive number C . Thus, we solve our optimization problem for both SSP and SNP algorithms. Moreover, the high-dimensional vector  X  is the parameter of the function R , while the objective function F (  X  ) does not depend on this vector of parameters. Hence, our optimization method has much lower dimensionality and, therefore, is orders of magnitude faster.
In our experiments we consider discrete-time Markov pro-cesses on a hyperlink graph. All experiments are performed with the graph containing pages and links crawled in June 2013 by Yandex. We utilize a corpus of web pages in the do-main of one of the largest European countries. The data set contains  X  2.52B pages and  X  21.12B links. Since the data set is rather large, we use Pregel [24] for parallel computations (the graph was divided randomly into 700 parts). To define weights of nodes and edges we consider two sets of pages X  features: the ones used by SSP in the original paper [7] and the temporal features described below.

As it was proposed in [7], for each edge in the graph, we extract ten features, including the type of the edge (i.e., intra-site or inter-site), the numbers of incoming and outgo-ing links of both the source and the destination nodes of the edge (four features in total), the URL depth and the URL length of both the source and the destination nodes of the edge (four features in total), and the weight (link number) of the edge. For each node, we extract five features, including the inlink number of the node, the outlink number of the node, the number of two-step neighbors, the URL depth of the node, and the URL length of the node.

We use the notations from [26] (that generalized the model from [5]) for the temporal features (see Section 2). Let T be the period which starts from January 1, 2013. Let n 0 ( p ) = 1, if page p is created in period T , otherwise n 0 ( p ) = 0; n ( p ) and n 3 ( p ) are the numbers of links  X  p  X  p and p  X   X  p respectively created in the period T such that at least one of pages p,  X  p is created in the period T ; n 2 ( p ) and n the numbers of links  X  p  X  p and p  X   X  p respectively created in the period T such that pages p ,  X  p are created before the period T . We consider the following temporal weights of nodes and edges.
 Here h = 10, l = 5, where l is the number of nodes X  features, h is the number of edges X  features (see Section 3.1).
We find the optimal values of the parameters for all the methods by minimizing the objective F defined by Equa-tion 23 by the gradient based optimization method (see Sec-tion 4.2 and Section 5.1). For ranking evaluation, a sample of queries issued by the users of the European country under study is selected. For each query, a set of URLs was judged by professional assessors hired by Yandex. When an asses-sor judges a pair &lt; query, URL &gt; , he assigns a label based on both the relevance of the page to the query and the fresh-ness of the page in respect to the query time. The relevance label is selected using a popular graded relevance scale with labels: perfect, excellent, good, fair, bad . The data we use contains  X  126 . 4K query-URL pairs and  X  16 . 7K queries. We select 90% of the queries as our training set used for pa-rameters optimization. We compare the methods in terms of average NDCG metric on the set of the remaining queries. Note that we calculated NDCG on condensed lists of docu-ments, obtained by removing all unjudged documents from the original ranked list, what is the best way to deal with incomplete judgments according to [19]. Our experimental setup is more realistic and industry-relevant than the one used by the authors of SSP, who labeled documents from the test set using binary relevance scale and trained SSP on noisy implicit relevance judgments inferred directly from documents X  click-through counts.
We evaluate the SNP algorithm and the SSP algorithm with the features described in the previous section. Besides, we use PageRank as the common baseline for the both al-gorithms (used as the only baseline for SSP in [7]).
In Table 2 we present the ranking performance in terms of NDCG@3 and NDCG@5.
 Features X  type Iter. Method NDCG@3 @5 SSP Feat. [7] First SNP 0.76522 0.79964 SSP Feat. [7] Last SNP 0.76909 0.80368
The NDCG@3 (@5) gain of the SNP method in compari-son with SSP equals 0 . 8% (0 . 4%) and 0 . 5% (0 . 5%) for tem-poral features and SSP features relatively. This gain cannot be considered as negligeable in the ranking problem under study. Indeed, the NDCG@3 (@5) gain of the SSP method in comparison with PageRank equals 0 . 4% (0 . 8%) for both temporal features and SSP features on our corpus of web pages (see Figure 1, Figure 2). The gain of the SSP method in comparison with PageRank is of the same order (1% for NDCG@3) in [7]. Besides, in [7] the ranking qualities can be overrated, because each document was labeled as  X  X elevant X  or  X  X rrelevant X  while in our study we used 5 relevance labels. Moreover, the algorithm BrowseRank [13], which is based on random walks on a user browsing graph, gives 1 . 6% gain of NDCG@3 in comparison with PageRank (see [13]).

We obtain the p -values of the paired t -tests for differences between SNP and SSP (in all the cases) on the test set of queries. These values are less than 0.005. Thus, we con-clude that SNP outperforms SSP significantly (see the rows corresponding to the last iterations in Table 2).

Originally, PageRank is computed with damping factor  X  = 0 . 15. To demonstrate the importance of tuning the parameters, we make the following experiments. First, we compare performances of the algorithms using temporal fea-tures, which are defined by the obtained optimal values of the parameters, with the algorithms defined by the same vectors of parameters, except for  X  , which we set to 0 . 15 (see Table 2 and Table 3). We can conclude that our learn-ing process makes the value of  X  indeed more optimal for producing scores in terms of NDCG@3,@5 (the algorithms with trained  X  outperforms the above-mentioned modifica-tions statistically significantly). Second, we tune the damp-ing factor  X  in classical PageRank (PR) algorithm and get better scores for PageRank with tuned alpha (PR++) (see Table 3, Figure 1, Figure 2). The trained parameter  X  equals 0 . 9514.
 Table 3: Perform ance of the algorithms SSP and SNP Figure 1: Perform ance for different values of  X  , tempo-Figure 2: Perform ance for different values of  X  , SSP Note that SNP reduces to SSP, if we set  X  1 =  X  2 = 1. We consider the opposite extreme case  X  1 =  X  2 = 0 and learn the remaining parameters. NDCG@3,5 of these  X  X x-treme algorithms X  are shown in Table 4. The ranking scores of all the other algorithms are shown in Figure 1, Figure 2. From the figures, we can see that the maximal values of NDCG@3,@5 over all  X  are greater for SNP in both cases (temporal features and SSP features). Moreover, SNP con-sistently outperforms all the other algorithms with all the considered values of parameter  X  .

Further in this section, we show how SNP algorithm solves the data sparseness problem. We consider only a representa-tive sample of the initial graph to speed up our computations in this part of the experiments. For any query q , let H ( q ) be the set of hosts containing at least one page p such that pair ( q, p ) is assigned with a relevance label. Let L ( q ) be the number of inner links in the hosts from H ( q ). We choose the set of queries X which consists of 12% of queries q with the smallest values of | L ( q ) | . We include all pages from the set S into our sample of the initial full graph.

We obtain  X  0 . 11B pages (4 . 4% of the number of vertices in the full graph) and  X  2 . 1B links (9 . 9% of the number of edges in the full graph) in our sample. The training set con-tains 8327 pairs &lt; query,URL &gt; and 1990 queries. The test set contains 726 pairs &lt; query,URL &gt; and 187 queries. We simulate sparseness in the data by sampling, for each tempo-ral feature, r % of pages, r  X  { 10 , 25 , 50 , 90 } , and removing the values of this feature for the sampled pages from the data set. On the obtained graph we compute SNP and SSP and show that sparseness of the data affects SSP stronger than SNP (see Figure 3).

We also compare SNP with its modifications which do not wait for convergence while smoothing the weights of vertices and edges. In other words, we consider variations of the algo-rithm from Table 1 that produce b s iterations of step 4, where b s is a small number. After b s iterations, we output the values of G 1 and G 2 by the equations of step 5. Note that, if we put b s = 0 and initialize G 1 0 ( i ) = F 1 1 ( i ) P on st ep 3, we obtain usual SSP. We try to show how the value of b s influences the performance of SNP on the sparse data set. Our intuition is that the more iterations we make, the more stable result we get. In total, we compare four methods, SSP ( b s = 0), SNP1 ( b s = 1), SNP2 ( b s = 2) and SNP. In Figure 3 we present the dynamics of their ranking performances. The learning algorithm for the parameters of the algorithms SNP1 and SNP2 is similar with the al-gorithm for SNP. We consider the same objective function and the same settings for the gradient descent method (see Section 5.1). The derivatives are evaluated by the algorithm from Table 1 with the following distinction. We go to the step 4 only once for SNP1 and twice for SNP2. As SNP is more stable than SSP, SNP1 and SNP2, these results justify the importance of convergence of SNP algorithm.
In this paper we introduce a new general graph-based ranking model, which is defined by a random walk conducted by weights of nodes and edges, which are in turn defined by random walks defined by nodes X  and edge X  X  features, and an efficient algorithm of tuning the parameters of that model. Our experimental results show that the algorithm outper-forms the state-of-the-art algorithm SSP, which is based on a mu ch simpler method of weighting nodes and edges using their features.

It would be interesting to continue to study the properties of our algorithm and its applicability. We plan to investi-gate the following cases. First, we will make experiments with other kinds of data (i.e. exploiting Continuous-Time Markov Processes), other types of graphs (e.g., a graph made of browsing trails of users), other sets of features, which de-fine the weights of nodes and edges. Second, we are going to seek for the ways to improve the speed of convergence of the gradient descent method applied for the objective function we use. Third, we plan to determine in more detail, how the numbers of iterations in the process of computing the weights influence the ranking scores and the performance (in terms of the objective function or some metrics).
From Lemma 1, functions  X  j ( i ) are differentiable with re-be an arbitrary number. As P n i =1 f (  X , i ) = 1, there exists i such that f (  X , i ) &gt; 0. Thus there exists  X  &gt; 0 and a column i of the matrix A T such that a i and any  X   X  (  X , 1). Therefore, convergence  X  j  X   X  is uni-form for  X   X  (  X , 1) (see [16]), and, moreover, there exists number  X   X  (0 , 1) such that for rather large j inequality |  X   X   X  j | &lt;  X  j holds.

Set  X  j =  X  X   X  X   X   X  X  j  X  X  . Fro m Equation 18 and Equation 13, that can be rewritten as  X  X   X  X  =  X  X   X  X   X  + A  X  X   X  X  , we g et
Let  X  be any positive number and a  X  be the largest abso-lute value of elements of  X  X   X  X  . Then there exists j 0  X  that an absolute value of each element of  X  j +1  X  A X  j is less than a  X   X  j for all j &gt; j 0 . As  X  j + k  X  A k  X  j =  X  A, A 2 , A 3 , . . . are stochastic, an absolute value of each ele- X 
Note that, for any n -dimensional vector  X  such that sum of its elements equals 0, we have lim is the maximal absolute value of elements of  X  , then the dif-ference of n -dimensional vector (1 /n, . . . , 1 /n ) T and  X /n X  some distribution. Therefore, lim j  X  X  X  A j ((1 /n, . . . , 1 /n )  X /n X   X  ) =  X  . Moreover, lim j  X  X  X  A j (1 /n, . . . , 1 /n ) lim j  X  X  X  A j  X  = 0. Therefore, there exists k 0 such that, for any k &gt; k 0 , any element of A k  X  j is less than  X / 2. Finally, for any s &gt; k 0 + j 0 , any element of  X  j is less than  X  . So, we get lim j  X  X  X   X  j = 0. Thus, convergence lim j  X  X  X   X  X  j  X  X  = pro ved.

Similarly, there exists i 0  X  { 1 , . . . , n } such that F and, hence, for some  X  &gt; 0 and any  X  1  X  (  X , 1), inequality f (  X , i 0 ) &gt;  X  X  holds. Thus, for fixed  X   X  (0 , 1), the following property of the i 0 -th column of A T holds: a i convergence lim from the uniform convergence  X  j  X   X  with rate  X  j for  X  1 (  X , 1).

Convergence lim as convergence lim
