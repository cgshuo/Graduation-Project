 Robustness analysis research has shown that conventional memory-based recommender systems are very susceptible to malicious profile-injection attacks. A number of attack models have been proposed and studied and recent work has suggested that model-based collaborative filtering (CF) algorithms have greater robustness against these attacks. Moreover, to combat such attacks, several attack detection algorithms have been proposed. One that has shown high detection accuracy is based on using principal component analysis (PCA) to cluster attack profiles on the basis that such profiles are highly correlated. In this paper, we ar-gue that the robustness observed in model-based algorithms is due to the fact that the proposed attacks have not tar-geted the specific vulnerabilities of these algorithms. We discuss how an effective attack targeting model-based algo-rithms that employ profile clustering can be designed. It transpires that the attack profiles employed in this attack, exhibit low rather than high pair-wise similarities and can easily be obfuscated to avoid PCA-based detection, while remaining effective.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  collaborative filtering, robustness ; G.3 [ Probability and Statistics ]: Robust regression Performance, Security
The robustness of recommendation algorithms has been studied for several years, in the context of profile injection or shilling attacks [14, 7]. In such attacks, malicious end-users, motivated to modify the recommendation output of the sys-tem, create false user profiles (sometimes called sybils), to distort the recommendation process. As an example of such an attack, a vendor, motivated to promote the ratings of a product in order to boost its sales, might create a set of false profiles that rate the product highly (a so-called push attack [14]). Alternatively, a competitor might be motivated to de-mote the product rating (a so-called nuke attack). A num-ber of different attack strategies have been studied and they have been categorized in [11] into several different types. Among these, the average attack has been found empiri-cally to be the most effective and this has been supported with an analytical argument in [8]. However, most anal-yses have been carried out on k -nearest neighbour (kNN) memory-based algorithms and the attack models have been proposed with these recommendation algorithms in mind. It is not particularly surprising therefore that an empirical analysis of these attacks applied to model-based algorithms [11, 6] shows that they are significantly less effective in this context. It is argued that the data abstraction component of model-based algorithms ameliorates the effect of attack profiles. Indeed, as shown in [8], the common model-based strategy of clustering can be effectively applied to attack detection, exploiting the fact that attack profiles tend to be highly correlated. This has led to the development of an unsupervised PCA-based detection technique that shows great accuracy in finding the malicious profiles of an average attack.

Clearly the key assumption that the above methods de-pend on is that there are high similarities among malicious attack profiles. To be more precise, the PCA-based detec-tion strategy depends on the covariance of attack profiles be-ing clearly distinguishable from that of genuine profiles. In this paper, we will show that it is possible to create effective attacks in which the pair-wise similarities between attack profiles are low, rather than high and we will demonstrate that further obfuscation can make them indistinguishable by covariance from genuine profiles. Defining diversity as the pair-wise dissimilarity of the profiles in the attack set, we will in fact show that it is possible to design effective attacks of maximum diversity . Every malicious user profile is as dissimilar as possible from the others, while simultaneously maintaining high correlation with genuine user profiles. As we will show, these attacks present a new vulnerability for model-based algorithms that has not been considered in pre-vious work. The contributions of this paper are summarised as follows: Sets are represented by uppercase calligraphic letters such as C and R . Vectors are represented by bold lowercase letters such as x . Rating databases are represented by matrices R, in which the rows consist of user profiles, such that if R is m  X  n then there are m users, who have rated over a product set of n items. Let the full set of items be denoted by I . For every rating matrix user profiles are represented by the corresponding lowercase letter. For example, for rating matrix R, we represent the u th user profile in R as the vector r . We represent the i th item profile (i.e. the set of all ratings for a particular item) as r 0 i . A particular rating of user u for item i is r u,i . Given a set K of items, we represent a user profile restricted to these items as r u, K . The mean of user profile r u over all rated items is written as r u generally, given some item-set K , we write r u, K to be the mean over all rated items in K . Typically, K will be items rated by each of two users. With an abuse of notation, we will write r u  X  r v to be the items rated by both user u and user v . We will use r u,i =  X  to represent a null rating, i.e. that the user-item pair ( u, i ) has no rating in the database.
The possibility of biasing a recommender system X  X  rating output by the creation of false profiles was first raised in [14]. Since then, a classification of such profile injection attacks has been proposed in [2] and the effectiveness of such attacks has been evaluated on both memory-based and model-based recommendation algorithms [11, 6]. The five general attack strategies proposed in [11] are sampling attacks, random at-tacks, average attacks, bandwagon attacks and segment at-tacks. In practice, an average attack is much more effective than a random attack. The bandwagon attack is nearly as effective as the average attack. Random, average, and bandwagon attack do not work well against item-based col-laborative filtering. Elementary obfuscation strategies and their effect on detection precision are discussed in [18]. Both [16, 2] also highlight the relation between domain knowledge and the effects of attacks.

Early shilling detection strategies focus on supervised clas-sification algorithms, using various feature-extraction tech-niques [4, 12, 15, 3]. An unsupervised PCA-based approach proposed in [8, 10] yields very high precision (over 90%) when applied to the detection of average attacks. The strat-egy is to form the covariance matrix of the rating database, which, under attack, includes both genuine and attack pro-files. The principal components of the covariance matrix are
We use term attacker to denote a malicious user profile. identified through PCA and used for variable selection . In this context, variables correspond to users. The technique essentially clusters the database into two groups of users, such that the pair-wise covariance of users in one group is distinguishable from the pair-wise covariance of users in the other. The cluster corresponding to users with highest pair-wise (Pearson) correlation is selected as the cluster of attack profiles.

In model-based CF algorithms, a theoretical model is pro-posed of user rating behavior. Rather than use the raw rating data directly in making predictions, instead the pa-rameters of the model are estimated from the available rat-ing data and the fitted model is used to make predictions. Many model-based CF algorithms have been studied over the last ten years. For example, [1] discusses two probabilis-tic models, namely, clustering and Bayesian networks. In [13], four partitioning-based clustering algorithms are used to make predictions, leading to better scalability and accu-racy in comparison to random partitioning. The probabilis-tic latent semantic analysis (PLSA) algorithm is introduced to CF recommendation in [5]. Its main idea is to employ la-tent class variables to learn users X  communities and valuable profiles and then make predictions based on them.
In this paper, we will focus on model-based algorithms that use clustering to group users into  X  X egments X  of similar users. Ratings are then formed by matching the active user, who is seeking a rating, to the most similar segments. We use the k -means algorithm for clustering and the algorithm is discussed in detail in the next section.
In [11], a model-based CF algorithm is proposed that clus-ters users-profiles into a set of k clusters or  X  X egments X . Once segments are identified, a representative profile is calculated for each segment, as the average of the profiles assigned to the segment. For a given active user and item, a predicted rating is made for the item in the following steps: 1. a set of neighbours, D , is identified as a fixed number 2. a prediction is made using the standard kNN formula We apply k -means clustering to identify the segments. k -means is a clustering method that has found wide appli-cation in data mining, statistics and machine learning. The input to k -means is the pair-wise distance between the items to be clustered, where the distance means the dissimilarity of the items. The number of clusters, k is also an input parameter. It is an iterative algorithm and starts with a random partitioning of the items into k clusters. Each iter-ation, the centroids of the clusters are computed and each item is reassigned to the cluster whose centroid is closest. The algorithm is described in detail below: Figure 1: Users distribution of k-Means CF against Random Attack
Algorithm 1. k -means clustering. 2 1. Input: R = 2. Function kmeans(R , k) 3. c i = r p i ,  X  r p i  X  R ,  X  c i  X  C ,  X  i = 1 , . . . , k ; 4. While ( k C 0  X  C k6 = 0) 5. C 0 = C; 7. c i = 8. End While 9. return C 0 .
According to the empirical analysis in [9], effective attack-ers always work together and are highly correlated. There-fore, examining the full set of attackers, high internal simi-larity, or low diversity, is a common feature in all of attack types up to now. We focus in particular on two standard at-tacks that have been described in [2] and labelled as random attacks and average attacks.

In random attacks and average attacks, the ratings of each attacker are divided into the target item  X  that is, the item to be pushed or nuked  X  and the other items that also re-ceive ratings in the attack profile, which are referred to as filler items. If it is a push action, target items are usually given the highest rating. Both random and average attacks use the Gaussian distribution ( N (  X ,  X  2 )) to generate the rat-ings for the filler items. However, they differ in the selection of the mean,  X  . For random attacks,  X  is the global mean of the overall ratings, and for average attacks, the mean differs
User p i is randomly selected from the rating database R and i = 1 , . . . , k . k C 0  X  C k is the largest singular value of C  X  C. c i  X  C means matrix C includes vector c i . Figure 2: Users distribution of k-Means CF against Average Attack for each chosen item and is calculated as the mean across all users that rated the item. Figure 1 and 2 show that at-tackers based on both attack types are clustered together in the k-means CF algorithm. Thus the effect of attackers are limited into a small subset of users. This explains why average attacks do not work well in the k-means algorithm compared with in kNN. We give the formal definitions of random attacks and average attacks below. Note that in defining attacks we consider the attack profile before inser-tion of the target attack rating i.e. we are concerned about the values of the filler items, rather than the target item. Definition 1. Random Attack: Definition 2. Average Attack:
From above definitions, we see that cohesion is the main reason that low diversity attacks are exposed to model-based CF algorithms and PCA-based detection. In this section, we present how to get rid of this characteristic and still keep the high efficient on rating shilling by constructing attackers based on random attacks and average attacks.

The Pearson correlation is the most popularly used simi-larity formula in recommender systems. The similarity be-tween user u and v can be calculated as follows: where K = r u  X  r v . s u,v  X  [  X  1 , 1] with  X  1 indicating maxi-mum dissimilarity and 1 indicating maximum similarity. Figure 3: Pearson similarity of high diversity at-tacks: a database of 100 genuine users and 20 at-tackers (labelled 101 to 120). Figure 4: Users distribution of k-Means CF against High Diversity Random Attack, d = 5 User1 4 3 4  X  3 User2 5 5 1 4 1 User3 1 5 2 5 4 User4 3 5 4 4 1 User5  X  5 5 4  X  Table 2: Pearson-based similarity matrix of Table 1 User1 1 0 -0.9487 0.169 0 User2 0 1 0.1074 0.5309 -0.2774 User3 -0.9487 0.1074 1 0.1996 -0.5 User4 0.169 0.5309 0.1996 1 0.5 User5 0 -0.2774 -0.5 0.5 1
From this formula, it is easy to find that Pearson-based similarity is not a transitive relation. That is, if user a is highly similar to user b and c respectively, it doesn X  X  mean there is definitely high similarity between b and c . In Table 1 and 2, we can see the similarities of user 4 to user 2 and user 5 are 0.5309 and 0.5. However, the similarity between user 4 and 2 is only -0.2774.

With this observation, it is possible to find a basis set of attackers B with high diversity satisfying the following: Definition 3. We define a set of profiles B satisfying as a basis for a high diversity attack. We refer to the size, d of B as the degree of the basis.

That is, each pair of attackers shares some items in com-mon, but no three attackers share items in common.
In practice, B is not a full set of actual attackers, but acts as a generating set for larger attacks. Initially we construct a basis set B of d maximally diverse attackers. The remaining attackers are modified copies of b i for some i = 1 . . . d . The following algorithm describes how to construct a basis, given a set of n  X  d attack profiles, A.

Algorithm 2. Basis Generation 3 1. Input: A = 2. Function genDissimilarAttackers(A) 3. b 1 = a 1 ; 4. For  X  a i  X  A  X  X  a 1 } 5. If a i  X  b j 6 =  X  X  X  b j  X  B and a i  X  b j  X  b t =  X  X  X  b 8. B = 9. End If 10. End For 11. return B
Algorithm 2 can be used to convert a set of standard ran-dom or average attacks A into a high diversity basis B. Thus, random attacks can be upgraded to high diversity random attack and average attacks can be upgraded to high diversity average attacks. As demonstrated below, these new attacks maintain the essential characteristics of their standard coun-terparts and so we can expect at least the same performance from them.
A  X  X  a 1 } means the matrix which is A with vector a 1 re-moved.
Theorem 1. A high diversity random attack B is a stan-dard random attack with a modified variance, that is:
Proof. Theorem 2. s u,v =  X  1 ,  X  b u , b v  X  B (Definition 3).
Proof.
Theorem 2 shows that there is very low cohesion among high diversity attackers. This point is illustrated in Fig-ures 3. Figure 4 and 5 demonstrate that high diversity random attackers and high diversity average attackers are clustered into different clusters when applying the k -means CF algorithm. This implies that there is greater potential to spread their influence across the database. We will show that this potential is realised in Section 7.
The possibility of obfuscating attacks has been considered previously in [18] where three different obfuscation strategies were proposed. These strategies represent ad hoc deviations from the standard attack models that an attacker might em-ploy in order to avoid detection. No guiding principle is em-ployed in the design of these obfuscations. Attack detection is possible only because attack profiles are statistically dif-ferent to genuine profiles. An effective obfuscation strategy will therefore try to minimise these statistical differences. Indeed the PCA-based detection algorithm relies on finding differences in the covariance of attack profiles and the covari-ance of genuine profiles. An obfuscated attack that can avoid PCA-based detection should try to minimise the differences between these covariances. In fact the raw high diversity attack strategies are detectable by PCA because of their generally lower pairwise similarity in comparison to genuine profiles. These differences can be reduced by the addition of extra filler items, designed to increase the covariance of Figure 5: Users distribution of k-Means CF against High Diversity Average Attack, d = 5 Figure 6: Obfuscated high diversity attacks: 100 genuine users and 20 attackers are used in this case with Pearson similarity. the attack profiles, without significantly reducing their ef-fectiveness. The strategy we employ is to add addition filler ratings in the most unpopular items, setting some of these filler ratings to 5 (the maximum rating) and others to 1 (the minimum rating). We will demonstrate in Section 7 that this simple strategy renders the attackers undetectable by the PCA method. Figure 6 depicts the Pearson-based sim-ilarities among genuine users and obfuscated high diversity attackers.
In order to examine the performance of high diversity attack, six attacks are selected to test. H-Random attack means high diversity random attack. H-Average attack means high diversity average attack. OH-Average attack means ob-fuscated high diversity average attack. Random and aver-age attacks are designed according to [2]. R-Average attack means attackers of this type are generated from real users Figure 7: High Rating Ratio(HRR): Attacks vs. k-Means CF, d/attacksize = 50% profiles. Theoretically speaking, it should be the hardest de-tectable attacks but not the most effective attacks. We use it as a standard to measure other attacks on detectability.
There have already been several metrics to evaluate mali-cious attacks. [14] first introduces the prediction shift (PS) metric, which measures the effectiveness of an attack by the difference between predictions before and after the attack. However, just as [11] mentioned, a strong prediction shifts does not always mean an effective attack result. For ex-ample, a PS is 1.5, whether it is from 1 to 2.5 or from 3 to 4.5. Obviously, the former doesn X  X  mean that the rec-ommendation results are affected much by attacks. A sim-ilar weakness exists with mean absolute error (MAE) shift, which is used in [10] to evaluate the robustness of the CF algorithms. MAE is widely used to evaluate the accuracy of the recommender systems. Still, its shift is not appropriate for evaluation of the effectiveness of the attacks. In [11], the Hit ratio is employed to measure the effectiveness on top-N recommendation systems, by examining the shift in the proportion of times that an item appears in the top-N list.
We introduce a new metric to evaluate the attack: high rating ratio (HRR), which shows how much predictions are pushed to high values for an attacked item.
 where i is the attack item,  X  is the given rating threshold, and U  X  R is a subset of users for which predictions are made. In practice, we find it is good measure of the ef-fectiveness of a push attack. For the Movielens dataset, in whic ratings are in the range from 1 to 5, we use  X  = 4 in all related experiments. Figure 8: High Rating Ratio(HRR): Attacks vs. k-NN CF, d/attacksize = 50%
Many evaluation metrics have been used in the literature to compare detection strategies. For example [8] uses detec-tion precision , defined as the number of attack profiles that are correctly identified as attack as a fraction of the total number of profiles identified as attack; and recall , number of attack profiles that are correctly identified as attack as a fraction of the total number of attack profiles. In [2], speci-ficity  X  the fraction of genuine profiles correctly identified  X  is also reported. The PCA-based detection algorithm re-quires the size of the attack cluster as an input parameter and these performance measures depend on the value of that parameter. As this is a binary classification problem, the full ability of the detection problem can be better understood by computing a receiver operating characteristic (ROC) curve. Varying the size of the attack cluster from zero to the total database size, we can compute for each value, the proba-bility of good detection (PGD) (the fraction attack profiles correctly classified) and the probability of false alarm (the fraction of genuine profiles incorrectly classified). The ROC curve plots PGD against PFA. A perfect detection algorithm has PGD=1 for all values of PFA. A detection algorithm that is no better than random classification results in a diagonal ROC curve.
The larger data set of MovieLens is adopted in our exper-iments, which consists of approximately 1 million ratings for 3952 movies by 6040 users. Movies are rated on a scale of one to five. From this dataset, we extract a series of sub-sets to conduct our tests. Each of them consists of 1220 items. The average sparsity of the selected rating matrices is 10.31%.
To evaluate the attack, we take the following approach. A subset of 200 users is extracted from the Movielens dataset along with 1220 items, which were rated by three or more users. The dataset is divided randomly in a 50:50 ratio into training and test sets, consisting of 100 users each. An item is selected at random on which to apply a push attack. Pre-Figure 9: High Rating Ratio(HRR): Attacks vs. k-Means CF with varied diversities Figure 10: ROC Curve: Attacks vs. PCA Detection Figure 11: ROC Curve: OH-Average Attacks vs.
 PCA Detection dictions are made for the attack item for users in the test set. False profiles are then injected into the training set. Predictions are made for the users in the test set and the prediction shift over all users in the test set is calculated. The process of profile injection and prediction shift calcu-lation is repeated 50 times. The average of the 50  X  100 prediction shifts is calculated as the attack performance.
We evaluate the results based on two parameters: attack size and diversity size. Attack size means the percentage of the number of attack profiles against the size of the pre-attack training set. Diversity size is the percentage of basis set size against the total number of attackers. For all tests we select 10% as filler size, from 5% to 25% as attack size, and from 10% to 100% as diversity size.

For both kNN and k-means, we apply 10 as the neigh-borhood size. For k-means, k = 10 is being used for user segments generation. In all cases, neighbors are filtered with a similarity value less than 0.1.

Figure 7 depicts HRR for random attack, H-Random at-tack, average attack and H-Average attack on k-means using attack size 5%, 10%, 15%, 20% and 25%. Apparently, H-Average attack and H-Random attack are much better than the other two. k-Means shows its stability against random attack and average attack. However, it is vulnerable against high diversity attacks. Especially when at 25% attack size, for H-average attack, the value of HRR nearly increases to 2.5 times before the attack on users who gave rating 4 for the target item. This means, for example, if 100 users like the item before the attack, then after the attack, there are 250 users like it.

Figure 8 shows HRR for attacks on kNN with the same parameters setting in Figure 7. This figure validates the result of Theorem 1. We can see that the differences among four attacks are not very large. From 5% to 15%, H-Average outperforms other attacks, however it goes down after 15%. The same situation occurs on H-Random attack which goes down after 20%. This may be because kNN doesn X  X  rely on maximization of the sum of the total similarities. At 25% attack size, average attack also nearly reach 2.5 on HRR. This proves that high diversity attacks make k-means as vulnerable as kNN.

In Figure 9, our results show that 50% diversity could be the optimal setting for high diversity attacks. From 50% to either smaller or greater percentages, the values of HRR both goes down.

The dataset on detectability experiments is a little differ-ent with above ones. In this case, 2000 genuine users and 400 attackers are being used. We also evaluate the perfor-mance against the filler size, that is, the percentage of rated items in the attack profile. The ROC curves of high diversity attacks against PCA-based detection are presented in Fig-ure 10 and 11. In Figure 10, H-Average attack is as easily detectable as low diversity attacks. However OH-Average attack shows the same level ROC curve as R-Average at-tack, which means the former is almost as undetectable as a real user in front of PCA-based detection. Figure 11 shows detectability for different filler sizes.
Recent studies have suggested two powerful ways to de-fend against profile injection attacks. One uses model-based CF algorithms, which are seen to be more robust than memory-based algorithms against the attack types proposed to date. The other employs PCA-based detection to eliminate the majority of malicious users before making accurate predic-tions. The obfuscated high-diversity attacks that we develop in this paper pose questions for these studies. They are both undetectable by PCA-based detection and highly effective against the k-means CF algorithm. This is because the at-tack profiles are designed to distribute into the k clusters evenly. Although raw high diversity attacks still keep a very low covariance between attackers, so that PCA-based detec-tion can identify them, obfuscated techniques are capable of being applied to fillers items to mix the covariance, and finally make covariance-based detection ineffective. There-fore, it is wrong to conclude that model-based algorithms are more robust than memory-based ones and that attack pro-files must be highly correlated to each other. Attackers can design effective algorithms using knowledge of the under-lying recommendation algorithm. We make the point that relying on keeping the recommendation algorithm secret is not a very secure strategy. We have also learned from the at-tackers point-of-view that it is not wise to consider arbitrary attacks, without also considering the detectability of these attacks. The good news from the system designers point-of-view is that it is hard to develop undetectable attacks. The worse news however is that attacks can be designed that are both hard to detect and effective. Thus, in order to resist varied attacks, we should develop related detection schemes for each attack strategy.
 This work is supported by Science Foundation Ireland, grant number 07/RFP/CMSF219. [1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [2] R. Burke, B. Mobasher, and R. Bhaumik. Limited [3] R. D. Burke, B. Mobasher, C. Williams, and [4] P.-A. Chirita, W. Nejdl, and C. Zamfir. Preventing [5] T. Hofmann. Latent semantic models for collaborative [6] R. D. B. Jeff J. Sandvig, Bamshad Mobasher. A [7] S. T. K. Lam and J. Riedl. Shilling recommender [8] B. Mehta. Unsupervised shilling detection for [9] B. Mehta, T. Hofmann, and P. Fankhauser. Lies and [10] B. Mehta, T. Hofmann, and W. Nejdl:. Robust [11] B. Mobasher, R. Burke, and J. Sandvig. Model-based [12] B. Mobasher, R. Burke, C. Williams, and [13] M. O X  X onnor and J. Herlocker. Clustering items for [14] M. O X  X ahony, N. Hurley, N. Kushmerick, and [15] M. P. O X  X ahony, N. J. Hurley, and G. C. M.
 [16] M. P. O X  X ahony, N. J. Hurley, and G. C. M. Silvestre:. [17] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [18] C. Williams, B. Mobasher, R. Burke, J. Sandvig, and
