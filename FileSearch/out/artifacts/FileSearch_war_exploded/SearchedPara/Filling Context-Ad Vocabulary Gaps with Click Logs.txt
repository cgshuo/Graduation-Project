 Contextual advertising is a form of textual advertising usu-ally displayed on third party Web pages. One of the main problems with contextual advertising is determining how to select ads that are relevant to the page content and/or the user information in order to achieve both e ff ective adver-tising and a positive user experience. Typically, the rele-vance of an ad to page content is indicated by a tf-idf score that measures the word overlap between the page and the ad content, so this problem is transformed into a similar-ity search in a vector space. However, such an approach is not useful if the vocabulary used on the page is expected to be di ff erent from that in the ad. There have been studies proposing the use of semantic categories or hidden classes to overcome this problem. With these approaches it is nec-essary to expand the ad retrieval system or build new index to handle the categories or classes, and it is not always easy to maintain the number of categories and classes required for business needs. In this work, we propose a translation method that learns the mapping of the contextual informa-tion to the textual features of ads by using past click data. The contextual information includes the user X  X  demographic information and behavioral information as well as page con-tent information. The proposed method is able to retrieve more preferable ads while maintaining the sparsity of the inverted index and the performance of the ad retrieval sys-tem. In addition, it is easy to implement and there is no need to modify an existing ad retrieval system. We evalu-ated this approach o ffl ine on a data set based on logs from an ad network. Our method achieved better results than ex-isting methods. We also applied our approach with a real ad serving system and compared the online performance using A/B testing. Our approach achieved an improvement over the existing production system.
 H.3.5 [ Information Storage and Retrieval ]: Online In-formation Services X  Commercial services ; I.2.6 [ Artificial Intelligence ]: Learning Contextual advertising, Learning-to-rank, Click feedback, Modeling. Online advertising is a key component supporting today X  X  Internet ecosystem and is growing into a multi-billion dol-lar industry. Many di ff erent types of advertising are used: sponsored search advertising, contextual advertising, display advertising, real-time bidding auctions, and more [28]. In this paper, we focus on contextual advertising, which con-sists of short text messages that are usually displayed on third party Web pages such as news sites or blogs. The ad-vertiser is primarily interested in targeting relevant users, and the publisher is concerned with keeping the user ex-perience pleasant. To satisfy these two objectives, an ad-networking service selects ads that are relevant to the page content and/or the user information. In this paper, we focus on increasing the click-through rate (CTR), as this metric directly relates to the user experience, publisher revenue, and advertising e ff ectiveness objectives.

The relevance of an ad to page content is typically deter-mined using a tf-idf score that measures the word overlap between the page content and the ad content. This task is therefore regarded as a similarity search using an inverted index. This is an e ff ective technique when the expected word overlap rate is high, but it falters if the vocabulary used on the page is di ff erent from the vocabulary used in the ad. For example, an ad for  X  X IM-free smartphones X  would be related to a Web page comparing of Mobile Virtual Network Oper-ator (MVNO) services, but the word overlap might not be very high. Another example could be an ad for  X  X TC One X  and a page about  X  X ew Nexus 7. X 
Some previous studies have used a semantic taxonomy in the matching function [4] or introduced a page-ad probabil-ity model with hidden classes [21]. However, in these ap-proaches, it is necessary to expand the ad retrieval system or build new index to handle the categories or classes. In addition, a review of the number and hierarchical structure of categories or a re-creation of clusters is periodically re-quired in the operation of the ad serving system, and these tasks are not always easy to perform.

To overcome the above problems, we have developed an approach that calculates a matching score between two term vectors using an inverted index and does not require modi-fication of an ordinary ad retrieval system. In other words, this approach translates ad request information into the tex-tual space of ads. With this translation table, the feature vector of ad requests is transformed into the input term vec-tor of the ad retrieval system. The process is illustrated in Fig. 1.

This translation table will become very large because the two spaces are typically quite large. We can e ffi ciently learn the translation table from past click data with low-rank ap-proximation of the matrix. However, even if the learning can be done e ffi ciently, it is necessary to make the transformed term vector sparse because the performance of the ad re-trieval system gets progressively worse in accordance with the number of nonzero values in the input vector. There-fore, we first select ad features related to each query feature according to our metric based on the past CTR, and then we learn the translation matrix. In other words, we choose a subset of the matrix elements and learn only the weights with past click logs.

We reported an overview of this method and preliminary experimental results in our work-in-progress paper [23]. In the current paper, we describe the details of the improved method and report the extensive evaluations. Our main contributions are as follows.
The rest of this paper is organized as follows. Section 2 provides a general overview of the contextual advertising system. Section 3 presents our method of translating query information into ad term vector space. Section 4 details the experimental setup and results. We conclude our paper in Section 5 by summarizing our findings and making a brief mention of future work.
This section provides a general overview of contextual ad-vertising and related studies.
There are four players in contextual advertising: the pub-lisher, the advertiser, the ad network, and the user. The publisher owns Web pages and reserves some space on these pages for ads. An ad network supplies the ads that an adver-tiser provides. In the common pay-per-click model, which is !"#$%&amp;'(&amp;##)*&amp;%+ ,)*#*-./(&amp;##)*&amp;%+ Figure 1: Typical approach (top) vs. our proposed approach (bottom). Proposed method is a transla-tion of request features into the input term vector of an ad retrieval system. the prevalent pricing model for contextual advertising, the advertiser pays the Web publisher and the ad network a fee only if a user clicks on their advertisement and visits their website. Thus, the expected revenue from displaying each ad is a function of both the bid price and the CTR. The bid price is the cost that the advertiser agrees to pay per click, so the advertising system already knows this. In contrast, the CTR for each ad can vary significantly depending on a variety of factors ranging from the Web page to the user. Consequently, one of the main problems in contextual ad-vertising is determining how to accurately predict CTR and e ffi ciently retrieve ads with a high CTR from an ad corpus.
Some previous works have focused on developing meth-ods to match ads to pages, since ads that are related to the page content are more likely than generic ads to provide a better user experience. That in turn increases the prob-ability of users clicking on the ads. In these studies, the problem of matching ads with pages is transformed into a similarity search in a vector space. The relevance of an ad to page content is indicated by a tf-idf score that measures the word overlap between the page content and the ad con-tent. Chakrabarti et al. [6] and Karimzadehgan et al. [16] introduced methods to learn the weights of each word in a page and an ad using HTML tags and ad sections. They use an inverted index to e ffi ciently retrieve top-K items from ad corpora.

While both pages and ads are mapped to the same space, there is a discrepancy (impedance mismatch) between the vocabulary used in the ads and on the pages. Various ap-proaches have been proposed to overcome this problem. Broder et al. [4] used a 6000-node semantic taxonomy in the match-ing function between pages and ads. In addition, Ratna-] Figure 2: Two-stage approach in the ad serving sys-tem. Ads are retrieved by multiple methods in the first stage. The ads are merged and passed on to the second stage for CTR prediction. parkhi [21] introduced a page-ad probability model in which semantic relationships between page terms and ad terms are modeled with hidden classes. Yih and Jiang [27] proposed an approach to map the original term vectors to a  X  X oncept space X  so that semantically close words would be captured by the same concept. Wang et al. [26] formulated and tack-led the problem of relevance learning for online targeting in heterogeneous social networks. They inferred user inter-ests and ad concepts from heterogeneous sources and links, and developed a user-ad relevance feature based on weighted matching between any pair of concept classes. Murdock et al. [20] applied machine translation techniques to improve the matching between pages and ads.

Joshi et al. [15] presented a method to leverage user in-formation including a user X  X  demographic information (e.g., age, gender, and location) and behavioral information (e.g., the user X  X  recent search history, page visits, and ad clicks) in a content match advertising setting. They mapped the non-textual user features to the textual space of ads.
In the cases where ad relevance cannot easily be gleaned from the page text alone, the  X  X lickable terms X  approach has been proposed [13]. This approach involves matching a Web site directly with a set of ad side terms, independent of the page content.

Another line of research attempts to predict the CTR of ads. These studies are not only related to contextual ad-vertising but also to sponsored search advertising because both typically employ the pay-per-click model. Predictions of CTR for ads are generally based on a statistical model trained by using past click data. Examples of such mod-els include logistic regression [7, 8, 19], probit regression [12], and boosted trees [9, 25]. The accuracy of the model depends greatly on the design of the features. Cheng and Cant X -Paz [7] presented a framework for the personalization of click models. These authors developed user-specific and demographic-based features that reflect the click behavior of individuals and groups. These features are based on obser-vations of the search and click behaviors of a large number of users of a commercial search engine. Other recent works [1, 17, 22] have proposed models to estimate conversion rates (CVR).
Although machine-learned CTR prediction models are more accurate, as described in Section 2.2, evaluating all the items in an ad corpus is too time-consuming if we want to ensure that Web page loads quickly [2]. Our ad serving system therefore adopts a two-stage approach similar to some other studies [2, 6]. The first stage retrieves top-K items from an ad corpus using an inverted index. The second stage selects the desired top-k using brute force CTR prediction on the K retrieved ads ( k  X  K ) . In the first stage, ads are inde-pendently retrieved by multiple methods in parallel. The retrieved ads in the first stage are merged and passed on to the second stage for CTR prediction. Ads are ranked and displayed on the basis of the predicted CTR and the bid price. This process is illustrated in Fig. 2. We refer to the  X  X d retrieval system X  as a part of the first stage and focus on the part. We have used a heavily tuned search engine that employs the WAND algorithm [5, 11, 10].

In this paper, we propose a method to e ffi ciently retrieve ads with high CTR using the search engine without any changes, even building new index. Unlike the method pro-posed by Agarwal and Gurevich [2] or approaches with se-mantic categories [4] or hidden classes [21], our method sim-ply utilize the existing index used by typical similarity search in a vector space.
In this section, we first define the matching function be-tween a query and an ad and then describe our approach to mapping the query information to the textual space of ads. We define a query feature vector as q =( q 1 ,...,q and an ad feature vector as a =( a 1 ,...,a query feature vector of an ad request, which includes Web page and user information. We also define a general form of the matching function for q and a using translation matrix where D dimension of ad feature space.
 Equation (1) is a general form of the matching function. If
D a is the same as D q and W is the identity matrix I , score( q , a ) turns out to be a simple dot product: Of course, the cosine similarity can be calculated if q and a are normalized. Also, in general cases, by multiplying the query feature vector q by the translation matrix W and using q  X  = W T q as an input vector, we calculate the score mscore ( q , a )= q T Wa = q  X  T a with an ordinary inverted index based ad retrieval system.
 When categories or classes are used, translation matrix W is decomposed as: where  X  and K is the number of categories or classes. Here,  X   X  vector q and ad feature vector a into categories or classes vector q is expressed as: where q be viewed as a matrix factorization or low-rank approxima-tion.
As described in Section 1, we need to learn the translation matrix W e ffi ciently and make the transformed term vec-tor sparse for e ffi cient ad retrieval. The translation matrix W can be learned directly with a large hash table and L1 regularization, as Wang et al. did [26]. In this paper, we propose another approach, in which we can directly control the sparseness of the matrix by considering the performance of the ad retrieval system. We first select a subset of the matrix elements and then learn the corresponding w
We calculate the following score m and a where ctr ( q tor includes q include feature a of ads that include feature a includes q feature a ture vector includes q m where T is a thresholding hyper-parameter. The number of non-zero elements in W decreases as a function of T .We use P and replace the matching function (1) as follows. If we perform an ordinary feature selection using mutual information or L1 regularization, we obtain features that lead negative w retrieve top-K ads which have larger mscore ( q , a ) from an ad corpus as described in Section 2.3. We cannot retrieve ads that have higher mscore ( q , a ) even if we use the negative w selecting the features to lead the positive w
We learn the above w proportional to the click-through rate (CTR) for q and a is therefore defined as having the following linear form: where bscore ( q , a ) is a basic score as bscore ( q , a . x ad X  X  own clickability. w ing to x Figure 3: Examples of clicked requests and non-clicked requests. Ticks denote clicked impressions and x X  X  represent non-clicked impressions. as w = " w T catenated vectors. The reason for adding bscore ( q , a ) to mscore ( q , a ) is that the score proportional to CTR consists of not only a matching score between query and ad but also other factors such as the ad X  X  own clickability and display position on the Web page.

As described in Section 2.3, our focus is improving the first stage of the two-staged ad serving system. We learn with click logs instead of simply using m first retrieving top-K ads based on a score approximating the second stage score leads to better top-k results at the second stage.
 We then describe how to utilize click logs to learn weights. In the contextual advertising setting, a Web publisher typ-ically requests some ads simultaneously because more than one ad is displayed on a page at the same time. In other words, one ad request r in the logs includes N ( r ) impressions of ads: Each impression of an ad consists of a tuple ( q ( r ) , a r pression in request r . The output variable y ( r ) clicked the ad and y ( r )
As described in our previous work [24], we focus on a kind of ad request and apply the learning-to-rank approach to learn the weights.
 There are two kinds of ad requests in data R : R clicked impression; hence we refer to R + as clicked re-quests . R  X  is called non-clicked requests since no ad requests in R  X  include clicked impressions. Of course, R R +  X  R  X  and R +  X  R  X  =  X  . Examples of these two kinds of ad request are shown in Fig. 3.

We regard ad impressions in an ad request as documents related to a query in an information retrieval context and apply the learning-to-rank approach to learn the weights. We make pairwise preferences from each clicked request r  X  R This process is illustrated in Fig. 4. ] Figure 4: Making pairwise preferences from clicked requests.

The preference ( a ( r ) tional to the CTR of a ( r ) than that of a ( r ) score ( q , a ) and transform using (2) as follows:
Using the squared hinge loss, we define a pairwise loss function L ( w ) like RankSVM [14], as follows:
L ( w )= We add a regularization term and seek the weight vector  X  that minimizes the following optimization problem: where C  X  0 is a penalty parameter. The translation matrix W is restored from the weight vector  X  w match , where  X  w  X  w
We conducted preliminary experiments using hinge loss and logistic loss in addition to the above squared hinge loss. We decided to use the squared hinge loss as it was found to have a favorable balance between accuracy and training time.
With the learned matrix W , the query feature vector q is transformed into the input term vector of the ad retrieval system for each ad request. Our proposed method only require this transformation. Thus it is easy to implement and maintain because there is no need to modify the existing inverted index or add new index.
This input term vector includes some non-zero values, which are proportional to the number of non-zero values in the query feature vector. However, the performance of the ad retrieval system declines in accordance with the number of non-zero values in the input vector. Therefore, we need to limit the number of these values with hyper-parameter M :  X  q its non-zero elements. We simply choose top-M elements, which have larger values.
This section describes o ffl ine and online evaluations. Due to business confidentiality, we report only relative perfor-mance when showing experimental results.
In this section, we first describe experimental settings such as data sets, features, models, and evaluation metric. Next, we compare our approach with existing methods and present model performances when changing the hyper-parameters T and M .
We compare the models using data sampled from an ad network for a period of eight weeks. Data from the first six weeks are used as a training set, data from the fifth week are used as a validation set, and data from the last week are treated as a testing set. This ad network is for the Japanese a few exceptions.

As described in Section 3.2, each sample of the data sets is an impression of an ad and consists of a tuple ( q ( r ) , a The output variable y ( r ) if not. The query features q ( r ) include Web page and user information. The Web page features are extracted terms. These terms are scored on the basis of their position on the page and HTML tags. Some terms are chosen by the score. The user features are terms and categories in which the user is interested, as well as gender, age, and location. The user X  X  gender falls into three classes: male, female, and unknown. Similarly, the user X  X  age is categorized into thirteen groups. As in the study by Aly et al. [3], these terms and cate-gories are extracted from user behavior events such as page visits, search queries, and ad clicks. These categories are similar to the hierarchical taxonomy in the work of Broder et al. [4]. Number of the categories is about 900. We sim-ply use textual features as the ad features a ( r ) tf-idf weighted terms based on the title and description in this paper. These features are summarized in Table 1.
The basic features x the display position on the Web page and the historical CTR of the ad and advertiser. These features are also summarized in Table 1.

We chose eight diverse Web sites, including news, blogs, question-and-answer, finance, sports, weather, and travel sites. The models we evaluate are constructed with respect to each Web site, since the Web pages and the users that visit them are di ff erent. The data statistics for each Web site are summarized in Table 2. The number of clicked requests $ $ R + $ $ and the average number of impressions per http://promotionalads.yahoo.co.jp/service/ydn/ index.html Table 2: Data statistics for Web sites used in evalu-ation.
 sonal trends, changes in the budget of the advertisers, and actions carried out by publishers to achieve sales targets. # clicks , which is the average number of clicked impressions per clicked request, is approximately 1.
We compared the proposed method with three existing in production methods: existing 1 , 2 , and 3 . Existing 1 utilizes only terms extracted from Web page for ad retrieval and existing 2 and 3 use terms and categories based on user X  X  behavioral events respectively. Please also refer Section 4.1.1 and Table 1.

In the comparison, we use the following score instead of score ( q , a ) in Equation (2): where escore ( q , a ) is a matching score calculated by an ex-isting method. Each existing method has a di ff erent escore
As described in Section 3.3, we need to limit the number of query terms because of the performance of the ad retrieval system. In the experiment, we carried out our evaluation by changing the value of M . Thus, we rewrite the scoring function for the prediction as: where t -mscore ( q , a ) is a matching function using truncated q term vector q ing. This means the same translation matrix W is used. Note that this evaluation does not reflect the actual on-line setting very well when the value of M is limited. We retrieved by t -mscore ( q , a ) from an ad corpus in the ac-tual online setting. Because of bscore ( q , a ) , the order by t -requests in the testing set.

We evaluated the performance of the model by using mean average precision (MAP) [18]: uments for request r , and P ( r ) ranks in the k th position by the predicted score score (
We normalize the scores of the method by a basic model that uses only bscore ( q , a ) during both the training and evaluation. All values of metrics in this paper are trans-formed by Note that this MAP play position included in x
We first evaluated our approach when changing the thresh-olding hyper-parameter T . As described in Section 3.2, the number of non-zero elements in W decreases as a function of
T . This means that model performance is expected to improve with decreasing T . In this setting, M is not lim-ited during the evaluation. The experimental results are summarized in Table 3. The bold elements indicate the best performance of the methods. Our proposed method achieved an improvement over the existing methods. As ex-pected, MAPs are improved with decreasing T .ForWeb sites B and H, which has a lot of training data,  X  MAP is larger than other Web sites and the impact of changes in T is relatively small. For Web site A, the MAPs of existing 1 are higher than the scores when T =0 . 20 and 0 . 15 . The impact of changes in T is large. This result indicates that the model trained with more data achieves larger and robust improvement. In comparing the existing methods, there are strong and weak points for each Web site. Existing 1 was superior to the other two methods for Web sites A, E, and F. Conversely, existing 2 achieved better results for Web sites B, C, D, G, and H. What this means is that the importance of the features used to retrieve ads is significantly di ff erent depending on the Web site. In contrast with these exist-ing methods, our proposed method uses both Web page and user information for ad retrieval, which is why it had the better results.

Next, we investigated the model performance of each T when changing M . As described in Section 4.1.2, we change M and truncate the query term vector q input during the evaluation, not during the training. The experimental re-sults are shown in Fig. 5. As expected, the MAPs decay in response to a decrease of M . One might think that our pro-posed method is quite a bit worse than the basic model in situations where the  X  MAP is a negative value, such as T 0 . 05 and M =50 on Web site H. However, such o ffl ine eval-uation results do not reflect the actual online performance very well because of the di ff erence between t -score ( t -mscore ( q , a ) , as described in Section 4.1.2. In the next section, the comparison of the existing methods and our proposed method when M is limited is carried over to the online evaluation. Here, we claim that M is first determined by the performance of the ad retrieval system and that T then needs to be tuned for each Web site in a real ad serving setting.

Tables 4 and 5 are examples of the mapping tables used on Web site B for user terms and categories, respectively. As expected, user terms are translated into the same term and related terms. In addition, the weight of the same term is larger than that of related terms in almost all cases. Sim-ilarly, user categories are translated into related terms.
The data sets used in the o ffl ine evaluation are based on past click data, which are results of ad serving by an existing system. Therefore, the results of o ffl ine evaluation might not reflect actual online performance because ads retrieved by our approach in the online setting are possibly di ff erent from those in the logs.

To measure the online performance, we applied our ap-proach to a real ad serving system. This ad serving system adopts a two-stage approach, as described in Section 2.3 and shown in Fig. 2. We added the proposed method to the first stage and compared the online performance by conducting A/B testing. Hyper-parameters are set as ( T =0 . 20 ,M = 20) . For a fair comparison, the total number of ads retrieved in the first stage is set to be the same because CTR can be higher even if the number of ads just increases. The CTR prediction model used for each version in the second stage was also the same. This prediction model was a statistical model trained by using the past click data [24]. We ran the online test over 1-week period in November 2013 for each Web site.

We use three metrics for the online test: CTR, cost per click (CPC), and revenue per request (RPR). These metrics are defined as follows: where | R | denotes the number of ad requests. Revenue is the total amount of the fee that advertisers paid.
The experimental results are summarized in Table 6. These percentages also represent the relative gain. The CTR was improved for all Web sites expect site A. We simply set hyper-parameter as ( T =0 . 20 ,M =20) for all Web sites although the result of T =0 . 20 is worse than the result of existing 1 and 2 on Web site A in Table 3. Thus, this result is reasonable and indicates that hyper-parameters need to be tuned for each Web site. For Web sites B and H, which has a lot of training data, the improvement of CTR is larger than other Web sites as well as o ffl ine test. We performed chi-squared test on the CTR results. The results of the Web sites A, B, D, E, and H are statistically significant at the 5% level (p-value &lt; 0.05). The RPR was also improved for all Web sites expect A, whereas the CPC was decreased for Web sites B, E, G, and H. This drop in CPC is usually favored by the advertisers. In this online testing, ads were ranked and displayed by considering revenues. Ads retrieved by our pro-posed method had a high CTR and relatively low bid price, which is why the Web sites had the result. As described in Section 1, we focus on increasing CTR in this paper. Conse-quently, our proposed method improve revenue. This result indicates that our proposed method achieved an improve-ment in the online setting as well as the o ffl ine setting.
Contextual advertising is a form of textual advertising usually displayed on third party Web pages. Because of the need to achieve both e ff ective advertising and a positive user experience, one of the main problems with contextual advertising is determining how to select ads that are rele-vant to the page content and/or the user information. In this paper, we introduced a translation method that learns a mapping of contextual information to the textual features of ads. The contextual information includes the user X  X  de-mographic and behavioral information as well as Web page content information. Our proposed method only require the transformation of the context feature vector with a learned matrix into the input vector of the ad retrieval system. So it is easy to implement and there is no need to modify the existing inverted index or add new index. We evaluated this approach o ffl ine on a real-world data set from an ad network and obtained better results compared to existing methods. We also applied our approach with a real ad serving sys-tem and achieved improvement over the existing production system. methods.
 Web site
Our future work will take three directions. First, we want to study the use of various types of context features such as ad request time and weather. Second, we plan to investigate sophisticated regularization term in objective function for making the weight matrix sparse. Finally, distributed online learning of the translation matrix is an interesting challenge that we wish to explore.
We would like to thank our colleagues for their assistance with data collection, model evaluation, and many insightful discussions. [1] D. Agarwal, R. Agrawal, R. Khanna, and N. Kota. (case) 0.1534 (Toyota Purius) 0.2600 (mileage) 0.0732 (dentistry) 0.3297 (dentist) 0.1892 (pores) 0.2319 (face washing) 0.1001 (cosmetics) 0.0663 (hot spring) 0.1730 (Japanese inn) 0.1272 (outdoor hot spring) 0.0809 (car navigation system) 0.1229 (Toyota) 0.0906 (Honda) 0.0720  X  X  X  X  X  (Toyota Crown) 0.2605  X  X  X  X  X  X  X  X  X  X  (Toyota Prius) 0.2171  X  X  X  X  X  (Toyota Land Cruiser) 0.2053  X  X  (blood pressure) 0.1784  X  X  X  (high blood pressure) 0.1196  X  X  X  X  (diet) 0.0531  X  X  (overseas) 0.1181  X  X  X  X  X  X  X  (Europe) 0.1168  X  X  X  X  X  (foreign travel) 0.0868  X  X  X  (marriage hunting) 0.1100  X  X  X  X  (matchmaking) 0.0742  X  X  X  X  X  (couple) 0.0546  X  X  X  X  X  X  X  X  X  (wedding) 0.1398  X  X  X  (engagement) 0.1391  X  X  X  X  (dress) 0.1024 [2] D. Agarwal and M. Gurevich. Fast top-k retrieval for [3] M. Aly, A. Hatch, V. Josifovski, and V. K. Narayanan. [4] A. Broder, M. Fontoura, V. Josifovski, and L. Riedel. [5] A. Z. Broder, D. Carmel, M. Herscovici, A. So ff er, and [6] D. Chakrabarti, D. Agarwal, and V. Josifovski. [7] H. Cheng and E. Cant X -Paz. Personalized click [8] H. Cheng, R. van Zwol, J. Azimi, E. Manavoglu, [9] K. S. Dave and V. Varma. Learning the click-through *:p-value&lt;0.05,**:p-value&lt;0.01,***:p-value&lt;0.001 Website [10] S. Ding and T. Suel. Faster top-k document retrieval [11] M. Fontoura, V. Josifovski, J. Liu, S. Venkatesan, [12] T. Graepel, J. Q. Candela, T. Borchert, and [13] A. Hatch, A. Bagherjeiran, and A. Ratnaparkhi. [14] T. Joachims. Optimizing search engines using [15] A. Joshi, A. Bagherjeiran, and A. Ratnaparkhi. User [16] M. Karimzadehgan, W. Li, R. Zhang, and J. Mao. A [17] K.-C. Lee, B. Orten, A. Dasdan, and W. Li.
 [18] C. D. Manning, P. Raghavan, and H. Schtze.
 [19] H. B. McMahan, G. Holt, D. Sculley, M. Young, [20] V. Murdock, M. Ciaramita, and V. Plachouras. A [21] A. Ratnaparkhi. A hidden class page-ad probability [22] R. Rosales, H. Cheng, and E. Manavoglu. Post-click [23] Y. Tagami, T. Hotta, Y. Tanaka, S. Ono, [24] Y. Tagami, S. Ono, K. Yamamoto, K. Tsukamoto, and [25] I. Trofimov, A. Kornetova, and V. Topinskiy. Using [26] C. Wang, R. Raina, D. Fong, D. Zhou, J. Han, and [27] W.-t. Yih and N. Jiang. Similarity models for ad [28] S. Yuan, A. Z. Abidin, M. Sloan, and J. Wang.
