 Since th e beginning of the new millennium, there has been a growing need in the medical community for Natural Language Processing (NLP) technol o-gy to provide computable information from narr a-tive text and enable improved data quality and d e-cision -making. Many NLP researchers working with clinical text (i.e. documents in the electronic health record) are also realizing that the transition to machine learning techniques from traditional rule -based methods can lead to more efficient ways to process increasingly large collections of clinical narratives. As evidence of this transition, nearly all of the best -performing systems in the Fourth i2b2/VA Challenge (Uzuner and DuVall, 2010) used machine learning methods. 
In this paper, we focus on the medical assertions classi fication task. Given a medical problem me n-tioned in a clinical text, an assertion classifier must look at the context and choose the status of how the medical problem pertains to the patient by a s-signing one of six labels: present, absent, hypothe t-ical, po ssible, conditional , or not associated with the patient . The corpus for this task consists of di s-charge summaries from Partners HealthCare (Bo s-ton, MA) and Beth Israel Deaconess Medical Ce n-ter, as well as discharge summaries and progress notes from the Uni versity of Pittsburgh Medical Center (Pittsburgh, PA).
 Our system performed well in the i2b2/VA Challenge, achieving a micro -averaged F 1 -measure of 93.01%. However, two of the assertion categ o-ries ( present and absent ) accounted for nearly 90% of the instan ces in the data set, while the other four classes were relatively infrequent. When we an a-lyzed our results, we saw that our performance on the four minority classes was weak (e.g., recall on the conditional class was 22.22%) . Even though the minority class es are not common, they are e x-tremely important to identify accurately (e.g., a medical problem not associated with the patient should not be assigned to the patient). 
In this paper, we present our efforts to reduce the performance gap between the dominan t asse r-tion classes and the minority classes. We made three types of changes to address this issue: we changed the multi -class learning strategy, filtered the training data to remove redundancy, and added new features specifically designed to increase r e-ca ll o n the minority classes. We compare the pe r-formance of our new classifier with our original i2b2/VA Challenge classifier and show that it pe r-forms su b stantially better on the minority classes, while increasing overall performance as well . D uring the Fourth i2b2/VA Challenge , the asse r-tion classification task was tackled by participating researchers. T he best pe r forming system (Berry de Bruijn et al., 2011) reached a micro -averaged F 1 measure of 93.62% . Their breakdown of F 1 scores on the ind ividual classes was: present 95.94 % , a b-sent 94.23 % , possible 64.33 % , conditional 26.26 % , hypothetical 88.40 % , and not ass o ciated with the patient 82 . 35 % . Our system had the 6 th best score out of 21 teams, with a micro -averaged F -measure of 93.01%.

Pre viously , some researchers had developed sy s-tems to recognize specific assertion categories. Chapman et al. (2001) created the NegEx alg o-rithm, a simple rule -based system that uses regular expressions with trigger terms to determine whet h-er a medical term i s absent in a patient. They r e-ported 77.8% recall and 84.5% precision for 1,235 medical problems in discharge summaries. Cha p-man et al. (2007) also introduced the ConText a l-gorithm, which e x tended the NegEx algorithm to detect four assertion categories: ab sent, hypothe t-ical, histor i cal , and not associated with the patient . Uzuner et al. (2009) developed the Statistical A s-sertion Classifier (StAC) and showed that a m a-chine learning approach for assertion classification could achieve results competitive wit h their own implementation of Extended NegEx algorithm (ENegEx). They used four assertion classes : pr e-sent, absent, uncertain in the patient , or not ass o-ciated with the p a tient . We approach the assertion classification task as a su pervised learning problem. The classifier is gi v-en a medical term within a sentence as input and must assign one of the six assertion categories to the medical term based on its surrounding context. 3.1 Pipeline Architecture We built a UIMA (Ferrucci and La lly, 200 4; Apache, 2008) based pipeline with multiple co m-ponents, as depicted in Figure 1. The architecture includes a section detector (adapted from earlier work by Meystre and Haug (2005)), a tokenizer (based on regular expressions to split text on white space characters), a part -of -speech (POS) tagger (OpenNLP (Baldridge et al., 2005) module with trained model from cTAKES (Savova et al., 2010)), a context analyzer (local implementation of the ConText algorithm (Chapman et al., 2001)), and a normalizer ba sed on the LVG (Lexical Var i-ants Generation) (LVG, 2010) annotator from cTAKES to retrieve normalized word forms .

The assertion classifier uses features extracted by the subcomponents to represent training and test instances. We used LIBSVM, a library for support vector machine s (SVM), (Chang and Lin, 2001) for multi -class classification with the RBF (Radial Basis Function) kernel. 3.2 Original i2b2 Feature Set The assertion classifi er that we created for the i2b2 /VA Challenge used t he features listed below, which we developed by manual ly examin ing the training data :
Lexical Features: The medical term itself, the three words preceding it, and the three words fo l-lowing it. We used the LVG annotator in Lexical Tools (McCray et al., 1994 ) to normalize each word (e.g., with respect to case and tense).

Syntactic Features: Part -of -speech tags of the three words preceding the medical term and the three words following it. 
Lexico -Syntactic Features: We also defined features representing words corresponding to se v-eral parts -of -speech in the same sentence as the medical term. The value for each feature is the normalized word string. To mitigate the limited window size of lexical features, w e defined one feature each for the nearest preceding and follo w-ing adje c tive, adverb, preposition, and verb, and one additional preceding adjective and prep o sition and one additional following verb and pre p osition. Contextual Features: We incorporated the ConText algorithm (Chapman et al., 2001) to d e-tect four contextual properties in the sentence: a b-sent (negation) , hypothetical, histor i cal , and not associated with the patient. The alg o rithm assigns one of three values to each feature: true , false , or possible . We also created one feature to represent the Secti on Header with a string value normalized using (Meystre and Haug, 2005). The system only using contextual features gave reaso n able result s : F -measure overall 89.96% , present 91.39%, a b-sent 86.58% , and hypothetical 72.13%.

Feature Pruning: We created an U NKNOWN feature value to cover rarely seen feature values. Lexical feature values that had frequency &lt; 4 and other feature values that had frequency &lt; 2 were all encoded as UNKNOWNs. 3.3 New Features for Improvements After the i2b2 /VA Challenge submission, we ad d-ed the following new features, specifically to try to improve performance on the minority classes:
Lexical Features: We created a second set of lexical features that were case -insensitive. We also create d three additional binary features for each lexica l feature. We compute d the average tf -idf score for the words comprising the medical term i t self, the average tf -idf score for the three words to its left, and the average tf -idf score for the three words to its right. Each binary feature has a value of tr ue if the average tf -idf score is smaller than a threshold (e.g. 0.5 for the medical term i t self) , or false otherwise. Finally, we created another binary fe a ture that is true if the medical term contains a word with a negative pr e fix . 1
Lexico -Syntactic Fea tures: We define d two binary features that check for the presence of a comma or question mark adjacent to the medical term. We also define d features for the nearest pr e-ceding and following modal verb and wh -adverb (e.g., where and when). Finally, w e reduc ed the scope of these features from the entire sentence to a context window of size eight around the med i cal term. 
Sentence Features: We create d two binary fe a-tures to represent whether a sentence is long (&gt; 50 words) or short (&lt;= 50 words), and whether t he sentence contains more than 5 punctuation marks , prim aril y to identify sentences containing lists. 2 Context Features: We created a second set of ConText algorithm properties for negation restric t-ed to the six word context window around the me d ical term . According to the a ssertion a nnot a-tion guideline s , problems associated with a llergies were defined as conditional . So w e added one b i-nary feature that is true if the section headers co n-tain terms related to allergies (e.g.,  X  X edication alle r gies X ).

Featur e Pruning: We changed the pruning strategy to use document frequency values instead of corpus frequency for the lexical features, and used document frequency &gt; 1 for normalized words and &gt; 2 for case -insensitive words as thresholds. We also removed 57 redu ndant i n-stances from the training set. Finally, when a me d-ical term co -exists with other medical terms (pro b-lem concepts) in the same sentence, the others are excluded from the lexical and lexico -syntactic fe a-tures. 3.4 Multi -class Learning Strategies Our orig inal i2b2 system used a 1 -vs -1 classific a-tion strategy. This approach creates one class i fier for each possible pair of labels (e.g., one class i fier decides whether an instance is present vs. absent , another decides whether it is present vs. conditio n-al , et c.). All of the classifiers are applied to a new instance and t he label for the instance is dete r-mined by summing the votes of the classifiers . However, Huang et al. (2001) reported that this a p proach did not work well for data sets that had highly unbalan ced class probabi l ities. 
Therefore we experimented with a n alternative 1 -vs -all classification strategy. I n this approach, we create one classifier for each type of label using i n stances with that label as positive instances and instances with any othe r label as negative instan c-es . The f i nal class label is assigned by choosing the class that was assigned with the highest confidence value (i.e., the classifier X  X  score) . After changing to the 1 -vs -all multi -class strategy and adding the new fea ture set , we evaluate d our i m proved system on the test data and compared its performance with our ori g inal system. 4.1 Data 
The training set includes 349 clinical notes, with 11,967 assertions of medical problems. The test set includes 477 texts with 18,550 a ssertions. These assertions were distributed as follows (Table 1): 4.2 Results For the i2b2/VA Challenge submission, our system showed good performance, with 93.01% micro -averaged F 1 -measure . However, the macro F 1 -measure was much lower because our recall on the m i nority classes was weak . For example, most of the conditional test cases were misclassified as pr e sent . Table 2 shows the comparative results of the two systems (named  X  X 2b2 X  for the i2b2/VA Challenge system, and  X  X ew X  for our improved sy s-tem).
 The micro -averaged F 1 -measure of our new system is 94.17%, which now outperforms the best official score reported for the 2010 i2b2 challenge (which was 93.62%). The macro -averaged F 1 -measure increased from 76.38% to 79.76% because perfo r-mance on the m inority classes improved. The F 1 -measure improved in all classes, but we saw esp e-cially large improvements with the possible class ( + 6.32%) and the conditional class ( + 8.58%). Al t-hough the improvement on the dominant classes was limited in absolute terms ( + .79% F 1 -measure for present and + 1.86% for absent ), the relative reduction in error rate was greater than for the m i-nority classes: -29.25 % reduction in error rate for absent asser tions, -17.32% for present asse r tions, and -13.3% for conditional asse r tion s .
 4.3 Analysis We performed five -fold cross validation on the training data to measure the impact of each of the four subsets of features explained in Section 3. T a-ble 3 shows the cross validation results when c u-mulatively adding each set of features . Apply ing the 1 -vs -all strategy showed interesting r e sults: recall went up and precision went down for all classes except present . Al though the overall F 1 -measure remained almost same , it helped to i n-crease the r e call on the minority classes , and we were able to gain most of the precision back (wit h-out sacrificing this recall) by adding the new fe a-tures. 
The new lexical features including negative pr e-fixes and binary tf -idf features primarily i n creased performance on the absent class . Using document frequency to prune lexical feature s showed small gain s in all classes except absent . Sentence fe a-tures helped recogni z e hypothetical assertions , which often occur in relatively long sentences .
The possible class be n efitted the most from the new lexico -syntactic fe a tur es, with a 3.38% recall gain. We observed that many possible concepts were preceded by a question mark ('?') in the trai n-ing corpus. The new conte x tual features helped detect more conditional cases. Five allergy -related se c tion headers (i.e.  X  Allergies X  ,  X  Allergies and Med i cine Reactions X  ,  X  Allergies / Sensitivities X  ,  X  Allergy X  , and  X  Medication Allergies X ) were ass o-ciated with conditional assertions. Together, all the new features increased recall by 26.21% on the cond i tional class, 15.5% on possible , and 14. 14% on not associated with the patient . We created a more accurate assertion classifier that now achieves state -of -the -art performance on a s-sertion labeling for clinical texts. We showed that it is possible to improve performance on recog ni z-ing minority classes by 1 -vs -all strategy and richer features designed with the minority classes in mind. However, performance on the minority cla s-ses still lags behind the dominant classes, so more work is needed in this area.
 We thank the i2b2/VA challenge organizers for their efforts, and gratefully acknowledge the su p-port and resources of the VA Consortium for Healthcare Informatics Research (CHIR), VA HSR HIR 08 -374 Transl a tional Use Case Projects; Utah CDC Center of Excellence in Pu blic Health Info r-matics (Grant 1 P01HK000069 -01) , the National Sc i ence Foundation under grant IIS -1018314, and the University of Utah Department of Biomedical Informatics. We also wish to thank our other i2b2 team members: Guy Divita , Qing Z. Treitler, Dou g Redd , Adi Gundlapalli, and Sasikiran Ka n dula . Finally, w e truly appreciate Berry de Bruijn and Colin Cherry for the prompt response s to our i n-qui ry .

