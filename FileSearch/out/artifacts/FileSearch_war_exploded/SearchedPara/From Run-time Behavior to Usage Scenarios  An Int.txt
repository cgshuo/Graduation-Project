
The cornerstone of the new front-end interface construction in CelLEST is the availability of examples of how the task scenario is currently accomplished with the legacy interface. 
These examples are mined as instances of frequently occurring patterns in the system-user traces, using IPM2, the CelLEST sequential-pattem mining algorithm. 
Let us now illustrate the CelLEST process with the case study that we will use later to evaluate IPM2. This case study was conducted with the Library Of Congress 
Information System (LOCIS) 1. Four traces were recorded while a user retrieved detailed information about pieces of federal legislation through the LOCIS IBM 3270 public connection 2. The user started by making the menu selections needed to open the relevant library catalog. Then he performed some information-retrieval tasks for several times. Figure 2.a shows 20 consecutive screen snapshots of one of the recorded traces with the keystrokes that occurred on each snapshot. The solid-line snapshots constitute an instance of the first user task. In this scenario, the user issued a browse (b) command with some keyword(s) to browse the relevant part of the library catalog file. Then he issued a retrieve (r) command to retrieve a subset of the catalog items. Then, he displayed brief information about the items in this set using display (d) command. Finally, he selected an item using the display item (d item) command to display its full or partial information, e.g. the full legislation, its abstract, its list of sponsors, its official title, etc. LeNDI built the corresponding state-transition model. Figure 2.b shows the part of this model that is relevant to the trace segment in Figure 2.a. The top left corner of every screen contains its ID, as given by LeNDI. The labels on the edges represent models for the user actions that enable the transition of the interface from a screen to another. 
The CelLEST interaction-pattern mining algorithm is used to discover the user tasks performed with LOCIS, in order to model and subsequently migrate them. Provided that a sufficient number of instances of each task appear in the recorded traces and that they meet some user-defined criterion for pattern interestingness, our method can discover that these instances represent a candidate interaction-pattern, even if some of the instances include some insertion errors. In this context, insertion errors are extra snapshots that may exist in the instances of a pattern, due to user mistakes or the existence of alternative paths for the same task. The pattern corresponding to the task instance of Figure 2.a is {4+,5,6+,7+,8+,9}, where + is one or more. In section 6, we discuss how this pattern was extracted. 
This pattern was subsequently augmented with the semantic 8. The density of a pattern p supported by a set of episodes 
E, written as density (p), is the ratio of IPl to the average episode length of episodes E E: density (p) = [p! * sum~ort (t~) 9. A qualification criterion c, or simply criterion, is a user defined quadruplet (minLen, minSupp, maxError, minScore). Given a pattern p, the minimum length (a) A part of the LOCIS trace used in the example. @E (a) 
The interaction-pattern discovered for the information retrieval task of Figure 1.a, augmented with action locations. @ ?, 67 means that the user action occurs on the screen snapshot at an unspecified row and column 67. 10.A maximalpattern is a pattern that is not a sub-pattern 11.A qualified pattern is a pattern that meets the user-12. A candidate pattern is a pattern under analysis that 
Given the above definitions, the problem of interaction-pattern discovery can be formulated as follows: Given (a) an alphabet A, (b) a set of sequences S, and (c) a user criterion c, Find all the qualified maximal patterns in S. 4. RELATED PATTERN MINING WORK 
Sequer.tial-pattern mining is a generic problem with instances in a range of domains. It was first introduced in [1] under the name "mining sequential patterns", inspired by applications in the retail industry, where given a set of customers and their sequences of transactions, the goal is to discover sequences of items (patterns) occurring in the transactions of the same customer. 
The interaction-pattern mining problem is different from the above, but similar to the problem of "discovery of frequent episodes in event sequences" [17]. In this problem, the discovered frequent episodes can have different types of ordering: full (serial episodes), none (parallel episodes) or partial and have to appear within a user-defined time window. The support of a pattern is measured as the percentage of windows containing it. Some Apriori-based algorithms were developed to tackle this problem, e.g. WINEPI and MINEPI [17] and Seq-Ready&amp;Go [3]. 
The interaction-pattern mining problem is also similar to the problem of discovering patterns in genetic and protein sequences. There, the objective is to discover either probabilistic patterns or deterministic patterns with noise, e.g. flexible gaps, wild-cards (don't care characters) and/or ambiguous characters (which can be replaced by any character of a subset of A) [5]. Because bio-sequential data is usually very large, an efficient search strategy is to discover short or less ambiguous patterns using exhaustive search, possibly with pruning. Then the patterns that have enough support are extended to form longer or more ambiguous patterns. This process continues until no more patterns can be discovered. Two elegant examples of this category are PRATT [14] and TEIRESIAS [13] algorithms. PRATT can discover patterns of the quite general PROSITE format [2], e.g. C-x(5)-G-x(2,4)-H-[BD], where x(2,4) is a flexible gap of length 2 to 4, and [BD] is an ambiguous character that can be replaced by B or D. The pattern {4,5,6,7 } if maxError &lt; 5. To avoid this, we encode s using the run-length encoding algorithm that replaces immediate repetitions with a count followed by the repeated ID. Repetition counts are stored separate from the sequence. We call this representation R1. Figure 4 shows RO and R1 representations of the trace segment of Figure 2.a. 5.2 Pattern Discovery with IPM2 The input to IPM2 algorithm is a set of sequences S and a criterion c, IPM2 outputs all maximal qualified patterns in S. IPM2 consists of two distinct phases. First, it exhaustively searches the input sequences to find all the candidate patterns of length 2 that meet the "minimum support" and "maximum error" conditions (Procedure 1). For every such pattern, a location list is constructed. The patterns are stored in a vector of length [A I of pattern lists, ptListVec, whose cells are labeled after the IDs ~ A. Each cell ptListVec[i] contains all patterns p, such that p[1]= i. For example, the pattern { 1,3} is stored inptLisVect[1]. In the second phase (Procedure 2), the algorithm recursively extends each candidate pattern in ptListVec using a depth-first approach. If an extension of a candidate pattern pl using another pattern p2 produces a new candidate pattern p3 = pl+p212], then p3 is extended further, pl can be extended only with patterns in ptListVec [pl[[pll]], i.e. patterns of length 2 whose first ID is the same as the last ID of pl. The location lists of pl and p2 are used to construct that of p3 (Procedure 3). The locations of the episodes that support p3, but have more insertion errors than maxError are excluded. If support (p3) &gt;_ minSupp then p3 is extended further using the patterns in ptListVec [p3[~p3l]], otherwise p3 is ignored and the algorithm records pl if it is qualified and then backtracks. During backtracking and after reporting a pattern pl, the algorithm examines the parent pattern pO ofpl. Since pO is a sub-pattern of pl, it is a candidate pattern also. If pO is qualified and support (pO) &gt; support (pl), i.e. it is not non-maximal relative to pl, then it is recorded too. After trying to extend all patterns in ptListVec, non-maximal patterns are removed and only qualified maximal patterns are reported. 5.2.1 Procedure 1: Producing the Initial Candidate The algorithm of Figure 4 describes the first procedure of IPM2 algorithm. Step 1 creates a vector ptListVec of pattern lists. PatternList is a hash-table-like data structure that can hold a list of hashed patterns. Steps 3 to 14 are repeated for every input sequence (trace) sk ~ S. Step 3 1]. In steps 4 and 5, each ID is used to build a pattern with Procedure 2 Input: A vector of pattern lists initialized with all candidate patterns of length 2 and their location lists and a criterion c. Output: All the maximal patterns, qualified according to c. Steps: 1. PatternList resultsIPM2 2. For every id ~ A 3. For every pattern p in ptListVec [id] 4. PatternList tempResults = Extend (p) 5. Merge tempResults with resultsIPM2 6. Remove non-maximal patterns from resultsIPM2 7. Report resultsIPM2 PatternList Extend (pl) 1. PattemList extensionResults 2. For every pattern p2 in ptListVec [pl[tolJ]] 3. Construct new pattern p3 = p l + p2 [[o21] 4. Construct the location list of p3 (Procedure 3) 5. If support (p3) _&gt; minSupp Then 6. PatternList tempResults = Extend (p3) 7. Merge tempResults with extensionResults 8. If support (p l) &gt; support (p3) 9. If ~pl I _&gt; minLen AND score (p l ) _&gt; minScore 10. Ifpl is NOT in extensionResults 11. Add pl to extensionResults 12. Else 13. If Loll _&gt; minLen AND score (p l) _&gt; minScore 14. Ifpl is NOT in extensionResults 15. Add pl to extensionResults 16. Return extensionResults p3 &gt;_ minSupp. Steps 6 to 11 are executed in case of True and steps 13 to 15 are executed in case of False. In case of a successful extension, step 6 extends the new candidate p3 more by calling Extend (pl) with p3 as a parameter. Step 7 adds the qualified patterns resulting from extending p3 to extensionResults. Steps 8 to 11 add pl to extensionResults if it has more support than its successful extension p3, is qualified and is not already in extensionResults. In case of failing to extend pl using p2, then the extension pattern p3 is ignored and steps 13 to 15 add pl to the results list extensionResults if it is qualified and is not already in extensionResults. Step 16 reports back all qualified maximal (relative to one another) extension patterns ofpl. 5.2.3 Procedure 3: Constructing the Location List of The algorithm of Figure 6 describes the procedure for creating the location list of a new candidate pattern. It combines the locations lists of two patterns pl and p2, where ~21 = 2, to provide the location list of p3, where p3 = pl + p2 [2]. Step 2 iterates over the locations of the episodes supporting pl. Steps 3 retrieves the location of such an episode el. Step 4 retrieves the locations of the episodes that support p2 and satisfy some conditions. If we have such an episode e2, then: (1,1,3) (1,1,4) (2,1,3) (1,3,6) (1,3,5) Table 2: All maximal qualified patterns discovered in for extension. The location list of every generated pattern is shown under its box. Qualified patterns that are reported by the sub-procedure "Extend (pI)" are in bold font. Maximal qualified patterns, returned by IPM2, are in double-line boxes. Note that the pattern {3,2,4} is qualified but not reported by "Extend (pl)" because its extension {3,2,4,3} which has the same support, is reported first, while {2,4,3} is reported by ''Extend (pl)" but is removed at the end of procedure 2 for being non-maximal. Table 2 shows the discovered maximal qualified patterns, their support, density and score. 5.4 Understanding the Extracted Patterns 
After reviewing the discovered patterns, the criterion c can be modified to narrow or widen the result set, if too few or too many patterns have been retrieved. Furthermore, a group of patterns, whose score and/or support are within specific range(s), can be selected and compacted by removing any pattern that is a sub-pattern of another pattern, even if it is maximal. 
This interactive step of scoping out and "cleaning" the extracted interaction patterns is crucial in identifying the usage scenarios corresponding to the functional requirements of the legacy application. Methodologically, the longer the recorded traces and the "stricter" the criterion c, the more likely it becomes to discover true usage scenarios, since all "noise patterns" should not gain enough support when evaluated in the context of long-term use. 
Ultimately, however, a user with knowledge of the application domain and the organization's processes has to decide which of the discovered patterns correspond indeed to usage scenarios, corresponding to required functionality. address exactly this requirement, i.e., to discover fully ordered sequential patterns with possible insertion errors. To date, we have evaluated this algorithm against a realistic case study with a real legacy application. We plan to evaluate it further with bigger artificial and real data sets (interaction traces), that cover a wide range of applications and interaction styles. Furthermore, we plan to compare its effectiveness and efficiency relative to other related algorithms, including our own earlier IPM algorithm. We believe that our interaction-pattern mining approach to legacy interface migration is an interesting variant of the sequential-pattern mining problem and a compelling application of this class of knowledge-discovery algorithms. As our initial results indicate, its deployment in the context of the CelLEST process can help provide a powerful, low-risk, lightweight solution to a challenging IT problem, namely the web-enabling of legacy applications. This work was supported by NSERC grant 215451-98 and Alberta Software Engineering Research Consortium (ASERC). [1] Agrawal, R. and Srikant, R.. Mining Sequential Patterns. [2] Bairoch, A. and Bucher, P. PROSITE: Recent [3] Baixeries, J., Casas, G. and Balcazar, J. L. Frequent Sets, [4] Biuk-Aghai, R. and Simoff, S. Assisting the Design of [5] Brejova, B., DiMarco, C., Vinar, T., Hidalgo, S. R., [6] Chikofsky, E. and Cross, J.H.II. Reverse Engineering and [7] Cypher, A. (ed.). Watch What I Do: Programming by [8] Di Lucca, G., Fasolino, A., and De Carlini, U. Recovering [9] El-Rarely, M., Iglinski, P., Stroulia, E., Sorenson, P. and 
