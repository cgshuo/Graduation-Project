 Effective organization of web sear ch results can greatly improve the utility of search engine a nd enhance the quality of search results. However, the organization of search results is difficult because the sub-topics of a query are usually not explicitly given. In this paper, we propose a novel topic-driven search result organization method, which can first detect the sub-topics of a query by finding the coherent Wikipedia concept groups from its search results; then organize these results using a topic-driven clustering algorithm; in the end we score and rank the topics using the support vector regression model. Empirical results show that our method can achieve competitive performance. H.3.3 [ Information Search and Retrieval ]: Clustering, Search process General Terms : Algorithms, Experimentation Search Result Organization, T opic Detection, Topic Ranking, Topic-Driven Clustering. With the explosion of Web, search engine has been the critical way for finding the relevant information from billions of web pages. Given a user query, most today X  X  search engines present the relevant documents as a fl at ranked list. The ranked list presentation, however, although works well for the simple and navigational queries, can often fa il in addressing vague, broad or ambiguous queries, where the search result is often the mixture of web pages belonging to diffe rent subtopics of the given query. For example, as shown in Table 1, when we query Google with  X  X aguar X  and  X  X nf ormation Retrieval X , both their returned results contain more than 10 topics. Query Subtopics Jaguar Jaguar(animal cat), Jaguar(car), Atari Information Retrieval In order to improve the utility of search engine, a possible solution is search result organization, which groups search results into clusters according to the subtopics of a given query, so that a user can easily navigate into a particular interesting subtopic. Furthermore, as shown in Hearst and Pedersen [1], search results organization can also enhance the quality of search results, since relevant doc uments tend to be more similar to each other. The search result organization, however, is difficult because the subtopic knowledge of a query is usually not explicitly given. Conventionally, the traditional me thods organize search results based on only content similarities ([1][5]) or whether some salient phrases are shared ([6][7][8][9]). By taking no topic knowledge (sub-topics of a query) into consideration, the traditional clustering-based met hods often generate clusters which do not correspond to semantically meaningful topics. In order to resolve the traditi onal methods X  deficiencies, this paper proposes a novel topic-driven search result organization method. The start point of our method is that a topic can be represented efficiently using a set of coherent Wikipedia concepts. Starting from this point, given the query and the returned by a certain web search engine, our method works as follows: Firstly, the sub-topics of the query are detected by finding the coherent Wikipedia concept groups through a community detection process. S econdly, the search results are clustered according to the detected topics using a topic-driven user-friendly way, the topics are scored and ranked by combining their properties (including Salience , Predictiveness , Coherence and Distinguishness ) using the support vector regression model. This paper is organized as follows . The related work is reviewed in Section 2. The problem is defi ned in Section 3. In Section 4, we introduce our topic detection method. The topic-driven search result organization method is described in Section 5. The experimental results are presente d and discussed in Section 6. Finally we conclude the paper a nd give some future work in Section 7. The problem of search result orga nization has been investigated in a number of previous research es. According to how well they generate user-friendly labels of clusters, the traditional methods can be classified into two categories: the data-centric method and the label-centric method. The data-centric methods ([1][5]) usually group search results into clusters using conventional document clustering algorithms, then produce some kind of textual label of resulting clusters for end users. Unlike the data-centric methods, the label-centric methods put their emphasis on the quality of cluster labels. One of the pioneer researches was the Suffix Tree Clustering (STC) method proposed by Zamir and Etzioni [6], which selected th e frequent phrases as the labels of clusters. The STC method was extended in a follow-up algorithm called HSTC [7]. Another method was the Lingo method proposed by Osiriski [8], which found the cluster labels through the singular value decomposition process. Lawrie and Croft [9] also proposed a method which selected cluster labels based on two specific document st atistics named topicality and predictiveness. In this section, we formulize the topic-driven search result organization problem. Conventiona lly, as shown in Figure 1, a topic-driven search result organi zation system is defined as a six-tuple {, , , , , } OqDTC  X   X  = , where: q is the query, such as  X  X aguar X  and  X  X nformation Retrieval X ; returned by a certain search e ngine such as Google and Yahoo!; T(q) = {t 1 , t 2 , ..., t k } is the subtopics of query q ; C = {D(q,t)} is the clusters of search results, each cluster D(q,t) corresponds to a specific topic t within T(q) ; :() () D qTq C  X   X  X  is the clustering algorithm, which groups search results into clusters ba sed on the sub-topics of a query;  X  = is the topic ranking algorithm, which scores the importance and relevance of each topic. Based on the above formalization, the main task of our topic-driven search result organization is to design the clustering algorithm :() () D qTq C  X   X  X  and the topic ranking algorithm  X  = . On the other hand, because the topic knowledge T(q) is not given, an additional topic detection step is also needed. In this section, we demonstrate how to detect the topics within search results by leveraging Wi kipedia semantic knowledge. In concepts, e.g., the Jaguar(animal cat) topic can be represented as {Animal, Jaguar, Big Cat, Leopard, Wildcat, Felis, ...} . finding the coherent Wikipedia concept groups within the search results, which is composed of th ree steps: (1) Wikipedia concept extraction; (2) semantic graph building; (3) community detection. In the following we respectively describe each of the three steps. Wikipedia Concept Extraction. The goal of this step is to extract Wikipedia concepts from search results. In this paper, we extract Wikipedia concepts us ing the method described in Medelyan et al. [2]. Semantic Graph Building. In this step we model the semantic relations between the Wikipedia c oncepts as a semantic graph, which is defined as follows: To build the semantic graph, we first measure the semantic relatedness sr between Wikipedia concepts using the method proposed in Witten and Milne [4], then use a semantic relatedness threshold ST to determine whether two concepts are semantically related, i.e., two Wikipedia concepts are considered semantically relate d if the semantic relatedness between them is larger than ST. Th e value of ST is set to 0.3 in this paper through a learning process. For demonstration, a semantic graph of four Jaguar search results is shown in Figure 2. 
Figure 2. A semantic graph and its community detection Community Detection. Given the semantic graph, the goal of this step is to find the cohere nt groups of Wikipedia concepts, with each resulting group corresponding to one specific topic. We observe that the semantic relations are dense between the Wikipedia concepts within the same topic; while the semantic relations are sparse between the Wikipedia concepts across different topics. Based on the a bove observation, we can regard the topics as the community structures in networks [3]. Therefore we can detect the topics by finding the communities in the semantic graph. We em ploy the algorithm described in Newman and Girvan [3] to discover the communities in a semantic graph. For demonstra tion, we show the community detection result of the semantic graph in Figure 2. In the above section, we have detected a set of topics T(q) = {t t , ..., t k } for the query q , with each topic t represented as a set of coherent Wikipedia concepts {c 1 , c 2 , ..., c m } . In this section, we organize search results according to the detected topics T(q) through the following two steps described in the following subsections: driven search result clustering algorithm; model, so that the relevant and important topics will be presented at the top positions. Our topic-driven search result clustering algorithm groups search results into clusters by assigning documents to topics based on their content similarity . The documents assigned to the D(t) for simplicity. The first step is to compute th e similarity between a document d and a topic t . We first represent both the document and the topic as a weighted Wikipedia concept set {(c 1 , w(c 1 )), (c (c , w(c m ))} , where w(c) is the weight of concept c . For a topic t , the concepts are weighted using the following formula: which means the weight of a concept is its average semantic relatedness to all the other concepts within the same topic. For a document d , we first obtain its Wikipedia concept set representation by extracting all the Wikipedia concepts within its content (title and snippet) using the same method described in Section 4.1, then weight the concepts using the above formula. Based on the weighted Wikipedia concept set representation, we compute the similarity between a topic t and a document d as: Based on the computed similarities, we assign a document d to a threshold CT (a document may be assigned to multiple topics). process. Finally, we generate the label for each cluster D(t) . In our method, we simply choose the Wikipedia concept with the maximal weight in topic t as the D(t)  X  X  label. Till now, we have organized the search results into clusters according to the detected topics. However, not all the topics are equally relevant and important to users: some topics may not be relevant to the query; some topi cs may not be salient in the presenting the relevant and importa nt topics at the top positions to users. In this section, we propose an algorithm which can rank topics by giving each topic an importance score. The topic ranking algorithm first measures four properties of a topic (including Salience , Predictiveness , Coherence and Distinguishness ) which are supposed to be the important factors for topic ranking; then combines all these properties using the support vector regression model. The detail description is shown in follows. Salience. The salience measures how salient a topic is in the topic of the documents within D(t) and contained in many search results. So we can measure the salience of a topic using the following two measures: The Average Concept Frequency in Topic Cluster: The Document Frequency of Topic t : Coherence. The coherence measures the quality of a topic, that is, how coherent a topic is. Intuitively, a topic t is coherent if the concepts within it are highly semantically related and the documents assigned to this topic are highly similar to each other, which are measured as two individual values: The Concept Coherence: The Cluster Coherence: Predictiveness. The predictiveness measures how well a user can deduce the content of the cluster D(t) by glancing through the representation of topic t , which is computed as the average similarity between the topic t and the documents assigned to it: Distinguishness. The distinguishness meas ures how well a topic can distinguish the documents a ssigned to it from the documents not assigned to it, which is calculated as the average similarity between the topic t and the documents not assigned to it: Combining all the Evidences by SVM Regression. Given the four properties of a topic, in the following we combine them and calculate a single importance score for each topic. In this paper, we use support vector regression ([10]) to combine the four properties, which can balance the four properties X  values and output a final their importance scores. Section 6.2. Wikipedia We use the English Wikipedia version released on Mar. 6, 2009, which contains more than 6,600,000 distinct concepts. Dataset We adopt the AMBIENT [7] dataset for evaluation, which consists of 44 ambiguous and broad queries. For each query, the AMBIENT dataset provide a set of subtopics (totally 790 subtopics) and a list of 100 ranked doc uments returned by a search information. We also build a dataset for training and evaluating our topic ranking algorithm: We manually annot ate the topics detected by our method with three importance scores: 1.0 , 0.5 and 0 , where the score 1.0 means that this topic is very important; 0.5 means that this this topic is not relevant to the query. Evaluation Criteria To compare the clustering performance of our method with other search result clustering methods, we adopt the same method as in [1], that is, we compare the quality of the best cluster, which is defined as th e one with the largest number of relevant documents. We use Pr ecision at top 5 documents ( P@5 ) in the best cluster as the primary measure to compare different methods. Except for the P@5 , we also provided the P@10 and the Mean Reciprocal Rank (MRR) as additional precision metrics. performance of the topic ranking algorithm, we adopt the precision at the top N topics ( TP@N ). We compare our method with three baselines: 1) The original ranked list of search results returned by a search engine, where all the search results are viewed as a single cluster  X  we denoted it as Ranked_List ; 2) The Suffix Tree Clustering method proposed by Zamir and Etzioni[6]  X  we denoted it as STC ; 3) the LINGO method described in Osir iski et al. [8]  X  we denoted it as LINGO . STC 0.45 0.37 0.16 0.85 LINGO 0.48 0.30 0.29 0.70 Our Method 0.53 0.38 0.36 0.92 Table 2. Performance results of baselines and our method Polynomial 0.05 0.22 0.42 0.67 We compare our method with all the three baselines. The overall performance is shown in Table 2. From the performance results in Table 2, we can see that: performance and utility of search engine: compared with the Ranked_List baseline, all the three search result organization methods obtained significant pe rformance improvements: the STC, LINGO and Our Method achieve respectively 34%, 37%, 42% P@5 improvement. results. Compared with the STC baseline, our method gets 8% P@5 improvement; compared with the LINGO baseline, our method gets 5% P@5 improvement. into clusters which are not only precise but also with high-recall as well. Compared with the STC and the LINGO, our method can obtain not only high precision but also high recall as well: the MRR is 0.36, 7% improvement over the LINGO; the Recall is 0.92, 7% improvement over the STC. To evaluate the efficiency of topic ranking, we show its performance in Table 3 (we use the topics of 30 queries for training, 14 queries for testing). Fr om the results in Table 3, we can see that: 1) The topic ranking is critical for search result organization: 2) Our topic ranking algorithm is effective. It can achieve In this paper we propose a novel topic-driven search result organization method, which firs tly detect the topic knowledge of a query from its search results, then organize the search results according to the detected topics. By detecting and integrating the topic knowledge, our method can achieve competitive results. For future work, we will organize the search results through detecting a hierarchical topic structure, which can further improve the utility of orga nized search results. The work is supported by the National Natural Science Foundation of China under Grants no. 60875041 and 60673042, and the National High Technol ogy Development 863 Program of China under Grants no. 2006AA01Z144. 
