 The central problem of Information Retrieval (IR) is to satisfy the user X  X  information need, which is typically expressed through a short (typically 2-3 words) and often ambiguous query. The problem of matching the user X  X  query to the documents is rendered difficult by natural language phenomena like morphological variations , polysemy and syn-onymy . Relevance Feedback (RF) tries to over-come these problems by eliciting user feedback on the relevance of documents obtained from the initial ranking and then uses it to automatically refine the query. Since user input is hard to ob-tain, Pseudo-Relevance Feedback (PRF) (Buckley et al., 1994; Xu and Croft, 2000; Mitra et al., 1998) is used as an alternative, wherein RF is performed by assuming the top k documents from the initial retrieval as being relevant to the query. Based on the above assumption, the terms in the feedback document set are analyzed to choose the most dis-tinguishing set of terms that characterize the feed-back documents and as a result the relevance of a document. Query refinement is done by adding the terms obtained through PRF, along with their weights, to the actual query.

Although PRF has been shown to improve re-trieval, it suffers from the following drawbacks: (a) the type of term associations obtained for query expansion is restricted to co-occurrence based re-lationships in the feedback documents, and thus other types of term associations such as lexical and semantic relations (morphological variants, syn-onyms) are not explicitly captured, and (b) due to the inherent assumption in PRF, i.e. , relevance of top k documents, performance is sensitive to that of the initial retrieval algorithm and as a result is not robust.

Multilingual Pseudo-Relevance Feedback (MultiPRF) (Chinnakotla et al., 2010) is a novel framework for PRF to overcome both the above limitations of PRF. It does so by taking the help of a different language called the assisting language . In MultiPRF, given a query in source language L 1 , the query is automatically translated into the assisting language L 2 and PRF performed in the assisting language. The resultant terms are translated back into L 1 using a probabilistic bi-lingual dictionary. The translated feedback model, is then combined with the original feed-back model of L 1 to obtain the final model which is used to re-rank the corpus. MulitiPRF showed remarkable improvement on standard CLEF collections over plain Model Based Feedback (MBF) uniformly for 4 languages, viz., French, German, Hungarian and Finnish with English as the assisting language. This fact inspired us to study the effect of any source-assistant pair on PRF performance from out of a set of languages with widely different characteristics, viz., Dutch, English, Finnish, French, German and Spanish . Carrying this further, we looked into the effect of using two assisting languages together on PRF.
The present paper is a report of these in-vestigations, their results and conclusions drawn therefrom. While performance improvement on PRF is observed whatever the assisting language and whatever the source, observations are mixed when two assisting languages are used simulta-neously. Interestingly, the performance improve-ment is more pronounced when the source and as-sisting languages are closely related , e.g., French and Spanish.

The paper is organized as follows: Section 2, discusses the related work. Section 3, explains the Language Modeling (LM) based PRF approach. Section 4, describes the MultiPRF approach. Sec-tion 5 discusses the experimental set up. Section 6 presents the results, and studies the effect of vary-ing the assisting language and incorporates mul-tiple assisting languages. Finally, Section 7 con-cludes the paper by summarizing and outlining fu-ture work. PRF has been successfully applied in various IR frameworks like vector space models, probabilis-tic IR and language modeling (Buckley et al., 1994; Jones et al., 2000; Lavrenko and Croft, 2001; Zhai and Lafferty, 2001). Several ap-proaches have been proposed to improve the per-formance and robustness of PRF. Some of the rep-resentative techniques are (i) Refining the feed-back document set (Mitra et al., 1998; Sakai et al., 2005), (ii) Refining the terms obtained through PRF by selecting good expansion terms (Cao et al., 2008) and (iii) Using selective query expan-sion (Amati et al., 2004; Cronen-Townsend et al., 2004) and (iv) Varying the importance of docu-ments in the feedback set (Tao and Zhai, 2006). Another direction of work, often reported in the TREC Robust Track, is to use a large external col-lection like Wikipedia or the Web as a source of expansion terms (Xu et al., 2009; Voorhees, 2006). The intuition behind the above approach is that if the query does not have many relevant docu-ments in the collection then any improvements in the modeling of PRF is bound to perform poorly due to query drift.

Several approaches have been proposed for including different types of lexically and se-mantically related terms during query expansion. Voorhees (1994) use Wordnet for query expan-sion and report negative results. Recently, random walk models (Lafferty and Zhai, 2001; Collins-Thompson and Callan, 2005) have been used to learn a rich set of term level associations by com-bining evidence from various kinds of information sources like WordNet, Web etc . Metzler and Croft (2007) propose a feature based approach called la-tent concept expansion to model term dependen-cies.

All the above mentioned approaches use the re-sources available within the language to improve the performance of PRF. However, we make use of a second language to improve the performance of PRF. Our proposed approach is especially attrac-tive in the case of resource-constrained languages where the original retrieval is bad due to poor cov-erage of the collection and/or inherent complexity of query processing (for example term conflation ) in those languages.

Jourlin et al. (1999) use parallel blind relevance feedback, i.e. they use blind relevance feedback on a larger, more reliable parallel corpus, to improve retrieval performance on imperfect transcriptions of speech. Another related idea is by Xu et al. (2002), where a statistical thesaurus is learned us-ing the probabilistic bilingual dictionaries of Ara-bic to English and English to Arabic. Meij et al. (2009) tries to expand a query in a differ-ent language using language models for domain-specific retrieval, but in a very different setting. Since our method uses a corpus in the assisting language from a similar time period, it can be likened to the work by Talvensaari et al. (2007) who used comparable corpora for Cross-Lingual Information Retrieval (CLIR). Other work pertain-ing to document alignment in comparable corpora, such as Braschler and Sch  X  auble (1998), Lavrenko et al. (2002), also share certain common themes with our approach. Recent work by Gao et al. (2008) uses English to improve the performance over a subset of Chinese queries whose transla-tions in English are unambiguous. They use inter-document similarities across languages to improve the ranking performance. However, cross lan-guage document similarity measurement is in it-self known to be an hard problem and the scale of their experimentation is quite small. The Language Modeling (LM) Framework allows PRF to be modelled in a principled manner. In the LM approach, documents and queries are modeled using multinomial distribution over words called document language model P ( w | D ) and query lan-guage model P ( w |  X  Q ) respectively. For a given query, the document language models are ranked based on their proximity to the query language model, measured using KL-Divergence.
 Since the query length is short, it is difficult to es-timate  X  Q accurately using the query alone. In PRF, the top k documents obtained through the ini-tial ranking algorithm are assumed to be relevant and used as feedback for improving the estima-tion of  X  Q . The feedback documents contain both relevant and noisy terms from which the feedback language model is inferred based on a Generative Mixture Model (Zhai and Lafferty, 2001).

Let D F = { d 1 ,d 2 ,...,d k } be the top k docu-ments retrieved using the initial ranking algorithm. Zhai and Lafferty (Zhai and Lafferty, 2001) model the feedback document set D F as a mixture of two distributions: (a) the feedback language model and (b) the collection model P ( w | C ) . The feedback language model is inferred using the EM Algo-rithm (Dempster et al., 1977), which iteratively accumulates probability mass on the most distin-guishing terms, i.e. terms which are more fre-quent in the feedback document set than in the entire collection. To maintain query focus the fi-nal converged feedback model,  X  F is interpolated with the initial query model  X  Q to obtain the final query model  X  F inal .
  X  F inal is used to re-rank the corpus using the KL-Divergence ranking function to obtain the fi-nal ranked list of documents. Henceforth, we refer to the above technique as Model Based Feedback (MBF) . The schematic of the MultiPRF approach is shown in Figure 1. Given a query Q in the source lan-guage L 1 , we automatically translate the query into the assisting language L 2 . We then rank the documents in the L 2 collection using the query likelihood ranking function (John Lafferty and Chengxiang Zhai, 2003). Using the top k doc-uments, we estimate the feedback model using MBF as described in the previous section. Simi-larly, we also estimate a feedback model using the original query and the top k documents retrieved from the initial ranking in L 1 . Let the resultant feedback models be  X  F L The feedback model estimated in the assisting lan-guage  X  F L using a probabilistic bi-lingual dictionary t ( f | e ) from L 2  X  L 1 as follows:
The probabilistic bi-lingual dictionary t ( f | e ) is learned from a parallel sentence-aligned corpora in L 1  X  L 2 based on word level alignments. Tiede-mann (Tiedemann, 2001) has shown that the trans-lation alternatives found using word alignments could be used to infer various morphological and semantic relations between terms. In Table 3, we show the top translation alternatives for some sample words. For example, the French word am  X  ericain (american) brings different variants of the translation like american, america, us, united, state, america which are lexically and semanti-cally related. Hence, the probabilistic bi-lingual dictionary acts as a rich source of morphologically and semantically related feedback terms. Thus, during this step, of translating the feedback model as given in Equation 1, the translation model adds related terms in L 1 which have their source as the term from feedback model  X  F L PRF model is obtained by interpolating the above translated feedback model with the original query model and the feedback model of language L 1 as given below:
Since we want to retain the query focus during back translation the feedback model in L 2 is inter-polated with the translated query before transla-tion of the L 2 feedback model. The parameters  X  and  X  control the relative importance of the orig-inal query model, feedback model of L 1 and the translated feedback model obtained from L 1 and are tuned based on the choice of L 1 and L 2 . We evaluate the performance of our system us-ing the standard CLEF evaluation data in six lan-guages, widely varying in their familial relation-ships -Dutch, German, English, French, Span-ish and Finnish using more than 600 topics. The details of the collections and their corresponding topics used for MultiPRF are given in Table 1. Note that, in each experiment, we choose assist-ing collections such that the topics in the source language are covered in the assisting collection so as to get meaningful feedback terms. In all the top-ics, we only use the title field. We ignore the top-ics which have no relevant documents as the true performance on those topics cannot be evaluated.
We demonstrate the performance of MultiPRF approach with French, German and Finnish as source languages and Dutch, English and Span-ish as the assisting language. We later vary the assisting language, for each source language and study the effects. We use the Terrier IR platform (Ounis et al., 2005) for indexing the documents. We perform standard tokenization, stop word re-moval and stemming. We use the Porter Stemmer for English and the stemmers available through the Snowball package for other languages. Other than these, we do not perform any language-specific processing on the languages. In case of French, since some function words like l X  , d X  etc., occur as prefixes to a word, we strip them off during index-ing and query processing, since it significantly im-proves the baseline performance. We use standard evaluation measures like MAP , P@5 and P@10 for evaluation. Additionally, for assessing robust-ness, we use the Geometric Mean Average Preci-sion (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Trans-late as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use the MBF approach explained in Section 3 as a baseline for comparison. We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically  X  and  X  , and choose the values which give the optimal performance on a given collec-tion. We uniformly choose the top ten documents for feedback. Table 4 gives the overall results. In Table 4, we see the performance of the Multi-PRF approach for three assisting languages, and how it compares with the baseline MBF meth-ods. We find MultiPRF to consistently outperform the baseline value on all metrics, namely MAP (where significant improvements range from 4.4% to 7.1%); P@5 (significant improvements range from 4.9% to 39.5% and P@10 (where MultiPRF has significant gains varying from 4% to 22.8%). Additionally we also find MultiPRF to be more ro-bust than the baseline, as indicated by the GMAP score, where improvements vary from 4.2% to 730%. Furthermore we notice these trends hold across different assisting languages, with Span-ish and Dutch outperforming English as the as-sisting language on some of the French and Ger-man collections. On performing a more detailed study of the results we identify the main reason for improvements in our approach is the ability to obtain good feedback terms in the assisting lan-guage coupled with the introduction of lexically and semantically related terms during the back-translation step.

In Table 5, we see some examples, which illus-trates the feedback terms brought by the MultiPRF method. As can be seen by these example, the gains achieved by MultiPRF are primarily due to one of three reasons: (a) Good Feedback in As-sisting Language: If the feedback model in the assisting language contains good terms, then the back-translation process will introduce the corre-sponding feedback terms in the source language, thus leading to improved performance. As an example of this phenomena, consider the French Query  X  X aladie de Creutzfeldt-Jakob X  . In this case the original feedback model also performs quite strongly with a MAP score of 0.507. Al-though there is no significant topic drift in this case, there are not many relevant terms apart from the query terms. However the same query per-forms very well in English with all the documents in the feedback set of the English corpus being rel-evant, thus resulting in informative feedback terms such as { bovin, scientif, recherch } . (b) Finding Synonyms/Morphological Variations: Another sit-uation in which MultiPRF leads to large improve-ments is when it finds semantically/lexically re-lated terms to the query terms which the origi-nal feedback model was unable to. For example, consider the French query  X  X ng  X  enierie g  X n  X tique X  . While the feedback model was unable to find any of the synonyms of the query terms, due to their lack of co-occurence with the query terms, the MultiPRF model was able to get these terms, which are introduced primarily during the back-translation process. Thus terms like { genetic, gen, engineering } , which are synonyms of the query words, are found thus resulting in improved per-formance. (c) Combination of Above Factors: Sometimes a combination of the above two factors causes improvements in the performance as in the German query  X   X  Olkatastrophein Sibirien X  . For this query, MultiPRF finds good feedback terms such as { russisch, russland } while also obtaining semantically related terms such as { olverschmutz, erdol, olunfall } .

Although all of the previously described exam-ples had good quality translations of the query in the assisting language, as mentioned in (Chin-nakotla et al., 2010), the MultiPRF approach is robust to suboptimal translation quality as well. To see how MultiPRF leads to improvements even with errors in query translation consider the Ger-man Query  X  X iegerinnen von Wimbledon X  . When this is translated to English, the term  X  X ady X  is dropped, this causes only  X  X imbledon Champi-ons X  to remain. As can be observed, this causes terms like sampras to come up in the MultiPRF model. However, while the MultiPRF model has some terms pertaining to Men X  X  Winners of Wim-bledon as well, the original feedback model suf-fers from severe topic drift, with irrelevant terms such as { telefonbuch, telekom } also amongst the top terms. Thus we notice that despite the er-ror in query translation MultiPRF still manages to correct the drift of the original feedback model, while also introducing relevant terms such as { verfecht, steffi, martina, novotna, navratilova } as well. Thus as shown in (Chinnakotla et al., 2010), having a better query translation system can only lead to better performance. We also perform a detailed error analysis and found three main reasons for MultiPRF failing: (i) Inaccura-cies in query translation (including the presence of out-of-vocabulary terms). This is seen in the Ger-man Query AI in Lateinamerika , which wrongly translates to Avian Flu in Latin America in Span-ish thus affecting performance. (ii) Poor retrieval in Assisting Language. Consider the French query Les droits de l X  X nfant , for which due to topic drift in English, MultiPRF performance reduces. (iii) In a few rare cases inaccuracy in the back transla-tion affects performance as well. 6.1 Parameter Sensitivity Analysis The MultiPRF parameters  X  and  X  in Equation 2 control the relative importance assigned to the original feedback model in source language L 1 , the translated feedback model obtained from as-sisting language L 2 and the original query terms. We varied the  X  and  X  parameters for French, Ger-man and Finnish collections with English, Dutch and Spanish as assisting languages and studied its effect on MAP of MultiPRF. The results are shown in Figure 2. The results show that, in all the three collections, the optimal value of the parameters almost remains the same and lies in the range of 0.4-0.48. Due to the above reason, we arbitrarily choose the parameters in the above range and do not use any technique to learn these parameters. 6.2 Effect of Assisting Language Choice In this section, we discuss the effect of varying the assisting language. Besides, we also study the inter and intra familial behaviour of source-assisting language pairs. In order to ensure that the results are comparable across languages, we indexed the collections from the years 2002, 2003 and use common topics from the topic range 91-200 that have relevant documents across all the six languages. The number of such common topics were 67. For each source language, we use the other languages as assisting collections and study the performance of MultiPRF. Since query trans-lation quality varies across language pairs, we an-alyze the behaviour of MultiPRF in the following two scenarios: (a) Using ideal query translation (b) Using Google Translate for query translation. In ideal query translation setup, in order to elim-inate its effect, we skip the query translation step and use the corresponding original topics for each target language instead. The results for both the above scenarios are given in Tables 6 and 7. From the results, we firstly observe that besides English, other languages such as French, Spanish, German and Dutch act as good assisting languages and help in improving performance over mono-lingual MBF. We also observe that the best as-sisting language varies with the source language. However, the crucial factors of the assisting lan-guage which influence the performance of Multi-PRF are: (a) Monolingual PRF Performance: The main motivation for using a different language was to get good feedback terms, especially in case of queries which fail in the source language. Hence, an assisting language in which the monolingual feedback performance itself is poor, is unlikely to give any performance gains. This observation is evident in case of Finnish, which has the low-est Monolingual MBF performance. The results show that Finnish is the least helpful of assist-ing languages, with performance similar to those of the baselines. We also observe that the three best performing assistant languages, i.e. English, French and Spanish, have the highest monolingual performances as well, thus further validating the claim. One possible reason for this is the relative ease of processing in these languages. (b) Familial Similarity Between Languages: We observe that the performance of MultiPRF is good if the as-sisting language is from the same language fam-ily. Birch et al. (2008) show that the language family is a strong predictor of machine transla-tion performance. Hence, the query translation and back translation quality improves if the source and assisting languages belong to the same family. For example, in the Germanic family, the source-assisting language pairs German-English, Dutch-English, Dutch-German and German-Dutch show good performance. Similarly, in Romance family, the performance of French-Spanish confirms this behaviour. In some cases, we observe that Multi-PRF scores decent improvements even when the assisting language does not belong to the same language family as witnessed in French-English and English-French. This is primarily due to their strong monolingual MBF performance. 6.3 Effect of Language Family on Back As already mentioned, the performance of Multi-PRF is good if the source and assisting languages belong to the same family. In this section, we ver-ify the above intuition by studying the impact of language family on back translation performance. The experiment designed is as follows: Given a query in source language L 1 , the ideal translation in assisting language L 2 is used to compute the query model in L 2 using only the query terms. Then, without performing PRF the query model is directly back translated from L 2 into L 1 and finally documents are re-ranked using this trans-lated feedback model. Since the automatic query translation and PRF steps have been eliminated, the only factor which influences the MultiPRF per-formance is the back-translation step. This means that the source-assisting language pairs for which the back-translation is good will score a higher performance. The results of the above experiment is shown in Table 8. For each source language, the best performing assisting languages have been highlighted.

The results show that the performance of closely related languages like French-Spanish and German-Dutch is more when compared to other source-assistant language pairs. This shows that in case of closely related languages, the back-translation step succeeds in adding good terms which are relevant like morphological variants, synonyms and other semantically related terms. Hence, familial closeness of the assisting language helps in boosting the MultiPRF performance. An exception to this trend is English as assisting lan-guage which shows good performance across both families. 6.4 Multiple Assisting Languages So far, we have only considered a single assist-ing language. However, a natural extension to the method which comes to mind, is using mul-tiple assisting languages. In other words, com-bining the evidence from all the feedback mod-els of more than one assisting language, to get a feedback model which is better than that obtained using a single assisting language. To check how this simple extension works, we performed exper-iments using a pair of assisting languages. In these experiments for a given source language (from amongst the 6 previously mentioned languages) we tried using all pairs of assisting languages (for each source language, we have 10 pairs possible). To obtain the final model, we simply interpolate all the feedback models with the initial query model, in a similar manner as done in MultiPRF. The re-sults for these experiments are given in Table 9. As we see, out of the 60 possible combinations of source language and assisting language pairs, we obtain improvements of greater than 3% in 16 cases. Here the improvements are with respect to the best model amongst the two MultiPRF mod-els corresponding to each of the two assisting lan-guages, with the same source language. Thus we observe that a simple linear interpolation of mod-els is not the best way of combining evidence from multiple assisting languages. We also observe than when German or Spanish are used as one of the two assisting languages, they are most likely to lead to improvements. A more detailed study of this observation needs to be done to explain this. We studied the effect of different source-assistant pairs and multiple assisting languages on the per-formance of MultiPRF. Experiments across a wide range of language pairs with varied degree of fa-milial relationships show that MultiPRF improves performance in most cases with the performance improvement being more pronounced when the source and assisting languages are closely related . We also notice that the results are mixed when two assisting languages are used simultaneously. As part of future work, we plan to vary the model interpolation parameters dynamically to improve the performance in case of multiple assisting lan-guages.
 The first author was supported by a fellowship award from Infosys Technologies Ltd., India. We would like to thank Mr. Vishal Vachhani for his help in running the experiments.
