 University of Pennsylvania In the online learning framework, the learner is faced with a sequence of data appearing at discrete evaluated after the sequence is completely revealed, in the online framework the learner is evaluated at every round. Furthermore, in the batch scenario the data source is typically assumed to be i.i.d. with an unknown distribution, while in the online framework we relax or eliminate any stochastic assumptions on the data source. As such, the online learning problem can be phrased as a repeated two-player game between the learner (player) and the adversary (Nature).
 Let F be a class of functions and X some set. The Online Learning Model is defined as the following T -round interaction between the learner and the adversary: On round t = 1 ,...,T , the Learner chooses f t  X  F , the Adversary picks x t  X  X , and the Learner suffers loss f t ( x t ) . At the end of T rounds we define regret as the difference between the cumulative loss of the player as compared to the cumulative loss of the best fixed comparator. For the given pair ( F , X ) , the problem is said to be online learnable if there exists an algorithm for the learner such that regret grows sublinearly. Learnability is closely related to Hannan consistency [13, 9].
 There has been a lot of interest in a particular setting of the online learning model, called online assumption is made that the function x t is convex in its argument. The particular convexity structure enables the development of optimization-based algorithms for learner X  X  choices. Learnability and precise rates of growth of regret have been shown in a number of recent papers (e.g. [33, 25, 1]). The online learning model also subsumes the prediction setting. In the latter, the learner X  X  choice of a Y -choice of the adversary. In Section 6 we discuss the prediction setting in more detail. distribution over some product X  X Y . Learnability results have been extensively studied in the the binary case (that is, Y = { X  1 , +1 } ) is completely characterized by finiteness of the Vapnik-Chervonenkis combinatorial dimension of the function class [32, 31]. In the real-valued case, a number of combinatorial quantities have been proposed: P -dimension [23], V -dimension, as well as the scale-sensitive versions P  X  -dimension [17, 5] and V  X  -dimension [3]. The last two dimensions were shown to be characterizing learnability [3] and uniform convergence of means to expectations for function classes.
 In contrast to the classical learning setting, there has been surprisingly little work on characterizing learnability for the online learning framework. Littlestone [19] has shown that, in the setting of prediction of binary outcomes, a certain combinatorial property of the binary-valued function class characterizes learnability in the realizable case. The result has been extended to the non-realizable case by Shai Ben-David, D  X  avid P  X  al and Shai Shalev-Shwartz [7] who named this combinatorial quantity the Littlestone X  X  dimension . In parallel to [7], minimax analysis of online convex optimiza-tion yielded new insights into the value of the game, its minimax dual representation, as well as algorithm-independent upper and lower bounds [1, 27]. In this paper, we build upon these results and the findings of [7] to develop a theory of online learning.
 We show that in the online learning model, a notion which we call Sequential Rademacher complex-ity allows us to easily prove learnability for a vast array of problems. The role of this complexity tend Littlestone X  X  dimension to the real-valued case. We show that finiteness of this scale-sensitive version, which we call the fat-shattering dimension , is necessary and sufficient for learnability in the prediction setting. Extending the binary-valued result of [7], we introduce a generic algorithm which plays the role similar to that of empirical risk minimization for i.i.d. data: if the problem is learnable in the supervised setting, then it is learnable by this algorithm. Along the way we de-velop analogues of Massart X  X  finite class lemma, the Dudley integral upper bound on the Sequential Rademacher complexity, appropriately defined packing and covering numbers, and even an analogue of the Sauer-Shelah combinatorial lemma. In the full version of this paper, we introduce a general-ization of the uniform law of large numbers for non-i.i.d. distributions and show that finiteness of the fat-shattering dimension implies this convergence.
 Many of the results come with more work than their counterparts in statistical learning theory. In particular, instead of training sets we have to work with trees, making the results somewhat involved. For this reason, we state our results without proofs, deferring the details to the full version of this paper. While the spirit of the online theory is that it provides a  X  X emporal X  generalization of the  X  X atch X  learning problem, not all the results from statistical learning theory transfer to our setting. For instance, two distinct notions of a packing set exist for trees, and these notions can be seen to coincide in  X  X atch X  learning. The fact that many notions of statistical learning theory can be extended to the online learning model is indeed remarkable. By phrasing the online learning model as a repeated game and considering its minimax value, we naturally arrive at an important object in combinatorial game theory: trees. Unless specified, all trees considered in this paper are rooted binary trees with equal-depth paths from the root to the leaves. While it is useful to have the tree picture in mind when reading the paper, it is also necessary to precisely define trees as mathematical objects. We opt for the following definition. Given some set Z , a Z -valued tree of depth T is a sequence ( z 1 ,..., z T ) of T mappings z i : { X  1 } i  X  1 7 X  Z . The root of the tree z is the constant function z 1  X  X  . Armed with this definition, we can talk about various operations on trees. For a function f : Z 7 X  U , f ( x ) denotes the U -valued tree defined by We shall abuse notation by referring to x i ( 1 ,..., i  X  1 ) by x i ( ) . Clearly x i only depends on the first i  X  1 elements of .
 We denote ( y a ,...,y b ) by y a : b . The set of all functions from X to Y is denoted by Y X , and the t -fold product X  X  ...  X X is denoted by X t . For any T  X  N , [ T ] denotes the set { 1 ,...,T } . Whenever the variable in sup ( inf ) is not quantified, it ranges over the set of all possible values. Fix the sets F and X and consider the online learning model stated in the introduction. We assume that F is a separable metric space. Let Q be the set of Borel probability measures on F . Assume that Q is weakly compact. We consider randomized learners who predict a distribution q t  X  X  on every round. Formally, define a learner X  X  strategy  X  as a sequence of mappings  X  t : X t  X  1  X F t  X  1 7 X  Q for each t  X  [ T ] . We define the value of the game as where f t has distribution q t . We consider here the adaptive adversary who gets to choose each x t based on the history of moves f 1: t  X  1 and x 1: t  X  1 .
 Note that our assumption that F is a separable metric space implies that Q is tight [28] and Prokhorov X  X  theorem states that compactness of Q under weak topology is equivalent to tightness [28]. Hence we have that Q is compact under weak topology and this is essentially what we need to apply a modification of Theorem 1 of [1]. Specifically we show the following: Theorem 1. Let F and X be the sets of moves for the two players, satisfying the necessary con-ditions for the minimax theorem to hold. Denote by Q and P the sets of probability distributions (mixed strategies) on F and X , respectively. Then The question of learnability in the online learning model is now reduced to the study of V T ( F , X ) , taking Eq. (2) as the starting point. In particular, under our definition, showing that the value grows sublinearly with T is equivalent to showing learnability.
 Definition 1. A class F is said to be online learnable with respect to the given X if The rest of the paper is aimed at understanding the value of the game V T ( F , X ) for various function classes F . Since complexity of F is the focus of the paper, we shall often write V T ( F ) , and the dependence on X will be implicit. One of the key notions introduced in this paper is the complexity which we term Sequential Rademacher complexity . A natural generalization of Rademacher com-plexity [18, 6, 21], the sequential analogue possesses many of the nice properties of its classical cousin. The properties are proved in Section 7 and then used to show learnability for many of the examples in Section 8. The first step, however, is to show that Sequential Rademacher complexity upper bounds the value of the game. This is the subject of the next section. Definition 2. The Sequential Rademacher Complexity of a function class F  X  R X is defined as where the outer supremum is taken over all X -valued trees of depth T and = ( 1 ,..., T ) is a sequence of i.i.d. Rademacher random variables.
 Theorem 2. The minimax value of a randomized game is bounded as V T ( F )  X  2 R T ( F ) . Theorem 2 relies on a technical lemma, whose proof requires considerably more work than the classical symmetrization proof [11, 21] due to the non-i.i.d. nature of the sequences. We mention that under strong assumptions on the space of functions, the Sequential Rademacher and the classical Rademacher complexities coincide (see [1]). In general, however, the two complexities are very different. For example, the discrepancy is exhibited by a class of linear threshold functions. In online learning, the notion characterizing learnability for binary prediction in the realizable case has been introduced by Littlestone [19] and extended to the non-realizable case of binary predic-tion by Shai Ben-David, D  X  avid P  X  al and Shai Shalev-Shwartz [7]. Next, we define the Littlestone X  X  dimension [19, 7] and propose its scale-sensitive versions for real-valued function classes. In the sequel, these combinatorial parameters are shown to control the growth of covering numbers on trees. In the setting of prediction, the combinatorial parameters are shown to exactly characterize learnability (see Section 6).
 Definition 3 ([19, 7]) . An X -valued tree x of depth d is shattered by a function class F  X  X  X  1 } X if for all  X  { X  1 } d , there exists f  X  F such that f ( x t ( )) = t for all t  X  [ d ] . The Littlestone dimension Ldim( F , X ) is the largest d such that F shatters an X -valued tree of depth d . Definition 4. An X -valued tree x of depth d is  X  -shattered by a function class F  X  R X , if there exists an R -valued tree s of depth d such that The tree s is called the witness to shattering . The fat-shattering dimension fat  X  ( F , X ) at scale  X  is the largest d such that F  X  -shatters an X -valued tree of depth d .
 With these definitions it is easy to see that fat  X  ( F , X ) = Ldim( F , X ) for a binary-valued function class F  X  { 0 , 1 } X for any 0 &lt;  X   X  1 . When X and/or F is understood from the context, we will simply write fat  X  or fat  X  ( F ) instead of fat  X  ( F , X ) .
 Let us mention that if trees x are defined by constant mappings x t ( ) = x t , the combinatorial pa-rameters coincide with the Vapnik-Chervonenkis dimension and with the scale-sensitive dimension P . Therefore, the notions we are studying are a strict  X  X emporal X  generalizations of the VC theory. As in statistical learning theory, the combinatorial parameters are only useful if they can be shown to capture that aspect of F which is important for learnability. In particular, a  X  X ize X  of a function class is known to be related to complexity of learning from i.i.d. data., and the classical way to measure  X  X ize X  is through a cover or a packing set. We propose the following definitions for online learning. Definition 5. A set V of R -valued trees of depth T is an  X  -cover (with respect to ` p -norm) of F  X  R X on a tree x of depth T if The covering number N p (  X , F , x ) of a function class F on a given tree x is the size of the smallest cover. Further define N p (  X , F ,T ) = sup x N p (  X , F , x ) , the maximal ` p covering number of F over depth T trees.
 In particular, a set V of R -valued trees of depth T is a 0 -cover of F  X  R X on a tree x of depth T if for all f  X  F and  X  { X  1 } T , there exists v  X  V s.t. v t ( ) = f ( x t ( )) . We denote by N (0 , F , x ) the size of a smallest 0 -cover on x and N (0 , F ,T ) = sup x N (0 , F , x ) . The 0 -cover should not be mistaken for the size |{ f ( x ) : f  X  F}| of the projection of F onto the tree x , and the same care should be taken when dealing with  X  -covers.
 We would like to comment that while in the i.i.d. setting there is a notion of packing number that upper and lower bounds covering number, in the sequential counterpart such an analog fails. 5.1 A Combinatorial Upper Bound We now relate the combinatorial parameters introduced in the previous section to the size of a cover. In the binary case ( k = 1 below), a reader might notice a similarity of Theorem 3 to the classical results due to Sauer [24], Shelah [26] (also, Perles and Shelah), and Vapnik and Chervonenkis [32]. There are several approaches to proving what is often called the Sauer-Shelah lemma. We opt for the inductive-style proof (e.g. Alon and Spencer [4]). Dealing with trees, however, requires more work than in the VC case.
 Theorem 3. Let F  X  X  0 ,...,k } X be a class of functions with fat 1 ( F ) = d 1 , fat 2 ( F ) = d 2 . Then Of particular interest is the case k = 1 , when fat 1 ( F ) = Ldim( F ) . Armed with Theorem 3, we can reduce the problem of bounding the size of a cover at an  X  scale by a discretization trick. For the classical case of a cover based on a set points, the discretization idea appears in [3, 22]. We now show that the covering numbers are bounded in terms of the fat-shattering dimension.
 Corollary 4. Suppose F is a class of [  X  1 , 1] -valued functions on X . Then for any  X  &gt; 0 , any T &gt; 0 , and any X -valued tree x of depth T , When bounding deviations of means from expectations uniformly over the function class, the usual approach proceeds by a symmetrization argument [12] followed by passing to a cover of the function class and a union bound (e.g. [21]). Alternatively, a more refined chaining analysis integrates over covering at different scales (e.g. [30]). By following the same path, we are able to prove a number of similar results for our setting. Next, we present a bound similar to Massart X  X  finite class lemma [20, Lemma 5.2]. This result will be used when integrating over different scales for the cover. 5.2 Finite Class Lemma and the Chaining Method Lemma 5. For any finite set V of R -valued trees of depth T we have that A simple consequence of the above lemma is that if F  X  [0 , 1] X is a finite class, then for any given tree x we obtain a p 2 T log( |F| ) upper bound. If f  X  F is associated with an  X  X xpert X  (see [9]), this result combined with Theorem 2 yields a bound given by the expert X  X  algorithm. In Section 8 we discuss this case in more detail. However, as we show next, Lemma 5 goes well beyond just finite classes and can be used to get an analog of Dudley entropy bound [10] for the online setting through a chaining argument.
 Definition 6. The Integrated complexity of a function class F  X  [  X  1 , 1] X is defined as The basic idea in the proof of the following theorem is the same as in statistical learning: R T ( F ) is bounded by controlling the complexity along the chain of coverings. The argument for trees, though, is more involved than the classical case.
 Theorem 6. For any function class F  X  [  X  1 , 1] X , R T ( F )  X  D T ( F ) In this section we study the supervised learning problem where player picks a function f t  X  R X | f ( x t )  X  y t | . Note that if F  X  X  X  1 } X and each y t  X  X  X  1 } then the problem boils down to binary classification problem. As we are interested in prediction , we allow f t to be outside of F . Though we use the absolute loss in this section, it is easy to see that all the results hold (with modified rates)  X  and  X  are monotonically increasing functions. For instance the squared loss is a classic example. To formally define the value of the online supervised learning game, fix a set of labels Y  X  [  X  1 , 1] . Given F , define the associated loss class, F S = { ( x,y ) 7 X  X  f ( x )  X  y | : f  X  X } . Now, the supervised game is obtained using the pair ( F S , X  X Y ) and we accordingly define V S T ( F ) = V T ( F S , X  X Y ) . Binary classification is, of course, a special case when Y = { X  1 } and F  X  { X  1 } X . In that case, we simply use V Binary T for V S T . Proposition 7. For the supervised learning game played with a function class F  X  [  X  1 , 1] X , for any T  X  1 Theorem 8. For any function class F  X  [  X  1 , 1] X , F is online learnable in the supervised setting then the value of the supervised game V S T ( F ) , the Sequential Rademacher complexity R ( F ) , and the Integrated complexity D ( F ) are within a multiplicative factor of O (log 3 / 2 T ) of each other. Corollary 9. For the binary classification game played with function class F we have that for some universal constants K 1 ,K 2 . This recovers the result of [7].
 We wish to point out that lower bound of Proposition 7 also holds for  X  X mproper X  supervised learning algorithms, i.e. those simply output a prediction  X  y t  X  Y rather than a function f t  X  F . Since a proper learning strategy can always be used as an improper learning strategy, we trivially have that if class is online learnable in the supervised setting then it is improperly online learnable. Because the above mentioned property of lower bound of Proposition 7, we also have the non-trivial reverse implication: if a class is improperly online learnable in the supervised setting, it is online learnable. 6.1 Generic Algorithm We shall now present a generic improper learning algorithm for the supervised setting that achieves a low regret bound whenever the function class is online learnable. For any  X  &gt; 0 define an  X  -for 0  X  k and (2 k + 1)  X   X  4 . Also for any a  X  [  X  1 , 1] define b a c  X  = argmin functions V  X  X  , any r  X  B  X  and x  X  X  define V ( r,x ) = { f  X  V | f ( x )  X  ( r  X   X / 2 ,r +  X / 2] } . The algorithm proceeds by generating X  X xperts X  in a way similar to [7]. Using these experts along with exponentially weighted experts algorithm we shall provide the generic algorithm for online supervised learning.
 Algorithm 1 Expert ( F , X , 1  X  i 1 &lt; ... &lt; i L  X  T,Y 1 ,...,Y L ) For each L  X  fat  X  ( F ) and every possible choice of 1  X  i 1 &lt; ... &lt; i L  X  T and Y 1 ,...,Y L  X  B  X  we generate an expert. Denote this set of experts as E T . Each expert outputs a function f t  X  F at every round T . Hence each expert e  X  E T can be seen as a sequence ( e 1 ,...,e T ) of mappings e t : X t  X  1 7 X  F . The number of unique experts is | E T | = P Using an argument similar to [7], for any f  X  F there exists e  X  E T such that for any t  X  [ T ] , | f ( x t )  X  e ( x 1: t  X  1 )( x t ) | X   X  .
 Theorem 10. For any  X  &gt; 0 if we run the exponentially weighted experts algorithm with the set E T of experts then the expected regret of the algorithm is bounded as
Further if F be bounded by 1 then by running an additional experts algorithm over the experts for discretizations over  X  , we can provide regret guarantee of Being able to bound complexity of a function class by a complexity of a simpler class is of great utility for proving bounds. In statistical learning theory, such structural results are obtained through properties of Rademacher averages [21, 6]. In particular, the contraction inequality due to Ledoux and Talagrand, allows one to pass from a composition of a Lipschitz function with a class to the function class itself. This wonderful property permits easy convergence proofs for a vast array of problems. We show that the notion of Sequential Rademacher complexity also enjoys many of the same properties. In Section 8, the effectiveness of the results is illustrated on a number of examples. First, we prove the contraction inequality.
 Lemma 11. Fix a class F  X  R Z and a function  X  : R  X Z 7 X  R . Assume, for all z  X  X  ,  X  (  X  ,z ) is a L -Lipschitz function. Then R (  X  ( F ))  X  L  X  R ( F ) where  X  ( F ) = { z 7 X   X  ( f ( z ) ,z ) : f  X  X } . The next lemma bounds the Sequential Rademacher complexity for the product of classes. Lemma 12. Let F = F 1  X  ...  X F k where each F j  X  R X . Also let  X  : R k 7 X  R be L -Lipschitz w.r.t. k X k  X  norm. Then we have that R (  X   X F )  X  L O log 3 / 2 ( T ) P k j =1 R ( F j ) . Corollary 13. For a fixed binary function b : { X  1 } k 7 X  { X  1 } and classes F 1 ,..., F k of { X  1 } -valued functions, R ( g ( F 1 ,..., F k ))  X O log 3 / 2 ( T ) P k j =1 R ( F j ) .
 In the next proposition, we summarize some basic properties of Sequential Rademacher complexity (see [21, 6] for the results in the i.i.d. setting): Proposition 14. Sequential Rademacher complexity satisfies the following properties: ( i ) if F  X  X  ,  X  : R 7 X  R is L -Lipschitz, then R (  X  ( F ))  X  L R ( F ) ; ( v ) For any h , R ( F + h ) = R ( F ) where F + h = { f + h : f  X  X } . Example: Linear Function Classes Suppose F W is a class consisting of linear functions x 7 X   X  w,x  X  where the weight vector w comes from some set W , F W = { x 7 X  X  w,x  X  : w  X  X } . Often, it is possible to find a strongly convex function  X ( w )  X  0 such that  X ( w )  X   X  max &lt;  X  for all w  X  X  (for example the function k w k 2 2 on any bounded subset of R d ).
 Theorem 15. Let W be a class of weight vectors such that 0  X   X ( w )  X   X  max for all w  X  W . Suppose that  X  is  X  -strongly convex w.r.t. a given norm k  X  k . Then, we have, R T ( F W )  X  kXk ? p 2  X  max T/ X  , where kXk ? = sup x  X  X  k x k ? , the maximum dual norm of any vector in the input space.
 The above result actually allows us to recover the O ( (including Zinkevich X  X  online gradient descent) obtained in the online convex optimization literature. There, the set X is set of convex Lipschitz functions on a convex set F . We interpret f ( x ) as x ( f ) . It is easy to bound the value of the convex game by that of the linear game [2], i.e. one in which X is the set of linear functions. Then we directly appeal to the above theorem to bound the value of the linear game. The online convex optimization setting includes supervised learning using convex losses and linear predictors and so our theorem also proves existence of O ( in that setting.
 Example: Margin Based Regret We prove a general margin based mistake bound for binary classification. This shows the generality of our framework since we do not require assumptions like convexity to bound the minimax regret. The proof of the following result uses a non-convex Lipschitz  X  X amp X  function along with Lemma 11. As far as we know, this is the first general margin based mistake bound in the online setting for a general function class.
 Theorem 16. For any function class F  X  R X bounded by B , there exists a randomized player strategy  X  such that for any sequence ( x 1 ,y 1 ) ,..., ( x T ,y T )  X  ( X  X { X  1 } ) T , Example : Neural Networks and Decision Trees We now consider a k -layer 1 -norm neural network. To this end let function class F 1 be given by for 2  X  i  X  k . The theory we have developed provides us with enough tools to control the sequential Rademacher complexity of classes like the above that are built using simpler components. The following result shows that neural networks can be learned online. A similar result, but for statistical learning, appeared in [6]. Let X  X  R d , and X  X  be such that  X  x  X  X  , k x k  X   X  X  X  . Theorem 17. Let  X  : R 7 X  [  X  1 , 1] be L -Lipschitz. Then We can also prove online learnability of decision trees under appropriate restrictions on their depth and number of leaves. We skip the formal statement in the interest of space but the proof proceeds in a fashion similar to the decision tree result in [6]. The structural results enjoyed by the sequential Rademacher complexity (esp. Corollary 13) are key to making the proof work.
 Example: Transductive Learning and Prediction of Individual Sequences Let F  X  R X and N  X  (  X , F ,T )  X  b N  X  (  X , F ) for all T . This simple observation can be applied in several situations. First, consider transductive learning , where the set X = { z 1 } n i =1 is a finite set. To ensure online learnability, it is sufficient to consider an assumption on the dependence of b N  X  (  X , F ) on  X  . An obvious example of such a class is a VC-type class with b N  X  (  X , F )  X  ( c/ X  ) d for some c which can depend on n . Assuming that F  X  [0 , 1] X , the value of the game is upper bounded by 2 D T ( F )  X  4  X  value of the game is at most 4 p dT log( eT ) , matching the result of [15] up to a constant 2 . In the context of prediction of individual sequences, Cesa-Bianchi and Lugosi [8] proved upper bounds in terms of the (classical) Rademacher complexity and the (classical) Dudley integral. The particular assumption made in [8] is that experts are static . Formally, we define static experts as map-pings f : { 1 ,...,T } 7 X  [0 , 1] , and let F denote a class of such experts. Defining X = { 1 ,...,T } puts us in the setting considered earlier with n = T . We immediately obtain 4 p dT log( eT ) , match-ing the results on [8, p. 1873]. For the case of a finite number of experts, clearly b N  X   X  N which gives the classical O ( Example: Isotron Recently, Kalai and Sastry [16] introduced a method called Isotron for learn-ing Single Index Models (SIM), which generalize linear and logistic regression, generalized linear models, and classification by linear threshold functions. A natural open question posed by the au-thors is whether there is an online variant of Isotron. Before even attempting a quest for such an algorithm, we can ask a more basic question: is the (Idealized) SIM problem even learnable in the online framework? We answer the question in positive with the tools we have developed by proving that the following class (with X a Euclidean ball in R d and Y = [  X  1 , 1] ) is learnable: where u and w range over the possibilities. Using the machinery we developed, it is not hard to show that the class H is online learnable in the supervised setting. Moreover, V T ( H , X  X Y ) = O (  X 
