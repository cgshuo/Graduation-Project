 In the age of big data, automatic methods for creating sum-maries of documents become increasingly important. In this paper we propose a novel, unsupervised method for (multi-)document summarization. In an unsupervised and language-independent fashion, this approach relies on the strength of word associations in the set of documents to be summarized. The summaries are generated by picking sen-tences which cover the most specific word associations of the document(s). We measure the performance on the DUC 2007 dataset. Our experiments indicate that the proposed method is the best-performing unsupervised summarization method in the state-of-the-art that makes no use of human-curated knowledge bases.
 I.2.7 [ Natural Language Processing ]: Language mod-els X  abstracting methods, summarization Multi-Document Summarization; Word Associations We propose a novel method for document summarization, Association Mixture Text Summarization, aimed to abstract a news story into a shorter text. Like most other meth-ods, Association Mixture Text Summarization works in a sentence-based manner, selecting a set of sentences from the document to be summarized to constitute its summary. The sentences are chosen so that they collectively cover as much of the relevant information in the original document as pos-sible. The main difficulties are to define what is relevant and to measure how well sets of sentences cover relevant information. Our method has three central characteristics: (1) Relevance is based on the relative associations between words, helping to grasp the most salient information in a news story. Much of the core content of news stories is in the http://dx.doi.org/10.1145/2600428.2609500 links they establish, e.g., between people, acts, events, and places. We argue that associations at subtler levels can also be important, even ones between adjectives or adverbs and noun or verbs used in the news. Recognition of associations is based on statistical analysis of word co-occurrences within sentences. We believe that such associations reflect the key ideas of news and are useful for selecting sentences. (2) Novel associations in a document are recognized by contrasting them against a background corpus. News stories are supposed to tell something new and a key problem in summarization is to identify what is new in a given doc-ument. We treat this as a novelty detection task by con-trasting the document to a background corpus to see which associations are emphasized more in the document. (3) Natural language processing is trivial, making the method language-independent. All processed documents are split to sentences and tokens (words) based on punctuation and whitespaces; numbers are removed, and the remaining tokens are used as they are, without any further processing.
In this paper we focus on the sentence selection subtask of document summarization. We do not address the issue of arranging or processing the sentences for improved read-ability. We evaluate the method in English using public benchmarks, and leave experiments with other languages for future work. In the experiments, our proposed method outperforms all unsupervised summarization methods that do not use semantic resources such as Wordnet.

This paper is organised as follows. We next briefly review related work. We then present the Association Mixture Text Summarization method in Section 3. The performance of the method is evaluated in Section 4, while Section 5 concludes this article with a discussion.
Document summarization is a well-studied area. There are two types of summarizations methods: methods which select existing sentences and methods which generate sen-tences. Both of these types of methods can be either super-vised or unsupervised, i.e., either learning from examples of existing summaries or not. We focus on the unsupervised domain, of which we give a very brief overview. Nenkova and McKeown [10] provide an exhaustive review of the topic.
Some methods use Latent Semantic Analysis (LSA) [2] as their basis (e.g. [4]). The state-of-the art in purely unsuper-vised summarization is represented by the DSDR method of He et al. [5]. This approach generates a summary by us-ing sentences that best  X  X econstruct X  the original document. This work has been extended by Zhang et al. [11] who com-bined document reconstruction and topic decomposition.
A number of unsupervised methods take advantage of ad-ditional linguistic resources. In particular, the Two-Tiered Topic model by Celikyilmaz [1] uses Wordnet [9] and the DUC-provided user query for selecting the summary sen-tences. The Document Understanding Conference 1 (DUC) provides most evaluation procedures and collections in the summarization field. We provide further details in Section 4.
The Association Mixture Text Summarization method proposed below takes as its input a document D to be sum-marized and a background corpus B consisting of a set of documents representing the norm or the current state of in-formation.
 As a special case, the background corpus can be empty. Additionally, by extension, instead of a single document a set of documents can be summarized by simply giving their concatenation as the input document D , as will be done in the experimental section.

The method has two parts: (1) computation of document-specific word associations, and (2) selection of sentences with strong word associations. These two steps are described in the following subsections.
We consider two relevance criteria for associations in the given document D .

First, an association between two words is more relevant if they are statistically mutually dependent, i.e., if they co-occur in D more frequently than they would by chance. This, of course, is a classic idea.

Second, and more interestingly, the association is charac-teristic for document D if the two words co-occur in D more frequently than in the background corpus B .

The second criterion is in principle more useful since it uses additional data to assess the association, but it is of little value if the background corpus is small or if the words or the word pair does not occur in the corpus. Our method therefore uses a mixture model of the two criteria above.
Notation. We first define the notation for various counts of words and word pairs in document D and in back-ground B . Let t i and t j be words. We use n ij to denote the number of sentences in document D that contain both words t i and t j , n i  X  j the number of sentences containing word t i but not t j , n  X  ij the number of sentences containing t but not t i , and n  X  i  X  j the number of sentences containing neither t i nor t j . We use n i  X  = n ij + n i  X  j to denote the total number of sentences containg word t i , and respectively for n . Let n = | D | denote the total number of sentences in and m be the respective counts in the background corpus B .
Statistical Model. Consider the association between words t i and t j . We use multinomial distributions to model the probabilities of observing different combinations of existence/non-existence of words t i and t j in a sentence. The four respective model parameters are p ij , p i  X  j and p  X  i  X  j , affecting the likelihood of the observed counts n next, and the fit of the data to these models is later used to assign a weight to the association between t i and t j . The http://duc.nist.gov/ third model is the Association Mixture model, while the first two are simpler models that will be used as the components of the mixture.

For convenience, we below define the models using pa-rameters p i  X  (the probability of observing word t i ), p probability of observing word t j ), and p ij (the probability of observing both t i and t j ). These give more natural defini-tions for the models. The multinomial model parameters can then easily be obtained as p i  X  j = p i  X   X  p ij ; p  X  ij p
The independence model (component) p D-ind consid-ers observed frequencies of words t 1 and t 2 only in docu-ment D and assumes that they are statistically independent: p If the data fits this model badly, i.e., essentially if n ates a lot from n i  X   X  n  X  j /n , then the words are likely to be statistically dependent.

The background model (component) p B estimates all three parameters from the respective relative frequencies in the background corpus B : If the data fits this model badly then the word pair occurs in the document differently from the background. This signals that the association is novel.

The association mixture model p B+D-ind averages the two components above, weighted by their sample sizes n and m : p B+D-ind = ( n  X  p D-ind + m  X  p B ) / ( n + m ). This gives In other words, the mixture model combines information from document D itself and from the background B . Their relative weights adapt to their relative sizes, giving more emphasis to the statistically more reliable source of infor-mation.

Association Weights. The weight of the association be-tween two words is based on a log-likelihood ratio test [3]. The test compares two models for each word pair: (1) a null model, in our case the mixture model, and (2) a max-imum likelihood alternative model. If the likelihood of the alternative model is much higher, then the null model is less likely to be true. In other words, the mixture model is an expression of expectations, and we are actually interested in finding exceptions to them.

The maximum likelihood model p D is obtained by simply assigning the model parameters directly from the observed relative frequencies: p D i  X  = n i  X  /n ; p D  X  j = n  X  j
Let L ( p D ) be the likelihood of the maximum likelihood ment D , and let L ( p B+D-ind ) be the likelihood of the mix-ture model given the same counts. We define the weight w ( t i , t j ) of the association between t i and t j as the value of the respective log-likelihood ratio test: Multinomial coefficients in the likelihoods cancel out, and after simplification we have
The log-likelihood ratio test gives lower weights for word pairs that better match the mixture model and higher weights for those associations that are unexpected with re-spect to the mixture model. In text summarization, we are interested in word pairs that have a higher relative frequency in the document D than in the background B , and that have a high log-likelihood ratio.
The other subtask is to select from document D sentences that contain strong word associations. In the sentence selec-tion phase, our goal is to preserve as many of the stronger associations and thereby as much as possible of the core contents of the original document D .

Given a fixed target size of the summary (e.g. 250 words) and the association weights, we aim to pick sentences such that the sum of the log-likelihood ratios of word pairs in the summary is maximized. To avoid selecting sentences with too similar content, each pair is taken into account once.
Formally, let document D be a set of sentences and let each sentence be a set of words. We call any subset S = { s 1 , . . . , s 0 s }  X  D of sentences a summary of D . We define the total weight of associations in summary S as i.e., as a sum over the set of word pairs in any sentence of the summary. Every pair is only counted once.
 In the sentence selection step we aim to find a summary S  X   X  D with a maximal total weight, i.e., where || S || is the number of words in summary S . In our experiments below, the upper limit is set to L = 250 words.
This problem is similar to the weighted set cover prob-lem [6]: use sentences of the document to cover as much of the associations as possible. Due to the limited length of the summary, a natural  X  X ost X  of a sentence is the number of words in it. Given the computational complexity of the task, we resort to a greedy algorithm [6] to find a summary S that approximates the optimum S  X  .

For the sake of simplicity, in the experiments below we add sentences to the summary S until the maximum size is reached ( || S ||  X  L ) and then simply truncate the summary to L words.
In this section, we describe experiments carried out to evaluate the proposed Association Mixture Text Summa-rization method. We aim to address the following questions: (1) How does the method perform in comparison to state-of-the-art unsupervised summarization methods? (2) What are the contributions of the components p B and p D-ind to the method? (3) What is the effect of the size of the background corpus B on the quality of the summaries?
For experiments and comparisons we use the DUC 2007 dataset consisting of 45 topics. Each topic of 25 documents from the AQUAINT corpus of English news is to be sum-marized into a collective abstract of at most 250 words.
The evaluation measure is the well-known ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [8]. We use the model summaries of the DUC datasets and their associated tools to compute the ROUGE measures. Accord-ing to Lin and Hovy [7] the ROUGE-1 score has the best correspondence with human judgements. It is therefore the main focus of our evaluation. We experimented with sev-eral background corpora: the Brown corpus, the G  X  utenberg corpus, the Reuters RCV-1 corpus, as well as combinations.
Data Preprocessing. We remove all markup tags from the documents and leave only the headline and textual con-tent of the news story. We then split the content to sentences with the DUC 2003 sentence segmentation tool and keep all words of length at least two.

Comparative Evaluation. We compare the Associa-tion Mixture Text Summarization method against results given in literature for state-of-the-art unsupervised summa-rization methods: Document Summarization Based on Data Reconstruction, linear and non-linear (DSDR-lin, DSDR-non) [5], Topic DSDR (TDSRD) [11], Two-Tiered Topic Model (TTM) and Enriched TTM (ETTM) [1]. The last two use Wordnet and topic description as additional resources. We also include two baseline methods provided with the DUC: NIST BL and CLASSY04. The latter is actually a supervised method.
Association Mixture Model and Its Two Compo-nents: In terms of F-measure for ROUGE-1, Figure 1 illus-trates the performance of the overall model and the inde-pendence and background corpus components as functions of the size of the background corpus B .

The performance improves from 0.380 to 0.422 as the size of the background B grows from 10 to 10,000 sentences. This illustrates how a larger background corpus is a simple but effective way to provide auxiliary information to the summa-rization process. In our experiments, 1,000 X 3,000 sentences were already sufficient as a background corpus. The im-provement after this was very limited.

Next, consider the performance of the two components of the model individually. The independence component does obviously not depend on the background corpus B and is hence represented by a horizontal line on the figure.
The background component, in turn, shows a longer pe-riod of improvement than the Association Mixture model and converges later than the 1,000 X 3,000 sentences range.
Overall, the Association Mixture Text Summarization method seems to successfully combine the two components into a model that clearly dominates both of them. Contrary to our expectations, there is a clear margin over the back-ground component for large background corpus sizes, even though the relative weight of the independence component is very small there.

Comparison to Other Methods. A comparison to state-of-the-art in unsupervised summarization methods shows that the Association Mixture model is very competi-tive (Table 1). ROUGE-1 results are additionally shown as thin, unlabeled horizontal lines in Figure 1.
