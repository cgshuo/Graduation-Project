 Modern web search engines, while indexing billions of web pages, are expected to process queries and return results in a very short time. Many approaches have been proposed for efficiently computing top-k query results, but most of them ignore one key factor in the ranking functions of com-mercial search engines -term-proximity , which is the metric of the distance between query terms in a document. When term-proximity is included in ranking functions, most of the existing top-k algorithms will become inefficient. To address this problem, in this paper we propose to build a compact phrase index to speed up the search process when incorpo-rating the term-proximity factor. The compact phrase index can help more accurately estimate the score upper bounds of unknown documents. The size of the phrase index is con-trolled by including a small portion of phrases which are possibly helpful for improving search performance. Phrase index has been used to process phrase queries in existing work. It is, however, to the best of our knowledge, the first time that phrase index is used to improve the performance of generic queries . Experimental results show that, compared with the state-of-the-art top-k computation approaches, our approach can reduce average query processing time to 1/5 for typical setttings.
 H.3.3 [ Information Search and Retrieval ]: Search Pro-cess; H.3.4 [ Systems and Software ]: Performance evalua-tion (efficiency and effectiveness) Algorithms, Performance, Experimentation  X 
This work was done when the author was an intern at Mi-crosoft Research Asia.
 Top-k , Dynamic index pruning, Term proximity, Phrase in-dex, Compact phrase indexing
Modern commercial web search engines are expected to process queries very efficiently, typically thousands of queries in one second. It is a challenging task considering that they have grown to index billions of pages. To improve search efficiency, various efficient query processing approaches [1, 3, 4, 8, 9, 10, 11, 13, 17] have been proposed and studied. Given that only top few (e.g., top-10) results instead of all relevant documents are often required in IR and web search, these strategies speed up the searching process by carefully reordering documents in the inverted index and skipping the relevance computation of some documents on retrieval time. Most of existing efficient top-k approaches assume that the following type of ranking functions is utilized in evaluating documents, where F(D,Q ) represents the overall relevance score of docu-ment D to query Q , G(D) is the (query-independent) static rank (e.g., PageRank [6]), and T(D,t) is the term-score of D with respect to query term t, computed via a term-weighting function (e.g., BM25 [16]). And  X  ,  X  , and  X  t are parameters satisfying  X  +  X  = 1 and
Ranking functions of the above format come from stan-dard IR models and have been utilized in real information retrieval problems. It is therefore meaningful for efficient top-k approaches to be proposed and studied based on them in traditional IR. Large scale web search engines, however, typically adopt much more complex ranking functions which contain additional important factors/features than those in-cluded in Formula 1. Among them, term-proximity is an important factor which is critical for the search quality of large scale web search engines.

Term-proximity demonstrates how close query terms ap-pear in a document. Intuitively, one document in which query terms are near in the document should be more rel-evant to the query than another document in which query terms are far away from one another, if other factors are the same for the two documents. Take query { knowledge management } as an example. It is clear that quite a lot of pages on the web containing both  X  X nowledge X  and  X  X an-agement X  are actually irrelevant to knowledge management. While if term  X  X nowledge X  appears in a document followed by term  X  X anagement X , the document will be very probably relevant.

When the term-proximity factor is considered in ranking functions, approaches optimized for Formula 1 may not be efficient anymore. Specifically, approaches based on frequency-ordering [1] or impact-ordering [4] become inefficient, be-cause high term scores do not mean high term-proximity scores. According to [20], mainstream top-k strategies even perform worse than the baseline (in which all documents are evaluated and no top-k processing strategies is adopted) when the weight of term proximity scores is large enough.
Including term-proximity in ranking functions does not mean treating queries as phrase queries . A phrase query is a multi-term query that only matches documents contain-ing query terms as a phrase (i.e., query terms appear in the document consecutively). End users typically input a phrase query to web search engines by surrounding query terms in double quotation marks or connecting them via hyphens, e.g., {  X  X nowledge management X  } or { knowledge-management } . A document is not treated as being relevant to phrase query {  X  X nowledge management X  } if it only con-tains text snippet  X  X he management of knowledge X  but not  X  X nowledge management X . However, the same document is considered to be relevant to non-phrase query { knowledge management } .

Phrase queries are a special type of queries which are able to be processed efficiently via phrase indexing [5, 18]. In phrase indexing, inverted lists are built for phrases rather than single terms. The inverted list for a phrase includes the information of all documents containing the phrase. It is clear that, to process a phrase query, only the inverted list for the phrase need to be scanned, which should be more efficient than scanning the inverted lists corresponding to all the query terms contained in the query.

Given that 1) most existing top-k approaches fail to ef-ficiently answer generic queries with term-proximity sup-port, and 2) phrase indexing is efficient in processing phrase queries, one natural question is: Can phrase indexing be uti-lized for speeding up generic (non-phrase) queries ? After all, most query strings input by end users are not surrounded by double quotation marks or connected by hyphens (thus not strict phrase queries).

It is however not that easy for generic (non-phrase) queries to be processed via phrase index. If only the phrase index is scanned to answer a generic query, good documents may be omitted, because a relevant document is not necessary to contain the whole phrase for a generic query.

In this paper, we explore how to efficiently process generic (non-phrase) queries with the aid of phrase indexing. We build a compact phrase index , in addition to the standard in-verted index for single terms. Based on the compact phrase index, we propose a retrieval strategy which, in processing a query, scans both the phrase index and the inverted lists for all its query terms. The strategy speeds up the search process by making a more accurate estimation of the score upper bounds of unknown documents. The size of the phrase index is controlled by including a small portion of phrases which are possibly helpful for improving search performance. Experimental results show that, for typical settings, our ap-proach reduces average query processing time to 1/5, com-pared with existing mainstream efficient top-k approaches in the literature. Thus the answer to the above question is Figure 1: Inverted lists for terms  X  X nowledge X  and  X  X anagement X  (documents are ordered by static rank).
 YES. To the best of our knowledge, it is the first time to utilize phrase index to improve the performance of generic queries .

The rest of this paper is organized as follows. Section 2 contains some background information, including the brief introduction of inverted index, and existing efficient query processing approaches. Related work is discussed in Sec-tion 3. Section 4 analyzes the difficulties of top-k processing when term proximity is included in ranking functions. Our approach is illustrated in detail in Section 5. Section 6 is experimental setup and results. Finally Section 7 is conclu-sions and future work.
Indexing and ranking are two key components of a web search engine. To support efficient retrieval, a web collection needs to be offline indexed. Given a query, one ranking function is adopted to compute a relevance score for each document based on the information stored in the index. The documents are then sorted by their scores and the top k documents with the highest scores are returned to end users.
One primary way of indexing large scale web documents is the inverted index , which consists of many inverted lists , corresponding to different terms. For a term t , its inverted list includes the information (doc-ids, occurring positions, etc) of all documents containing the term. Zobel and Moffat [21] give a comprehensive introduction to inverted index for text search engines. Figure 1 shows the inverted lists of term  X  X nowledge X  and  X  X anagement X  respectively. In the figure,  X  D 356 , 0.99 X  represents a document with doc-id 356 and static-rank value 0.99.
Various dynamic index pruning techniques have been pro-posed for efficient top-k computation. They aim to correctly identify the top k results without completely scanning in-verted lists and/or computing the relevance scores of all documents. One common idea shared among most existing efficient query processing approaches is score upper-bound estimation and early stopping . During processing a query, the maximal possible score of all unseen (or un-evaluated) documents is estimated. When the maximal possible score is not greater than the score of the k th document in current top-k , we can skip processing the remaining documents and return current top-k results to users. Let S k to be the score of the k th document (in terms of relevance scores) in pro-cessing a query, and S T to be the maximum possible score of all unseen documents. Then the early-stopping condition is,
The organization of inverted index is the key to score upper-bound estimation. For example, if documents are nat-urally ordered by doc-ids in inverted lists, it should be hard to get a desired score upper-bound estimation, because it provides little information about the scoring factors of un-seen documents.

Order by Static-Rank One simple way of organizing inverted lists for improving top-k computation is to have documents sorted in descending order by static rank scores as shown in Figure 1. The intuition here is that, since static rank is an important factor of a ranking function (Formula 1), documents with relatively high static rank scores are more likely to appear in the final top results. Because doc-uments are sorted by static-rank, the score upper-bound of unseen documents can be estimated as, where g cur is the static rank of the last seen document (i.e., the last document we evaluated till now), and t max ( t ) is the maximum value of all the term scores in the inverted list for term t .

Such an index structure achieve hardly any performance gain in practice, except when the static-rank weight (  X  ) is set to be large (e.g., larger than 0.5).

Multi-segment Divided by Impact Values Another index structure is to divide an inverted list into multiple segments according to one type of specific term impact val-ues, with documents in each segment ordered by doc-id or static-rank [4, 11, 14]. The phrase  X  X erm impact X  is first adopted by Anh and Moffat [3] to represent term scores, TFs or other factors related to the relevance score of a doc-ument to a term. As the weight of static rank is typically smaller than that of term weighting scores in real ranking functions, splitting inverted lists by impact scores might be more effective than purely sorting documents by static rank. The reason of ordering documents in each segment by doc-id or static-rank is for ease of merging multiple inverted lists in processing multi-term queries and for effective index com-pression. In such an index structure, the score upper-bounds of unseen documents can be estimated as (assuming we are now in segment i ),
In case of two documents having the same static score, they can be sorted in ascending order by doc-id. If inverted list compression is required or critical, documents can be re-assigned new doc-id according to static rank scores, e.g. the document with the maximal static rank is assigned doc-id 0. A hashtable or an array can be used to maintain the relationship between new doc-ids and old ones if necessary. where t max ( t, i, j ) is the maximum term score of all docu-ments from segment i to segment j , g cur is the static rank of the last seen document in current segment, g max is the maximum static rank of all documents, and s is the number of segments. In the above formula, S T 1 represents the max-imal score of the remaining documents in current segment, and S T 2 represents the score upper bound of documents in remaining segments (from i + 1 to the last segment).
Such an index structure of dividing index by impact values is typically able to achieve much better performance than purely ordering documents by static-rank.
Efficient query processing is an important topic both in databases (DB) and in information retrieval (IR) and web search. In database community, Fagin et al. have a series of comprehensive work [8, 9, 10] on efficient top-k computa-tion. As Fagin states, if multiple inverted lists are sorted by attributes value and the combination function is monotonic, then an efficient top-k algorithm exists.

In information retrieval area, the work of index pruning could go back to 1980s. Their main idea is to sort the entries by their contribution to the score of the document and put the important entries in the front of inverted index for early termination. Much work has attempted to optimize the in-dex structure in various ways. Persin et al. [14] propose to partition the inverted list into several parts. After PageRank shows its power in web search, pruning techniques consider-ing PageRank are studied by Long [11]. Recent top-k work [13] includes the study of keyword locality and document locality to get an optimized ratio between small index and full index.

There were a couple of proposals for accelerating phrase queries via phrase indexing. Williams et al. [5, 18] further propose NextWord index to get a better trade-off between search performance and index size. NextWord index can be treated as a special kind of phrase index which takes less disk space by storing the first term only once if multiple phrases share the same first-term. As demonstrated in the introduc-tion section, it is not straightforward to utilize phrase index to speed up generic (non-phrase) queries.

Zhu et al. [20] suggest organizing the inverted index by document structure, which performs better than other ap-proaches for term proximity. They address the term proxim-ity problem indirectly by adopting document structure. For documents which are not structured (i.e., containing only one field), the approach degrades to one traditional approach which does not perform well for ranking functions consider-ing term-proximity. Differently, we address this problem in this paper directly by building a compact phrase index which does not depend on document structure. Our ap-proach in this paper is orthogonal to the approach in [20] and can hopefully be combined with it to achieve better performance. We would like to leave it as future work. We are also aware of some other interesting related work. Suel and Long [12] proposed the intersection-caching to ex-ploit frequently occurring pairs. Their intersection list con-tains postings with document ID and information about all occurrences of both words in the document. Moura et al. [7] develop a locality based static pruning method which utilizes proximity constraints (by phrases) to achieve the reduction in index size and result in the save of query processing time. Static index pruning may lead to the degradation of results quality.
Term proximity means the distance relationship between query terms in a document. Given that there are typically a lot of documents containing all query terms in large scale web search, term-proximity is very important in helping to discriminate highly relevant documents from generally rele-vant ones.

When term-proximity is included, a reasonable ranking function could be as follows, F ( D, Q ) =  X   X  G ( D )+  X  1  X  where X ( D, Q ) is the term-proximity score of document D to query Q, G ( D ) is the static rank of D , and T ( D, t ) is the term-score of D with respect to query term t , computed via a term-weighting function (e.g., BM25 [16]). Parameters  X ,  X  1 and  X  2 satisfy  X  +  X  1 +  X  2 = 1. One formula for term-proximity computation is proposed in [15].

The above ranking function will be presumed in the re-maining part of the paper. Without loss of generality, we assume all static rank scores, term weighting scores and term proximity scores have been normalized into [0.0, 1.0]. When the ranking function of Formula 1 is replaced by Formula 5 with the term-proximity factor included, the es-timation of score upper bounds (e.g., Formula 3 and 4) may also change. As a result, the performance of existing top-k processing approaches may change accordingly. Here is a brief analysis.

Taking the index structure of multi-segment divided by impact values in Section 2.2 as an example, the score upper bound of Formula 4 is changed to S where x max is the maximal possible term-proximity score of unseen documents. To achieve better performance, we hope x max is estimated properly (with as low value as possible). For a multi-term query, however, it may not be easy to esti-mate the maximal term-proximity score of a document given its maximal possible term scores. Given query { knowledge management } , for example, assume it has been known that the maximal possible term scores of document D for terms  X  X nowledge X  and  X  X anagement X  are respectively 0.7 and 0.8. Such information could hardly help to lower down the esti-mation of its maximal term-proximity score, because term-proximity scores depend heavily on the distance between query terms. Therefore we have to assume x max = 1 . 0 at the moment before finding better upper-bounds.

We are interested in the delta between S T and S  X  T . The larger the value of score upper-bound S  X  T , the less chance of the early-stopping condition (Formula 2) being satisfied. Considering that  X  +  X  1 +  X  2 =  X  +  X  = 1, we have
Note that t max ( t, i ) &lt; 1 if we are currently not in the first segment (i.e., i &gt; 1), for the term impact scores of all documents in segment i is smaller than the impact scores in segment i  X  1. Considering that x max = 1 . 0 (refer to the discussion above), we have S  X  T 1  X  S T 1 &gt; 0. In other words, the estimated score upper bound gets larger when term proximity is included. In addition, the bigger the term-proximity weight (  X  2 ), the larger the estimated score upper bound. Similarly, S  X  T 2 gets larger when the weight of term-proximity increases.

In summary, unlike term weights, whose upper bounds can be effectively lowered down via placing documents with high term scores on top of inverted lists, because term-proximity scores are determined by the distance relation-ship between query terms, we lack an effective estimation of term-proximity upper-bounds in most existing index struc-tures.
As has been discussed in the previous section, the hardness of properly estimating the upper-bound of term-proximity scores is the main reason why most existing approaches do not perform well when term-proximity is included in ranking functions.

Fortunately, phrase index can provide some clues which help to constrain the range of term-proximity values 2 . In our approach, a compact phrase index is built based on which a lower score upper-bound for term-proximity scores is estimated. By this way, the maximal possible score of un-seen documents is reduced accordingly, resulting in better retrieval performance.
Intuitively, if it is already known that a document does not contain the query as a phrase (i.e., query terms are not adja-cent in the document), then the term-proximity score of the document should be less than the maximal possible term-proximity score a document could have. That is because, according to the definition of term-proximity, when mov-ing query terms together in a document, its term-proximity score should increase. Formally, a reasonable term-proximity formula should have the following property.

Phrase-Friendly Property : Assume a term-proximity function has maximal score value X M . The function is said to be phrase-friendly if and only if there exists a constant  X  &lt; 1 such that for any document which does not contain the query as a phrase, its term-proximity score is not greater than  X   X  X M .
 Example : Let X  X  study a very simple term-proximity for-mula for two-term queries. For query Q = { t 1 , t 2 } , where p 1 , p 2 are the positions of query term t 1 and t document D respectively. The above formula reaches the
Please keep in mind that phrase index itself cannot be used independently to answer generic (non-phrase) queries. maximal value of 1.0 when p 2 = p 1 + 1 (i.e., when term t followed by t 2 ). And if it is given that phrase  X  t 1 t appear in a document, the maximal possible term-proximity score for the document reduces to 1/4. Therefore, the above formula satisfies the phrase-friendly property with  X  = 1 / 4.
With the phrase-friendly property, if we know that a doc-ument does not contain the query as a phrase, then its maxi-mal possible term-proximity score can be lowered down from X M to  X   X  X M .

So the basic idea of our approach is simple: utilizing a phrase index to lower down the estimated score upper-bound of term proximity. Our approach works by making extra ef-forts in both offline index building phase and online retrieval phase. In the offline index building phase, a compact phrase index is built for some key phrases, recording all documents containing the phrases. While in the query processing time, we first refer to the phrase index to evaluate all documents containing the query phrase. And then the inverted lists corresponding to all the query terms are scanned. When we check the early-stop condition of Formula 2 in process-ing the term inverted lists, all documents containing the query phrase are omitted because they have been processed in scanning the phrase index. Therefore the maximal possi-ble term-proximity score is bounded by  X   X  X M rather than X
M . This way, we hope query processing can stop earlier than existing approaches.

In the remaining parts of this section, we give some de-tails about offline phrase-index building and online query processing.
Phrase index building can be performed by following a routine similar to term index building, or embedded in the process of term index building to avoid accessing the docu-ment collection for multiple times.
 Two things are important for building the phrase index: First, we should choose an appropriate phrase index format to achieve the best tradeoff among performance, index size, and flexibility. Second, it is desired to include only a subset of phrases in the phrase index to reduce index size and to save index building time.
In terms of how the information of a document is arranged and stored in the inverted list of a phrase, at least three phrase index formats are available: doc-id list, doc-score list , and extended hit list . They are illustrated in Figure 2, 3, and 4 respectively.

Figure 2 shows, for some sample phrases, the phrase index of the first format (doc-id list). In the figure, phrase  X  X ew account X  appears in documents D 3 , D 63 , D 124 , etc. Such an index can be treated as a lookup table with which we are able to quickly know whether a document contains a query
Figure 3: Phrase index format II: doc-score list Figure 4: Phrase index format III: extended hit-list phrase. We will describe, in Section 5.3.2, how to process queries efficiently based on such a phrase index format.
Figure 3 shows the second format of phrase index ( doc-score list ). In the figure, &lt; D 3 , 0.8 &gt; means the document with identifier 3 gets pre-processed score 0.8 for query { new account } . The scores of each document in the phrase index are calculated beforehand in offline processing time. When processing a query, we first process the phrase index, and then refer to the inverted lists for terms. As all documents containing the query phrase have been processed, we expect a lower score upper bound for unseen documents when pro-cessing the inverted lists of query terms. Section 5.3.1 gives the details of retrieval strategies based on this index format. The third phrase index format is depicted in Figure 4. In this index format, we try to keep all the occurrences (or hits) information of query terms in a document if the doc-ument contains the phrase. Each hit is attached with one flag with value L , R or A . Hit L :25 means that the first (or left) term of the phrase appears in position 25 without fol-lowed by the second term. Similarly, R :83 means that the second (or right) term of the phrase appears in position 83, but the term in position 82 is not the first term. And A :9 means the phrase appears in position 9 (i.e., the first term appears in position 9 and the second term appears in posi-tion 10). Therefore the meaning of &lt; D 63, 2[ A :9, R :83] &gt; is: The phrase appears in position 9 of document D 63 , and the second term also appears in position 83. Retrieval strategies for this kind of index format are discussed in Section 5.3.1.
Each of the above formats has its own advantages and drawbacks, as summarized in Table 1. From the viewpoint of index size, it is clear that phrase indices of the first two formats are much smaller than the third, for they do not keep the occurrence information. It is more time-consuming to build a phrase index of format II, because it requires pre-computing the scores of all documents in the phrase in-dex. Index format I is expected to achieve fair performance gain by helping to skip the evaluation of significant number of documents (refer to corresponding retrieval strategies in Section 5.3). And the performance of the other two index formats (II and III) should be better, because they help to Expected Retrieval Performance Fair Good Good achieve early-stopping. It is often important for the phrase index to be flexible to support different ranking functions and parameters. Format II loses such flexibility as the doc-ument scores are precomputed. We will validate our analysis via experiments in Section 6.
Ideally, the phrase index can be built for all bigrams ap-pearing in the document collection. This would, however, yield a large phrase index (about two times of the term in-dex). Although large index itself does not have great impact on online retrieval performance (given that the inverted list for one phrase is small), the time cost for building a large index is significant. We should guarantee that the overhead of building the phrase index does not outweigh the benefits of online performance gain.

We observed that there are much more different phrases (bigrams) than terms in a common web collection; and the index of some phrases may not be very helpful in improving search performance. Table 2 is a statistics (on the GOV2 dataset, refering to Section 6.1 and Table 3) about the per-centage of phrases in different frequency slots. Terms and phrases are divided into three slots by frequency: popular , normal , and rare . All web pages in the GOV2 dataset are distributed on five machines, with each machine indepen-dently determine whether a term or a phrase is popular, normal, or rare. For each machine, a term is treated as being  X  popular  X  if it appears in at least 50,000 documents (i.e. one percent of documents). And the term-frequency threshold between normal terms and rare terms is 500. For phrases, the frequency thresholds among rare , normal , and popular phrases are 10 and 10,000. In the table, row  X  X op-ular + normal X  means the first term of the phrase is popu-lar and the second is normal; and column  X  X are X  means the phrase itself is rare. We can learn from the bottom right cell of the table that there are about 37.851% phrases which are rare themselves and each of which consists of two rare terms. Intuitively, if a phrase itself is rare in frequency, we can consider not adding it into the phrase index, because the possibility of users inputting it as a query is small. And if both terms of the phrase is rare, we can also exclude it from the phrase index, because the query could be efficiently processed by the term index (without the aid of the phrase index). Therefore, we choose to only build the phrase index for the phrases which are not rare themselves and contain at least one popular or normal term. From Table 2, we can see that most phrases can be excluded from the phrase index by the above filtering policy. Please note that the filtering policy is query-independent. Thus we do not need to know a list of queries beforehand in index building time.
To build the compact phrase index, it seems we need to scan the collection two times: the first time for calculating term frequency information, and the second time for build-ing the inverted index. It is not a big problem since web Table 2: Phrase statistics by term and phrase fre-quencies (Dataset: GOV2) Term Freq/Phrase Freq Popular Normal Rare Popular + Popular 0.014% 2.003% 0.003% Popular + Normal 0.001% 1.576% 0.206% Popular + Rare 0.000% 0.422% 8.875% Normal + Popular 0.001% 1.669% 0.200% Normal + Normal 0.000% 0.620% 3.037% Normal + Rare 0.000% 0.100% 16.029% Rare + Popular 0.000% 0.411% 10.237% Rare + Normal 0.000% 0.094% 16.587%
Rare + Rare 0.000% 0.063% 37.851% search engines typically need to rebuild indices frequently. The term/phrase frequency information of the last index-build can be utilized in index building this time.
Once the compact phrase index with one specific format has been built, a retrieval strategy is needed in online re-trieval time for efficient query processing. The design of a re-trieval strategy depends on the phrase index format and the structure of the term index. In discussing retrieval strate-gies here, we assume all queries to be processed contain two terms. Readers may find it is not hard (although not that straightforward) to extend most of the strategies to queries of arbitrary length. We would like to leave as future work the processing of queries with length larger than two.
Figure 5 shows our retrieval strategy for phrase-index for-mat III ( extended hit-list ) and the order-by-static-rank index structure. According to the strategy, query processing con-sists of two major steps: processing the phrase index, and processing term inverted lists. In the first step, documents in the phrase index are retrieved in turn and added into current top-k list if their scores are large enough. Since all documents containing the query phrase have been processed in the first step, we need only in the second step to consider the documents in which query terms are not adjacent. The early-stop condition is checked after processing a document in the term inverted lists. By the phrase-friendly property (Section 5.1), the score upper-bound of unseen documents should be as follows,
If the phrase index is not processed first, the score upper-bound of unseen documents would be,
Since  X  &lt; 1, we get a lower (and therefore better) esti-mation of S T with the aid of the phrase index. The whole process ends when S T satisfies the stopping condition.
Please note that routine R .AddDoc does more work than simply adding a document to top-k list R . It checks whether R contains at least k documents or whether the score of the k th document is smaller than d 0 s score. The document will be added into R only if | R | &lt; k or d  X  X  score is larger than the k 0 th score in R . Figure 5: Retrieval strategy for efficient query pro-cessing with the aid of compact phrase index (phrase index format: extended hit-list ; term index struc-ture: order by static-rank )
The retrieval strategy for phrase index format II is almost the same as that shown in Figure 5, except that the  X  X valuate d  X  line in procedure ProcessPhraseIndex is omitted, for d  X  X  score has been pre-computed and stored in the phrase index.
In the case of the inverted index being divided by impact scores into multiple segments (refer to Section 2.2), the re-trieval strategy is similar but slightly more complex. A doc-ument score accumulator should be maintained to record the partial scores of the documents which have the possibility of being in top-k . Details are omitted due to space limitations.
The phrase index format I ( doc-id list ) is quite different in query processing from the other two formats. This is because not enough information is available in the phrase index of this format for computing the scores of its docu-ments. Figure 6 shows the retrieval strategy for this phrase index format. In the strategy, the early-stop condition is harder to be satisfied (please pay attention that Formula 10 is utilized to estimate S T now). The phrase index P is uti-lized here as a lookup table. When a document d is in not in the table, which means that the document does not contain the query phrase, Formula 9 can be utilized to estimate its possible maximal score. If the estimated maximal score is Figure 6: Retrieval strategy for efficient query pro-cessing with the aid of compact phrase index (phrase index format: doc-id list ; term index structure: or-der by static-rank) Table 3: Test collections used in the experiments not larger than the k 0 th score in R , it will not be necessary to send the document to the ranking function to evaluate it. Considering that document score computation (especially term-proximity score computation) is time-consuming, this strategy improves document processing efficiency via skip-ping the score computation of significant number of docu-ments.
Datasets : We use two TREC (http://trec.nist.gov) test collections in the experiments, as illustrated in Table 3. The GOV collection consists of about 1.25 million web pages crawled from web sites in the .gov domain in 2002; and the GOV2 corpus is a crawl of .gov sites in early 2004 (please refer to http://ir.dcs.gla.ac.uk/test collections/ for more in-formation about the two collections).

Query Sets : We select 15,105 two-term queries out of the set 2006 Efficiency task topics from Terabyte Track 2006.
Hardware and Software Environment : For the GOV dataset, experiments are carried out on a single machine with Dual 2.4 GHz AMD Opteron Processor 250, 8G RAM and 840 GB local SATA disk. While for corpus GOV2, we distribute its documents to 5 machines (via URL hashing), with each machine having about 5 million documents in-dexed. The 5 nodes exchange link information by network communication, based on which each document X  X  static rank is computed and its anchor text is accumulated. Only one CPU per machine is used in the pruning experiments, i.e., we are running a single-thread program on each machine.
Index Structures and Strategies: The following in-dex structures and strategies are compared under various settings, Doc-id, and no pruning strategies are performed. by static rank. The traditional top-k strategy is adopted. segment, and a low score segment. Documents in each seg-ment are sorted by static rank. The traditional top-k strat-egy is adopted. index . The pruning strategies in section 5.3 are adopted. index . The pruning strategies in section 5.3 are adopted.
Parameters : Given one kind of index structure, the per-formance of a top-k algorithm depends on the parameters in the ranking function. We tested different parameter values (as shown in Table 4) in the experiments, trying to give a comprehensive comparison between different pruning strate-gies. Parameter  X  measures the importance of static rank in computing document scores. The optimal value of  X  may vary from corpus to corpus. Common practice tells us that its value should not exceed 0.5. The weight of term proxim-ity scores relative to that of term weighting scores is deter-mined by how much we emphasize the importance of prox-imity score in the ranking function
Evaluation Metrics : There are basically two kinds of metrics for evaluating a top-k algorithm: search quality (P@10, average precision, etc), and processing performance (average query processing time, throughput, etc). As this paper only focuses on exact top-k computation, all strate-gies are required to return the same results as no pruning being performed. So we measure the performance of pruning by average query execution time. Experiments are conducted with different parameters in Table 4 and the results are presented as follows. First we compare our approach with some existing ones in search performance. Then the three phrase index formats are com-pared. Finally, we study how the values of various parame-ters affect the performance of our approach.
First we study how effective the compact phrase index is in improving query processing performance when term-proximity is included in ranking functions.

Table 5 shows the performance (measured by average pro-cessing time) comparison among various approaches on dif-ferent datasets and query sets. We can see that the 2-Seg-Phrase approach performs much better than others on such parameter settings. This demonstrates that, when combined with proper term index structures, our approach can achieve Table 5: Average query execution time of vari-ous approaches on different datasets and query sets (Static Rank weight  X  = 0 . 3 , Relative Term Proxim-ity Weight  X  2 / X  1 = 1 ; return top 10 results) Avg Proc. Time (s) All Queries Hard Queries Table 6: Comparison of three types of compact phrase index formats (the average query processing time is performed by 2-seg-phrase with parameter settings in Table 5, the size is measured by the ratio of compact phrase index compared to the original single term inverted index) apparent performance improvements (saving more than 65% of average processing time on the GOV2 dataset). Existing approaches ( 1-seg and 2-seg ) only have very small perfor-mance improvements relative to the baseline. The 1-Seg-Phrase approach performs not that good on the specific pa-rameter settings, partially because the 1-Seg index structure is less efficient than the 2-Seg index structure.
Slightly more performance improvements are observed for  X  X ard X  queries (queries with baseline processing time over one second). We can see that the 2-seg-phrase approach re-duces more than 80% of the processing time on the GOV2 dataset. Performance improvements over hard queries is es-pecially important, as users typically would not like to wait more than one second to see the search results.
Here we compare, by experimental results, the perfor-mance and cost of the three phrase index formats illustrated in Section 5.2.1.

Table 6 lists the performance and size of the three formats of compact phrase index. As expected, the performance of format I is up to 15% worse than the other two formats. While the performance difference of the other two struc-tures is very small, which indicates the cost of extra online evaluation for documents in the compact phrase index is not significant. Regarding the space overheads, Format III con-sumes much more disk space as it stores all the occurrences information needed for online evaluation. The size of format II index is a bit bigger than the format I as it has to store scores as well as doc-ids.

Please notice that we have not yet applied any compres-sion techniques to these phrase indexes. It is clear that continuous doc-ids and postings could be effectively com-
Parameters Description Values pressed [19, 21]. Document scores can also be presented by simplified term ranks which occupies smaller space [2]. The phrase indices are going to be smaller if these techniques are applied.
In this section, we study how different parameters in the ranking function affect the performance of different top-k processing approaches.

In Figure 7 we vary the static rank weight from 0.1 to 0.5 (from practical experiences, in most scenarios it X  X  unrea-sonable to have too big static rank weight). All the struc-tures benefit from the increase of  X  value. With the compact phrase index , the top-k processing time drops dramatically as  X  value increases. We can see that the 2-seg-Phrase struc-ture could save nearly 40% of time even when  X  is 0.1. How-ever, without the compact phrase index , there is hardly any performance gain from the traditional index structures when  X  is smaller than 0.3. Figure 7: Query execution time for different static-rank weights (Relative Term Proximity Weight  X  / X  1 = 1 )
Figure 8 presents how the query processing performance will be affected by the term-proximity score weight. When proximity score weight is 0, which means term proximity is not included in the ranking function, utilizing the multi-segment divided by impact values index structure could save more than 90% of query processing time. In this setting, our approach behaves as well as 2-Seg-Phrase . However, when proximity score is considered, the performance of traditional strategies drops quickly.
It is challenging to process queries efficiently when term-proximity is included in ranking functions, mainly because it is hard to get a good estimation of the upper-bound of term-proximity scores based on the maximal possible term scores. This paper demonstrates that a phrase index can be Figure 8: Query execution time for different relative term-proximity weights (static-rank weight  X  = 0 . 3 ) effectively utilized to improve the efficiency of generic (non-phrase) queries by reducing the upper-bound estimation of term-proximity scores.

In the future, we would like to study how to extend our ap-proach to support queries containing more than two terms. Another direction for future studies is to explore better phrase filtering strategies to reduce the phrase index size. [1] V. N. Anh, O. de Kretser, and A. Moffat. Vector-space [2] V. N. Anh and A. Moffat. Simplified similarity scoring [3] V. N. Anh and A. Moffat. Pruned query evaluation [4] V. N. Anh and A. Moffat. Pruning strategies for [5] D. Bahle, H. E. Williams, and J. Zobel. Efficient [6] S. Brin and L. Page. The anatomy of a large-scale [7] E. S. de Moura, C. F. dos Santos, D. R. Fernandes, [8] R. Fagin. Combining fuzzy information from multiple [9] R. Fagin. Combining fuzzy information: an overview. [10] R. Fagin, A. Lotem, and M. Naor. Optimal [11] X. Long and T. Suel. Optimized query execution in [12] X. Long and T. Suel. Three-level caching for efficient [13] A. Ntoulas and J. Cho. Pruning policies for two-tiered [14] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered [15] Y. Rasolofo and J. Savoy. Term proximity scoring for [16] S. Robertson, S. Walker, and M. Beaulieu. Okapi at [17] M. Theobald, G. Weikum, and R. Schenkel. Top-k [18] H. E. Williams, J. Zobel, and D. Bahle. Fast phrase [19] I. H. Witten, A. Moffat, and T. C. Bell. Managing [20] M. Zhu, S. Shi, M. Li, and J.-R. Wen. Effective top-k [21] J. Zobel and A. Moffat. Inverted files for text search
