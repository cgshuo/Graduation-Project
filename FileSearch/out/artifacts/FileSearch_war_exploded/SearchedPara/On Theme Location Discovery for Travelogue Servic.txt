 In this paper, we aim to develop a travelogue service that discovers and conveys various travelogue digests, in form of theme locations, geographical scope, traveling trajectory and location snippet, to users. In this service, theme loca-tions in a travelogue are the core information to discover. Thus we aim to address the problem of theme location dis-covery to enable the above travelogue services. Due to the inherent ambiguity of location relevance, we perform loca-tion relevance mining (LRM) in two complementary angles, relevance classification and relevance ranking, to provide comprehensive understanding of locations. Furthermore, we explore the textual (e.g., surrounding words) and geographi-cal (e.g., geographical relationship among locations) features of locations to develop a co-training model for enhancement of classification performance. Built upon the mining result of LRM, we develop a series of techniques for provisioning of the aforementioned travelogue digests in our travelogue system. Finally, we conduct comprehensive experiments on collected travelogues to evaluate the performance of our lo-cation relevance mining techniques and demonstrate the ef-fectiveness of the travelogue service.
 H.3.3 [ Information Storage and Retrieval ]: Information Filtering; I.2.7 [ Artificial Intelligence ]: Natural Language Processing Experimentation classification, ranking, co-training, travelogue services
Continued flourish of World Wide Web (WWW) and ad-vance of transportation systems have made travel , an inte-gral part of our life, very easy. Particularly, with the ad-vantages of Web 2.0 technology, many people are willing to  X  Part of this work was done when the author was visiting Microsoft Research Asia.
 share their travelogues , which record travel experiences, on weblogs, forums and social communities for travels, (e.g., TravelPod 1 , IgoUgo 2 and TravelBlog 3 ).

Travelogues, which usually contain rich travel informa-tion, such as the tours, lodging, meals, expenses, weather conditions, and so on, are highly valuable to a trip planner. Thus, many people turn to on-line travelogue archives or dis-cussion forums to review travelogues well before taking their trips. While reading travelogues may be fun and enjoyable for some, digging into numerous travelogues to find useful trip information is a tedious and boring task for many. Thus, there is a need for developing automatic travelogue mining techniques to convey useful information in a travelogue to its readers in a more effective way.

Generally, there are two kinds of information for a travel-ogue to be mined; (1)  X  X hereabout X  of the travelogue, and (2)  X  X ow-about X  of the mentioned attractions.

As a travelogue intends to record activities and experi-ences of its author at locations on a trip (i.e., the where-about of the trip), a key problem related to (1) concerns extraction of theme locations , i.e., locations appeared in a travelogue which are closely relevant to the main themes of the travelogue. Location extraction techniques have been developed in the past [1, 14]. However, due to the nature of human language presentation, locations extracted are not necessarily theme locations of the travelogue. For example, in Figure 1, Siesta Key is very relevant to the theme of this paragraph but Boston is not.
 Figure 1: A paragraph in a travelogue for Siesta Key. Relevant locations are in bold, partial relevant locations are in teletype , and irrelevant locations are in italic .

Another important problem, related to (2) is about ex-tracting specific how-about information regarding theme lo-cations. Hao et. al. [7] pioneered a knowledge discovery technique that extracts general information (e.g., food, surf-ing, shopping) regarding travel destinations from a corpus of travelogues. However, this technique has mainly focussed on location information extraction without distinguishing http://www.travelpod.com http://igougo.com http://www.travelblog.com whether locations in a travelogue is relevant to its themes or not. As a result, the result is inevitably biased by noisy locations.

To tackle the theme location discovery problem, we pro-pose to extract textual features of locations (e.g., surround-ing words and syntactic pattern) as well as geographical fea-tures of locations (e.g., individual location types, structural constraints derived from location ontology) for location rel-evance mining. With those features, we perform location relevance classification to differentiate relevant theme loca-tions from others in a travelogue. Moreover, we propose a co-training model, by taking advantages of the independent textual and geographical views of the extracted features, to boost classification performance,
Unfortunately, human perception of locations relevant to the themes of a travelogue tends to be fuzzy! Different peo-ple may employ different personal criteria to assess relevant theme locations. What X  X  more, the content of a travelogue may sometimes be insufficient for one to decide whether a location is a theme location or not. However, based on the context of a travelogue, we often can still tell whether a lo-cation l A is more relevant than another location l B to the travelogue, without necessarily deciding whether l A and l are considered as theme locations or not. Based on this ob-servation, we also develop algorithms for location relevance ranking.

Relevance classification and ranking provide two alterna-tive and complementary aspects in our study of location relevance mining. To our best knowledge, there is no exist-ing work addressing the issues of location relevance mining for a given travelogue, not to mention its support for provi-sioning of various information digests in a travelogue service. Built upon the mining result of location relevance mining, we develop a series of techniques, including theme locations detection, geographical scope calculation, travel trajectory extraction and location snippet extraction, to embody a travelogue service which not only enable trip planners. to find where to go but also what to do. Finally, we conduct a comprehensive set of experiments on collected travelogues to validate our ideas, evaluate the performance of our location relevance mining techniques, and demonstrate the effective-ness of the travelogue service.

The main contributions made in this paper are summa-rized as follows.
The remainder of the paper is organized as follows. Sec-tion 2 introduces the most related literatures. Section 3 pro-vides a overview about location relevance mining for theme location discovery. Section 4 describes the features we ex-tract to perform location relevance study, and Section 5 dis-cusses the detailed algorithms for location relevance mining. Section 6 introduces the techniques to realize travelogue ser-vices built upon LRM. Section 7 conducts performance eval-uation to validate the proposed location relevance mining techniques and demonstrate the travelogue service. Finally, Section 8 concludes the paper and discusses the future work.
In this section, we first introduce some existing studies on spatial information retrieval, such as news and travelogues. Then we review techniques related to location relevance min-ing, followed by a brief summary of semi-supervised learning techniques.

Location-based search has received a lot of interests from both the academia and industry in the past few years. With advances in location extraction techniques [1, 14], spatial interests expressed in text can be learned to support web services for users looking for spatial information [6, 1, 17, 13]. Wang et. al. propose a notion of query dominant location (QDL) to detect the locations truly searched for by queries [17]. On the contrary, Ding et. al., propose to study the geographical extent of spatial web resources that their creators intend to reach [6]. Amitay et. al. propose to assign to each page a (or a few)  X  X eographic focus X  in [1]. They identify the focus of a given page by assigning different confidence score for different locations and use hierarchical structure of location terms to summarize locations with high confidence. Silva et. al. [16] propose to use a graph-based approach akin to PageRank to determine a single scopes for each document, based on a geographic knowledge repository. In [13], Aencar et. al. describe strategies for document clas-sification into geography-related categories, using evidence extracted from Wikipedia. Recently, Hao et. al., aiming to provide travelogue services based on summarization of a travelogue corpus, propose to mine location-specific knowl-edge from a large collection of travelogues using a proba-bilistic generative model [7]. Different from most existing work, our study enables provisioning of travelogue digests in our travelogue system, and provide new views for users to understand a travelogue.

In this paper, we explore location relevance classification and ranking techniques to address the issues of location rel-evance mining. While there exist many textual classification techniques such as Support Vector Machine (SVM) [2] and logistic regression [2] and document ranking methods [15, 10, 9, 5] in the literature, the problem of location relevance min-ing discussed in this paper is very much new, which requires a unique treatment of certain geographical characteristics. For example, Siesta Key is a sibling city of Tampa, while Florida is the state where Siesta Key and Tampa reside. These unique geographical characteristics motivate us to ex-plore interesting location features in devising techniques for location relevance classification and ranking.

In this paper, we follow the semi-supervised learning parad -igm to address the issues of location relevance mining. Semi-supervised learning is desirable for our study because we have obtained a small set of labeled data and a large vol-ume of unlabeled data. The key idea of semi-supervised learning is to enrich labeled training data by labeling unla-beled data via certain learning techniques. Basically, there are three techniques to realize semi-supervise learning, in-cluding (1) using the EM (expectation-maximization) algo-rithm to estimate the parameters of a generative model and the labels of unlabel data [12], (2) defining a graph over the data instances on the basis of certain similarity metric and determining the labels of unlabeled data [3], and (3) using co-training algorithms to exploit the strengthes of multiple learners to label the unlabeled data [4, 8]. In this work, we realize the semi-supervised learning by exploring two in-dependent views, i.e., textual and geographical views, in a co-training approach.
Theme location discovery aims to discover and assess the theme locations in a given travelogue. The problem of theme location discovery raises two different yet complementary questions: (1) what locations in a travelogue are theme lo-cations? (2) given two locations in a travelogue, which one is more likely to be a theme location?
These two questions are difficult to answer because we don X  X  know exactly what is the main theme of a travel-ogue perceived by author and readers. However, based on the intention of travelogue writing, we argue that there in-deed exist one or more themes in a travelogue, which match well with the purposes/activities/destinations of this trip. To identify the theme locations, one naive approach is to mandate the travelogue authors to supply them or have the readers to label them, but this manual approach is hard to enforce. Moreover, there are already a huge volume of travel-ogues made available on-line. Therefore, a mining technique that extracts the theme locations for a given travelogue au-tomatically is highly desirable. Based on observations ob-tained in our preliminary study of labeled travelogues, the theme locations perceived by different people are similar to some extent, even though they may not be the same. Thus, by leveraging the human knowledge, we apply a supervised learning approach to automatically discover theme locations from travelogues using a labeled training dataset. Moreover, as mentioned earlier, we adopt a semi-supervised learning approach to enrich the limited labeled dataset in order to boost the learning performance. To answer the two ques-tions raised above, we study the issues of location relevance for finding the theme locations in two complementary as-pects: location relevance classification and location relevance ranking .
 Location relevance classification. The first question can be considered as a classical classification problem by extracting features for each candidate location in the travel-ogue. However, as we mentioned before, there is an inherent ambiguity among different people in terms of how relevant a candidate location is to the theme of the travelogue. What X  X  more, the content of travelogue is sometimes insufficient to assess whether a location is a theme location or not. For example, in Figure 1, one may assess that Siesta Key is the only theme location; while another person may consider both Sarasota and Florida are also theme locations. Thus, as shown in Figure 2, the main challenge for location rel-evance classification is where to set a boundary separating theme location from irrelevant locations.
 Location relevance ranking. Instead of determining whether a location is a theme location, the second question we aim to answer is whether one location is more relevant than another location to the theme of this trip. As shown in Figure 2, assuming that Siesta Key is the sole theme, we may assess that Tampa is less relevant to the theme location Figure 2: Dilemma in relevant location classification than Sarasota. In this paper, we adopt two alternative ap-proaches, namely location likelihood estimation and learning to rank , for location relevance ranking. As discussed in Sec-tion 2, while document classification and ranking techniques have been explored for document retrieval, there is an inher-ent difference between travelogues and documents because locations in a travelogue usually have some interesting rela-tionship, e.g., Siesta Key is a sibling city of Tampa, while Florida is the state which covers Siesta Key and Tampa. Thus, conventional document mining techniques cannot be applied directly to our problem. These unique spatial char-acteristics motivates us to explore interesting features for location relevance mining.
To perform location relevance mining, it is essential to identify useful features of a location that can help to as-sess whether the location is relevant to main themes of the travelogue or not. Since travelogues are textual documents recording the authors X  experiences in touring places of inter-ests, it naturally contains textual and geographical features. Thus, we identify features associate with locations in these two aspects. Table 1 summarizes the features extracted in our study.
 Category Features Textual Geographical
On the one hand, for a travelogue, we usually have a title to summarize the theme of the travel. The most relevant lo-cations are usually included there. What X  X  more, interested locations might be mentioned several times in a travelogue, while irrelevant locations appear less frequently. According to this observation, we extract two kinds of features, namely, is in title? (denoted as F 1 ) and number of appearance (de-noted as F 2 ), respectively. Besides, surrounding words of a location also provides useful hints. For example, in Fig-ure 1, one may easily understand that  X  X iesta Key X  is the most relevant location name in this paragraph, because im-portant locations are usually heading the paragraphs. Thus for a location in a travelogue, we use its surrounding words to extract bag-of-word feature (denoted as F 3 ) and syntac-tic pattern feature (denoted as F 4 ) to describe the location. Those above four features are categorized as textual feature.
On the other hand, each location as a physical entity holds geographical properties in the real word. For example, lo-cation names referred in a travelogue usually have different location types in location partonomy. As shown in Figure 3, among the locations mentioned in the travelogue in Figure 1, some of them are state name (e.g., Florida), while some are county or township names (e.g., Sarasota and Siesta Key). Location names with smaller scope usually hold higher rel-evance, otherwise, travelers would not bother to mention them in the travelogue. Thus, we consider the location type to be an important feature, named as location type (denoted as F 5 ).
 Figure 3: Partonomy hierarchy of locations men-tioned in the travelogue shown in Figure 1
Additionally, relevant locations are usually clustered in the partonomy hierarchy of a location ontology. Moreover, people would likely stay in the same state or the same city during the trip. In other words, partonomy distance among the locations provides important information to leverage rel-evant locations. More specifically, we extract the partonomy distance among locations as feature (denoted as F 6 ) as fol-lows. Let the partonomy distance ( d par ) between two loca-tions be the total number of hops in the partonomy hierarchy to their immediate common ancestor. Let l 1 and l 2 be two different locations mentioned in a given travelogue, and l be the immediate common ancestor of l 1 and l 2 . where hops ( l x ,l y ) denotes the number of hops between l and l y along the path of partonomy hierarchy (it equals zero if l x = l y ). For example, in Figure 3, we have the partonomy distance between  X  X iesta Key X  and  X  X oston X  computed as 5, where the immediate common ancestor is  X  X nited State X . Finally, if two locations are far away, e.g., Siesta Key and Boston in Figure 3, only one of them could likely be the relevant location for a travelogue. Therefore, we consider geographical proximity ( d geo ) between two different loca-tions (mentioned in the same travelogue) to be an impor-tant feature (denoted as F 7 ). More specifically, let l be two different locations mentioned in a given travelogue, and their latitude and longitude are denoted as ( x 1 ,y 1 ( x 2 ,y 2 ) respectively. For simplicity, we use Euclidian dis-tance to present the geographical distance between l 1 and l as follows.
In this section, we introduce algorithms to realize the two mining tasks, namely, location relevance classification and location relevance ranking , for theme location discovery.
Location relevance classification aims to predict whether a location is relevant to the theme of the travelogue or not. As aforementioned, both textual and geographical features are able to assess whether a location is relevant to the theme of a travelogue or not, so we exploit both feature sets of a location to realize location relevance classification. Because of its popularity and good performance in text mining, we Figure 4: Co-training framework for location rele-vance classification adopt SVM to perform supervised classification. Neverthe-less, based on our preliminary study, directly applying SVM to perform supervised classification does not produce a good performance. On the one hand, location relevance classifi-cation is very challenging due to the inherent ambiguity of location relevance and the limited amount of labeled data available. On the other hand, we noticed that travelogues naturally contains two independent feature sets, i.e., textual and geographical features. Aiming to boost the performance of location relevance classification, we adopt the co-training framework (i.e., semi-supervised learning) as shown in Fig-ure 4 to explore the two feature sets in order to enrich the training set with high-quality newly labeled data in order to obtain a better SVM classifier model. As one of the popu-lar semi-supervised learning algorithms, co-training is a per-fectly fit for the classification of location relevance here. It has been shown in [12] that co-training works well under two conditions: (1) each set of features is sufficient for clas-sification, and (2) the two feature sets of each instance are conditionally independent. As both textual and geographi-cal features provide strong hints about whether a location is relevant to the theme location of the travelogue. Based on our preliminary experimentation, we found that the SVM classifiers modeled based on either textual features or ge-ographical features are capable of doing location relevance classification. Moreover, textual and geographical features are proposed to capture the characteristics of a location in totally independent angles, and thus complementary with each other. With both of the above conditions hold, we adopt co-training to boost the performance for location rel-evance classification.

Figure 4 illustrates the proposed framework for overall location relevance classification. As shown, the location ex-traction component in our system scans the travelogue cor-pus to extract the locations together with their features for each travelogue. The resulted datasets, including candidate set and training set corresponding to unlabeled and labeled travelogues, are fed to the co-training module to produce a enriched training set (including the original training set plus those high quality newly labeled data) for further classifica-tion in the final SVM module (i.e., the bottom box of the figure). Notice that, the final SVM module performs clas-sification in the entire feature space including both textual and geographical features.

Co-training is an iterative process, which typically runs on a large corpus of text documents (i.e., the candidate set) to-gether with a seed training data set (i.e., labeled travelogues here). The main idea of our co-training framework is to explore both textual features and geographical features as-sociated with locations in travelogues to independently and iteratively mine high-quality labels for travelogues. Our co-training algorithm starts with a small number of seed data in the training set. By treating the data instance space in two different views, namely, textual view and geographical view, we have X = X t  X  X g , where X denotes the entire feature space, while X t and X g present textual feature space and geographical feature space, respectively. Iterating between these two different views, we use two separate SVMs (one for each view) to decide the labels for those unlabeled travel-ogues in the candidate set. With newly labeled travelogues, we validate their labels by assigning confidence scores, which are derived based on the distance of a given travelogue to the classification hyperplane learned by SVM. More specifi-cally, the confidence score s ( x ) for a newly labeled travelogue x  X  X t (or X g ) is calculated as follows. where w  X  is the optimized hyperplane, while b is the bias term. In order to enrich the training set with high-quality la-beled travelogues, we derive a good confidence score thresh-old  X  based on a validation dataset and the current training model learned in each round. As such, only high-quality data (i.e., those newly labeled travelogues with high confi-dence scores ( s ( x )  X   X  ) are included the training set. As the co-training runs, the training set is enriched continu-ously until it converges eventually. Finally, a new training dataset larger than the original one is derived from the co-training process. We then adopt SVM to learn upon this new training dataset in the complete feature space (includ-ing both textual and geographical features) to obtain the final classifier model.
Location relevance ranking aims to sort locations in ac-cordance with their relevances to the theme of a travelogue. It can be analogized to the problem of document relevance ranking. In location relevance ranking problem, we treat the themes of a travelogue as the query keywords, locations in-cluded in the travelogue as candidate documents. However, different from traditional document retrieval, the query key-words (i.e., themes) are implicitly contained in travelogues instead of explicitly specified by users. Here, we introduce two alternative approaches, namely, location likelihood esti-mation and learning to rank algorithms to address the rank-ing problem.
A travelogue is written to record the trip experiences of the author over visited theme locations. Thus, an idea to estimate and rank the relevance of a location in a travelogue to the main themes of the travelogue, motivated by language modeling in information retrieval, is to consider the genera-tion probability of a location in the travelogue. Let l and t denote a location and a travelogue, we use p ( l | t ) to denote the probability of l appearing in the observed travelogue t . Intuitively, the larger the generation probability of l in t holds, the more relevant l is to the travelogue t . Thus, we define the relevance of location l to a travelogue t as below. where  X  is a smoothing factor, and M t and M c are the lo-cation vocabularies built upon travelogue t and the whole corpus respectively. tf l,t ,tf l are term frequency of location term l appearing in travelogue t and the whole travelogue corpus respectively, and N t and N are the number of loca-tion terms in travelogue t and the whole travelogue corpus, respectively.
Recall our example in Figure 1. There are five locations included in the travelogue, but each of them appears only once in the whole document. Based on location likelihood estimate, we may assign them the same rankings, given that smoothing is not applied. Since Siesta Key, Florida, Tampa, and Boston are all popular places, the smoothing technique is not expected to help here. The question is why the loca-tion likelihood estimation approach would suggest all those locations to have the same ranks, which is actually against our intuition. The reason is that the language model mainly considers the frequencies of locations, without taking ac-count of other valuable features of given documents, e.g., the surrounding words of locations and the correlation among locations in a travelogue. Thus, we propose an alternative approach, learning to rank model, to realize location rel-evance ranking by exploiting the textual and geographical feature of the travelogue.
 Due to its popularity and simplicity, we adopt Ranking SVM [9], which takes pair-wise relationship of locations in a travelogue to learn a ranking model. Given an input feature space X , where X includes both textual and geographical features, there exists an output space of ranks represented by labels Y = { r 1 ,  X  X  X  ,r q } , where q denotes the possible number of ranks. Further, assume that there exists a total order amongst the ranks r q r q  X  1  X  X  X  r 1 , where de-notes a preference relationship. Notice that, in this paper, we have three ranks of location relevance, namely  X  X elevant X ,  X  X artial relevant X  and  X  X rrelevant X , and the preference rela-tionship in location relevance ranking is  X  X elevant partial relevant irrelevant X .

Given a set of ranked instances Z = { ( x 1 ,y 1 ) ,  X  X  X  , ( x where n is the number of training instances, ( x j ,y j )(1  X  j  X  n ) is from the space of X  X  Y . If y i &gt; y j , we have x ahead of x j , denoted as x i x j . Assume that F is the set of ranking functions, such that each function f  X  F can rank location instances as:
In Ranking SVM, f is assumed to be a linear function [9], where  X  is weight vector and  X  X  ,  X  X  denotes inner product. f ( x ) = 0 corresponds to a hyperplane in the feature space,. Thus we have
Given an instance pair x i and x j , we create a new instance x  X  x j . If x i is ranked ahead of x j , we assign a label +1, otherwise  X  1 to the newly generated instance. As such, we produce a new data set upon which we can build a binary classification model, i.e., the Ranking SVM model. With the Ranking SVM model, and the optimal setting of  X   X  , for each location instance x we get its ranking score as f ( x ) =  X   X 
In this section, we study how to realize the proposed trav-elogue service based on the mined location relevance. Par-ticularly, we are interested in conveying theme locations, geographical scope, traveling trajectory and location snip-pets in a travelogue to the users. Figure 5 illustrates a mock up of our proposed travelogue service, which provides visu-alized information for a travelogue over a map. As shown, New York is the geographical scope of the trip. The trav-eler visited Central Park, Bronx Zoo and The Cloisters in sequence (i.e., three theme locations and a traveling trajec-tory). By moving the mouse cursor to one of the theme locations, associated location snippet pops out to provide some information. In the following, we present how we use the result of location relevance mining for provisioning of the digests in the travelogue service.
 Theme Locations. Locations is an essential entity of trav-elogues. Anticipating that users would be interested in quickly identifying where the trip activities have happened, we dis-play the theme locations of a travelogue. As we mentioned before, the theme locations can be generated in two ways: i) automatically discovered from the travelogue; and ii) tagged by the travelogue author. Thus, our location relevance clas-sification technique can be used to automatically identify the theme locations. For author-tagged theme locations, we develop a location tag recommendation service to assist the travelogue authors to tag theme locations when they upload their travelogues. Specifically, the location tag rec-ommendation service, presented to the author as a list of ranked theme locations in accordance with their estimated relevances to the theme of the uploaded travelogue, is re-alized based on the location relevance ranking techniques presented earlier.
 Geographical Scope. As a travelogue may cover several theme locations, it is desirable to present the geographical scope of trip activities to its readers. Previous works define geographical scope as a single (or a few) location names to cover all locations mentioned in a web page [1, 17]. For our travelogue service, we argue that not all locations are useful for deducing the geographical scope for a travelogue, especially when the noisy locations may produce misleading results. Consider the travelogue in Figure 1, we may ar-gue that its geographical scope should be narrowed down to Florida or even Siesta Key, since both Tampa and Boston are deviating from the theme of this travelogue. Therefore, we follow the ideas in [1] to compute the geographical scope but put our focus on how to derive the input location set, since noisy locations hamper the accuracy of expected geo-graphical scope.

To compute the geographic scope of a travelogue t , we consider only the theme locations L 0 t obtained from loca-tion relevance classification which effectively purges noisy locations from the entire location set L t in t . 4 Thus, the geographical scope computing algorithm takes L 0 t as input and operates upon the partonomy hierarchy of location on-tology (see Figure 3 as an example). First, for each location l in L 0 t , we initiate an importance score v l of l as the number of its appearance in the travelogue. Next, we propagate the influence of l to its parent node l 0 (and recursively to its ancestor nodes) by adding v l  X  d to v 0 l where 0 &lt; d &lt; 1 is a decay factor. Consider the example in Figure 3, Siesta Key would propagate its influence of importance score to its par-ent node Sarasota and grand-parent node Florida because the traveler visits Siesta Key and she also stays at Sarasota and Florida. As such, each location in L 0 t obtains an impor-tance score that takes influence from its descendants into account. We derive the geographical scope as a location set by adding the theme locations in order of their importance but skipping those with one or more ancestors or decedents already included in the set.
 Traveling Trajectory. Traveling trajectory (denoted as T ) is extracted based on the result of location relevance classification. Given a travelogue, we obtain a set of theme locations, denoted as L = { l 1 ,l 2 ,  X  X  X } , from location rele-vance mining. Given two locations l x ,l y  X  L , it is possible that l x is part of l y in the partonomy hierarchy. In this case, we exclude l y from the trajectory. For example, in Figure 3, if Siesta Key and Sarasota are both classified as theme locations, we consider Siesta Key be the reason for the traveler to visit Sarasota. Thus, for trajectory extraction, we highlight the specific point-of-interests and investigate their travel sequence to form a trajectory, which is a subset of L . In other words, locations included in a trajectory are not part of each other. The algorithm for forming POI set is shown in Algorithm 1.
 Algorithm 1 POI Set Formation Algorithm
Upon the POI set, we construct a trajectory T based on a simple assumption that the appearance sequence of those location in T is supposed to match well with the travel se-quence of the traveler X  X  real trajectory. Thus, we construct the trajectory by sorting locations in the POIs in accordance with the sequence of their appearances in the travelogue to form T . Of course, there still is a room for improvement in forming the trajectory. We plan to further investigate this issue in the future work.
 Location Snippet. Location snippet consists of a few (usu-ally one or two) sentences extracted from a travelogue to describe the corresponding location. Given a location l in a travelogue, a desired location snippet is one that includes rel-evant information about l , e.g., interesting description about some features of l . Based on topic generative model, we may find a word w related to a location l . Specifically, we may derive a probability p ( w | l ) that models how likely a word w describes a location l for all words in the vocabulary V , which contains all possible words in travelogues [7]. Based on p ( w | l ), we construct a word set W l (i.e., a subset of V )
An alternative of L 0 t is to use the highest ranked locations obtained from location relevance ranking with some prede-termined rank threshold. which includes informative words regarding l , i.e., word w with high p ( w | l ) are included in W l .

Next, for each theme location l , we determine the seman-tic relevance (SemRel) between l and a candidate snippet s by comparing the  X  X ord similarity X  between W l and the set of words in s , denoted as W s . Intuitively, we can simply use cosine similarity to calculate the distance between W l and W s . However, cosine similarity does not capture the latent topic behind of words (e.g.,  X  X unch X  and  X  X ood X  are treated as independent semantically). Thus, we propose to use la-tent topic distribution to measure the similarity between a location l and a candidate snippet s as follow.
 SemRel( l,s ) = where where  X  w denotes the topic distribution of the word [7],  X  is a normalizing factor, and D JS ( p || q ) denotes the Jensen-Shannon(JS) divergence.

Here please note that, while we only consider the seman-tic relevance in our selection of representative snippet for a theme location, the geographical relevance has been im-plicitly taken into consideration in the process of location relevance mining, which effectively purges noisy locations.
In this section, we evaluate performance of the proposed location relevance mining techniques and demonstrate the effectiveness of the travelogue service.
There are many sources of travelogues on the Web, rang-ing from Weblogs such as Windows Live Spaces to dedicated travel web-site such as TravelPod , IgoUgo and TravelBlog . We collected approximately 100,000 travelogues in English with location labels fallen in United States to form an En-glish Corpus. Nevertheless, instead of relying on the lo-cation labels directly, we implemented a location extractor to extract locations mentioned in these travelogues, yield-ing 18,000 unique locations. Because some tasks require evaluation by human beings with travel-related background and knowledge, we also built a Chinese Corpus by collecting travelogues from Ctrip 5 , which consists of 94,000 Chinese travelogues related to around 32,000 locations in China.
Here, we first introduce the performance metrics and then present the results of our evaluation on location relevance mining.
In the experiments, Precision and Recall are used to evalu-ate the performance of location relevance classification; Nor-malized Discounted Cumulative Gain (NDCG) and Mean Average Precision (MAP) are used to evaluate the perfor-mance of location relevance ranking. Since Precision and Recall are well known metrics, we only discuss NDCG and MAP.

For location relevance ranking problem, given a travelogue t , the NDCG score (NDCG t ) is computed according to the ranked location list L t (i.e., the output of location relevance http://www.ctrip.com rank of the location at the j th position of the location list L and n t is a normalization constant, which is chosen so that a perfect ranking X  X  NDCG score is 1. The final NDCG score is averaged over the scores of all the travelogues. In this paper, the NDCG scores for ranked location lists which include top 1, 3, 5, 7, 9 and 11 locations are reported. MAP stands for the mean of average precisions over all the travelogues. Given a travelogue t and a ranked location list L t , average and R j denote the total number of relevant locations and the number of relevant locations before the position ( j + 1), respectively, and I ( j ) is an indicator which takes value 1 if the location at position j is relevant and value 0 otherwise.
An important factor crucial to performance of location relevance classification and ranking is the location features extracted for mining. Thus, to facilitate our studies on im-pact of extracted features, we form the following four fea-ture groups : (1) baseline group -we consider  X  X s in title ? X  ( F 1 ) and  X  X umber of appearance X  ( F 2 ) as two basic features, which are frequently used for text mining; (2) textual group -we consider all textual features; (3) geographical group -we consider all geographical features; (4) textual + geographical group -we consider both the textual and geographical fea-tures.

As there is no existing dataset for evaluation of location relevance mining, we have to built our own training dataset manually. Since we usually consider a destination in our trip as relevant locations , those pass-by/stop-by/nearby lo-cations as partial relevant location , and others as irrelevant locations , we labeled 1,000 travelogues in the Chinese Cor-pus for our performance evaluation.
For location relevance classification, we consider relevant locations as positive cases and the other locations as negative cases. Among those 1,000 labeled travelogues, we randomly select 100 travelogues as the test set and the remaining trav-elogues for training. Figure 6(a) shows the precision-recall curves of location relevance classification with different fea-ture groups. We found that the baseline group (i.e., whether the location appears in the title and the count of locations in a travelogue) already provides strong support for deciding relevant locations. However, classifier using baseline features is effective only to some extent. With more textual features, the location relevance classifier gain improvement. From the figure, we observe that geographical features perform classi-fication very well, showing better performance than baseline features particularly when the precision is higher, as baseline features consider only very limited information. Also shown in Figure 6(a), combining textual and geographical features has the best performance because textual features and geo-graphical features are independent. As a result, combining those two provide more information to assess whether a lo-cation is relevance or not.

In this work, co-training approach has been adopted to improve the classification performance (i.e., to combine ap-proximately 1,000 labeled travelogues with approximately 93,000 unlabeled travelogues). In our experiment, we set the labeled data set as seed training set. As discussed in Section 5, a confidence threshold  X  has been used in our co-training algorithm to derive high-quality labeled train-ing set. Here we estimate  X  based on the precision thresh-old value of  X  , which is set as  X  = 0 . 95 in the test. In the co-training process, both textual-feature classifier and geographical-feature classifier are trained as high-precision classifiers (i.e., by setting  X  = 0 . 95). In this experiment, af-ter 4 round of iterations, co-training process terminates. The new training set is then used in classification. We compare the classification results by running the SVM classifier on the original training set (labeled as SVM) and new training set (labeled SVM+Co-Training). Figure 6(b) shows that co-training leads to a better precision-recall performance. As a matter of fact, this improvement can be expected, because both textual features and geographical features can be used to perform the classification task. Moreover, those two are independent and even complementary, so the combination of them enhance the classification performance as shown in Figure 6(a). Figure 7: Challenge in location relevance classifica-tion
To show the inherent challenges in location relevance clas-sification, we collect a training set with relevant and irrele-vant locations, with all partial relevant location filtered out. Let x denotes the feature vector of a location, we calculate f ( x ) = w  X  x + b (denoted as f -score) in the trained SVM model ( w  X  is the optimized hyperplane, while b is the bias term) for each location in the travelogues of testing dataset. Here, f -score indicates the distance to the classifier hyper-plan. Notice that in the test dataset, locations are cate-gorized into three groups, i.e., relevant locations, partial-relevant locations and irrelevant locations. For each group, we plot its f -score distribution in Figure 7. We find that, f -score distribution of partial-relevant location overlaps to some extent with one of relevant locations. This is due to the ambiguity in location relevance perceived by different people. In contrast to the location relevance classification problem, it seems to be easier to rank the relevance of dif-ferent locations for a given travelogue. In Figure 7, we find the  X  X enters X  of the distributions with respect to each loca-tion relevance class differ. As shown, the irrelevant location class is positioned in the leftmost part while the relevant location class stands at the rightmost part.

Next, we evaluate the performance of location relevance ranking techniques, including location likelihood estimation (LLE) and learning to rank (L2R), using the same dataset. There are three labeled ranks in our dataset, i.e., relevant, partial relevant and irrelevant. As discussed earlier, NDCG@N and MAP are used as the performance metrics for the ex-periment. 6 Figure 9: Improvement with different feature groups
Since there is a smoothing factor  X  in the location likeli-hood estimation, we experimentally find the optimal setting of LLE by tuning  X  from 0.2 to 1.0 with a 0.2 step. In-terestingly, although LLE is based on the idea of language model, it shows a behavior different from a conventional language model. Specifically, the smoothing parameter in a language model is used to improve the document rank-ing performance but it has no effect on location relevance ranking, i.e.,  X  = 1 . 0, as shown in our experiments. The is possibly because location relevance ranking is constrained within the given travelogue. As a result, count of a location appearance is much more important than its global popu-larity.

Next, we show impact of extracted feature groups on LLE and L2R via NDCG@N test (see Figure 9(a)) and MAP test (see Figure 9(b)), respectively. For simplicity, only the best performance (when  X  = 1 . 0) of LLE is plotted in these two figures. As shown L2R consistently outperforms LLE. Particularly, since LLE is mainly based on word frequency, which is considered as feature F 2 , the experiments demon-strate that both textual features and geographical features are indeed effective for improving the performance of loca-tion relevance ranking. Also note that the location relevance ranking problem is different from traditional document re-trieval problem, where thousands and even millions of can-didate documents are to be ranked for a given query. In location relevance ranking, the number of candidate loca-tions in a given travelogue are usually no more than 15. Therefore, it is imperative to ensure all relevant locations ranked higher than the other locations. In the MAP test, we find that the learning to rank approach outperforms the location likelihood estimation approach significantly.
Note that, we only consider relevant locations and other locations in measurement of MAP, since it considers binary cases in ranking performance evaluation.
Finally, we demonstrate the effectiveness of our travel-ogue service by evaluating the proposed travelogue digests, including theme locations, geographical scope, traveling tra-jectory and location snippet.
In our travelogue service, theme locations can be acquired via 1) location relevance classification; or 2) author tagging. The effectiveness of our classification technique has been studied in the last section. On the other hand, author tag-ging can be assisted by location tag recommendation backed by our location relevance ranking techniques. Here, we eval-uate the precision@N and recall@N of tag recommendation (where N = 1 , 3 , 5 , 7 , 9 , 11). Figure 10(a) and Figure 10(b) show that both L2R has a much better performance than LLE (especially when N = 3 and 5) in support of location tag recommendation. These results are consistent with the findings in Figure 9(b).
Here, we would like to evaluate whether location rele-vance mining can help improve the accuracy for geographical scope identification. Since there is no existing dataset with labeled geographical scope, we use the travelogues labeled with theme locations to derive the ground truth and use la-beled theme locations as inputs for our geographical scope computation algorithm.

We introduce two performance metrics, namely, average number of missing scopes ( N m ) (i.e., the correct scopes not found) and average number of wrong scopes ( N w ) (i.e., the scopes found incorrectly) to evaluate the performance. Let S  X  = { l 1 ,l 2 ,  X  X  X } denote the ground truth scopes for a given travelogue and S be the result we compute. Given two locations l and l 0 , let r ( l,l 0 ) denote that l is neither an-cestor nor descendant of l 0 in the ontology hierarchy, e.g., r (Boston , Florida) holds for the example in Figure 3 but r (Siesta key , Florida) does not. Thus, we have N m = |{ l | l  X  S ,  X  l 0  X  S,r ( l,l 0 ) }| and N w = |{ l | l  X  S,  X  l 0  X  S
We compare our approach which takes theme locations as input for geographical scope computation with a naive approach that considers all locations as input. As shown in Figure 11, our approach achieves a much better perfor-mance than the naive approach in terms of average number of wrong scopes, while remaining to be competitive in terms of average number of missing scopes. Hence, location rele-vance mining which helps filter out irrelevant locations can improve the accuracy of geographical scope identification.
In this experiment, we prepared 100 travelogues with la-beled traveling trajectories as the ground truth dataset. In order to evaluate the accuracy of our proposed trajectory extraction technique, we introduce a performance metrics, namely trajectory similarity ( TS ( t 1 ,t 2 )), which is defined as the graph edit distance [11] between two traveling trajecto-ries t 1 and t 2 . Here, we compare our approach with a naive approach that forms a trajectory by considering all locations in a given travelogue as the POI set. As shown in Figure 12, our approach achieves a much better performance since both location relevance classification and POI set formation im-prove the trajectory extraction accuracy significantly.
Figure 12: Test on TS
Here we evaluate the effectiveness of the extracted loca-tion snippets. In [7], sentences/small paragraphs with mul-tiple different locations are ignored due to the lack of loca-tion relevance mining techniques. However, those ignored snippets may contain interesting information to the users, because point of interests/locations are usually clustered in geographical proximity and mentioned close by in the text of travelogues. For example, Table 2 shows some interesting location snippets that we extract but missed in [7]. Take the location snippet for  X  X attery Park X  as an example. There are quite a few  X  X oise X  locations in the snippet but they pro-vide very informative knowledge about what to and see in Battery Park. In the snippet of  X  X he Cloisters X , we find that other locations also provide informative knowledge about where  X  X he Cloisters X  locates, i.e.,  X ... around of New York. Located up at 190th Street ... X . Finally, travelogue authors often describe locations by comparison, e.g.,  X  X olden Gate Park X  vs.  X  X entral Park X  in the snippet for  X  X olden Gate Park X .

We conduct a user study to evaluate whether our location snippets are informative in terms of conveying information of the corresponding location. Based on the Chinese corpus, we prepared 20 travelogues, where each travelogue consists of more than 5 locations mentioned. Intuitively, if a small paragraph contains a location name l , then we consider this small paragraph should be describing this location in some way. Thus, a naive approach is to consider those small para-graphs as snippets for the corresponding location involved.
Twenty graduate students were asked to assess the snip-pets of all 20 travelogues in 1 to 5 ratings in three aspects: namely, (1) geographical-relevance (i.e., to what extent the snippets are describing the corresponding location), (2) com-prehensiveness (i.e., to what extent the snippets provide rich information about the themes of the given travelogue), and focused location noisy location(s) snippet
Battery Park 94th Street, Manhat-
The Cloisters Metropolitan Mu-(3) overall satisfaction. Accordingly, we want to demon-strate whether the proposed method can suggest snippets not only relevant to the corresponding location, but also comprehensive to provide interesting information. For each travelogue, we average all the users X  evaluation in all three ratings of each snippet set in a travelogue. Three approaches (i.e., the naive approach, topic modeling approach [7] and the proposed approach) are compared as shown in Figure 13. Since topic modeling approach purges the snippets by delet-ing those containing multiple locations, it performs the best in terms of geographical relevance. However, our proposed approach also shows very competitive performance in terms of geographic relevance, because our location relevance min-ing helps to highlight theme locations. For the compre-hensiveness, both naive approach and topic modeling ap-proach show worse performance than our proposed approach does. The reason is that our proposed approach includes the location snippet as shown in Table 2, thus providing very comprehensive information against topic modeling ap-proach. Notice that, the naive approach can not differentiate which location is relevant, thus showing the worst perfor-mance in the aspect of geographical relevance, and affecting the comprehensiveness consequently. Overall, our proposed approach shows the best performance and user satisfactory.
In this paper, we develop location relevance mining tech-niques to discover theme locations of travelogues in support of a proposed travelogue service. Due to inherent ambiguity of location relevance, we perform location relevance mining in two complementary angles, relevance classification and relevance ranking, to provide comprehensive understanding of locations in a travelogue. Furthermore, we explore the textual and geographical features of locations and adopt a co-training model to improve the classification. Built upon the mining result of location relevance mining, we develop tech-niques for provisioning of various digests, including theme locations, geographical scope, traveling trajectory and loca-tion snippets, in our travelogue service. Finally, we conduct comprehensive experiments on collected travelogues to eval-uate the performance of our location relevance mining tech-niques and demonstrate the effectiveness of the travelogue service.

In the future, we plan to improve the traveling trajectory extraction by considering context provided in travelogue, and utilize location relevance mining techniques to support other travelogue services, such as location-based search. [1] E. Amitay, N. Har X  X l, R. Sivan, and A. Soffer. [2] C. M. Bishop. Pattern Recognition and Machine [3] A. Blum and S. Chawla. Learning from labeled and [4] A. Blum and T. M. Mitchell. Combining labeled and [5] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. [6] J. Ding, L. Gravano, and N. Shivakumar. Computing [7] Q. Hao, R. Cai, C. Wang, R. Xiao, J.-M. Yang, [8] U. Irmak and R. Kraft. A scalable machine-learning [9] T. Joachims. Optimizing search engines using [10] J. D. Lafferty and C. Zhai. Document language [11] M. Neuhaus and H. Bunke. Bridging the Gap Between [12] K. Nigam, A. McCallum, S. Thrun, and T. M.
 [13] R. Odon de Alencar, C. A. Davis, Jr., and M. A. [14] T. Qin, R. Xiao, L. Fang, X. Xie, and L. Zhang. An [15] S. E. Robertson and D. A. Hull. The trec-9 filtering [16] M. J. Silva, B. Martins, M. S. Chaves, A. P. Afonso, [17] L. Wang, C. Wang, X. Xie, J. Forman, Y. Lu, W.-Y.
