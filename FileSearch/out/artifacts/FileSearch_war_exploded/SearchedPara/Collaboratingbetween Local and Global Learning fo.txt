 This paper studies the novel learning scenarios of Distribut-ed Online Multi-tasks (DOM), where the learning individ-uals with continuously arriving data are distributed sepa-rately and meanwhile they need to learn individual model-s collaboratively. It has three characteristics: distributed learning, online learning and multi-task learning. It is mo-tivated by the emerging applications of wearable devices, which aim to provide intelligent monitoring services, such as health emergency alarming and movement recognition.
To the best of our knowledge, no previous work has been done for this kind of problems. Thus, in this paper a collabo-rative learning scheme is proposed for this problem. Specif-ically, it performs local learning and global learning alter-nately. First, each client performs online learning using the increasing data locally. Then, DOM switches to global learn-ing on the server side when some condition is triggered by clients. Here, an asynchronous online multi-task learning method is proposed for global learning. In this step, only this client X  X  model, which triggers the global learning, is up-dated with the support of the difficult local data instances and the other clients X  models. The experiments from 4 ap-plications show that the proposed method of global learning can improve local learning significantly. DOM framework is effective, since it can share knowledge among distributed tasks and obtain better models than learning them separate-ly. It is also communication efficient, which only requires the clients send a small portion of raw data to the server. I.2.6 [ Artificial Intelligence ]: Learning X  Machine Learn-ing multi-task learning; online learning; distributed tasks;
Many real world problems include a number of related learning tasks, for which multi-task learning (MTL) [5, 9, 10, 29] methods are favorable, as they can learn multiple related tasks together so as to improve the performance of each task relative to learning them separately. In certain sit-uations, the data are continually arriving, and online multi-task learning methods [6, 30] are useful to efficiently learn these data samples. All these methods require that the data are collected at a centralized place, so that a central learner can be used to learn all the tasks X  prediction models. Howev-er, data and tasks are distributed on isolated clients in many problems. At the same time, data are continually arriving, which make them more challenging.

The emerging applications of wearable devices motivate these tasks. Wearable devices are becoming more and more prevalent these days. By various sensors these devices con-tinuously collect the data from people and then provide some intelligent services, such as health monitor, emergency alarming, and movement recognition. The key component on wearable devices is the prediction model for these moni-tor services. However, the learning of the prediction models should consider the following challenges. First, the sensors on wearable devices usually have high sampling frequency, and the local data may increase dramatically. Thus, we need the online learning method for these models. Second, since different person may have different activity patterns, a distinct model should be learned for each user. Addition-ally, for the complex tasks the local model should leverage the knowledge from other devices for better prediction per-formance. Thus, the multi-task learning scheme should be adopted. Finally, since all these devices are distributed sep-arately, we need to carefully consider the communication overhead involved in the collaborative learning due to the limited communication bandwidth and the shortage of de-vice power.

By combining all these challenges, we actually face the learning scenarios of Distributed Online Multi-tasks (DOM), where the learning individuals with continuously arriving data are distributed separately and meanwhile they need to learn individual models collaboratively. Obviously, tradi-tional centralized multi-task learning methods [5, 9, 10, 29] are not suitable for these problems since they require that all the data be collected to a central place and then do the learning in batch mode. Previous online multi-task learning methods [6, 30] can not be used for these problems because in the learning process of these methods, one task must use the raw training samples from all the other tasks, which is n ot feasible in our problem. Distributed online multi-task learning problems has also been studied [15], but the main focus of Dinuzzo et al. [15] is how to divided the overall com-putation into each client, so that the server can do learning more efficiently. The communication cost is too high for real distributed applications, because each client should send all their data to the server. Then, the server has to send all the data from all the clients to each client.

To solve this problem, we assume that a global server exists for coordinating the collaborative learning, and the clients can only communicate with this server. In this client-server setting, a collaborative scheme with local learning and global learning alternatively is proposed. First, it in-cludes the local online learning on clients. Each client can learn from the local data and obtain a preliminary prediction model. Second, on the server side, to efficiently incorporate knowledge from multiple clients, an asynchronous multi-task learning method is proposed. Specifically, only the client X  X  model, which triggers the global learning, is updated with the support of the difficult local data instances and the other clients X  models. Compared to previous methods, this asyn-chronous global learning strategy is more efficient for com-putation and economical for communication. In these two alternate steps, local learning depends on global learning to obtain knowledge of other related clients, while global learning is based on the results of local learning to reduce the amount of raw training samples needed, which reduces communication cost.

The main contributions of this paper can be summarized as follows. 1. Problem Definition: we introduce a novel Distribut-2. Framework: a collaborative learning scheme is pro-3. Algorithm: an asynchronous online multi-task learning 4. Experiments: it is tested on four real-world problems
Notations. In this paper, [ N : M ] ( M &gt; N ) denotes a set of integers in the range of N to M inclusively.  X  X  X  X  represents the Frobenius norm of a matrix. I l denotes the l  X  l identity matrix. Some specific notations used in the paper are summarized in Table 1.

The Distributed Online Multi-task (DOM) learning prob-lem can be formally described as follows. Let T be the num-ber of clients (number of tasks), they are connected to a server, although different clients are not connected direct-ly. For each client t  X  [1 : T ], there are n t data examples { feature vector for the i -th example in the t -th task while y is its label. The dimension of the feature vector is d . For sim-plicity, this paper only considers binary classification prob-lems, i.e., y t,i  X  X  X  1 , 1 } . These data come in sequentially in time, i.e., the i -th example arrives before the ( i + 1)-th ex-ample. This is a distributed learning problem, because each cl ient does not have access to the data from other clients, and the clients can not transmit all their data to the server due to communication cost and privacy issues. The goal is to progressively train a distinct model with the continual-ly arrived examples for each client, as different clients have distinct patterns. However, because these clients are related to each other, we need to devise a communication efficient method to share knowledge among them to obtain better models. Clients and tasks have the same meaning in this paper and they are used interchangeably in the paper. In this paper, a simple form of linear predictor is used. The goal is to learn a distinct model f t ( x ) = w  X  t x for each client t , which is a linear separator function parameterized by weight vector w t  X  R d .

After receiving the representative data and the local mod-el for a client, the server will do global multi-task learning. Unlike in the centralized online multi-task learning [28], in the method proposed in this paper, the server only learns and updates the model for this client in this learning step while keeping other clients X  models unchanged. This asyn-chronous learning method for multiple tasks has several ad-vantages. First, only computing the new model for a single task each time can reduce the computation cost and make the algorithm more efficient. Second, in this way, multi-ple clients are more loosely coupled with each other. Each client only takes advantage of other clients models, not the frequently changing or even noisy training samples, which keep the learning process more robust. Third, to guarantee the models on clients and server are consistent, updating one model each time means that the server only need to send one model back to a client, which is more communication effi-cient. Also, clients request the server to do global learning asynchronously, so it is very natural to use this asynchronous update method.
The overall framework for the distributed online multi-task learning problem is shown in Figure 1. Clients make request to do global learning, and the server will send the updated models back to clients. The explicit interactions between clients and the server are shown in Figure 2. The co mmunication flow between clients and the server is rep-resented by black dashed arrows. The main works done by clients and the server are described in the following. Fi gure 1: The Overall Framework for the Distribut-ed Online Learning Problem Fi gure 2: Communication between Client t and The Server
Learning on Clients. In this part, the simple, fast and state-of-the-art online learning method soft confidence-weighted classifier (SCW) [31] can be used by clients. Using this method, the learned model can be represented by a weight vector w t , which is convenient to transmit between clients and the server. Although the data arrive continual-ly in each client, to facilitate the manipulation of the da-ta transmission process, clients interact with the server by dealing with the data block-by-block at the clients. It is sup-posed that each client contains a buffer with size k , which can store a small number of samples. After a whole block of samples are learned by the client, this client will obtain a newly updated prediction model. Then, to request the server to do global multi-task learning for it, a client need to send some representative data D t and its current model w t to the server. Usually, it is restricted that a maximum number l of samples can be sent for each block learning process.
Learning on The Server. For the server, it keeps all the clients X  latest models { w t } t  X  [1: T ] and their relations A . A is a T  X  T matrix, each of its element a i,j represents the correlation between the i -th and j -th tasks. We propose an asynchronous multi-task learning method for server. Up-on request by a client, the server will conduct global online multi-task learning for this specific client, i.e., update the model for this client while keep other clients X  models un-changed. The multi-task learning method should produce a linear prediction model, which the server will send back to the client to help client X  X  later local learning process.
In summary, in our framework the local learning on clients and global learning on the server work collaboratively to im-prove the performance of distributed online multi-task learn-ing problem, and efficiently alleviate the privacy-preserving concern and communication cost.
Recall that the server maintains the latest models { w t } for all the clients. When a client requests the server to do the global learning for it, it will send its new model w t and some representative data D t = { ( x t,i ,y t,i ) } i  X  [1: l t where l t is the number of samples.

To do online multi-task learning, it is important to cor-relate multiple tasks to let them collaborate with each oth-er in the learning process. Usually, a correlation matrix A  X  R T  X  T is used to represent the relations between d-ifferent tasks. Previous online multi-task learning method assumes that prior knowledge about task relations is avail-able in the form of correlation matrix A [7]. In this paper, the more flexible way to adaptively learn the correlation ma-trix in the learning process is adopted. Also, different from previous works, the models for different tasks are updated asynchronously. Each time, it only updates the model for the client that requests the server to do the global learning. This update strategy is more computation efficient. Differ-ent clients only loosely couple with each other, which makes the algorithm more robust. In this paper, it is assumed that the correlation matrix A can have both positive and nega-tive values, which means it can deal with both positively and negatively related tasks. The t -th column of A is denoted as a = [ a 1 ,t ,a 2 ,t ,...,a T,t ]  X  , where a j,t represents the relation of the j -th and t -th tasks. To sequentially learn each sample ( x t,i ,y t,i ) for task t , the optimization problem is as follows: where w  X  t is the new model after update, a  X  t is the updated correlations, the matrix W = [ w 1 ,w 2 ,...,w T ], l ( w is the hinge loss function defined as follows: The first term in the optimization problem (1) correlates multiple clients X  models and let one task take advantage of other tasks. It implies that when a  X  j,t is large, the two tasks are strongly correlated and we expect w  X  t  X  w j will also has guarantee the correctness of the method. The last term is a regularization term to control the complexity of the model. The constraint a  X  t,t = 1 suggests that each task is positively related with itself. Constraint to restrict the absolute values of the correlations between this client and other clients. These correlations are used in the optimization problem and their absolute values will determine how the other clients can influence a certain client that are currently being learned. The effect of other clients X  models can be controlled by setting different values for  X  . The weight vector  X  controls the complexity of the model. In this paper, it is fixed as  X  = of the correlation matrix is set as A = I T , which means at start we assume different tasks are irrelevant to avoid any error bias.

Simultaneously optimizing w  X  t and a  X  t in problem (1) is dif-ficult, so we alternately optimize one variable while the other is fixed. Denote the objective function in problem (1) as F when the loss is larger than zero, the objective function X  X  derivative with respect to w  X  t is: When a  X  t are fixed, and let the derivative in Eq.(3) equal to zero, the following solution can be obtained:
When w  X  t is given, the optimization problem (1) becomes the following constrained optimization problem: It can be solved using Lagrange method, which gives the solution:
When a client requests the server to do the global multi-task learning, it will send its current model and some repre-sentative samples to the server. Then, server will send the newly updated model back to the client. So, in one interac-tion, a client sends one prediction model and l representative samples to the server, and the server sends a model back to the client. The communication cost in one interaction is l +2 vectors, each vector has the same size as a data sample. The total communication cost for the T clients and the server in the overall learning process is: where  X  x  X  represents rounding the number x to the nearest integer towards infinity, n t is the number of training sam-ples for task t , k is the buffer size. It can be seen that the communication cost can be easily controlled by changing the values of k and l .

In fact, in the distributed online learning scenario, even if the clients transmit all their data to the server and server do centralized online multi-task learning, the server should also repeatedly send the learned models to clients, so that clients can use the up-to-date models for prediction. So, the model transmission is unavoidable, and we mainly consider how to reduce the raw data transmitted to the server.
Data are continually arriving at the clients, so the clients must be able to do the single task online learning. Also, to take advantage of the models of other clients, it should interact with the server to exchange knowledge among them. These interactions will cause communication cost and affect the learning process of the server and clients, which need special attentions.
One work of the clients is to do the local single task online learning to incrementally learn the classification models. In this part, the simple, fast and state-of-the-art online learn-ing method soft confidence-weighted classifier (SCW) [31] is used. For each client t , SCW assumes a Gaussian distribu-tion of weights with mean vector w t  X  R d and covariance matrix  X  t  X  R d  X  d . The mean w t corresponds to the lin-ear classifier as described in Section 3. When a new sample ( x t,i ,y t,i ) comes in, SCW updates the model by solving the following optimization problem: where  X  controls the confidence of each update, and C bal-ances between conservativeness and aggressiveness. D KL means the Kullback-Leibler divergence. Through minimiz-ing the divergence between the newly estimated weight dis-tribution and the previous one, it can avoid the parameters change dramatically in each update and keep the algorith-m robust against noises. The second term guarantees the correctness of the algorithm.

This optimization problem has closed-form solution, which is expressed as follows: where the updating coefficients are as follows:  X  t = min { C, max { 0 , where u t = 1 4 (  X   X  t  X  t  X  + m In this paper, the parameters for SCW are fixed as C = 1,  X  = 0 . 6 and  X  =  X   X  1 (  X  ).

SCW have many advantages. SCW improves over the o-riginal confidence-weighted (CW) [13] algorithm by adding the capability to handle the non-separable cases, and im-proves over adaptive regularization of weights (AROW) [14] by adding the adaptive margin property [31]. SCW also enjoys the large margin training and confidence weighting properties. It can achieve better predictive accuracy and is more computational efficient [31].
Local learner SCW can obtain a prediction model rep-resented by w t and a covariance matrix  X  t  X  R d  X  d that captures the relations between different features. Although  X  t is beneficial for the later learning process, it can not be tra nsmitted to the server due to its large size. To simplify the interaction process, suppose each client has a buffer of size k . A client interacts with the server when its buffer is full. In each interaction, the client will select at most l rep-resentative samples from the buffer and send them to the server. The samples must be carefully selected so that the most useful samples are selected. In this paper, the sam-ples that have the largest hinge loss are selected, as they are the most difficult for local model to discriminate. This trigger condition for global learning is called Regular Trigger Condition and it is the default trigger condition used in the paper. Although global learning is triggered when a client has learned a certain number of samples (buffer size), our DOM framework makes no special requirement that mul-tiple tasks must be synchronized when do global learning. Since the data arrive at different nodes with different speeds, the clients may trigger the global learning for updating its own model at different time points. Thus, it is actually an asynchronous process.

After receiving the updated model, this client will take the newly learned model by the server as its current model and it is the starting point for its later learning. So, the server and clients must use the same prediction model formulation and they should be compatible with each other.

At the initial stage of the learning process, the models clients learned may not be so accurate. In this case, letting these clients learn from each other could even be harmful. So, in the beginning, a client will learn a certain number of samples before sending its model to the server to do the initial global learning. When it sends model to server, the model is at least a weak classifier.

Adaptive Trigger Condition. In the above, the trigger con-dition for global learning is easy to understand with clear analysis on communication cost. Compared with this Reg-ular Trigger Condition, we can also dynamically trigger the global learning based on the number of misclassified in-stances by local learning. In other words, when more er-rors occur in local learning, we trigger the global learning more frequently. Specifically, client can store the samples that are misclassified by the local model in its buffer. When error number reaches a certain number l  X  , client will send these l  X  samples to the server for global learning. We have tested the performance of this Adaptive Trigger Condition on all the datasets. However, the results are similar to the results with Regular Trigger Condition in terms of model accuracy and communication overhead. So, only the result-s with Regular Trigger Condition are given in Experiments section.
In this section, we evaluate the effectiveness of the pro-posed algorithm for the Distributed Online Multi-task (DOM) learning problem.
Four real world datasets are used to test our algorithm, two of them are text datasets and the other two are image datasets. Some statistics of the datasets are summarized in Table 2, where n p and n n denote the number of positive and negative samples in each task, respectively. n t is the number of labeled training samples in each task, and the rest samples are used as testing set.
 Email Spam: The first dataset is the ECML/PKDD 20 06 email spam dataset [3]. It includes 15 persons X  emails, each person has 400 emails, which form 15 tasks (clients). These emails are labeled as spam or not. The goal is to learn a distinct prediction model for each person to classify emails. The tf-idf weighting scheme is adopted to represent the samples. Also, we have normalized the features to ensure that each sample X  X  feature vector has norm 1.

Sentiment: The Multi-Domain Sentiment Dataset con-tains product reviews taken from Amazon.com from four product types (tasks), namely, books, dvd, electronics and kitchen [4]. The reviews are split into two classes, positive and negative. The goal is to learn a distinct prediction model for each product type. The features used are tf-idf features.
NUS-WIDE Object: In NUS-WIDE Object web image database [11], each image is annotated by objects such as  X  X ars X , X  X og X , and etc. We select the images only belonging to one class. Similarly, we have normalized the features to ensure that each sample X  X  feature vector has norm 1. We randomly select 7 classes that have not too few samples to form 12 tasks, the goal is to classify different classes. The tasks are shown in Table 3.
 Table 3: Tasks for NUS-WIDE Object Dataset
Imag enet: ImageNet 1 is an image database organized according to the WordNet hierarchy. For the images, the 1000-dimension bag-of-word representations [24] based on raw SIFT [25] features provided by the ImageNet are used. We have normalized the features to ensure that each sam-ple X  X  feature vector has norm 1. We randomly select 6 class to form 9 tasks, the goal is to classify different classes. The tasks are shown in Table 4.

Previous multi-task learning methods cannot be used in the situation that data are distributed on different clients and at the same time, new data are continually arriving and real-time online learning is necessary. So, we compare our algorithm with the single task online learning algorithm SCW, which learns each task separately. This algorithm is h ttp://image-net.org/download-features a lso the local algorithm each client uses in our distributed online multi-task learning (DOM) algorithm.

OMT. Furthermore, we compare DOM algorithm with the centralized online multi-task learning (OMT) algorith-m [7]. This algorithm requires the prior knowledge of task correlations, so the pairwise distance interaction matrix giv-en in Eq.(4) in its original paper [7] are used. Although OMT collects all the data to a cental place and each task have access to the data from all the other tasks, it is not nec-essarily better than DOM which contains two collaborative learners.

MTRL. Multi-task relationship learning (MTRL) [34] is a centralized multi-task learning algorithm. It is not an online algorithm. Since in this algorithm, all the tasks have access to the data from all the other tasks, and they stored all the data from beginning to do learning in the batch mode, it is supposed that it can obtain better results than DOM algorithm. It is used as an baseline to shown whether DOM can obtain comparable results to MTRL algorithm. We have used cross validation methods to select the parameters  X  1 and  X  2 used in MTRL algorithm.
 In these experiments, we want to show the effectiveness of DOM algorithm and how the parameters affect the perfor-mance and communication overhead. The effectiveness can be shown in two aspects. One is that whether DOM is better than only using SCW for each task separately and whether DOM obtains comparable or even better results than OMT and MTRL algorithms which require all the data be collect-ed to a same place. The other one is that, within DOM algorithm, whether global learning can help improve the re-sults of local learning.

In each experiment, we randomly held out a number of samples for testing. The remaining data are used as train-ing set. To reduce the effect of randomness, for each dataset, 5 random permutations of the samples are used to test the algorithms, and the mean results are given. For compari-son, we test the single task online leaning algorithm SCW and OMT algorithm at regular intervals of buffer size, and calculate the accuracy of its current model for the testing data.

At the start of the learning process of our multi-task learn-ing, clients learn at least 30 training samples before request-ing the server to do global learning. That is because global learning is the most beneficial when each client X  X  model is not so bad. For all the problems, we set  X  = 0 . 01, the buffer size k = 20 and select l = 2 (10%) samples to send to the server in each interaction.  X  is set as 0.01 for Sentiment dataset and 0.001 for other datasets.
The number of training samples n t for each data set is shown in Table 2. The mean classification accuracy for 5 runs are displayed in Table 5. It can be seen that, for NUS-WIDE Object dataset, for 10 out of 12 tasks, our DOM al-gorithm obtains improved results compared to learning each task separately. For every task in the other three datasets, DOM algorithm always obtains improved results compared to learn each task separately. So, DOM algorithm is supe-rior to SCW algorithms, which demonstrates that our algo-rithm can effectively share knowledge among multiple tasks and obtain better prediction models. It is interesting to see that our DOM algorithm is also better than centralized on-line multi-task algorithm OMT, which require all the data Table 5: Classification Accuracy for Four Problems SCW only 0.866 0.709 0.842 0.829 0.753 0.820 SCW only 0.815 0.700 0.857 0.841 0.725 0.813 SCW only 0.919 0.944 0.952 0.901 0.909 SCW only 0.928 0.820 0.907 0.931 0.888 SCW only 0.905 0.888 0.944 0.893 0.913 SCW only 0.919 0.926 0.925 0.919 0.910 SCW only 0.922 0.930 0.927 0.930 b e collected at a same place. The reason maybe that: (a) OMT requires prior knowledge about task correlations, and a fixed interaction matrix given in Eq.(4) in its original pa-per [7] may not reflect the real task correlations. (b) Our DOM algorithm contains two collaborative learners, which is more robust.

To show the incremental online learning process more ex-plicitly, we display how the accuracy changes with the in-creasing training sample numbers in Figure 3. In DOM algo-rithm, if through sharing knowledge among multiple tasks, global learning obtains improved result compared to local learning in each interaction, a red bar is plotted, and its length represents the absolute accuracy improvement. Sim-ilarly, if global learning failed to improve the local learning results, a blue bar is plotted. Due to the space limit, for each problem, we only display the two tasks that DOM ob-tains the largest improvement and the smallest improvement compared to SCW algorithm according to the final results in Table 5. It can be seen that, for most tasks, our DOM al-gorithm is superior to the single task SCW algorithm in the whole learning process. In addition, these improvements are obtained at the cost of only transmitting 10% of the sam-ples to the server, which is communication efficient. DOM is also better than the centralized online multi-task algorith-m OMT, which require all the data be collected at a same place. MTRL is better than DOM in most cases. Howev-er, DOM can obtain comparable result with MTRL when the number of training samples is large. So, our alternately two-learner DOM algorithm is very effective for distributed multiple tasks. Global learning within DOM algorithm is very beneficial, as it can be seen that, in most cases, it can help improve the local models. (a ) Email Spam, Task 12 (e) WIDE Object, Task 8 Figure 3: Classification Accuracy for Four Datasets
Most of the parameters in DOM can be easily set, and only one parameter may need further tuning to obtain better results. Due to the space limitation, only the results for the first task in each problem are shown.
We first analyze the effect of parameter l , which is the number of samples that can be sent to the server in one in-teraction. The value of l controls the communication cost of our algorithm. We fix the buffer size k as 10, and set l = { 1 , 2 , 4 , 6 , 8 , 10 } , respectively, which correspond to 40% , 60% , 80% , 100% } of the data samples can be sent to the server. For each dataset, the first task X  X  result is shown in Figure 4. It can be seen that, for Email Spam and Sentiment datasets, the accuracy slightly improves with the increasing number of l . The improvement is not so significant, especial-ly when the number of total training samples is large. In this paper, to reduce communication cost, for all the datasets, only 10% of the data samples are sent to the server in each interaction. Figure 4: Classification Accuracy against Different l
To analyze how buffer size influences the performance, we set k = { 10 , 40 , 100 } , respectively. We correspondingly set l = 0 . 1 k . The results are given in Figure 5. In this comparison, since the value of l is fixed, the total number of data instances sent to the server is also fixed. Assume that the total number of training data on each client t is n . Then, the total number of instances sent to the server equals to 0 . 1 n t . Each time a client only sends 0 . 1 k instances to the server. Thus, the total number of times that a client send data equals to n t k (Th is number is also the times for global learning triggered by client t ). Therefore, the value of k actually controls the time when the data from clients arrive at the server. The smaller the value of k is, the earlier the data arrive at the server.

As shown in Figure 5, with different settings of k all the curves converge to the same value eventually. It indicates that the final model accuracy is not sensitive to k (since the total number of instances sent to the server is the same). Ho wever, in the learning process smaller k outputs better performances since the data from the clients arrive at the server earlier to trigger the global learning.
Parameter  X  in Eq.(1) controls the importance of the training data. We set  X  = { 1 e  X  1 , 1 e  X  2 , 1 e  X  3 , 1 e 5 , 1 e  X  6 } , respectively. The result are shown in Figure 6. It can be seen that, DOM algorithm X  X  performance is rela-tive stable with different  X  values used in this experiment, except for the NUS-WIDE Object dataset with  X  = 0 . 1. In this paper, we set  X  = 0 . 01 for all the datasets. Figure 6: Classification Accuracy against Different  X 
Parameter  X  in Eq.(1) constraint the correlations between different tasks and the influences of other tasks for a par-ticular task. To analyze the effect of parameter  X  , we set  X  = { 1 e  X  1 , 1 e  X  2 , 1 e  X  3 , 1 e  X  4 , 1 e  X  5 , 1 e ly. The accuracy is shown in Figure 7. It can be seen that, different  X  values affect the performance of DOM algorith-m. So, parameter  X  need to be fine tuned to obtain better results. Figure 7: Classification Accuracy against Different  X 
To guarantee the local models learned by clients are not so bad when they are sent to the server and be used by other clients, user may want the clients send their models to the server after they learned a certain number of samples and obtained good models. We want to know how the number of samples clients learned before initial global learning af-fects the performance of the algorithm. We set this number equals to { 10 , 30 , 50 , 70 , 90 , 110 } , respectively. The results are shown in Figure 8. It can be seen that, for Sentiment dataset, it needs at least 30 samples to be learned by clients before doing global learning to obtain good results. The number of samples needed is very small. In this paper, we set the minimum number equal to 30 for all the datasets. Fi gure 8: Classification Accuracy against Different Minimum Numbers of Samples before Initial Global Learning (Sentiment dataset)
To sum up, the buffer size k , number l of samples sent to the server in each interaction, minimum local sample num-ber and weighting parameter  X  can be easily set and our algorithm can obtain good results in a wide range of param-eter settings. Only the constraint parameter  X  need to be tuned by users.
Online learning, multi-task learning and distributed data mining are three different learning scenarios. Traditionally, they are studied separately, some works also start to try to solve problems with more than one of these characteristics.
Online learning method [20, 36, 37] learns a set of data samples that arrive sequentially in time. At each time step, the algorithm processes an incoming sample and update the prediction model accordingly. The computation of online learning methods cannot be too complex, as they are effi-cient real-time learning algorithms. Online learning has also been applied to a wide range of applications [23]. Online learning has been thoroughly studied and a variety of online learning algorithms have been proposed. The first kind is the first-order algorithms include the classical Perceptron algo-rithm [26] and the well-known Passive-Aggressive algorith-m [12]. Recently, second-order online learning algorithms are studied extensively. It has been shown that, by using parameter confidence information, second-order algorithms can improve online learning performance [8]. Confidence-weighted learning maintains a Gaussian distribution over the linear prediction models, which is also used to guide the model updating process [17]. However, due to its strict as-sumption that all the data samples are separable, it takes aggressive update rules and can cause overfit problem in certain situations. To improve this algorithm, Adaptive Regularization of Weights algorithm relaxes the separable assumption, which is capable to deal with noisy and non-separable data [14]. However, because it directly adds loss and confidence regularization, it loses the adaptive margin property [31]. In Soft Confidence-Weighted (SCW) learn-ing method, the adaptive margin method assigns different ma rgins for different instances via a probability formulation, which is more robust to handle noisy and non-separable da-ta, and is also more effective and efficient [31]. Online s-parse kernel learning has also been proposed to online learn a kernel classifier with a bounded number of support vec-tors [33]. SCW has the large margin, adaptive margin, con-fidence weighted properties and is able to deal with non-separable data. So, in this paper, it is taken as the local online learning method on the clients.

Multi-task learning (MTL) conducts multiple related learn-ing tasks simultaneously so that the useful information in one task can be used for other tasks. Traditional MTL meth-ods consider the centralized learning scenario that all the data are collected at a same place, where each task has ac-cess to all the data from other tasks, which is different from our problem settings. The earliest MTL method [5] learns a shared hidden layer representation for different tasks. Multi-task feature learning learns a low-dimensional representation which is shared across a set of multiple related tasks [2, 19]. The methods to learn predictive structures on hypothesis s-paces from multiple learning tasks are also proposed [1, 9]. Supposing that all the tasks are similar, a regularization for-mulation is proposed for MTL [18]. MTL can be modeled by stochastic process methods, such as [29, 32]. To deal with outlier tasks, a robust multi-task learning algorithm is pro-posed [10]. MTDA algorithm [35] is a single view multi-task learning algorithm that can deal with learning tasks with d-ifferent data representations. Multi-task learning with mul-tiple views (MTMV) are also studied. CSL-MTMV [21] is a shared structure learning framework, which can learn shared predictive structures on common views from multiple relat-ed tasks, and use the consistency among different views to improve the performance. MAMUDA [22] can solve MTMV problems with heterogeneous tasks. All these algorithms are designed for centralized multi-task learning problems and they learn in the batch mode, that cannot do the real-time online learning.

Centralized multi-task learning under the online learning setting has also been studied. In online multi-domain learn-ing [16], it first uses single task online learning method to learn a model for each task separately, and then proposes a method to combined all these models into a synthesized model. Cavallanti et al. [6] introduced new Perceptron-based algorithms for the online multi-task binary classifi-cation problem. They have proven that, under suitable reg-ularity conditions, multi-task learning algorithms can im-prove on single task learning by a factor proportional to the number of tasks, which demonstrates the effectiveness of online multi-task learning. Saha et al. proposed an on-line multi-task learning algorithm that can adaptively learn task relationships [28]. It dose not assume fixed task relat-edness, which makes it more flexible to deal with real world problems. Sun et al. proposed an online multi-task learning method to solve the human activity recognition problem-s [30]. Their major motivation for using online training al-gorithm is to speed up the training process. Instead of using batch training methods such as, steepest gradient descen-t, conjugate gradient descent, and limited-memory BFGS, they employed the online training method stochastic gradi-ent descent to solve their problem. There are also efforts to solve multi-task learning in a lifelong learning setting [27]. All these algorithms are centralized learning algorithms, s-ince not only the centered learner has access to all the data from all the tasks, each task can also obtains other tasks X  data if it finds it is necessary. So, they are not suitable for our problems that the data are distributed stored and no one can obtain a whole copy of the data from all the tasks.
Dinuzzo et al. studied the online multi-task learning from distributed datasets [15]. They divided the overall compu-tation into each client and the server can do learning more efficiently. Also, their method can preserve privacy of indi-vidual data. More specifically, although each client has ac-cess to the data from other clients, it does not know which client a particular data sample belongs to. However, the communication cost in this method is very high. Each clien-t should send all their data to the server. Then, the server has to send all the data from all the clients to each client. Transmitting these huge amount of data between clients and the server is not possible in many real world applications. For example, a cell phone can not transmit all its data to the server or receive all other persons X  data to help its local learning process.
In this paper, we formulated a new type of multi-task learning problem, i.e., distributed online multi-task learn-ing problem. To solve it, a Distributed Online Multi-task (DOM) learning framework is proposed, which includes col-laborative local learning and global learning. An asynchronous online multi-task learning method is proposed for the server, which is more efficient for computation and economical for communication. Our method can help the isolated clients to learn from each other and obtain better results than learn separately. There is no direct communication among differ-ent clients and the server does not transmit a client X  X  data to other clients, so data privacy is perfectly conserved. Most of the parameters in the algorithm can be easily set. Also, experiments have proved the effectiveness of our method. This work is supported by the National Natural Science Foundation of China (No. 61473273, 61473274, 61175052, 61203297), National High-tech R&amp;D Program of China (863 Program) (No.2014AA015105, 2013AA01A606). [1] R. K. Ando and T. Zhang. A framework for learning [2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task [3] S. Bickel. Ecml-pkdd discovery challenge 2006 [4] J. Blitzer, M. Dredze, and F. Pereira. Biographies, [5] R. Caruana. Multitask learning. Machine learning , [6] G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear [7 ] G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear [8] N. Cesa-Bianchi, A. Conconi, and C. Gentile.
 [9] J. Chen, L. Tang, J. Liu, and J. Ye. A convex [10] J. Chen, J. Zhou, and J. Ye. Integrating low-rank and [11] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and [12] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, [13] K. Crammer, M. Dredze, and F. Pereira. Exact convex [14] K. Crammer, A. Kulesza, and M. Dredze. Adaptive [15] F. Dinuzzo, G. Pillonetto, and G. De Nicolao. [16] M. Dredze and K. Crammer. Online methods for [17] M. Dredze, K. Crammer, and F. Pereira.
 [18] T. Evgeniou and M. Pontil. Regularized multi-task [19] A. Jalali, P. Ravikumar, S. Sanghavi, and C. Ruan. A [20] R. Jin, S. C. H. Hoi, and T. Yang. Online multiple [21] X. Jin, F. Zhuang, S. Wang, Q. He, and Z. Shi. Shared [22] X. Jin, F. Zhuang, H. Xiong, C. Du, P. Luo, and [23] B. Li, P. Zhao, S. C. H. Hoi, and V. Gopalkrishnan. [24] F.-F. Li and P. Perona. A bayesian hierarchical model [25] D. G. Lowe. Distinctive image features from [26] F. Rosenblatt. The perceptron: a probabilistic model [27] P. Ruvolo and E. Eaton. Online multi-task learning [28] A. Saha, P. Rai, S. Venkatasubramanian, and [29] G. Skolidis and G. Sanguinetti. Bayesian multitask [30] X. Sun, H. Kashima, and N. Ueda. Large-scale [31] J. Wang, P. Zhao, and S. C. H. Hoi. Exact soft [32] S. Yu, V. Tresp, and K. Yu. Robust multi-task [33] L. Zhang, J. Yi, R. Jin, M. Lin, and X. He. Online [34] Y. Zhang and D.-Y. Yeung. A convex formulation for [35] Y. Zhang and D.-Y. Yeung. Multi-task learning in [36] P. Zhao, S. C. H. Hoi, and R. Jin. Double updating [37] P. Zhao, S. C. H. Hoi, R. Jin, and T. Yang. Online auc
