 With the development of the semantic web, knowledge graph has been con-structed for recording different entities in the world and connecting them with different links. Many commercial search engines (e.g., Google, Bing, and Baidu) have been constructing their own knowledge graphs, due to linked data in knowl-edge graph supplies their users with comprehensive knowledge which is helpful for improving retrieval performance and users X  satisfaction. Traditional way of utilizing knowledge graph in information retrieval task is regarding it as exter-nal expansion source [ 1 , 4 , 8 ]. Diaz and Metzler has demonstrated that external expansion outperforms simulated relevance feedback in their research [ 2 ]. Freebase is a large structured knowledge graph which consists of multi-relational data. Each node in it represents a specific entity (e.g., person/place/event) and a set of properties are attached to it, these properties establish relationships between nodes and link them together as a graph. It now contains 46 million entities that covered massive domains, such as music, film and book. Therefore Freebase has been thought as a good external resource for information retrieval. Previous works [ 8 ], processed only query entities in Freebase into single terms and combined with relevance model for query expansion. However, in general, keyword-based queries contain few entities and may not be enough to repre-sent users X  information needs. Considering the positive impact of entities in top-ranked pseudo-relevance feedback documents, Dalton et al. explored entities in both queries and documents for query expansion in their resent work [ 1 ]. Dif-ferent from these works, we propose using the global and local importance of entities to discover expansion Freebase entities that related to query and the top-ranked pseudo-relevance feedback documents. Inspired by the idea of using MRF model for modeling dependence between query and document [ 6 ], we build MRF-KG model and improve it by adding two variants: expansion entities and associate properties to enhance retrieval performance.
 Three tasks are involved in the study to achieve our goal: (a) how to model query-related entities and associate properties into MRF model, (b) when esti-mating the distribution of entities, how to balance the global importance of them and the local importance of entities in the context of the query entities, (c) how to filter and weight entity property terms as expansion terms. 2.1 Overview of MRF-KG The MRF for IR is a graph model used for model the joint distribution of one or more query terms with each document in [ 6 ], we make it as the baseline model. Based on the three cliques mentioned in MRF, including full independence, sequential dependence, and full dependence of query terms (shown in Fig. 1 (a)), we add another clique to it, which is constructed by expansion entity set EN ,the associate entity property set EP , documents D and queries Q ( as shown in Fig. 1 (b). With the expansion graph H , a set of potentials  X  , and a parameter vector  X  , the joint distribution P H, X  ( EN, EP, D, Q ) can be defined as follows: where Z  X  = EN,EP,Q,D c  X  C ( H )  X  ( c ;  X  ) is a normalizing constant. C ( H )is the set of cliques in H .Each  X  ( c ;  X  ) is a non-negative potential function over clique configurations parameterized by  X  . For ranking purpose, the document score is computed based on the posterior: P H, X  ( D | EN, EP, Q )= P H, X  ( EN, EP, Q, D ) /P H, X  ( EN, EP, Q ) We denote the potential functions of cliques that are composed of document D and query terms q i as  X  MRF ( c ;  X  ), which is detailedly described in [ 6 ]. So the ranking function can be simplified in the following form:
P H, X  ( D | EN, EP, Q ) rank =(1  X   X  )  X  MRF ( c ;  X  )+  X  where C ( P ) is the set of cliques on { EN, EP, Q, D } , f ( EN, EP, Q, D )isthe feature function on C ( P ). This feature function describes how well query-related entities and properties match the documents. Hypothesizing that entities en in EN are independent to each other, much the same as property terms ep in EP , we can approximate the computation formulation as: where E R denotes the set of top-ranked expansion entities, D ranked documents in first-round retrieval. We get P ( ep | language model. P ( en | Q, d i ) is estimated as the distribution of expansion enti-ties; P ( ep | en ) is estimated as the distribution of expansion property terms. We will illustrate these two distributions in the following parts. 2.2 Estimating Entity Distribution With the constructed graph H , we will select expansion entities first and use it as sources for expanding property terms. Entity distribution is influenced by two factors, i.e., the global and local importance, showing as follows: where GI ( en ) implies the global importance of candidate entities, and LI ( en ) implies the local importance of candidate entities,  X  is a coefficient to balance the global and local importance.
 The global importance measures the influence of queries Q and all documents D over candidate entities. Limited by available annotated resources, we approx-imate the joint distribution P ( Q, D )to P ( D R ). Therefore, global importance can be estimated as: where P ( d i | Q ) indicates the retrieval score of d i on Q ,and P ( en frequency over document d i  X  X  all annotated entities.
 The local importance reflects the positive influence of contextual entities in d received from entities E Q (i.e., the set of entities that explicitly appears in query). Each document has an entity sequence which is built by the position order of entities of it. According to the intuition that entities closer to E more relevant to query topic [ 5 ], we assign more weights to contextual entities which are closer to E Q . The estimation of local importance is as follows: where i and j are the index of entity in the sequence. In order to fully capture contextual information in D R , we regard all entities in d as context snippet. 2.3 Estimating Property Distribution For the distribution of query-related property terms, we adopt the less-noisy properties (i.e., description and article) of entities in Freebase, which contain succinct description about entities. The probability of a property term ep in entity en is estimated by the term frequency (TF) of ep in the property values of en .
 After estimating expansion entities and property terms X  X  distribution above, we can directly derive the feature function f ( EN, EP, Q, D ) in Formulate ( 4 ). 3.1 Experimental Setting Two web collections ClueWeb12B and WT10G are employed in our experi-ment. The Clueweb12B dataset contains 52,343,021 documents (1.95T) with title queries from 201 to 250, whose entity annotation coverage is 48/50. And the WT10G dataset contains 1,692,096 documents (11G) with title queries from 501 to 550, whose entity annotation coverage is 40/50. Indri is used to implement our proposed model and baseline model, i.e. MRF and latent concept expansion (LCE) [ 7 ]. For both datasets, the processing of documents and queries includes stemming with Porter stemmer and stopwords removal using the standard Stop-words list. We use four metrics (i.e., MAP, P@20, NDCG@20 and ERR@20) to evaluate the retrieval effectiveness. 3.2 Entity Annotation Queries and documents are annotated with Freebase entities in our experiment. We split each query into several fragments, then search them in Freebase knowl-edge graph using Freebase X  X  API. The matched entities are regarded as annota-tions of entities, which is weighted by the match score provided by Freebase X  X  API. Notice that there are 2 in topic 201-250 and 10 in topic 501-550 that have no entity been annotated, so we only employ global importance on it. Different methods are applied to annotate entities on different datasets. We use Google FACC1 [ 3 ] data for ClueWeb12, which automatically annotate ClueWeb12 doc-uments with Freebase entities and the annotations are of generally high quality. Because no publicly available entity annotations exist for WT10G, we leverage the Alchemy API to annotate entities for WT10G documents, which can provide an entity identifier in Freebase for the annotated entity. 3.3 Parameter Setups and Experimental Results We adopt the ranking function in Formulate ( 3 ) to the retrieval task, where our proposed feature function is estimated in Sect. 2.2 , and the MRF potential function with its parameters are the same with [ 6 ]. In practice, we select top 100 documents in the first-round retrieval as D R and set the number of query-related entities in E R to 5. Three further parameters need to be adjusted in our MRF-KG model: the number of expansion property terms k , the interpolated coefficient  X  in Formulate ( 3 ) and the balance parameter  X  . We sweep over k  X  X  10 , 20 , ..., 50 } ,  X ,  X   X  X  0 , 0 . 1 , 0 . 2 , ..., 1 . 0  X  =0 . 6 for two test collections to get the optimal retrieval performance. For the implementation of the baseline model MRF and LCE, we refer to the parameters setting in [ 6 , 7 ] respectively.
 vations. Firstly, taking expansion entities or concepts into account, MRF-KG performs significantly better than LCE in ClueWeb12B on all the evaluation metrics and in WT10G on MAP and P@20. Because, in addition to global impor-tance of entities or concepts as LCE does, we also consider local importance in a document, which reflects the degree of entities related to queries more accu-rately. Secondly, comparing with MRF and LCE, the less perfect appearance of MRF-KG on NDCG@20 and ERR@20 cannot disguise its superiority in overall performance represented by a higher MAP value. In summary, the MRF-KG model is more efficient than MRF and LCE with leveraging external knowledge graph, making it richer and more accurate for entity analysis in queries. In this paper, we proposed a query expansion approach by using entity distri-bution based on Markov Random Fields, called MRF-KG. In MRF-KG, two expanded variants, i.e. entities and properties, are integrated with MRF, which can expand the original query to better represent user X  X  information needs. Experimental results on WT10G and ClueWeb12B show that the MRF-KG per-forms better on web collections than the baseline model MRF and the expan-sion model LCE. The effectiveness of MRF-KG depends on the accuracy and comprehensiveness of entity annotations in documents. In the future work, we will investigate the relationships between entities, e.g., hypernym/co-hyponym, which is ignored in the current MRF-KG model. Moreover, we will experiment on more large-scale entity annotation resources, such as Wikipedia, to further demonstrate the effectiveness of our MRF-KG.

