 Entity Linking is the task of detecting, in text documents, relevant mentions to entities of a given knowledge base. To this end, entity-linking algorithms use several signals and features extracted from the input text or from the knowl-edge base. The most important of such features is entity relatedness . Indeed, we argue that these algorithms benefit from maximizing the relatedness among the relevant enti-ties selected for annotation, since this minimizes errors in disambiguating entity-linking.

The definition of an effective relatedness function is thus a crucial point in any entity-linking algorithm. In this paper we address the problem of learning high-quality entity relat-edness functions. First, we formalize the problem of learn-ing entity relatedness as a learning-to-rank problem. We propose a methodology to create reference datasets on the basis of manually annotated data. Finally, we show that our machine-learned entity relatedness function performs better than other relatedness functions previously proposed, and, more importantly, improves the overall performance of dif-ferent state-of-the-art entity-linking algorithms.
 H.4 [ Information Systems Applications ]: Miscellaneous; H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  | Information Filtering, Search process Algorithms, Design, Experimentation.
 Entity linking, relatedness measures, learning to rank
Document enriching is today a fundamental technique to improve the quality of several text analysis tasks, including Web search [21, 24]. In this work we specifically address the Entity Linking Problem : given a plain text, the entity linking task aims at identifying the small fragments of text (in the following interchangeably called spots or mentions ) referring to any named entity that is listed in a given knowledge base, e.g., Wikipedia. The ambiguity of natural language makes it a non trivial task. The same entity can be in fact mentioned with different text fragments, e.g.,  X  X resident Obama X  or  X  X arack Obama X . On the other hand, the same mention may refer to different entities, e.g.,  X  X resident X  may refer to the U.S. president or to Alain Chesnais, the president of the Association for Computing Machinery.

A typical entity linking system performs this task in two steps: spotting and disambiguation . The spotting process identifies a set of candidate spots in the input document, and produces a list of candidate entities for each spot. Then, the disambiguation process selects the most relevant spots and the most likely entities among the candidates. The spot-ting step exploits a given catalog of named entities, or some knowledge base, to devise the possible mentions of entities occurring in the input. One common approach to address this issue is resorting to Wikipedia [12, 19]: each Wikipedia article is considered to be a named entity, and the anchor texts associated with Wikipedia links a rich source of possi-ble mentions to the linked entity. The spotter can thus pro-cess the input text looking for any fragment of text matching any of the Wikipedia mentions, and therefore potentially re-ferring to an entity. Indeed, the spotter should detect all the mentions and find all the possible entities associated with such mentions. The coverage of the source knowledge base and the accuracy of the spotter have in fact a strong impact on the recall of the entity linking system [4]. To isolate the impact of spotting, we implemented a general framework for entity linking that uses the same spotting technique to feed several state-of-the-art disambiguation algorithms.
Let us introduce a simple example to describe how the entity linking process works:
The text  X  X resident Kennedy X  can be easily spotted and linked to John F. Kennedy , since in Wikipedia there are 98 anchors exactly matching such fragment of text and linking to the U.S. president page. In addition, the text  X  X pollo 11 X  may refer to two distinct candidates: the famous spaceflight mission, or the 1996 film directed by Norberto Barba. Simi-larly, the text  X  X ichael Collins X  may refer to either the well known astronaut, or to the Irish leader and president of the Irish provisional government in 1922. Indeed, mentions to the latter (408) are much more frequent than those to the former (141) 1 .

The above spots and the relative candidate entities are further processed during the disambiguation step. The goal of disambiguation is twofold. First, only relevant spots have to be filtered. For instance, the word  X  X he X  may refer to the entity associated with the definite article, but this linking might be relevant only for documents discussing the English grammar. Second, the best candidate entity for each spot has to be selected. This is usually done by considering the context of close mentions and by maximizing some measure of relatedness among the linked entities [6, 8, 13, 19, 22]. In our example, the astronaut  X  X ichael Collins X  and the  X  X pollo 11 X  spaceflight mission entities are preferred since they are clearly strongly related to each other and to the other entities found in the document, i.e., Buzz Aldrin and John F. Kennedy.

The effectiveness of the entity relatedness function adopted is thus a key-point for the accuracy of any entity-linking al-gorithm. In this work we propose a machine learning ap-proach to devise a high-quality entity relatedness function. The main contributions of this paper are:
The paper is organized as follows. In Section 2 we for-malize the problem of learning automatically a entity relat-edness function. In Section 3 we discuss related works, and how entity relatedness functions are used in these works. In Section 4 we evaluate some machine learned entity related-ness functions, and in Section 5 we evaluate their impact on entity linking algorithms. Finally, Section 6 draws some final conclusions.
Given a set of known entities E from a knowledge base KB , and an unstructured text document D , entity linking aims at identifying all the relevant mentions in D to the entities of E . The entity linking process involves two steps that we are going to detail in the following.
 Spotting and Candidate Selection. Spotting aims at identifying spots, i.e., contiguous sequences of n terms ( n-grams ) occurring in D that might mention some entity e  X  X  .
Throughout this paper, we used the 04/03/2013 dump, available at http://dumps.wikimedia.org/enwiki/ 20130403/enwiki-20130403-pages-articles.xml.bz2 A common method to identify the spots S D = { s 1 ,s 2 ,... } is to exploit a controlled vocabulary of spots L , and to search the input document for the n -grams that exactly match an entry of this vocabulary.

When Wikipedia is used as KB , each Wikipedia article identifies an entity, and the vocabulary L can be easily built by considering the article titles along with the anchor texts of all internal Wikipedia hyperlinks.

Each spot s i  X  S D is then associated with a set of candi-date entities C ( s i )  X  X  . This is done by considering all the entities of E that are referred to in KB by using spot s i an anchor text. Unfortunately the same spot s i can occur in different places of KB (and even of D !) and refer to distinct entities. Finally, we denote by ( s i )  X  C ( s i ) the entity that is actually mentioned by s i in D .

Figure 1 illustrates the three spots { s 1 ,s 2 ,s 3 in our text example. For each s i , the outgoing dashed di-rected edges identify the set of candidate entities C ( s where ( s i )  X  C ( s i ), i.e., the entity that is actually men-tioned by s i , is represented as a rectangle.

To limit the set of spots and candidate entities to the most meaningful ones, link probability and commonness properties can be usefully exploited [17]. The link probability for a spot s is defined as the number of times s i occurs as a mention in KB , divided by its total number of occurrences. This permits to discard spots that are rarely used as a mention to a relevant entity. For example the spot  X  X uly 20 X , introduced in the example of Section 1, occurs hundreds of times in Wikipedia, and, even if it is the title of an article, only in a few cases it used as anchor text.

The commonness of a candidate c  X  C ( s i ) for spot s i is instead defined as the fraction between the number of oc-currences of s i in KB actually referring to c , and the total number of occurrences of s i in KB as a mention to an entity. For example, the spot  X  X ichael Collins X  may refer to more than 20 different entities, but the Irish revolutionary leader (421 mentions, commonness 0 . 5), the film about his life (126 mentions, commonness 0 . 15) and the astronaut (132 men-tions, commonness 0 . 15) are largely the most common.
Setting a threshold on minimum linking probability and minimum commonness has been proven to be a simple and effective strategy to limit the number of spots and associated candidates, without harming the recall of the entity linking process [19].
 Disambiguation and Linking. Since in many cases we have several candidates for a single spot s i (i.e., | C ( s 1), the spot has to be disambiguated by choosing the right entity ( s i ) among the candidates C ( s i ). For each spot, a disambiguation algorithm outputs the selected entity and a confidence score. This confidence score can be used to select the most likely matching entities, and to trade precision with recall.

In order to choose the best entity for a spot, disambigua-tion may exploit different signals and features. These in-clude commonness and linking probability, and many others features considering the text surrounding the spot, and the other spots of the document. The most important of such features is entity relatedness , usually defined as a real func-tion  X  : E  X E  X  [0 , 1], where 0 and 1 are the minimum and maximum relatedness measure, respectively. To guarantee the accuracy of entity linking, the entities selected by the disambiguation process to be linked to the detected spots have in fact to be strongly related to each other. other candidate entities.

Figure 1 shows the relatedness graph referred to our exam-ple. The selection of the best entities is often implemented on top of this relatedness graph, where edges are weighted by some entity relatedness function. Therefore, the role of such entity relatedness function is crucial for the accuracy of the disambiguation process.

Even if the definition of a entity relatedness function is not a trivial task, several works agree on the effectiveness of the Wikipedia-based relatedness function proposed by Milne and Witten [19, 18]. The relatedness between two entities a and b is in this case computed by exploiting the graph structure of Wikipedia:  X  where W is the set of all Wikipedia entities, while in ( a ) and in ( b ) are the sets of Wikipedia articles linking to a and b , respectively. When | in ( a )  X  in ( b ) | = 0, we have  X  0. In addition,  X  MW is maximum (equal to 1) when in ( a )  X  in ( b ) = in ( a ) = in ( b ), and thus all the articles that cite a also cite b , and vice versa.

The  X  MW function, promoting entities that are co-cited by the same Wikipedia articles, is considered the state-of-the-art relatedness measure, adopted also in [8, 12, 14]. On the other hand, there is no guarantee that  X  MW would produce a proper scoring of the candidate entities.

Example 2.1. Given the entities a =  X  X ndronicus of Rho-des X  , b =  X  X hondrichthyes X  , and c =  X  X ristotle X  occurring in a document, we have that  X  MW ( a,b ) = 0 . 54 and  X  MW ( a,c ) = 0 . 56 2 . The connection between entities a and c is very strong since Andronicus of Rhodes is credited with the production of the first reliable edition of Aristotle X  X  works. The (un-expected) high relatedness score between entities a and b is instead due to a single co-citing Wikipedia article (which is c ) that reports about Aristotle X  X  studies of a group of fishes
The values to compute the two  X  MW measures are: | in ( a ) | = in ( c ) | = 17, and | W | = 4 , 255 , 306. he named selachians, a.k.a. chondrichthyes. Therefore, in this case a single co-citation is enough to produce an unex-pected high value  X  MW ( a,b ) , which is similar to the expected large value of  X  MW ( a,c ) .
 Another interesting observation is that  X  MW is symmetric: Andronicus of Rhodes is relevant to Aristotle, to the same degree Aristotle is relevant to Andronicus of Rhodes.
Our claim is that a good entity relatedness function  X  can improve the performance of a large class of entity linking algorithms. In Section 3 we will discuss related works and show the crucial role of entity relatedness functions in many proposals. Here, we propose a set of properties that an op-timal entity relatedness measure should satisfy, and we for-malize the problem of discovering a good entity relatedness function into a learning-to-rank problem.
 Relatedness as a Ranking Function. Suppose that an entity linking algorithm identifies only two spots s h and s for a document D , and for these spots it generates the two sets of candidate entities C ( s h ) and C ( s i ) respectively. Most disambiguation algorithms assume that if one of the candi-date entities in C ( s h ) is highly related to another entity in C ( s i ), then it is very likely that they are the entities ( s and ( s i ) actually mentioned by the two spots.

We claim that a good entity relatedness function  X  should promote the relatedness of correct entities: given entity ( s its relatedness with ( s i ) should be larger then that with any other candidate in C ( s i ). This should hold for every spot s 6 = s h .

Proposition 2.1. Given D , S D = { s 1 ,s 2 ,... } , and, for each spot s i , C ( s i ) and ( s i ) , a relatedness function  X  im-proves entity-linking accuracy if the following constraint holds:
Indeed, the constraint in Eq. 1 nicely fits into a learning-to-rank based formulation [16]. The relatedness function  X  can be in fact modeled as a ranking function, with entity ( s h ) used as a query. According to the above Proposition, function  X  should score all the entities actually mentioned in the document, i.e. ( s i ) for all s i 6 = s h , higher than any other false-positive candidate, i.e. c  X  C ( s i ) \{ ( s s 6 = s h .

Given document D and spots S D = { s 1 ,s 2 ,...,s h ,... } , we denote by R h D =  X  i 6 = h C ( s i ) the set of candidates to be ranked for query ( s h ), and by E h D =  X  i 6 = h ( s relevant entities for the query, where E h D  X  R h D . From an information retrieval perspective, items in R h D are relevant for query ( s h ) if and only if they belongs to E h D . Note that we are considering the spots of D altogether, and there-fore there are potentially many related entities to the query ( s h ) that should be ranked high. Let us denote with  X  the score descending ordering of R h D induced by our rank-ing relatedness function  X  for query ( s h ). According to Proposition 2.1, a scored list  X  h  X  is effective when entities in E
D are in the top positions of the list. We can thus mea-sure the effectiveness of our ranking relatedness function by using common information retrieval quality metrics such as NDCG [15]. In our context we define DCG (  X  h  X  ) as: where  X  h  X  [ j ] denotes the j -th item of the scored list, and equals 1 if x is true and 0 otherwise. NDCG is defined as the usual normalized version of DCG .

We can now introduce the Entity Relatedness Discovery problem.

Let D be a collection of entity-linked documents, where for each document D  X  D and every relevant spot s i of S D we know ( s i ) . Given the entity ( s h ) and the set R h D , a ranking relatedness function  X  induces an ordering  X  h  X  of R h D .

The Entity Relatedness Discovery Problem requires to find the function  X  that maximizes the ranking quality:
In our experiments, we chose to optimize NDCG to find a good entity relatedness function, but we used several other ranking quality functions to assess the goodness of results.
Unlike previous approaches, we do not suggest a spe-cific novel entity relatedness function. Rather, we define a learning-to-rank framework to discover the optimal entity relatedness function.
In the following we discuss how the notion of entity re-latedness is exploited by state-of-the-art entity linking algo-rithms. Emphasis is given to the solutions proposed in [19] and [12] and [8] which are the most relevant proposals in the field, and they are all adopting  X  MW as entity related-ness function. We show that the entity relatedness function defined in Proposition 2.1 can replace  X  MW since it fits better the framework and the objectives of the above algorithms.
WikiMiner [19]. Given a document D , let us consider its spots S D and for each spot s i the associated set of can-didates C ( s i ). Let us suppose that a subset of the spots are associated with only a single entity. We denote with U  X  E the context : the set of unambiguous entities linked to spots in S D , i.e., U = S | C ( s algorithm exploits the entities in U as safe reference points to help the disambiguation of the other ambiguous spots for ambiguous spot of S D the entity which is, on average, the most related with the  X  X afe X  entities in U . The relatedness function adopted is  X  MW . It is worth noting that not all the entities in U have the same impact: an entity u  X  U is in fact considered of high quality if it is strongly related to the other entities in U , and if the link probability of the corre-sponding spot is high. These two criteria allow a weight w 0  X  w u  X  1 to be assigned to each entity u in U . Note that the main aim of this weight is to reduce the impact of low-quality entities occurring in U . When applied to our simple example, the low resulting weight would demote the importance of the safe entity  X  X uly 20 X .

Every candidate c in C ( s i ) is scored according to the fol-lowing function:
It is easy to show that the accuracy of the disambiguation would improve if we adopted, instead of  X  MW , a relatedness function  X  that satisfies our Proposition 2.1.

Given an entity u  X  U , we can rewrite Eq. 1 and derive as follows: P
Therefore, a relatedness function satisfying Proposition 2.1 would always correctly rank entity ( s i ) higher than any other candidate for the corresponding spot s i even when in-tegrated in the WikiMiner framework.

Interestingly, the authors of [19] use machine learning to combine the above relatedness score with other two features: commonness and context quality (measured as P w u ). They experiment with a training set built from 500 Wikipedia arti-cles. However, machine learning is not exploited to improve the relatedness function as in our proposal.

Referent Graph [12]. Referent Graph , a graph-based method still exploiting the relatedness function  X  MW , is pro-posed in [12]. Let RG ( V,E ) be a weighted directed graph where the nodes includes all the spots s i of S D and can-didates C ( s i ). RG has a directed edge from s i to every c  X  C ( s i ), and reciprocal edges connecting every pair of candidate entities a and b , a  X  C ( s i ) ,b  X  C ( s h ) ,i 6 = h . Spot-candidate edges ( s i ,c ) are weighted according to the cosine similarity between the Wikipedia article correspond-ing to entity c and a local context window of 50 words around the spot s i . The candidate-candidate edges ( a,b ) are weighted by using  X  MW . Finally, weights are normalized so that weights on outgoing edges from a given node always sum up to 1. The graph shown in Figure 1 is a toy referent graph, where relatedness edges connecting candidates enti-ties for the spot s 1 with candidates entities for the spot s are omitted for clarity.

The score of a candidate entity for a given spot is given by the steady state distribution of a random walk with restarts [20] in RG , where candidate nodes have restart probability 0, and spot nodes have a restart probability proportional to their inverse document frequency score in the Wikipedia corpus. Also in this case, assigning a different restart proba-bility to spot nodes, and weighting as above explained spot-candidate edges is aimed to limit the impact of non relevant or incorrectly matched mentions.

The rationale of the random walk approach is to evaluate the relationships among the whole set of candidates simulta-neously, in contrast to previous methods where the scores of candidate entities are assigned independently of each other. Also in this algorithm the choice of the entity relatedness function  X  has a strong impact on the performance since it drives the random walk process. A set of entities being very related to each other is likely to produce a reinforcement loop, and eventually include the most probable states of the random walk.

Even if we do not provide a formal proof as for WikiMiner, it is clear that a good relatedness function should promote the reciprocal relatedness among the right entities in the graph, thus helping the random walk to converge to the correct ranking of candidates.

A similar approach is used in [26], where a slightly dif-ferently weighted referent graph is pruned progressively by removing iteratively the node with the lowest weighted de-gree (sum of the weights of incoming edges). Even in this case, the weights of candidate-candidate edges are computed with the  X  MW relatedness function. The paper do not com-pare performances with those of [19], [12], or other algo-rithms, and it is thus difficult to estimate the impact of this proposal.

TAGME [8]. TAGME is an annotation framework fo-cussing on efficiency that exploits two main features: com-monness and the  X  MW relatedness. First, candidate entities for a spot s i are ranked according to their average related-ness with other candidate entities for spots s j 6 = s i , weighted by their commonness. Then, from the top 30% candidates of the resulting ranked list, the entity with the largest com-monness is finally selected.

Also this algorithm would benefit by a relatedness func-tion satisfying Proposition 2.1, since it would help to boost the score of the actual entities mentioned in the document. However, the benefit is limited, since the relatedness func-tion impacts more on the pruning irrelevant candidates, while the final choice of the best entity is mainly driven by the commonness feature.

Other approaches. Relatedness function  X  MW is par-tially inspired by the so-called Normalized Google Distance ( NGD ) [5], which borrows from Kolmogorov complexity and information distance concepts. While NDG is tailored to measure similarity between words or phrases,  X  MW measure is specifically tailored to entities represented in a graph struc-ture such as the one of Wikipedia. In [10] another Wikipedia-based relatedness measure, named ESA , is proposed. A word is represented in a high dimensional space by considering for each Wikipedia article the relevances of the word in the ar-ticle, and by summing such score vectors for longer text fragments. Also [13] investigates new text-based relatedness measures that try to go beyond link-based similarities. The study conducted in [18] shows however that ESA has a per-formance similar to that of  X  Milne , with the latter being much cheaper to be computed since it does not require to index the whole Wikipedia textual content. In [22], the authors improve only slightly the solution proposed in [6], but they do not provide any comparison with [19, 12].

The authors of [23] propose a machine learning approach to rank entity-based facets related to a given Web search query. Since the paper focuses on a special set of entities, such as monument and celebrities, the presented technique exploits information coming from image search queries and Flickr image tags. The goal of [23] is not to discover the degree of relatedness between entities, but rather to suggest entities that are most likely to generate a large click through.
Finally, several works [7, 8, 19] exploit machine learning techniques for entity linking, but in this paper we use learn-ing to rank for improving the relatedness function , which is important for improving quality of entity linking task as well in other tasks, such as entity ranking [1] or entity sugges-tion [2].
In the following we describe the methodology adopted to build a reference dataset for the learning process, the feature used to describe entities, and finally the performance of two automatically learned relatedness functions.
In order to evaluate the impact of different relatedness functions, we built a benchmark dataset for Problem 2.1. This dataset, used to train and test our relatedness func-tion, contains a set of tuples in the form  X  , R , E  X  , where is an entity occurring in a document D , R is a set of can-didate entities possibly occurring in D , and E  X  X  are the relevant entities occurring in D besides .

In order to build these tuples, we need both positive and negative examples, i.e., positive ones from E and negative ones from R \E . In most entity-annotated datasets, each document is annotated by one or more human assessors, who manually performed some kind of spotting and entity disambiguation tasks. Therefore, for each document D we only have positive examples, i.e. the set A D of entities ac-tually occurring in D . In addition, we do not know the spot in D that actually mentions each entity in A D .

Hence, to generate our dataset for training our related-ness function, we have to devise a sort of reverse annotation process, aimed at discovering the spots associated with the known entities, and the potential candidates of such spots. In this way, we identify also the negative examples to build the tuples  X  , R , E  X  . In more detail, we generate our bench-mark dataset as described below: 1. we set up a knowledge base KB of entities based on 2. we generate all n-grams of every given document D , 3. for each spot s i in S D , we retrieve the candidate enti-4. we finally consider the set of relevant entities A D of D ,
At the end of the process, for each document D we have: a set of spots S D and, for each spot s i , a set of candidate entities C ( s i ) and also the mentioned entity ( s i ).
Thus, for every spot s h of every document D , we can gen-erate a tuple  X  , R , E  X  for the benchmark dataset that con-tains: (i) the actually mentioned entity ( s i ), (ii) the set of candidate entities for every other spot in the document, and (iii) the set of correctly linked, and thus related, entities in the document. By assuming that close spots are more likely to be related, we did not consider in this tuple generation step those spots occurring at a distance larger than  X  = 150 characters from the current spot associated with entity .
In our experiments we used a subset of the CoNLL 2003 entity recognition [14] task dataset, which includes anno-tated news stories of the Reuters Corpus V1. The dataset contains 1494 documents with an average length of 187 terms. Each document contains on average 11 . 7 entities.

We processed the corpus as explained above, and we thus built a dataset for evaluating the relatedness containing over 1 . 6 million tuples. We split the tuples in training, valida-tion, and test set, respectively containing 977 , 514, 369 , 798 and 302 , 529 records. Please observe that we take care of producing each dataset from a disjoint subset of documents in the collection, so that the tuples in the training and test sets were actually generated from a different subset of doc-uments.
A pair of entities a and b , for which the relatedness  X  ( a,b ) has to be estimated, is represented by a set of 27 features shown in Table 1. The choice of such features is driven by the following considerations. First, we want to maximize their applicability by using publicly available data, and by using measures that can be easily applied to other entity knowledge bases, e.g., FreeBase. 4 For this reason we do not use click-through, access log, or query log based data, which are very difficult to obtain. We use instead several features related to the link structure of our knowledge base, such as the number of in-links in ( e ) and out-links out ( e ) of an entity e .

Second, there are applications of the entity relatedness function where the concept of spot is not applicable. Con-sider, for instance, the case of related entity recommenda-tion where the query is a entity that is not associated with
In our datasets, this happens in only 2% of the cases. http://www.freebase.com/ any spot. Therefore, we do not include features such as link probability and commonness .

Finally, we do not include text-based similarity measures, such as cosine similarity between Wikipedia articles pages, because this kind of approaches have been proven to perform similarly to the  X  MW measure, but are much more computa-tionally expensive [18].

Note that, by using the proposed machine learning ap-proach, the feature set we adopt can be easily enriched with any additional feature, or by analyzing any other different knowledge base.

We categorize the features listed in Table 1 in three cate-gories: singleton , asymmetric and symmetric .

Singleton features regard a single entity. They include only frequency and entropy, computed on the basis of the fre-quency of Wikipedia links to the entity article page. These features are computed for both entities of a given pair ( a , b ), resulting in four scores.

We claim that a relatedness function should not be sym-metric. Consider for example the entities Neil Armstrong and United States of America : it seems reasonable that the relatedness of United States of America given Neil Arm-strong is greater than the relatedness of Neil Armstrong given the United States of America . For this reason we in-cluded five asymmetric features, which are computed in both directions of the pair, resulting in ten scores.
 Last, we considered 13 symmetric features, such as  X  MW . Some of these features derive from asymmetric ones, and others are variations computed by considering outgoing links of an entity instead of incoming ones.

All the above features are computed on the basis of the same Wikipedia dump mentioned in the Section 1. There-fore, features are not extracted on the training or test dataset.
To solve the Entity Relatedness Discovery problem, we used an existing tool for learning ranking functions, named RankLib. 5 This includes the implementation of several ef-fective algorithms. We report the results of the two most effective: Gradient-Boosted Regression Trees [9] and Lamb-daMart [25]. We denote the models built with those algo-
Note that the two models differ significantly in the objec-tive function being optimized. The  X   X  MART model was built by a list-wise algorithm and minimizing NDCG @10. This is indeed in perfect agreement with our definition of entity relatedness problem, and with the benchmark created. On the other hand, the  X  GDBT model optimizes the error in pre-dicting the class label (i.e., relevant vs. not relevant) of a given instance. Therefore, the prediction can be used to pro-duce a ranking, but the model does not optimize the ranking directly.

In Table 3 we report the performance of the two relat-edness functions  X  GDBT and  X   X  MART , and compare it against  X 
MW . The improvement of using a machine learned func-tion that exploits 27 features is apparent with every ranking quality measure adopted. If we consider NDCG @10,  X   X  MART improves over  X  MW by a factor of 25%. The two learned func-tions have very similar performance, with no significant dif-ference. Recalling to the Example 2.1,  X  GDBT ( a,b ) = 0 . 0015 while  X  GDBT ( a,c ) = 0 . 66: the value of  X  GDBT ( a,b ) ( Androni-cus of Rhodes and Chondrichthyes ) is low as we expected. http://people.cs.umass.edu/~vdang/ranklib.html Table 1: Features for entity relatedness learning.
In order to gain some insight on the learned functions, and on the role of the different features, we run a study based on a na  X   X ve feature selection algorithm [11]. This algorithm ranks features by leveraging their similarity and the score of single-features models. It promotes effective features and demotes features similar to any other already selected one. Our objective here is not to find the best performing subset of features, but rather to investigate the importance of  X  compared with other features not considered by state-of-the-art algorithm.

We measured the performance of the models built by means of LambdaMart algorithm when exploiting a single feature. In Table 2 we reported for each feature the score it can achieve. Recall that the relatedness function is required to Table 2: Entity ranking performance with a single feature. Features are sorted by NDCG @10.
  X 
MW 0 . 59 0 . 63 0 . 62 0 . 42 0 . 31 0 . 72  X   X  MART 0.75 0.79 0.80 0.51 0.36 0.87  X  GDBT 0.75 0 . 78 0.80 0.51 0 . 35 0 . 86 Table 3: Entity ranking performance of learned re-latedness functions. learn a score of a candidate entity w.r.t. to a correct entity, which in the table are denoted with c and e respectively. Therefore, P ( c | e ) is the conditional probability of finding the candidate entity c given our actually mentioned entity e , while P ( e | c ) is the converse.

Results are very similar for every quality measure. Let X  X  consider NDCG @10. The function  X  MW is the fourth most effective feature with a score slightly below that of Jaccard and Friend functions. The most effective feature is P ( c | e ), that is the conditional probability of the finding a mention to entity c given a Wikipedia page that mentions the entity e . Note that this quite intuitive feature behaves largely better than  X  MW with a score of . 72, but it is however far from the score achievable with the full set of features. Also, note that statistic P ( c | e ) comes from a collection being completely different from the test set, since it was computed on the Wikipedia corpus and not on the train collection. A third interesting property is the asymmetry of this feature.
The second column of Table 2 reports the rank assigned by feature selection algorithm. While P ( c | e ) is ranked first being the most effective features,  X  MW is ranked only 19-th. This is due to the heuristic strategy of the algorithm, which demotes features if they are similar to previously selected ones.

Figure 2 shows the result of a multidimensional scaling mapping of the 27 features into a 2-dimensional space, thus Figure 2: Multidimensional mapping of feature sim-ilarity computed using Kendall X  X   X  coefficient. The size of each circle is proportional to the single-feature model score. approximately preserving feature similarity. We measured the similarity between a feature pair according to the Kendall X  X   X  coefficient. We can identify two interesting clusters. The first contains  X  MW together with J in -out and  X  2 , and, indeed, the first two have identical performance. The second cluster includes the two best performing features P ( c | e ), P ( e,c ) and also Jaccard similarity. Even if the features in those clusters are similar w.r.t. the Kendall X  X   X  coefficient, the score of the corresponding single feature model is very different, in particular for the best scoring P ( c | e ). This suggest that the Kendall X  X   X  coefficient may not be the best indicator in this context, and the feature selection may not be trivial.
Finally, in Figure 3 we measured the relative improve-ment provided by each feature. Features are sorted accord-ing to the ranking given by the feature selection algorithm mentioned above, and we measured the performance of the model by adding features incrementally. The model achieves almost optimal performance with the first 5 features. Opti-mal performance are achieved after 9 features are introduced in to the model. This shows that not all the features are necessary, and that a wisely chosen subset of features can provide optimal performance, or help in trading accuracy with efficiency. Several existing feature selection techniques can be used to this end. However, this is outside the scope of this work.
We run a set of experiments to show how the automati-cally learned relatedness function can be profitably exploited by a class of entity disambiguation algorithms. We plugged the learned function into several annotation methods, which can be considered the state-of-the-art ones:
WikiMiner. The method proposed by Milne and Witten N
DCG @ k
Referent Graph. This method takes into account all the
TAGME. This annotator computes the weighted average
With the exception of WikiMiner, the source code of the frameworks proposed is not publicly available. Furthermore the code released is not easy to extend for implementing other annotators. Annotation depends on several subtasks, i.e., (i) process Wikipedia (parse the dump, generate the possible spots, filter stop-words, etc.); (ii) perform the spot-ting (relying on a dictionary or using a name entity recog-nition framework, like the Stanford Named Entity Recog-nizer 6 ); (iii) disambiguate the ambiguous spots, and (iv) rank entity candidates.

It is worth to observe that a good performance obtained in the first tasks may heavily impact on the performance of the whole system, as well as using a different dump of Wikipedia (i.e., old dumps contain less entities, but also have less am-biguity for each spot), or a different commonness or link probability thresholds. For these reasons, we strongly be-lieve that for this kind of research it is important to share a unique framework where these tasks are well separated and easy to isolate in order to study their performance. This would also allow us to experiment hybrid solutions combin-ing subtask solutions of different methods (e.g., the TAGME spotter with the WikiMiner disambiguation algorithm).
We developed Dexter [3], an entity annotator framework, containing several utilities to manage the Wikipedia dump, http://www-nlp.stanford.edu/software/CRF-NER. shtml a spotter based on the anchors and titles extracted from the dump, and data structures for retrieving all the features used by the annotators. Unlike WikiMiner, our framework does not rely on an external database to store the labels. In addition, during the execution it can maintain the model either on the disk or in main memory to improve perfor-mance. The framework runs also on normal hardware, since we exploit efficient data structures in order to maintain com-pressed data in main memory. The dataset we used, the source code and more detailed informations can be found at this address: dexter.isti.cnr.it .

We implemented WikiMiner, Referent Graph and TAGME in our framework, in order to verify if our relatedness func-tion is able to improve the annotator performance. Dur-ing the implementation, we slightly modified WikiMiner and TAGME: in WikiMiner we decided to rank the entities using a linear combination of commonness, link probability, and average relatedness with the context (the authors employed a classifier trained with several features that were heavy to retrieve); in TAGME we relied on our spotter that returns all the possible spots detected in the text, while in the orig-inal version the authors employ a specific policy for deleting spots in case of overlaps (we remove overlapping annotations at the end of the process, relying on the final ranking of the entities). We set the commonness threshold to 0 . 03 and we discard spots with link probability lower than 0 . 02.
Note that we are not interested in the absolute entity-linking performance of WikiMiner, TAGME, and Referent Graph, but rather on how the relatedness function impacts on the disambiguation process. For this reason, we im-plemented all the three algorithms within the same frame-work, and thus providing them with the output of the same spotter. For the same reason, the results of the Web ser-vices implementation of WikiMiner and TAGME are not reported. Those services use a different dump of Wikipedia, which is processed in a different way (e.g., tokenization, etc.), and they exploit a slightly different spotting algorithm, and this makes such results non significant within the scope of this work. However, it is important to report that we observed that our implementation always improves over the WikiMiner online service, and that it behaves only slightly worse then TAGME after the top 5 results, probably due to a different processing of Wikipedia.

We compared the results obtained by embedding different implementations of  X  :  X  MW ,  X   X  MART , and  X  GDBT . Note that by embedding  X  MW we are replicating the original algorithms that we consider as baselines to evaluate our proposed re-latedness function.

The quality of the resulting algorithms is evaluated with the usual Precision@ k ( k = 1 , 5 , 10), Recall, and NDCG mea-sures. We also report the interpolated precision at a certain recall cutoff r , iP r with r = 0 . 1 and r = 0 . 5, the Mean Re-ciprocal Rank MRR and the Precision after R documents have been retrieved, where R is the total number of relevant entities for the document ( RPrec ).

We remind that in this evaluation we want to evaluate the number of correctly annotated entities for a given doc-ument ; the evaluation is not spot-based, but we are rather considering the entity linking process as a whole, and its goodness on the full document.

The test dataset adopted is the same as the one of previ-ous experiment, meaning that there is no overlap among the documents used for training the function  X  , and the docu-ments used to evaluate its impact on the entity annotation process.

Table 4 reports the performance of the three annotators: for each annotator we show the performance using the orig-inal  X  MW relatedness function, and then the effects of re-placing the relatedness function with our learned relatedness  X   X  MART and  X  GDBT . The performance improvement given by the trained functions is significant:
Referent Graph . The proposed functions improve the
WikiMiner .  X  GDBT improves both recall and NDCG , with
TAGME . Recall, NDCG , and precision exhibit a positive
In general, the best result quality was obtained using the  X 
In this work, we have proposed a machine learning based approach aimed at discovering the entity relatedness func-tion that can better support the entity linking task. We illustrated some of the properties that such function should preserve, and we presented a simple method to generate a training set form a collection of document human assessed entity linked documents. We casted the problem of discov-ering a suitable entity relatedness function into a learning to rank formulation. Our proposed approach is thus able to learn how to wisely blend the available features to generate a good entity relatedness function. We demonstrated that by exploiting our framework it is possible to better estimate the relatedness of two entities, and to compare and improve the performance of different state-of-the-art entity linking algorithms.

The proposed framework opens up a wide spectrum of improvement opportunities. In particular, We plan to in-vestigate the tread-off between feature computational cost and benefit, and to embed our machine learned relatedness function into other entity-based tasks.
 This work was partially supported by the EU projects In-GeoCLOUDS (no. 297300), MIDAS (no. 318786), E-CLOUD (no. 325091) and the Regional (Tuscany) project SECURE! (FESR PorCreo 2007-2011). [1] M. Bron, K. Balog, and M. de Rijke. Ranking related [2] D. Ceccarelli, S. Gordea, C. Lucchese, F. M. Nardini, [3] D. Ceccarelli, C. Lucchese, S. Orlando, R. Perego, and [4] S. Chakrabarti, S. Kasturi, B. Balakrishnan, [5] R. Cilibrasi and P. Vitanyi. The google similarity [6] S. Cucerzan. Large-scale named entity disambiguation [7] M. Dredze, P. McNamee, D. Rao, A. Gerber, and [8] P. Ferragina and U. Scaiella. Tagme: on-the-fly [9] J. Friedman. Greedy function approximation: a [10] E. Gabrilovich and S. Markovitch. Computing [11] X. Geng, T.-Y. Liu, T. Qin, and H. Li. Feature [12] X. Han, L. Sun, and J. Zhao. Collective entity linking [13] J. Hoffart, S. Seufert, D. B. Nguyen, M. Theobald, and [14] J. Hoffart, M. Yosef, I. Bordino, H. F  X  urstenau, [15] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [16] T. Joachims. Optimizing search engines using [17] R. Mihalcea and A. Csomai. Wikify!: linking [18] D. Milne and I. H. Witten. An effective, low-cost [19] D. Milne and I. H. Witten. Learning to link with [20] L. Page, S. Brin, R. Motwani, and T. Winograd. The [21] P. Pantel and A. Fuxman. Jigs and lures: Associating [22] W. Shen, J. Wang, P. Luo, and M. Wang. Linden: [23] R. van Zwol, L. Garcia Pueyo, M. Muralidharan, and [24] G. Weikum and M. Theobald. From information to [25] Q. Wu, C. Burges, K. Svore, and J. Gao. Adapting [26] M. Yosef, J. Hoffart, I. Bordino, M. Spaniol, and
