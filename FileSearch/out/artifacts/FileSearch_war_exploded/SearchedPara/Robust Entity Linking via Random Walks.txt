 Entity Linking is the task of assigning entities from a Knowl-edge Base to textual mentions of such entities in a docu-ment. State-of-the-art approaches rely on lexical and sta-tistical features which are abundant for popular entities but sparse for unpopular ones, resulting in a clear bias towards popular entities and poor accuracy for less popular ones. In this work, we present a novel approach that is guided by a natural notion of semantic similarity which is less amenable to such bias. We adopt a unified semantic representation for entities and documents X  X he probability distribution ob-tained from a random walk on a subgraph of the knowledge base X  X hich can overcome the feature sparsity issue that affects previous work. Our algorithm continuously updates the semantic signature of the document as mentions are disambiguated, thus focusing the search based on context. Our experimental evaluation uses well-known benchmarks and different samples of a Wikipedia-based benchmark with varying entity popularity; the results illustrate well the bias of previous methods and the superiority of our approach, especially for the less popular entities.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  information filtering, search process Entity linking, relatedness measure, random walk
Entity Linking (EL) is the task of assigning unique iden-tifiers of entities in a Knowledge Base (KB) to mentions of named entities in a text document. EL is key for Infor-mation Extraction (IE) and many other applications. For instance, it enables expanding or correcting a KB with facts extracted from documents X  X  task called Knowledge Base Population [15]. Another application is Semantic Search, the emerging paradigm of Web search that combines Infor-mation Retrieval approaches over document corpora with KB-style query answering and reasoning to offer more accu-rate and concise answers to Web searches.

EL is challenging due to the inherent ambiguity of nat-ural language: most entities can be referred to in different ways, and the same mention may refer to multiple real-world entities, as illustrated in the following examples: Example 1. Saban , previously a head coach of NFL  X  X  Miami , is now coaching Crimson Tide . His achievements include leading LSU to the BCS National Championship once and Alabama three times.

Example 2. After his departure from Buffalo , Saban returned to coach college football teams including Miami , Army and UCF .

In Example 1, both Crimson Tide and Alabama refer to the same football team, the Alabama Crimson Tide of the University of Alabama. On the other hand, Saban refers to two different coaches: Nick Saban in Example 1 and Lou Saban in Example 2. Similarly, Miami in Example 1 refers to the NFL football team Miami Dolphins , while in Example 2 it refers to the college football team Miami Hurricanes .
The EL task can be cast as an all-against-all matching problem: given m mentions in a document and n entities in a KB, perform the m  X  n comparisons and pick the ones with the highest similarity (one for each mention, of course). This is prohibitively expensive and unnecessary, however. Most methods, including ours, operate in two stages: the first is to select a suitable set of candidate entities for each mention, and the second is to perform the actual mention disambiguation. Selecting candidate entities is done, pri-marily, by consulting alias dictionaries (e.g., produced from a Wikipedia corpus). In the examples above, both coaches Lou Saban and Nick Saban would be picked as candidates for the mention Saban , as would the companies Saban Capital Group and Saban Entertainment . As for the disambiguation phase, most methods in the literature can be divided into two main groups, discussed next.
 lexical features, such as contextual words or named entities, surrounding each mention in the document [2, 3]. They dis-ambiguated each mention independently, typically by rank-ing the candidate entities according to their feature similar-ity with the mention, and picking the most similar candi-date. These approaches work best when the context is rich enough to uniquely identify a mention, which is not always the case. For instance, both Saban and Miami in the exam-ples above are hard to disambiguate locally. Another issue is the feature sparsity problem , which arises because many mentions to the same entity are too dissimilar to match (e.g., Edmonton and The City of Champions ), and are thus missed by the similarity measure. False-positives are also common: the mention to Miami in the examples above may mislead the disambiguation of Saban , leading to the erroneous con-clusion that both sentences refer to a single football coach. count the semantics of the mentions and candidate entities, represented as a graph consisting of entities and links in the KB. In general, they start with a graph that has all m men-tions in the document, linked to every one of their candidate entities in the KB. In turn, the candidate entities are also linked to a small subset of their full neighborhood in the KB. Disambiguation in this approach is done collectively on all mentions at the same time [6, 13, 16, 23]: they seek to find a forest embedded in the constructed graph in which each mention remains linked to a single candidate entity. This approach is motivated by the premise that the disam-biguation of one mention contributes to the disambiguation of the remaining mentions in the same document. For ex-ample, linking Crimson Tide to Alabama Crimson Tide will make it easier to disambiguate Saban in Example 1 to Nick Saban since he is more semantically related to that team (i.e., there is a link between these entities in the KB).
Of course, the notion of semantic relatedness used by each method is key to its accuracy and cost. One successful strategy uses a text-based relatedness measure [12] based on weighted (multi-word) keyphrases about the entities, col-lected at the time the KB is built. This approach works best when the input document mentions the candidate en-tities in similar ways to those in the corpus used for the KB construction. Another approach uses the set of entities directly connected in the KB [20]. Doing so, however, ig-nores entities that are indirectly connected but semantically related, making limited use of the KB graph.

Another observation about global methods is that, to pro-duce meaningful results, the search must be constrained so that it produces a small mention-to-entity assignment (i.e., forest in the original graph) with high global coherence (e.g., based on semantic relatedness). However, finding such an assignment is NP-Hard [16], and all methods turn to ap-proximate algorithms or heuristics. One interesting way to cope with the complexity is to use a greedy search, starting with mentions that are easy to disambiguate (e.g., have just one candidate entity) [21].
This paper introduces Rel-RW (Robust EL with Ran-dom Walks): a global EL approach based on an iterative mention disambiguation algorithm. We use a novel measure of semantic relatedness: we build an expanded entity graph like other global approaches, and we represent each candi-date entity by the stationary probability distribution result-ing from a random walk with restart [24] on that graph. We call such distributions the semantic signature s of the enti-ties. As demonstrated in the personalized PageRank algo-rithm [11], a random walk with restart on a graph can prop-agate information along the edges and provide a relatedness measure between indirectly connected nodes. The proba-bility value in the stationary distribution can be viewed as the interestingness these target entities have on each entity in the graph, with higher value indicates higher relatedness between each entity and target entities. Thus, our semantic signatures capture the semantics of the entities in terms of their relevance with respect to all other entities in the entity graph. Because the graph is built for each document, our semantic signatures are specific to the domain of the doc-ument. Semantic relatedness in our approach is measured using Zero-KL Divergence [14], although other ways are pos-sible (e.g., cosine similarity of the semantic signatures).
Our disambiguation algorithm is iterative. Suppose that at a given round there are k mentions already disambiguated. The algorithm uses a random walk with restart using all k entities to find the semantic signature of the document , which is used to compute the similarity of all ambiguous mentions against their candidate entities. The algorithm picks one entity and greedily assigns it to the candidate with highest total score above a threshold, or NIL if no such can-didate exists, and proceeds to the next round, re-computing the semantic signature of the document as mentions are dis-ambiguated. For the first round, the semantic signature of the document can be initialized in one of two ways. First, if there are unambiguous mentions [21] at the beginning of the first round, those are used to define the signature. Oth-erwise, the candidate entities of mentions weighted by their importance and prior probability are used.
 There are several advantages in using semantic signatures. First, they capture the semantics of an entity in a more fine-grained manner than the 0-1 coarse weighting in lo-cal approaches. Second, through the random walk on an entity graph, they incorporate those indirectly-connected but semantically-related entities into the representation of the target entity, which are ignored by the current link-based relatedness measures. Third, the global coherence assumption X  X hat coherent entities form a dense subgraph X  still applies on an entity graph carefully constructed from the knowledge base, which means that the less popular en-tities in a KB can still get high score in the entity graph since they are semantically more related with other entities in the graph thus receive more connections. As confirmed by the experiments reported in this paper, this enables our approach to excel in disambiguating less popular entities, without compromising accuracy for very popular ones. Fi-nally, the random walk with restart can be used on a set of target entities to compute the semantic signature of doc-uments (represented by a set of target entities). In other words, the semantic signature is a unified representation for entities and documents, and can greatly facilitate the mea-sure of global coherence between entities and documents.
The contributions of this work are:
Given a knowledge base (KB), usually in the form of a graph, and a document d with mentions marked up (usually through a named entity recognition process), entity linking aims at assigning unique entities from the KB to those men-tions, whenever appropriate. More precisely:
Definition 1 (Entity Linking). Given a set of men-tions M = { m 1 ,...,m n } in a document d , and a knowledge base KB whose entity set is E , the problem of entity linking is to find an assignment  X  : M  X  E  X  X  NIL } .
 As usual, NIL is used for mentions outside of the KB.
As mentioned, Rel-RW is a global EL approach. Our goal is to find the best assignment  X  that is contextually com-patible with mentions in M , and has maximum coherence. Formally, the solution to the EL problem is an assignment  X   X  maximizing the following objective function: in which  X  ( m i ,e i ) measures the local compatibility of m and e i , and  X ( X ) measures the global coherence of an as-signment  X .
Since the compatibility measure  X  ( m i ,e i ) is straightfor-ward to compute 1 , the focus of the objective function above is the measure of coherence among entities in an assignment. Recall that solving Equation 1 is NP-hard in general. Our approach is to use a greedy and iterative heuristic: in each iteration, we re-compute the semantic signature of the doc-ument d , and disambiguate a mention m according to: where CS ( m ) are the candidate entities for m , and  X  ( e the semantic relatedness measure. In the next iteration, the entity e i linked to the mention m will be taken into account when re-computing the semantic signature of the document. By doing so, we guide the search and increase the coherence of the resulting assignment.
 Linking to NIL . A mention is linked to NIL in one of two cases: (1) when the mention has no good candidate enti-ties; and (2) when the similarity score of the entity maxi-mizing Equation 2 and the document is below a threshold. Both thresholds are, of course, application-specific. In fu-ture work, we will study their impact on typical EL tasks.
Knowledge bases are graphs where the nodes are entities and edges between entities exist whenever they are semanti-cally related. The graph connectivity can be used to measure relatedness between entities as follows. Let G = ( V,E ) be a graph and let  X  V  X  V be a set of vertices such that |  X  The semantic signature of a vertex v  X   X  V is a n -dimensional vector where the weight of index i is the relatedness between v and the vertex i in  X  V . In this work, relatedness is defined as the probability that node i is visited in a random walk
We combine the prior probability and context similarity to measure the local compatibility in our system. Figure 1: Semantic signature of entities and documents. process restarting at vertex v . We call each n -dimensional vector the semantic signature of the vertex v .

Th notion of signature extends naturally to a set of k ver-tices of  X  V : perform a random walk with restart from the k vertices and consider the resulting probability distribution over the n vertices. Thus, we can obtain the semantic signa-ture of an entire document by performing the random walks from the entities that are mentioned in it.

Figure 1 illustrates the idea of the semantic signature of entities and documents.
A random walk with restart is a stochastic process to tra-verse a graph, resulting in a probability distribution over the vertices corresponding to the likelihood those vertices are visited. This probability can be interpreted as the relat-edness between nodes in the graph. The random walk starts with an initial distribution over the nodes in the graph, prop-agating the distribution to adjacent vertices proportionally, until convergence.

Let A be the transition matrix of the KB graph, with A ij being the probability of reaching entity e j from entity e which can be computed as follows: in which OUT ( e i ) is the set of entities directly reachable from e i , and w ij is the weight of the edge between e i defined as the number of their co-occurrences in the knowl-edge base (see below).

Let r t be the probability distribution at iteration t , and r be the value of entity e i , then r t +1 i is computed as follows: in which IN ( e i ) is the set of entities linking to e i
As customary, we incorporate a random restart proba-bility in the preference vector to avoid the issues caused by sinks and guarantee convergence. Formally, the random walk model can be modeled as: where ~v is the preference vector, and P v i = 1. We also follow the standard convention and set  X  = 0 . 85.

When a random walk process converges to a stationary state, we obtain a stationary distribution , which is what we use as our semantic signature. Mentions Candidates Extended entities Entity Graph We follow the standard practice of deriving a KB from Wikipedia. The entity graph G = ( V,E ) is such that V contains the entities (i.e., individual articles in Wikipedia) and the edges in E are added if the two entities: (1) are men-tioned in the same Wikipedia article, within a window [4] of 500 words 2 , or (2) there is an explicit hyper-link from one entity to the other. In this way, we construct a very dense entity graph consisting of over 4 million entities (i.e., Wikipedia articles). However, with respect to the semantic signature computation, the efficiency on this large graph will be a big concern. Thus, we seek to construct a much smaller subgraph that can improve the efficiency without sacrificing the effectiveness.
 with a set of candidate entities for mentions in a document. Given a set of mentions M , the first step is to find good candidate entities from the KB X  X  set of entities that could be referred to by mentions in M (details about candidate selection will be described in Section 4.1). The candidate entities and the edges among them form an initial entity graph, which is expanded by adding all entities adjacent to a candidate entity (and the edges within that subgraph too). Figure 2 illustrates the process: the leftmost column shows the mentions, the middle column lists the set of candidate entities, while the rightmost column has the extra entities added to the graph.

We post-process the expanded graph to remove noisy en-tities and reduce the size of the subgraph by pruning non-candidate entities that are connected to just one candidate entity as well as entities with low degree (200 was exper-imentally chosen as the minimum value). Our KB graph 500 was chosen based on intuition, without detailed exper-imental evaluation. Tuning the best window size will be a subject of future work. is so dense that, without pruning, the expanded subgraph of most mentions quickly becomes prohibitively large. No-tice that candidate entities are never pruned, to make sure unpopular entities are not ignored.
 proving the efficiency of the random walk process, another advantage of the smaller subgraph we build is that candi-date entities and their semantically-related entities are more densely connected (as per co-occurrence and direct linkage in Wikipedia), which preserves the global coherence assump-tion in most global approaches. As illustrated in Figure 2, the football related entities such as Nick Saban , National Football League , and others form a much denser subgraph than other entities.
With the entity graph, we can then compute the semantic signatures of entities with the random walk model.
To compute the semantic signature for a target entity e i we need to ensure that the random walk always restarts from e . This can be done by setting the preference vector ~v with v
In principle, computing the semantic signature of a docu-ment is no different than doing so for a single entity. Given a set of entities E d representing a document, we set their preference probability in vector ~v , and then compute the se-mantic signature of the document through the random walk with restart from entities in E d .

However, there are two problems here. First, we do not know the true entity set E d that represents the document (finding this set is the goal of EL after all). Second, it is not clear how to set the weights in the preference vector. Differ-ent entities may have different importance to the document and a uniform weight may not reflect their importance. To solve these two problems, we adopt the following strategies. Finding E d . We say a mention is unambiguous if there is only one entity in the KB associated with it. Unambiguous mentions have been shown to help in the EL task [21]. In Example 1, BCS National Championship is one such unam-biguous mention, which is very useful to disambiguate other mentions. We initialize the set E d with the referent entities of all unambiguous mentions in M , and expand it as more mentions are disambiguated.

In case all mentions in the document are ambiguous, we approximate E d using candidate entities of the mentions in M . Although this approximation can bring in a lot of noise, and thus decrease the accuracy of the disambiguation, the effectiveness may not be affected much by the noisy entities when the true entities are well connected in the graph. entity e i could be affected mainly by two factors: P ( e the probability mention m refers to e i , and I ( m ) X  X he im-portance of the mention in its document.

For the case that the referent entities of unambiguous mentions are used, the P ( e i ,m ) is 1 since e i is considered as the true entity of m . When using the candidate enti-ties, the probability P ( e i ,m ) can be measured in several ways. Prior probability is a statistical measure shown to be a strong baseline [8]. Other alternatives are using the context similarity between e i and m or assigning weights uniformly. We experimented with several options, and, for-tunately, as shown in our experimental evaluation, Rel-RW is very robust to the choice of weights, consistently yielding good results.

The importance of a mention I ( m ) is measured using the standard tf-idf scheme.

Combining the two factors P ( e i ,m ) and I ( m ) together, we can compute the preference probability as follows:
With the preference vector ~v , the semantic signature of a document can be computed using a random walk with restart on the entity graph. As shown in Figure 1, the row for document d gives its semantic signature. Suppose there are total K candidates for all mentions in M , we need to compute K + 1 semantic signatures ( K for entities, and 1 for the document). To improve the efficiency, we adopt the following methods. First, we rank candidates by their relevance to mentions and select only the top candi-dates for each mention. Second, we limit the size of the en-tity graph by pruning uncommon entities as described above. Third, we parallelize the computation of the semantic signa-tures for the candidate entities. Our current implementation of
Rel-RW was done with accuracy in mind, and we have not yet investigated how to properly engineer it to make it real-time. Nevertheless, it is competitive with other off-line state of the art methods. Future work will explore the rich literature on speeding up the computation of random walks, as well as efficient indexing mechanisms for the efficient com-putation of the entity graphs from the KB.
After computing the semantic signatures of the document and entities, the next step is to disambiguate mentions in the document.
Mention disambiguation starts with generating candidates for each mention in M from the knowledge base. For this purpose, we use an alias dictionary collected from Wikipedia titles, redirect pages, disambiguation pages, and the anchor text in Wikilinks [6]. The alias dictionary maps each alias to a list of entities it refers to in Wikipedia.

Given a mention m , we search its name against the alias dictionary and select the set of entities the mention name refers to. This would generate a long list of candidates. To keep the list short and improve the efficiency, we prune noisy candidates according to the following two criteria. Algorithm 1 Iterative Mention Disambiguation Input: M = { m 1 ,m 2 ,...,m n } , G = ( V,E ) Output: An assignment  X  = { e 1 ,e 2 ,...,e n } , in which e 1: E d =  X  ,  X  =  X  2: for all m i  X  M do 3: if | CS ( m i ) | = 0 then 4:  X ( m i ) = NIL 5: else if | CS ( m i ) | = 1 then 6: E d = E d  X  CS ( m i );  X ( m i ) = e  X   X  CS ( m i ). 7: end if 8: end for 9: if | E d | = 0 then 10: Initialize E d with candidates of mentions in M . 11: end if 12: SS ( d ) = ComputeSignature ( G,E d ) 13: Rank m i  X  M by their ambiguity | CS ( m i ) | . 14: for all m i  X  M and | CS ( m i ) | &gt; 1 do 15: for e j  X  CS ( m i ) do 16: SS ( e j ) = ComputeSignature ( G,e j ) 17:  X  ( e j ,d ) = SemanticSimilarity ( SS ( e j ) ,SS ( d )) 18: SimilarityScore ( e j ) =  X  ( m i ,e j ) +  X  ( e j ,d ). 19: end for 20: Rank candidates CS ( m i ). 21: Select the target entity e  X  with the maximum score. 22: Remove the rest candidates from CS ( m i ). 23: if SimilarityScore ( e  X  ) &lt;  X  then 24:  X ( m i ) = NIL ; Remove e  X  from CS ( m i ). 25: else 26: E d = E d  X  X  e  X  } ;  X ( m i ) = e  X  . 27: end if 28: if E d is changed then 29: SS ( d ) = ComputeSignature ( G,E d ) 30: end if 31: end for
The second step is to select the referent entity from the candidate set CS ( m ). As defined in the objective function 2, the referent entity is the entity that is most coherent with the mention and the document.
Let SS ( e i ) be the semantic signature of a candidate en-tity e i  X  CS ( m ), and SS ( d ) be the semantic signature of the document d . There are several ways one can compare these probability distributions to estimate the semantic sim-ilarity of the m and d . One standard way of doing so is to use The Kullback-Leibler (KL) divergence: given two prob-ability distributions P and Q , their KL divergence measures their distance, as follows:
In this work, we use Zero-KL Divergence [14], a better approximation of the KL divergence that handles the case Datasets Systems Accuracy F1@MI F1@MA Accuracy F1@MI F1@MA Accuracy F1@MI F1@MA PriorProb 85.98 86.50 87.15 84.87 87.27 87.16 84.82 85.49 87.13 Local 77.43 77.91 72.30 66.44 68.32 68.09 61.48 61.96 56.95 Cucerzan 87.80 88.34 87.76 76.62 78.67 78.22 78.99 79.30 78.22 M&amp;W 68.45 78.43 80.37 79.92 85.13 84.84 75.54 81.29 84.25 Han X 11 87.65 88.46 87.93 77.16 79.46 78.80 72.76 73.48 66.80 AIDA 76.83 78.81 76.26 52.54 56.47 56.46 77.04 80.49 84.13 GLOW 65.55 75.37 77.33 75.65 83.14 82.97 75.49 81.91 83.18 RI 88.57 90.22 90.87 85.01 87.72 87.74 82.35 86.60 87.13 REL-RW 90.12 91.37 91.73 88.99 90.74 90.58 86.93 87.68 89.23 when Q i is zero.
 in which  X  is a real number coefficient. Following the recom-mendation in [14], we set  X  = 20, arriving at the semantic similarity used in Equation 2:
With the candidate set and semantic relatedness mea-sure, we can then disambiguate mentions by selecting en-tities maximizing the ranking function in Equation 2.
As described in Section 3, the representative entities are crucial for computing the semantic signature of a document. Using candidates of mentions to represent a document may bring in noisy entities that are not useful. While unambigu-ous mentions are informative, they could be rare so that only partial semantics of the document is captured. To address this issue, we propose an iterative algorithm which utilizes the disambiguation results of previous iterations to progres-sively update the representative entity set and the semantic signature of the document.

Instead of ranking candidates and choosing entities with the highest score for each mention independently, our algo-rithm performs the disambiguation iteratively in the order of their ambiguity (which is measured by their number of candidates) from the least ambiguous mention to the most ambiguous one. In each iteration, the results of previous it-erations are used to update the representative entity set and the semantic signature of the document. For the case we start with the candidates of mentions (when no unambigu-ous mentions exist), the representative entity set is changed to the disambiguation results right after they become avail-able.

Algorithm 1 shows the disambiguation process. We first disambiguate mentions with none or one candidate and ini-tialize the entity set E d with the entities of unambiguous mentions (Lines 2-8). In case all mentions are ambiguous, the candidates of mentions are used to initialize E d (Lines 9-11). We then compute the semantic signature of the doc-ument using E d (Line 12), and sort mentions according to their ambiguity (Line 13). In each iteration of the disam-biguation process, we update the similarity score between each candidate e i and document d with the latest semantic signature (Lines 15-19). Note that the semantic signatures of all candidate entities are pre-computed. After that, we rank the candidates and choose the entity with the maxi-mum score (Lines 20-22). If the score of the best candidate for a mention is below a threshold  X  , we link the mention to NIL (Line 24). Otherwise, we update the entity set E d using the linked entity e  X  (Line 26), and the semantic signature of the document with the enriched E d . The new SS ( d ) will be used for disambiguation in the next iteration (Line 16). The whole process continues until all mentions are disam-biguated.
We now report on a comprehensive experimental evalua-tion of our Rel-RW method, comparing it to the state-of-the-arts and strong baselines.
 tor systems: Cucerzan [6] X  X he first collective EL system that solved the EL as an optimization problem, M&amp;W [21] X  a representative machine learning EL system, Han X 11 [10] X  a graph-based collective system exploiting the random walk model on an entity graph to jointly link mentions, AIDA [13] X  a collective approach tackling entity linking as a dense sub-graph problem, GLOW [23] X  X  system combining local and global features for entity linking, and RI [5] X  X he start-of-the art EL system using relational inference for mention disam-biguation.

In addition, we also test 2 strong baselines: PriorProb which links mentions to the entities with the highest prior probability, and Local which chooses the candidate with maximum local compatibility  X  ( e i ,m ).
 MSNBC [6], with 20 news articles from 10 different topics (2 articles per topic) and 739 mentions in total; (2) AQUAINT, compiled by Milne and Witten [21], with 50 documents and 727 mentions from a news corpus from the Xinhua News Ser-vice, the New York Times, and the Associated Press; and (3) ACE2004 [23], a subset of the ACE2004 Coreference docu-ments with 57 articles and 306 mentions, annotated through crowdsourcing .
 Evaluation Measures. Given the ground truth T and out-put of EL systems O , in which T ent and O ent are the sets of mentions linking to entities, and T nil and O nil are the sets of mentions linking to NIL respectively ( T = T ent O = O ent  X  O nil , and | T | = | O | ), we use the standard accu-racy, precision, recall , and F1 :
Table 1 lists the results of these EL systems on the 3 benchmarks in terms of accuracy and F1, aggregated across mentions (micro-averaged, indicated as F1@MI ) and across documents (macro-averaged, F1@MA ).
 Several observations are worth noting here. First, the Local baseline indicates that text-based features alone can-not solve the EL problem satisfactorily. Combining local compatibility with the semantic relatedness, as in Han X 11 , provides substantial gains. The RI system, which takes ad-vantage of the relational constraints, performs much better than most systems. Our system Rel-RW outperforms all the state-of-the-arts and the baselines on the three datasets, showing the superiority of our semantic signatures and the mention disambiguation algorithm. It also shows that the coherence between entities and the document may be a bet-ter choice for the measure of global coherence.

Another general observation is that there is quite a bit of variability in the relative effectiveness of the systems across benchmarks. The exceptions to this rule are the RI and Rel-RW as well as the PriorProb baseline. In fact, Pri-orProb consistently outperforms many EL systems. This points to limitations in the benchmarks themselves X  X hey are clearly biased towards popular entities, and thus, not representative of all scenarios where EL is necessary.
In order to investigate how the popularity (measured by the prior probability) of entities affects the effectiveness of Figure 4: Accuracy of Rel-RW with different configu-the competing systems, we devised the following experiment. Ideally, we would use multiple subsets from the Wikipedia dump, where all entities have the same popularity. How-ever, such datasets are very hard to obtain. Instead, we used the PriorProb baseline as a proxy: we applied that baseline on all articles, and grouped them by the resulting accuracy, aggregating at one decimal place. For example, documents whose accuracy are in the range [0 . 3 , 0 . 4) are grouped together. We randomly chose 40 articles from each group, restricting selections to articles with 20 to 40 Wik-ilinks. We also resolved the redirect entities and removed mentions whose referent entities did not exist any more. In this way, we obtained 8 datasets, each of which, on average, had about 1000 mentions to be disambiguated.

Figure 3 compares all systems and baselines on the datasets we produced. As designed, the PriorProb shows a linear increase in accuracy as the  X  X ggregate popularity X  of men-tions in the datasets increases. It is worth mentioning that this experiment is particularly favorable to the M&amp;W sys-tem, which is trained on Wikipedia itself 3 . Thus, these re-sults must be taken in consideration with those on the other benchmarks (Table 1). A general trend observed for all sys-tems is that their accuracy improves as more popular en-tities are used. However, our Rel-RW is the only system that is consistently superior to the PriorProb baseline. This somewhat surprising result indicates that there is quite a lot of room for improvement before EL can be successfully ap-plied to the  X  X ong-tail X  of the Web, given their bias towards popular entities.

The high accuracy of Rel-RW on unpopular mentions is partially explained by the way we construct our entity graph. As described in Section 3, the graph is initialized with candidates, and expanded using their neighbors to in-crease connectivity. In this way, semantically-related entities are likely to form a dense subgraph. This also works for un-popular entities, on which the lexical and statistical features used by other approaches fail. Another factor is the seman-tic relatedness between indirectly connected entities which can be measured by the semantic propagation in the random walks. This effect can also be verified in the Han X 11 system,
For the sake of validity, we ensured that none of the articles in our tests appear in their training data. Figure 5: Accuracy of Rel-RW using unambiguous men-Figure 6: Accuracy of Rel-RW using candidates with which utilizes the random walk for semantic relatedness and outperforms most systems on unpopular entities.
We also performed an evaluation of Rel-RW on the TAC 2011 4 Entity Linking task. Compared to the previously dis-cussed benchmarks, the TAC dataset contains many more abbreviations and acronyms, making the mentions more am-biguous. We perform a query expansion on the abbrevia-tion mentions by extracting definitions of abbreviations us-ing patterns definition (Abbrev) and Abbrev (definition) .
Table 2 shows the results of our Rel-RW system, RI and a few top EL systems in the submissions, in terms of link-ing accuracy. Rel-RW is very competitive overall, virtually tying with RI and the top submissions to the TAC contest. It is worth noting that the MS-MLI system exploits exter-nal web search logs for candidate generation and additional training datasets. http://www.nist.gov/tac/2011/ Table 2: Accuracy of EL systems on 2011 TAC EL task.
The following experiments are aimed at determining how robust Rel-RW is relative to the choice of representative entities and weighting schemes. We compare the iterative process with the non-iterative process using two different en-tity sets and different weighting schemes on the Wikipedia-based benchmarks. For entities, we use the referent entities of unambiguous mentions or the candidates of mentions. For weighting scheme, we use tf-idf and uniform for the impor-tance of mentions I ( m ), and uniform , prior probability , and context similarity to weight the mention-entity compatibil-ity. For simplicity, we use unambiguous mentions to refer to the referent entity of unambiguous mentions.
 tion process and representative entities. Figure 4 shows the results with three different configurations: iterative process with unambiguous mentions (ITER-UNAMB), non-iterative process with unambiguous mentions (NITE-UNAMB), and non-iterative process with candidates of mentions (NITE-AMBIG). The results are reported using the average value of different weighting schemes. Note that we do not report the results of iterative process on ambiguous mentions, since we change the entity set of candidates to the disambiguation results after the first iteration, which is the same as the it-erative process on unambiguous mentions.

As we see from Figure 4, the effectiveness of the iterative process is better than the non-iterative process. This is be-cause the iterative process exploits the entity linking results in previous iterations to enrich the representative entity set which can improve the semantic representation of documents and the overall effectiveness while the non-iterative process only uses the entities of unambiguous mentions. We also found that the entity set of unambiguous mentions was a much better approximation of documents than the candi-dates of mentions.

Another observation is that the accuracy gap among dif-ferent configurations gradually decreases as the popularity of entities in datasets increases. The explanation could be that in datasets with low popularity, the true entity of a mention is rarely the candidate with the highest prior probability or context similarity, so that the semantic similarity plays a more important role for the disambiguation. While in datasets with high popularity, the difference is much smaller. sults of various weighting schemes using unambiguous men-tions and candidates of mentions respectively. As we can see from the figures, different weighting schemes make al-most no difference on the overall effectiveness of the EL sys-tem, which means that the semantic signature of a document is more dependent on the representative entities than the weighting of each entity. It also means that the entity graph structure is more important for the semantic signature than the weighting schemes.
 our method is fairly robust as the construction of the entity graph requires essentially no parameter tuning.
Earlier work on Entity Linking disambiguated each men-tion in isolation using a compatibility function to approxi-mate the likelihood of an entity being the referent entity for a mention, and treated entity linking as a ranking problem which chose the candidate with the highest compatibility. In these approaches, mentions and entities are represented as feature vectors and vector similarity measures are used to es-timate their compatibility. The most common local features include lexical features such as bag-of-words or named enti-ties from surrounding context and statistical features such as the prior probability of entities given a mention from a knowledge base. Unsupervised approaches [2, 3] commonly use the cosine similarity of feature vectors to measure the compatibility, while supervised approaches [7, 18, 21, 25 X 27] exploit various classifiers trained on labeled datasets (often derived from Wikipedia) to predict the compatibility. By restricting themselves to local features, these methods suf-fer from the data sparsity problem. Moreover, individually linking mentions does not take into account the inherent semantic coherence among them.

More recent EL systems follow the global coherence hy-pothesis and take into account the semantic relations be-tween mentions and entities, employing various measures of semantic relatedness. Most of these approaches assume that mentions in a document are semantically coherent around the subject of the document, and thus cast the entity linking as an optimization problem aiming at finding the assignment with maximum semantic coherence. Cucerzan [6] measures the global coherence using Wikipedia categories. Milne and Witten (M&amp;W) [21] use directly connected entities to rep-resent each entity and measure relatedness using normalized Google distance. Kulkarni et al. [16] also use the M&amp;W se-mantic relatedness measure and formalize the problem as an integer linear programming problem to find the assign-ment collectively. Ratinov et al. [23] add the PMI (Pointwise Mutual Information) of entities into their SVM classifier for entity linking. To use more fine-grained semantics such as relations between mentions, Cheng and Roth [5] formalize the EL as an integer linear programming problem with re-lations as constraints, and find the assignment to meet the relational constraints. Cai et al. [4] measure the semantic relatedness using the co-occurrence of entities from a link-enriched Wikipedia corpus. AIDA [13] formalizes the EL problem as a dense subgraph problem, which aims to find a dense subgraph from a mention-entity graph such that the subgraph contains all mentions and one mention-entity edge for each mention according to their definition of graph den-sity. Han and Sun [9] combine the local compatibility and global coherence using a generative entity-topic model to in-fer the underlying referent entities. Also through a genera-tive graphical model, Li et al. [17] propose to mine additional information for entities from external corpus, which can help improve the effectiveness of entity linking, especially for en-tities with rare information available in the knowledge base.
The approach closest to ours is that of Han et. al [10], which uses a random walk with restart to obtain a vector of relevance for all candidates of mentions, and considers the relevance value in the vector to be the relatedness be-tween a mention and its candidate. Like other semantic relatedness measures, their measure can only compute the relatedness between two entities. Instead, we use a unified semantic representation for both documents and entities. As a result, we can measure the coherence between entities and between entities and documents in a unified way. Also our representation can capture the semantics of unpopular enti-ties, which makes our EL approach more robust for datasets with less popular entities. The idea of using random walk with restart has been applied on graphs constructed from the WordNet [19], with the stationary distribution to represent the semantics of words. It has been shown to be effective in the word similarity measurement [1, 14], and word sense disambiguation [22]. However, we are not aware of any pre-vious work using the stationary distribution from random walk with restart to represent entities and documents in en-tity linking.
Entity linking mainly involves measuring the compatibil-ity and semantic relatedness between mentions and entities, for which the semantic representation plays a critical role. The lexical and statistical features used in traditional lo-cal approaches are limited by the feature sparsity issue and cannot capture the semantics of entities. Recently proposed keyphrase and link-based representations provide richer fea-ture sets for popular entities, but are still challenged for less popular ones. In this work, we proposed the use of the probability distribution resulting from a random walk with restart over a suitable entity graph to represent the seman-tics of entities and documents in a unified way. Our semantic representation uses all relevant entities from the knowledge base as features, thus reducing the effect of feature spar-sity. Also the random walk with restart helps capture the semantics of unpopular entities from the entity graph.
Our experimental evaluation compared our method to 6 leading competitor systems and 2 very strong baselines, re-vealing the superiority and robustness of our entity linking system in a variety of settings, including 4 public bench-marks. Our method was particularly stronger when disam-biguating unpopular entities, making it a good candidate to address the  X  X ong tail X  in Information Extraction.
 exist. First, several disambiguation mistakes are still pos-sible. For instance, when we have two Miami s in the same sentence, one referring to the city in Florida and the other to Miami Dolphins , our method might mistakenly link both to the same entity. In this case, simple type information like location and sports team , which are provided by named en-tity recognition systems can help with the disambiguation. Combining our current approach with typing information or other kinds of constraints would help advance the field.
Our system performs multiple random walk computations, making it time consuming if implemented naively, as in our current implementation. On a standard entry-level server, the average time to disambiguate a document in our bench-marks (in the order of tens of mentions) is in the order of a few minutes. Therefore, designing proper system infras-tructure with the appropriate indexes and/or parallel com-puting infrastructure to optimize these computations would be interesting. Moreover, other state-of-the-art systems per-form other expensive operations as well, such as accessing the Web. Thus, designing objective and fair benchmarks for comparing these different approaches in a more holistic way would be of great value.

Finally, our approach, like most other systems, has many application-specific parameters (recall Section 2) and de-pends on specific similarity measures (e.g., to filter candi-date entities). Further studies are needed to understand how the accuracy of our approach is affected by the choice of similarity measures and configuration of parameters. This work was supported in part by grants from the Natu-ral Sciences and Engineering Council of Canada, through its Business Intelligence Network, and Alberta Innovates Tech-nology Futures. [1] E. Agirre, E. Alfonseca, K. Hall, J. Kravalova, [2] A. Bagga and B. Baldwin. Entity-based [3] R. C. Bunescu and M. Pas , ca. Using encyclopedic [4] Z. Cai, K. Zhao, K. Q. Zhu, and H. Wang.
 [5] X. Cheng and D. Roth. Relational inference for [6] S. Cucerzan. Large-scale named entity disambiguation [7] M. Dredze, P. McNamee, D. Rao, A. Gerber, and [8] Z. Guo and D. Barbosa. Entity linking with a unified [9] X. Han and L. Sun. An entity-topic model for entity [10] X. Han, L. Sun, and J. Zhao. Collective entity linking [11] T. H. Haveliwala. Topic-sensitive pagerank: A [12] J. Hoffart, S. Seufert, D. B. Nguyen, M. Theobald, and [13] J. Hoffart, M. A. Yosef, I. Bordino, H. F  X  urstenau, [14] T. Hughes and D. Ramage. Lexical semantic [15] H. Ji and R. Grishman. Knowledge base population: [16] S. Kulkarni, A. Singh, G. Ramakrishnan, and [17] Y. Li, C. Wang, F. Han, J. Han, D. Roth, and X. Yan. [18] R. Mihalcea and A. Csomai. Wikify!: linking [19] G. A. Miller. Wordnet: A lexical database for english. [20] D. Milne and I. H. Witten. An effective, low-cost [21] D. Milne and I. H. Witten. Learning to link with [22] M. T. Pilehvar, D. Jurgens, and R. Navigli. Align, [23] L.-A. Ratinov, D. Roth, D. Downey, and M. Anderson. [24] H. Tong, C. Faloutsos, and J.-Y. Pan. Fast random [25] W. Zhang, Y. C. Sim, J. Su, and C. L. Tan. Entity [26] W. Zhang, J. Su, C. L. Tan, and W. Wang. Entity [27] Y. Zhou, L. Nie, O. Rouhani-Kalleh, F. Vasile, and
