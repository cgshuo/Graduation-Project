 In recent years, there has been a dr amatic proliferation of research on information retrieval based on highly subjective concepts such as emotion, preference and aesthe tic. Such retrieval methods are fascinating but challenging since it is difficult to built a general retrieval model that performs equally well to everyone. In this paper, we propose two novel met hods, bag-of-users model and residual modeling, to accommodate the individual differences for emotion-based music retrieval. The proposed methods are intuitive and generally applicable to other information retrieval tasks that involve subjective pe rception. Evaluation result shows the effectiveness of the proposed methods. Information Search and Retrieva l: Retrieval Models; H.5.5 Sound and Music Computing: Systems, Modeling General Terms: Algorithms, Performance, Human Factors Keywords: personalization, emotion, perceptual residual Due to the explosive growth of digital data, innovative multimedia retrieval methods based on highly subjective concepts such as emotion [1], preference [2] and aesthetic [3] emerge as an alter-native of conventional keyword-based methods. For example, a music emotion recognition (MER) system estimates the affective content of music signals so that a user can retrieve songs of certain desired emotions. Such a retrieval method is fascinating because it is content-centric and functionally powerful. However, because human perception is intrinsically subjective, developing a general retrieval m odel that performs equally well for everyone can be very challenging. For example, each circle in Figure 1 corresponds to the annotation of a subject for a song over the 2D emotion plane, which defi nes emotion in terms of valence (how positive and negative) and arousal (how high and low) [4]. Evidently, simply assigning one emotion value to each song in a deterministic manner does not perform well in practice because the emotion perception varies greatly from person to person. In this paper, two novel methods, bag-of-users model and residual modeling, are proposed to accommodate the individual differences in subjective emotion perception. A personalized MER system is built and evaluated to showcase th e effectiveness of the proposed methods. We differentiate the following two MER problems: z General recognition: Given a song s i , recognize the emotion z Personalized recognition: Given a song s i and a user u Despite that the subjective nature of emotion is well recognized, most previous works on MER only address the general recognition. In [1], emotion recognition is fo rmulated as a regression problem. i th song s i , and y i  X  [  X 1,1] is the emotion value obtained by averaging the annotations of subj ects, a general regression model M ( X ) is trained by minimizing the squared error between y M ( x i ), where M ( x i ) is the recognition result for s method as the baseline in this paper. 1 A schematic diagram of the pers onalize MER system is shown in Figure 2. To improve general recognition, we propose the bag-of-users model (BoU) to better utilize the annotations collected from subjective test. To make personali zed recognition, we develop the residual modeling (RM) method based on the novel notion of perception residual . These methods are described in detail below. The ground truth data needed for training a retrieval model is typically obtained by averaging the opinions of subjects. This procedure, however, makes little use of the individual annotations assigned by each subject, which may provide abundant cues of the perception of a song. Figure 1(c) illustrates that simply averaging annotations loses the information that the human perception of the song is nearly bi-modal. In the bag-of-users model, we train a regression model M each subject u j using his/her annotations and obtain a bag of subjects. We then aggregate the models using a super regression Figure 1. Emotion annotation s in the 2D valence-arousal emotion plane [4] for four songs: (a) Smells like teen spirit by Nirvana, (b) A whole new wo rld by Peabo Bryson and Regina Belle, (c) The rose by Janis Joplin, (d) Tell Laura I love her by Ritchie Valens. Each circle corresponds to the annotation of a subject. model to make general recognition. Let  X  i =[  X  i1 ,  X  i2 vector of the recognition results for s i , where  X  ij = M super model M * ( X ) by minimizing the error between y The estimate M * (  X  i ) can be regarded as the aggregation of the opinions of the U subjects. Given the general perception y i of a song s i perception residual of a user u j as the difference between the general perception and the personalized one, r ij = y ij personalized recognition can be deco mposed into the recognition of the general perception y i and the perception residual r is more related to the content of the music sample, while the latter is more related to the user. The recognition of perception resi dual is called residual modeling. number of songs  X  and use the annotations to train a personalized model M z ( X ) that minimizes the error between r iz The personalized emotion is then computed by y iz we use the bag-of-users model to recognize general perception. The music database consists of 60 popular songs from English albums. 99 subjects are recruited from the campus, making each song annotated by 40 subjects. Each song is represented by 80-dimension Mel-frequency cepstral coefficients X  X  widely-used feature representation for audio signal processing [5]. Support vector regression (SVR) is adopted to train the regression models. Our implementation of SVR is based on the library LIBSVM [6]. A standard measure of the goodness of fit for a regression model is the squared sample correlation coefficient R 2 between the ground truth and the estimated ones [7]. The value of R 2 ranges from 0 to 1; an R of 1.0 means perfect fit. For general recognition, we compare the performance of the bag-of-users model against the baseline m odel described in Section 2. We randomly select 10 songs as the test data and the remaining ones as training data. The overall procedure is repeated 1000 times to get the averaged result. While the R 2 of arousal is both around 0.70, the bag-of-users model improves the R 2 of valence from 0.149 to 0.158, a 6.4% relative improvement. Table 1. Accuracy ( R 2 ) of personalized valence recognition 
BoU+RM 0.1724* 0.1758* 0.1788* 0.1816* To evaluate personalized recognition, we use the 6 subjects who have annotated all the 60 songs as test users and the remaining ones as training users. The annotations of a test user u selected songs are used to train a personalized model M annotations of the same user for another 10 songs are used to evaluate M z ( X ). The result of the personalized valence recognition with varying numbers of |  X  | is shown in Table 1, with each star denoting a significant improvement over the baseline model at the  X  =0.01 significance level . It can be found that the proposed methods indeed improve personalized recognition. When |  X  | is small, the combination of BoU and RM performs the best; a 7.5% relative improvement is achieved with only |  X  |=10 user inputs. Besides, the performance of RM increases as the number of |  X  | increases. When |  X  | is large, RM starts to outperform BoU+RM. A 12.2% relative improvement is obtained when |  X  |=30. As for arousal, the baseline model and the personalized mode l produce similar results (about perception of arousal is much less subjective than that of valence [1]. We have presented two methods to accommodate individual differences for subjective concep t-based information retrieval systems. The bag-of-users model pr ovides a better way to aggre-gate the individual perceptions of the subjects, while the residual modeling makes a personalized syst em focus on music content and user perception in different stages. The novel perspectives introduced in this paper can be applied to other applications that involve subjective human perception. This work was supported by the National Science Council of Taiwan under contract number NSC 97-2221-E-002-111-MY3. [1] Y.-H. Yang et al,  X  X  regression approach to music emotion [2] A. S. Harpale and Y.-M. Yang,  X  X ersonalized active learning [3] C. Dorai et al,  X  X omputational media aesthetics: finding [4] R. E. Thayer, The Biopsychology of Mood and Arousal, New [5] M. A. Casey et al,  X  X ontent-based music information retrieval: [6] C.-C. Chang and C.-J. Lin,  X  X IBSVM: a library for support [7] A. Sen and M. Srivastava, Regression Analysis: Theory, Figure 2. A schematic diagram of the personalized system.
